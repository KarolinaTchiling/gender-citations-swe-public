FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Avola, D
   Cinque, L
   Foresti, GL
   Marini, MR
AF Avola, Danilo
   Cinque, Luigi
   Foresti, Gian Luca
   Marini, Marco Raoul
TI A novel low cybersickness dynamic rotation gain enhancer based on
   spatial position and orientation in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual locomotion technique; Reorientation; Dynamic rotation gain; User
   experience; Human-computer interaction
ID MOTION SICKNESS; POSTURAL INSTABILITY; REALITY; WALKING; LOCOMOTION;
   CAVE
AB Hardware and software resources nowadays make possible new Virtual Reality (VR) interaction methods. Numerous challenges have been involved over the years, and one of the most interesting is locomotion in virtual environments. In particular, Real Walking (RW) is one of the most effective Virtual Locomotion Techniques (VLT). It causes only reduced cybersickness, but it also requires proportional real walkable space to the virtual one, often requiring wide areas. In this context, optimization techniques have been proposed in the literature, e.g., reorientation or relocation. In this work, a novel method for improving reorientation in a virtual environment, exploiting a dynamic Rotation Gain Multiplication Factor (RGMF) based on the competence of the user in VR systems usage is proposed. The results highlight the effectiveness of the system and show the specific target of users that mainly appreciated it.
C1 [Avola, Danilo; Cinque, Luigi; Marini, Marco Raoul] Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00199 Rome, Italy.
   [Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
C3 Sapienza University Rome; University of Udine
RP Marini, MR (corresponding author), Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00199 Rome, Italy.
EM avola@di.uniroma1.it; cinque@di.uniroma1.it; gianluca.foresti@uniud.it;
   marini@di.uniroma1.it
RI Marini, Marco Raoul/AAR-5812-2021
OI Marini, Marco Raoul/0000-0002-2540-2570
FU This work was supported by the "Smart unmannEd AeRial vehiCles for Human
   likE monitoRing (SEARCHER)" project of the Italian Ministry of Defence
   (CIG: Z84333EA0D) and the research leading to these results has received
   funding from Project "Ecosistema dell'i [CIG: Z84333EA0D]; (SEARCHER)"
   project of the Italian Ministry of Defence; Ecosistema dell'innovazione
   - Rome Technopole [1051 23.06.2022 - CUP H33C22000420001]; EU
FX This work was supported by the "Smart unmannEd AeRial vehiCles for Human
   likE monitoRing (SEARCHER)" project of the Italian Ministry of Defence
   (CIG: Z84333EA0D) and the research leading to these results has received
   funding from Project "Ecosistema dell'innovazione - Rome Technopole"
   financed by EU in NextGenerationEU plan through MUR Decree n. 1051
   23.06.2022 - CUP H33C22000420001.
CR Ajay S., 2014, International Journal of economics, commerce and management, P1
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Al-Sada M, 2020, VIRTUAL REAL-LONDON, V24, P191, DOI 10.1007/s10055-019-00404-x
   [Anonymous], 1975, Motion sickness
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Avila L, 2014, IEEE COMPUT GRAPH, V34, P103, DOI 10.1109/MCG.2014.103
   Avola D, 2019, J BIOMED INFORM, V89, P81, DOI 10.1016/j.jbi.2018.11.012
   Avola D, 2018, MULTIMED TOOLS APPL, V77, P24955, DOI 10.1007/s11042-018-5730-1
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Burdea GC, 1999, IEEE T ROBOTIC AUTOM, V15, P400, DOI 10.1109/70.768174
   Cardoso JCS, 2019, COMPUT GRAPH-UK, V85, P55, DOI 10.1016/j.cag.2019.09.005
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cohen AR, 2013, CHILD NERV SYST, V29, P1235, DOI 10.1007/s00381-013-2139-z
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Fussell Stephanie G., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P2303, DOI 10.1177/1071181319631494
   Gálvez-García G, 2015, HUM FACTORS, V57, P649, DOI 10.1177/0018720814554948
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Han D., 2019, Augmented Reality and Virtual Reality - The Power of AR and VR for Business, P113, DOI [DOI 10.1007/978-3-030-06246-09, 10.1007/978-3-030-06246-0_9, DOI 10.1007/978-3-030-06246-0_9]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217808
   Kourtesis P., 2023, Virtual Worlds, V2, P16, DOI [DOI 10.3390/VIRTUALWORLDS2010002, 10.3390/virtualworlds2010002]
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee H, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103229
   Li HY, 2020, IEEE ACCESS, V8, P180210, DOI 10.1109/ACCESS.2020.3027985
   Liang ZP, 2019, IEEE ACCESS, V7, P118639, DOI 10.1109/ACCESS.2019.2934990
   Liu HR, 2018, I C VIRTUAL REALITY, P150, DOI 10.1109/ICVRV.2018.00052
   Llobera J, 2019, IEEE T GAMES, V11, P311, DOI 10.1109/TCIAIG.2017.2755699
   MARTINEZGONZALE.P, 2019, VIRTUAL REAL-LONDON, P1, DOI DOI 10.1007/S10055-019-00399-5
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Ng AKT, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.08.004
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Prinz LM, 2023, IEEE T VIS COMPUT GR, V29, P5208, DOI 10.1109/TVCG.2022.3206915
   Raaen K, 2015, LECT NOTES COMPUT SC, V9353, P457, DOI 10.1007/978-3-319-24589-8_40
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Rangelova S, 2020, ADV INTELL SYST COMP, V973, P192, DOI 10.1007/978-3-030-20476-1_20
   Razzaque S., 2005, REDIRECTED WALKING
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Ren Aizhu, 2008, Tsinghua Science and Technology, V13, P674, DOI 10.1016/S1007-0214(08)70107-X
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Sprent P., 2016, APPL NONPARAMETRIC S, DOI [10.1201/b15842, DOI 10.1201/B15842]
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Sudman S., 1976, APPL SAMPLING
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Turolla A, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-85
   Viglialoro RM, 2019, IEEE T BIO-MED ENG, V66, P2091, DOI 10.1109/TBME.2018.2883816
   Wang QY, 2020, IEEE T AUTOM SCI ENG, V17, P799, DOI 10.1109/TASE.2019.2945607
   Warwick-Evans LA, 1998, BRAIN RES BULL, V47, P465, DOI 10.1016/S0361-9230(98)00090-2
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Ye XZ, 2020, IEEE T LEARN TECHNOL, V13, P340, DOI 10.1109/TLT.2019.2913408
   Zhang R., 2013, Proc. Proceedings of the ACM Symposium on Applied Perception (SAP), P71
NR 69
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3191
EP 3209
DI 10.1007/s10055-023-00865-1
EA OCT 2023
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001091528100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Evans, JO
   Tsaneva-Atanasova, K
   Buckingham, G
AF Evans, Jack Owen
   Tsaneva-Atanasova, Krasimira
   Buckingham, Gavin
TI Using immersive virtual reality to remotely examine performance
   differences between dominant and non-dominant hands
SO VIRTUAL REALITY
LA English
DT Article
DE Meta Quest; Dominant hand; Non-dominant hand; Assessment; Stroke; Upper
   limb
ID REACH-TO-GRASP; OUTCOME MEASURES; COORDINATION DYNAMICS; BIMANUAL
   COORDINATION; MANUAL ASYMMETRIES; BLOCK TEST; STROKE; MOVEMENT; ARM;
   TASK
AB Circle drawing may be a useful task to study upper-limb function in patient populations. However, previous studies rely on expensive and bulky robotics to measure performance. For clinics or hospitals with limited budgets and space, this may be unfeasible. Virtual reality (VR) provides a portable and low-cost tool with integrated motion capture. It offers potentially a more feasible medium by which to assess upper-limb motor function. Prior to use with patient populations, it is important to validate and test the capabilities of VR with healthy users. This study examined whether a VR-based circle drawing task, completed remotely using participant's own devices, could capture differences between movement kinematics of the dominant and non-dominant hands in healthy individuals. Participants (n = 47) traced the outline of a circle presented on their VR head-mounted displays with each hand, while the positions of the hand-held controllers were continuously recorded. Although there were no differences observed in the size or roundness of circles drawn with each hand, consistent with prior literature our results did show that the circles drawn with the dominant hand were completed faster than those with the non-dominant hand. This provides preliminary evidence that a VR-based circle drawing task may be a feasible method for detecting subtle differences in function in clinical populations.
C1 [Evans, Jack Owen; Buckingham, Gavin] Univ Exeter, Dept Publ Hlth & Sport Sci, Richards Bldg,Magdalen Rd, Exeter EX2 4TA, Devon, England.
   [Tsaneva-Atanasova, Krasimira] Univ Exeter, Living Syst Inst, Dept Math & Stat, Exeter EX4 4QD, Devon, England.
   [Tsaneva-Atanasova, Krasimira] Univ Exeter, EPSRC Hub Quantitat Modelling Healthcare, Exeter EX4 4QD, Devon, England.
C3 University of Exeter; University of Exeter; University of Exeter
RP Evans, JO (corresponding author), Univ Exeter, Dept Publ Hlth & Sport Sci, Richards Bldg,Magdalen Rd, Exeter EX2 4TA, Devon, England.
EM je426@exeter.ac.uk; K.Tsaneva-Atanasova@exeter.ac.uk;
   G.Buckingham@exeter.ac.uk
OI Tsaneva-Atanasova, Krasimira/0000-0002-6294-7051
FU EPSRC [EP/T017856/1]
FX AcknowledgementsWe would like to thank all of our participants for
   taking the time to complete the study, and all of those who showed an
   interest in the work while it was being advertised. JE would also like
   to thank his co-authors and his partner for their continuous support
   throughout this work. KTA gratefully acknowledges the financial support
   of the EPSRC via grant EP/T017856/1.
CR Abdlkarim D, 2022, BIORXIV, DOI [10.1101/2022.02.18.481001, DOI 10.1101/2022.02.18.481001]
   Alt Murphy M, 2017, EXP BRAIN RES, V235, P3295, DOI 10.1007/s00221-017-5058-5
   Alt Murphy M, 2015, BMC NEUROL, V15, DOI 10.1186/s12883-015-0292-6
   Alt Murphy M, 2011, NEUROREHAB NEURAL RE, V25, P71, DOI 10.1177/1545968310370748
   Alves T, 2022, FRONT ROBOT AI, V9, DOI 10.3389/frobt.2022.739088
   ANNETT J, 1979, Q J EXP PSYCHOL, V31, P641, DOI 10.1080/14640747908400755
   [Anonymous], ACT RES ARM TEST KIT
   Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131
   Arthur T, 2021, CORTEX, V138, P318, DOI 10.1016/j.cortex.2021.02.013
   Bagesteiro LB, 2002, J NEUROPHYSIOL, V88, P2408, DOI 10.1152/jn.00901.2001
   Bagesteiro LB, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.554378
   Bank PJM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1100-9
   Batmaz AU, 2020, 26 ACM S VIRTUAL REA, P1, DOI [10.1145/3385956.3418971, DOI 10.1145/3385956.3418971]
   Blank R, 2019, DEV MED CHILD NEUROL, V61, P242, DOI 10.1111/dmcn.14132
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Bryden PJ, 2007, LATERALITY, V12, P364, DOI 10.1080/13576500701356244
   Buckingham G, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01587
   Buckingham G, 2009, EXP BRAIN RES, V194, P197, DOI 10.1007/s00221-008-1689-x
   Byblow WD, 1999, HUM MOVEMENT SCI, V18, P281, DOI 10.1016/S0167-9457(99)00012-3
   Carson RG, 1997, Q J EXP PSYCHOL-A, V50, P664, DOI 10.1080/713755721
   Catz A, 1997, SPINAL CORD, V35, P850, DOI 10.1038/sj.sc.3100504
   Chen ZJ, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.660015
   Cidota MA, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P144, DOI 10.1109/ISMAR.2017.31
   Coderre AM, 2010, NEUROREHAB NEURAL RE, V24, P528, DOI 10.1177/1545968309356091
   Desrosiers J, 2003, CLIN REHABIL, V17, P666, DOI 10.1191/0269215503cr662oa
   Dipietro L, 2007, J NEUROPHYSIOL, V98, P757, DOI 10.1152/jn.01295.2006
   Eastough D, 2007, EXP BRAIN RES, V176, P193, DOI 10.1007/s00221-006-0749-3
   ELLIOTT D, 1993, CAN J EXP PSYCHOL, V47, P570, DOI 10.1037/h0078856
   Everard G, 2022, J NEUROENG REHABIL, V19, DOI 10.1186/s12984-022-00981-0
   FRANKS IM, 1990, HUM MOVEMENT SCI, V9, P573, DOI 10.1016/0167-9457(90)90017-8
   Fransson PA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39104-6
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P30, DOI 10.1037/a0026092
   FUGLMEYER AR, 1975, SCAND J REHABIL MED, V7, P13
   Gagnon C, 2014, J NEUROL SCI, V347, P341, DOI 10.1016/j.jns.2014.09.032
   Harrison JK, 2013, CLIN INTERV AGING, V8, P201, DOI 10.2147/CIA.S32405
   Hobart JC, 2007, LANCET NEUROL, V6, P1094, DOI 10.1016/S1474-4422(07)70290-9
   Holzwarth V., 2021, 5 INT C VIRT AUGM RE, DOI [10.1145/3463914.3463921, DOI 10.1145/3463914.3463921]
   Hsueh IP, 2002, CLIN REHABIL, V16, P617, DOI 10.1191/0269215502cr530oa
   Hunt J, 2021, CHILD CARE HLTH DEV, V47, P174, DOI 10.1111/cch.12824
   Jette DU, 2009, PHYS THER, V89, P125, DOI 10.2522/ptj.20080234
   Johansson GM, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0479-y
   JORGENSEN HS, 1995, ARCH PHYS MED REHAB, V76, P399, DOI 10.1016/S0003-9993(95)80567-2
   Jorgensen HS., 2000, TOPICS STROKE REHABI, V6, P1, DOI DOI 10.1310/BT7J-2N6U-VD53-E1QU
   Jung B, 2020, HCI INT 2020 22 INT, P19, DOI DOI 10.1007/978-3-030-50726-8_3
   Krabben T, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-15
   Krebs HI, 2012, NEUROREHAB NEURAL RE, V26, P855, DOI 10.1177/1545968311433427
   Kwakkel G, 2017, NEUROREHAB NEURAL RE, V31, P784, DOI 10.1177/1545968317732662
   Lamers I, 2013, DISABIL REHABIL, V35, P2016, DOI 10.3109/09638288.2013.771703
   Laparidou D, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00976-3
   Lawrence ES, 2001, STROKE, V32, P1279, DOI 10.1161/01.STR.32.6.1279
   Lewis GN, 2004, J MOTOR BEHAV, V36, P174, DOI 10.3200/JMBR.36.2.174-188
   Lodha N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083468
   Mansfield A, 2011, CLIN BIOMECH, V26, P312, DOI 10.1016/j.clinbiomech.2010.10.001
   Mao Y, 2015, IEEE T NEUR SYS REH, V23, P84, DOI 10.1109/TNSRE.2014.2329018
   MATHIOWETZ V, 1985, AM J OCCUP THER, V39, P386, DOI 10.5014/ajot.39.6.386
   Melim A, 2022, OPTIMIZING OCULUS IN
   Mieschke PE, 2001, BRAIN COGNITION, V45, P129, DOI 10.1006/brcg.2000.1262
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nouredanesh M, 2019, INT C REHAB ROBOT, P1221, DOI [10.1109/ICORR.2019.8779461, 10.1109/icorr.2019.8779461]
   Oliveira LF, 1996, PHYSIOL MEAS, V17, P305, DOI 10.1088/0967-3334/17/4/008
   Pedersen AV, 2003, EXP BRAIN RES, V149, P249, DOI 10.1007/s00221-003-1373-0
   Persson HC, 2012, BMC NEUROL, V12, DOI 10.1186/1471-2377-12-162
   Pfann KD, 2002, J NEUROPHYSIOL, V88, P2399, DOI 10.1152/jn.00946.2001
   Platz T, 2005, CLIN REHABIL, V19, P404, DOI 10.1191/0269215505cr832oa
   Potter K, 2011, J NEUROL PHYS THER, V35, P57, DOI 10.1097/NPT.0b013e318219a51a
   Professional, PROF BOX BLOCK TEST
   Repp BH, 2011, HUM MOVEMENT SCI, V30, P18, DOI 10.1016/j.humov.2010.09.002
   Sachlikidis A, 2007, SPORT BIOMECH, V6, P334, DOI 10.1080/14763140701491294
   Sainburg RL, 2002, EXP BRAIN RES, V142, P241, DOI 10.1007/s00221-001-0913-8
   Schaffer JE, 2017, NEUROSCIENCE, V350, P54, DOI 10.1016/j.neuroscience.2017.03.025
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Schwarz A, 2020, IEEE T BIO-MED ENG, V67, P1684, DOI 10.1109/TBME.2019.2942974
   Schwarz A, 2019, STROKE, V50, P718, DOI 10.1161/STROKEAHA.118.023531
   Shirota C, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0519-7
   Southard D, 2006, RES Q EXERCISE SPORT, V77, P316
   Subramanian SK, 2010, STROKE, V41, P2303, DOI 10.1161/STROKEAHA.110.593368
   Sullivan JE, 2013, PHYS THER, V93, P1383, DOI 10.2522/ptj.20120492
   Sullivan JE, 2011, J NEUROL PHYS THER, V35, P65, DOI 10.1097/NPT.0b013e31821a24eb
   Summers JJ, 2008, HUM MOVEMENT SCI, V27, P823, DOI 10.1016/j.humov.2007.11.003
   Tan C, 2012, NEUROREHAB NEURAL RE, V26, P957, DOI 10.1177/1545968312437938
   Temporiti F, 2023, J HAND THER, V36, P560, DOI 10.1016/j.jht.2022.01.007
   Tomczak M., 2014, NEED REPORT EFFECT S, DOI DOI 10.1186/S13054-016-1208-6
   Tseng YW, 2005, ACTA PSYCHOL, V120, P172, DOI 10.1016/j.actpsy.2005.04.001
   Tua L., 2019, J MILITARY TECHNOLOG, V2, P17, DOI [10.32754/jmt.2019.2.03, DOI 10.32754/JMT.2019.2.03]
   van Kordelaar J, 2012, EXP BRAIN RES, V221, P251, DOI 10.1007/s00221-012-3169-6
   Veale JF, 2014, LATERALITY, V19, P164, DOI 10.1080/1357650X.2013.783045
   Vitterso AD, 2021, CORTEX, V140, P157, DOI 10.1016/j.cortex.2021.03.028
   Voigt-Antons JN, 2020, ARXIV
   Vuillermot S, 2009, J NEUROSCI METH, V177, P452, DOI 10.1016/j.jneumeth.2008.10.018
   WANN J, 1988, J EXP PSYCHOL HUMAN, V14, P622, DOI 10.1037/0096-1523.14.4.622
   Wilson BN, 2013, CHILD CARE HLTH DEV, V39, P296, DOI 10.1111/j.1365-2214.2012.01403.x
   Xiao X, 2019, MATH BIOSCI ENG, V16, P1611, DOI 10.3934/mbe.2019077
   Zollo L, 2011, MED BIOL ENG COMPUT, V49, P1131, DOI 10.1007/s11517-011-0808-1
NR 94
TC 2
Z9 2
U1 2
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2211
EP 2226
DI 10.1007/s10055-023-00794-z
EA MAY 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000982374200001
PM 37360802
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kang, DS
   Lee, CG
   Kwon, O
AF Kang, Daeseok
   Lee, Chang-Gyu
   Kwon, Ohung
TI Pneumatic and acoustic suit: multimodal haptic suit for enhanced virtual
   reality simulation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Haptics; Wearable; Pneumatic actuation; Acoustic
   vibration; Human computer interaction
ID DISPLAY
AB A haptic device provides users with physical feedback to enhance their experience in virtual reality (VR). We developed a multimodal haptic suit, called as Pneumatic and Acoustic (PA) suit, which exhibits high-resolution haptic feedback, and applies high pressure and realistic vibration to a user. The PA suit artificially simulates the sensation of brief and strong collisions such as the impact of an explosion, ball, or fist. The pneumatic actuators, consisting of 40 air bladders, are designed as bellows-type pneumatic devices for vertical inflation. The air bladders are placed on the chest at an equal interval distance of 30 mm for high-resolution feedback. The acoustic actuators use an effective sound signal of a collision similar to realistic vibrations. This study aims to examine the effectiveness of our multimodal haptic suit in improving VR experience of users. The recognition tests clearly show that participants distinguish between the haptic patterns and position of collided virtual objects with the suit. The user study involving a collision of a ball shows that the PA suit transmits the approximate pressure of a real ball collision with artificial haptic feedback. Our receiving ball and explosion VR simulations confirm that the PA suit improves a VR experience depending on the types of actuators and VR contents. The results prove that the PA suit creates distinguishable haptic patterns for guiding a task and improves the VR experience of users with powerful and multimodal haptic feedback hence providing high-quality VR simulation.
C1 [Kang, Daeseok; Lee, Chang-Gyu; Kwon, Ohung] Korea Inst Ind Technol KITECH, Digital Transformat R&D Dept, Ansan, Gyeonggi Do, South Korea.
   [Kang, Daeseok; Kwon, Ohung] Univ Sci & Technol UST, Robot, Daejeon, South Korea.
C3 Korea Institute of Industrial Technology (KITECH); University of Science
   & Technology (UST)
RP Kwon, O (corresponding author), Korea Inst Ind Technol KITECH, Digital Transformat R&D Dept, Ansan, Gyeonggi Do, South Korea.; Kwon, O (corresponding author), Univ Sci & Technol UST, Robot, Daejeon, South Korea.
EM kds60513@kitech.re.kr; cglee@kitech.re.kr; ohung@kitech.re.kr
OI Lee, Chang-Gyu/0000-0002-7500-1150; Kang, Daeseok/0000-0002-0611-1954
CR Al-Sada M, 2020, VIRTUAL REAL-LONDON, V24, P191, DOI 10.1007/s10055-019-00404-x
   ARAIG, 2013, AC DEV VR
   Barreiros J, 2019, IEEE ROBOT AUTOM LET, V4, P277, DOI 10.1109/LRA.2018.2888628
   DALZIEL CF, 1956, IRE T MED ELECTRON, P44, DOI 10.1109/IRET-ME.1956.5008573
   Delazio A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173894
   Dementyev A., 2020, Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, UIST'20, (New York, NY, USA), P420
   Foo EW, 2019, IEEE INT SYM WRBL CO, P54, DOI 10.1145/3341163.3347732
   Franceschi M, 2017, IEEE T HAPTICS, V10, P162, DOI 10.1109/TOH.2016.2618377
   Furukawa T, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338569
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Germani M, 2013, INT J ADV MANUF TECH, V68, P2185, DOI 10.1007/s00170-013-4832-1
   Guenther S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376195
   Gunther Sebastian, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382916
   Hirayama R, 2019, NATURE, V575, P320, DOI 10.1038/s41586-019-1739-5
   Holbert RL, 2007, J BROADCAST ELECTRON, V51, P20, DOI 10.1080/08838150701308002
   Ida N., 2014, Sensors, Actuators, and Their Interfaces: A MultidisciplinaryIntroduction
   Israr A, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641570
   Jain D, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P729, DOI 10.1145/2984511.2984519
   Kang H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P699, DOI [10.1109/vr.2019.8798251, 10.1109/VR.2019.8798251]
   Konishi Y, 2018, LECT NOTES ELECTR EN, V432, P499, DOI 10.1007/978-981-10-4157-0_84
   KOR-FX, 2014, AC DEV VR
   Lemmens P, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P7, DOI 10.1109/WHC.2009.4810832
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Lindeman RW., 2006, Virtual Reality, V9, P203, DOI [DOI 10.1007/S10055-005-0010-6, 10.1007/s10055-005-0010-6]
   Liu C., 2014, J SENS TECHNOL, V4, P66, DOI [10.4236/jst.2014.42008, DOI 10.4236/jst.2014.42008]
   McGregor C, 2017, IEEE INT CONF SERIOU
   Microsoft, 2018, VIS BAS NET IS MULT
   Mun S, 2018, IEEE T HAPTICS, V11, P15, DOI 10.1109/TOH.2018.2805901
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Prada R, 2009, VIRTUAL REAL-LONDON, V13, P117, DOI 10.1007/s10055-009-0115-4
   R Core Team, 2017, R IS LANG ENV STAT C
   Raitor M., 2017, 2017 IEEE Int. Conf. Robotics and Automation (ICRA), P427, DOI DOI 10.1109/ICRA.2017.7989055
   Sauvet B, 2017, MECHATRONICS, V45, P100, DOI 10.1016/j.mechatronics.2017.06.006
   Schaack S, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311840
   Schacher L, 2011, SENSORY PHYSIOLOGICA, P153, DOI [10.5772/25244, DOI 10.5772/25244]
   SELIGMAN ME, 1968, J COMP PHYSIOL PSYCH, V66, P402, DOI 10.1037/h0026355
   Shi YX, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abe2943
   Smets NJJM, 2008, 10 MOB HCI C NEWYORK, DOI [10.1145/1409240.1409249, DOI 10.1145/1409240.1409249]
   TactSuit, 2017, VIBR DEV VR
   TESLASUIT, 2018, EL TACT DEV VR VR EL
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Woojer, 2017, AC DEV VR
   Wu WC, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P193, DOI [10.1109/whc.2019.8816170, 10.1109/WHC.2019.8816170]
   Yang TH, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202008831
   Young EM, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P55, DOI [10.1109/whc.2019.8816075, 10.1109/WHC.2019.8816075]
   Zhao S, 2015, P INT C INT DES CHIL, P239, DOI 10.1145/2771839.2771886
   Zhu MJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376333
NR 49
TC 2
Z9 2
U1 13
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1647
EP 1669
DI 10.1007/s10055-023-00756-5
EA FEB 2023
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000928557700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Xie, T
   Zheng, L
   Liu, GP
   Liu, LP
AF Xie, Tao
   Zheng, Ling
   Liu, Geping
   Liu, Leping
TI Exploring structural relations among computer self-efficacy, perceived
   immersion, and intention to use virtual reality training systems
SO VIRTUAL REALITY
LA English
DT Article
DE Computer self-efficacy; Perceived immersion; Intention to use; VR
   training systems; TAM
ID TECHNOLOGY ACCEPTANCE MODEL; BEHAVIORAL INTENTION; DESK-TOP;
   UNOBSERVABLE VARIABLES; UNIVERSITY-STUDENTS; PRESERVICE TEACHERS;
   EQUATION MODELS; ENVIRONMENTS; GENDER; DETERMINANTS
AB The use of virtual reality (VR) training systems for education has grown in popularity in recent years. Scholars have reported that self-efficacy and interactivity are important predictors of learning outcomes in virtual learning environments, but little empirical research has been conducted to explain how computer self-efficacy (as a subcategory of self-efficacy) and perceived immersion (as a correlate of interactivity) are connected to the intention to use VR training systems. The present study aims to determine which factors significantly influence behavioral intention when students are exposed to VR training systems via an updated technology acceptance frame by incorporating the constructs of computer self-efficacy and perceived immersion simultaneously. We developed a VR training system regarding circuit connection and a reliable and validated instrument including 9 subscales. The sample data were collected from 124 junior middle school students and 210 senior high school students in two schools located in western China. The samples were further processed into a structural equation model with path analysis and cohort analysis. The results showed that the intention to use VR training systems was indirectly influenced by computer self-efficacy but directly influenced by perceived immersion (beta = 0.451). However, perceived immersion seemed to be influenced mostly by learner interaction (beta = 0.332). Among external variables, learner interaction (beta = 0.149) had the largest total effect on use intention, followed by facilitating conditions (beta = 0.138), computer self-efficacy (beta = 0.104), experimental fidelity (beta = 0.083), and subjective norms (beta = 0.077). The moderating roles of gender differences, grade level, and previous experience in structural relations were also identified. The findings of the present study highlight the ways in which factors and associations are considered in the practical development of VR training systems.
C1 [Xie, Tao; Zheng, Ling; Liu, Geping] Southwest Univ, Fac Educ, Chongqing 400715, Peoples R China.
   [Liu, Leping] Univ Nevada, Coll Educ, Reno, NV 89557 USA.
   [Zheng, Ling] Fac Yibin Radio & TV Univ, Yibin, Sichuan, Peoples R China.
C3 Southwest University - China; Nevada System of Higher Education (NSHE);
   University of Nevada Reno
RP Xie, T (corresponding author), Southwest Univ, Fac Educ, Chongqing 400715, Peoples R China.
EM xietao@swu.edu.cn
FU Social Science Planning Foundation of Chongqing [2018BS100]; Fundamental
   Research Funds for the Central Universities [SWU2109320]
FX This document presents the results of the research project funded by the
   Social Science Planning Foundation of Chongqing under grant number
   2018BS100 and the Fundamental Research Funds for the Central
   Universities under grant number SWU2109320.
CR Abali Ozturk Y., 2015, INT J SOCIAL SCI, V31, P343
   Abdullah F, 2016, COMPUT HUM BEHAV, V63, P75, DOI 10.1016/j.chb.2016.05.014
   Agudo-Peregrina AF, 2014, COMPUT HUM BEHAV, V34, P301, DOI 10.1016/j.chb.2013.10.035
   ALJUNDI H, 2022, VIRTUAL REAL-LONDON
   [Anonymous], 2003, VIDEO GAME THEORY RE
   [Anonymous], 2019, PROCEEDINGS, DOI DOI 10.1007/978-3-030-23089-0_2
   Awofala AOA, 2019, DIGIT EDUC REV, P51
   Baki R, 2018, TURK ONLINE J DISTAN, V19, P4
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Bates R, 2007, COMPUT HUM BEHAV, V23, P175, DOI 10.1016/j.chb.2004.04.004
   Bedford D.W., 2005, Empirical investigation of the acceptance and intended use of mobile commerce: Location, personal privacy and trust
   Bertram J, 2015, COMPUT HUM BEHAV, V43, P284, DOI 10.1016/j.chb.2014.10.032
   Bogusevschi D., 2020, J COMPUT MATH SCI TE, V39, P5
   BRECKLER SJ, 1991, J SOC BEHAV PERS, V6, P529
   Çakiroglu Ü, 2019, COMPUT EDUC, V133, P56, DOI 10.1016/j.compedu.2019.01.014
   Sánchez-Prieto JC, 2017, COMPUT HUM BEHAV, V72, P644, DOI 10.1016/j.chb.2016.09.061
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Celik V, 2013, COMPUT EDUC, V60, P148, DOI 10.1016/j.compedu.2012.06.008
   Chang CT, 2017, COMPUT EDUC, V111, P128, DOI 10.1016/j.compedu.2017.04.010
   Chao CM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01652
   Cheng KH, 2020, BRIT J EDUC TECHNOL, V51, P2139, DOI 10.1111/bjet.12956
   Choi B, 2011, COMPUT EDUC, V57, P2382, DOI 10.1016/j.compedu.2011.06.019
   Chow M, 2013, NURS EDUC TODAY, V33, P655, DOI 10.1016/j.nedt.2012.01.009
   Compeau D. R., 1995, Management Information Systems Quarterly, V19, P189, DOI 10.2307/249688
   Concannon BJ, 2019, FRONT EDUC, V4, DOI 10.3389/feduc.2019.00080
   CSIKSZENTMIHALYI M, 1987, J NERV MENT DIS, V175, P526, DOI 10.1097/00005053-198709000-00004
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Davis F.D., 1986, TECHNOLOGY ACCEPTANC
   Eryilmaz M, 2019, INTERACT LEARN ENVIR, V27, P432, DOI 10.1080/10494820.2018.1522652
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fussell S. G., 2020, DISSERTATION
   Fussell SG, 2022, VIRTUAL REAL-LONDON, V26, P249, DOI 10.1007/s10055-021-00554-x
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Hair JF, 2010, Multivariate data analysis
   Hatlevik OE, 2018, COMPUT EDUC, V118, P107, DOI 10.1016/j.compedu.2017.11.011
   He J, 2010, COMMUN ASSOC INF SYS, V26, P225
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Hsia JW, 2014, BEHAV INFORM TECHNOL, V33, P51, DOI 10.1080/0144929X.2012.702284
   Huang CL, 2020, J EDUC COMPUT RES, V58, P596, DOI 10.1177/0735633119867422
   Huang HM, 2018, INT REV RES OPEN DIS, V19, P91
   Huang HM, 2016, INTERACT LEARN ENVIR, V24, P3, DOI 10.1080/10494820.2013.817436
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Hung JC, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.022
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jimenez Z. A., 2019, TECHNOLOGY INTEGRATI, V1318, P31, DOI DOI 10.1021/BK-2019-1318.CH003
   Joo YJ, 2018, EDUC TECHNOL SOC, V21, P48
   Kim P, 2006, INTERACT LEARN ENVIR, V14, P25, DOI 10.1080/10494820600697687
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Laily N., 2019, J ACCOUNTING BUSINES, V3, P141, DOI [10.26675/jabe.v3i2.8166, DOI 10.26675/JABE.V3I2.8166]
   Langerman D, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286182
   Lee DY, 2013, COMPUT EDUC, V61, P193, DOI 10.1016/j.compedu.2012.10.001
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Li R, 2019, COMPUT ASSIST LANG L, V32, P784, DOI 10.1080/09588221.2018.1540433
   Lim JS, 2013, COMPUT HUM BEHAV, V29, P2816, DOI 10.1016/j.chb.2013.07.022
   Lin JW, 2019, AUSTRALAS J EDUC TEC, V35, P163, DOI 10.14742/ajet.4684
   Lin KM, 2011, COMPUT EDUC, V56, P515, DOI 10.1016/j.compedu.2010.09.017
   Lin PH, 2019, INT J HUM-COMPUT INT, V35, P1736, DOI 10.1080/10447318.2019.1571784
   Liu L, 2013, APPL STRUCTURAL EQUA, P75
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Marakas GM, 1998, INFORM SYST RES, V9, P126, DOI 10.1287/isre.9.2.126
   Mcilroy D, 2007, COMPUT HUM BEHAV, V23, P1285, DOI 10.1016/j.chb.2004.12.004
   Merchant Z, 2012, COMPUT EDUC, V59, P551, DOI 10.1016/j.compedu.2012.02.004
   Moos DC, 2009, REV EDUC RES, V79, P576, DOI 10.3102/0034654308326083
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nisha B, 2019, EDUC PSYCHOL-UK, V39, P1233, DOI 10.1080/01443410.2019.1661356
   Norman D.A., 2007, EMOTIONAL DESIGN WHY
   Pande M, 2020, THINK SKILLS CREAT, V36, DOI 10.1016/j.tsc.2020.100637
   Panksepp J, 2017, NEUROSCI BIOBEHAV R, V76, P187, DOI 10.1016/j.neubiorev.2016.09.010
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Pfandler M, 2017, SPINE J, V17, P1352, DOI 10.1016/j.spinee.2017.05.016
   Rangelova Stanislava, 2018, P 17 DRIVING SIMULAT, P209
   Sagnier C, 2019, ADV INTELLIGENT SYST, P305
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Scherer R, 2015, COMPUT HUM BEHAV, V53, P48, DOI 10.1016/j.chb.2015.06.038
   Schiopu AF, 2021, TELEMAT INFORM, V60, DOI 10.1016/j.tele.2021.101575
   Schmitt N, 1996, PSYCHOL ASSESSMENT, V8, P350, DOI 10.1037/1040-3590.8.4.350
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Srisupawong Y, 2018, EDUC INF TECHNOL, V23, P681, DOI 10.1007/s10639-017-9630-1
   Sun JCY, 2012, BRIT J EDUC TECHNOL, V43, P191, DOI 10.1111/j.1467-8535.2010.01157.x
   Surendran Priyanka, 2012, International journal of business and social research, V2, P175, DOI [DOI 10.18533/IJBSR.V2I4.161, 10.1016/j.biortech.2015.06.132, DOI 10.1016/J.BIORTECH.2015.06.132]
   Sutcliffe A, 2016, DESIGNING USER EXPER, P105
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Tarhini A, 2014, J EDUC COMPUT RES, V51, P163, DOI 10.2190/EC.51.2.b
   Teo T, 2019, ETR&D-EDUC TECH RES, V67, P749, DOI 10.1007/s11423-019-09650-x
   Teo T, 2014, J COMPUT HIGH EDUC, V26, P124, DOI 10.1007/s12528-014-9080-3
   Turan Z, 2020, OPEN LEARN, V35, P122, DOI 10.1080/02680513.2019.1691518
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2000, INFORM SYST RES, V11, P342, DOI 10.1287/isre.11.4.342.11872
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Wahyudiati D, 2020, INT J INSTR, V13, P235, DOI 10.29333/iji.2020.13116a
   Wang YF, 2017, BRIT J EDUC TECHNOL, V48, P431, DOI 10.1111/bjet.12388
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wongwatkit C, 2020, J COMPUT EDUC, V7, P229, DOI 10.1007/s40692-020-00154-9
   Yerdelen S, 2019, INT J SCI MATH EDUC, V17, P89, DOI 10.1007/s10763-018-9921-z
   Yesilyurt E, 2016, COMPUT HUM BEHAV, V64, P591, DOI 10.1016/j.chb.2016.07.038
   Zinzow HM, 2018, COGN BEHAV PRACT, V25, P296
   Zydney JM, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103678
NR 101
TC 14
Z9 14
U1 15
U2 69
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1725
EP 1744
DI 10.1007/s10055-022-00656-0
EA JUN 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000810844800001
PM 35730035
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Arlati, S
   Keijsers, N
   Paolini, G
   Ferrigno, G
   Sacco, M
AF Arlati, Sara
   Keijsers, Noel
   Paolini, Gabriele
   Ferrigno, Giancarlo
   Sacco, Marco
TI Kinematics of aimed movements in ecological immersive virtual reality: a
   comparative study with real world
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Kinematics; Movement analysis; Hand dominance
ID UPPER EXTREMITY FUNCTION; VISUAL FEEDBACK; STROKE; REHABILITATION;
   DOMINANT; ENVIRONMENT; HAND; ADULTS; PARTICIPATION; COMPENSATION
AB Virtual reality (VR) has recently emerged as a promising technology to rehabilitate upper limb functions after stroke. To promote the recovery of functions, retraining physiological movement patterns is essential. However, it is still unclear whether VR can elicit functional movements that are similar to those performed in the real world (RW). This study aimed to investigate the kinematics of reach-to-grasp and transport movements performed in the real world and immersive VR by examining whether kinematic differences between the two conditions exist and their extent. A within-subject repeated-measures study was conducted. A realistic setup resembling a supermarket shelf unit was built in RW and VR. The analysis compared reaching and transport gestures in VR and RW, also considering potential differences due to: (i) holding the controller needed to interact with virtual items, (ii) hand dominance, and (iii) target positions. Ten healthy young adults were enrolled in the study. Motion data analysis showed that reach-to-grasp and transport required more time in VR, and that holding the controller had no effects. No major differences occurred between the two hands. Joint angles, except for thorax rotation, and hand trajectory curvature were comparable across conditions, suggesting that VR has the potentialities to retrain physiological movement patterns. Results were satisfying, though they did not demonstrate the superiority of ecological environments in eliciting natural gestures. Further studies should determine the extent of kinematic similarity required to obtain functional gains in VR-based upper limb rehabilitation.
C1 [Arlati, Sara; Sacco, Marco] Italian Natl Res Council, Inst Intelligent Ind Syst & Technol Adv Mfg, I-23900 Lecce, LC, Italy.
   [Arlati, Sara; Ferrigno, Giancarlo] Politecn Milan, Dept Elect Informat & Bioengn, I-20133 Milan, MI, Italy.
   [Keijsers, Noel] Sint Maartensklin, Dept Res Sint Maartenskliniek, NL-6574 NA Ubbergen, Netherlands.
   [Paolini, Gabriele] GPEM Srl, I-07041 Alghero, SS, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Polytechnic University of
   Milan; Sint Maartens Clinic
RP Arlati, S (corresponding author), Italian Natl Res Council, Inst Intelligent Ind Syst & Technol Adv Mfg, I-23900 Lecce, LC, Italy.; Arlati, S (corresponding author), Politecn Milan, Dept Elect Informat & Bioengn, I-20133 Milan, MI, Italy.
EM sara.arlati@stiima.cnr.it
RI Sacco, marco/AAI-3566-2020; Arlati, Sara/P-8502-2018
OI Sacco, marco/0000-0002-5055-4031; ARLATI, SARA/0000-0001-8092-1499
CR Arlati S, 2021, J ALZHEIMERS DIS, V80, P1025, DOI 10.3233/JAD-201431
   Arlati S, 2018, LECT NOTES COMPUT SC, V10850, P133, DOI 10.1007/978-3-319-95270-3_9
   Assi A, 2016, HUM MOVEMENT SCI, V50, P10, DOI 10.1016/j.humov.2016.09.002
   Bagesteiro LB, 2002, J NEUROPHYSIOL, V88, P2408, DOI 10.1152/jn.00901.2001
   BRADSHAW JL, 1990, NEUROPSYCHOLOGIA, V28, P917, DOI 10.1016/0028-3932(90)90108-Z
   Câmara J, 2023, VIRTUAL REAL-LONDON, V27, P291, DOI 10.1007/s10055-021-00559-6
   Cirstea MC, 2003, EXP BRAIN RES, V151, P289, DOI 10.1007/s00221-003-1438-0
   Connolly JD, 1999, EXP BRAIN RES, V125, P281, DOI 10.1007/s002210050684
   Costela FM, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.8.6
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Diffendaffer AZ, 2019, SPORT BIOMECH, V18, P448, DOI 10.1080/14763141.2018.1429489
   El Jamiy F, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ELECTRO INFORMATION TECHNOLOGY (EIT), P63, DOI [10.1109/EIT.2019.8834182, 10.1109/eit.2019.8834182]
   Fahle M, 1996, INVEST OPHTH VIS SCI, V37, P869
   Faria AL, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0204-z
   Furmanek MP, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0525-9
   Gerig N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189275
   Gershon P, 2015, ACTA PSYCHOL, V155, P37, DOI 10.1016/j.actpsy.2014.11.014
   González-Alvarez C, 2007, OPHTHAL PHYSL OPT, V27, P265, DOI 10.1111/j.1475-1313.2007.00476.x
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Haaland KY, 2004, BRAIN, V127, P1145, DOI 10.1093/brain/awh133
   Holmes D., 2016, J ALTERN MED RES, V9, P1
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Jang SH, 2013, NEUROREHABILITATION, V32, P311, DOI 10.3233/NRE-130849
   Jones TA, 2017, NAT REV NEUROSCI, V18, P267, DOI 10.1038/nrn.2017.26
   Knaut LA, 2009, ARCH PHYS MED REHAB, V90, P793, DOI 10.1016/j.apmr.2008.10.030
   Koenig S.T., 2019, Handbook of Rehabilitation Psychology, V3rd ed., P521, DOI [10.1037/0000129-032, DOI 10.1037/0000129-032]
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee S, 2016, OCCUP THER INT, V23, P357, DOI 10.1002/oti.1437
   Levin MF, 2020, EXPERT REV NEUROTHER, V20, P195, DOI [10.1080/14737175.2020.1727741, 10.1007/978-3-030-64455-0_1]
   Levin MF, 2015, IEEE T NEUR SYS REH, V23, P1047, DOI 10.1109/TNSRE.2014.2387412
   Levin MF, 2009, NEUROREHAB NEURAL RE, V23, P313, DOI 10.1177/1545968308328727
   Liebermann DG, 2012, IEEE T NEUR SYS REH, V20, P778, DOI 10.1109/TNSRE.2012.2206117
   Lindsay MP, 2019, INT J STROKE, V14, P806, DOI 10.1177/1747493019881353
   Liu L, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P219, DOI 10.1109/VR.2009.4811026
   Loftus A, 2004, EXP BRAIN RES, V158, P317, DOI 10.1007/s00221-004-1905-2
   Lum PS, 2009, TOP STROKE REHABIL, V16, P237, DOI 10.1310/tsr1604-237
   Magdalon EC, 2011, ACTA PSYCHOL, V138, P126, DOI 10.1016/j.actpsy.2011.05.015
   Matsuki K, 2011, J SHOULDER ELB SURG, V20, P659, DOI 10.1016/j.jse.2010.09.012
   Mayo NE, 2002, ARCH PHYS MED REHAB, V83, P1035, DOI 10.1053/apmr.2002.33984
   Mekbib DB, 2020, BRAIN INJURY, V34, P456, DOI 10.1080/02699052.2020.1725126
   Mieschke PE, 2001, BRAIN COGNITION, V45, P129, DOI 10.1006/brcg.2000.1262
   Minderer M, 2016, NATURE, V533, P324, DOI 10.1038/nature17899
   Mondellini M, 2018, P 2018 IEEE 6 INT C, P1, DOI DOI 10.1109/SEGAH.2018.8401313
   Mottura S, 2015, J MULTIMODAL USER IN, V9, P341, DOI 10.1007/s12193-015-0184-5
   Murphy S., 2018, FIELD VIEW EVALUATIO
   Norrving B, 2013, NEUROLOGY, V80, pS5, DOI 10.1212/WNL.0b013e3182762397
   Olbrich M, 2018, LECT NOTES COMPUT SC, V10909, P438, DOI 10.1007/978-3-319-91581-4_33
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pieri L, 2022, VIRTUAL REAL-LONDON, V26, P639, DOI 10.1007/s10055-021-00526-1
   Pollock A, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010820.pub2
   Przybyla A, 2012, EXP BRAIN RES, V216, P419, DOI 10.1007/s00221-011-2946-y
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Sachlikidis A, 2007, SPORT BIOMECH, V6, P334, DOI 10.1080/14763140701491294
   Sampson M, 2012, DISABIL REHABIL-ASSI, V7, P55, DOI 10.3109/17483107.2011.562959
   Schettino LF, 2003, EXP BRAIN RES, V151, P158, DOI 10.1007/s00221-003-1435-3
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stewart JC, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-27
   Subramanian S, 2008, 2008 VIRTUAL REHABILITATION, P181, DOI 10.1109/ICVR.2008.4625157
   Viau Antonin., 2004, Journal of NeuroEngineering and Rehabilitation, P1, DOI 10.1186/1743-0003-1-11
   Villa R, 2018, EXP BRAIN RES, V236, P2123, DOI 10.1007/s00221-018-5286-3
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Xiao X, 2019, MATH BIOSCI ENG, V16, P1611, DOI 10.3934/mbe.2019077
   Yates M, 2016, BRAIN INJURY, V30, P855, DOI 10.3109/02699052.2016.1144146
   Yoshizaki K, 2009, J SHOULDER ELB SURG, V18, P756, DOI 10.1016/j.jse.2009.02.021
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
   Zimmerli L, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-6
NR 67
TC 9
Z9 11
U1 1
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 885
EP 901
DI 10.1007/s10055-021-00603-5
EA NOV 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000716832400001
DA 2024-07-18
ER

PT J
AU Harada, Y
   Ohyama, J
AF Harada, Yuki
   Ohyama, Junji
TI Quantitative evaluation of visual guidance effects for 360-degree
   directions
SO VIRTUAL REALITY
LA English
DT Article
DE Attention; Visual guidance technique; Visual search; Cognitive load; 3D
   user interface
ID ATTENTION; SEARCH; PSEUDONEGLECT; MECHANISMS; STIMULI
AB A head-mounted display cannot cover an angle of visual field as wide as that of natural view (out-of-view problem). To enhance the visual cognition of an immersive environment, previous studies have developed various guidance designs that visualize the location or direction of items presented in the users' surroundings. However, two issues regarding the guidance effects remain unresolved: How are the guidance effects different with each guided direction? How much is the cognitive load required by the guidance? To investigate the two issues, we performed a visual search task in an immersive environment and measured the search time of a target and time spent to recognize a guidance design. In this task, participants searched for a target presented on a head-mounted display and reported the target color while using a guidance design. The guidance designs (a moving window, 3D arrow, radiation, spherical gradation, and 3D radar) and target directions were manipulated. The search times showed an interaction effect between guidance designs and guided directions, e.g., the 3D arrow and radar shorten the search time for targets presented at the back of users. The recognition times showed that the participants required short times to recognize the details of the moving window and radiation but long times for the 3D arrow, spherical gradation, and 3D radar. These results suggest that the moving window and radiation are effective with respect to cognitive load, but the 3D arrow and radar are effective for guiding users' attention to necessary items presented at the out-of-view.
C1 [Harada, Yuki; Ohyama, Junji] Natl Inst Adv Ind Sci & Technol, Human Augmentat Res Ctr, Kashiwa, Chiba, Japan.
   [Harada, Yuki] Natl Rehabil Ctr Persons Disabil, Dept Rehabil Brain Funct, Res Inst, Tokorozawa, Saitama, Japan.
C3 National Institute of Advanced Industrial Science & Technology (AIST)
RP Ohyama, J (corresponding author), Natl Inst Adv Ind Sci & Technol, Human Augmentat Res Ctr, Kashiwa, Chiba, Japan.
EM j.ohyama@aist.go.jp
RI Ohyama, Junji/M-6439-2016
OI Ohyama, Junji/0000-0002-1208-7196
FU Council for Science, Technology and Innovation, "Cross-ministerial
   Strategic Innovation Promotion Program (SIP), Big-data and AI-enabled
   Cyberspace Technologies". (funding agency: NEDO)
FX This work was supported by Council for Science, Technology and
   Innovation, "Cross-ministerial Strategic Innovation Promotion Program
   (SIP), Big-data and AI-enabled Cyberspace Technologies". (funding
   agency: NEDO).
CR Ardouin J., 2012, P ACM S VIRTUAL REAL, P41
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baudisch P, 2003, P SIGCHI C HUM FACT, P481, DOI 10.1145/642611.642695
   Bichot NP, 2005, SCIENCE, V308, P529, DOI 10.1126/science.1109676
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Chen JJ, 2018, SAFETY SCI, V105, P9, DOI 10.1016/j.ssci.2018.01.020
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   DAVID FN, 1951, BIOMETRIKA, V38, P43, DOI 10.2307/2332316
   DAWSON MRW, 1988, BEHAV RES METH INS C, V20, P54, DOI 10.3758/BF03202603
   Engbert R., 2015, Microsaccade toolbox for R. Potsdam Mind Research Repository
   Fan K., 2014, PROC AH, DOI [10.1145/2582051.2582100, DOI 10.1145/2582051.2582100]
   Finlayson NJ, 2015, ATTEN PERCEPT PSYCHO, V77, P2322, DOI 10.3758/s13414-015-0924-3
   Franconeri SL, 2003, PERCEPT PSYCHOPHYS, V65, P999, DOI 10.3758/BF03194829
   Friedman D, 2008, AGING NEUROPSYCHOL C, V15, P95, DOI 10.1080/13825580701533769
   Friesen CK, 2004, J EXP PSYCHOL HUMAN, V30, P319, DOI 10.1037/0096-1523.30.2.319
   Ganel T, 2003, NATURE, V426, P664, DOI 10.1038/nature02156
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   Gruenefeld U., 2018, Beyond Halo and Wedge, P1
   Gruenefeld U, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P742, DOI [10.1109/vr.2019.8797725, 10.1109/VR.2019.8797725]
   Gruenefeld U, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P109, DOI 10.1145/3131277.3132175
   Gruenefeld U, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3122124
   Harada Y, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237717
   Harada Y, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52313-3
   HENDERSON JM, 1993, PERCEPT PSYCHOPHYS, V53, P221, DOI 10.3758/BF03211732
   Hicks M., 2004, Virtual Reality, V7, P148, DOI 10.1007/s10055-004-0126-0
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Huang LQ, 2005, COGNITION, V94, pB101, DOI 10.1016/j.cognition.2004.06.006
   Jewell G, 2000, NEUROPSYCHOLOGIA, V38, P93, DOI 10.1016/S0028-3932(99)00045-7
   JONIDES J, 1988, PERCEPT PSYCHOPHYS, V43, P346, DOI 10.3758/BF03208805
   Joy T, 2022, VIRTUAL REAL-LONDON, V26, P615, DOI 10.1007/s10055-021-00511-8
   Kanji GK, 1977, INT J MATH ED SCI TE, V8, P293, DOI [10.1080/0020739770080305, DOI 10.1080/0020739770080305]
   Leonards U, 2000, J COGNITIVE NEUROSCI, V12, P61, DOI 10.1162/089892900564073
   Levy J, 2001, J EXP PSYCHOL HUMAN, V27, P862, DOI 10.1037//0096-1523.27.4.862
   Mackworth N.H., 1965, PSYCHON SCI, V3, P67, DOI DOI 10.3758/BF03343023
   Maringelli F, 2001, COGNITIVE BRAIN RES, V10, P317, DOI 10.1016/S0926-6410(00)00039-2
   Mitsudo H, 2010, PERCEPTION, V39, P1591, DOI 10.1068/p6739
   Orlosky J., 2014, P ACM S SPATIAL USER, P54, DOI [10.1145/2659766.2659771, DOI 10.1145/2659766.2659771]
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   PALMER J, 1994, VISION RES, V34, P1703, DOI 10.1016/0042-6989(94)90128-7
   Pratt J, 2010, PSYCHOL SCI, V21, P1724, DOI 10.1177/0956797610387440
   Renner P, 2017, IEEE SYMP 3D USER, P186, DOI 10.1109/3DUI.2017.7893338
   Ristic J, 2012, VIS COGN, V20, P244, DOI 10.1080/13506285.2012.658101
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Tripathi S, 2017, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2017.101
   Turner RJ, 2001, INTRO ANAL VARIANCE, DOI [10.4135/9781412984621, DOI 10.4135/9781412984621]
   Wolfe Jeremy M, 2010, Curr Biol, V20, pR346, DOI 10.1016/j.cub.2010.02.016
   Yang Chin-Shung., 2004, P 20 ISPRS C, P778
   Zago L, 2017, NEUROPSYCHOLOGIA, V94, P75, DOI 10.1016/j.neuropsychologia.2016.11.024
NR 53
TC 13
Z9 15
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 759
EP 770
DI 10.1007/s10055-021-00574-7
EA SEP 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000692304800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Genova, C
   Biffi, E
   Arlati, S
   Redaelli, DF
   Prini, A
   Malosio, M
   Corbetta, C
   Davalli, A
   Sacco, M
   Reni, G
AF Genova, C.
   Biffi, E.
   Arlati, S.
   Redaelli, D. F.
   Prini, A.
   Malosio, M.
   Corbetta, C.
   Davalli, A.
   Sacco, M.
   Reni, G.
TI A simulator for both manual and powered wheelchairs in immersive virtual
   reality CAVE
SO VIRTUAL REALITY
LA English
DT Article
DE Manual wheelchair; Powered wheelchair; Simulating system; Immersive
   virtual reality
ID SPINAL-CORD-INJURY; QUALITY-OF-LIFE; COMMUNITY PARTICIPATION; DRIVING
   PERFORMANCE; USERS; SKILLS; MOBILITY; PEOPLE; IMPACT; FALLS
AB A large number of people in the world need to use a wheelchair because of different disabilities. Driving a wheelchair requires complex physical and cognitive abilities which need to be trained. Virtual training helps users acquire driving skills in a safe environment. The aim of this paper is to describe and technically validate simulation models for both manual (MW) and powered wheelchairs (PW) based on immersive virtual reality CAVE (VR). As VR system, the Gait Real-time Analysis Interactive Lab (GRAIL) was used, a CAVE equipped with a motion platform with two degrees of freedom and an optoelectronic motion capture system. A real wheelchair was positioned onto the motion platform with rear wheels free to turn in MW modality, and a commercial joystick was installed on an armrest to simulate the PW modality. Passive markers were used to track the wheel rotation, the joystick and the user hand motion. Custom D-flow applications were developed to manage virtual scene response to user actions. Overground tests, based on single wheel rotation, were performed to verify the simulation model reliability. Quantitative results demonstrated that the MW simulator kinematics was consistent with a real wheelchair overground in the absence of wheel slip and inertia (median error for MW 0.40 degrees, no systematic bias p = 0.943, high correlation rho > 0.999, p < 0.01). The proposed solution is flexible and adaptable to different wheelchairs, joysticks and optoelectronic systems. The main limitation is the absence of force feedback. Nevertheless, it is a reliable prototype that can be used to validate new virtual scenarios as well as for wheelchair training. The next steps include the system validation with real end users and assessment of the simulator effectiveness as a training tool.
C1 [Genova, C.; Biffi, E.; Redaelli, D. F.; Corbetta, C.; Reni, G.] IRCCS E Medea, Sci Inst, Via Don Luigi Monza 20, I-23842 Bosisio Parini, Lecco, Italy.
   [Arlati, S.; Prini, A.; Malosio, M.; Sacco, M.] Natl Res Council Italy, Inst Intelligent Ind Technol & Syst Adv Mfg, Lecce, Italy.
   [Davalli, A.] Ist Nazl Assicuraz Infortuni Sul Lavoro INAIL, Ctr Protesi Vigorso Budrio, Bologna, Italy.
C3 IRCCS Eugenio Medea; Consiglio Nazionale delle Ricerche (CNR)
RP Biffi, E (corresponding author), IRCCS E Medea, Sci Inst, Via Don Luigi Monza 20, I-23842 Bosisio Parini, Lecco, Italy.
EM emilia.biffi@lanostrafamiglia.it
RI Sacco, marco/AAI-3566-2020; Biffi, Emilia/B-7982-2012; Corbetta,
   Claudio/HHN-0500-2022; Arlati, Sara/P-8502-2018; Malosio,
   Matteo/AAX-3274-2020; REDAELLI, DAVIDE FELICE/AAY-9296-2020
OI Sacco, marco/0000-0002-5055-4031; Biffi, Emilia/0000-0002-2568-9735;
   Corbetta, Claudio/0000-0003-4246-2441; Malosio,
   Matteo/0000-0002-4961-376X; REDAELLI, DAVIDE FELICE/0000-0002-8513-8222;
   Davalli, Angelo/0000-0002-5007-8661
FU National Institute for Insurance against Accidents at Work (INAIL), part
   of the Rientr@ project [PDT2/1]; Italian Ministry of Health
FX This study was supported by the National Institute for Insurance against
   Accidents at Work (INAIL), being part of the Rientr@ project
   (PDT2/1-"Rientr@: Ambienti Virtuali per facilitare il rientro al lavoro
   dopo incidente" [Virtual Environments to Facilitate the Return to Work
   after an Accident]), and by the Italian Ministry of Health (Ricerca
   Corrente 2020/2021 to Dr. E. Biffi).
CR Abdulsada HF, 2019, IIUM ENG J, V20, P194
   Alkhateeb AM, 2021, ASSIST TECHNOL, V33, P326, DOI 10.1080/10400435.2019.1641167
   Arai K, 2011, J ROBOT MECHATRON, V23, P66, DOI 10.20965/jrm.2011.p0066
   Archambault PS, 2017, DISABIL REHABIL, V39, P1549, DOI 10.1080/09638288.2016.1226423
   Archambault PS, 2012, DISABIL REHABIL-ASSI, V7, P226, DOI 10.3109/17483107.2011.625072
   Arlati S, 2020, ASSIST TECHNOL, V32, P294, DOI 10.1080/10400435.2018.1553079
   Bayley K, 2020, J PAEDIATR CHILD H, V56, P1419, DOI 10.1111/jpc.14963
   Bigras C, 2019, INT C VIRT REH ICVR, DOI [10.1109/ICVR46560.2019.8994644, DOI 10.1109/ICVR46560.2019.8994644]
   Bigras C, 2020, DISABIL REHABIL-ASSI, V15, P76, DOI 10.1080/17483107.2018.1527957
   Blouin M, 2015, IEEE T NEUR SYS REH, V23, P104, DOI 10.1109/TNSRE.2014.2330837
   Borg J, 2011, DISABIL SOC, V26, P151, DOI 10.1080/09687599.2011.543862
   Brandt Å, 2004, J REHABIL MED, V36, P70, DOI 10.1080/16501970310017432
   Briley SJ, 2020, J BIOMECH, V113, DOI 10.1016/j.jbiomech.2020.110099
   Carlozzi NE, 2013, DISABIL REHABIL-ASSI, V8, P176, DOI 10.3109/17483107.2012.699990
   Chénier F, 2014, IEEE-ASME T MECH, V19, P321, DOI 10.1109/TMECH.2012.2235079
   Cooper RA, 2011, ASSIST TECHNOL, V23, P177, DOI 10.1080/10400435.2011.588991
   Corfman TA, 2003, ARCH PHYS MED REHAB, V84, P1797, DOI 10.1016/S0003-9993(03)00467-2
   Crichlow L. R, 2011, DEV COMPREHENSIVE MA
   Davies A, 2003, DISABIL REHABIL, V25, P286, DOI 10.1080/0963828021000043734
   Desbonnet M, 1998, P EUR C DIS VIRT REA, V11, P177
   Devigne L, 2017, INT C REHAB ROBOT, P995, DOI 10.1109/ICORR.2017.8009379
   Devitt Rachel, 2004, Occup Ther Health Care, V17, P63, DOI 10.1080/J003v17n03_05
   Dieruf K, 2008, J SPINAL CORD MED, V31, P578, DOI 10.1080/10790268.2008.11754605
   Domingues I, 2020, IFMBE PROC, V76, P947, DOI 10.1007/978-3-030-31635-8_115
   Domingues I, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7040073
   Evans S, 2007, DISABIL REHABIL, V29, P1281, DOI 10.1080/09638280600964406
   Panadero CF, 2014, J UNIVERS COMPUT SCI, V20, P1629
   Field D, 1999, ASSIST TECHNOL, V11, P20, DOI 10.1080/10400435.1999.10131982
   Frost KL, 2020, DISABIL REHABIL-ASSI, V15, P629, DOI 10.1080/17483107.2019.1604824
   Geijtenbeek Thomas, 2011, P 10 INT C VIRT REAL, DOI [DOI 10.1145/2087756.2087785, 10.1145/2087756.2087785]
   Grant, 2011, P 2011 ANN RESNA C, P8
   Harrison A, 2002, DISABIL REHABIL, V24, P599, DOI 10.1080/09638280110111360
   Harrison C., 2000, The 3rd international conference on disability, virtual reality and associated technologies, P1
   Hasdai A, 1998, AM J OCCUP THER, V52, P215, DOI 10.5014/ajot.52.3.215
   Hosseini SM, 2012, ARCH PHYS MED REHAB, V93, P2237, DOI 10.1016/j.apmr.2012.05.021
   Karmarkar AM, 2009, J REHABIL RES DEV, V46, P567, DOI 10.1682/JRRD.2008.08.0102
   Keeler L, 2019, DISABIL REHABIL-ASSI, V14, P391, DOI 10.1080/17483107.2018.1456566
   Kim G, 2018, LECT NOTES COMPUT SC, V10910, P94, DOI 10.1007/978-3-319-91584-5_8
   Kirby RL, 2015, ARCH PHYS MED REHAB, V96, P2017, DOI 10.1016/j.apmr.2015.07.009
   KIRBY RL, 1994, AM J PHYS MED REHAB, V73, P319, DOI 10.1097/00002060-199409000-00004
   Kuntal Konica, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0632, DOI 10.1109/ICCSP48568.2020.9182157
   Labbé D, 2020, AGEING SOC, V40, P626, DOI 10.1017/S0144686X18001228
   Mahajan, 2013, DISSERTATION ABSTR B, V74, pNO
   Mahajan HP, 2013, J SPINAL CORD MED, V36, P322, DOI 10.1179/2045772313Y.0000000130
   Maxhall, 2004, 5 INT C DIS VIRT REA, P225
   Miles-Tapping C., 1996, Canadian Journal of Rehabilitation, V10, P137
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Morgan KA, 2017, DISABIL REHABIL-ASSI, V12, P28, DOI 10.3109/17483107.2015.1063015
   Mountain AD, 2010, DISABIL REHABIL-ASSI, V5, P230, DOI 10.3109/17483100903391145
   Mountain AD, 2010, ARCH PHYS MED REHAB, V91, P596, DOI 10.1016/j.apmr.2009.12.011
   Nassif, 2020, EEG WHEELCHAIR PEOPL
   Nunnerley J, 2017, DISABIL REHABIL-ASSI, V12, P417, DOI 10.1080/17483107.2016.1176259
   Pithon T., 2009, TECHNOL DISABIL, V21, P1, DOI DOI 10.3233/TAD-2009-0268
   Quilico EL, 2021, QUAL RES SPORT EXERC, V13, P800, DOI 10.1080/2159676X.2020.1778064
   Revathi P., 2008, INT RES J ENG TECH, V6, P1901
   Rice LA, 2019, AM J PHYS MED REHAB, V98, P649, DOI 10.1097/PHM.0000000000001161
   Richardson M, 2009, DISABIL REHABIL-ASSI, V4, P181, DOI 10.1080/17483100802543114
   Rodby-Bousquet E, 2010, BMC PEDIATR, V10, DOI 10.1186/1471-2431-10-59
   Rousseau-Harrison K, 2009, DISABIL REHABIL-ASSI, V4, P344, DOI 10.1080/17483100903038550
   Rozas Llontop D. A., 2020, 2020 IEEE INT C ENG, P1, DOI [10.1109/ICEV50249.2020.9289665, DOI 10.1109/ICEV50249.2020.9289665]
   Ruzaij MF, 2017, 2017 IEEE 15TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI), P399, DOI 10.1109/SAMI.2017.7880342
   Shino M, 2019, TECHNOL DISABIL, V31, P101, DOI [10.3233/TAD-190225, DOI 10.3233/TAD-190225]
   Silveira SL, 2020, HEALTH EDUC RES, V35, P270, DOI 10.1093/her/cyaa013
   Singh H, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2019-034279
   Spaeth DM, 2008, ARCH PHYS MED REHAB, V89, P996, DOI 10.1016/j.apmr.2007.11.030
   Torkia C, 2015, DISABIL REHABIL-ASSI, V10, P211, DOI 10.3109/17483107.2014.898159
   van den Akker LE, 2020, DISABIL REHABIL, V42, P1934, DOI 10.1080/09638288.2019.1577503
   Walford SL, 2019, CLIN BIOMECH, V65, P1, DOI 10.1016/j.clinbiomech.2019.03.003
   Webster JS, 2001, ARCH PHYS MED REHAB, V82, P769, DOI 10.1053/apmr.2001.23201
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   WHO, 2018, ASSIST TECHNOL
   Xiang H, 2006, INJURY PREV, V12, P8, DOI 10.1136/ip.2005.010033
NR 72
TC 5
Z9 5
U1 1
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 187
EP 203
DI 10.1007/s10055-021-00547-w
EA JUN 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000663979600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Rothe, S
   Schmidt, A
   Montagud, M
   Buschek, D
   Hussmann, H
AF Rothe, Sylvia
   Schmidt, Alexander
   Montagud, Mario
   Buschek, Daniel
   Hussmann, Heinrich
TI Social viewing in cinematic virtual reality: a design space for social
   movie applications
SO VIRTUAL REALITY
LA English
DT Article
DE Cinematic virtual reality; Omnidirectional video; 360 degrees video;
   Social viewing; Interactive TV
ID TV
AB Since watching movies is a social experience for most people, it is important to know how an application should be designed for enabling shared cinematic virtual reality (CVR) experiences via head-mounted displays (HMDs). Viewers can feel isolated when watching omnidirectional movies with HMDs. Even if they are watching the movie simultaneously, they do not automatically see the same field of view, since they can freely choose their viewing direction. Our goal is to explore interaction techniques to efficiently support social viewing and to improve social movie experiences in CVR. Based on the literature review and insights from earlier work, we identify seven challenges that need to be addressed: communication, field-of-view (FoV) awareness, togetherness, accessibility, interaction techniques, synchronization, and multiuser environments. We investigate four aspects (voice chat, sending emotion states, FoV indication, and video chat) to address some of the challenges and report the results of four user studies. Finally, we present and discuss a design space for CVR social movie applications and highlight directions for future work.
C1 [Rothe, Sylvia; Schmidt, Alexander; Hussmann, Heinrich] Ludwig Maximilians Univ Munchen, Inst Informat, Munich, Germany.
   [Montagud, Mario] Univ Valencia, Valencia, Spain.
   [Montagud, Mario] I2CAT Fdn, Valencia, Spain.
   [Buschek, Daniel] Univ Bayreuth, Dept Comp Sci, Res Grp HCI AI, Bayreuth, Germany.
C3 University of Munich; University of Valencia; Internet I Innovacio
   Digital A Catalunya (I2CAT); University of Bayreuth
RP Rothe, S (corresponding author), Ludwig Maximilians Univ Munchen, Inst Informat, Munich, Germany.
EM sylvia.rothe@ifi.lmu.de; alexander.x.schmidt@gmail.com;
   mario.montagud@i2cat.net; daniel.buschek@ifi.lmu.de; hussmann@ifi.lmu.de
OI Schmidt, Alexander/0000-0001-7090-2198; Montagud,
   Mario/0000-0002-2398-1505; Rothe, Sylvia/0000-0002-3819-3608; Hussmann,
   Heinrich/0000-0003-1709-7905
FU Spanish Ministry of Science, Innovation, and Universities with a Juan de
   la Cierva - Incorporacion grant [IJCI-2017-34611]; European Union
   [762111]
FX The work by Mario Montagud has been funded by the Spanish Ministry of
   Science, Innovation, and Universities with a Juan de la Cierva -
   Incorporacion grant, with reference IJCI-2017-34611, and by European
   Union's Horizon 2020 program, under agreement no 762111 (VRTogether).
CR Abreu J, 2002, SPRING EUROGRAP, P199
   [Anonymous], 2018, UNITY MANUAL MULTIPL
   [Anonymous], 2017, HEADS REM
   [Anonymous], 2017, Journal of Media Practice, DOI DOI 10.1080/14682753.2017.1305838
   Belda J, 2015, P ACM TVX BRUSS BELG, P9
   Boronat F, 2018, IEEE T BROADCAST, V64, P52, DOI 10.1109/TBC.2017.2737819
   Burgos-Artizzu Xavier P, 2015, Kobe, Japan) 15). SIGGRAPH Asia 2015 Technical Briefs, P1, DOI [DOI 10.1145/2820903.2820910, 10.1145/2820903.2820910]
   CARLSSON C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P394, DOI 10.1109/VRAIS.1993.380753
   Chambel T, 2011, P 8 INT C ADV COMP E, P1, DOI [10.1145/2071423.2071518, DOI 10.1145/2071423.2071518]
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Nguyen C, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P267, DOI 10.1145/3126594.3126659
   De Greef P, 2001, CYBERPSYCHOL BEHAV, V4, P307, DOI 10.1089/109493101300117974
   De Simone F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P890, DOI [10.1109/VR.2019.8798264, 10.1109/vr.2019.8798264]
   Dorta T, 2016, ACTES DE LA 28EME CONFERENCE DE L'ASSOCIATION FRANCOPHONE D'INTERACTION HOMME-MACHINE (IHM16), P211, DOI 10.1145/3004107.3004117
   Durlach N, 2000, PRESENCE-TELEOP VIRT, V9, P214, DOI 10.1162/105474600566736
   Facebook, 2019, FACEB SPAC
   Geerts D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P311
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Gunkel SNB, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P498, DOI 10.1145/3204949.3208115
   Gunkel Simon NB, 2017, ACM international conference on interactive experiences for TV and online video (ACM), P83, DOI [DOI 10.1145/3084289.3089914, 10.1145/3084289.3089914]
   Harboe G., 2008, ACM COMPUTERS ENTERT, V6, P1, DOI DOI 10.1145/1350843.1350851
   Harboe G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1
   Hassib M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6133, DOI 10.1145/3025453.3025953
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Ho C., 1998, P BRIT TEL WORKSH PR, P10
   Holderied H, 2017, INFORM 2017, P2511, DOI [10.18420/in2017_254, DOI 10.18420/IN2017_254]
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   IJsselsteijn W, 2009, HUM-COMPUT INT-SPRIN, P473, DOI 10.1007/978-1-84882-477-5_20
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim J, 2018, MASS COMMUN SOC, V21, P50, DOI 10.1080/15205436.2017.1350715
   Margery D., 1999, Virtual Environments '99 Proceedings of the Eurographics Workshop. Eurographics, P169
   Matos H, 2018, SPR TRANS CIV ENV EN, P1, DOI 10.1007/978-981-10-7170-6_1
   Montagud M, 2015, IEEE COMPUT SOC STCS, V3, P1
   Montagud M, 2018, P 2018 ACM INT C INT
   Montagud M, 2012, MULTIMEDIA SYST, V18, P459, DOI 10.1007/s00530-012-0278-9
   Moreno R, 1999, J EDUC PSYCHOL, V91, P358, DOI 10.1037/0022-0663.91.2.358
   Nathan M., 2008, P INT C DESIGNING IN, P85, DOI DOI 10.1145/1453805.1453824
   Neng Luisa. R., 2010, Proceedings of the 14th International Academic MindTrek Conference on Envisioning Future Media Environments-MindTrek '10, P119, DOI DOI 10.1145/1930488.1930512
   Nielsen LT, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P229, DOI 10.1145/2993369.2993405
   Normand V, 1999, PRESENCE-TELEOP VIRT, V8, P218, DOI 10.1162/105474699566189
   Nunez A, 2018, WORKSH VIRT REAL COL
   O'Hagan RG, 2002, INTERACT COMPUT, V14, P231, DOI 10.1016/S0953-5438(01)00050-9
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Pakkanen T, 2017, P IEEE VIRT REAL ANN, P279, DOI 10.1109/VR.2017.7892285
   Rothe S, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010019
   Rothe S, 2018, LECT NOTES COMPUT SC, V10850, P101, DOI 10.1007/978-3-319-95270-3_7
   Schubert T, 2002, IGROUP PRESENCE QUES
   Schultze U, 2019, INFORM SYST J, V29, P707, DOI 10.1111/isj.12230
   Shin DH, 2015, ONLINE INFORM REV, V39, P416, DOI 10.1108/OIR-12-2014-0299
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Tang A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4501, DOI 10.1145/3025453.3025519
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644
   Voorveld HAM, 2015, MEDIA PSYCHOL, V18, P499, DOI 10.1080/15213269.2013.872038
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Weisz JD, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P877
   Yeh M, 1999, HUM FACTORS, V41, P524, DOI 10.1518/001872099779656752
NR 57
TC 14
Z9 14
U1 2
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 613
EP 630
DI 10.1007/s10055-020-00472-4
EA OCT 2020
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000579607700001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Teixeira, J
   Palmisano, S
AF Teixeira, Joel
   Palmisano, Stephen
TI Effects of dynamic field-of-view restriction on cybersickness and
   presence in HMD-based virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Virtual reality; Head-mounted display; Vection; Presence
ID INDUCED MOTION SICKNESS; CONSOLE VIDEO GAMES; POSTURAL INSTABILITY;
   VIEWPOINT JITTER; SEX-DIFFERENCES; VECTION; HABITUATION; PERFORMANCE;
   STABILITY; NYSTAGMUS
AB The phenomenon of cybersickness is currently hindering the mass market adoption of head-mounted display (HMD) virtual reality (VR) technologies. This study examined the effects ofdynamic field-of-view (FOV) restrictionon the cybersickness generated by ecological HMD-based gameplay. Forty participants were exposed to a commercially available HMD game (Marvel Powers United VR) under bothunrestricted FOVanddynamic FOV restrictionconditions across three sessions. Participants had their spontaneous postural instability measured before entering VR. Then, during/following each of these 10-min exposures to HMD VR, they rated their cybersickness, vection (illusory self-motion), and feelings of presence. Individual differences in spontaneous postural instability were found to predict cybersickness during HMD VR gameplay. Cybersickness severity increased steadily over the course of each VR exposure and was significantly reduced bydynamic FOV restriction. Presence also increased steadily over the course of each VR exposure and was positively correlated with vection. We conclude that: (1) postural instability can identify people who are more susceptible to cybersickness, (2) vection can increase an HMD user's feelings of presence, and (3)dynamic FOV restrictioncan serve as a viable countermeasure to cybersickness.
C1 [Teixeira, Joel; Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
C3 University of Wollongong
RP Palmisano, S (corresponding author), Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
EM stephenp@uow.edu.au
RI ; Palmisano, Stephen/O-1553-2018
OI Teixeira, Joel/0009-0003-9154-044X; Palmisano,
   Stephen/0000-0002-9140-5681
CR Al Zayer M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300584
   [Anonymous], 1975, Motion sickness
   [Anonymous], 2019, DAYDREAM ELEMENTS VR
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Bonato F, 2005, AVIAT SPACE ENVIR MD, V76, P823
   Bonato F, 2004, AVIAT SPACE ENVIR MD, V75, P306
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bonnet CT, 2006, HUM MOVEMENT SCI, V25, P800, DOI 10.1016/j.humov.2006.03.001
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Chang CH, 2013, EXP BRAIN RES, V229, P235, DOI 10.1007/s00221-013-3609-y
   Chang CH, 2012, EXP BRAIN RES, V217, P299, DOI 10.1007/s00221-011-2993-4
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Flanagan MB, 2002, AVIAT SPACE ENVIR MD, V73, P1067
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2017, J EXP PSYCHOL-APPL, V23, P85, DOI 10.1037/xap0000107
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim J, 2008, BRAIN RES BULL, V77, P335, DOI 10.1016/j.brainresbull.2008.09.011
   Kim S, 2018, J SOC INF DISPLAY, V26, P376, DOI 10.1002/jsid.669
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Koslucher F, 2015, AEROSP MED HUM PERF, V86, P787, DOI 10.3357/AMHP.4243.2015
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lin CJ, 2015, HUM FACTOR ERGON MAN, V25, P523, DOI 10.1002/hfm.20566
   LORCH RF, 1990, J EXP PSYCHOL LEARN, V16, P149, DOI 10.1037/0278-7393.16.1.149
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Melo M, 2018, COMPUT GRAPH-UK, V71, P159, DOI 10.1016/j.cag.2017.11.007
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Minsky M, 1980, OMNI, V2, P404
   Mondellini M, 2018, LECT NOTES COMPUTER, V10850
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nalivaiko Eugene, 2014, Temperature (Austin), V1, P164, DOI 10.4161/23328940.2014.982047
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Palmisano S, 2009, ATTEN PERCEPT PSYCHO, V71, P1842, DOI 10.3758/APP.71.8.1842
   Pinto M., 2018, P INT C GRAPH INT IC, P1
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   SEAY AF, 2002, HUMAN FACTORS COMPUT
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   STOFFREGEN TA, 1986, PERCEPT PSYCHOPHYS, V39, P355, DOI 10.3758/BF03203004
   Stoffregen TA, 2000, HUM FACTORS, V42, P458, DOI 10.1518/001872000779698097
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Stoffregen TA, 2010, ECOL PSYCHOL, V22, P169, DOI 10.1080/10407413.2010.496645
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Vinson NormanG., 2012, Proceedings of Graphics Interface 2012, P69
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Yokota Y, 2005, ACTA OTO-LARYNGOL, V125, P280, DOI 10.1080/00016480510003192
NR 67
TC 45
Z9 48
U1 0
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 433
EP 445
DI 10.1007/s10055-020-00466-2
EA AUG 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000559299200001
DA 2024-07-18
ER

PT J
AU Gutiérrez-Maldonado, J
   Rus-Calafell, M
   González-Conde, J
AF Gutierrez-Maldonado, Jose
   Rus-Calafell, Mar
   Gonzalez-Conde, Joan
TI Creation of a new set of dynamic virtual reality faces for the
   assessment and training of facial emotion recognition ability
SO VIRTUAL REALITY
LA English
DT Article
DE Emotion recognition; Virtual agents; Dynamism; Social skills;
   Cyberintervention
ID SOCIAL COMPETENCE; SCHIZOPHRENIA; EXPRESSIONS; COGNITION; PSYCHOLOGY;
   TECHNOLOGY; PERCEPTION; DISORDERS; MOVEMENT; PROGRAM
AB The ability to recognize facial emotions is target behaviour when treating people with social impairment. When assessing this ability, the most widely used facial stimuli are photographs. Although their use has been shown to be valid, photographs are unable to capture the dynamic aspects of human expressions. This limitation can be overcome by creating virtual agents with feasible expressed emotions. The main objective of the present study was to create a new set of dynamic virtual faces with high realism that could be integrated into a virtual reality (VR) cyberintervention to train people with schizophrenia in the full repertoire of social skills. A set of highly realistic virtual faces was created based on the Facial Action Coding System. Facial movement animation was also included so as to mimic the dynamism of human facial expressions. Consecutive healthy participants (n = 98) completed a facial emotion recognition task using both natural faces (photographs) and virtual agents expressing five basic emotions plus a neutral one. Repeated-measures ANOVA revealed no significant difference in participants' accuracy of recognition between the two presentation conditions. However, anger was better recognized in the VR images, and disgust was better recognized in photographs. Age, the participant's gender and reaction times were also explored. Implications of the use of virtual agents with realistic human expressions in cyberinterventions are discussed.
C1 [Gutierrez-Maldonado, Jose; Rus-Calafell, Mar; Gonzalez-Conde, Joan] Univ Barcelona, Dept Personal Assessment & Psychol Treatments, Barcelona 08035, Spain.
C3 University of Barcelona
RP Rus-Calafell, M (corresponding author), Univ Barcelona, Dept Personal Assessment & Psychol Treatments, Passeig Vall dHebron 171, Barcelona 08035, Spain.
EM jgutierrezm@ub.edu; m.ruscalafell@gmail.com; jgonzalezconde@yahoo.es
RI Rus Calafell, Mar/HKV-5173-2023; Gutiérrez -Maldonado, José/L-1302-2014;
   González-Conde Cantero, Joan/P-6179-2014
OI Rus Calafell, Mar/0000-0003-2293-3875; Gutiérrez -Maldonado,
   José/0000-0001-7977-2051; González-Conde Cantero,
   Joan/0000-0001-6625-1716
FU Institute for the Brain, Cognition, and Behaviour (IR3C), University of
   Barcelona; government of Catalonia's Agency for the Management of
   University and Research Grants (AGAUR) (FI-DGR)
FX We are grateful to the University of Pennsylvania's Brain Behaviour
   Laboratory for allowing us to use their facial emotional stimuli (Gur et
   al. 2002a, b; Kohler et al. 2003). We wish to acknowledge the Computer
   Scientists Nicolas Toledan and Victor Sanchez of the VR-PSY Lab for
   their invaluable work. This study was supported by the Institute for the
   Brain, Cognition, and Behaviour (IR3C), University of Barcelona, and by
   a research grant awarded to Mar Rus-Calafell by the government of
   Catalonia's Agency for the Management of University and Research Grants
   (AGAUR) (FI-DGR/2010).
CR Addington J, 1998, SCHIZOPHR RES, V32, P171, DOI 10.1016/S0920-9964(98)00042-5
   [Anonymous], 1975, PICTURES FACIAL AFFE
   ARCHER J, 1994, BRIT J CLIN PSYCHOL, V33, P517, DOI 10.1111/j.2044-8260.1994.tb01148.x
   Bellack AS., 2004, SOCIAL SKILLS TRAINI
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Borras L, 2009, EUR PSYCHIAT, V24, P307, DOI 10.1016/j.eurpsy.2009.01.003
   Calder AJ, 2003, NEUROPSYCHOLOGIA, V41, P195, DOI 10.1016/S0028-3932(02)00149-5
   Calder AJ, 2000, COGNITION, V76, P105, DOI 10.1016/S0010-0277(00)00074-3
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Couture SM, 2006, SCHIZOPHRENIA BULL, V32, pS44, DOI 10.1093/schbul/sbl029
   Davis PJ, 2000, J ABNORM PSYCHOL, V109, P445, DOI 10.1037//0021-843X.109.3.445
   Domes G, 2009, J PERS DISORD, V23, P6, DOI 10.1521/pedi.2009.23.1.6
   Dyck M, 2010, PSYCHIAT RES, V179, P247, DOI 10.1016/j.psychres.2009.11.004
   Dyck M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003628
   Edwards J, 2002, CLIN PSYCHOL REV, V22, P789, DOI 10.1016/S0272-7358(02)00130-7
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Ekman P, 1978, FACIAL ACTION CODING
   Fabri M., 2004, Virtual Reality, V7, P66, DOI 10.1007/s10055-003-0116-7
   Fabri M, 2002, P AUT AG MULT SYST B
   Gaggioli A, 2003, CYBERPSYCHOL BEHAV, V6, P117, DOI 10.1089/109493103321640301
   Green MF, 2005, SCHIZOPHRENIA BULL, V31, P882, DOI 10.1093/schbul/sbi049
   Gur RC, 2002, NEUROIMAGE, V16, P651, DOI 10.1006/nimg.2002.1097
   Gur RC, 2002, J NEUROSCI METH, V115, P137, DOI 10.1016/S0165-0270(02)00006-7
   Gutierrez-Maldonado J, 2012, STUD HEALTH TECHNOL, V181, P88, DOI 10.3233/978-1-61499-121-2-88
   Han K, 2009, COMPUT BIOL MED, V39, P173, DOI 10.1016/j.compbiomed.2008.12.002
   Harwood NK, 1999, AM J MENT RETARD, V104, P270, DOI 10.1352/0895-8017(1999)104<0270:ROFEEF>2.0.CO;2
   Irani F, 2012, SCHIZOPHR RES, V137, P203, DOI 10.1016/j.schres.2012.01.023
   Knight B, 1997, VIS COGN, V4, P265, DOI 10.1080/713756764
   Kohler CG, 2003, AM J PSYCHIAT, V160, P1768, DOI 10.1176/appi.ajp.160.10.1768
   Kohler CG, 2004, CNS SPECTRUMS, V9, P267, DOI 10.1017/S1092852900009202
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   Ku J, 2007, CYBERPSYCHOL BEHAV, V10, P567, DOI 10.1089/cpb.2007.9989
   Ku J, 2006, CYBERPSYCHOL BEHAV, V9, P531, DOI 10.1089/cpb.2006.9.531
   Leppänen JM, 2006, CURR OPIN PSYCHIATR, V19, P34, DOI 10.1097/01.yco.0000191500.46411.00
   Lisetti CL, 2002, P MULT 02 JUAN LES P
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Machado-de-Sousa JP, 2010, J NEUROSCI METH, V193, P1, DOI 10.1016/j.jneumeth.2010.08.013
   Mill A, 2009, EMOTION, V9, P619, DOI 10.1037/a0016562
   Mueser KT, 1996, J ABNORM PSYCHOL, V105, P271, DOI 10.1037/0021-843X.105.2.271
   Park KM, 2011, PSYCHIAT RES, V189, P166, DOI 10.1016/j.psychres.2011.04.003
   Park KM, 2009, HUM PSYCHOPHARM CLIN, V24, P619, DOI 10.1002/hup.1071
   Parsons TD, 2011, STUD COMPUT INTELL, V337, P271
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rus-Calafell M, 2012, STUD HEALTH TECHNOL, V181, P283, DOI 10.3233/978-1-61499-121-2-283
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Sachs G, 2004, SCHIZOPHR RES, V68, P27, DOI 10.1016/S0920-9964(03)00131-2
   Sandín B, 1999, PSICOTHEMA, V11, P37
   Sato W, 2007, J NONVERBAL BEHAV, V31, P119, DOI 10.1007/s10919-007-0025-7
   Scherer KR, 2007, EMOTION, V7, P113, DOI 10.1037/1528-3542.7.1.113
   Spencer-Smith J, 2001, BEHAV RES METH INS C, V33, P115, DOI 10.3758/BF03195356
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   Vilagrasa S, 2009, 4 IB S COMP GRAPH IS
   Vogeley K, 2010, NEURAL NETWORKS, V23, P1077, DOI 10.1016/j.neunet.2010.06.003
   Watson C, 1988, J PERS SOC PSYCHOL, V54, P1063
   Yee N, 2007, P C COMP HUM INT CHI
NR 56
TC 35
Z9 39
U1 0
U2 48
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2014
VL 18
IS 1
SI SI
BP 61
EP 71
DI 10.1007/s10055-013-0236-7
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AB2WI
UT WOS:000331652400006
DA 2024-07-18
ER

PT J
AU Houliez, C
   Gamble, E
AF Houliez, Chris
   Gamble, Edward
TI Dwelling in Second Life? A phenomenological evaluation of online virtual
   worlds
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual worlds; Second Life; Qualitative studies; Phenomenology;
   Presence
ID SOCIAL PRESENCE; ENVIRONMENTS; EXPERIENCE
AB In previous research on virtual worlds, the question of whether virtual space can be evaluated just like "real world" space has not been fully addressed. This paper challenges the perceived commonsensical set of assumptions through which virtual world activities are usually unpacked and proposes a new method of evaluating virtual worlds based on Martin Heidegger's phenomenology. Various focus groups conducted in the virtual world Second Life confirmed that a phenomenological paradigm is more appropriate to fully make sense of and leverage this new medium. Besides questioning the relevancy of dealing with virtual worlds as if they were parallel spaces, this paper, by leveraging a new conceptualization of virtual worlds, also offers suggestions for new online qualitative methodologies.
C1 [Houliez, Chris] Grp Sup Co La Rochelle CEREGE, F-17000 La Rochelle, France.
   [Gamble, Edward] Univ Prince Edward Isl, Sch Business, Charlottetown, PE C1A 4P3, Canada.
C3 University of Prince Edward Island
RP Houliez, C (corresponding author), Grp Sup Co La Rochelle CEREGE, 102 Rue Coureilles, F-17000 La Rochelle, France.
EM houliezc@esc-larochelle.fr; egamble@upei.ca
RI Gamble, Edward/KHX-4626-2024
CR [Anonymous], WE BECAME POSTHUMANS
   [Anonymous], 1986, UNDERSTANDING COMPUT
   Arnold JT, 2009, HRMAGAZINE, P36
   Au JW, 2008, NEW WORLD NOTES
   Barnes S, 2008, J ELECTRON COMMER RE, V9, P195
   Barnes SJ, 2011, J MARKET MANAG-UK, V27, P934, DOI 10.1080/0267257X.2011.565686
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Biocca F, 1997, HUMAN INTERFACES QUE, P115
   Boellstorff T, 2008, COMING OF AGE IN SECOND LIFE: AN ANTHROPOLOGIST EXPLORES THE VIRTUALLY HUMAN, P1
   Bouvier P., 2008, Presence 2008: Proceedings of the 11th International Workshop, P246
   Broitman A, 2007, IMEDIA CONNECTION
   Castells M., 1997, The Power of Identity, The Information Age: Economy, Society and Culture
   Castronova EW, 2010, FED CONS VIRT WORLDS
   Cyber Creatives Inc, 2011, MMORPG GAM
   Descartes Rene., 1951, Discourse on Method and Selected Writings
   Doueihi Milad., 2008, La grande conversion numerique
   Dreyfus H. L., 1991, BEING IN THE WORLD C
   Dreyfus H. L., 1992, What Computers Still Cant Do: a Critique of Artificial Reason
   Dreyfus Hubert., 1993, WHAT COMPUTERS STILL
   Foster A., 2007, The Chronicle of Higher Education, V54, P24
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Galloway K.L., 2011, New Directions for Evaluation, V131, P47, DOI 10.1002/ev.377
   Garau M., 2004, The 7th Annual International Presence Workshop, P232
   Guo Y, 2009, ELECTRON COMMER RES, V9, P77, DOI 10.1007/s10660-009-9032-6
   Haans A., 2009, P 12 ANN INT WORKSHO, P1, DOI 10.13140/2.1.4867.3289
   Haraway D., 1990, SIMIANS CYBORGS WOME
   Heidegger M., 1977, The Question Concerning Technology and Other Essays
   Heidegger Martin, 1962, BEING TIME
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Hemp P, 2006, HARVARD BUS REV, V84, P48
   Hine C., 2005, VIRTUAL METHODS ISSU, P1
   Hofstadter Albert, 1971, Poetry, Language, Thought, P141
   Husserl E., 1913, General introduction to pure phenomenology
   IJsselsteijn W., 2002, P PRESENCE 02, P245
   Introna L., 2002, Internet management issues: A global perspective, P220
   Introna LD, 2004, EUR J INFORM SYST, V13, P221, DOI 10.1057/palgrave.ejis.3000503
   (ISPR) International Society for Presence Research, 2000, The concept of presence: Explication statement
   Jennings N., 2007, International Journal of Social Sciences, V2, P180
   Jones M.T., 2007, Proceedings of the Tenth Annual International Meeting of the Presence Workshop, P115
   Kopp D.M., 2010, International Journal of Advanced Corporate Learning, V3, P19, DOI DOI 10.3991/IJAC.V3I3.1373
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lehar Steven., 1999, Gestalt theory, V21, P122
   Lepecq JC, 2008, P 11 ANN INT WORKSH, P202
   Levy P, 1994, COLLECTIVE INTELLIGE
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lombard M., 2009, P 12 ANN INT WORKSH, P1
   Mantovani G, 1999, PRESENCE-TELEOP VIRT, V8, P540, DOI 10.1162/105474699566459
   Merleau-Ponty M., 1945, Phenomenologie de la perception
   Minsky M., 1980, OMNI, V2, P45, DOI DOI 10.1145/566654.566630
   Mitropoulos M, 2003, SHIFTING PHYS ELECT
   Molina F., 1962, EXISTENTIALISM PHILO
   Moon JW, 2001, INFORM MANAGE-AMSTER, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Murray P, 2006, QUAL HEALTH RES, V7, P542
   Nunez D, 2003, P 6 ANN INT WORKSH P
   Parmentier G, 2009, RECH APPL MARKET-ENG, V24, P43, DOI 10.1177/205157070902400302
   RICE RE, 1993, HUM COMMUN RES, V19, P451, DOI 10.1111/j.1468-2958.1993.tb00309.x
   Ringo T, 2007, RES TECHNOL MANAGE, V50, P6
   Riva G., 2008, 1 ANN INT WORKSH PRE, P66
   Schmeil A, 2009, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INTELLECTUAL CAPITAL, KNOWLEDGE MANAGEMENT & ORGANISATIONAL LEARNING, P245
   Searle J., 1989, Minds, brains, and science
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Short J., 1976, The social psychology of telecommunications
   Slater M., 2003, P 6 INT WORKSHOP PRE
   Slater M., 1993, Presence, V2, P221, DOI [DOI 10.1162/PRES.1993.2.3.221, 10.1162/pres.1993.2.3.221]
   Slater M., 2000, PRESENCE, V9, P423
   Slater M, 2009, ANU PSICOL, V40, P193
   Steiner G., 1978, HEIDEGGER
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stewart D, 2007, FOCUS GROUPS THEORY, Vxi, P66
   Sundar SS., 2008, PRESENCE 2008 P 11 A, P219
   Towell J, 1997, PRESENCE-TELEOP VIRT, V7, P78
   Turney L., 2005, International Journal of Qualitative Methods, V4, P32, DOI [DOI 10.1177/160940690500400203, 10.1177/160940690500400203]
   Wagner C., 2008, Journal of Information Systems Education, V19, P263
   WARC, 2010, P G PLOTS DIG DRIV
   Ward J, 2010, MARK INTELL PLAN, V28, P862, DOI 10.1108/02634501011086463
   Wasko M, 2011, MIS QUART, V35, P645
   Waterworth EL, 2001, CYBERPSYCHOL BEHAV, V4, P203, DOI 10.1089/109493101300117893
   Weckstrom N, 2004, FINDING REALIT UNPUB
   Weibel D, 2007, P 10 ANN INT WORKSH, P379
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
NR 84
TC 9
Z9 12
U1 1
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2013
VL 17
IS 4
BP 263
EP 278
DI 10.1007/s10055-012-0218-1
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 239BT
UT WOS:000325997200002
DA 2024-07-18
ER

PT J
AU McConville, KMV
   Virk, S
AF McConville, Kristiina M. Valter
   Virk, Sumandeep
TI Evaluation of an electronic video game for improvement of balance
SO VIRTUAL REALITY
LA English
DT Article
DE Balance training; Difficulty model; Motor learning; Simulator sickness;
   Video game; Virtual environment
ID MOVEMENTS; SPECIFICITY; STRENGTH; MOTION; POWER; GAIN; SWAY
AB Virtual environments have been investigated for fitness and medical rehabilitation. In this study, the Sony EyeToy (A (R)) and PlayStation 2 (A (R)) were used with the AntiGrav (TM) game to evaluate their potential for improving postural balance. The game required lateral head, body, and arm movements. The performance on balance tests of subjects who trained for 3 weeks with this game was compared to the performance of controls who were not trained. Training subjects showed improvement for two of the three tests (each testing a different facet of balance), suggesting specificity of training, while control subjects did not show significant improvement on any test. Simulator sickness questionnaire results showed a variety of mild symptoms, which decreased over the training sessions. Motor learning analysis of the game scores showed that mastery had been achieved on the easier level in the game, but not on the second level of difficulty. This reflects the potential for continued learning and training through advanced levels within a game. A model parameter using the time constants of game score improvement was developed, which could be used to quantify the difficulty for any video game design. The results suggest that this video game could be used for some aspects of balance training.
C1 [McConville, Kristiina M. Valter; Virk, Sumandeep] Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON M5B 2K3, Canada.
   [McConville, Kristiina M. Valter] Univ Toronto, Inst Biomat & Biomed Engn, Toronto, ON, Canada.
   [McConville, Kristiina M. Valter] Toronto Rehabil Inst, Lyndhurst Ctr, Toronto, ON, Canada.
C3 Toronto Metropolitan University; University of Toronto; University of
   Toronto; University Health Network Toronto; Toronto Rehabilitation
   Institute
RP McConville, KMV (corresponding author), Ryerson Univ, Dept Elect & Comp Engn, 350 Victoria St, Toronto, ON M5B 2K3, Canada.
EM kmcconvi@ee.ryerson.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX We are grateful to Dr. Ken Norwich at the University of Toronto for
   reviewing the manuscript, for his insights on motor learning, including
   conceptualizing the motor learning parameter to compare game difficulty,
   and for his support and encouragement. We are also grateful to Matija
   Milosevic of Ryerson University for use of the data recording equipment
   and his assistance with the analysis. We thank Lisa D'Alessandro at the
   University of Toronto, David Michael Mravyan of Elmedex Inc. in Toronto,
   and Chih-Chuan (Leo) Kant for their assistance. The authors acknowledge
   the Natural Sciences and Engineering Research Council of Canada (NSERC)
   for supporting this work.
CR COHEN H, 1995, OTOLARYNG HEAD NECK, V112, P526, DOI 10.1177/019459989511200404
   COYLE EF, 1981, J APPL PHYSIOL, V51, P1437, DOI 10.1152/jappl.1981.51.6.1437
   Curb JD, 2006, J AM GERIATR SOC, V54, P737, DOI 10.1111/j.1532-5415.2006.00700.x
   Deutsch JE, 2008, PHYS THER, V88, P1196, DOI 10.2522/ptj.20080062
   Di Fabio R P, 1993, J Vestib Res, V3, P409
   Emery CA, 2005, CAN MED ASSOC J, V172, P749, DOI 10.1503/cmaj.1040805
   Findorff MJ, 2009, J WOMENS HEALTH, V18, P1769, DOI 10.1089/jwh.2008.1265
   Flynn Sheryl, 2007, J Neurol Phys Ther, V31, P180, DOI 10.1097/NPT.0b013e31815d00d5
   FOSTER CA, 1994, BAILLIERE CLIN NEUR, V3, P577
   Gandevia SC, 2001, PHYSIOL REV, V81, P1725, DOI 10.1152/physrev.2001.81.4.1725
   Gottshall KR, 2006, J VESTIBUL RES-EQUIL, V16, P29
   Heitkamp HC, 2001, INT J SPORTS MED, V22, P285, DOI 10.1055/s-2001-13819
   HOSHOWSKY B, 1994, LARYNGOSCOPE, V104, P140
   Izquierdo M, 2002, EUR J APPL PHYSIOL, V87, P264, DOI 10.1007/s00421-002-0628-y
   JACOB RG, 1993, J PSYCHOPATHOL BEHAV, V15, P299, DOI 10.1007/BF00965035
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim N G, 1999, IEEE Trans Rehabil Eng, V7, P482, DOI 10.1109/86.808952
   Maki BE, 2003, IEEE ENG MED BIOL, V22, P20, DOI 10.1109/MEMB.2003.1195691
   Maki BE, 2006, AGE AGEING, V35, P12, DOI 10.1093/ageing/afl078
   McConville K, 1994, J Vestib Res, V4, P391
   McConville KMV, 2007, 2007 3RD INTERNATIONAL IEEE/EMBS CONFERENCE ON NEURAL ENGINEERING, VOLS 1 AND 2, P600, DOI 10.1109/CNE.2007.369743
   Mochizuki G, 2004, EXP BRAIN RES, V155, P352, DOI 10.1007/s00221-003-1732-x
   Newell KM, 2001, PSYCHOL REV, V108, P57, DOI 10.1037//0033-295X.108.1.57
   NORRE ME, 1988, ARCH OTOLARYNGOL, V114, P883
   Quesada Peter M., 2007, Occupational Ergonomics, V7, P3
   Shuo Wang, 2006, Conference on Human Factors in Computing Systems. CHI2006, P1097
   Silsupadol P, 2006, PHYS THER, V86, P269, DOI 10.1093/ptj/86.2.269
   Sparto P, 2004, J NEURO ENG REHABIL, V1, P1, DOI DOI 10.1186/1743-0003-1-14
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Vereeck L, 2008, INT J AUDIOL, V47, P67, DOI 10.1080/14992020701689688
   Weiss Patrice L, 2004, J Neuroeng Rehabil, V1, P12, DOI 10.1186/1743-0003-1-12
   Yamazaki Y, 2005, BRAIN RES BULL, V67, P30, DOI 10.1016/j.brainresbull.2005.05.015
NR 32
TC 16
Z9 18
U1 2
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2012
VL 16
IS 4
BP 315
EP 323
DI 10.1007/s10055-012-0212-7
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 025YG
UT WOS:000310233000005
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Lu, G
   Shark, LK
   Hall, G
   Zeshan, U
AF Lu, Gan
   Shark, Lik-Kwan
   Hall, Geoff
   Zeshan, Ulrike
TI Immersive manipulation of virtual objects through glove-based hand
   gesture interaction
SO VIRTUAL REALITY
LA English
DT Article
DE Hand gesture tracking and recognition; Immersive stereoscopic
   visualisation; Virtual object manipulation
ID REALITY; INTERFACES; MRI
AB Immersive visualisation is increasingly being used for comprehensive and rapid analysis of objects in 3D and object dynamic behaviour in 4D. Challenges are therefore presented to provide natural user interaction to enable effortless virtual object manipulation. Presented in this paper is the development and evaluation of an immersive human-computer interaction system based on stereoscopic viewing and natural hand gestures. For the development, it is based on the integration of a back-projection stereoscopic system for object and hand display, a hybrid inertial and ultrasonic tracking system to provide the absolute positions and orientations of the user's head and hands, as well as a pair of high degrees-of-freedom data gloves to provide the relative positions and orientations of digit joints and tips on both hands. For the evaluation, it is based on a two-object scene with a virtual cube and a CT (computed tomography) volume created for demonstration of real-time immersive object manipulation. The system is shown to provide a correct user view of objects and hands in 3D with depth, as well as to enable a user to use a number of simple hand gestures to perform basic object manipulation tasks involving selection, release, translation, rotation and scaling. Also included in the evaluation are some quantitative tests of the system performance in terms of speed and latency.
C1 [Lu, Gan; Shark, Lik-Kwan; Hall, Geoff] Univ Cent Lancashire, Appl Digital Signal & Image Proc Res Ctr, Preston PR1 2HE, Lancs, England.
   [Zeshan, Ulrike] Univ Cent Lancashire, Int Ctr Sign Languages & Deaf Studies, Preston PR1 2HE, Lancs, England.
C3 University of Central Lancashire; University of Central Lancashire
RP Lu, G (corresponding author), Univ Cent Lancashire, Appl Digital Signal & Image Proc Res Ctr, Preston PR1 2HE, Lancs, England.
EM glu@uclan.ac.uk
CR Adamo-Villani N., 2007, ACM P IMMERSCOM 2007, P10
   [Anonymous], SHAPEHAND DAT GLOV
   [Anonymous], IS 900 PREC IN ULTR
   Badler N. I., 1993, Simulating humans: computer graphics animation and control
   Bowman D., 2001, Proc. HCII, P629
   Corradini A., 2002, P INT CLASS WORKSH N
   Corvaglia D., 2004, Proc. of the 1st International Workshop on Web3D Technologies in Learning, Education and Training (LETWEB3D 2004), Udine, P28
   Danisch L., 1999, SENSOR REV, V19, P106, DOI DOI 10.1108/02602289910266142
   Demirdjian David., 2005, VIRTUAL REAL-LONDON, V8, P222
   Dipietro L, 2008, IEEE T SYST MAN CY C, V38, P461, DOI 10.1109/TSMCC.2008.923862
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Garg P., 2009, P WORLD ACAD SCI ENG, V49, P972
   Johnson W. L., 1997, SIGART Bulletin, V8, P16
   Kober C, 2007, SPRINGER PROC PHYS, V114, P175
   Lécuyer A, 2008, COMPUTER, V41, P66, DOI 10.1109/MC.2008.410
   Liverneaux P, 2009, CHIR MAIN, V28, P278, DOI 10.1016/j.main.2009.08.002
   O'Hagan RG, 2002, INTERACT COMPUT, V14, P231, DOI 10.1016/S0953-5438(01)00050-9
   Patel D, 2007, RADIOTHER ONCOL, V82, P218, DOI 10.1016/j.radonc.2006.11.024
   Schaver C, 2004, COMMUN ACM, V47, P32, DOI 10.1145/1012037.1012059
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Toyama H, 2006, IEIC TECH REP, V91, P53
   Wang XH, 2005, ACAD RADIOL, V12, P1512, DOI 10.1016/j.acra.2005.06.009
   WOODS AJ, 2005, P INT DISPL MAN C TA
   Wormell D., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P47, DOI 10.1145/769953.769959
   Zhang S, 2001, IEEE VISUAL, P437, DOI 10.1109/VISUAL.2001.964545
NR 25
TC 28
Z9 30
U1 2
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2012
VL 16
IS 3
BP 243
EP 252
DI 10.1007/s10055-011-0195-9
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 990MV
UT WOS:000307635900006
DA 2024-07-18
ER

PT J
AU Simard, J
   Ammi, M
AF Simard, Jean
   Ammi, Mehdi
TI Haptic interpersonal communication: improvement of actions coordination
   in collaborative virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Collaborative virtual environments; Haptics; Awareness; Sensorial
   communication; Communication metaphors
ID GROUPWARE; SUPPORT; VIDEO
AB This article explores the use of haptic feedback for interpersonal communication in collaborative virtual environments. After a detailed presentation of all communication mechanisms involved, we propose the investigation of a low-level communication approach through the feedthrough mechanism. This channel is used to communicate kinematic information about a partner's gestures during closely coupled collaboration. Several communication metaphors, with complementary behaviors, were investigated to improve the coordination between two partners during an assembly task. The results clearly show the role of communication strategies for the improvement of gesture coordination and highlight the correlation between applied force and the level of efficiency.
C1 [Simard, Jean; Ammi, Mehdi] Univ Paris Sud, LIMSI CNRS, Orsay, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Cite
RP Ammi, M (corresponding author), Univ Paris Sud, LIMSI CNRS, Orsay, France.
EM Jean.Simard@limsi.fr; Mehdi.Ammi@limsi.fr
CR Ammi M, 2007, IEEE INT CONF ROBOT, P454, DOI 10.1109/ROBOT.2007.363828
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   BLY SA, 1993, COMMUN ACM, V36, P28, DOI 10.1145/151233.151235
   Catlin T., 1989, SIGCHI Bulletin, P365
   Cha J, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596993
   Chan A, 2008, INT J HUM-COMPUT ST, V66, P333, DOI 10.1016/j.ijhcs.2007.11.002
   Cockburn A, 1999, INT J HUM-COMPUT INT, V11, P231, DOI 10.1207/S15327590IJHC1103_3
   Codella C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P329, DOI 10.1145/142750.142825
   Collier G., 1985, EMOTIONAL EXPRESSION
   Dix A., 1997, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V6, P135, DOI 10.1023/A:1008635907287
   ELLIS CA, 1991, COMMUN ACM, V34, P38
   Enriquez M., 2006, Proceedings of the 8th international conference on Multimodal interfaces (ICMI '06), P302, DOI DOI 10.1145/1180995.1181053
   Gentry S., 2005, THESIS MIT
   Glynn S.J., 2001, P HUMAN FACTORS ERGO, V45, P1911
   Grasset R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P90
   Grasset R, 2004, ENV REALITE AUGMENTE
   Gutwin C., 1999, ACM Transactions on Computer-Human Interaction, V6, P243, DOI 10.1145/329693.329696
   Gutwin C, 2000, IEEE 9TH INTERNATIONAL WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P98, DOI 10.1109/ENABL.2000.883711
   Hill J., 2003, P 2003 INT ACM SIGGR, P258, DOI DOI 10.1145/958160.958201
   Kjolberg J., 2002, P EUR 02 MAY 2002, P71
   Marsh J, 2006, IEEE T VIS COMPUT GR, V12, P405, DOI 10.1109/TVCG.2006.40
   Negron APP, 2009, WORKSH INT INN SUPP, P19
   Pinelle D., 2003, ACM Transactions on Computer-Human Interaction, V10, P281, DOI 10.1145/966930.966932
   Redfern S., 2002, Journal of Information Technology Education, V1
   Reed KB, 2008, IEEE T HAPTICS, V1, P108, DOI 10.1109/ToH.2008.13
   Sallnas E.-L., 2000, ACM Transactions on Computer-Human Interaction, V7, P461, DOI 10.1145/365058.365086
   Shergill SS, 2003, SCIENCE, V301, P187, DOI 10.1126/science.1085327
   Simard J, 2010, P 17 ACM S VIRT REAL, V1, P181
   Takemura H., 1992, CSCW '92. Sharing Perspectives. Proceedings of the Conference on Computer-Supported Cooperative Work, P226, DOI 10.1145/143457.269747
   Varadaradjou ES, 2006, VIRT REAL INT C ROCQ, P103
   Yano H, 1994, IPSJ SIG NOTES, V94, P31
   Ye-Seul Kim, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P3371
NR 32
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2012
VL 16
IS 3
BP 173
EP 186
DI 10.1007/s10055-011-0201-2
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 990MV
UT WOS:000307635900001
DA 2024-07-18
ER

PT J
AU Aleotti, J
   Caselli, S
AF Aleotti, Jacopo
   Caselli, Stefano
TI Physics-based virtual reality for task learning and intelligent
   disassembly planning
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Disassembly planning; Precedence graphs; Physics-based
   animation; Programming by demonstration
ID ASSEMBLIES
AB Physics-based simulation is increasingly important in virtual manufacturing for product assembly and disassembly operations. This work explores potential benefits of physics-based modeling for automatic learning of assembly tasks and for intelligent disassembly planning in desktop virtual reality. The paper shows how realistic physical animation of manipulation tasks can be exploited for learning sequential constraints from user demonstrations. In particular, a method is proposed where information about physical interaction is used to discover task precedences and to reason about task similarities. A second contribution of the paper is the application of physics-based modeling to the problem of disassembly sequence planning. A novel approach is described to find all physically admissible subassemblies in which a set of rigid objects can be disassembled. Moreover, efficient strategies are presented aimed at reducing the computational time required for automatic disassembly planning. The proposed strategies take into account precedence relations arising from user assembly demonstrations as well as geometrical clustering. A motion planning technique has also been developed to generate non-destructive disassembly paths in a query-based approach. Experiments have been performed in an interactive virtual environment including a dataglove and motion tracker that allows realistic object manipulation and grasping.
C1 [Aleotti, Jacopo; Caselli, Stefano] Univ Parma, Dipartimento Ingn Informaz, I-43100 Parma, Italy.
C3 University of Parma
RP Aleotti, J (corresponding author), Univ Parma, Dipartimento Ingn Informaz, Viale GP Usberti 181-A, I-43100 Parma, Italy.
EM aleotti@ce.unipr.it; caselli@ce.unipr.it
RI Caselli, Stefano/HLX-0917-2023
OI Caselli, Stefano/0000-0003-0774-7871
FU Laboratory AER-TECH of Regione Emilia-Romagna, Italy
FX This research is partially supported by Laboratory AER-TECH of Regione
   Emilia-Romagna, Italy.
CR Aguinaga I, 2008, INT J ADV MANUF TECH, V36, P1221, DOI 10.1007/s00170-007-0930-2
   ALEOTTI J, 2007, IEEE RSJ INT C INT R
   ALEOTTI J, 2009, IEEE INT C ROB AUT K
   BERGAMASCO M, 1994, IEEE RSJ GI INT C AD, P3489
   BORST CW, 2005, IEEE C VIRT REAL, P2938
   CHEN K, 1994, IEEE INT CONF ROBOT, P1476, DOI 10.1109/ROBOT.1994.351282
   Cortés J, 2008, IEEE T ROBOT, V24, P475, DOI 10.1109/TRO.2008.915464
   DEMELLO LSH, 1990, IEEE T ROBOTIC AUTOM, V6, P188, DOI 10.1109/70.54734
   Dong TY, 2006, INT J ADV MANUF TECH, V30, P507, DOI 10.1007/s00170-005-0036-7
   GADH R, 1998, IEEE ANN REL MAINT S
   Garbaya Samir, 2007, Virtual Reality, V11, P287, DOI 10.1007/s10055-007-0075-5
   HALPERIN D, 1998, ACM ANN S COMP GEOM
   HIROTA K, 2003, IEEE C VIRT REAL
   Howard Brad M., 2007, Virtual Reality, V11, P207, DOI 10.1007/s10055-007-0069-3
   HUAGEN W, 2004, ACM SIGGRAPH INT C V, P81
   IKEUCHI K, 1994, IEEE T ROBOTIC AUTOM, V10, P368, DOI 10.1109/70.294211
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   LEE S, 1994, IEEE T SYST MAN CYB, V24, P493, DOI 10.1109/21.278997
   LEE S, 1993, IEEE INT C ROB AUT A
   LEE SH, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pB521
   Lim T., 2007, Virtual Reality, V11, P241, DOI 10.1007/s10055-007-0072-8
   Loomis A, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4181, DOI 10.1109/IROS.2006.281910
   Mattikalli R, 1996, IEEE T ROBOTIC AUTOM, V12, P290, DOI 10.1109/70.488948
   MATTIKALLI RS, 1990, IEEE INTERNATIONAL CONFERENCE ON SYSTEMS ENGINEERING /, P399, DOI 10.1109/ICSYSE.1990.203181
   Mosemann H, 1997, IEEE T ROBOTIC AUTOM, V13, P805, DOI 10.1109/70.650159
   OGATA H, 1994, IEEE T ROBOTIC AUTOM, V10, P391, DOI 10.1109/70.294213
   OGAWARA K, 2003, P IEEE INT C ROB AUT
   Ong NS, 1999, INT J ADV MANUF TECH, V15, P425, DOI 10.1007/s001700050086
   Pardowitz M, 2005, IEEE-RAS INT C HUMAN, P424
   Ramos C, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON ASSEMBLY AND TASK PLANNING (ISATP'97) - TOWARDS FLEXIBLE AND AGILE ASSEMBLY AND MANUFACTURING, P19, DOI 10.1109/ISATP.1997.615378
   Sappa AD, 2004, IEEE INT CONF ROBOT, P5287, DOI 10.1109/ROBOT.2004.1302557
   Sundaram S, 2001, IEEE INT CONF ROBOT, P1475, DOI 10.1109/ROBOT.2001.932818
   SUNG R, 2009, ASME AFM WORLD C INN
   Torres F, 2003, INT J ADV MANUF TECH, V21, P317, DOI 10.1007/s001700300037
   WAARTS JJ, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P2431, DOI 10.1109/ROBOT.1992.220100
   ZAEH MF, 2004, INT C ART REAL TEL
   Zöllner R, 2005, IEEE INT CONF ROBOT, P1535
NR 37
TC 30
Z9 32
U1 0
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2011
VL 15
IS 1
SI SI
BP 41
EP 54
DI 10.1007/s10055-009-0145-y
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HZ
UT WOS:000296280000004
DA 2024-07-18
ER

PT J
AU Wong, EYC
   Hui, RTY
   Kong, H
AF Wong, Eugene Yin-cheung
   Hui, Ray Tak-yin
   Kong, Hao
TI Perceived usefulness of, engagement with, and effectiveness of virtual
   reality environments in learning industrial operations: the moderating
   role of openness to experience
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Pedagogical development; Openness to experience;
   Perceived usefulness of VR; Attitude towards learning; Technology
   acceptance model
ID 5 PERSONALITY-TRAITS; TECHNOLOGY ACCEPTANCE MODEL; TASK COMPLEXITY; USER
   ACCEPTANCE; SELF-EFFICACY; MEDIATION; EDUCATION; PERFORMANCE; STYLES;
   DESIGN
AB The development of virtual reality (VR) in enhancing the effectiveness of the learning process, with its interactive, immersive, and intuitive pedagogical environment, has become a necessity for corporations with increasingly complex operations. However, VR users' perceptions, openness and learning effectiveness are seldom comprehensively evaluated, particularly in learning complex industrial operations. In this study, grounded in the technology acceptance model, a moderated mediation model of perceived usefulness, ease of use, openness to experience, and engagement in VR-based learning was developed. The model was empirically validated using responses collected from 321 users who were trained on aircraft and cargo terminal operations powered by a novel VR-based learning platform. A survey to measure openness to experience and a pre-training performance test were carried out, followed by a post-training survey of learners' intrinsic factors, including the influence of perceived usefulness, openness to experience, and attitude towards learning. The study revealed that learners with an open attitude towards experiencing new technology tend to perceive VR technology as a useful platform for training. In addition, the learners with more positive views of VR technology-supported training were more engaged in learning.
C1 [Wong, Eugene Yin-cheung] Hang Seng Univ Hong Kong, Sch Decis Sci, Dept Supply Chain & Informat Management, Hong Kong, Peoples R China.
   [Hui, Ray Tak-yin] Nagaya Univ Commerce & Business, NUCB Business Sch, Nagoya, Japan.
   [Kong, Hao] Hang Seng Univ Hong Kong, Sch Business, Dept Management, Hong Kong, Peoples R China.
C3 Hang Seng University of Hong Kong; Hang Seng University of Hong Kong
RP Wong, EYC (corresponding author), Hang Seng Univ Hong Kong, Sch Decis Sci, Dept Supply Chain & Informat Management, Hong Kong, Peoples R China.
EM eugenewong@hsu.edu.hk; ray_hui@nucba.ac.jp; hkong@hsu.edu.hk
OI Hui, Ray Tak-yin/0000-0001-7133-7370
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [UGC/IIDS14/B01/21]; Education Bureau of the Hong Kong Special
   Administrative Region, China [T02/QESS/2020]; Virtual Reality Centre,
   the Hang Seng University of Hong Kong
FX The study was partially supported by a Research Grants Council of the
   Hong Kong Special Administrative Region, China (UGC/IIDS14/B01/21) and a
   Quality Enhancement Support Schemes grant from the Education Bureau of
   the Hong Kong Special Administrative Region, China (T02/QESS/2020). The
   study was also supported by Virtual Reality Centre, the Hang Seng
   University of Hong Kong.
CR Abulrub A. G., 2011, 2011 IEEE Global Engineering Education Conference (EDUCON), P751, DOI 10.1109/EDUCON.2011.5773223
   Aiken MP, 2015, VIRTUAL REAL-LONDON, V19, P95, DOI 10.1007/s10055-015-0260-x
   Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI 10.1007/978-3-642-69746-3_2
   Akbulut A, 2018, COMPUT APPL ENG EDUC, V26, P918, DOI 10.1002/cae.21935
   Alsop T, 2022, AUGMENTED REALITY AR
   Alsop T, INVESTMENT AUGMENTED
   Armitage CJ, 2001, BRIT J SOC PSYCHOL, V40, P471, DOI 10.1348/014466601164939
   BANDURA A, 1983, J PERS SOC PSYCHOL, V45, P1017, DOI 10.1037/0022-3514.45.5.1017
   BARRICK MR, 1991, PERS PSYCHOL, V44, P1, DOI 10.1111/j.1744-6570.1991.tb00688.x
   Bawack RE, 2021, INT J INFORM MANAGE, V58, DOI 10.1016/j.ijinfomgt.2021.102309
   Beach L.R., 1978, ACAD MANAGE REV, V3, P439, DOI DOI 10.5465/AMR.1978.4305717
   Bertrand M., 2008, Journal of CyberTherapy and Rehabilitation, V1, P200, DOI DOI 10.1007/S11528-007-0024-X
   Birrenbach T, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29586
   Blasco-Arcas L, 2013, COMPUT EDUC, V62, P102, DOI 10.1016/j.compedu.2012.10.019
   Bourhim E, 2020, INT J HUM-COMPUT ST, V142, DOI 10.1016/j.ijhcs.2020.102484
   Bracq MS, 2019, SIMUL HEALTHC, V14, P188, DOI 10.1097/SIH.0000000000000347
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Burmester A, 2008, EDMEDIA INNOVATE LEA, P5843
   Busato VV, 1999, PERS INDIV DIFFER, V26, P129
   Calisir F, 2014, HUM FACTOR ERGON MAN, V24, P515, DOI 10.1002/hfm.20548
   Chang CW, 2018, IEEE ACCESS, V6, P66590, DOI 10.1109/ACCESS.2018.2878270
   Chang SE, 2005, COMPUT HUM BEHAV, V21, P713, DOI 10.1016/j.chb.2004.02.021
   Chang SC, 2020, INTERACT LEARN ENVIR, V28, P915, DOI 10.1080/10494820.2018.1548490
   Chen LW, 2019, COMPUT APPL ENG EDUC, V27, P1043, DOI 10.1002/cae.22133
   Chen PSD, 2010, COMPUT EDUC, V54, P1222, DOI 10.1016/j.compedu.2009.11.008
   Chirieleison Jr A, 2004, U.S. Patent, Patent No. [6,744,436, 6744436]
   Chow IHS, 2018, LEADERSHIP ORG DEV J, V39, P202, DOI 10.1108/LODJ-03-2016-0060
   Chow M, 2012, COMPUT EDUC, V59, P1136, DOI 10.1016/j.compedu.2012.05.011
   Costa P.T., 1992, REVISED NEO PERSONAL
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Czernuszenko M., 1997, Computer Graphics, V31, P46, DOI 10.1145/271283.271303
   Davis F.D., 1986, TECHNOLOGY ACCEPTANC
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Demiralp Ç, 2006, IEEE T VIS COMPUT GR, V12, P323, DOI 10.1109/TVCG.2006.42
   Devaraj S, 2008, INFORM SYST RES, V19, P93, DOI 10.1287/isre.1070.0153
   DeYoung CG, 2014, J PERS ASSESS, V96, P46, DOI 10.1080/00223891.2013.806327
   Ding D, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102400
   Duderstadt JamesJ., 2002, Higher Education in the Digital Age: Technology Issues and Strategies for American Colleges and Universities
   Durodolu O.O., 2016, Library Philosophy and Practice e-journal
   Fishbein M, 1977, Belief, attitude, intention, and behavior: An introduction to theory and research, V5, P177
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fussell SG, 2022, VIRTUAL REAL-LONDON, V26, P249, DOI 10.1007/s10055-021-00554-x
   Gao L, 2021, INT J HUM-COMPUT INT, V37, P1771, DOI 10.1080/10447318.2021.1913858
   Izard SG, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0900-2
   Guan JQ, 2023, INTERACT LEARN ENVIR, V31, P2016, DOI 10.1080/10494820.2021.1871631
   Guo ZY, 2018, COMPUT IND, V101, P41, DOI 10.1016/j.compind.2018.06.007
   Haji FA, 2016, MED EDUC, V50, P955, DOI 10.1111/medu.13086
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Han H.-C., 2015, ART EDUC, V68, P22, DOI DOI 10.1080/00043125.2015.11519344
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   Heilig M, 1962, Patent No. [3,050,870, 3050870]
   Hilfert Thomas, 2016, Visualization in Engineering, V4, DOI 10.1186/s40327-015-0031-5
   Horowitz K., 2004, Sega VR: Great Idea or Wishful Thinking?
   Hu PJH, 2012, DECIS SUPPORT SYST, V53, P782, DOI 10.1016/j.dss.2012.05.014
   Huang HM, 2018, INT REV RES OPEN DIS, V19, P91
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang W, 2021, J COMPUT ASSIST LEAR, V37, P745, DOI 10.1111/jcal.12520
   Huang YC, 2014, INT C HUM COMP INT, P579, DOI DOI 10.1007/978-3-319-07857-1_102
   Hui RTY, 2021, INT J HUM RESOUR MAN, V32, P4163, DOI 10.1080/09585192.2019.1569547
   Hui RTY, 2013, HUM RESOUR DEV Q, V24, P429, DOI 10.1002/hrdq.21170
   Jackson JJ, 2012, PSYCHOL AGING, V27, P286, DOI 10.1037/a0025918
   Jena RK, 2016, BEHAV INFORM TECHNOL, V35, P946, DOI 10.1080/0144929X.2016.1212930
   John O.P., 1999, HDB PERSONALITY THEO, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260
   Jou M, 2013, COMPUT HUM BEHAV, V29, P433, DOI 10.1016/j.chb.2012.04.020
   Kalantari M, 2018, PROGR IS, P229, DOI 10.1007/978-3-319-64027-3_16
   Kapoor K, 2022, ANAT HISTOL EMBRYOL, V51, P163, DOI 10.1111/ahe.12783
   Katrimpouza A, 2019, INNOV EDUC TEACH INT, V56, P25, DOI 10.1080/14703297.2017.1392890
   Kaufman SB, 2010, COGNITION, V116, P321, DOI 10.1016/j.cognition.2010.05.011
   Kaufmann H, 2006, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VR.2006.48
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Komarraju M, 2011, PERS INDIV DIFFER, V51, P472, DOI 10.1016/j.paid.2011.04.019
   Krueger Myron W., 1985, Proceedings of the SIGCHI conference on Human factors in computing systems, P35, DOI [10.1145/1165385.317463, DOI 10.1145/1165385.317463, 10.1145/317456.317463]
   Lanier J, 1989, P UISE ANN ACM SIGGR
   Lau HYK, 2009, ADV INTEL SOFT COMPU, V60, P313
   Lau H, 2007, INT J INTERACT DES M, V1, P107, DOI 10.1007/s12008-007-0013-5
   Lee EL, 2009, LEARNING EFFECTIVENE
   Lee EAL, 2010, LECT NOTES COMPUT SC, V6250, P79, DOI 10.1007/978-3-642-14484-4_8
   Li S, 2014, P 2014 VIRT REAL INT, P8
   Limniou M, 2008, COMPUT EDUC, V51, P584, DOI 10.1016/j.compedu.2007.06.014
   Lohre Ryan, 2020, J Spine Surg, V6, pS208, DOI 10.21037/jss.2019.11.16
   Luckey P., 2013, Building a sensor for low latency virtual reality - Oculus Rift - virtual reality headset for 3d gaming
   Luo H, 2021, J COMPUT ASSIST LEAR, V37, P887, DOI 10.1111/jcal.12538
   Lyons FA, 2016, U.S. Patent, Patent No. [D751,072, 751072]
   Madrid HP, 2016, LEARN INDIVID DIFFER, V51, P409, DOI 10.1016/j.lindif.2015.07.010
   Madrid HP, 2014, J ORGAN BEHAV, V35, P234, DOI 10.1002/job.1867
   Martinez JJ, 2020, INT J CONTROL, V93, P2314, DOI [10.1080/00207179.2018.1554910, 10.1109/ISCAS.2018.8351861]
   Massei Marina, 2013, International Journal of Simulation and Process Modelling, V8, P42
   Matsas E, 2018, ROBOT CIM-INT MANUF, V50, P168, DOI 10.1016/j.rcim.2017.09.005
   Matz SC, 2021, J PERS SOC PSYCHOL, V121, P1284, DOI 10.1037/pspp0000324
   McCrae R.R., 1985, PERSPECTIVES PERSONA, P145, DOI [DOI 10.1002/9781118367377.CH12, 10.1002/9781118367377.ch12]
   Müller D, 2007, INT J ONLINE ENG, V3, P15
   Murphy M, 2016, TECHWORLD
   Ng KY, 2008, J APPL PSYCHOL, V93, P733, DOI 10.1037/0021-9010.93.4.733
   North Max M., 2016, Australasian Journal of Information Systems, V20, P1
   Parker E, 2020, CONVERGENCE-US, V26, P1159, DOI 10.1177/1354856519897251
   Peter Z., 2008, PRODUCT ENG TOOLS ME, P277
   Petrov C, 2019, TECHJURY
   Preacher KJ, 2004, BEHAV RES METH INS C, V36, P717, DOI 10.3758/BF03206553
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Preacher KJ, 2007, MULTIVAR BEHAV RES, V42, P185, DOI 10.1080/00273170701341316
   Puente-Díaz R, 2022, PERS INDIV DIFFER, V185, DOI 10.1016/j.paid.2021.111240
   PytlikZillig LM, 2011, CONTEMP EDUC PSYCHOL, V36, P302, DOI 10.1016/j.cedpsych.2011.07.002
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Reznek MA, 2002, ACAD EMERG MED, V9, P1319
   Rovira A, 2017, INT J HUM-COMPUT ST, V98, P89, DOI 10.1016/j.ijhcs.2016.10.007
   Russell J., 2016, Journal of Geoscience Education, V64, P37, DOI [10.5408/15-084.1, DOI 10.5408/15-084.1]
   Sampaio AZ, 2014, AUTOMAT CONSTR, V37, P58, DOI 10.1016/j.autcon.2013.10.015
   Shrout PE, 2002, PSYCHOL METHODS, V7, P422, DOI 10.1037//1082-989X.7.4.422
   Soffer T, 2018, J COMPUT ASSIST LEAR, V34, P534, DOI 10.1111/jcal.12258
   Soliman M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062879
   Song H, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103506
   Sterling Rod., 2008, P 2008 WORKSHOP IMME, P10
   Tabatabaei SS., 2018, CURR CONTENTS, V13, P49
   Tarr MJ, 2002, NAT NEUROSCI, V5, P1089, DOI 10.1038/nn948
   Time, 2016, TIME TECH
   Trentsios P, 2020, INT C REM ENG VIRT I, P375
   Vasileva S., 2019, J INT COOP DEV, V2, P34, DOI [10.36941/jicd-2019-0005, DOI 10.36941/JICD-2019-0005]
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Wedlock B.C., 2019, Research Issues in Contemporary Education, V4, P6
   Widyanti A, 2022, VIRTUAL REAL-LONDON, V26, P631, DOI 10.1007/s10055-021-00525-2
   Won J., 2021, J POSIT PSYCHOL WELL, V5, P578
   Wong EYC, 2021, INT J COMPUT INTEG M, V34, P801, DOI 10.1080/0951192X.2020.1775299
   Xi NN, 2023, INFORM SYST FRONT, V25, P659, DOI 10.1007/s10796-022-10244-x
   Xu M, 2022, IEEE ICC, P5220, DOI 10.1109/ICC45855.2022.9838736
   Yusoff Rasimah Che Mohd, 2011, Australasian Journal of Educational Technology, V27, P1369
   Zhang M, 2022, AUTOMAT CONSTR, V135, DOI 10.1016/j.autcon.2021.104113
   Zhang X, 2017, BEHAV INFORM TECHNOL, V36, P548, DOI 10.1080/0144929X.2016.1268647
NR 130
TC 7
Z9 7
U1 14
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2149
EP 2165
DI 10.1007/s10055-023-00793-0
EA APR 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000975233300001
PM 37360804
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Simons, A
   Wohlgenannt, I
   Zelt, S
   Weinmann, M
   Schneider, J
   vom Brocke, J
AF Simons, Alexander
   Wohlgenannt, Isabell
   Zelt, Sarah
   Weinmann, Markus
   Schneider, Johannes
   vom Brocke, Jan
TI Intelligence at play: game-based assessment using a virtual-reality
   application
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Video games; Recruitment; Assessment; Intelligence;
   Cognition
ID VIDEO GAMES; STEALTH ASSESSMENT; BERLIN MODEL; SKILLS; PERFORMANCE;
   VALIDITY; ABILITY; SPEED; FLUID
AB Several studies have shown that video games may indicate or even develop intellectual and cognitive abilities. As intelligence is one of the most widely used predictors of job performance, video games could thus have potential for personnel assessment. However, few studies have investigated whether and how virtual reality (VR) games can be used to make inferences about intelligence, even though companies increasingly use VR technology to recruit candidates. This proof-of-concept study contributes to bridging this gap between research and practice. Under controlled laboratory conditions, 103 participants played the commercial VR game Job Simulator and took the short version of the intelligence test BIS-4. Correlation and regression analysis reveal that, on average, participants who completed the game more quickly than others had higher levels of general intelligence and processing capacity, suggesting that VR games may provide useful supplementary tools in the prediction of job performance. Still, our results also indicate that game-based assessments have limitations that deserve researchers' attention, which lead us to discuss directions for future research.
C1 [Simons, Alexander; Wohlgenannt, Isabell; Zelt, Sarah; Schneider, Johannes; vom Brocke, Jan] Univ Liechtenstein, Fuerst Franz Josef Str, FL-9490 Vaduz, Liechtenstein.
   [Weinmann, Markus] Univ Cologne, Albert Magnus Pl, D-50923 Cologne, Germany.
   [Simons, Alexander] Vorarlberg Univ Appl Sci, CAMPUS 5,Hochschulstr 1, A-6850 Dornbirn, Austria.
C3 University of Liechtenstein; University of Cologne
RP vom Brocke, J (corresponding author), Univ Liechtenstein, Fuerst Franz Josef Str, FL-9490 Vaduz, Liechtenstein.
EM jan.vom.brocke@uni.li
FU University of Liechtenstein; Liechtenstein National Research Fund
   [wi-1-16]
FX Open access funding provided by University of Liechtenstein. Financial
   support was received from the Liechtenstein National Research Fund under
   grant number wi-1-16.
CR Ackerman PL, 2000, J EXP PSYCHOL-APPL, V6, P259, DOI 10.1037//1076-898X.6.4.259
   Aguinis H, 2001, INT J SELECT ASSESS, V9, P70, DOI 10.1111/1468-2389.00164
   Quiroga MA, 2015, INTELLIGENCE, V53, P1, DOI 10.1016/j.intell.2015.08.004
   Quiroga MA, 2011, INT J ONLINE PEDAGOG, V1, P18, DOI 10.4018/ijopcd.2011070102
   Arthur W, 2003, PERS PSYCHOL, V56, P125, DOI 10.1111/j.1744-6570.2003.tb00146.x
   Baniqued PL, 2013, ACTA PSYCHOL, V142, P74, DOI 10.1016/j.actpsy.2012.11.009
   Barber CS, 2017, P 38 INT C INFORM SY
   Barr M, 2017, COMPUT EDUC, V113, P86, DOI 10.1016/j.compedu.2017.05.016
   Beauducel A, 2002, EUR J PSYCHOL ASSESS, V18, P97, DOI 10.1027//1015-5759.18.2.97
   Bhatia S, 2018, RES HUM R M, P81
   Bina S., 2021, Proceedings of the 54th Hawaii International Conference on System Sciences p, P1325, DOI DOI 10.24251/HICSS.2021.161
   Boot WR, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00003
   Brunner M, 2005, EDUC PSYCHOL MEAS, V65, P227, DOI 10.1177/0013164404268669
   Bucik V, 1996, PERS INDIV DIFFER, V21, P987, DOI 10.1016/S0191-8869(96)00129-8
   Buday R, 2012, GAMES HEALTH J, V1, P257, DOI 10.1089/g4h.2012.0026
   Bürkner PC, 2018, R J, V10, P395
   Buford CC, 2015, INT J GAMING COMPUT-, V7, DOI 10.4018/IJGCMS.2015100101
   Carpenter Bob, 2017, J Stat Softw, V76, DOI 10.18637/jss.v076.i01
   Climent G, 2021, APPL NEUROPSYCH-ADUL, V28, P403, DOI 10.1080/23279095.2019.1646745
   Consultancy.uk, 2019, BDO TRIALL VIRT REAL
   Debusmann B, 2021, BRIT BROADCASTING CO
   Entertainment Software Association, 2020, 2020 ESS FACTS VID G
   Fetzer M., 2017, WILEY BLACKWELL HDB, P293
   Fetzer M., 2015, IND ORG PSYCHOL, V52, P117
   Foroughi CK, 2016, INTELLIGENCE, V56, P58, DOI 10.1016/j.intell.2016.02.011
   Half Robert, 2017, STAND OUT SKILLS TOD
   Hallgren Kevin A, 2012, Tutor Quant Methods Psychol, V8, P23
   Hausknecht JP, 2004, PERS PSYCHOL, V57, P639, DOI 10.1111/j.1744-6570.2004.00003.x
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI [DOI 10.1080/10618600.1996.10474713, 10.2307/1390807, DOI 10.2307/1390807]
   Jager A.O., 1997, Berliner Intelligenzstruktur-Test (BIS-Test): Form 4
   Keith M., 2018, AIS T HUMAN COMPUTER, V10, P205, DOI DOI 10.17705/1THCI.00110
   Koch M, 2021, INTELLIGENCE, V89, DOI 10.1016/j.intell.2021.101596
   Kokkinakis AV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186621
   Krause DE, 2014, INT J SELECT ASSESS, V22, P384, DOI 10.1111/ijsa.12085
   Kruschke JK, 2012, ORGAN RES METHODS, V15, P722, DOI 10.1177/1094428112457829
   Kuo I, 2013, WHY WIBIDATAS PORTAL
   Landers RN, 2022, INT J SELECT ASSESS, V30, P1, DOI 10.1111/ijsa.12376
   Latham Andrew J, 2013, Front Psychol, V4, P941, DOI 10.3389/fpsyg.2013.00941
   Leutner F, 2021, J MANAGE PSYCHOL, V36, P533, DOI 10.1108/JMP-01-2020-0023
   Lievens F.R. O., 2017, Handbook of Employee Selection, P342, DOI DOI 10.4324/9781315690193-15
   Lim Jessie, 2018, Computer Games Journal, V7, P27, DOI 10.1007/s40869-018-0053-z
   Lisk TC, 2012, SIMULAT GAMING, V43, P133, DOI 10.1177/1046878110391975
   Lloyds Banking Group, 2021, VIRT REAL ASS BRING
   Lopez-Fernandez O, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00454
   Lucas K, 2004, COMMUN RES, V31, P499, DOI 10.1177/0093650204267930
   McElreath R., 2020, STAT RETHINKING BAYE, DOI DOI 10.1201/9780429029608
   Mcpherson J, 2008, BEHAV RES METHODS, V40, P969, DOI 10.3758/BRM.40.4.969
   Melchers KG, 2022, INT J SELECT ASSESS, V30, P48, DOI 10.1111/ijsa.12337
   Peters H, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106701
   Petter S, 2018, MIS Q EXEC, V17, P315, DOI 10.17705/2msqe.00004
   Quiroga M., 2020, CAMBRIDGE HDB INTELL, P626, DOI [10.1017/9781108770422, DOI 10.1017/9781108770422]
   Quiroga MA, 2019, INTELLIGENCE, V75, P85, DOI 10.1016/j.intell.2019.05.001
   Quiroga MA, 2016, SPAN J PSYCHOL, V19, DOI 10.1017/sjp.2016.84
   Quiroga MA, 2009, COMPUT EDUC, V53, P414, DOI 10.1016/j.compedu.2009.02.017
   RABBITT P, 1989, ACTA PSYCHOL, V71, P243, DOI 10.1016/0001-6918(89)90011-5
   Rubenfire A, 2014, WALL STR J
   Sanchez DR, 2022, INT J SELECT ASSESS, V30, P103, DOI 10.1111/ijsa.12369
   Schmidt F.L., 2016, VALIDITY UTILITY SEL, DOI DOI 10.13140/RG.2.2.18843.26400
   Schneider J., 2018, Contemporary intellectual assessment: Theories, tests, and issues, P73, DOI DOI 10.1002/9781118660584.ESE0431
   Shute VJ, 2021, COMPUT HUM BEHAV, V116, DOI 10.1016/j.chb.2020.106647
   Shute VJ, 2016, COMPUT HUM BEHAV, V63, P106, DOI 10.1016/j.chb.2016.05.047
   Shute VJ, 2015, COMPUT EDUC, V80, P58, DOI 10.1016/j.compedu.2014.08.013
   Simons A, 2021, REV MANAG SCI, V15, P957, DOI 10.1007/s11846-020-00378-0
   Sourmelis T, 2017, COMPUT HUM BEHAV, V67, P41, DOI 10.1016/j.chb.2016.10.020
   Su H.-M., 2005, Handbook of understanding and measuring intelligence, P313, DOI [DOI 10.4135/9781452233529.N18, 10.4135/9781452233529.n18]
   Süss HM, 2002, INTELLIGENCE, V30, P261, DOI 10.1016/S0160-2896(01)00100-3
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Unsworth N, 2015, PSYCHOL SCI, V26, P759, DOI 10.1177/0956797615570367
   Valmaggia L, 2017, WORLD PSYCHIATRY, V16, P246, DOI 10.1002/wps.20443
   van der Linden WJ, 2006, J EDUC BEHAV STAT, V31, P181, DOI 10.3102/10769986031002181
   Vichitvanichphong Suchada, 2016, Australasian Journal of Information Systems, V20, P1
   Wais PE, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82109-3
   Wan B, 2021, IEEE ACCESS, V9, P18326, DOI 10.1109/ACCESS.2021.3053621
   Weidner N, 2019, CAMB HANDB PSYCHOL, P151
   Weiner EJ, 2020, INT J SELECT ASSESS, V28, P215, DOI 10.1111/ijsa.12295
   Weis S, 2007, PERS INDIV DIFFER, V42, P3, DOI 10.1016/j.paid.2006.04.027
   Wohlgenannt I, 2020, BUS INFORM SYST ENG+, V62, P455, DOI 10.1007/s12599-020-00658-9
   Wu FY, 2022, INT J SELECT ASSESS, V30, P62, DOI 10.1111/ijsa.12360
   Youtube, 2016, JOB SIM GOURM CHEF
NR 81
TC 2
Z9 2
U1 11
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1827
EP 1843
DI 10.1007/s10055-023-00752-9
EA MAR 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000941892900001
OA hybrid
DA 2024-07-18
ER

PT J
AU De Paolis, LT
   De Luca, V
AF De Paolis, Lucio Tommaso
   De Luca, Valerio
TI The effects of touchless interaction on usability and sense of presence
   in a virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Handheld controller; Touchless interaction; Usability; User experience;
   Presence; Virtual environment
ID USER EXPERIENCE; MOTION; VISUALIZATION; TECHNOLOGIES
AB For software applications with a significant level of user involvement, the traditional concept of usability has evolved into the more complex idea of user experience, which also covers emotional, cognitive or physical responses. In virtual reality, user experience also depends on the user perception related to some peculiarities of immersive environments, where also the devices employed for user interaction play a determinant role. This has led to the design of the Presence Questionnaire (PQ) for the evaluation of the effectiveness of virtual environments. This work analyzes the effects of two different interaction modalities on usability and sense of presence: in particular, the Myo armband, a gesture-based device for touchless interaction, is compared with the Vive handheld controller bundled with the HTC Vive headset. A total of 84 subjects were recruited to test the virtual environment and asked them to fill in a questionnaire obtained by combining the Usability Metric for User eXperience (UMUX) questionnaire, the System Usability Scale (SUS) and the presence questionnaire (PQ), which was specifically designed for virtual environments. A comparison between the scores obtained for the two interaction modalities revealed which questionnaire items are significantly influenced by the input interface and deduce some insights about the consequences on human factors.
C1 [De Paolis, Lucio Tommaso; De Luca, Valerio] Univ Salento, Dept Engn Innovat, Lecce, Italy.
C3 University of Salento
RP De Luca, V (corresponding author), Univ Salento, Dept Engn Innovat, Lecce, Italy.
EM lucio.depaolis@unisalento.it; valerio.deluca@unisalento.it
RI De Luca, Valerio/HGJ-6239-2022; De Luca, Valerio/JBJ-2116-2023; De
   Paolis, Lucio Tommaso/R-2421-2016
OI De Luca, Valerio/0000-0003-3018-7251; De Paolis, Lucio
   Tommaso/0000-0003-1274-9070
CR Agrawal S, 2020, J AUDIO ENG SOC, V68, P404, DOI 10.17743/jaes.2020.0039
   [Anonymous], 2018, ISO 9241-11:2018
   [Anonymous], 2010, ISO 9241-210:2010
   Arsenault D, 2005, GAMEON-NA 2005: 1st International North-American Conference on Intelligent Games and Simulation, P50
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Bailey Shannon K. T., 2019, Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018). Volume IX: Aging, Gender and Work, Anthropometry, Ergonomics for Children and Educational Environments. Advances in Intelligent Systems and Computing (AISC 826), P663, DOI 10.1007/978-3-319-96065-4_70
   Barbot B, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106431
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Benalcazar, 2017, IEEE 2 ECUADOR TECHN, P1, DOI DOI 10.1109/ETCM.2017.8247458
   Benko Hrvoje, 2009, P ACM INT C INTERACT, P93, DOI [DOI 10.1145/1731903.17319242,3, 10.1145/1731903.1731924, DOI 10.1145/1731903.1731924]
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cain B, 2004, RTOTRHFM121 NATO 2
   Cao S, 2020, VIRTUAL REAL-LONDON, V24, P503, DOI 10.1007/s10055-019-00412-x
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Charrad M, 2014, J STAT SOFTW, V61, P1
   Chen KY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1829
   Chen MY, 2015, USER DEFINED GAME IN
   Clemente M, 2014, EXPERT SYST APPL, V41, P1584, DOI 10.1016/j.eswa.2013.08.055
   Corelli F, 2020, HUCAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 2: HUCAPP, P146, DOI 10.5220/0008962401460153
   De Mauro A., 2012, INT J COMPUT ASSIST, V7, P19, DOI [10.1007/s11548-012-0700-y, DOI 10.1007/S11548-012-0700-Y]
   De Paolis Lucio Tommaso, 2018, Bioinformatics and Biomedical Engineering. 6th International Work-Conference, IWBBIO 2018. Proceedings: LNB 10814, P118, DOI 10.1007/978-3-319-78759-6_12
   De Paolis LT, 2016, 14 MED C MED BIOL EN, V57, P880
   De Paolis LT, 2020, VIRTUAL REAL-LONDON, V24, P483, DOI 10.1007/s10055-019-00409-6
   De Paolis LT, 2019, LECT NOTES COMPUT SC, V11614, P348, DOI 10.1007/978-3-030-25999-0_30
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   De Paolis LT, 2018, COMP M BIO BIO E-IV, V6, P396, DOI 10.1080/21681163.2017.1287598
   Deller M, 2006, INFORMATION VISUALIZATION-BOOK, P563
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dolopikos Christos, 2021, Advances in Information and Communication. Proceedings of the 2021 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1364), P898, DOI 10.1007/978-3-030-73103-8_65
   Dong H, 2016, ELICITATION STUDY GE
   Finstad K, 2010, INTERACT COMPUT, V22, P323, DOI 10.1016/j.intcom.2010.04.004
   Freitas ML, 2016, J EQUINE VET SCI, V46, P1, DOI 10.1016/j.jevs.2016.07.003
   Garber L, 2013, COMPUTER, V46, P22, DOI 10.1109/MC.2013.352
   Gieser SN, 2017, LECT NOTES COMPUT SC, V10280, P97, DOI 10.1007/978-3-319-57987-0_8
   Gieser S. N., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P3, DOI 10.1007/978-3-319-39907-2_1
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Grandhi SA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P821
   Hajesmaeel-Gohari S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01407-y
   HTC, 2021, HTC VIVE
   Huang D, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P523, DOI 10.1145/2807442.2807506
   Indraccolo C, 2017, LECT NOTES COMPUT SC, V10325, P63, DOI 10.1007/978-3-319-60928-7_6
   International Organization For Standardization, 1998, ISO 9241-11
   Invitto S, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030394
   Invitto S, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P88, DOI 10.4108/icst.intetain.2015.259537
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Jo YU, 2020, J MECH MED BIOL, V20, DOI 10.1142/S021951942040028X
   Jonghwa Kim, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P30
   Kang HJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P275, DOI [10.1109/VR46266.2020.00-57, 10.1109/VR46266.2020.00047]
   KIRAKOWSKI J, 1993, BRIT J EDUC TECHNOL, V24, P210, DOI 10.1111/j.1467-8535.1993.tb00076.x
   Kosmas P, 2018, TECHTRENDS, V62, P594, DOI 10.1007/s11528-018-0294-5
   Kratz L, 2012, MAKING GESTURAL INPU, P1747, DOI [10.1145/2207676.2208304, DOI 10.1145/2207676.2208304]
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lallemand C., 2020, ACM INT C PROCEEDING, DOI DOI 10.1145/3419249.3420156
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P1148, DOI 10.1080/10447318.2017.1418805
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Li M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P566, DOI [10.1109/VR46266.2020.00-26, 10.1109/VR46266.2020.1581301697128]
   Lin ACH, 2012, DECIS SUPPORT SYST, V53, P846, DOI 10.1016/j.dss.2012.05.020
   Livatino S, 2015, IEEE T IND ELECTRON, V62, P525, DOI 10.1109/TIE.2014.2334675
   Lou XL, 2021, VIRTUAL REAL-LONDON, V25, P367, DOI 10.1007/s10055-020-00461-7
   Lu LJ, 2020, IEEE T BIOMED CIRC S, V14, P681, DOI 10.1109/TBCAS.2020.3005148
   McMahan R, 2015, UTDCS0615
   Microsoft, 2021, MICR HOL 2
   Microsoft, 2021, AZ KIN DK
   Motion L., 2018, LEAP MOTION
   Moustafa K., 2017, 1 INT S HUM MENT WOR
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Nio J., 2019, SOC IMAGING SCI TECH, DOI [10.2352/ISSN.2470-1173.2019.2.ERVR-184, DOI 10.2352/ISSN.2470-1173.2019.2.ERVR-184]
   Norman Don, 2013, The design of everyday things
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Qingfeng Dai, 2021, ICCCM '21: The 2021 9th International Conference on Computer and Communications Management, P52, DOI 10.1145/3479162.3479170
   Rawat S, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P115, DOI 10.1109/SYSMART.2016.7894501
   Rhiu I, 2020, INT J IND ERGONOM, V79, DOI 10.1016/j.ergon.2020.103002
   Riva G, 2004, CYBERPSYCHOL BEHAV, V7, P402, DOI 10.1089/cpb.2004.7.402
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   Ryan Marie-Laure., 2003, Narrative as Virtual Reality: Immersion and Interactivity in Literature and Electronic Media
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Saponas TS, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Saponas TS, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P851
   Saponas TS, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P515
   Schäfer A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060715
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Steam, 2021, STEAMVR
   Tcha-Tokey K., 2017, EFFECTS USER EXPERIE
   Thill S, 2013, NEUROSCI BIOBEHAV R, V37, P491, DOI 10.1016/j.neubiorev.2013.01.012
   Tullis T., 2013, Measuring the User Experience: Collecting, Analyzing, and Presenting Usability Metrics
   Unity, 2021, Unity
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Vuletic T, 2019, INT J HUM-COMPUT ST, V129, P74, DOI 10.1016/j.ijhcs.2019.03.011
   Wan B, 2017, INT C COMP SUPP COOP, P127, DOI 10.1109/CSCWD.2017.8066682
   Waterworth EL, 2001, CYBERPSYCHOL BEHAV, V4, P203, DOI 10.1089/109493101300117893
   Webster Rustin, 2017, 2017 ASEE ANN C EXP
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wobbrock J.O., 2005, P CHI 05 HUM FACT CO, P1869, DOI [DOI 10.1145/1056808.1057043, 10.1145/1056808.1057043]
   Xie SP, 2019, IEEE ACCESS, V7, P37536, DOI 10.1109/ACCESS.2019.2891626
   Yang L., 2019, Virtual Real. Intell. Hardw, V1, P84, DOI [10.3724/SP.J.2096-5796.2018.0006, DOI 10.3724/SP.J.2096-5796.2018.0006, 10.3724/sp.j.2096-5796.2018.0006]
   Yu ML, 2019, APPL ERGON, V74, P206, DOI 10.1016/j.apergo.2018.08.012
   Zenner A, 2020, IEEE T VIS COMPUT GR, V26, P2104, DOI 10.1109/TVCG.2020.2973476
   Zocco A, 2015, LECT NOTES COMPUT SC, V9254, P432, DOI 10.1007/978-3-319-22888-4_32
NR 106
TC 5
Z9 5
U1 3
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1551
EP 1571
DI 10.1007/s10055-022-00647-1
EA APR 2022
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000787117800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Matsangidou, M
   Frangoudes, F
   Schiza, E
   Neokleous, KC
   Papayianni, E
   Xenari, K
   Avraamides, M
   Pattichis, CS
AF Matsangidou, Maria
   Frangoudes, Fotos
   Schiza, Eirini
   Neokleous, Kleanthis C.
   Papayianni, Ersi
   Xenari, Katerian
   Avraamides, Marios
   Pattichis, Constantinos S.
TI Participatory design and evaluation of virtual reality physical
   rehabilitation for people living with dementia
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Dementia; Physical rehabilitation; Eye tracking;
   Emotional health
ID EXERCISE PROGRAM; ALZHEIMERS-DISEASE; OLDER-PEOPLE; COGNITIVE
   STIMULATION; INTERVENTIONS; IMPAIRMENT; DEPRESSION; TRIAL;
   OSTEOARTHRITIS; DISABILITY
AB Emerging research confirms the need for technologically enhanced solutions to support non-pharmacological interventions which can improve the quality of life, the mental and physical health of demented people. Several types of research examined if virtual reality can be an effective solution. This paper aims to present the cyclic process of prototyping, testing, analysing, and refining the VR system in real-world clinical settings. Seven people with moderate to severe dementia were recruited. The experiment required the patients to attend three virtual reality iterations of rapid prototyping with user testing. All three iterations involved training activities with upper body movements similar to their usual physical training. A mixed-methods design measured affect and emotional behaviour using the Observed Emotion Rating Scale and the Visual Analog Scale. Content analysis was conducted following observations and interviews. During each iteration of rapid prototyping with user testing, quantitative measurements of performance, independence and time were recorded. Eye tracking and movement information were captured by the system. Finally, a simplified version of the presence and usability scales evaluated the system. The results of this study provide further evidence that virtual reality can play a significant role in the improvement of people's with dementia physical training and emotional health when is appropriately designed. The results present the vital factors which should be incorporated in a virtual reality system which are: 1) a simple interactions modality; 2) visible visual targets and continuous feedback; 3) personalized virtual environments; 4) personalized range of movements.
C1 [Matsangidou, Maria; Frangoudes, Fotos; Schiza, Eirini; Neokleous, Kleanthis C.; Avraamides, Marios; Pattichis, Constantinos S.] CYENS Ctr Excellence, Nicosia, Cyprus.
   [Papayianni, Ersi; Xenari, Katerian] Archangelos Michael Elderly People Nursing Home, Rehabil Ctr Patients Alzheimer AMEN, Nicosia, Cyprus.
RP Matsangidou, M (corresponding author), CYENS Ctr Excellence, Nicosia, Cyprus.
EM m.matsangidou@cyens.org.cy
RI Frangoudes, Fotos/ABZ-4099-2022; Pattichis, Constantinos/J-5116-2012
OI Frangoudes, Fotos/0000-0002-2543-8194; Schiza, Eirini
   C./0000-0002-3593-6605; Pattichis, Constantinos/0000-0003-1271-8151;
   Matsangidou, Maria/0000-0003-3804-5565
FU European Union [739578]; Government of the Republic of Cyprus through
   the Deputy Ministry of Research, Innovation and Digital Policy;
   "Archangelos Michael" Dementia; Alzheimer psychiatric hospital
FX We thank the "Archangelos Michael" Dementia and Alzheimer psychiatric
   hospital for providing the support to conduct this research. We also
   thank all PwD who participated in the study and their families. This
   project has received funding from the European Union's Horizon 2020
   Research and Innovation Programme under Grant Agreement No 739578 and
   the Government of the Republic of Cyprus through the Deputy Ministry of
   Research, Innovation and Digital Policy.
CR Aguirre E, 2013, INT J GERIATR PSYCH, V28, P284, DOI 10.1002/gps.3823
   Alizadehsalehi S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073225
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   Alzheimer's Society, 2017, WHAT IS DEM
   Banerjee S, 2013, HEALTH TECHNOL ASSES, V17, P1, DOI 10.3310/hta17070
   Banerjee S., 2009, USE ANTIPSYCHOTIC ME
   Bielsa VF, 2021, J PLAST RECONSTR AES, V74, P2372, DOI 10.1016/j.bjps.2021.03.066
   Brett J, 2015, AUST PRESCR, V38, P152, DOI 10.18773/austprescr.2015.055
   Brooke J., 1986, Digital equipment co ltd
   Brown D, 2015, PHYSIOTHERAPY, V101, P126, DOI 10.1016/j.physio.2015.01.002
   Cancela JM, 2016, J SCI MED SPORT, V19, P293, DOI 10.1016/j.jsams.2015.05.007
   Cheng ST, 2014, AM J GERIAT PSYCHIAT, V22, P63, DOI 10.1016/j.jagp.2013.01.060
   Clarke DE, 2008, J NEUROPSYCH CLIN N, V20, P337, DOI 10.1176/appi.neuropsych.20.3.337
   Conradsson M, 2010, AGING MENT HEALTH, V14, P565, DOI 10.1080/13607860903483078
   Crombie IK, 2004, AGE AGEING, V33, P287, DOI 10.1093/ageing/afh089
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   Doniger Glen M, 2018, Alzheimers Dement (N Y), V4, P118, DOI 10.1016/j.trci.2018.02.005
   Douglas S., 2004, Advances in Psychiatric Treatment, V10, P171, DOI DOI 10.1192/APT.10.3.171
   Eggermont LHP, 2009, BEHAV BRAIN RES, V196, P271, DOI 10.1016/j.bbr.2008.09.012
   Eisapour Mahzar, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P528, DOI 10.1177/1541931218621120
   Eisapour M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174362
   Eisapour M, 2020, J REHABIL ASSIST TER, V7, DOI 10.1177/2055668320913770
   Fenney A, 2010, ACT ADAPT AGING, V34, P303, DOI 10.1080/01924788.2010.525736
   Flynn D, 2003, CYBERPSYCHOL BEHAV, V6, P591, DOI 10.1089/109493103322725379
   Gallaway PJ, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7020022
   Gould D, 2001, J CLIN NURS, V10, P697, DOI 10.1046/j.1365-2702.2001.00525.x
   Heath M, 2016, J ALZHEIMERS DIS, V54, P923, DOI 10.3233/JAD-160288
   Hodge J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174088
   Hoey J., 2013, ACM Transactions on Interactive Intelligent Systems (TiiS), V2, P1, DOI DOI 10.1145/2395123.2395125
   Holzwarth V, 2021, VIRTUAL REAL-LONDON, V25, P1139, DOI 10.1007/s10055-021-00518-1
   Ijaz K, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/13887
   Kasl-Godley J, 2000, CLIN PSYCHOL REV, V20, P755, DOI 10.1016/S0272-7358(99)00062-8
   Kitching D, 2015, AUST PRESCR, V38, P209, DOI 10.18773/austprescr.2015.071
   Korczyn AD, 2009, J NEUROL SCI, V283, P139, DOI 10.1016/j.jns.2009.02.346
   Lawton M., 1999, J MENTAL HLTH AGING, V5, P69
   Littbrand H, 2011, AM J PHYS MED REHAB, V90, P495, DOI 10.1097/PHM.0b013e318214de26
   Livingston G, 2014, BRIT J PSYCHIAT, V205, P436, DOI 10.1192/bjp.bp.113.141119
   Logsdon Rebecca G, 2007, Alzheimers care today, V8, P309
   Loprinzi PD, 2013, BRAIN RES, V1539, P95, DOI 10.1016/j.brainres.2013.10.004
   Lyketsos CG, 2000, AM J PSYCHIAT, V157, P708, DOI 10.1176/appi.ajp.157.5.708
   Ma MH, 2011, STUD COMPUT INTELL, V337, P169
   Manera V, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151487
   Manera V, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00024
   Mapelli D, 2013, DEMENT GER COGN D EX, V3, P263, DOI 10.1159/000353457
   Matsangidou Maria, 2020, Universal Access in Human-Computer Interaction. Design Approaches and Supporting Technologies. 14th International Conference, UAHCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12188), P366, DOI 10.1007/978-3-030-49282-3_26
   MCALINDON TE, 1993, ANN RHEUM DIS, V52, P258, DOI 10.1136/ard.52.4.258
   Medlock MC., 2002, USAB PROF ASS, V51
   Moyle W, 2018, GERONTOLOGIST, V58, P478, DOI 10.1093/geront/gnw270
   Muliyala KP, 2010, ANN INDIAN ACAD NEUR, V13, P69, DOI 10.4103/0972-2327.74248
   Nyman SR, 2011, CAN J AGING, V30, P45, DOI 10.1017/S0714980810000759
   Optale G, 2010, NEUROREHAB NEURAL RE, V24, P348, DOI 10.1177/1545968309353328
   Pedram S., 2021, VIRTUAL REAL-LONDON, V25, P1
   Pitkälä KH, 2013, JAMA INTERN MED, V173, P894, DOI 10.1001/jamainternmed.2013.359
   Plotzky C, 2021, NURS EDUC TODAY, V101, DOI 10.1016/j.nedt.2021.104868
   Potter R, 2011, INT J GERIATR PSYCH, V26, P1000, DOI 10.1002/gps.2641
   Rolland Y, 2007, J AM GERIATR SOC, V55, P158, DOI 10.1111/j.1532-5415.2007.01035.x
   Rose V., 2018, A Scoping Review Exploring the Feasibility of Virtual Reality Technology Use with Individuals Living with Dementia, DOI [10.2312/egve.20181325, DOI 10.2312/EGVE.20181325]
   Rose V, 2021, DEMENTIA-LONDON, V20, P106, DOI 10.1177/1471301219868036
   Santana-Sosa E, 2008, INT J SPORTS MED, V29, P845, DOI 10.1055/s-2008-1038432
   Savva GM, 2009, BRIT J PSYCHIAT, V194, P212, DOI 10.1192/bjp.bp.108.049619
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schiza E, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00100
   Siriaraya P, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3977, DOI 10.1145/2556288.2557035
   Spector A, 2003, BRIT J PSYCHIAT, V183, P248, DOI 10.1192/bjp.183.3.248
   Suttanon P, 2012, INT PSYCHOGERIATR, V24, P1172, DOI 10.1017/S1041610211002729
   Tabbaa L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300466
   Tedesco D., 2006, US PROF ASS C, V2006, P1
   Trautwein S, 2017, JMIR RES PROTOC, V6, P22, DOI 10.2196/resprot.6792
   United Nations, 2017, World Population Prospects The 2017 Revision: Key Findings and Advance Tables
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Baar ME, 1998, J RHEUMATOL, V25, P125
   Verbeek H, 2010, J AM MED DIR ASSOC, V11, P662, DOI 10.1016/j.jamda.2010.08.001
   Vreugdenhil A, 2012, SCAND J CARING SCI, V26, P12, DOI 10.1111/j.1471-6712.2011.00895.x
   Woods B, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001120.pub3
   Woods B, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005562.pub2
   World Health Organization-WHO, 2017, GLOB ACT PLAN PUBL H
   Yamaguchi H, 2011, INT PSYCHOGERIATR, V23, P674, DOI 10.1017/S1041610210001912
   Yu F, 2009, GERIATR NURS, V30, P250, DOI 10.1016/j.gerinurse.2008.11.001
   Zakzanis KK, 2009, MED SCI MONITOR, V15, pCR140
   Zheng GH, 2016, BRIT J SPORT MED, V50, P1443, DOI 10.1136/bjsports-2015-095699
NR 80
TC 3
Z9 3
U1 11
U2 46
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 421
EP 438
DI 10.1007/s10055-022-00639-1
EA APR 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000779611800002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Han, DID
   Bergs, Y
   Moorhouse, N
AF Han, Dai-In Danny
   Bergs, Yoy
   Moorhouse, Natasha
TI Virtual reality consumer experience escapes: preparing for the metaverse
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality experience; Escapism; Consumer-centered design; Research
   agenda; Metaverse
ID HEALTH; IMPACT; DESIGN; SENSE; ENVIRONMENTS; TECHNOLOGIES; DISORDERS;
   INTENTION; IMMERSION; FRAMEWORK
AB Virtual Reality (VR) experience escapes allow individuals to spend hours on end in immersive virtual environments and interact with content in a world that is providing shelter and illusion of an alternative reality - the metaverse. Discussions on possible risks have largely remained limited to usability challenges, while only a few studies reflect on social, psychological and physical implications this immersive technology exposes and the considerations consumers and businesses need to take. This paper critically reviews literature on escapism to discuss issues in the design and employment of virtual reality consumer experience escapes. Key issues relating to VR experience escapes and resulting effects on consumer health and well-being are discussed, emphasizing needed consumer-centered research and design. Future considerations include (1) Self-indulgent escapism through VR consumer experiences, (2) Ethical considerations in the design of VR consumer experience escapes, and (3) Purposeful design of VR consumer experiences escapes. A sequential research agenda is presented that integrates antecedents of VR experience escapes that connect to three main future research streams; designing purpose-driven VR consumer experience escapes, complementing methodologies for VR consumer experience research, and meaningful VR consumer experience escapes.
C1 [Han, Dai-In Danny; Bergs, Yoy] Breda Univ Appl Sci, Acad Hotel & Facil, Breda, Netherlands.
   [Han, Dai-In Danny] Zuyd Univ Appl Sci, Res Ctr Future Food, Maastricht, Netherlands.
   [Moorhouse, Natasha] Manchester Metropolitan Univ, Fac Business & Law, Righton Bldg,Cavendish St, Manchester M15 6BG, Lancs, England.
C3 Breda University of Applied Sciences; Manchester Metropolitan University
RP Han, DID (corresponding author), Breda Univ Appl Sci, Acad Hotel & Facil, Breda, Netherlands.; Han, DID (corresponding author), Zuyd Univ Appl Sci, Res Ctr Future Food, Maastricht, Netherlands.
EM han.d@buas.nl; bergs.y@buas.nl; n.moorhouse@mmu.ac.uk
CR Alcañiz M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01530
   Andreassen CS, 2016, PSYCHOL ADDICT BEHAV, V30, P252, DOI 10.1037/adb0000160
   [Anonymous], 2008, STEPPING VIRTUAL REA
   Appelhans BM, 2006, REV GEN PSYCHOL, V10, P229, DOI 10.1037/1089-2680.10.3.229
   Bailey JO, 2017, J CHILD MEDIA, V11, P107, DOI 10.1080/17482798.2016.1268779
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Bastiaansen M, 2019, INT J CONTEMP HOSP M, V31, P651, DOI [10.1108/IJCHM-11-2017-0761, 10.1108/ijchm-11-2017-0761]
   Bhatt G, 2004, INT J HUM-COMPUT ST, V60, P1, DOI 10.1016/j.ijhcs.2003.07.002
   Biocca F, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P12, DOI 10.1109/CT.1997.617676
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Cairns P, 2014, HANDBOOK OF DIGITAL GAMES, P339
   Cao S, 2020, VIRTUAL REAL-LONDON, V24, P503, DOI 10.1007/s10055-019-00412-x
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Loureiro SMC, 2021, J BUS RES, V134, P288, DOI 10.1016/j.jbusres.2021.05.035
   Loureiro SMC, 2019, J BUS RES, V100, P514, DOI 10.1016/j.jbusres.2018.10.055
   Cowan K, 2019, EUR J MARKETING, V53, P1585, DOI 10.1108/EJM-10-2017-0733
   CROSS N., 1994, ENG DESIGN METHODS S
   Deci EL, 2000, PSYCHOL INQ, V11, P227, DOI 10.1207/S15327965PLI1104_01
   Degli Innocenti E, 2019, COMPUT EDUC, V139, P102, DOI 10.1016/j.compedu.2019.04.010
   Engelberg E, 2004, CYBERPSYCHOL BEHAV, V7, P41, DOI 10.1089/109493104322820101
   Evans A., 2001, This virtual life: Escapism and simulation in our media world
   Farah MF, 2019, J RETAIL CONSUM SERV, V48, P136, DOI 10.1016/j.jretconser.2019.02.016
   Flavián C, 2021, J HOSP MARKET MANAG, V30, P1, DOI 10.1080/19368623.2020.1770146
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Han DID, 2019, HOSP SOC, V9, P237, DOI 10.1386/hosp.9.2.237_7
   Hardie E., 2007, Australian Journal of Emerging Technologies and Society, V5, P34
   Hartl E, 2017, P 25 EUR C INF SYST, P2413
   Harz N, 2022, J MARKETING, V86, P157, DOI 10.1177/00222429211014902
   Heller J, 2021, J SERV RES-US, V24, P84, DOI 10.1177/1094670520933692
   Henning B, 2001, J COMMUN, V51, P100, DOI 10.1111/j.1460-2466.2001.tb02874.x
   Honegger F, 2021, J UNIVERS COMPUT SCI, V27, P582, DOI 10.3897/jucs.68384
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Kahneman D, 2011, THINKING FAST SLOW, DOI [10.1108/EJM-10-2017-0733, DOI 10.1108/EJM-10-2017-0733]
   Kao YieFang Kao YieFang, 2008, Asia Pacific Journal of Tourism Research, V13, P163, DOI 10.1080/10941660802048480
   Kardefelt-Winther D, 2014, COMPUT HUM BEHAV, V31, P351, DOI 10.1016/j.chb.2013.10.059
   Kheirandish S, 2020, TECHNOL SOC, V62, DOI 10.1016/j.techsoc.2020.101302
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Kircaburun K, 2019, INT J MENT HEALTH AD, V17, P909, DOI 10.1007/s11469-018-9895-7
   Kounavis CD, 2012, INT J ENG BUS MANAG, V4, DOI 10.5772/51644
   Kuo A, 2016, J CONSUM MARK, V33, P498, DOI 10.1108/JCM-04-2016-1775
   Kuss DJ, 2012, CYBERPSYCH BEH SOC N, V15, P480, DOI 10.1089/cyber.2012.0034
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lavoie R, 2020, CAN J ADM SCI, V37, P9, DOI 10.1002/cjas.1537
   Lee H, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103229
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Lin JHT, 2018, NEW MEDIA SOC, V20, P3223, DOI 10.1177/1461444817744850
   Lindner P, 2017, COGN BEHAV THERAPY, V46, P404, DOI 10.1080/16506073.2017.1280843
   Macgregor DM, 2000, SCOT MED J, V45, P150, DOI 10.1177/003693300004500507
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Melancon JP, 2011, J RES INTERACT MARK, V5, P298, DOI 10.1108/17505931111191500
   Millett CJ, 1997, SEIZURE-EUR J EPILEP, V6, P457, DOI 10.1016/S1059-1311(97)80020-9
   Mishra A, 2021, PSYCHOL MARKET, V38, P385, DOI [10.1002/mar.21436, 10.1016/j.procir.2020.04.049]
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Moorhouse N., 2019, AUGMENTED REALITY VI, P277, DOI DOI 10.1007/978-3-030-06246-0_20
   Morahan-Martin J, 2003, COMPUT HUM BEHAV, V19, P659, DOI 10.1016/S0747-5632(03)00040-2
   Newton C., 2021, THE VERGE
   Nichols S, 2002, APPL ERGON, V33, P251, DOI 10.1016/S0003-6870(02)00020-0
   Panova T, 2016, COMPUT HUM BEHAV, V58, P249, DOI 10.1016/j.chb.2015.12.062
   Pantelidis V. S., 1993, Educational Technology, V33, P23
   Peperkorn HM, 2015, COMPUT HUM BEHAV, V48, P542, DOI 10.1016/j.chb.2015.02.028
   Pine JosephB., 2011, The Experience Economy
   Raisamo R, 2019, INT J HUM-COMPUT ST, V131, P131, DOI 10.1016/j.ijhcs.2019.05.008
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Schott G, 2006, J HEALTH PSYCHOL, V11, P309, DOI 10.1177/1359105306061189
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Smit B., 2018, Sustainable Customer Experience Design: Co-creating Experiences in Events, Tourism and Hospitality
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Stettler N, 2004, OBES RES, V12, P896, DOI 10.1038/oby.2004.109
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Thoits PA, 2010, J HEALTH SOC BEHAV, V51, pS41, DOI 10.1177/0022146510383499
   Tussyadiah IP, 2018, J TRAVEL RES, V57, P597, DOI 10.1177/0047287517709090
   Van Kerrebroeck H, 2017, COMPUT HUM BEHAV, V77, P437, DOI 10.1016/j.chb.2017.07.019
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Verhagen T, 2014, COMPUT HUM BEHAV, V39, P270, DOI 10.1016/j.chb.2014.07.036
   Violante MG, 2019, INT J INTERACT DES M, V13, P243, DOI 10.1007/s12008-018-00528-5
   Walsh K.R., 2002, Communications of the Associations of the Information Systems, V8 issue1, p, P20, DOI DOI 10.17705/1CAIS.00820
   Wibirama S, 2020, VIRTUAL REAL-LONDON, V24, P39, DOI 10.1007/s10055-019-00386-w
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yee N, 2006, PRESENCE-VIRTUAL AUG, V15, P309, DOI 10.1162/pres.15.3.309
   Yi S, 2012, J CONSUM POLICY, V35, P393, DOI 10.1007/s10603-012-9194-9
   Young K, 2009, J CONTEMP PSYCHOTHER, V39, P241, DOI 10.1007/s10879-009-9120-x
   Yulin Yao, 2014, International Journal of Organizational and Collective Intelligence, V4, P64, DOI 10.4018/ijoci.2014040104
NR 88
TC 86
Z9 87
U1 42
U2 363
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1443
EP 1458
DI 10.1007/s10055-022-00641-7
EA MAR 2022
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000769336000001
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Kober, SE
   Settgast, V
   Brunnhofer, M
   Augsdörfer, U
   Wood, G
AF Kober, Silvia Erika
   Settgast, Volker
   Brunnhofer, Marlies
   Augsdorfer, Ursula
   Wood, Guilherme
TI Move your virtual body: differences and similarities in brain activation
   patterns during hand movements in real world and virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Brain activity; Brain lateralization; Motor task; Presence; Virtual
   reality
ID MOTOR IMAGERY; STROKE; DESYNCHRONIZATION; SYNCHRONIZATION;
   REHABILITATION; METAANALYSIS; ENVIRONMENT; HANDEDNESS; CORRELATE; LIMB
AB Virtual reality (VR) is a promising tool for neurological rehabilitation, especially for motor rehabilitation. In the present study, we investigate whether brain activation patterns that are evoked by active movements are comparable when these movements are carried out in reality and in VR. Therefore, 40 healthy adults (20 men, mean age 25.31 years) performed hand movements and viewed these movements in a first-person view in reality, a VR scene showing realistic virtual hands, and a VR scene showing abstract virtual hands, in a randomized order. The VR conditions were presented via an immersive 3D head-mounted display system. EEG activity was assessed over the hand motor areas during and after movement execution. All three conditions led to typical EEG activation patterns over the motor cortex. Hence, brain activation patterns were largely comparable between conditions. However, the VR conditions, especially the abstract VR condition, led to a weaker hemispheric lateralization effect compared to the real-world condition. This indicates that hand models in VR should be realistic to be able to evoke activation patterns in the motor cortex comparable to real-world scenarios.
C1 [Kober, Silvia Erika; Brunnhofer, Marlies; Wood, Guilherme] Karl Franzens Univ Graz, Inst Psychol, Univ Pl 2, A-8010 Graz, Austria.
   [Kober, Silvia Erika; Wood, Guilherme] BioTechMed Graz, Graz, Austria.
   [Settgast, Volker; Augsdorfer, Ursula] Graz Univ Technol, Inst Comp Graph & Knowledge Visualisat, Graz, Austria.
   [Settgast, Volker] Fraunhofer Austria Res GmbH Geschaftsbereich Visu, Graz, Austria.
C3 University of Graz; Graz University of Technology
RP Kober, SE (corresponding author), Karl Franzens Univ Graz, Inst Psychol, Univ Pl 2, A-8010 Graz, Austria.; Kober, SE (corresponding author), BioTechMed Graz, Graz, Austria.
EM silvia.kober@uni-graz.at; v.settgast@tugraz.at;
   marlies.brunnhofer@gmail.com; u.augsdorfer@cgv.tugraz.at;
   guilherme.wood@uni-graz.at
OI Settgast, Volker/0000-0003-3842-5349
FU University of Graz
FX Open access funding provided by University of Graz. The authors
   acknowledge the financial support by the University of Graz.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Aghajan ZM, 2015, NAT NEUROSCI, V18, P121, DOI 10.1038/nn.3884
   Alimardani M., 2018, EVOLVING BCI THERAPY, DOI DOI 10.5772/INTECHOPEN.78695
   Baumeister J, 2010, NEUROSCI LETT, V481, P47, DOI 10.1016/j.neulet.2010.06.051
   Beier G., 1999, Report Psychologie, V24, P684
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   dos Santos LF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0289-4
   Pacheco TBF, 2017, NEUROREHABILITATION, V40, P391, DOI 10.3233/NRE-161426
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Jung SH, 2005, ARCH PHYS MED REHAB, V86, P2218, DOI 10.1016/j.apmr.2005.04.015
   KALCHER J, 1995, ELECTROEN CLIN NEURO, V94, P381, DOI 10.1016/0013-4694(95)00040-6
   Karamians R, 2020, ARCH PHYS MED REHAB, V101, P885, DOI 10.1016/j.apmr.2019.10.195
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kizony R., 2006, P 11 ANN CYB C VIRT
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee HY, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9461960
   Levin MF, 2012, NEUROL THER, V1, DOI 10.1007/s40120-012-0003-9
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matamala-Gomez M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020291
   McFarland DJ, 2000, BRAIN TOPOGR, V12, P177, DOI 10.1023/A:1023437823106
   Merians AS, 2009, STUD HEALTH TECHNOL, V145, P109, DOI 10.3233/978-1-60750-018-6-109
   Meyerbröker K, 2011, STUD COMPUT INTELL, V337, P47
   Neuper C, 2006, PROG BRAIN RES, V159, P211, DOI 10.1016/S0079-6123(06)59014-4
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Ono T, 2013, CLIN NEUROPHYSIOL, V124, P1779, DOI 10.1016/j.clinph.2013.03.006
   Perani D, 2001, NEUROIMAGE, V14, P749, DOI 10.1006/nimg.2001.0872
   PFURTSCHELLER G, 1989, Brain Topography, V2, P3, DOI 10.1007/BF01128838
   Pfurtscheller G, 1996, ELECTROEN CLIN NEURO, V98, P281, DOI 10.1016/0013-4694(95)00258-8
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pfurtscheller G, 1997, NEUROSCI LETT, V239, P65, DOI 10.1016/S0304-3940(97)00889-6
   Pfurtscheller G, 2007, PRESENCE-VIRTUAL AUG, V16, P111, DOI 10.1162/pres.16.1.111
   Piron L, 2009, J REHABIL MED, V41, P1016, DOI 10.2340/16501977-0459
   Putrino D, 2014, CURR OPIN NEUROL, V27, P631, DOI 10.1097/WCO.0000000000000152
   Pyasik M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62394-0
   Romero-Soto FO, 2020, IFMBE PROC, V75, P156, DOI 10.1007/978-3-030-30648-9_22
   SALMELIN R, 1994, NEUROSCIENCE, V60, P537, DOI 10.1016/0306-4522(94)90263-1
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   Shahrbanian S., 2012, EUR J EXP BIOL, V2, P1408
   Shin JH, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0125-x
   de Oliveira SMS, 2018, NEUROL RES, V40, P160, DOI 10.1080/01616412.2017.1420584
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Solodkin A, 2001, EUR J NEUROL, V8, P425, DOI 10.1046/j.1468-1331.2001.00242.x
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Teo WP, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00284
   Tunik E, 2013, IEEE T NEUR SYS REH, V21, P198, DOI 10.1109/TNSRE.2013.2238250
   WANG WE, 2020, IEEE T NEURAL SYST R
   World Medical Association Inc Declaration of Helsinki, 2009, J INDIAN MED ASSOC, V107, P405
NR 48
TC 6
Z9 6
U1 7
U2 45
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 501
EP 511
DI 10.1007/s10055-021-00588-1
EA OCT 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000707569100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lorentz, L
   Simone, M
   Zimmermann, M
   Studer, B
   Suchan, B
   Althausen, A
   Estocinova, J
   Müller, K
   Lendt, M
AF Lorentz, Lukas
   Simone, Mariella
   Zimmermann, Marcel
   Studer, Bettina
   Suchan, Boris
   Althausen, Anita
   Estocinova, Jana
   Mueller, Kristina
   Lendt, Michael
TI Evaluation of a VR prototype for neuropsychological rehabilitation of
   attentional functions
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive VR; Neuropsychological rehabilitation; Feasibility; Attention
   training
ID CHILDREN; QUESTIONNAIRE; ADHD
AB Background Recent research has established virtual reality (VR) applications as a valid and viable tool for neuropsychological assessment. In contrast, there are only a few studies on its potential as a therapeutic program. To examine the prospects of VR as a tool for functional rehabilitation, a VR training program of attentional functions was conceptualized during a Hackathon in 2018. The prototype of the immersive VR training program takes the patient on a virtual journey around the world (VR Traveller). In different locations around the globe, patients exercise different subcomponents of attention in a visually appealing and ecologically valid environment. Objective To evaluate the feasibility, acceptability and tolerability of the newly developed VR Traveller prototype for neurorehabilitation training. Method Thirty-five patients with acquired brain injury and mild to moderate attention deficits were instructed to complete the VR Traveller training program in a 20-30 min session during inpatient neurorehabilitation. Feasibility and acceptability were assessed with the user experience questionnaire (UEQ) and a self-constructed feasibility questionnaire, and tolerability was assessed with the virtual reality sickness questionnaire (VRSQ). Results Analyses of the UEQ and the feasibility questionnaire yield evidence for a high acceptance among most patients. The VRSQ data suggest that symptoms of VR sickness were hardly experienced. Conclusion Patients' ratings of the VR training in terms of acceptability and feasibility were positive, suggesting that VR programs represent an accepted, feasible, and well-received alternative to traditional cognitive rehabilitation approaches.
C1 [Lorentz, Lukas; Studer, Bettina; Mueller, Kristina; Lendt, Michael] St Mauritius Therapieklin, Strumper Str 111, D-40670 Meerbusch, Germany.
   [Simone, Mariella; Estocinova, Jana] SRH Gesundheitszentrum Bad Wimpfen GmbH, Bad Wimpfen, Germany.
   [Zimmermann, Marcel] ReIntegro Koln, Cologne, Germany.
   [Studer, Bettina] Heinrich Heine Univ Dusseldorf, Med Fac, Inst Clin Neurosci & Med Psychol, Dusseldorf, Germany.
   [Suchan, Boris] Ruhr Univ Bochum, Neuropsychol Therapy Ctr, Inst Cognit Neurosci, Clin Neuropsychol, Bochum, Germany.
   [Althausen, Anita] Neurol Therapiectr Koln gGmbH, Cologne, Germany.
C3 Heinrich Heine University Dusseldorf; Ruhr University Bochum
RP Lorentz, L (corresponding author), St Mauritius Therapieklin, Strumper Str 111, D-40670 Meerbusch, Germany.
EM lukas.lorentz@stmtk.de
RI Studer, Bettina/E-6177-2017
FU Interreg North-West Europe (NWE) program "VR4Rehab" [NWE585]
FX This project was funded by the Interreg North-West Europe (NWE) program
   "VR4Rehab" (NWE585;
   www.nweurope.eu/projects-search/vr4rehab-virtual-reality-for-rehab
   ilitation/).
CR Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   [Anonymous], 2009, WECHSLER MEMORY SCAL
   [Anonymous], 1999, Mehrfachwahl-Wortschatz-Intelligenztest (MWT-B)
   Bioulac S, 2020, J ATTEN DISORD, V24, P326, DOI 10.1177/1087054718759751
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   Chevignard M, 2018, SYST REV META ANAL M, DOI [10.1177/1087054718808590, DOI 10.1177/1087054718808590]
   Corsi P.M., 1972, Human memory and the medial temporal region of the brain, V34, p819B, DOI DOI 10.1016/B978-0-12-564350-4.50011-7
   DELIS DC, 1988, J CONSULT CLIN PSYCH, V56, P123, DOI 10.1037/0022-006X.56.1.123
   Gamito P, 2017, DISABIL REHABIL, V39, P385, DOI 10.3109/09638288.2014.934925
   Gerlowska J, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00392
   Giaschi D, 2013, VISION RES, V89, P65, DOI 10.1016/j.visres.2013.07.011
   Huygelier H, 2022, APPL NEUROPSYCH-ADUL, V29, P915, DOI 10.1080/23279095.2020.1821030
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim WS, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103369
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lorenz M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24453-5
   Manera V, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151487
   Matheis RJ, 2007, CLIN NEUROPSYCHOL, V21, P146, DOI 10.1080/13854040601100668
   McCleery JP, 2020, AUTISM RES, V13, P1418, DOI 10.1002/aur.2352
   Parsons TD, 2007, CHILD NEUROPSYCHOL, V13, P363, DOI 10.1080/13825580600943473
   Ponsford JL, 2014, J NEUROTRAUM, V31, P64, DOI 10.1089/neu.2013.2997
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Roberts M, 2019, P 13 INT C VIRT REH
   ROBERTSON I, 1990, APHASIOLOGY, V4, P381, DOI 10.1080/02687039008249090
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Schröder J, 2019, DISABIL REHABIL-ASSI, V14, P2, DOI 10.1080/17483107.2018.1503738
   Shipstead Z, 2012, PSYCHOL BULL, V138, P628, DOI 10.1037/a0027473
   Sivan M, 2010, CLIN REHABIL, V24, P110, DOI 10.1177/0269215509343234
   Tennant M, 2020, J PEDIATR ONCOL NURS, V37, P265, DOI 10.1177/1043454220917859
   Warland A, 2019, DISABIL REHABIL, V41, P2119, DOI 10.1080/09638288.2018.1459881
   Yaddaden A., P 5 EAI INT C SMART, DOI [DOI 10.1145/3342428.3342653, 10.1145/33424 28.3342653]
   Zimmermann P, 2007, MEASUREMENT INSTRUME
NR 34
TC 8
Z9 8
U1 8
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 187
EP 199
DI 10.1007/s10055-021-00534-1
EA JUN 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000663493200002
DA 2024-07-18
ER

PT J
AU Pastel, S
   Burger, D
   Chen, CH
   Petri, K
   Witte, K
AF Pastel, S.
   Burger, D.
   Chen, C. H.
   Petri, K.
   Witte, K.
TI Comparison of spatial orientation skill between real and virtual
   environment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Spatial orientation; Visual perception; Head-mounted
   display
ID NAVIGATION; MEMORY; WALKING; REPRESENTATION; RELIABILITY; INFORMATION;
   DEFICITS
AB Virtual reality (VR) is a promising tool and is increasingly used in many different fields, in which virtual walking can be generalized through detailed modeling of the physical environment such as in sports science, medicine and furthermore. However, the visualization of a virtual environment using a head-mounted display (HMD) differs compared to reality, and it is still not clear whether the visual perception works equally within VR. The purpose of the current study is to compare the spatial orientation between real world (RW) and VR. Therefore, the participants had to walk blindfolded to different placed objects in a real and virtual environment, which did not differ in physical properties. They were equipped with passive markers to track the position of the back of their hand, which was used to specify each object's location. The first task was to walk blindfolded from one starting position to different placed sport-specific objects requiring different degrees of rotation after observing them for 15 s (0 degrees, 45 degrees, 180 degrees, and 225 degrees). The three-way ANOVA with repeated measurements indicated no significant difference between RW and VR within the different degrees of rotation (p > 0.05). In addition, the participants were asked to walk blindfolded three times from a new starting position to two objects, which were ordered differently during the conditions. Except for one case, no significant differences in the pathways between RW and VR were found (p > 0.05). This study supports that the use of VR ensures similar behavior of the participants compared to real-world interactions and its authorization of use.
C1 [Pastel, S.; Burger, D.; Chen, C. H.; Petri, K.; Witte, K.] Otto Von Guericke Univ, Dept Sports Engn & Movement Sci, Inst Sports Sci 3, Magdeburg, Germany.
C3 Otto von Guericke University
RP Pastel, S (corresponding author), Otto Von Guericke Univ, Dept Sports Engn & Movement Sci, Inst Sports Sci 3, Magdeburg, Germany.
EM stefan.pastel@ovgu.de
OI Pastel, Stefan/0000-0002-3662-2683
FU German Research Foundation (DFG) [WI 1456/22-1]
FX Open Access funding enabled and organized by Projekt DEAL. The study was
   financed by the German Research Foundation (DFG) under Grant WI
   1456/22-1.
CR Battaglia-Mayer A, 2003, CEREB CORTEX, V13, P1009, DOI 10.1093/cercor/13.10.1009
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Byrne PA, 2010, J NEUROPHYSIOL, V103, P3054, DOI 10.1152/jn.01008.2009
   Cao LJ, 2019, COMPUT HUM BEHAV, V90, P37, DOI 10.1016/j.chb.2018.08.041
   CARBONELLCARRER.C, 2018, EURASIA J MATH SCI T
   Christensen JV, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234297
   Cirio G, 2013, IEEE T VIS COMPUT GR, V19, P671, DOI 10.1109/TVCG.2013.34
   Cohen J., 1988, STAT POWER ANAL BEHA
   Coughlan G, 2018, NAT REV NEUROL, V14, P496, DOI 10.1038/s41582-018-0031-x
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   Diersch N, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.187252
   Flanagin VL, 2019, J NEUROL, V266, P126, DOI 10.1007/s00415-019-09409-7
   FLEISHMAN JJ, 1971, PSYCHOL REP, V29, P523, DOI 10.2466/pr0.1971.29.2.523
   Ghinea M, 2018, LECT NOTES COMPUT SC, V10850, P148, DOI 10.1007/978-3-319-95270-3_10
   Harris Kristen, 2005, Can J Occup Ther, V72, P21
   Hicheur H, 2007, EUR J NEUROSCI, V26, P2376, DOI 10.1111/j.1460-9568.2007.05836.x
   Hirt C, 2018, LECT NOTES COMPUT SC, V10850, P35, DOI 10.1007/978-3-319-95270-3_3
   Ishikawa T, 2019, PROF GEOGR, V71, P197, DOI 10.1080/00330124.2018.1479970
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kimura K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18289-8
   KITCHIN RM, 1994, J ENVIRON PSYCHOL, V14, P1, DOI 10.1016/S0272-4944(05)80194-X
   Klatzky R. L., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P1
   Klinghammer M, 2016, VISION RES, V129, P13, DOI 10.1016/j.visres.2016.10.004
   Laczó J, 2018, AGING-US, V10, P3050, DOI 10.18632/aging.101634
   Lehnung M, 1998, BRIT J PSYCHOL, V89, P463, DOI 10.1111/j.2044-8295.1998.tb02697.x
   León I, 2016, BEHAV BRAIN RES, V306, P8, DOI 10.1016/j.bbr.2016.03.008
   Mondellini M, 2018, LECT NOTES COMPUT SC, V10850, P3, DOI 10.1007/978-3-319-95270-3_1
   Murgia Alessio, 2009, International Journal of Virtual Reality, V8, P67
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Palieri M, 2018, LECT NOTES COMPUT SC, V10850, P21, DOI 10.1007/978-3-319-95270-3_2
   Pastel S, 2021, J MOTOR BEHAV, V53, P693, DOI 10.1080/00222895.2020.1843390
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Pastel S, 2021, VIRTUAL REAL-LONDON, V25, P175, DOI 10.1007/s10055-020-00449-3
   Petri K., 2018, International Journal of Computer Science in Sport, V17, P1, DOI 10.2478/ijcss-2018-0001
   Petri K, 2019, SPORTS ENG, V22, DOI 10.1007/s12283-019-0299-0
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Read Jacob M., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2105, DOI 10.1177/1541931213602008
   San Vito PD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300440
   Sattar MU, 2019, PAK J MED SCI, V35, P852, DOI 10.12669/pjms.35.3.44
   Schütz I, 2015, EXP BRAIN RES, V233, P1225, DOI 10.1007/s00221-015-4197-9
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Thompson AA, 2011, VISION RES, V51, P819, DOI 10.1016/j.visres.2011.01.006
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   Walch M, 2017, P 2017 CHI C HUM FAC, P2982, DOI [DOI 10.1145/3027063.3053202, 10.1145/3027063.3053202]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolbers T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00571
   Wolbers T, 2010, TRENDS COGN SCI, V14, P138, DOI 10.1016/j.tics.2010.01.001
NR 50
TC 13
Z9 13
U1 0
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 91
EP 104
DI 10.1007/s10055-021-00539-w
EA JUN 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000658068200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Arisoy, MV
   Küçüksille, EU
AF Varol Arisoy, Merve
   Kucuksille, Ecir Ugur
TI Landmine detection training simulation using virtual reality technology
SO VIRTUAL REALITY
LA English
DT Article
DE Landmine detection training; Simulation; VR; Unity 3D; Landmine
   sweeping; Kinect V2
ID GROUND-PENETRATING RADAR; SOIL-MOISTURE; THERAPY
AB Landmines are frequently used for defence and attack. Thus, landmine detection is vital to preventing the damages incurred. Various landmine detection methods have been developed from the past to the present. Thus, a need has arisen for the employment of qualified personnel in this field. In today's landmine detection training, soldiers are first subjected to theoretical training about landmine types. After this stage, they attend practical training in the field. However, when training is given in this way, sample application fields do not contain all possible terrain and weather conditions. Also, many accidents and injuries occur during this practical training. To overcome the disadvantages elucidated above, a landmine detection training simulation was developed in this study, which supports real terrain conditions and creates a safe detection environment. In this study, the developed simulation software was based on virtual reality technology. The interaction with the computer is both provided by a detector appearance control device (DACD) controller developed for this simulator and by Kinect controller. The simulator has remarkable benefits concerning time and cost when compared with the landmine detection training given today. At the same time, detections performed in a safe environment without any risk factors and real land conditions were provided close to reality. Also, the actual space coordinates of the joints in the human body can be detected correctly using the DACD controller, as much as the Kinect device.
C1 [Varol Arisoy, Merve] Mehmet Akif Ersoy Univ, Dept Informat, Istiklal Campus, Burdur, Turkey.
   [Kucuksille, Ecir Ugur] Suleyman Demirel Univ, Dept Comp Engn, Fac Engn, West Campus, Isparta, Turkey.
C3 Mehmet Akif Ersoy University; Suleyman Demirel University
RP Arisoy, MV (corresponding author), Mehmet Akif Ersoy Univ, Dept Informat, Istiklal Campus, Burdur, Turkey.
EM mvarisoy@mehmetakif.edu.tr; ecirkucuksille@sdu.edu.tr
RI Kucuksille, Ecir Ugur/AAG-6721-2019
OI Kucuksille, Ecir Ugur/0000-0002-3293-9878
CR Machado AFA, 2015, IEEE MILIT COMMUN C, P1270, DOI 10.1109/MILCOM.2015.7357620
   [Anonymous], 5 INT S TECHN MIN PR
   Baxter HC, 2004, INT IND TRAIN SIM ED
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Brown B, 2010, THESIS
   Brown R, 2016, IEEE INT CONF SERIOU
   Can Laser, 2010, GOR MAY BULM SIST
   Chen G, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P494, DOI 10.1109/ICACTE.2008.30
   Conn MA, 2016, 2016 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P387, DOI [10.1109/CTS.2016.73, 10.1109/CTS.2016.0075]
   Define aretleri, 2018, YERALTI GORUNTULEME
   Detsch RM, 1998, PROC SPIE, V3392, P1261
   Eldem MO, 2017, TMMOB EMO ANKARA SUB, V4, P2
   Geoghegan B, 2015, THESIS
   Greunke L, 2016, IEEE T VIS COMPUT GR, V22, P1482, DOI 10.1109/TVCG.2016.2518098
   Hang Qiu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1391, DOI 10.1109/ICISE.2009.870
   HENDRICKX JMH, 2003, GEOL SOC LOND SPECIA, V211, P191, DOI DOI 10.1144/GSL.SP.2001.211.01.16
   Ho KC, 2008, IEEE T GEOSCI REMOTE, V46, P1177, DOI 10.1109/TGRS.2008.915747
   Ho KC, 2004, IEEE T GEOSCI REMOTE, V42, P249, DOI 10.1109/TGRS.2003.817804
   Khooshabeh P, 2017, P IEEE VIRT REAL ANN, P333, DOI 10.1109/VR.2017.7892312
   Kwon B, 2017, IEEE ACCESS, V5, P12496, DOI 10.1109/ACCESS.2017.2723039
   Ma'sum MA, 2013, INT C ADV COMP SCI I, P161, DOI 10.1109/ICACSIS.2013.6761569
   Miller T, 2002, P SOC PHOTO-OPT INS, V4742, P281, DOI 10.1117/12.479099
   Nolan J.M., 2005, THESIS
   Postal GR, 2016, SYMP VIRTUAL AUGMENT, P183, DOI 10.1109/SVR.2016.39
   Rappaport CM, 2006, IEEE MTT-S, P280, DOI 10.1109/MWSYM.2006.249488
   Ren K, 2008, 7TH INTERNATIONAL CONFERENCE ON SYSTEM SIMULATION AND SCIENTIFIC COMPUTING ASIA SIMULATION CONFERENCE 2008, VOLS 1-3, P593, DOI 10.1109/ASC-ICSC.2008.4675429
   Rizzo A, 2014, COMPUTER, V47, P31, DOI 10.1109/MC.2014.199
   Robitaille N, 2017, DISABIL REHABIL-ASSI, V12, P758, DOI 10.1080/17483107.2016.1229048
   Shiau YH, 2007, IEEE INT CONF INF VI, P807
   Siu KC, 2016, MIL MED, V181, P214, DOI 10.7205/MILMED-D-15-00164
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Speidel S, 2011, 2011 8 INT C INF COM, DOI 10.1109/ICICS.2011.6173577
   Takahashi K, 2011, PROC SPIE, V8017, DOI 10.1117/12.883798
   Takahashi K, 2011, J APPL GEOPHYS, V73, P368, DOI 10.1016/j.jappgeo.2011.02.008
   Torrione P, 2006, INT GEOSCI REMOTE SE, P153, DOI 10.1109/IGARSS.2006.44
   Trang AH, 1996, P SOC PHOTO-OPT INS, V2765, P430, DOI 10.1117/12.241246
   Van Dam RL, 2005, INT J SYST SCI, V36, P573, DOI 10.1080/00207720500147800
   Veziridis S, 2017, IEEE GLOB ENG EDUC C, P920, DOI 10.1109/EDUCON.2017.7942958
   Wang XJ, 2012, APPL MECH MATER, V226-228, P2098, DOI 10.4028/www.scientific.net/AMM.226-228.2098
   Williamson BM, 2011, P INT IND TRAIN SIM, P2103
   Young-Bae Son, 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P690
   Zhu W, 2011, P 2011 INT C COMP GR
   Zinzow HM, 2018, COGN BEHAV PRACT, V25, P296
NR 43
TC 3
Z9 4
U1 0
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 461
EP 490
DI 10.1007/s10055-020-00467-1
EA AUG 2020
PG 30
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000564550000001
DA 2024-07-18
ER

PT J
AU Johnson, D
   Damian, D
   Tzanetakis, G
AF Johnson, David
   Damian, Daniela
   Tzanetakis, George
TI Evaluating the effectiveness of mixed reality music instrument learning
   with the theremin
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Music pedagogy; Learning transfer; Training; Immersive
   learning environments
ID VIRTUAL-REALITY; ENVIRONMENTS; IMPLEMENTATION
AB Learning music is a challenging process that requires years of practice to master, either with lessons from a professional teacher or through self-teaching. While practicing, students are expected to self-evaluate their performance which may be difficult without timely feedback from a professional. Research into computer-assisted music instrument tutoring (CAMIT) attempts to address this through the use of emerging technologies. In this paper, we study CAMIT for mixed reality (MR) by developing MR:emin, an immersive MR music learning environment for the theremin, an electronic music instrument that is controlled without physical contact. MR:emin integrates a physical theremin with the immersive learning environment. To better understand the effectiveness of such environments, we perform a user study with MR:emin comparing traditional music learning with two virtual learning environments, an immersive one and a non-immersive one. In a between-groups study, 30 participants were trained to play a sequence of notes on the theremin using one of the three training environments. Results of our statistical analysis show that performance error during training is significantly smaller in the immersive MR environment. This does not necessarily lead to improved performance after training; analysis of post-training improvement indicates that immersive training results in the smallest amount of improvement. Participants, however, indicate that the MR:emin environment is more engaging and increases confidence during practice. We discuss potential factors leading to the decrease in learning and provide some environment guidelines to aid in the design of engaging immersive music learning environments.
C1 [Johnson, David; Damian, Daniela; Tzanetakis, George] Univ Victoria, 3800 Finnerty Rd, Victoria, BC V8P 5C2, Canada.
C3 University of Victoria
RP Johnson, D (corresponding author), Univ Victoria, 3800 Finnerty Rd, Victoria, BC V8P 5C2, Canada.
EM davidjo@uvic.ca; danielad@uvic.ca; gtzan@uvic.ca
OI Johnson, David/0000-0003-4852-8827
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Berthaut F, 2011, J NEW MUSIC RES, V40, P253, DOI 10.1080/09298215.2011.602693
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Cormier S., 1987, Transfer of learning: Contemporary research and applications
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dalmazzo D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00344
   DANNENBERG RB, 1990, INTERFACE-J NEW MUS, V19, P155, DOI 10.1080/09298219008570563
   Dannenberg RB, 1993, FOURTH BIENNIAL ARTS & TECHNOLOGY SYMPOSIUM, PROCEEDINGS, P143
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Feng Huang, 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P47, DOI 10.1109/IHMSC.2011.82
   Giraldo S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00334
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   John NW, 2018, IEEE T VIS COMPUT GR, V24, P1867, DOI 10.1109/TVCG.2017.2700273
   John NW, 2016, PRESENCE-TELEOP VIRT, V25, P289, DOI 10.1162/PRES_a_00270
   Kweon Y, 2018, COMM COM INF SC, V851, P296, DOI 10.1007/978-3-319-92279-9_40
   Lehmann KS, 2005, ANN SURG, V241, P442, DOI 10.1097/01.sla.0000154552.89886.91
   Maki-Patola T., 2005, P 2005 C NEW INTERFA, P11, DOI DOI 10.5281/ZENODO.1176780
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mora J, 2006, 2006 IEEE INT WORKSH, P157
   Murcia-López M, 2018, IEEE T VIS COMPUT GR, V24, P1574, DOI 10.1109/TVCG.2018.2793638
   Ng K, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P339
   Oren M, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P27, DOI 10.1109/VR.2012.6180873
   Percival G., 2007, EMME 07 P INT WORKSH, P67
   Ranaiefar F, 2013, TRANSPORT RES REC, P73, DOI 10.3141/2378-08
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Schoonderwaldt E., 2005, P INT COMP MUS C, P97
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.9781/ijimai.2017.445, DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337]
   Serafin S, 2016, COMPUT MUSIC J, V40, P22, DOI 10.1162/COMJ_a_00372
   Siegel Sidney, 1988, Nonparametric statistics for the behavioral sciences
   Thomsen ASS, 2017, OPHTHALMOLOGY, V124, P524, DOI 10.1016/j.ophtha.2016.11.015
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Werrlich S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P297, DOI 10.1145/3197768.3201564
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 45
TC 15
Z9 16
U1 2
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 303
EP 317
DI 10.1007/s10055-019-00388-8
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800010
DA 2024-07-18
ER

PT J
AU Vretos, N
   Daras, P
   Asteriadis, S
   Hortal, E
   Ghaleb, E
   Spyrou, E
   Leligou, HC
   Karkazis, P
   Trakadas, P
   Assimakopoulos, K
AF Vretos, Nicholas
   Daras, Petros
   Asteriadis, Stylianos
   Hortal, Enrique
   Ghaleb, Esam
   Spyrou, Evaggelos
   Leligou, Helen C.
   Karkazis, Panagiotis
   Trakadas, Panagiotis
   Assimakopoulos, Kostantinos
TI Exploiting sensing devices availability in AR/VR deployments to foster
   engagement
SO VIRTUAL REALITY
LA English
DT Article
DE Affect state detection; Engagement; Interpretation of interaction;
   Multimodal affect state detection
ID EMOTION RECOGNITION; FEATURES; SPEECH
AB Currently, in all augmented reality (AR) or virtual reality (VR) educational experiences, the evolution of the experience (game, exercise or other) and the assessment of the user's performance are based on her/his (re)actions which are continuously traced/sensed. In this paper, we propose the exploitation of the sensors available in the AR/VR systems to enhance the current AR/VR experiences, taking into account the users' affect state that changes in real time. Adapting the difficulty level of the experience to the users' affect state fosters their engagement which is a crucial issue in educational environments and prevents boredom and anxiety. The users' cues are processed enabling dynamic user profiling. The detection of the affect state based on different sensing inputs, since diverse sensing devices exist in different AR/VR systems, is investigated, and techniques that have been undergone validation using state-of-the-art sensors are presented.
C1 [Vretos, Nicholas; Daras, Petros] Ctr Res & Technol Hellas, Thessaloniki, Greece.
   [Asteriadis, Stylianos; Hortal, Enrique; Ghaleb, Esam] Univ Maastricht, Maastricht, Netherlands.
   [Spyrou, Evaggelos] Natl Ctr Sci Res Demokritos, Athens, Greece.
   [Leligou, Helen C.; Karkazis, Panagiotis; Trakadas, Panagiotis; Assimakopoulos, Kostantinos] Technol Educ Inst Sterea Ellada, Psahna, Halkida, Greece.
C3 Centre for Research & Technology Hellas; Maastricht University; National
   Centre of Scientific Research "Demokritos"
RP Trakadas, P (corresponding author), Technol Educ Inst Sterea Ellada, Psahna, Halkida, Greece.
EM pkarkazis@isc.tuc.gr
RI Vretos, Nicholas/ABA-6038-2021; Karkazis, Panagiotis/AAH-4711-2020;
   /AAD-7611-2019; Leligou, Nelly/HNP-1616-2023; Leligou,
   Nelly/AAP-6583-2021; Daras, Petros/F-5284-2012; Hortal,
   Enrique/K-5126-2014; Asteriadis, Stylianos/O-2140-2016
OI Vretos, Nicholas/0000-0003-3604-9685; Karkazis,
   Panagiotis/0000-0003-4971-826X; /0000-0002-5146-5954; Daras,
   Petros/0000-0003-3814-6710; Leligou, Helen C.
   (Nelly)/0000-0002-1489-1495; Hortal, Enrique/0000-0003-2119-4169;
   Asteriadis, Stylianos/0000-0002-4298-6870
FU European Union [687772]; H2020-MaTHiSiS Project
FX The work presented in this document has been partially funded through
   H2020-MaTHiSiS Project. This project has received funding from the
   European Union's Horizon 2020 Programme (H2020-ICT-2015) under Grant
   Agreement No. 687772.
CR Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], ARXIV160303669
   Baker RSJD, 2010, INT J HUM-COMPUT ST, V68, P223, DOI 10.1016/j.ijhcs.2009.12.003
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Burkhardt F, 2005, P INT LISS
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Coutrix C, 2012, P 2012 ACM C UB COMP
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Csikszentmihalyi M., 1996, CREATIVITY FLOW PSYC
   DigiCapital, 2017, DIGICAPITAL
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Ghaleb E, 2017, MULT FUS BAS INF GAI
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Haq S., 2009, INT C AUDITORY VISUA, P53
   Kanade T, 2010, EXTENDED COHN KANADE
   Kim M, 2013, IEEE INT C CONS EL I
   Li F, 2015, IEEE COMPUT SOC CONF
   Li W, 2010, P IEEE INT C COMP VI
   Mora K. A. F., 2014, P S EYE TRACK RES AP, P255, DOI [10.1145/2578153.2578190, 10.1145/2578153]
   Nottingham Trent University, 2017, AD PERS PRINC BAS MA
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   R Vemulapalli, 2014, P IEEE INT C COMP VI
   Rikert TD, 1998, P 3 IEEE INT C AUT F
   Wang W, 2015, P IEEE INT C COMP VI
   West E, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/s12913-014-0496-2
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhang X., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI 10.1109/CVPR.2015.7299081
   Zhang X., 2017, IEEE transactions on pattern analysis and machine intelligence (PAMI)
NR 28
TC 5
Z9 5
U1 1
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 399
EP 410
DI 10.1007/s10055-018-0357-0
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300007
OA Green Published
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI EMBRACING AN AUGMENTED AND VIRTUAL FUTURE
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR [Anonymous], 2016, SCI FRIDAY      0202
   [Anonymous], 2015, STAT STAT PORTAL
   [Anonymous], 2017, AM CYB
   Geiger AW., 2018, AM HAVE VIEWED GOVER
   Madary Michael, 2016, REAL VIRTUALITY CODE, DOI DOI 10.3389/FR0BT.2016.00003/FULL
   Mason Will, 2016, OCULUS ALWAYS SERVIC
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Robertson Adi, 2018, THE VERGE       0419
   Yoon Gunwood, 2014, KNOW THY AVATAR UNIN, DOI [10.1177/0956797613519271?journalCode=pssa, DOI 10.1177/0956797613519271?J0URNALC0DE=PSSA]
NR 9
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 187
EP +
PG 27
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200009
DA 2024-07-18
ER

PT J
AU Puthenveetil, SC
   Daphalapurkar, CP
   Zhu, WJ
   Leu, MC
   Liu, XQF
   Gilpin-Mcminn, JK
   Snodgrass, SD
AF Puthenveetil, Sajeev C.
   Daphalapurkar, Chinmay P.
   Zhu, Wenjuan
   Leu, Ming C.
   Liu, Xiaoqing F.
   Gilpin-Mcminn, Julie K.
   Snodgrass, Scott D.
TI Computer-automated ergonomic analysis based on motion capture and
   assembly simulation
SO VIRTUAL REALITY
LA English
DT Article
DE Assembly simulation; CAVE; Ergonomic analysis; Firefly; Kinect; Motion
   capture; Virtual fastening
AB This paper describes a method of simulating an assembly operation in a fully immersive virtual environment in order to analyze the postures of workers as they perform assembly operations in aerospace manufacturing. The challenges involved in capturing the movements of humans performing an assembly operation in a real work environment were overcome by developing a marker-based motion capture system and using it in a cave automatic virtual environment (CAVE). The development of the system focuses on real-time human motion capture and automated simulation for ergonomic analysis. Human movements were tracked in a CAVE, with infrared (IR) LEDs mounted on a human body. The captured motion data were used to generate a simulation in real-time and perform an ergonomic analysis in Jack software. The simulation also included the use of Microsoft Kinect as a marker-less human body capture system for the purpose of scaling the digital human model in Jack. The developed system has been demonstrated for human motion capture and ergonomic analysis for the fastening operation of an aircraft fuselage.
C1 [Puthenveetil, Sajeev C.] Codeware Inc, Sarasota, FL 34233 USA.
   [Daphalapurkar, Chinmay P.] ESI Grp, Farmington Hills, MI 48334 USA.
   [Zhu, Wenjuan; Leu, Ming C.; Liu, Xiaoqing F.] Missouri Univ Sci & Technol, Rolla, MO 65409 USA.
   [Gilpin-Mcminn, Julie K.; Snodgrass, Scott D.] Spirit AeroSyst, Wichita, KS 67278 USA.
C3 University of Missouri System; Missouri University of Science &
   Technology
RP Puthenveetil, SC (corresponding author), Codeware Inc, 5224 Stn Way, Sarasota, FL 34233 USA.
EM sajeev_ekmin@yahoo.co.in
FU Industrial Consortium of the Center for Aerospace Manufacturing
   Technologies (CAMT)
FX The authors would like to acknowledge the financial support for this
   research from the Industrial Consortium of the Center for Aerospace
   Manufacturing Technologies (CAMT). The great help of Peter Wu and Alpha
   Chang to initiate and conduct the project is especially appreciated.
CR AForge.NET, 2012, COMP VIS ART INT ROB
   [Anonymous], 2012, PHASESPACE MOTION CA
   [Anonymous], 2012, Kinect for windows sdk
   Badler N., 1999, SIMULATING HUMANS CO
   Bouguet JY, 2012, Camera calibration toolbox for matlab
   Chadda A, 2011, P ASME INT DES ENG T
   Fernando T, 2000, P EUR PORT CHAPT, P43
   Frati V., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P317, DOI 10.1109/WHC.2011.5945505
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Joshi AS, 2008, P 2 CIRP C ASS TECHN
   Kurihara K, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1241, DOI 10.1109/ROBOT.2002.1014713
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   Stowers J., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics (ICM), P358, DOI 10.1109/ICMECH.2011.5971311
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao W., 2006, P ACM INT C VIRT REA, P245
NR 15
TC 29
Z9 32
U1 5
U2 73
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2015
VL 19
IS 2
BP 119
EP 128
DI 10.1007/s10055-015-0261-9
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CJ9MO
UT WOS:000355826700005
DA 2024-07-18
ER

PT J
AU Audet, S
   Okutomi, M
   Tanaka, M
AF Audet, Samuel
   Okutomi, Masatoshi
   Tanaka, Masayuki
TI Augmenting moving planar surfaces robustly with video projection and
   direct image alignment
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Vision-based tracking; Projector-camera systems;
   Video projection; Image alignment
AB Augmented reality applications based on video projection, to be effective, must track moving targets and make sure that the display remains aligned even when they move, but the projection can severely alter their appearances to the point where traditional computer vision algorithms fail. Current solutions consider the displayed content as interference and largely depend on channels orthogonal to visible light. They cannot directly align projector images with real-world surfaces, even though this may be the actual goal. We propose instead to model the light emitted by projectors and reflected into cameras and to consider the displayed content as additional information useful for direct alignment. Using a color camera, our implemented software successfully tracks with subpixel accuracy a planar surface of diffuse reflectance properties at an average of eight frames per second on commodity hardware, providing a solid base for future enhancements.
C1 [Audet, Samuel; Okutomi, Masatoshi; Tanaka, Masayuki] Tokyo Inst Technol, Meguro Ku, Tokyo 152, Japan.
C3 Tokyo Institute of Technology
RP Audet, S (corresponding author), Tokyo Inst Technol, Meguro Ku, 2-12-1 Ookayama, Tokyo 152, Japan.
EM saudet@ok.ctrl.titech.ac.jp; mxo@ctrl.titech.ac.jp;
   mtanaka@ctrl.titech.ac.jp
RI Tanaka, Masayuki/B-9385-2015
OI Tanaka, Masayuki/0000-0002-5756-1904
FU Ministry of Education, Culture, Sports, Science and Technology (MEXT) of
   the Japanese Government
FX This work was supported by a scholarship from the Ministry of Education,
   Culture, Sports, Science and Technology (MEXT) of the Japanese
   Government.
CR [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Audet Samuel, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P47, DOI 10.1109/CVPR.2009.5204319
   Audet S, 2010, 2010 IEEE C COMP VIS
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S., 2006, Tech. Rep. CMU-RI-TR-06-11
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bartoli A, 2008, IEEE T PATTERN ANAL, V30, P2098, DOI 10.1109/TPAMI.2008.22
   Bradski G., 2008, LEARNING OPENCV
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Chen X., 2008, Proceedings of the 5th ACM/IEEE International Workshop on Projector camera systems, PROCAMS '08, P1
   International Electrotechnical Commission,, 1999, IEC 61966-2-1
   John T, 2007, Proceedings of the ASME Power Conference 2007, P1
   Leibe B, 2000, 2000 IEEE VIRT REAL, P13
   Moritani T, 2006, INT C PATT RECOG, P747
   Raskar R, 2003, ACM T GRAPHIC, V22, P809, DOI 10.1145/882262.882349
   Raskar R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P179, DOI 10.1145/280814.280861
   Silveira G, 2007, 2007 IEEE C COMP VIS
   Sturm P, 2000, PROC CVPR IEEE, P706, DOI 10.1109/CVPR.2000.855889
   Sugimoto S, 2007, 2007 IEEE C COMP VIS
   Takao N, 2003, INT J COMPUT VISION, V53, P115, DOI 10.1023/A:1023084706295
   Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661
   Wagner D, 2007, 12 COMP VIS WINT WOR
   Xiao J, 2004, PROC CVPR IEEE, P535
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 25
TC 5
Z9 6
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2013
VL 17
IS 2
SI SI
BP 157
EP 168
DI 10.1007/s10055-012-0210-9
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 139IH
UT WOS:000318575200006
DA 2024-07-18
ER

PT J
AU Yoganandan, AR
   Banerjee, PP
   Luciano, CJ
   Rizzi, SHR
AF Yoganandan, Arun Rakesh
   Banerjee, P. Pat
   Luciano, Cristian J.
   Rizzi, Silvio H. R.
TI Prototyping flexible touch screen devices using collocated
   haptic-graphic elastic-object deformation on the GPU
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality prototyping; Flexible displays; Product simulation;
   Haptics
ID VIRTUAL-REALITY; CHAINMAIL
AB Rapid advances in flexible display technologies and the benefits that they provide are promising enough to consider them for futuristic mobile devices. Current prototyping methods lack facilities to simulate such flexible touch screen displays and the interaction with them. In this paper, we present a technique that provides product developers a tool to interactively simulate products featuring flexible displays, using Augmented Reality and Haptics. This GPU-based algorithm is computationally inexpensive and efficient to deform a polygonal mesh in real time while maintaining an acceptable haptic feedback. The implementation of the algorithm has been found to be successful when applied to a variety of product simulations. This simulation tool can enhance or even replace traditional prototyping and facilitate testing of the prototype at various stages of the design cycle.
C1 [Yoganandan, Arun Rakesh; Banerjee, P. Pat; Luciano, Cristian J.; Rizzi, Silvio H. R.] Univ Illinois, Ind Virtual Real Inst, Dept Mech & Ind Engn, Chicago, IL 60607 USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
RP Banerjee, PP (corresponding author), Univ Illinois, Ind Virtual Real Inst, Dept Mech & Ind Engn, Chicago, IL 60607 USA.
EM banerjee@uic.edu
CR [Anonymous], 11 INT C HUM COMP IN
   Bullinger HJ, 2000, COMPUT IND, V42, P99, DOI 10.1016/S0166-3615(99)00064-0
   de Pascale M, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P545
   Faeth AJ, 2009, THESIS IOWA STATE U
   Georgii J., 2005, P VMV
   Jo D, 2007, ACM INT C P SERIES, V309
   Kerttula M, 1997, P IEEE RAP SYST PROT, P2, DOI 10.1109/IWRSP.1997.618812
   Krause FL, 2001, CIRP ANN-MANUF TECHN, V50, P81, DOI 10.1016/S0007-8506(07)62076-9
   Krauss M, 2006, ACM INT C P SERIES, V159
   Li Y, 2003, COMPUT GRAPH FORUM, V22, P717, DOI 10.1111/j.1467-8659.2003.00719.x
   Liukkunen K, 2008, LECT NOTES COMPUT SC, V5089, P174, DOI 10.1007/978-3-540-69566-0_16
   Luciano C.J., 2007, 3 ANN IEEE C AUTOMAT, P146
   Mosegaard J, 2005, P IEEE VIRT REAL ANN, P147
   Pascale D.M., 2004, P EUROHAPTICS, P44
   Pering C., 2002, Interactions, V9, P36, DOI 10.1145/581951.581952
   Sa M, 2006, CHI 06 HUM FACT COMP
   Schill MA, 1998, LECT NOTES COMPUT SC, V1496, P679, DOI 10.1007/BFb0056254
   Schwesig Carsten., 2003, CHI '03: CHI '03 extended abstracts on Human factors in computing systems, P954
   Sorensen TS, 2006, STUD HEALTH TECHNOL, V119, P523
   Wang G. G., 2002, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V2, P232, DOI 10.1115/1.1526508
   Ye J, 2007, LECT NOTES COMPUT SC, V4553, P1190
   Yoganandan AR, 2009, WORKSH CLOUD MOB CON
NR 22
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 33
EP 43
DI 10.1007/s10055-010-0155-9
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600005
DA 2024-07-18
ER

PT J
AU Nassiri, N
   Powell, N
   Moore, D
AF Nassiri, Nasser
   Powell, Norman
   Moore, David
TI Human interactions and personal space in collaborative virtual
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE Collaborative virtual environment; Anxiety; Personal space
ID DISTANCE; SEX
AB As humans start to spend more time in collaborative virtual environments (CVEs) it becomes important to study their interactions in such environments. One aspect of such interactions is personal space. To begin to address this, we have conducted empirical investigations in a non immersive virtual environment: an experiment to investigate the influence on personal space of avatar gender, and an observational study to further explore the existence of personal space. Experimental results give some evidence to suggest that avatar gender has an influence on personal space although the participants did not register high personal space invasion anxiety, contrary to what one might expect from personal space invasion in the physical world. The observational study suggests that personal space does exist in CVEs, as the users tend to maintain, in a similar way to the physical world, a distance when they are interacting with each other. Our studies provide an improved understanding of personal space in CVEs and the results can be used to further enhance the usability of these environments.
C1 [Nassiri, Nasser] Dubai Womens Coll, Higher Coll Technol, Dept Informat Technol, Dubai, U Arab Emirates.
   [Powell, Norman] Univ Manchester, CEEBL, Manchester M60 1QD, Lancs, England.
   [Moore, David] Leeds Metropolitan Univ, Innovat N Fac Informat & Technol, Leeds LS6 3QS, W Yorkshire, England.
C3 Higher Colleges of Technology - United Arab Emirates; University of
   Manchester; Leeds Beckett University
RP Nassiri, N (corresponding author), Dubai Womens Coll, Higher Coll Technol, Dept Informat Technol, POB 16062, Dubai, U Arab Emirates.
EM nasser.nassiri@hct.ac.ae; norman.powell@manchester.ac.uk;
   d.moore@leedsmet.ac.uk
CR ABBEY A, 1995, SEX ROLES, V32, P297, DOI 10.1007/BF01544599
   ADAMS L, 1991, J GEN PSYCHOL, V118, P335, DOI 10.1080/00221309.1991.9917794
   ADLER LL, 1974, PERCEPT MOTOR SKILL, V39, P683, DOI 10.2466/pms.1974.39.2.683
   Aiello JR, 1987, HDB ENV PSYCHOL
   ALLGEIER AR, 1973, J SOC PSYCHOL, V90, P213, DOI 10.1080/00224545.1973.9712561
   ARGYLE M, 1965, SOCIOMETRY, V28, P289, DOI 10.2307/2786027
   Argyle Michael, 1975, BODILY COMMUNICATION
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Becker B, 2002, COMP SUPP COMP W SER, P19
   BECKER FD, 1971, ENVIRON BEHAV, V3, P375
   COBB S, 2000, DIGIT CREATIV, V13, P11
   COCHRAN CD, 1984, J PSYCHOL, V117, P121, DOI 10.1080/00223980.1984.9923667
   COCHRAN D, 1984, J PSYCHOL, V111, P137
   CORBIT M, 2000, P CVE 2000 C SAN FRA
   DOSEY MA, 1969, J PERS SOC PSYCHOL, V11, P93, DOI 10.1037/h0027040
   Durlach N, 2000, PRESENCE-TELEOP VIRT, V9, P214, DOI 10.1162/105474600566736
   EFRAN MG, 1974, J PERS SOC PSYCHOL, V29, P219, DOI 10.1037/h0035908
   Fabri M., 2005, USE EMOTIONALLY EXPR
   FELIPE NJ, 1966, SOC PROBL, V14, P206, DOI 10.1525/sp.1966.14.2.03a00080
   Gifford R., 1996, ENV PSYCHOL
   Gifford R., 1987, Environmental psychology
   Hall E. T., 1959, SILENT LANGUAGE
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   HALL ET, 1963, AM ANTHROPOL, V65, P1003, DOI 10.1525/aa.1963.65.5.02a00020
   HAYDUK LA, 1981, CAN J BEHAV SCI, V13, P274, DOI 10.1037/h0081182
   HAYDUK LA, 1983, PSYCHOL BULL, V94, P293, DOI 10.1037/0033-2909.94.2.293
   HEWITT J, 1987, PERCEPT MOTOR SKILL, V64, P809, DOI 10.2466/pms.1987.64.3.809
   Jeffrey P., 1998, C HUM FACT HUM FACT, P347
   JEFFREY P, 1988, WORKSH PERS SOC NAV, P24
   Johnson A, 1999, IEEE COMPUT GRAPH, V19, P60, DOI 10.1109/38.799741
   KLINGE J, 1999, DIFFERENT AREAS PERS
   Knapp M.L., 1978, NONVERBAL COMMUNICAT
   KRIKORIAN D, 2000, J COMP MEDIATED COMM, V4
   Lea R., 1997, J COLLABORATIVE COMP, V6, P227
   Nassiri N., 2004, VIRTUAL REAL-LONDON, DOI [10.1007/s10055-004-0142-0, DOI 10.1007/S10055-004-0142-0]
   NASSIRI N, 2006, THESIS LEEDS METROPO
   OLIVEIRA C, 2000, P WORKSH APPL VIRT R
   PATTERSON ML, 1971, SOCIOMETRY, V34, P114, DOI 10.2307/2786354
   Sawada Y, 2003, JPN PSYCHOL RES, V45, P115, DOI 10.1111/1468-5884.t01-2-00039
   SCHROEDER R, 2002, SOCIAL LIFE AVATARS, pCH1
   SOMMER R, 2002, PERSONAL SPACE DIGIT
   Sommer R., 1969, Personal Space: Behavioural Basis of Design
   STEED A, 2005, P HCI LAS VEG
   TAYLOR T, 2002, SOCIAL LIFE AVATARS, pCH3
   VAKSMAN E, 1979, VISUAL SPATIAL BEHAV
   WORCHEL S, 1976, J PERS SOC PSYCHOL, V34, P30
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
NR 49
TC 14
Z9 20
U1 6
U2 45
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2010
VL 14
IS 4
BP 229
EP 240
DI 10.1007/s10055-010-0169-3
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HX
UT WOS:000296279800002
DA 2024-07-18
ER

PT J
AU Luciano, C
   Banerjee, P
   DeFanti, T
AF Luciano, Cristian
   Banerjee, Pat
   DeFanti, Thomas
TI Haptics-based virtual reality periodontal training simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Simulation; Training; Haptics; Dentistry; Periodontics
ID VALIDATION
AB This paper focuses upon the research and development of a prototype dental simulator for training of periodontal procedures. By the use of virtual reality and haptics technology, the periodontal simulator allows trainees to learn performing diagnosis and treatment of periodontal diseases by visualizing a three-dimensional virtual human mouth and feeling real tactile sensations while touching the surface of teeth, gingiva, and calculi with virtual dental instruments. Since periodontics requires dentists to depend primarily on tactile sensations to perform diagnostic and surgical procedures, the use of haptics is unquestionably crucial for a realistic periodontal simulator. The haptics-based virtual reality periodontal training simulator has been validated by a experiment conducted by the College of Dentistry at University of Illinois at Chicago (UIC) with faculty members and dental students, which demonstrates the scientific contribution and usefulness of the simulator as a vital part of the curriculum of the Department of Periodontics at UIC.
C1 [Luciano, Cristian; Banerjee, Pat; DeFanti, Thomas] Univ Illinois, Chicago, IL 60607 USA.
   [DeFanti, Thomas] Univ Calif San Diego, San Diego, CA 92103 USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; University of California
   System; University of California San Diego
RP Luciano, C (corresponding author), Univ Illinois, Chicago, IL 60607 USA.
EM clucia1@uic.edu; banerjee@uic.edu; tom@uic.edu
FU Fulbright-YPF; Link Foundation; NIST ATP [70NANB1H3014]; UIC Department
   of Mechanical and Industrial Engineering; UIC Department of Periodontics
FX This work was partially funded by the Fulbright-YPF Fellowship and the
   Link Foundation Fellowship, a subcontract from NIST ATP Cooperative
   Agreement 70NANB1H3014, the UIC Department of Mechanical and Industrial
   Engineering and the UIC Department of Periodontics. The authors would
   like to thank Dr. Arnold Steinberg and Dr. Jim Drummond, from the UIC
   Department of Periodontics, for their technical feedback and thoughts
   from dental educators' perspective, and to Dr. Bruce Graham, Dean of the
   UIC College of Dentistry, for showing so much interest in this project.
CR [Anonymous], SOFTW DEV KIT PROGR
   [Anonymous], MMVR
   [Anonymous], I MED REP ERR IS HUM
   [Anonymous], J DENT ED
   [Anonymous], MMVR
   [Anonymous], ANESTHESIOLOGY
   [Anonymous], THESIS TU MUNCHEN GE
   [Anonymous], MMVR
   [Anonymous], AM J RESP CRIT CARE
   [Anonymous], HAPTIC 3D VIRTUAL RE
   [Anonymous], SIMULIFE SYSTEMS
   [Anonymous], VIRT REAL C
   [Anonymous], MMVR
   [Anonymous], THESIS UIC
   [Anonymous], MMVR
   [Anonymous], MMVR
   Buchanan J A, 2001, J Dent Educ, V65, P1225
   Buchanan Judith A, 2004, J Dent Educ, V68, P1258
   Craig JJ., 1986, INTRO ROBOTICS MECH
   Datta VK, 2001, GUT, V48, pA97
   Jasinevicius T Roma, 2004, J Dent Educ, V68, P1151
   Kim L, 2006, VISUAL COMPUT, V22, P90, DOI 10.1007/s00371-006-0369-8
   Steinberg A.D., 2003, J DENT EDUC, V67, P161
   Steinberg AD, 2007, J DENT EDUC, V71, P1574
   Wong T, 2001, J AM COLL CARDIOL, V37, p493A
NR 25
TC 72
Z9 83
U1 1
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2009
VL 13
IS 2
BP 69
EP 85
DI 10.1007/s10055-009-0112-7
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XD
UT WOS:000208104200001
DA 2024-07-18
ER

PT J
AU Geronazzo, M
   Barumerli, R
   Cesari, P
AF Geronazzo, Michele
   Barumerli, Roberto
   Cesari, Paola
TI Shaping the auditory peripersonal space with motor planning in immersive
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Peripersonal space; Motor planning; Spatial audio
   rendering; Immersive audio
ID EAR TRANSFER-FUNCTIONS; SPATIAL AUDIO; INDIVIDUAL-DIFFERENCES;
   PERCEPTUAL BIAS; HEAD; LOCALIZATION; ADVANTAGE; SOUNDS; MOVEMENTS;
   PREMOTOR
AB Immersive audio technologies require personalized binaural synthesis through headphones to provide perceptually plausible virtual and augmented reality (VR/AR) simulations. We introduce and apply for the first time in VR contexts the quantitative measure called premotor reaction time (pmRT) for characterizing sonic interactions between humans and the technology through motor planning. In the proposed basic virtual acoustic scenario, listeners are asked to react to a virtual sound approaching from different directions and stopping at different distances within their peripersonal space (PPS). PPS is highly sensitive to embodied and environmentally situated interactions, anticipating the motor system activation for a prompt preparation for action. Since immersive VR applications benefit from spatial interactions, modeling the PPS around the listeners is crucial to reveal individual behaviors and performances. Our methodology centered around the pmRT is able to provide a compact description and approximation of the spatiotemporal PPS processing and boundaries around the head by replicating several well-known neurophysiological phenomena related to PPS, such as auditory asymmetry, front/back calibration and confusion, and ellipsoidal action fields.
C1 [Geronazzo, Michele] Univ Padua, Dept Engn & Management, Vicenza, Italy.
   [Geronazzo, Michele] Imperial Coll London, Dyson Sch Design Engn, London, England.
   [Barumerli, Roberto] Austrian Acad Sci, Acoust Res Inst, Vienna, Austria.
   [Cesari, Paola] Univ Verona, Dept Neurol Biomed & Movement Sci, Verona, Italy.
C3 University of Padua; Imperial College London; Austrian Academy of
   Sciences; University of Verona
RP Geronazzo, M (corresponding author), Univ Padua, Dept Engn & Management, Vicenza, Italy.; Geronazzo, M (corresponding author), Imperial Coll London, Dyson Sch Design Engn, London, England.
EM michele.geronazzo@unipd.it; roberto.barumerli@oeaw.ac.at;
   paola.cesari@univr.it
RI ; Geronazzo, Michele/U-8886-2017
OI Barumerli, Roberto/0000-0002-0155-3921; Geronazzo,
   Michele/0000-0002-0621-2704
FU The authors would like to thank all the participants who took part in
   the experimental sessions and Hefio Oy for their prompt assistance with
   their great headphone solution. We wish to thank K. Britsch for his
   assistance in proofreading the manuscript's fi; Verona Brain Research
   Foundation; Aalborg University
FX The authors would like to thank all the participants who took part in
   the experimental sessions and Hefio Oy for their prompt assistance with
   their great headphone solution. We wish to thank K. Britsch for his
   assistance in proofreading the manuscript's first draft. This study was
   supported by the Verona Brain Research Foundation and the
   internationalization grant of the 2016-2021 strategic program "Knowledge
   for the World" awarded by Aalborg University to MG.
CR Aggius-Vella E, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27370-9
   Atherton J, 2020, J NEW MUSIC RES, V49, P35, DOI 10.1080/09298215.2019.1705862
   Aussal M, 2012, AUD ENG SOC UK C, V04
   Bach DR, 2009, INT J PSYCHOPHYSIOL, V74, P28, DOI 10.1016/j.ijpsycho.2009.06.004
   Bahadori M, 2021, NEUROPSYCHOLOGIA, V155, DOI 10.1016/j.neuropsychologia.2021.107790
   Berger CC, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00021
   BOUISSET S, 1987, J BIOMECH, V20, P735, DOI 10.1016/0021-9290(87)90052-2
   Bowman A., 1997, Applied Smoothing Techniques for Data Analysis: The Kernel Approach with S-Plus Illustrations
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Brent RP., 2013, ALGORITHMS MINIMIZAT
   Brinkmann F, 2015, IEEE J-STSP, V9, P931, DOI 10.1109/JSTSP.2015.2414905
   Brungart DS, 1999, J ACOUST SOC AM, V106, P1465, DOI 10.1121/1.427180
   Buck LE, 2022, IEEE T VIS COMPUT GR, V28, P2102, DOI 10.1109/TVCG.2022.3150483
   Bufacchi RJ, 2016, J NEUROPHYSIOL, V115, P218, DOI 10.1152/jn.00691.2015
   Bufacchi RJ, 2018, TRENDS COGN SCI, V22, P1076, DOI 10.1016/j.tics.2018.09.004
   Cadet LB, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102506
   Camponogara I, 2015, NEUROSCIENCE, V304, P101, DOI 10.1016/j.neuroscience.2015.07.054
   Canzoneri E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044306
   Cattaneo L, 2015, NEUROSCIENCE, V304, P81, DOI 10.1016/j.neuroscience.2015.07.053
   Cesari P, 2022, NEUROSCIENCE, V490, P25, DOI 10.1016/j.neuroscience.2022.03.005
   CHALLIS JH, 1995, J BIOMECH, V28, P733, DOI 10.1016/0021-9290(94)00116-L
   Cooke DF, 2003, P NATL ACAD SCI USA, V100, P6163, DOI 10.1073/pnas.1031751100
   Cuevas-Rodríguez M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211899
   Deng YQ, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116151
   Filimon F, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00648
   Finisguerra A, 2015, NEUROPSYCHOLOGIA, V70, P421, DOI 10.1016/j.neuropsychologia.2014.09.043
   Geronazzo M, 2023, SONIC INTERACTIONS V, P3, DOI [10.1007/978-3-031-04021-4_1, DOI 10.1007/978-3-031-04021-4_1]
   Geronazzo M., 2023, SONIC INTERACTIONS V, DOI [10.1007/978-3-031-04021-4, DOI 10.1007/978-3-031-04021-4]
   Geronazzo M, 2020, INT CONF ACOUST SPEE, P411, DOI [10.1109/icassp40776.2020.9053873, 10.1109/ICASSP40776.2020.9053873]
   Geronazzo M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P299, DOI 10.1145/2993369.2996303
   Gibson E.Pick., 2000, ECOLOGICAL APPROACH
   Graziano MSA, 1999, NATURE, V397, P428, DOI 10.1038/17115
   GRAZIANO MSA, 1994, SCIENCE, V266, P1054, DOI 10.1126/science.7973661
   Griffiths TD, 1999, NEUROIMAGE, V10, P84, DOI 10.1006/nimg.1999.0464
   Grivaz P, 2017, NEUROIMAGE, V147, P602, DOI 10.1016/j.neuroimage.2016.12.052
   Gulli A, 2023, P 26 INT C DIG AUD E
   Hacihabiboglu H, 2017, IEEE SIGNAL PROC MAG, V34, P36, DOI 10.1109/MSP.2017.2666081
   Hendrikse MME, 2018, SPEECH COMMUN, V101, P70, DOI 10.1016/j.specom.2018.05.008
   Hiipakka M, 2010, J AUDIO ENG SOC, V58, P269
   Hiscock M, 2011, BRAIN COGNITION, V76, P263, DOI 10.1016/j.bandc.2011.03.016
   Hobeika L, 2020, J NEUROSCI METH, V332, DOI 10.1016/j.jneumeth.2019.108534
   Hobeika L, 2018, EXP BRAIN RES, V236, P609, DOI 10.1007/s00221-017-5158-2
   Kan A, 2009, J ACOUST SOC AM, V125, P2233, DOI 10.1121/1.3081395
   Kandula M, 2017, EXP BRAIN RES, V235, P2511, DOI 10.1007/s00221-017-4965-9
   Katz BFG, 2014, J ACOUST SOC AM, V135, P3530, DOI 10.1121/1.4875714
   Komeilipoor N, 2015, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fnins.2015.00149, 10.3389/fnins.7015.00149]
   Majdak P, 2013, AUDIO ENG SOC CONVEN, V134
   Majdak P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00319
   MASSION J, 1992, PROG NEUROBIOL, V38, P35, DOI 10.1016/0301-0082(92)90034-C
   Middlebrooks JC, 1999, J ACOUST SOC AM, V106, P1480, DOI 10.1121/1.427176
   Middlebrooks JC, 1999, J ACOUST SOC AM, V106, P1493, DOI 10.1121/1.427147
   MOLLER H, 1992, APPL ACOUST, V36, P171, DOI 10.1016/0003-682X(92)90046-U
   Moore BCJ, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516682698
   Neuhoff JG, 1998, NATURE, V395, P123, DOI 10.1038/25862
   Neuhoff JG, 2001, ECOL PSYCHOL, V13, P87, DOI 10.1207/S15326969ECO1302_2
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Noel JP, 2018, J NEUROPHYSIOL, V119, P2307, DOI 10.1152/jn.00652.2017
   Nordahl Rolf., 2016, The Oxford Handbook of Interactive Audio, P213, DOI DOI 10.1093/OXFORDHB/9780199797226.013.013
   Occelli V, 2011, NEUROSCI BIOBEHAV R, V35, P589, DOI 10.1016/j.neubiorev.2010.07.004
   Parseihian G, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00269
   PERROTT DR, 1990, J ACOUST SOC AM, V87, P1728, DOI 10.1121/1.399421
   Poirier-Quinot D, 2020, J AUDIO ENG SOC, V68, P248, DOI 10.17743/jaes.2020.0004
   Prepelita ST, 2020, J ACOUST SOC AM, V147, P3631, DOI 10.1121/10.0001230
   Railo H, 2011, BRAIN COGNITION, V77, P391, DOI 10.1016/j.bandc.2011.08.019
   Ramstead MJD, 2020, ADAPT BEHAV, V28, P225, DOI 10.1177/1059712319862774
   Rizzolatti G, 1997, SCIENCE, V277, P190, DOI 10.1126/science.277.5323.190
   Romblom D, 2008, AUDIO ENG SOC CONVEN, V125
   Sætrevik B, 2007, NEUROPSYCHOLOGIA, V45, P282, DOI 10.1016/j.neuropsychologia.2006.07.005
   Savel S, 2009, HEARING RES, V255, P142, DOI 10.1016/j.heares.2009.06.013
   Schissler C, 2018, IEEE T VIS COMPUT GR, V24, P1246, DOI 10.1109/TVCG.2017.2666150
   Schissler C, 2016, IEEE T VIS COMPUT GR, V22, P1356, DOI 10.1109/TVCG.2016.2518134
   Serino A., 2018, Frontiers in ICT, V4, P31, DOI [10.3389/fict.2017.00031, DOI 10.3389/FICT.2017.00031]
   Serino A, 2019, NEUROSCI BIOBEHAV R, V99, P138, DOI 10.1016/j.neubiorev.2019.01.016
   Serino A, 2015, SCI REP-UK, V5, DOI 10.1038/srep18603
   Serino A, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006582
   Staude G., 2001, EURASIP Journal on Applied Signal Processing, V2001, P67, DOI 10.1155/S1110865701000191
   Taffou M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79767-0
   Techentin C, 2009, BRAIN COGNITION, V70, P201, DOI 10.1016/j.bandc.2009.02.003
   Valori I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0222253
   Vasser M, 2020, CURR OPIN PSYCHOL, V36, P71, DOI 10.1016/j.copsyc.2020.04.010
   Vorländer M, 2014, ARCH ACOUST, V39, P307, DOI 10.2478/aoa-2014-0036
   Wefers F, 2018, VIRTUAL REAL-LONDON, V22, P281, DOI 10.1007/s10055-018-0332-9
   Xie B., 2013, Head-related transfer function and virtual auditory display, V2nd
   Zahorik P, 2001, NAT NEUROSCI, V4, P78, DOI 10.1038/82931
   Zhang S, 2013, J SPORT MED PHYS FIT, V53, P566
   Zhang ZY, 2014, NEURAL COMPUT, V26, P2570, DOI 10.1162/NECO_a_00646
   Zotkin DN, 2004, IEEE T MULTIMEDIA, V6, P553, DOI [10.1109/TMM.2004.827516, 10.1109/tmm.2004.827516]
NR 87
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3067
EP 3087
DI 10.1007/s10055-023-00854-4
EA OCT 2023
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001077694600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Cruz, JT
   Coluci, VR
   Moraes, R
AF Cruz, Jhasmani Tito
   Coluci, Vitor Rafael
   Moraes, Regina
TI ORUN-VR2: a VR serious game on the projectile kinematics: design,
   evaluation, and learning outcomes
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Physics teaching; Kinematics; STEM; Serious games
ID VIRTUAL ENVIRONMENTS; REALITY
AB Virtual reality (VR) offers possibilities for Science, Technology, Engineering, and Mathematics education by facilitating the understanding of abstract concepts. In this work, we designed, developed, and tested an immersive VR serious game-ORUN-VR-to engage students and to improve their understanding of the Physics concepts related to the projectile kinematics. User-based experiments, knowledge and usability tests, engagement and presence evaluations, screen capturing, and statistical analysis were performed to obtain and analyse data from over 130 high school students that have played ORUN-VR. Knowledge tests indicated an overall learning gain of 52% for the students who played in comparison with those who did not, with differences between men and women. Game engagement and presence VR were positively evaluated. The effects of game engagement, presence in VR, and gender on the learning outcomes are discussed. Our results showed that ORUN-VR can be a valuable immersive VR environment to support learning in projectile kinematics.
C1 [Cruz, Jhasmani Tito; Coluci, Vitor Rafael; Moraes, Regina] Univ Estadual Campinas, Sch Technol, Limeira, SP, Brazil.
   [Moraes, Regina] Univ Coimbra, Dept Informat Engn, Coimbra, Portugal.
C3 Universidade Estadual de Campinas; Universidade de Coimbra
RP Cruz, JT (corresponding author), Univ Estadual Campinas, Sch Technol, Limeira, SP, Brazil.
EM j265442@dac.unicamp.br; coluci@unicamp.br; regina@ft.unicamp.br
RI Coluci, Vitor R/E-1079-2012
OI Moraes, Regina/0000-0003-0678-4777; Tito Cruz,
   Jhasmani/0000-0003-0639-797X
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brazil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior-Brazil (CAPES)-Finance Code 001.
CR Adamo-Villani N, 2008, VIS 2008: INTERNATIONAL CONFERENCE VISUALISATION, PROCEEDINGS, P114, DOI 10.1109/VIS.2008.10
   Boettcher KER, 2020, IEEE GLOB ENG EDUC C, P1563, DOI [10.1109/educon45650.2020.9125348, 10.1109/EDUCON45650.2020.9125348]
   Brockmyer JH, 2009, J EXP SOC PSYCHOL, V45, P624, DOI 10.1016/j.jesp.2009.02.016
   Calderon R., 2019, 2019 IEEE WORLD C EN, P1, DOI [10.1109/EDUNINE.2019.8875824, DOI 10.1109/EDUNINE.2019.8875824]
   Ciavarro C, 2008, COMPUT HUM BEHAV, V24, P2862, DOI 10.1016/j.chb.2008.04.011
   Dergham M, 2019, INT CONF COGN INFO, P107, DOI [10.1109/coginfocom47531.2019.9089971, 10.1109/CogInfoCom47531.2019.9089971]
   Halloun I, 2007, EVALUATION IMPACT NE
   Handoko E, 2019, PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON NEW MEDIA STUDIES (CONMEDIA 2019), P165, DOI [10.1109/CONMEDIA46929.2019.8981837, 10.1109/conmedia46929.2019.8981837]
   Hestenes D., 1992, The Physics Teacher, V30, P159
   Jesse S., 2008, ART GAME DESIGN BOOK
   Johnson-Glenberg MC, 2021, J COMPUT ASSIST LEAR, V37, P1263, DOI 10.1111/jcal.12567
   Johnson-Glenberg MC, 2019, SMART COMPUT INTELL, P83, DOI 10.1007/978-981-13-8265-9_5
   Kalina E, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P31, DOI [10.23919/ilrn47897.2020.9155160, 10.23919/iLRN47897.2020.9155160]
   Liou W.-K., 2018, INT SCI PROFESSIONAL, P1, DOI DOI 10.1109/SPIT.2018.8350861
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Naranjo JE, 2020, INT CONF EDEMOC EGOV, P253, DOI 10.1109/ICEDEG48599.2020.9096744
   Natucci GC, 2021, IEEE CONF COMPU INTE, P151, DOI 10.1109/COG52621.2021.9619144
   Nersesian E, 2019, INTEGR STEM EDU CONF, P83, DOI [10.1109/ISECon.2019.8882070, 10.1109/isecon.2019.8882070]
   Nielsen J., 2020, 10 Usability Heuristics for User Interface Design
   NIELSEN J., 1993, Usability Engineering, P23, DOI [10.1016/B978-0-08-052029-2.50005-X, DOI 10.1016/B978-0-08-052029-2.50005-X, https://doi.org/10.1016/B978-0-08-052029-2.50005-X]
   Oyelere SS, 2020, SMART LEARN ENVIRON, V7, DOI 10.1186/s40561-020-00142-7
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   Pirker J, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P242, DOI [10.23919/iLRN47897.2020.9155167, 10.23919/ilrn47897.2020.9155167]
   Pirker J, 2017, IEEE INT CONF ADV LE, P482, DOI 10.1109/ICALT.2017.92
   Qorbani HS, 2021, 2021 4TH IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2021), P267, DOI 10.1109/AIVR52153.2021.00060
   Radu I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300774
   Ralph P., 2015, The Computer Games Journal, V4, P81
   REBER AS, 1989, J EXP PSYCHOL GEN, V118, P219, DOI 10.1037/0096-3445.118.3.219
   Silva GR, 2016, VIRTUAL REAL-LONDON, V20, P237, DOI 10.1007/s10055-016-0295-7
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Southgate E, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P418, DOI [10.1109/VRW50115.2020.00089, 10.1109/VRW50115.2020.0-187]
   Sulaiman Hidayah, 2020, 2020 IEEE Conference on e-Learning, e-Management and e-Services (IC3e), P1, DOI 10.1109/IC3e50159.2020.9288464
   Sutcliffe A, 2004, INTERACT COMPUT, V16, P831, DOI 10.1016/j.intcom.2004.05.001
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   Tito J, 2022, UNICAMPS RES DATA RE, DOI [10.25824/redu/NQZRAW, DOI 10.25824/REDU/NQZRAW]
   Triola MF, 2008, INTRO ESTATISTICA, V10a, P722
   Tuli N., 2020, Procedia Computer Science, V172, P660
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Economic Forum, 2020, FUT JOBS REP 2020
   Yuan Jiugen, 2020, 2020 15th International Conference on Computer Science & Education (ICCSE), P262, DOI 10.1109/ICCSE49874.2020.9201890
   Zhao JY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P893, DOI [10.1109/VR46266.2020.00114, 10.1109/VR46266.2020.1581091793502]
NR 42
TC 2
Z9 2
U1 13
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2583
EP 2604
DI 10.1007/s10055-023-00824-w
EA JUL 2023
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001025578800001
DA 2024-07-18
ER

PT J
AU Kammler-Sücker, KI
   Löffler, A
   Flor, H
AF Kammler-Suecker, Kornelius Immanuel
   Loeffler, Annette
   Flor, Herta
TI Effects of personalized movement models in virtual reality on pain
   expectancy and motor behavior in patients with chronic back pain: a
   feasibility study
SO VIRTUAL REALITY
LA English
DT Article
DE Chronic back pain; Virtual reality; Mixed reality; Fear avoidance;
   Observational modelling; Observational placebo; Movement behavior; Range
   of motion; Model-observer similarity; Pain expectancy;
   Cognitive-behavioral therapy; Virtual doppelgangers; Avatars;
   Third-person perspective
ID FEAR-AVOIDANCE MODEL; CHRONIC MUSCULOSKELETAL PAIN; SELF-EFFICACY;
   OBSERVER SIMILARITY; QUESTIONNAIRE; EXPOSURE; BELIEFS; DOPPELGANGERS;
   MECHANISMS; INFERENCE
AB Cognitive-behavioral therapy (CBT) of chronic pain focuses on behavioral, cognitive, affective and social factors that play a role in the transition from acute to chronic pain, which often is initially caused by a specific event but then takes on "a life of its own". CBT models assume that fear of pain and subsequent avoidance behavior contribute to pain chronicity and the maintenance of chronic pain. In chronic back pain (CBP), avoidance is often addressed by teaching patients to reduce pain behaviors (such as guarding and bracing that may become dysfunctional over time) and increase healthy behaviors (such as physical exercise and meaningful social activities). The current study explored if personalized virtual movement models (doppelganger avatars), who maximize model-observer similarity in virtual reality (VR), can influence fear of pain, motor avoidance and movement-related pain and function. In a randomized controlled trial, participants with CBP observed and imitated an avatar (AVA, N = 17) or a videotaped model (VID, N = 16) over three sessions, where moving a beverage crate, bending sideward (BS), and rotation in the horizontal plane (RH) were shown. Self-reported pain expectancy, as well as engagement, functional capacity and pain during movements, were analyzed along with range of motion (ROM). The AVA group reported higher engagement with no significant group differences observed in ROM. Pain expectancy increased in AVA but not VID over the sessions. Pain and limitations did not significantly differ. However, we observed a significant moderation effect of group, with prior pain expectancy predicting pain and avoidance in the VID but not in the AVA group. This can be interpreted as an effect of personalized movement models decoupling pain behavior from movement-related fear and pain expectancy. Thus, personalized virtual movement models may provide an additional tool for exposure and exercise treatments in cognitive-behavioral treatment approaches to CBP.
C1 [Kammler-Suecker, Kornelius Immanuel; Loeffler, Annette; Flor, Herta] Heidelberg Univ, Cent Inst Mental Hlth, Med Fac Mannheim, Dept Cognit & Clin Neurosci, D-68159 Mannheim, Germany.
   [Kammler-Suecker, Kornelius Immanuel] Heidelberg Univ, Cent Inst Mental Hlth, Med Fac Mannheim, Ctr Innovat Psychiat & Psychotherapeut Res, D-68159 Mannheim, Germany.
C3 Central Institute of Mental Health; Ruprecht Karls University
   Heidelberg; Central Institute of Mental Health; Ruprecht Karls
   University Heidelberg
RP Kammler-Sücker, KI (corresponding author), Heidelberg Univ, Cent Inst Mental Hlth, Med Fac Mannheim, Dept Cognit & Clin Neurosci, D-68159 Mannheim, Germany.; Kammler-Sücker, KI (corresponding author), Heidelberg Univ, Cent Inst Mental Hlth, Med Fac Mannheim, Ctr Innovat Psychiat & Psychotherapeut Res, D-68159 Mannheim, Germany.
EM kornelius.kammler-suecker@zi-mannheim.de
RI Loeffler, Annette/JWA-2308-2024; Kammler-Sücker, Kornelius
   Immanuel/JBI-7018-2023
OI Loeffler, Annette/0000-0001-7337-2559; Kammler-Sücker, Kornelius
   Immanuel/0000-0002-6127-5468
FU Reinhart Koselleck award of the Deutsche Forschungsgemeinschaft [FL
   156/41-1]; Projekt DEAL
FX We want to express our gratitude to Iris Reinhard and Dieter Kleinboehl
   for their valuable advice on statistical matters. Our thanks for
   valuable assistance go to Melissa Mohr, who also re-staged the
   experiment, and Anna Staib, Isabelle Neumann, and Jerusha Devendraraj.
   We also want to thank all participants, especially those who have agreed
   to the use of their doppelganger image. This work was funded by a
   Reinhart Koselleck award of the Deutsche Forschungsgemeinschaft to HF
   (FL 156/41-1).Open Access funding enabled and organized by Projekt DEAL
CR Alemanno F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216858
   Babel P, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00449
   Bailenson JN, 2012, PSYCHOLOGIST, V25, P36
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Bandura A., 1986, Social foundations of thought and action: A social cognitive theory, V1986, P23
   Bandura A., 1998, SELF EFFICACY EXERCI
   Bartl A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694617
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bordeleau M, 2022, J PAIN, V23, P175, DOI 10.1016/j.jpain.2021.08.001
   Braaksma MAH, 2002, J EDUC PSYCHOL, V94, P405, DOI 10.1037//0022-0663.94.2.405
   Brea-Gomez B, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182211806
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Colloca L, 2013, PAIN, V154, P511, DOI 10.1016/j.pain.2013.02.002
   Colloca L, 2009, PAIN, V144, P28, DOI 10.1016/j.pain.2009.01.033
   Crombez G, 1999, PAIN, V80, P329, DOI 10.1016/S0304-3959(98)00229-2
   Crombez G, 2012, CLIN J PAIN, V28, P475, DOI 10.1097/AJP.0b013e3182385392
   DOVE JL, 1972, PSYCHOL REP, V31, P599, DOI 10.2466/pr0.1972.31.2.599
   Duffy KA, 2015, CURR OPIN BEHAV SCI, V3, P112, DOI 10.1016/j.cobeha.2015.03.002
   Flor H, 1990, Schmerz, V4, P82, DOI 10.1007/BF02527839
   Flor H., 2011, Chronic Pain: An Integrated Biobehavioral Approach
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   France CR, 2018, CONTEMP CLIN TRIALS, V69, P83, DOI 10.1016/j.cct.2018.05.001
   Garcia LM, 2021, J MED INTERNET RES, V23, DOI 10.2196/26292
   Gatzounis R, 2021, J PAIN, V22, P1315, DOI 10.1016/j.jpain.2021.04.012
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Goubert L, 2011, J PAIN, V12, P167, DOI 10.1016/j.jpain.2010.10.001
   Grassini S, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19074071
   Greer RD, 2006, INT J PSYCHOL, V41, P486, DOI 10.1080/00207590500492435
   Hamilton AFD, 2015, CURR OPIN BEHAV SCI, V3, P63, DOI 10.1016/j.cobeha.2015.01.011
   Hasenbring MI, 2012, PAIN, V153, P211, DOI 10.1016/j.pain.2011.10.019
   Hennessy RW, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/17799
   Herrmann C., 1995, HADS D
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoogerheide V, 2018, COMPUT HUM BEHAV, V89, P457, DOI 10.1016/j.chb.2017.11.012
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Hox JJ., 2017, MULTILEVEL ANAL TECH, DOI [10.4324/9781315650982, DOI 10.4324/9780203852279]
   Jansen-Kosterink SM, 2013, GAMES HEALTH J, V2, P299, DOI 10.1089/g4h.2013.0043
   Janssens T, 2019, PAIN REP, V4, DOI 10.1097/PR9.0000000000000748
   Kammler-Sücker KI, 2021, IEEE T NEUR SYS REH, V29, P2173, DOI 10.1109/TNSRE.2021.3120795
   Kenward MG, 1997, BIOMETRICS, V53, P983, DOI 10.2307/2533558
   KERNS RD, 1985, PAIN, V23, P345, DOI 10.1016/0304-3959(85)90004-1
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Klinger R, 2017, PAIN, V158, P1893, DOI 10.1097/j.pain.0000000000000977
   Kohlmann T., 1996, Die Rehabilitation, V35, P1, DOI DOI 10.1055/S-00000065
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Laird RA, 2014, BMC MUSCULOSKEL DIS, V15, DOI 10.1186/1471-2474-15-229
   LETHEM J, 1983, BEHAV RES THER, V21, P401, DOI 10.1016/0005-7967(83)90009-8
   LITT MD, 1988, J PERS SOC PSYCHOL, V54, P149, DOI 10.1037/0022-3514.54.1.149
   Main C., 2014, Fordyce's Behavioral Methods for Chronic Pain and Illness
   Marich AV, 2018, PHYS THER, V98, P605, DOI 10.1093/ptj/pzy044
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   Nambi G, 2021, TECHNOL HEALTH CARE, V29, P155, DOI 10.3233/THC-202301
   Nicholas MK, 2007, EUR J PAIN, V11, P153, DOI 10.1016/j.ejpain.2005.12.008
   Nierula B, 2017, J PAIN, V18, P645, DOI 10.1016/j.jpain.2017.01.003
   Nilsen DLF, 1998, HUMOR, V11, P111, DOI 10.1515/humr.1998.11.2.111
   Öztürk Ö, 2021, J CLIN NEUROSCI, V90, P144, DOI 10.1016/j.jocn.2021.05.055
   Peterson BN, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.742290
   Pfingsten M, 2000, EUR J PAIN-LONDON, V4, P259, DOI 10.1053/eujp.2000.0178
   Raspe H H, 1991, Schmerz, V5, pS38, DOI 10.1007/BF02530069
   Raspe HH., 1990, Wohnortnahe Betreuung Rheumakranker: Ergebnisse sozialwissenschaftlicher Evaluation eines Modellversuches, P164
   Riecke J, 2020, EUR J PAIN, V24, P1495, DOI 10.1002/ejp.1604
   Schenk LA, 2017, PAIN, V158, P2077, DOI 10.1097/j.pain.0000000000000943
   Schmitz J, 2019, PSYCHOTHER PSYCHOSOM, V88, P203, DOI 10.1159/000501385
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Tack C, 2021, DISABIL REHABIL-ASSI, V16, P637, DOI 10.1080/17483107.2019.1688399
   Tang NKY, 2007, BEHAV RES THER, V45, P2821, DOI 10.1016/j.brat.2007.05.004
   Tomasello M, 2016, CHILD DEV, V87, P643, DOI 10.1111/cdev.12499
   Trost Z, 2008, PAIN, V137, P26, DOI 10.1016/j.pain.2007.08.005
   van Dieën JH, 2017, EXERC SPORT SCI REV, V45, P223, DOI 10.1249/JES.0000000000000121
   Vlaeyen, 2012, PAIN RELATED FEAR EX
   Vlaeyen JWS, 2016, PAIN, V157, P1588, DOI 10.1097/j.pain.0000000000000574
   Vlaeyen JWS, 2012, PAIN, V153, P1144, DOI 10.1016/j.pain.2011.12.009
   Vlaeyen JWS, 2000, PAIN, V85, P317, DOI 10.1016/S0304-3959(99)00242-0
   Volders S, 2015, BEHAV RES THER, V64, P31, DOI 10.1016/j.brat.2014.11.003
   Von Korff M, 2020, PAIN, V161, P651, DOI 10.1097/j.pain.0000000000001758
   VONKORFF M, 1992, PAIN, V50, P133, DOI 10.1016/0304-3959(92)90154-4
   WADDELL G, 1993, PAIN, V52, P157, DOI 10.1016/0304-3959(93)90127-B
   Wenninger S., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418940, 10.1145/3385956.3418940]
   Wertli MM, 2014, SPINE J, V14, P816, DOI 10.1016/j.spinee.2013.09.036
   Woods MP, 2008, PAIN, V136, P271, DOI 10.1016/j.pain.2007.06.037
   Zentall TR, 2006, ANIM COGN, V9, P335, DOI 10.1007/s10071-006-0039-2
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 88
TC 0
Z9 0
U1 10
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3581
EP 3598
DI 10.1007/s10055-023-00800-4
EA MAY 2023
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000986040300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Marques, B
   Ferreira, C
   Silva, S
   Dias, P
   Santos, BS
AF Marques, Bernardo
   Ferreira, Carlos
   Silva, Samuel
   Dias, Paulo
   Santos, Beatriz Sousa
TI Is social presence (alone) a general predictor for good remote
   collaboration? comparing video and augmented reality guidance in
   maintenance procedures
SO VIRTUAL REALITY
LA English
DT Article
DE Remote collaboration; Social presence; Collaborative process; Task
   resolution; Video stream; Augmented reality annotations; User study
AB A common practice in scenarios of remote collaboration is to provide a representation from distributed team members, aiming to positively influence the level of social presence and in turn the work effort. Nevertheless, these stimuli can lead to fractured learning experiences, since collaborators need to split attention among the task, the shared information, and the counterpart representation. This paper explored how the last affects social presence, and other dimensions of collaboration, as well as task resolution in scenarios of remote guidance. A user study was conducted, comparing two distinct conditions: traditional video chat (team members representation always visible) and Augmented Reality (AR) annotations (collaborators representation never available). These were selected due to ongoing research with partners from the industry sector, following the insights of a participatory design process. A real-life use-case was considered, i.e., synchronous maintenance task with 4 completion stages that required a remote expert using a computer to guide 37 on-site participants wielding a handheld device. The results of the study are described and discussed based on data analysis, showing that the majority of participants preferred the AR-based condition, despite the absence of the expert representation.
C1 [Marques, Bernardo; Ferreira, Carlos; Silva, Samuel; Dias, Paulo; Santos, Beatriz Sousa] Univ Aveiro, IEETA, LASI, DETI, Campus Univ Santiago, Aveiro, Portugal.
C3 Universidade de Aveiro
RP Marques, B (corresponding author), Univ Aveiro, IEETA, LASI, DETI, Campus Univ Santiago, Aveiro, Portugal.
EM bernardo.marques@ua.pt
RI Dias, Paulo PMD/G-3681-2013
OI Dias, Paulo PMD/0000-0002-3754-2749; Ferreira,
   Carlos/0000-0002-2799-643X; Marques, Bernardo/0000-0002-4454-710X
FU University of Aveiro [POCI-01-0247-FEDER-007678]; Bosch Termotecnologia
   S.A. [POCI-01-0247-FEDER-007678]; European Regional Development Fund;
   Portugal 2020 under COMPETE 2020
FX We would like to thank the reviewers for their thoughtful comments and
   suggestions toward improving on an earlier version of this manuscript.
   To everyone involved in the user study, and discussion groups, thanks
   for your time and expertise. The user study of this research was
   possible due to an industrial collaboration under the Smart Green Homes
   Project [POCI-01-0247-FEDER-007678], a co-promotion between Bosch
   Termotecnologia S.A. and the University of Aveiro. It is financed by
   Portugal 2020 under COMPETE 2020 and by the European Regional
   Development Fund.
CR Alves JB, 2022, VIRTUAL REAL-LONDON, V26, P235, DOI 10.1007/s10055-021-00557-8
   Arias E., 2000, ACM Transactions on Computer-Human Interaction, V7, P84, DOI 10.1145/344949.345015
   Aschenbrenner D, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P69, DOI 10.1109/ISMAR-Adjunct.2018.00036
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barnum C.M., 2010, Usability Testing Essentials
   Billinghurst M., 1998, Virtual Reality, V3, P25, DOI 10.1007/BF01409795
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Gerhard M, 2004, INT J HUM-COMPUT ST, V61, P453, DOI 10.1016/j.ijhcs.2003.12.014
   Gervasi R, 2020, INT J ADV MANUF TECH, V108, P841, DOI 10.1007/s00170-020-05363-1
   Gonçalves G, 2022, VIRTUAL REAL-LONDON, V26, P1, DOI 10.1007/s10055-021-00530-5
   Grudin J, 2013, INTERACT FOUND
   Hall M, 2018, DS 92 P DESIGN 2018
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Jalo H., 2018, P 10 INT JOINT C KNO, P41, DOI [10.5220/0006889800410051, DOI 10.5220/0006889800410051]
   Johnson S, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P1825, DOI 10.1145/2675133.2675176
   Kim K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P529, DOI [10.1109/VR46266.2020.00-30, 10.1109/VR46266.2020.1581084624004]
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim S, 2020, J MULTIMODAL USER IN, V14, P313, DOI 10.1007/s12193-020-00346-8
   Kim S, 2018, COMPUT SUPP COOP W J, V27, P569, DOI 10.1007/s10606-018-9324-2
   Kim Y, 2018, VIRTUAL REAL-LONDON, V22, P25, DOI 10.1007/s10055-017-0315-2
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Lee G, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P343, DOI [10.1109/VR46266.2020.1581166222244, 10.1109/VR46266.2020.00-50]
   Liberatore MJ, 2021, VIRTUAL REAL-LONDON, V25, P773, DOI 10.1007/s10055-020-00492-0
   Ludwig T, 2021, COMPUT SUPP COOP W J, V30, P119, DOI 10.1007/s10606-021-09393-5
   Marques B, IEEE INT S MIXED AUG, P336
   Marques B, 17 ACM SIGGRAPH INT, P267
   Marques B, 2022, COMPUT GRAPH-UK, V102, P413, DOI 10.1016/j.cag.2021.10.009
   Marques B, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P705, DOI 10.1109/VRW55335.2022.00208
   Marques B, 2022, COMPUT GRAPH-UK, V102, P619, DOI 10.1016/j.cag.2021.08.006
   Marques B, 2022, INT J INTERACT DES M, V16, P419, DOI 10.1007/s12008-021-00798-6
   Marques B, 2022, IEEE T VIS COMPUT GR, V28, P5113, DOI 10.1109/TVCG.2021.3101545
   Marques B, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P567, DOI 10.1109/VRW52623.2021.00166
   Marques Bernardo, 2022, IEEE C VIRTUAL REALI
   Marques Bernardo, 2022, IEEE INT S MIXED AUG
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Osmers N, 2021, CHI C HUMAN FACTORS, P1
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Rhee T, 2020, IEEE T VIS COMPUT GR, V26, P1923, DOI 10.1109/TVCG.2020.2973065
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schneider M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1277, DOI 10.1109/ICIT.2017.7915547
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Teo T, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365687
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Thomas PJ., 1996, SPRINGER THESES-RECO, DOI [10.1007/978-1-4471-3056-7, DOI 10.1007/978-1-4471-3056-7]
   Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/vr.2019.8797719, 10.1109/VR.2019.8797719]
NR 52
TC 5
Z9 5
U1 3
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1783
EP 1796
DI 10.1007/s10055-023-00770-7
EA FEB 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000937418400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, JW
   Han, SH
   Choi, S
AF Lee, Jiwan
   Han, Sung H.
   Choi, Seungmoon
TI Sensory cue integration of visual and vestibular stimuli: a case study
   for 4D rides
SO VIRTUAL REALITY
LA English
DT Article
DE Self-motion perception; Visuo-vestibular perception; Bayesian
   integration; Vestibular capture; Differential threshold; Visual
   distractor; Dual-task paradigm
ID SELF-MOTION; PERCEPTION; COMBINATION; INFORMATION; DURATION; FUSION
AB This paper investigated human self-motion perception through the visual and vestibular sensory systems under the context of virtual reality (VR) and 4D. Consistently with general 4D riding applications, we designed and used sinusoidal motions as stimuli, which resembled simple roller coaster rides moving in three directions of pitch, surge, and heave. Based on the Bayesian integration model, we experimented to determine the uncertainty involved in the two sensory systems and their relative contributions. We factored in small sensory discrepancies between the visual and vestibular cues and visually noticeable obstacles that could distract viewers. We found that the vestibular system contributed more dominantly to the perception in the ratio of 7:3 than the vision, demonstrating vestibular capture. We also discovered that the visual scenes that contain eye-catching elements and pure optical flows can hamper self-motion perception while increasing the perceptual uncertainty. Our findings can serve as a basis for designing motion effects for VR and 4D applications, especially in situations where multiple sensory systems are stimulated simultaneously.
C1 [Lee, Jiwan; Choi, Seungmoon] POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
   [Han, Sung H.] POSTECH, Dept Ind & Management Engn, Pohang, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Pohang University
   of Science & Technology (POSTECH)
RP Choi, S (corresponding author), POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
EM jiwan.lee@postech.ac.kr; shan@postech.ac.kr; choism@postech.ac.kr
OI Lee, Jiwan/0000-0003-0281-2005
FU Samsung Research Funding and Incubation Center of Samsung Electronics
   [SRFC-IT1802-05]
FX This study was funded by Samsung Research Funding and Incubation Center
   of Samsung Electronics under a grant (SRFC-IT1802-05).
CR Alais D., 2019, Springer Handbook of Auditory Research, V68, P9, DOI [10.1007/978-3-030-10461-0_2, DOI 10.1007/978-3-030-10461-0_2, 10.1007/978-3-030-10461-02, DOI 10.1007/978-3-030-10461-02]
   Angelaki DE, 2009, NEURON, V64, P448, DOI 10.1016/j.neuron.2009.11.010
   BANDAI NAMCO amusement, 2021, VR ZON
   Butler JS, 2011, SEEING PERCEIVING, V24, P453, DOI 10.1163/187847511X588070
   Butler JS, 2010, J VISION, V10, DOI 10.1167/10.11.23
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Covaci A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3233774
   DeAngelis G.C., 2012, The Neural Bases of Multisensory Processes, P629
   DiCiccio TJ, 1996, STAT SCI, V11, P189
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   FERNANDEZ C, 1976, J NEUROPHYSIOL, V39, P970, DOI 10.1152/jn.1976.39.5.970
   Fetsch CR, 2009, J NEUROSCI, V29, P15601, DOI 10.1523/JNEUROSCI.2574-09.2009
   Gibson J.J., 1950, The American Journal of Psychology, V64, P440, DOI [10.2307/1419017, DOI 10.2307/1419017]
   Grabherr L, 2008, EXP BRAIN RES, V186, P677, DOI 10.1007/s00221-008-1350-8
   Han S, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P670, DOI 10.1109/VR50410.2021.00093
   Hillis JM, 2002, SCIENCE, V298, P1627, DOI 10.1126/science.1075396
   Hinde SJ, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0140-5
   Hou H., 2020, MULTISENS RES, DOI [10.1163/22134808-00002527, DOI 10.1163/22134808-00002527]
   Hutchings JB, 1998, AZIMUTH, V1, P221, DOI 10.1016/S1387-6783(98)80011-1
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M
   Lappe M, 1999, TRENDS COGN SCI, V3, P329, DOI 10.1016/S1364-6613(99)01364-9
   LAWTHER A, 1987, J ACOUST SOC AM, V82, P957, DOI 10.1121/1.395295
   Lee EC, 2010, IEEE T CONSUM ELECTR, V56, P1677, DOI 10.1109/TCE.2010.5606312
   Lee J, 2016, IEEE T VIS COMPUT GR, V22, P2300, DOI 10.1109/TVCG.2015.2507591
   Lee J, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489870
   Lee J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P219, DOI [10.1145/2872518.2890553, 10.1145/2993369.2993389]
   Lim B, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489854
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   Meijer D, 2020, MULTISENSORY PERCEPTION: FROM LABORATORY TO CLINIC, P113, DOI 10.1016/B978-0-12-812492-5.00005-X
   Oruç I, 2003, VISION RES, V43, P2451, DOI 10.1016/S0042-6989(03)00435-8
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Pridmore RW, 2021, COLOR RES APPL, V46, P482, DOI 10.1002/col.22576
   Prsa M, 2012, J NEUROPHYSIOL, V108, P2282, DOI 10.1152/jn.00439.2012
   Reason JT., 1975, INT J MAN MACH STUD
   Rohde M, 2016, MULTISENS RES, V29, P279, DOI 10.1163/22134808-00002510
   Sato Y, 2007, NEURAL COMPUT, V19, P3335, DOI 10.1162/neco.2007.19.12.3335
   Seber G. A. F., 2003, NONLINEAR REGRESSION
   Shin S, 2014, MULTIMEDIA SYST, V20, P327, DOI 10.1007/s00530-013-0322-4
   Solimini AG, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056160
   ter Horst AC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145015
   Triesch J, 2002, PERCEPTION, V31, P421, DOI 10.1068/p3314
   Watanabe K, 1998, PERCEPTION, V27, P1041, DOI 10.1068/p271041
   Welch R.B., 1978, PERCEPTUAL MODIFICAT
   Wilder JD, 2009, VISION RES, V49, P1017, DOI 10.1016/j.visres.2008.04.032
   Witten IB, 2005, NEURON, V48, P489, DOI 10.1016/j.neuron.2005.10.020
   Yakubovich S, 2020, BRAIN COMMUN, V2, DOI 10.1093/braincomms/fcaa035
   Yang SN, 2012, OPTOMETRY VISION SCI, V89, P1068, DOI 10.1097/OPX.0b013e31825da430
   Yuille A.L., 1996, Perception as Bayesian inference, P123
   Yun G, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445358
   Zhou YH, 2018, PROC CVPR IEEE, P7425, DOI 10.1109/CVPR.2018.00775
NR 52
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1671
EP 1683
DI 10.1007/s10055-023-00762-7
EA FEB 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000930670400001
DA 2024-07-18
ER

PT J
AU Bian, YL
   Zhou, C
   Gai, W
   Liu, J
   Yang, CL
AF Bian, Yulong
   Zhou, Chao
   Gai, Wei
   Liu, Juan
   Yang, Chenglei
TI The effect of embodied interaction designs on flow experience:
   examination in VR games
SO VIRTUAL REALITY
LA English
DT Article
DE Embodied interaction; Flow experience; Virtual reality; Avatar; Tangible
   interaction
ID TECHNOLOGY; METAPHORS; IMMERSION; RESPONSES; AROUSAL; STRESS
AB Embodied interaction (EI) is a body-based interactive paradigm that has the potential to enhance the flow experience in virtual reality (VR). To examine this hypothesis, this paper distinguishes three common types of EI in VR, namely body-based, tangible, and avatar-based EI. In empirical studies 1-3, three comparative experiments were carried out to examine the respective effects of these EI modes on flow experience. Subjective and physiological data (e.g., electrodermal activity, etc.) from studies 1-2 show that the use of body-based and tangible EI leads to the enhancement of physiological arousal (an important indicator of concentration) and flow experience. Study 3 reveals the effect of avatar-based EI on flow experience. Using a high-ownership avatar is found to enhance the sense of presence and involvement, which then improves flow. This effect is only for experienced users, showing a moderating effect. The mechanism of these positive effects requires further clarification.
C1 [Bian, Yulong; Gai, Wei; Liu, Juan; Yang, Chenglei] Shandong Univ, Shandong, Peoples R China.
   [Bian, Yulong; Gai, Wei; Liu, Juan; Yang, Chenglei] Key Lab Shandong Prov Software Engn, Shandong, Peoples R China.
   [Zhou, Chao] Tsinghua Univ, Beijing, Peoples R China.
C3 Shandong University; Tsinghua University
RP Bian, YL (corresponding author), Shandong Univ, Shandong, Peoples R China.; Bian, YL (corresponding author), Key Lab Shandong Prov Software Engn, Shandong, Peoples R China.; Zhou, C (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM bianyulong@sdu.edu.cn; zhouchao@tsinghua.edu.cn
FU NationalNatural Science Foundation of China [61972233, 62277035,
   62007021]; postdoctoral research foundation of china [2021TQ0178]; Young
   Scholars Program of Shandong University,Weihai [20820211005]; Special
   Project of Science and Technology Innovation Base of Key Laboratory of
   Shandong Province for Software Engineering [11480004042015]
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments on earlier drafts of thispaper. The authors
   thank Pu Qin for the help in preparing the experiment. This work is
   supported by the National Natural Science Foundation of China
   (61972233;62277035;62007021); the postdoctoral research foundation of
   china (2021TQ0178),Young Scholars Program of Shandong University,Weihai
   (20820211005) and Special Project of Science and TechnologyInnovation
   Base of Key Laboratory of Shandong Province for Software Engineering
   (11480004042015).
CR Antle AN, 2009, INT J ARTS TECHNOL, V2, P235, DOI 10.1504/IJART.2009.028927
   Aymerich-Franch L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00944
   Bakker S, 2012, PERS UBIQUIT COMPUT, V16, P433, DOI 10.1007/s00779-011-0410-4
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Berta R, 2013, IEEE T COMP INTEL AI, V5, P164, DOI 10.1109/TCIAIG.2013.2260340
   BIAN Y, 2018, IEEE POWER ENERGY SO, V2018, DOI DOI 10.1109/PESGM.2018.8585932
   Bian YL, 2022, VIRTUAL REAL-LONDON, V26, P1277, DOI 10.1007/s10055-021-00621-3
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Calvo-Porrarl C, 2017, COMPUT HUM BEHAV, V66, P400, DOI 10.1016/j.chb.2016.10.008
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   Cumming J, 2007, J SPORT EXERCISE PSY, V29, P629, DOI 10.1123/jsep.29.5.629
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Daiber F, 2009, LECT NOTES COMPUT SC, V5531, P81
   Davies AC, 2014, PHYSIOL BEHAV, V123, P93, DOI 10.1016/j.physbeh.2013.10.008
   Djajadiningrat T, 2004, PERS UBIQUIT COMPUT, V8, P294, DOI 10.1007/s00779-004-0293-8
   Dorner Ralf., 2016, Entertainment Computing and Serious Games: International GI-Dagstuhl Seminar 15283, Dagstuhl Castle, Germany, July 5-10, 2015, Revised Selected Papers
   Dourish P., 2004, ACTION IS FDN EMBODI
   Engeser S, 2012, ADVANCES IN FLOW RESEARCH, P1, DOI 10.1007/978-1-4614-2359-1
   Fu FL, 2009, COMPUT EDUC, V52, P101, DOI 10.1016/j.compedu.2008.07.004
   Gai W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5016, DOI 10.1145/3025453.3025494
   Goldin-Meadow S, 2001, PSYCHOL SCI, V12, P516, DOI 10.1111/1467-9280.00395
   Harmat L, 2015, INT J PSYCHOPHYSIOL, V97, P1, DOI 10.1016/j.ijpsycho.2015.05.001
   Hornecker Eva, 2011, Interactions, V18, P19, DOI 10.1145/1925820.1925826
   Hornecker E, 2006, P SIGCHI C HUM FACT, P437, DOI [10.1145/1124772.1124838, DOI 10.1145/1124772.1124838]
   Hurtienne Jorn, 2007, TEI'07. First International Conference on Tangible and Embedded Interaction, P127, DOI 10.1145/1226969.1226996
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jin SAA, 2011, J BROADCAST ELECTRON, V55, P114, DOI 10.1080/08838151.2011.546248
   Johnson Mark, 1987, The Body in the Mind: The Bodily Basis. Meaning, Imagination, and Reason
   Kahneman D, 2003, NOBEL PRIZE LECT MAP, P416
   Lackey SJ, 2016, ERGONOMICS, V59, P1060, DOI 10.1080/00140139.2015.1122234
   Marsh HW, 1999, STRUCT EQU MODELING, V6, P343, DOI 10.1080/10705519909540140
   Marshall P, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2442106.2442107
   Matulic Fabrice, 2016, P 2016 CHI C EXT ABS, P1713, DOI [10.1145/2851581-2892501, DOI 10.1145/2851581-2892501]
   Maurer B, 2016, LECT NOTES COMPUT SC, V9970, P378, DOI 10.1007/978-3-319-46152-6_15
   Michailidis L, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01682
   Nacke LE, 2009, J CAN GAME STUD ASS
   Nowak KL, 2005, J COMPUT-MEDIAT COMM, V11
   Ohyama S, 2007, AURIS NASUS LARYNX, V34, P303, DOI 10.1016/j.anl.2007.01.002
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Parmar D, 2016, VIRTUAL REAL-LONDON, V20, P141, DOI 10.1007/s10055-016-0287-7
   Peifer C, 2014, J EXP SOC PSYCHOL, V53, P62, DOI 10.1016/j.jesp.2014.01.009
   Pfeifer R., 2006, How the body shapes the way we think: a new view of intelligence, DOI [DOI 10.7551/MITPRESS/3585.001.0001, 10.7551/mitpress/3585.001.0001]
   Qin Pu, 2017, Journal of Computer Aided Design & Computer Graphics, V29, P2083
   Sharlin E, 2004, PERS UBIQUIT COMPUT, V8, P338, DOI 10.1007/s00779-004-0296-5
   Sjolie D., 2014, INTERACTING PRESENCE, P46
   Skulmowski A, 2016, COMPUT EDUC, V92-93, P64, DOI 10.1016/j.compedu.2015.10.011
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Su YS, 2016, COMPUT HUM BEHAV, V63, P240, DOI 10.1016/j.chb.2016.05.049
   Sun XW, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P473
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Terrenghi L, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1157
   Tozman T, 2015, COMPUT HUM BEHAV, V52, P408, DOI 10.1016/j.chb.2015.06.023
   Triberti S, 2015, STUD HEALTH TECHNOL, V219, P107, DOI 10.3233/978-1-61499-595-1-107
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   van Schaik P, 2012, J COMPUT ASSIST LEAR, V28, P350, DOI 10.1111/j.1365-2729.2011.00455.x
   Vecera SP, 2003, NEUROL CLIN, V21, P575, DOI 10.1016/S0733-8619(02)00103-2
   Wang CC, 2014, INFORM MANAGE-AMSTER, V51, P912, DOI 10.1016/j.im.2014.05.010
   Wang P, 2020, INT J HUM-COMPUT INT, V36, P1242, DOI 10.1080/10447318.2020.1732140
   Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345
   Won AS, 2015, PAIN MED, V16, P1644, DOI 10.1111/pme.12755
   Zhang T, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2953887
   Zhou C, 2020, IEEE ACCESS, V8, P73791, DOI 10.1109/ACCESS.2020.2988678
   Zuckerman O., 2005, P C HUMAN FACTORS CO, P859, DOI [10.1145/1054972.1055093, DOI 10.1145/1054972.1055093]
NR 67
TC 0
Z9 0
U1 10
U2 36
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1549
EP 1565
DI 10.1007/s10055-023-00758-3
EA JAN 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000921659500001
DA 2024-07-18
ER

PT J
AU Gao, MYZ
   Boehm-Davis, DA
AF Gao, Meiyuzi
   Boehm-Davis, Deborah A.
TI Development of a customizable interactions questionnaire (CIQ) for
   evaluating interactions with objects in augmented/virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Usability testing; Questionnaire; Metrics; User studies
AB As new methods for interacting with systems are being developed for use within augmented or virtual reality, their impact on the quality of the user's experience needs to be assessed. Although many instruments exist for evaluating the overall user experience or the computer interface used to complete tasks, few provide measures that can be used to evaluate the specific forms of interaction typically used in these environments. This paper describes the development of a customizable questionnaire for measuring the subjective user experience that focuses on the quality of the interactions with objects in augmented reality/virtual reality (AR/VR) worlds, which we are calling the Customizable Interactions Questionnaire, or (CIQ). The final questionnaire measures five factors that are related to user satisfaction while using the system: quality of interactions, assessment of task performance, comfort, quality of sensory enhancements, and consistency with expectations.
C1 [Gao, Meiyuzi; Boehm-Davis, Deborah A.] Meta, Redmond, WA 98052 USA.
RP Gao, MYZ (corresponding author), Meta, Redmond, WA 98052 USA.
EM Meiyuzi.gao@rice.edu; Boehmdavis@gmail.com
RI Boehm-Davis, Deborah A/C-5482-2009
OI Boehm-Davis, Deborah A/0000-0002-7731-9963; Gao,
   Meiyuzi/0000-0003-3857-8994
CR [Anonymous], 2012, ISO 9241-411:2012
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], 2008, 9241410 ISO
   Beat Games, 2018, BEAT SABER
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cai T, 2016, INSTINCTIVE COMPUTIN
   Dickie C., 2006, P AUSTRALASIAN COMPU, P119
   Fahmi F., 2020, IOP Conference Series: Materials Science and Engineering, V851, DOI 10.1088/1757-899X/851/1/012024
   Haptx, 2019, HAPTX
   HART S G, 1988, P139
   HORN JL, 1965, PSYCHOMETRIKA, V30, P179, DOI 10.1007/BF02289447
   IBM Support, 2020, TRANSF DIFF LIK SCAL
   Karev K, 2018, TECHNOLOGY PART 7 CO
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Lu FY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P930, DOI [10.1109/VR46266.2020.00118, 10.1109/VR46266.2020.1581100361198]
   MacKenzie I. S., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P161, DOI 10.1145/108844.108868
   MacKenzie IS, 2001, LECT NOTES COMPUT SC, V2254, P235
   Oculus, 2020, OCULUS RIFT
   Owlchemy Labs, 2016, JOB SIM
   Owlchemy Labs, JOB SIM SCREENSH OFF
   PAAS FGWC, 1994, PERCEPT MOTOR SKILL, V79, P419, DOI 10.2466/pms.1994.79.1.419
   PlayStation, 2018, EUROPE BEAT SABER 1
   Roth D., 2019, ARXIV
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Suchoski JM, 2016, IEEE INT CONF ROBOT, P4030, DOI 10.1109/ICRA.2016.7487593
   Tactical Haptics, 2019, ABOUTUS
   Vannette DL, 2019, QUALTRICS HDB QUESTI
   Wanderley MM, 2002, COMPUT MUSIC J, V26, P62, DOI 10.1162/014892602320582981
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Willis G.B., 1999, M AM STAT ASS
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 34
TC 0
Z9 0
U1 5
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 699
EP 716
DI 10.1007/s10055-022-00678-8
EA AUG 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000844459000001
PM 36042785
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Paulo, SF
   Medeiros, D
   Lopes, D
   Jorge, J
AF Paulo, Soraia F.
   Medeiros, Daniel
   Lopes, Daniel
   Jorge, Joaquim
TI Controlling camera movement in VR colonography
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Colonography; Navigation; Medical imagery;
   Human-centered computing
ID VIRTUAL ENDOSCOPY; CT COLONOGRAPHY; VISUALIZATION; NAVIGATION; MODEL;
   PATH
AB Immersive colonography allows medical professionals to navigate inside the intricate tubular geometries of subject-specific 3D colon images using Virtual Reality displays. Typically, camera travel is performed via Fly-Through or Fly-Over techniques that enable semi-automatic traveling through a constrained, well-defined path at user-controlled speeds. However, Fly-Through is known to limit the visibility of lesions located behind or inside haustral folds. At the same time, Fly-Over requires splitting the entire colon visualization into two specific halves. In this paper, we study the effect of immersive Fly-Through and Fly-Over techniques on lesion detection and introduce a camera travel technique that maintains a fixed camera orientation throughout the entire medial axis path. While these techniques have been studied in non-VR desktop environments, their performance is not well understood in VR setups. We performed a comparative study to ascertain which camera travel technique is more appropriate for constrained path navigation in immersive colonography and validated our conclusions with two radiologists. To this end, we asked 18 participants to navigate inside a 3D colon to find specific marks. Our results suggest that the Fly-Over technique may lead to enhanced lesion detection at the cost of higher task completion times. Nevertheless, the Fly-Through method may offer a more balanced trade-off between speed and effectiveness, whereas the fixed camera orientation technique provided seemingly inferior performance results. Our study further provides design guidelines and informs future work.
C1 [Paulo, Soraia F.; Lopes, Daniel; Jorge, Joaquim] Univ Lisbon, Inst Super Tecn, INESC ID Lisboa, Av Prof Dr Cavaco Silva, P-2744016 Porto Salvo, Portugal.
   [Medeiros, Daniel] Univ Glasgow, Glasgow, Lanark, Scotland.
C3 INESC-ID; Universidade de Lisboa; University of Glasgow
RP Jorge, J (corresponding author), Univ Lisbon, Inst Super Tecn, INESC ID Lisboa, Av Prof Dr Cavaco Silva, P-2744016 Porto Salvo, Portugal.
EM jaj@inesc-id.pt
RI Simoes Lopes, Daniel/M-2930-2015; Jorge, Joaquim/C-5596-2008
OI Simoes Lopes, Daniel/0000-0003-0917-9396; F Paulo,
   Soraia/0000-0002-0812-1072; Jorge, Joaquim/0000-0001-5441-4637
FU Fundacao para a Ciencia e a Tecnologia, Portugal [UIDB/50021/2020,
   SFRH/BD/136212/2018]; MBIE Grant, New Zealand [ILF-VUW1901]; Fundação
   para a Ciência e a Tecnologia [SFRH/BD/136212/2018] Funding Source: FCT
FX This work was supported by FundacAo para a Ciencia e a Tecnologia,
   Portugal, through Grant Numbers UIDB/50021/2020 and SFRH/BD/136212/2018,
   and by MBIE Grant ILF-VUW1901, New Zealand. We are grateful to Dr.
   Isabel Nobre and Dr. Sandra Sousa from the Imagiology Service of
   Hospital Lusiadas Lisboa for their professional assessment and comments.
   The authors would also like to thank Pedro Borges for his contributions
   during his MSc thesis work.
CR Aguilar WG, 2017, LECT NOTES COMPUT SC, V10325, P155, DOI 10.1007/978-3-319-60928-7_13
   Bartz D, 2005, COMPUT GRAPH FORUM, V24, P111, DOI 10.1111/j.1467-8659.2005.00831.x
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Chaudhuri P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P188, DOI 10.1109/CGI.2004.1309210
   Cheng I, 2014, IEEE ENG MED BIO, P5647, DOI 10.1109/EMBC.2014.6944908
   Codd AM, 2011, ANAT SCI EDUC, V4, P119, DOI 10.1002/ase.214
   de Visser H, 2011, MED J AUSTRALIA, V194, pS38
   Elmqvist N., 2006, NAVIGATION GUIDANCE
   Elmqvist N, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P207
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Haigron P, 2004, IEEE T MED IMAGING, V23, P1380, DOI 10.1109/TMI.2004.836869
   Haker S, 2000, IEEE T MED IMAGING, V19, P665, DOI 10.1109/42.875181
   Hassouna MS, 2006, LECT NOTES COMPUT SC, V4190, P381
   He TS, 2001, IEEE T VIS COMPUT GR, V7, P333, DOI 10.1109/2945.965347
   Huang A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P279
   Huang A, 2006, PROC SPIE, V6143, DOI 10.1117/12.653934
   King F., 2016, J. Med. Robot. Res, V1, P1640003, DOI DOI 10.1142/S2424905X16400031
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lichan Hong, 1995, Proceedings. 1995 Biomedical Visualization (Cat. No.95TB100001), P26, DOI 10.1109/BIOVIS.1995.528702
   Lopes DS, 2018, LECT NOTES COMPUT SC, V11071, P629, DOI 10.1007/978-3-030-00934-2_70
   Medeiros D, 2020, IEEE T VIS COMPUT GR, V26, P2793, DOI 10.1109/TVCG.2019.2905200
   Mirhosseini K, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P75, DOI 10.1109/3DVis.2014.7160105
   Mirhosseini S, 2019, IEEE T VIS COMPUT GR, V25, P2011, DOI 10.1109/TVCG.2019.2898763
   Noser H, 2003, INT CONGR SER, V1256, P29, DOI 10.1016/S0531-5131(03)00347-9
   Pareek T.G., 2018, BIOMED PHARMACOL J, V11, P2091, DOI [DOI 10.13005/bpj/1588, 10.13005/bpj/1588]
   Randall D., 2015, J BIOMED GRAPH COMPU, V6, P34, DOI DOI 10.5430/JBGC.V6N1P34
   Ribeiro N., 2009, 3 D SOLID FINITE ELE
   Robinett R., 1992, P 1992 S INT 3D GRAP, P189, DOI 10.1145/147156.1472012
   Schuchardt P, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P121, DOI 10.1115/IMECE2007-43781
   Shanmugan S, 2014, DIS COLON RECTUM, V57, P210, DOI 10.1097/DCR.0000000000000031
   Sousa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4057, DOI 10.1145/3025453.3025566
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   Venson JE, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P349, DOI 10.1145/2993369.2996333
   Vos FM, 2003, RADIOLOGY, V228, P878, DOI 10.1148/radiol.2283020846
   Vosburgh Kirby G, 2013, Stud Health Technol Inform, V184, pvii
   Wang HF, 2015, COMP M BIO BIO E-IV, V3, P213, DOI 10.1080/21681163.2014.917335
   Wirth M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P867, DOI 10.1145/3242587.3242636
   Yao JH, 2010, IEEE T BIO-MED ENG, V57, P2861, DOI 10.1109/TBME.2010.2052255
NR 38
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1079
EP 1088
DI 10.1007/s10055-021-00620-4
EA JAN 2022
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000740136600001
DA 2024-07-18
ER

PT J
AU Morotti, E
   Stacchio, L
   Donatiello, L
   Roccetti, M
   Tarabelli, J
   Marfia, G
AF Morotti, Elena
   Stacchio, Lorenzo
   Donatiello, Lorenzo
   Roccetti, Marco
   Tarabelli, Jari
   Marfia, Gustavo
TI Exploiting fashion x-commerce through the empowerment of voice in the
   fashion virtual reality arena Integrating voice assistant and virtual
   reality technologies for fashion communication
SO VIRTUAL REALITY
LA English
DT Article
DE X-commerce; Voice assistant; Fashion retail; Mixed reality
ID AUGMENTED REALITY; USABILITY; EXPERIENCE; INTERFACES
AB The ongoing development of eXtended Reality (XR) technologies is supporting a rapid increase of their performances along with a progressive decrease of their costs, making them more and more attractive for a large class of consumers. As a result, their widespread use is expected within the next few years. This may foster new opportunities for e-commerce strategies, giving birth to an XR-based commerce (x-commerce) ecosystem. With respect to web and mobile-based shopping experiences, x-commerce could more easily support brick-and-mortar store-like experiences. One interesting and consolidated one amounts to the interactions among customers and shop assistants inside fashion stores. In this work, we concentrate on such aspects with the design and implementation of an XR-based shopping experience, where vocal dialogues with an Amazon Alexa virtual assistant are supported, to experiment with a more natural and familiar contact with the store environment. To verify the validity of such an approach, we asked a group of fashion experts to try two different XR store experiences: with and without the voice assistant integration. The users are then asked to answer a questionnaire to rate their experiences. The results support the hypothesis that vocal interactions may contribute to increasing the acceptance and comfortable perception of XR-based fashion shopping.
C1 [Morotti, Elena] Univ Bologna, Dept Polit & Social Sci, Bologna, Italy.
   [Stacchio, Lorenzo] Univ Bologna, Dept Life Qual Studies, Rimini, Italy.
   [Donatiello, Lorenzo; Roccetti, Marco; Tarabelli, Jari] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
   [Marfia, Gustavo] Univ Bologna, Dept Arts, Bologna, Italy.
C3 University of Bologna; University of Bologna; University of Bologna;
   University of Bologna
RP Marfia, G (corresponding author), Univ Bologna, Dept Arts, Bologna, Italy.
EM gustavo.marfia@unibo.it
RI Stacchio, Lorenzo/JEO-9407-2023; Morotti, Elena/AAU-1716-2021; Marfia,
   Gustavo/D-1347-2010
OI Stacchio, Lorenzo/0000-0002-9341-7651; Morotti,
   Elena/0000-0002-4283-2994; MARFIA, GUSTAVO/0000-0003-3058-8004
FU University of Bologna -Alma Attrezzature 2017 grant
FX This work was supported in part by the University of Bologna -Alma
   Attrezzature 2017 grant. We also express our gratitude to all the
   fashion experts whose feedback provided us with the material for this
   contribution and to Alessia Angeli and Shirin Hajahmadi, who helped us
   carry out the experiments.
CR [Anonymous], 2012, Wkly Epidemiol Rec, V87, P1
   [Anonymous], 2019, COVERGIRL OFFERS AUG
   [Anonymous], 2020, US VIRTUAL AUGMENTED
   [Anonymous], 2019, DIGITAL MARKET OUTLO
   [Anonymous], 2021, DELL ALIENWARE DESKT
   [Anonymous], 2019, XR TECHNOLOGY SURVEY
   [Anonymous], 2019, EXTENDED REALITY CON
   [Anonymous], 2021, VOICE ASSISTANT USE
   [Anonymous], 2018, INCREASE YOUR SALES
   [Anonymous], 2021, INTRO VARJO XR 3 ONL
   [Anonymous], 2019, MICROSOFT APP STORE
   [Anonymous], 2020, YOU CURRENTLY EVER U
   [Anonymous], 2019, WAKING NEW REALITY
   [Anonymous], 2018, DOUBLE FUN WORLDS 1
   [Anonymous], 2019, DIOR EYES VIRTUAL RE
   [Anonymous], 2019, TOPSHOP VIRTUAL REAL
   Araujo Tiago, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P199, DOI 10.1007/978-3-319-39907-2_19
   Bevan N, 2001, INT J HUM-COMPUT ST, V55, P533, DOI 10.1006/ijhc.2001.0483
   Bigné E, 2016, J BUS RES, V69, P1423, DOI 10.1016/j.jbusres.2015.10.119
   Brengman Malaika, 2019, Virtual Reality, V23, P269, DOI 10.1007/s10055-018-0335-6
   Callaghan MJ, 2019, LECT NOTE NETW SYST, V47, P570, DOI 10.1007/978-3-319-95678-7_63
   Croasmun J.T., 2011, J ADULT ED, V40, P19, DOI DOI 10.1007/S10640-011-9463-0
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Cardoso LFD, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106159
   Donatiello L, 2018, 2018 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P17, DOI 10.1109/PIMRC.2018.8581036
   Dzardanova E, 2017, IEEE SYMP COMP COMMU, P6, DOI 10.1109/ISCC.2017.8024496
   Farinazzo Martins Valeria, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P222, DOI 10.1007/978-3-319-39907-2_21
   Faulkner L, 2003, BEHAV RES METH INS C, V35, P379, DOI 10.3758/BF03195514
   Goff BG, 1997, J RETAILING, V73, P171, DOI 10.1016/S0022-4359(97)90002-6
   Herz M, 2019, TECHNOL FORECAST SOC, V138, P228, DOI 10.1016/j.techfore.2018.09.008
   Hu HZ, 2019, CURR MED SCI, V39, P1, DOI 10.1007/s11596-019-1992-8
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   Jang JY, 2019, FASH TEXT, V6, DOI 10.1186/s40691-018-0166-9
   Kapusy K, 2017, INT CONF COGN INFO, P237, DOI 10.1109/CogInfoCom.2017.8268249
   Ketelaar PE, 2018, J BUS RES, V91, P277, DOI 10.1016/j.jbusres.2018.06.018
   Kim JH, 2007, J RETAIL CONSUM SERV, V14, P95, DOI 10.1016/j.jretconser.2006.05.001
   Kim YK, 2005, PSYCHOL MARKET, V22, P995, DOI 10.1002/mar.20095
   Lau HF, 2014, SHOPPING EXPERIENCE
   Lau KW, 2019, VIRTUAL REAL-LONDON, V23, P255, DOI 10.1007/s10055-018-0362-3
   Lewis C., 1982, USING THINKING ALOUD
   Likert R., 1932, ARCH PSYCHOL, V22, P55
   Martínez-Navarro J, 2019, J BUS RES, V100, P475, DOI 10.1016/j.jbusres.2018.10.054
   Marzo-Navarro M., 2004, J FASH MARK MANAG, V8, P425
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mirri S, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0129-6
   Moes A, 2017, HELIYON, V3, DOI 10.1016/j.heliyon.2017.e00336
   MOROTTI E, 2020, IEEE 6 WORKSH EV VIR
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Muñoz-Saavedra L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010322
   Papagiannidis S, 2017, INFORM TECHNOL PEOPL, V30, P163, DOI 10.1108/ITP-03-2015-0069
   Park M, 2018, FASH TEXT, V5, DOI 10.1186/s40691-018-0149-x
   Polap D, 2018, FED CONF COMPUT SCI, P497, DOI 10.15439/2018F13
   Rauschnabel Philipp A., 2016, i-com: A Journal of Interactive and Cooperative Media, V15, P179, DOI 10.1515/icom-2016-0021
   Rauschnabel PA, 2019, J RETAIL CONSUM SERV, V49, P43, DOI 10.1016/j.jretconser.2019.03.004
   Rese A, 2017, TECHNOL FORECAST SOC, V124, P306, DOI 10.1016/j.techfore.2016.10.010
   Salomoni P, 2017, J MULTIMODAL USER IN, V11, P173, DOI 10.1007/s12193-016-0236-5
   Singh H, 2019, ADV INTELL SYST, V841, P445, DOI 10.1007/978-981-13-2285-3_52
   Speicher M., 2017, J P ACM INTERACT MOB, V1, P1, DOI [10.1145/3130967, DOI 10.1145/3130967]
   Speicher M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P816, DOI 10.1109/VR.2018.8446187
   Suznjevic M, 2017, INT WORK QUAL MULTIM
   Taber KS, 2018, RES SCI EDUC, V48, P1273, DOI 10.1007/s11165-016-9602-2
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Venkatesh V, 2003, COMMUN ACM, V46, P53, DOI 10.1145/953460.953488
   Wang R, 2018, IND MAINTENANCE RELI, P160
   Weiss Y, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P50, DOI 10.1109/CW.2018.00021
   Wolfensberger M, 2019, CAMB BIOETH LAW, P119
   Wrzesien M, 2015, THEOR ISS ERGON SCI, V16, P124, DOI 10.1080/1463922X.2014.903307
   Wu HY, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0204-7
   Xi NN, 2021, J BUS RES, V134, P37, DOI 10.1016/j.jbusres.2021.04.075
   Yim MYC, 2019, J BUS RES, V100, P581, DOI 10.1016/j.jbusres.2018.10.041
   Zhang Lingling, 2014, Advanced Materials Research, V962-965, P2944, DOI 10.4028/www.scientific.net/AMR.962-965.2944
   Zhao Y., 2017, INT WORKSH SYMB INT, P98
NR 73
TC 10
Z9 10
U1 1
U2 43
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 871
EP 884
DI 10.1007/s10055-021-00602-6
EA NOV 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000716292800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Gao, Y
   Chang, C
   Yu, XX
   Pang, PJ
   Xiong, NA
   Huang, CA
AF Gao, Yi
   Chang, Cheng
   Yu, Xiaxia
   Pang, Pengjin
   Xiong, Nian
   Huang, Chuan
TI A VR-based volumetric medical image segmentation and visualization
   system with natural human interaction
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Natural user interaction; Medical image segmentation;
   Volume rendering; Transfer function
ID VIRTUAL-REALITY SIMULATION; LOCAL ROBUST STATISTICS
AB Volume rendering produces informative two-dimensional (2D) images from a 3-dimensional (3D) volume. It highlights the region of interest and facilitates a good comprehension of the entire data set. However, volume rendering faces a few challenges. First, a high-dimensional transfer function is usually required to differentiate the target from its neighboring objects with subtle variance. Unfortunately, designing such a transfer function is a strenuously trial-and-error process. Second, manipulating/visualizing a 3D volume with a traditional 2D input/output device suffers dimensional limitations. To address all the challenges, we design NUI-VR2, a natural user interface-enabled volume rendering system in the virtual reality space. NUI-VR2 marries volume rendering and interactive image segmentation. It transforms the original volume into a probability map with image segmentation. A simple linear transfer function will highlight the target well in the probability map. More importantly, we set the entire image segmentation and volume rendering pipeline in an immersive virtual reality environment with a natural user interface. NUI-VR2 eliminates the dimensional limitations in manipulating and perceiving 3D volumes and dramatically improves the user experience.
C1 [Gao, Yi; Yu, Xiaxia; Pang, Pengjin] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518060, Peoples R China.
   [Gao, Yi] Shenzhen Key Lab Precis Med Hematol Malignancies, Shenzhen 518060, Peoples R China.
   [Gao, Yi] Marshall Lab Biomed Engn, Shenzhen 518060, Peoples R China.
   [Gao, Yi] Pengcheng Lab, Shenzhen 518060, Peoples R China.
   [Chang, Cheng] SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Xiong, Nian] Huazhong Univ Sci & Technol, Union Hosp, Tongji Med Coll, Dept Neurol, Wuhan 430074, Hubei, Peoples R China.
   [Xiong, Nian] Wuhan Red Cross Hosp, Dept Neurol, Wuhan 430015, Hubei, Peoples R China.
   [Huang, Chuan] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
C3 Shenzhen University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; Huazhong University of
   Science & Technology; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Chang, C (corresponding author), SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
EM gaoyi@szu.edu.cn; cheng.chang@alumni.stonybrook.edu;
   xiaxiayu@szu.edu.cn; 2016222064@email.szu.edu.cn; nianxiong@hust.edu.cn;
   chuan.huang@stonybrookmedicine.edu
RI gao, yi/HCI-8298-2022
OI Huang, Chuan/0000-0001-6052-0663
FU Department of Education of Guangdong Province [2017KZDXM072]; National
   Natural Science Foundation of China [61601302]; Shenzhen Key Laboratory
   Foundation [ZDSYS20200811143757022]; Shenzhen Peacock Plan
   [KQTD2016053112051497]; Faculty Development Grant of Shenzhen University
   [2018009]; National Key R&D Program of China [2016YFC1306600,
   2018YFC1314700]; Natural Science Foundation of Hubei Province
   [2016CFB624]; The Youth Science and technology morning light program of
   Wuhan City [2017050304010278]; Hubei medical research project
   [WJ2019F030]; Wuhan medical research project [WX18A10]; Wuhan Young and
   Middle-aged medical Talents Program; Hubei provincial Party Committee
   Organization Department the second batch of Hubei youth elite
   development plan; Youth Faculty of Shenzhen University [2018009];
   National Institute of General Medical Sciences of the National
   Institutes of Health [P41 GM103545-18]; DOE SciDAC Visualization and
   Analytics Center for Enabling Technologies [DEFC0206ER25781]
FX This work was supported in part by the Department of Education of
   Guangdong Province under Grant 2017KZDXM072, in part by the National
   Natural Science Foundation of China under Grant 61601302, in party by
   the Shenzhen Key Laboratory Foundation ZDSYS20200811143757022, in part
   by the Shenzhen Peacock Plan under Grant KQTD2016053112051497, and in
   part by the Faculty Development Grant of Shenzhen University under Grant
   2018009. N. Xiong would like to thank the support from the National Key
   R&D Program of China 2016YFC1306600 and 2018YFC1314700, grant 2016CFB624
   from Natural Science Foundation of Hubei Province, Grant
   2017050304010278 from The Youth Science and technology morning light
   program of Wuhan City, 2018 Hubei medical research project WJ2019F030,
   2018 Wuhan medical research project WX18A10, 2018 Wuhan Young and
   Middle-aged medical Talents Program and 2017 Hubei provincial Party
   Committee Organization Department the second batch of Hubei youth elite
   development plan. X. Yu would like to thank the support from the Startup
   funding for Youth Faculty of Shenzhen University Grant 2018009. We thank
   the authors of ImageVis3D, supported by the National Institute of
   General Medical Sciences of the National Institutes of Health under
   grant number P41 GM103545-18, and the DOE SciDAC Visualization and
   Analytics Center for Enabling Technologies, DEFC0206ER25781.
CR [Anonymous], 2004, VISUALIZATION TOOLKI
   Arens S., 2010, Proceedings of the 8th IEEE/EG International Conference on Volume Graphics, VG'10, P77
   Bajaj CL, 1997, VISUALIZATION '97 - PROCEEDINGS, P167, DOI 10.1109/VISUAL.1997.663875
   Bali A, 2015, INT C ADV COMPUT COM, P113, DOI 10.1109/ACCT.2015.63
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Caban JJ, 2008, IEEE T VIS COMPUT GR, V14, P1364, DOI 10.1109/TVCG.2008.169
   Chan S, 2013, NEUROSURGERY, V72, pA154, DOI 10.1227/NEU.0b013e3182750d26
   Chang C, 2018, HUM BRAIN MAPP, V39, P472, DOI 10.1002/hbm.23856
   Cohen AR, 2013, CHILD NERV SYST, V29, P1235, DOI 10.1007/s00381-013-2139-z
   El Beheiry M, 2019, J MOL BIOL, V431, P1315, DOI 10.1016/j.jmb.2019.01.033
   Faludi B, 2019, LECT NOTES COMPUT SC, V11768, P29, DOI 10.1007/978-3-030-32254-0_4
   Fogal T., 2010, P C HIGH PERF GRAPH, P57, DOI DOI 10.2312/EGGH/HPG10/057-066
   Gao Y., 2010, SEGMENTATION ENDOCAR
   Gao Y, 2012, MED IMAGE ANAL, V16, P1216, DOI 10.1016/j.media.2012.06.002
   Gao Y, 2011, LECT NOTES COMPUT SC, V6533, P195, DOI 10.1007/978-3-642-18421-5_19
   Hänel C, 2016, IEEE T VIS COMPUT GR, V22, P1472, DOI 10.1109/TVCG.2016.2518338
   He TS, 1996, IEEE VISUAL, P227, DOI 10.1109/VISUAL.1996.568113
   Ju M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061746
   Karasev P, 2013, IEEE T MED IMAGING, V32, P2127, DOI 10.1109/TMI.2013.2274734
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kuruvilla J, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P198, DOI 10.1109/SAPIENCE.2016.7684170
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Mady AS, 2020, INT J ONLINE BIOMED, V16, P95, DOI 10.3991/ijoe.v16i06.13627
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Paniagua B, 2017, INSIGHT J, P80014
   Pfister H, 2001, IEEE COMPUT GRAPH, V21, P16, DOI 10.1109/38.920623
   Sabella P., 1988, Computer Graphics, V22, P51, DOI 10.1145/378456.378476
   Takeshima Y, 2005, VOLUME GRAPHICS 2005, P137
   Tappenbeck Andreas., 2006, SimVis, P259
   TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768
   Tiede U, 1998, VISUALIZATION '98, PROCEEDINGS, P255, DOI 10.1109/VISUAL.1998.745311
   Tzeng FY, 2005, IEEE T VIS COMPUT GR, V11, P273, DOI 10.1109/TVCG.2005.38
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Vilanova A, 2001, SPRING CONFERENCE ON COMPUTER GRAPHICS, PROCEEDINGS, P241, DOI 10.1109/SCCG.2001.945360
   Wang YW, 2017, IEEE IMAGE PROC, P4593, DOI 10.1109/ICIP.2017.8297156
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P330, DOI 10.1109/TVCG.2007.47
   Zhu J, 2004, ADV NEUR IN, V16, P49
   Zhu L., 2014, MICCAI WORKSH INT ME
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 40
TC 5
Z9 5
U1 6
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 415
EP 424
DI 10.1007/s10055-021-00577-4
EA SEP 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000695769600001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Pan, ZG
   Luo, TR
   Zhang, MM
   Cai, N
   Li, YH
   Miao, JD
   Li, Z
   Pan, ZP
   Shen, YZ
   Lu, JJ
AF Pan, Zhigeng
   Luo, Tianren
   Zhang, Mingmin
   Cai, Ning
   Li, Yongheng
   Miao, Jinda
   Li, Zheng
   Pan, Zhipeng
   Shen, Yuze
   Lu, Jijian
TI MagicChem: a MR system based on needs theory for chemical experiments
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Virtual-real occlusion; Multi-camera collaboration;
   Virtual-real interaction; Chemical education
ID SYNTHETIC VOICE; EDUCATION; PERCEPTION; INTERFACE
AB Real chemical experiments may be dangerous or pollute the environment; meanwhile, the preparation of drugs and reagents is time-consuming. Due to the above-mentioned reasons, few experiments can be actually operated by students, which is not conducive to the chemistry learning and the phenomena principle understanding. Recently, due to the impact of Covid-19, many schools adopt online teaching, which is even more detrimental to students' learning of chemistry. Fortunately, MR(mixed reality) technology provides us with the possibility of solving the safety issues and breaking the space-time constraints, while the theory of human needs (Maslow's hierarchical needs) provides us with a way to design a comfortable and stimulant MR system with realistic visual presentation and interaction. The paper combines with the theory of human needs to propose a new needs model for virtual experiment. Based on this needs model, we design and develop a comprehensive MR system called MagicChem, which offers a robust 6-DoF interactive and illumination consistent experimental space with virtual-real occlusion, supporting realistic visual interaction, tangible interaction, gesture interaction with touching, voice interaction, temperature interaction, olfactory interaction and virtual human interaction. User study shows that MagicChem satisfies the needs model better than other MR experimental environments that partially meet the needs model. In addition, we explore the application of the needs model in VR environment.
C1 [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Coll Artificial Intelligence, Nanjing, Peoples R China.
   [Luo, Tianren] Inst Software, Chinese Acad Sci, State Key Lab Comp Sci, Beijing Key Lab Human Comp Interact, Beijing, Peoples R China.
   [Luo, Tianren] Univ Chinese Acad Sci, Coll Comp Sci & Technol, Beijing, Peoples R China.
   [Zhang, Mingmin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Cai, Ning; Li, Zheng; Pan, Zhipeng; Shen, Yuze] Hangzhou Normal Univ, Res Inst Virtual Real & Intelligent Syst, Hangzhou, Peoples R China.
   [Li, Yongheng] Foshan Univ, Automat Coll, Foshan, Peoples R China.
   [Miao, Jinda] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Lu, Jijian] Hangzhou Normal Univ, Jing Hengyi Educ Coll, Hangzhou, Peoples R China.
C3 Nanjing University of Information Science & Technology; Chinese Academy
   of Sciences; Institute of Software, CAS; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; Zhejiang University;
   Hangzhou Normal University; Foshan University; Zhejiang University;
   Hangzhou Normal University
RP Luo, TR (corresponding author), Inst Software, Chinese Acad Sci, State Key Lab Comp Sci, Beijing Key Lab Human Comp Interact, Beijing, Peoples R China.; Luo, TR (corresponding author), Univ Chinese Acad Sci, Coll Comp Sci & Technol, Beijing, Peoples R China.; Zhang, MM (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
EM luo_tianren@qq.com; zhangmm95@zju.edu.cn
RI zhang, mm/IWV-4201-2023; Zhang, Miao/JXY-8985-2024; Luo,
   Tianren/CAI-9775-2022; Lu, Jijian/HMD-2487-2023; Lu,
   Jijian/GYV-0784-2022
OI Luo, Tianren/0000-0002-6752-9182; 
FU National Key R&D project of China [2018YFB1004902]; NSFC project
   [62077041]; University Student Science and Technology Innovation
   Activity Plan in Zhejiang Province (Xinmiao Talent Plan) [2020R427068]
FX This paper is supported by National Key R&D project of China (Grant No.
   2018YFB1004902), NSFC project (Grant No. 62077041) and University
   Student Science and Technology Innovation Activity Plan in Zhejiang
   Province(Xinmiao Talent Plan, Grant No. 2020R427068).
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Angel SA, 2015, EDUC CHEM ENG, V13, P1, DOI 10.1016/j.ece.2015.06.004
   Arici F, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103647
   Bai H, 2013, 2013 IEEE INT S MIX, P1
   Balakrishnan B, 2011, HUM-COMPUT INTERACT, V26, P161, DOI 10.1080/07370024.2011.601689
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Benson Suzanne G, 2003, J Nurs Manag, V11, P315, DOI 10.1046/j.1365-2834.2003.00409.x
   BENWARE CA, 1984, AM EDUC RES J, V21, P755, DOI 10.3102/00028312021004755
   Bernath PF, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2005GL022386
   Boletsis Costas, 2013, Serious Games Development and Applications. 4th International Conference, SGDA 2013. Proceedings: LNCS 8101, P86, DOI 10.1007/978-3-642-40790-1_9
   Bozzelli G., 2019, DIGITAL APPL ARCHAEO, V15, P113
   Brooke J, 1996, USABILITY EVALUATION, V11, P188
   Cabral JP, 2017, INTERSPEECH, P229, DOI 10.21437/Interspeech.2017-325
   Chamilothori K, 2019, LEUKOS, V15, P203, DOI 10.1080/15502724.2017.1404918
   Chang SC, 2018, COMPUT EDUC, V125, P226, DOI 10.1016/j.compedu.2018.06.007
   Chihara T, 2018, APPL ERGON, V68, P204, DOI 10.1016/j.apergo.2017.11.016
   Duan X., 2020, KSII T INT INF SYST, V14, P69
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Ellis SR, 1998, HUM FACTORS, V40, P415, DOI 10.1518/001872098779591278
   Gan HS, 2018, BIOCHEM MOL BIOL EDU, V46, P245, DOI 10.1002/bmb.21117
   Gao L, 2013, THESIS U CANTERBURY
   Goel S, 2018, BMC MED EDUC, V18, DOI 10.1186/s12909-018-1123-4
   Gratch J, 2016, LECT NOTES ARTIF INT, V10011, P283, DOI 10.1007/978-3-319-47665-0_25
   Guex LG, 2017, NANOSCALE, V9, P9562, DOI 10.1039/c7nr02943h
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   Hacker BA, 2009, CONTEL 2009: PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS, P163
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Healy Kevin, 2016, Br J Psychiatry, V208, P313, DOI 10.1192/bjp.bp.115.179622
   Hodges GW, 2018, COMPUT EDUC, V122, P179, DOI 10.1016/j.compedu.2018.03.003
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Jacobs K, 2006, COMPUT GRAPH FORUM, V25, P29, DOI 10.1111/j.1467-8659.2006.00816.x
   Kalkofen D., 2007, P INT S MIXED AUGMEN, P191, DOI [10.1109/ISMAR.2007.4538846, DOI 10.1109/ISMAR.2007.4538846]
   Kiel J., 1999, J INSTR PSYCHOL, V26, P167
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   LESTER D, 1983, J GEN PSYCHOL, V109, P83, DOI 10.1080/00221309.1983.9711513
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo TR, 2020, IEEE T VIS COMPUT GR, V26, P3524, DOI 10.1109/TVCG.2020.3023602
   Luo TR, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1068, DOI [10.1109/VR.2019.8797811, 10.1109/vr.2019.8797811]
   Luo TR, 2018, I C VIRTUAL REALITY, P116, DOI 10.1109/ICVRV.2018.00033
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Maier P, 2013, 2013 2ND EXPERIMENT@ INTERNATIONAL CONFERENCE (EXP.AT'13), P164, DOI 10.1109/ExpAt.2013.6703055
   MAPES DP, 1995, PRESENCE-TELEOP VIRT, V4, P403, DOI 10.1162/pres.1995.4.4.403
   Martin-Villalba C, 2012, COMPUT CHEM ENG, V39, P170, DOI 10.1016/j.compchemeng.2011.10.010
   Matsutomo S, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2665563
   McLeod S. A., 2007, SIMPLY PSYCHOL
   Muller C., 2018, J INTEGRATIVE BIOINF, V15, P31
   Nachairit A, 2015, P 23 INT C COMPUTERS, P519
   Oswald P., 2014, Proceedings of the 11th Conference on Advances in Computer Entertainment Technology, V11, P1, DOI [10.1145/2663806.2663853, DOI 10.1145/2663806.2663853]
   Pollock B, 2012, IEEE T VIS COMPUT GR, V18, P581, DOI 10.1109/TVCG.2012.58
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Sapargaliyev D, 2015, COMM COM INF SC, V560, P343, DOI 10.1007/978-3-319-25684-9_25
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shoura MM, 1999, J MANAGE ENG, V15, P44, DOI 10.1061/(ASCE)0742-597X(1999)15:5(44)
   Silva T, 2017, SYMP VIRTUAL AUGMENT, P155, DOI 10.1109/SVR.2017.28
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Stern SE, 2006, INT J HUM-COMPUT ST, V64, P43, DOI 10.1016/j.ijhcs.2005.07.002
   Strzys MP, 2017, PHYS TEACH, V55, P376, DOI 10.1119/1.4999739
   Tuli N, 2015, J ENG ED TRANSFORMAT, P188
   Ullah S, 2016, J CHEM EDUC, V93, P2018, DOI 10.1021/acs.jchemed.5b00969
   Verkuyl M, 2017, CLIN SIMUL NURS, V13, P238, DOI 10.1016/j.ecns.2017.02.004
   Wang FX, 2018, INT J EMERG TECHNOL, V13, P83, DOI 10.3991/ijet.v13i04.8472
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang CK, 2020, VIRTUAL REAL-LONDON, V24, P527, DOI 10.1007/s10055-019-00415-8
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou W, 2008, IMAGE VISION COMPUT, V26, P415, DOI 10.1016/j.imavis.2006.12.003
   Zhu BL, 2018, J CHEM EDUC, V95, P1747, DOI 10.1021/acs.jchemed.8b00116
NR 68
TC 14
Z9 14
U1 8
U2 36
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 279
EP 294
DI 10.1007/s10055-021-00560-z
EA JUL 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000675773900001
PM 34312581
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hong, MS
   Rozenblit, JW
   Hamilton, AJ
AF Hong, Minsik
   Rozenblit, Jerzy W.
   Hamilton, Allan J.
TI Simulation-based surgical training systems in laparoscopic surgery: a
   current review
SO VIRTUAL REALITY
LA English
DT Review
DE Surgical training; Laparoscopy; Virtual reality; Augmented reality;
   Haptic guidance; Objective assessment
ID MINIMALLY INVASIVE SURGERY; VIRTUAL-REALITY SIMULATOR; AUGMENTED
   REALITY; LOW-COST; CONSTRUCT-VALIDITY; HAPTIC FEEDBACK; OBJECTIVE
   ASSESSMENT; COLLISION DETECTION; PSYCHOMOTOR-SKILLS; FORCE FEEDBACK
AB Simulation-based training has been widely used in medical education. More specifically, various systems for minimally invasive surgery training have been proposed in the past two decades. The aim of this article is to review and summarize the existing simulation-based training systems for laparoscopic surgery in terms of their technical realizations. Forty-three training systems were found and analyzed. These training systems generally consist of training tasks, a visualization interface, and an instrument interface. Three different approaches-physical, virtual, and augmented reality-to implement visualization interfaces are discussed first. Then, haptic feedback, performance evaluation, and guidance methods are summarized. Portable devices to enable at-home training and instrument tracking technologies to support visualization, evaluation, and guidance are also presented. Based on survey of the relevant literature, we propose several recommendations to design the next-generation training systems in laparoscopic surgery. Novel guidance and assessment schemes with augmented reality visualization are recommended to design an intelligent surgical training simulator. This intelligent simulator enhances the training procedure and ultimately improves the patient safety.
C1 [Hong, Minsik; Rozenblit, Jerzy W.] Univ Arizona, Dept Elect & Comp Engn, 1230 E Speedway Blvd, Tucson, AZ 85721 USA.
   [Rozenblit, Jerzy W.; Hamilton, Allan J.] Univ Arizona, Dept Surg, 1501 N Campbell Ave, Tucson, AZ 85724 USA.
C3 University of Arizona; University of Arizona
RP Hong, MS (corresponding author), Univ Arizona, Dept Elect & Comp Engn, 1230 E Speedway Blvd, Tucson, AZ 85721 USA.
EM mshong@email.arizona.edu; jr@ece.arizona.edu; allan@surgery.arizona.edu
OI Hong, Minsik/0000-0002-0431-1127; Rozenblit, Jerzy/0000-0002-7348-4128
FU National Science Foundation [1622589]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1622589] Funding
   Source: National Science Foundation
FX This material is based upon work supported by the National Science
   Foundation under Grant Number 1622589 "Computer Guided Laparoscopy
   Training." Any opinions, findings, and conclusions or recommendations
   expressed in this material are those of the authors and do not
   necessarily reflect the views of the National Science Foundation.
CR Abboudi H, 2013, BJU INT, V111, P194, DOI 10.1111/j.1464-410X.2012.11270.x
   Acosta Eric, 2005, Stud Health Technol Inform, V111, P8
   Adrales GL, 2003, SURG ENDOSC, V17, P580, DOI 10.1007/s00464-002-8841-7
   Ahmad S, 2013, 2013 INTERNATIONAL CONFERENCE ON AEROSPACE SCIENCE & ENGINEERING (ICASE), P57
   Alcañiz M, 2003, ST HEAL T, V94, P16
   Andreatta PB, 2006, ANN SURG, V243, P854, DOI 10.1097/01.sla.0000219641.79092.e5
   [Anonymous], 2004, Moneyball: The art of winning an unfair game
   [Anonymous], 2011, FUNDAMENTALS SURG SI
   Basdogan C, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1274062
   Basdogan C, 2007, IEEE COMPUT GRAPH, V27, P54, DOI 10.1109/MCG.2007.51
   Beatty JD, 2005, BJU INT, V96, P679, DOI 10.1111/j.1464-410X.2005.05704.x
   Bokhari R, 2010, AM SURGEON, V76, P583
   Botden SMBI, 2009, SURG ENDOSC, V23, P2131, DOI 10.1007/s00464-008-0240-2
   Botden SMBI, 2008, SURG ENDOSC, V22, P1214, DOI 10.1007/s00464-007-9589-x
   Botden SMBI, 2008, SIMUL HEALTHC, V3, P97, DOI 10.1097/SIH.0b013e3181659e91
   Botden SMBI, 2009, SURG ENDOSC, V23, P1693, DOI 10.1007/s00464-008-0144-1
   Bowyer SA, 2014, IEEE T ROBOT, V30, P138, DOI 10.1109/TRO.2013.2283410
   Bric JD, 2016, SURG ENDOSC, V30, P2169, DOI 10.1007/s00464-015-4517-y
   Çakmak H, 2005, MINIM INVASIV THER, V14, P134, DOI 10.1080/13645700510033958
   Chandarsekera SK, 2006, EUR UROL, V50, P1285, DOI 10.1016/j.eururo.2006.05.052
   Chen R.-J., 2011, Int. J. Autom. Smart Technol, V1, P41, DOI DOI 10.5875/AUSMT.V1I1.102
   Chen ZH, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2343, DOI 10.1109/IROS.2016.7759365
   Chmarra MK, 2007, MINIM INVASIV THER, V16, P328, DOI 10.1080/13645700701702135
   Chmarra MK, 2008, SURG ENDOSC, V22, P2140, DOI 10.1007/s00464-008-9937-5
   Chmarra MK, 2010, SURG ENDOSC, V24, P1031, DOI 10.1007/s00464-009-0721-y
   Cleary K, 2010, ANNU REV BIOMED ENG, V12, P119, DOI 10.1146/annurev-bioeng-070909-105249
   Cotin S, 2002, LECT NOTES COMPUT SC, V2488, P35
   De Loose J, 2017, GYNECOL SURG, V14, DOI 10.1186/s10397-017-1028-y
   De Luca V, 2016, LECT NOTES COMPUT SC, V9769, P65, DOI 10.1007/978-3-319-40651-0_6
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   Debes AJ, 2012, AM J SURG, V203, P768, DOI 10.1016/j.amjsurg.2011.07.022
   Debes AJ, 2010, AM J SURG, V199, P840, DOI 10.1016/j.amjsurg.2009.05.016
   Duffy AJ, 2005, SURG ENDOSC, V19, P401, DOI 10.1007/s00464-004-8202-9
   Fraser SA, 2003, SURG ENDOSC, V17, P964, DOI 10.1007/s00464-002-8828-4
   Gao BF, 2012, IEEE INT C AUTOMAT L, P611, DOI 10.1109/ICAL.2012.6308151
   Gillespie R.B., 2013, J. Chem. Inf. Model, V53, P1689, DOI DOI 10.1021/CI400128M
   Hardon SF, 2018, SURG ENDOSC, V32, P3609, DOI 10.1007/s00464-018-6090-7
   Hasson H M, 2001, JSLS, V5, P255
   Hernansanz Albert, 2012, Information Processing in Computer-Assisted Interventions. Proceedings Third International Conference, IPCAI 2012, P157, DOI 10.1007/978-3-642-30618-1_16
   Hong M, 2019, INTELLIGENT GUIDANCE
   Hong M, 2017, IEEE SYS MAN CYBERN, P3083, DOI 10.1109/SMC.2017.8123100
   Horeman T, 2012, SURG ENDOSC, V26, P242, DOI 10.1007/s00464-011-1861-4
   Howard T, 2014, P IEEE RAS-EMBS INT, P58, DOI 10.1109/BIOROB.2014.6913752
   Hruby GW, 2008, J UROLOGY, V179, P662, DOI 10.1016/j.juro.2007.09.030
   Huang L, 2013, INTERNATIONAL CONFERENCE ON COMPLEX SCIENCE MANAGEMENT AND EDUCATION SCIENCE (CSMES 2013), P1
   Iwata N, 2011, SURG ENDOSC, V25, P423, DOI 10.1007/s00464-010-1184-x
   Jaber Nidal, 2010, J Minim Access Surg, V6, P3, DOI 10.4103/0972-9941.62525
   Jain S., 2019, 2019 Spring Simulation Conference (SpringSim), P1
   Jiménez P, 2001, COMPUT GRAPH-UK, V25, P269, DOI 10.1016/S0097-8493(00)00130-8
   Jinao Zhang, 2018, IEEE Reviews in Biomedical Engineering, V11, P143, DOI 10.1109/RBME.2017.2773521
   Kawaguchi K, 2014, MINIM INVASIV THER, V23, P287, DOI 10.3109/13645706.2014.903853
   Khan ZA, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1771
   Kim YS, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P559, DOI 10.1109/WHC.2013.6548469
   Korndorffer JR, 2012, AM J SURG, V203, P1, DOI 10.1016/j.amjsurg.2011.07.001
   Kunkler K, 2006, INT J MED ROBOT COMP, V2, P203, DOI 10.1002/rcs.101
   Lahanas V, 2015, SURG ENDOSC, V29, P2224, DOI 10.1007/s00464-014-3930-y
   Lau WY, 1997, WORLD J SURG, V21, P444, DOI 10.1007/PL00012268
   Liao HE, 2010, IEEE T BIO-MED ENG, V57, P1476, DOI 10.1109/TBME.2010.2040278
   Loukas C., 2016, International Journal of Advanced Robotics and Automation, V1, P1, DOI DOI 10.15226/2473-3032/1/2/00109
   Loukas C, 2013, INT J MED ROBOT COMP, V9, pE34, DOI 10.1002/rcs.1485
   Maciel A, 2008, INT J MED ROBOT COMP, V4, P131, DOI 10.1002/rcs.185
   Makary MA, 2016, BMJ-BRIT MED J, V353, DOI 10.1136/bmj.i2139
   Martins JMP, 2015, ABCD-ARQ BRAS CIR DI, V28, P204, DOI 10.1590/S0102-67202015000300015
   Meier U, 2005, COMPUT METH PROG BIO, V77, P183, DOI 10.1016/j.cmpb.2004.11.002
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Moreno M.R., 2012, International Conference on Design and PROcesses for MEdical Devices, P207
   Oropesa I, 2014, SURG ENDOSC, V28, P657, DOI 10.1007/s00464-013-3226-7
   Oropesa I, 2013, SURG INNOV, V20, P299, DOI 10.1177/1553350612459808
   Oropesa I, 2011, J SURG RES, V171, pE81, DOI 10.1016/j.jss.2011.06.034
   Oussi N, 2018, SURG ENDOSC, V32, P87, DOI 10.1007/s00464-017-5641-7
   Overtoom EM, 2018, J SURG ED
   Panait L, 2009, J SURG RES, V156, P312, DOI 10.1016/j.jss.2009.04.018
   Peng KS, 2017, EUROCAST, V2017, P254
   Escamirosa FP, 2015, SURG ENDOSC, V29, P3392, DOI 10.1007/s00464-014-4032-6
   Prada R, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P375
   Rahman MAA, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55533
   Riojas M, 2011, APPL SOFT COMPUT, V11, P3697, DOI 10.1016/j.asoc.2011.01.041
   Ritter EM, 2007, SURG INNOV, V14, P107, DOI 10.1177/1553350607302329
   Rosen J, 2002, ST HEAL T, V85, P412
   Ruparel RK, 2014, UROLOGY, V83, P116, DOI 10.1016/j.urology.2013.09.030
   Ruthenbeck GS, 2013, J SIMUL, V7, P101, DOI 10.1057/jos.2012.22
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   Salkini MW, 2010, J ENDOUROL, V24, P99, DOI 10.1089/end.2009.0307
   Schijven M, 2002, SURG ENDOSC, V16, P1764, DOI 10.1007/s00464-001-9229-9
   Shamsunder SC, 2008, STUD HEALTH TECHNOL, V132, P454
   Sharpe BA, 2005, UROLOGY, V66, P50, DOI 10.1016/j.urology.2005.01.015
   Soper Nathaniel J, 2008, Bull Am Coll Surg, V93, P30
   Soyinka AS, 2008, FERTIL STERIL, V90, P1988, DOI 10.1016/j.fertnstert.2007.08.077
   Speicher M, 2019, P 2019 CHI C HUM FAC, P1
   Spruit EN, 2014, PSYCHOL RES-PSYCH FO, V78, P878, DOI 10.1007/s00426-013-0525-5
   Sridhar AN, 2017, CURR UROL REP, V18
   Stylopoulos N, 2004, SURG ENDOSC, V18, P782, DOI 10.1007/s00464-003-8932-0
   Sucan IA, 2012, IEEE ROBOT AUTOM MAG, V19, P72, DOI 10.1109/MRA.2012.2205651
   Tagawa Kazuyoshi, 2013, Stud Health Technol Inform, V184, P431
   Tendick F, 2000, PRESENCE-VIRTUAL AUG, V9, P236, DOI 10.1162/105474600566772
   Teo CL, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P335, DOI 10.1109/HAPTIC.2002.998977
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Thinggaard E, 2015, BRIT J SURG, V102, P1106, DOI 10.1002/bjs.9857
   van der Meijden OAJ, 2009, SURG ENDOSC, V23, P1180, DOI 10.1007/s00464-008-0298-x
   Van Sickle KR, 2005, SURG ENDOSC, V19, P1227, DOI 10.1007/s00464-004-8274-6
   Våpenstad C, 2013, SURG ENDOSC, V27, P1386, DOI 10.1007/s00464-012-2621-9
   Vassiliou MC, 2005, AM J SURG, V190, P107, DOI 10.1016/j.amjsurg.2005.04.004
   Verdaasdonk EGG, 2006, SURG ENDOSC, V20, P511, DOI 10.1007/s00464-005-0230-6
   Wagner A., 2017, Proceedings of the Symposium on Modeling and Simulation in Medicine, P855
   Wang F, 2005, P ANN INT IEEE EMBS, P5778, DOI 10.1109/IEMBS.2005.1615801
   Westebring-van der Putten EP, 2008, MINIM INVASIV THER, V17, P3, DOI 10.1080/13645700701820242
   Wilson MS, 1997, ANN ROY COLL SURG, V79, P403
   Wu J, 2015, COMPUT GRAPH FORUM, V34, P161, DOI 10.1111/cgf.12528
   Yang T, 2013, ADV INTELL SYST, V194, P17
   Yiasemidou M, 2017, J SURG RES, V213, P69, DOI 10.1016/j.jss.2017.02.038
   Yoon R, 2015, J SURG EDUC, V72, P41, DOI 10.1016/j.jsurg.2014.06.011
   Zahiri M, 2017, J MED DEVICES, V11, DOI 10.1115/1.4034881
   Zhang AM, 2008, SURG ENDOSC, V22, P1440, DOI 10.1007/s00464-007-9625-x
   Ziv A, 2000, MED TEACH, V22, P489, DOI 10.1080/01421590050110777
NR 115
TC 13
Z9 14
U1 0
U2 49
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 491
EP 510
DI 10.1007/s10055-020-00469-z
EA SEP 2020
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000571042600001
DA 2024-07-18
ER

PT J
AU Lovreglio, R
   Duan, XY
   Rahouti, A
   Phipps, R
   Nilsson, D
AF Lovreglio, Ruggiero
   Duan, Xinyue
   Rahouti, Anass
   Phipps, Robyn
   Nilsson, Daniel
TI Comparing the effectiveness of fire extinguisher virtual reality and
   video training
SO VIRTUAL REALITY
LA English
DT Article
DE Fire safety; Fire extinguishers; Virtual reality; Serious games;
   Training
ID SERIOUS GAMES; PREPAREDNESS; ENVIRONMENTS; INFORMATION; VS.
AB Fire is a major hazard in built environments. Fires in buildings cause fatalities, serious injuries and tremendous damage. Most fires can be extinguished in the early stages of the fire's development, with the right equipment and correct use of the equipment. However, as there can be as little as a few minutes between a fire starting and very dire consequences, rapid and correct responses are critical. Implementing effective training solutions is necessary to enable members of the public, who are not experts in fire safety, to use a fire extinguisher correctly. This can assist to build resilience to fires. In recent decades, virtual reality (VR) has aroused the fire safety community's attention, as a smart, safe and effective training method compared to the traditional methods of lectures, non-interactive videos, and brochures. VR has been used for training for fire emergency preparedness and to collect data about evacuee decision-making, but VR has rarely been applied to a fully immersive training experience about fire extinguishers operation steps. Fire extinguisher operation steps are Pull, Aim, Squeeze and Sweep. Each step is critical to quickly extinguish a fire. This paper compares fire extinguisher training using a VR simulation with a non-interactive training video and evaluates the trainees learning of a fire extinguisher's basic operation steps, in terms of knowledge acquisition, retention of information and change of self-efficacy. The results showed that the VR trainees scored better than video trainees, in terms of knowledge acquisition, even if the same trend was observed for long term retention of information. It was also observed that VR training provided a higher increment of self-efficacy right after the training. The VR group participants had maintained the same level of self-efficacy even 3-4 weeks after the training, while the video group had shown a significant drop of self-efficacy.
C1 [Lovreglio, Ruggiero; Duan, Xinyue; Phipps, Robyn] Massey Univ East Precinct, Sch Built Environm, Dairy Flat Highway SH17, Auckland 0632, New Zealand.
   [Rahouti, Anass] Univ Mons, Fac Engn, Mons, Belgium.
   [Nilsson, Daniel] Univ Canterbury, Dept Civil & Nat Resources Engn, Christchurch, New Zealand.
C3 University of Mons; University of Canterbury
RP Lovreglio, R (corresponding author), Massey Univ East Precinct, Sch Built Environm, Dairy Flat Highway SH17, Auckland 0632, New Zealand.
EM R.Lovreglio@massey.ac.nz
RI Phipps, Robyn/AAG-6243-2020; duan, xinyue/B-3870-2011; Lovreglio,
   Ruggiero/AAH-7275-2019
OI Phipps, Robyn/0000-0003-2810-7662; Lovreglio,
   Ruggiero/0000-0003-4596-7656
FU College of Science of Massey University through the MURF fund [SREF]
FX The authors are grateful to MAMMOTH VR and HONE Ltd. for providing the
   license of the PASS training application. Dr Lovreglio thanks the
   College of Science of Massey University for funding this research
   through the MURF fund (Grant No. SREF). Finally Dr Lovreglio would like
   to thank Phil Jackson (EvacuationNow) and the Fire Protection
   Association (NZ Chapter) for helping with the data collection.
CR Bass A., 2014, Pass-fire extinguisher safety
   Burigat S, 2016, INT J HUM-COMPUT ST, V87, P92, DOI 10.1016/j.ijhcs.2015.11.004
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Chittaro L, 2018, SAFETY SCI, V102, P159, DOI 10.1016/j.ssci.2017.10.012
   Chittaro L, 2016, IEEE T VIS COMPUT GR, V22, P1527, DOI 10.1109/TVCG.2015.2443787
   Chittaro L, 2015, COMPUT HUM BEHAV, V50, P508, DOI 10.1016/j.chb.2015.03.074
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Chittaro L, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P76, DOI 10.1109/VS-GAMES.2009.8
   De Gloria A, 2014, INT J SERIOUS GAMES, V1, DOI 10.17083/ijsg.v1i1.11
   Duckworth S, 2016, INT GOOD PRACTICE SA
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Inoue Y., 1999, Campus-Wide Information Systems, V16, P95, DOI 10.1108/10650749910281250
   Kim JH, 2001, VIRTUAL REALITY SIMU
   Kinateder M, 2014, APPL ERGON, V45, P1649, DOI 10.1016/j.apergo.2014.05.014
   Kinateder M, 2013, TRANSPORT RES F-TRAF, V17, P20, DOI 10.1016/j.trf.2012.09.001
   Korea Railroad Research Institute, 2018, Preliminary Study on the Self-Powered Wireless Sensing Technology for the Safety of Rail Power Distribution Line, P1
   Lebram M, 2009, INTEL SYST CONTR AUT, V37, P19
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Lovreglio R, 2020, SAFETY SCI, V128, DOI 10.1016/j.ssci.2020.104750
   Lovreglio R, 2018, ADV ENG INFORM, V38, P670, DOI 10.1016/j.aei.2018.08.018
   MADDUX JE, 1983, J EXP SOC PSYCHOL, V19, P469, DOI 10.1016/0022-1031(83)90023-9
   Mansson J., 2018, THESIS
   NZG-New Zealand Government, COMM US FIR EXT
   Poole B, 2012, ORDINARY PEOPLE EFFE
   Rüppel U, 2011, ADV ENG INFORM, V25, P600, DOI 10.1016/j.aei.2011.08.001
   Silva JF, 2013, 2013 IEEE 2ND INTERNATIONAL CONFERENCE ON SERIOUS GAMES AND APPLICATIONS FOR HEALTH (SEGAH)
   Smith SP, 2009, FIRE SAFETY J, V44, P559, DOI 10.1016/j.firesaf.2008.11.004
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Taitt HA, 1993, CURRICULUM REPORT, V22
   Tate DL, 1997, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VRAIS.1997.583045
   Trusted Reviews, 2018, CAN YOUR PC RUN HTC
   Xu Z, 2014, ADV ENG SOFTW, V68, P1, DOI 10.1016/j.advengsoft.2013.10.004
NR 32
TC 62
Z9 62
U1 7
U2 86
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 133
EP 145
DI 10.1007/s10055-020-00447-5
EA MAY 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000534863000001
OA Green Published
DA 2024-07-18
ER

PT J
AU Cook, M
   Grime, J
AF Cook, Matt
   Grime, John
TI Motivations, design, and preliminary testing for a 360° vision simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cognitive load; Scientific data visualization; Academic
   technologies
ID VIRTUAL-REALITY; VISUALIZATION; CAPACITY; MEMORY; LOAD; VR
AB Contemporary virtual reality systems enable academics to more efficiently explore and analyze complex three-dimensional (3D) content, but their utility is limited by visual short-term memory. Janus, a geometry agnostic shader script, circumvents this cognitive limitation by automatically rendering complex object meshes to fit entirely within the field-of-view of consumer head-mounted displays. The resulting 360 degrees vision experience represents an advantage over existing scientific data visualization tools, which have sought to replicate real-world viewing experiences but have inadvertently replicated associated limitations as well. By presenting data in such a way so as to effectively circumvent cognitive loads associated with body (or object) movement, academics can use the Janus shader to more readily engage in the exploratory analysis of complex 3D data sets, thereby facilitating scientific insight. This paper explores the motivations and design of the Janus shader and describes preliminary results from user testing conducted under controlled conditions. For the 24 study participants (N = 24), statistically significant time-to-completion decreases were observed for spatial analysis tasks taking place in intervention (Janus-enabled) VR scenes of low-to-moderate complexity.
C1 [Cook, Matt] Harvard Lib, 1 Harvard Yard, Cambridge, MA 02138 USA.
   [Grime, John] Univ Oklahoma Lib, 401 West Brooks St, Norman, OK 73019 USA.
C3 University of Oklahoma System; University of Oklahoma - Norman
RP Cook, M (corresponding author), Harvard Lib, 1 Harvard Yard, Cambridge, MA 02138 USA.
EM matt_cook@harvard.edu; jgrime@ou.edu
CR Acevedo D, 2001, IEEE VISUAL, P493, DOI 10.1109/VISUAL.2001.964560
   Alliez Pierre., 2017, Digital 3D Objects in Art and Humanities: challenges of creation, interoperability and preservation, P71
   Alvarez GA, 2004, PSYCHOL SCI, V15, P106, DOI 10.1111/j.0963-7214.2004.01502006.x
   Andersen SAW, 2016, J SURG EDUC, V73, P45, DOI 10.1016/j.jsurg.2015.09.010
   Ardouin J., 2012, P ACM S VIRTUAL REAL, P41
   Cook M, 2019, REALITY AUGMENTED VI
   Cook M, 2018, J ACAD LIBR, V44, P145, DOI 10.1016/j.acalib.2017.09.003
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Donalek C., 2014, ARXIV14107670
   Evagorou G, 2018, VISUAL EXPLORATION I
   Fan Kevin, 2014, P 5 AUGM HUM INT C K
   JOHNSTON EB, 1994, VISION RES, V34, P2259, DOI 10.1016/0042-6989(94)90106-6
   Kersten-Oertel M, 2014, IEEE T VIS COMPUT GR, V20, P391, DOI 10.1109/TVCG.2013.240
   Lages WS, 2018, MOVE OBJECT MOVE MYS
   Laha B, 2014, IEEE T VIS COMPUT GR, V20, P513, DOI 10.1109/TVCG.2014.20
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Maan ZN, 2012, BRIT J SURG, V99, P1610, DOI 10.1002/bjs.8893
   Milovanovic J, 2017, 17 INT C CAAD FUT 20
   Orlosky J., 2014, P ACM S SPATIAL USER, P54, DOI [10.1145/2659766.2659771, DOI 10.1145/2659766.2659771]
   Pfarr-Harfst Mieke, 2016, 3D Research Challenges in Cultural Heritage II. How to Manage Data and Knowledge Related to Interpretative Digital 3D Reconstructions of Cultural Heritage. LNCS 10025, P32, DOI 10.1007/978-3-319-47647-6_2
   Prabhat, 2008, IEEE T VIS COMPUT GR, V14, P551, DOI 10.1109/TVCG.2007.70433
   Ragan ED, 2013, IEEE T VIS COMPUT GR, V19, P886, DOI 10.1109/TVCG.2012.163
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Silvestri C, 2010, DESIGN STUD, V31, P363, DOI 10.1016/j.destud.2010.03.001
   Strasburger H, 2011, J VISION, V11, DOI 10.1167/11.5.13
   Thomas LE, 2010, COGNITION, V117, P80, DOI 10.1016/j.cognition.2010.07.002
   Thompson M., 2018, Making virtual reality a reality in today's classroom
   van Dam A, 2002, COMPUT GRAPH-UK, V26, P535, DOI 10.1016/S0097-8493(02)00113-9
   Veurink NL, 2009, ENG DES GRAPH J, V73, P2
   Ware C., 2005, Proceedings of the 2nd Symposium on Applied Perception in Graphics and Visualization (A Corona, Spain, August 26 - 28, V95, P51, DOI DOI 10.1145/1080402.1080411
   Yoon S. Y., 2011, Psychometric properties of the revised Purdue spatial visualization tests: Visualization of rotations (the revised PSVT-R)
NR 32
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 247
EP 255
DI 10.1007/s10055-020-00433-x
EA APR 2020
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000528299800001
DA 2024-07-18
ER

PT J
AU Zhao, JB
   Allison, RS
AF Zhao, Jingbo
   Allison, Robert S.
TI Comparing head gesture, hand gesture and gamepad interfaces for
   answering Yes/No questions in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Head gesture; Hand gesture; Virtual reality; Usability
AB A potential application of gesture recognition algorithms is to use them as interfaces to interact with virtual environments. However, the performance and the user preference of such interfaces in the context of virtual reality (VR) have been rarely studied. In the present paper, we focused on a typical VR interaction scenario-answering Yes/No questions in VR systems to compare the performance and the user preference of three types of interfaces. These interfaces included a head gesture interface, a hand gesture interface and a conventional gamepad interface. We designed a memorization task, in which participants were asked to memorize several everyday objects presented in a virtual room and later respond to questions on whether they saw a specific object through the given interfaces when these objects were absent. The performance of the interfaces was evaluated in terms of the real-time accuracy and the response time. A user interface questionnaire was also used to reveal the user preference for these interfaces. The results showed that head gesture is a very promising interface, which can be easily added to existing VR systems for answering Yes/No questions and other binary responses in virtual environments.
C1 [Zhao, Jingbo] China Agr Univ, Coll Informat & Elect Engn, 17 Tsinghua East Rd, Beijing 100083, Peoples R China.
   [Zhao, Jingbo; Allison, Robert S.] York Univ, Dept Elect Engn & Comp Sci, 4700 Keele St, Toronto, ON M3J 1P3, Canada.
C3 China Agricultural University; York University - Canada
RP Zhao, JB (corresponding author), China Agr Univ, Coll Informat & Elect Engn, 17 Tsinghua East Rd, Beijing 100083, Peoples R China.; Zhao, JB (corresponding author), York Univ, Dept Elect Engn & Comp Sci, 4700 Keele St, Toronto, ON M3J 1P3, Canada.
EM jingbo@eecs.yorku.ca; allison@eecs.yorku.ca
OI Allison, Robert/0000-0002-4485-2665; Zhao, Jingbo/0000-0002-6279-9570
CR Abate AF, 2011, J VISUAL LANG COMPUT, V22, P415, DOI 10.1016/j.jvlc.2011.02.005
   Cardoso JCS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P319, DOI 10.1145/2993369.2996327
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Morency LP, 2007, ARTIF INTELL, V171, P568, DOI 10.1016/j.artint.2007.04.003
   Morimoto C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P461, DOI 10.1109/ICPR.1996.546990
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Robinett R., 1992, P 1992 S INT 3D GRAP, P189, DOI 10.1145/147156.1472012
   Terven JR, 2014, LECT NOTES COMPUT SC, V8495, P152, DOI 10.1007/978-3-319-07491-7_16
   Wille M, 2015, P HFES ANN M
   Yan ZX, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P27, DOI 10.1109/3DUI.2016.7460027
   Zhao JB, 2017, IEEE SYS MAN CYBERN, P2361, DOI 10.1109/SMC.2017.8122975
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 18
TC 10
Z9 11
U1 2
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 515
EP 524
DI 10.1007/s10055-019-00416-7
EA NOV 2019
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000499612900001
DA 2024-07-18
ER

PT J
AU Catal, C
   Akbulut, A
   Tunali, B
   Ulug, E
   Ozturk, E
AF Catal, Cagatay
   Akbulut, Akhan
   Tunali, Berkay
   Ulug, Erol
   Ozturk, Eren
TI Evaluation of augmented reality technology for the design of an
   evacuation training game
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Evacuation training system; Software; Unity3D;
   Training; ARKit framework; Animation; Game engine
ID MOBILE ESCAPE GUIDELINES; USABILITY; SYSTEM
AB Building evacuation training systems and training employees in an organization have a vital role in emergency cases in which people need to know what to do exactly. In every building, procedures, rules, and actions are attractively shown on the walls, but most of the people living in that building are not aware of these procedures and do not have any experience what to do in these dangerous situations. In order to be able to apply these procedures properly in an emergency situation, community members should be trained with the state-of-the-art equipment and technologies, but to do so, up-front investment and development of such a system are necessary. In this study, augmented reality (AR) technology was applied to realize a game-based evacuation training system that implements gamification practices. The architectural plans of a university were used to model the floors and the relevant environment. Employees are trained to learn how to reach the nearest exit location in the event of a fire or earthquake, and also, the system provides the shortest path for the evacuation. In addition to these features, our training game has educational animations about the fire, chemical attack, and earthquake events. A mobile application was implemented to train employees working in the building and inform them to know how to escape in an emergency situation. The technology acceptance model and the related questionnaire form were applied, and the response of 36 participants was analyzed. It was demonstrated that AR and relevant tools provide a flexible environment to develop evacuation systems in a university, our mobile application enabled participants to be trained in a realistic environment, and trainees were highly satisfied with the system. Educational animations were also another benefit for the trainees.
C1 [Catal, Cagatay] Wageningen Univ & Res, Informat Technol Grp, Wageningen, Netherlands.
   [Akbulut, Akhan; Tunali, Berkay; Ulug, Erol; Ozturk, Eren] Istanbul Kultur Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Wageningen University & Research; Istanbul Kultur University
RP Catal, C (corresponding author), Wageningen Univ & Res, Informat Technol Grp, Wageningen, Netherlands.
EM cagatay.catal@wur.nl; a.akbulut@iku.edu.tr; 1401026029@stu.iku.edu.tr;
   1401026028@stu.iku.edu.tr; 1301020434@stu.iku.edu.tr
RI Hidayat, Ima Kusumawati/ABF-6870-2021; Akbulut, Akhan/AAC-5992-2020;
   Catal, Cagatay/AAF-3929-2019
OI Hidayat, Ima Kusumawati/0000-0002-3387-9213; Akbulut,
   Akhan/0000-0001-9789-5012; Catal, Cagatay/0000-0003-0959-2930
CR A. Inc, 2018, ARK APPL DEV
   Ahad AR, 2004, SICE 2004 ANNUAL CONFERENCE, VOLS 1-3, P1041
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Bach B, 2017, IEEE VIS
   Bai Z, 2012, INTERACT COMPUT, V24, P450, DOI 10.1016/j.intcom.2012.07.004
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Brigade IF, 2018, FIRE STAT
   Cabrilo I, 2015, WORLD NEUROSURG, V83, P596, DOI 10.1016/j.wneu.2014.12.020
   Cabrilo I, 2014, OPER NEUROSURG, V10, P252, DOI 10.1227/NEU.0000000000000328
   Chandrasekera T., 2015, THESIS U MISSOURI
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dey A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P49, DOI [10.1109/ISMAR-Adjunct.2016.0036, 10.1109/ISMAR-Adjunct.2016.29]
   Disaster EM Authority, 2018, GEN STAT
   Dunser A., 2008, A survey of evaluation techniques used in augmented reality studies
   Edward J, 2005, 1 INT C VIRT REAL LA
   Faroque S, 2018, COMPUT ELECTR ENG, V67, P656, DOI 10.1016/j.compeleceng.2017.04.030
   Iguchi K, 2016, INT CONF INFORM COMM, P158
   Junho Ahn, 2011, Proceedings of the 2011 IEEE Asia-Pacific Services Computing Conference (APSCC), P70, DOI 10.1109/APSCC.2011.26
   Kawai J, 2016, INTERACT TECHNOL SMA, V13, P186, DOI 10.1108/ITSE-01-2016-0001
   Kawai J, 2015, PROCEDIA COMPUT SCI, V72, P329, DOI 10.1016/j.procs.2015.12.147
   Khor WS, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.12.23
   Leelawat N, 2018, INT J DISAST RISK RE, V29, P63, DOI 10.1016/j.ijdrr.2017.06.014
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Lovo EE, 2007, NEUROSURGERY, V60, P366, DOI 10.1227/01.NEU.0000255360.32689.FA
   Ma M, 2016, CLIN ANAT, V29, P446, DOI 10.1002/ca.22675
   Mota JM, 2018, COMPUT ELECTR ENG, V65, P250, DOI 10.1016/j.compeleceng.2017.08.025
   Mitsuhara H, 2018, PR IEEE INT CONF TEA, P893, DOI 10.1109/TALE.2018.8615405
   Mitsuhara H, 2016, IEEE INT CONF ADV LE, P133, DOI 10.1109/ICALT.2016.71
   Mitsuhara H, 2015, PROCEDIA COMPUT SCI, V72, P277, DOI 10.1016/j.procs.2015.12.141
   Pallotta F, 2017, MAKE AUGMENTED REALI
   Shenai MB, 2011, NEUROSURGERY, V68, DOI 10.1227/NEU.0b013e3182077efd
   Tatic D, 2017, COMPUT IND, V85, P1, DOI 10.1016/j.compind.2016.11.004
   Tsai MK, 2013, J ENVIRON RADIOACTIV, V118, P15, DOI 10.1016/j.jenvrad.2012.11.001
   Tsai MK, 2012, J ENVIRON RADIOACTIV, V109, P36, DOI 10.1016/j.jenvrad.2011.12.025
   U. Technologies, 2018, UN VID GAM ENG
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Volonté F, 2011, J HEPATO-BIL-PAN SCI, V18, P506, DOI 10.1007/s00534-011-0385-6
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
NR 38
TC 28
Z9 30
U1 4
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 359
EP 368
DI 10.1007/s10055-019-00410-z
EA NOV 2019
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000498619700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Liu, SG
   Ma, C
   Feng, G
AF Liu, Shiguang
   Ma, Chao
   Feng, Gang
TI Haptic rendering for the coupling between fluid and deformable object
SO VIRTUAL REALITY
LA English
DT Article
DE Haptic rendering; Fluid; Deformable objects; Force feedback
AB It remains a challenging problem to simulate the haptic interaction between the fluid and deformable objects due to the inhomogeneity of the deformable object. In this paper, we present a novel position-based haptic interaction method to tackle this problem. On the one hand, according to the inhomogeneity of the deformable object, we calculate the properties of different regions of the deformable object and then evaluate its haptic force so as to make the results more realistic. On the other hand, to preserve more details of haptic feedback forces, we especially incorporate the calculation of buoyancy, pressure, viscous force and elastic force into our framework and design a novel integration scheme for assembling such forces. Moreover, by respecting the influence from fluid viscosity, our method can obtain different haptic force feedback for fluids of different viscosities. Various experiments validated our new method.
C1 [Liu, Shiguang; Ma, Chao; Feng, Gang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
   [Liu, Shiguang] Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.; Liu, SG (corresponding author), Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
EM shgliu@126.com
FU National Natural Science Foundation of China [61672375, 61170118]
FX The study was funded by National Natural Science Foundation of China
   with Grant Nos. 61672375 and 61170118.
CR [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Bargteil AW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239467
   Bodin K, 2012, IEEE T VIS COMPUT GR, V18, P516, DOI 10.1109/TVCG.2011.29
   Cirio G, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P157, DOI 10.1109/WHC.2013.6548401
   Cirio G, 2011, IEEE T VIS COMPUT GR, V17, P1714, DOI 10.1109/TVCG.2010.271
   Dobashi Y, 2007, IEEE COMPUT GRAPH, V27, P90, DOI 10.1109/MCG.2007.52
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Karadogan E, 2013, VIRTUAL REAL-LONDON, V17, P45, DOI 10.1007/s10055-013-0220-2
   Liu G., 2008, Virtual Reality, V12, P99, DOI DOI 10.1007/S10055-008-0094-X
   Luciano C, 2009, VIRTUAL REAL-LONDON, V13, P69, DOI 10.1007/s10055-009-0112-7
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Monaghan JJ, 2000, J COMPUT PHYS, V159, P290, DOI 10.1006/jcph.2000.6439
   Mora J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P75
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2006, P WORKSH VIRT REAL I
   Nixon D, 2002, IEEE COMPUT GRAPH, V22, P68, DOI 10.1109/MCG.2002.1016700
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Tavakoli M., 2006, VIRTUAL REAL-LONDON, V9, P160, DOI [10.1007/s10055-005-0017-z, DOI 10.1007/S10055-005-0017-Z]
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Violeau D, 2015, J COMPUT PHYS, V288, P119, DOI 10.1016/j.jcp.2015.02.015
   Wang Z, 2014, P INT C COMP SCI ITS, P808
   Wicke M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778786
   Yang M, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENT AND GAMES, P24, DOI 10.1109/HAVE.2009.5356132
   Zhang XY, 2017, VIRTUAL REAL-LONDON, V21, P165, DOI 10.1007/s10055-017-0308-1
NR 27
TC 2
Z9 4
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 33
EP 44
DI 10.1007/s10055-018-0351-6
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500004
DA 2024-07-18
ER

PT J
AU Turchet, L
   Spagnol, S
   Geronazzo, M
   Avanzini, F
AF Turchet, Luca
   Spagnol, Simone
   Geronazzo, Michele
   Avanzini, Federico
TI Localization of self-generated synthetic footstep sounds on different
   walked-upon materials through headphones
SO VIRTUAL REALITY
LA English
DT Article
DE Walking; Interactive auditory feedback; Localization
ID SEMANTIC CONGRUENCE; HEAD
AB This paper focuses on the localization of footstep sounds interactively generated during walking and provided through headphones. Three distinct experiments were conducted in a laboratory involving a pair of sandals enhanced with pressure sensors and a footstep synthesizer capable of simulating two typologies of surface materials: solid (e.g., wood) and aggregate (e.g., gravel). Different sound delivery methods (mono, stereo, binaural) as well as several surface materials, in the presence or absence of concurrent contextual auditory information provided as soundscapes, were evaluated in a vertical localization task. Results showed that solid surfaces were localized significantly farther from the walker's feet than the aggregate ones. This effect was independent of the used rendering technique, of the presence of soundscapes, and of merely temporal or spectral attributes of sound. The effect is hypothesized to be due to a semantic conflict between auditory and haptic information such that the higher the semantic incongruence the greater the distance of the perceived sound source from the feet. The presented results contribute to the development of further knowledge toward a basis for the design of continuous multimodal feedback in virtual reality applications.
C1 [Turchet, Luca] Aalborg Univ, Dept Architecture Design & Media Technol, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
   [Spagnol, Simone] Univ Iceland, Fac Ind Engn Mech Engn & Comp Sci, Sch Engn & Nat Sci, Taeknigarour Dunhagi 5, IS-107 Reykjavik, Iceland.
   [Geronazzo, Michele; Avanzini, Federico] Univ Padua, Dept Informat Engn, Via Gradenigo 6-A, I-35131 Padua, Italy.
C3 Aalborg University; University of Iceland; University of Padua
RP Turchet, L (corresponding author), Aalborg Univ, Dept Architecture Design & Media Technol, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
EM tur@create.aau.dk; spagnols@hi.is; geronazzo@dei.unipd.it;
   avanzini@dei.unipd.it
RI Turchet, Luca/M-9679-2013; Spagnol, Simone/D-7948-2014; Avanzini,
   Federico/HCI-9135-2022; Geronazzo, Michele/U-8886-2017
OI Turchet, Luca/0000-0003-0711-8098; Avanzini,
   Federico/0000-0002-1257-5878; Geronazzo, Michele/0000-0002-0621-2704;
   Spagnol, Simone/0000-0002-9309-0871
FU Danish Council for Independent Research [12-131985]
FX The work of the first author was supported by the Danish Council for
   Independent Research, Grant No. 12-131985.
CR Algazi V.R., 2001, IEEE WORKSHOP APPL S, P1
   Algazi VR, 2002, J ACOUST SOC AM, V112, P2053, DOI 10.1121/1.1508780
   Avanzini F., 2001, Proc. COST-G6 Conf. Digital Audio Effects (DAFX-01), P61
   Begault DR, 2001, J AUDIO ENG SOC, V49, P904
   Blauert J., 1983, SPATIAL HEARING PSYC
   Boren BB, 2014, P 137 AUD ENG SOC CO
   BURKHARD MD, 1975, J ACOUST SOC AM, V58, P214, DOI 10.1121/1.380648
   Caclin A, 2002, PERCEPT PSYCHOPHYS, V64, P616, DOI 10.3758/BF03194730
   Cheng CI, 2001, J AUDIO ENG SOC, V49, P231, DOI 10.1016/S0022-5096(00)00039-9
   Cook PR, 1997, COMPUT MUSIC J, V21, P38, DOI 10.2307/3681012
   Duda R. O., 2002, AUDIO ENG SOC CONVEN, V113
   Geronazzo M., 2013, P 134 AUD ENG SOC CO
   Geronazzo M., 2013, P 18 INT C DIG SIGN
   Geronazzo M., 2014, P IEEE INT C AC SPEE, P4496, DOI DOI 10.1109/ICASSP.2014.6854446
   Giordano BL, 2012, J ACOUST SOC AM, V131, P4002, DOI 10.1121/1.3699205
   HEBRANK J, 1974, J ACOUST SOC AM, V56, P1829, DOI 10.1121/1.1903520
   Howard I.P., 1966, Human Spatial Orientation
   HUNT KH, 1975, J APPL MECH-T ASME, V42, P440, DOI 10.1115/1.3423596
   Hwang S, 2008, ACTA ACUST UNITED AC, V94, P965, DOI 10.3813/AAA.918113
   Jousmäki V, 1998, CURR BIOL, V8, pR190, DOI 10.1016/S0960-9822(98)70120-4
   Kitagawa N, 2006, JPN PSYCHOL RES, V48, P158, DOI 10.1111/j.1468-5884.2006.00317.x
   Kobayashi Y, 2008, IEEE T NEUR SYS REH, V16, P99, DOI 10.1109/TNSRE.2007.910283
   Laurienti PJ, 2004, EXP BRAIN RES, V158, P405, DOI 10.1007/s00221-004-1913-2
   Middlebrooks JC, 1999, J ACOUST SOC AM, V106, P1480, DOI 10.1121/1.427176
   Moller H, 1996, J AUDIO ENG SOC, V44, P451
   Nordahl R, 2010, P IEEE VIRT REAL ANN, P147, DOI 10.1109/VR.2010.5444796
   Nordahl R, 2010, LECT NOTES COMPUT SC, V6192, P123, DOI 10.1007/978-3-642-14075-4_18
   Papetti S., 2011, Proceedings of international conference of new interfaces for musical expression, P473
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Rayleigh, 1904, PHILOS T R SOC LOND, V203, P87
   Serafin S., 2010, Proceedings of Eurohaptics, P61
   Slater M, 2009, ANU PSICOL, V40, P193
   Spagnol S, 2014, INT J PERVASIVE COMP, V10, P239, DOI 10.1108/IJPCC-06-2014-0035
   Spagnol S, 2013, IEEE T AUDIO SPEECH, V21, P508, DOI 10.1109/TASL.2012.2227730
   Stein Barry E., 1993, The Merging of the Senses. The Merging of the Senses. Cognitive Neuroscience
   Steinicke F, 2013, Human walking in virtual environments
   Thomas JP, 2010, J VISION, V10, DOI 10.1167/10.12.14
   Turchet Luca, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P269, DOI 10.1109/MMSP.2010.5662031
   Turchet L, 2010, P SOUND MUS COMP C
   Turchet L., 2015, APPL ACOUST IN PRESS
   Turchet L, 2015, VIRTUAL REA IN PRESS
   Turchet L, 2011, P DIG AUD EFF C, P53
   Turchet L, 2015, EXP BRAIN RES, V233, P205, DOI 10.1007/s00221-014-4104-9
   Turchet L, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2536764.2536770
   Turchet L, 2013, APPL ACOUST, V75, P59, DOI 10.1016/j.apacoust.2013.06.016
   Turchet L, 2013, APPL ACOUST, V74, P566, DOI 10.1016/j.apacoust.2012.10.010
   Visell Y, 2009, INT J HUM-COMPUT ST, V67, P947, DOI 10.1016/j.ijhcs.2009.07.007
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Vliegen J, 2004, J ACOUST SOC AM, V115, P1705, DOI 10.1121/1.1687423
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   Zanotto D, 2014, P IEEE RAS-EMBS INT, P193, DOI 10.1109/BIOROB.2014.6913775
NR 51
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2016
VL 20
IS 1
BP 1
EP 16
DI 10.1007/s10055-015-0272-6
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1FY
UT WOS:000376092000001
DA 2024-07-18
ER

PT J
AU Serino, S
   Triberti, S
   Villani, D
   Cipresso, P
   Gaggioli, A
   Riva, G
AF Serino, Silvia
   Triberti, Stefano
   Villani, Daniela
   Cipresso, Pietro
   Gaggioli, Andrea
   Riva, Giuseppe
TI Toward a validation of cyber-interventions for stress disorders based on
   stress inoculation training: a systematic review
SO VIRTUAL REALITY
LA English
DT Review
DE Stress inoculation training; Virtual reality; Validation; Stress
   management; Systematic review; Cyber-interventions
ID VIRTUAL-REALITY EXPOSURE; ANXIETY DISORDERS; HEALTH-PROMOTION; THERAPY;
   COMPUTER; INTERREALITY; TECHNOLOGY; PSYCHOTHERAPY; DEPRESSION;
   MANAGEMENT
AB New advanced technologies have recently emerged as a potentially effective way for delivering stress management techniques. Specifically, the stress inoculation training (SIT) represents a validated approach to manage stress in several settings, and research is growing related to this clinical protocol combined with advanced technologies. This review aims to outline the state of the art of cyber-interventions based on SIT methodology (cyber-SIT). In the current review, we deeply analyzed and discussed three aspects of the selected studies: (1) the type of technological devices used for delivering cyber-SIT; (2) the sampling strategies; (3) and the stress-related measures for assessing the effectiveness of cyber-SIT. The results of this systematic review suggest the potential efficacy of cyber-SIT for managing psychological stress in several settings. Considering cyber-SIT for psychological stress, controlled trials testing a greater number of participants are needed. Other future challenges include adopting better inclusion/exclusion criteria, standardized outcome measures, and different conditions for comparing the effect and/or the integration of different technological devices. In conclusion, as the cyber-SIT may play an important role in the future clinical psychology, it is crucial to enhance the validation of this approach from a methodological point of view.
C1 [Serino, Silvia; Cipresso, Pietro; Gaggioli, Andrea; Riva, Giuseppe] IRCCS Ist Auxol Italiano, Appl Technol Neuropsychol Lab, I-20149 Milan, MI, Italy.
   [Triberti, Stefano; Villani, Daniela; Gaggioli, Andrea; Riva, Giuseppe] Univ Cattolica Sacro Cuore, ICE NET, I-20100 Milan, MI, Italy.
C3 IRCCS Istituto Auxologico Italiano; Catholic University of the Sacred
   Heart
RP Serino, S (corresponding author), IRCCS Ist Auxol Italiano, Appl Technol Neuropsychol Lab, Via Pellizza da Volpedo 41, I-20149 Milan, MI, Italy.
EM s.serino@auxologico.it
RI Cipresso, Pietro/G-4676-2011; Gaggioli, Andrea/AAA-2678-2020; Triberti,
   Stefano/IAQ-0714-2023; Serino, Silvia/AAM-5297-2020; Riva,
   Giuseppe/C-5917-2008; Serino, Silvia/K-5142-2016
OI Cipresso, Pietro/0000-0002-0662-7678; Gaggioli,
   Andrea/0000-0001-7818-7598; Serino, Silvia/0000-0002-8422-1358; Riva,
   Giuseppe/0000-0003-3657-106X; Serino, Silvia/0000-0002-8422-1358;
   Triberti, Stefano/0000-0001-5691-5531
FU research project "NeuroVirtual 3D"; Regione Piemonte [FA 211-432C-2012];
    [FP7-247685]
FX The present work was supported by the European-funded project
   "Interstress"-Interreality in the management and treatment of
   stress-related disorders (FP7-247685) and by the research project
   "NeuroVirtual 3D," funded by Regione Piemonte (Grant No. FA
   211-432C-2012).
CR Ahuja MK, 1999, ORGAN SCI, V10, P741, DOI 10.1287/orsc.10.6.741
   Albentosa Marina, 1994, Aquaculture, V126, P315, DOI 10.1016/0044-8486(94)90048-5
   Andersson G, 2009, BEHAV RES THER, V47, P175, DOI 10.1016/j.brat.2009.01.010
   [Anonymous], 2009, J VIS EXP, DOI DOI 10.3791/1554
   [Anonymous], STUD HLTH TECHNOL IN
   [Anonymous], 2009, MULT LEARN 2 ED
   [Anonymous], 2006, NEO PI R PERSONALITY
   [Anonymous], VIRT REAL INT C VRIC
   [Anonymous], INVISIBLE WOUNDS NEW
   [Anonymous], FACE 2010 DELPHI POL
   [Anonymous], INVISIBLE WOUNDS NEW
   [Anonymous], MESURE STRESS PSYCHO
   [Anonymous], 2006, HDB ED PSYCHOL
   [Anonymous], FORMALNA CHARAKTERYS
   [Anonymous], INVISIBLE WOUNDS NEW
   [Anonymous], TEST M S P ALTRI STU
   Antoni MH, 2006, NAT REV CANCER, V6, P240, DOI 10.1038/nrc1820
   Bandura A, 1998, PSYCHOL HEALTH, V13, P623, DOI 10.1080/08870449808407422
   Bandura A, 2004, HEALTH EDUC BEHAV, V31, P143, DOI 10.1177/1090198104263660
   Barbieri R, 2002, AM J PHYSIOL-REG I, V283, pR1210, DOI 10.1152/ajpregu.00127.2002
   Becher EH, 2011, J LOSS TRAUMA, V16, P574, DOI 10.1080/15325024.2011.578021
   Bordnick PS, 2012, RES SOCIAL WORK PRAC, V22, P293, DOI 10.1177/1049731511426880
   Botella C, 2012, CYBERPSYCH BEH SOC N, V15, P78, DOI 10.1089/cyber.2011.0140
   Brown R L, 2001, J Am Board Fam Pract, V14, P95
   Bruning R.H., 2004, COGNITIVE PSYCHOL IN, V4th
   CARR AC, 1988, CAN J PSYCHIAT, V33, P112, DOI 10.1177/070674378803300208
   Carver CS, 1997, INT J BEHAV MED, V4, P92, DOI 10.1207/s15327558ijbm0401_6
   CECIL MA, 1990, J SCHOOL PSYCHOL, V28, P105, DOI 10.1016/0022-4405(90)90002-O
   Cleland J, 2007, J TELEMED TELECARE, V13, P85, DOI 10.1258/135763307780096230
   Cohen S, 2007, JAMA-J AM MED ASSOC, V298, P1685, DOI 10.1001/jama.298.14.1685
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Emmelkamp PMG, 2001, CYBERPSYCHOL BEHAV, V4, P335, DOI 10.1089/109493101300210222
   FOLEY FW, 1987, J CONSULT CLIN PSYCH, V55, P919, DOI 10.1037/0022-006X.55.6.919
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Free Caroline, 2010, BMC Res Notes, V3, P250, DOI 10.1186/1756-0500-3-250
   Free C, 2013, PLOS MED, V10, DOI [10.1371/journal.pmed.1001363, 10.1371/journal.pmed.1001362]
   Gaggioli A, 2011, STUD HEALTH TECHNOL, V163, P185, DOI 10.3233/978-1-60750-706-2-185
   Gates MA, 2012, PSYCHOL SERV, V9, P361, DOI 10.1037/a0027649
   Glantz K, 2003, PSYCHOTHERAPY, V40, P55, DOI 10.1037/0033-3204.40.1-2.55
   Gonçalves R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048469
   Gorini Alessandra, 2008, Expert Rev Neurother, V8, P215, DOI 10.1586/14737175.8.2.215
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Grassi A, 2011, STUD HEALTH TECHNOL, V167, P57, DOI 10.3233/978-1-60750-766-6-57
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   HOKANSON JE, 1968, J PERS, V36, P386, DOI 10.1111/j.1467-6494.1968.tb01481.x
   HOKANSON JE, 1971, J PERS SOC PSYCHOL, V19, P60, DOI 10.1037/h0031052
   Hourani L.L., 2011, Journal of CyberTherapy Rehabilitation, V4, P101
   Ilnicki S, 2012, STUD HEALTH TECHNOL, V181, P113, DOI 10.3233/978-1-61499-121-2-113
   Kay M., 2011, MHEALTH NEW HORIZONS
   Keane T.M., 1989, Psychological Assessment, V1, P53, DOI DOI 10.1037/1040-3590.1.1.53
   KIRSCHBAUM C, 1994, PSYCHONEUROENDOCRINO, V19, P313, DOI 10.1016/0306-4530(94)90013-2
   Kramer RM, 1999, ANNU REV PSYCHOL, V50, P569, DOI 10.1146/annurev.psych.50.1.569
   Kroenke K, 2002, PSYCHOSOM MED, V64, P258, DOI 10.1097/00006842-200203000-00008
   Lazarus RS, 1984, Stress, appraisal, and coping
   Leserman J, 2002, PSYCHOL MED, V32, P1059, DOI 10.1017/S0033291702005949
   Lewicki RJ, 2006, J MANAGE, V32, P991, DOI 10.1177/0149206306294405
   Mace R, 1986, Br J Sports Med, V20, P115
   Manzoni GM, 2009, J AM DIET ASSOC, V109, P1427, DOI 10.1016/j.jada.2009.05.004
   Marks IM, 2004, PSYCHOL MED, V34, P9, DOI 10.1017/S003329170300878X
   Mayer RE, 2003, WEB-BASED LEARNING: WHAT DO WE KNOW? WHERE DO WE GO?, P23
   Meichenbaum D., 1985, Stress inoculation training
   Meichenbaum D., 1977, Cognitive-behavior modification: An integrative approach
   Meyerbröker K, 2010, DEPRESS ANXIETY, V27, P933, DOI 10.1002/da.20734
   Miyahira SD, 2010, STUD HEALTH TECHNOL, V154, P82, DOI 10.3233/978-1-60750-561-7-82
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moore K, 1981, Cancer Nurs, V4, P389
   North MM, 1997, AM J PSYCHIAT, V154, P130
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Preziosa A, 2009, BRIT J GUID COUNS, V37, P313, DOI 10.1080/03069880902957031
   Proudfoot J, 2004, BRIT J PSYCHIAT, V185, P46, DOI 10.1192/bjp.185.1.46
   Repetto C, 2011, NEUROPSYCHIATRY-LOND, V1, P31, DOI 10.2217/NPY.11.5
   Repetto C, 2013, PERS UBIQUIT COMPUT, V17, P253, DOI 10.1007/s00779-011-0467-0
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Riva G., 2012, Being there: Understanding the feeling of presence in a synthetic environment and its potential for clinical change
   Riva Giuseppe, 2012, Stud Health Technol Inform, V173, P369
   Riva G, 2012, CYBERPSYCH BEH SOC N, V15, P69, DOI 10.1089/cyber.2011.0139
   Riva G, 2010, CYBERPSYCH BEH SOC N, V13, P55, DOI 10.1089/cyber.2009.0320
   Riva G, 2009, BRIT J GUID COUNS, V37, P337, DOI 10.1080/03069880902957056
   Riva G, 2007, STUD HEALTH TECHNOL, V125, P406
   Ross MJ, 1996, J CONSULT CLIN PSYCH, V64, P406, DOI 10.1037/0022-006X.64.2.406
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Rothbaum BO, 1999, J TRAUMA STRESS, V12, P263, DOI 10.1023/A:1024772308758
   Rozanski A, 1999, CIRCULATION, V99, P2192, DOI 10.1161/01.CIR.99.16.2192
   Russ TC, 2012, BMJ-BRIT MED J, V345, DOI 10.1136/bmj.e4933
   Saunders T, 1996, J Occup Health Psychol, V1, P170, DOI 10.1037/1076-8998.1.2.170
   Scherer KR, 2001, SOC SCI INFORM, V40, P125, DOI 10.1177/053901801040001007
   Schum JL, 2003, J BEHAV MED, V26, P395, DOI 10.1023/A:1025767900757
   Spielberger C., 1970, STAI manual for the Stait -Trait Anxiety Inventory, DOI DOI 10.1037/T06496-000
   Spielberger C.D., 1991, MANUAL STATE TRAIT A
   Stetz MC, 2007, AVIAT SPACE ENVIR MD, V78, pB252
   Stetz MC, 2007, ANN REV CYBERTHERAPY, V5, P192
   Stetz MC, 2011, MIL MED, V176, P1065, DOI 10.7205/MILMED-D-10-00393
   Storr A., 1990, The art of psychotherapy
   Strelau J, 2005, Kwestionariusz Radzenia Sobie w Sytuacjach Stresowych CISS
   Timmons PL, 1997, COMPUT HUM BEHAV, V13, P51, DOI 10.1016/S0747-5632(96)00029-5
   Tuunainen A, 2001, PSYCHIAT RES, V103, P261, DOI 10.1016/S0165-1781(01)00278-5
   Vakili V, 2012, STUD HEALTH TECHNOL, V181, P22, DOI 10.3233/978-1-61499-121-2-22
   Villani D., 2007, Int. J. Stress Manag. Copyr, V14, P260, DOI [DOI 10.1037/1072-5245.14.3.260, 10.1037/1072-5245.14.3.260https://dx.doi.org/10.1037/1072-5245.14.3.260, DOI 10.1037/1072-5245.14.3.260HTTPS://DX.DOI.ORG/10.1037/1072-5245.14.3.260]
   Villani D, 2013, PSYCHOL SERV, V10, P315, DOI 10.1037/a0026459
   Villani D, 2012, CYBERPSYCH BEH SOC N, V15, P24, DOI 10.1089/cyber.2011.0141
   Vincelli F, 1999, Cyberpsychol Behav, V2, P241, DOI 10.1089/cpb.1999.2.241
   VONBAEYER C, 1983, INT J PSYCHIAT MED, V13, P113, DOI 10.2190/WPV9-0Y55-55TX-FMX1
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weathers F., 1994, The PTSD checklist-civilian version (PCL-C)
   Weathers F., 1991, PTSD CHECKLIST MILIT
   Wiederhold B.K., 2008, Journal of CyberTherapy Rehabilitation, V1, P23
   Wiederhold BK, 2003, CYBERPSYCHOL BEHAV, V6, P441, DOI 10.1089/109493103322278844
   Wiederhold BK, 2006, CYBERPSYCHOL BEHAV, V9, P727
   Zuckerman M., 1965, MANUAL MULTIPLE AFFE
NR 109
TC 46
Z9 49
U1 1
U2 38
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2014
VL 18
IS 1
SI SI
BP 73
EP 87
DI 10.1007/s10055-013-0237-6
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AB2WI
UT WOS:000331652400007
DA 2024-07-18
ER

PT B
AU Bouchard, S
   Labonté-Chartrand, G
AF Bouchard, Stephane
   Labonte-Chartrand, Genevieve
BE Kim, JJ
TI Emotions and the Emotional Valence Afforded by the Virtual Environment
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID MOOD INDUCTION PROCEDURES; REALITY EXPOSURE THERAPY; ANXIETY; IMMERSION
C1 [Bouchard, Stephane; Labonte-Chartrand, Genevieve] Univ Quebec Outaouais, Gatineau, ON, Canada.
C3 University of Quebec; University Quebec Outaouais
RP Bouchard, S (corresponding author), Univ Quebec Outaouais, Gatineau, ON, Canada.
CR Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Bouchard S., 2008, PRESENCE TELEOPERATO
   Bouchard S., 2006, HDB EXPOSURE, V347-388
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Cote S., 2008, Journal of Cyber Therapy and Rehabilitation, V1, P75
   Gerardi M, 2010, CURR PSYCHIAT REP, V12, P298, DOI 10.1007/s11920-010-0128-4
   GERRARDSHESSE A, 1994, BRIT J PSYCHOL, V85, P55, DOI 10.1111/j.2044-8295.1994.tb02508.x
   Gilet AL, 2008, ENCEPHALE, V34, P233, DOI 10.1016/j.encep.2006.08.003
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   MARTIN M, 1990, CLIN PSYCHOL REV, V10, P669, DOI 10.1016/0272-7358(90)90075-L
   MAYER JD, 1988, J PERS SOC PSYCHOL, V55, P102, DOI 10.1037/0022-3514.55.1.102
   Michaud M., 2004, CYB C 2004 SAN DIEG
   Moore K, 2002, CYBERPSYCHOL BEHAV, V5, P197, DOI 10.1089/109493102760147178
   PRATT DR, 1995, COMPUTER, V28, P17
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Sadowski W, 2002, HUM FAC ER, P791
   VELTEN E, 1968, BEHAV RES THER, V6, P473, DOI 10.1016/0005-7967(68)90028-4
   Westermann R, 1996, EUR J SOC PSYCHOL, V26, P557, DOI 10.1002/(SICI)1099-0992(199607)26:4<557::AID-EJSP769>3.0.CO;2-4
   Wiederhold B K, 1999, Cyberpsychol Behav, V2, P161, DOI 10.1089/cpb.1999.2.161
   Wiederhold B.K., 2005, Virtual reality therapy for anxiety disorders: Advances in evaluation and treatment
   Wiederhold BK, 2000, CYBERPSYCHOL BEHAV, V3, P393, DOI 10.1089/10949310050078841
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 26
TC 4
Z9 4
U1 0
U2 3
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 501
EP 514
D2 10.5772/553
PG 14
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400025
DA 2024-07-18
ER

PT B
AU Moraes, RM
   Machado, LS
AF Moraes, Ronei M.
   Machado, Liliane S.
BE Kim, JJ
TI Development of a Medical Training System with Integration of Users'
   Skills Assessment
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID VIRTUAL-REALITY; LAPAROSCOPIC SURGERY; PERFORMANCE; SIMULATION;
   PALPATION; VR
C1 [Moraes, Ronei M.; Machado, Liliane S.] Univ Fed Paraiba, BR-58059900 Joao Pessoa, Paraiba, Brazil.
C3 Universidade Federal da Paraiba
RP Moraes, RM (corresponding author), Univ Fed Paraiba, BR-58059900 Joao Pessoa, Paraiba, Brazil.
RI Machado, Liliane S/K-5340-2014; de Moraes, Ronei Marcos/AAE-8156-2019
CR [Anonymous], P WORLD C COMP SCI E
   [Anonymous], P 40 CAN C ART INT
   [Anonymous], P SAF ENV WORLD C 20
   [Anonymous], P 6 INT C ENG COMP E
   [Anonymous], ARTIFICIAL INTELLIGE
   [Anonymous], 1965, INF CONTROL
   [Anonymous], P INT C ENG TECHN ED
   [Anonymous], P GLOB C ENG TECHN E
   [Anonymous], COMPUTER, DOI DOI 10.1109/2.53
   [Anonymous], P WORLD C COMP SCI E
   [Anonymous], P SAF HLTH ENV WORLD
   [Anonymous], P 6 INT C TECHN MED
   [Anonymous], STUDIES HLTH TECHNOL
   [Anonymous], THESIS U SAO PAULO
   [Anonymous], P GLOB C ENG TECHN E
   [Anonymous], THESIS RUTGERS U
   [Anonymous], P 9 INT FLINS C FDN
   [Anonymous], FUZZY RULE BASED EVA
   [Anonymous], 2010, COMP INT COMPLEX DEC
   Burdea G, 1998, P IEEE VIRT REAL ANN, P190, DOI 10.1109/VRAIS.1998.658489
   Burdea G. C., 2003, Virtual reality technology
   Corra C. G., 2009, P 2009 ACM S APPL CO, P821, DOI [DOI 10.1145/1529282.1529457, https://doi.org/10.1145/1529282.1529457]
   Darzi A, 1999, BRIT MED J, V318, P887, DOI 10.1136/bmj.318.7188.887
   Derossis AM, 1998, AM J SURG, V175, P482, DOI 10.1016/S0002-9610(98)00080-4
   Dinsmore M, 1997, P IEEE VIRT REAL ANN, P54, DOI 10.1109/VRAIS.1997.583044
   Dubois D, 1980, Fuzzy sets and systems
   Dubois D., 1988, Possibility Theory: an Approach to Computerized Processing of Uncertainty
   Duda R., 1973, Pattern Classification and Scene Analysis
   Färber M, 2008, STUD HEALTH TECHNOL, V132, P112
   Gallagher AG, 2005, ANN SURG, V241, P364, DOI 10.1097/01.sla.0000151982.85062.80
   Gallagher AG, 1999, ENDOSCOPY, V31, P310
   Gallagher AG, 2001, WORLD J SURG, V25, P1478, DOI 10.1007/s00268-001-0133-1
   Huang J, 2005, STUD HEALTH TECHNOL, V111, P194
   Johnson R.A., 2001, APPL MULTIVARIATE ST, V5th
   Krause PJ, 1998, KNOWL ENG REV, V13, P321, DOI 10.1017/S0269888998004019
   Langrana N, 1997, COMPUT GRAPH, V21, P451, DOI 10.1016/S0097-8493(97)00021-6
   Machado LD, 2008, J MULT-VALUED LOG S, V14, P511
   Machado LS, 2009, STUD HEALTH TECHNOL, V142, P168, DOI 10.3233/978-1-58603-964-6-168
   Machado LS, 2009, STUD HEALTH TECHNOL, V142, P174, DOI 10.3233/978-1-58603-964-6-174
   Mackel T, 2006, STUD HEALTH TECHNOL, V119, P355
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   McBeth PB, 2002, ST HEAL T, V85, P280
   McCloy R, 2001, BRIT MED J, V323, P912, DOI 10.1136/bmj.323.7318.912
   Moraes RM, 2007, LECT NOTES COMPUT SC, V4756, P950
   Neapolitan R., 2003, Learning Bayesian networks, P543
   Souza Daniel FL, 2007, PROC S VIRTUAL AUGME, P100
   Taffinder N, 1998, ST HEAL T, V50, P124
   Wilson MS, 1997, ANN ROY COLL SURG, V79, P403
NR 48
TC 7
Z9 7
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 325
EP 348
D2 10.5772/553
PG 24
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400016
DA 2024-07-18
ER

PT J
AU Sung, WH
   Jiang, CF
   Su, TS
   Sun, SP
AF Sung, Wen-Hsu
   Jiang, Ching-Fen
   Su, Tai-Sin
   Sun, Shuh-Ping
TI A virtual positioning system for external beam radiotherapy
SO VIRTUAL REALITY
LA English
DT Article
DE Radiation treatment planning; Positioning verification; Virtual
   simulation; Image registration
ID RADIATION; REGISTRATION; REALITY; CT
AB In radiation therapy, positioning patients to ensure the accuracy of the setup of a procedure is a routine and labour-intensive process that substantially determines the efficacy of treatment. In this study, we propose a virtual positioning system that can simulate the positioning process with a visible beam path under the broad view of a life-like patient-positioning platform to obviate problems with excessively narrow view. This system integrates image processing, computer graphics, and virtual reality to encompass a 3D treatment target reconstructed from medical images of different modalities in a virtual scene. An innovative evaluation method is further proposed to verify the efficacy of the system using a full-scale 3D solid anthropometric model, and a treatment target showed an accuracy of 99% in calibration and a mean compatibility of 95% with an actual measurement. The proposed virtual positioning system provides a training and education platform for radiation therapy. The methodology through which the system was developed is also disclosed as a promising approach to improve the efficiency and safety of the position verification process for existing systems.
C1 [Sung, Wen-Hsu; Jiang, Ching-Fen; Su, Tai-Sin; Sun, Shuh-Ping] Natl Yang Ming Chiao Tung Univ, Dept Phys Therapy & Assist Technol, Taipei, Taiwan.
   [Sung, Wen-Hsu; Jiang, Ching-Fen; Su, Tai-Sin; Sun, Shuh-Ping] I Shou Univ, Grad Program Smart Healthcare & Bioinformat, Kaohsiung, Taiwan.
   [Sung, Wen-Hsu; Jiang, Ching-Fen; Su, Tai-Sin; Sun, Shuh-Ping] I Shou Univ, Dept Biomed Engn, Kaohsiung, Taiwan.
   [Sung, Wen-Hsu; Jiang, Ching-Fen; Su, Tai-Sin; Sun, Shuh-Ping] I Shou Univ, Dept Digital Media Design, Kaohsiung, Taiwan.
C3 National Yang Ming Chiao Tung University; I Shou University; I Shou
   University; I Shou University
RP Jiang, CF (corresponding author), Natl Yang Ming Chiao Tung Univ, Dept Phys Therapy & Assist Technol, Taipei, Taiwan.; Jiang, CF (corresponding author), I Shou Univ, Grad Program Smart Healthcare & Bioinformat, Kaohsiung, Taiwan.; Jiang, CF (corresponding author), I Shou Univ, Dept Biomed Engn, Kaohsiung, Taiwan.; Jiang, CF (corresponding author), I Shou Univ, Dept Digital Media Design, Kaohsiung, Taiwan.
EM cfjiang@isu.edu.tw
CR Aznar M, 2021, BRIT J RADIOL, V94, DOI 10.1259/bjr.20210618
   Boejen A, 2011, SURG ONCOL, V20, P185, DOI 10.1016/j.suronc.2010.07.004
   Chao K., 2011, Radiation Oncology Management Decisions, V3rd
   Dawson LA, 2006, LANCET ONCOL, V7, P848, DOI 10.1016/S1470-2045(06)70904-4
   EKOULE AB, 1991, ACM T GRAPHIC, V10, P182, DOI 10.1145/108360.108363
   Fiorino C, 2020, MOL ONCOL, V14, P1500, DOI 10.1002/1878-0261.12659
   Fujita H, 2010, RADIOL PHYS TECHNOL, V3, P46, DOI 10.1007/s12194-009-0075-0
   GOITEIN M, 1983, INT J RADIAT ONCOL, V9, P789, DOI 10.1016/0360-3016(83)90003-2
   GOITEIN M, 1983, INT J RADIAT ONCOL, V9, P777, DOI 10.1016/0360-3016(83)90002-0
   Guo W, 2020, IEEE INT SYM MED MEA, DOI 10.1109/memea49120.2020.9137355
   Hamza-Lup FG, 2015, WEB3D 2015, P107, DOI 10.1145/2775292.2775294
   Hamza-Lup FG, 2008, INT J COMPUT ASS RAD, V3, P275, DOI 10.1007/s11548-008-0232-7
   Hamza-Lup FG., 2007, ADV IMAG ONCOL ADM, V17, P64
   Hill F.S., 2008, COMPUTER GRAPHICS US, V3rd
   Jiang CF, 2009, IFMBE PROC, V23, P1019
   Jiang CF, 2008, COMPUT BIOL MED, V38, P90, DOI 10.1016/j.compbiomed.2007.07.005
   Jiang CF, 2012, MULTIDIM SYST SIGN P, V23, P437, DOI 10.1007/s11045-011-0162-3
   Jiang CF, 2011, J MED BIOL ENG, V31, P217, DOI 10.5405/jmbe.677
   Khamene A, 2006, MED IMAGE ANAL, V10, P96, DOI 10.1016/j.media.2005.06.002
   Miao JJ, 2020, J APPL CLIN MED PHYS, V21, P65, DOI 10.1002/acm2.12915
   Ntasis E, 2005, COMPUT BIOL MED, V35, P765, DOI 10.1016/j.compbiomed.2004.06.007
   Ntasis E, 2002, IEEE T BIO-MED ENG, V49, P1444, DOI 10.1109/TBME.2002.805450
   Organization WH, 2017, WHO LIST PRIOR MED D
   Owrangi AM, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaaca4
   Phillips R, 2008, STUD HEALTH TECHNOL, V132, P366
   Su TS, 2005, P ANN INT IEEE EMBS, P6104, DOI 10.1109/IEMBS.2005.1615886
   Tai-Sin Su, 2005, Journal of Medical and Biological Engineering, V25, P61
   Videtic G., 2011, Handbook of treatment planning in radiation oncology, V1st
   Webb S., 1993, PHYS 3 DIMENSIONAL R
   Xing L, 2006, MED DOSIM, V31, P91, DOI 10.1016/j.meddos.2005.12.004
   Zhou ZY, 2019, VIRTUAL REAL-LONDON, V23, P347, DOI 10.1007/s10055-018-0350-7
NR 31
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2569
EP 2582
DI 10.1007/s10055-023-00833-9
EA JUL 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001023969700001
DA 2024-07-18
ER

PT J
AU Kim, W
   Xiong, SP
AF Kim, Woojoo
   Xiong, Shuping
TI ViewfinderVR: configurable viewfinder for selection of distant objects
   in VR
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Selection techniques; Mid-air interaction; Task
   performance; Workload
ID 3D SELECTION; FITTS LAW; PERFORMANCE; USABILITY; DESIGN; INPUT; AGE
AB Selection is one of the fundamental user interactions in virtual reality (VR) and 3D user interaction, and raycasting has been one of the most popular object selection techniques in VR. However, the selection of small or distant objects through raycasting has been known to be difficult. To overcome this limitation, this study proposed a new technique called ViewfinderVR for improved selection of distant objects in VR, utilizing a virtual viewfinder panel with a modern adaptation of the through-the-lens metaphor. ViewfinderVR enables faster and more accurate target selection by allowing customization of the interaction space projected onto a virtual panel within reach, and users can select objects reflected on the panel with either ray-based or touch interaction. Experimental results of Fitts' law-based tests with 20 participants showed that ViewfinderVR outperformed traditional raycasting in terms of task performance (movement time, error rate, and throughput) and perceived workload (NASA-TLX ratings), where touch interaction was superior to ray-based interaction. The associated user behavior was also recorded and analyzed to understand the underlying reasons for the improved task performance and reduced workload. The proposed technique can be used in VR applications to enhance the selection of distant objects.
C1 [Kim, Woojoo; Xiong, Shuping] Korea Adv Inst Sci & Technol KAIST, Coll Engn, Dept Ind & Syst Engn, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Xiong, SP (corresponding author), Korea Adv Inst Sci & Technol KAIST, Coll Engn, Dept Ind & Syst Engn, 291 Daehak Ro, Daejeon 34141, South Korea.
EM xml1324@kaist.ac.kr; shupingx@kaist.ac.kr
RI Xiong, Shuping/G-3073-2016; Kim, Woojoo/HTL-8595-2023
OI Xiong, Shuping/0000-0003-1549-515X; Kim, Woojoo/0000-0001-6203-7309
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Science, ICT and Future Planning
   [NRF-2020R1F1A1048510]; KAIST Faculty Research Fund [A0601003029]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Science, ICT and Future Planning (NRF-2020R1F1A1048510), and the KAIST
   Faculty Research Fund (A0601003029).
CR Andujar C, 2007, COMPUT GRAPH-UK, V31, P15, DOI 10.1016/j.cag.2006.09.003
   Argelaguet F., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P163
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Bacim F, 2013, INT J HUM-COMPUT ST, V71, P785, DOI 10.1016/j.ijhcs.2013.03.003
   Baloup, 2019, C HUM FACT COMP SYST
   Batmaz Anil Ufuk, 2021, FUTURE TECHNOLOGIES, V2, P792, DOI [10.1007/978-3-030-63089-8_52, DOI 10.1007/978-3-030-63089-8_52, 10.1007]
   Boring S, 2009, 21 ANN C AUSTR COMP, P161
   Bowman D., 2001, USING PINCH GLOVES T
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 1997, PROCEEDINGSVIRTUAL R, P4552
   Brasier E, 2020, INT SYM MIX AUGMENT, P332, DOI 10.1109/ISMAR50242.2020.00060
   Browning Graeme, 2014, CHI 14 HUM FACT COMP, P2053
   Brucker B, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106708
   Cashion J, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P107, DOI 10.1109/3DUI.2013.6550205
   Cashion J, 2012, IEEE T VIS COMPUT GR, V18, P634, DOI 10.1109/TVCG.2012.40
   Charness N, 2004, HUM FACTORS, V46, P373, DOI 10.1518/hfes.46.3.373.50396
   Clergeaud D, 2017, IEEE SYMP 3D USER, P2, DOI 10.1109/3DUI.2017.7893311
   Cockburn A, 2011, INT J HUM-COMPUT ST, V69, P401, DOI 10.1016/j.ijhcs.2011.02.005
   Cohen J., 1988, STAT POWER ANAL BEHA
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI DOI 10.2312/EGVE/IPT_EGVE2005/201-209
   Evangelista Belo JM, 2021, P 2021 CHI C HUM FAC, P1
   Facebook, 2021, OCULUS DEV
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Forlines C, 2007, P SIGCHI C HUMAN FAC
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   FREES S, 2007, ACM T COMPUT-HUM INT, V14, P1, DOI DOI 10.1145/1229855.1229857
   Gallo L, 2010, 2010 INT C COMPLEX I
   Grossman T., 2006, P UIST 2006, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Grossman Tovi., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '05, P281, DOI [10.1145/1054972.1055012, DOI 10.1145/1054972.1055012]
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   HART S G, 1988, P139
   Herndon KP., 1994, ACM SIGCHI B, V10
   Hincapi-Ramos JD, 2014, P SIGCHI C HUMAN FAC
   Hourcade Juan Pablo, 2012, P SIGCHI C HUM FACT, P213, DOI DOI 10.1145/2207676.2207706
   Hwang F, 2013, ACM T ACCESS COMPUT, V5, DOI 10.1145/2514848
   International Organization for Standardization, 2002, ISO 9241-9
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   JOTA R, 2010, P GRAPHICS INTERFACE
   Kia K, 2021, APPL ERGON, V97, DOI 10.1016/j.apergo.2021.103502
   Kiana Kia, 2020, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V64, DOI 10.1177/1071181320641510
   Kim JH, 2020, APPL ERGON, V88, DOI 10.1016/j.apergo.2020.103175
   Kin K., 2009, Proceedings of Graphics Interface 2009, P119
   König WA, 2009, LECT NOTES COMPUT SC, V5726, P658, DOI 10.1007/978-3-642-03655-2_73
   Kopper R, 2011, 3DUI 2011 IEEE S 3D
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee SY, 2003, PROC SPIE, V4756, P38, DOI 10.1117/12.497665
   Lee YH, 2013, HUM MOVEMENT SCI, V32, P511, DOI 10.1016/j.humov.2012.02.001
   Lemmerman DK, 2007, PROCEEDINGSIEEE VIRT
   Li JL, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P120, DOI 10.1145/3267782.3267797
   Li N, 2022, PSYCHOL HEALTH MED, V27, P2229, DOI 10.1080/13548506.2021.1990363
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Lin J, 2019, INT J HUM-COMPUT INT, V35, P1729, DOI 10.1080/10447318.2019.1571783
   Lindeman RW, 1999, PROCEEDINGSVIRTUAL R
   List C, 2019, LECT NOTES COMPUT SC, V11748, P669, DOI 10.1007/978-3-030-29387-1_39
   Liu Z, 2018, P 7 ACM INT S PERVAS, P19
   Lou XL, 2018, INT J HUM-COMPUT INT, V34, P519, DOI 10.1080/10447318.2017.1370811
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   MACKENZIE CL, 1987, Q J EXP PSYCHOL-A, V39, P629, DOI 10.1080/14640748708401806
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   MacKenzie IS, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1633
   McGuffin M. J., 2005, ACM Transactions on Computer-Human Interaction, V12, P388, DOI 10.1145/1121112.1121115
   McLaughlin AC, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502802
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Moore AG, 2018, INT J HUM-COMPUT ST, V120, P36, DOI 10.1016/j.ijhcs.2018.07.003
   Murata A, 2005, HUM FACTORS, V47, P767, DOI 10.1518/001872005775570952
   Nunnari F, 2016, P 9 INT C MOT GAM, P155
   Ortega M, 2013, IEEE S 3D USER INTER
   Penumudi SA, 2020, APPL ERGON, V84, DOI 10.1016/j.apergo.2019.103010
   Perea P., 2020, PROC INT C ADV VIS I, P1
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Ramcharitar A, 2018, P GRAPHICS INTERFACE, P114
   Reed CL, 2006, J EXP PSYCHOL HUMAN, V32, P166, DOI 10.1037/0096-1523.32.1.166
   Scott MacKenzie I., 2015, Human-Computer Interaction. Interaction Technologies. 17th International Conference, HCI International 2015. Proceedings: LNCS 9170, P238, DOI 10.1007/978-3-319-20916-6_23
   SEARS A, 1991, INT J MAN MACH STUD, V34, P593, DOI 10.1016/0020-7373(91)90037-8
   Shin GS, 2011, ERGONOMICS, V54, P733, DOI 10.1080/00140139.2011.592604
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Steed A, 2006, 3DUI 2006 IEEE S 3D
   Steed Anthony, 2004, 8 INT IMM PROJ TECHN, V2
   Steinicke F, 2006, COMPUT IMAGING VIS, V32, P320, DOI 10.1007/1-4020-4179-9_46
   Stephenson ML, 2020, HUM FACTORS, V62, P589, DOI 10.1177/0018720819852509
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Stoev Stanislav L., 2002, P ACM S VIRTUAL REAL, P57, DOI [10.1145/585740.585751, DOI 10.1145/585740.585751]
   Surale HB, 2019, P 2019 CHI C HUMAN F, P113
   Tao D, 2021, APPL ERGON, V93, DOI 10.1016/j.apergo.2021.103370
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Teather RJ, 2013, P SIGCHI C HUM FACT
   Tseng P, 2011, EXP BRAIN RES, V209, P257, DOI 10.1007/s00221-011-2544-z
   Vanacken L, 2007, 2007 IEEE S 3D USER
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Ware C., 1997, ACM Transactions on Computer-Human Interaction, V4, P309, DOI 10.1145/267135.267136
   Watson D., 2013, P 2013 ACM INT C INT, P199, DOI [DOI 10.1145/2512349.2512819, https://doi.org/10.1145/2512349.2512819]
   Weise Matthias, 2020, i-com: Journal of Interactive Media, V19, P67, DOI 10.1515/icom-2020-0011
   Wickens C., 1980, ATTENTION PERFORM
   Wingrave C. A., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P63
   Wingrave CA, 2006, 3D USER INTERFACES 3, P1116
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376876
   Yang XD, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2585
   Yang Z, 2019, APPL ERGON, V78, P164, DOI 10.1016/j.apergo.2019.03.006
   Zhou XZ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12101723
NR 103
TC 5
Z9 6
U1 10
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1573
EP 1592
DI 10.1007/s10055-022-00649-z
EA MAY 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000791673000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Al-Jundi, HA
   Tanbour, EY
AF Al-Jundi, Hamza A.
   Tanbour, Emad Y.
TI A framework for fidelity evaluation of immersive virtual reality systems
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Fidelity; Collaborative; Immersion; Digital sensory
   system; Tracking system; Simulation
ID ENVIRONMENTS; EXPERIENCE; SIMULATION; DISPLAY; DESIGN
AB Developments in visual and tracking systems have expanded virtual reality (VR) applications and led to VR becoming a powerful tool for decision making, planning, and conducting training and experiments across several fields. VR's goal is to fully immerse a user in a virtual environment through simulating the same kinds of physical and psychological reactions they would experience in the real world. Fidelity is a common and useful concept for distinguishing different VR systems, as a common goal for VR is to provide a high-fidelity experience similar to the real world. The purpose of this study was to provide a comprehensive framework and a scale for evaluating the fidelity of VR systems by addressing their architecture and the factors that affect overall fidelity with respect to the digital sensory and tracking systems used. The proposed framework characterizes itself from other fidelity evaluation frameworks in the involvement of integration and synchronization of VR system data and devices as the main factors in fidelity evaluation. Also, it presents a scale for fidelity evaluation of VR systems and defines high-level useful concepts for distinguishing different VR systems with respect to fidelity.
C1 [Al-Jundi, Hamza A.; Tanbour, Emad Y.] Eastern Michigan Univ EMU, GameAbove Coll Engn & Technol, Ypsilanti, MI 48197 USA.
RP Tanbour, EY (corresponding author), Eastern Michigan Univ EMU, GameAbove Coll Engn & Technol, Ypsilanti, MI 48197 USA.
EM haljundi@emich.edu; etanbour@emich.edu
OI Al-Jundi, Hamza/0000-0002-5287-7061
FU Eastern Michigan University
FX This work was funded by Eastern Michigan University.
CR Aggarwal R, 2007, ANN SURG, V246, P771, DOI 10.1097/SLA.0b013e3180f61b09
   Becher A, 2018, ARXIV180906320
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Cabrera ME, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00008
   Carmack J., 2013, LATENCY MITIGATION
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dmitrenko D, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P171, DOI 10.1145/3132272.3134121
   Elor Aviv, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3396249
   Franzluebbers A, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P16, DOI 10.1145/3267782.3267790
   Frithioff A, 2020, EUR ARCH OTO-RHINO-L, V277, P1335, DOI 10.1007/s00405-020-05858-3
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Grajewski D, 2013, PROCEDIA COMPUT SCI, V25, P289, DOI 10.1016/j.procs.2013.11.035
   Grant P, 2007, J AIRCRAFT, V44, P927, DOI 10.2514/1.25807
   Grimshaw Mark., 2014, The Oxford Handbook of Virtuality
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Harrison NR, 2010, J VISION, V10, DOI 10.1167/10.14.16
   Hoedt S, 2017, INT J PROD RES, V55, P7496, DOI 10.1080/00207543.2017.1374572
   Hontvedt M, 2020, COMPUT SUPP COOP W J, V29, P85, DOI 10.1007/s10606-019-09367-8
   Jang W, 2016, COMPUT METH PROG BIO, V135, P115, DOI 10.1016/j.cmpb.2016.07.026
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Kerruish E, 2019, SENSES SOC, V14, P31, DOI 10.1080/17458927.2018.1556952
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Knecht M, 2012, COMPUT GRAPH-UK, V36, P846, DOI 10.1016/j.cag.2012.04.013
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Liu HX, 2019, IEEE INT CONF ROBOT, P5180, DOI [10.1109/icra.2019.8794230, 10.1109/ICRA.2019.8794230]
   Liu KY, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1881
   Maran NJ, 2003, MED EDUC, V37, P22, DOI 10.1046/j.1365-2923.37.s1.9.x
   McMahan RyanP., 2016, FRONTIERS ICT, V3, DOI DOI 10.3389/FICT.2016.00029
   Menzies RJ, 2016, VIRTUAL REAL-LONDON, V20, P173, DOI 10.1007/s10055-016-0288-6
   Meyer GF, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044381
   Meyer GF, 2005, EXP BRAIN RES, V166, P538, DOI 10.1007/s00221-005-2394-7
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Ni T, 2006, PROC GRAPH INTERF, P139
   Norman Donald A., 2010, interactions, V17, P6, DOI [DOI 10.1145/1744161.1744163, 10.1145/1744161.1744163]
   Oviatt S., 2004, P 6 INT C MULT INT, P129, DOI DOI 10.1145/1027933.1027957
   Pala P, 2021, ACCIDENT ANAL PREV, V152, DOI 10.1016/j.aap.2021.106004
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Pastel S, 2021, VIRTUAL REAL-LONDON, V25, P175, DOI 10.1007/s10055-020-00449-3
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rey B, 2010, VIRTUAL REAL-LONDON, V14, P55, DOI 10.1007/s10055-009-0141-2
   Rheingold H., 1991, VIRTUAL REAL-LONDON
   Richardson Douglas, 2017, INT ENCY GEOGRAPHY, V15th
   Rogers K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300644
   Rouby C, 2002, OLFACTION, TASTE, AND COGNITION, P140, DOI 10.1017/CBO9780511546389.015
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Shi Y., 2007, CHI 07 EXTENDED ABST, P2651, DOI DOI 10.1145/1240866.1241057
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Srivastava P, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00050
   Trepkowski C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P575, DOI [10.1109/vr.2019.8798312, 10.1109/VR.2019.8798312]
   van der Kruk E, 2018, EUR J SPORT SCI, V18, P806, DOI 10.1080/17461391.2018.1463397
   Volonte M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P141, DOI 10.1145/3308532.3329461
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolfartsberger J, 2019, AUTOMAT CONSTR, V104, P27, DOI 10.1016/j.autcon.2019.03.018
   Won AS, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4070052
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
   Youngblut C., 2003, Experience of presence in virtual environments
   Zizza C, 2018, CONSUM COMM NETWORK
NR 71
TC 15
Z9 16
U1 1
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1103
EP 1122
DI 10.1007/s10055-021-00618-y
EA JAN 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000742979800001
DA 2024-07-18
ER

PT J
AU Pellas, N
   Mystakidis, S
   Kazanidis, I
AF Pellas, Nikolaos
   Mystakidis, Stylianos
   Kazanidis, Ioannis
TI Immersive Virtual Reality in K-12 and Higher Education: A systematic
   review of the last decade scientific literature
SO VIRTUAL REALITY
LA English
DT Review
DE Immersive technologies; Virtual reality; Human&#8211; computer
   interface; Simulations; Systematic review
ID SCIENCE; PERCEPTIONS
AB There has been an increasing interest in applying immersive virtual reality (VR) applications to support various instructional design methods and outcomes not only in K-12 (Primary and Secondary), but also in higher education (HE) settings. However, there is a scarcity of studies to provide the potentials and challenges of VR-supported instructional design strategies and/or techniques that can influence teaching and learning. This systematic review presents a variety of studies that provide qualitative and/or quantitative data to investigate the current practices with VR support focusing on students' outcomes, performance, alongside with the benefits and challenges of this technology concerning the analysis of visual features and design elements with mobile and desktop computing devices in different learning subjects. During the selection and screening process, forty-six (n = 46) articles published from the middle of 2009 until the middle of 2020 were finally included for a detailed analysis and synthesis of which twenty-one and twenty-five in K-12 and HE, respectively. The majority of studies were focused on describing and evaluating the appropriateness or the effectiveness of the applied instructional design processes using various VR applications to disseminate their findings on user experience, usability issues, students' outcomes, and/or learning performance. This study contributes by reviewing how instructional design strategies and techniques can potentially benefit students' learning performance using a wide range of VR applications. It also proposes some recommendations to guide and lead effective instructional design settings in several teaching and learning contexts to outline a more accurate and up-to-date picture of the current state of literature.
C1 [Pellas, Nikolaos] Univ Western Macedonia, Dept Commun & Digital Media, Fourka 52100, Kastoria, Greece.
   [Mystakidis, Stylianos] Univ Patras, Sch Nat Sci, Rion Achaia 26504, Greece.
   [Kazanidis, Ioannis] Int Hellen Univ, Adv Educ Technol & Mobile Applicat Lab, Ag Loukas 65404, Kavala, Greece.
C3 University of Patras
RP Pellas, N (corresponding author), Univ Western Macedonia, Dept Commun & Digital Media, Fourka 52100, Kastoria, Greece.
EM aff00192@uowm.gr; smyst@upatras.gr; kazanidis@teiemt.gr
RI Mystakidis, Stylianos/AAC-5678-2021; Pellas, Nikolaos/S-8996-2016
OI Mystakidis, Stylianos/0000-0002-9162-8340; Pellas,
   Nikolaos/0000-0002-3071-6275; Kazanidis, Ioannis/0000-0002-7199-9945
CR Abdullah J, 2019, VIRTUAL REAL-LONDON, V23, P461, DOI 10.1007/s10055-019-00381-1
   Akdeniz C., 2016, Instructional Process and Concepts in Theory and Practice
   Alfalah SFM, 2018, EDUC INF TECHNOL, V23, P2633, DOI 10.1007/s10639-018-9734-2
   Alrehaili EA, 2022, INTERACT LEARN ENVIR, V30, P922, DOI 10.1080/10494820.2019.1703008
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Billingsley G, 2019, J INTERACT LEARN RES, V30, P91
   Blume F, 2019, LEARN INSTR, V61, P138, DOI 10.1016/j.learninstruc.2018.10.004
   Bonfil, 2020, COMPUT EDUC, V151
   BRUNER JS, 1961, HARVARD EDUC REV, V31, P21
   Burdea G., 1994, VIRTUAL REALITY TECH
   Chang S, 2018, INTERACT LEARN ENV
   Chang S-C, 2019, BR J ED TECHNOL
   Chang S-C, 2019, COMPUT ED
   Chen, 2019, J COMPUT ASSIST LEAR
   Cheng KH, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103600
   Chien S-Y, 2019, COMPUT ED
   Concannon BJ, 2019, FRONT EDUC, V4, DOI 10.3389/feduc.2019.00080
   Degli Innocenti E, 2019, COMPUT EDUC, V139, P102, DOI 10.1016/j.compedu.2019.04.010
   Ferguson C, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103671
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gunduz G.F., 2016, Instructional Process and Concepts in Theory and Practice: Improving the Teaching Process, P147, DOI [DOI 10.1007/978-981-10-2519-84, DOI 10.1007/978-981-10-2519-8_4]
   Guyatt G., 2003, HEALTH INFORMATION AND LIBRARIES JOURNAL, V20, P79
   Han I, 2019, BR J ED TECHNOL
   Hite RL, 2019, J SCI EDUC TECHNOL, V28, P265, DOI 10.1007/s10956-018-9764-y
   Huang CL, 2020, J EDUC COMPUT RES, V58, P596, DOI 10.1177/0735633119867422
   Huang HF, 2022, INTERACT LEARN ENVIR, V30, P848, DOI 10.1080/10494820.2019.1691605
   Huang W, 2022, INTERACT LEARN ENVIR, V30, P100, DOI 10.1080/10494820.2019.1641525
   Kartiko I, 2010, COMPUT EDUC, V55, P881, DOI 10.1016/j.compedu.2010.03.019
   Kitchenham B., 2007, GUIDELINES PERFORMIN
   Kozhevnikov M, 2013, J SCI EDUC TECHNOL, V22, P952, DOI 10.1007/s10956-013-9441-0
   Lamb RL, 2019, J SCI EDUC TECHNOL, V28, P371, DOI 10.1007/s10956-019-09774-y
   Limniou M, 2008, COMPUT EDUC, V51, P584, DOI 10.1016/j.compedu.2007.06.014
   Lin HCS, 2021, INTERACT LEARN ENVIR, V29, P1272, DOI 10.1080/10494820.2019.1624579
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   McFaul H, 2020, BRIT J EDUC TECHNOL, V51, P572, DOI 10.1111/bjet.12850
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Pellas N, 2020, EDUC INF TECHNOL, V25, P2481, DOI 10.1007/s10639-019-10076-4
   Pirker J, 2017, INT J ONLINE ENG, V13, P106, DOI 10.3991/ijoe.v13i08.7371
   Potkonjak V, 2016, COMPUT EDUC, V95, P309, DOI 10.1016/j.compedu.2016.02.002
   Sasinka C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010003
   Segura RJ, 2020, COMPUT APPL ENG EDUC, V28, P31, DOI 10.1002/cae.22172
   Selzer MN, 2019, DISPLAYS, V59, P9, DOI 10.1016/j.displa.2019.04.002
   Shi AL, 2022, INTERACT LEARN ENVIR, V30, P721, DOI 10.1080/10494820.2019.1681467
   Shu Y., 2019, VIRTUAL REAL-LONDON, V23, P437, DOI [DOI 10.1007/S10055-018-0376-X., DOI 10.1007/S10055-018-0376-X]
   Southgate Erica, 2019, International Journal of Child-Computer Interaction, V19, P19, DOI 10.1016/j.ijcci.2018.10.002
   Starr CR, 2019, J SCI EDUC TECHNOL, V28, P493, DOI 10.1007/s10956-019-09781-z
   Sun WD, 2020, ACTA PETROL SIN, V36, P1, DOI 10.18654/1000-0569/2020.01.01
   Taçgin Z, 2020, EDUC INF TECHNOL, V25, P2791, DOI 10.1007/s10639-019-10088-0
   van Ginkel S, 2019, COMPUT EDUC, V134, P78, DOI 10.1016/j.compedu.2019.02.006
   Taranilla RV, 2022, INTERACT LEARN ENVIR, V30, P608, DOI 10.1080/10494820.2019.1674886
   Wang A, 2019, INTERACT LEARN ENV
   Webster R, 2016, INTERACT LEARN ENVIR, V24, P1319, DOI 10.1080/10494820.2014.994533
   Wolfartsberger J, 2019, AUTOMAT CONSTR, V104, P27, DOI 10.1016/j.autcon.2019.03.018
   Wu JN, 2021, INTERACT LEARN ENVIR, V29, P496, DOI 10.1080/10494820.2019.1587469
   Yeh SC, 2013, INTERACT LEARN ENVIR, V21, P184, DOI 10.1080/10494820.2012.705854
NR 57
TC 98
Z9 102
U1 10
U2 117
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 835
EP 861
DI 10.1007/s10055-020-00489-9
EA JAN 2021
PG 27
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000605101200002
DA 2024-07-18
ER

PT J
AU Rogers, JM
   Mumford, N
   Caeyenberghs, K
   Richards, H
   Nuijen, N
   Steenbergen, B
   Williams, G
   Shum, DHK
   Duckworth, J
   Amos, N
   Wilson, PH
AF Rogers, Jeffrey M.
   Mumford, Nick
   Caeyenberghs, Karen
   Richards, Hannah
   Nuijen, Nienke
   Steenbergen, Bert
   Williams, Gavin
   Shum, David H. K.
   Duckworth, Jonathan
   Amos, Natalie
   Wilson, Peter H.
TI Co-located (multi-user) virtual rehabilitation of acquired brain injury:
   feasibility of the <i>Resonance</i> system for upper-limb training
SO VIRTUAL REALITY
LA English
DT Article
DE Brain injury; Group therapy; Rehabilitation; Time-series analysis; Upper
   limb; Virtual reality
ID MOTOR REHABILITATION; ARM FUNCTION; BLOCK TEST; STROKE; THERAPY;
   REALITY; ENVIRONMENTS; PERFORMANCE; VALIDITY; OUTCOMES
AB Upper-limb virtual rehabilitation (VR) in adult acquired brain injury (ABI) is based largely on systems administered on a one-to-one basis. Multi-user interaction between co-located participants may offer advantages over single-user methods. The present study examined the feasibility of deploying a co-located VR system (Resonance) in a clinical setting. Following a baselining period, 5 patients with ABI completed 12 Resonance sessions over 4-6 weeks. Feasibility criteria included recruitment, intervention delivery, attrition, user experience, and suitability of outcome measures. Individual participant motor proficiency (box and blocks task) was examined using a time-series analysis with reliable change indices and curve fitting. All feasibility criteria were satisfied, with positive reports of user experience. Repeated collection of outcome measures was successfully integrated into the training schedule. Time-series analysis was successfully conducted, providing a detailed account of individual training-related change. Within a clinical setting, it was feasible to deliver Resonance and regularly monitor motor function. User feedback regarding the co-located VR intervention was generally positive, but expectations regarding the level of immersion may need to be managed. Individual time-series analysis is recommended as an adjunct to group-based analysis in future VR research. These findings can inform the design of a clinical trial.
C1 [Rogers, Jeffrey M.] Univ Sydney, Fac Med & Hlth, Sydney, NSW, Australia.
   [Mumford, Nick; Richards, Hannah; Amos, Natalie; Wilson, Peter H.] Australian Catholic Univ, Sch Psychol, Fac Hlth Sci, Fitzroy, Vic, Australia.
   [Mumford, Nick; Richards, Hannah; Steenbergen, Bert; Amos, Natalie; Wilson, Peter H.] ACU, Ctr Disabil & Dev Res CeDDR, Fitzroy, Vic, Australia.
   [Caeyenberghs, Karen] Deakin Univ, Sch Psychol, Cognit Neurosci Unit, Burwood, Australia.
   [Nuijen, Nienke; Steenbergen, Bert] Radboud Univ Nijmegen, Behav Sci Inst, Nijmegen, Netherlands.
   [Williams, Gavin] Epworth Med Fdn, Melbourne, Vic, Australia.
   [Williams, Gavin] Univ Melbourne, Physiotherapy Dept, Melbourne, Vic, Australia.
   [Shum, David H. K.] Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Peoples R China.
   [Shum, David H. K.] Griffith Univ, Menzies Hlth Inst Queensland, Brisbane, Qld, Australia.
   [Shum, David H. K.] Griffith Univ, Sch Appl Psychol, Brisbane, Qld, Australia.
   [Shum, David H. K.] Chinese Acad Sci, Inst Psychol, Neuropsychol & Appl Cognit Neurosci Lab, Beijing, Peoples R China.
   [Shum, David H. K.] Chinese Acad Sci, Inst Psychol, Key Lab Mental Hlth, Beijing, Peoples R China.
   [Duckworth, Jonathan] RMIT Univ, Sch Design, Creat Intervent Art & Rehabilitat Technol CiART, Melbourne, Vic, Australia.
   [Wilson, Peter H.] Australian Catholic Univ, Sch Behav & Hlth Sci, 115 Victoria Parade, Melbourne, Vic 3450, Australia.
C3 University of Sydney; Australian Catholic University; Australian
   Catholic University; Deakin University; Radboud University Nijmegen;
   Epworth Medical Foundation; University of Melbourne; Hong Kong
   Polytechnic University; Griffith University; Menzies Health Institute
   Queensland; Griffith University; Chinese Academy of Sciences; Institute
   of Psychology, CAS; Chinese Academy of Sciences; Institute of
   Psychology, CAS; Royal Melbourne Institute of Technology (RMIT);
   Australian Catholic University
RP Wilson, PH (corresponding author), Australian Catholic Univ, Sch Psychol, Fac Hlth Sci, Fitzroy, Vic, Australia.; Wilson, PH (corresponding author), ACU, Ctr Disabil & Dev Res CeDDR, Fitzroy, Vic, Australia.; Wilson, PH (corresponding author), Australian Catholic Univ, Sch Behav & Hlth Sci, 115 Victoria Parade, Melbourne, Vic 3450, Australia.
EM peterh.wilson@acu.edu.au
RI Amos, Natalie/AHE-0667-2022; Shum, David/A-3914-2008; Wilson,
   Peter/E-2881-2018
OI Amos, Natalie/0000-0001-6558-2580; Wilson, Peter/0000-0003-3747-0287
FU Australian Research Council [LP110200802]; Australia Council for the
   Arts; Australian Catholic University; Australian Research Council
   [LP110200802] Funding Source: Australian Research Council
FX This research was made possible through the following: an Australian
   Research Council Linkage Grant (LP110200802); a Synapse Grant through
   the Australia Council for the Arts; and an ACURF Program Grant from the
   Australian Catholic University.
CR Aminov A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0370-2
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Burridge J, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00567
   Caeyenberghs K, 2009, DEV NEUROPSYCHOL, V34, P103, DOI 10.1080/87565640802499183
   CAMEIRAO MS, 2017, INT C VIRT REH ICVR
   Chen HM, 2009, NEUROREHAB NEURAL RE, V23, P435, DOI 10.1177/1545968308331146
   Cohen J., 1988, STAT POWER ANAL BEHA
   Damiano DL, 2014, DEV MED CHILD NEUROL, V56, P1141, DOI 10.1111/dmcn.12505
   Davids K., 2008, DYNAMICS SKILL ACQUI
   Palma GCD, 2017, TOP STROKE REHABIL, V24, P269, DOI 10.1080/10749357.2016.1250373
   Dourish P., 2004, ACTION IS FDN EMBODI
   Doussoulin A, 2018, INT J REHABIL RES, V41, P35, DOI 10.1097/MRR.0000000000000257
   Duckworth Jonathan, 2013, Design, User Experience, and Usability. Health, Learning, Playing, Cultural, and Cross-Cultural User Experience.Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8013, P391, DOI 10.1007/978-3-642-39241-2_43
   Duckworth J, 2015, LECT NOTES COMPUT SC, V9177, P420, DOI 10.1007/978-3-319-20684-4_41
   English C, 2010, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD007513.pub2
   Fraser SN, 2002, J BEHAV MED, V25, P233, DOI 10.1023/A:1015328627304
   GAJADHAR BJ, 2009, INT J GAMING COMPUT
   Glegg SMN, 2013, CYBERPSYCH BEH SOC N, V16, P385, DOI 10.1089/cyber.2013.1506
   Hammond FM, 2015, ARCH PHYS MED REHAB, V96, pS282, DOI 10.1016/j.apmr.2014.11.029
   Hatem SM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00442
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Imms C, 2017, DEV MED CHILD NEUROL, V59, P16, DOI 10.1111/dmcn.13237
   JACOBSON NS, 1991, J CONSULT CLIN PSYCH, V59, P12, DOI 10.1037/0022-006X.59.1.12
   Jeong H, 2016, EDUC PSYCHOL-US, V51, P247, DOI 10.1080/00461520.2016.1158654
   Kinugasa T, 2004, SPORTS MED, V34, P1035, DOI 10.2165/00007256-200434150-00003
   Kozlowski AJ, 2013, ARCH PHYS MED REHAB, V94, P589, DOI 10.1016/j.apmr.2012.08.199
   Kwakkel G, 2006, STROKE, V37, P2348, DOI 10.1161/01.STR.0000238594.91938.1e
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lang CE, 2015, CURR OPIN NEUROL, V28, P549, DOI 10.1097/WCO.0000000000000256
   Laver KE, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub3
   Lexell J, 2015, NEUROREHABILITATION, V36, P5, DOI 10.3233/NRE-141184
   Maclean N, 2000, BMJ-BRIT MED J, V321, P1051, DOI 10.1136/bmj.321.7268.1051
   MATHIOWETZ V, 1985, AM J OCCUP THER, V39, P386, DOI 10.5014/ajot.39.6.386
   Mumford N, 2012, BRAIN INJURY, V26, P166, DOI 10.3109/02699052.2011.648706
   Mumford N, 2010, BRAIN INJURY, V24, P780, DOI 10.3109/02699051003652807
   NEWELL KM, 1991, ANNU REV PSYCHOL, V42, P213, DOI 10.1146/annurev.ps.42.020191.001241
   Patino CM, 2018, J BRAS PNEUMOL, V44, P183, DOI 10.1590/S1806-37562018000000164
   Patterson F, 2016, DISABIL REHABIL, V38, P1961, DOI 10.3109/09638288.2015.1111436
   Platz T, 2005, CLIN REHABIL, V19, P404, DOI 10.1191/0269215505cr832oa
   Pomeroy V, 2011, NEUROREHAB NEURAL RE, V25, p33S, DOI 10.1177/1545968311410942
   Renner CIE, 2016, CLIN REHABIL, V30, P637, DOI 10.1177/0269215515600206
   Rick J, 2011, PROCEEDINGS OF IDC 2011: THE 10TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2011), P109
   Rogers JM, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0531-y
   Ballester BR, 2012, PRESENCE-TELEOP VIRT, V21, P490, DOI 10.1162/PRES_a_00129
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Sideridis GD, 1997, J BEHAV EDUC, V7, P191, DOI DOI 10.1023/a:1022841108508
   Verhelst H, 2017, GAMES HEALTH J, V6, P28, DOI 10.1089/g4h.2016.0043
   Vogt S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00807
   Vratsistas-Curto A, 2018, CLIN REHABIL, V32, P1098, DOI 10.1177/0269215518778316
   Wilson PH, 2007, 2007 VIRTUAL REHABILITATION, P13
   Wilson PH, 2013, DEV MED CHILD NEUROL, V55, P217, DOI 10.1111/j.1469-8749.2012.04436.x
   Wilson PH., 2016, Curr Dev Disord Rep, V3, P138, DOI [DOI 10.1007/S40474-016-0083-9, 10.1007/s40474-016-0083-9]
   Withiel TD, 2020, DISABIL REHABIL, V42, P3033, DOI 10.1080/09638288.2019.1579260
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Health Organization (WHO), 2017, INT CLASS FUNCT DIS
NR 56
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 719
EP 730
DI 10.1007/s10055-020-00486-y
EA NOV 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000591269300002
OA Green Published
DA 2024-07-18
ER

PT J
AU Lipp, N
   Dotmanska-Misiarczyk, NDO
   Strojny, A
   Strojny, P
AF Lipp, Natalia
   Duzmanska-Misiarczyk, Natalia
   Strojny, Agnieszka
   Strojny, Pawel
TI Evoking emotions in virtual reality: schema activation via a
   freeze-frame stimulus
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Serious games; Cognitive schema; Emotions; Training;
   Simulation
ID COGNITIVE REPRESENTATION; VENTILATION RATIOS; PUBLIC SPEAKING;
   BABY-SCHEMA; FIREFIGHTERS; STRESS; COMMUNICATION; COMPRESSION;
   EXPERIENCES; MOTIVATION
AB Virtual reality can be used for educational purposes, particularly in demanding professions such as firefighting. Such virtual training may be useful for preparing trainees for distress, fear, or frustration experienced during real rescue operations. Evoking cognitive schemas, especially of other people, during training appears to be crucial as well, as the greatest stressors in the firefighting profession are social. Based on interviews with firefighters, two types of people (children and young women) were chosen as stimuli in the research design. In an experimental study with three iterations, the stimuli designed to evoke the schema of a significant other were implemented in a virtual reality simulator to evoke a cognitive schema in firefighters through emotions (positive and negative) and several dimensions of stress. The first iteration of the study did not yield expected results, as the stimulus (a child's toy) was not as suggestive and vivid as it was expected. In the second attempt, the stimulus was improved and evoked feelings of challenge, harm, and loss in the participants. In the third iteration, the stimulus was changed once more (to a white dress) and this time it evoked negative emotions of fear, anger, guilt, and sadness. However, after correcting for multiple comparisons, only results regarding emotional response remained statistically significant. The results are discussed in light of cognitive schemas' activation, and perspectives for further research in this scope are proposed. Due to research outcomes, the issues of manipulation checks in experimental psychology and limitations of the VR technology are taken into consideration.
C1 [Lipp, Natalia; Strojny, Agnieszka; Strojny, Pawel] Nano Games Sp ZOO, R&D Unit, Ul Gromadzka 101, PL-30719 Krakow, Poland.
   [Lipp, Natalia; Duzmanska-Misiarczyk, Natalia; Strojny, Agnieszka; Strojny, Pawel] Jagiellonian Univ, Inst Appl Psychol, Fac Management & Social Commun, Ul Stanislawa Lojasiewicza 4, PL-30348 Krakow, Poland.
   [Duzmanska-Misiarczyk, Natalia; Strojny, Pawel] Simpro Sp ZOO, R&D Unit, Ul Gromadzka 101, PL-30719 Krakow, Poland.
C3 Jagiellonian University
RP Lipp, N (corresponding author), Nano Games Sp ZOO, R&D Unit, Ul Gromadzka 101, PL-30719 Krakow, Poland.; Lipp, N (corresponding author), Jagiellonian Univ, Inst Appl Psychol, Fac Management & Social Commun, Ul Stanislawa Lojasiewicza 4, PL-30348 Krakow, Poland.
EM natalia.lipp@student.uj.edu.pl
RI Strojny, Pawel/AAY-3596-2021
OI Strojny, Pawel/0000-0002-6016-044X; Strojny,
   Agnieszka/0000-0002-0625-383X; Duzmanska-Misiarczyk,
   Natalia/0000-0001-7769-968X; Lipp, Natalia/0000-0002-5738-6771
FU Polish National Centre for Research and Development under the grant
   "Widespread Disaster Simulator - research and preparation for
   implementation" [POIR.01.01.01-00.0042/16]
FX This work was supported by the Polish National Centre for Research and
   Development under the grant "Widespread Disaster Simulator - research
   and preparation for implementation" (project number
   POIR.01.01.01-00.0042/16; the Smart Growth Operational Programme,
   sub-measure 1.1.1. Industrial research and development work implemented
   by enterprises) received by Nano Games sp. z o.o.
CR Alexander A.L., 2005, DARWARS Training Impact Group, V5, P1, DOI [DOI 10.1016/J.ATHORACSUR.2004.02.012, DOI 10.5171/2012.800962]
   Andersen SM, 1996, J PERS SOC PSYCHOL, V71, P1108, DOI 10.1037/0022-3514.71.6.1108
   [Anonymous], 2004, STAT APPL GENET MOL, DOI DOI 10.2202/1544-6115.1040
   [Anonymous], 2013, ZASADY ORG RATOWNICT
   Appelbaum LG, 2009, J VISION, V9, DOI 10.1167/9.11.18
   Arias S, 2019, FIRE TECHNOL, V55, P2319, DOI 10.1007/s10694-019-00868-y
   AXELROD R, 1973, AM POLIT SCI REV, V67, P1248, DOI 10.2307/1956546
   Azevedo TM, 2005, PSYCHOPHYSIOLOGY, V42, P255, DOI 10.1111/j.1469-8986.2005.00287.x
   Babbs CF, 2004, RESUSCITATION, V61, P173, DOI 10.1016/j.resuscitation.2003.12.024
   Beaton R, 1998, J TRAUMA STRESS, V11, P821, DOI 10.1023/A:1024461920456
   Beaudoin P., 2001, P GRAPH INTERFACE, P159
   Ben-Ezra M, 2005, STRESS HEALTH, V21, P269, DOI 10.1002/smi.1065
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Berninger A, 2010, PUBLIC HEALTH REP, V125, P556, DOI 10.1177/003335491012500411
   BLANEY PH, 1986, PSYCHOL BULL, V99, P229, DOI 10.1037/0033-2909.99.2.229
   Brackney DE, 2017, J NURS MEAS, V25, pE66, DOI 10.1891/1061-3749.25.2.E66
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brooks Samantha K, 2016, BMC Psychol, V4, P18, DOI 10.1186/s40359-016-0120-9
   Carey MG, 2011, J OCCUP ENVIRON MED, V53, P928, DOI 10.1097/JOM.0b013e318225898f
   Cetin M, 2005, J TRAUMA STRESS, V18, P485, DOI 10.1002/jts.20056
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   COHEN R, 1988, NEW YORK TIMES BK R, P19
   De Soir E, 2012, PREHOSPITAL DISASTER, V27, P115, DOI 10.1017/S1049023X12000507
   Derry SJ, 1996, EDUC PSYCHOL, V31, P163, DOI 10.1207/s15326985ep3103&4_2
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   Evans D, 2019, 33 1-3 SERIES, P13
   Fabricatore C, 2014, PROC EUR CONF GAME, P110
   Fiske S.T., 1991, SOCIAL COGNITION
   Fredrickson B.L., 1998, J DIVISION 1 AM PSYC, P300, DOI [https://doi.org/10.1037/1089-2680.2.3.300, DOI 10.1037/1089-2680.2.3.300]
   Gladwin TE, 2016, NEUROSCI LETT, V619, P182, DOI 10.1016/j.neulet.2016.03.027
   Glocker ML, 2009, ETHOLOGY, V115, P257, DOI 10.1111/j.1439-0310.2008.01603.x
   Gormley M., 2008, The Irish Journal of Psychology, V29, P7, DOI DOI 10.1080/03033910.2008.10446270
   Graafland M, 2012, BRIT J SURG, V99, P1322, DOI 10.1002/bjs.8819
   Hagenaars MA, 2014, ANXIETY STRESS COPIN, V27, P27, DOI 10.1080/10615806.2013.809420
   Han PH, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281507
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Hoffman Bobby, 2010, Educational Technology, Research and Development, V58, P245, DOI 10.1007/s11423-009-9134-9
   Hommel B, 1996, PSYCHOL RES-PSYCH FO, V59, P176, DOI 10.1007/BF00425832
   Huang JH, 2013, NEURAL REGEN RES, V8, P1898, DOI 10.3969/j.issn.1673-5374.2013.20.009
   Jahnke SA, 2013, OBESITY, V21, P1505, DOI 10.1002/oby.20436
   Johnsen K, 2005, P IEEE VIRT REAL ANN, P179
   Katsavouni F, 2016, OCCUP MED-OXFORD, V66, P32, DOI 10.1093/occmed/kqv144
   LEVENSON RW, 1992, PSYCHOL SCI, V3, P23, DOI 10.1111/j.1467-9280.1992.tb00251.x
   Lin JHT, 2017, COMPUT HUM BEHAV, V72, P350, DOI 10.1016/j.chb.2017.02.057
   Lourel M., 2008, N AM J PSYCHIAT, V10, P489
   Ly V, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186648
   McDonald JH., 2009, Handbook of Biological Statistics, P6
   Miesler L, 2011, INT J DES, V5, P17
   Monteiro Janine Kieling, 2013, Estud. psicol. (Campinas), V30, P437
   MURPHY ST, 1993, J PERS SOC PSYCHOL, V64, P723, DOI 10.1037/0022-3514.64.5.723
   O'Connor RE, 2019, CARDIOPULMONARY RESU
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Pertaub DP, 2001, STUD HEALTH TECHNOL, V81, P372
   Regehr C, 2003, STRESS HEALTH, V19, P189, DOI 10.1002/smi.974
   Rosser JC, 2007, ARCH SURG-CHICAGO, V142, P181, DOI 10.1001/archsurg.142.2.181
   Sigall H, 1998, Pers Soc Psychol Rev, V2, P218, DOI 10.1207/s15327957pspr0203_5
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Smith J., 2012, INTERPRETATIVE PHENO, P1
   Smith TD, 2018, SAFETY SCI, V103, P287, DOI 10.1016/j.ssci.2017.12.005
   Strojny P, 2018, BEZPIECZESTWO TECHNI, V49, P14, DOI [10.12845/bitp.49.1.2018.1, DOI 10.12845/BITP.49.1.2018.1]
   Supreme Audit Office, 2012, FUNKCJ SZKO OR SZKOL
   TESSER A, 1977, J EXP SOC PSYCHOL, V13, P340, DOI 10.1016/0022-1031(77)90004-X
   The State Fire Service of Poland, 2016, PROGR SZKOL PODST ZA
   The State Fire Service of Poland, 2018, STAN WYP PSP OSP
   Ucros C.G., 1989, COGNITION EMOTION, V3, P139, DOI [10.1080/02699938908408077, DOI 10.1080/02699938908408077]
   Wagner S.L., 2010, Traumatology, V76, P26, DOI [10.1177/1534765610362803, DOI 10.1177/1534765610362803]
   Williams-Bell FM, 2015, FIRE TECHNOL, V51, P553, DOI 10.1007/s10694-014-0398-1
   WODARCZYK D, 2010, PRZEGLD PSYCHOL, V53, P479
   Wojciszke B., 2005, CZASOPISMO PSYCHOL, V11, P31
   Woodall J., 1997, Clinical Sociology Review, V15, P153
   WYER RS, 1984, J EXP SOC PSYCHOL, V20, P445, DOI 10.1016/0022-1031(84)90037-4
   Yannopoulos D, 2006, CRIT CARE MED, V34, P1444, DOI 10.1097/01.CCM.0000216705.83305.99
NR 76
TC 6
Z9 8
U1 8
U2 48
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 279
EP 292
DI 10.1007/s10055-020-00454-6
EA JUL 2020
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000545178900001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Puig, A
   Rodríguez, I
   Arcos, JL
   Rodríguez-Aguilar, JA
   Cebrián, S
   Bogdanovych, A
   Morera, N
   Palomo, A
   Piqué, R
AF Puig, Anna
   Rodriguez, Inmaculada
   Arcos, Josep Ll
   Rodriguez-Aguilar, Juan A.
   Cebrian, Sergi
   Bogdanovych, Anton
   Morera, NOria
   Palomo, Antoni
   Pique, Raquel
TI Lessons learned from supplementing archaeological museum exhibitions
   with virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual heritage; VR analytics; Gamified experiences
ID LA DRAGA BANYOLES; SITE
AB Archaeological excavations provide us with important clues about the past. Excavated artefacts represent an important connection to civilisations that no longer exist and help us understand some of their customs, traditions and common practices. With the help of academics and practitioners from various disciplines, the results of archaeological excavations can be analysed and a body of knowledge about the corresponding society can be created and shared with members of the general public. Museums have traditionally served the purpose of communicating this knowledge and backing it up with the help of the excavated artefacts. Many museum visitors, however, find it difficult to develop a coherent understanding of the corresponding society only based on the artefacts and annotations shown in museums. Effective modern techniques that have high potential in helping museum visitors with better understanding of the past are 3D reconstruction and virtual reality. 3D reconstruction offers a cost-effective way of recreating historical settlements in a computer-generated virtual environment, while virtual reality helps with immersing people into such environments and reaching a high degree of realism. With the help of these technologies, it becomes possible to relive history, imagine yourself being a part of the reconstructed society and learn about its culture firsthand. The combination of 3D reconstruction and virtual reality represents a very powerful learning tool; however, this tool has been rarely used in a museum setting and its correct use has not been properly investigated. In this paper, we present a study into using virtual reality in itinerant archaeological exhibitions. We discuss the lessons we have learned from developing an interactive virtual reality simulation of the Neolithic settlement of La Draga. These lessons feature our analysis of qualitative and quantitative feedback of museum visitors, as well as what we have learned from analysing their navigation and interaction patterns.
C1 [Puig, Anna; Rodriguez, Inmaculada] Univ Barcelona, Barcelona, Spain.
   [Arcos, Josep Ll; Rodriguez-Aguilar, Juan A.; Cebrian, Sergi] IIIA CSIC, Barcelona, Spain.
   [Bogdanovych, Anton] Univ Western Sydney, Sydney, NSW, Australia.
   [Morera, NOria; Pique, Raquel] Autonomous Univ Barcelona, Barcelona, Spain.
   [Palomo, Antoni] Museu Arqueol Catalunya, Barcelona, Spain.
C3 University of Barcelona; Consejo Superior de Investigaciones Cientificas
   (CSIC); CSIC - Instituto de Investigacion en Inteligencia Artificial
   (IIIA); Western Sydney University; Autonomous University of Barcelona
RP Puig, A (corresponding author), Univ Barcelona, Barcelona, Spain.
EM annapuig@ub.edu; inmarodriguez@ub.edu; arcos@iiia.csic.es;
   jar@iiia.csic.es; scebrian@iiia.csic.es;
   A.Bogdanovych@westernsydney.edu.au; nuria.morera@uab.cat;
   antoni.palomo@gencat.cat; raquel.pique@uab.cat
RI Yang, Li/JMP-4403-2023; Rodriguez-Aguilar, Juan A/H-1952-2015; Puig,
   Anna/ADI-9599-2022; Rodriguez, Inmaculada/H-9298-2015
OI Rodriguez-Aguilar, Juan A/0000-0002-2940-6886; Puig,
   Anna/0000-0002-2184-2800; Rodriguez, Inmaculada/0000-0001-5931-7713;
   Palomo Perez, Antoni/0000-0001-9954-7310; Pique Huerta,
   Raquel/0000-0002-8253-6874; Arcos, Josep Lluis/0000-0001-7751-1210;
   Bogdanovych, Anton/0000-0003-0822-4116
CR [Anonymous], 2005, Learning by doing: a comprehensive guide to simulations, computer games, and pedagogy in e-learning and other educational experiences
   [Anonymous], 2019, CHRONICLESVR
   [Anonymous], 2019, TATE MODERN MUSEUM
   [Anonymous], 2019, VIRTUAL DUTCH MEN
   Antolin F, 2014, CEREALS POPPY ACORNS
   Antolín F, 2014, ENVIRON ARCHAEOL, V19, P241, DOI 10.1179/1749631414Y.0000000027
   Antoniou A., 2010, ACM J COMPUT CULT HE, V3, P7, DOI DOI 10.1145/1841317.1841322
   AROYO L, 2007, INT MUS WEB C SAN FR
   Bartle R., 1996, J MUD Res, V1, P19, DOI DOI 10.1007/S00256-004-0875-6
   Bauckhage C, 2015, IEEE T COMP INTEL AI, V7, P266, DOI 10.1109/TCIAIG.2014.2376982
   Bogdanovych A, 2010, APPL ARTIF INTELL, V24, P617, DOI 10.1080/08839514.2010.492172
   Bosch A, 2000, MONOGRAFIAS CASC, V2
   Campana I., 2018, THESIS
   Carrozzino M, 2018, LECT NOTES COMPUT SC, V10851, P292, DOI 10.1007/978-3-319-95282-6_22
   Carrozzino M, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P187, DOI 10.1109/DigitalHeritage.2015.7419486
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Ferme LC, 2014, HOLOCENE, V24, P266, DOI 10.1177/0959683613517400
   Chang HL, 2018, 22 PAC AS C INF SYST, P915
   Dopker A, 2013, P INFORM 2013, P2308
   Falk J. H., 2000, Learning from museums: Visitor Experiences and the making of meaning
   Gaitatzes A., 2001, Proceedings of the 2001 conference on virtual reality, archaeology, and cultural heritage, P103, DOI [10.1145/584993.585011, DOI 10.1145/584993.585011]
   Garcia-Puchol O., 2017, Times of Neolithic Transition along the Western Mediterranean, P199, DOI [10.1007/978-3-319-52939-4_8, DOI 10.1007/978-3-319-52939-4_8]
   Hall Tony., 2001, P 2001 C VIRTUAL REA, P91
   Home M., 2016, P ANN C MUS WEB, P6
   Hou HT, 2014, EDUC TECHNOL SOC, V17, P207
   Kersten T. P., 2017, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLII
   King B, 2015, MANUAL MUSEUM LEARNI
   Livingston D.W., 2006, Learning in places: The informal education reader, P203
   Lopez i Bulto JO, 2015, THESIS
   Mantyjarvi Jani., 2006, P 8 C HUMAN COMPUTER, P191, DOI DOI 10.1145/1152215.1152256
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   MOSS J, 2018, THESIS
   National Research Council, 1995, VIRTUAL REALITY SCI
   Norman D.A., 2004, Ubiquity, DOI DOI 10.1145/985600.966013
   Poveda M. M. R, 2015, THESIS
   Pujol L, 2010, P 38 ANN C COMP APPL
   Roussou M., 2001, Immersive Interactive Virtual Reality in the Museum Maria Roussou, Foundation of the Hellenic World
   Sánchez-Cabrero R, 2018, DATA BRIEF, V21, P2651, DOI 10.1016/j.dib.2018.11.127
   Schofield G, 2018, P 2018 DES INT SYST
   Schugurensky D., 2000, The forms of information learning: towards a conceptualization of the field
   Shah Mohd Noor., 2018, Communications in Computer and Information Science, P35, DOI DOI 10.1007/978-981-13-1628-9_4
   Shunli Liu, 2018, MATEC Web of Conferences, V176, DOI 10.1051/matecconf/201817604007
   Sifa R., 2018, Social interactions in virtual worlds: an interdisciplinary perspective, P337, DOI 10.1017/9781316422823.014
   Spronck P., 2012, AIIDE"
   Terrenghi L., 2004, P 9 INT C INT US INT, P334, DOI [10.1145/964442.964523, DOI 10.1145/964442.964523]
   Valiathan P., 2002, LEARNING CIRCUITS, V3, P50
   Whittaker JohnC., 1994, Flintknapping: Making and Understanding Stone Tools
   Wojciechowski R., 2004, Proceedings of the ninth international conference on 3D Web technology, Monterey, CA, DOI [DOI 10.1145/985040.985060, https://doi.org/10.1145/985040.985060]
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
NR 49
TC 28
Z9 28
U1 10
U2 80
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 343
EP 358
DI 10.1007/s10055-019-00391-z
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sharma, A
   Ikbal, MS
   Cuong, DT
   Zoppi, M
AF Sharma, Aman
   Ikbal, Mohamed Sadiq
   Duc Trinh Cuong
   Zoppi, Matteo
TI A sliding mode-based approach to motion cueing for virtual reality
   gaming using motion simulators
SO VIRTUAL REALITY
LA English
DT Article
DE Parallel manipulators; Motion simulators; Virtual reality gaming; Motion
   cueing; Sliding mode control
ID DESIGN
AB Motion simulators have been of significant importance for the aviation sector in training pilots. However, the present boom in the utilization of robotics for virtual reality (VR) gaming has given rise to a new application of motion simulators. Motion cueing algorithms (MCA) play a key role in mapping the motions from a gaming scenario to the workspace of a simulator. This workspace is small (as compared to the gaming world), and on reaching the boundary, it becomes necessary to saturate the motion. Each degree of freedom, in the Cartesian space, is saturated between two fixed extremities. This hampers the perception of motion of a user enjoying the scenario. In order to address this practical problem, we make an attempt to enlarge the workspace and develop a mathematical methodology to prevent the simulator from exiting a non-cuboidal workspace. To do so, we propose sliding mode-based cueing algorithm (SMCA), which makes the simulator to slide in close proximity across the boundary of workspace. We make use of discrete-time models to present this methodology in order to ensure straightforward implementation by researchers in the future. Veracity of SMCA is testified by means of experimentation on SP7 motion simulator. The experimental results give evidence of a 57% increase in the considered sub-workspace, thereby reducing the relative necessity to saturate the motions as compared to classical MCA. This leads to a better experience of a user enjoying the VR scenario. On the other hand, the following drawbacks are reported: (1) necessity to analytically model the workspace boundary and ensuring that it is smooth with nonzero gradient, (2) SMCA parameter selection is more cumbersome than classical MCA, thereby making its utility restricted to recorded scenarios.
C1 [Sharma, Aman; Ikbal, Mohamed Sadiq; Duc Trinh Cuong; Zoppi, Matteo] Univ Genoa, PMAR Robot Lab, Via Opera Pia 15A, I-16145 Genoa, Italy.
C3 University of Genoa
RP Sharma, A (corresponding author), Univ Genoa, PMAR Robot Lab, Via Opera Pia 15A, I-16145 Genoa, Italy.
EM amansharma.nitg@gmail.com; mohamedsadiq.ikbal@edu.unige.it;
   cuong@dimee.unige.it; zoppi@dimee.unige.it
RI Zoppi, Matteo/I-7105-2012
OI Zoppi, Matteo/0000-0003-0122-3196; SHARMA, Aman/0000-0003-0862-8401
CR [Anonymous], 2005, APPL MATH SERIES
   Aponso B, 2009, ROYAL AER SOC SPRING, V1, P3
   Arkin R., 1998, BEHAV BASED ROBOTICS
   Asadi H, 2017, IEEE T SYST MAN CY-S, V47, P238, DOI 10.1109/TSMC.2016.2523906
   Bruce GE, 2008, BLACKWELL HDB SENSAT
   Bruschetta M, 2018, IEEE T HUM-MACH SYST, V48, P6, DOI 10.1109/THMS.2017.2776207
   Bruschetta M, 2017, IEEE T CONTR SYST T, V25, P686, DOI 10.1109/TCST.2016.2560120
   Campos LCA, 2018, J LOW FREQ NOISE V A, V37, P144, DOI 10.1177/1461348418757889
   Conrad B, 1970, MOTION DRIVE SIGNALS
   Cortés C, 2014, BIOMED RES INT-UK, V2014, DOI 10.1155/2014/821908
   Cyrus ML, 1978, MOTION SYSTEMS ROLE
   Dagdelen M, 2009, CONTROL ENG PRACT, V17, P995, DOI 10.1016/j.conengprac.2009.03.002
   Galante F., 2018, J ADV TRANSPORT, V2018, P1, DOI DOI 10.1155/2018/6713745
   Giordano PR, 2010, IEEE INT CONF ROBOT, P3876, DOI 10.1109/ROBOT.2010.5509647
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Grant, 2011, P 2011 ANN RESNA C, P8
   Jansen J, 2009, INT J FLUID POWER, V10, P19, DOI 10.1080/14399776.2009.10780975
   Abásolo MJ, 2014, LECT NOTES COMPUT SC, V8563, P106, DOI 10.1007/978-3-319-08849-5_11
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Krebs M, 2001, 1 HUM CTR TRANSP SIM, P1
   Moglia A, 2016, EUR UROL, V69, P1065, DOI 10.1016/j.eururo.2015.09.021
   Nahon M, 1985, Technical report
   NAHON MA, 1992, J GUID CONTROL DYNAM, V15, P376, DOI 10.2514/3.20846
   Nordmark Staffan, 2004, P DRIVING SIMULATION, P45
   Page RayL., 2000, SimTecT 2000 Proceedings, P11
   Parrish R. V., 1975, Journal of Aircraft, V12, P44, DOI 10.2514/3.59800
   Pham D.A., 2017, A Study on State-of-the-Art Motion Cueing Algorithms Applied to Planar Motion with Pure Lateral Acceleration - Comparison, Auto-Tuning and Subjective Evaluation on a KUKA Robocoaster Serial Ride Simulator
   Sharma A, 2019, IEEE ROBOT AUTOM LET, V4, P1013, DOI 10.1109/LRA.2019.2893709
   SIVAN R, 1982, IEEE T SYST MAN CYB, V12, P818, DOI 10.1109/TSMC.1982.4308915
   Sterling GC, 2000, SIM TECT 2000 CCONFE
   Stewart D., 1965, P I MECH ENG, V180, P371, DOI DOI 10.1243/PIME_PROC_1965_180_029_02
   Teixeira J., 2015, ED ROBOTIC SIMULATOR
   Telban R.J., 2000, MOTION CUEING ALGORI
   Wentink, 2005, P AIAA MOD SIM TECHN, P6501
   Wu W., 1997, AM I AERONAUT ASTRON, P23
   Zacharias G. L., 1978, TECHNICAL REPORT
NR 36
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 95
EP 106
DI 10.1007/s10055-020-00439-5
EA APR 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000524376100001
DA 2024-07-18
ER

PT J
AU Klippel, A
   Zhao, JY
   Oprean, D
   Wallgrün, JO
   Stubbs, C
   La Femina, P
   Jackson, KL
AF Klippel, Alexander
   Zhao, Jiayan
   Oprean, Danielle
   Wallgrun, Jan Oliver
   Stubbs, Chris
   La Femina, Peter
   Jackson, Kathy L.
TI The value of being there: toward a science of immersive virtual field
   trips
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive learning; Virtual field trips; STEM; Place-based learning
ID SPATIAL ORIENTATION; REALITY; EDUCATION
AB With immersive experiences becoming a medium for mass communication, we need pedagogies as well as scientific, evidence-based design principles for immersive learning. To foster evidence-based designs of immersive learning, we detail an empirical evaluation of a geosciences field trip, common in undergraduate education across numerous disciplines. The study builds on a previously proposed research framework in which we detailed a basic taxonomy of virtual field trips distinguishing between basic, plus, and advanced immersive virtual field trip experiences. The experiment reported here expands the original evaluation of basic field trips into the realm of plus versions using pseudo-aerial 360 degrees imagery to provide embodied experiences that are not possible during the actual field trip. We also refined our original experimental design placing a stronger focus on the qualitative feedback elicited from the students. Results show an overwhelmingly positive response of students to virtual field trips with significantly higher-valued learning experience and enjoyment. Furthermore, the introduction of pseudo-aerial imagery (together with higher image resolution) shows a significant improvement in the participants spatial situation model. As contextualizing and spatially grounding is essential for place-based learning experiences, plus versions of virtual field trips have the potential to add value to the learning outcome and immersive virtual field trip experience. We discuss these encouraging results as well as critical feedback from the participants, such as the absence of touch in virtual experiences, and lay out our vision for the future of immersive learning experiences across environmental sciences.
C1 [Klippel, Alexander; Zhao, Jiayan; Wallgrun, Jan Oliver] Penn State Univ, Dept Geog, ChoroPhronesis, University Pk, PA 16802 USA.
   [Oprean, Danielle] Univ Missouri, Sch Informat Sci & Learning Technol, Columbia, MO USA.
   [Stubbs, Chris] Penn State Univ, Teaching & Learning Technol, University Pk, PA 16802 USA.
   [La Femina, Peter] Penn State Univ, Dept Geosci, University Pk, PA 16802 USA.
   [Jackson, Kathy L.] Penn State Univ, Sch Engn Design Technol & Profess Programs, State Coll, PA USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park; University of Missouri System; University of Missouri
   Columbia; Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University
RP Klippel, A (corresponding author), Penn State Univ, Dept Geog, ChoroPhronesis, University Pk, PA 16802 USA.
EM klippel@psu.edu
RI Wallgrün, Jan Oliver/H-5241-2012; LaFemina, Peter/C-4233-2011; Oprean,
   Danielle/AGV-8283-2022
OI KLIPPEL, ALEXANDER/0000-0002-7171-492X; Oprean,
   Danielle/0000-0001-8052-0791; LaFemina, Peter/0000-0001-6053-2074
FU Penn State Strategic Planning award; National Science Foundation
   [1617396, 1526520]; Direct For Social, Behav & Economic Scie; Division
   Of Behavioral and Cognitive Sci [1617396] Funding Source: National
   Science Foundation; Div Of Information & Intelligent Systems; Direct For
   Computer & Info Scie & Enginr [1526520] Funding Source: National Science
   Foundation
FX The authors would like to thank students of Geosc 001 for their
   participation, the instructor, Peter Heaney, for his support, as well as
   the anonymous reviewers for their deeply insightful comments. This study
   was funded through a Penn State Strategic Planning award. Dr. Klippel
   would like to additionally acknowledge funding through the National
   Science Foundation Grants #1617396 and #1526520.
CR Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   [Anonymous], 2018, UNITY UNITY3D
   Blascovich J., 2011, Infinite Reality: Avatars, Eternal Life, New Worlds, and the Dawn of the Virtual Revolution
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brown A, 2016, TECHTRENDS, V60, P517, DOI 10.1007/s11528-016-0102-z
   Bursztyn N., 2017, GSA TODAY, V27, P4, DOI DOI 10.1130/GSATG304A.1
   Carrera CC, 2017, J GEOGR HIGHER EDUC, V41, P119, DOI 10.1080/03098265.2016.1260530
   Carrivick J.L., 2016, STRUCTURE MOTION GEO, DOI DOI 10.1002/9781118895818
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351
   Clifton PG, 2016, COGN RES, V1, DOI 10.1186/s41235-016-0032-5
   de Jong T., 1991, Education & Computing, V6, P217, DOI 10.1016/0167-9287(91)80002-F
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dolphin G., 2019, J GEOSCIENCE ED, V67, P114, DOI [DOI 10.1080/10899995.2018.1547034, 10.1080/10899995.2018, DOI 10.1080/10899995.2018]
   Elkins J.T., 2007, J GEOSCIENCE ED, V55, P126, DOI DOI 10.5408/1089-9995-55.2.126
   Fisher P., 2002, Virtual reality in geography
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Gelman A, 2010, COLL TEACH, V50, P151, DOI [10.1080/87567550209595897, DOI 10.1080/87567550209595897]
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   Hurst SD, 1998, COMPUT GEOSCI, V24, P653, DOI 10.1016/S0098-3004(98)00043-0
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Kamarainen AM, 2018, COMM COM INF SC, V840, P36, DOI 10.1007/978-3-319-93596-6_3
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930302297
   Ketelhut DJ, 2010, BRIT J EDUC TECHNOL, V41, P56, DOI 10.1111/j.1467-8535.2009.01036.x
   Klippel A, 2019, J EDUC COMPUT RES, V57, P1745, DOI 10.1177/0735633119854025
   Klippel A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1612, DOI [10.1109/vr.2019.8798153, 10.1109/VR.2019.8798153]
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Lages W. S., 2018, Frontiers in ICT, V5, P1, DOI [DOI 10.3389/FICT.2018.00015, 10.3389/fict.2018.00015]
   Lave J., 1991, SITUATED LEARNING LE, DOI DOI 10.1017/CBO9780511815355
   Lee EAL, 2014, COMPUT EDUC, V79, P49, DOI 10.1016/j.compedu.2014.07.010
   Liu D., 2017, VIRTUAL AUGMENTED MI
   Makransky G., 2017, Learning and Instruction, V60, P225, DOI [DOI 10.1016/J.LEARNINSTRUC.2017.12.007, 10.1016/j.learninstruc.2017.12.007]
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Mead C., 2019, Journal of Geoscience Education, V67, P131, DOI [10.1080/10899995.2019.1565285, DOI 10.1080/10899995.2019.1565285]
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Minocha S, 2017, 31 BRIT HUM COMP INT, P1
   Narciso D, 2019, UNIVERSAL ACCESS INF, V18, P77, DOI 10.1007/s10209-017-0581-5
   NORMAN DA, 1980, PSYCHOL EVERYDAY THI
   Piaget J., 1974, UNDERSTAND IS INVENT
   Relf P, 1996, MAGIC SCH BUS WET AL
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Ruberto T, 2017, P GEOL SOC AM GSA 22, V49, DOI [10.1130/abs/2017AM-306229, DOI 10.1130/ABS/2017AM-306229]
   Schreier M., 2013, QUALITATIVE CONTENT
   Semken S., 2017, J GEOSCIENCE ED, V65, P542, DOI [DOI 10.5408/17-276.1, 10.5408/17-276.1]
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sriarunrasmee J, 2015, PROCD SOC BEHV, V197, P1721, DOI 10.1016/j.sbspro.2015.07.226
   Steinicke F, 2013, Human walking in virtual environments
   Stumpf RJ, 2008, J GEOGR HIGHER EDUC, V32, P387, DOI 10.1080/03098260802221140
   Vorderer P., 2004, REPORT EUROPEAN COMM
   Vygotskii LS, 1978, MIND SOC DEV HIGHER
   Zhao J., 2018, 7 INT C SPAT COGN IC
   Zhao JY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P155, DOI [10.1109/VR.2019.8797867, 10.1109/vr.2019.8797867]
NR 55
TC 49
Z9 57
U1 12
U2 62
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 753
EP 770
DI 10.1007/s10055-019-00418-5
EA DEC 2019
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000542936700002
DA 2024-07-18
ER

PT J
AU Felip, F
   Galán, J
   García-García, C
   Mulet, E
AF Felip, Francisco
   Galan, Julia
   Garcia-Garcia, Carlos
   Mulet, Elena
TI Influence of presentation means on industrial product evaluations with
   potential users: a first study by comparing tangible virtual reality and
   presenting a product in a real setting
SO VIRTUAL REALITY
LA English
DT Article
DE Tangible virtual reality; Product presentation; Attributes evaluation;
   Industrial design
ID CONSUMER RESPONSES; DIMENSIONS; PERCEPTION; CUSTOMERS; IMPACTS; DESIGN
AB Nowadays, virtual reality allows products to be presented to potential users, but as they cannot feel them physically, their perception of some product attributes can be distorted. Conversely, the mixture of visual and touch feelings that tangible virtual reality (TVR) offers could act as a similar approach to knowing products in real settings. This is a first study to compare the evaluation of product attributes presented in a real setting and by tangible virtual reality to verify the possible equivalence of both means. The semantic differential method was used to evaluate product attributes by creating a semantic scale with 16 bipolar pairs. Seventy-seven people (mean age of 21.7) evaluated one product by both means in an alternate viewing order. The results revealed that the product that was chosen was rated with more positive attributes in some bipolar pairs when experienced via TVR, while it was better rated in others when experienced in a real environment. The Wilcoxon test (alpha = 0.05) corroborated that the presentation means used to evaluate the product influenced the evaluation of 15 of 16 attributes.
C1 [Felip, Francisco; Galan, Julia; Garcia-Garcia, Carlos] Univ Jaume 1, Dept Ind Syst Engn & Design, Av Vicent Sos Baynat S-N, Castellon De La Plana 12071, Spain.
   [Mulet, Elena] Univ Jaume 1, Dept Mech Engn & Construct, Av Vicent Sos Baynat S-N, Castellon De La Plana 12071, Spain.
C3 Universitat Jaume I; Universitat Jaume I
RP Felip, F (corresponding author), Univ Jaume 1, Dept Ind Syst Engn & Design, Av Vicent Sos Baynat S-N, Castellon De La Plana 12071, Spain.
EM ffelip@uji.es
RI Mulet, Elena/ADT-3895-2022; Garcia-Garcia, Carlos/E-9240-2016; Felip,
   Francisco/G-7400-2015
OI Mulet, Elena/0000-0003-4903-1273; Garcia-Garcia,
   Carlos/0000-0003-2524-0177; Felip, Francisco/0000-0002-7225-2536
FU Spanish Ministerio de Economia y Competitividad MINECO
   [TIN2016-75866-C3-1-R]; Universitat Jaume I [P1.1B2015-30]
FX This work was supported by the Spanish Ministerio de Economia y
   Competitividad MINECO (Grant Number TIN2016-75866-C3-1-R); and
   Universitat Jaume I (Grant Number P1.1B2015-30). The authors also wish
   to thank the designers Jose Maria Pizana Garcia and Javier Lebrija
   Morilla for their collaboration.
CR ACHICHE S, 2014, P ASME 2014 INT MECH
   Al-Hindawe J., 1996, TROBE PAPERS LINGUIS, V9, P1
   [Anonymous], COMPUTERS
   Artacho-Ramírez MA, 2008, INT J IND ERGONOM, V38, P942, DOI 10.1016/j.ergon.2008.02.020
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baker J., 1994, J ACAD OFMARKETING S, V22, P328, DOI DOI 10.1177/0092070394224002
   Blijlevens J, 2009, INT J DES, V3, P27
   CARROLL JB, 1959, LANGUAGE, V35, P58, DOI 10.2307/411335
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chang JSK, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P68, DOI 10.1145/3131277.3132171
   Chang WC, 2007, INT J DES, V1, P3
   CHITTARO L, 2000, P CHI 2000 WORKSH DE
   De Troyer Olga, 2007, Virtual Reality, V11, P89, DOI 10.1007/s10055-006-0058-y
   Forslund K, 2013, INT J DES, V7, P69
   Harley D, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1253, DOI 10.1145/3064663.3064680
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Horváth I, 2008, PROC MONOGR ENG WATE, P35
   HORVATH I, 2008, P IDETC CIE 2008 ASM, P1
   Horváth I, 2009, WINVR2009: PROCEEDINGS OF THE ASME/AFM WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2009, P45
   Hsiao KA, 2006, INT J IND ERGONOM, V36, P553, DOI 10.1016/j.ergon.2005.11.009
   Hsiao SW, 2008, INT J IND ERGONOM, V38, P910, DOI 10.1016/j.ergon.2008.02.009
   Hung WK, 2012, INT J DES, V6, P81
   Jeong SW, 2009, INTERNET RES, V19, P105, DOI 10.1108/10662240910927858
   Jiang ZH, 2007, INFORM SYST RES, V18, P454, DOI 10.1287/isre.1070.0124
   Jordan P.W., 2000, Designing Pleasurable Products
   Karana E, 2010, INT J DES, V4, P43
   Katicic J, 2015, PRESENCE-TELEOP VIRT, V24, P62, DOI 10.1162/PRES_a_00215
   Khalaj J, 2014, INT J DES, V8, P79
   Lanier J., 1992, Interactive Learning International, V8, P275
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Martínez-Navarro J, 2019, J BUS RES, V100, P475, DOI 10.1016/j.jbusres.2018.10.054
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mondragón S, 2005, INT J IND ERGONOM, V35, P1021, DOI 10.1016/j.ergon.2005.05.001
   PEREZMATA M, 2017, RES ENG DES, V28, P357
   Pizzi G, 2019, COMPUT HUM BEHAV, V96, P1, DOI 10.1016/j.chb.2019.02.008
   Rahman O, 2012, INT J DES, V6, P11
   Reid TN, 2013, J MECH DESIGN, V135, DOI 10.1115/1.4024724
   Rojas JC, 2015, PACKAG TECHNOL SCI, V28, P1047, DOI 10.1002/pts.2178
   Söderman M, 2005, J ENG DESIGN, V16, P311, DOI 10.1080/09544820500128967
   SODERMAN M, 2001, THESIS
   SPEICHER M, 2017, P ACM INT MOB WEAR U
   Tiger L., 1992, The Pursuit of Pleasure
   Wright P. C., 1991, SIGCHI Bulletin, V23, P55, DOI 10.1145/122672.122685
   Yoo J, 2014, J BUS RES, V67, P2464, DOI 10.1016/j.jbusres.2014.03.006
   Zielinski DJ, 2017, P IEEE VIRT REAL ANN, P221, DOI 10.1109/VR.2017.7892256
   ZIMMERMAN DW, 1993, J EXP EDUC, V62, P75, DOI 10.1080/00220973.1993.9943832
NR 46
TC 10
Z9 10
U1 2
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 439
EP 451
DI 10.1007/s10055-019-00406-9
EA OCT 2019
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000489923000001
DA 2024-07-18
ER

PT J
AU Jiang, XT
   Xiao, ZG
   Menon, C
AF Jiang, Xianta
   Xiao, Zhen Gang
   Menon, Carlo
TI Virtual grasps recognition using fusion of Leap Motion and force
   myography
SO VIRTUAL REALITY
LA English
DT Article
DE VR; Hand gesture recognition; Grasp classification; Leap Motion; Force
   myography
ID PATTERN-RECOGNITION; SENSOR
AB Hand gesture recognition is important for interactions under VR environment. Traditional vision-based approaches encounter occlusion problems, and thus, wearable devices could be an effective supplement. This study presents a hand grasps recognition method in virtual reality settings, by fusing signals acquired using force myography (FMG), a muscular activity-based hand gesture recognition method, and Leap Motion. We conducted an experiment where participants performed grasping of virtual objects with VR goggles on their head, an FMG band on their wrist, and a Leap Motion positioned either on the desk or on the goggles (two experimental settings). The FMG, Leap Motion, and fusion of both signals were used for training and testing a simple, but effective linear discriminant analysis classifier, as well as three other mainstream classification algorithms. The results showed that the fusion of both signals achieved a significant improvement in classification accuracy, compared to using Leap Motion alone in both experimental settings.
C1 [Jiang, Xianta; Xiao, Zhen Gang; Menon, Carlo] Simon Fraser Univ, Menrva Res Grp, Sch Mechatron Syst, Surrey, BC V3T 0A3, Canada.
   [Jiang, Xianta; Xiao, Zhen Gang; Menon, Carlo] Simon Fraser Univ, Menrva Res Grp, Sch Engn Sci, Surrey, BC V3T 0A3, Canada.
C3 Simon Fraser University; Simon Fraser University
RP Menon, C (corresponding author), Simon Fraser Univ, Menrva Res Grp, Sch Mechatron Syst, Surrey, BC V3T 0A3, Canada.; Menon, C (corresponding author), Simon Fraser Univ, Menrva Res Grp, Sch Engn Sci, Surrey, BC V3T 0A3, Canada.
EM cmenon@sfu.ca
RI Jiang, Xianta/GXZ-9678-2022; Menon, Carlo/GZG-8210-2022
OI Menon, Carlo/0000-0002-2309-9977; Jiang, Xianta/0000-0002-3219-1871
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   Canadian Institutes of Health Research (CIHR); Canada Research Chair
   (CRC) program
FX This research was supported by the Natural Sciences and Engineering
   Research Council of Canada (NSERC), the Canadian Institutes of Health
   Research (CIHR), and the Canada Research Chair (CRC) program. The
   authors thank Mary Yu, Tingyu Hu, and Wenxuan Song for helping with the
   VR content development and data collection.
CR Al-Timemy AH, 2016, IEEE T NEUR SYS REH, V24, P650, DOI 10.1109/TNSRE.2015.2445634
   Amsüss S, 2014, IEEE T BIO-MED ENG, V61, P1167, DOI 10.1109/TBME.2013.2296274
   [Anonymous], 2013, Virtual and augmented reality applications in manufacturing
   [Anonymous], 2014, Proc. 27th Annu. ACM Symp. on User Interface Software and Technology, DOI 10.1145/2642918.2647396
   Burdea G. C., 2003, Virtual reality technology
   Castro MCF, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0025-5
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P553, DOI 10.1109/ICMLA.2014.112
   Colgan A, 2018, LEAP MOTION BLOG
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Englehart K, 2003, IEEE T BIO-MED ENG, V50, P848, DOI 10.1109/TBME.2003.813539
   Faria AJ, 2009, SIMULAT GAMING, V40, P464, DOI 10.1177/1046878108327585
   Farrell TR, 2007, IEEE T NEUR SYS REH, V15, P111, DOI 10.1109/TNSRE.2007.891391
   Feix T, 2014, IEEE T HAPTICS, V7, P311, DOI 10.1109/TOH.2014.2326871
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fove Inc, 2017, FOVE 0 EYE TRACK VIR
   Grimm F, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00518
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   InterlinkElectronics, 2010, FSR INT GUID EV PART
   Jiang XT, 2018, IEEE T HUM-MACH SYST, V48, P219, DOI [10.1109/THMS.2017.2693245, 10.1109/TNNLS.2017.2689098]
   Jiang XT, 2017, MED ENG PHYS, V41, P63, DOI 10.1016/j.medengphy.2017.01.015
   Jin HY, 2016, CAAI T INTELL TECHNO, V1, P104, DOI 10.1016/j.trit.2016.03.010
   Kolsch Mathias., 2004, Vision based hand gesture interfaces for wearable computing and virtual environments"
   Li N, 2012, J BIONIC ENG, V9, P39, DOI 10.1016/S1672-6529(11)60095-4
   Luna MF, 2015, BRAZ SYM COMPUT SYST, P128, DOI 10.1109/SBESC.2015.31
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Mine M. R., 1995, TR95018 UNC CHAP HIL
   Motion L, 2017, LEAP MOTION SDK
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   Riillo F, 2014, BIOMED SIGNAL PROCES, V14, P117, DOI 10.1016/j.bspc.2014.07.007
   Sadarangani Gautam P, 2017, Front Bioeng Biotechnol, V5, P42, DOI 10.3389/fbioe.2017.00042
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Satava R., 1997, Annals Academy of Medicine Singapore, V26, P118
   Scheme E, 2011, J REHABIL RES DEV, V48, P643, DOI 10.1682/JRRD.2010.09.0177
   Sutherland LM, 2006, ANN SURG, V243, P291, DOI 10.1097/01.sla.0000200839.93965.26
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Vargas H.F., 2015, 2014 19 S IM SIGN PR, P3502, DOI [10.1109/STSIVA.2014.7010172, DOI 10.1109/STSIVA.2014.7010172]
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Wininger M, 2008, J REHABIL RES DEV, V45, P883, DOI 10.1682/JRRD.2007.11.0187
   Yaniger S. I., 1991, Electro International. Conference Record, P666, DOI 10.1109/ELECTR.1991.718294
   Zhang HS, 2013, IEEE ENG MED BIO, P4267, DOI 10.1109/EMBC.2013.6610488
   Zurada J.M., 1992, INTRO ARTIFICIAL NEU
NR 45
TC 21
Z9 21
U1 3
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 297
EP 308
DI 10.1007/s10055-018-0339-2
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600002
DA 2024-07-18
ER

PT J
AU Kim, Y
   Hong, S
   Kim, GJ
AF Kim, Youngsun
   Hong, Seokjun
   Kim, Gerard Jounghyun
TI Augmented reality-based remote coaching for fast-paced physical task
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Tele-coaching; Multimodal feedback; Pre-attentive
   recognition
ID VIRTUAL ENVIRONMENTS; VISUALIZATION; SPEECH
AB One popular application of augmented reality (AR) is the real-time guidance and training in which the AR user receives useful information by a remote expert. For relatively fast-paced tasks, presentation of such guidance in a way that the recipient can make immediate recognition and quick understanding can be an especially challenging problem. In this paper, we present an AR-based tele-coaching system applied to the game of tennis, called the AR coach, and explore for interface design guidelines through a user study. We have evaluated the player's performance for instruction understanding when the coaching instruction was presented in four different modalities: (1) Visual-visual only, (2) Sound-aural only/mono, (3) 3D Sound-aural only/3D and (4) Multimodal-both visual and aural/mono. Results from the experiment suggested that, among the three, the visual-only augmentation was the most effective and least distracting for the given pace of information transfer (e.g., under every 3 s). We attribute such a result to the characteristic of the visual modality to encode and present a lot of information at once and the human's limited capability in handling and fusing multimodal information at a relatively fast rate.
C1 [Kim, Youngsun; Hong, Seokjun; Kim, Gerard Jounghyun] Korea Univ, Digital Experience Lab, Seoul, South Korea.
C3 Korea University
RP Kim, GJ (corresponding author), Korea Univ, Digital Experience Lab, Seoul, South Korea.
EM zyoko85@korea.ac.kr; hong921122@korea.ac.kr; gjkim@korea.ac.kr
FU Institute for Information & communications Technology Promotion(IITP)
   grant - Korea government(MSIP) [R0190-16-2011]; National Research
   Foundation of Korea (NRF) Grant - Korean Government(MSIP) [2011-0030079]
FX This work was supported in part by Institute for Information &
   communications Technology Promotion(IITP) grant funded by the Korea
   government(MSIP) (No. R0190-16-2011, Development of Vulnerability
   Discovery Technologies for IoT Software Security), and also in part by
   the National Research Foundation of Korea (NRF) Grant funded by the
   Korean Government(MSIP) (No. 2011-0030079).
CR [Anonymous], 2012, INFORM VISUAL
   Avery B, 2012, P IEEE C VIRT REAL, P79
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Blattner M. M., 1989, Human-Computer Interaction, V4, P11, DOI 10.1207/s15327051hci0401_1
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Borst JP, 2010, J EXP PSYCHOL LEARN, V36, P363, DOI 10.1037/a0018106
   Byrne MD, 2001, PSYCHOL REV, V108, P847, DOI 10.1037/0033-295X.108.4.847
   Damos D., 1991, Multiple-task performance, P101
   Fuchs H, 1998, LECT NOTES COMPUT SC, V1496, P934, DOI 10.1007/BFb0056282
   Grasso M. A., 1998, ACM Transactions on Computer-Human Interaction, V5, P303, DOI 10.1145/300520.300521
   Gröhn M, 2001, P SOC PHOTO-OPT INS, V4302, P13, DOI 10.1117/12.424939
   HAUPTMANN AG, 1993, INT J MAN MACH STUD, V38, P231, DOI 10.1006/imms.1993.1011
   Hecht D, 2006, PRESENCE-TELEOP VIRT, V15, P515, DOI 10.1162/pres.15.5.515
   JAIMES A, 2005, IEEE INT WORKSH HUM
   Kajastila R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P758, DOI 10.1145/2858036.2858450
   Lécuyer A, 2003, P IEEE VIRT REAL ANN, P251, DOI 10.1109/VR.2003.1191147
   Manuri Federico., 2016, ACSIJ ADV COMPUTER S, V5, P19
   Narzt W., 2006, Universal Access in the Information Society, V4, P177, DOI 10.1007/s10209-005-0017-5
   Navab N, 2007, IEEE COMPUT GRAPH, V27, P10, DOI 10.1109/MCG.2007.117
   Oviatt S., 2002, MULTIMODAL INTERFACE
   Richard P., 1994, P ICAT 94 C, P49
   Rubinstein JS, 2001, J EXP PSYCHOL HUMAN, V27, P763, DOI 10.1037//0096-1523.27.4.763
   Sallnas E.-L., 2000, ACM Transactions on Computer-Human Interaction, V7, P461, DOI 10.1145/365058.365086
   Salvucci DD, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1819
   Schwald B, 2003, P WSCG 2003
   Strayer D.L., 2007, ATTENTION THEORY PRA, P121
   Tatzgern M, 2013, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2013.6549347
   Tonnis M, 2009, P INT ERG ASS
   Walker BN, 2013, HUM FACTORS, V55, P157, DOI 10.1177/0018720812450587
   Zheng XJS, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2125, DOI 10.1145/2702123.2702305
NR 30
TC 8
Z9 10
U1 0
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 25
EP 36
DI 10.1007/s10055-017-0315-2
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200003
DA 2024-07-18
ER

PT J
AU Smolentsev, A
   Cornick, JE
   Blascovich, J
AF Smolentsev, Alexander
   Cornick, Jessica E.
   Blascovich, Jim
TI Using a preamble to increase presence in digital virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Environment; Familiarity; Immersion; Preamble; Presence; Transitional
   environment; Virtual reality
ID REALITY; FAMILIARITY; IMMERSION; BEHAVIOR
AB Immersion in a digital virtual environment (DVE) increases the likelihood that individuals will feel present in the DVE and hence respond as they would in a similar physically grounded environment. Previous research utilizing high-fidelity technology has demonstrated that by starting a virtual experience in a virtual replica of the immediate physical environment, presence is increased. The purpose of this study was to determine whether utilizing such a transitional environment to increase presence could be replicated on a significantly less immersive system-a 2D desktop monitor with mouse and keyboard for navigation. Participants began their DVE experience either in a "preamble" DVE made to look like the surrounding physical laboratory space, or in a novel DVE (i.e., a house). Then, they were given verbal instructions to leave their respective environments and told to go up a set of stairs to explore a museum. Afterward, they reported levels of immersion and presence in the latter DVE. Results demonstrated that entering a target DVE via a familiar "preamble" environment increased perceptions of reality judgment of the virtual experience, perceptions of possibility to act, and levels of presence. These results suggest that incorporating a familiar digital preamble environment as a prelude to the target DVE enables DVE designers and enthusiasts to increase presence without having to invest in more expensive hardware, but it could also augment existing immersive technology. Their efficacy may be because they offer a gradual transition into the virtual world, such that the familiarity eases users into the novel experience.
C1 [Smolentsev, Alexander; Cornick, Jessica E.; Blascovich, Jim] Univ Calif Santa Barbara, Dept Psychol, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara
RP Smolentsev, A (corresponding author), Univ Calif Santa Barbara, Dept Psychol, Santa Barbara, CA 93106 USA.
EM alexandersmolentsev@umail.ucsb.edu
OI Smolentsev, Alexander/0000-0002-1930-5264
FU Undergraduate Research and Creative Activities Grant by the University
   of California, Santa Barbara [2691]
FX Research was funded by the Undergraduate Research and Creative
   Activities Grant #2691 provided by the University of California, Santa
   Barbara.
CR [Anonymous], P 11 ANN INT WORKSH
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Barfield W, 2016, PRESENCE-TELEOP VIRT, V25, P148, DOI 10.1162/PRES_a_00252
   Blascovich J., 2011, Infinite Reality: Avatars, Eternal Life, New Worlds, and the Dawn of the Virtual Revolution
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   EPSTEIN W, 1960, PSYCHOL MONOGR, V74, P1
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Kihlstrom JF, 2003, HANDBOOK OF SELF AND IDENTITY, P68
   Klimmt C, 2003, PRESENCE-VIRTUAL AUG, V12, P346, DOI 10.1162/105474603322391596
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Ogletree SM, 2007, SEX ROLES, V56, P537, DOI 10.1007/s11199-007-9193-5
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   Seow SC, 2008, DESIGNING ENG TIME P, P65
   SHAPIRO MA, 1992, J COMMUN, V42, P94, DOI 10.1111/j.1460-2466.1992.tb00813.x
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Soppe M, 2005, INSTR SCI, V33, P271, DOI 10.1007/s11251-004-7688-9
   Sproll D, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P175, DOI 10.1109/3DUI.2013.6550235
   Steinicke F, 2010, COMPUT GRAPH-UK, V34, P26, DOI 10.1016/j.cag.2009.12.003
   Steinicke F, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P203, DOI 10.1109/VR.2009.4811024
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Swaney W, 2001, ANIM BEHAV, V62, P591, DOI 10.1006/anbe.2001.1788
   Trimble Navigation Limited, 2014, SKETCHUP PRO VERS 14
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   WorldViz, 2015, VIZ VERS 5 2
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
NR 34
TC 19
Z9 21
U1 1
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2017
VL 21
IS 3
BP 153
EP 164
DI 10.1007/s10055-017-0305-4
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA FB8YV
UT WOS:000406427400004
DA 2024-07-18
ER

PT J
AU Parmar, D
   Bertrand, J
   Babu, SV
   Madathil, K
   Zelaya, M
   Wang, TW
   Wagner, J
   Gramopadhye, AK
   Frady, K
AF Parmar, Dhaval
   Bertrand, Jeffrey
   Babu, Sabarish V.
   Madathil, Kapil
   Zelaya, Melissa
   Wang, Tianwei
   Wagner, John
   Gramopadhye, Anand K.
   Frady, Kristin
TI A comparative evaluation of viewing metaphors on psychophysical skills
   education in an interactive virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE HMD; Human factors; Education; 3D human-computer interaction
ID 3D; PERFORMANCE; SYSTEM
AB In an empirical evaluation, we examined the effect of viewing condition on psychophysical skills education in an interactive 3D simulation to train users in electrical circuitry. We compared an immersive head-mounted display (HMD)-based viewing metaphor versus a limited, desktop-based virtual reality (DVR) viewing metaphor with interaction using a spatial user interface. Psychophysical skills education involves the association of cognitive functions with motor functions to make the task autonomous with repeated practice. In electrical circuitry, this is demonstrated by the fine movements involved in handling and manipulating components on the electrical circuit, particularly while measuring electrical parameters. We created an interactive circuitry simulation (IBAS) where participants could learn about electrical measurement instruments such as the ammeter, voltmeter and multimeter, in a simulated breadboard VR system. Twenty-four participants utilized the simulation (12 in each condition), and the quantitative and qualitative aspects of psychophysical skills education with respect to the viewing metaphor were examined. Each viewing condition in IBAS was head-tracked and non-stereoscopic. Perspective correction was coupled with head-tracking in the DVR condition. The key quantitative measures were cognitive questionnaires addressing different levels of Bloom's cognitive taxonomy and a real-world psychophysical task addressing various levels of Dave's psychomotor taxonomy. The qualitative measures were the Witmer-Singer sense of presence questionnaire and self-report. Results suggest that there was a significant increase in cognition post-experiment in both DVR and HMD viewing conditions in levels of knowledge, application, analysis and evaluation. Results also revealed a significant learning benefit with respect to the higher level concepts pertaining to evaluation in the HMD condition as compared to DVR. Participants seem to have enjoyed a greater level of affordance in task performance and spent a larger amount of time to complete the simulated exercises as well as manually maneuvered to further distances in the HMD viewing condition as compared to DVR viewing.
C1 [Parmar, Dhaval; Bertrand, Jeffrey; Babu, Sabarish V.] Clemson Univ, Sch Comp, 120 McAdams Hall, Clemson, SC 29634 USA.
   [Madathil, Kapil; Zelaya, Melissa; Frady, Kristin] Clemson Univ, Dept Ind Engn, 110 Freeman Hall, Clemson, SC 29634 USA.
   [Wang, Tianwei; Wagner, John] Clemson Univ, Dept Mech Engn, 212 Fluor Daniel, Clemson, SC 29634 USA.
   [Gramopadhye, Anand K.] Clemson Univ, Coll Engn & Sci, 109 Riggs Hall, Clemson, SC 29634 USA.
C3 Clemson University; Clemson University; Clemson University; Clemson
   University
RP Parmar, D (corresponding author), Clemson Univ, Sch Comp, 120 McAdams Hall, Clemson, SC 29634 USA.
EM dkparma@clemson.edu
RI Frady, Kristin/AAQ-7129-2021; Parmar, Dhaval/W-2724-2019
OI Parmar, Dhaval/0000-0003-4031-7144; Frady, Kristin/0000-0002-4194-8848;
   Bertrand, Jeffrey/0000-0002-3921-4693
FU National Science Foundation [DUE-1104181]
FX This work was supported by the National Science Foundation under Grant
   No. DUE-1104181. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the National Science
   Foundation.
CR Aoki H, 2008, ACTA ASTRONAUT, V63, P841, DOI 10.1016/j.actaastro.2007.11.001
   ARTHUR KW, 1993, ACM T INFORM SYST, V11, P239, DOI 10.1145/159161.155359
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P88, DOI 10.1109/93.998075
   Baheti A, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P479
   Bell JT, 1997, ANN ARBOR, V48, P109
   Bertrand J, 2015, IEEE VIRT REAL C VR
   Bloom B, 1956, TAXONOMY ED OBJECTIV
   Chen ZheMin, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P585, DOI 10.1109/CSIE.2009.180
   Crooks TJ, 1988, ASSESSING STUDENT PE, V8
   Dave R.H., 1975, DEV WRITING BEHAV OB
   Demiralp C., 2003, Proceedings of the 14th IEEE Visualization (VIS'03), P86
   Ekstrom R., 1976, Kit of factor-referenced cognitive tests
   El-Chaar J., 2011, Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety (ICRMS 2011), P1376, DOI 10.1109/ICRMS.2011.5979485
   ERICSSON KA, 1994, AM PSYCHOL, V49, P725, DOI 10.1037/0003-066X.49.8.725
   Finkelstein ND, 2005, PHYS REV SPEC TOP-PH, V1, DOI 10.1103/PhysRevSTPER.1.010101
   Green M, 1996, COMMUN ACM, V39, P46, DOI 10.1145/229459.229465
   Guilford JP, 1948, J APPL PSYCHOL, V32, P24, DOI 10.1037/h0063610
   He Lingsong, 2011, 2011 IEEE Conference on Open Systems, P139, DOI 10.1109/ICOS.2011.6079284
   InterSense, 2015, INTERSENSE PREC MOT
   Jou M, 2013, COMPUT HUM BEHAV, V29, P433, DOI 10.1016/j.chb.2012.04.020
   Kaufmann H., 2000, Education and Information Technologies, V5, P263, DOI 10.1023/A:1012049406877
   Kiyokawa K, 1998, ELECTRON COMM JPN 3, V81, P18, DOI 10.1002/(SICI)1520-6440(199811)81:11<18::AID-ECJC3>3.0.CO;2-N
   Kotranza A, 2009, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2009.5336485
   Menéndez LM, 2006, IEEE IND ELEC, P4581
   Mizell D.W., 2002, COMP IMMERSIVE VIRTU
   Mlyniec P, 2011, STUD HEALTH TECHNOL, V163, P372, DOI 10.3233/978-1-60750-706-2-372
   Noble RA, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P187, DOI 10.1109/CGI.1998.694266
   Aguirre IJO, 2013, IEEE REV IBEROAM TEC, V8, P143, DOI 10.1109/RITA.2013.2273115
   Parmar D, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P181, DOI 10.1109/3DUI.2014.6798880
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Qi W., 2006, Proc. Symp. on Applied Perception in Graphics and Visualization (APGV), P51, DOI DOI 10.1145/1140491.1140502
   Ragan ED, 2013, IEEE T VIS COMPUT GR, V19, P886, DOI 10.1109/TVCG.2012.163
   Razer, 2015, RAZ HYDR GAM CONTR
   Richardson JJ, 2011, ENG DES GRAPH J, V74, P1
   Robertson G., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P11, DOI 10.1145/263407.263409
   Rosenbaum DA, 2001, ANNU REV PSYCHOL, V52, P453, DOI 10.1146/annurev.psych.52.1.453
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Schmitz B., 2012, P 11 WORLD C MOB CON, P140
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Tawfik M, 2013, IEEE T LEARN TECHNOL, V6, P60, DOI 10.1109/TLT.2012.20
   Unity, 2015, UN GAM ENG
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zacharia ZC, 2007, J COMPUT ASSIST LEAR, V23, P120, DOI 10.1111/j.1365-2729.2006.00215.x
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
NR 44
TC 36
Z9 38
U1 6
U2 77
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2016
VL 20
IS 3
BP 141
EP 157
DI 10.1007/s10055-016-0287-7
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DV0XZ
UT WOS:000382645300001
DA 2024-07-18
ER

PT J
AU Borsci, S
   Lawson, G
   Jha, B
   Burges, M
   Salanitri, D
AF Borsci, Simone
   Lawson, Glyn
   Jha, Bhavna
   Burges, Mark
   Salanitri, Davide
TI Effectiveness of a multidevice 3D virtual environment application to
   train car service maintenance procedures
SO VIRTUAL REALITY
LA English
DT Article
DE Automotive; Effectiveness of training; Virtual reality; Usability; Turst
ID AUGMENTED REALITY; DESK-TOP; ACQUISITION; SKILLS; CLASSIFICATION;
   SATISFACTION; USABILITY; MODEL
AB This paper reports a study which demonstrates the advantages of using virtual-reality-based systems for training automotive assembly tasks. Sixty participants were randomly assigned to one of the following three training experiences to learn a car service procedure: (1) observational training through video instruction; (2) an experiential virtual training and trial in a CAVE; and (3) an experiential virtual training and trial through a portable 3D interactive table. Results show that virtual trained participants, after the training, can remember significantly better (p < .05) the correct execution of the steps compared to video-trained trainees. No significant differences were identified between the experiential groups neither in terms of post-training performances nor in terms of proficiency, despite differences in the interaction devices. The relevance of the outcomes for the automotive fields and for the designers of virtual training applications are discussed in light of the outcomes, particularly that virtual training experienced through a portable device such as the interactive table can be effective, as can training performed in a CAVE. This suggests the possibility for automotive industries to invest in advanced portable hardware to deliver effectively long-distance programs of training for car service operators placed all over the world.
C1 [Borsci, Simone] Univ London Imperial Coll Sci Technol & Med, Natl Inst Hlth Res Diagnost Evidence Cooperat Lon, London, England.
   [Lawson, Glyn; Salanitri, Davide] Univ Nottingham, Fac Engn, Human Factors Res Grp, Nottingham NG7 2RD, England.
   [Jha, Bhavna] Jaguar Land Rover, Abbey Rd, Coventry CV3 4LF, W Midlands, England.
   [Burges, Mark] Holovis Int Ltd, Lutterworth, England.
C3 Imperial College London; University of Nottingham; Jaguar Land Rover
RP Borsci, S (corresponding author), Univ London Imperial Coll Sci Technol & Med, Natl Inst Hlth Res Diagnost Evidence Cooperat Lon, London, England.
EM simone.borsci@gmail.com; bjha1@jaguarlandrover.com
RI Borsci, Simone/AAB-2369-2019; Borsci, Simone/GRS-3540-2022
OI Borsci, Simone/0000-0002-3591-3577; Borsci, Simone/0000-0002-3591-3577;
   Lawson, Glyn/0000-0002-8906-4873; Salanitri, Davide/0000-0001-5151-3103
FU Live Augmented Reality Training Environments (LARTE) [101509];
   Technology Strategy Board
FX This paper was completed as part of Live Augmented Reality Training
   Environments (LARTE)-101509 Project. The authors would like to
   acknowledge the Technology Strategy Board for funding the work.
CR Ahlberg G, 2007, AM J SURG, V193, P797, DOI 10.1016/j.amjsurg.2006.06.050
   Alippi C, 2003, IEEE T SYST MAN CY C, V33, P259, DOI 10.1109/TSMCC.2003.814035
   Anastassova M, 2005, INT J IND ERGONOM, V35, P67, DOI 10.1016/j.ergon.2004.08.005
   Anastassova M, 2009, APPL ERGON, V40, P713, DOI 10.1016/j.apergo.2008.06.008
   ANDERSON JR, 1982, PSYCHOL REV, V89, P369, DOI 10.1037/0033-295X.89.4.369
   [Anonymous], 2011, BIO WEB C, DOI DOI 10.1051/BIOCONF/20110100029
   Bandura A., 1992, Encyclopedia of learning and memory
   Belardinelli C, 2008, COGN PROCESS, V9, P217, DOI 10.1007/s10339-008-0216-0
   Borsci Simone, 2015, Human-Computer Interaction, Users and Contexts. 17th International Conference, HCI International 2015. Proceedings: LNCS 9171, P135, DOI 10.1007/978-3-319-21006-3_14
   Borsci S, 2015, INT J HUM-COMPUT INT, V31, P484, DOI 10.1080/10447318.2015.1064648
   Borsci S, 2015, COMPUT IND, V67, P17, DOI 10.1016/j.compind.2014.12.002
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Bruner J., 1966, Toward a theory of instruction
   Cabral M.C., 2005, P 2005 LAT AM C HUM
   Corvaglia D., 2004, Proc. of the 1st International Workshop on Web3D Technologies in Learning, Education and Training (LETWEB3D 2004), Udine, P28
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   Dombrowski U., 2011, 2011 IEEE International Conference on Service Operations and Logistics and Informatics (SOLI), P77, DOI 10.1109/SOLI.2011.5986532
   Fast K, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P298, DOI 10.1109/ISMAR.2004.65
   Flavián C, 2006, INFORM MANAGE-AMSTER, V43, P1, DOI 10.1016/j.im.2005.01.002
   Gaiardelli P, 2014, J CLEAN PROD, V66, P507, DOI 10.1016/j.jclepro.2013.11.032
   Garg AX, 2002, ACAD MED, V77, pS97, DOI 10.1097/00001888-200210001-00030
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   HART S G, 1988, P139
   *ISO, 1998, 924111 ISO CEN
   Kolb A.Y., 2005, BOSTON MA, P72
   Kolb AY, 2005, ACAD MANAG LEARN EDU, V4, P193, DOI 10.5465/AMLE.2005.17268566
   Kolb D., 1984, Experimental Learning as the Science of Learning and Development
   Kothari SN, 2002, J LAPAROENDOSC ADV A, V12, P167, DOI 10.1089/10926420260188056
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Malmsköld L, 2015, HUM FACTOR ERGON MAN, V25, P304, DOI 10.1002/hfm.20540
   Mantovani F, 2003, CYBERPSYCHOL BEHAV, V6, P389, DOI 10.1089/109493103322278772
   Mantovani F., 2003, Towards Cyberpsychology: Mind, Cognitions and Society in the Internet Age, P207
   Mavrikios D, 2006, INT J COMPUT INTEG M, V19, P294, DOI 10.1080/09511920500340916
   McKnight D. H., 2011, Trans. Manag. Inf. Syst., V2, P1, DOI [10.1145/1985347.1985353, DOI 10.1145/1985347.1985353]
   Mikropoulos T., 1997, Education and Information Technologies, V2, P131, DOI 10.1023/A:1018648810609
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Noor AK, 2015, ADV ENG SOFTW, V81, P1, DOI 10.1016/j.advengsoft.2014.10.004
   Ottosson S, 2002, J ENG DESIGN, V13, P159, DOI 10.1080/09544820210129823
   Parry G, 2011, SERV SCI RES INNOV S, P19, DOI 10.1007/978-1-4419-8321-3_2
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Renkl A, 2014, COGNITIVE SCI, V38, P1, DOI 10.1111/cogs.12086
   Salanitri D, 2015, LECT NOTES COMPUT SC, V9169, P49, DOI 10.1007/978-3-319-20901-2_5
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Selvander M, 2012, ACTA OPHTHALMOL, V90, P412, DOI 10.1111/j.1755-3768.2010.02028.x
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sherman V, 2005, SURG ENDOSC, V19, P678, DOI 10.1007/s00464-004-8943-5
   Stork A., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P347, DOI 10.1109/VSMM.2012.6365944
   Tang A., 2003, P SIGCHI C HUM FACT
   Valdez MT, 2013, 2013 PROCEEDINGS OF THE 24TH ANNUAL CONFERENCE ON EUROPEAN ASSOCIATION FOR EDUCATION IN ELECTRICAL AND INFORMATION ENGINEERING (EAEEIE), P145, DOI 10.1109/EAEEIE.2013.6576518
   Watterson JD, 2002, J UROLOGY, V168, P1928, DOI 10.1016/S0022-5347(05)64265-6
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
   Yuviler-Gavish N, 2011, INT J HUM-COMPUT ST, V69, P113, DOI 10.1016/j.ijhcs.2010.11.005
NR 60
TC 28
Z9 32
U1 4
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2016
VL 20
IS 1
BP 41
EP 55
DI 10.1007/s10055-015-0281-5
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1FY
UT WOS:000376092000004
OA Green Published, Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Iwai, D
   Sato, K
AF Iwai, Daisuke
   Sato, Kosuke
TI Document search support by making physical documents transparent in
   projection-based mixed reality
SO VIRTUAL REALITY
LA English
DT Article
DE Projection-based mixed reality; Document search support; Making
   documents transparent; Thermal image processing; Thermal trace; Touch
   sensing
AB This paper presents Limpid Desk that supports document search on a physical desktop by making the upper layer of a document stack transparent in a projection-based mixed reality environment. A user can visually access a lower-layer document without physically removing the upper documents. This is accomplished by superimposition of cover textures of lower-layer documents on the upper documents by projected imagery. This paper introduces a method of generating projection images that make physical documents transparent. Furthermore, a touch sensing method based on thermal image processing is proposed for the system's input interface. Areas touched by a user on physical documents can be detected without any user-worn or handheld devices. This interface allows a user to select a stack to be made transparent by a simple touch gesture. Three document search support techniques are realized using the system. User studies are conducted, and the results show the effectiveness of the proposed techniques.
C1 [Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Osaka 5608531, Japan.
C3 Osaka University
RP Iwai, D (corresponding author), Osaka Univ, Grad Sch Engn Sci, Machikaneyama 1-3, Osaka 5608531, Japan.
EM daisuke.iwai@sys.es.osaka-u.ac.jp
RI Iwai, Daisuke/R-8174-2019
OI Iwai, Daisuke/0000-0002-3493-5635
CR [Anonymous], P 14 ANN ACM S US IN
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2007, EG SHORT PAPERS
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Baudisch P., 2004, P SIGCHI C HUMAN FAC, P367, DOI DOI 10.1145/985692.985739
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Bonanni Leonardo., 2005, CHI '05 Extended Abstracts on Human Factors in Computing Systems. CHIEA '05, P1228, DOI DOI 10.1145/1056808.1056883
   Grundhöfer A, 2008, IEEE T VIS COMPUT GR, V14, P97, DOI 10.1109/TVCG.2007.1052
   HO HN, 2007, P 2007 INFRAMATION C, P431
   Inami M, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P348, DOI 10.1109/ISMAR.2003.1240754
   Iwai D., 2006, P ACM S VIRTUAL REAL, P112, DOI [DOI 10.1145/1180495.1180519, 10.1145/1180495.1180519]
   IWAI D, 2006, P IEEE WORKSH EM DIS, P30
   Iwai D., 2005, Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology, P213
   Kim J., 2004, UIST, P99, DOI [10.1145/1029632.1029650, DOI 10.1145/1029632.1029650]
   Koike H., 2001, ACM Transactions on Computer-Human Interaction, V8, P307, DOI 10.1145/504704.504706
   Launius R., 2005, Arkham Horror
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Sato K., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P657
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   SIIO I, 2003, P ACM C HUM FACT COM, P982
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Yasuda K, 2004, IEEE COMPUT GRAPH, V24, P26, DOI 10.1109/MCG.2004.1255805
   Yoshida T., 2003, P INT C VIRT SYST MU, P161
NR 24
TC 22
Z9 27
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 147
EP 160
DI 10.1007/s10055-010-0159-5
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200006
DA 2024-07-18
ER

PT B
AU Gamito, P
   Oliveira, J
   Morais, D
   Rosa, P
   Saraiva, T
AF Gamito, Pedro
   Oliveira, Jorge
   Morais, Diogo
   Rosa, Pedro
   Saraiva, Tomaz
BE Kim, JJ
TI Serious Games for Serious Problems: from <i>Ludicus</i> to Therapeuticus
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID DSM-IV DISORDERS; VIRTUAL-REALITY; PHARMACOLOGICAL-TREATMENTS; COGNITIVE
   THERAPY; EXPOSURE THERAPY; WAR VETERANS; PAIN-CONTROL; ANXIETY;
   SCHIZOPHRENIA; METAANALYSIS
C1 [Gamito, Pedro; Oliveira, Jorge; Morais, Diogo; Rosa, Pedro; Saraiva, Tomaz] Univ Lusofona Humanidades & Tecnol, Lisbon, Portugal.
   [Gamito, Pedro] Clin S Joao deDeus, Lisbon, Portugal.
   [Rosa, Pedro] ISCTE IUL CIS, Lisbon, Portugal.
C3 Lusofona University
RP Gamito, P (corresponding author), Univ Lusofona Humanidades & Tecnol, Lisbon, Portugal.
RI Morais, Diogo/N-1425-2019; Oliveira, J/F-4476-2015; Oliveira,
   Jorge/HSH-4076-2023; gamito, pedro/G-4353-2013
OI Morais, Diogo/0000-0002-7482-1448; Oliveira, J/0000-0002-3467-4981;
   Oliveira, Jorge/0009-0002-3122-8457; gamito, pedro/0000-0003-0585-8447
CR Abramowitz JS, 1997, J CONSULT CLIN PSYCH, V65, P44, DOI 10.1037/0022-006X.65.1.44
   Alexander R. D., 1987, Evolutionary Foundations of Human Behavior Series
   Allred RP, 2005, RESTOR NEUROL NEUROS, V23, P297
   Anderson E. F., 2009, 10 INT S VIRT REAL A, P29
   [Anonymous], 1974, The psychology of learning and motivation, DOI DOI 10.1016/S0079-7421(08)60452-1
   [Anonymous], GLOB ENT MED OUTL 20
   [Anonymous], P MIE2006
   [Anonymous], 2007, SERIOUS GAMES OVERVI
   APA A.P. A., 2000, Diagnostic and statistical manual of mental disorders: DSM-IV, V4th
   BADDELEY A, 1993, NEUROPSYCHOL REHABIL, V3, P235, DOI 10.1080/09602019308401438
   Baños RM, 2006, LECT NOTES COMPUT SC, V3962, P7
   Beck A.T., 1979, COGNITIVE THERAPY DE
   Beck Aaron T., 1996, P1
   Becker D., 2004, USA PUSHES VIDEO GAM
   Bellack AS, 2006, SCHIZOPHRENIA BULL, V32, P432, DOI 10.1093/schbul/sbj044
   Bender E., 2004, PSYCHIAT NEWS, V39, P45
   Bhugra D, 2005, PLOS MED, V2, P372, DOI 10.1371/journal.pmed.0020151
   Bjorklund D.F., 2007, WHY YOUTH IS NOT WAS
   Botella C, 2004, ST HEAL T, V99, P37
   Botella C, 2004, CYBERPSYCHOL BEHAV, V7, P527, DOI 10.1089/cpb.2004.7.527
   Botella C, 2000, BEHAV THER, V31, P583, DOI 10.1016/S0005-7894(00)80032-5
   Bryanton C, 2006, CYBERPSYCHOL BEHAV, V9, P123, DOI 10.1089/cpb.2006.9.123
   Carrougher GF, 2003, J BURN CARE REHABIL, V24, P1, DOI 10.1097/00004630-200301000-00003
   Chen Y., 2004, PHYS THER, V87, P1441
   Cooper RA, 2008, MED ENG PHYS, V30, P1387, DOI 10.1016/j.medengphy.2008.09.003
   Craske M.G., 1999, Anxiety disorders: Psychological approaches to theory and treatment
   David A S, 2001, Health Technol Assess, V5, P1
   Dgansetheman, 2005, MILITARY STEPS RECRU
   Difede J, 2006, ANN NY ACAD SCI, V1071, P500, DOI 10.1196/annals.1364.052
   Ditton Theresa, 1997, J COMPUTER MEDIATED, V3
   Dunbar J. C., 1966, AUTOMATED DOCUMENTAT
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Etkin A, 2007, AM J PSYCHIAT, V164, P1476, DOI 10.1176/appi.ajp.2007.07030504
   Fedoroff IC, 2001, J CLIN PSYCHOPHARM, V21, P311, DOI 10.1097/00004714-200106000-00011
   Foa E.B., 2000, Effective treatments for PTSD: Practice guidelines from the International Society for Traumatic Stress Studies
   Freeman D, 2008, SCHIZOPHRENIA BULL, V34, P605, DOI 10.1093/schbul/sbn020
   Gamito P., P 8 INT C D IN PRESS
   GAMITO P, 2008, J CYBERTHERAPY REHAB, V1, P258
   Gamito P, 2010, CYBERPSYCH BEH SOC N, V13, P43, DOI 10.1089/cyber.2009.0237
   Gamito P, 2009, STUD HEALTH TECHNOL, V144, P269, DOI 10.3233/978-1-60750-017-9-269
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Gazzaniga M.S., 2006, Psychological science: Mind, brain, and behavior, V2nd
   Gershon J, 2003, CYBERPSYCHOL BEHAV, V6, P657, DOI 10.1089/109493103322725450
   Glick F. K., 1970, COMPREHENSIVE DIGITA
   Gloaguen V, 1998, J AFFECT DISORDERS, V49, P59, DOI 10.1016/S0165-0327(97)00199-7
   Goodman WK, 2004, J CLIN PSYCHIAT, V65, P8
   Gorini Alessandra, 2008, Expert Rev Neurother, V8, P215, DOI 10.1586/14737175.8.2.215
   Gould NF, 2007, AM J PSYCHIAT, V164, P516, DOI 10.1176/appi.ajp.164.3.516
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Green C.S., 2006, Digital Media: Transformations in Human Communication
   Green CS, 2006, J EXP PSYCHOL HUMAN, V32, P1465, DOI 10.1037/0096-1523.32.6.1465
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   GREENFIELD PM., 1984, MIND MEDIA EFFECTS T
   Hamm AO, 2005, INT J PSYCHOPHYSIOL, V57, P5, DOI 10.1016/j.ijpsycho.2005.01.006
   Hirschfeld R., 2004, COURSE TREATMENT BIP, P28
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Hofmann SG, 2008, J CLIN PSYCHIAT, V69, P621, DOI 10.4088/jcp.v69n0415
   Huizinga J., 1971, Homo Ludens
   Josman N, 2009, SCHIZOPHR RES, V115, P270, DOI 10.1016/j.schres.2009.09.015
   Kessler RC, 2005, ARCH GEN PSYCHIAT, V62, P593, DOI 10.1001/archpsyc.62.6.593
   Koepp MJ, 1998, NATURE, V393, P266, DOI 10.1038/30498
   Leahy R.L., 2003, Cognitive therapy techniques: A practitioner's guide
   LeDoux JE, 2000, ANNU REV NEUROSCI, V23, P155, DOI 10.1146/annurev.neuro.23.1.155
   Levin MF, 2005, HONG KONG PHYSIOTHER, V23, P2, DOI 10.1016/S1013-7025(09)70052-1
   Lewis JA, 2006, CYBERPSYCHOL BEHAV, V9, P142, DOI 10.1089/cpb.2006.9.142
   MARK TL, 2007, SAMHSA PUBLICATION
   MELZACK R, 1990, SCI AM, V262, P27, DOI 10.1038/scientificamerican0290-27
   Michael D., 2006, SERIOUS GAMES GAMES
   Murray CJL, 1996, SCIENCE, V274, P740, DOI 10.1126/science.274.5288.740
   North MM, 1996, PRESENCE-TELEOP VIRT, V5, P346, DOI 10.1162/pres.1996.5.3.346
   Optale G, 2004, ST HEAL T, V99, P165
   Optale G, 1998, ST HEAL T, V58, P136
   Papalia D. E., 2005, CHILDS WORLD LIFEMAP
   Paré D, 2004, J NEUROPHYSIOL, V92, P1, DOI 10.1152/jn.00153.2004
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Perpiñá C, 2003, EUR EAT DISORD REV, V11, P261, DOI 10.1002/erv.520
   Rakoczy H, 2007, NEW DIR CHILD ADOLES, V115, P53, DOI 10.1002/cad.182
   Rand D., 2001, Phys. Occup. Ther. Geriatr, V18, P69, DOI [10.1080/J148v18n03_05, DOI 10.1080/J148V18N03_05]
   Ritterfeld U, 2009, CYBERPSYCHOL BEHAV, V12, P691, DOI 10.1089/cpb.2009.0099
   Riva G, 2004, ST HEAL T, V99, P121
   Riva G, 2003, CYBERPSYCHOL BEHAV, V6, P251, DOI 10.1089/109493103322011533
   Riva G., 1998, EXPERIENTIAL COGNITI
   Rizzo A., 2006, NATO Security through Science Series E Human and Societal Dynamics, V6, P235
   Rothbaum BO, 2002, AM J PSYCHOTHER, V56, P59, DOI 10.1176/appi.psychotherapy.2002.56.1.59
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Saraiva T, 2007, ANN REV CYBERTHERAPY, V5, P241
   Sohlberg M.M., 2001, COGNITIVE REHABILITA
   Sohlberg MM, 1989, INTRO COGNITIVE REHA
   Steele E, 2003, CYBERPSYCHOL BEHAV, V6, P633, DOI 10.1089/109493103322725405
   Strickland D, 1997, ST HEAL T, V44, P81
   Sugarman H, 2006, CYBERPSYCHOL BEHAV, V9, P178, DOI 10.1089/cpb.2006.9.178
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Üstün TB, 1999, LANCET, V354, P111, DOI 10.1016/S0140-6736(98)07507-2
   Viau A., 2004, P 15 INT SOC EL KIN, P51
   Vincelli F., 2002, EXPERT REV NEUROTHER, V2, P89
   Wang PJ, 2004, COMPUT METH PROG BIO, V74, P235, DOI 10.1016/j.cmpb.2003.08.001
   Weissman M., 2000, COMPREHENSIVE GUIDET
   WHO, 2004, GLOB BURD DIS 2004 I
   Wiederhold B.K., 2008, Journal of CyberTherapy Rehabilitation, V1, P23
   Williams LM, 2006, NEUROIMAGE, V29, P347, DOI 10.1016/j.neuroimage.2005.03.047
   Wilson B., 2003, NEUROPSYCHOLOGICAL R
   Wilson P. H., 2006, IEEE 5 INT WORKSH VI
   Wolpe J., 1973, PRACTICE BEHAV THERA
   Wykes T, 2007, BRIT J PSYCHIAT, V190, P421, DOI 10.1192/bjp.bp.106.026575
   Yehuda R, 1998, PSYCHIAT CLIN N AM, V21, P359, DOI 10.1016/S0193-953X(05)70010-1
   Ylvisaker M., 1998, TRAUMATIC BRAIN INJU, P221
   Yusoff A, 2009, 2009 9 IEEE INT C AD
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 109
TC 14
Z9 14
U1 0
U2 6
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 515
EP 536
D2 10.5772/553
PG 22
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400026
DA 2024-07-18
ER

PT J
AU Cowan, B
   Kapralos, B
AF Cowan, Brent
   Kapralos, Bill
TI GPU-based real-time acoustical occlusion modeling
SO VIRTUAL REALITY
LA English
DT Article
DE Graphics processing unit; Acoustical occlusion; Acoustical diffraction;
   Spatial sound; Real-time
ID EDGE-DIFFRACTION; COMPUTATION; SOUND
AB In typical environments, the direct path between a sound source and a listener is often occluded. However, due to the phenomenon of diffraction, sound still reaches the listener by "bending" around an obstacle that lies directly in the line of straight propagation. Modeling occlusion/diffraction effects is a difficult and computationally intensive task and thus generally ignored in virtual reality and videogame applications. Driven by the gaming industry, consumer computer graphics hardware and the graphics processing unit (GPU) in particular, have greatly advanced in recent years, outperforming the computational capacity of central processing units. Given the affordability, widespread use, and availability of computer graphics hardware, here we describe a computationally efficient GPU-based method that approximates acoustical occlusion/diffraction effects in real time. Although the method has been developed primarily for videogames where occlusion/diffraction is typically overlooked, it is relevant for dynamic and interactive virtual environments as well.
C1 [Cowan, Brent; Kapralos, Bill] Univ Ontario, Inst Technol, HETRU, Fac Business & Informat Technol, Oshawa, ON L1H 7K4, Canada.
C3 Ontario Tech University
RP Cowan, B (corresponding author), Univ Ontario, Inst Technol, HETRU, Fac Business & Informat Technol, 2000 Simcoe St N, Oshawa, ON L1H 7K4, Canada.
EM brent.cowan@uoit.ca; bill.kapralos@uoit.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX The financial support of the Natural Sciences and Engineering Research
   Council of Canada (NSERC) in the form of an Undergraduate Summer
   Research Award and a Post Graduate Scholarship to Brent Cowan and a
   Discovery Grant to Bill Kapralos is gratefully acknowledged.
CR ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   [Anonymous], PRINCIPLES APPL ROOM
   BASS HE, 1990, J ACOUST SOC AM, V88, P2019, DOI 10.1121/1.400176
   BIOT MA, 1957, J ACOUST SOC AM, V29, P381, DOI 10.1121/1.1908899
   Buck I, 2004, ACM T GRAPHIC, V23, P777, DOI 10.1145/1015706.1015800
   Calamia P. T., 2005, P FOR AC BUD HUNG AU, P2499
   Ekman M., 1994, Computer Architecture News, V33, P144
   Foley D., 1994, Introduction to Computer Graphics
   Funkhouser T, 2004, J ACOUST SOC AM, V115, P739, DOI 10.1121/1.1641020
   GEER D, 2005, IEEE COMPUT, V39, P14
   Hamidi Foad., 2009, The Open Virtual Reality Journal, V1, P8
   Hecht E., 2019, OPTICS, V5th
   HILLESLAND KE, 2004, P ACM WORKSH GEN PUR, P8
   Jensen HW., 2001, REALISTIC IMAGE SYNT, DOI [10.1201/9780429294907, DOI 10.1201/9780429294907]
   Kapralos B, 2008, PRESENCE-VIRTUAL AUG, V17, P527, DOI 10.1162/pres.17.6.527
   Kapralos B, 2008, BUILD ACOUST, V15, P289, DOI 10.1260/135101008786939973
   KELLER JB, 1962, J OPT SOC AM, V52, P116, DOI 10.1364/JOSA.52.000116
   Kuttrff H., 2000, Room acoustics, V4th edn
   LOKKI T, 2002, P AUD ENG SOC 21 INT, P317
   Luebke D, 2007, COMPUTER, V40, P96, DOI 10.1109/MC.2007.59
   Mark WR, 2003, ACM T GRAPHIC, V22, P896, DOI 10.1145/882262.882362
   Mehta Madan., 1999, ARCHITECTURAL ACOUST
   *MENSH, 2003, MOD AUD TECHN GAM
   MURPHY DT, 2003, P AUD ENG SOC 24 INT, P207
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Rost R.J., 2006, OpenGL Shading Language, V2nd
   Sherrod A., 2008, Game graphics programming
   Stevenson D., 1987, ACM SIGPLAN NOTICES, V22, P9
   Svensson UP, 1999, J ACOUST SOC AM, V106, P2331, DOI 10.1121/1.428071
   Torres RR, 2001, J ACOUST SOC AM, V109, P600, DOI 10.1121/1.1340647
   Tsingos N, 2001, COMP GRAPH, P545, DOI 10.1145/383259.383323
   Tsingos N, 2002, IEEE COMPUT GRAPH, V22, P28, DOI 10.1109/MCG.2002.1016696
   Tsingos N, 1997, PROC GRAPH INTERF, P9
   TSINGOS N, 2007, P EUR S REND GREN FR
   TSINGOS N, 1998, 104 CONV AUD ENG SOC
NR 35
TC 8
Z9 11
U1 0
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2010
VL 14
IS 3
BP 183
EP 196
DI 10.1007/s10055-010-0166-6
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HW
UT WOS:000296279700002
DA 2024-07-18
ER

PT J
AU Prada, R
   Payandeh, S
AF Prada, Rodolfo
   Payandeh, Shahram
TI On study of design and implementation of virtual fixtures
SO VIRTUAL REALITY
LA English
DT Article
DE Multimodal cues; Haptic interaction; Automatic constraints;
   Human-computer interaction; Scene graph environments; User performance
AB Virtual fixtures (VFs) can be defined as guiding constraints designed to enhance or assist human performance in a computer-controlled system by providing cues of haptic or audiovisual nature. In this paper we present a new characterization of VFs based on mechanics, and provide a set practical guidelines for the designers of such fixtures from a software architecture point of view. We propose an event-driven approach that facilitates the integration of these guiding constraints in a scene graphed-based environment. In this context some novel implementation of VFs are presented, where users may interact with a single or an assembled set of fixtures. We present two types of force attributes for VF and present their implications in a trajectory-following problem.
C1 [Prada, Rodolfo; Payandeh, Shahram] Simon Fraser Univ, Expt Robot & Graph Lab, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Payandeh, S (corresponding author), Simon Fraser Univ, Expt Robot & Graph Lab, Burnaby, BC V5A 1S6, Canada.
EM shahram@cs.sfu.ca
RI Payandeh, Shahram/IZQ-1865-2023
OI Payandeh, Shahram/0000-0001-6846-7289
CR Abbott JJ, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2699
   Bettini A, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1171, DOI 10.1109/IROS.2001.976327
   Chan M, 2004, P 1 S APPL PERC GRAP, P173
   Galeano D, 2005, 2005 IEEE International Workshop on Haptic Audio Visual Environments and their Applications, P45
   GILLESPIE B, 1998, P ASME, V64, P171
   Kuang AB, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P367, DOI 10.1109/HAPTIC.2004.1287223
   Marayong P, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1089, DOI 10.1109/IRDS.2002.1043876
   Nolin JT, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P404, DOI 10.1109/HAPTIC.2003.1191325
   Park S., 2001, INT C MEDICAL IMAGE, P1419, DOI DOI 10.1007/3-540-45468-3_
   Payandeh S, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P18, DOI 10.1109/HAPTIC.2002.998936
   Payandeh S, 2001, P AMER CONTR CONF, P4532, DOI 10.1109/ACC.2001.945693
   PAYANDEH S, 2003, P ACM 5 INT C MULT I, P301
   Prada R, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P375
   ROSENBERG LB, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P76, DOI 10.1109/VRAIS.1993.380795
   Sayers CP, 1994, OPERATOR INTERFACE T, V3, P4
   Schroeder WJ, 1996, IEEE VISUAL, P93, DOI 10.1109/VISUAL.1996.567752
   STRAUSS PS, 1992, COMP GRAPH, V26, P341, DOI 10.1145/142920.134089
   *VRML CONS, 1997, 147721 ISOIEC DIS VR
   Zhang H, 2004, IEEE INT CONF ROBOT, P3908
NR 19
TC 26
Z9 34
U1 1
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2009
VL 13
IS 2
BP 117
EP 129
DI 10.1007/s10055-009-0115-4
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XD
UT WOS:000208104200004
DA 2024-07-18
ER

PT J
AU Moody, L
   Waterworth, A
   Arthur, JG
   McCarthy, AD
   Harley, PJ
   Smallwood, RH
AF Moody, Louise
   Waterworth, Alan
   Arthur, John G.
   McCarthy, Avril D.
   Harley, Peter J.
   Smallwood, Rod H.
TI Beyond the visuals: tactile augmentation and sensory enhancement in an
   arthroscopy simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Tactile augmentation; Sensory enhancement; Sensory illusion; Surgical
   simulator; Mixed reality
AB This paper considers tactile augmentation, the addition of a physical object within a virtual environment (VE) to provide haptic feedback. The resulting mixed reality environment is limited in terms of the ease with which changes can be made to the haptic properties of objects within it. Therefore sensory enhancements or illusions that make use of visual cues to alter the perceived hardness of a physical object allowing variation in haptic properties are considered. Experimental work demonstrates that a single physical surface can be made to 'feel' both softer and harder than it is in reality by the accompanying visual information presented. The strong impact visual cues have on the overall perception of object hardness, indicates haptic accuracy may not be essential for a realistic virtual experience. The experimental results are related specifically to the development of a VE for surgical training; however, the conclusions drawn are broadly applicable to the simulation of touch and the understanding of haptic perception within VEs.
C1 [Moody, Louise] Coventry Univ, Sch Art & Design, Coventry CV1 5FB, W Midlands, England.
   [Waterworth, Alan; Smallwood, Rod H.] Univ Sheffield, Kroto Res Inst, Sheffield S3 7HQ, S Yorkshire, England.
   [Arthur, John G.] Univ Warwick, Dept Stat, Risk Initiat & Stat Consultancy Unit RISCU, Coventry CV4 7AL, W Midlands, England.
   [McCarthy, Avril D.] Royal Hallamshire Hosp, Med Engn Sect, Sheffield Teaching Hosp Trust, Sheffield S10 2JF, S Yorkshire, England.
   [Harley, Peter J.] Univ Sheffield, Dept Appl Math, Sheffield S3 7RH, S Yorkshire, England.
C3 Coventry University; University of Sheffield; University of Warwick;
   University of Sheffield; University of Sheffield
RP Moody, L (corresponding author), Coventry Univ, Sch Art & Design, Coventry CV1 5FB, W Midlands, England.
EM Louise.moody@coventry.ac.uk
RI Smallwood, Rod/C-5583-2011; Moody, Louise/Q-5133-2017
OI Smallwood, Rod/0000-0003-0134-0632; Arthur, John/0000-0002-6814-7178;
   Moody, Louise/0000-0003-2326-4124; McCarthy, Avril
   Dawn/0000-0001-8144-9480
CR Agus M, 2003, STUD HEALTH TECHNOL, V94, P4
   [Anonymous], 2002, EXPT PSYCHOL
   Basdogan C, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1274062
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   BOSHRA M, 1994, P IEEE INT C MULT FU, V2, P243
   BroNielsen M, 1997, MINIM INVASIV THER, V6, P106, DOI 10.3109/13645709709152712
   Burdea G., 1994, VIRTUAL REALITY TECH
   Chen E, 1998, P IEEE, V86, P524, DOI 10.1109/5.662877
   DIFRANCO DE, 1997, P ASME DYN SYST CONT, V61, P17
   DURFEE WK, 1997, P ASME DYN SYST CONT, V61, P139
   ELLIS RR, 1993, PERCEPT PSYCHOPHYS, V53, P315, DOI 10.3758/BF03205186
   England Rupert., 1995, Simulated and Virtual Realities: Elements of Perception, P131
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Gibson J. J., 1966, The ecological approach to visual perception
   Hillis JM, 2002, SCIENCE, V298, P1627, DOI 10.1126/science.1075396
   HOFFMAN H, 1996, P 1996 CONV AM PSYCH
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   LECUYER A, 2000, IEEE INT C VIRT REAL
   LECUYER A, 2001, IEEE INT C VIRT REAL
   LECUYER A, 2000, NATO RTA HUM FACT ME
   Lindeman R. W., 2002, Virtual Reality, V6, P130, DOI 10.1007/s100550200014
   McCarthy AD, 1998, ST HEAL T, V50, P302
   MCCARTHY AD, 2000, THESIS U SHEFFIELD U
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MINER N, 1996, P 1996 IMAGE C PHOEN
   MOODY L, 2003, HUMAN FACTORS AGE VI, P43
   Niemeyer G, 2004, STUD HEALTH TECHNOL, V98, P272
   PETZOLD B, 2004, PRESENCE, V12, P16
   SCHULTZ LM, 1994, PERCEPT MOTOR SKILL, V78, P395, DOI 10.2466/pms.1994.78.2.395
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   SRINIVASAN MA, 1996, IMPACT VISUAL INFORM, V58, P555
   TAN HZ, 1994, DYNAMIC SYSTEMS CONT, V55, P353
   Thomas, 1986, HDB PERCEPTION HUMAN
   WANG Y, 2000, CHI 2000 1 6 APR, P532
   Webster RW, 2001, ST HEAL T, V81, P567
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Zivanovic A, 2003, ST HEAL T, V94, P413
NR 37
TC 13
Z9 15
U1 1
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 59
EP 68
DI 10.1007/s10055-008-0106-x
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kang, CL
   Yeom, I
   Ashtari, A
   Woo, W
   Noh, J
AF Kang, Cholmin
   Yeom, Inhwa
   Ashtari, Amirsaman
   Woo, Woontack
   Noh, Junyong
TI ARbility: re-inviting older wheelchair users to in-store shopping via
   wearable augmented reality
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Accessibility; Object detection; Wheelchair users
ID ACCESSIBILITY; DISABILITY; OUTCOMES; RISK; PAIN
AB Engaging in outdoor daily activities such as shopping is an essential, yet challenging activity for older wheelchair users (OWU). However, little is investigated on how to augment the OWU's independence during their in-person shopping experiences, specifically by addressing their physical conditions. We first conducted semi-structured interviews and a large-scale survey with 77 people in total to discover OWU's needs and pain points in comparison with those of general older adults or wheelchair population. Based on these findings, we propose ARbility, a wearable AR-based shopping system for OWU which supports product recognition from seated positions on wheelchairs and one-stop shopping functionality for minimizing physical loads. In our user evaluation with 13 OWU in a real-world environment, ARbility demonstrated 33% decrease in arm movement, with the participants validating its efficacy and usability in qualitative interviews. We conclude with implications on how a wearable AR-based shopping system supports the active aging and inclusion of OWU.
C1 [Kang, Cholmin; Yeom, Inhwa; Ashtari, Amirsaman; Woo, Woontack; Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daehak ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Woo, W; Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daehak ro, Daejeon 34141, South Korea.
EM stevekang@kaist.ac.kr; yinhwa@kaist.ac.kr; a.s.ashtari@kaist.ac.kr;
   wwoo@kaist.ac.kr; junyongnoh@kaist.ac.kr
RI Woo, Woontack/C-3696-2012; Noh, Junyong/C-1663-2011
OI Woo, Woontack/0000-0002-5501-4421; Noh, Junyong/0000-0003-1925-3326
CR Ahmed Mohamed S, 2005, Phys Med Rehabil Clin N Am, V16, P19, DOI 10.1016/j.pmr.2004.06.017
   Ahn J, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808207
   Andersen JH, 2002, SPINE, V27, P660
   Arshad H., 2017, Int. J. Adv. Sci. Eng. Inf. Technol, V7, P139, DOI [10.18517/ijaseit.7.1.1793, DOI 10.18517/IJASEIT.7.1.1793]
   Becker SA, 2004, SOC SCI COMPUT REV, V22, P11, DOI 10.1177/0894439303259876
   Boldu R, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3432196
   Boyarski Dan, 1998, Proceedings of the 1998 CHI Conference, P87, DOI 10.1145/274644.274658
   Bright AK, 2013, 6 INT C PERVASIVE TE, DOI 10.1145/2504335.2504344
   Bromley RDF, 2007, CITIES, V24, P229, DOI 10.1016/j.cities.2007.01.009
   Bureau UC, 2021, NAT POP TOT COMP CHA
   Capoor Jaishree, 2005, Phys Med Rehabil Clin N Am, V16, P129, DOI 10.1016/j.pmr.2004.06.016
   Cohen RB, 1998, CLIN ORTHOP RELAT R, P95
   Cornman JC, 2005, GERONTOLOGIST, V45, P347, DOI 10.1093/geront/45.3.347
   Dalton NS, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3889, DOI 10.1145/2702123.2702150
   Electronics L, 2018, LG G7 THINQ
   Electronics S, 2021, SAMS BIXB YOUR PERS
   Fernandez-Ballesteros R, 2008, ACTIVE AGING CONTRIB, P7
   Frost P, 2002, AM J IND MED, V41, P11, DOI 10.1002/ajim.10019
   Geng WD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1706, DOI 10.1145/3240508.3240522
   Gerling K.M., 2013, P 15 INT ACM SIGACCE, p27:1, DOI DOI 10.1145/2513383.2513436
   Gilleard C, 1996, AGEING SOC, V16, P489, DOI 10.1017/S0144686X00003640
   Google, 2021, GOOGL PIX 2 GEN HARD
   Guo HJ., 2020, INSTRUMENTAL ACTIVIT
   Gutierrez F, 2018, P 20 INT C HUM COMP, P339, DOI [10.1145/3236112.3236161, DOI 10.1145/3236112.3236161]
   Hoenig H, 2003, AM J PUBLIC HEALTH, V93, P330, DOI 10.2105/AJPH.93.2.330
   Hoenig H., 2004, ANNAL LONG TERM CARE, V12, P12
   inc A, 2020, APPL SIR VIRT ASS
   Karmarkar Amol M, 2011, J Aging Res, V2011, P560358, DOI 10.4061/2011/560358
   Kaye H., 2002, Disability Statistics
   Kemp B., 2004, Aging with a disability: What the clinician needs to know
   Kline DW, 1985, VISION AGING
   Kuoppamäki S, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3463516
   LAWTON MP, 1969, GERONTOLOGIST, V9, P179, DOI 10.1093/geront/9.3_Part_1.179
   Lee B, 2009, P 2 INT C INTERACTIO, P1110, DOI [10.1145/1655925.1656127, DOI 10.1145/1655925.1656127]
   Li Franklin Mingzhe, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351253
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mason L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300262
   Microsoft, 2021, CORT YOUR PERS PROD
   MicroSoft, 2020, MRTK V2
   Microsoft, 2020, HOLOLENS 1 GEN HARDW
   Niwa H, 2016, 2016 IEEE 5 GLOBAL C, P1, DOI [10.1109/GCCE.2016.7800481, DOI 10.1109/GCCE.2016.7800481]
   Organization W.H., 2002, ACT AG POL FRAM
   PENTLAND W, 1995, PARAPLEGIA, V33, P367, DOI 10.1038/sc.1995.84
   Qiao SY, 2017, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2017.199
   Rashid Z, 2015, BRIDGING OFFLINE SHO, V9254, DOI [10.1007/978-3-319-22888-4_31, DOI 10.1007/978-3-319-22888-4_31]
   Rashid Z, 2016, THESIS, DOI [10.13140/RG.2.2.13769.60004, DOI 10.13140/RG.2.2.13769.60004]
   Rashid Z, 2019, ASSIST TECHNOL, V31, P9, DOI 10.1080/10400435.2017.1329240
   Rashid Z, 2017, FUTURE GENER COMP SY, V76, P248, DOI 10.1016/j.future.2016.11.030
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Rello L, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3637, DOI 10.1145/2858036.2858204
   Rodger S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300860
   Salisbury SK, 2006, SPINAL CORD, V44, P723, DOI 10.1038/sj.sc.3101908
   SEKULER R, 1980, SCIENCE, V209, P1255, DOI 10.1126/science.7403884
   SMITH GC, 1988, GEOFORUM, V19, P189, DOI 10.1016/S0016-7185(88)80028-9
   Tolerico ML, 2007, J REHABIL RES DEV, V44, P561, DOI 10.1682/JRRD.2006.02.0017
   Tonioni A, DEEP LEARNING PIPELI
   Trefler E, 2004, ASSIST TECHNOL, V16, P18, DOI 10.1080/10400435.2004.10132071
   Wang Q, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0229-y
   Winlock Tess, 2010, Toward real-time grocery detection for the visually impaired, DOI [10.1109/CVPRW.2010.5543576, DOI 10.1109/CVPRW.2010.5543576]
   Wobbrock JO., 2016, RES CONTRIBUTIONS HU, V23, P38
NR 61
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1919
EP 1936
DI 10.1007/s10055-023-00769-0
EA MAR 2023
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000954596600001
DA 2024-07-18
ER

PT J
AU Corrigan, N
   Pasarelu, CR
   Voinescu, A
AF Corrigan, Niamh
   Pasarelu, Costina-Ruxandra
   Voinescu, Alexandra
TI Immersive virtual reality for improving cognitive deficits in children
   with ADHD: a systematic review and meta-analysis
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Attention deficit-hyperactivity disorder (ADHD);
   Children; Cognition; Attention; Memory
ID HYPERACTIVITY DISORDER; CEREBRAL-PALSY; ADOLESCENTS; INATTENTION;
   CLASSROOM
AB Virtual reality (VR) shows great potential in treating and managing various mental health conditions. This includes using VR for training or rehabilitation purposes. For example, VR is being used to improve cognitive functioning (e.g. attention) among children with attention/deficit-hyperactivity disorder (ADHD). The aim of the current review and meta-analysis is to evaluate the effectiveness of immersive VR-based interventions for improving cognitive deficits in children with ADHD, to investigate potential moderators of the effect size and assess treatment adherence and safety. The meta-analysis included seven randomised controlled trials (RCTs) of children with ADHD comparing immersive VR-based interventions with controls (e.g. waiting list, medication, psychotherapy, cognitive training, neurofeedback and hemoencephalographic biofeedback) on measures of cognition. Results indicated large effect sizes in favour of VR-based interventions on outcomes of global cognitive functioning, attention, and memory. Neither intervention length nor participant age moderated the effect size of global cognitive functioning. Control group type (active vs passive control group), ADHD diagnostic status (formal vs. informal) and novelty of VR technology were not significant moderators of the effect size of global cognitive functioning. Treatment adherence was similar across groups and there were no adverse effects. Results should be cautiously interpreted given the poor quality of included studies and small sample.
C1 [Corrigan, Niamh; Voinescu, Alexandra] Univ Bath, Dept Psychol, Bath BA2 7AY, England.
   [Pasarelu, Costina-Ruxandra] Babe Bolyai Univ, Int Inst Adv Studies Psychotherapy & Appl Mental H, Dept Clin Psychol & Psychotherapy, 37,Republ St, Cluj Napoca 400015, Romania.
C3 University of Bath; Babes Bolyai University from Cluj
RP Voinescu, A (corresponding author), Univ Bath, Dept Psychol, Bath BA2 7AY, England.
EM niamh.corrigan@yahoo.co.uk; costinapasarelu@psychology.ro;
   av561@bath.ac.uk
RI Păsărelu, Costina Ruxandra/AAZ-1758-2020
OI Păsărelu, Costina Ruxandra/0000-0002-8228-5833; Voinescu,
   Alexandra/0000-0001-7689-335X
CR Adabla S, 2021, ADV NEURODEV DISORD, V5, P304, DOI 10.1007/s41252-021-00207-9
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Bahar-Fuchs A, 2019, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD013069.pub2
   Barba MC, 2019, LECT NOTES COMPUT SC, V11613, P394, DOI 10.1007/978-3-030-25965-5_30
   Bashiri Azadeh, 2017, Korean J Pediatr, V60, P337, DOI 10.3345/kjp.2017.60.11.337
   Bellanti CJ, 2000, J CLIN CHILD PSYCHOL, V29, P66, DOI 10.1207/S15374424jccp2901_7
   Bikic A, 2017, CLIN PSYCHOL REV, V52, P108, DOI 10.1016/j.cpr.2016.12.004
   Bioulac S, 2020, J ATTEN DISORD, V24, P326, DOI 10.1177/1087054718759751
   Borenstein M., 2013, BIOSTAT
   Bul KCM, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5173
   Canu WH., 2022, BEHAV THERAPY 1 2 3, P629, DOI [10.1007/978-3-031-11677-3_27, DOI 10.1007/978-3-031-11677-3_27]
   Castells X, 2021, J ATTEN DISORD, V25, P1352, DOI 10.1177/1087054720903372
   Cénat JM, 2024, J CLIN CHILD ADOLESC, V53, P373, DOI 10.1080/15374416.2022.2051524
   Chen YP, 2014, PEDIATR PHYS THER, V26, P289, DOI 10.1097/PEP.0000000000000046
   Chen YP, 2018, PHYS THER, V98, P63, DOI 10.1093/ptj/pzx107
   Cho BH, 2004, CYBERPSYCHOL BEHAV, V7, P519, DOI 10.1089/cpb.2004.7.519
   Cho BH, 2002, ST HEAL T, V85, P89
   Choi MT, 2019, J INTELL ROBOT SYST, V95, P351, DOI 10.1007/s10846-018-0890-9
   Coghill DR, 2014, PSYCHOL MED, V44, P1087, DOI 10.1017/S0033291713001761
   Coghill D, 2023, EUR CHILD ADOLES PSY, V32, P1337, DOI 10.1007/s00787-021-01871-x
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cortese S, 2015, J AM ACAD CHILD PSY, V54, P164, DOI 10.1016/j.jaac.2014.12.010
   David D, 2021, COGNITIVE THER RES, V45, P149, DOI 10.1007/s10608-020-10157-6
   Deeks J. J., 2008, Cochrane Handbook for Systematic Reviews of Interventions, P243, DOI DOI 10.1002/9781119536604
   Dekkers TJ, 2022, J AM ACAD CHILD PSY, V61, P478, DOI 10.1016/j.jaac.2021.06.015
   Dobrean A., 2018, EVIDENCE BASED PSYCH, P435
   Duval S, 2000, BIOMETRICS, V56, P455, DOI 10.1111/j.0006-341X.2000.00455.x
   Evans SW, 2018, J CLIN CHILD ADOLESC, V47, P157, DOI [10.1080/15374416.2017.1390757, 10.1080/15374416.2013.850700]
   Faraone SV, 2021, NEUROSCI BIOBEHAV R, V128, P789, DOI 10.1016/j.neubiorev.2021.01.022
   Florean IS, 2020, CLIN CHILD FAM PSYCH, V23, P510, DOI 10.1007/s10567-020-00326-0
   Fodor LA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28113-6
   Fridman M, 2017, NEUROPSYCH DIS TREAT, V13, P947, DOI 10.2147/NDT.S128752
   Gilboa Y, 2021, J ATTEN DISORD, V25, P300, DOI 10.1177/1087054718808590
   Goharinejad S, 2022, BMC PSYCHIATRY, V22, DOI 10.1186/s12888-021-03632-1
   Golberstein E, 2020, JAMA PEDIATR, V174, P819, DOI 10.1001/jamapediatrics.2020.1456
   Groenman AP, 2022, J AM ACAD CHILD PSY, V61, P144, DOI 10.1016/j.jaac.2021.02.024
   Holmberg K, 2014, J ATTEN DISORD, V18, P635, DOI 10.1177/1087054712452136
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Iriarte Y, 2016, J ATTEN DISORD, V20, P542, DOI 10.1177/1087054712465335
   Kaimara P, 2022, VIRTUAL REAL-LONDON, V26, P697, DOI 10.1007/s10055-021-00563-w
   Kappi A, 2022, J ATTEN DISORD, V26, P408, DOI 10.1177/1087054720986909
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khalafallah A, 2010, MEDITERR J HEMATOL I, V2, DOI [10.1136/bmj.l4898, 10.4084/MJHID.2010.005]
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim S, 2020, IEEE ACCESS, V8, P45996, DOI 10.1109/ACCESS.2020.2977688
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Kolasinski, 1995, SIMULATOR SICKNESS V, DOI [10.21236/ADA295861, DOI 10.21236/ADA295861]
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Lakes KD, 2022, COMPUT HUM BEHAV REP, V6, DOI 10.1016/j.chbr.2022.100174
   Lee JM, 2001, P ANN INT IEEE EMBS, V23, P3754, DOI 10.1109/IEMBS.2001.1019654
   Legemaat AM, 2022, PSYCHOL MED, V52, P4146, DOI 10.1017/S0033291721001100
   Lehtimaki S, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/25847
   McGowan G, 2020, J AM ACAD CHILD PSY, V59, pS251, DOI 10.1016/j.jaac.2020.08.412
   Mekbib DB, 2020, BRAIN INJURY, V34, P456, DOI 10.1080/02699052.2020.1725126
   National Institute for health and care excellence, 2018, DIAGNOSIS MANAGEMENT
   Negut A, 2017, CHILD NEUROPSYCHOL, V23, P692, DOI 10.1080/09297049.2016.1186617
   Ottosen C, 2016, J AM ACAD CHILD PSY, V55, P227, DOI 10.1016/j.jaac.2015.12.010
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Papaioannou T, 2022, J ALZHEIMERS DIS, V88, P1341, DOI 10.3233/JAD-210672
   Parsons TD, 2019, NEUROPSYCHOL REV, V29, P338, DOI 10.1007/s11065-019-09407-6
   Pasarelu CR, 2020, INT J MED INFORM, V138, DOI 10.1016/j.ijmedinf.2020.104133
   Pasarelu CR, 2016, COGN BEHAV THERAPY, V46, P1, DOI 10.1080/16506073.2016.1231219
   Peñuelas-Calvo I, 2022, EUR CHILD ADOLES PSY, V31, P5, DOI 10.1007/s00787-020-01557-w
   Polanczyk GV, 2014, INT J EPIDEMIOL, V43, P434, DOI 10.1093/ije/dyt261
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Rodrigo-Yanguas M, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.798480
   Rodrigo-Yanguas M, 2021, GAMES HEALTH J, V10, P283, DOI 10.1089/g4h.2021.0073
   Romero-Ayuso D, 2021, CHILDREN-BASEL, V8, DOI 10.3390/children8020070
   Sacchetti GM, 2017, J ATTEN DISORD, V21, P1009, DOI 10.1177/1087054714557355
   Schein J, 2022, J MED ECON, V25, P193, DOI 10.1080/13696998.2022.2032097
   Skalski S, 2021, INT J PSYCHOPHYSIOL, V170, P59, DOI 10.1016/j.ijpsycho.2021.10.001
   Sonuga-Barke EJS, 2023, J CHILD PSYCHOL PSYC, V64, P506, DOI 10.1111/jcpp.13696
   Tabrizi M, 2020, INT ARCH HEALTH SCI, V7, P37, DOI 10.4103/iahs.iahs_66_19
   Tikhomirova T, 2020, BEHAV SCI-BASEL, V10, DOI 10.3390/bs10100158
   Torgalsboen BR, 2021, J ATTEN DISORD, V25, P895, DOI 10.1177/1087054719879491
   Tuerk C, 2021, J NEUROPSYCHOL, V15, P477, DOI 10.1111/jnp.12230
   Voinescu A., 2021, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD013853
   Voinescu A, 2021, J CLIN MED, V10, DOI 10.3390/jcm10071478
   Welch V, 2022, J MED INTERNET RES, V24, DOI 10.2196/33560
   Wolraich ML, 2019, PEDIATRICS, V144, DOI 10.1542/peds.2019-2528
   World Health Organization, 2001, DISABIL HLTH ICF, V28, P66
   Wright N, 2015, J CHILD PSYCHOL PSYC, V56, P598, DOI 10.1111/jcpp.12398
NR 83
TC 9
Z9 9
U1 24
U2 60
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3545
EP 3564
DI 10.1007/s10055-023-00768-1
EA FEB 2023
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000936141100001
PM 36845650
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Asbee, J
   Kelly, K
   McMahan, T
   Parsons, TD
AF Asbee, Justin
   Kelly, Kimberly
   McMahan, Timothy
   Parsons, Thomas D.
TI Machine learning classification analysis for an adaptive virtual reality
   Stroop task
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality stroop task; Adaptive virtual environment; Machine
   learning; Classification; Human-Computer interaction
ID ANTERIOR CINGULATE CORTEX; COMPLEXITY; DORSAL
AB Advances in virtual environment (VE) technologies have afforded psychologists with high-dimensional virtual reality (VR) platforms that enhance the complexity and dimensionality of cognitive assessments. The Virtual Reality Stroop Task HMMWV (VRST; Stroop stimuli embedded within a virtual high mobility multipurpose wheeled vehicle) is a VR assessment involving both cognitive and affective components. There is a need for adaptive virtual environments (AVEs) that can adjust the complexity of environmental stimuli relative to the way the participant is performing. To develop the VRST into an AVE assessment, classifier algorithms must be developed. While previous research has explored classifier algorithms for modeling arousal and cognitive performance in the VRST, machine learning (ML) classifiers have not been developed for an adaptive VRST. The current study developed ML classifiers for an adaptive version of the VRST. The assessment of Naive Bayes (NB), k-Nearest Neighbors (kNN), and Support Vector Machines (SVM) machine learning classifiers found that SVM and NB classifiers tended to have the highest accuracies and greatest areas under the curve when classifying users as high or low performers. The kNN algorithms did not perform as well. As such, SVM and NB may be the best candidates for creation of an adaptive version of the VRST.
C1 [Asbee, Justin] Univ Arkansas, Inst Integrat & Innovat Res, Adapt Neural Syst Grp, Fayetteville, AR 72704 USA.
   [Kelly, Kimberly] Univ North Texas, Dept Psychol, Denton, TX 76207 USA.
   [McMahan, Timothy] Univ North Texas, Dept Learning Technol, Denton, TX 76207 USA.
   [Parsons, Thomas D.] Arizona State Univ, Edson Coll, Grace Ctr, Tempe, AZ 85281 USA.
   [Parsons, Thomas D.] Arizona State Univ, Computat Neuropsychol & Simulat, Tempe, AZ 85281 USA.
C3 University of Arkansas System; University of Arkansas Fayetteville;
   University of North Texas System; University of North Texas Denton;
   University of North Texas System; University of North Texas Denton;
   Arizona State University; Arizona State University-Tempe; Arizona State
   University; Arizona State University-Tempe
RP Parsons, TD (corresponding author), Arizona State Univ, Edson Coll, Grace Ctr, Tempe, AZ 85281 USA.; Parsons, TD (corresponding author), Arizona State Univ, Computat Neuropsychol & Simulat, Tempe, AZ 85281 USA.
EM Thomas.Parsons@asu.edu
OI Asbee, Justin/0000-0002-8210-5855
CR Arar ÖF, 2017, APPL SOFT COMPUT, V59, P197, DOI 10.1016/j.asoc.2017.05.043
   Armstrong CM, 2013, J CLIN EXP NEUROPSYC, V35, P113, DOI 10.1080/13803395.2012.740002
   Beunza JJ, 2019, J BIOMED INFORM, V97, DOI 10.1016/j.jbi.2019.103257
   Bhavsar H., 2012, Int. 1. Adv. Res. Comput. Eng. Technol., V1, P185
   Briscoe E, 2011, COGNITION, V118, P2, DOI 10.1016/j.cognition.2010.10.004
   Bzdok Danilo, 2018, Nat Methods, V15, P233, DOI 10.1038/nmeth.4642
   Cai XY, 2012, J NEUROSCI, V32, P3791, DOI 10.1523/JNEUROSCI.3864-11.2012
   Cieslik EC, 2015, NEUROSCI BIOBEHAV R, V48, P22, DOI 10.1016/j.neubiorev.2014.11.003
   Galatzer-Levy IR, 2017, TRANSL PSYCHIAT, V7, DOI 10.1038/tp.2017.38
   Gross JJ, 2015, PSYCHOL INQ, V26, P1, DOI 10.1080/1047840X.2014.940781
   Hautamäki V, 2005, LECT NOTES COMPUT SC, V3540, P978
   Heidlmayr K, 2020, BRAIN COGNITION, V146, DOI 10.1016/j.bandc.2020.105637
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jung Y, 2018, J NONPARAMETR STAT, V30, P197, DOI 10.1080/10485252.2017.1404598
   Luo G, 2016, NETW MODEL ANAL HLTH, V5, DOI 10.1007/s13721-016-0125-6
   Mahesh B., 2020, nternational Journal of Science and Research (IJSR), V9, P381, DOI [DOI 10.21275/ART20203995, 10.21275/ART20203995]
   McMahan T, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.673191
   Mitra J, 2016, NEUROIMAGE, V129, P247, DOI 10.1016/j.neuroimage.2016.01.056
   Mosavi A, 2018, WATER-SUI, V10, DOI 10.3390/w10111536
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Omar Kazi Shahrukh, 2019, 2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT), DOI 10.1109/ICASERT.2019.8934542
   Parsons TD, 2022, IEEE T AFFECT COMPUT, V13, P3, DOI 10.1109/TAFFC.2020.2992437
   Parsons TD, 2018, IEEE T AFFECT COMPUT, V9, P66, DOI 10.1109/TAFFC.2016.2569086
   Parsons TD, 2013, J CLIN EXP NEUROPSYC, V35, P812, DOI 10.1080/13803395.2013.824556
   Parsons TD, 2012, IEEE T CONSUM ELECTR, V58, P197, DOI 10.1109/TCE.2012.6227413
   Probst P, 2019, J MACH LEARN RES, V20
   Rodríguez-Ardura I, 2016, INFORM MANAGE-AMSTER, V53, P504, DOI 10.1016/j.im.2015.11.005
   Rozenek EB, 2019, ARH HIG RADA TOKSIKO, V70, P150, DOI 10.2478/aiht-2019-70-3298
   Scarpina F, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00557
   Shenhav A, 2016, NAT NEUROSCI, V19, P1286, DOI 10.1038/nn.4384
   Stevens FL, 2011, J NEUROPSYCH CLIN N, V23, P120, DOI 10.1176/appi.neuropsych.23.2.121
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Thompson G, 2017, BRIT J SOCIOL EDUC, V38, P827, DOI 10.1080/01425692.2016.1158640
   Thorne DR, 2006, BEHAV RES METHODS, V38, P569, DOI 10.3758/BF03193886
   Vural MS, 2017, NEURAL COMPUT APPL, V28, P2581, DOI 10.1007/s00521-016-2205-z
   Wu DWL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053856
   Wu DR, 2010, IEEE T AFFECT COMPUT, V1, P109, DOI 10.1109/T-AFFC.2010.12
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
   Zelazo PD, 2015, DEV REV, V38, P55, DOI 10.1016/j.dr.2015.07.001
NR 40
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1391
EP 1407
DI 10.1007/s10055-022-00744-1
EA JAN 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000912230900001
DA 2024-07-18
ER

PT J
AU Cummings, JJ
   Cahill, TJ
   Wertz, E
   Zhong, QK
AF Cummings, James J.
   Cahill, Tiernan J.
   Wertz, Erin
   Zhong, Qiankun
TI Psychological predictors of consumer-level virtual reality technology
   adoption and usage
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Uses and gratifications; Adoption; Immersion;
   Absorption; Individual differences
ID SENSATION SEEKING; PERSONALITY; ABSORPTION; DIFFUSION; MEDIA; NEED;
   ENVIRONMENTS; REGRESSION; OPENNESS; NETWORK
AB In recent years, virtual reality (VR) technology has been mainstreamed for at-home use, with various consumer-oriented devices released by media firms such as Meta, Google, Samsung, and HTC. The present research investigates the role of psychological traits-including immersive tendencies, absorption, sensation seeking, need for cognition, neophobia, and belief in science-as well as trait levels of individual innovativeness, self-perception of social well-being, and owner demographics, in predicting VR adoption rates and sustained use over time. Separate analyses were conducted for different classes of VR device (fixed, mobile, and standalone devices). In general, psychological factors generally emerged as more determinative of adoption than did demographics. Users' immersive tendencies predicted earlier adoption of VR technology while absorption was associated with later adoption, with both predictive of higher overall initial usage of different types of devices. Additionally, perceiving oneself as socially successful was associated with higher initial VR usage, while a tendency to see one's emotions as influenced by in-person rather than online contacts was negatively associated with usage. Finally, belief in science predicted greater consistency in usage over time while higher levels of absorption were associated with unstable usage patterns. These findings expand upon the limited work previously investigating the role of individual differences in adoption of VR and mark the promise of psychometrics for understanding the diffusion and continued usage of consumer-facing VR devices.
C1 [Cummings, James J.; Cahill, Tiernan J.; Wertz, Erin; Zhong, Qiankun] Boston Univ, Coll Commun, Div Emerging Media Studies, Boston, MA 02215 USA.
   [Zhong, Qiankun] Univ Calif Davis, Dept Commun, Davis, CA USA.
C3 Boston University; University of California System; University of
   California Davis
RP Cummings, JJ (corresponding author), Boston Univ, Coll Commun, Div Emerging Media Studies, Boston, MA 02215 USA.
EM cummingj@bu.edu
RI Cahill, Tiernan/AAH-5647-2019
OI Cahill, Tiernan/0000-0001-5715-9192; Cummings,
   James/0000-0001-6239-2634; Wertz, Erin/0000-0003-0293-2840; Zhong,
   Qiankun/0000-0001-6234-0172
CR [Anonymous], 2017, Top Trends in the Gartner Hype Cycle for Emerging Technologies
   Arbore A, 2014, J ASSOC INF SYST, V15, P86
   Arnett JJ, 1996, PERS INDIV DIFFER, V20, P693, DOI 10.1016/0191-8869(96)00027-X
   Banos R, 1999, Cyberpsychol Behav, V2, P143, DOI 10.1089/cpb.1999.2.143
   Belliveau J, 2022, EXP CLIN PSYCHOPHARM, V30, P424, DOI 10.1037/pha0000575
   Bradshaw T., 2017, Financial Times
   CACIOPPO JT, 1982, J PERS SOC PSYCHOL, V42, P116, DOI 10.1037/0022-3514.42.1.116
   CACIOPPO JT, 1984, J PERS ASSESS, V48, P306, DOI 10.1207/s15327752jpa4803_13
   Callegaro M, 2014, WILEY SER SURV METH, P23
   Cescau, 2016, YOUNG BLOOD WHITE PA
   Chang, 2021, BLOOMBERG
   Chang BH, 2006, NEW MEDIA SOC, V8, P295, DOI 10.1177/1461444806059888
   Chen CM, 2000, J AM SOC INFORM SCI, V51, P499, DOI 10.1002/(SICI)1097-4571(2000)51:6<499::AID-ASI2>3.0.CO;2-K
   Chuah S.H. W., 2019, International Journal of Technology Marketing, V13, P205, DOI DOI 10.1504/IJTMKT.2019.104586
   Clement J, 2021, VR AR OWNERSHIP PURC
   Coelho GLD, 2020, ASSESSMENT, V27, P1870, DOI 10.1177/1073191118793208
   Coursaris C.K., 2010, 2010 Ninth International Conference, P481, DOI DOI 10.1109/ICMB-GMR.2010.44
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Darlington R. B., 2017, Regression Analysis and Linear Models
   Dieck DT, 2018, LEISURE STUD, V37, P371, DOI 10.1080/02614367.2018.1466905
   Farias M, 2013, J EXP SOC PSYCHOL, V49, P1210, DOI 10.1016/j.jesp.2013.05.008
   Giordano S, 2018, INT J GASTRON FOOD S, V11, P1, DOI 10.1016/j.ijgfs.2017.10.001
   GLISKY ML, 1991, J PERS SOC PSYCHOL, V60, P263, DOI 10.1037/0022-3514.60.2.263
   Harrell FE, 2015, SPRINGER SER STAT, DOI 10.1007/978-3-319-19425-7
   Hartl E, 2017, P 25 EUR C INF SYST, P2413
   Herz M, 2019, TECHNOL FORECAST SOC, V138, P228, DOI 10.1016/j.techfore.2018.09.008
   Holman, 2020, BLOOMBURG
   Huang TL, 2015, ELECTRON COMMER RES, V15, P269, DOI 10.1007/s10660-014-9163-2
   Hurt H.T., 1977, HUM COMMUN RES, V4, P58, DOI DOI 10.1111/J.1468-2958.1977.TB00597.X
   Im S, 2003, J ACAD MARKET SCI, V31, P61, DOI 10.1177/0092070302238602
   Jenkins A., 2019, Fortune
   Kalantari M, 2018, PROGR IS, P229, DOI 10.1007/978-3-319-64027-3_16
   Katz E., 1973, PUBLIC OPIN QUART, V37
   Kim MJ, 2019, COMPUT HUM BEHAV, V90, P60, DOI 10.1016/j.chb.2018.08.046
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Laarni J., 2004, P 7 ANN INT WORKSHOP, P88
   Laurell C, 2019, J BUS RES, V100, P469, DOI 10.1016/j.jbusres.2019.01.017
   Macedonio MF, 2007, CYBERPSYCHOL BEHAV, V10, P508, DOI 10.1089/cpb.2007.9997
   McErlean ABJ, 2020, PEERJ, V8, DOI 10.7717/peerj.8588
   Mutterlein Joschka, 2017, P 23 AM C INF SYST A
   Nimrod G, 2018, EDUC GERONTOL, V44, P148, DOI 10.1080/03601277.2018.1428145
   OSBERG TM, 1987, J PERS ASSESS, V51, P441, DOI 10.1207/s15327752jpa5103_11
   Patterson DR, 2006, INT J CLIN EXP HYP, V54, P130, DOI 10.1080/00207140500528182
   Pea R, 2012, DEV PSYCHOL, V48, P327, DOI 10.1037/a0027030
   PLINER P, 1992, APPETITE, V19, P105, DOI 10.1016/0195-6663(92)90014-W
   Qin H, 2009, INT J HUM-COMPUT INT, V25, P107, DOI 10.1080/10447310802546732
   Rauschnabel Philipp A., 2016, i-com: A Journal of Interactive and Cooperative Media, V15, P179, DOI 10.1515/icom-2016-0021
   Roberts J., 2017, Fortune
   Robertson T.S., 1971, Innovative behavior and communication
   Robillard G., 2002, P 25IEME CONGRES SOC
   ROCHE SM, 1990, J PERS SOC PSYCHOL, V59, P91, DOI 10.1037/0022-3514.59.1.91
   ROGERS E.M., 1974, Communication of Innovations, V9, P476
   Rogers EM, 2003, DIFFUSION INNOVATION
   Rogers EM., 1961, Characteristics of Agricultural Innovators and Other Adopters Catagories
   Royston P, 2009, STATA J, V9, P547, DOI 10.1177/1536867X0900900403
   SAUERBREI W, 1992, STAT MED, V11, P2093, DOI 10.1002/sim.4780111607
   Sinkovics R.R., 2002, THUNDERBIRD INT BUS, V44, P477, DOI [10.1002/tie.10033, DOI 10.1002/TIE.10033]
   Smith G, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0143-6
   Standen P, 2015, PHYS THER, V95, P350, DOI 10.2522/ptj.20130564
   Statt Nick, 2018, VERGE
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sundar SS, 2013, J BROADCAST ELECTRON, V57, P504, DOI 10.1080/08838151.2013.845827
   TELLEGEN A, 1974, J ABNORM PSYCHOL, V83, P268, DOI 10.1037/h0036681
   UQO Cyberpsychology Lab, 2004, IMM TEND QUEST
   Venkatesh V, 2001, MIS QUART, V25, P71, DOI 10.2307/3250959
   Vishwakarma P, 2020, J DESTIN MARK MANAGE, V17, DOI 10.1016/j.jdmm.2020.100456
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Weisskirch RS, 2004, ADOLESCENCE, V39, P189
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zuckerman M, 2000, J PERS, V68, P999, DOI 10.1111/1467-6494.00124
NR 70
TC 4
Z9 5
U1 5
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1357
EP 1379
DI 10.1007/s10055-022-00736-1
EA DEC 2022
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000905876800001
PM 36597421
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Lee, H
   Bang, S
   Woo, W
AF Lee, Hyunjin
   Bang, Sunyoung
   Woo, Woontack
TI Effects of coordinate system and position of AR notification while
   walking
SO VIRTUAL REALITY
LA English
DT Article
DE AR notification; Augmented reality; User interface; Placement;
   Coordinate systems; Walking
ID TEXT READABILITY; DISPLAYS; OPTIMIZATION
AB Augmented reality (AR) head-mounted displays (HMDs) allow users to easily receive notifications while participating other tasks by projecting information directly in their field of view. Although HMDs offer such benefits in displaying notifications, there is insufficient research on the effective placement of AR notifications when the user is walking. For this, we conducted two studies based on different types of AR information to identify how the users perceive and understand the AR notifications according to placement while walking. We compared two different coordinate systems (display-fixed and body-fixed) and three different positions (top, right, and bottom) for icon-type and text-type notifications. The results indicated that using a display-fixed coordinate system for icon-type notifications yields significantly higher noticeability and comprehension. In contrast, using a body-fixed coordinate system for text-type notifications significantly improved comprehension and walking performance. Regarding the position of notifications, the bottom position resulted in a significantly higher noticeability and comprehension for both icon- and text-type notifications compared with the top. Based on these results, we draw some recommendations for the future design of notifications in AR HMDs.
C1 [Lee, Hyunjin; Bang, Sunyoung; Woo, Woontack] KAIST UVR Lab, 2325,N5,291 Daehak Ro, Daejeon, South Korea.
   [Woo, Woontack] KAIST KI ITC Augmented Real Res Ctr, 303,E4,291 Daehak Ro, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Woo, W (corresponding author), KAIST UVR Lab, 2325,N5,291 Daehak Ro, Daejeon, South Korea.; Woo, W (corresponding author), KAIST KI ITC Augmented Real Res Ctr, 303,E4,291 Daehak Ro, Daejeon, South Korea.
EM wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2019-0-01270]
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2019-0-01270, WISE AR UI/UX Platform Development
   for Smartglasses).
CR Ali H, 2016, LECT NOTES COMPUT SC, V9754, P401, DOI 10.1007/978-3-319-39943-0_39
   Barnard L, 2005, INT J HUM-COMPUT ST, V62, P487, DOI 10.1016/j.ijhcs.2004.12.002
   Billinghurst M, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P76, DOI 10.1109/ISWC.1998.729532
   Billinghurst M, 1998, P IEEE VIRT REAL ANN, P20, DOI 10.1109/VRAIS.1998.658418
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Borg O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129902
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Chua Soon Hau., 2016, INT S CHINESE CHI CH, P1, DOI DOI 10.1145/2948708.2948713
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Ens Barrett., 2014, Proceedings of the 2nd ACM symposium on Spatial user interaction (SUI'14), P2, DOI [10.1145/2659766.2659769, DOI 10.1145/2659766.2659769]
   Feiner S., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P145, DOI 10.1145/168642.168657
   Fukushima S, 2020, INT SYM MIX AUGMENT, P649, DOI 10.1109/ISMAR50242.2020.00093
   Gabbard JL, 2019, IEEE T VIS COMPUT GR, V25, P2228, DOI 10.1109/TVCG.2018.2832633
   Genç Ç, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1538, DOI 10.1145/2858036.2858449
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Gutwin C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P208, DOI 10.1145/3025453.3025984
   Harding TH, 2010, PROC SPIE, V7688, DOI 10.1117/12.848931
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Imamov S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P851, DOI [10.1109/VR46266.2020.1581435674325, 10.1109/VR46266.2020.00110]
   Iqbal ST, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1879831.1879833
   Ishiguro Yoshio., 2011, P 2 AUGMENTED HUMAN, P8
   Jaschinski W, 1999, ERGONOMICS, V42, P535, DOI 10.1080/001401399185450
   Klose EM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P636, DOI [10.1109/vr.2019.8797992, 10.1109/VR.2019.8797992]
   Komatsubara A., 2008, MARUZEN, V2, P3
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kruijff E, 2019, IEEE T VIS COMPUT GR, V25, P2821, DOI 10.1109/TVCG.2018.2854737
   Kushlev K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1011, DOI 10.1145/2858036.2858359
   Lages WS, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3358755
   Lee H, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P189, DOI 10.1109/ISMAR-Adjunct51615.2020.00057
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Lucero Andres, 2014, P 11 C ADV COMP ENT, P1, DOI DOI 10.1145/2663806.2663824
   MagicLeap, 2020, HEAD LOCK CONT UN
   Mairena A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300870
   Matsuura Y, 2019, IEEE INT SYM WRBL CO, P150, DOI 10.1145/3341163.3347748
   McCrickard D. S., 2003, ACM Transactions on Computer-Human Interaction, V10, P312, DOI 10.1145/966930.966933
   McCrickard DS, 2003, INT J HUM-COMPUT ST, V58, P509, DOI 10.1016/S1071-5819(03)00025-9
   Mehrotra A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1021, DOI 10.1145/2858036.2858566
   MENOZZI M, 1994, OPHTHAL PHYSL OPT, V14, P393, DOI 10.1111/j.1475-1313.1994.tb00131.x
   Microsoft, 2019, TYP MIX REAL
   Microsoft, 2019, COORDINATE SYSTEMS M
   Microsoft, 2020, COMF MIX REAL
   Mustonen T, 2013, J EXP PSYCHOL-APPL, V19, P333, DOI 10.1037/a0034635
   OBERG T, 1993, J REHABIL RES DEV, V30, P210
   Panero J., 1979, HUMAN DIMENSION INTE
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Pielot M, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229445
   Pielot M, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P233, DOI 10.1145/2628363.2628364
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Rzayev R, 2021, P 2021 CHI C HUM FAC, P1, DOI [10.1145/3411764.3445606, DOI 10.1145/3411764.3445606]
   Rzayev R, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P199, DOI 10.1145/3311350.3347190
   Rzayev R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173619
   Rzayev Rufat, 2020, P 11 NORD C HUM COMP, P1, DOI [10.1145/3419249.3420095, DOI 10.1145/3419249.3420095]
   Schildbach B., 2010, Proceedings of the 12th international conference on Human computer interaction with mobile devices and services, P93, DOI DOI 10.1145/1851600.1851619
   Tanaka K, 2008, INT SYM MIX AUGMENT, P139, DOI 10.1109/ISMAR.2008.4637340
   Uchimura M, 2015, EUR J NEUROSCI, V42, P1651, DOI 10.1111/ejn.12935
   Uchimura M, 2013, J NEUROSCI, V33, P7595, DOI 10.1523/JNEUROSCI.5702-12.2013
   Vadas K, 2006, READING GO EVALUATIO
   Weber Dominik, 2016, P ACM INT C INT EXP, P13, DOI [10.1145/2932206.2932212, DOI 10.1145/2932206.2932212]
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Xiao R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1221, DOI 10.1145/2858036.2858212
   Zenner A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188505
   Zhao X, 2019, 2019 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P175, DOI 10.1109/CW.2019.00036
NR 62
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 829
EP 848
DI 10.1007/s10055-022-00693-9
EA SEP 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000856592600002
DA 2024-07-18
ER

PT J
AU Ropelato, S
   Menozzi, M
   Huang, MYY
AF Ropelato, Sandro
   Menozzi, Marino
   Huang, Melody Ying-Yu
TI Hyper-reoriented walking in minimal space
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Virtual locomotion; Natural walking; Redirected walking
ID VIRTUAL-REALITY APPLICATIONS; MOTION SICKNESS; SUSCEPTIBILITY; IMMERSION
AB We present a new reorientation technique, "hyper-reoriented walking," which greatly reduces the amount of physical space required in virtual reality (VR) applications asking participants to walk along a grid-like path (such as the most common layout in department stores). In hyper-reoriented walking, users walk along the gridlines with a virtual speed of twice the speed of real walking and perform turns at cross-points on the grid with half the speed of the rotation speed in the physical space. The impact of the technique on participants' sense of orientation and increase in simulator sickness was investigated experimentally involving 19 participants walking in a labyrinth of infinite size that included straight corridors and 90 degrees T-junctions at the end of the corridors. Walking accuracy was assessed by tracking the position of the head mounted display, and cyber-sickness was recorded with the simulator sickness questionnaire and with open questions. Walking straight forward was found to closely match the ideal path, which is the grid line, but slight errors occasionally occurred when participants turned at the T-junctions. A correction algorithm was therefore necessary to bring users back to the gridline. For VR experiments in a grid-like labyrinth with paths of 5 m in length, the technique reduces required size of the tracked physical walking area to 3 m x 2 m.
C1 [Ropelato, Sandro; Menozzi, Marino; Huang, Melody Ying-Yu] Swiss Fed Inst Technol, Human Factors Engn, Zurich, Switzerland.
   [Huang, Melody Ying-Yu] Univ Bern, Bern Univ Hosp, Dept Anaesthesiol & Pain Med, Inselspital, Bern, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; University of
   Bern; University Hospital of Bern
RP Ropelato, S (corresponding author), Swiss Fed Inst Technol, Human Factors Engn, Zurich, Switzerland.
EM sandro.ropelato@gmail.com
RI Menozzi, Marino/A-3530-2014
OI Menozzi, Marino/0000-0001-7020-4808; Huang, Melody
   Ying-Yu/0000-0003-4368-9648
FU Swiss Federal Institute of Technology Zurich; EMDO Stiftung Zurich
   [942]; ETH Zurich
FX Open access funding provided by Swiss Federal Institute of Technology
   Zurich. This research is funded by the EMDO Stiftung Zurich, 2018.
   Project title: Left or Right? Spontaneous Alternation Behavior in
   Zebrafish and Man (Gesuch Nr. 942) and ETH Zurich.
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   [Anonymous], 2006, Proceedings of the 3rd Symposium on Applied Perception in Graphics and Visualization, APGV'06, DOI 10.1145/1140491.1140495
   Balcombe J, 2004, ATLA-ALTERN LAB ANIM, V32, P553, DOI 10.1177/026119290403201s90
   Benzeroual K, 2013, INT CONF 3D IMAG
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Cardoso JCS, 2019, COMPUT GRAPH-UK, V85, P55, DOI 10.1016/j.cag.2019.09.005
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   Courtine G, 2003, EUR J NEUROSCI, V18, P177, DOI 10.1046/j.1460-9568.2003.02736.x
   Doniec A, 2020, INFORM SCIENCES, V521, P380, DOI 10.1016/j.ins.2020.02.054
   Englund C, 2017, HIGH EDUC RES DEV, V36, P73, DOI 10.1080/07294360.2016.1171300
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Jaeger B. K., 2001, P HUM FACT ERG SOC A, P1896, DOI DOI 10.1177/154193120104502709
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim W, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102648
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Lawson G, 2015, APPL ERGON, V48, P240, DOI 10.1016/j.apergo.2014.12.007
   Lombart C, 2020, COMPUT HUM BEHAV, V110, DOI 10.1016/j.chb.2020.106374
   Lubeck AJA, 2015, DISPLAYS, V38, P55, DOI 10.1016/j.displa.2015.03.001
   Meldrum D, 2012, DISABIL REHABIL-ASSI, V7, P205, DOI 10.3109/17483107.2011.616922
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Mottura S, 2003, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON ADVANCED RESEARCH IN VIRTUAL AND RAPID PROTOTYPING, P297
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Quevedo WX, 2018, LECT NOTES COMPUT SC, V10851, P176, DOI 10.1007/978-3-319-95282-6_13
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Razzaque S., 2001, Proc. Eurogr, P289, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Reif R, 2008, VISUAL COMPUT, V24, P987, DOI 10.1007/s00371-008-0271-7
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Shibata T., 2002, Quarterly Report of RTRI, V43, P87, DOI 10.2219/rtriqr.43.87
   Siegrist M, 2019, FOOD RES INT, V117, P50, DOI 10.1016/j.foodres.2018.02.033
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI 10.1145/1450579.1450611
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Sun Q., 2020, REDIRECTED WALKING V, P285
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Verhulst A, 2017, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2017.7892231
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Yu R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P313, DOI 10.1109/VR.2018.8448288
   Zentes J., 2017, Strategic Retail Management, P207, DOI [DOI 10.1007/978-3-658-10183-1, 10.1007/978-3-658-10183-1_10, DOI 10.1007/978-3-658-10183-1_10]
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 41
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1009
EP 1017
DI 10.1007/s10055-021-00608-0
EA DEC 2021
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000729010600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Voinescu, A
   Petrini, K
   Fraser, DS
   Lazarovicz, RA
   Papava, I
   Fodor, LA
   David, D
AF Voinescu, Alexandra
   Petrini, Karin
   Stanton Fraser, Danae
   Lazarovicz, Radu-Adrian
   Papava, Ion
   Fodor, Liviu Andrei
   David, Daniel
TI The effectiveness of a virtual reality attention task to predict
   depression and anxiety in comparison with current clinical measures
SO VIRTUAL REALITY
LA English
DT Article
DE Attention; Response inhibition; Depression; Anxiety; Cognitive ability;
   Virtual reality
ID CONTINUOUS PERFORMANCE-TEST; EXECUTIVE FUNCTION; MAJOR DEPRESSION;
   SELECTIVE ATTENTION; COGNITIVE-STYLE; REACTION-TIME; DISORDER;
   ENVIRONMENTS; USABILITY; SYMPTOMS
AB Previous studies have revealed that attention and inhibition are impaired in individuals with elevated symptoms of depression and anxiety. Virtual reality (VR)-based neuropsychological assessment may be a valid instrument for assessing attention and inhibition given its higher ecological validity when compared to classical tests. However, it is still unclear as to whether a VR assessment can predict depression and anxiety with the same or higher level of effectiveness and adherence as classical neuropsychological measures. The current study examined the effectiveness of a new VR test, Nesplora Aquarium, by testing participants with low (N = 41) and elevated (N = 41) symptoms of depression and anxiety. Participants completed a continuous performance test where they had to respond to stimuli (species of fish) in a virtual aquarium, as well as paper-and-pencil and computerised tests. Participants' performance in Nesplora Aquarium was positively associated with classic measures of attention and inhibition, and effectively predicted symptoms of depression and anxiety above and beyond traditional cognitive measures such as psychomotor speed and executive functioning, spatial working memory span. Hence, VR is a safe, enjoyable, effective and more ecological alternative for the assessment of attention and inhibition among individuals with elevated anxiety and depression symptoms.
C1 [Voinescu, Alexandra; Petrini, Karin; Stanton Fraser, Danae] Univ Bath, Dept Psychol, Bath BA2 7AY, Avon, England.
   [Lazarovicz, Radu-Adrian] Clin Cty Emergency Hosp Pius Branzeu, Clin Psychiat, Iancu Vacarescu 21, Timisoara 300425, Romania.
   [Papava, Ion] Univ Med & Pharm Victor Babes Eftimie Murgu, Discipline Psychiat, Dept Neurosci, Timisoara 30041, Romania.
   [Voinescu, Alexandra; Fodor, Liviu Andrei] Babes Bolyai Univ, Int Inst Adv Studies Psychotherapy & Appl Mental, 37 Repub St, Cluj Napoca 400015, Romania.
   [David, Daniel] Babes Bolyai Univ, Dept Clin Psychol & Psychotherapy, 37 Republ St, Cluj Napoca 400015, Romania.
   [Fodor, Liviu Andrei] Babes Bolyai Univ, Evidence Based Psychol Assessment & Intervent Doc, 37 Republ St, Cluj Napoca 400015, Romania.
C3 University of Bath; Babes Bolyai University from Cluj; Babes Bolyai
   University from Cluj; Babes Bolyai University from Cluj
RP Voinescu, A (corresponding author), Univ Bath, Dept Psychol, Bath BA2 7AY, Avon, England.; Voinescu, A (corresponding author), Babes Bolyai Univ, Int Inst Adv Studies Psychotherapy & Appl Mental, 37 Repub St, Cluj Napoca 400015, Romania.
EM av561@bath.ac.uk; kp504@bath.ac.uk; pssds@bath.ac.uk;
   l.radu.adrian@gmail.com; papava.ion@umft.ro;
   liviu.andrei.fodor@gmail.com; DanielDavid@psychology.ro
RI David, Daniel/N-1285-2014; Fodor, Liviu Andrei/I-7424-2019; Lazarovicz,
   Radu-Adrian/HOH-9267-2023; Fodor, Liviu Andrei/ABH-4529-2020; Voinescu,
   Alexandra/AAD-9003-2019
OI Fodor, Liviu Andrei/0000-0003-3461-1240; Voinescu,
   Alexandra/0000-0001-7689-335X; Petrini, Karin/0000-0001-5354-5600;
   Stanton Fraser, Danae/0000-0002-3062-731X
FU European Commission under Horizon 2020 Program (Project VRMIND-Virtual
   Reality Based Evaluation of Mental Disorders) [733901]; H2020 -
   Industrial Leadership [733901] Funding Source: H2020 - Industrial
   Leadership; EPSRC [EP/T022523/1] Funding Source: UKRI
FX The equipment used for the study (Nesplora Aquarium VR system) was
   funded by the European Commission under Horizon 2020 Program (Grant
   733901, from Project VRMIND-Virtual Reality Based Evaluation of Mental
   Disorders). The funding source had no involvement in the research and
   preparation of the article.
CR AlFaris E, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0794-y
   [Anonymous], 2017, Saudi. Med. J., V38, P444
   Armstrong CM, 2013, J CLIN EXP NEUROPSYC, V35, P113, DOI 10.1080/13803395.2012.740002
   Asahi S, 2004, EUR ARCH PSY CLIN N, V254, P245, DOI 10.1007/s00406-004-0488-z
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bayard S, 2011, ARCH CLIN NEUROPSYCH, V26, P653, DOI 10.1093/arclin/acr053
   Beck A.T., 2012, Inventarul de Depresie Beck, V2nd ed.
   Beck AT, 1996, Psychol Assess, DOI [10.1037/t00742-000, DOI 10.1037/T00742-000]
   BENTON AL, 1994, ANNU REV PSYCHOL, V45, P1, DOI 10.1146/annurev.ps.45.020194.000245
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Brooke J., 1986, Digital equipment co ltd
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Chang Y, 2011, BIOL PSYCHIAT, V69, P742, DOI 10.1016/j.biopsych.2010.12.024
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Chisholm D, 2016, LANCET PSYCHIAT, V3, P415, DOI 10.1016/S2215-0366(16)30024-4
   Climent G, 2021, APPL NEUROPSYCH-ADUL, V28, P403, DOI 10.1080/23279095.2019.1646745
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Coles, 2009, MAJOR DEPRESSIVE DIS, P51, DOI [10.1016/B978-0-323-58131-8.00004-5, DOI 10.1016/B978-0-323-58131-8.00004-5]
   Conners CK, 2003, J ABNORM CHILD PSYCH, V31, P555, DOI 10.1023/A:1025457300409
   Corno G, 2014, STUD HEALTH TECHNOL, V199, P168, DOI 10.3233/978-1-61499-401-5-168
   Corsi P.M., 1972, Dissertation Abstracts International, V34
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Degl'Innocenti A, 1998, ACTA PSYCHIAT SCAND, V97, P182, DOI 10.1111/j.1600-0447.1998.tb09985.x
   Den Hartog HM, 2003, PSYCHOL MED, V33, P1443, DOI 10.1017/S003329170300833X
   Disner SG, 2011, NAT REV NEUROSCI, V12, P467, DOI 10.1038/nrn3027
   Drummond R.J., 2016, ASSESSMENT PROCEDURE
   Efron B., 1993, INTRO BOOTSTRAP, DOI 10.1007/978-1-4899-4541-9
   Egeland J, 2003, ACTA PSYCHIAT SCAND, V108, P276, DOI 10.1034/j.1600-0447.2003.00146.x
   Evenden JL, 1998, PSYCHOPHARMACOLOGY, V140, P319, DOI 10.1007/s002130050773
   Eysenck MW, 2007, EMOTION, V7, P336, DOI 10.1037/1528-3542.7.2.336
   Field A., 2013, DISCOVERING STAT USI
   Fox J., 2016, Applied Regression Analysis, Linear Models, and Related Methods, DOI DOI 10.5860/CHOICE.34-6323
   GILBOA Y, 2018, J ATTEN DISORD
   Godard J, 2011, PSYCHIAT RES, V190, P244, DOI 10.1016/j.psychres.2011.06.014
   Greve KW, 2005, ARCH CLIN NEUROPSYCH, V20, P355, DOI 10.1016/j.acn.2004.09.004
   Gualtieri C Thomas, 2005, Psychiatry (Edgmont), V2, P44
   Hadwin JA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00047
   Hallion LS, 2018, J ANXIETY DISORD, V53, P39, DOI 10.1016/j.janxdis.2017.10.007
   HALPERIN JM, 1991, DEV NEUROPSYCHOL, V7, P207, DOI 10.1080/87565649109540488
   HARTLAGE S, 1993, PSYCHOL BULL, V113, P247, DOI 10.1037/0033-2909.113.2.247
   Iriarte Y, 2016, J ATTEN DISORD, V20, P542, DOI 10.1177/1087054712465335
   Kähkönen S, 2007, J PSYCHIATR NEUROSCI, V32, P316
   Keller AS, 2019, TRANSL PSYCHIAT, V9, DOI 10.1038/s41398-019-0616-1
   Kemp AH, 2010, J AFFECT DISORDERS, V123, P202, DOI 10.1016/j.jad.2009.08.010
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kertzman S, 2010, J AFFECT DISORDERS, V122, P167, DOI 10.1016/j.jad.2009.08.009
   Kessels RPC, 2019, CLIN NEUROPSYCHOL, V33, P357, DOI 10.1080/13854046.2018.1518489
   Kim A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0225-2
   Kim YI, 2019, PSYCHIAT INVEST, V16, P167, DOI 10.30773/pi.2018.12.25.1
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Koc-Januchta M, 2017, COMPUT HUM BEHAV, V68, P170, DOI 10.1016/j.chb.2016.11.028
   Lalonde G, 2013, J NEUROSCI METH, V219, P76, DOI 10.1016/j.jneumeth.2013.07.005
   Laver K, 2012, PRESENCE-TELEOP VIRT, V21, P183, DOI 10.1162/PRES_a_00098
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lezak MD, 2004, Neuropsychological Assessment, DOI DOI 10.1017/S0033291718001599
   Li HJ, 2019, INT J NURS SCI, V6, P117, DOI 10.1016/j.ijnss.2018.11.007
   Liu J, 2020, J AFFECT DISORDERS, V260, P91, DOI 10.1016/j.jad.2019.08.091
   Losier BJ, 1996, J CHILD PSYCHOL PSYC, V37, P971, DOI 10.1111/j.1469-7610.1996.tb01494.x
   Mallinckrodt B, 2006, J COUNS PSYCHOL, V53, P372, DOI 10.1037/0022-0167.53.3.372
   Marazziti D, 2010, EUR J PHARMACOL, V626, P83, DOI 10.1016/j.ejphar.2009.08.046
   Mayer RE, 2003, J EDUC PSYCHOL, V95, P833, DOI 10.1037/0022-0663.95.4.833
   MILLER J, 1991, Q J EXP PSYCHOL-A, V43, P907, DOI 10.1080/14640749108400962
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Möller HJ, 2016, EUR ARCH PSY CLIN N, V266, P725, DOI 10.1007/s00406-016-0684-7
   Morán AL, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0297-0
   Motter JN, 2016, J AFFECT DISORDERS, V189, P184, DOI 10.1016/j.jad.2015.09.022
   Mousavi M, 2013, ADV ENG FORUM, V10, P34, DOI 10.4028/www.scientific.net/AEF.10.34
   Mueller ST, 2014, J NEUROSCI METH, V222, P250, DOI 10.1016/j.jneumeth.2013.10.024
   Nandi A, 2009, BMC PSYCHIATRY, V9, DOI 10.1186/1471-244X-9-31
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Negut A., 2015, Transylvanian Journal of Psychology, V16
   Negut A, 2017, CHILD NEUROPSYCHOL, V23, P692, DOI 10.1080/09297049.2016.1186617
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Negut A, 2016, COMPUT HUM BEHAV, V54, P414, DOI 10.1016/j.chb.2015.08.029
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Pachet AK, 2003, PSYCHOPHARMACOLOGY, V170, P225, DOI 10.1007/s00213-003-1592-x
   Parry I, 2015, J BURN CARE RES, V36, P534, DOI 10.1097/BCR.0000000000000165
   Parsons T. D., 2019, Virtual Realityfor Psychological and Neurocognitive Interventions, P247, DOI [10.1007/978-1-4939-9482-3_11, DOI 10.1007/978-1-4939-9482-3_11]
   Parsons TD, 2019, NEUROPSYCHOL REV, V29, P338, DOI 10.1007/s11065-019-09407-6
   Parsons TD, 2017, J ALZHEIMERS DIS, V59, P1227, DOI 10.3233/JAD-170295
   Parsons TD, 2017, NEUROPSYCHOL REHABIL, V27, P777, DOI 10.1080/09602011.2015.1109524
   Pedroli E, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072343
   Pedroli E, 2013, INT CONF PER COMP, P453, DOI 10.4108/icst.pervasivehealth.2013.252359
   Pacheco-Unguetti AP, 2011, J ANXIETY DISORD, V25, P888, DOI 10.1016/j.janxdis.2011.04.010
   Piper B, 2016, PEERJ, V4, DOI 10.7717/peerj.1772
   Qiu XH, 2011, NEUROSCI LETT, V491, P53, DOI 10.1016/j.neulet.2011.01.006
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Remes O, 2016, BRAIN BEHAV, V6, DOI 10.1002/brb3.497
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rizzo AA, 2006, CNS SPECTRUMS, V11, P35, DOI 10.1017/S1092852900024196
   Rizzo A, 2020, URBAN STUD, V57, P1520, DOI 10.1177/0042098018812009
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Rock PL, 2014, PSYCHOL MED, V44, P2029, DOI 10.1017/S0033291713002535
   Rodríguez C, 2018, INT J CLIN HLTH PSYC, V18, P254, DOI 10.1016/j.ijchp.2018.06.003
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   ROSENBLAT J, 2015, INT J NEUROPSYCHOPH
   ROSVOLD HE, 1956, J CONSULT PSYCHOL, V20, P343, DOI 10.1037/h0043220
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Schirmer A, 2010, CLIN NEUROPHYSIOL, V121, P53, DOI 10.1016/j.clinph.2009.09.029
   Schultheis M., 2017, The role of technology in clinical neuropsychologypp, P47
   Servera M, 2006, INT J CLIN HLTH PSYC, V6, P697
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Snyder HR, 2013, PSYCHOL BULL, V139, P81, DOI 10.1037/a0028727
   Spielberger CD, 1970, MANUAL STATE TRAIT A
   Spielberger CD, 2007, STAI Y STATE TRAIT A
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   Stein RA, 1998, ARCH CLIN NEUROPSYCH, V13, P259, DOI 10.1016/S0887-6177(97)00027-9
   Strauss E., 2006, COMPENDIUM NEUROPSYC
   STUSS DT, 1984, PSYCHOL BULL, V95, P3, DOI 10.1037/0033-2909.95.1.3
   STUSS DT, 1989, J NEUROL NEUROSUR PS, V52, P742, DOI 10.1136/jnnp.52.6.742
   Sun HM, 2015, APPL ERGON, V50, P126, DOI 10.1016/j.apergo.2015.03.006
   Takei Y, 2009, PSYCHOPHYSIOLOGY, V46, P52, DOI 10.1111/j.1469-8986.2008.00748.x
   Tiller JWG, 2013, MED J AUSTRALIA, V199, P28, DOI 10.5694/mjao12.10628
   Tinius TP, 2003, ARCH CLIN NEUROPSYCH, V18, P439, DOI 10.1016/S0887-6177(02)00144-0
   Tyrer P, 2001, BRIT J PSYCHIAT, V179, P191, DOI 10.1192/bjp.179.3.191
   Urbina S., 2004, Essentials of Psychological Testing
   Vilgis V, 2015, EUR CHILD ADOLES PSY, V24, P365, DOI 10.1007/s00787-015-0675-7
   Voinescu A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1207, DOI [10.1109/VR.2019.8798191, 10.1109/vr.2019.8798191]
   Wagner S, 2012, ACTA PSYCHIAT SCAND, V125, P281, DOI 10.1111/j.1600-0447.2011.01762.x
   Weiner IB., 2013, HDB PSYCHOL ASSESSME
   WEINSTEIN AM, 1995, BIOL PSYCHIAT, V37, P847, DOI 10.1016/0006-3223(94)00249-3
   Wingo AP, 2009, J CLIN PSYCHIAT, V70, P1588, DOI 10.4088/JCP.08r04972
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang XX, 2020, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00899
   Zweerings J, 2019, HUM BRAIN MAPP, V40, P3657, DOI 10.1002/hbm.24623
NR 127
TC 14
Z9 15
U1 3
U2 46
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 119
EP 140
DI 10.1007/s10055-021-00520-7
EA APR 2021
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000640829900001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Gonçalves, A
   Montoya, MF
   Llorens, R
   Badia, SBI
AF Goncalves, A.
   Montoya, M. F.
   Llorens, R.
   Badia, S. Bermudez i
TI A virtual reality bus ride as an ecologically valid assessment of
   balance: a feasibility study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Balance assessment; Posturography; Ecological validity;
   Visual motion
ID POSTURAL BALANCE; ENVIRONMENTS; SPECIFICITY; LIMITATIONS; STROKE; SYSTEM
AB Balance disorders can have substantial adverse implications on the performance of daily activities and lead to an increased risk of falls, which often have severe negative consequences for older adults. Quantitative assessment through computerized force plate-based posturography enables objective assessment of postural control but could not successfully represent specific abilities required during daily activities. The use of virtual reality (VR) could improve the representative design of functional activities and increase the ecological validity of posturographic tests, which would enhance the transferability of results to the real world. In this work, we investigate the feasibility of a simulated bus ride experienced in a surround-screen VR system to assess balance with increased ecological validity. Participants were first evaluated with a posturography test and then with the VR-based bus ride test, while the reactions of their centre of pressure were registered. Lastly, participants provided self-reported measures of the elicited sense of presence during the test. A total of 16 healthy young adults completed the study. Results showed that the simulation could elicit significant medial-lateral excursions of the centre of pressure in response to variations in the optical flow. Furthermore, these responses' amplitude negatively correlated with the participants' posturography excursions when fixating a target. Although the sense of presence was moderate, likely due to the passive nature of the test, the results support the feasibility of our proposed paradigm, based in the context of a meaningful daily living activity, in assessing balance control components.
C1 [Goncalves, A.; Badia, S. Bermudez i] Univ Madeira, Madeira Interact Technol Inst, Funchal, Portugal.
   [Goncalves, A.; Badia, S. Bermudez i] Univ Madeira, Fac Ciencias Exatas & Engn, Funchal, Portugal.
   [Goncalves, A.; Badia, S. Bermudez i] Univ Nova Lisboa, NOVA LINCS, Caparica, Portugal.
   [Montoya, M. F.] Univ Tecnol Pereira, Human Comp Interact Grp, Pereira, Colombia.
   [Llorens, R.] Univ Politecn Valencia, Neurorehabil & Brain Res Grp, Valencia, Spain.
   [Llorens, R.] Hosp Vithas, Serv Neurorrehabil, NEURORHB, Valencia, Spain.
C3 Universidade da Madeira; Universidade da Madeira; Universidade Nova de
   Lisboa; Universidad Tecnologica de Pereira; Universitat Politecnica de
   Valencia
RP Gonçalves, A (corresponding author), Univ Madeira, Madeira Interact Technol Inst, Funchal, Portugal.; Gonçalves, A (corresponding author), Univ Madeira, Fac Ciencias Exatas & Engn, Funchal, Portugal.; Gonçalves, A (corresponding author), Univ Nova Lisboa, NOVA LINCS, Caparica, Portugal.
EM afonso.goncalves@m-iti.org
RI Llorens, Roberto/AAL-2604-2021; Badia, Sergi Bermúdez i/C-8681-2018
OI Llorens, Roberto/0000-0002-8677-8707; Badia, Sergi Bermúdez
   i/0000-0003-4452-0414; Montoya, Maria Fernanda/0000-0001-8587-2358;
   Goncalves, Afonso/0000-0003-3196-2678
FU Fundacao para a Ciencia e Tecnologia through the AHA project
   [CMUPERI/HCI/0046/2013]; Fundacao para a Ciencia e Tecnologia through
   the NOVA-LINCS [UID/CEC/04516/2019]; INTERREG program through the
   MACBIOIDI project [MAC/1.1.b/098]; project VALORA of the Fundacio la
   Marato de la TV3 (Barcelona, Spain) [201701-10]; European Union through
   the Operational Program of the European Regional Development Fund (ERDF)
   of the Valencian Community 2014-2020 [IDIFEDER/2018/029]; Fundação para
   a Ciência e a Tecnologia [UID/CEC/04516/2019] Funding Source: FCT
FX This work was supported by the Fundacao para a Ciencia e Tecnologia
   through the AHA project (CMUPERI/HCI/0046/2013), and NOVA-LINCS
   (UID/CEC/04516/2019), by the INTERREG program through the MACBIOIDI
   project (MAC/1.1.b/098), by project VALORA, Grant 201701-10 of the
   Fundacio la Marato de la TV3 (Barcelona, Spain) and the European Union
   through the Operational Program of the European Regional Development
   Fund (ERDF) of the Valencian Community 2014-2020 (IDIFEDER/2018/029).
CR Allum JHJ, 1997, J VESTIBUL RES-EQUIL, V7, P189, DOI 10.1016/S0957-4271(97)00029-3
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   Bonan IV, 2004, ARCH PHYS MED REHAB, V85, P268, DOI 10.1016/j.apmr.2003.06.017
   Borrego A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0174-1
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   BRONFENBRENNER U, 1977, AM PSYCHOL, V32, P513, DOI 10.1037/0003-066x.32.7.513
   Burdea G. C., 2003, Virtual reality technology
   Claesson IM, 2017, PHYSIOTHER THEOR PR, V33, P490, DOI 10.1080/09593985.2017.1318424
   Clark RA, 2010, GAIT POSTURE, V31, P307, DOI 10.1016/j.gaitpost.2009.11.012
   Clark RA, 2011, GAIT POSTURE, V34, P288, DOI 10.1016/j.gaitpost.2011.04.010
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Elion O, 2015, BRAIN RES, V1609, P54, DOI 10.1016/j.brainres.2015.03.020
   Giboin LS, 2015, HUM MOVEMENT SCI, V44, P22, DOI 10.1016/j.humov.2015.08.012
   Goncalves Afonso, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3229092
   Goncalves A., 2021, IEEE Transactions on Visualization and Computer Graphics
   Horak FB, 2009, PHYS THER, V89, P484, DOI 10.2522/ptj.20080071
   Huurnink A, 2013, J BIOMECH, V46, P1392, DOI 10.1016/j.jbiomech.2013.02.018
   i Badia Sergi Bermudez, 2016, Neurorehabilitation Technology, P573, DOI [10.1007/978-3-319-28603-7_28, DOI 10.1007/978-3-319-28603-7_28]
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Llorens R, 2016, GAIT POSTURE, V43, P228, DOI 10.1016/j.gaitpost.2015.10.002
   Lord SR, 1996, GERONTOLOGY, V42, P199, DOI 10.1159/000213793
   Mancini M, 2010, EUR J PHYS REHAB MED, V46, P239
   Mihara M, 2012, NEUROREPORT, V23, P314, DOI 10.1097/WNR.0b013e328351757b
   Morel M, 2015, NEUROPHYSIOL CLIN, V45, P315, DOI 10.1016/j.neucli.2015.09.007
   Naumann T, 2015, GAIT POSTURE, V41, P774, DOI 10.1016/j.gaitpost.2015.02.003
   Navalón N, 2014, BRAIN INJURY, V28, P1417, DOI 10.3109/02699052.2014.917200
   Pardasaney PK, 2013, PHYS THER, V93, P1351, DOI 10.2522/ptj.20130028
   Rubenstein LZ, 2006, AGE AGEING, V35, P37, DOI 10.1093/ageing/afl084
   Salzman B, 2010, AM FAM PHYSICIAN, V82, P61
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   Teresa P, 2019, EXP INT C 2019S
   Tyson SF., 2009, Clinical Rehabilitation
   Visser JE, 2008, CLIN NEUROPHYSIOL, V119, P2424, DOI 10.1016/j.clinph.2008.07.220
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yelnik AP, 2006, GAIT POSTURE, V24, P262, DOI 10.1016/j.gaitpost.2005.09.007
NR 38
TC 5
Z9 6
U1 4
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 109
EP 117
DI 10.1007/s10055-021-00521-6
EA APR 2021
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000636420700001
DA 2024-07-18
ER

PT J
AU Harris, DJ
   Buckingham, G
   Wilson, MR
   Brookes, J
   Mushtaq, F
   Mon-Williams, M
   Vine, SJ
AF Harris, David J.
   Buckingham, Gavin
   Wilson, Mark R.
   Brookes, Jack
   Mushtaq, Faisal
   Mon-Williams, Mark
   Vine, Samuel J.
TI Exploring sensorimotor performance and user experience within a virtual
   reality golf putting simulator
SO VIRTUAL REALITY
LA English
DT Article
DE VR; Sport; Training; Construct validity; Simulation
ID DISTANCE PERCEPTION; CONSTRUCT-VALIDITY; FACE
AB In light of recent advances in technology, there has been growing interest in virtual reality (VR) simulations for training purposes in a range of high-performance environments, from sport to nuclear decommissioning. For a VR simulation to elicit effective transfer of training to the real-world, it must provide a sufficient level of validity, that is, it must be representative of the real-world skill. In order to develop the most effective simulations, assessments of validity should be carried out prior to implementing simulations in training. The aim of this work was to test elements of the physical fidelity, psychological fidelity and construct validity of a VR golf putting simulation. Self-report measures of task load and presence in the simulation were taken following real and simulated golf putting to assess psychological and physical fidelity. The performance of novice and expert golfers in the simulation was also compared as an initial test of construct validity. Participants reported a high degree of presence in the simulation, and there was little difference between real and virtual putting in terms of task demands. Experts performed significantly better in the simulation than novices (p = .001, d = 1.23), and there was a significant relationship between performance on the real and virtual tasks (r = .46, p = .004). The results indicated that the simulation exhibited an acceptable degree of construct validity and psychological fidelity. However, some differences between the real and virtual tasks emerged, suggesting further validation work is required.
C1 [Harris, David J.; Buckingham, Gavin; Wilson, Mark R.; Vine, Samuel J.] Univ Exeter, Sch Sport & Hlth Sci, St Lukes Campus, Exeter EX1 2LU, Devon, England.
   [Brookes, Jack; Mushtaq, Faisal; Mon-Williams, Mark] Univ Leeds, Sch Psychol, Leeds LS2 9JZ, W Yorkshire, England.
   [Mushtaq, Faisal; Mon-Williams, Mark] Univ Leeds, Ctr Immers Technol, Leeds LS2 9JZ, W Yorkshire, England.
   [Mon-Williams, Mark] Bradford Teaching Hosp NHS Fdn Trust, Bradford, W Yorkshire, England.
   [Mon-Williams, Mark] Univ South Eastern Norway, Natl Ctr Opt Vis & Eye Care, Hasbergs Vei 36, N-3616 Kongsberg, Norway.
C3 University of Exeter; University of Leeds; University of Leeds;
   University College of Southeast Norway
RP Harris, DJ (corresponding author), Univ Exeter, Sch Sport & Hlth Sci, St Lukes Campus, Exeter EX1 2LU, Devon, England.
EM D.J.Harris@exeter.ac.uk; G.Buckingham@exeter.ac.uk;
   Mark.Wilson@exeter.ac.uk; ed11jb@leeds.ac.uk; F.Mushtaq@leeds.ac.uk;
   M.Mon-Williams@leeds.ac.uk; S.J.Vine@exeter.ac.uk
RI Harris, David/H-9114-2019; Buckingham, Gavin/A-8715-2008
OI Harris, David/0000-0003-3880-3856; Mon-Williams,
   Mark/0000-0001-7595-8545
FU Royal Academy of Engineering UKIC Fellowship; Alan Turing Institute;
   EPSRC [EP/R031193/1]; EPSRC [EP/R031193/1] Funding Source: UKRI
FX This work was supported by a Royal Academy of Engineering UKIC
   Fellowship awarded to D Harris. F.M and M.M-W were supported by
   Fellowships from the Alan Turing Institute and a Research Grant from the
   EPSRC (EP/R031193/1).
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Bideau B, 2003, PRESENCE-TELEOP VIRT, V12, P411, DOI 10.1162/105474603322391631
   Bideau B., 2004, Proceedings of the 2004 ACM SIGGRAPH international conference on Virtual Reality continuum and its applications in industry, P210
   Bingham GP, 2001, J EXP PSYCHOL HUMAN, V27, P1314, DOI 10.1037//0096-1523.27.6.1314
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bright E, 2012, INT J SURG, V10, P163, DOI 10.1016/j.ijsu.2012.02.012
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Burdea G. C., 2003, VIRTUAL REALITY TECH, DOI DOI 10.1162/105474603322955950
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Durgin FH, 2011, ATTEN PERCEPT PSYCHO, V73, P1856, DOI 10.3758/s13414-011-0143-5
   Gray R., 2019, Anticipation and Decision Making in Sport
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Harris D, 2020, VIRTUAL REAL-LONDON, V24, P557, DOI 10.1007/s10055-019-00422-9
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   HART S G, 1988, P139
   Ijsselsteijn W., 2004, P VIRTUAL REALITY DE, P22
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   JASP Team, 2018, JASP VERS 0 9 COMP S
   Lammfromm R., 2011, BIOWEB C, V1, P00054, DOI [10.1051/bioconf/20110100054, DOI 10.1051/BIOCONF/20110100054]
   Moore LJ, 2012, PSYCHOPHYSIOLOGY, V49, P1005, DOI 10.1111/j.1469-8986.2012.01379.x
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Schorer, 2015, PSYCHOL TEST ASSESSM, V57, P13
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Stoffregen TA, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P111, DOI 10.1201/9781410608888.ch6
   Sweet R, 2004, J UROLOGY, V172, P1953, DOI 10.1097/01.ju.0000141298.06350.4c
   Todorov E, 1997, J MOTOR BEHAV, V29, P147, DOI 10.1080/00222899709600829
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Walters-Symons R, 2018, COGN PROCESS, V19, P47, DOI 10.1007/s10339-017-0841-6
   Wann J, 1996, INT J HUM-COMPUT ST, V44, P829, DOI 10.1006/ijhc.1996.0035
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
NR 34
TC 21
Z9 22
U1 4
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 647
EP 654
DI 10.1007/s10055-020-00480-4
EA OCT 2020
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000581786800001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU La Salandra, A
   Frajberg, D
   Fraternali, P
AF La Salandra, Antonio
   Frajberg, Darian
   Fraternali, Piero
TI A virtual reality application for augmented panoramic mountain images
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Mobile applications; Location-based systems; Remote
   sensing; Environmental monitoring; Mountain identification
ID GIS
AB Virtual reality is a powerful interaction mechanism that holds the promise of engaging users, not only for entertainment, but also for social and environmental purposes. In this paper we present PeakLensVR, a virtual reality mobile application that enables users to capture panoramic mountain images with their mobile devices and later visualize such images, enriched with metadata about the peaks visible from the capture point, with a low-end VR device. The application exploits a multi-stage data processing pipeline, which comprises the following steps: (1) the acquisition of a sequence of frames with the mobile phone camera and their annotation with sensor readings captured during the shooting session; (2) the creation of a panoramic image from the acquired frames, with state-of-the art stitching algorithms; (3) the registration of the panoramic image to the mountain skyline in view, by comparing the image skyline with a virtual profile extracted from the NASA SRTM Digital Elevation Model of the Earth; (4) the enrichment of the registered panoramic image with markers and metadata (name, altitude, etc.) of the peaks in view, by querying the OpenStreetMap GIS.
C1 [La Salandra, Antonio; Frajberg, Darian; Fraternali, Piero] Politecn Milan, Piazza L Da Vinci 32, Milan, Italy.
C3 Polytechnic University of Milan
RP Frajberg, D (corresponding author), Politecn Milan, Piazza L Da Vinci 32, Milan, Italy.
EM darian.frajberg@polimi.it
CR [Anonymous], 2017, GRAPH CUTS VERSUS DY
   [Anonymous], 2017, IMAGE BLENDING
   [Anonymous], IEEE C COMP VIS PATT
   Baboud L, 2011, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2011.5995727
   Borba EZ, 2017, P IEEE VIRT REAL ANN, P463, DOI 10.1109/VR.2017.7892380
   Boulos MNK, 2017, INT J HEALTH GEOGR, V16, DOI 10.1186/s12942-017-0081-0
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Cai QJ, 2009, HT2008: PROCEEDING OF THE ASME SUMMER HEAT TRANSFER CONFERENCE, VOL 3, P293
   Castelletti A., 2016, P 24 ACM INT C MULT, P948, DOI 10.1145/2964284.2976759
   Chai Q., 2016, P IEEE INT C MULTIME, P1
   Coburn JQ, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4036921
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Fedorov R, 2017, THESIS
   Fedorov R, 2016, LECT NOTES COMPUT SC, V9768, P281, DOI 10.1007/978-3-319-40621-3_21
   Ferster CJ, 2013, COMPUT GEOSCI-UK, V51, P339, DOI 10.1016/j.cageo.2012.09.009
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frajberg D, 2017, PR INT CONF DATA SC, P313, DOI 10.1109/DSAA.2017.5
   Frajberg D, 2017, LECT NOTES COMPUT SC, V10614, P12, DOI 10.1007/978-3-319-68612-7_2
   Ha SJ, 2007, IEEE T CONSUMER ELEC, V53
   Ha SJ, 2008, IEEE T CONSUMER ELEC, V54
   Huang B, 2001, INT J GEOGR INF SCI, V15, P439, DOI 10.1080/13658810110046574
   Ishimaru T, 2008, BEILSTEIN J ORG CHEM, V4, DOI 10.3762/bjoc.4.16
   Joly A., 2016, P ACM 24 ACM INT C M, P958
   Keis F, 2014, INT SENS SENS NETW I, P1
   Kim BS, 2011, IEEE T CONSUMER ELEC, V57
   Kim HK, 2011, IEEE T CONSUM ELECTR, V57, P1875, DOI 10.1109/TCE.2011.6131166
   La Salandra A, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1206, DOI 10.1145/3184558.3191559
   Liu S, 2018, IEEE T MULTIMEDIA
   Liu SG, 2019, IEEE T MULTIMEDIA, V21, P690, DOI 10.1109/TMM.2018.2864576
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry CS, 2013, GROUND WATER, V51, P151, DOI 10.1111/j.1745-6584.2012.00956.x
   Maisonneuve N, 2009, ENVIRON SCI ENG, P215, DOI 10.1007/978-3-540-88351-7_16
   Piccolo L., 2016, P INT AAAI C WEB SOC, V10
   POYNTON C, 2001, YUV LUMINANCE CONSID
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Sharma P, 2015, ACM SIGGRAPH 2015 TA, P57
   Slater M, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00003
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sullivan BL, 2009, BIOL CONSERV, V142, P2282, DOI 10.1016/j.biocon.2009.05.006
   Survey UG, 2009, SHUTTL RAD TOP MISS
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Verbree E, 1999, INT J GEOGR INF SCI, V13, P385, DOI 10.1080/136588199241265
   Xiong Y., 2010, IEEE T CONSUMER ELEC, V56
   Zepeda-Mendoza M. L., 2013, HIERARCHICAL AGGLOME, P886, DOI DOI 10.1007/978-1-4419-9863-7_1371
NR 44
TC 4
Z9 4
U1 0
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 123
EP 141
DI 10.1007/s10055-019-00385-x
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800008
DA 2024-07-18
ER

PT J
AU Torres-Ruiz, M
   Mata, F
   Zagal, R
   Guzman, G
   Quintero, R
   Moreno-Ibarra, M
AF Torres-Ruiz, Miguel
   Mata, Felix
   Zagal, Roberto
   Guzman, Giovanni
   Quintero, Rolando
   Moreno-Ibarra, Marco
TI A recommender system to generate museum itineraries applying augmented
   reality and social-sensor mining techniques
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Tour recommendations; Internet of things; Semantic
   classification; Mobile devices
ID KNOWLEDGE; IMPACT; KDD
AB Nowadays, museums offer technological and digital options to enrich the user experience in a visit. However, questions arise like which exhibition/museum could I visit? How to tour it and get the best experience? These questions are not easy to answer, because they do not represent tasks straightforward. Considering that the experiences of visiting a museum are now available in social networks, in which users describe, rate, and disseminate a work of art/exhibition of a museum, this information can be mined to generate tour recommendations in museums. Such recommendations could be improved by combining and applying data mining obtained from Internet of Things sensors installed in museums. In this paper, a hybrid approach to make recommendations for museum visits is proposed. It includes an Internet of Things architecture of beacons, incorporating some technologies based on semantic analysis, data mining, and machine learning. This approach integrates and combines data sources for generating and recommending indoor and outdoor itineraries for museums, which are visualized with augmented reality. The itinerary is built, taking into consideration opinions and assessments from social networks, the semantic classification of museums, and cultural activities, as well as data measured by beacon sensors in museum exhibitions. The result is a customized tour with augmented reality that contains a set of recommendations of how to visit a set of museums and obtain a better experience of the visit. A prototype of mobile application is available in the Google Play, called the "Historic Center," with almost 500 downloads and an acceptable evaluation.
C1 [Torres-Ruiz, Miguel; Mata, Felix; Zagal, Roberto; Guzman, Giovanni; Quintero, Rolando; Moreno-Ibarra, Marco] Inst Politecn Nacl, CIC, UPALM Zacatenco, Mexico City 07320, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Torres-Ruiz, M (corresponding author), Inst Politecn Nacl, CIC, UPALM Zacatenco, Mexico City 07320, DF, Mexico.
EM mtorres@cic.ipn.mx
RI Torres-Ruiz, Miguel/AAU-9308-2021; Guzman, Giovanni/HJP-1053-2023;
   Rivera, Miguel Felix MR Mata/R-2141-2018; QUINTERO,
   ROLANDO/AGN-4493-2022; Torres, Miguel/HZK-8113-2023
OI Torres-Ruiz, Miguel/0000-0001-8289-6979; Guzman,
   Giovanni/0000-0002-8420-3520; QUINTERO, ROLANDO/0000-0003-4454-8791;
   Moreno-Ibarra, Marco/0000-0002-0349-5585; ZAGAL-FLORES,
   ROBERTO-ESWART/0000-0001-5649-6189
FU Instituto Politecnico Nacional (IPN); Secretaria de Investigacion y
   Posgrado (SIP) [20171918, 20171086, 20171463, 20171192]; Consejo
   Nacional de Ciencia y Tecnologia (CONACYT) [1051]
FX This work was partially sponsored by the Instituto Politecnico Nacional
   (IPN), the Secretaria de Investigacion y Posgrado (SIP) under Grants
   20171918, 20171086, 20171463, and 20171192, as well as the Consejo
   Nacional de Ciencia y Tecnologia (CONACYT) with the grant 1051.
   Additionally, we are thankful to the reviewers for their invaluable and
   constructive feedback that helped improve the quality of the paper.
CR Abu-Mostafa Y. S., 2012, Learning from Data: A Short Course
   Adu-Poku S, 2012, THESIS
   Alexander EdwardP., 2017, MUSEUMS MOTION INTRO
   Amores M, 2016, COMPUT SIST, V20, P263, DOI [10.13053/cys-20-2-2318, 10.13053/CyS-20-2-2318]
   Araujo C., 2018, DEV ADV INTELLIGENT, P91, DOI [DOI 10.1007/978-3-319-58965-7, 10.1007/978-3-319-58965-7_7]
   Baraldi L, 2015, IEEE SENS J, V15, P2705, DOI 10.1109/JSEN.2015.2411994
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blazquez D, 2017, BIG DATA SOURCES MET
   Capuano N, 2016, BEHAV INFORM TECHNOL, V35, P968, DOI 10.1080/0144929X.2016.1208774
   García-Palomares JC, 2015, APPL GEOGR, V63, P408, DOI 10.1016/j.apgeog.2015.08.002
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Chianese A, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P403, DOI 10.1109/SITIS.2013.73
   Choi HS, 2017, INT J INFORM MANAGE, V37, P1519, DOI 10.1016/j.ijinfomgt.2016.04.017
   Dim E, 2015, ACM T INTERACT INTEL, V4, DOI 10.1145/2662869
   Falk J. H., 2000, Learning from museums: Visitor Experiences and the making of meaning
   Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Hajmoosaei A, 2016, IEEE INT C SEMANT CO, P100, DOI 10.1109/ICSC.2016.74
   Hu YJ, 2015, COMPUT ENVIRON URBAN, V54, P240, DOI 10.1016/j.compenvurbsys.2015.09.001
   Huang W, 2016, EXPERT SYST APPL, V55, P48, DOI 10.1016/j.eswa.2016.01.037
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Jung Timothy., 2016, INFORM COMMUNICATION, P621, DOI [DOI 10.1007/978-3-319-28231-2_45, 10.1007/978-3-319-28231-245, DOI 10.1007/978-3-319-28231-245]
   Kumar V., 2006, Introduction to Data Mining
   Lara JA, 2014, INFORM SYST, V44, P54, DOI 10.1016/j.is.2014.03.002
   Lindqvist J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2409
   Lytras MD, 2017, INT J SEMANT WEB INF, V13, P1, DOI 10.4018/IJSWIS.2017010101
   Martini RG, 2016, ADV INTELL SYST, V444, P401, DOI 10.1007/978-3-319-31232-3_38
   Mata F, 2011, P 19 ACM SIGSPATIAL, P497, DOI [10.1145/2093973.2094058, DOI 10.1145/2093973.2094058]
   Mata F, 2016, MOB INF SYST, V2016, P1, DOI 10.1155/2016/8068209
   Mata F, 2011, LECT NOTES COMPUT SC, V6574, P5, DOI 10.1007/978-3-642-19173-2_3
   McKercher B, 2016, TOURISM MANAGE, V54, P196, DOI 10.1016/j.tourman.2015.11.008
   Pallud J, 2017, INFORM MANAGE-AMSTER, V54, P465, DOI 10.1016/j.im.2016.10.004
   Papatheodorou A, 2010, J TRAVEL RES, V49, P39, DOI 10.1177/0047287509355327
   Perkins J, 2010, COVERING DISASTER: LESSONS FROM MEDIA COVERAGE OF KATRINA AND RITA, P1
   Reyes JA, 2013, COMPUT SIST, V17, P263
   Sampson A, 2012, THESIS
   STYLIANI S, 2009, J CULT HERIT, V10, P520, DOI [DOI 10.1016/J.CULHER.2009.03.003, 10.1016/j.culher.2009.03.003]
   Su SL, 2016, APPL GEOGR, V73, P26, DOI 10.1016/j.apgeog.2016.06.001
   Visvizi A, 2017, J SCI TECHNOL POLICY, V8, P227, DOI 10.1108/JSTPM-05-2017-0020
   Waske B, 2009, LECT NOTES COMPUT SC, V5519, P375, DOI 10.1007/978-3-642-02326-2_38
   Younes Georges, 2017, Digital Applications in Archaeology and Cultural Heritage, V5, P1, DOI 10.1016/j.daach.2017.03.002
   Zhang CS, 2017, EXPERT SYST APPL, V82, P128, DOI 10.1016/j.eswa.2017.04.003
   Zhou XL, 2015, COMPUT ENVIRON URBAN, V54, P144, DOI 10.1016/j.compenvurbsys.2015.07.006
NR 44
TC 23
Z9 23
U1 4
U2 66
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 175
EP 189
DI 10.1007/s10055-018-0366-z
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800012
DA 2024-07-18
ER

PT J
AU Dickinson, P
   Gerling, K
   Hicks, K
   Murray, J
   Shearer, J
   Greenwood, J
AF Dickinson, Patrick
   Gerling, Kathrin
   Hicks, Kieran
   Murray, John
   Shearer, John
   Greenwood, Jacob
TI Virtual reality crowd simulation: effects of agent density on user
   experience and behaviour
SO VIRTUAL REALITY
LA English
DT Article
DE Crowd simulation; User experience; Agent density
ID ENVIRONMENTS; EVACUATION
AB Agent-based crowd simulations are used for modelling building and space usage, allowing designers to explore hypothetical real-world scenarios, including extraordinary events such as evacuations. Existing work which engages virtual reality (VR) as a platform for crowd simulations has been primarily focussed on the validation of simulation models through observation; the use of interactions such as gaze to enhance a sense of immersion; or studies of proxemics. In this work, we extend previous studies of proxemics and examine the effects of varying crowd density on user experience and behaviour. We have created a simulation in which participants walk freely and perform a routine manual task, whilst interacting with agents controlled by a typical social force simulation model. We examine and report the effects of crowd density on both affective state and behaviour. Our results show a significant increase in negative affect with density, measured using a self-report scale. We further show significant differences in some aspects of user behaviours, using video analysis, and discuss how our results relate to VR simulation design for mixed human-agent scenarios.
C1 [Dickinson, Patrick; Hicks, Kieran; Shearer, John; Greenwood, Jacob] Univ Lincoln, Sch Comp Sci, Lincoln, England.
   [Gerling, Kathrin] Katholieke Univ Leuven, E Media Res Lab, Leuven, Belgium.
   [Murray, John] Univ Hull, Sch Comp Sci, Kingston Upon Hull, N Humberside, England.
C3 University of Lincoln; KU Leuven; University of Hull
RP Dickinson, P (corresponding author), Univ Lincoln, Sch Comp Sci, Lincoln, England.
EM pdickinson@lincoln.ac.uk
RI Gerling, Kathrin/AAB-9227-2020
OI Gerling, Kathrin/0000-0002-8449-6124
CR Ahn Junghyun., 2012, P 11 ACM SIGGRAPH IN, P231
   Boucsein W, 1992, ELECTRODERMAL ACTIVI
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Christou C, 2015, INT CONF AFFECT, P35, DOI 10.1109/ACII.2015.7344548
   Curtis S, 2013, VISUAL COMPUT, V29, P1277, DOI 10.1007/s00371-012-0769-x
   Dawson M, 2007, HDB PSYCHOPHYSIOLOGY, P152
   DeCuir-Gunby JT, 2011, FIELD METHOD, V23, P136, DOI 10.1177/1525822X10388468
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Farina F, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169734
   Ferrer G, 2013, IEEE INT C INT ROBOT, P1688, DOI 10.1109/IROS.2013.6696576
   Filingeri V, 2017, APPL ERGON, V59, P431, DOI 10.1016/j.apergo.2016.09.009
   Fink PW, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1227134.1227136
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Gérin-Lajoie M, 2008, GAIT POSTURE, V27, P239, DOI 10.1016/j.gaitpost.2007.03.015
   HALL ET, 1963, AM ANTHROPOL, V65, P1003, DOI 10.1525/aa.1963.65.5.02a00020
   Helbing D, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P21
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hupont Isabelle., 2015, 2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX), P1, DOI [DOI 10.1109/QOMEX.2015.7148110, 10.1109/QoMEX.2015.7148110]
   Johansson A, 2012, LANCET INFECT DIS, V12, P150, DOI 10.1016/S1473-3099(11)70287-0
   Karamouzas I, 2009, MOTION GAMES MIG 200
   Kim S, 2016, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2016.7504685
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Kyriakou M, 2015, P IEEE VIRT REAL ANN, P217, DOI 10.1109/VR.2015.7223373
   Li WH, 2017, PHYSICA A, V469, P157, DOI 10.1016/j.physa.2016.11.047
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Narang S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P91, DOI 10.1145/2993369.2993378
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pelechano Nuria, 2016, 2016 IEEE Virtual Humans and Crowds for Immersive Environments (VHCIE), P17, DOI 10.1109/VHCIE.2016.7563568
   Pelechano N., 2008, SYNTHESILECT COMPU
   Pelechano N, 2008, P INT C AUT AG MULT, P136
   Rojas F. A., 2013, P 12 ACM SIGGRAPH IN, P31, DOI DOI 10.1145/2534329.2534336
   Rojas FA, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P31, DOI 10.1109/CW.2014.13
   Sanz FA, 2015, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2015.7223327
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Sohre N, 2017, 2017 IEEE VIRTUAL HUMANS AND CROWDS FOR IMMERSIVE ENVIRONMENTS (VHCIE)
   Sticco IM, 2017, PHYSICA A, V474, P172, DOI 10.1016/j.physa.2017.01.079
   Tang TQ, 2017, PHYSICA A, V467, P157, DOI 10.1016/j.physa.2016.10.008
   Ulicny B, 2001, SPRING EUROGRAP, P163
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wilcox Laurie M., 2006, ACM Trans. on Perception, V3, P412, DOI [DOI 10.1145/1190036.1190041, 10.1145/1190036.1190041]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zheng XP, 2009, BUILD ENVIRON, V44, P437, DOI 10.1016/j.buildenv.2008.04.002
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 46
TC 37
Z9 43
U1 2
U2 38
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 19
EP 32
DI 10.1007/s10055-018-0365-0
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500003
OA Green Published, hybrid, Green Accepted
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI THE MANY SHAPES AND FORMS OF AR AND VR
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR [Anonymous], 2017, FITNESS         0815
   [Anonymous], 2018, VIRTUAL REALITY BECO
   Fu Beimeng, 2018, ABC NEWS        0208
   Health Alex, 2017, BUSINESS INSIDE 0421
   Ho Vanessa, 2017, MICROSOFT NEWS   JUN
   Lewis Tanya, 2014, LIVE SCI        0808
   Milgram Paul, 1994, IEICE T INFORM SY ED, V77
   Roberts G., 2018, NEW YORK TIMES 0201
   Ryzik Melena, 2018, NEW YORK TIMES 0320
   Vanian Jonathan, 2016, FORTUNE         0322
NR 10
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 37
EP +
PG 30
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200004
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI MORALITY, ETHICS, LAW, AND SOCIAL CONSEQUENCES
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR Aardema F, 2006, CYBERPSYCHOL BEHAV, V9, P653
   Anderson C. A., 2010, PSYCHOL BULL, V126
   [Anonymous], 2016, PHYS MENTAL EFFECTS
   [Anonymous], 2016, DECCAN CHRONICL 0110
   Bailenson, EXPERIENCE DEMAND
   Bailenson, EXPERIENCE DEMAND
   Bailenson, EXPERIENCE DEMAND
   Bailenson Jeremy, EXPERIENCE DEMAND WH
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Brown MM, 2008, FRONTIERSMAN: DANIEL BOONE AND THE MAKING OF AMERICA, P21
   Campbell JC, 2002, LANCET, V359, P1331, DOI 10.1016/S0140-6736(02)08336-8
   Dawson Joe, 2018, ASS PSYCHOL SCI
   Experience on Demand, 2018, EXPERIENCE DEMAND WH
   Griffiths Sarah, 2014, DAILY MAIL COM  0826
   Hoffman David M., 2008, VERGENCE ACCOMMODATI
   Hunt K., 2015, CNN 0119
   Kristoffel N, 2008, NATO SCI PEACE SEC B, P179
   Lemley Mark A., 2018, 2933867 UCLA SCH LAW, DOI DOI 10.2139/SSRN.2933867
   Madary M., 2016, FRONTIERS ROBOTICS A, DOI [10.3389/frobt.2016.00003/full, DOI 10.3389/FROBT.2016.00003/FULL]
   Madary Michael, 2016, LS N GLOBAL     0404
   Madary Michael, 2016, FRONTIERS ROBOT 0219, DOI DOI 10.3389/FO0BT.2016.00003/FULL
   Markey Patrick M., 2017, M COMBAT WHY WAR VIO
   Reddick Graham, 2015, TELEGRAPH       0304
   Rizzo Albert Skip, 2003, ETHICAL ISSUES CLIN, P243
   Silverman C., 2016, BuzzFeed News, V6
   Solon Olivia, 2013, WIRED           1021
   STINSON L, 1992, J PERS SOC PSYCHOL, V62, P787, DOI 10.1037/0022-3514.62.5.787
   Strohmeyer Robert, PC WORLD
   Tobias can Schneider, 2016, MEDIUM 1107
   Vasdekis AE, 2015, SCI REP-UK, V5, DOI 10.1038/srep17689
   Volokh Eugene, 2017, WASHINGTON POST 0322
   World Health Organization (WHO), 2002, ICD116C51 WHO
   Worrall Simon, 2018, NATL GEOGRAPHIC 0211
NR 33
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 153
EP +
D2 10.7551/mitpress/11836.001.0001
PG 38
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200008
DA 2024-07-18
ER

PT J
AU Liang, H
   Deng, SJ
   Chang, J
   Zhang, JJ
   Chen, C
   Tong, RF
AF Liang, Hui
   Deng, Shujie
   Chang, Jian
   Zhang, Jian Jun
   Chen, Can
   Tong, Ruofeng
TI Semantic framework for interactive animation generation and its
   application in virtual shadow play performance
SO VIRTUAL REALITY
LA English
DT Article
DE Semantic framework; Virtual interactive; Animation generation; Ontology;
   Hand-gesture-based interaction; Animation data management; Chinese
   shadow play
ID ONTOLOGY; REPRESENTATION; DESIGN
AB Designing and creating complex and interactive animation is still a challenge in the field of virtual reality, which has to handle various aspects of functional requirements (e.g. graphics, physics, AI, multimodal inputs and outputs, and massive data assets management). In this paper, a semantic framework is proposed to model the construction of interactive animation and promote animation assets reuse in a systematic and standardized way. As its ontological implementation, two domain-specific ontologies for the hand-gesture-based interaction and animation data repository have been developed in the context of Chinese traditional shadow play art. Finally, prototype of interactive Chinese shadow play performance system using deep motion sensor device is presented as the usage example.
C1 [Liang, Hui] Zhengzhou Univ Light Ind, Zhengzhou, Henan, Peoples R China.
   [Deng, Shujie; Chang, Jian; Zhang, Jian Jun] Natl Ctr Comp Animat, Poole, Dorset, England.
   [Chen, Can] Changzhou Univ, Changzhou, Peoples R China.
   [Tong, Ruofeng] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Zhengzhou University of Light Industry; Changzhou University; Zhejiang
   University
RP Chang, J (corresponding author), Natl Ctr Comp Animat, Poole, Dorset, England.
EM jchang@bournemouth.ac.uk
RI Liu, Liu/JXM-8208-2024
FU People Programme (Marie Curie Actions) of the European Union's Seventh
   Framework Programme FP7 under REA Grant [623883]; project AniNex
   [FP7-IRSES-612627];  [FP7-ICT-611383]
FX The research leading to these results has received funding from the
   People Programme (Marie Curie Actions) of the European Union's Seventh
   Framework Programme FP7/2007-2013/under REA Grant Agreement No
   [623883]-"AniM". The authors acknowledge partial support from project Dr
   Inventor (FP7-ICT-611383). The authors acknowledge partial support from
   project AniNex (FP7-IRSES-612627).
CR [Anonymous], 2007, P MIR 2007
   [Anonymous], 2009, 4 INT C DES SCI RES
   [Anonymous], 2014, P 2 INT C TECHN EC E, DOI DOI 10.1145/2669711.2669904
   Anthony M. K., 2009, INT IND TRAIN SIM ED
   Arndt R., 2009, HDB ONTOLOGIES, P403, DOI DOI 10.1007/9783-54092673-3_18
   Bilasco I. M., 2005, 13th Annual ACM International Conference on Multimedia, P471, DOI 10.1145/1101149.1101254
   BinSubaih A., 2005, P 2005 ACM SIGCHI IN, P458
   Borst WN., 1997, Construction of engineering ontologies for knowledge sharing and reuse"
   Chang PHM, 2005, LECT NOTES ARTIF INT, V3661, P134
   Chen F, 2015, PACIFIC SCI, V201
   De Boeck J., 2006, Task Models and Diagrams for Users Interface Design. 5th International Workshop, TAMODIA 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4385), P217
   Dubin D, 2015, PROCEEDINGS OF THE 15TH ACM/IEEE-CS JOINT CONFERENCE ON DIGITAL LIBRARIES (JCDL'15), P165, DOI 10.1145/2756406.2756939
   Falcidieno B, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P329, DOI 10.1109/SMI.2004.1314520
   Falcidieno Bianca., 2004, EWIMT
   Flotynski J, 2013, FED CONF COMPUT SCI, P541
   Flotynski J, 2014, IFIP ADV INF COMM TE, V423, P63
   Flotynski J, 2013, LECT NOTES BUS INF P, V160, P244
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Gruninger M., 1995, P IJCAI95 WORKSHOP B, p6.1
   Gutiérrez M, 2007, VISUAL COMPUT, V23, P207, DOI 10.1007/s00371-006-0093-4
   Gutiérrez M, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P277, DOI 10.1109/MMMC.2005.65
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Leino OT, 2010, MEAN PLAY 2010 C P U
   Li ZJ, 2007, AI EDAM, V21, P137, DOI 10.1017/S0890060407070199
   Liang H, 2015, 14TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, VRCAI 2015, P63, DOI 10.1145/2817675.2817680
   Mansouri H, 2005, THESIS
   Mirbakhsh N., 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT 2010), P234, DOI 10.1109/WI-IAT.2010.161
   Otto K, 2005, P WORKSH SEM VIRT EN
   Parkkila J, 2015, P 11 BIANN C IT SIGC, P26
   Ruminski D, 2014, INT SYM MIX AUGMENT, P401
   Sa V., 2008, P INT STUD COMP SCI, P44
   Studer R, 1998, DATA KNOWL ENG, V25, P161, DOI 10.1016/S0169-023X(97)00056-6
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Thalman D., 1999, DAT APPL NONTR ENV 1, P471
   Tutenel T., 2009, AIIDE
   Walczak K., 2013, P 5 JOINT VIRT REAL, P41
   World Wide Web Consortium, 2012, OWL 2 WEB ONT LANG D
   Zhang YD, 2015, ADV MECH ENG, V7, DOI 10.1177/1687814015589479
NR 39
TC 18
Z9 18
U1 6
U2 47
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2018
VL 22
IS 2
SI SI
BP 149
EP 165
DI 10.1007/s10055-018-0333-8
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GC5KP
UT WOS:000429826700006
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Punpongsanon, P
   Iwai, D
   Sato, K
AF Punpongsanon, Parinya
   Iwai, Daisuke
   Sato, Kosuke
TI Projection-based visualization of tangential deformation of nonrigid
   surface by deformation estimation using infrared texture
SO VIRTUAL REALITY
LA English
DT Article
DE Projection-based mixed reality; User interaction; Deformable surface
AB In this paper, we propose a projection-based mixed reality system that visualizes the tangential deformation of a nonrigid surface by superimposing graphics directly onto the surface by projected imagery. The superimposed graphics are deformed according to the surface deformation. To achieve this goal, we develop a computer vision technique that estimates the tangential deformation by measuring the frame-by-frame movement of an infrared (IR) texture on the surface. IR ink, which can be captured by an IR camera under IR light, but is invisible to the human eye, is used to provide the surface texture. Consequently, the texture does not degrade the image quality of the augmented graphics. The proposed technique measures individually the surface motion between two successive frames. Therefore, it does not suffer from occlusions caused by interactions and allows touching, pushing, pulling, and pinching, etc. The moving least squares technique interpolates the measured result to estimate denser surface deformation. The proposed method relies only on the apparent motion measurement; thus, it is not limited to a specific deformation characteristic, but is flexible for multiple deformable materials, such as viscoelastic and elastic materials. Experiments confirm that, with the proposed method, we can visualize the surface deformation of various materials by projected illumination, even when the user's hand occludes the surface from the camera.
C1 [Punpongsanon, Parinya; Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Toyonaka, Osaka 5608531, Japan.
C3 Osaka University
RP Punpongsanon, P (corresponding author), Osaka Univ, 1-3 Machikaneyama, Toyonaka, Osaka 5608531, Japan.
EM parinya@sens.sys.es.osaka-u.ac.jp; daisuke.iwai@sys.es.osaka-u.ac.jp;
   sato@sys.es.osakau.ac.jp
RI PUNPONGSANON, PARINYA/B-4884-2013; Iwai, Daisuke/R-8174-2019
OI PUNPONGSANON, PARINYA/0000-0003-2720-7768; Iwai,
   Daisuke/0000-0002-3493-5635
FU Grants-in-Aid for Scientific Research [22135003] Funding Source: KAKEN
CR Alvarez L, 2000, INT J COMPUT VISION, V39, P41, DOI 10.1023/A:1008170101536
   [Anonymous], ACM T GRAPH
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/2470654.2466112
   [Anonymous], 2013, Proc. CHI 2013, DOI DOI 10.1145/2470654.2470688
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, UIST '11
   [Anonymous], 2005, CHI'05: CHI'05 extended abstracts on Human factors in computing systems
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bimber O, 2008, ACM T GRAPHIC, V27
   Bluteau J., 2005, INT C AUGM TEL EX, P98
   Fujimoto Y, 2014, IEEE T VIS COMPUT GR, V20, P540, DOI 10.1109/TVCG.2014.25
   Haouchine N., 2012, WORKSH VIRT REAL INT
   Heo Seongkook, 2013, P SIGCHI C HUMAN FAC, P281, DOI 10.1145/2470654.2470693
   Hisada M, 2006, 2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13, P2475
   Ito Y, 2014, ADV ROBOT AUTOM, V3
   Iwai D, 2011, VIRTUAL REAL-LONDON, V15, P147, DOI 10.1007/s10055-010-0159-5
   Johnson MH, 2011, SEMIN ULTRASOUND CT, V32, P1, DOI 10.1053/j.sult.2010.11.003
   Kamiyama K, 2005, IEEE COMPUT GRAPH, V25, P68, DOI 10.1109/MCG.2005.27
   Kocev B, 2013, INT J COMPUT ASSIST, V8, P1015
   Matoba Y, 2012, ACM SIGGRAPH EMERGIN
   Mine M, 2012, COMPUTER, V45, P32, DOI 10.1109/MC.2012.154
   Ni T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3333
   Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9
   Piper B., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P355, DOI 10.1145/503376.503439
   Raskar R, 2001, SPRING EUROGRAP, P89
   Raskar R., 2006, P INT S NONPH AN REN, P7
   Rong-Chi Chang, 2010, 2010 3rd IEEE International Conference on Ubi-Media Computing (U-Media 2010), P44, DOI 10.1109/UMEDIA.2010.5543933
   Saakes D, 2010, ACM SIGGRAPH EMERGIN, P22
   Sato T, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P43
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shimazu S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P235, DOI 10.1109/ISMAR.2011.6092393
   Shimizu N, 2013, INT C COMP VIS THEOR, P1
   Uchiyama H., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P237, DOI 10.1109/ISMAR.2011.6092394
   Uchiyama H, 2011, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2011.5759433
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
NR 36
TC 36
Z9 37
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2015
VL 19
IS 1
BP 45
EP 56
DI 10.1007/s10055-014-0256-y
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CB5CS
UT WOS:000349645700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hugues, O
   Cieutat, JM
   Guitton, P
AF Hugues, Olivier
   Cieutat, Jean-Marc
   Guitton, Pascal
TI Real-time infinite horizon tracking with data fusion for augmented
   reality in a maritime operations context
SO VIRTUAL REALITY
LA English
DT Article
DE Image processing; Data fusion; Augmented reality; Electronic chart
   system; Geographical information system
ID VISION
AB In this paper, we propose a method for real-time horizon tracking (i.e., separation line between the sky and the sea) in a maritime operations context. We present the fusion of an image processing algorithm with the data obtained from the inertial measurement unit (IMU). The initial aim is to filter out environmental conditions using inertial information in order to combine a video stream with onboard electronic charts. This is achieved by the detection of the horizon with an image processing algorithm in an area defined by the IMU. We then present an evaluation of the algorithm with regard to the rate of detection of the horizon and the impact of the image resolution on the computational time. The purpose of developing this method is to create an augmented reality maritime operations application. We combine the video stream with electronic charts in a single display. We use the position of the horizon in the image to split the display into different areas. Then, we use transparency to display the video, the electronic charts or both.
C1 [Hugues, Olivier] ESTIA Res, MaxSea, LaBRI INRIA, Bidart, France.
   [Cieutat, Jean-Marc] ESTIA Res, Bidart, France.
   [Guitton, Pascal] Univ Bordeaux 1, LaBRI IPARLA INRIA, Bordeaux, France.
C3 Universite de Bordeaux
RP Hugues, O (corresponding author), ESTIA Res, MaxSea, LaBRI INRIA, Bidart, France.
EM o.hugues@net.estia.fr; j.cieutat@estia.fr; guitton@labri.fr
CR Bouma H, 2008, P SPIE ELECT IMAGING, V7114, P1
   Calvary G, 2003, INTERACT COMPUT, V15, P289, DOI 10.1016/S0953-5438(03)00010-9
   Cornall T, 2004, MECSE42004
   Ettinger SM, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2134, DOI 10.1109/IRDS.2002.1041582
   Fefilatyev S, 2006, ICMLA 2006: 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P17
   French Government, 2009, OC ROUND TABL
   Grant S, 2010, ECDIS PRESENT FUTURE
   Hong-Zhao Yuan, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P191, DOI 10.1109/IASP.2010.5476135
   Hugues O, 2010, 12 VIRT REAL INT C V, P149
   Hugues O, 2010, P AH 10 2010 AUGM HU P AH 10 2010 AUGM HU, P1
   Maidi M, 2007, THESIS EVRY VAL ESSO
   Petit M, 2008, P 8 INT S WEB WIR GE, V5373, P100
   Phillips O, 1966, CAMBRIDGE MONOGRAPHS
   Pillich B, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P1116
   Ribo M, 2002, IEEE COMPUT GRAPH, V22, P54, DOI 10.1109/MCG.2002.1046629
   Todorovic S, 2004, FLOR C REC ADV ROB
   Wang Jie, 2008, 2008 IEEE International Conference on Systems, Man and Cybernetics (SMC 2008), P1895, DOI 10.1109/ICSMC.2008.4811566
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Woo J., 2005, MVA, P526
   You S, 1999, P IEEE VIRT REAL ANN, P260, DOI 10.1109/VR.1999.756960
   You SY, 2001, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2001.913772
   Zabala FA, 2006, HOUGH TRANSFORM IMPL
   Zafarifar B, 2008, PROC SPIE, V6822, DOI 10.1117/12.766689
NR 23
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2014
VL 18
IS 2
BP 129
EP 138
DI 10.1007/s10055-013-0234-9
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HV
UT WOS:000340622300004
DA 2024-07-18
ER

PT B
AU Chessa, M
   Solari, F
   Sabatini, SP
AF Chessa, Manuela
   Solari, Fabio
   Sabatini, Silvio P.
BE Kim, JJ
TI Virtual Reality to Simulate Visual Tasks for Robotic Systems
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID FLOW
C1 [Chessa, Manuela; Solari, Fabio; Sabatini, Silvio P.] Univ Genoa, Dept Biophys & Elect Engn, Via Opera Pia 11-A, I-16145 Genoa, Italy.
C3 University of Genoa
RP Chessa, M (corresponding author), Univ Genoa, Dept Biophys & Elect Engn, Via Opera Pia 11-A, I-16145 Genoa, Italy.
RI Solari, Fabio/O-4729-2016; Sabatini, Silvio P./A-5500-2012; Chessa,
   Manuela/O-4628-2016
OI Sabatini, Silvio P./0000-0002-0557-7306; 
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678
   [Anonymous], ADV TELEROBOTICS
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], WORKSH PERF METR INT
   Awaad I., 2008, WORKSH ROB SIM IROS0
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Bourke P., 2007, WORKSH 13 INT C VIRT
   Cannata G, 2008, IEEE T ROBOT, V24, P27, DOI 10.1109/TRO.2007.906270
   Chessa M, 2009, LECT NOTES COMPUT SC, V5815, P184, DOI 10.1007/978-3-642-04667-4_19
   Davis J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P144
   EYESHOTS, 2008, FP7ICT217077 EYESHOT
   Ferre M, 2008, IEEE ROBOT AUTOM MAG, V15, P50, DOI 10.1109/MRA.2008.929929
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   Gibaldi A, 2010, NEUROCOMPUTING, V73, P1065, DOI 10.1016/j.neucom.2009.11.016
   GRINBERG VS, 1994, P SOC PHOTO-OPT INS, V2177, P56, DOI 10.1117/12.173906
   HASLWANTER T, 1995, VISION RES, V35, P1727, DOI 10.1016/0042-6989(94)00257-M
   HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455
   Horaud R, 2006, MACH VISION APPL, V16, P331, DOI 10.1007/s00138-005-0182-9
   HUNG GK, 1986, IEEE T BIO-MED ENG, V33, P1021, DOI 10.1109/TBME.1986.325868
   Jorgensen J., 2008, WORKSH ROB SIM IROS0
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   Ma Y., 2004, INVITATION 3D VISION
   McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930
   Michel O., 2004, International Journal of Advanced Robotic Systems, V1, P39
   Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099
   Okada K., 2002, IEEE RSJ IROS
   OTTE M, 1995, ARTIF INTELL, V78, P5, DOI 10.1016/0004-3702(95)00033-X
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Schreiber K, 2001, NATURE, V410, P819, DOI 10.1038/35071081
   SOUTHARD DA, 1992, COMPUT GRAPH, V16, P401, DOI 10.1016/0097-8493(92)90027-S
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Ulusoy I, 2004, LECT NOTES COMPUT SC, V3280, P400
   VANRIJN LJ, 1993, VISION RES, V33, P691, DOI 10.1016/0042-6989(93)90189-4
   VOLPEL B, 1995, IEEE T SYST MAN CYB, V25, P1628, DOI 10.1109/21.478448
   WANN JP, 1995, VISION RES, V35, P2731, DOI 10.1016/0042-6989(95)00018-U
   Yamanoue H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1701, DOI 10.1109/ICME.2006.262877
   Yang ZY, 2003, NETWORK-COMP NEURAL, V14, P371, DOI 10.1088/0954-898X/14/3/301
NR 41
TC 5
Z9 5
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 71
EP 92
D2 10.5772/553
PG 22
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400005
DA 2024-07-18
ER

PT B
AU De Felice, F
   Renna, F
   Attolico, G
   Distante, A
AF De Felice, Fabio
   Renna, Floriana
   Attolico, Giovanni
   Distante, Arcangelo
BE Kim, JJ
TI Hapto-Acoustic Interaction Metaphors in 3D Virtual Environments for
   Non-Visual Settings
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID FEEDBACK
C1 [De Felice, Fabio] Univ Bari A Moro, Comp Sci Dept, Bari, Italy.
   [Renna, Floriana; Attolico, Giovanni; Distante, Arcangelo] CNR, Inst Intelligent Syst Automat, Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro; Consiglio Nazionale delle
   Ricerche (CNR); Istituto di Studi sui Sistemi Intelligenti per
   l'Automazione (ISSIA-CNR)
RP De Felice, F (corresponding author), Univ Bari A Moro, Comp Sci Dept, Bari, Italy.
RI Attolico, Giovanni/AAX-3475-2020
CR AKAMATSU M, 1995, ERGONOMICS, V38, P816, DOI 10.1080/00140139508925152
   Anderson T. G., 1998, THESIS U WASHINGTON
   [Anonymous], 2005, P 7 INT C VIRT REAL
   Boeck Joan De, 2002, P EUR ED 2002, P36
   Bowman D., 1999, P ACM S VIRT REAL SO, P26
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bowmann D, 2005, 3D user interfaces: Theory and practice
   Bowmann D. A., 1997, P S INT 3D GRAPH PRO
   Cockburn A, 2005, ERGONOMICS, V48, P1129, DOI 10.1080/00140130500197260
   Conti F., 2005, IEEE P WORLDHAPTICS
   Coomans M. K. D., 1997, P 4 INT C INF VIS EN
   Cuppens E., 2004, P NORDICHI 2004 TAMP
   De Boeck J., 2003, P HCI INT 2003, V2, P621
   De Felice F, 2009, LECT NOTES COMPUT SC, V5763, P71, DOI 10.1007/978-3-642-04076-4_8
   DEBOECK J, 2001, P 6 PHANTOM US GROUP
   ESPOSITO C, 1996, HUM FACT COMP SYST C
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   Gabbard J.L., 1997, TAXONOMY USABILITY C
   Garre C., 2009, P CEIG 09 SAN SEB SE
   Gramegna T., 2005, IEEE P HAVE 2005 OTT
   Hinkley K., 1994, P SIGCHI C HUM FACT, P452
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   IGARASHI T, 1998, P 11 ANN ACM S US IN, P173, DOI DOI 10.1145/288392.288599
   JACOBSON RD, 2002, P 6 INT C INF VIS
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   KLATZKY RL, 1995, PERCEPT PSYCHOPHYS, V57, P1111, DOI 10.3758/BF03208368
   Kolcarek P., 2005, P 3 INT C COMP GRAPH
   Lahav O, 2008, INT J HUM-COMPUT ST, V66, P23, DOI 10.1016/j.ijhcs.2007.08.001
   Lakoff G., 2003, METAPHORS WE LIVE
   Lécuyer A, 2003, P IEEE VIRT REAL ANN, P251, DOI 10.1109/VR.2003.1191147
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Magnusson C., 2003, P EUROHAPTICS 2003 D
   Magnusson C., 2005, P ENACTIVE05 2 INT C
   Magnusson C., 2004, P EUROHAPTICS 2004 M
   Ménélas B, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P51, DOI 10.1109/3DUI.2010.5444722
   MINE M., 1996, Working in a Virtual World
   MINE MR, 1995, TR95020 UNC CHAP HIL
   MINE MR, 1997, P SIGGRAPH 1997 ANN
   Moustakas K, 2007, IEEE MULTIMEDIA, V14, P62, DOI 10.1109/MMUL.2007.10
   Murai Y., 2006, P ICCHP 2006 LINTZ A
   Okamura AM, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2930, DOI 10.1109/ROBOT.1999.774042
   Ott R., 2010, Computer-Aided Design and Applications, V7, P125, DOI [10.3722/cadaps.2010.125-138, DOI 10.3722/CADAPS.2010.125-138]
   Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398
   Panëels S, 2010, IEEE T HAPTICS, V3, P119, DOI [10.1109/TOH.2009.44, 10.1109/ToH.2009.44]
   Parente P., 2003, P ACM SE REG C MARCH
   Piateski E, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P90
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Pokluda L., 2005, P WORLDHAPTICS 2005
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Prada R, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P375
   Renna F., 2007, P WORLDHAPTICS 2007
   Roberts JC, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P316
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   SJOSTROM C, 1999, IT POTENTIAL HAPTICS
   TZAFESTAS CS, 2003, IEEE T SYSTEMS MAN A, V33
   Vanacken L, 2009, INT J HUM-COMPUT ST, V67, P237, DOI 10.1016/j.ijhcs.2008.09.001
   Vidholm E, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P288
   Wai Yu, 2002, ASSETS 2002. Proceedings of the Fifth International ACM SIGCAPH Conference on Assistive Technologies, P57, DOI 10.1145/638249.638261
   Wall W., 2002, Proceedings of Eurohaptics 2002, P23
   WARE C, 1990, COMPUTER GRAPHICS, V24
   Welch G, 2001, PRESENCE-VIRTUAL AUG, V10, P1, DOI 10.1162/105474601750182289
   ZHAI SM, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P459, DOI 10.1145/191666.191822
   Zilles C. B., 1995, P INT C INT ROB SYST, V3
NR 66
TC 2
Z9 2
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 21
EP 48
D2 10.5772/553
PG 28
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400003
DA 2024-07-18
ER

PT B
AU Riecke, BE
AF Riecke, Bernhard E.
BE Kim, JJ
TI Compelling Self-Motion Through Virtual Environments without Actual
   Self-Motion - Using Self-Motion Illusions ("Vection") to Improve User
   Experience in VR
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID CIRCULAR VECTION; SPATIAL-FREQUENCY; STIMULUS ECCENTRICITY;
   PERIPHERAL-VISION; VISUAL-PERCEPTION; PERCEIVED SPEED; JITTER; SIZE;
   NYSTAGMUS; ROTATION
C1 [Riecke, Bernhard E.] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Riecke, BE (corresponding author), Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
RI Riecke, Bernhard/C-6399-2011
OI Riecke, Bernhard/0000-0001-7974-0850
CR Allison RS, 1999, PERCEPTION, V28, P299, DOI 10.1068/p2891
   ANDERSEN GJ, 1986, PSYCHOL BULL, V99, P52, DOI 10.1037/0033-2909.99.1.52
   ANDERSEN GJ, 1985, J EXP PSYCHOL HUMAN, V11, P122, DOI 10.1037/0096-1523.11.2.122
   Becker W, 2002, EXP BRAIN RES, V144, P554, DOI 10.1007/s00221-002-1104-y
   Berger DR, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658354
   BERTHOZ A, 1975, EXP BRAIN RES, V23, P471
   Bles W., 1981, Attention and Performance IX, P47
   BRANDT T, 1977, EXP BRAIN RES, V30, P331
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   BRANDT T, 1975, PERCEPT PSYCHOPHYS, V17, P497, DOI 10.3758/BF03203301
   Bubka A, 2010, PERCEPTION, V39, P627, DOI 10.1068/p6315
   CHEUNG BSK, 1989, ACTA OTO-LARYNGOL, V108, P336, DOI 10.3109/00016488909125537
   Cress JD, 1997, IEEE COMPUT GRAPH, V17, P46, DOI 10.1109/38.626969
   Dichgans Johannes, 1978, Perception, P755, DOI [DOI 10.1007/978-3-642-46354-9253F, DOI 10.1007/978-3-642-46354-9_25, DOI 10.1007/978-3-642-46354-925]
   DIENER HC, 1976, VISION RES, V16, P169, DOI 10.1016/0042-6989(76)90094-8
   Fischer MH, 1930, J PSYCHOL NEUROL, V41, P273
   Giannopulu I, 1998, PERCEPTION, V27, P363, DOI 10.1068/p270363
   GIBSON JJ, 1954, PSYCHOL REV, V61, P304, DOI 10.1037/h0061885
   Guerraz M, 2008, NEUROSCI LETT, V443, P12, DOI 10.1016/j.neulet.2008.07.053
   HELD R, 1975, VISION RES, V15, P357, DOI 10.1016/0042-6989(75)90083-8
   Hettinger LJ, 2002, HUM FAC ER, P471
   Howard I.P., 1986, Handbook of perception and human performance, P1
   Howard I.P., 1982, HUMAN VISUAL ORIENTA
   HOWARD IP, 1994, PERCEPTION, V23, P753, DOI 10.1068/p230753
   HOWARD IP, 1994, PERCEPTION, V23, P745, DOI 10.1068/p230745
   HOWARD IP, 1989, PERCEPTION, V18, P657, DOI 10.1068/p180657
   Hu SQ, 1997, AVIAT SPACE ENVIR MD, V68, P306
   Ito H, 2005, VISION RES, V45, P397, DOI 10.1016/j.visres.2004.11.009
   Ji JTT, 2009, HUM FACTORS, V51, P739, DOI 10.1177/0018720809349708
   JOHANSSON G, 1977, PERCEPTION, V6, P365, DOI 10.1068/p060365
   Johnson WH, 1999, J VESTIBUL RES-EQUIL, V9, P83
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kim J, 2008, BRAIN RES BULL, V77, P335, DOI 10.1016/j.brainresbull.2008.09.011
   Kitazaki M, 2003, PERCEPTION, V32, P475, DOI 10.1068/p5037
   Kovács G, 2008, CEREB CORTEX, V18, P1779, DOI 10.1093/cercor/bhm203
   LACKNER JR, 1977, AVIAT SPACE ENVIR MD, V48, P129
   Larsson P., 2004, Proceedings of 7th Annual Workshop of Presence, P252
   LEE DN, 1974, PERCEPT PSYCHOPHYS, V15, P529, DOI 10.3758/BF03199297
   Lepecq JC, 2006, J NEUROPHYSIOL, V95, P3199, DOI 10.1152/jn.00478.2005
   LEPECQ JC, 1995, PERCEPTION, V24, P435, DOI 10.1068/p240435
   Lowther K., 1996, C COMPANION HUMAN FA, P233, DOI DOI 10.1145/257089.257297
   Mach E., 1875, GRUNDLINIEN LEHRE BE
   Mergner T, 2000, ARCH ITAL BIOL, V138, P139
   Mergner T, 2000, ARCH ITAL BIOL, V138, P123
   Mergner T., 1990, Perception and Control of Self-Motion, P219
   Nakamura S, 1999, PERCEPTION, V28, P893, DOI 10.1068/p2939
   Nakamura S, 2008, JPN PSYCHOL RES, V50, P77, DOI 10.1111/j.1468-5884.2008.00363.x
   Nakamura S, 2006, VISION RES, V46, P2344, DOI 10.1016/j.visres.2006.01.016
   Nakamura S, 2010, PERCEPTION, V39, P320, DOI 10.1068/p6534
   OHMI M, 1987, PERCEPTION, V16, P17, DOI 10.1068/p160017
   OHMI M, 1988, PERCEPTION, V17, P5, DOI 10.1068/p170005
   Palmisano S, 2004, PERCEPTION, V33, P987, DOI 10.1068/p5242
   Palmisano S, 2003, PERCEPTION, V32, P97, DOI 10.1068/p3468
   Palmisano S, 2002, PERCEPTION, V31, P463, DOI 10.1068/p3321
   Palmisano S, 1998, PERCEPTION, V27, P1067, DOI 10.1068/p271067
   Palmisano S, 1996, PERCEPT PSYCHOPHYS, V58, P1168, DOI 10.3758/BF03207550
   Palmisano S, 2000, PERCEPTION, V29, P57, DOI 10.1068/p2990
   Palmisano S, 2007, AVIAT SPACE ENVIR MD, V78, P951, DOI 10.3357/ASEM.2079.2007
   Palmisano S, 2009, ATTEN PERCEPT PSYCHO, V71, P1842, DOI 10.3758/APP.71.8.1842
   PAVARD B, 1977, PERCEPTION, V6, P529, DOI 10.1068/p060529
   POST RB, 1988, PERCEPTION, V17, P737, DOI 10.1068/p170737
   Prothero J.D., 1998, The role of rest frames in vection, presence and motion sickness
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Richards JT, 2004, PRESENCE-TELEOP VIRT, V13, P371, DOI 10.1162/1054746041422299
   Riecke B.E., 2009, JAPANESE J PSYCHONOM, V28, P135, DOI [DOI 10.14947/PSYCH0N0.KJ00005878681, DOI 10.14947/PSYCHONO.KJ00005878681]
   Riecke B.E., 2010, P 7 S APPL PERCEPTIO, P158, DOI DOI 10.1145/1836248.1836280
   Riecke B. E., 2006, 7 INT MULT RES FOR I
   Riecke B. E., 2005, P HCI INT 2005 LAS V, P1, DOI DOI 10.HTTP://EN.SCIENTI-
   Riecke B. E., 2003, THESIS EBERHARD KARL
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI DOI 10.1145/1180495.1180517
   Riecke BE, 2005, P IEEE VIRT REAL ANN, P131
   Riecke BE, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498701
   Sato T, 2007, PERCEPTION, V36, P180
   Schulte-Pelkum J., 2007, PhD Thesis
   Schulte-Pelkum J., 2003, P PRESENCE 2003
   Schulte-Pelkum J., 2004, INT MULT RES FOR IMR
   Seno T, 2009, VISION RES, V49, P2973, DOI 10.1016/j.visres.2009.09.017
   Steen F. A. M., 1998, THESIS TU DELFT NETH
   Trutoiu LC, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P190
   Trutoiu LC, 2009, COMPUT GRAPH-UK, V33, P47, DOI 10.1016/j.cag.2008.11.008
   Tschermak A., 1931, HDB NORMALEN PATHOLO, P834
   Valjamae A., 2007, PhD Thesis,
   Väljamäe A, 2006, J AUDIO ENG SOC, V54, P954
   Väljamäe A, 2009, BRAIN RES REV, V61, P240, DOI 10.1016/j.brainresrev.2009.07.001
   Väljamäe A, 2009, J AUDIO ENG SOC, V57, P111
   van der Steen FAM, 2000, PERCEPT PSYCHOPHYS, V62, P89, DOI 10.3758/BF03212063
   von der Heyde M., 2002, 5 ANN INT WORKSH PRE, P37
   Wallach H, 1940, J EXP PSYCHOL, V27, P339, DOI 10.1037/h0054629
   Wang Y, 2010, EXP BRAIN RES, V201, P663, DOI 10.1007/s00221-009-2082-0
   WANN J, 1994, BEHAV BRAIN SCI, V17, P338, DOI 10.1017/S0140525X00034932
   Warren H. C., 1895, Psychol. Rev., V2, P273, DOI [10.1037/h0074437, DOI 10.1037/H0074437]
   Warren R., 1990, PERCEPTION CONTROL S
   WERTHEIM AH, 1994, BEHAV BRAIN SCI, V17, P293, DOI 10.1017/S0140525X00034646
   WIST ER, 1975, PERCEPT PSYCHOPHYS, V17, P549, DOI 10.3758/BF03203967
   Wolpert L., 1990, PERCEPTION CONTROL S, P101
   WONG SCP, 1981, PERCEPT PSYCHOPHYS, V30, P228, DOI 10.3758/BF03214278
   Wood R.W., 1895, PSYCHOL REV, V2/3, P277, DOI [DOI 10.1037/H0073333, 10.1037/h0073333]
   Wright WG, 2006, J VESTIBUL RES-EQUIL, V16, P23
   Young L R, 1983, Adv Otorhinolaryngol, V30, P230
   Young L. R., 1990, Perception and Control of Self-Motion: Resources for Ecological Psychology
   YOUNG LR, 1975, AVIAT SPACE ENVIR MD, V46, P264
   ZACHARIAS GL, 1981, EXP BRAIN RES, V41, P159
NR 103
TC 64
Z9 68
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 149
EP 176
D2 10.5772/553
PG 28
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400009
DA 2024-07-18
ER

PT J
AU Hsu, FS
   Wang, TM
   Chen, LH
AF Hsu, Fu-Song
   Wang, Te-Mei
   Chen, Liang-Hsun
TI Robust vision-based glove pose estimation for both hands in virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Glove tracking; Glove dataset; Hand tracking; Vision-based tracking;
   Hand pose estimation; Haptic glove
AB In virtual reality (VR) applications, haptic gloves provide feedback and more direct control than bare hands do. Most VR gloves contain flex and inertial measurement sensors for tracking the finger joints of a single hand; however, they lack a mechanism for tracking two-hand interactions. In this paper, a vision-based method is proposed for improved two-handed glove tracking. The proposed method requires only one camera attached to a VR headset. A photorealistic glove data generation framework was established to synthesize large quantities of training data for identifying the left, right, or both gloves in images with complex backgrounds. We also incorporated the "glove pose hypothesis" in the training stage, in which spatial cues regarding relative joint positions were exploited for accurately predict glove positions under severe self-occlusion or motion blur. In our experiments, a system based on the proposed method achieved an accuracy of 94.06% on a validation set and achieved high-speed tracking at 65 fps on a consumer graphics processing unit.
C1 [Hsu, Fu-Song] Natl Yang Ming Chiao Tung Univ, Inst Commun Studies, Hsinchu, Taiwan.
   [Wang, Te-Mei] Ind Technol Res Inst, Elect & Optoelect Syst Res Labs, Hsinchu, Taiwan.
   [Chen, Liang-Hsun] Natl Yang Ming Chiao Tung Univ, Inst Multimedia Engn, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University; Industrial Technology Research
   Institute - Taiwan; National Yang Ming Chiao Tung University
RP Hsu, FS (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Commun Studies, Hsinchu, Taiwan.
EM fshsu@nycu.edu.tw; TeMeiWang@itri.org.tw; bill5254.cs05@nycu.edu.tw
FU Industrial Technology Research Institute [112-2221-E-A49-129]; National
   Science and Technology Council, Taiwan; NSTC;  [NSTC 111-2222-E-A49-008]
FX This study was supported by the Industrial Technology Research
   Institute, the National Science and Technology Council, Taiwan (Grant
   Numbers: NSTC 111-2222-E-A49-008 and NSTC 112-2221-E-A49-129).
CR Barron C, 2000, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2000.855884
   Buxton W., 1995, Readings in Human-Computer Interaction, P494, DOI [10.1016/B978-0-08-051574-8.50051-0, DOI 10.1016/B978-0-08-051574-8.50051-0]
   Buxton William, 1986, P SIGCHI C HUM FACT, P321, DOI [10.1145/22627.22390, DOI 10.1145/22627.22390, 10.1145/22339.22390]
   Chen WY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041074
   Chen YJ, 2021, PROC CVPR IEEE, P10446, DOI 10.1109/CVPR46437.2021.01031
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Cheng W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11240, DOI 10.1109/ICCV48922.2021.01107
   Doosti B, 2020, PROC CVPR IEEE, P6607, DOI 10.1109/CVPR42600.2020.00664
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fang Linpu, 2020, EUR C COMP VIS
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Hinckley K., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P121, DOI 10.1145/253284.253318
   Hinckley K., 1998, ACM Transactions on Computer-Human Interaction, V5, P260, DOI 10.1145/292834.292849
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Kotranza A, 2006, P ACM S VIRT REAL SO, P31, DOI 10.1145/1180495.1180503
   Lin FQ, 2021, IEEE WINT CONF APPL, P2372, DOI 10.1109/WACV48630.2021.00242
   Liu SW, 2021, PROC CVPR IEEE, P14682, DOI 10.1109/CVPR46437.2021.01445
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Mueller F, 2017, IEEE I CONF COMP VIS, P1163, DOI 10.1109/ICCV.2017.131
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Rad M, 2018, PROC CVPR IEEE, P4663, DOI 10.1109/CVPR.2018.00490
   Ren PF, 2022, PROC CVPR IEEE, P20523, DOI 10.1109/CVPR52688.2022.01990
   Rhodin H, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980235
   Rudnev V, 2021, P IEEE CVF INT C COM, P2385, DOI [10.48550/arXiv.2012.06475, DOI 10.48550/ARXIV.2012.06475]
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Spurr Adrian, 2021, P IEEE CVF INT C COM, P11230
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Vogiatzidakis P, 2022, INT J HUM-COMPUT ST, V159, DOI 10.1016/j.ijhcs.2021.102755
   Voigt-Antons JN, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123085
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiong F, 2019, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2019.00088
   Yang LL, 2019, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2019.00242
   Yang LX, 2022, PROC CVPR IEEE, P2740, DOI 10.1109/CVPR52688.2022.00277
   Zhao ZM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11646, DOI 10.1109/ICCV48922.2021.01146
NR 36
TC 0
Z9 0
U1 14
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3133
EP 3148
DI 10.1007/s10055-023-00860-6
EA SEP 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001065994300001
DA 2024-07-18
ER

PT J
AU Michalski, SC
   Gallomarino, NC
   Szpak, A
   May, KW
   Lee, G
   Ellison, C
   Loetscher, T
AF Michalski, Stefan Carlo
   Gallomarino, Nicholas Charles
   Szpak, Ancret
   May, Kieran William
   Lee, Gun
   Ellison, Caroline
   Loetscher, Tobias
TI Improving real-world skills in people with intellectual disabilities: an
   immersive virtual reality intervention
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Intellectual disability; Training; Learning; Transfer;
   Skill generalisation; Adaptive functioning; Cybersickness
ID ADAPTIVE-BEHAVIOR; SOCIAL-SKILLS; INDIVIDUALS; ADULTS
AB Virtual reality (VR) is a promising tool for training life skills in people with intellectual disabilities. However, there is a lack of evidence surrounding the implementation, suitability, and effectiveness of VR training in this population. The present study investigated the effectiveness of VR training for people with intellectual disabilities by assessing (1) their ability to complete basic tasks in VR, (2) real-world transfer and skill generalisation, and (3) the individual characteristics of participants able to benefit from VR training. Thirty-two participants with an intellectual disability of varying severity completed a waste management training intervention in VR that involved sorting 18 items into three bins. Real-world performance was measured at pre-test, post-test, and delayed time points. The number of VR training sessions varied as training ceased when participants met the learning target (approximate to 90% correct). A survival analysis assessed training success probability as a function of the number of training sessions with participants split by their level of adaptive functioning (as measured on the Adaptive Behaviour Assessment System Third Edition). The learning target was met by 19 participants (59.4%) within ten sessions (Mdn = 8.5, IQR 4-10). Real-world performance significantly improved from pre- to post-test and pre- to delayed test. There was no significant difference from post- to delayed test. Further, there was a significant positive relationship between adaptive functioning and change in the real-world assessment from the pre-test to the post- and delayed tests. VR facilitated the learning of most participants, which led to demonstrations of real-world transfer and skill generalisation. The present study identified a relationship between adaptive functioning and success in VR training. The survival curve may assist in planning future studies and training programs.
C1 [Michalski, Stefan Carlo; Gallomarino, Nicholas Charles; Szpak, Ancret; May, Kieran William; Lee, Gun; Ellison, Caroline; Loetscher, Tobias] Univ South Australia, Adelaide, Australia.
   [Michalski, Stefan Carlo] Univ Sydney, Sydney, Australia.
C3 University of South Australia; University of Sydney
RP Michalski, SC (corresponding author), Univ South Australia, Adelaide, Australia.; Michalski, SC (corresponding author), Univ Sydney, Sydney, Australia.
EM Stefan.Michalski@mymail.unisa.edu.au
RI Loetscher, Tobias/I-1865-2019; Lee, Gun/AAS-9903-2021
OI Loetscher, Tobias/0000-0003-1967-2926; Lee, Gun/0000-0002-1644-6934;
   Ellison, Caroline/0000-0003-2359-414X; Michalski, Stefan
   Carlo/0000-0002-8542-8246
CR Abernethy B, 2001, J SPORT SCI, V19, P203, DOI 10.1080/026404101750095376
   Alford BL, 2016, EARLY CHILD EDUC J, V44, P623, DOI 10.1007/s10643-015-0748-8
   Balboni G, 2020, RES DEV DISABIL, V104, DOI 10.1016/j.ridd.2020.103718
   Barker RM, 2013, AJIDD-AM J INTELLECT, V118, P365, DOI 10.1352/1944-7558-118.5.365
   Buckingham G, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.728461
   Cherix Robin, 2020, HCI in Mobility, Transport, and Automotive Systems. Driving Behavior, Urban and Smart Mobility. Second International Conference, MobiTAS 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12213), P161, DOI 10.1007/978-3-030-50537-0_13
   Choi KS, 2012, DISABIL REHABIL-ASSI, V7, P507, DOI 10.3109/17483107.2011.652998
   de OliveiraMalaquias., 2017, Technology and Disability, V28, P133
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fransson G, 2020, EDUC INF TECHNOL, V25, P3383, DOI 10.1007/s10639-020-10119-1
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Harrison P.L., 2015, ADAPTIVE BEHAV ASSES, V3rd
   Jeffs T.L., 2010, Themes in science and technology education, V2, P253
   Kellems R O., 2022, Research Anthology on Inclusive Practices for Educators and Administrators in Special Education, P737, DOI [10.4018/978-1-6684-3670-7.ch041, DOI 10.4018/978-1-6684-3670-7.CH041]
   Klang N, 2020, INT J DISABIL DEV ED, V67, P151, DOI 10.1080/1034912X.2019.1679724
   Krinsky-McHale SJ, 2014, J APPL RES INTELLECT, V27, P247, DOI 10.1111/jar.12062
   Lee CRK, 2020, J RES TECHNOL EDUC, V52, P163, DOI 10.1080/15391523.2020.1726234
   Lee LN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173556
   Lindsay S, 2019, DISABIL REHABIL, V41, P2607, DOI 10.1080/09638288.2018.1471165
   Michalski SC, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.627301
   Michalski SC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02159
   Michalski SC, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/34373
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Nabors L, 2020, ADV NEURODEV DISORD, V4, P344, DOI 10.1007/s41252-020-00177-4
   Panerai S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01730
   Parsons S, 2002, J INTELL DISABIL RES, V46, P430, DOI 10.1046/j.1365-2788.2002.00425.x
   Patel DR, 2020, TRANSL PEDIATR, V9, P23, DOI 10.21037/tp.2020.02.02
   Raty L.M., 2016, J ED LEARNING, V5, P318, DOI DOI 10.5539/JEL.V5N2P318
   Rodrigues A.R., 2019, Physiotherapy Research and Reports, V2, P1, DOI DOI 10.15761/PRR.1000122
   Standen PJ, 2020, BRIT J EDUC TECHNOL, V51, P1748, DOI 10.1111/bjet.13010
   Standen PJ, 2005, CYBERPSYCHOL BEHAV, V8, P272, DOI 10.1089/cpb.2005.8.272
   Szpak A, 2020, J MED INTERNET RES, V22, DOI 10.2196/19840
   Tamm L, 2022, J AUTISM DEV DISORD, V52, P1247, DOI 10.1007/s10803-021-05013-9
   Tassé MJ, 2016, INTELLECT DEV DISAB, V54, P381, DOI 10.1352/1934-9556-54.6.381
   Tichon J, 2007, CYBERPSYCHOL BEHAV, V10, P286, DOI 10.1089/cpb.2006.9957
   Tsikinas S, 2018, IEEE GLOB ENG EDUC C, P1896, DOI 10.1109/EDUCON.2018.8363467
   Vahia VN, 2013, INDIAN J PSYCHIAT, V55, P220, DOI 10.4103/0019-5545.117131
   van Vonderen A, 2004, J INTELL DISABIL RES, V48, P245, DOI 10.1111/j.1365-2788.2003.00555.x
   Walker Z, 2016, EDUC TECHNOL SOC, V19, P76
   Wang X, 2023, INT J DEV DISABIL, V69, P524, DOI 10.1080/20473869.2021.1970938
   Woolf S, 2010, INTELLECT DEV DISAB, V48, P209, DOI 10.1352/1944-7558-48.3.209
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 46
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3521
EP 3532
DI 10.1007/s10055-023-00759-2
EA APR 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000962048700001
PM 37360807
OA Green Accepted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Karaoglan-Yilmaz, FG
   Yilmaz, R
   Zhang, K
   Ustun, AB
AF Karaoglan-Yilmaz, Fatma Gizem
   Yilmaz, Ramazan
   Zhang, Ke
   Ustun, Ahmet Berk
TI Development of educational virtual reality attitude scale: A validity
   and reliability study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Attitude; Virtual reality attitude instrument; Attitude
   towards virtual reality
ID HEAD-MOUNTED DISPLAYS; TECHNOLOGY; TEACHERS; DESIGN; MODEL
AB The aim of the study is to address a gap in the literature by developing an educational virtual reality (edVR) attitude measurement instrument, which determines college students' attitudes towards using VR technology for educational purposes. A sequential exploratory mixed method was employed to develop the measurement instrument. Initially, a qualitative approach was used to establish the face and content validity of the instrument and subsequently a quantitative approach was used to test the construct validity and reliability of attitude statement items. Critical reviews and constructive feedback were gathered from a range of parties, including target users (i.e., college students), learning technology experts, assessment and evaluation authority, and linguists of English and Turkish. The psychometric properties of edVR attitude measurement instrument were tested with a total sample of 305 sophomore, junior and senior students studying at different faculties. The exploratory factor analysis (EFA) results confirmed the single-factor structure with nine items, explaining 63.46% of the total variance and the confirmatory factor analysis (CFA) results indicated a sufficient fit of this single-factor model. The Cronbach's alpha coefficient for the edVR attitude measurement instrument was 0.92 and the test-retest reliability of the instrument was 0.94. The t-values were significant for all items for 27% of the participants to compare the top and bottom. As a result, the edVR attitude measurement instrument was valid and reliable in measuring students' attitudes towards educational VR.
C1 [Karaoglan-Yilmaz, Fatma Gizem; Yilmaz, Ramazan; Ustun, Ahmet Berk] Bartin Univ, Fac Sci, Dept Comp Technol & Informat Syst, Bartin, Turkiye.
   [Zhang, Ke] Wayne State Univ, Collece Educ Learning Design & Technol, Detroit, MI USA.
C3 Bartin University; Wayne State University
RP Ustun, AB (corresponding author), Bartin Univ, Fac Sci, Dept Comp Technol & Informat Syst, Bartin, Turkiye.
EM gkaraoglanyilmaz@gmail.com; ramazanyilmaz067@gmail.com;
   ke.zhang@wayne.edu; ustun.ab@gmail.com
RI Karaoglan Yilmaz, Fatma Gizem/W-2168-2017; Ustun, Ahmet
   Berk/AAQ-1271-2021; Yilmaz, Ramazan/F-9517-2019
OI Karaoglan Yilmaz, Fatma Gizem/0000-0003-4963-8083; Ustun, Ahmet
   Berk/0000-0002-1640-4291; Yilmaz, Ramazan/0000-0002-2041-1750; Zhang,
   Ke/0000-0002-4690-7586
CR Aïm F, 2016, ARTHROSCOPY, V32, P224, DOI 10.1016/j.arthro.2015.07.023
   Akbulut Y., 2010, Sosyal bilimlerde SPSS uygulamalari: Sik kullanilan istatistiksel analizler ve aciklamali SPSS cozumleri
   Alasmari T, 2019, EDUC INF TECHNOL, V24, P2127, DOI 10.1007/s10639-019-09865-8
   Alfadil M, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103893
   Alfalah SFM, 2018, EDUC INF TECHNOL, V23, P2633, DOI 10.1007/s10639-018-9734-2
   [Anonymous], 2019, HUAWEIS GLOBAL IND V
   Bower M, 2020, BRIT J EDUC TECHNOL, V51, P2214, DOI 10.1111/bjet.13009
   Buyukozturk, 2010, S OSYAL BILIMLER ICI
   Byrne B, 2010, INTERNATIONAL HANDBOOK OF PSYCHOLOGY IN EDUCATION, P3
   Çakiroglu Ü, 2019, COMPUT EDUC, V133, P56, DOI 10.1016/j.compedu.2019.01.014
   Cattell R. B., 1978, The scientific use of factor analysis in behavioral life sciences
   Chavez Bayron, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 746), P1345, DOI 10.1007/978-3-319-77712-2_129
   Cokluk O., 2012, Sosyal Bilimler Icin Cok Degiskenli Istatistik: SPSS ve Lisrel Uygulamalari
   Comrey A. L., 1992, A first course in factor analysis, DOI DOI 10.4324/9781315827506-16
   Edwards, 1957, TECHNIQUES ATTITUDE, DOI [10.1037/14423-000, DOI 10.1037/14423-000]
   El Beheiry M, 2019, J MOL BIOL, V431, P1315, DOI 10.1016/j.jmb.2019.01.033
   Erkus A., 2012, Psikolojide Olcme Ve Olcek Gelistirme
   Fetscherin M, 2008, J ELECTRON COMMER RE, V9, P231
   Fraenkel J.R., 2012, How to design and evaluate research in education, V8th
   Fransson G, 2020, EDUC INF TECHNOL, V25, P3383, DOI 10.1007/s10639-020-10119-1
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gadelha R., 2018, CHILDHOOD EDUC, V94, P40, DOI [DOI 10.1080/00094056.2018.1420362, 10.1080/00094056.2018.1420362, 10.1080/00094056.2018, DOI 10.1080/00094056.2018]
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Hair JF., 1979, Multivariate data analysis: With readings
   Hanson K, 2008, EDUC TECHNOL SOC, V11, P118
   Hooper D, 2007, Electronic Journal of Business Research Methods, V6, P53, DOI [DOI 10.21427/D7CF7R, 10.21427/D7CF7R]
   Horzum MB, 2012, TURK ONLINE J DISTAN, V13, P50
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Huang HM, 2018, INT REV RES OPEN DIS, V19, P91
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Ilhan M, 2014, EGIT BILIM, V39, P31
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   King D, 2018, NURS EDUC TODAY, V71, P7, DOI 10.1016/j.nedt.2018.08.002
   Kline R.B., 2016, Principles and Practice of Structural Equation Modeling, VFourth
   Kline R.B., 1994, EASY GUIDE FACTOR AN
   Kline T.J., 2005, Psychological testing: A practical approach to design and evaluation, P167, DOI [DOI 10.4135/9781483385693, 10.4135/9781483385693]
   Korkmaz Ö, 2012, COMPUT EDUC, V59, P1162, DOI 10.1016/j.compedu.2012.05.021
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Küçük S, 2014, EGIT BILIM, V39, P383
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Makransky G, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0620-6
   Markowitz D., 2019, Human Communication Research, V34, P287
   Norris MW., 2019, Professional Safety, V64, P36
   Hernández-Ramos JP, 2014, COMPUT HUM BEHAV, V31, P509, DOI 10.1016/j.chb.2013.04.039
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Sezer B, 2019, AUSTRALAS J EDUC TEC, V35, P15, DOI 10.14742/ajet.3959
   Shim KC, 2003, J BIOL EDUC, V37, P71, DOI 10.1080/00219266.2003.9655854
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Stevens JP., 2002, APPL MULTIVARIATE ST
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Taherdoost H, 2019, Int J Acad Res Mgmt, V8, P2296
   Tezbasaran A.A., 1997, Likert type scale preparation guide
   Uppot RN, 2019, RADIOLOGY, V291, P570, DOI 10.1148/radiol.2019182210
   Ustun AB, 2020, Mobile devices and smart gadgets in medical sciences, P56
   Ustun AB, 2023, VIRTUAL REAL-LONDON, V27, P1063, DOI 10.1007/s10055-022-00717-4
   Ustun AB, 2020, EDUC INF TECHNOL, V25, P1529, DOI 10.1007/s10639-019-09999-9
   Verhagen T, 2012, COMPUT HUM BEHAV, V28, P484, DOI 10.1016/j.chb.2011.10.020
   Yavuz S., 2005, The Turkish Online Journal of Educational Technology (TOJET), P17, DOI DOI 10.1111/J.1467-8535.2008.00879.X
   Yilmaz A., 2021, INT J ACTIVE LEARNIN, V6, P98
   Zhang K., 2020, INT J SMART TECHNOL, V2, P136, DOI [10.1504/IJSMARTTL.2020.112130, DOI 10.1504/IJSMARTTL.2020.112130]
   Zhang MS, 2018, INT J EMERG TECHNOL, V13, P138, DOI 10.3991/ijet.v13i01.7773
NR 65
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1875
EP 1885
DI 10.1007/s10055-023-00778-z
EA MAR 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000945793400001
DA 2024-07-18
ER

PT J
AU Rothbaum, AO
   Tannenbaum, LR
   Zimand, E
   Rothbaum, BO
AF Rothbaum, Alex O.
   Tannenbaum, Libby R.
   Zimand, Elana
   Rothbaum, Barbara Olasov
TI A pilot randomized controlled trial of virtual reality delivered
   relaxation for chronic low back pain
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Chronic pain; Back pain; Progressive muscle relaxation;
   Cognitive behavior therapy; Relaxation
ID LUMBAR INSTRUMENTED FUSION; QUALITY-OF-LIFE; COGNITIVE INTERVENTION;
   ANXIETY DISORDERS; UNITED-STATES; DISTRACTION; THERAPY; EPIDEMIOLOGY;
   DEPRESSION; INDIVIDUALS
AB Chronic lower back pain (CLBP) is a widespread health problem with lifetime incidence up to 80% in the U.S. Conventional treatments, such as surgery and pharmacotherapy have limitations in that they primarily target physical aspects of pain, and certain medications run the risk of abuse, tolerance, sedation, and possible overdose. Progressive muscle relaxation (PMR) is a validated technique that is neither invasive nor with impairing side effects. The effects and reach of PMR may be enhanced using technological advances, such as virtual reality (VR), which is piloted for feasibility in the current project. This study presents a randomized controlled trial investigating the usability and efficacy of a VR-based PMR program. Participants (n = 18) were randomly assigned to the VR treatment or waitlist control group. Treatment participants completed five VR-PMR sessions. Results indicated the novel VR program was highly usable and immersive. Comparison of pre- and post-treatment measures indicated that VR participants reported significantly lower pain levels and improvements in pain-related beliefs compared to controls. Additionally, those who received VR-PMR reported significantly lower state anxiety at the conclusion of the study. Improvements in medication-related beliefs were also found post-treatment. This controlled trial provides preliminary support for a novel, immersive VR relaxation modality as a promising new adjunctive or alternative approach for CLBP management. Future studies can further validate the use of VR, specifically VR-based PMR, for management and treatment of chronic pain. With increased accessibility of consumer VR headsets, a program such as this may improve pain management outside of the medical setting.
C1 [Rothbaum, Alex O.] Skyland Trail, Dept Res & Outcomes, Atlanta, GA 30329 USA.
   [Rothbaum, Alex O.; Rothbaum, Barbara Olasov] Emory Univ, Dept Psychiat & Behav Sci, Sch Med, Atlanta, GA 30322 USA.
   [Tannenbaum, Libby R.] Virtually Better Inc, Decatur, GA USA.
   [Zimand, Elana] Path Grp Atlanta, Atlanta, GA USA.
C3 Emory University
RP Rothbaum, AO (corresponding author), Skyland Trail, Dept Res & Outcomes, Atlanta, GA 30329 USA.; Rothbaum, AO (corresponding author), Emory Univ, Dept Psychiat & Behav Sci, Sch Med, Atlanta, GA 30322 USA.
EM arothbaum@skylandtrail.org
OI Rothbaum, Barbara/0000-0002-8793-7124
FU National Institutes of Health [1R43AR050863-01]
FX AcknowledgementsWe would like to acknowledge the contributions of Peter
   Campos, Astha Vijayananda, and Mirtha Ferrer to the success of this
   project. This project was funded by National Institutes of Health
   1R43AR050863-01.
CR Alemanno F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216858
   Asmundson GJG, 2009, DEPRESS ANXIETY, V26, P888, DOI 10.1002/da.20600
   Bantick SJ, 2002, BRAIN, V125, P310, DOI 10.1093/brain/awf022
   Beck A.T., 1996, Psychological assessment, V2nd ed.
   Bertisch SM, 2009, J PSYCHOSOM RES, V66, P511, DOI 10.1016/j.jpsychores.2008.12.003
   Booth J, 2017, MUSCULOSKELET CARE, V15, P413, DOI 10.1002/msc.1191
   Bordnick PS, 2004, ADDICT BEHAV, V29, P1889, DOI 10.1016/j.addbeh.2004.06.008
   Brox JI, 2006, PAIN, V122, P145, DOI 10.1016/j.pain.2006.01.027
   Brox JI, 2003, SPINE, V28, P1913
   Bushnell MC, 1999, P NATL ACAD SCI USA, V96, P7705, DOI 10.1073/pnas.96.14.7705
   cdc, Understanding the epidemic-Centers for Disease Control and Prevention
   Claiborne N, 2002, EVAL PROGRAM PLANN, V25, P61, DOI 10.1016/S0149-7189(01)00049-0
   Conrad A, 2007, J ANXIETY DISORD, V21, P243, DOI 10.1016/j.janxdis.2006.08.001
   Dagenais S, 2008, SPINE J, V8, P8, DOI 10.1016/j.spinee.2007.10.005
   Dart RC, 2015, NEW ENGL J MED, V372, P241, DOI [10.1056/NEJMsa1406143, 10.1056/NEJMc1501822]
   Fairbank J, 2005, BMJ-BRIT MED J, V330, P1233, DOI 10.1136/bmj.38441.620417.8F
   Fillingim RB, 2003, SPINE, V28, P143, DOI 10.1097/00007632-200301150-00010
   First M, 2022, Structured clinical interview for DSM-IV-TR axis I disorders
   Freburger JK, 2009, ARCH INTERN MED, V169, P251, DOI 10.1001/archinternmed.2008.543
   Garcia L, 2021, J MED INTERNET RES
   Garrett B, 2014, CLIN J PAIN, V30, P1089, DOI 10.1097/AJP.0000000000000064
   Gatchel RJ, 2007, PSYCHOL BULL, V133, P581, DOI 10.1037/0033-2909.133.4.581
   Gay MC, 2002, EUR J PAIN-LONDON, V6, P1, DOI 10.1053/eujp.2001.0263
   Gerrits MMJG, 2012, PAIN, V153, P429, DOI 10.1016/j.pain.2011.11.001
   Gershon J, 2004, J AM ACAD CHILD PSY, V43, P1243, DOI 10.1097/01.chi.0000135621.23145.05
   Harvie DS, 2020, CLIN J PAIN, V36, P101, DOI 10.1097/AJP.0000000000000780
   Harvie DS, 2017, PEERJ, V5, DOI 10.7717/peerj.3023
   Hennessy RW, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/17799
   Hofbauer RK, 2001, J NEUROPHYSIOL, V86, P402, DOI 10.1152/jn.2001.86.1.402
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2008, CLIN J PAIN, V24, P299, DOI 10.1097/AJP.0b013e318164d2cc
   Horng YS, 2005, SPINE, V30, P551, DOI 10.1097/01.brs.0000154623.20778.f0
   HUSKISSON EC, 1974, LANCET, V2, P1127, DOI 10.1016/S0140-6736(74)90884-8
   JENSEN MP, 1994, PAIN, V57, P301, DOI 10.1016/0304-3959(94)90005-1
   Kamper SJ, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD000963.pub3
   Karjalainen K, 2003, SPINE, V28, P2634, DOI 10.1097/01.BRS.0000099097.61495.2E
   Knaster P, 2012, GEN HOSP PSYCHIAT, V34, P46, DOI 10.1016/j.genhosppsych.2011.09.004
   Kroenke K, 2003, INT J METH PSYCH RES, V12, P34, DOI 10.1002/mpr.140
   Last AR, 2009, AM FAM PHYSICIAN, V79, P1067
   Lerman SF, 2015, PSYCHOSOM MED, V77, P333, DOI 10.1097/PSY.0000000000000158
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Linton SJ, 2001, PAIN, V90, P83, DOI 10.1016/S0304-3959(00)00390-0
   Longe SE, 2001, NEUROREPORT, V12, P2021, DOI 10.1097/00001756-200107030-00047
   Magora F, 2006, ISR MED ASSOC J, V8, P261
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Markus LA, 2009, BURNS, V35, P967, DOI 10.1016/j.burns.2009.01.013
   McCracken LM, 2002, SPINE, V27, P2564, DOI 10.1097/00007632-200211150-00033
   Means-Christensen AJ, 2008, DEPRESS ANXIETY, V25, P593, DOI 10.1002/da.20342
   Meeus Mira., 2016, Pain, V1, P23
   Mistry D, 2020, PSYCHOL TRAUMA-US
   NORTH RB, 1991, NEUROSURGERY, V28, P692, DOI 10.1227/00006123-199105000-00009
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pincus Tamar, 2002, Spine (Phila Pa 1976), V27, pE133, DOI 10.1097/00007632-200203010-00020
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Ressler KJ, 2004, ARCH GEN PSYCHIAT, V61, P1136, DOI 10.1001/archpsyc.61.11.1136
   Ricci JA, 2006, SPINE, V31, P3052, DOI 10.1097/01.brs.0000249521.61813.aa
   Rosner B., 2010, FUNDAMENTALS BIOSTAT
   Rothbaum BO, 2001, J CLIN PSYCH
   Rubin DI, 2007, NEUROL CLIN, V25, P353, DOI 10.1016/j.ncl.2007.01.004
   Shahrbanian S, 2009, STUD HEALTH TECHNOL, V144, P40, DOI 10.3233/978-1-60750-017-9-40
   Spielberger CD, 1983, State-trait anxiety inventory for adults, DOI DOI 10.1037/T06496-000
   Stamm O, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00753-8
   Tack C, 2021, DISABIL REHABIL-ASSI, V16, P637, DOI 10.1080/17483107.2019.1688399
   Tashjian VC, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7387
   Thomas JS, 2016, J PAIN, V17, P1302, DOI 10.1016/j.jpain.2016.08.011
   Torrance N, 2006, J PAIN, V7, P281, DOI 10.1016/j.jpain.2005.11.008
   Turk, 1998, PHYS REHABIL MED, V10
   Turk DC, 2002, CLIN J PAIN, V18, P355, DOI 10.1097/00002508-200211000-00003
   TURNER JA, 1995, NEUROSURGERY, V37, P1088, DOI 10.1227/00006123-199512000-00008
   TURNER JA, 1984, J CLIN PSYCHOL, V40, P909, DOI 10.1002/1097-4679(198407)40:4<909::AID-JCLP2270400407>3.0.CO;2-J
   van Tulder M, 2002, BEST PRACT RES CL RH, V16, P761, DOI 10.1053/berh.2002.0267
   Vollenbroek-Hutten MMR, 2004, CLIN REHABIL, V18, P566, DOI 10.1191/0269215504cr772oa
   Wiederhold BK, 2014, CYBERPSYCH BEH SOC N, V17, P346, DOI 10.1089/cyber.2014.0207
   Wolitzky K, 2005, PSYCHOL HEALTH, V20, P817, DOI 10.1080/14768320500143339
   Wright JL, 2005, UROLOGY, V66, P13201, DOI 10.1016/j.urolog.2005.06.123
   Yeh SC, 2014, COMPUT METH PROG BIO, V116, P311, DOI 10.1016/j.cmpb.2014.04.014
   Zimand E., 2001, IMMERSION QUESTIONNA
NR 78
TC 2
Z9 2
U1 5
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3533
EP 3543
DI 10.1007/s10055-023-00760-9
EA FEB 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000924074100001
DA 2024-07-18
ER

PT J
AU Brepohl, PCA
   Leite, H
AF Brepohl, Polyana Cristina Alves
   Leite, Higor
TI Virtual reality applied to physiotherapy: a review of current knowledge
SO VIRTUAL REALITY
LA English
DT Review
DE Physiotherapy; Virtual reality; Rehabilitation; Technology; Exergaming
ID CONVENTIONAL PHYSICAL-THERAPY; QUALITY-OF-LIFE; PARKINSONS-DISEASE
   PATIENTS; KINECT-BASED SYSTEM; VIDEO GAMES; MULTIPLE-SCLEROSIS; EXERCISE
   THERAPY; CEREBRAL-PALSY; XBOX KINECT; WII FIT
AB Technological innovations have enabled physiotherapy to apply new possibilities in the rehabilitation of patients, especially in the use of virtual reality (VR). Although the literature provides several examples of VR applications, benefits, and barriers in physiotherapy, scholars obverse that there is still a dearth of studies that discuss and unify the results and impacts of this emerging technology on patients and physiotherapists. Thus, the aim of this study is to analyze the use of VR within physiotherapy and its impact on rehabilitation outcomes. A systematic literature review based on the PRISMA protocol was applied in this study. After searching on databases, such as Bireme, Cochrane, Emerald, Google Scholar, Lilacs, Medline, PEDro, PubMed, and Science Direct, we found 152 articles that complied with our protocol. The initial period of the search was open up to June 2020. Our results show an increased use of VR in neurology with elderly patients. We have identified underlying barriers (issues implementing VR, lack of protocols, and influence of patients) and benefits (effectiveness of treatment, motor development, and patient independence) of VR implementation. Finally, our study provides implications for VR in physiotherapy: a prominent increase in the use of VR in rehabilitation; value co-creation: interactions between patients and physiotherapists are crucial in the use of VR in physiotherapy; barriers related to technology, applicability, and the patient's influence need to be overcome for VR practice to be used as a 'business as usual' modality in physiotherapy; the benefits of VR treatment can overcome the barriers faced by its use in rehabilitation.
C1 [Brepohl, Polyana Cristina Alves] Univ Tecnol Fed Parana, Biomed Engn Postgrad Res Programme, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.
   [Leite, Higor] Univ Tecnol Fed Parana, Biomed Engn Postgrad Res Programme, Sch Management & Econ, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.
C3 Universidade Tecnologica Federal do Parana; Universidade Tecnologica
   Federal do Parana
RP Brepohl, PCA (corresponding author), Univ Tecnol Fed Parana, Biomed Engn Postgrad Res Programme, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.
EM brepohly@gmail.com; higor@utfpr.edu.br
OI Leite, Higor/0000-0002-2451-4124; Brepohl, Polyana/0000-0003-1401-9776
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brasil
   (CAPES (Coordination for the Improvement of Higher Education Personnel))
   [001]
FX We would like to acknowledge the generosity of the Biomedical
   Engineering Postgraduate Research Programme of the Federal University of
   Technology of Parana-their support has been invaluable in putting this
   theme together. Furthermore, this study was financed in part by the
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brasil
   (CAPES (Coordination for the Improvement of Higher Education
   Personnel))-Finance Code 001.
CR Abbott JH, 2014, J ORTHOP SPORT PHYS, V44, P555, DOI 10.2519/jospt.2014.0110
   Adams J, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0337-y
   Adie K, 2017, CLIN REHABIL, V31, P173, DOI 10.1177/0269215516637893
   Afsar SI, 2018, J STROKE CEREBROVASC, V27, P3473, DOI 10.1016/j.jstrokecerebrovasdis.2018.08.007
   Ahn S, 2019, J EXERC REHABIL, V15, P358, DOI 10.12965/jer.1938174.087
   Alahmari KA, 2014, IEEE T NEUR SYS REH, V22, P389, DOI 10.1109/TNSRE.2013.2294904
   Andrysek J, 2012, ARCH PHYS MED REHAB, V93, P358, DOI 10.1016/j.apmr.2011.08.031
   Appel L, 2020, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00329
   Arman N, 2019, AM J PHYS MED REHAB, V98, P174, DOI 10.1097/PHM.0000000000001001
   Arrebola LS, 2019, J PEDIATR REHAB MED, V12, P65, DOI 10.3233/PRM-170529
   Askin A, 2018, SOMATOSENS MOT RES, V35, P25, DOI 10.1080/08990220.2018.1444599
   Banerjee-Guenette P, 2020, PHYS OCCUP THER PEDI, V40, P201, DOI 10.1080/01942638.2019.1650867
   Bateni H, 2012, PHYSIOTHERAPY, V98, P211, DOI 10.1016/j.physio.2011.02.004
   Bevilacqua R, 2019, J CLIN MED, V8, DOI 10.3390/jcm8111882
   Blasco JM, 2021, PHYSIOTHER THEOR PR, V37, P682, DOI 10.1080/09593985.2019.1641865
   Bonnechère B, 2014, RES DEV DISABIL, V35, P1899, DOI 10.1016/j.ridd.2014.04.016
   Bonnechère B, 2018, PHYSIOTHER RES INT, V23, DOI 10.1002/pri.1752
   Bonnechère B, 2016, INT J REHABIL RES, V39, P277, DOI 10.1097/MRR.0000000000000190
   Bower KJ, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0057-x
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Chan TC, 2012, GERIATR GERONTOL INT, V12, P714, DOI 10.1111/j.1447-0594.2012.00848.x
   Chang CM, 2012, PATIENT PREFER ADHER, V6, P821, DOI 10.2147/PPA.S37190
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Clark WE, 2019, J REHABIL ASSIST TER, V6, DOI 10.1177/2055668319863557
   Collado-Mateo D, 2017, ARCH PHYS MED REHAB, V98, P1725, DOI 10.1016/j.apmr.2017.02.011
   Cook DJ, 1997, ANN INTERN MED, V127, P210, DOI 10.7326/0003-4819-127-3-199708010-00006
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   Cuthbert JP, 2014, BRAIN INJURY, V28, P181, DOI 10.3109/02699052.2013.860475
   da Fonseca EP, 2017, J STROKE CEREBROVASC, V26, P94, DOI 10.1016/j.jstrokecerebrovasdis.2016.08.035
   Ribeiro NMD, 2015, TOP STROKE REHABIL, V22, P299, DOI 10.1179/1074935714Z.0000000017
   Dahl-Popolizio S, 2014, GAMES HEALTH J, V3, P157, DOI 10.1089/g4h.2014.0002
   Das Debashish A, 2005, BMC Pediatr, V5, P1, DOI 10.1186/1471-2431-5-1
   de Assis GA, 2016, DISABIL REHABIL-ASSI, V11, P521, DOI 10.3109/17483107.2014.979330
   Cerqueira TMD, 2020, PHYSIOTHER RES INT, V25, DOI 10.1002/pri.1807
   Farr WJ, 2021, DISABIL REHABIL, V43, P85, DOI 10.1080/09638288.2019.1618400
   Feng H, 2019, MED SCI MONITOR, V25, P4186, DOI 10.12659/MSM.916455
   Fernández-González P, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0593-x
   Feyzioglu O, 2020, SUPPORT CARE CANCER, V28, P4295, DOI 10.1007/s00520-019-05287-x
   Ficklscherer A, 2016, ARCH MED SCI, V12, P1273, DOI 10.5114/aoms.2016.59722
   Ford CG, 2018, BURNS, V44, P886, DOI 10.1016/j.burns.2017.11.020
   Forsberg A, 2015, DISABIL REHABIL, V37, P338, DOI 10.3109/09638288.2014.918196
   Franciulli PM., 2016, ACTA FISI T, V23, P191, DOI [10.5935/0104-7795.20160036, DOI 10.5935/0104-7795.20160036]
   Freke M, 2018, J ORTHOP SPORT PHYS, V48, P280, DOI 10.2519/jospt.2018.7946
   Fung J, 2017, J PHYSIOTHER, V63, P114, DOI [10.1016/j.jphys.2017.02.009, 10.1016/j.jphys.2017.02.010]
   Fung V, 2012, PHYSIOTHERAPY, V98, P183, DOI 10.1016/j.physio.2012.04.001
   Garcia-Agundez A, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0492-1
   García-Bravo S, 2021, DISABIL REHABIL, V43, P448, DOI 10.1080/09638288.2019.1631892
   Gianola S, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000019136
   Giemza C, 2007, AGING MALE, V10, P67, DOI 10.1080/13685530701390859
   Glegg SMN, 2018, PM&R, V10, P1237, DOI 10.1016/j.pmrj.2018.07.004
   Grant MJ, 2009, HEALTH INFO LIBR J, V26, P91, DOI 10.1111/j.1471-1842.2009.00848.x
   Gregg L, 2007, SOC PSYCH PSYCH EPID, V42, P343, DOI 10.1007/s00127-007-0173-4
   Grunert R, 2019, INT J NEUROSCI, V129, P770, DOI 10.1080/00207454.2019.1567510
   Gumaa M, 2019, PHYS THER, V99, P1304, DOI 10.1093/ptj/pzz093
   Hills Rosemary, 2007, Physiotherapy Theory and Practice, V23, P255, DOI 10.1080/09593980701249929
   Hoda M, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/590584
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   House G, 2016, BRIT J PAIN, V10, P186, DOI 10.1177/2049463716664370
   Howcroft J, 2012, ARCH PHYS MED REHAB, V93, P1448, DOI 10.1016/j.apmr.2012.02.033
   Howie EK, 2017, RES DEV DISABIL, V60, P1, DOI 10.1016/j.ridd.2016.10.013
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Hu Q, 2015, J MANUF TECHNOL MANA, V26, P980, DOI 10.1108/JMTM-02-2014-0013
   Casuso-Holgado MJ, 2018, CLIN REHABIL, V32, P1220, DOI 10.1177/0269215518768084
   Jonsdottir J, 2019, MULT SCLER RELAT DIS, V35, P76, DOI 10.1016/j.msard.2019.07.010
   Joo S, 2015, MED SCI MONITOR, V21, P1806, DOI 10.12659/MSM.893420
   Jorgensen Pia, 2000, Physiotherapy Theory and Practice, V16, P105, DOI 10.1080/095939800407295
   Jung HT, 2017, IEEE ENG MED BIO, P3856, DOI 10.1109/EMBC.2017.8037698
   Karahan AY, 2016, ADV CLIN EXP MED, V25, P931, DOI 10.17219/acem/32590
   Karahan AY, 2015, CENT EUR J PUBL HEAL, V23, pS14
   Katajapuu N, 2017, INT CONF COGN INFO, P85, DOI 10.1109/CogInfoCom.2017.8268221
   Kho ME, 2012, J CRIT CARE, V27, DOI 10.1016/j.jcrc.2011.08.017
   Kim EK, 2012, J PHYS THER SCI, V24, P901, DOI 10.1589/jpts.24.901
   Ku J, 2019, CYBERPSYCH BEH SOC N, V22, P132, DOI 10.1089/cyber.2018.0261
   Laut Jeffrey, 2016, Curr Phys Med Rehabil Rep, V4, P312, DOI 10.1007/s40141-016-0139-0
   Lee G, 2013, J PHYS THER SCI, V25, P595, DOI 10.1589/jpts.25.595
   Lee SH, 2020, PM&R, V12, P257, DOI 10.1002/pmrj.12206
   LeGear T, 2016, CLIN RESPIR J, V10, P303, DOI 10.1111/crj.12216
   Leite H, 2021, AUST J PUBL ADMIN, V80, P300, DOI 10.1111/1467-8500.12473
   Leite H, 2022, PROD PLAN CONTROL, V33, P403, DOI 10.1080/09537287.2020.1823511
   Leite H, 2020, PUBLIC MONEY MANAGE, V40, P483, DOI 10.1080/09540962.2020.1748855
   Lewis GN, 2012, DISABIL REHABIL, V34, P1880, DOI 10.3109/09638288.2012.670036
   Lin YT, 2020, ANN PHYS REHABIL MED, V63, P458, DOI 10.1016/j.rehab.2019.11.008
   Logeswaran Abison, 2021, Future Healthc J, V8, pe79, DOI 10.7861/fhj.2020-0112
   Loureiro Ana Paula Cunha, 2012, Fisioter. mov., V25, P659
   Lozano-Quilis JA, 2014, JMIR SERIOUS GAMES, V2, P43, DOI 10.2196/games.2933
   Luque-Moreno C, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/342529
   Matheve T, 2018, GAMES HEALTH J, V7, P262, DOI 10.1089/g4h.2017.0173
   Mazzoleni S, 2014, RESP MED, V108, P1516, DOI 10.1016/j.rmed.2014.07.004
   McClanachan NJ, 2013, BRAIN INJURY, V27, P1402, DOI 10.3109/02699052.2013.823654
   Meijer HA, 2018, ARCH PHYS MED REHAB, V99, P1890, DOI 10.1016/j.apmr.2017.10.018
   Meldrum D, 2015, ARCH PHYS MED REHAB, V96, P1319, DOI 10.1016/j.apmr.2015.02.032
   Mohammadi R, 2019, J STROKE CEREBROVASC, V28, P1787, DOI 10.1016/j.jstrokecerebrovasdis.2019.03.054
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Morri M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1271-z
   Morris LD, 2010, BURNS, V36, P659, DOI 10.1016/j.burns.2009.09.005
   Münter KH, 2018, DISABIL REHABIL, V40, P1808, DOI 10.1080/09638288.2017.1314556
   Negrini S, 2017, J BODYW MOV THER, V21, P117, DOI 10.1016/j.jbmt.2016.06.001
   Neira-Tovar L, 2018, LECT NOTES COMPUT SC, V10910, P126, DOI 10.1007/978-3-319-91584-5_11
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Norouzi-Gheidari N, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010113
   Nuic D, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0375-x
   Ogawa EF, 2016, J AGING PHYS ACTIV, V24, P332, DOI 10.1123/japa.2014-0267
   Oh YB, 2019, ARCH PHYS MED REHAB, V100, P1400, DOI 10.1016/j.apmr.2019.03.013
   Palacios-Navarro G, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0289-0
   Palaniappan SM, 2018, IEEE INT SYMP SIGNAL, P90, DOI 10.1109/ISSPIT.2018.8642784
   Park DS, 2017, J STROKE CEREBROVASC, V26, P2313, DOI 10.1016/j.jstrokecerebrovasdis.2017.05.019
   Pazzaglia C, 2020, PHYSIOTHERAPY, V106, P36, DOI 10.1016/j.physio.2019.12.007
   Pekyavas NO, 2017, ACTA ORTHOP TRAUMATO, V51, P238, DOI 10.1016/j.aott.2017.03.008
   Pham TN, 2018, BURNS, V44, P2080, DOI 10.1016/j.burns.2018.08.032
   Pompeu JE, 2014, PHYSIOTHERAPY, V100, P162, DOI 10.1016/j.physio.2013.10.003
   Prahm C, 2018, PM&R, V10, P1252, DOI 10.1016/j.pmrj.2018.09.027
   Pua YH, 2019, ACTA ORTHOP, V90, P179, DOI 10.1080/17453674.2018.1560647
   Punt IM, 2016, SCAND J MED SCI SPOR, V26, P816, DOI 10.1111/sms.12509
   Punt IM, 2017, GAIT POSTURE, V58, P52, DOI 10.1016/j.gaitpost.2017.06.284
   Putrino D, 2017, GAMES HEALTH J, V6, P295, DOI 10.1089/g4h.2016.0108
   Rajaratnam B S, 2013, Rehabil Res Pract, V2013, P649561, DOI 10.1155/2013/649561
   Regenbrecht H, 2004, PRESENCE-TELEOP VIRT, V13, P338, DOI 10.1162/1054746041422334
   Bacha JMR, 2018, GAMES HEALTH J, V7, P24, DOI 10.1089/g4h.2017.0065
   Severiano MIR, 2018, ARQ NEURO-PSIQUIAT, V76, P78, DOI [10.1590/0004-282X20170195, 10.1590/0004-282x20170195]
   Rosly MM, 2017, DISABIL REHABIL, V39, P727, DOI 10.3109/09638288.2016.1161086
   Rubini Ercole da Cruz, 2016, Fisioter. mov., V29, P421, DOI 10.1590/0103-5150.029.002.AO21
   Rutkowski S, 2020, INT J CHRONIC OBSTR, V15, P117, DOI 10.2147/COPD.S223592
   Sajan JE, 2017, DEV NEUROREHABIL, V20, P361, DOI 10.1080/17518423.2016.1252970
   Santos P, 2019, NEUROREHABILITATION, V45, P255, DOI 10.3233/NRE-192771
   Saposnik G, 2016, LANCET NEUROL, V15, P1019, DOI 10.1016/S1474-4422(16)30121-1
   Scapin S, 2018, BURNS, V44, P1403, DOI 10.1016/j.burns.2017.11.002
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Sessoms PH, 2023, VIRTUAL REAL-LONDON, V27, P263, DOI 10.1007/s10055-021-00546-x
   Sharar SR, 2007, ARCH PHYS MED REHAB, V88, pS43, DOI 10.1016/j.apmr.2007.09.004
   Shin JH, 2015, COMPUT BIOL MED, V63, P92, DOI 10.1016/j.compbiomed.2015.03.011
   Shin JH, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-32
   Sin H, 2013, AM J PHYS MED REHAB, V92, P871, DOI 10.1097/PHM.0b013e3182a38e40
   Smith CM, 2012, PHYS THER REV, V17, P1, DOI 10.1179/1743288X11Y.0000000047
   Streicher MC, 2018, INT J THER REHABIL, V25, P522, DOI 10.12968/ijtr.2018.25.10.522
   Subramaniam S, 2019, TOP STROKE REHABIL, V26, P565, DOI 10.1080/10749357.2019.1625545
   Tarakci E, 2020, J HAND THER, V33, P220, DOI 10.1016/j.jht.2019.03.012
   Taylor LM, 2018, J GERIATR PHYS THER, V41, P108, DOI 10.1519/JPT.0000000000000078
   Thornton M, 2005, BRAIN INJURY, V19, P989, DOI 10.1080/02699050500109944
   Tough D, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-5068-0
   Tranfield D, 2003, BRIT J MANAGE, V14, P207, DOI 10.1111/1467-8551.00375
   Tsuda K, 2016, INTERNAL MED, V55, P347, DOI 10.2169/internalmedicine.55.5275
   Utkan Karasu A, 2018, J REHABIL MED, V50, P406, DOI 10.2340/16501977-2331
   Valdés BA, 2018, GAMES HEALTH J, V7, P197, DOI 10.1089/g4h.2017.0137
   Vernadakis N, 2014, PHYS THER SPORT, V15, P148, DOI 10.1016/j.ptsp.2013.08.004
   Viglialoro RM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052338
   Villafaina S, 2019, GAMES HEALTH J, V8, P380, DOI 10.1089/g4h.2019.0023
   Voon K, 2016, BURNS, V42, P1797, DOI 10.1016/j.burns.2016.06.007
   Walker ML, 2010, ARCH PHYS MED REHAB, V91, P115, DOI 10.1016/j.apmr.2009.09.009
   Warland A, 2019, DISABIL REHABIL, V41, P2119, DOI 10.1080/09638288.2018.1459881
   Wuang YP, 2011, RES DEV DISABIL, V32, P312, DOI 10.1016/j.ridd.2010.10.002
   Yazgan YZ, 2020, MULT SCLER RELAT DIS, V39, DOI 10.1016/j.msard.2019.101902
   Yohannan SK, 2012, J BURN CARE RES, V33, P36, DOI 10.1097/BCR.0b013e318234d8ef
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 153
TC 10
Z9 10
U1 8
U2 38
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 71
EP 95
DI 10.1007/s10055-022-00654-2
EA JUL 2022
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000828931800004
DA 2024-07-18
ER

PT J
AU Sereno, M
   Besançon, L
   Isenberg, T
AF Sereno, Mickael
   Besancon, Lonni
   Isenberg, Tobias
TI Point specification in collaborative visualization for 3D scalar fields
   using augmented reality
SO VIRTUAL REALITY
LA English
DT Article
DE AR; CSCW; 3D visualization; 3D point specification
ID DIRECT-TOUCH INTERACTION; SELECTION TECHNIQUES; REPLICATION; STATISTICS;
   CRISIS; USER
AB We compared three techniques to specify 3D positions for collaborative augmented reality (AR) visualization. AR head-mounted displays allow multiple users to share the same physical space, while keeping seamless social interactions. Interactions being key parts of exploratory visualization tasks, we adapted from the virtual reality literature three distinct techniques to specify points in 3D space, such as for placing annotations for which they cannot rely on existing data objects. We evaluated these techniques on their accuracy and speed, the user's subjective workload and preferences, as well as their co-presence, mutual understanding, and behavior in collaborative tasks. Our results suggest that all the three techniques provide good mutual understanding and co-presence among collaborators. They differ, however, in the way users behave, their accuracy, and their speed.
C1 [Sereno, Mickael; Isenberg, Tobias] Univ Paris Saclay, CNRS, INRIA, LISN, Orsay, France.
   [Besancon, Lonni] Linkoping Univ, Linkoping, Sweden.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Inria; Microsoft; Universite Paris Cite; Linkoping University
RP Sereno, M (corresponding author), Univ Paris Saclay, CNRS, INRIA, LISN, Orsay, France.
EM serenomickael@gmail.com; lonni.besancon@gmail.com;
   tobias.isenberg@inria.fr
RI Besançon, Lonni/N-1856-2017; Sereno, Mickael/H-2447-2019; Isenberg,
   Tobias/A-7575-2008
OI Sereno, Mickael/0000-0003-1298-0774; Isenberg,
   Tobias/0000-0001-7953-8644
CR Adcock M., 2013, P SUI, P1
   Amrhein V, 2019, AM STAT, V73, P262, DOI 10.1080/00031305.2018.1543137
   Amrhein V, 2019, NATURE, V567, P305, DOI 10.1038/d41586-019-00857-9
   [Anonymous], 2016, P AVI, DOI DOI 10.1145/2909132.2909247
   [Anonymous], 2013, Evaluating the Efciency of Physical Visualizations, DOI DOI 10.1145/2470654.2481359
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Baguley T, 2009, BRIT J PSYCHOL, V100, P603, DOI 10.1348/000712608X377117
   Balogun MB, 2019, AFRICON, DOI [10.1109/africon46755.2019.9133906, 10.1145/3290605.3300331]
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1687, DOI [10.1109/VR.2019.8798038, 10.1109/vr.2019.8798038]
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Benko H., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1263
   Benko H, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P79
   Besancon L., 2021, HAL OPEN SCI, DOI [10.31219/osf.io/mjg7h, DOI 10.31219/OSF.IO/MJG7H]
   Besançon L, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3310432
   Besancon L, 2019, COMPUT GRAPH FORUM, V38, P553, DOI 10.1111/cgf.13710
   Besançon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1831, DOI 10.1145/3025453.3025890
   Besançon L, 2017, IEEE T VIS COMPUT GR, V23, P881, DOI 10.1109/TVCG.2016.2599217
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Bornik A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P29, DOI 10.1109/TRIDUI.2006.1618267
   Bowman D, 2001, TR0123 DEP COMP SCI
   Bowman D. A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P26, DOI 10.1145/323663.323667
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bruckner S, 2019, IEEE T VIS COMPUT GR, V25, P2514, DOI 10.1109/TVCG.2018.2848906
   Bruder G, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P115, DOI 10.1109/3DUI.2013.6550207
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Cockburn A, 2020, COMMUN ACM, V63, P70, DOI 10.1145/3360311
   Cockburn A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173715
   Coe Robert, 2002, ITS EFFECT SIZE STUP, P1
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Czauderna T, 2018, LECT NOTES COMPUT SC, V11190, P289, DOI 10.1007/978-3-030-01388-2_10
   Daiber F, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P441, DOI 10.1145/2254556.2254641
   Dragicevic P., 2014, CHI EXTENDED ABSTRAC, P607, DOI DOI 10.1145/2559206.2578881
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   FLEMING PJ, 1986, COMMUN ACM, V29, P218, DOI 10.1145/5666.5673
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   Fu CW, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2213
   Gigerenzer G, 2018, ADV METH PRACT PSYCH, V1, P198, DOI 10.1177/2515245918771329
   Grossman T., 2006, P UIST 2006, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Grossman Tovi., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '05, P281, DOI [10.1145/1054972.1055012, DOI 10.1145/1054972.1055012]
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gutwin C., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P411, DOI 10.1023/A:1021271517844
   Harmon R, 1996, P IEEE VIRT REAL ANN, P239, DOI 10.1109/VRAIS.1996.490533
   Harms C., 2004, 7 ANN INT WORKSH PRE
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Irlitti A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P31, DOI [10.1109/ISMAR-Adjunct.2016.25, 10.1109/ISMAR-Adjunct.2016.0032]
   Isenberg T., 2016, Collaboration Meets Interactive Spaces, P97, DOI [10.1007/978-3-319-45853-3_6, DOI 10.1007/978-3-319-45853-3_6]
   Issartel P, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P215, DOI [10.1109/ISMAR-Adjunct.2016.70, 10.1109/ISMAR-Adjunct.2016.0079]
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Keefe DF, 2013, COMPUTER, V46, P51, DOI 10.1109/MC.2013.178
   Keefe DF, 2010, IEEE COMPUT GRAPH, V30, P8, DOI 10.1109/MCG.2010.30
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Klapperstück M, 2016, 2016 INTERNATIONAL SYMPOSIUM ON BIG DATA VISUAL ANALYTICS (BDVA), P7, DOI 10.1109/WiMOB.2016.7763189
   Klein T, 2012, COMPUT GRAPH FORUM, V31, P1225, DOI 10.1111/j.1467-8659.2012.03115.x
   Krzywinski M, 2013, NAT METHODS, V10, P921, DOI 10.1038/nmeth.2659
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Lenne D, 2009, RES ENG DES, V20, P149, DOI 10.1007/s00163-009-0071-8
   Longo L, 2017, LECT NOTES COMPUT SC, V10514, P202, DOI 10.1007/978-3-319-67684-5_13
   Looser J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P203
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   McShane BB, 2017, J AM STAT ASSOC, V112, P885, DOI 10.1080/01621459.2017.1289846
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   Oda O, 2012, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2012.6402558
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Rheingans P, 2002, IEEE COMPUT GRAPH, V22, P6, DOI 10.1109/38.974511
   Ro H, 2017, IEEE SYS MAN CYBERN, P2873, DOI 10.1109/SMC.2017.8123063
   Rosa D. A. W., 2010, 2010 Proceedings of XXIX International Conference of the Chilean Computer Science Society (SCCC 2010), P218, DOI 10.1109/SCCC.2010.51
   Saalfeld P, 2017, COMPUT GRAPH-UK, V65, P12, DOI 10.1016/j.cag.2017.03.003
   Sauro J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2347
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Sherbondy A, 2005, IEEE T VIS COMPUT GR, V11, P419, DOI 10.1109/TVCG.2005.59
   Springmeyer R. R., 1992, Proceedings. Visualization '92 (Cat. No.92CH3201-1), P235, DOI 10.1109/VISUAL.1992.235203
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300243
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Teo T, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P406, DOI 10.1145/3292147.3292200
   Top A, 2011, LECT NOTES COMPUT SC, V6533, P204, DOI 10.1007/978-3-642-18421-5_20
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Valentine JC, 2015, BASIC APPL SOC PSYCH, V37, P260, DOI 10.1080/01973533.2015.1060240
   VandenBos G.R., 2009, PUBL MAN AM PSYCH AS
   Wang X, 2019, WORKSH CHI IA GLASG
   Wang XM, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120643
   Yu LY, 2016, IEEE T VIS COMPUT GR, V22, P886, DOI 10.1109/TVCG.2015.2467202
   Yu LY, 2012, IEEE T VIS COMPUT GR, V18, P2245, DOI 10.1109/TVCG.2012.217
   Yu LY, 2010, IEEE T VIS COMPUT GR, V16, P1613, DOI 10.1109/TVCG.2010.157
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 98
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1317
EP 1334
DI 10.1007/s10055-021-00614-2
EA FEB 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000757751600001
DA 2024-07-18
ER

PT J
AU Bian, YL
   Zhou, C
   Liu, J
   Geng, WX
   Shi, Y
AF Bian, Yulong
   Zhou, Chao
   Liu, Juan
   Geng, Wenxiu
   Shi, Ying
TI The effect of reducing distraction on the flow-performance link in
   virtual experiential learning environment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Experiential learning; Flow-performance link;
   Distraction; Guideline
ID AUGMENTED REALITY; PERCEPTUAL LOAD; ATTENTION; INTERACTIVITY; IMPACT;
   CONSTRUCTION; VIVIDNESS; EDUCATION; SELECTION; LOCUS
AB In virtual experiential learning environment (VELE), distraction can reduce learners' flow experience, learning performance, and the link between them, which are important aspects for high-quality learning. Based on the weak association model (WAM), we proposed two potential guidelines to deal with distraction and then improve these aspects. Guideline1 is directly decreasing the amount of attractive but task-irrelevant distractors in VELE. Guideline2 is enhancing the congruence between distractors and primary task by guiding attention from task-irrelevant distractors to task-relevant elements. To explore the effect of the guidelines, this paper develops a prototype VR experiential learning system, based on which two experiments were performed. Experiment 1 and experiment 2, respectively, conducted a comparative experiment to test the effect of guideline 1 and guideline 2 on flow, performance, and flow-performance link. Results show that both guidelines helped enhance the learning performance without any damage on flow experience and alleviated the weak flow-performance link. The two guidelines provide easy ways to guide task-relevant attention to optimize VELE.
C1 [Bian, Yulong; Liu, Juan; Geng, Wenxiu] Shandong Univ, Weihai, Peoples R China.
   [Bian, Yulong] MOE, Engn Res Ctr Digital Media Technol, Jinan, Peoples R China.
   [Zhou, Chao] Tsinghua Univ, Beijing, Peoples R China.
   [Shi, Ying] Jinan Univ, Affiliated Hosp 1, Guangzhou, Peoples R China.
C3 Shandong University; Tsinghua University; Jinan University
RP Bian, YL (corresponding author), Shandong Univ, Weihai, Peoples R China.; Bian, YL (corresponding author), MOE, Engn Res Ctr Digital Media Technol, Jinan, Peoples R China.; Zhou, C (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM bianyulong@sdu.edu.cn; zhouchao@tsinghua.edu.cn
FU National Natural Science Foundation of China [61802232, 61972233];
   postdoctoral research foundation of china [2021TQ0178]; Young Scholars
   Program of Shandong University, Weihai [20820211005]; Special Project of
   Science and Technology Innovation Base of Key Laboratory of Shandong
   Province for Software Engineering [11480004042015]
FX The authors would like to thank the editor and the three anonymous
   reviewers for their valuable comments on earlier drafts of this paper.
   The authors thank Prof. Chenglei Yang for the financial support; Prof.
   Sheng Li and Mrs. Dongli Li for the help in preparing and revising
   paper. This work is supported by the National Natural Science Foundation
   of China (61802232;61972233); the postdoctoral research foundation of
   china (2021TQ0178), Young Scholars Program of Shandong University,Weihai
   (20820211005) and Special Project of Science and Technology Innovation
   Base of Key Laboratory of Shandong Province for Software Engineering
   (11480004042015).
CR Alhalabi Wadee S., 2016, Behaviour & Information Technology, V35, P919, DOI 10.1080/0144929X.2016.1212931
   Alvarez, 2018, OCCASIONAL PAPER SER, V2018, P8, DOI DOI 10.58295/2375-3668.1195
   [Anonymous], 1980, Attention Per- form. VIII
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P88, DOI 10.1109/93.998075
   Baran M., 2006, Hum. Factors Ergon. Soc. Annu. Meet. Proc., V50, P2008
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   Bian YL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018)
   Bian YL, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P852, DOI [10.1109/vr.2019.8798237, 10.1109/VR.2019.8798237]
   Bian YL, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P433, DOI 10.1145/2858036.2858351
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Bressler DM, 2013, J COMPUT ASSIST LEAR, V29, P505, DOI 10.1111/jcal.12008
   Cheng KH, 2014, COMPUT EDUC, V72, P302, DOI 10.1016/j.compedu.2013.12.003
   Cheng LK, 2014, VIRTUAL REAL-LONDON, V18, P173, DOI 10.1007/s10055-014-0244-2
   Choi B, 2011, COMPUT EDUC, V57, P2382, DOI 10.1016/j.compedu.2011.06.019
   Coyle JR, 2001, J ADVERTISING, V30, P65, DOI 10.1080/00913367.2001.10673646
   Dourish P., 2004, ACTION IS FDN EMBODI
   El Sayed NAM, 2011, COMPUT EDUC, V56, P1045, DOI 10.1016/j.compedu.2010.10.019
   Engeser S, 2005, Z PADAGOG PSYCHOL, V19, P159, DOI 10.1024/1010-0652.19.3.159
   Engeser S, 2012, ADVANCES IN FLOW RESEARCH, P1, DOI 10.1007/978-1-4614-2359-1
   Engeser S, 2008, MOTIV EMOTION, V32, P158, DOI 10.1007/s11031-008-9102-4
   Esteban-Millat I, 2014, COMPUT EDUC, V71, P111, DOI 10.1016/j.compedu.2013.09.012
   Flynn EA, 1999, AM J HEALTH-SYST PH, V56, P1319, DOI 10.1093/ajhp/56.13.1319
   Fortin DR, 2005, J BUS RES, V58, P387, DOI 10.1016/S0148-2963(03)00106-1
   Furió D, 2015, J COMPUT ASSIST LEAR, V31, P189, DOI 10.1111/jcal.12071
   Gai W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5016, DOI 10.1145/3025453.3025494
   GHANI JA, 1994, J PSYCHOL, V128, P381, DOI 10.1080/00223980.1994.9712742
   Giesbrecht B, 2014, ANN NY ACAD SCI, V1316, P71, DOI 10.1111/nyas.12404
   Grogorick S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P563, DOI 10.1109/VR.2018.8446215
   Hsu TC, 2017, COMPUT EDUC, V106, P137, DOI 10.1016/j.compedu.2016.12.007
   Huang HM, 2016, INTERACT LEARN ENVIR, V24, P3, DOI 10.1080/10494820.2013.817436
   Huang LT, 2011, CYBERPSYCH BEH SOC N, V14, P3, DOI 10.1089/cyber.2009.0256
   Huang WH, 2010, COMPUT EDUC, V55, P789, DOI 10.1016/j.compedu.2010.03.011
   Huang-Pollock CL, 2005, J CHILD PSYCHOL PSYC, V46, P1211, DOI 10.1111/j.1469-7610.2005.00410.x
   Hung CY, 2015, INTERACT LEARN ENVIR, V23, P172, DOI 10.1080/10494820.2014.997248
   Hwang GJ, 2012, COMPUT EDUC, V59, P1246, DOI 10.1016/j.compedu.2012.05.009
   Johnson L.F., 2010, EDUC DIG, V76, P34
   Kiili K., 2005, Internet and Higher Education, V8, P13, DOI 10.1016/j.iheduc.2004.12.001
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim J, 2018, INT WORK QUAL MULTIM, P13
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Lambooij M, 2013, DISPLAYS, V34, P8, DOI 10.1016/j.displa.2012.09.002
   Lambooij M, 2011, IEEE T BROADCAST, V57, P432, DOI 10.1109/TBC.2011.2134590
   Lavie N, 2003, PERCEPT PSYCHOPHYS, V65, P202, DOI 10.3758/BF03194795
   LAVIE N, 1994, PERCEPT PSYCHOPHYS, V56, P183, DOI 10.3758/BF03213897
   Lee EC, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P259, DOI [10.1109/vr.2019.8798154, 10.1109/VR.2019.8798154]
   Li H., 2001, Journal of Interactive Marketing, V15, P13, DOI [10.1002/dir.1013, DOI 10.1002/DIR.1013]
   Liu J, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-2941-7
   Liu TC, 2012, COMPUT EDUC, V58, P172, DOI 10.1016/j.compedu.2011.08.007
   Marshall P, 2013, INTRO SPECIAL ISSUE
   Martín-Gutiérrez J, 2017, EURASIA J MATH SCI T, V13, P469, DOI 10.12973/eurasia.2017.00626a
   MCKENNA FP, 1986, ERGONOMICS, V29, P649, DOI 10.1080/00140138608968300
   Mihye Kim, 2012, Knowledge Management and Acquisition for Intelligent Systems. Proceedings of the 12th Pacific Rim Knowledge Acquisition Workshop, PKAW 2012, P364, DOI 10.1007/978-3-642-32541-0_32
   Mohammadyari S, 2015, COMPUT EDUC, V82, P11, DOI 10.1016/j.compedu.2014.10.025
   NORMAN DA, 1975, COGNITIVE PSYCHOL, V7, P44, DOI 10.1016/0010-0285(75)90004-3
   Parmar D, 2016, VIRTUAL REAL-LONDON, V20, P141, DOI 10.1007/s10055-016-0287-7
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Raptis GE, 2018, INT J HUM-COMPUT ST, V114, P69, DOI 10.1016/j.ijhcs.2018.02.003
   Renner P, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P771, DOI 10.1109/VR.2018.8446396
   Schüler J, 2009, PSYCHOL SPORT EXERC, V10, P168, DOI 10.1016/j.psychsport.2008.07.001
   Schüler J, 2007, Z PADAGOG PSYCHOL, V21, P217, DOI 10.1024/1010-0652.21.3.217
   Shin DH, 2013, BEHAV INFORM TECHNOL, V32, P203, DOI 10.1080/0144929X.2011.606334
   Skadberg YX, 2004, COMPUT HUM BEHAV, V20, P403, DOI 10.1016/S0747-5632(03)00050-5
   Sung HY, 2013, COMPUT EDUC, V63, P43, DOI 10.1016/j.compedu.2012.11.019
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Tang YM, 2018, INT J ENG BUS MANAG, V10, DOI 10.1177/1847979018809599
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang LC, 2010, INNOV EDUC TEACH INT, V47, P39, DOI 10.1080/14703290903525838
   Ward CC, 2004, J SOC PERS RELAT, V21, P611, DOI 10.1177/0265407504045890
   WEBSTER J, 1993, COMPUT HUM BEHAV, V9, P411, DOI 10.1016/0747-5632(93)90032-N
   Wei XD, 2015, COMPUT EDUC, V81, P221, DOI 10.1016/j.compedu.2014.10.017
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   YANTIS S, 1990, J EXP PSYCHOL HUMAN, V16, P135, DOI 10.1037/0096-1523.16.1.135
   Zhang T, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2953887
   Zhou C, 2021, INT J PHYTOREMEDIAT, V23, P80, DOI 10.1080/15226514.2020.1797628
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 78
TC 4
Z9 4
U1 9
U2 38
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1277
EP 1290
DI 10.1007/s10055-021-00621-3
EA FEB 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000753724800001
DA 2024-07-18
ER

PT J
AU Sauer, Y
   Sipatchin, A
   Wahl, S
   García, MG
AF Sauer, Yannick
   Sipatchin, Alexandra
   Wahl, Siegfried
   Garcia, Miguel Garcia
TI Assessment of consumer VR-headsets' objective and subjective field of
   view (FoV) and its feasibility for visual field testing
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Field of view; HMD; Perimetry; Eye relief; Visual
   field; Eye
ID VIRTUAL-REALITY; VISION; ENVIRONMENTS; PERCEPTION; SURGERY
AB Virtual reality as a research environment has seen a boost in its popularity during the last decades. Not only the usage fields for this technology have broadened, but also a research niche has appeared as the hardware improved and became more affordable. Experiments in vision research are constructed upon the basis of accurately displaying stimuli with a specific position and size. For classical screen setups, viewing distance and pixel position on the screen define the perceived position for subjects in a relatively precise fashion. However, projection fidelity in HMDs strongly depends on eye and face physiological parameters. This study introduces an inexpensive method to measure the perceived field of view and its dependence upon the eye position and the interpupillary distance, using a super wide angle camera. Measurements of multiple consumer VR headsets show that manufacturers' claims regarding field of view of their HMDs are mostly unrealistic. Additionally, we performed a "Goldmann" perimetry test in VR to obtain subjective results as a validation of the objective camera measurements. Based on this novel data, the applicability of these devices to test humans' field of view was evaluated.
C1 [Sauer, Yannick; Sipatchin, Alexandra; Wahl, Siegfried; Garcia, Miguel Garcia] Univ Tubingen, Inst Ophthalm Res, Elfriede Aulhorn Str 7, D-72072 Tubingen, Germany.
   [Wahl, Siegfried] Carl Zeiss Vis Int GmbH, Turnstr 27, D-73430 Aalen, Germany.
C3 Eberhard Karls University of Tubingen; Eberhard Karls University
   Hospital
RP Sauer, Y (corresponding author), Univ Tubingen, Inst Ophthalm Res, Elfriede Aulhorn Str 7, D-72072 Tubingen, Germany.
EM yannick.sauer@uni-tuebingen.de
RI Wahl, Siegfried/I-7200-2016
OI Sauer, Yannick/0000-0002-7513-341X; Garcia Garcia,
   Miguel/0000-0001-7379-0080
FU Projekt DEAL; Federal Ministry of Education and Research (BMBF)
   [16SV8104]; University of Tubingen through the mini graduate school
   'Integrative Augmented Reality (I-AR)'
FX Open Access funding enabled and organized by Projekt DEAL. The Federal
   Ministry of Education and Research (BMBF) supported the project in the
   framework of IDeA (project number 16SV8104). Authors also recognize
   intra-mutual funding of the University of Tubingen through the mini
   graduate school 'Integrative Augmented Reality (I-AR)'. The founders did
   not have any additional role in the study design, data collection and
   analysis, decision to publish or preparation of the manuscript.
CR Alexander T, 2017, ADV INTELL SYST, V498, P23, DOI 10.1007/978-3-319-42070-7_3
   Bashshur R, 2020, TELEMED E-HEALTH, V26, P571, DOI 10.1089/tmj.2020.29040.rb
   Bric JD, 2016, SURG ENDOSC, V30, P2169, DOI 10.1007/s00464-015-4517-y
   Caramenti M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02344
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Elias ZM, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102879
   GOLDMANN H, 1946, OPHTHALMOLOGICA, V111, P187, DOI 10.1159/000300322
   Hassan SE, 2007, VISION RES, V47, P2115, DOI 10.1016/j.visres.2007.03.012
   Hollander DA, 2000, BRIT J OPHTHALMOL, V84, P1185, DOI 10.1136/bjo.84.10.1185
   Kirchner J, 2022, ENEURO, V9, DOI [10.1523/ENEURO.0357-21.2021, 10.1523/ENEUR0.0357-21.2021]
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lee Ho-Sun, 2006, Korean J Ophthalmol, V20, P79
   Lynn MH, 2020, OPTOMETRY VISION SCI, V97, P573, DOI 10.1097/OPX.0000000000001541
   Martschinke J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1848, DOI [10.1109/VR.2019.8798107, 10.1109/vr.2019.8798107]
   Masnadi S, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P542, DOI 10.1109/VRW52623.2021.00153
   Mees L, 2020, J GLAUCOMA, V29, P86, DOI 10.1097/IJG.0000000000001415
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   MONWILLIAMS M, 1993, OPHTHAL PHYSL OPT, V13, P387, DOI 10.1111/j.1475-1313.1993.tb00496.x
   Musil R, 2021, HMD GEOMETRY DATABAS
   Neugebauer A, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11020223
   Osuobeni E.P., 1997, CLIN EXP OPTOM, V80, P35, DOI DOI 10.1111/J.1444-0938.1997.TB04845.X
   Pfandler M, 2017, SPINE J, V17, P1352, DOI 10.1016/j.spinee.2017.05.016
   Pohl D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P323, DOI 10.1145/2993369.2996300
   Pretto P, 2009, COMPUT GRAPH-UK, V33, P139, DOI 10.1016/j.cag.2009.01.003
   Rolland J. P., 1993, METHOD COMPUTATIONAL
   Sauer Y, 2022, ISCIENCE, V25, DOI 10.1016/j.isci.2021.103567
   Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372
   Segawa K, 2012, OPT REV, V19, P268, DOI 10.1007/s10043-012-0041-7
   Sipatchin A, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020180
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Tatiyosyan SA, 2020, RESTOR NEUROL NEUROS, V38, P119, DOI 10.3233/RNN-190937
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Tsapakis S, 2018, CLIN OPHTHALMOL, V12, P2597, DOI 10.2147/OPTH.S187832
   Tsapakis S, 2017, CLIN OPHTHALMOL, V11, P1431, DOI 10.2147/OPTH.S131160
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   Urban S, 2015, ISPRS J PHOTOGRAMM, V108, P72, DOI 10.1016/j.isprsjprs.2015.06.005
   Wang YF, 2013, INVEST OPHTH VIS SCI, V54, P756, DOI 10.1167/iovs.12-10468
   WANN JP, 1995, VISION RES, V35, P2731, DOI 10.1016/0042-6989(95)00018-U
   WARREN WH, 1992, PERCEPT PSYCHOPHYS, V51, P443, DOI 10.3758/BF03211640
   WEBER J, 1989, INT OPHTHALMOL, V13, P47, DOI 10.1007/BF02028637
   Wheelwright B, 2018, PROC SPIE, V10676, DOI 10.1117/12.2307303
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 42
TC 16
Z9 16
U1 2
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1089
EP 1101
DI 10.1007/s10055-021-00619-x
EA JAN 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000742796600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Park, S
   Kim, L
   Kwon, J
   Choi, SJ
   Whang, M
AF Park, Sangin
   Kim, Laehyun
   Kwon, Jangho
   Choi, Soo Ji
   Whang, Mincheol
TI Evaluation of visual-induced motion sickness from head-mounted display
   using heartbeat evoked potential: a cognitive load-focused approach
SO VIRTUAL REALITY
LA English
DT Article
DE Visual-induced motion sickness (VIMS); Heartbeat evoked potential (HEP);
   Head-mounted display (HMD); Heart-brain synchronization; Cognitive load
ID VIRTUAL-REALITY; AUGMENTED REALITY; BRAIN POTENTIALS; AUTONOMIC
   RESPONSES; CARDIAC AWARENESS; RATE-VARIABILITY; VAGAL TONE; FATIGUE;
   AMPLITUDE; INTERACTIVITY
AB Based on sensory conflict theory, motion sickness is strongly related to the information processing capacity or resources of the brain to cope with the multi-sensory stimuli experienced by watching virtual reality (VR) content. The purpose of this research was to develop a method of measuring motion sickness using the heart-evoked potential (HEP) phenomenon and propose new indicators for evaluating motion sickness. Twenty-eight undergraduate volunteers of both genders (14 females) participated in this study by watching VR content on both 2D and head-mounted devices (HMD) for 15 min. The responses of HEP measures such as alpha power, latency, and amplitude of first and second HEP components were compared using paired t-tests and ANCOVA. This study confirmed that motion sickness leads to a decline in cognitive processing, as demonstrated by increasing in alpha power of HEP. Also, the proposed indicators such as latency and amplitude of the HEP waveform showed significant differences during the experience of motion sickness and exhibited high correlations with alpha power measures. Latencies of the first HEP component, in particular, are recommended as better quantitative evaluators of motion sickness than other measures, following the multitrait-multimethod matrix. The proposed model for motion sickness was implemented in a support vector machine with a radial basis function kernel, and validated on twenty new participants. The accuracy, F1 score, precision, recall, and area under the curve (AUC) of the motion-sickness classification results were 0.875, 0.865, 0.941, 0.8, and 0.962, respectively.
C1 [Park, Sangin; Kim, Laehyun; Kwon, Jangho] Korea Inst Sci & Technol, Ctr Bion, 5 Hwarang Ro 14 Gil, Seoul, South Korea.
   [Kim, Laehyun] Hanyang Univ, Dept HY KIST Bioconvergence, Seoul 04763, South Korea.
   [Choi, Soo Ji] Sch Art Inst Chicago, Fine Arts, Emphasis Visual Commun Design, 36 S Wabash, Chicago, IL 60603 USA.
   [Whang, Mincheol] Sangmyung Univ, Dept Intelligent Engn Informat Human, Jongro Ku, 7 Hongji Dong, Seoul, South Korea.
C3 Korea Institute of Science & Technology (KIST); Hanyang University;
   School of the Art Institute of Chicago; Sangmyung University
RP Whang, M (corresponding author), Sangmyung Univ, Dept Intelligent Engn Informat Human, Jongro Ku, 7 Hongji Dong, Seoul, South Korea.
EM sipark@kist.re.kr; laehyunk@kist.re.kr; g15007@kist.re.kr;
   sooart0504@gmail.com; whang@smu.ac.kr
RI 박, 상인/JEO-2268-2023
OI Park, Sangin/0000-0003-2992-5122; Whang, Mincheol/0000-0003-4301-9089;
   Choi, Soo Ji/0000-0003-1013-9391
FU Electronics and Telecommunications Research Institute (ETRI) - Korean
   government [21ZS1100]; Institute of Information and communications
   Technology Planning & Evaluation (IITP) - Korea government (MSIT)
   [2017-0-00432]
FX This work was supported by the Electronics and Telecommunications
   Research Institute (ETRI) grant funded by the Korean government
   [21ZS1100, Core Technology Research for Self-Improving Integrated
   Artificial Intelligence System] and Institute of Information and
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT) (No. 2017-0-00432, Development of
   non-invasive integrated BCI SW platform to control home appliances and
   external devices by user's thought viaAR/VR interface).
CR Annett J, 2002, ERGONOMICS, V45, P966, DOI 10.1080/00140130210166951
   [Anonymous], 1989, J PSYCHOPHYSIOL, DOI DOI 10.1016/0301-0511(94)00969-5
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bailenson J, 2008, MEDIA PSYCHOL, V11, P354, DOI 10.1080/15213260802285214
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Bouchard S., 2011, Journal of Computer and Information Technology, V1, P20
   Boussaoud D, 2001, NEUROIMAGE, V14, pS40, DOI 10.1006/nimg.2001.0816
   Cain B., 2007, A Review of the Mental Workload Literature. Technical Report
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Chang Y., 2010, Journal of Machine Learning Research, V11, P1471, DOI [DOI 10.5555/1756006.1859899, 10.5555/1756006.1859899]
   Chang YK, 2017, PSYCHOPHYSIOLOGY, V54, P289, DOI 10.1111/psyp.12784
   Chardonnet J.-R., 2015, International conference on artificial reality and telexistence eurographics symposium on virtual environments, P9
   Chen YC, 2010, NEUROIMAGE, V49, P2862, DOI 10.1016/j.neuroimage.2009.10.005
   Chuang SW, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500076
   Clemente M, 2014, EXPERT SYST APPL, V41, P1584, DOI 10.1016/j.eswa.2013.08.055
   DAVIS AM, 1993, TEX HEART I J, V20, P158
   de Morree HM, 2014, J APPL PHYSIOL, V117, P1514, DOI 10.1152/japplphysiol.00898.2013
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Diykh M, 2016, EXPERT SYST APPL, V63, P241, DOI 10.1016/j.eswa.2016.07.004
   Drew RC, 2008, J APPL PHYSIOL, V104, P716, DOI 10.1152/japplphysiol.00956.2007
   DUNNETT CW, 1955, J AM STAT ASSOC, V50, P1096, DOI 10.2307/2281208
   FRIEDERICI AD, 1993, COGNITIVE BRAIN RES, V1, P183, DOI 10.1016/0926-6410(93)90026-2
   Fukushima H, 2011, INT J PSYCHOPHYSIOL, V79, P259, DOI 10.1016/j.ijpsycho.2010.10.015
   Fuster JoaquinM., 1988, Comparative Neuroscience and Neurobiology, P107, DOI [10.1007/978-1-4899-6776-3_43, DOI 10.1007/978-1-4899-6776-3_43]
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Getzmann S, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.13026
   Gianaros PJ, 2003, PSYCHOPHYSIOLOGY, V40, P39, DOI 10.1111/1469-8986.00005
   Hansen AL, 2003, INT J PSYCHOPHYSIOL, V48, P263, DOI 10.1016/S0167-8760(03)00073-4
   Hartikainen K.M., 2003, Detection of Change, P99, DOI DOI 10.1007/978-1-4615-0294-4
   Herrera LJ, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500123
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   Huck S.W., 1974, Reading statistics and research
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Janig W, 1996, BIOL PSYCHOL, V42, P29, DOI 10.1016/0301-0511(95)05145-7
   Käthner I, 2014, BIOL PSYCHOL, V102, P118, DOI 10.1016/j.biopsycho.2014.07.014
   Kato Y, 2009, INT J PSYCHOPHYSIOL, V72, P204, DOI 10.1016/j.ijpsycho.2008.12.008
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keselman HJ, 1998, REV EDUC RES, V68, P350, DOI 10.2307/1170601
   Kesim M, 2012, PROCD SOC BEHV, V47, P297, DOI 10.1016/j.sbspro.2012.06.654
   Kim S, 2018, J SOC INF DISPLAY, V26, P376, DOI 10.1002/jsid.669
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kiryu T, 2008, IEEE ENG MED BIO, P4597, DOI 10.1109/IEMBS.2008.4650237
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lambooij MTM, 2007, PROC SPIE, V6490, DOI 10.1117/12.705527
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Lechinger J, 2015, PSYCHOPHYSIOLOGY, V52, P1441, DOI 10.1111/psyp.12508
   Li HCO, 2008, 3DTV CONF, P193
   Li WF, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156479
   Lima CAM, 2009, EXPERT SYST APPL, V36, P10054, DOI 10.1016/j.eswa.2009.01.022
   Lin CT, 2007, P ANN INT IEEE EMBS, P3872, DOI 10.1109/IEMBS.2007.4353178
   Lin CT, 2013, IEEE T NEUR NET LEAR, V24, P1689, DOI 10.1109/TNNLS.2013.2275003
   Malinska M, 2015, INT J OCCUP SAF ERGO, V21, P47, DOI 10.1080/10803548.2015.1017964
   McCraty R., 2009, Integral Rev, V5
   McGibbon CA, 2004, J APPL PHYSIOL, V96, P149, DOI 10.1152/japplphysiol.00422.2003
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Miller MW, 2011, INT J PSYCHOPHYSIOL, V80, P75, DOI 10.1016/j.ijpsycho.2011.02.003
   MONTOYA P, 1993, ELECTROEN CLIN NEURO, V88, P163, DOI 10.1016/0168-5597(93)90001-6
   MONWILLIAMS M, 1993, OPHTHAL PHYSL OPT, V13, P387, DOI 10.1111/j.1475-1313.1993.tb00496.x
   Morris NB, 2014, J APPL PHYSIOL, V116, P1088, DOI 10.1152/japplphysiol.01059.2013
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Mullen T, 2013, IEEE ENG MED BIO, P2184, DOI 10.1109/EMBC.2013.6609968
   Mun S, 2014, INT J PSYCHOPHYSIOL, V94, P373, DOI 10.1016/j.ijpsycho.2014.08.1389
   Mun S, 2012, NEUROSCI LETT, V525, P89, DOI 10.1016/j.neulet.2012.07.049
   Murata A, 2005, INT J IND ERGONOM, V35, P761, DOI 10.1016/j.ergon.2004.12.003
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Naqvi SAA, 2013, IEEE ENG MED BIO, P6405, DOI 10.1109/EMBC.2013.6611020
   Nauta WJH., 1986, FUNDAMENTAL NEUROANA
   Nieuwenhuys R., 2007, The Human Central Nervous System: A Synopsis and Atlas
   Ohyama S, 2007, AURIS NASUS LARYNX, V34, P303, DOI 10.1016/j.anl.2007.01.002
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Park MC, 2015, J DISP TECHNOL, V11, P877, DOI 10.1109/JDT.2015.2389212
   Park S, 2014, INT J PSYCHOPHYSIOL, V92, P42, DOI 10.1016/j.ijpsycho.2014.02.003
   Park S, 2019, APPL OPTICS, V58, P3467, DOI 10.1364/AO.58.003467
   Park S, 2015, INT J PSYCHOPHYSIOL, V97, P120, DOI 10.1016/j.ijpsycho.2015.04.006
   Pereira JM, 2016, PROC ECON FINANC, V39, P634, DOI 10.1016/S2212-5671(16)30310-0
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Pollatos O, 2004, PSYCHOPHYSIOLOGY, V41, P476, DOI 10.1111/1469-8986.2004.00170.x
   Porges SW, 2007, BIOL PSYCHOL, V74, P116, DOI 10.1016/j.biopsycho.2006.06.009
   Porges SW, 1997, ANN NY ACAD SCI, V807, P62, DOI 10.1111/j.1749-6632.1997.tb51913.x
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Raajan NR, 2012, PROCEDIA ENGINEER, V38, P1559, DOI 10.1016/j.proeng.2012.06.191
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Regan EC, 1996, AVIAT SPACE ENVIR MD, V67, P222
   Rodríguez A, 2015, EXPERT SYST APPL, V42, P1699, DOI 10.1016/j.eswa.2014.10.006
   Ryan ML, 1999, SUB-STANCE, P110
   Saito T, 2017, BIOINFORMATICS, V33, P145, DOI 10.1093/bioinformatics/btw570
   SCHANDRY R, 1986, INT J NEUROSCI, V30, P261, DOI 10.3109/00207458608985677
   SCHANDRY R, 1990, INT J NEUROSCI, V53, P243, DOI 10.3109/00207459008986611
   Schandry R, 1996, BIOL PSYCHOL, V42, P75, DOI 10.1016/0301-0511(95)05147-3
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shyh-Yueh Cheng, 2007, Journal of Medical and Biological Engineering, V27, P124
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stolz C, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13308
   Uetake A, 2000, IEEE RO-MAN 2000: 9TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P235, DOI 10.1109/ROMAN.2000.892501
   UIJTDEHAAGE SHJ, 1992, PSYCHOPHYSIOLOGY, V29, P193, DOI 10.1111/j.1469-8986.1992.tb01685.x
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Villena-González M, 2017, PSYCHOPHYSIOLOGY, V54, P1483, DOI 10.1111/psyp.12894
   WARNER HR, 1962, J APPL PHYSIOL, V17, P349, DOI 10.1152/jappl.1962.17.2.349
   Yokota Y, 2005, ACTA OTO-LARYNGOL, V125, P280, DOI 10.1080/00016480510003192
   Zhang Y, 2012, BIOMED SIGNAL PROCES, V7, P104, DOI 10.1016/j.bspc.2011.02.002
   Zhao CL, 2011, EXPERT SYST APPL, V38, P1859, DOI 10.1016/j.eswa.2010.07.115
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zuzewicz K, 2011, INT J OCCUP SAF ERGO, V17, P403
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 113
TC 10
Z9 10
U1 2
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 979
EP 1000
DI 10.1007/s10055-021-00600-8
EA DEC 2021
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000724639800001
OA hybrid
DA 2024-07-18
ER

PT J
AU McDermott, EJ
   Metsomaa, J
   Belardinelli, P
   Grosse-Wentrup, M
   Ziemann, U
   Zrenner, C
AF McDermott, Eric J.
   Metsomaa, Johanna
   Belardinelli, Paolo
   Grosse-Wentrup, Moritz
   Ziemann, Ulf
   Zrenner, Christoph
TI Predicting motor behavior: an efficient EEG signal processing pipeline
   to detect brain states with potential therapeutic relevance for VR-based
   neurorehabilitation
SO VIRTUAL REALITY
LA English
DT Article
DE EEG; Brain-state decoding; Machine learning; Classification;
   Brain-computer interface (BCI); Motor intention; Motor behavior; Hand
   selection; Virtual reality; Neurorehabilitation; EEG-VR; Pre-movement;
   Human-in-the-loop; Open source pipeline
ID SINGLE-TRIAL CLASSIFICATION; HUMAN VOLUNTARY MOVEMENT; DORSAL PREMOTOR
   CORTEX; CORTICAL POTENTIALS; HAND; INTENTION; FINGER; RHYTHM; WRIST;
   REAL
AB Virtual reality (VR)-based motor therapy is an emerging approach in neurorehabilitation. The combination of VR with electroencephalography (EEG) presents further opportunities to improve therapeutic efficacy by personalizing the paradigm. Specifically, the idea is to synchronize the choice and timing of stimuli in the perceived virtual world with fluctuating brain states relevant to motor behavior. Here, we present an open source EEG single-trial based classification pipeline that is designed to identify ongoing brain states predictive of the planning and execution of movements. 9 healthy volunteers each performed 1080 trials of a repetitive reaching task with an implicit two-alternative forced choice, i.e., use of the right or left hand, in response to the appearance of a visual target. The performance of the EEG decoding pipeline was assessed with respect to classification accuracy of right vs. left arm use, based on the EEG signal at the time of the stimulus. Different features, feature extraction methods, and classifiers were compared at different time windows; the number and location of informative EEG channels and the number of calibration trials needed were also quantified, as well as any benefits from individual-level optimization of pipeline parameters. This resulted in a set of recommended parameters that achieved an average 83.3% correct prediction on never-before-seen testing data, and a state-of-the-art 77.1% in a real-time simulation. Neurophysiological plausibility of the resulting classifiers was assessed by time-frequency and event-related potential analyses, as well as by Independent Component Analysis topographies and cortical source localization. We expect that this pipeline will facilitate the identification of relevant brain states as prospective therapeutic targets in closed-loop EEG-VR motor neurorehabilitation.
C1 [McDermott, Eric J.; Metsomaa, Johanna; Belardinelli, Paolo; Ziemann, Ulf; Zrenner, Christoph] Eberhard Karls Univ Tubingen, Dept Neurol & Stroke, Hoppe Seyler Str 3, D-72076 Tubingen, Germany.
   [McDermott, Eric J.; Metsomaa, Johanna; Belardinelli, Paolo; Ziemann, Ulf; Zrenner, Christoph] Eberhard Karls Univ Tubingen, Hertie Inst Clin Brain Res, Hoppe Seyler Str 3, D-72076 Tubingen, Germany.
   [McDermott, Eric J.] Int Max Planck Res Sch, Tubingen, Germany.
   [McDermott, Eric J.] Grad Training Ctr Neurosci, Tubingen, Germany.
   [Grosse-Wentrup, Moritz] Univ Vienna, Fac Comp Sci, Res Platform Data Sci, Vienna, Austria.
   [Grosse-Wentrup, Moritz] Univ Vienna, Vienna Cognit Sci Hub, Vienna, Austria.
   [Belardinelli, Paolo] Univ Trento, Ctr Mind Brain Sci, CIMeC, Trento, Italy.
C3 Eberhard Karls University of Tubingen; Eberhard Karls University of
   Tubingen; Eberhard Karls University Hospital; Max Planck Society;
   University of Vienna; University of Vienna; University of Trento
RP Ziemann, U (corresponding author), Eberhard Karls Univ Tubingen, Dept Neurol & Stroke, Hoppe Seyler Str 3, D-72076 Tubingen, Germany.; Ziemann, U (corresponding author), Eberhard Karls Univ Tubingen, Hertie Inst Clin Brain Res, Hoppe Seyler Str 3, D-72076 Tubingen, Germany.
EM ulf.ziemann@uni-tuebingen.de
RI Belardinelli, Paolo/AAN-6304-2021
OI Belardinelli, Paolo/0000-0002-9290-1804; Zrenner,
   Christoph/0000-0002-9595-6923; Grosse-Wentrup,
   Moritz/0000-0001-9787-2291
FU Projekt DEAL; German Federal Ministry of Education and Research (BMBF)
   [13GW0213A]; Clinician Scientist Program at the Faculty of Medicine at
   the University of Tubingen; Emil Aaltonen Foundation; Kaute Foundation
FX Open Access funding enabled and organized by Projekt DEAL. This project
   has received funding from the German Federal Ministry of Education and
   Research (BMBF, grant agreement No 13GW0213A), to E.J.M. and P. B. C.Z.
   acknowledges support from the Clinician Scientist Program at the Faculty
   of Medicine at the University of Tubingen. J.M. has received funding
   from the Emil Aaltonen Foundation and Kaute Foundation.
CR Adeli H, 2003, J NEUROSCI METH, V123, P69, DOI 10.1016/S0165-0270(02)00340-0
   Atzori M, 2016, FRONT NEUROROBOTICS, V10, DOI 10.3389/fnbot.2016.00009
   Bai O, 2005, CLIN NEUROPHYSIOL, V116, P1213, DOI 10.1016/j.clinph.2005.01.006
   Bai O, 2007, CLIN NEUROPHYSIOL, V118, P2637, DOI 10.1016/j.clinph.2007.08.025
   Bai O, 2011, CLIN NEUROPHYSIOL, V122, P364, DOI 10.1016/j.clinph.2010.07.010
   Bhattacharyya Saugat., 2010, 2010 INT C SYST MED, P126, DOI DOI 10.1109/ICSMB.2010.5735358
   BIRBAUMER N, 1990, PHYSIOL REV, V70, P1, DOI 10.1152/physrev.1990.70.1.1
   Blankertz B, 2002, ADV NEUR IN, V14, P157
   Botvinik-Nezer R, 2020, NATURE, V582, P84, DOI 10.1038/s41586-020-2314-9
   Brass M, 2008, NEUROSCIENTIST, V14, P319, DOI 10.1177/1073858408317417
   Brunia C.H. M., 2003, The Bereitschaftspotential: Movement-Related Cortical Potentials, P207, DOI [DOI 10.1007/978-1-4615-0189-3_13, 10.1007/978-1-4615-0189-3_13]
   Chu YQ, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00680
   COLES MGH, 1989, PSYCHOPHYSIOLOGY, V26, P251, DOI 10.1111/j.1469-8986.1989.tb01916.x
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cozza F, 2020, SMART INNOV SYST TEC, V151, P107, DOI 10.1007/978-981-13-8950-4_11
   Crammond DJ, 2000, J NEUROPHYSIOL, V84, P986, DOI 10.1152/jn.2000.84.2.986
   DEECKE L, 1976, BIOL CYBERN, V23, P99, DOI 10.1007/BF00336013
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dohle C, 2009, NEUROREHAB NEURAL RE, V23, P209, DOI 10.1177/1545968308324786
   Doud AJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026322
   Eimer M, 1998, BEHAV RES METH INS C, V30, P146, DOI 10.3758/BF03209424
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hammon PS, 2008, IEEE SIGNAL PROC MAG, V25, P69, DOI 10.1109/MSP.2008.4408443
   Hastie T., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, DOI DOI 10.1007/978-0-387-84858-7
   Haw C.J., 2006, User Specific Template Matching for Event Detection Using Single Channel EEG
   Hazarika N, 1997, SIGNAL PROCESS, V59, P61, DOI 10.1016/S0165-1684(97)00038-8
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Hyvärinen A, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2011.0534
   Jasper H., 1949, Arch. F. uR. Psychiatr. Und Z. Neurol., V183, P163, DOI DOI 10.1007/BF01062488
   Jayaram V, 2016, IEEE COMPUT INTELL M, V11, P20, DOI 10.1109/MCI.2015.2501545
   Jiang N, 2015, CLIN NEUROPHYSIOL, V126, P154, DOI 10.1016/j.clinph.2014.05.003
   Jochumsen M, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/5/056015
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Karimi F, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00356
   KORNHUBER HH, 1965, PFLUG ARCH GES PHYS, V284, P1, DOI 10.1007/BF00412364
   Koza JR, 1996, ARTIFICIAL INTELLIGENCE IN DESIGN '96, P151
   Kropotov JD, 2016, FUNCTIONAL NEUROMARKERS FOR PSYCHIATRY: APPLICATIONS FOR DIAGNOSIS AND TREATMENT, P1
   Lew Eileen, 2012, Front Neuroeng, V5, P13, DOI 10.3389/fneng.2012.00013
   Li AS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116429
   Liao K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085192
   LIBET B, 1990, BEHAV BRAIN SCI, V13, P672, DOI 10.1017/S0140525X00080869
   LIBET B, 1983, ELECTROEN CLIN NEURO, V56, P367, DOI 10.1016/0013-4694(83)90262-6
   Loukas C, 2004, J NEUROSCI METH, V137, P193, DOI 10.1016/j.jneumeth.2004.02.017
   Loveless N E, 1974, Biol Psychol, V1, P303, DOI 10.1016/0301-0511(74)90005-2
   Lu MK, 2012, HUM BRAIN MAPP, V33, P824, DOI 10.1002/hbm.21248
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   McDermott EJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207326
   Meinel A, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00170
   Metsomaa J, 2014, J NEUROSCI METH, V228, P15, DOI 10.1016/j.jneumeth.2014.02.019
   Mitchell T. M, 1997, Mach Learn, V1
   Mohri M., 2012, Foundations of Machine Learning
   Morash V, 2008, CLIN NEUROPHYSIOL, V119, P2570, DOI 10.1016/j.clinph.2008.08.013
   Muller-Putz G., 2008, INT J BIOELECTROMAGN, V10, P52
   Niazi IK, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/6/066009
   Nunez P.L., 2006, Electric fields of the brain: The neurophysics of EEG, DOI DOI 10.1093/ACPROF:OSO/9780195050387.001.0001
   Ofner P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182578
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pereira J, 2017, NEUROIMAGE, V149, P129, DOI 10.1016/j.neuroimage.2017.01.030
   Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003
   Pfurtscheller G, 1998, ELECTROMYOGR MOTOR C, V109, P154, DOI 10.1016/S0924-980X(97)00070-2
   PFURTSCHELLER G, 1981, ELECTROEN CLIN NEURO, V51, P253, DOI 10.1016/0013-4694(81)90139-5
   PFURTSCHELLER G, 1979, ELECTROEN CLIN NEURO, V46, P138, DOI 10.1016/0013-4694(79)90063-4
   Pfurtscheller G., 1991, RHYTHMS PHYSL SYSTEM, P289, DOI [10.1007/978-3-642-76877-4_20, DOI 10.1007/978-3-642-76877-4_20]
   Planelles D, 2014, SENSORS-BASEL, V14, P18172, DOI 10.3390/s141018172
   Pudil P., 1998, FEATURE EXTRACTION C, P101, DOI DOI 10.1007/978-1-4615-5725-8_7
   Rohrbaugh J.W., 1983, Tutorials in ERP Research: Endogenous Components, P269
   Roy Rinku., 2012, Computing Communication Networking Technologies, P1
   Russell S., 2016, Artificial intelligence a modern approach
   Schmidt S, 2016, NEUROSCI BIOBEHAV R, V68, P639, DOI 10.1016/j.neubiorev.2016.06.023
   Schultze-Kraft M, 2017, SPRBRIEF ELECT, P79, DOI 10.1007/978-3-319-64373-1_8
   Schultze-Kraft M, 2016, P NATL ACAD SCI USA, V113, P1080, DOI 10.1073/pnas.1513569112
   Shakeel A, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/346217
   SHIBASAKI H, 1980, ELECTROEN CLIN NEURO, V49, P213, DOI 10.1016/0013-4694(80)90216-3
   Shibasaki H, 2006, CLIN NEUROPHYSIOL, V117, P2341, DOI 10.1016/j.clinph.2006.04.025
   Solopchuk O, 2016, J NEUROSCI, V36, P6599, DOI 10.1523/JNEUROSCI.1199-16.2016
   Tavakolan M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174161
   Toma K, 2002, NEUROIMAGE, V17, P161, DOI 10.1006/nimg.2002.1165
   Toni I, 2003, BEREITSCHAFTSPOTENTI, P269, DOI 10.1007/978-1-4615-0189-3_16
   Tzagarakis C, 2010, J NEUROSCI, V30, P11270, DOI 10.1523/JNEUROSCI.6026-09.2010
   Ulrich R, 1998, PSYCHOPHYSIOLOGY, V35, P721, DOI 10.1111/1469-8986.3560721
   VAUGHAN HG, 1968, ELECTROEN CLIN NEURO, V25, P1, DOI 10.1016/0013-4694(68)90080-1
   Velu PD, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00084
   Vuckovic A, 2008, MED BIOL ENG COMPUT, V46, P529, DOI 10.1007/s11517-008-0345-8
   Waldert S, 2008, J NEUROSCI, V28, P1000, DOI 10.1523/JNEUROSCI.5171-07.2008
   WALTER WG, 1964, NATURE, V203, P380, DOI 10.1038/203380a0
   Wierzgala P, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00078
   Wright DJ, 2011, J MOTOR BEHAV, V43, P193, DOI 10.1080/00222895.2011.557751
   Yavuzer G, 2008, ARCH PHYS MED REHAB, V89, P393, DOI 10.1016/j.apmr.2007.08.162
   Yuan GX, 2012, P IEEE, V100, P2584, DOI 10.1109/JPROC.2012.2188013
   Zrenner C, 2018, BRAIN STIMUL, V11, P374, DOI 10.1016/j.brs.2017.11.016
NR 92
TC 10
Z9 10
U1 6
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 347
EP 369
DI 10.1007/s10055-021-00538-x
EA SEP 2021
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000698575700001
PM 36915631
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mickiewicz, P
   Gawecki, W
   Gawlowska, MB
   Talar, M
   Wegrzyniak, M
   Wierzbicka, M
AF Mickiewicz, Patrycja
   Gawecki, Wojciech
   Gawlowska, Maria Bratumila
   Talar, Marcin
   Wegrzyniak, Magdalena
   Wierzbicka, Malgorzata
TI The assessment of virtual reality training in antromastoidectomy
   simulation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Surgery training; Medical sciences; Antromastoidectomy
   performance; Virtual education; Temporal bone; Simulation model
AB Virtual reality (VR) may be a good alternative for cadaveric temporal bone surgical dissection courses, which are an important part of otolaryngology resident's training. The aim of the study was to assess the VR temporal bone surgery simulator in an antromastoidectomy simulation. The VR system was based on the Geomagic Touch Haptic Device from 3D System. The research was designed as a prospective study, with three sessions of VR simulation training. The group of four ENT specialists unexperienced in otosurgery and 11 otorhinolaryngology residents performed a series of virtual dissections of a VR temporal bone model. Two experts with a broad experience in ear surgery participated in the study as supervisors for all the participants. At the end of each session, the experts controlled the accuracy of the simulated surgery performance assigning positive points for each correctly performed step and negative points for each mistake. After each session, participants of the study were asked to fill in the questionnaire concerning their impression of a VR system simulation. The evaluation of every simulation (total score) was based on the duration of a VR session, the quality of performance (positive points) and the number of mistakes (negative points). During consecutive VR sessions, evident shortening of the length of performance, as well as an improvement in the quality of performance and reduction in mistakes, was observed. Sixty percent of study participants answered that signaling damage to the critical elements was good (40%-sufficient), and 67% assessed that they had made a progress in consecutive sessions. After three sessions, 100% of participants indicated higher self-confidence in relation to their own surgical skills. Also, all the participants indicated that VR training should be included in a routine educational program for medical students. VR training provides a structured, safe and supportive environment to familiarize oneself with complex anatomy and practical skills.
C1 [Mickiewicz, Patrycja] WSB Univ, Dabrowa Gornicza, Poland.
   [Gawecki, Wojciech; Wegrzyniak, Magdalena; Wierzbicka, Malgorzata] Poznan Univ Med Sci, Dept Otolaryngol & Laryngol Oncol, Poznan, Poland.
   [Gawlowska, Maria Bratumila] Poznan Univ Med Sci, Poznan, Poland.
   [Gawlowska, Maria Bratumila; Talar, Marcin] Medicus Sp ZOO, Wroclaw, Poland.
   [Talar, Marcin] Pomeranian Med Univ, Szczecin, Poland.
C3 WSB University; Poznan University of Medical Sciences; Poznan University
   of Medical Sciences; Pomeranian Medical University
RP Mickiewicz, P (corresponding author), WSB Univ, Dabrowa Gornicza, Poland.
EM p.mickiewicz86@wp.pl
RI Gawecki, Wojciech/HGB-3688-2022
OI Gawecki, Wojciech/0000-0002-6174-9758; Wierzbicka,
   Malgorzata/0000-0003-0006-6352; Gawlowska, Maria/0000-0001-8063-8829;
   Mickiewicz, Patrycja/0000-0002-2624-1342; Talar,
   Marcin/0000-0001-6490-6395
CR Al-Noury K, 2012, INDIAN J OTOLARYNGOL, V64, P162, DOI 10.1007/s12070-011-0290-y
   American Board of Internal Medicine, 2010, PROC REQ INT MED
   Andersen SAW, 2015, LARYNGOSCOPE, V125, P431, DOI 10.1002/lary.24838
   Andersen SAW, 2019, EUR ARCH OTO-RHINO-L, V276, P3345, DOI 10.1007/s00405-019-05648-6
   Andersen SAW, 2016, JAMA OTOLARYNGOL, V142, P635, DOI 10.1001/jamaoto.2016.0454
   Eldred-Evans D, 2013, J SURG EDUC, V70, P544, DOI 10.1016/j.jsurg.2013.04.003
   European Political Strategy Centre, 2017, 10 TRENDS TRANSF ED
   Fernandez R, 2013, CRIT CARE MED, V41, P2551, DOI 10.1097/CCM.0b013e31829828f7
   Francis HW, 2012, LARYNGOSCOPE, V122, P1385, DOI 10.1002/lary.22378
   Ioannou I, 2017, OTOL NEUROTOL, V38, pE85, DOI 10.1097/MAO.0000000000001398
   Johnston TJ, 2013, WORLD J SURG, V37, P957, DOI 10.1007/s00268-013-1945-5
   Kashikar TS, 2019, LARYNGOSCOPE INVEST, V4, P420, DOI 10.1002/lio2.277
   Kerwin T, 2012, INT J COMPUT ASS RAD, V7, P1, DOI 10.1007/s11548-011-0566-4
   Khan MW, 2014, J SURG EDUC, V71, P79, DOI 10.1016/j.jsurg.2013.05.009
   Khemani S, 2012, OTOL NEUROTOL, V33, P1225, DOI 10.1097/MAO.0b013e31825e7977
   Morris D, 2006, IEEE COMPUT GRAPH, V26, P48, DOI 10.1109/MCG.2006.140
   Mulla M, 2012, J SURG EDUC, V69, P190, DOI 10.1016/j.jsurg.2011.07.011
   Nickel F, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000000764
   Nickel F, 2014, TRIALS, V15, DOI 10.1186/1745-6215-15-137
   O'Leary SJ, 2008, LARYNGOSCOPE, V118, P1040, DOI 10.1097/MLG.0b013e3181671b15
   Oestergaard J, 2012, BMC MED EDUC, V12, DOI 10.1186/1472-6920-12-7
   Pahuta Markian A, 2012, J Bone Joint Surg Am, V94, pe182, DOI 10.2106/JBJS.K.00996
   Piromchai P, 2014, Int J Clin Med, V5, P558, DOI DOI 10.4236/IJCM.2014.510077
   Poirrier AL, 2019, EVALUATION SURG SIMU
   Rafiq A, 2008, J SURG EDUC, V65, P270, DOI 10.1016/j.jsurg.2008.05.012
   Reddy-Kolanu G, 2011, ANN ROY COLL SURG, V93, P205, DOI 10.1308/003588411X565987
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Schroedl CJ, 2012, J CRIT CARE, V27, DOI 10.1016/j.jcrc.2011.08.006
   Sorensen MS, 2009, OTOL NEUROTOL, V30, P484, DOI 10.1097/MAO.0b013e3181a5299b
   Weiss PL, 2003, CYBERPSYCHOL BEHAV, V6, P335, DOI 10.1089/109493103322011650
   Wiet GJ, 2012, LARYNGOSCOPE, V122, pS1, DOI 10.1002/lary.22499
   Wiet Gregory J, 2009, J Grad Med Educ, V1, P61, DOI 10.4300/01.01.0010
   Wijewickrema S, 2018, LECT NOTES ARTIF INT, V10947, P584, DOI 10.1007/978-3-319-93843-1_43
   Wong D, 2014, J OTOLARYNGOL-HEAD N, V43, DOI 10.1186/s40463-014-0031-9
   Zhao YC, 2011, LARYNGOSCOPE, V121, P831, DOI 10.1002/lary.21287
   Zhao YC, 2011, OTOLARYNG HEAD NECK, V144, P357, DOI 10.1177/0194599810391624
   Zirkle M, 2007, LARYNGOSCOPE, V117, P258, DOI 10.1097/01.mlg.0000248246.09498.b4
NR 37
TC 7
Z9 7
U1 3
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1113
EP 1121
DI 10.1007/s10055-021-00516-3
EA APR 2021
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000636420700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Gutiérrez-Braojos, C
   Montejo-Gamez, J
   Marin-Jimenez, A
   Campaña, J
AF Gutierrez-Braojos, Calixto
   Montejo-Gamez, Jesus
   Marin-Jimenez, Ana
   Campana, Jesus
TI Hybrid learning environment: Collaborative or competitive learning?
SO VIRTUAL REALITY
LA English
DT Article
DE CSCL; SOLO taxonomy; Socio-cognitive conflict; Positive interdependence;
   Intergroup competition; Collaborative learning
ID CONFLICT; COOPERATION; ENGAGEMENT; STUDENTS; DESIGN; IMPACT
AB The aim of this study is to analyze the effect of different conditions of face-to-face learning on the participation and learning of students in the virtual community. In particular, we analyze the effect of collaboration vs intergroup competition learning on interdependence, regulation of socio-cognitive conflict, participation, and the quality of the contributions in a virtual learning platform. This study took place in an educational research course. The participants in the full investigation were 36 (94.44% females) undergraduates enrolled in the subject of educational research, which was part of a 4-year social education degree program. A Latin Squares design was applied to carry out the full investigation. The results show that conditions of collaboration without competition in face-to-face environments facilitate better quality of learning to a greater extent. In addition, there are no benefits of intergroup competition over individual competition learning. Thus, in this study, collaborative learning designs without any competition could be considered more consistent with the goal that underpins the main right to education: Each student is able to achieve what he has to achieve, taking advantage of the abilities of each and every agent in the learning community (teacher and students) to do so. These results are not consistent with previous studies. We suggest that characteristics of the sample could explain these differences between studies.
C1 [Gutierrez-Braojos, Calixto] Univ Granada, Fac Educ Sci, Dept Res Methods Educ, Campus Univ Cartuja S-N, Granada 18011, Spain.
   [Montejo-Gamez, Jesus] Univ Granada, Fac Educ Sci, Dept Math Educ, Campus Univ Cartuja S-N, Granada 18011, Spain.
   [Marin-Jimenez, Ana] Univ Granada, Fac Business Management, Dept Quantitat Methods, Campus Univ Cartuja S-N, Granada 18011, Spain.
   [Campana, Jesus] Univ Granada, High Sch Informat & Telecommun, Dept Comp Sci & Artificial Intelligence, Calle Periodista Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
C3 University of Granada; University of Granada; University of Granada;
   University of Granada
RP Gutiérrez-Braojos, C (corresponding author), Univ Granada, Fac Educ Sci, Dept Res Methods Educ, Campus Univ Cartuja S-N, Granada 18011, Spain.
EM calixtogb@ugr.es; jmontejo@ugr.es; anamarin@ugr.es;
   jesuscg@decsai.ugr.es
RI Campaña, Jesús R./L-9945-2018; Jiménez, Ana Eugenia Marín/Z-3057-2019;
   Gutiérrez-Braojos, Calixto/AAA-5342-2021
OI Jiménez, Ana Eugenia Marín/0000-0003-4170-4381; Gutiérrez-Braojos,
   Calixto/0000-0002-6901-2566
CR [Anonymous], 2002, 3 HELL C INF COMM TE
   [Anonymous], 2013, PSYCHOL SOCIALE CONN
   [Anonymous], 2001, GROUP CONSENSUMINO
   Arnab S, 2015, P INT GAM BUS C 21 2
   Baelo Alvarez R., 2009, Revista Iberoamericana de Educacion / Revista Ibero-americana de Educacao, V50, P1
   Baer M, 2010, ACAD MANAGE J, V53, P827, DOI 10.5465/AMJ.2010.52814611
   Basheri M, 2013, INT J ADV COMPUT SC, V4, P60
   Biggs J. B., 1982, Evaluating the quality of learning: The SOLO taxonomy
   Brown N., 2006, P 5 INT C NETW LEARN, P315
   Butera F., 2010, Rebels in Groups: Dissent, deviance, difference and defiance, P36, DOI DOI 10.1002/9781444390841.CH3
   Carter SP, 2017, ECON EDUC REV, V56, P118, DOI 10.1016/j.econedurev.2016.12.005
   Chen CH, 2016, COMPUT EDUC, V103, P99, DOI 10.1016/j.compedu.2016.09.007
   Commission E, 2015, ECTS US GUID
   Darnon C, 2006, J EDUC PSYCHOL, V98, P766, DOI 10.1037/0022-0663.98.4.766
   Deutsch M, 1949, HUM RELAT, V2, P129, DOI 10.1177/001872674900200204
   Deutsch Morton., 2006, PEACE PSYCHOL BOOK S, P23, DOI DOI 10.1007/978-1-4419-9994-8_2
   DOISE W, 1975, EUR J SOC PSYCHOL, V5, P367, DOI 10.1002/ejsp.2420050309
   Doise W., 1984, SOCIAL DEV INTELLECT
   Downing K, 2004, EDUC STUD-UK, V30, P265, DOI 10.1080/0305569042000224215
   Echeverría L, 2017, COMPUT APPL ENG EDUC, V25, P719, DOI 10.1002/cae.21832
   Fischer G, 2007, INT J COMP-SUPP COLL, V2, P9, DOI 10.1007/s11412-007-9009-1
   Garrison D. R., 2004, Internet and Higher Education, V7, P95, DOI 10.1016/j.iheduc.2004.02.001
   Ghaith GM., 2007, SYSTEM, V35, P229, DOI [10.1016/j.system.2006.11.003, DOI 10.1016/j.system.2006.11.003]
   Gutierrez-Braojos C, 2012, BUILDING KNOWLEDGE T
   Gutiérrez-Braojos C, 2015, INFANC APRENDIZ, V38, P327, DOI 10.1080/02103702.2015.1016746
   Hatzipanagos S., 2006, European Journal of Open, Distance and e-Learning
   Holmes K, 2005, AUST J EDUC DEV PSYC, V5, P117
   Inkpen K, 1995, PROCEEDINGS OF CSCL '95 - THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER SUPPORT FOR COLLABORATIVE LEARNING, P177, DOI 10.3115/222020.222164
   Johnson D.W., 1989, COOPERATION COMPETIT
   Johnson D.W., 1996, Meaningful and manageable assessment through cooperative learning
   Johnson D.W., 2004, HDB RES ED COMMUNICA, P785
   Johnson DW, 2005, GENET SOC GEN PSYCH, V131, P285, DOI 10.3200/MONO.131.4.285-358
   Ke FF, 2007, BRIT J EDUC TECHNOL, V38, P249, DOI 10.1111/j.1467-8535.2006.00593.x
   Koschmann T., 1996, CSCL, P1
   Lacasa P, 1993, INFANC APRENDIZ, V61, P5, DOI [10.1080/02103702.1993.108, DOI 10.1080/02103702.1993.10822362]
   Mehlenbacher B, 2010, INSTRUCTION TECHNOLO, P495
   MUGNY G, 1978, PSYCHOLOGIE, V37, P22
   MUGNY G, 1976, B PSYCHOL, V29, P199
   Mugny G., 1983, CONSTRUCCION SOCIAL
   Mugny G., 1984, Social interaction in individual development, P127
   Mugny G., 1998, CONNEXIONS, V72, P55
   Mugny G., 1978, Bulletin de Psychologie, V32, P979
   Neugebauer J, 2016, LEARN INSTR, V44, P41, DOI 10.1016/j.learninstruc.2016.02.007
   Regueras LM, 2009, IEEE T EDUC, V52, P279, DOI 10.1109/TE.2008.928198
   Scardamalia M., 2002, LIBERAL ED KNOWLEDGE, P67, DOI DOI 10.1046/J.1420-9101.1995.8050575.X
   Scardamalia M., 2004, CSILE/Knowledge forum. Education and technology: An encyclopedia, P183
   Schrire S, 2006, COMPUT EDUC, V46, P49, DOI 10.1016/j.compedu.2005.04.006
   Stahl G., 2006, Group cognition: Computer support for building collaborative knowledge
   Stahl G, 2006, CAMB HANDB PSYCHOL, P409
   Tauer JM, 2004, J PERS SOC PSYCHOL, V86, P849, DOI 10.1037/0022-3514.86.6.849
   Wang XH, 2017, COMPUT HUM BEHAV, V72, P140, DOI 10.1016/j.chb.2017.02.045
   Westbrook V, 2006, TEACH HIGH EDUC, V11, P471, DOI 10.1080/13562510600874276
   Yang SJH, 2007, EDUC TECHNOL SOC, V10, P84
   Yazici HJ, 2005, EDUC TRAIN, V47, P216, DOI 10.1108/00400910510592257
   Yu FY, 2008, CYBERPSYCHOL BEHAV, V11, P511, DOI 10.1089/cpb.2007.0171
   Yu FY, 2001, J EDUC COMPUT RES, V24, P99, DOI 10.2190/3U7R-DCD5-F6T1-QKRJ
NR 56
TC 11
Z9 13
U1 2
U2 44
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 411
EP 423
DI 10.1007/s10055-018-0358-z
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300008
DA 2024-07-18
ER

PT J
AU Sun, R
   Wu, YJ
   Cai, Q
AF Sun, Rui
   Wu, Yenchun Jim
   Cai, Qian
TI The effect of a virtual reality learning environment on learners'
   spatial ability
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); Event-related potential (ERP); Spatial ability;
   Cognitive load; Education
ID COGNITIVE LOAD; VISUALIZATIONS; INFORMATION; TECHNOLOGY; PERCEPTION;
   EXPERIENCE; INTERVAL; ODDBALL; TASKS; P300
AB This study employed electroencephalography to record event-related potentials to investigate the difference in learning performance between learners with different levels of spatial ability in a traditional learning environment that utilizes presentation slides and a learning environment that incorporates virtual reality (VR). Thirty-two university students participated in the experiment. The N1 and P2 components were results that indicated selective attention at an early stage; their amplitudes were proportional to the cognitive loads. The experiment results revealed that the main effect of learning environment was significant. The N1 and P2 components had larger amplitudes and indicated higher cognitive loads in the presentation slides-based environment than in the VR-based environment. The main effect of spatial ability was also significant. The N1 and P2 amplitudes evoked in the high spatial ability (HSA) learners were smaller than those evoked in the low spatial ability (LSA) learners, indicating that the LSA learners possessed fewer cognitive resources and bore relatively high cognitive loads. The interaction effect of learning environment and spatial ability was significant. Larger P2 amplitude was observed in LSA learners in the presentation slides-based environment than in the VR-based environment, implying that VR facilitates the reduction of cognitive loads in LSA learners. The P2 amplitude detected in HSA learners did not show any significant difference in both learning environments, indicating that the VR-based learning environment did not enhance their learning. This result supports the ability-as-compensator hypothesis to a certain extent.
C1 [Sun, Rui; Cai, Qian] Huaqiao Univ, Coll Business Adm, Quanzhou, Fujian, Peoples R China.
   [Sun, Rui] Huaqiao Univ, East Business Management Res Ctr, Quanzhou, Fujian, Peoples R China.
   [Wu, Yenchun Jim] Natl Taiwan Normal Univ, Taipei, Taiwan.
C3 Huaqiao University; Huaqiao University; National Taiwan Normal
   University
RP Wu, YJ (corresponding author), Natl Taiwan Normal Univ, Taipei, Taiwan.
EM 24891328@qq.com; wuyenchun@gmail.com; 964388634@qq.com
RI 吳, 書平/GXG-9770-2022
OI Wu, Yenchun/0000-0001-5479-2873
FU Ministry of Science and Technology, Taiwan [MOST 106-2511-S-003 -029
   -MY3]
FX Funding was provided by Ministry of Science and Technology, Taiwan
   (Grant No. MOST 106-2511-S-003 -029 -MY3).
CR [Anonymous], 2014, THESIS
   [Anonymous], 2014, THESIS
   Quintana MGB, 2015, COMPUT HUM BEHAV, V51, P594, DOI 10.1016/j.chb.2015.03.016
   Bell JT, 2004, IEEE, V2004, P27, DOI [10.1109/VR.2004.1310077, DOI 10.1109/VR.2004.1310077]
   Boucheix JM, 2009, LEARN INSTR, V19, P112, DOI 10.1016/j.learninstruc.2008.03.004
   Bricken M., 1991, Computer Graphics, V25, P178, DOI 10.1145/126640.126657
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Chen C. J., 2006, E J INSTRUCTIONAL SC, V9, P1
   Cheng K, 2009, PSYCHOL DEV ED, V25, P83
   Chia CC, 2017, INTERACT LEARN ENVIR, V7, P1, DOI [10.1080/10494820.2017.385488, DOI 10.1080/10494820.2017.385488]
   Christodoulou Y, 2016, INT J SEMANT WEB INF, V12, P100, DOI 10.4018/IJSWIS.2016040105
   Clark RE, 2014, MOD DISTANCE ED RES, V3, P52, DOI [10.1017/CBO9780511844744.012, DOI 10.1017/CBO9780511844744.012]
   David T, 2014, J NEURAL TRANSM, V122, P375, DOI [10.1007/s00702-01401258-3, DOI 10.1007/S00702-01401258-3]
   Eliot J, 2002, PERCEPT MOTOR SKILL, V94, P479
   Fan Y, 2008, NEUROPSYCHOLOGIA, V46, P160, DOI 10.1016/j.neuropsychologia.2007.07.023
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Gannouni S, 2017, INT J SEMANT WEB INF, V13, P55, DOI 10.4018/IJSWIS.2017040104
   Gonsalvez CJ, 2007, PSYCHOPHYSIOLOGY, V44, P245, DOI 10.1111/j.1469-8986.2007.00495.x
   Gurtubay IG, 2001, CLIN NEUROPHYSIOL, V112, P1219, DOI 10.1016/S1388-2457(01)00557-0
   HAWKINS D.-G., 1995, COMMUNICATION AGE VI, P159
   Hegarty M, 2008, LEARNING WITH ANIMATION: RESEARCH IMPLICATIONS FOR DESIGN, P3
   Heiling M., 1962, Sensorama Simulator
   Höffler TN, 2010, EDUC PSYCHOL REV, V22, P245, DOI 10.1007/s10648-010-9126-7
   Höffler TN, 2011, COMPUT HUM BEHAV, V27, P209, DOI 10.1016/j.chb.2010.07.042
   Horat SK, 2016, NEUROPSYCHOLOGIA, V82, P11, DOI 10.1016/j.neuropsychologia.2015.12.013
   Kalyuga S, 2003, EDUC PSYCHOL-US, V38, P23, DOI 10.1207/S15326985EP3801_4
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   LAVIE N, 1994, PERCEPT PSYCHOPHYS, V56, P183, DOI 10.3758/BF03213897
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Lee EAL, 2014, COMPUT EDUC, V79, P49, DOI 10.1016/j.compedu.2014.07.010
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Leite WL, 2010, EDUC PSYCHOL MEAS, V70, P323, DOI 10.1177/0013164409344507
   Liu TY, 2009, EDUC TECHNOL SOC, V12, P161
   Lytras MD, 2017, INT J SEMANT WEB INF, V13, P1, DOI 10.4018/IJSWIS.2017010101
   Mayer RE., 2001, Pain perception
   Meng J, 2013, NEUROIMAGE, V72, P164, DOI 10.1016/j.neuroimage.2013.01.024
   Merchant Z, 2013, J COMPUT ASSIST LEAR, V29, P579, DOI 10.1111/jcal.12018
   Münzer S, 2011, SPAT COGN COMPUT, V11, P281, DOI 10.1080/13875868.2011.571326
   Näätänen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   NISBETT RE, 1977, PSYCHOL REV, V84, P231, DOI 10.1037/0033-295X.84.3.231
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Plass JL, 2003, COMPUT HUM BEHAV, V19, P221, DOI 10.1016/S0747-5632(02)00015-8
   RIEBER LP, 1990, J EDUC PSYCHOL, V82, P135, DOI 10.1037/0022-0663.82.1.135
   RITTER W, 1969, SCIENCE, V164, P326, DOI 10.1126/science.164.3877.326
   Santangelo V, 2010, NEUROIMAGE, V49, P2717, DOI 10.1016/j.neuroimage.2009.10.061
   Shim KC, 2003, J BIOL EDUC, V37, P71, DOI 10.1080/00219266.2003.9655854
   Silver HarveyF., 2000, So Each May Learn: Integrating Learning Styles and Multiples Intelligences
   Strüber D, 2002, INT J PSYCHOPHYSIOL, V45, P187, DOI 10.1016/S0167-8760(02)00071-5
   Thurstone L.L., 1938, Primary Mental Abilities
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   Wei J., 2010, PRINCIPLE TECHNIQUE
   Wetter S, 2004, INT J PSYCHOPHYSIOL, V54, P263, DOI 10.1016/j.ijpsycho.2004.04.008
   WICKENS C, 1983, SCIENCE, V221, P1080, DOI 10.1126/science.6879207
   [辛勇 Xin Yong], 2010, [心理学报, Acta Psychologica Sinica], V42, P334
   [袁加锦 Yuan Jiajin], 2017, [中国科学. 生命科学, Scientia Sinica Vitae], V47, P1065
NR 55
TC 47
Z9 55
U1 5
U2 86
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 385
EP 398
DI 10.1007/s10055-018-0355-2
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300006
DA 2024-07-18
ER

PT J
AU Fountain, J
   Smith, SP
AF Fountain, Jake
   Smith, Shamus P.
TI Detecting rigid links between sensors for automatic sensor space
   alignment in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Tracking; Input devices; Calibration; Usability; Sensors
ID SIMULTANEOUS ROBOT-WORLD; ACTIVITY RECOGNITION; AM I; CALIBRATION;
   DISPLACEMENT; ROBUSTNESS
AB Simultaneous use of multiple sensor systems provides improved accuracy and tracking range compared to use of a single sensor system for virtual reality applications. However, calibration of multiple sensor technologies is non-trivial and at a minimum will require significant, and likely regular, user actioned calibration procedures. To enable ambient sensor calibration, we present techniques for automatically identifying relations between rigidly linked 6DoF and 3DoF sensors belonging to different sensor systems for body tracking. The techniques allow for subsequent automatic alignment of the sensor systems. Two techniques are presented, analysed in simulation for performance under varying noise and latency conditions, and are applied to two case studies. The first study identified sensors tracked by a gold standard rigid body tracker with one of six rigid bodies tracked by the first generation Kinect sensor with each sensor identified correctly in at least 76% of estimates. The second case study was an interactive version of the system that can detect a change in sensor configuration in 1-2s and only requires movements of less than 15cm or 90 degrees. Our methods represent a key step in creating highly accessible multi-device 3D virtual environments.
C1 [Fountain, Jake; Smith, Shamus P.] Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
C3 University of Newcastle
RP Smith, SP (corresponding author), Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
EM Jake.Fountain@uon.edu.au; Shamus.Smith@newcastle.edu.au
RI Smith, Shamus/HCI-0648-2022
OI Smith, Shamus/0000-0001-9135-1356
FU Australian Postgraduate Allowance Scholarship; Newcastle Robotics
   Laboratory at The University of Newcastle, Australia
FX This work was supported by an Australian Postgraduate Allowance
   Scholarship and the Newcastle Robotics Laboratory at The University of
   Newcastle, Australia.
CR [Anonymous], P 27 INT C ART REAL
   [Anonymous], 2010, ARMADILLO OPEN SOURC
   Bahle G, 2013, INT CONF PERVAS COMP, P409
   Baños O, 2012, IEEE INT SYM WRBL CO, P92, DOI 10.1109/ISWC.2012.17
   Calatroni A, 2010, METHODOLOGY USE UNKN
   Chavarriaga R, 2013, PERS UBIQUIT COMPUT, V17, P479, DOI 10.1007/s00779-011-0493-y
   Deng SJ, 2017, INT J HUM-COMPUT ST, V105, P68, DOI 10.1016/j.ijhcs.2017.04.002
   Destelle F, 2014, EUR SIGNAL PR CONF, P371
   Dornaika F, 1998, IEEE T ROBOTIC AUTOM, V14, P617, DOI 10.1109/70.704233
   Förster K, 2009, IEEE INT SYM WRBL CO, P77, DOI 10.1109/ISWC.2009.12
   Fountain J, 2016, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2016.7504710
   GOTTSCHALK S, 1993, P 20 ANN C COMP GRAP, P65
   Kai KZ, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P20, DOI 10.1145/1409635.1409639
   Kunze K, 2005, LECT NOTES COMPUT SC, V3479, P264, DOI 10.1007/11426646_25
   Kunze K, 2009, IEEE INT SYM WRBL CO, P149, DOI 10.1109/ISWC.2009.33
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lester J, 2004, LECT NOTES COMPUT SC, V3001, P33
   Li AG, 2010, INT J PHYS SCI, V5, P1530
   Moser K, 2015, IEEE T VIS COMPUT GR, V21, P491, DOI 10.1109/TVCG.2015.2391856
   Pearl T, 2012, THESIS
   Plopski A, 2015, IEEE T VIS COMPUT GR, V21, P481, DOI 10.1109/TVCG.2015.2391857
   Schapansky K, 2014, THESIS
   Shah M, 2013, J MECH ROBOT, V5, DOI 10.1115/1.4024473
   Shah M, 2011, COMPUT VIS IMAGE UND, V115, P1355, DOI 10.1016/j.cviu.2011.05.007
   ZHUANG HQ, 1994, IEEE T ROBOTIC AUTOM, V10, P549, DOI 10.1109/70.313105
NR 25
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 71
EP 84
DI 10.1007/s10055-018-0341-8
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500007
DA 2024-07-18
ER

PT J
AU Aissaoui, A
   Ouafi, A
   Pudlo, P
   Gillet, C
   Baarir, ZE
   Taleb-Ahmed, A
AF Aissaoui, Azeddine
   Ouafi, Abdelkrim
   Pudlo, Philippe
   Gillet, Christophe
   Baarir, Zine-Eddine
   Taleb-Ahmed, Abdelmalik
TI Designing a camera placement assistance system for human motion capture
   based on a guided genetic algorithm
SO VIRTUAL REALITY
LA English
DT Article
DE Multi-camera-based motion capture systems; Optimal camera
   configurations; Genetic algorithm; Optimization
AB In multi-camera motion capture systems, determining the optimal camera configuration (camera positions and orientations) is still an unresolved problem. At present, configurations are primarily guided by a human operator's intuition, which requires expertise and experience, especially with complex, cluttered scenes. In this paper, we propose a solution to automate camera placement for motion capture applications in order to assist a human operator. Our solution is based on the use of a guided genetic algorithm to optimize camera network placement with an appropriate number of cameras. In order to improve the performance of the genetic algorithm (GA), two techniques are described. The first is a distribution and estimation technique, which reduces the search space and generates camera positions for the initial GA population. The second technique is an error metric, which is integrated at GA evaluation level as an optimization function to evaluate the quality of the camera placement in a camera network. Simulation experiments show that our approach is more efficient than other approaches in terms of computation time and quality of the final camera network.
C1 [Aissaoui, Azeddine; Ouafi, Abdelkrim; Baarir, Zine-Eddine] Biskra Univ, LESIA Lab, BP 145 RP, Biskra 07000, Algeria.
   [Pudlo, Philippe; Gillet, Christophe; Taleb-Ahmed, Abdelmalik] UVHC, LAMIH, F-59313 Valenciennes, France.
   [Pudlo, Philippe; Gillet, Christophe; Taleb-Ahmed, Abdelmalik] CNRS, UMR 8201, F-59313 Valenciennes, France.
   [Pudlo, Philippe; Gillet, Christophe; Taleb-Ahmed, Abdelmalik] Univ Lille Nord France, F-59000 Lille, France.
C3 Universite Mohamed Khider Biskra; Centre National de la Recherche
   Scientifique (CNRS); Universite Polytechnique Hauts-de-France; Centre
   National de la Recherche Scientifique (CNRS); Universite Polytechnique
   Hauts-de-France; Universite de Lille
RP Aissaoui, A (corresponding author), Biskra Univ, LESIA Lab, BP 145 RP, Biskra 07000, Algeria.
EM aissaoui_azeddine@hotmail.fr
RI Azeddine, AISSAOUI/HOC-6248-2023
OI Azeddine, AISSAOUI/0009-0009-1943-4080
FU Franco-Algerian cooperation programme PHC TASSILI [12MDU876]
FX This research was supported by the Franco-Algerian cooperation programme
   PHC TASSILI (12MDU876) Grants. Entitled "Assistant System to the Cameras
   Location in the MOCAP'', the Project gathers members of Automatic
   Control and Human-Machine Systems of LAMIH Laboratory-Valenciennes
   University-France, and AISEL Laboratory-Biskra University-Algerie.
CR Aissaoui A, 2014, COMPUT METHOD BIOMEC, V17, P122, DOI 10.1080/10255842.2014.931517
   Al Hasan M, 2008, OPTIM LETT, V2, P99, DOI 10.1007/s11590-007-0046-5
   Angeline P.J., 1995, IEEE PROCEDEENG COMP, P152
   [Anonymous], 1987, ART GALLERY THEOREMS
   [Anonymous], P 4 ACM IEEE INT C D
   [Anonymous], MATL R2015A
   [Anonymous], BIONICS COMPUTATIONA
   [Anonymous], J CONVERG
   [Anonymous], 8 WORKSH OMN VIS CAM
   Bao SY, 2011, J HUM GENET, V56, P406, DOI 10.1038/jhg.2011.43
   Chen X, 2008, MACH VISION APPL, V19, P217, DOI 10.1007/s00138-007-0094-y
   CHVATAL V, 1975, J COMB THEORY B, V18, P39, DOI 10.1016/0095-8956(75)90061-1
   Ercan AO, 2006, LECT NOTES COMPUT SC, V4026, P389
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Gonzalez-Barbosa JJ, 2009, IEEE INT CONF ROBOT, P3672
   Horster E., 2006, P 4 ACM INT WORKSH V, P111
   Indu S, 2009, ICDSC 2009 3 ACMIEEE, P1
   Kita H, 2001, EVOL COMPUT, V9, P223, DOI 10.1162/106365601750190415
   LEE DT, 1986, IEEE T INFORM THEORY, V32, P276, DOI 10.1109/TIT.1986.1057165
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Mittal A, 2008, INT J COMPUT VISION, V76, P31, DOI 10.1007/s11263-007-0057-9
   Morsly Y, 2012, IEEE SENS J, V12, P1402, DOI 10.1109/JSEN.2011.2170833
   Olague G, 2002, PATTERN RECOGN, V35, P927, DOI 10.1016/S0031-3203(01)00076-0
   Piciarelli C., 2010, ACM/IEEE International Conference on Distributed Smart Cameras, P88, DOI DOI 10.1145/1865987.1866002
   Rahimian Pooya, 2015, P 21 ACM S VIRT REAL, P129, DOI [10.1145/2821592.2821596, DOI 10.1145/2821592.2821596]
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Yao Y, 2010, IEEE T SYST MAN CY B, V40, P101, DOI 10.1109/TSMCB.2009.2017507
   Zhao J, 2009, MULTI-CAMERA NETWORKS: PRINCIPLES AND APPLICATIONS, P139, DOI 10.1016/B978-0-12-374633-7.00006-9
   Zhao J, 2008, IEEE J-STSP, V2, P464, DOI 10.1109/JSTSP.2008.2001430
NR 30
TC 12
Z9 13
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 13
EP 23
DI 10.1007/s10055-017-0310-7
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200002
DA 2024-07-18
ER

PT J
AU Menzies, RJ
   Rogers, SJ
   Phillips, AM
   Chiarovano, E
   de Waele, C
   Verstraten, FAJ
   MacDougall, H
AF Menzies, R. J.
   Rogers, S. J.
   Phillips, A. M.
   Chiarovano, E.
   de Waele, C.
   Verstraten, F. A. J.
   MacDougall, H.
TI An objective measure for the visual fidelity of virtual reality and the
   risks of falls in a virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Postural sway; Virtual reality fidelity; Risk of falls; Safety
ID POSTURAL CONTROL; EXPERIENCE; SWAY
AB Despite decades of development of virtual reality (VR) devices and VR's recent renaissance, it has been difficult to measure these devices' effectiveness in immersing the observer. Previously, VR devices have been evaluated using subjective measures of presence, but in this paper, we suggest that postural stability can be used to objectively assess visual fidelity of VR headsets. We validated this measure by testing known differences between the devices. This study also aimed to determine the stability of healthy participants, while in a stable virtual world, compared to eyes-open and eyes-closed conditions and therefore provide a standard of safety requirements for future experimentation. Participants' ability to maintain a stable centre of pressure was measured using a Wii Balance Board, covered by a foam pad. Stability in eyes-open and eyes-closed conditions was compared with: (1) an iPod Touch in a simple Google cardboard style headset, (2) the Oculus Rift Development Kits (DK) DK1, DK2, with and without the tracking of linear head movements, and (3) the Samsung Gear VR. With a stable VR visual stimulus, the eyes-open condition allowed for significantly greater postural stability than the other conditions, which supports the validity of posturography as a measure of visual fidelity. Further, the iPod Touch, with its narrow field of view and rudimentary software, was significantly less effective at destabilising participants with visual perturbations than the other headsets, with their wider field of view and time warping. Unexpected results are discussed with respect to the possible limitations of the experimental design.
C1 [Menzies, R. J.; Rogers, S. J.; Phillips, A. M.; Verstraten, F. A. J.; MacDougall, H.] Univ Sydney, Sch Psychol, Sydney, NSW, Australia.
   [Chiarovano, E.; de Waele, C.] Ctr Etud Sensorimotricite, Paris, France.
C3 University of Sydney
RP Menzies, RJ (corresponding author), Univ Sydney, Sch Psychol, Sydney, NSW, Australia.
EM rmen9752@uni.sydney.edu.au
OI MacDougall, Hamish/0000-0001-6201-1707; Menzies,
   Rosemary/0000-0002-1894-5657; Chiarovano, Elodie/0000-0002-3738-0700
FU University of Sydney, School of Psychology (RIBG Pilot Project Grant);
   Garnett Passe and Rodney Williams Memorial Foundation
FX We gratefully acknowledge funding support from the University of Sydney,
   School of Psychology (RIBG Pilot Project Grant) and the Garnett Passe
   and Rodney Williams Memorial Foundation.
CR [Anonymous], PHYSL STIMUL CHARACT
   [Anonymous], THESIS
   [Anonymous], RTO M P 58 WHAT IS E
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   [Anonymous], SENSO PRESENZA NELLE
   [Anonymous], THESIS
   Blanks R H, 1996, J Am Acad Audiol, V7, P39
   Bronstein AM, 1997, EXP BRAIN RES, V113, P243, DOI 10.1007/BF02450322
   Chiarovano E, 2015, FRONT NEUROL, V6, DOI 10.3389/fneur.2015.00164
   Clark RA, 2010, GAIT POSTURE, V31, P307, DOI 10.1016/j.gaitpost.2009.11.012
   Czernuszenko M., 1997, Computer Graphics, V31, P46, DOI 10.1145/271283.271303
   DIENER HC, 1984, ELECTROEN CLIN NEURO, V57, P134, DOI 10.1016/0013-4694(84)90172-X
   Duarte M, 2010, BRAZ J PHYS THER, V14, P183, DOI 10.1590/S1413-35552010000300003
   ELLIOTT DB, 1995, OPHTHAL PHYSL OPT, V15, P553, DOI 10.1016/0275-5408(95)00025-9
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Goble DJ, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-12
   Goradia I., 2014, INT J CURRENT ENG TE, V4, P3196
   Khasnis A, 2003, J Postgrad Med, V49, P169
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   LaValle SM, 2014, IEEE INT CONF ROBOT, P187, DOI 10.1109/ICRA.2014.6906608
   Mark W. R., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P7, DOI 10.1145/253284.253292
   NASHNER LM, 1982, J NEUROSCI, V2, P536
   Niven J I, 1966, Acta Otolaryngol, V62, P429, DOI 10.3109/00016486609119587
   Prieto TE, 1996, IEEE T BIO-MED ENG, V43, P956, DOI 10.1109/10.532130
   Riemann BL, 1999, J SPORT REHABIL, V8, P71, DOI 10.1123/jsr.8.2.71
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Simoneau M, 1999, J AM GERIATR SOC, V47, P235, DOI 10.1111/j.1532-5415.1999.tb04584.x
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2009, ANU PSICOL, V40, P193
   Takatalo J, 2008, COMPUT HUM BEHAV, V24, P1, DOI 10.1016/j.chb.2006.11.003
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vouriot A, 2004, NEUROSCI RES, V48, P239, DOI 10.1016/j.neures.2003.11.001
   Winter DA, 2009, BIOMECHANICS MOTOR C, DOI [10.1002/9780470549148, DOI 10.1002/9780470549148]
NR 33
TC 29
Z9 30
U1 0
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2016
VL 20
IS 3
BP 173
EP 181
DI 10.1007/s10055-016-0288-6
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DV0XZ
UT WOS:000382645300003
DA 2024-07-18
ER

PT J
AU Ishikawa, T
   Thangamani, K
   Kourogi, M
   Gee, AP
   Mayol-Cuevas, W
   Hyun, J
   Kurata, T
AF Ishikawa, Tomoya
   Thangamani, Kalaivani
   Kourogi, Masakatsu
   Gee, Andrew P.
   Mayol-Cuevas, Walterio
   Hyun, Jungwoo
   Kurata, Takeshi
TI Interactive 3-D indoor modeler for virtualizing service fields
SO VIRTUAL REALITY
LA English
DT Article
DE Interaction; 3-D indoor model; Service field; Augmented virtuality
AB This paper describes an interactive 3-D indoor modeler that effectively creates photo-realistic 3-D indoor models from multiple photographs. This modeler supports the creation of 3-D models from photographs by implementing interaction techniques that use geometric constraints estimated from photographs and visualization techniques that help to easily understand shapes of 3-D models. We evaluated the availability and usability by applying the modeler to model service fields where actual workers provide services and an experience-based exhibit. Our results confirmed that the modeler enables the creation of large-scale indoor environments such as hot-spring inns and event sites at a relatively modest cost. We also confirmed that school children could learn modeling operations and create 3-D models from a photograph for approximately 20 min because of the easy operations. In addition, we describe additional functions that increase the effectiveness of 3-D modeling based on knowledge from service-field modeling. We present applications for behavior analysis of service workers and for 3-D indoor navigation using augmented virtuality (AV)-based visualization realized by photo-realistic 3-D models.
C1 [Ishikawa, Tomoya; Thangamani, Kalaivani; Kourogi, Masakatsu; Hyun, Jungwoo; Kurata, Takeshi] Natl Inst Adv Ind Sci & Technol, Ctr Serv Res, AIST Tsukuba Cent 2, Tsukuba, Ibaraki 3058568, Japan.
   [Gee, Andrew P.; Mayol-Cuevas, Walterio] Univ Bristol, Bristol BS8 1UB, Avon, England.
C3 National Institute of Advanced Industrial Science & Technology (AIST);
   University of Bristol
RP Ishikawa, T (corresponding author), Natl Inst Adv Ind Sci & Technol, Ctr Serv Res, AIST Tsukuba Cent 2, 1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.
EM tomoya-ishikawa@aist.go.jp; thangamani.kalaivani@aist.go.jp;
   m.kourogi@aist.go.jp; gee@cs.bris.ac.uk; wmayol@cs.bris.ac.uk;
   jw.hyun@aist.go.jp; t.kurata@aist.go.jp
RI Mayol-Cuevas, Walterio/AAD-6590-2019; Kourogi, Masakatsu/P-5068-2016;
   Kurata, Takeshi/N-4998-2016
OI Mayol-Cuevas, Walterio/0000-0001-8973-1931; Kurata,
   Takeshi/0000-0002-6380-2823
CR Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bunnun P, 2008, INT SYM MIX AUGMENT, P61, DOI 10.1109/ISMAR.2008.4637325
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furukawa Y, 2009, IEEE I CONF COMP VIS, P80, DOI 10.1109/ICCV.2009.5459145
   Gee AP, 2008, IEEE T ROBOT, V24, P980, DOI 10.1109/TRO.2008.2004641
   Goesele M., 2007, P INT C COMP VIS ICC, P14
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Ishikawa Tomoya, 2011, International Journal of Organizational and Collective Intelligence, V2, P1, DOI 10.4018/joci.20.1010101
   Kitajima M, 2010, P ANN M HUM FACT ERG
   Kourogi M, 2006, LECT NOTES COMPUT SC, V4282, P1310
   Kurata Takeshi, 2010, 2010 8th IEEE International Conference on Industrial Informatics (INDIN 2010), P967, DOI 10.1109/INDIN.2010.5549612
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Neubert J., 2007, P IEEE ACM INT S MIX, P79
   Oh BM, 2001, COMP GRAPH, P433
   OH JY, 2005, P EUR WORKSH SKETCH, P81
   Simon G, 2010, P EUR
   Sinha SN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409112
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   van den Hengel A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239537, 10.1145/1276377.1276485]
   van den Hengel A, 2009, INT SYM MIX AUGMENT, P107, DOI 10.1109/ISMAR.2009.5336482
   Williams L., 1978, P ANN C COMP GRAPH I, P270
NR 24
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2013
VL 17
IS 2
SI SI
BP 89
EP 109
DI 10.1007/s10055-011-0202-1
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 139IH
UT WOS:000318575200001
DA 2024-07-18
ER

PT J
AU Zhu, WJ
   Vader, AM
   Chadda, A
   Leu, MC
   Liu, XQF
   Vance, JB
AF Zhu, Wenjuan
   Vader, Anup M.
   Chadda, Abhinav
   Leu, Ming C.
   Liu, Xiaoqing F.
   Vance, Jonathan B.
TI Wii remote-based low-cost motion capture for automated assembly
   simulation
SO VIRTUAL REALITY
LA English
DT Article
DE Wii remote; Low cost; Motion capture; Hybrid camera calibration
   algorithm; Assembly simulation
ID CALIBRATION
AB This paper describes the development of a Wii remote (Wiimote)-based low-cost motion capture system and demonstrates its application for automated assembly simulation. Multiple Wiimotes are used to form a vision system to perform motion capture in 3D space. A hybrid algorithm for calibrating a multi-camera stereo vision system has been developed based on Zhang's and Svoboda's calibration algorithms. This hybrid algorithm has been evaluated and shown accuracy improvement over Svoboda's algorithm for motion capture with multiple cameras. The captured motion data are used to automatically generate an assembly simulation of objects represented by CAD models in real time. The Wiimote-based motion capture system is practically attractive because it is inexpensive, wireless, and easily portable. Application examples have been developed for a single vision system with two Wiimotes to track the assembly of a microsatellite prototype frame and for an integrated vision system with four Wiimotes to track the assembly of a bookshelf.
C1 [Zhu, Wenjuan; Leu, Ming C.; Liu, Xiaoqing F.] Missouri Univ Sci & Technol, Rolla, MO USA.
   [Vader, Anup M.] Caterpillar Inc, Mossville, IL USA.
   [Chadda, Abhinav] Salesforce Com, San Francisco, CA USA.
   [Vance, Jonathan B.] Boeing Res & Technol, St Louis, MO USA.
C3 University of Missouri System; Missouri University of Science &
   Technology; Caterpillar Inc; Salesforce; Boeing
RP Zhu, WJ (corresponding author), Missouri Univ Sci & Technol, Rolla, MO USA.
EM zhuwe@mst.edu; Vader_Anup@cat.com; abhinavchadda@gmail.com;
   mleu@mst.edu; fliu@mst.edu; Jonathan.B.Vance@boeing.com
FU Center for Aerospace Manufacturing Technologies (CAMT) through Air Force
   Research Laboratory [FA8650-04-C-5704]; Boeing; Spirit AeroSystems; GKN
   Aerospace; Bell Helicopters; Rolls Royce; Siemens; KMT Waterjet; Product
   Innovation and Engineering; Steelville Manufacturing
FX The authors would like to acknowledge the financial support for this
   research from the Center for Aerospace Manufacturing Technologies (CAMT)
   through Air Force Research Laboratory contract FA8650-04-C-5704 and the
   CAMT Industrial Consortium whose members include Boeing, Spirit
   AeroSystems, GKN Aerospace, Bell Helicopters, Rolls Royce, Siemens, KMT
   Waterjet, Product Innovation and Engineering, and Steelville
   Manufacturing.
CR [Anonymous], EUR C COMP VIS ECCV
   Baggett P., 1991, INT J IND ERGONOM, V7, P217
   Bouguet J., 2010, CAMERA CALIBRATION T
   Chen C, 2000, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.2000.854901
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hay S, 2008, P IEEE ACM INT S MIX
   Heikkila J., 1997, IEEE COMP SOC C COMP
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   iotracker, 2011, ADV OPT MOT TRACK
   Kibira D, 2002, PROCEEDINGS OF THE 2002 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1130, DOI 10.1109/WSC.2002.1166368
   Lee J., 2007, HEAD TRACKING DESKTO
   Martinec D, 2002, LECT NOTES COMPUT SC, V2351, P355
   Melen T, 1994, THESIS I TEKNISK KYB
   NaturalPoint, 2011, OPTITRACK
   PhaseSpace, 2011, PHASESPACE OPT MOT C
   PINTARIC T, 2007, P TRENDS ISS TRACK V
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Tsai R.Y., 1986, P IEEE C COMPUTER VI, P364
   Vicon, 2011, VIC MOT SYST
   Wang W, 2008, INT ARCH PHOTOGRAMME, VXXXVII
   Wengert C, 2008, IMPLEMENTATION CLOSE
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zollner H, 2004, P 28 WORKSH AUSTR AS, P234
NR 24
TC 6
Z9 7
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2013
VL 17
IS 2
SI SI
BP 125
EP 136
DI 10.1007/s10055-011-0204-z
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 139IH
UT WOS:000318575200003
DA 2024-07-18
ER

PT J
AU Bouras, C
   Giannaka, E
   Tsiatsos, T
AF Bouras, Christos
   Giannaka, Eri
   Tsiatsos, Thrasyvoulos
TI Performance improvement of Distributed Virtual Environments by
   exploiting objects' attributes
SO VIRTUAL REALITY
LA English
DT Article
DE Distributed virtual environments; Load balancing; VR techniques and
   systems
ID SYSTEMS
AB Distributed virtual environments need to address issues related to the control of network traffic, resource management, and scalability. Given the distributed nature of these environments, the main problems they need to overcome are the efficient distribution of workload among the servers and the minimization of the communication cost. In this direction, a lot of work has been done and numerous relevant techniques and algorithms have been proposed. The majority of these approaches mainly focus on user entities and their interactions. However, most of actual DVE systems include additional and non-dynamic elements, denoted as objects, whose presence can affect users' behavior. This paper introduces virtual objects' attributes and proposes two approaches that exploit these attributes in order to handle workload assignment and communication cost in DVE systems. Both approaches take into account scenario-specific aspects of DVE systems, such as the impact that entities' attributes have on each other and the way this impact can affect the system's state. These scenario-specific aspects are then combined with quantitative factors of the system, such as workload, communication cost, and utilization. The experiments conducted in order to validate the behavior of the proposed approach show that the incorporation of object's presence can improve the DVE system's performance. More specifically, objects' presence and their attributes can assist in the significant reduction in the communication cost along with effective workload distribution among the system's servers.
C1 [Bouras, Christos] Univ Patras, Res Acad Comp Technol Inst, Patras 26500, Greece.
   [Bouras, Christos] Univ Patras, Comp Engn & Informat Dept, Patras 26500, Greece.
   [Giannaka, Eri] Athens Informat Technol, Athens 19002, Greece.
   [Tsiatsos, Thrasyvoulos] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 University of Patras; University of Patras; Aristotle University of
   Thessaloniki
RP Bouras, C (corresponding author), Univ Patras, Res Acad Comp Technol Inst, N Kazantzaki Str, Patras 26500, Greece.
EM bouras@cti.gr; elgi@ait.gr; tsiatsos@csd.auth.gr
RI Tsiatsos, Thrasyvoulos/W-5386-2019
OI Tsiatsos, Thrasyvoulos/0000-0002-4946-9585
CR BEATRICE N, 2002, P ACM S VIRT REAL SO
   Bouras C, 2009, P 2 INT C SIM TOOLS
   Chen Jin., 2005, PPOPP 05, P289
   Chertov R., 2006, P 16 ACM INT WORKSH, P74
   De Vleeschauwer B, 2005, P NETG 2005 NEW YORK
   DIS Steering Committee, 1998, IEEE STAND DISTR INT, DOI [10.1109/IEEESTD.1998.88572, DOI 10.1109/IEEESTD.1998.88572]
   Frécon E, 2001, PRESENCE-TELEOP VIRT, V10, P109, DOI 10.1162/105474601750182351
   Henderson T., 2003, Proceedings of the ACM SIGCOMM 2003, P141
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   LIU G., 1996, MOBILE NETW APPL, V1, P113, DOI DOI 10.1007/BF01193332
   Lui JCS, 2002, IEEE T PARALL DISTR, V13, P193, DOI 10.1109/71.993202
   MACEDONIA MR, 1995, P VIRT REAL ANN INT
   McCoy A, 2004, P INT C COMP GAM ART
   Morillo P, 2005, IEEE T PARALL DISTR, V16, P637, DOI 10.1109/TPDS.2005.83
   Morillo P, 2003, P 14 JORN PAR MADR S, P299
   MORILLO P, 2003, P EUR C PAR PROC EUR
   Morillo P, 2007, IEEE T PARALL DISTR, V18, P1215, DOI 10.1109/TPDS.2007.1055
   Schroeder R, 2006, PRESENCE-VIRTUAL AUG, V15, P655, DOI 10.1162/pres.15.6.655
   Shirmohammadi S, 2008, SIMUL-T SOC MOD SIM, V84, P215, DOI 10.1177/0037549708092832
   Tam PT, 1998, D91 SECURESCM
   Varvello M., 2008, P 2008 ACM CONEXT C, P1
   Verdickt T, 2007, CGAMES'2007: PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES: AI, ANIMATION, MOBILE, EDUCATIONAL AND SERIOUS GAMES, P92
NR 22
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2012
VL 16
IS 3
BP 187
EP 203
DI 10.1007/s10055-011-0198-6
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 990MV
UT WOS:000307635900002
DA 2024-07-18
ER

PT J
AU Ajanki, A
   Billinghurst, M
   Gamper, H
   Järvenpää, T
   Kandemir, M
   Kaski, S
   Koskela, M
   Kurimo, M
   Laaksonen, J
   Puolamäki, K
   Ruokolainen, T
   Tossavainen, T
AF Ajanki, Antti
   Billinghurst, Mark
   Gamper, Hannes
   Jarvenpaa, Toni
   Kandemir, Melih
   Kaski, Samuel
   Koskela, Markus
   Kurimo, Mikko
   Laaksonen, Jorma
   Puolamaki, Kai
   Ruokolainen, Teemu
   Tossavainen, Timo
TI An augmented reality interface to contextual information
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Gaze tracking; Information retrieval; Machine
   learning; Pattern recognition
ID EYE-MOVEMENTS; GAZE
AB In this paper, we report on a prototype augmented reality (AR) platform for accessing abstract information in real-world pervasive computing environments. Using this platform, objects, people, and the environment serve as contextual channels to more information. The user's interest with respect to the environment is inferred from eye movement patterns, speech, and other implicit feedback signals, and these data are used for information filtering. The results of proactive context-sensitive information retrieval are augmented onto the view of a handheld or head-mounted display or uttered as synthetic speech. The augmented information becomes part of the user's context, and if the user shows interest in the AR content, the system detects this and provides progressively more information. In this paper, we describe the first use of the platform to develop a pilot application, Virtual Laboratory Guide, and early evaluation results of this application.
C1 [Ajanki, Antti; Kandemir, Melih; Koskela, Markus; Kurimo, Mikko; Laaksonen, Jorma; Ruokolainen, Teemu] Aalto Univ, Dept Informat & Comp Sci, Espoo, Finland.
   [Gamper, Hannes; Puolamaki, Kai; Tossavainen, Timo] Aalto Univ, Dept Media Technol, Espoo, Finland.
   [Billinghurst, Mark] Univ Canterbury, HIT Lab NZ, Christchurch 1, New Zealand.
   [Jarvenpaa, Toni] Nokia Res Ctr, Tampere, Finland.
   [Kaski, Samuel] Aalto Univ, Helsinki, Finland.
   [Kaski, Samuel] Univ Helsinki, Helsinki Inst Informat Technol HIIT, Helsinki, Finland.
C3 Aalto University; Aalto University; University of Canterbury; Nokia
   Corporation; Nokia Finland; Siemens AG; Nokia Siemens Networks; Aalto
   University; University of Helsinki; Aalto University
RP Ajanki, A (corresponding author), Aalto Univ, Dept Informat & Comp Sci, Espoo, Finland.
EM antti.ajanki@tkk.fi; mark.billinghurst@canterbury.ac.nz;
   hannes.gamper@tkk.fi; toni.jarvenpaa@nokia.com; melih.kandemir@tkk.fi;
   samuel.kaski@tkk.fi; markus.koskela@tkk.fi; mikko.kurimo@tkk.fi;
   jorma.laaksonen@tkk.fi; kai.puolamaki@tkk.fi; teemu.ruokolainen@tkk.fi;
   timo.tossavainen@tkk.fi
RI Kurimo, Mikko/F-6647-2012; Kandemir, Melih/AAT-7435-2021; Kaski,
   Samuel/B-6684-2008; Billinghurst, Mark/AAJ-4236-2020; Gamper,
   Hannes/E-7576-2012; Puolamäki, Kai/C-9016-2017; Koskela,
   Markus/O-4165-2016; Laaksonen, Jorma/Q-1307-2016
OI Kaski, Samuel/0000-0003-1925-9154; Billinghurst,
   Mark/0000-0003-4172-6759; Puolamäki, Kai/0000-0003-1819-1047; Laaksonen,
   Jorma/0000-0001-7218-3131; Kandemir, Melih/0000-0001-6293-3656
FU Aalto MIDE programme (project UI-ART); Finnish Funding Agency for
   Technology and Innovation (TEKES); PASCAL2 Network of Excellence [ICT
   216886]
FX Antti Ajanki, Melih Kandemir, Samuel Kaski, Markus Koskela, Mikko
   Kurimo, Jorma Laaksonen, Kai Puolamaki, and Teemu Ruokolainen belong to
   Adaptive Informatics Research Centre at Aalto University, Antti Ajanki,
   Melih Kandemir, Samuel Kaski, and Kai Puolamaki to Helsinki Institute
   for Information Technology HIIT, and Kai Puolamaki to the Finnish Centre
   of Excellence in Algorithmic Data Analysis. This work has been funded by
   Aalto MIDE programme (project UI-ART) and in part by Finnish Funding
   Agency for Technology and Innovation (TEKES) under the project DIEM/MMR
   and by the PASCAL2 Network of Excellence, ICT 216886.
CR Ajanki A, 2009, USER MODEL USER-ADAP, V19, P307, DOI 10.1007/s11257-009-9066-4
   [Anonymous], 2009, ICMI MLMI
   [Anonymous], 1991, CMUCS91132 CARN MELL
   [Anonymous], 1997, Proceedings of the fifth conference on Applied natural language processing - ANLC'97, P20
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baillot Y, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P39, DOI 10.1109/ISWC.2001.962094
   Bee N, 2008, LECT NOTES ARTIF INT, V5078, P111, DOI 10.1007/978-3-540-69369-7_13
   BRZEZOWSKI S, 1996, SPIE SURVEILLANCE AS, P24
   Crestani F, 2007, INFORM RETRIEVAL, V10, P111, DOI 10.1007/s10791-007-9022-z
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Farringdon J, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P167, DOI 10.1109/ISWC.2000.888484
   HAHN D, 2005, INT C INF CONTR AUT, P146
   Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009
   HENDRICKSEN K, 2002, P 1 INT C PERV COMP, P167
   Henrysson A., 2004, Proceedings of the 3rd international conference on Mobile and ubiquitous multimedia, P41, DOI [10.1145/1052380.1052387, DOI 10.1145/1052380.1052387]
   Hirsimäki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   HOLLERER T., 1997, ISWC 97, P208, DOI DOI 10.1007/BF01682023
   Hyrskykari Aulikki, 2000, P 2000 S EYE TRACKIN, P9, DOI DOI 10.1145/355017.355019
   Iordanoglou C, 2000, INT CONF ACOUST SPEE, P2365, DOI 10.1109/ICASSP.2000.859316
   *ISO IEC, 2002, 1593832002E ISOIEC
   JARVENPAA T, 2008, P SOC PHOTO-OPT INS, V7001
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Julier S, 2002, IEEE COMPUT GRAPH, V22, P12, DOI 10.1109/MCG.2002.1028721
   Julier S, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P3, DOI 10.1109/ISAR.2000.880917
   KANDEMIR M, 2010, ETRA 2010, P105
   Klein G, 2008, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2008.4637324
   Klein George, 2007, P1
   Land MF, 2006, PROG RETIN EYE RES, V25, P296, DOI 10.1016/j.preteyeres.2006.01.002
   Lee R, 2009, INT CONF NEXT GEN, P58, DOI 10.1109/NGMAST.2009.90
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Nilsson S, 2009, PSYCHNOLOGY J, V7, P175
   OYEKOYA O, 2006, INT WORKSH INT COMP, P281
   PARK HM, 2008, P MIXER 08 CAMBR UK, P175, DOI DOI 10.1109/ISMAR.2008.4637353
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Pentland AlexP., 1998, Wearable intelligence
   PFEIFFER T, 2008, J VIRTUAL REAL BROAD, V5
   Puolamaki K., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P146, DOI 10.1145/1076034.1076062
   Pylvanainen T., 2008, P 18 INT C ART REAL, P5
   Qvarfordt P., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, New York, NY, USA, P221
   RAUHALA M, 2006, HCI 06, P145, DOI DOI 10.1145/1152215.1152245
   Rebman CM, 2003, INFORM MANAGE-AMSTER, V40, P509, DOI 10.1016/S0378-7206(02)00067-8
   Rekimoto J, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P68, DOI 10.1109/ISWC.1998.729531
   Singletary Bradley, 2001, PROC HUMAN COMPUTER, P813
   Starner T., 1997, PRESENCE-TELEOP VIRT, V6, P452
   SUN Y, 2008, CHI 2008 HUM FACT CO, P3483
   Tanriverdi V., 2000, Proceedings of the SIGCHI conference on human factors in computing systems, P272
   Turpin A., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P11, DOI 10.1145/1148170.1148176
   Vertegaal R., 2002, Proceedings of the 2002 symposium on eye tracking research applications, P30
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang H, 2008, P IEEE C COMP COMM I, P1382
   Ward DJ, 2002, NATURE, V418, P838, DOI 10.1038/418838a
   YAMAGISHI J, 2009, P 10 ANN C INT SPEEC
   Yap KK, 2005, P 3 INT C EMB NETW S, P166
NR 53
TC 36
Z9 47
U1 0
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 161
EP 173
DI 10.1007/s10055-010-0183-5
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200007
DA 2024-07-18
ER

PT J
AU White, SA
   Prachyabrued, M
   Chambers, TL
   Borst, CW
   Reiners, D
AF White, Steven A.
   Prachyabrued, Mores
   Chambers, Terrence L.
   Borst, Christoph W.
   Reiners, Dirk
TI Low-cost simulated MIG welding for advancement in technical training
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Welding; Finite difference; Simulation; Acoustics
AB The simulated MIG lab (sMIG) is a training simulator for Metal Inert Gas (MIG) welding. It is based on commercial off the shelf (COTS) components and targeted at familiarizing beginning students with the MIG equipment and best practices to follow to become competent and effective MIG welders. To do this, it simulates the welding process as realistically as possible using standard welding hardware components (helmet, gun) for input and by using head-tracking and a 3D-capable low-cost monitor and standard speakers for output. We developed a simulation to generate realistic audio and visuals based on numerical heat transfer methods and verified the accuracy against real welds. sMIG runs in real time producing a realistic, interactive, and immersive welding experience while maintaining a low installation cost. In addition to being realistic, the system provides instant feedback beyond what is possible in a traditional lab. This help students avoid learning (and unlearning) incorrect movement patterns.
C1 [White, Steven A.; Prachyabrued, Mores; Chambers, Terrence L.; Borst, Christoph W.; Reiners, Dirk] Univ Louisiana Lafayette, Lafayette, LA 70506 USA.
C3 University of Louisiana Lafayette
RP White, SA (corresponding author), Univ Louisiana Lafayette, 537 Cajundome Blvd, Lafayette, LA 70506 USA.
EM saw7186@cacs.louisiana.edu
RI Chambers, Terrence/AAC-8259-2019
CR *3D GAM STUD, 2009, CON DAT 1
   AGLAWE A, 2008, THESIS U LOUISIANA L
   Aiteanu D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P309, DOI 10.1109/ISMAR.2003.1240734
   Chan B, 1999, CAN METALL QUART, V38, P43, DOI 10.1016/S0008-4433(98)00037-8
   Chu YX, 2004, WELD J, V83, p336S
   Cudina M, 2003, P I MECH ENG C-J MEC, V217, P483, DOI 10.1243/095440603765226777
   *ESAB GROUP I, 2000, LESS 2 COMM EL WELD
   Fast K, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P298, DOI 10.1109/ISMAR.2004.65
   Hermans MJM, 1999, WELD J, V78, p137S
   JONES AL, 1997, 9 ANN C IR STEEL TEC
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kim IS, 1998, J MATER PROCESS TECH, V77, P17, DOI 10.1016/S0924-0136(97)00383-X
   Kobayashi K., 2001, In Int. Conf. Artif. Real Telexistence, P175
   KUMAR S, 1994, METALL MATER TRANS B, V25, P435, DOI 10.1007/BF02663394
   Mansoor A.M., 1999, Ninth International Conference on Computer Technology in Welding, P312
   Martin B.K. J., 2005, International Conference on Computer Simulation in Information and Communication Engineering, P20
   Mavrikios D, 2006, INT J COMPUT INTEG M, V19, P294, DOI 10.1080/09511920500340916
   Parker JR, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P317
   Patankar S., 1980, NUMERICAL HEAT TRANS
   Porter N.C., 2006, Journal of Ship Production, V22, P126
   *SYST C, 2009, CS WAV VIRT WELD TRA
   Tschirner P, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P257, DOI 10.1109/ISMAR.2002.1115098
   Wang YZ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P954, DOI 10.1109/ROBIO.2006.340349
   WORMELL D, 2003, EUR WORKSH VIRT ENV, P47
NR 24
TC 8
Z9 59
U1 1
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2011
VL 15
IS 1
SI SI
BP 69
EP 81
DI 10.1007/s10055-010-0162-x
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HZ
UT WOS:000296280000006
DA 2024-07-18
ER

PT J
AU Coelho, RC
   Calonego, N
   Consularo, LA
AF Coelho, Regina Celia
   Calonego, Nivaldi, Jr.
   Consularo, Luis Augusto
TI Visualization and simulation of 3D artificial neural structures
   generated by L-system
SO VIRTUAL REALITY
LA English
DT Article
DE L-system; Stochastic L-system; Neural growth; Neural simulation; Virtual
   reality environment; Collaborative environments
ID DENDRITIC COMPETITION; MORPHOLOGY; MODELS; TOOL
AB This paper presents the visualization and simulation environment of 3D artificial neural structures. A stochastic L-system has been employed to generate neural structures based on features extracted from natural cells and it takes into account an hierarchical description of each neurite to allow interactions of the users in the virtual environment built. The implemented distributed virtual reality environment has its architecture explained, as well as its user interaction features to handle virtual neural structures. Furthermore, attraction/repulsion trophic fields had their effects simulated into these virtual neural structures. This approach illustrates aspects related to the neurogenesis and neural reorganization processes regarding attractive, repulsive or both interaction fields.
C1 [Coelho, Regina Celia] Univ Fed Sao Paulo, Sci & Technol Dept, Sao Jose Dos Campos, SP, Brazil.
   [Calonego, Nivaldi, Jr.] UNEMAT Univ Estado Mato Grosso, Fac Ciencias Exatas, Dept Comp, Caceres, MT, Brazil.
   [Consularo, Luis Augusto] TSE Tribunal Super Eleitoral STI CLOGI SEAD, Brasilia, DF, Brazil.
C3 Universidade Federal de Sao Paulo (UNIFESP); Universidade do Estado de
   Mato Grosso
RP Coelho, RC (corresponding author), Univ Fed Sao Paulo, Sci & Technol Dept, 330 Talim St Vila Nair, Sao Jose Dos Campos, SP, Brazil.
EM rccoelho@unifesp.br; nivaldi.calonegojr@gmail.com; laugusto@tse.gov.br
RI Coelho, Regina Celia/AAG-2223-2020; Coelho, Regina Celia/C-4333-2012
OI Coelho, Regina Celia/0000-0002-4428-9745; Coelho, Regina
   Celia/0000-0002-4428-9745
CR Ascoli GA, 2000, NEUROCOMPUTING, V32, P1003, DOI 10.1016/S0925-2312(00)00272-1
   BOER MJM, 1991, ARTIFICIAL LIFE 2, V10
   CHEN YPP, 2003, KNOWL INF SYST, V5, P288
   CLARKE PGH, 1985, TRENDS NEUROSCI, V8, P345, DOI 10.1016/0166-2236(85)90120-1
   *CNIC, NEUROGL 1 2
   Coelho RC, 2003, LECT NOTES COMPUT SC, V2905, P675
   Coelho RC, 2002, NEUROCOMPUTING, V48, P555, DOI 10.1016/S0925-2312(01)00628-2
   DEVAUL RW, 1996, NEURON DEV MODELING, P1
   Eberhard JP, 2006, NEUROCOMPUTING, V70, P327, DOI 10.1016/j.neucom.2006.01.028
   Feng N, 2005, NEUROCOMPUTING, V68, P70, DOI 10.1016/j.neucom.2005.01.007
   HAMILTON P, 1993, BIOL CYBERN, V68, P559, DOI 10.1007/BF00200816
   Ichikawa K, 2005, NEUROINFORMATICS, V3, P49, DOI 10.1385/NI:3:1:049
   JACOB C, 1995, P 1 INT MATH S SOUTH, P215
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9
   MCCORMICK BH, 1994, P SOC PHOTO-OPT INS, V2359, P693
   MULCHANDANI K, 1996, THESIS TEXAS A M U C
   Nielsen BT, 2008, NEUROCOMPUTING, V71, P963
   PERRY VH, 1988, DEV BRAIN RES, V41, P195, DOI 10.1016/0165-3806(88)90182-4
   PERRY VH, 1982, NATURE, V297, P683, DOI 10.1038/297683a0
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   vanOss C, 1997, J THEOR BIOL, V185, P263, DOI 10.1006/jtbi.1996.0361
   Zamir M, 2001, J GEN PHYSIOL, V118, P267, DOI 10.1085/jgp.118.3.267
NR 24
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2010
VL 14
IS 2
BP 119
EP 129
DI 10.1007/s10055-009-0123-4
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HV
UT WOS:000296279600003
DA 2024-07-18
ER

PT J
AU Katz, D
   Hyers, B
   Hojsak, S
   Shin, DW
   Wang, ZY
   Park, C
   Burnett, G
AF Katz, Daniel
   Hyers, Benjamin
   Hojsak, Stephanie
   Shin, Da Wi
   Wang, Zhi-yuan
   Park, Chang
   Burnett, Garrett
TI Utilization of virtual reality for operating room fire safety training:
   a randomized trial
SO VIRTUAL REALITY
LA English
DT Article
DE Fire safety; High-fidelity simulation; Operating room fire; Patient
   safety; Virtual reality
ID SIMULATOR; DISASTER
AB Operating room fires are catastrophic and often preventable. The optimal means to prepare healthcare workers for a fire is unclear. Virtual reality allows for hands-on practice in scenarios that are difficult to replicate in real life. Therefore, we designed an examination of the impact of virtual reality fire safety training. Sixty anesthesiology residents were randomized into three groups. One group underwent standard fire safety training, one group watched a fire safety video, and one group completed a virtual reality-based fire safety module. After an 8-month washout, residents were asked to manage a simulated case of an operating room fire. Participants were graded on their performance, completed a knowledge assessment, and provided feedback about their experiences. In total, 47 residents completed the follow-up assessment. No knowledge gains were seen in any group. Those in the VR group exhibited enhanced skills with fire management as they were more likely to douse the flame within 10 s as compared to both the control (12 (63.2) vs. 2 (13.0), adj p = 0.012) and the video group (12(63.2) vs. 3 (23.0), adj p = 0.043). Self-rated performance in the simulated fire was no different between the groups; however, the self-rated "effectiveness" of training was superior for VR. Utilizing virtual reality-based training for OR fire safety demonstrated enhanced management skills when managing a simulated operating room fire. More work is needed to further elucidate the optimal timing and frequency of training as well as examine the optimal modality for fire safety training.
C1 [Katz, Daniel; Hyers, Benjamin; Hojsak, Stephanie; Shin, Da Wi; Wang, Zhi-yuan; Park, Chang; Burnett, Garrett] Icahn Sch Med Mt Sinai, Dept Anesthesiol Pain & Perioperat Med, 1 Gustave L Levy Pl,Box 1010, New York, NY 10029 USA.
C3 Icahn School of Medicine at Mount Sinai
RP Katz, D (corresponding author), Icahn Sch Med Mt Sinai, Dept Anesthesiol Pain & Perioperat Med, 1 Gustave L Levy Pl,Box 1010, New York, NY 10029 USA.
EM Daniel.Katz@mountsinai.org
OI Park, Chang/0000-0001-8185-5526
FU Patient Safety Innovation Grant from the Hospitals Insurance Corporation
FX This study was funded by a Patient Safety Innovation Grant from the
   Hospitals Insurance Corporation.
CR Adams E, 2018, WIRED
   Alfakhry G, 2022, CLIN EXP DENT RES, V8, P883, DOI 10.1002/cre2.567
   Amer Soc Anesthesiologists, 2013, ANESTHESIOLOGY, V118, P271, DOI 10.1097/ALN.0b013e31827773d2
   Anesthesia Patient Safety Foundation, 2010, PREVENTION MANAGEMEN
   Anesthesia Patient Safety Foundation, 2018, APSF FIR SAF VID CON
   [Anonymous], 2013, SENTINEL EVENT ALERT
   Bank I, 2016, PREHOSP DISASTER MED, V31, P551, DOI 10.1017/S1049023X16000704
   Bogers H, 2018, J OBSTET GYNAECOL RE
   Busci R, 2006, RISK MANAGEMENT DIGE
   Dorozhkin D, 2017, SURG ENDOSC, V31, P3527, DOI 10.1007/s00464-016-5379-7
   ECRI Institute, 2009, Health Devices, V38, P314
   Grottke O, 2009, BRIT J ANAESTH, V103, P594, DOI 10.1093/bja/aep224
   Jiang BL, 2018, SIMUL HEALTHC, V13, P83, DOI 10.1097/SIH.0000000000000299
   Karnick A, 2021, SURGERY, V170, P1353, DOI 10.1016/j.surg.2021.04.008
   Katz D, 2020, J MED INTERNET RES, V22, DOI 10.2196/17425
   Khanal P, 2014, J BIOMED INFORM, V51, P49, DOI 10.1016/j.jbi.2014.04.005
   Kim Y, 2018, IEEE ENG MED BIO, P1887, DOI 10.1109/EMBC.2018.8512708
   Landro L., 2009, WALL STR J
   Nayar SK, 2018, IR J MED SCI
   Qi D, 2021, SURG ENDOSC, V35, P779, DOI 10.1007/s00464-020-07447-1
   Rosenfeld J, 2015, HOSP DOCTORS FOUND L
   Rossler KL, 2018, NURSE ED
   Roy S, 2019, OTOLARYNG CLIN N AM, V52, P163, DOI 10.1016/j.otc.2018.08.011
   Sankaranarayanan G, 2018, SURG ENDOSC, V32, P3439, DOI 10.1007/s00464-018-6063-x
   Savran MM, 2018, SURG ENDOSC
   Shoaf E, 2016, AORN J, V104, P453, DOI 10.1016/j.aorn.2016.09.009
   Smith C., 2004, AORN J, V80, P23, DOI 10.1016/S0001-2092(06)60840-5
   Steadman RH, 2006, CRIT CARE MED, V34, P151, DOI 10.1097/01.CCM.0000190619.42013.94
   Ullrich S, 2009, STUD HEALTH TECHNOL, V142, P392, DOI 10.3233/978-1-58603-964-6-392
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Yardley IE, 2010, SURG-J R COLL SURG E, V8, P87, DOI 10.1016/j.surge.2010.01.005
   Yardley S, 2012, MED TEACH, V34, P161, DOI 10.3109/0142159X.2012.643264
NR 32
TC 1
Z9 1
U1 7
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3211
EP 3219
DI 10.1007/s10055-023-00866-0
EA OCT 2023
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001088163900001
DA 2024-07-18
ER

PT J
AU Santa-Bárbara, RA
   Rivera, FG
   Lamb, M
   Da-Silva, RV
   Bedmar, MG
AF Almiron Santa-Barbara, Rafael
   Garcia Rivera, Francisco
   Lamb, Maurice
   Viquez Da-Silva, Rodrigo
   Gutierrez Bedmar, Mario
TI New technologies for the classification of proximal humeral fractures:
   Comparison between Virtual Reality and 3D printed models-a randomised
   controlled trial
SO VIRTUAL REALITY
LA English
DT Article
DE Proximal humeral fracture; Three-dimensional printed models; Virtual
   Reality; Interobserver agreement; Shoulder surgery planning
ID COST-EFFECTIVENESS; 4-PART
AB Correct classification of fractures according to their patterns is critical for developing a treatment plan in orthopaedic surgery. Unfortunately, for proximal humeral fractures (PHF), methods for proper classification have remained a jigsaw puzzle that has not yet been fully solved despite numerous proposed classifications and diagnostic methods. Recently, many studies have suggested that three-dimensional printed models (3DPM) can improve the interobserver agreement on PHF classifications. Moreover, Virtual Reality (VR) has not been properly studied for classification of shoulder injuries. The current study investigates the PHF classification accuracy relative to an expert committee when using either 3DPM or equivalent models displayed in VR among 36 orthopaedic surgery residents from different hospitals. We designed a multicentric randomised controlled trial in which we created two groups: a group exposed to a total of 34 3DPM and another exposed to VR equivalents. Association between classification accuracy and group assignment (VR/3DPM) was assessed using mixed effects logistic regression models. The results showed VR can be considered a non-inferior technology for classifying PHF when compared to 3DPM. Moreover, VR may be preferable when considering possible time and resource savings along with potential uses of VR for presurgical planning in orthopaedics.
C1 [Almiron Santa-Barbara, Rafael] Hosp Antequera, Dept Orthopaed Surg & Traumatol, Malaga, Spain.
   [Almiron Santa-Barbara, Rafael] Univ Malaga, Sch Med, Malaga, Spain.
   [Garcia Rivera, Francisco; Lamb, Maurice] Univ Skovde, Sch Engn Sci, Skovde, Sweden.
   [Lamb, Maurice] Univ Skovde, Sch Informat, Skovde, Sweden.
   [Viquez Da-Silva, Rodrigo] Hosp Univ Virgen Victoria, Dept Orthopaed Surg & Traumatol, Malaga, Spain.
   [Gutierrez Bedmar, Mario] Univ Malaga, Sch Med, Prevent Med & Publ Hlth Dept, Malaga 29010, Spain.
   [Gutierrez Bedmar, Mario] IBIMA, Biomed Res Inst Malaga, Malaga 29010, Spain.
   [Gutierrez Bedmar, Mario] Carlos III Hlth Inst, CIBERCV Cardiovasc Dis, Madrid 28029, Spain.
C3 Universidad de Malaga; University of Skovde; University of Skovde;
   Hospital Virgen de la Victoria; Universidad de Malaga; Instituto de
   Investigacion Biomedica de Malaga y Plataforma en Nanomedicina (IBIMA);
   Universidad de Malaga
RP Santa-Bárbara, RA (corresponding author), Hosp Antequera, Dept Orthopaed Surg & Traumatol, Malaga, Spain.; Santa-Bárbara, RA (corresponding author), Univ Malaga, Sch Med, Malaga, Spain.
EM ralmiron@uma.es
RI García Rivera, Francisco/HNR-0507-2023
OI Lamb, Maurice/0000-0003-2254-1396; Almiron Santa Barbara,
   Rafael/0000-0001-7816-7538
FU Universidad Malaga/CBUA
FX Funding for open access publishing: Universidad Malaga/CBUA.
CR Berton A, 2020, J CLIN MED, V9, DOI 10.3390/jcm9082567
   Bougher Hannah, 2021, JSES Int, V5, P198, DOI 10.1016/j.jseint.2020.10.019
   Carofino BC, 2013, CLIN ORTHOP RELAT R, V471, P39, DOI 10.1007/s11999-012-2454-9
   Chen YX, 2018, J BONE JOINT SURG AM, V100, P1960, DOI 10.2106/JBJS.18.00477
   Cocco LF, 2020, PATIENT SAF SURG, V14, DOI 10.1186/s13037-020-00258-2
   Corbacho B, 2016, BONE JOINT J, V98B, P152, DOI 10.1302/0301-620X.98B2.36614
   Ejnisman L, 2021, CURR REV MUSCULOSKE, V14, P1, DOI 10.1007/s12178-020-09691-3
   Fürnstahl P, 2012, MED IMAGE ANAL, V16, P704, DOI 10.1016/j.media.2010.07.012
   Hasan LK, 2021, ADV MED EDUC PRACT, V12, P1295, DOI 10.2147/AMEP.S321885
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1
   Iordens GIT, 2016, J ORTHOP SCI, V21, P596, DOI 10.1016/j.jos.2016.05.011
   Levy J., 2017, ORTHOPAEDIC P, V99, P92, DOI 10.1302/1358-992X.99BSUPP_4.ISTA2016-092
   Li K, 2022, EUR J TRAUMA EMERG S, V48, P3493, DOI 10.1007/s00068-021-01851-5
   Lohre Ryan, 2020, JSES Int, V4, P215, DOI 10.1016/j.jseint.2020.02.005
   Mahabier KC, 2015, INJURY, V46, P1930, DOI 10.1016/j.injury.2015.07.025
   Matamala-Gomez M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08917-3
   Moldovan F, 2021, J PERS MED, V11, DOI 10.3390/jpm11030190
   Mulligan J-A, 2003, DIS CONTROL PRIORITI
   Negrillo-Cárdenas J, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105407
   Neumann PJ, 2017, NEW ENGL J MED, V376, P203, DOI 10.1056/NEJMp1612619
   Raeker-Jordan EA, 2021, JAAOS GLOB RES REV, V5, DOI 10.5435/JAAOSGlobal-D-20-00224
   Roux A, 2012, ORTHOP TRAUMATOL-SUR, V98, P715, DOI 10.1016/j.otsr.2012.05.013
   Schumaier A, 2018, GERIATR ORTHOP SURG, V9, DOI 10.1177/2151458517750516
   Spek RWA, 2022, CLIN ORTHOP RELAT R, V480, P150, DOI 10.1097/CORR.0000000000001921
   Sukthankar AV, 2013, J SHOULDER ELB SURG, V22, pE1, DOI 10.1016/j.jse.2012.09.018
   Sumrein BO, 2017, OSTEOPOROSIS INT, V28, P901, DOI 10.1007/s00198-016-3808-z
   Thorsness R, 2016, J ORTHOP TRAUMA, V30, P262, DOI 10.1097/BOT.0000000000000513
   Verhey JT, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2067
   Yammine K, 2022, EUR J TRAUMA EMERG S, V48, P3479, DOI 10.1007/s00068-021-01758-1
   You W, 2016, ORTHOP TRAUMATOL-SUR, V102, P897, DOI 10.1016/j.otsr.2016.06.009
   Zhang HL, 2021, FRONT SURG, V8, DOI 10.3389/fsurg.2021.705532
NR 31
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1623
EP 1634
DI 10.1007/s10055-023-00757-4
EA FEB 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000926409600001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Korkut, EH
   Surer, E
AF Korkut, Elif Hilal
   Surer, Elif
TI Visualization in virtual reality: a systematic review
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Visualization; Game technologies; Systematic review
ID INFORMATION VISUALIZATION; AUGMENTED REALITY; 3D VISUALIZATION; VISUAL
   ANALYTICS; SIMULATION; REHABILITATION; ENVIRONMENT; EMERGENCY; PLATFORM;
   DESIGN
AB Rapidly growing virtual reality (VR) technologies and techniques have gained importance over the past few years, and academics and practitioners have been searching for efficient visualizations in VR. To date, the emphasis has been on the employment of game technologies. Despite the growing interest and potential, visualization studies have lacked a common baseline in the transition period of 2D visualizations to immersive ones. To this end, the presented study aims to provide a systematic literature review that explains the state-of-the-art research and future trends in visualization in virtual reality. The research framework is grounded in empirical and theoretical works of visualization. We characterize the reviewed literature based on three dimensions: (a) Connection with visualization background and theory, (b) Evaluation and design considerations for virtual reality visualization, and (c) Empirical studies. The results from this systematic review suggest that: (1) There are only a few studies that focus on creating standard guidelines for virtual reality, and each study individually provides a framework or employs previous studies on traditional 2D visualizations; (2) With the myriad of advantages provided for visualization and virtual reality, most of the studies prefer to use game engines; (3) Although game engines are extensively used, they are not convenient for critical scientific studies; and (4) 3D versions of traditional statistical visualization techniques, such as bar plots and scatter plots, are still commonly used in the data visualization context. This systematic review attempts to add a clear picture of the emerging contexts, different elements, and interdependencies to the literature.
C1 [Korkut, Elif Hilal; Surer, Elif] Middle East Tech Univ, Grad Sch Informat, Dept Modeling & Simulat, TR-06800 Ankara, Turkiye.
C3 Middle East Technical University
RP Surer, E (corresponding author), Middle East Tech Univ, Grad Sch Informat, Dept Modeling & Simulat, TR-06800 Ankara, Turkiye.
EM elif.korkut@metu.edu.tr; elifs@metu.edu.tr
RI Surer, Elif/I-5157-2015
OI Surer, Elif/0000-0002-0738-6669; Korkut, Elif Hilal/0000-0002-8836-6685
CR Aamir A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010083
   Akin S, 2021, ENG CONSTR ARCHIT MA, V28, P1319, DOI 10.1108/ECAM-07-2020-0562
   Akpan IJ, 2019, SIMUL-T SOC MOD SIM, V95, P145, DOI 10.1177/0037549718757039
   Amores J., 2015, P 33 ANN ACM C EXTEN, P1343, DOI DOI 10.1145/2702613.2732927
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   Aparicio M., 2015, Communication design quarterly review, V3, P7, DOI DOI 10.1145/2721882.2721883
   Ardulov V, 2017, P IEEE VIRT REAL ANN, P263, DOI 10.1109/VR.2017.7892277
   Asjad NS, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225171
   Bailey BJ, 2019, 17 INT C VIRTUAL REA, P1
   Bender J., 2015, P EUROGRAPHICS TUTOR, P8
   Bergmann T, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P330, DOI 10.5220/0006262903300334
   Bertin J., 1983, SEMIOLOGY GRAPHICS D
   Bianchi RM, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921402013
   Biek L., 1963, Archaeology and the Microscope. The Scientific Examination of Archaeological Evidence
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Bo Sun, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P24
   Bobek S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010331
   Bonali FL, 2022, GEOSCIENCES, V12, DOI 10.3390/geosciences12010009
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brunhart-Lupo N, 2020, NRELCP2C0076783
   Butcher PWS, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312798
   Caldarola E. G., 2017, Big data visualization tools: a survey
   Caserman P, 2020, IEEE T VIS COMPUT GR, V26, P3089, DOI 10.1109/TVCG.2019.2912607
   Cassidy KC, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007747
   Chang TP, 2016, CLIN PEDIATR EMERG M, V17, P224, DOI 10.1016/j.cpem.2016.05.002
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   Chawla P, 2020, VIS INFORM, V4, P132, DOI 10.1016/j.visinf.2020.04.006
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Curtis V, 2015, SCI COMMUN, V37, P723, DOI 10.1177/1075547015609322
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Dong HM, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/8430186
   Drogemuller Adam, 2017, P BDVA, DOI [10.13140/RG.2.2.34201.67689, DOI 10.13140/RG.2.2.34201.67689]
   Drouhard M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2453, DOI 10.1109/BigData.2015.7364040
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Du RF, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300915
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Elden M, 2017, THESIS, P108
   Ens B, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503726
   Escobar-Castillejos D, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0459-8
   Ferdani D, 2020, GROMA DOCUMENTING AR
   Ferrell JB, 2019, J CHEM EDUC, V96, P1961, DOI 10.1021/acs.jchemed.9b00036
   Fittkau F, 2015, 2015 IEEE 3RD WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P130, DOI 10.1109/VISSOFT.2015.7332423
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Friendly M, 2007, STAT SCI, V22, P368, DOI 10.1214/07-STS241
   Friendly M, 2016, ASHG STUD TECH COMM, P219
   Fussell SusanR., 2014, The Oxford Handbook of Language and Social Psychology, P471
   Gal R, 2014, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2014.6948429
   Gamberini L, 2015, COMPUT HUM BEHAV, V48, P104, DOI 10.1016/j.chb.2015.01.040
   Gibson JJ., 1977, The Concept of Affordances in Perceiving, Acting, and Knowing
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Gradl S, 2018, INT CONF WEARAB IMPL, P152, DOI 10.1109/BSN.2018.8329681
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Guo RC, 2020, VIS INFORM, V4, P72, DOI 10.1016/j.visinf.2020.04.001
   Hadjar H, 2018, WS.2 2018: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON WEB STUDIES, P56, DOI 10.1145/3240431.3240442
   Hanwell Marcus D., 2015, SoftwareX, V1-2, P9, DOI 10.1016/j.softx.2015.04.001
   He ZY, 2020, INT SYM MIX AUGMENT, P542, DOI 10.1109/ISMAR50242.2020.00082
   Helbig C, 2014, ENVIRON EARTH SCI, V72, P3767, DOI 10.1007/s12665-014-3136-6
   Hirota K, 2016, P IEEE VIRT REAL ANN, P49, DOI 10.1109/VR.2016.7504687
   Hoppe Adrian H., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432950
   Horton BK, 2019, SOFTWAREX, V9, P112, DOI 10.1016/j.softx.2019.01.009
   Huang JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1311, DOI [10.1109/VR.2019.8797771, 10.1109/vr.2019.8797771]
   Huang YL, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME), P499, DOI [10.1109/ITME.2016.0119, 10.1109/ITME.2016.187]
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Ibayashi H., 2015, SIGGRAPH Asia 2015 emerging technologies, P1
   Ivson P, 2020, IEEE T VIS COMPUT GR, V26, P3109, DOI 10.1109/TVCG.2019.2907583
   Jacovi A, 2018, ARXIV
   Jamróz D, 2020, VISUAL COMPUT, V36, P733, DOI 10.1007/s00371-019-01653-2
   Jamroz D, 2018, LECT NOTES ARTIF INT, V10842, P364, DOI 10.1007/978-3-319-91262-2_33
   Jamroz D, 2009, ADV INTELL SOFT COMP, V59, P445
   Jeelani I, 2020, ENG CONSTR ARCHIT MA, V27, P1853, DOI 10.1108/ECAM-07-2019-0391
   Fernández-Palacios BJ, 2017, J CULT HERIT, V23, P40, DOI 10.1016/j.culher.2016.09.003
   Joo SY, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030731
   Juanes JA, 2016, P 4 INT C TECHNOLOGI, P473
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Keiriz JJG, 2018, NETW NEUROSCI, V2, P344, DOI 10.1162/netn_a_00044
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-2, P361, DOI 10.5194/isprs-archives-XLII-2-W3-361-2017
   Kitchenham B., 2007, GUIDELINES PERFORMIN
   Kokelj Z, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P299, DOI 10.23919/MIPRO.2018.8400057
   Kraus M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376675
   Kriglstein S, 2019, DATA ANAL APPL GAMIN, P223
   Krokos E, 2018, IEEE SYM VIS CYB SEC
   Kwok PK, 2019, COMPUT IND ENG, V135, P711, DOI 10.1016/j.cie.2019.06.035
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Kwon OH, 2015, IEEE PAC VIS SYMP, P63, DOI 10.1109/PACIFICVIS.2015.7156357
   Lee H, 2019, INT SYM MIX AUGMENT, P318, DOI 10.1109/ISMAR.2019.00030
   Li DD, 2020, ELECTRON J DIFFER EQ, P1
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Li H, 2018, MULTIMED TOOLS APPL, V77, P30149, DOI 10.1007/s11042-018-6454-y
   Li W, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360700
   Li XM, 2016, ADV ENG SOFTW, V93, P1, DOI 10.1016/j.advengsoft.2015.11.003
   Liimatainen K, 2020, ARXIV
   Liu MB, 2010, ARCH COMPUT METHOD E, V17, P25, DOI 10.1007/s11831-010-9040-7
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SG, 2019, VIRTUAL REAL-LONDON, V23, P33, DOI 10.1007/s10055-018-0351-6
   Liu SG, 2015, VIRTUAL REAL-LONDON, V19, P291, DOI 10.1007/s10055-015-0271-7
   Liu SG, 2013, VIRTUAL REAL-LONDON, V17, P77, DOI 10.1007/s10055-013-0222-0
   Lv ZH, 2016, IEEE INTERNET THINGS, V3, P1015, DOI 10.1109/JIOT.2016.2546307
   Lynch T, 2015, J BROADCAST ELECTRON, V59, P298, DOI 10.1080/08838151.2015.1029128
   Marks S, 2017, SIGGRAPH ASIA 2017 SYMPOSIUM ON EDUCATION (SA'17), DOI 10.1145/3134368.3139218
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P259, DOI 10.1007/978-3-030-01388-2_9
   Martinez X, 2020, BIORXIV
   Mascolino V, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338135
   Medler Ben., 2011, PARSONS J INFORM MAP, V3, P1
   Mehrotra C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1229, DOI 10.1109/CCAA.2017.8229987
   Mei HH, 2018, VIS INFORM, V2, P71, DOI 10.1016/j.visinf.2018.04008
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Miller JA, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P535, DOI 10.1145/3341215.3356274
   Misiak M, 2018, 2018 SIXTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P112, DOI 10.1109/VISSOFT.2018.00020
   Molka-Danielsen J, 2015, NORSK KONFERANSE ORG, V23
   Monaco D, 2022, J CULT HERIT, V53, P127, DOI 10.1016/j.culher.2021.11.002
   Monteiro P, 2021, IEEE T VIS COMPUT GR, V27, P2702, DOI 10.1109/TVCG.2021.3067687
   Moon J., 2016, Improving Health Management Through Clinical Decision Support Systems, P1, DOI DOI 10.4018/978-1-4666-9432-3.CH001
   Munster Sander, 2020, SUMAC'20: Proceedings of the 2nd Workshop on Structuring and Understanding of Multimedia heritAge Contents, P33, DOI 10.1145/3423323.3425748
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Oberhauser R., 2017, International Journal of Virtual Reality, V17, P79, DOI DOI 10.20870/IJVR.2017.17.2.2894
   Okada K, 2018, IEEE INT CON INF VIS, P91, DOI 10.1109/iV.2018.00026
   Onorati T, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P176, DOI 10.1145/3266037.3271642
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pajorova Eva, 2018, Journal of Physics: Conference Series, V1098, DOI 10.1088/1742-6596/1098/1/012001
   Pan JJ, 2015, VISUAL COMPUT, V31, P947, DOI 10.1007/s00371-015-1106-y
   Peter Z., 2008, PRODUCT ENG TOOLS ME, P277
   Polys N. F., 2004, Virtual Reality, V8, P41, DOI 10.1007/s10055-004-0134-0
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Rachevsky DC, 2018, SYMP VIRTUAL AUGMENT, P89, DOI 10.1109/SVR.2018.00024
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Raya L, 2021, IEEE COMPUT GRAPH, V41, P106, DOI 10.1109/MCG.2021.3055685
   Reddivari S, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P280, DOI 10.1109/CHASE.2017.102
   Rehme M, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P82, DOI 10.1109/SciVis.2018.8823604
   Ren DH, 2017, COMPUT GRAPH FORUM, V36, P179, DOI 10.1111/cgf.13178
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Ren H, 2021, TEI 2021 P 15 INT C
   Rendgen S., 2018, The Minard system. The complete statistical graphics of Charles-Joseph Minard
   Rhyne TM, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P611, DOI 10.1109/VISUAL.2003.1250428
   Roberts JC, 2022, COMPUTERS, V11, DOI 10.3390/computers11020020
   Ronchi E, 2016, FIRE TECHNOL, V52, P623, DOI 10.1007/s10694-015-0462-5
   Rosero F, 2017, ASSESSMENT PEOPLES P
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Sauzeon H., 2012, EXP PSYCHOL
   Schreiber M, 2011, PROCEDIA COMPUT SCI, V4, P984, DOI 10.1016/j.procs.2011.04.104
   Schweibenz W., 1998, Proceedings of the 6th ISI Conference, P185
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Sevastjanova R, 2019, MLUI 2019 MACHINE LE
   Shamsuzzoha A, 2021, INTERACT LEARN ENVIR, V29, P1339, DOI 10.1080/10494820.2019.1628072
   Shrestha S, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P968, DOI 10.1145/2957265.2962644
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Skamantzari M, 2018, 3D VISUALIZATION VIR
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Soeiro J, 2016, IEEE INT CONF INF VI, P124, DOI 10.1109/IV.2016.18
   Sommer B, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0043
   Sooai AG., 2017, 2017 TRON S TRONSH, P1
   Sousa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4057, DOI 10.1145/3025453.3025566
   Steinbeck M, 2019, INT C PROGRAM COMPRE, P231, DOI 10.1109/ICPC.2019.00042
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Surer E, 2021, J MULTIMODAL USER IN, V15, P393, DOI 10.1007/s12193-020-00348-6
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Thanyadit S, 2020, P SUI 2020 ACM S SPA
   Tinati R, 2017, COMPUT HUM BEHAV, V73, P527, DOI 10.1016/j.chb.2016.12.074
   Tinati R, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P45, DOI 10.1145/2908131.2908151
   Tommasini R, 2019, DEBS'19: PROCEEDINGS OF THE 13TH ACM INTERNATIONAL CONFERENCE ON DISTRIBUTED AND EVENT-BASED SYSTEMS, P199, DOI 10.1145/3328905.3332462
   Tsuji T, 2015, J ROBOT MECHATRON, V27, P122, DOI 10.20965/jrm.2015.p0122
   Usher W, 2018, IEEE T VIS COMPUT GR, V24, P994, DOI 10.1109/TVCG.2017.2744079
   Vahdatikhaki F, 2019, ISARC P INT S AUTOMA, P218, DOI [10.22260/isarc2019/0030, DOI 10.22260/ISARC2019/0030]
   Vanden Broucke S, 2019, IEEE INT SM C CONF, P685, DOI [10.1109/isc246665.2019.9071699, 10.1109/ISC246665.2019.9071699]
   Vincur J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P509, DOI 10.1109/QRS-C.2017.88
   Voinea A, 2015, I C CONTR SYS COMP S, P856, DOI 10.1109/CSCS.2015.123
   Wallner G, 2013, ENTERTAIN COMPUT, V4, P143, DOI 10.1016/j.entcom.2013.02.002
   Wang MN, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1923
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Wanick V, 2019, APPL GAMES DESIGN TH
   WARE C, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P37
   Wilkinson L., 2012, Handbook of Computational Statistics, P375, DOI [10.1007/978-3-642-21551-3_13d, DOI 10.1007/978-3-642-21551-3_13D]
   Wongsuphasawat K, 2011, IEEE VISWEEK WORKSH, P25
   Wu HJ, 2020, J VISUAL-JAPAN, V23, P339, DOI 10.1007/s12650-019-00617-x
   Xia H., 2018, Spacetime: Enabling Fluid Individual and Collaborative Editing in Virtual Reality
   Xia HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P853, DOI 10.1145/3242587.3242597
   Xu J., 2017, INT J VIRTUAL REALIT, V17, P15
   Yan FT, 2020, MULTIMED TOOLS APPL, V79, P31541, DOI 10.1007/s11042-020-08863-0
   Yang BS, 2005, PHOTOGRAMM ENG REM S, V71, P917, DOI 10.14358/PERS.71.8.917
   Yates M, 2016, BRAIN INJURY, V30, P855, DOI 10.3109/02699052.2016.1144146
   Yin H, 2021, SCI ROBOT, V6, DOI 10.1126/scirobotics.abd8803
   Yoo S, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P391, DOI 10.1145/3099023.3099102
   Yu P, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1940
   Zebari R., 2020, Journal of Applied Science and Technology Trends, V1, P56, DOI [DOI 10.38094/JASTT1224, 10.38094/jastt1224]
   Zhang XY, 2017, VIRTUAL REAL-LONDON, V21, P165, DOI 10.1007/s10055-017-0308-1
   Zhang YX, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103311
   Zhuochen Jin, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3344258
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 200
TC 17
Z9 17
U1 73
U2 210
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1447
EP 1480
DI 10.1007/s10055-023-00753-8
EA JAN 2023
PG 34
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000914718900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, SG
   Yang, ZY
AF Liu, Shiguang
   Yang, Zhongyao
TI Virtual water wave simulation with multiple wavenumbers
SO VIRTUAL REALITY
LA English
DT Article
DE Water wave simulation; Wave packet; Wavenumber; Diffraction
   approximation; Singular boundary method
ID SINGULAR BOUNDARY METHOD; FLUID; BEM
AB This paper proposes a novel particle-based scheme for simulating interactive water waves. We first modify the implementation of the wave packet so that each packet can carry two wavenumbers. As a consequence, the wavelength-dependent behaviors can be accurately simulated. We then optimize the approximation technique of diffraction for simulating partial diffraction and promoting rendering efficiency. Lastly, we provide a novel evaluation module based on wave patterns generated by solving wave functions. Specifically, we introduce the singular boundary method (SBM) to serve as an analytical solution of the Laplace equation. We tested our scheme and other state-of-the-art approaches on scenes with regular-shaped, complex-shaped, and user-designed obstacles. Various results indicate that, compared to the state of the arts, our scheme can achieve higher physical accuracy and more satisfying computational efficiency.
C1 [Liu, Shiguang; Yang, Zhongyao] Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
FU Natural Science Foundation of China [62072328]
FX This research was partly supported by the Natural Science Foundation of
   China under Grant No. 62072328
CR [Anonymous], 2008, VERTICAL DERIVATIVE
   Bargteil AW, 2006, ACM T GRAPHIC, V25, P19, DOI 10.1145/1122501.1122503
   Bridson R., 2015, FLUID SIMULATION COM, DOI [10.1201/9781315266008, DOI 10.1201/9781315266008]
   Bruno F, 2018, VIRTUAL REAL-LONDON, V22, P91, DOI 10.1007/s10055-017-0318-z
   Canabal JA, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982415
   Chen W., 2009, Acta Mech. Solida Sin., V30, P592
   Chen W, 2009, CMES-COMP MODEL ENG, V54, P65
   Chentanez Nuttapong., 2010, P 2010 ACM SIGGRAPH, P197
   Da F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925899
   Feng G, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1781
   Hafner C, 2019, SUPPLEMENTARY MAT CL, P1
   Huang KM, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3321360
   Jensen LS, 2006, P GAM DEV C GAM, P1
   Jeschke S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073678
   Jeschke S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201336
   Jeschke S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2714572
   Jiang M, 2018, VIRTUAL REAL-LONDON, V22, P137, DOI 10.1007/s10055-018-0334-7
   Kawulich BB, 2019, VIRTUAL REAL-LONDON, V23, P375, DOI 10.1007/s10055-018-0353-4
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Klaseboer E, 2011, ENG ANAL BOUND ELEM, V35, P489, DOI 10.1016/j.enganabound.2010.09.005
   Lee Minjae., 2019, P 18 ANN ACM SIGGRAP, P1
   Liang H, 2018, APPL OCEAN RES, V74, P80, DOI 10.1016/j.apor.2018.02.025
   Liu SG, 2013, VIRTUAL REAL-LONDON, V17, P77, DOI 10.1007/s10055-013-0222-0
   Loviscach J, 2002, P EUR SHORT PAP, P1
   MASTIN GA, 1987, IEEE COMPUT GRAPH, V7, P16, DOI 10.1109/MCG.1987.276961
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   Ottosson B, 2011, THESIS KTH ROYAL I T
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Raveendran K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601126
   Ravnik J, 2016, ENG ANAL BOUND ELEM, V67, P13, DOI 10.1016/j.enganabound.2016.02.006
   Razafizana Z, 2015, OCEAN ENG, V96, P330, DOI 10.1016/j.oceaneng.2014.12.008
   Reddy J.N., 2015, An Introduction to Nonlinear Finite Element Analysis: with Applications to Heat Transfer, Fluid Mechanics, and Solid Mechanics
   Reddy JN., 2010, The Finite Element Method in Heat Transfer and Fluid Dynamics, DOI [10.1201/9781439882573, DOI 10.1201/9781439882573]
   Ren B, 2018, IEEE T VIS COMPUT GR, V24, P2411, DOI 10.1109/TVCG.2017.2720672
   Schreck C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323002
   Skrivan T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392466
   Tessendorf J., 2001, P ACM SIGGRAPH COURS
   Tessendorf Jerry, 2004, GAME PROGRAMMING GEM, V4, P265
   Wu HY, 2017, EUR J MECH B-FLUID, V65, P54, DOI 10.1016/j.euromechflu.2017.02.008
   Wu ML, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2006
   Xie C, 2010, P ACM SIGGRAPH INT C, P332
   Yang Z., 2021, VIRTUAL REAL INTELL, V3, P118, DOI [10.1016/j.vrih.2021.01.003, DOI 10.1016/J.VRIH.2021.01.003]
   Yang ZY, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1886
   Yeh HC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508420
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
   Zhang XY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1801
NR 46
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1221
EP 1231
DI 10.1007/s10055-022-00729-0
EA DEC 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000895033800005
DA 2024-07-18
ER

PT J
AU Hsin, LJ
   Chao, YP
   Chuang, HH
   Kuo, TBJ
   Yang, CCH
   Huang, CG
   Kang, CJ
   Lin, WN
   Fang, TJ
   Li, HY
   Lee, LA
AF Hsin, Li-Jen
   Chao, Yi-Ping
   Chuang, Hai-Hua
   Kuo, Terry B. J.
   Yang, Cheryl C. H.
   Huang, Chung-Guei
   Kang, Chung-Jan
   Lin, Wan-Ni
   Fang, Tuan-Jen
   Li, Hsueh-Yu
   Lee, Li-Ang
TI Mild simulator sickness can alter heart rate variability, mental
   workload, and learning outcomes in a 360° virtual reality application
   for medical education: a post hoc analysis of a randomized controlled
   trial
SO VIRTUAL REALITY
LA English
DT Article
DE Heart rate variability; Mini-clinical evaluation exercise; Simulator
   sickness; Task load index; Visual reality; 360 degrees video
ID CLINICAL-EVALUATION EXERCISE; MOTION-SICKNESS; STRESS; IMPLEMENTATION;
   METAANALYSIS; RELIABILITY; EXPERIENCE; EXAMPLES
AB Virtual reality (VR) applications could be beneficial for education, training, and treatment. However, VR may induce symptoms of simulator sickness (SS) such as difficulty focusing, difficulty concentrating, or dizziness that could impair autonomic nervous system function, affect mental workload, and worsen interventional outcomes. In the original randomized controlled trial, which explored the effectiveness of using a 360 degrees VR video versus a two-dimensional VR video to learn history taking and physical examination skills, only the former group participants had SS. Therefore, 28 undergraduate medical students who participated in a 360 degrees VR learning module were included in this post hoc study using a repeated measures design. Data of the Simulator Sickness Questionnaire (SSQ), heart rate variability (HRV) analysis, Task Load Index, and Mini-Clinical Evaluation Exercise were retrospectively reviewed and statistically analyzed. Ten (36%) participants had mild SS (total score > 0 and <= 20), and 18 (64%) had no SS symptom. Total SSQ score was positively related to the very low frequency (VLF) band power, physical demand subscale, and frustration subscale, and inversely related to physical examination score. Using multilevel modeling, the VLF power mediated the relationship between total SSQ score and physical examination score. Furthermore, frustration subscale moderated the mediating effects of the VLF power. Our results highlight the importance of documenting SS to evaluate a 360 degrees VR training program. Furthermore, the combination of HRV analysis with mental workload measurement and outcome assessments provided the important clinical value in evaluating the effects of SS in VR applications in medical education.
C1 [Hsin, Li-Jen; Kang, Chung-Jan; Lin, Wan-Ni; Fang, Tuan-Jen; Li, Hsueh-Yu; Lee, Li-Ang] Linkou Chang Gung Mem Hosp, Dept Otorhinolaryngol Head & Neck Surg, Sleep Ctr, Linkou Med Ctr, 5 Fu Hsing St, Taoyuan 33305, Taiwan.
   [Hsin, Li-Jen; Chuang, Hai-Hua; Kang, Chung-Jan; Lin, Wan-Ni; Fang, Tuan-Jen; Li, Hsueh-Yu; Lee, Li-Ang] Chang Gung Univ, Fac Med, Grad Inst Clin Med Sci, Taoyuan 33302, Taiwan.
   [Chao, Yi-Ping] Chang Gung Univ, Grad Inst Biomed Engn, Dept Comp Sci & Informat Engn, Taoyuan 33302, Taiwan.
   [Chao, Yi-Ping] Linkou Chang Gung Mem Hosp, Dept Neurol, Taoyuan 33305, Taiwan.
   [Chuang, Hai-Hua] Chang Gung Mem Hosp, Taipei Branch, Dept Family Med, Linkou Med Ctr, 5 Fu Hsing St, Taoyuan 33305, Taiwan.
   [Chuang, Hai-Hua] Chang Gung Mem Hosp, Linkou Main Branch, Linkou Med Ctr, 5 Fu Hsing St, Taoyuan 33305, Taiwan.
   [Chuang, Hai-Hua] Natl Taipei Univ Technol, Dept Ind Engn & Management, Taipei 10608, Taiwan.
   [Kuo, Terry B. J.; Yang, Cheryl C. H.; Lee, Li-Ang] Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei 11221, Taiwan.
   [Huang, Chung-Guei] Linkou Chang Gung Mem Hosp, Dept Lab Med, Taoyuan 33305, Taiwan.
   [Huang, Chung-Guei] Chang Gung Univ, Grad Inst Biomed Sci, Dept Med Biotechnol & Lab Sci, Taoyuan 33302, Taiwan.
   [Chuang, Hai-Hua; Lee, Li-Ang] Natl Tsing Hua Univ, Sch Med, Hsinchu 300044, Taiwan.
C3 Chang Gung Memorial Hospital; Chang Gung University; Chang Gung
   University; Chang Gung Memorial Hospital; Chang Gung Memorial Hospital;
   Chang Gung Memorial Hospital; National Taipei University of Technology;
   National Yang Ming Chiao Tung University; Chang Gung Memorial Hospital;
   Chang Gung University; National Tsing Hua University
RP Lee, LA (corresponding author), Linkou Chang Gung Mem Hosp, Dept Otorhinolaryngol Head & Neck Surg, Sleep Ctr, Linkou Med Ctr, 5 Fu Hsing St, Taoyuan 33305, Taiwan.; Chuang, HH; Lee, LA (corresponding author), Chang Gung Univ, Fac Med, Grad Inst Clin Med Sci, Taoyuan 33302, Taiwan.; Chuang, HH (corresponding author), Chang Gung Mem Hosp, Taipei Branch, Dept Family Med, Linkou Med Ctr, 5 Fu Hsing St, Taoyuan 33305, Taiwan.; Chuang, HH (corresponding author), Chang Gung Mem Hosp, Linkou Main Branch, Linkou Med Ctr, 5 Fu Hsing St, Taoyuan 33305, Taiwan.; Chuang, HH (corresponding author), Natl Taipei Univ Technol, Dept Ind Engn & Management, Taipei 10608, Taiwan.; Lee, LA (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei 11221, Taiwan.; Chuang, HH; Lee, LA (corresponding author), Natl Tsing Hua Univ, Sch Med, Hsinchu 300044, Taiwan.
EM lijen.hsin@gmail.com; yiping@mail.cgu.edu.tw; chhaihua@gmail.com;
   tbjkuo@gmail.com; cchyang@gmail.com; joyce@cgmh.org.tw;
   handneck@gmail.com; wannilin@hotmail.com; fang3109@cgmh.org.tw;
   hyli38@cgmh.org.tw; Dr.U.Ang.Lee@gmail.com
RI Li, Hsueh-Yu/JMR-1981-2023; Chuang, Hai-Hua/A-5144-2015; Chao,
   Yi-Ping/GOP-0833-2022
OI Li, Hsueh-Yu/0000-0002-9016-8098; Chuang, Hai-Hua/0000-0002-7394-4016;
   Chao, Yi-Ping/0000-0002-1681-5410; Hsin, Li-Jen/0000-0001-9201-0270
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [106-2511-S-182A-003-MY2, 108-2511-H-182A-001]; Chang Gung Medical
   Foundation, Taiwan, R.O.C. [CMRPG3G1381-3]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, R.O.C. (106-2511-S-182A-003-MY2 and 108-2511-H-182A-001) and a
   grant from the Chang Gung Medical Foundation, Taiwan, R.O.C.
   (CMRPG3G1381-3) awarded to L.-A. Lee.
CR Alvares GA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070468
   Ammanuel S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1308-3
   [Anonymous], 1975, Motion sickness
   Barré J, 2019, OBES SURG, V29, P1309, DOI 10.1007/s11695-018-03680-9
   Blake TA, 2016, BRAIN INJURY, V30, P132, DOI 10.3109/02699052.2015.1093659
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Burr RL, 2007, SLEEP, V30, P913, DOI 10.1093/sleep/30.7.913
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Castaldo R, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0742-y
   Chalmers JA, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00080
   Chang YC, 2013, J ACUTE MED, V3, P110, DOI 10.1016/j.jacme.2013.06.004
   Chao YP, 2023, VIRTUAL REAL-LONDON, V27, P637, DOI 10.1007/s10055-022-00664-0
   Chao YP, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/13124
   Chen FQ, 2020, J MED INTERNET RES, V22, DOI 10.2196/18290
   CHI MTH, 1989, COGNITIVE SCI, V13, P145, DOI 10.1207/s15516709cog1302_1
   Chu H, 2013, BMC COMPLEM ALTERN M, V13, DOI 10.1186/1472-6882-13-84
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Dias RD, 2018, BRIT J SURG, V105, P491, DOI 10.1002/bjs.10795
   Durning SJ, 2002, ACAD MED, V77, P900, DOI 10.1097/00001888-200209000-00020
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Dyer E, 2018, J MED LIBR ASSOC, V106, P498, DOI 10.5195/jmla.2018.518
   Faric N, 2019, J MED INTERNET RES, V21, DOI 10.2196/13833
   Foo JL, 2013, J LAPAROENDOSC ADV S, V23, P65, DOI 10.1089/lap.2012.0150
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Frendo M, 2020, OTOL NEUROTOL, V41, P476, DOI 10.1097/MAO.0000000000002541
   Gibbons CH, 2019, HAND CLINIC, V160, P407, DOI 10.1016/B978-0-444-64032-1.00027-8
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hauer K E, 2000, Acad Med, V75, P524, DOI 10.1097/00001888-200005000-00046
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Howard MC, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103707
   Juvrud J, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00305
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim HG, 2018, PSYCHIAT INVEST, V15, P235, DOI 10.30773/pi.2017.08.17
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim S, 2016, TEACH LEARN MED, V28, P424, DOI 10.1080/10401334.2016.1165682
   Klein MI, 2012, J ENDOUROL, V26, P1089, DOI 10.1089/end.2011.0641
   Koch A, 2019, SURG INNOV, V26, P234, DOI 10.1177/1553350618822869
   Kogan Jennifer R, 2002, Acad Med, V77, P1156, DOI 10.1097/00001888-200211000-00021
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Kuo TBJ, 1999, AM J PHYSIOL-HEART C, V277, pH2233, DOI 10.1152/ajpheart.1999.277.6.H2233
   LaCount LT, 2009, COMPUT CARDIOL, V36, P49
   Lau E, 2020, SURG ENDOSC, V34, P2551, DOI 10.1007/s00464-019-07038-9
   LeBreton JM, 2008, ORGAN RES METHODS, V11, P815, DOI 10.1177/1094428106296642
   Lee HS, 2020, RESTOR NEUROL NEUROS, V38, P165, DOI 10.3233/RNN-190975
   Lee LA., 2018, J LARYNGOL OTOL, V07, P69, DOI [10.4172/2324-8785-c3-014, DOI 10.4172/2324-8785-C3-014]
   Li XL, 2020, COMPUT METH PROG BIO, V188, DOI 10.1016/j.cmpb.2019.105266
   Lin CL, 2013, INT J PSYCHOPHYSIOL, V87, P70, DOI 10.1016/j.ijpsycho.2012.11.003
   Loft S, 2007, HUM FACTORS, V49, P376, DOI 10.1518/001872007X197017
   Matsumoto T, 2001, OBES RES, V9, P78, DOI 10.1038/oby.2001.10
   Mawdesley M, 2011, COMPUT EDUC, V56, P44, DOI 10.1016/j.compedu.2010.05.005
   McCraty R., 2009, Integral Rev, V5
   Menin A, 2018, IEEE COMPUT GRAPH, V38, P57, DOI 10.1109/MCG.2018.021951633
   MILLER JC, 1993, AVIAT SPACE ENVIR MD, V64, P813
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Morrison G.R., 2007, DESIGNING EFFECTIVE, V5th
   NORCINI JJ, 1995, ANN INTERN MED, V123, P795, DOI 10.7326/0003-4819-123-10-199511150-00008
   O'Sullivan B, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9596
   Ohyama S, 2007, AURIS NASUS LARYNX, V34, P303, DOI 10.1016/j.anl.2007.01.002
   Park MJ, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00505
   Park S, 2014, INT J PSYCHOPHYSIOL, V92, P42, DOI 10.1016/j.ijpsycho.2014.02.003
   Pecchia L, 2018, HEALTHC TECHNOL LETT, V5, P94, DOI 10.1049/htl.2017.0090
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Preacher KJ, 2010, PSYCHOL METHODS, V15, P209, DOI 10.1037/a0020141
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Renkl A, 1998, CONTEMP EDUC PSYCHOL, V23, P90, DOI 10.1006/ceps.1997.0959
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Samadbeik Mahnaz, 2018, J Adv Med Educ Prof, V6, P123
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Silva JNA, 2018, JACC-BASIC TRANSL SC, V3, P420, DOI 10.1016/j.jacbts.2017.11.009
   Takada M, 2015, ENVIRON HEALTH PREV, V20, P79, DOI 10.1007/s12199-014-0424-4
   Tang Kevin S, 2020, Can Med Educ J, V11, pe81, DOI 10.36834/cmej.61705
   Taylor JA, 1998, CIRCULATION, V98, P547, DOI 10.1161/01.CIR.98.6.547
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Tsue Terance T, 2014, J Grad Med Educ, V6, P162, DOI 10.4300/JGME-06-01s1-21
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   UNGS TJ, 1989, AVIAT SPACE ENVIR MD, V60, P252
   Usui H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182611
   Ventura S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02509
   Webb CM, 2009, AVIAT SPACE ENVIR MD, V80, P541, DOI 10.3357/ASEM.2454.2009
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wu SH, 2020, J EDUC EVAL HEALTH P, V17, DOI 10.3352/jeehp.2020.17.1
   Yang Y., 2010, PSYCHOL RES, V3, P36, DOI 10.3969/j.issn.2095-1159.2010.03.007
   Yoo HH, 2021, MED PRIN PRACT, V30, P193, DOI 10.1159/000513781
   Zou LY, 2018, J CLIN MED, V7, DOI 10.3390/jcm7110404
NR 94
TC 5
Z9 5
U1 3
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3345
EP 3361
DI 10.1007/s10055-022-00688-6
EA SEP 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000853285200001
PM 36118174
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Abril, T
   Oliveira, J
   Gamito, P
AF Abril, Tiago
   Oliveira, Jorge
   Gamito, Pedro
TI Construction and effect of relationships with agents in a virtual
   reality environment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cognitive flexibility; Complementarity;
   Anthropomorphism; Relation models
ID FLEXIBILITY; PERCEPTION; PROJECTION
AB Recent studies have been investigating behavior (of approach and avoidance) toward the interaction with agents in virtual reality. This paper aims to explore the cognitive construction of a complementary relationship with agents in virtual reality through a brief interaction in a virtual task. A sample of 53 adult participants with or attending higher education was studied, divided into a control group of 20, and two experimental groups, one of 20 and another of 13 participants. The experimental groups interacted with a virtual agent, one group knowing that it was a non-human character (NPC) that communicated verbally, and the second group being informed that it was an avatar controlled in real-time by another person. The results confirmed an effect of cognitive flexibility on the anthropomorphic and complementary perception of NPCs and the application of relational models toward NPCs. An effect of the nature of the agents (NPC vs. Avatar) in the application of relational models was mediated by the complementary anthropomorphic projection of the agents. The previous interaction with the virtual agent, perceived as an NPC, provided faster skin conductance responses with images of the NPC. These findings contribute to: (1) understanding the impact of cognitive flexibility, a neuropsychological construct, in the construction of projections and relationships with agents in virtual reality; (2) creation and use of virtual reality tools based on communication in a function-led approach; (3) critical view of social models, for the development of a scale that allows assessing anthropomorphism and complementarity in virtual reality.
C1 [Abril, Tiago; Oliveira, Jorge; Gamito, Pedro] Univ Lusofona Humanidades & Tecnol, HEI Lab, Escola Psicol & Ciencias Vida, Lisbon, Portugal.
C3 Lusofona University
RP Abril, T (corresponding author), Univ Lusofona Humanidades & Tecnol, HEI Lab, Escola Psicol & Ciencias Vida, Lisbon, Portugal.
EM tmcsabril@gmail.com
RI Oliveira, Jorge/KUH-2946-2024; gamito, pedro/G-4353-2013
OI gamito, pedro/0000-0003-0585-8447; Abril, Tiago/0000-0001-7697-4758
CR Bailenson J, 2018, JAMA PEDIATR, V172, P905, DOI 10.1001/jamapediatrics.2018.1909
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Bender H.A., 2019, Handbook on the Neuropsychology of Aging and Dementia. Clinical Handbooks in Neuropsychology, DOI DOI 10.1007/978-3-319-93497-6_24
   Brito R, 2011, J SOC PERS RELAT, V28, P406, DOI 10.1177/0265407510384420
   Bush KA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33621-6
   Daher S, 2017, LECT NOTES ARTIF INT, V10498, P87, DOI 10.1007/978-3-319-67401-8_10
   Daher S, 2017, IEEE SYMP 3D USER, P201, DOI 10.1109/3DUI.2017.7893341
   Dotsch R, 2008, J EXP SOC PSYCHOL, V44, P1194, DOI 10.1016/j.jesp.2008.03.003
   Emmelkamp PMG, 2020, CURR PSYCHIAT REP, V22, DOI 10.1007/s11920-020-01156-1
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Favre M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120882
   Fiske AP, 2000, PERS SOC PSYCHOL REV, V4, P76, DOI 10.1207/S15327957PSPR0401_7
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Gamito P, 2019, CYBERPSYCH BEH SOC N, V22, P69, DOI 10.1089/cyber.2017.0679
   Gatti E, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.120
   Hall-McMaster S, 2019, J NEUROSCI, V39, P8549, DOI 10.1523/JNEUROSCI.0631-19.2019
   Harvey PD, 2019, DIALOGUES CLIN NEURO, V21, P227, DOI 10.31887/DCNS.2019.21.3/pharvey
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Ho A, 2018, J COMMUN, V68, P712, DOI 10.1093/joc/jqy026
   Iacoboni M, 2004, NEUROIMAGE, V21, P1167, DOI 10.1016/j.neuroimage.2003.11.013
   Imhoff R, 2013, SOC COGNITION, V31, P806, DOI 10.1521/soco.2013.31.6.806
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Kim K, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1771
   McCall C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117532
   McGraw AP, 2005, J CONSUM PSYCHOL, V15, P2, DOI 10.1207/s15327663jcp1501_2
   Mepham KD, 2018, J LANG SOC PSYCHOL, V37, P51, DOI 10.1177/0261927X17706944
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Olfers KJF, 2018, PSYCHOL RES-PSYCH FO, V82, P186, DOI 10.1007/s00426-017-0933-z
   Oliveira J, 2018, APPL NEUROPSYCH-ADUL, V25, P555, DOI 10.1080/23279095.2017.1349661
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   ROKEACH M, 1948, J ABNORM SOC PSYCH, V43, P259, DOI 10.1037/h0056134
   Rosenfield NS, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020028
   Sabharwal NS., 2014, DOES SOCIAL PROTECTI
   Schul Y, 2000, PERS SOC PSYCHOL B, V26, P987, DOI 10.1177/01461672002610008
   Shriram K., 2017, Social Signal Processing p, P304, DOI DOI 10.1017/9781316676202.022
   Sundararajan L, 2015, J THEOR SOC BEHAV, V45, P64, DOI 10.1111/jtsb.12054
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Verweij M, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00332
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
NR 39
TC 1
Z9 1
U1 2
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3665
EP 3678
DI 10.1007/s10055-022-00669-9
EA JUL 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000830950600001
DA 2024-07-18
ER

PT J
AU Hoter, E
   Nagar, I
AF Hoter, Elaine
   Nagar, Ilan
TI The effects of a wheelchair simulation in a virtual world
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual worlds; Simulations; Proteus effect; Experiential learning;
   Persons with a disability
AB This study examines the effect of a simulation in a virtual world where the participants, 208 students, are wheelchair users and need to perform various tasks. The students' reflections were analyzed, and three themes emerged: feelings while doing the simulation, feelings in the real world, and calls for action. In the simulation, the students felt as if they had a disability. This experience changed their attitudes to persons with a disability in the real world and made them proponents of change to ensure the rights and equality of persons with a disability. When they were questioned after a year, the impact of the experience was still strong.
C1 [Hoter, Elaine; Nagar, Ilan] Talpiot Coll Educ, Holon, Israel.
   [Hoter, Elaine; Nagar, Ilan] Givat Washington Coll Educ, Givat Washington, Israel.
RP Hoter, E (corresponding author), Talpiot Coll Educ, Holon, Israel.; Hoter, E (corresponding author), Givat Washington Coll Educ, Givat Washington, Israel.
EM ehoter@gmail.com
RI Hoter, Elaine/Q-8236-2019
OI Hoter, Elaine/0000-0002-8956-6929
CR Alshaer, 2016, P 11 INT C DIS VIRT
   Bailey JO, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P181, DOI 10.1016/B978-0-12-809481-5.00009-2
   Bigras C, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0482-3
   Boughzala I, 2012, J ASSOC INF SYST, V13, P714
   Chapelle C.A., 2003, TESOL QUART, V37, P157
   Creswell J. W., 2013, RES DESIGN QUALITATI
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   DAVIS MH, 1983, J PERSONALITY SOCIAL, V0044
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Ferguson, 2017, OPEN U INNOV REP, V6, P1
   Genova, 2021, VIRTUAL REAL-LONDON, V1, P1
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Hoter E, 2016, RE IMAGINING LEARNIN
   Markowitz D., 2019, Human Communication Research, V34, P287
   Mor Y, 2016, MEDIA COMMUN-LISBON, V4, P15, DOI 10.17645/mac.v4i1.298
   Park JH, 2003, J NONVERBAL BEHAV, V27, P65, DOI 10.1023/A:1023910408854
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Ron Y, 2013, PEACE CONFL, V19, P281, DOI 10.1037/a0033686
   Rosen Y., 2013, International Journal of Higher Education, V2, P91, DOI DOI 10.5430/IJHE.V2N4P91
   Salomon G, 2004, J SOC ISSUES, V60, P273, DOI 10.1111/j.0022-4537.2004.00118.x
   Spencer, 2019, BR J ED TECHNOL, V46, P472
   Williams R., 2005, Schole: A Journal of Leisure Studies Recreation Education, V20, P140
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 24
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 407
EP 419
DI 10.1007/s10055-022-00625-7
EA FEB 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000756194800001
DA 2024-07-18
ER

PT J
AU Lin, W
   Zhu, ZJ
   He, BW
   Liu, YQ
   Hong, WY
   Liao, ZJ
AF Lin, Wei
   Zhu, Zhaoju
   He, Bingwei
   Liu, Yuqing
   Hong, Wenyao
   Liao, Zhengjian
TI A novel virtual reality simulation training system with haptic feedback
   for improving lateral ventricle puncture skill
SO VIRTUAL REALITY
LA English
DT Article
DE Lateral ventricle puncture; Virtual reality; Surgery simulation;
   Training system; Haptic feedback
ID VENTRICULOSTOMY SIMULATION; NEUROSURGICAL EDUCATION; ANATOMY
AB The lateral ventricle puncture is an important step of external ventricular drain. It is one of the most basic but challenging skills that must be mastered by physicians. For improving the lateral ventricle puncture skill, a novel virtual reality simulation training system equipped with haptic feedback was developed in this paper. A series of experiments and questionnaires were conducted to evaluate the fidelity of simulated haptic force and the effectiveness of this system. Both the forces generated by the haptic device during the virtual puncture and that generated during puncturing on a pig brain were obtained and compared. The results indicate that these two forces have the similar varying tendency under different puncturing conditions. In addition, two groups of neurosurgical interns named A (trained without this system) and B (trained with this system) were selected to verify the effectiveness of this system. The operation metrics, including operative dictation, operation time, positioning of Kocher's point, times of repeated punctures, and the punctured position on lateral ventricle, were assessed by the chief physician for both groups. The results show that group B achieved higher scores than group A in all operation metrics except only operative dictation (P = 0.001). This indicates that the proposed virtual training system is an effective aid in training neurosurgery physicians' lateral ventricle puncture skill.
C1 [Lin, Wei; Zhu, Zhaoju; He, Bingwei] Fuzhou Univ, Sch Mech Engn & Automat, 2 Xueyuan Rd, Fuzhou, Fujian, Peoples R China.
   [Liu, Yuqing; Hong, Wenyao; Liao, Zhengjian] Fujian Prov Hosp, Dept Neurosurg, Fuzhou, Peoples R China.
   [Zhu, Zhaoju] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Lin, Wei; Zhu, Zhaoju; He, Bingwei; Liu, Yuqing; Hong, Wenyao; Liao, Zhengjian] Fujian Engn Res Ctr Joint Intelligent Med Engn, Fuzhou, Peoples R China.
C3 Fuzhou University; Fujian Provincial Hospital; Chinese Academy of
   Sciences; Institute of Automation, CAS
RP Zhu, ZJ (corresponding author), Fuzhou Univ, Sch Mech Engn & Automat, 2 Xueyuan Rd, Fuzhou, Fujian, Peoples R China.; Zhu, ZJ (corresponding author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.; Zhu, ZJ (corresponding author), Fujian Engn Res Ctr Joint Intelligent Med Engn, Fuzhou, Peoples R China.
EM clin_wei@163.com; zhuzhaoju0216@163.com; mebwhe@fzu.edu.cn;
   2291510908@qq.com; awanel@126.com; doctorzhengjian@163.com
FU Fujian Provincial Health Commission [2019I0023]
FX This study was funded by the Fujian Provincial Health Commission
   (2019I0023).
CR Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   Bender M, 2019, J NEUROL SURG PART A, V80, P116, DOI 10.1055/s-0038-1676576
   Bow H, 2019, OPER NEUROSURG, V16, P496, DOI 10.1093/ons/opy142
   Choi KS, 2004, ARTIF INTELL MED, V32, P51, DOI 10.1016/j.artmed.2004.01.013
   Cuesta MJ, 2017, PSYCHIAT RES-NEUROIM, V269, P90, DOI 10.1016/j.pscychresns.2017.09.010
   Ferroli P, 2013, NEUROSURGERY, V72, pA54, DOI 10.1227/NEU.0b013e3182748ee8
   Grajewski D, 2013, PROCEDIA COMPUT SCI, V25, P289, DOI 10.1016/j.procs.2013.11.035
   Henn JS, 2002, J NEUROSURG, V96, P144, DOI 10.3171/jns.2002.96.1.0144
   Huyette DR, 2008, J NEUROSURG, V108, P88, DOI 10.3171/JNS/2008/108/01/0088
   Lemole GM, 2007, NEUROSURGERY, V61, P142, DOI 10.1227/01.neu.0000279734.22931.21
   Li Y, 2019, J NEUROSURG, V131, P1599, DOI 10.3171/2018.4.JNS18124
   Morone PJ, 2017, OPER NEUROSURG, V13, P603, DOI 10.1093/ons/opx022
   Osztie E, 2009, EUR J RADIOL, V69, P67, DOI 10.1016/j.ejrad.2007.10.001
   Perin A, 2018, ACTA NEUROCHIR, V160, P2087, DOI 10.1007/s00701-018-3676-8
   Pinzon D, 2016, SURG INNOV, V23, P415, DOI 10.1177/1553350616628680
   Rangwala S., 2018, COMPREHENSIVE HEALTH, P17, DOI DOI 10.1007/978-3-319-75583-0_2
   Rosser JC, 1998, ARCH SURG-CHICAGO, V133, P657, DOI 10.1001/archsurg.133.6.657
   Ryan JR, 2015, WORLD NEUROSURG, V84, P1333, DOI 10.1016/j.wneu.2015.06.016
   Singapogu RB, 2014, J MULTIMODAL USER IN, V8, P319, DOI 10.1007/s12193-014-0164-1
   Thomale UW, 2018, NEUROSURGERY, V83, P252, DOI 10.1093/neuros/nyx420
   Triantafyllou K, 2014, WORLD J GASTRO ENDOS, V6, P6, DOI 10.4253/wjge.v6.i1.6
   Wynn G, 2018, AM J SURG, V216, P610, DOI 10.1016/j.amjsurg.2017.11.034
   Xu F, 2019, WORLD J CLIN CASES, V7, P2644, DOI 10.12998/wjcc.v7.i17.2644
   Yi ZC, 2020, J NEUROINTERV SURG, V12, P94, DOI 10.1136/neurintsurg-2019-015008
   Zahiri M, 2018, MIL MED, V183, P86, DOI 10.1093/milmed/usx138
   Zhong S, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000013095
NR 26
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 399
EP 411
DI 10.1007/s10055-021-00578-3
EA SEP 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000695190000001
DA 2024-07-18
ER

PT J
AU Souchet, AD
   Philippe, S
   Lévêque, A
   Ober, F
   Leroy, L
AF Souchet, Alexis D.
   Philippe, Stephanie
   Leveque, Aurelien
   Ober, Floriane
   Leroy, Laure
TI Short- and long-term learning of job interview with a serious game in
   virtual reality: influence of eyestrain, stereoscopy, and apparatus
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Eyestrain; Serious Game; Stereoscopy; Head-Mounted
   Display; Learning
ID HEAD-MOUNTED DISPLAYS; VISUAL DISCOMFORT; 3D; FATIGUE; PERFORMANCE;
   ACCOMMODATION; ENVIRONMENTS; CONVERGENCE; ACQUISITION; TECHNOLOGY
AB Purpose Do apparatuses and eyestrain have effects on learning performances and quality of experience? Materials and Methods: 42 participants played a serious game simulating a job interview with a Samsung Gear VR Head-Mounted Display (HMD) or a computer screen. Participants were randomly assigned to 3 groups: PC, HMD biocular, and HMD stereoscopy (S3D). Participants played the game thrice. Eyestrain was assessed pre- and post-exposure with six optometric measures. Learning performances were obtained in-game. Quality of experience was measured with questionnaires. Results: eyestrain was higher with HMDs than PC based on Punctum Proximum of accommodation but similar between biocular and S3D. Knowledge gain and retention were similar with HMDs and PC based on scores and response time. All groups improved response time but without statistically significant differences between HMDs and PC. Visual discomfort difference was statistically significant between PC and HMDs (biocular and S3D). Flow difference was statistically significant between PC and HMDs (biocular and S3D), with the PC group reporting higher Flow than HMD-S3D. Conclusion: short-term learning is similar between PC and HMDs. Groups initially using HMDs continued improving during long-term learning but without statistically significant difference compared to PC. Eyestrain and visual discomfort were higher with HMDs than PC. Flow was higher with the PC group. Our results show that eyestrain does not seem to decrease learning.
C1 [Souchet, Alexis D.; Leroy, Laure] Paris 8 Univ, St Denis, France.
   [Souchet, Alexis D.; Philippe, Stephanie; Leveque, Aurelien; Ober, Floriane] Manzalab, Paris, France.
   [Souchet, Alexis D.] CNRS, Heudiasyc UMR 7253, Compiegne, France.
   [Souchet, Alexis D.; Leroy, Laure] IRBA, Neurosci Dept, Bretygny Sur Orge, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Souchet, AD (corresponding author), Paris 8 Univ, St Denis, France.; Souchet, AD (corresponding author), Manzalab, Paris, France.; Souchet, AD (corresponding author), CNRS, Heudiasyc UMR 7253, Compiegne, France.; Souchet, AD (corresponding author), IRBA, Neurosci Dept, Bretygny Sur Orge, France.
EM alexis.souchet@hds.utc.fr
OI Souchet, Alexis/0000-0003-4885-1392; Philippe,
   Stephanie/0000-0001-7184-7581
FU Manzalab Group (Paris, France); IDEFI-CreaTIC Programme: Initiatives of
   Excellence in Innovative Training; French National Association of
   Research and Technology (ANRT) [CIFRE 2016-1571]
FX This work was supported by Manzalab Group (Paris, France), IDEFI-CreaTIC
   Programme: Initiatives of Excellence in Innovative Training, and the
   French National Association of Research and Technology (ANRT) with the
   Grant CIFRE 2016-1571. Co-author Aurelien Leveque is now co-founder of
   the company Virtuallyz. Co-author Floriane Ober is now working at OHM
   Games. The authors would like to thank Professor Ghislaine Azemard for
   her overall supervision of the study.
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Alhassan M., 2021, Int J Ophthalmol. Vis. Sci, V6, P10, DOI [10.11648/j.ijovs.20210601.12, DOI 10.11648/J.IJOVS.20210601.12]
   Alhusuny A, 2021, SURG ENDOSC, V35, P6660, DOI 10.1007/s00464-020-08167-2
   [Anonymous], 2005, GAMING TRAINING REV, DOI DOI 10.1037/E500852012-001
   Banks MS, 2012, SMPTE MOTION IMAG J, V121, P24, DOI 10.5594/j18173
   Bernhardt KA, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103152
   Bodzin A, 2021, J SCI EDUC TECHNOL, V30, P347, DOI 10.1007/s10956-020-09870-4
   Boughzala I, 2015, P ANN HICSS, P626, DOI 10.1109/HICSS.2015.82
   Bowman D.A., 2009, Proceedings of Joint Virtual Reality Conference of EGVE - ICAT - EuroVR, Lyon, France, 7-9 December 2009, P121
   Bracq MS, 2019, NURS EDUC TODAY, V79, P153, DOI 10.1016/j.nedt.2019.05.026
   Buttussi F, 2021, IEEE T LEARN TECHNOL, V14, pC, DOI 10.1109/TLT.2020.3033766
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Calderón A, 2017, 2017 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING CURRICULA FOR MILLENNIALS (SECM), P21, DOI 10.1109/SECM.2017.3
   Capobianco, 2014, SYNERGIES PAYS GERMA
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chittaro L, 2016, IEEE T VIS COMPUT GR, V22, P1527, DOI 10.1109/TVCG.2015.2443787
   Cho TH, 2017, DISPLAYS, V49, P59, DOI 10.1016/j.displa.2017.07.002
   Clark DB, 2016, REV EDUC RES, V86, P79, DOI 10.3102/0034654315582065
   Cowan N, 2008, PROG BRAIN RES, V169, P323, DOI 10.1016/S0079-6123(07)00020-9
   Damian I, 2015, LECT NOTES ARTIF INT, V9112, P84, DOI 10.1007/978-3-319-19773-9_9
   Daniel F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37778-y
   Elias ZM, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102879
   Emoto M, 2005, J DISP TECHNOL, V1, P328, DOI 10.1109/JDT.2005.858938
   Engeser S, 2008, MOTIV EMOTION, V32, P158, DOI 10.1007/s11031-008-9102-4
   Fergo C, 2017, AM J SURG, V213, P159, DOI 10.1016/j.amjsurg.2016.07.030
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fuchs P., 2018, VIRTUAL REALITY AUGM, P289, DOI [10.1002/9781119341031.ch6, DOI 10.1002/9781119341031.CH6]
   Fuchs Philippe, 2017, Virtual Reality Headsets-A Theoretical and Pragmatic Approach, DOI [10.1201/9781315208244, DOI 10.1201/9781315208244]
   Gaggioli A., 2003, Being There: Concepts, effects and measurement of user presence in synthetic environments
   Gallear W, 2014, 2014 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL), P247, DOI 10.1109/IMCTL.2014.7011141
   Giessen HW, 2015, PROCD SOC BEHV, V174, P2240, DOI 10.1016/j.sbspro.2015.01.881
   Guo J, 2019, J SOC INF DISPLAY, V27, P108, DOI 10.1002/jsid.750
   Guo J, 2017, P IEEE VIRT REAL ANN, P249, DOI 10.1109/VR.2017.7892270
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Han J., 2017, IS. T. Int. Symp. Electron. Imaging Sci. Technol, V29, P212, DOI [10.2352/ISSN.2470-1173.2017.14.HVEI-146, DOI 10.2352/ISSN.2470-1173.2017.14.HVEI-146]
   Hansard ME, 2017, COMPUT RES REPOS COR
   Hirota M, 2019, ERGONOMICS, V62, P759, DOI 10.1080/00140139.2019.1582805
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Howard MC, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103707
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huckauf A., 2019, P MENSCH COMPUTER 20, P1, DOI [10.1145/3340764.3340776, DOI 10.1145/3340764.3340776]
   Hupont Isabelle., 2015, 2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX), P1, DOI [DOI 10.1109/QOMEX.2015.7148110, 10.1109/QoMEX.2015.7148110]
   Iskander J, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102883
   IWASAKI T, 1993, OPHTHAL PHYSL OPT, V13, P285, DOI 10.1111/j.1475-1313.1993.tb00470.x
   Jacobs J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3353902
   Jiang B.-c., 2002, Models of the visual system, P341
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Keebler, 2011, THESIS U CENTRAL FLO
   Keller K, 1998, P SOC PHOTO-OPT INS, V3362, P46, DOI 10.1117/12.317454
   Kim H, 2017, INTERACT LEARN ENVIR, V25, P543, DOI 10.1080/10494820.2016.1167744
   Kozulin P, 2009, OPTOMETRY VISION SCI, V86, P845, DOI 10.1097/OPX.0b013e3181adff42
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kulshreshth Arun., 2012, Proceedings of the International Conference on the Foundations of Digital Games, P33, DOI DOI 10.1145/2282338.2282350
   Kweon SH, 2018, ADV INTELL SYST, V592, P194, DOI 10.1007/978-3-319-60366-7_19
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Limniou M, 2008, COMPUT EDUC, V51, P584, DOI 10.1016/j.compedu.2007.06.014
   Limperos A, 2015, PRESENCE-VIRTUAL AUG, V23, P341, DOI 10.1162/PRES_a_00204
   Long Y, 2020, SEMIN OPHTHALMOL, V35, P170, DOI 10.1080/08820538.2020.1776342
   Loup-Escande E, 2017, INT J HUM-COMPUT INT, V33, P115, DOI 10.1080/10447318.2016.1220105
   Lovreglio R, 2021, VIRTUAL REAL-LONDON, V25, P133, DOI 10.1007/s10055-020-00447-5
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Matsuura Y, 2019, CURR TOP ENV HEAL PR, P89, DOI 10.1007/978-981-13-1601-2_8
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   Mistry M, 2013, J SURG EDUC, V70, P563, DOI 10.1016/j.jsurg.2013.04.006
   Mon-Williams M, 1998, HUM FACTORS, V40, P42, DOI 10.1518/001872098779480622
   MONWILLIAMS M, 1993, OPHTHAL PHYSL OPT, V13, P387, DOI 10.1111/j.1475-1313.1993.tb00496.x
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Mukai A, 2011, KNOWL MANAG E-LEARN, V3, P491
   Munsamy AJ, 2020, J OPTOM, V13, P163, DOI 10.1016/j.optom.2020.02.004
   O'Sullivan R., 2013, INT J SURG, V11, P599, DOI [10.1016/j.ijsu.2013.06.067, DOI 10.1016/J.IJSU.2013.06.067]
   Panke K, 2019, P 2 INT C APPL INT S, P1, DOI DOI 10.1145/3309772.3309786
   Papastergiou M, 2009, COMPUT EDUC, V52, P1, DOI 10.1016/j.compedu.2008.06.004
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Patterson R, 2009, J SOC INF DISPLAY, V17, P987, DOI 10.1889/JSID17.12.987
   Pavlas D., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P2398
   Pollard KA, 2020, VIRTUAL REAL-LONDON, V24, P783, DOI 10.1007/s10055-019-00411-y
   Price A, 2010, J SCI EDUC TECHNOL, V19, P90, DOI 10.1007/s10956-009-9182-2
   Price CA, 2015, SCI EDUC, V99, P1118, DOI 10.1002/sce.21185
   Ray AB, 2016, IEEE CONF TECHNOL ED, P68, DOI [10.1109/T4E.2016.022, 10.1109/T4E.2016.21]
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Roβing C., 2016, HDB CAMERA MONITOR S, P279, DOI [10.1007/978-3-319-29611-1_9, DOI 10.1007/978-3-319-29611-1_9]
   Rotter P, 2017, IEEE TECHNOL SOC MAG, V36, P81, DOI 10.1109/MTS.2017.2654294
   Rushton SK, 1999, APPL ERGON, V30, P69, DOI 10.1016/S0003-6870(98)00044-1
   SCHOR CM, 1992, OPTOMETRY VISION SCI, V69, P258, DOI 10.1097/00006324-199204000-00002
   Schrader C, 2012, COMPUT HUM BEHAV, V28, P648, DOI 10.1016/j.chb.2011.11.011
   Schroeder B. L., 2017, Commun. Comput. Inf. Sci, P54, DOI DOI 10.1007/978-3-319-58753-09
   Shen R., 2019, IMAGE GRAPHICS TECHN, P310, DOI [10.1007/978-981-13-9917-6_30, DOI 10.1007/978-981-13-9917-6_30]
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Smith MJ, 2017, PSYCHIAT SERV, V68, P747, DOI 10.1176/appi.ps.201600217
   Smith S.P., 2015, SERIOUS GAMES ANAL M, P31, DOI DOI 10.1007/978-3-319-05834-4_2
   Souchet AD, 2019, INT SYM MIX AUGMENT, P328, DOI 10.1109/ISMAR.2019.00031
   Souchet AD, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281509
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stone R. J., 2011, Proceedings of the 2011 5th International Conference on Recent Advances in Space Technologies (RAST), P655, DOI 10.1109/RAST.2011.5966921
   Storz P, 2012, SURG ENDOSC, V26, P1454, DOI 10.1007/s00464-011-2055-9
   Szpak A, 2020, J MED INTERNET RES, V22, DOI 10.2196/19840
   Takatalo J, 2011, MEDIA PSYCHOL, V14, P387, DOI 10.1080/15213269.2011.620538
   Thai KTP, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P468, DOI [10.1109/VRW50115.2020.0-177, 10.1109/VRW50115.2020.00099]
   Thalmann Daniel, 2016, P 29 INT C COMP AN S, P197, DOI 10.1145/2915926.2915954
   Thornby J., 2007, WORLD J SURG, V32, P110, DOI [10.1086/459563, DOI 10.1086/459563]
   Ujike H, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P668, DOI 10.1109/GCCE.2015.7398697
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   Wang Y, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0731-5
   Wang YC, 2017, IEEE T LEARN TECHNOL, V10, P514, DOI 10.1109/TLT.2016.2639019
   WANN JP, 1995, VISION RES, V35, P2731, DOI 10.1016/0042-6989(95)00018-U
   Webster R, 2016, INTERACT LEARN ENVIR, V24, P1319, DOI 10.1080/10494820.2014.994533
   Wilhelm D, 2014, SURG ENDOSC, V28, P2387, DOI 10.1007/s00464-014-3487-9
   Wouters P, 2013, J EDUC PSYCHOL, V105, P249, DOI 10.1037/a0031311
   Wrzesien M, 2010, COMPUT EDUC, V55, P178, DOI 10.1016/j.compedu.2010.01.003
   Yoon HJ, 2020, BMC OPHTHALMOL, V20, DOI 10.1186/s12886-020-01471-4
   Yu XY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P93, DOI 10.1109/ISMAR-Adjunct.2018.00042
   Yuan J., 2018, Int J Ophthalmol Clin Res, V5, P85, DOI 10.23937/2378-346X/1410085
   Yunhong Zhang, 2020, Advances in Physical, Social & Occupational Ergonomics. Proceedings of the AHFE 2020 Virtual Conferences on Physical Ergonomics and Human Factors, Social & Occupational Ergonomics and Cross-Cultural Decision Making. Advances in Intelligent Systems and Computing (AISC 1215), P213, DOI 10.1007/978-3-030-51549-2_28
   Zeri F, 2015, OPHTHAL PHYSL OPT, V35, P271, DOI 10.1111/opo.12194
NR 117
TC 9
Z9 10
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 583
EP 600
DI 10.1007/s10055-021-00548-9
EA JUN 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000663493200001
DA 2024-07-18
ER

PT J
AU Price, S
   Jewitt, C
   Yiannoutsou, N
AF Price, Sara
   Jewitt, Carey
   Yiannoutsou, Nikoleta
TI Conceptualising touch in VR
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Touch; Illusion; Reproduction; Social
   perspectives; Design
AB How touch is conceptualised matters in shaping technical advancements, bringing opportunities and challenges for development and design and raising questions for how touch experience is reconfigured. This paper explores the notion of touch in virtual reality (VR). Specifically, it identifies how touch 'connection' is realised and conceptualised in virtual spaces in order to explore how digital remediation of touch in VR shapes the sociality of touch experiences and touch practices. Ten participants from industry and academia with an interest in touch in virtual contexts were interviewed using an in-depth semi-structured approach to elicit experiences and perspectives around the role of touch in VR. Data analysis shows the growing value and significance of touch in virtual spaces and reveals particular ways in which touch is talked about, implemented and conceptualised. It highlights changes for the sociality of touch through participants' conceptualisations of touch as replication and illusion, and how the body is brought into this 'touch' space. These perspectives of touch shape who touches, what is touched and how it is touched and set an agenda for the types of touch that are facilitated by VR. The findings suggest ways in which technological techniques can be employed towards interpretive designs of touch that allow for new ways to look at touch and haptics. They also show how touch is distorted and disrupted in ways that have implications for disturbing established 'real world' socialities of touch as well as their renegotiation by users in the space of digitally mediated touch in VR.
C1 [Price, Sara; Jewitt, Carey] UCL Knowledge Lab, 23-29 Emerald St, London WC1N 3QS, England.
   [Yiannoutsou, Nikoleta] European Comiss, Joint Res Ctr, Edificio Expo,Calle Inca Garcilaso 3, Seville 41092, Spain.
C3 University of London; University College London; UCL Institute of
   Education
RP Price, S (corresponding author), UCL Knowledge Lab, 23-29 Emerald St, London WC1N 3QS, England.
EM sara.price@ucl.ac.uk
RI Price, Sara/AAG-5856-2021; Yiannoutsou, Nikoleta/HGE-5619-2022
OI Yiannoutsou, Nikoleta/0000-0002-1085-3854; Price,
   Sara/0000-0002-5092-1663; Jewitt, Carey/0000-0002-2971-984X
FU InTouch project, a European Research Council Consolidator Award
   [681489]; European Research Council (ERC) [681489] Funding Source:
   European Research Council (ERC)
FX This research was undertaken as a part of the InTouch project, a
   European Research Council Consolidator Award (Award Number: 681489).
CR Abrash MK, 2015, OCULUS CONNECT
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   [Anonymous], 2013, Doctoral Dissertation, Dissertation Success
   [Anonymous], 2008, SCIENCEDAILY
   [Anonymous], 2003, J MUSIC THER, DOI DOI 10.2307/3090688
   [Anonymous], 2014, NONVERBAL COMMUNICAT
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Bull M., 2006, Senses Society, V1, P5, DOI DOI 10.2752/174589206778055655
   Campbell J, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P279, DOI 10.1145/3173225.3173281
   Cheung KL., 2014, VIRTUAL REALITY PHYS, P5
   Classen C, 2012, ST SENS HIST, P1
   Classen Constance., 2005, BOOK TOUCH
   Collins K, 2019, SENSES SOC, V14, P313, DOI 10.1080/17458927.2019.1619318
   Cranny-Francis A, 2013, TECHNOLOGY TOUCH, DOI [10.1057/9781137268310, DOI 10.1057/9781137268310]
   Cranny-Francis A, 2008, VISUAL COMMUN-US, V7, P363, DOI 10.1177/1470357208092325
   Creswell JW, 2003, CHOOSING FIVE APPROA
   Finlay L, 2013, J HUMANIST PSYCHOL, V53, P172, DOI 10.1177/0022167812453877
   Finnegan R, 2014, COMMUNICATING, DOI [10.4324/9781315869872, DOI 10.4324/9781315869872]
   Gu X, 2016, P 2016 CHI C HUM FAC
   Hajas D, 2020, IEEE T HAPTICS, V13, P806, DOI 10.1109/TOH.2020.2966445
   Jewitt C., 2020, Springer Nature, DOI DOI 10.1007/978-3-030-24564-1
   JOURARD SM, 1966, BRIT J SOC CLIN PSYC, V5, P221
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Madigan J, 2010, GAMASUTRA ART BUSINE
   Mertens D.M., 2003, Handbook of mixed methods in social behavioral research, P135
   Muthukumarana S, 2019, SIGGRAPH ASIA 2019 X
   Muthukumarana S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376491
   Obrist M., 2013, P SIGCHI C HUMAN FAC, P1659, DOI [10.1145/2470654.2466220, DOI 10.1145/2470654.2466220]
   Obrist M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2053, DOI 10.1145/2702123.2702361
   Orzechowski P, 2011, P 13 INT C HCI MOB D
   Parisi D., 2020, EXPANDING UNIVERSE H
   Parisi D, 2017, NEW MEDIA SOC, V19, P1513, DOI 10.1177/1461444817717518
   Parisi David., 2018, Archaeologies of Touch: Interfacing with Haptics from Electricity to Computing
   Paterson M, 2006, ENVIRON PLANN D, V24, P691, DOI 10.1068/d394t
   Pietroszek K, 2018, ENCY COMPUTER GRAPHI
   Pittera Dario, 2019, P 2019 CHI C HUM FAC
   Price S, AFFECTIVE SUPP UNPUB
   Ravi DK, 2017, PHYSIOTHERAPY, V103, P245, DOI 10.1016/j.physio.2016.08.004
   Rovers A.F., 2006, Virtual Reality, V9, P177, DOI [10.1007/s10055-005-0016-0, DOI 10.1007/S10055-005-0016-0]
   Shilling Chris., 2008, CHANGING BODIES HABI, DOI DOI 10.4135/9781446212295
   Spence C, 2013, TOUCH FUTURE SENSE T
   Stone RJ, 2001, LECT NOTES COMPUT SC, V2058, P1
   Stone RJ, 2019, HAPTICS VR ARE WE RE
   Sutton Jane, 2015, Can J Hosp Pharm, V68, P226
   van Manen M., 1991, The tact of teaching: the meaning of pedagogical thoughtfulness
   Whelchel R. J., 1986, IEEE Technology and Society Magazine, V5, P3, DOI 10.1109/MTAS.1986.5010049
   Wu HC, 2017, TECHNOL HEALTH CARE, V25, P1183, DOI 10.3233/THC-171001
   Zhang Z, 2019, ICMI 19
NR 50
TC 19
Z9 19
U1 1
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 863
EP 877
DI 10.1007/s10055-020-00494-y
EA JAN 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000605101200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zeng, H
   He, XX
   Pan, HH
AF Zeng, Hong
   He, Xingxi
   Pan, Honghu
TI Implementation of escape room system based on augmented reality
   involving deep convolutional neural network
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Convolutional neural network; Image classification;
   Escape room game
ID IMMERSION
AB Escape room is a live-action adventure game, where the players search clues, solve puzzles and achieve the assigned tasks. This paper proposed a novel escape room system combining augmented reality and deep learning technology. The system adopts a client-server architecture and can be divided into the server module, the smart glasses module and the player-hardware interaction module. The player-hardware interaction module consists of subsystems each of which includes a Raspberry Pi 3. HoloLens is used as the smart glasses in the experiment of the paper. The server communicates with all the Raspberry Pis and HoloLens through TCP/IP protocol and manages all the devices to achieve the game flow by following the process timeline. The smart glasses module provides two display modes, i.e., the AR 3D models display and the 2D text clues display. In the first mode, the SDK Vuforia is used for detection and tracking of markers. In the second mode, the scene images captured by HoloLens camera are sent to the pre-trained image classifier based on deep convolutional neural network. Considering both the image category and the game status value, the server decides the text clue image to be displayed on HoloLens. The accuracy of the image classification model reaches 94.9%, which can be correctly classified for a certain rotation angle and partial occlusion. The integration of AR, deep learning, electronics and escape room games opens up exciting new directions for the development of escape room. Finally, a built mini-escape room is analyzed to prove that the proposed system can support more complicated narratives showing the potential of achieving immersion.
C1 [Zeng, Hong; He, Xingxi; Pan, Honghu] Chongqing Univ, Coll Mech Engn, Dept Mechatron, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP He, XX (corresponding author), Chongqing Univ, Coll Mech Engn, Dept Mechatron, Chongqing 400044, Peoples R China.
EM xingxi@cqu.edu.cn
OI He, Xingxi/0000-0003-3676-9033
CR Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Feng Huang, 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P47, DOI 10.1109/IHMSC.2011.82
   Griffiths Mark D, 2017, Curr Addict Rep, V4, P272, DOI 10.1007/s40429-017-0162-y
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kersten-Oertel M, 2015, INT J COMPUT ASS RAD, V10, P1823, DOI 10.1007/s11548-015-1163-8
   King-Shy Goh, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P395
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H, 2019, VIRTUAL REAL-LONDON, V23, P85, DOI 10.1007/s10055-018-0343-6
   Lima JP, 2017, EXPERT SYST APPL, V82, P100, DOI 10.1016/j.eswa.2017.03.060
   Lu AS, 2012, GAMES HEALTH J, V1, P199, DOI 10.1089/g4h.2011.0012
   Miller K, 2019, TLS-TIMES LIT SUPPL, P4
   Plowman L, 1996, BRIT J EDUC TECHNOL, V27, P92, DOI 10.1111/j.1467-8535.1996.tb00716.x
   Qin H, 2009, INT J HUM-COMPUT INT, V25, P107, DOI 10.1080/10447310802546732
   Rehman U, 2017, IEEE T HUM-MACH SYST, V47, P140, DOI 10.1109/THMS.2016.2620106
   SHI X., 2003, COMPUTER VISION PATT, V8, P95
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun G, 2015, INT C CYB TECHN IET
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thomas BH, 2012, COMPUT ENTERTAIN, V10, DOI 10.1145/2381876.2381879
   Warmelink H, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P110, DOI 10.1145/3130859.3131436
   Wolf MarkJ. P., 2001, The Medium of the Video Game
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
NR 25
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 585
EP 596
DI 10.1007/s10055-020-00476-0
EA OCT 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000576748300001
DA 2024-07-18
ER

PT J
AU Lou, XL
   Li, XA
   Hansen, P
   Du, P
AF Lou, Xiaolong
   Li, Xiangdong A.
   Hansen, Preben
   Du, Peng
TI Hand-adaptive user interface: improved gestural interaction in virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Free hand interaction; Hand choice; Adaptive user
   interface; Performance evaluation
ID FITTS LAW; SYSTEM
AB Most interactive user interfaces (UIs) for virtual reality (VR) applications are based on the traditional eye-centred UI design principle, which primarily considers the user's visual searching efficiency and comfort, but the hand operation performance and ergonomics are relatively less considered. As a result, the hand interaction in VR is often criticized as being less efficient and precise. In this paper, the user's arm movement features, such as the choice of the hand being used and hand interaction position, are hypothesized to influence the interaction results derived from a VR study. To verify this, we conducted a free hand target selection experiment with 24 participants. The results showed that (a) the hand choice had a significant effect on the target selection results: for a left hand interaction, the targets located in spaces to the left were selected more efficiently and accurately than those in spaces to the right; however, in a right hand interaction, the result was reversed, and (b) the free hand interactions at lower positions were more efficient and accurate than those at higher positions. Based on the above findings, this paper proposes a hand-adaptive UI technique to improve free hand interaction performance in VR. A comprehensive comparison between the hand-adaptive UI and traditional eye-centred UI was also conducted. It was shown that the hand-adaptive UI resulted in a higher interaction efficiency and a lower physical exertion and perceived task difficulty than the traditional UI.
C1 [Lou, Xiaolong; Du, Peng] Hangzhou Dianzi Univ, Coll Digital Media & Design, Room 505,10 Teaching Bldg,Xiasha Campus, Hangzhou 310018, Zhejiang, Peoples R China.
   [Li, Xiangdong A.] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Hansen, Preben] Stockholm Univ, Dept Comp & Syst Sci DSV, Stockholm, Sweden.
   [Lou, Xiaolong] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Lou, Xiaolong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University; Stockholm University;
   Nanjing University; Beihang University
RP Lou, XL (corresponding author), Hangzhou Dianzi Univ, Coll Digital Media & Design, Room 505,10 Teaching Bldg,Xiasha Campus, Hangzhou 310018, Zhejiang, Peoples R China.; Lou, XL (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.; Lou, XL (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM xlou@hdu.edu.cn
RI Lou, Xiaolong/AAD-9278-2022
OI Lou, Xiaolong/0000-0001-9790-3780
FU National Natural Science Foundation of China [61902097]; Zhejiang
   Provincial Natural Science Funding [Q19F020010]; Open Research Funding
   of State Key Laboratory for Novel Software Technology of Nanjing
   University [KFKT2019B18]; Open Research Funding of State Key Laboratory
   of Virtual Reality Technology and Systems [VRLAB2020B03]
FX This research was supported by the (National Natural Science Foundation
   of China) under Grant (61902097), the (Zhejiang Provincial Natural
   Science Funding) under Grant (Q19F020010), the (Open Research Funding of
   State Key Laboratory for Novel Software Technology of Nanjing
   University) under Grant (KFKT2019B18), and the (Open Research Funding of
   State Key Laboratory of Virtual Reality Technology and Systems) under
   Grant (VRLAB2020B03).
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   BORG GAV, 1982, MED SCI SPORT EXER, V14, P377, DOI 10.1249/00005768-198205000-00012
   Boring S., 2009, P 21 ANN C AUSTR COM, V411, P161, DOI 10.1145/1738826.1738853
   Bowman DA, 1999, ANN RHEUM DIS, V28, P37
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   CARD SK, 1991, ACM T INFORM SYST, V9, P99, DOI 10.1145/123078.128726
   Cho OH, 2012, FUTURE INFORM TECHNO, V179, P141
   Colby CL, 1998, NEURON, V20, P15, DOI 10.1016/S0896-6273(00)80429-8
   Danckert J, 2001, EXP BRAIN RES, V137, P303
   Fikkert FW, 2010, GESTURE INTERACTION
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Gerber D, 2005, P IEEE VIRT REAL ANN, P271
   Haque F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3653, DOI 10.1145/2702123.2702133
   Harrison Chris., 2012, Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction (TEI'12), P69, DOI DOI 10.1145/2148131.2148148
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Lemmerman DK, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P303
   Liu G, 2008, EXP BRAIN RES, V185, P709, DOI 10.1007/s00221-007-1196-5
   Lou XL, 2018, INT J HUM-COMPUT INT, V34, P519, DOI 10.1080/10447318.2017.1370811
   Lubos P, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P13, DOI 10.1145/2983310.2985753
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P11, DOI 10.1109/3DUI.2014.6798834
   MacKenzie I. S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P9, DOI 10.1145/365024.365028
   Makela V., 2014, P INT S PERV DISPL P, P112
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Murata A, 2001, HUM MOVEMENT SCI, V20, P791, DOI 10.1016/S0167-9457(01)00058-6
   Nancel M, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2766448
   Ohta Y., 2014, MIXED REALITY MERGIN
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Po B., 2004, P ACM C HUMAN FACTOR, P359
   PREVIC FH, 1990, BEHAV BRAIN SCI, V13, P519, DOI 10.1017/S0140525X00080018
   Ren G, 2013, COMPUT GRAPH-UK, V37, P101, DOI 10.1016/j.cag.2012.12.006
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Shoemaker Garth., 2010, Proceedings of the 6th Nordic Conference on Human- Computer Interaction: Extending Boundaries, NordiCHI '10, P463, DOI DOI 10.1145/1868914.1868967
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   TANII K, 1972, Journal of Human Ergology, V1, P143
   TRAVIS DS, 1990, BEHAV INFORM TECHNOL, V9, P425, DOI 10.1080/01449299008924256
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Ware C., 2004, Proceedings of the 1st Symposium on Applied perception in graphics and visualization, P135
   Wingrave CA, 2005, P HCI INT 2005 LAS V, ppp1
NR 41
TC 7
Z9 7
U1 13
U2 112
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 367
EP 382
DI 10.1007/s10055-020-00461-7
EA JUL 2020
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000552243500001
DA 2024-07-18
ER

PT J
AU Xia, ZP
   Hwang, A
AF Xia, Zhenping
   Hwang, Alex
TI Self-position awareness-based presence and interaction in virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Cyclopean eye; Virtual reality; Immersed experience; Accurate
   interaction
AB The awareness of self-position, which refers to the location of our cyclopean eye, is essential to the experience of being immersed and for interacting with a virtual environment. Currently, individual variability in the cyclopean eye location is not considered when presenting virtual reality content. The effect of the cyclopean eye shift was analyzed with theoretical and experimental methods, and it was found that human vision is sensitive to the visual direction offset caused by the cyclopean eye shift. To compensate for the cyclopean eye shift, an original model is proposed with shifting the 3D camera system accordingly. The proposed method is expected to make all individuals with different cyclopean eye shifts perceive the virtual environment from the same viewpoint as the designer desired and may achieve more accurate interaction.
C1 [Xia, Zhenping] Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou, Peoples R China.
   [Xia, Zhenping; Hwang, Alex] Harvard Med Sch, Massachusetts Eye & Ear, Dept Ophthalmol, Schepens Eye Res Inst, Boston, MA 02115 USA.
C3 Suzhou University of Science & Technology; Harvard University;
   Massachusetts Eye & Ear Infirmary; Schepens Eye Research Institute;
   Harvard Medical School
RP Xia, ZP (corresponding author), Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou, Peoples R China.; Xia, ZP (corresponding author), Harvard Med Sch, Massachusetts Eye & Ear, Dept Ophthalmol, Schepens Eye Res Inst, Boston, MA 02115 USA.
EM xzp@usts.edu.cn
OI Xia, Zhenping/0000-0002-6331-212X
FU China Scholarship Council (CSC) [201704515003]; National Eye Institute
   of the National Institutes of Health [P30EY003790]
FX This research is supported by the China Scholarship Council (CSC file
   No. 201704515003) and by the National Eye Institute of the National
   Institutes of Health under award number P30EY003790.
CR BARBEITO R, 1979, BEHAV RES METH INSTR, V11, P31, DOI 10.3758/BF03205428
   FRY G A, 1950, Am J Optom Arch Am Acad Optom, V27, P531
   FUNAISHI SHIN-ICHI, 1926, ALBR V GRAEFE S ARCH OPH THALMOL, V117, P296, DOI 10.1007/BF01854191
   Heinrich SP, 2005, VISION RES, V45, P1321, DOI 10.1016/j.visres.2004.09.045
   Hering E., 1879, SPATIAL SENSE MOVEME
   Hou C, 2017, J VISION, V17, DOI 10.1167/17.6.2
   Howard I.P., 1966, Human Spatial Orientation
   Interrante V, 2013, IEEE COMPUT GRAPH, V38, P28
   Jin LN, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-6
   Kishi Shinsuke, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7237, DOI 10.1117/12.807245
   Loomis JM, 2016, PRESENCE-TELEOP VIRT, V25, P169, DOI 10.1162/PRES_a_00255
   ONO H, 1982, PERCEPT PSYCHOPHYS, V32, P201, DOI 10.3758/BF03206224
   Reichelt S, 2010, PROC SPIE, V7690, DOI 10.1117/12.850094
   ROELOFS CO, 1959, ACTA PSYCHOL, V16, P226, DOI 10.1016/0001-6918(59)90096-4
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Turski J, 2016, VISION RES, V119, P73, DOI 10.1016/j.visres.2015.11.001
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   VANDEGRIND WA, 1995, PERCEPTION, V24, P215, DOI 10.1068/p240215
   WALLS GL, 1951, AMA ARCH OPHTHALMOL, V45, P387
   WOODS A, 1993, P SOC PHOTO-OPT INS, V1915, P36, DOI 10.1117/12.157041
   Zhenping Xia, 2018, SID Symposium Digest of Technical Papers, V49, P381, DOI 10.1002/sdtp.12578
NR 21
TC 7
Z9 9
U1 0
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 255
EP 262
DI 10.1007/s10055-019-00396-8
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800006
PM 33994832
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Scavarelli, A
   Arya, A
   Teather, RJ
AF Scavarelli, Anthony
   Arya, Ali
   Teather, Robert J.
TI Virtual reality and augmented reality in social learning spaces: a
   literature review
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Augmented reality; Mixed reality; Multi-user;
   Collaborative; Education; Social learning spaces
ID EDUCATION; ENVIRONMENTS; AFFORDANCES; REPRESENTATION; FRAMEWORK;
   IMPLICIT; DESIGN; WORLDS; PLACE; MODEL
AB In this survey, we explore Virtual Reality and Augmented Reality within social learning spaces, such as classrooms and museums, while also extending into relevant social interaction concepts found within more reality-based and social immersive media frameworks. To provide a foundation for our findings we explore properties and interactions relevant to educational use in social learning spaces; in addition to several learning theories such as constructivism, social cognitive theory, connectivism, and activity theory, within a CSCL lens, to build a theoretical foundation for future virtual reality/augmented reality educational frameworks. Several virtual reality/augmented reality examples for learning are explored, and several promising areas to further research, such as a greater focus on accessibility, the interplay between the physical and virtual environments, and suggestions for updated learning theory foundations, are proposed.
C1 [Scavarelli, Anthony; Arya, Ali; Teather, Robert J.] Carleton Univ, Ottawa, ON, Canada.
C3 Carleton University
RP Scavarelli, A (corresponding author), Carleton Univ, Ottawa, ON, Canada.
EM anthony.scavarelli@carleton.ca; ali.arya@carleton.ca;
   rob.teather@carleton.ca
RI Scavarelli, Anthony/JPA-5174-2023
OI Scavarelli, Anthony/0000-0001-7741-1703
CR Abeysekera L, 2015, HIGH EDUC RES DEV, V34, P1, DOI 10.1080/07294360.2014.934336
   Aguerreche L, 2010, COMP 3 INTERACTIVE T
   Ahn S.J., 2011, P 97 ANN C NAT COMM
   Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   Alexander JM, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.1446
   [Anonymous], 2010, MARK MUS MILL
   [Anonymous], 2009, P SIGCHI C HUM FACT
   [Anonymous], MOZ SPOK
   [Anonymous], 2016, NIANT
   [Anonymous], 2016, DREAMS DAL VIRT REAL
   [Anonymous], 2015, DEV KINECT
   [Anonymous], 2018, AUGM VIRT REAL SURV
   [Anonymous], 2019, WEBXR DEV API
   [Anonymous], 2019, OC QUEST
   [Anonymous], STEEL CRAT GAM
   [Anonymous], 2018, MOZ HUBS
   [Anonymous], 1992, Presence, DOI DOI 10.1162/PRES.1992.1.3.344
   [Anonymous], EXT REAL
   [Anonymous], ED EXP INMEDIASTUDIO
   Arya A, 2014, DESIGN EVALUATION LE
   Arya A, 2011, INT ED TECHN C SUN B, P11
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Baker H, 2019, HIGH FIDELITY LAYS H
   BANDURA A, 1989, AM PSYCHOL, V44, P1175, DOI 10.1037/0003-066X.44.9.1175
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Belch D, 2017, Google Patents, Patent No. [15/177,332, 15177332]
   Bell F, 2011, INT REV RES OPEN DIS, V12, P98, DOI 10.19173/irrodl.v12i3.902
   Bergmann J., 2012, FLIP YOUR CLASSROOM
   Bertrand P, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00026
   Biocca F, 1999, HUM FAC INF, V13, P113, DOI 10.1016/S0923-8433(99)80011-2
   Bishop J. L., 2013, ASEE National Conference Proceedings, V30, P1
   Boden Marie., 2013, Proceedings of the 12th International Conference on Interaction Design and Children, P228, DOI [10.1145/2485760.2485767, DOI 10.1145/2485760.2485767]
   Borrego A, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.01061
   Bostrom N, 2003, PHILOS QUART, V53, P243, DOI 10.1111/1467-9213.00309
   Bouras C, 2006, MULTIMED TOOLS APPL, V29, P153, DOI 10.1007/s11042-006-0005-7
   Bouras C, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P13, DOI 10.1109/ICALT.2001.943842
   Bouras C, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P1055, DOI 10.1109/MMCS.1999.778657
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brignull H., 2002, P INTERACT, V3, P17
   Buxton B., 1998, ACM SIGGRAPH COMPUTE, V32, P69, DOI [DOI 10.1145/307710.307732, 10.1145/307710.307732]
   Chee Y.S., 2002, Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community, P687
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Chun MM, 2003, J EXP PSYCHOL LEARN, V29, P224, DOI 10.1037/0278-7393.29.2.224
   Clarke-Midura J., 2011, The road ahead for state assessments, P27
   Corbit M, 2002, PRESENCE-TELEOP VIRT, V11, P55, DOI 10.1162/105474602317343659
   Cranton P., 2006, UNDERSTANDING PROMOT
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dede CJ, 2017, SMART COMPUT INTELL, P237, DOI 10.1007/978-981-10-5490-7_13
   Descartes Rene, 1993, Meditations on First Philosophy
   Dewey J., 1938, EXPERIENCE ED
   Dubois R, 2019, ACCESSIBLE LOCOMOTIO
   Dunleavy M., 2014, Handbook of Research on Educational Communications and Technology, P735, DOI [DOI 10.1007/978-1-4614-3185-5_59, 10.1007/978-1-4614-3185-5_59]
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Engestrom Y., 1999, Perspectives on activity theory, DOI [10.1017/CBO9780511812774, DOI 10.1017/CBO9780511812774]
   Engestrom Y., 1995, LEARNING EXPANDING A, V5, P319, DOI DOI 10.1016/0959-4752(95)00021-6
   Engestrom Y., 2016, Studies in expansive learning: Learning what is not yet there, DOI DOI 10.1017/CBO9781316225363
   Erickson T., 1993, VIRTUAL REAL-LONDON, P3, DOI 10.1016/ B978- 0- 12- 745045- 2.50009-X
   Falk J.H., 2016, MUSEUM EXPERIENCE RE
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Freitas R, 2008, P 22 BRIT HCI GROUP, P2
   Garcia A.S., 2008, P 7 ACM SIGGRAPH INT, p32:1
   Garg AX, 2002, ACAD MED, V77, pS97, DOI 10.1097/00001888-200210001-00030
   Grasset Raphael, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P231, DOI 10.1109/ISMAR.2006.297819
   Grasset R, 2005, P 4 IEEE ACM INT S M
   Grasset R, 2008, INT C ART REAL TEL I
   Greenwald ScottW., 2017, 12th International Conference on Computer Supported Collaborative Learning (CSCL), P1
   Greenwold Simon, 2003, Spatial computing
   Grotzer TA, 2015, TECHNOL KNOWL LEARN, V20, P43, DOI 10.1007/s10758-014-9241-5
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Hanson E, INDIGENOUS FDN ORAL
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hoang TN, 2017, PRESENCE-VIRTUAL AUG, V26, P402, DOI 10.1162/PRES_a_00307
   Irawati S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P201
   Ivanova G, 2014, P INT C E LEARN, P14
   Jacob R. J. K., 2008, P SIGCHI C HUM FACT
   Jenkins A., 2019, Fortune
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Johnson D.W., 2002, ASIA PAC J EDUC, V22, P95, DOI DOI 10.1080/0218879020220110
   Johnson D.W., 1989, COOPERATION COMPETIT
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Johnson-Glenberg MC, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0060-9
   Jonassen DH, 1999, ETR&D-EDUC TECH RES, V47, P61, DOI 10.1007/BF02299477
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Ketelhut DJ, 2010, BRIT J EDUC TECHNOL, V41, P56, DOI 10.1111/j.1467-8535.2009.01036.x
   Kieseberg P, 2015, ERCIM NEWS, P28
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   KIRSH D, 1994, COGNITIVE SCI, V18, P513, DOI 10.1207/s15516709cog1804_1
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kuutti K, 1993, P INTERACT 93 CHI 93
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lacoche J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139142
   Langbehn E, 2018, P IEEE WORKSH EV VIR
   Lave J., 1991, Situated Learning: Legitimate Peripheral Partic- ipation
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Leont'ev A.N., 1978, ACTIVITY CONSCIOUSNE
   Li Y., 2018, P 2018 3 DIGITAL HER, DOI 10.1109/DigitalHeritage.2018.8810126
   Liarokapis F., 2010, P EUROGRAPHICS, P9, DOI [10.2312/eged.20101010, DOI 10.2312/EGED.20101010]
   MacIntyre Blair., 2004, Presence: Teleoperators and Virtual Environments, V6, P197
   Magaki T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1072, DOI [10.1109/VR.2019.8797748, 10.1109/vr.2019.8797748]
   Maria Roussos, 1997, P ED MED ED TEL, V97, P917
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Zarzuela MM, 2013, PROCEDIA COMPUT SCI, V25, P382, DOI 10.1016/j.procs.2013.11.047
   Mazuryk T., 1996, Virtual reality-history, applications, technology and future
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Merriam S. B., 2013, Adult learning: Linking theory and practice
   Mezirow J., 2003, J TRANSFORM EDUC, V1, P58, DOI [DOI 10.1177/1541344603252172, 10.1177/1541344603252172]
   Michaels TCT, 2018, NEW J PHYS, V20, DOI 10.1088/1367-2630/aac0bc
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Milk Chris., 2015, Ted Talk
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Moglia A, 2016, EUR UROL, V69, P1065, DOI 10.1016/j.eururo.2015.09.021
   Monahan T, 2007, INT J EMERG TECHNOL, V2
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Nakamura Lisa, 1995, Works Days, V13, P181
   Nardi Bonnie A., 1995, Context and Consciousness: Activity Theory and Human-computer Interaction, P69
   Nonaka I., 1995, The Knowledge-Creating Company How Japanese Companies Create the Dynamics of Information, DOI DOI 10.1016/0024-6301(96)81509-3
   NUGENT GC, 1982, ECTJ-EDUC COMMUN TEC, V30, P163
   Otto O., 2006, VRCIA 06, P145, DOI DOI 10.1145/1128923.1128947
   Outlaw J., 2017, Why women don't like social virtual reality: A study of safety, usability and self-expression in social VR
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Paracuellos A, 2018, PROGR WEBXR
   Pinho MS, 2002, P ACM S VIRT REAL SO
   Plato, 1974, REPUBLIC
   Preece D, 2013, ANAT SCI EDUC, V6, P216, DOI 10.1002/ase.1345
   Preece J., 2000, Online communities. Designing usability, DOI DOI 10.1108/IMDS.2000.100.9.459.3
   Preuss S., 2019, FASHIONUNITED
   Proulx MJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00064
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Roberts D, 2003, PRESENCE-TELEOP VIRT, V12, P644, DOI 10.1162/105474603322955932
   Rogers K., 2019, P 2019 CHI C HUMAN F, P414
   Rose D.H., 2006, Journal of Postsecondary Education and Disability, V19, P135, DOI DOI 10.1016/J.APPLTHERMALENG.2016.10.067
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sawyer K., 2017, GROUP GENIUS CREATIV, V2nd
   Scavarelli A., 2017, P 2017 CHI C EXT ABS, P2915, DOI DOI 10.1145/3027063
   Scavarelli A, 2015, INT C HUM COMP
   Scavarelli A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1148, DOI [10.1109/vr.2019.8798100, 10.1109/VR.2019.8798100]
   Schrier K, 2006, ACM SIGGRAPH 2006 ED
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Schunk D., 1996, LEARNING THEORIES
   Shin DH, 2017, TELEMAT INFORM, V34, P1826, DOI 10.1016/j.tele.2017.05.013
   Sielhorst T, AUGMENTED REALITY DE
   Siemens G., 2005, Connectivism: learning as network creation
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smeets E, 2005, COMPUT EDUC, V44, P343, DOI 10.1016/j.compedu.2004.04.003
   Smith G, 1996, P 1996 ACM C COMP SU
   SMITH SM, 1979, J EXP PSYCHOL-HUM L, V5, P460, DOI 10.1037/0278-7393.5.5.460
   Southgate Erica, 2019, International Journal of Child-Computer Interaction, V19, P19, DOI 10.1016/j.ijcci.2018.10.002
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Stahl G., 2020, INT HDB COMPUTER SUP
   Stahl G, 2006, CAMB HANDB PSYCHOL, P409
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Stevenson Won A, HOMUNCULAR FLEXIBILI
   STYLIANI S, 2009, J CULT HERIT, V10, P520, DOI [DOI 10.1016/J.CULHER.2009.03.003, 10.1016/j.culher.2009.03.003]
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Thorsteinsson G., 2013, The Routledge International handbook of innovation education, P456
   Valve, STEAMVR UN PLUG
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Virtual Reality Labs, VIRT REAL LABS
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Weinbaum S.G., 1935, Pygmalion's Spectacles
   Wenger E., 1998, Communities of practice: learning, meaning, and identity, DOI [10.1017/CBO9780511803932, DOI 10.1017/CBO9780511803932]
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yang H, 2002, P 4 INT C COLL VIRT
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
   ZIMMERMAN BJ, 1989, J EDUC PSYCHOL, V81, P329, DOI 10.1037/0022-0663.81.3.329
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 179
TC 117
Z9 120
U1 65
U2 528
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 257
EP 277
DI 10.1007/s10055-020-00444-8
EA MAY 2020
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000535419900001
DA 2024-07-18
ER

PT J
AU Caserman, P
   Garcia-Agundez, A
   Konrad, R
   Göbel, S
   Steinmetz, R
AF Caserman, Polona
   Garcia-Agundez, Augusto
   Konrad, Robert
   Goebel, Stefan
   Steinmetz, Ralf
TI Real-time body tracking in virtual reality using a Vive tracker
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Real-time tracking; Full-body avatar; Low-latency; HTC
   Vive tracker; Inverse kinematics
ID LATENCY
AB Due to recent improvements in virtual reality (VR) technology, the number of novel applications for entertainment, education, and rehabilitation has increased. The primary goal of these applications is to enhance the sense of belief that the user is present in the virtual environment. By tracking the user's skeleton in real-time, it is possible to synchronize the avatar's motions with the user's motions. Although current common devices implement body tracking to a certain degree, most approaches are limited by either high latency or insufficient accuracy. Due to the lack of positional and rotation data, the current VR applications typically do not represent the user's motions. In this paper, we present an accurate, low-latency body tracking approach for VR-based applications using Vive Trackers. Using a HTC Vive headset and Vive Trackers, we have been able to create an immersive VR experience, by animating the motions of the avatar as smoothly, rapidly and as accurately as possible. An evaluation showed our solution is capable of tracking both joint rotation and position with reasonable accuracy and a very low end-to-latency of 6.71 +/- 0.80 ms. Due to this merely imperceptible delay and precise tracking, our solution can show the movements of the user in real-timein order to create deeper immersion.
C1 [Caserman, Polona; Garcia-Agundez, Augusto; Konrad, Robert; Goebel, Stefan; Steinmetz, Ralf] Tech Univ Darmstadt, Multimedia Commun Lab, D-64283 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Caserman, P (corresponding author), Tech Univ Darmstadt, Multimedia Commun Lab, D-64283 Darmstadt, Germany.
EM Polona.Caserman@kom.tu-darmstadt.de;
   Augusto.Garcia-Agundez@kom.tu-darmstadt.de;
   Robert.Konrad@kom.tu-darmstadt.de; Stefan.Gobel@kom.tu-darmstadt.de;
   Ralf.Steinmetz@kom.tu-darmstadt.de
RI Steinmetz, Patrick R. H./AAD-4093-2022; Garcia-Agundez,
   Augusto/AAK-5829-2021
OI Garcia-Agundez, Augusto/0000-0002-5440-1032; Caserman,
   Polona/0000-0002-3252-4533; Steinmetz, Ralf/0000-0002-6839-9359
CR [Anonymous], 2014, CHI 14 EXTENDED ABST, DOI [DOI 10.1145/2559206.2574827, 10.1145/2559206.2574827]
   [Anonymous], P ACM S VIRT REAL SO
   [Anonymous], P 2015 ACM INT JOINT
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Botev Jean, 2017, P 9THWORKSHOP MASSIV, P7, DOI [10.1145/3083207.3083209, DOI 10.1145/3083207.3083209]
   Caserman P, 2016, IEEE SYS MAN CYBERN, P3510, DOI 10.1109/SMC.2016.7844777
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   Choi S., 2016, SID, V47, P1381, DOI DOI 10.1002/sdtp.10930
   Collingwoode-Williams T, 2017, P IEEE VIRT REAL ANN, P253, DOI 10.1109/VR.2017.7892272
   Dempsey P., 2016, ENG TECHNOL, V11, P80
   Desai K, 2017, IEEE INT SYM MULTIM, P130, DOI 10.1109/ISM.2017.27
   Desai P R., 2014, International Journal of Engineering Trends and Technology (IJETT), V13, P175, DOI [DOI 10.14445/22315381/IJETT-V13P237, 10.14445/22315381/IJETT-V13P237]
   Farahani Navid, 2016, J Pathol Inform, V7, P22, DOI 10.4103/2153-3539.181766
   Frioriksson F. A., 2016, ICAT EGVE POST DEM, P19
   Friston S, 2014, IEEE T VIS COMPUT GR, V20, P616, DOI 10.1109/TVCG.2014.30
   Galna B, 2014, GAIT POSTURE, V39, P1062, DOI 10.1016/j.gaitpost.2014.01.008
   Goradia I., 2014, INT J CURRENT ENG TE, V4, P3196
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Huang J, 2017, COMPUT GRAPH FORUM, V36, P418, DOI 10.1111/cgf.13089
   Jain D., 2016, P 2016 CHI C HUM FAC, P1563
   Jiang F, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P309, DOI 10.1145/3013971.3013987
   Johnson M, 2016, P WORKSH ADV VIS INT, P316
   Kasahara S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6438, DOI 10.1145/3025453.3025962
   Kavan L, 2010, COMPUT GRAPH FORUM, V29, P327, DOI 10.1111/j.1467-8659.2009.01602.x
   Kenwright B, 2012, INT C CREAT CONT TEC, V4, P63
   Lange B., 2011, INTERSERVICE IND TRA
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P317, DOI 10.1145/2993369.2996308
   Martindale J., 2018, Oculus rift vs. HTC vive: Prices drop
   Melo M., 2016, P 7 INT C SOFTW DEV, P20
   NAKAMURA Y, 1986, J DYN SYST-T ASME, V108, P163, DOI 10.1115/1.3143764
   Orin D. E., 1984, International Journal of Robotics Research, V3, P66, DOI 10.1177/027836498400300404
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Raaen K, 2015, LECT NOTES COMPUT SC, V9353, P457, DOI 10.1007/978-3-319-24589-8_40
   Roberts D, 2009, IEEE ACM DIS SIM, P89, DOI 10.1109/DS-RT.2009.43
   Schmidt D., 2015, P 33 ANN ACM C, P359, DOI [10.1145/2702613.2725431, DOI 10.1145/2702613.2725431]
   Seele S, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P531, DOI 10.1145/3116595.3116619
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Shum H. P. H., 2012, P ACM S VIRT REAL SO, P17
   Sra Misha, 2015, ABS151202922 CORR
   Steed A., 2008, P 2008 ACM S VIRT RE, P123, DOI [10.1145/1450579.1450606, DOI 10.1145/1450579.1450606]
   Tao G., 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P164, DOI 10.1109/ICVR.2013.6662084
   Thomas JS, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2623787
NR 43
TC 62
Z9 69
U1 1
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 155
EP 168
DI 10.1007/s10055-018-0374-z
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500004
DA 2024-07-18
ER

PT J
AU Zhang, SY
   Dai, SL
AF Zhang, Shiyu
   Dai, Shuling
TI Workspace analysis for haptic feedback manipulator in virtual cockpit
   system
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual cockpit system (VCS); Haptic feedback; Workspace division; The
   Monte Carlo method; Boundary extraction; Volume calculation
ID ROBOT WORKSPACE
AB To obtain natural space experience of haptic interaction for users in virtual cockpit systems (VCS), a haptic feedback system and a workspace analysis framework for haptic feedback manipulator (HFM) are presented in this paper. Firstly, improving the classical three-dimensional workspace obtained by the Monte Carlo method, a novel workspace representation method, oriented workspace, is presented, which can indicate both the position and the orientation of the end-effector. Then, aimed at the characters of HFMs, the oriented workspace is divided into the effective workspace and the prohibited area by extracting the control panel area. At last, the effective workspace volume and the control panel area are calculated by the double-directed extremum method, with the accuracy improved by repeatedly adding and extracting boundary points. By simulation, the area in which interactions between the manipulator and users hand performed is determined and accordingly the effective workspace along with its boundary and volume are obtained in a relative high precision, which lay a basis for haptic interaction in VCS.
C1 [Zhang, Shiyu; Dai, Shuling] Beihang Univ, State Key Lab Virtual Real Technol & Syst, XueYuan Rd 37, Beijing, Peoples R China.
C3 Beihang University
RP Dai, SL (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, XueYuan Rd 37, Beijing, Peoples R China.
EM zhangshiyu@buaa.edu.cn; sldai@buaa.edu.cn
RI Zhang, Shiyu/KVY-5633-2024
OI Zhang, Shiyu/0000-0003-2474-7451
CR Alameldin TK, 2014, INT J COMPUT, V2, P48
   Bihari B, 2016, ROBOTICA, V34, P738, DOI 10.1017/S0263574714001830
   Cao Y, 2011, INT J ADV ROBOT SYST, V8, P1
   Ceccarelli Marco, 2013, International Journal of Mechanisms and Robotic Systems, V1, P2, DOI 10.1504/IJMRS.2013.051286
   [崔志宏 Cui Zhihong], 2016, [机械传动, Journal of Mechanical Transmission], V40, P85
   Dai Shu-ling, 2002, Journal of System Simulation, V14, P488
   Hatledal LI, 2015, ASME 2015 34 INT C O
   Hentz G, 2016, CR MECANIQUE, V344, P95, DOI 10.1016/j.crme.2015.10.001
   [侯雨雷 Hou Yulei], 2015, [中国机械工程, China Mechanical Engineering], V26, P308
   Jauer P, 2016, PROCEEDINGS OF 2016 THE 2ND INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS, P56, DOI 10.1109/ICCAR.2016.7486698
   Liu S, 1989, J UNIV SCI TECHNOL B, V11, P142
   [刘晓宇 Liu Xiaoyu], 2012, [机械设计, Journal of Machine Design], V29, P10
   [刘志忠 Liu Zhizhong], 2013, [农业机械学报, Transactions of the Chinese Society of Agricultural Machinery], V44, P230
   Porges O., 2014, ROBOT2013 1 IB ROB C, P703
   RASTEGAR J, 1990, J MECH DESIGN, V112, P452, DOI 10.1115/1.2912630
   Tang Y., 2012, THESIS
   THOMAS M, 1982, J DYN SYST-T ASME, V104, P218, DOI 10.1115/1.3139701
   [田海波 Tian Haibo], 2013, [农业机械学报, Transactions of the Chinese Society of Agricultural Machinery], V44, P196
   Wang Dangxiao, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P881
   Yang JZ, 2008, ROBOT CIM-INT MANUF, V24, P60, DOI 10.1016/j.rcim.2006.06.005
   Yin Feng, 2010, Control Theory & Applications, V27, P891
   Yu T., 2008, THESIS
   Zhong Y, 2004, MACHINE TOOL HYDRAUL, V4, P66
NR 23
TC 1
Z9 1
U1 0
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 321
EP 338
DI 10.1007/s10055-017-0327-y
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tyrrell, R
   Sarig-Bahat, H
   Williams, K
   Williams, G
   Treleaven, J
AF Tyrrell, Ryan
   Sarig-Bahat, Hilla
   Williams, Katrina
   Williams, Grace
   Treleaven, Julia
TI Simulator sickness in patients with neck pain and vestibular pathology
   during virtual reality tasks
SO VIRTUAL REALITY
LA English
DT Article
DE Simulator sickness; Dizziness; Virtual reality; Vestibular
ID MOTION SICKNESS; VISUAL DISTURBANCES; KINEMATICS; IMPAIRMENTS;
   DIZZINESS; SUSCEPTIBILITY; RELIABILITY; DISABILITY; SYMPTOMS
AB Immersion in virtual environments can cause simulator sickness (SS). Further, head and neck movement in interactive virtual reality (VR) assessment and training stimulates the vestibular and cervical afferent systems that can cause dizziness in subjects with neck pain and vestibular pathology. This cross-sectional, observational, study investigated SS and factors that may influence this between 20 neck pain, 14 vestibular pathology and 20 asymptomatic control subjects. Pre-VR questionnaires included a visual symptom scale and dizziness intensity. SS measures included the simulator sickness visual analogue scale and the simulator sickness questionnaire. Significantly greater incidence of any SS and higher values were found in the vestibular and neck pain groups compared to the control group in selected SS measures. No significant differences were found when comparing SS measures between the vestibular and neck pain groups. Significant mild-to-moderate correlations for the entire population were found between both SS measures to pre-VR visual symptoms and dizziness intensity. SS levels in neck pain and vestibular populations are comparable and higher than asymptomatic individuals. Dizziness and visual disturbances may be associated with an increase in severity of SS in these clinical populations.
C1 [Tyrrell, Ryan; Sarig-Bahat, Hilla; Williams, Katrina; Williams, Grace; Treleaven, Julia] Univ Queensland, St Lucia, Qld, Australia.
   [Sarig-Bahat, Hilla] Univ Haifa, Haifa, Israel.
C3 University of Queensland; University of Haifa
RP Tyrrell, R (corresponding author), Univ Queensland, St Lucia, Qld, Australia.
EM ryan.tyrrell@uq.net.au; hbahat@physicalvirtue.co.il;
   k.williams2@uq.edu.au; grace.williams1@uq.net.au; j.treleaven@uq.edu.au
RI Williams, Katrina/H-6511-2013; Treleaven, Julia/N-1379-2019
OI Williams, Katrina/0000-0001-5096-7752; Treleaven,
   Julia/0000-0002-6258-3972
FU Queensland Government
FX Equipment used in this study was purchased as part of the Health and
   Medical Research Grant from the Queensland Government.
CR Bahat HS, 2016, EUR SPINE J, V25, P2139, DOI 10.1007/s00586-016-4388-5
   Bahat HS, 2015, MANUAL THER, V20, P295, DOI 10.1016/j.math.2014.10.002
   Bahat HS, 2015, MANUAL THER, V20, P68, DOI 10.1016/j.math.2014.06.008
   Bahat HS, 2014, MANUAL THER, V19, P252, DOI 10.1016/j.math.2013.10.006
   Bahat HS, 2010, ARCH PHYS MED REHAB, V91, P1884, DOI 10.1016/j.apmr.2010.09.007
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   BRAITHWAITE MG, 1990, J SOC OCCUP MED, V40, P105
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Bryanton C, 2006, CYBERPSYCHOL BEHAV, V9, P123, DOI 10.1089/cpb.2006.9.123
   Chiu TT, 2005, ARCH PHYS MED REHAB, V86, P534, DOI 10.1016/j.apmr.2004.02.030
   Chu H, 2013, BMC COMPLEM ALTERN M, V13, DOI 10.1186/1472-6882-13-84
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hoy DG, 2010, BEST PRACT RES CL RH, V24, P783, DOI 10.1016/j.berh.2011.01.019
   JACOBSON GP, 1990, ARCH OTOLARYNGOL, V116, P424
   Jerome C, 2005, P HUM FACT ERG SOC
   Jinjakam C, 2012, BIOMED ENG INT CONF
   Jumisko-Pyykko S, 2010, 3DTV CON 2010 TRUE V
   Kawano N, 2012, AGING CLIN EXP RES, V24, P285, DOI 10.1007/BF03325260
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Ling Y, 2011, VTT SYMP, V269, P80
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Ohyama S, 2007, AURIS NASUS LARYNX, V34, P303, DOI 10.1016/j.anl.2007.01.002
   Paillard AC, 2013, J VESTIBUL RES-EQUIL, V23, P203, DOI 10.3233/VES-130501
   REGAN EC, 1994, AVIAT SPACE ENVIR MD, V65, P527
   Sarig-Bahat H, 2009, SPINE, V34, P1018, DOI 10.1097/BRS.0b013e31819b3254
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sjogaard G, 2000, EUR J APPL PHYSIOL, V83, P99, DOI 10.1007/s004210000285
   Sparto Patrick J, 2004, J Neuroeng Rehabil, V1, P14, DOI 10.1186/1743-0003-1-14
   Treleaven J, 2008, ARCH PHYS MED REHAB, V89, P522, DOI 10.1016/j.apmr.2007.11.002
   Treleaven J, 2016, MANUAL THER, V22, P109, DOI 10.1016/j.math.2015.10.015
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Treleaven J, 2014, MANUAL THER, V19, P203, DOI 10.1016/j.math.2014.01.005
   Treleaven J, 2011, SPINE, V36, pS211, DOI 10.1097/BRS.0b013e3182387f78
   Tsang SMH, 2013, CLIN BIOMECH, V28, P610, DOI 10.1016/j.clinbiomech.2013.05.009
   VERNON H, 1991, J MANIP PHYSIOL THER, V14, P409
   Warwick-Evans LA, 1998, BRAIN RES BULL, V47, P465, DOI 10.1016/S0361-9230(98)00090-2
   Webb CM, 2009, AVIAT SPACE ENVIR MD, V80, P541, DOI 10.3357/ASEM.2454.2009
   Wilhelmsen K, 2014, PHYS THER, V94, P1024, DOI 10.2522/ptj.20130070
   Winteler B, 2009, SWISS MED WKLY, V139, p10S
   Young SD, 2007, IEEE T VIS COMPUT GR, V13, P422, DOI [10.1109/TVCG.2007.1029, 10.1109/TVCG.2007.1041]
NR 42
TC 23
Z9 27
U1 1
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 211
EP 219
DI 10.1007/s10055-017-0324-1
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900003
DA 2024-07-18
ER

PT J
AU Attasiriluk, S
   Nakasone, A
   Hantanong, W
   Prada, R
   Kanongchaiyos, P
   Prendinger, H
AF Attasiriluk, Songpol
   Nakasone, Arturo
   Hantanong, Wisut
   Prada, Rui
   Kanongchaiyos, Pizzanu
   Prendinger, Helmut
TI Co-presence, collaboration, and control in environmental studies A
   Second Life-based approach
SO VIRTUAL REALITY
LA English
DT Article
DE Presence in shared virtual environments and online communities; Avatars;
   Presence applications (communications and collaboration; teleoperation)
ID REALITY
AB In this paper, we describe a framework for synchronous collaborative visualization and remote control in the agricultural domain. The framework builds on "Second Life" (SL), a popular networked online 3D virtual world, where users are represented as avatars (graphical self-representations). Co-presence in SL takes the form of instant (real-time) two-way interaction among two or more avatars. The aim of our work is to facilitate co-presence for sharing knowledge and exchanging wisdom about environmental practices. In order to establish a realistic simulated context for communication in SL, virtual counterparts of real devices are created in the virtual world. Specifically, we aim to represent field servers that sense and monitor fields such as rice paddies and vineyards. The Twin-World Mediator (TWM) is developed in order to replicate the behavior of real devices in virtual counterparts, and to facilitate seamless communication between real and virtual world. The TWM is an easy-to-use, extensible, and flexible communication framework. A small study demonstrated how the TWM can support collaboration and experience sharing in the agricultural domain.
C1 [Attasiriluk, Songpol; Nakasone, Arturo; Hantanong, Wisut; Prendinger, Helmut] Natl Inst Informat, Chiyoda Ku, Tokyo 1018430, Japan.
   [Attasiriluk, Songpol; Hantanong, Wisut; Kanongchaiyos, Pizzanu] Chulalongkorn Univ, Dept Comp Engn, Bangkok, Thailand.
   [Prada, Rui] INESC ID, IST UTL, P-2744016 Porto Salvo, Portugal.
C3 Research Organization of Information & Systems (ROIS); National
   Institute of Informatics (NII) - Japan; Chulalongkorn University;
   Universidade de Lisboa; INESC-ID
RP Prendinger, H (corresponding author), Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
EM arturonakasone@nii.ac.jp; wizzup@wizzup.com;
   rui.prada@gaips.inesc-id.pt; pizzanu@cp.eng.chula.ac.th;
   helmut@nii.ac.jp
RI Prada, Rui/AAK-7387-2020; Prada, Rui/A-6835-2012
OI Prada, Rui/0000-0002-5370-1893
FU NII, Tokyo
FX This research was partly supported by a "Grand Challenge" Grant from
   NII, Tokyo. We would like to thank Kazuki Kobayashi and Yasunori Saito
   from Shinshu University and the NARC research group for their kind
   support.
CR [Anonymous], J COMPUT MEDIATED CO
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Boellstorff T, 2008, COMING OF AGE IN SECOND LIFE: AN ANTHROPOLOGIST EXPLORES THE VIRTUALLY HUMAN, P1
   Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P233, DOI 10.1111/J.1471-1842.2007.00733.x
   BRANDHERM B, 2008, AAMAS 08, P1689
   Bray David A., 2007, Data Base for Advances in Information Systems, V38, P17, DOI 10.1145/1314234.1314239
   Bryson S, 1996, COMMUN ACM, V39, P62, DOI 10.1145/229459.229467
   CASANUEVA J, 2001, CS010200 U CAP TOWN
   DU K, 2008, DEV WEB BASED WIRELE, P799
   Eysenbach G, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1030
   FUNDINGER A, 2007, REAL LIFE CONTROL PA
   KOBAYASHI K, 2009, SHINSHU U FIELD SERV
   Leigh J, 1996, IEEE COMPUT GRAPH, V16, P47, DOI 10.1109/38.511853
   Lifton J, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P119, DOI 10.1109/IPSN.2007.4379671
   MANGAN J, 1997, PLA NOTES, P28
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Ogi T., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P87, DOI 10.1109/ICSMC.1999.816461
   *OPENMETAVERSE, 2009, VIRT WORLDS CONN LIB
   *OPENSIMULATOR, 2009, VIRT WORLDS SERV TEC
   Platel Richard., 2007, CREATING YOUR WORLD
   *SENSORML, 2009, SENS MOD LANG
   Valin S., 2001, P 34 ANN HAW INT C S
   VONKAPRI A, 2009, P PAC RIM S IM VID T
   Weaver AC, 2008, COMPUTER, V41, P97, DOI 10.1109/MC.2008.61
   Zhao SY, 2003, PRESENCE-VIRTUAL AUG, V12, P445, DOI 10.1162/105474603322761261
NR 25
TC 5
Z9 7
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 195
EP 204
DI 10.1007/s10055-009-0130-5
PN 1
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300007
DA 2024-07-18
ER

PT J
AU Stone, R
   White, D
   Guest, R
   Francis, B
AF Stone, Robert
   White, David
   Guest, Robert
   Francis, Benjamin
TI The Virtual Scylla: an exploration of "serious games", artificial life
   and simulation complexity
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Virtual heritage; Artificial life; Marine biology;
   Climate change; Simulation complexity
AB This paper addresses the integration of artificial life simulations with interactive games-based technologies and describes how the results are being exploited not only for scientific visualisation and education, but also for fundamental research into simulation complexity, focusing on the behavioural representation of species in fragile or long-vanished landscapes and ecosystems. Earlier research is described that supported the development of a virtual recreation of a submerged Mesolithic river valley, discovered during petrochemical surveys of the Southern Basin of the North Sea. Using pollen sample records and vegetation predictions from previous studies, a new alife "engine" was developed that simulated the interaction between "artificialised'' vegetation and environmental factors, thus helping researchers to postulate pre-glacial melting migratory and settlement patterns of ancient civilisations from continental Europe to the British Isles. More recently, and to take advantage of the existence of a more accessible and living ecosystem, work has been conducted in collaboration with the UK's National Marine Aquarium, this time focusing on the Scylla Artificial Reef-a Royal Navy frigate scuttled off the coast of Cornwall in South West England. The resulting "serious games"-based test beds are now providing the foundation for scientific investigations into how models and simulations of marine ecologies behave under different measures of complexity. The exploitation of the artificial life and underwater rendering efforts in others areas, including education and naval training, are also described.
C1 [Stone, Robert; White, David; Guest, Robert; Francis, Benjamin] Univ Birmingham, Human Interface Technol Team, Sch Elect Elect & Comp Engn, Birmingham B15 2TT, W Midlands, England.
C3 University of Birmingham
RP Stone, R (corresponding author), Univ Birmingham, Human Interface Technol Team, Sch Elect Elect & Comp Engn, Birmingham B15 2TT, W Midlands, England.
EM r.j.stone@bham.ac.uk
OI White, David/0000-0002-7095-8658
FU Advantage West Midlands
FX The authors would like to acknowledge contributions to the Virtual
   Scylla project from Debbie Snelling, Gareth Shaw and Paul Cox of the
   National Marine Aquarium, Dr Keith Hiscock of the Marine Biological
   Association, Dr Jason Hall-Spencer (University of Plymouth Marine
   Institute), Cdr Andy Waddington (Royal Navy Hydrographic, Meteorological
   and Oceanographic Training Group) and Mark Gormley (MEng student at the
   University of Birmingham). The previous alife research of Dr Eugene
   Ch'ng, now at the University of Wolverhampton is also acknowledged. The
   catalyst for Phase 1 of the Virtual Scylla project was a Royal Academy
   of Engineering grant to develop teaching in Integrated Systems Design.
   (based at the University of Plymouth and involving two of the
   authors-Robert Stone and Robert Guest). Phase 2 of the project was
   part-funded by Advantage West Midlands, via an Interactive Digital Media
   project coordinated by Birmingham City University.
CR [Anonymous], VSMM 2005 C EN BELG
   [Anonymous], 1996, HOME UNIVERSE SEARCH
   [Anonymous], 1989, P INT WORKSH SYNTH S
   [Anonymous], BAR BRIT SERIES
   [Anonymous], 1993, COMPLEXITY EMERGING
   Benford S, 2001, COMMUN ACM, V44, P79, DOI 10.1145/379300.379322
   Bonabeau E, 2000, SCI AM, V282, P72, DOI 10.1038/scientificamerican0300-72
   Bouras C, 2005, IEEE INT SYM MULTIM, P136
   Brooks R. J., 1999, UKSIM'99. Fourth National Conference of the UK Simulation Society, P88
   *CEFAS, 2005, ENV IMP RES DISP DRE
   Ch'ng E, 2006, PRESENCE-TELEOP VIRT, V15, P341, DOI 10.1162/pres.15.3.341
   CHNG E, 2005, P INT MULT SYST APPL
   CHNG E, 2004, P 5 INT S VIRT REAL
   Chwif L, 2000, PROCEEDINGS OF THE 2000 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P449, DOI 10.1109/WSC.2000.899751
   Clark J.G.D., 1936, MESOLITHIC SETTLEMEN
   FLACK S, 2006, ACM SIGGRAPH COMPUT, V40
   Fulton EA, 2003, MAR ECOL PROG SER, V253, P1, DOI 10.3354/meps253001
   Hiscock K, 2006, HYDROBIOLOGIA, V555, P309, DOI 10.1007/s10750-005-1127-z
   Holland JH., 1995, Hidden order: how adaptation builds complexity
   Holland JH, 1998, EMERGENCE CHAOS ORDE
   Kim KJ, 2006, ARTIF LIFE, V12, P153, DOI 10.1162/106454606775186455
   Kube C. Ronald, 1993, Adaptive Behavior, V2, P189, DOI 10.1177/105971239300200204
   LANGTON CG, 1986, P 5 ANN C CTR NONL S
   Langton CG., 1997, Artificial life: An overview
   LEECE, 2006, INGENIA, V29, P27
   LENTCZNER M, 2008, LINDEN LAB PUBLICATI
   Lewin R., 1993, Complexity: Life at the Edge of Chaos
   REFSLAND ST, 1998, LECT NOTES ARTIF INT, V1434, P323
   Reid C., 1913, SUBMERGED FORESTS
   Resnick Mitchel, 1994, Turtles, Termites and Traffic Jams: Explorations in Massively Parallel Microworlds
   Roberts P., 2002, TAKING WATER ENGLISH
   Robinson S, 2006, PROCEEDINGS OF THE 2006 WINTER SIMULATION CONFERENCE, VOLS 1-5, P792, DOI 10.1109/WSC.2006.323160
   SNELLING D, 2006, SCYLLA MONITORING PR
   Stone R., 1999, WORLD HERIT REV, Vb, P18
   von Neumann J., 1966, THEORY SELF REPRODUC
   WADDINGTON C, 2003, CURR ARCHAEOL, V16, P189
NR 36
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 13
EP 25
DI 10.1007/s10055-008-0111-0
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100003
DA 2024-07-18
ER

PT J
AU Chuang, TJ
   Tsai, YY
   Smith, S
AF Chuang, Tung-Jui
   Tsai, Yao-Yang
   Smith, Shana
TI A visuo-haptic mixed reality manual milling training simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Visuo-haptic; Mixed reality; Microsoft HoloLens 2; Manual milling
   operation
AB With the advancements in technology, mixed reality (MR) has found numerous applications in industries and job training. However, most MR applications only provide visual feedback, lacking realistic haptic feedback. Nevertheless, certain jobs require haptic sensations in the hands. To address this issue, this study integrates realistic haptic feedback into an MR environment and develops a visuo-haptic MR milling simulator for conventional manual milling operation training using Microsoft HoloLens 2. This simulator comprises a virtual spindle, a virtual milling tool, a virtual workpiece, and a physical mockup of the milling table. It provides realistic cutting force feedback when the virtual milling tool collides with the virtual workpiece. Users can operate the milling simulator with their bare hands and feel cutting force as if they were operating a real milling machine. The developed training system allows novices to intuitively understand the relationship between milling parameters and milling conditions. The usability and immersiveness of the visuo-haptic MR milling simulator are studied, and the results show that realistic haptic feedback increases usability, realism, immersiveness, and presence.
C1 [Chuang, Tung-Jui; Tsai, Yao-Yang; Smith, Shana] Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
C3 National Taiwan University
RP Smith, S (corresponding author), Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
EM ssmith@ntu.edu.tw
FU Ministry of Science and Technology, Taiwan, Republic of China [MOST
   110-2221-E-002-145]
FX AcknowledgmentsThe authors would like to thank the Ministry of Science
   and Technology, Taiwan, Republic of China for financially supporting
   this research under Contract MOST 110-2221-E-002-145.
CR Abou-El-Hossein KA, 2007, J MATER PROCESS TECH, V182, P241, DOI 10.1016/j.jmatprotec.2006.07.037
   Akshay N, 2013, IEEE IND ELEC, P6108, DOI 10.1109/IECON.2013.6700139
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chandran A, 2018, IEEE CONF TECHNOL ED, P97, DOI 10.1109/T4E.2018.00027
   Chardonnet J-R., 2017, RES SCI TODAY, V13, P25
   Chen YH, 2004, ROBOT CIM-INT MANUF, V20, P237, DOI 10.1016/j.rcim.2003.09.002
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cosco F, 2013, IEEE T VIS COMPUT GR, V19, P159, DOI 10.1109/TVCG.2012.107
   Crison F, 2005, P IEEE VIRT REAL ANN, P139
   Cukovic S, 2015, 12 IFIP INT C PROD L, P516, DOI DOI 10.1007/978-3-319-33111-9_47
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Fletcher C, 2013, COMPUT IND, V64, P1045, DOI 10.1016/j.compind.2013.07.005
   Geslain Benoit, 2021, SUI '21: Symposium on Spatial User Interaction, DOI 10.1145/3485279.3485291
   He XJ, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P435
   Hughes CL, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.602954
   Islam MS, 2022, APPL ERGON, V101, DOI 10.1016/j.apergo.2022.103694
   Loureiro SandraMaria Correia., 2020, Spanish Journal of Marketing - ESIC, DOI [DOI 10.1108/SJME-01-2020-0013, 10.1108/sjme-01-2020-0013]
   Minoufekr M, 2019, ICINCO: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL 2, P627, DOI 10.5220/0007920806270636
   Reyes AM, 2016, COMPUT APPL ENG EDUC, V24, P967, DOI 10.1002/cae.21772
   Pomerantz J., 2019, Information and Technology Transforming Lives: Connection, Interaction, Innovation, P137
   Shankhwar K, 2022, INT J ADV MANUF TECH, V121, P249, DOI 10.1007/s00170-022-09328-4
   STIFTER S, 1995, INT J ADV MANUF TECH, V10, P149, DOI 10.1007/BF01179343
   Tullis TS., 2006, US PROF ASS C, V1, P1
   Whelan T.J., 2008, SOCIAL PRESENCE MULT
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Yang CK, 2020, VIRTUAL REAL-LONDON, V24, P527, DOI 10.1007/s10055-019-00415-8
NR 27
TC 1
Z9 1
U1 8
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2417
EP 2430
DI 10.1007/s10055-023-00816-w
EA JUN 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001003553200001
DA 2024-07-18
ER

PT J
AU Tang, MW
   Ling, MG
   Tang, JL
   Hu, J
AF Tang, Mingwei
   Ling, Miaogui
   Tang, Jinglin
   Hu, Jie
TI A micro-expression recognition algorithm based on feature enhancement
   and attention mechanisms
SO VIRTUAL REALITY
LA English
DT Article
DE Micro-expression recognition; Feature enhancement; Attention mechanism;
   Feature extraction module; Local binary pattern
ID INFORMATION
AB In recent years, facial micro-expression recognition based on deep learning technology has become an important research hotspot. These techniques have been used by researchers in psychology, computer vision, and security to make breakthroughs. However, the proposed algorithm for micro-expression recognition faces some challenges in practical application. For example, the VGGMag method uses only one feature for micro-expression recognition, while the network cannot extract more useful features. The STRCN method does not focus on the key parts of facial micro-expressions, so that all parts of the face contribute equally to the micro-expression recognition model. A micro-expression recognition algorithm based on feature enhancement and attention mechanisms (FEAM) is proposed to further improve the recognition rate of micro-expressions. Firstly, the FEAM method designs a feature extraction module to extract micro-expression features and LBP image features, which preserves the texture information of the face. Secondly, the network constructs a feature augmentation module to highlight facial landmark points of faces as a way to increase the surrounding pixel weights. And then, the model designs the attention module to generate the attention correlation matrix of LBP and enhanced feature maps using the attention mechanism, which allows the network to pay more attention to the changes of features around the eyes and mouth of the face. Finally, the feature maps are input to the classification module for recognition. FEAM method is evaluated on three micro-expression datasets, and advanced results are obtained. The experimental results show that the proposed model FEAM can achieve state-of-the-art results compared to other models.
C1 [Tang, Mingwei; Ling, Miaogui; Tang, Jinglin] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
   [Hu, Jie] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Sichuan, Peoples R China.
C3 Xihua University; Southwest Jiaotong University
RP Tang, MW (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
EM tang4415@126.com
FU Scientific Research Funds project of Science and Technology Department
   of Sichuan Province [2019YFG0508, 2019GFW131]; Sichuan Key R D project
   [2023YFG0354]; National Natural Science Foundation of China [61902324];
   Funds Project of Chengdu Science and Technology Bureau
   [2017-RK00-00026-ZF, 2022-YF04-00065-JH]; Sichuan Youth Science and
   technology innovation research team; Science and Technology Planning
   Project of Guizhou Province; Xihua University Education and teaching
   reform project [xjjg2021115, QianKeHeJiChu-ZK[2021]YiBan319]; 
   [xjjg2021049]
FX This work is supported by the Scientific Research Funds project of
   Science and Technology Department of Sichuan Province (Nos. 2019YFG0508,
   2019GFW131, 2024JY**), Sichuan Key R & D project (No. 2023YFG0354), the
   National Natural Science Foundation of China (No. 61902324), Funds
   Project of Chengdu Science and Technology Bureau (Nos.
   2017-RK00-00026-ZF, 2022-YF04-00065-JH, 2023**), Sichuan Youth Science
   and technology innovation research team(2023**), Science and Technology
   Planning Project of Guizhou Province (No.
   QianKeHeJiChu-ZK[2021]YiBan319) and the Xihua University Education and
   teaching reform project (Nos: xjjg2021049, xjjg2021115).
CR Adegun IP, 2016, 2016 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH)
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   Azizi A, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/7179801
   Azizi A, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8564140
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Happy SL., 1949, IEEE T AFF COMPUT, V66, P1
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Jaiswal S, 2016, IEEE WINT CONF APPL
   Khor HQ, 2019, IEEE IMAGE PROC, P36, DOI [10.1109/icip.2019.8802965, 10.1109/ICIP.2019.8802965]
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Li J, 2019, PATTERN ANAL APPL, V22, P1331, DOI 10.1007/s10044-018-0757-5
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Li YT, 2021, IEEE T IMAGE PROCESS, V30, P249, DOI 10.1109/TIP.2020.3035042
   Li YT, 2018, IEEE IMAGE PROC, P3094, DOI 10.1109/ICIP.2018.8451376
   Litman Ron, 2020, CVPR, P11959, DOI 10.1109/CVPR42600.2020.01198
   Mayya V, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P699, DOI 10.1109/ICACCI.2016.7732128
   Munro J, 2020, PROC CVPR IEEE, P119, DOI 10.1109/CVPR42600.2020.00020
   Nie X, 2021, NEUROCOMPUTING, V427, P13, DOI 10.1016/j.neucom.2020.10.082
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Porter S, 2008, PSYCHOL SCI, V19, P508, DOI 10.1111/j.1467-9280.2008.02116.x
   Takalkar MA, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P688
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang Z., 2020, PATTERN RECOGNIT, V112
   Wu C, 2021, IEEJ T ELECTR ELECTR, V16, P98, DOI 10.1002/tee.23272
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Xiaojian Zhao., 2016, J COMPUT APPL, V36, P7
   Yan RJ, 2021, PROC CVPR IEEE, P284, DOI 10.1109/CVPR46437.2021.00035
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zhang M, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00329
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 36
TC 1
Z9 1
U1 16
U2 34
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2405
EP 2416
DI 10.1007/s10055-023-00808-w
EA JUN 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001003136600001
DA 2024-07-18
ER

PT J
AU Giardulli, B
   Battista, S
   Sansone, LG
   Manoni, M
   Francini, L
   Leuzzi, G
   Job, M
   Testa, M
AF Giardulli, Benedetto
   Battista, Simone
   Sansone, Lucia Grazia
   Manoni, Mattia
   Francini, Luca
   Leuzzi, Gaia
   Job, Mirko
   Testa, Marco
TI Real and perceived feet orientation under fatiguing and non-fatiguing
   conditions in an immersive virtual reality environment
SO VIRTUAL REALITY
LA English
DT Article
DE Position sense; Virtual reality; Fatigue; Lower limbs; Neuroscience;
   Proprioception
ID DYNAMIC POSTURAL CONTROL; JOINT POSITION SENSE; BODY REPRESENTATION;
   MUSCLE FATIGUE; PROPRIOCEPTION; VISION; KNEE; MOVEMENTS; EMOTIONS;
   BALANCE
AB Lower limbs position sense is a complex yet poorly understood mechanism, influenced by many factors. Hence, we investigated the position sense of lower limbs through feet orientation with the use of Immersive Virtual Reality (IVR). Participants had to indicate how they perceived the real orientation of their feet by orientating a virtual representation of the feet that was shown in an IVR scenario. We calculated the angle between the two virtual feet (alpha-VR) after a high-knee step-in-place task. Simultaneously, we recorded the real angle between the two feet (alpha-R) (T1). Hence, we assessed whether the acute fatigue impacted the position sense. The same procedure was repeated after inducing muscle fatigue (T2) and after 10 min from T2 (T3). Finally, we also recorded the time needed to confirm the perceived position before and after the acute fatigue protocol. Thirty healthy adults (27.5 +/- 3.8: 57% women, 43% men) were immersed in an IVR scenario with a representation of two feet. We found a mean difference between alpha-VR and alpha-R of 20.89 degrees [95% CI: 14.67 degrees, 27.10 degrees] in T1, 16.76 degrees [9.57 degrees, 23.94 degrees] in T2, and 16.34 degrees [10.00 degrees, 22.68 degrees] in T3. Participants spent 12.59, 17.50 and 17.95 s confirming the perceived position of their feet at T1, T2, T3, respectively. Participants indicated their feet as forwarding parallel though divergent, showing a mismatch in the perceived position of feet. Fatigue seemed not to have an impact on position sense but delayed the time to accomplish this task.
C1 [Giardulli, Benedetto; Battista, Simone; Sansone, Lucia Grazia; Manoni, Mattia; Francini, Luca; Leuzzi, Gaia; Job, Mirko; Testa, Marco] Univ Genoa, Dept Neurosci Rehabil Ophthalmol Genetics Maternal, Via Magliotto 2, I-17100 Savona, Italy.
C3 University of Genoa
RP Testa, M (corresponding author), Univ Genoa, Dept Neurosci Rehabil Ophthalmol Genetics Maternal, Via Magliotto 2, I-17100 Savona, Italy.
EM benedettogiardulli@gmail.com; simone.battista@edu.unige.it;
   luciagrazia.sansone@medicina.unige.it; manonimattia@gmail.com;
   luca.francini@unige.it; gaialeuzzi.gl@gmail.com;
   mirko.job.1991@hotmail.it; marco.testa@unige.it
RI Testa, Marianna/JAZ-0916-2023
OI Job, Mirko/0000-0002-0991-420X; Leuzzi, Gaia/0000-0002-8478-9621;
   Giardulli, Benedetto/0000-0002-0079-0714; Battista,
   Simone/0000-0002-7471-1951; Sansone, Lucia Grazia/0000-0002-4201-7762;
   Testa, Marco/0000-0001-8643-7200
FU Universita degli Studi di Genova within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Genova within
   the CRUI-CARE Agreement. The authors have no relevant financial or
   non-financial interests to disclose.
CR Abbruzzese G, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00961
   Abd-Elfattah HM, 2015, J ADV RES, V6, P351, DOI 10.1016/j.jare.2015.01.011
   Abdelkader NA, 2020, J MUSCULOSKEL NEURON, V20, P421
   Ates Y, 2020, SOMATOSENS MOT RES, V37, P307, DOI 10.1080/08990220.2020.1828057
   Batson Glenna, 2013, J Dance Med Sci, V17, P53
   Bayramova R, 2021, ATTEN PERCEPT PSYCHO, V83, P2865, DOI 10.3758/s13414-021-02344-8
   Beierholm UR, 2009, J VISION, V9, DOI 10.1167/9.5.23
   Bisson EJ, 2014, EXP BRAIN RES, V232, P837, DOI 10.1007/s00221-013-3795-7
   Eddy MD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130817
   Ferguson B., 2014, J CANADIAN CHIROPRAC, V58, P328, DOI DOI 10.1016/S0031-9406(10)61772-5
   Ferlinc Ana, 2019, Mater Sociomed, V31, P219, DOI 10.5455/msm.2019.31.219-221
   Fogg B.J., 2002, UBIQUITY, P2, DOI [DOI 10.1145/764008.763957, 10.1145/764008.763957]
   Ganea N, 2017, COGNITION, V162, P41, DOI 10.1016/j.cognition.2017.01.021
   Gear WS, 2011, J SPORT SCI MED, V10, P725
   Goldberg A, 2008, J NEUROL SCI, V270, P165, DOI 10.1016/j.jns.2008.03.002
   Harkins KM, 2005, J ATHL TRAINING, V40, P191
   Hatami Bahmanbegloo Z., 2021, MOT BEHAV, DOI [10.22089/MBJ.2021.10287.1959, DOI 10.22089/MBJ.2021.10287.1959]
   Herter TM, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-43
   HTC Vive, 2018, HTC VIVE TRACK 2018
   Immordino-Yang MH, 2016, EMOTION, V16, P1033, DOI 10.1037/emo0000201
   Jahjah A, 2018, BMC MUSCULOSKEL DIS, V19, DOI 10.1186/s12891-017-1909-2
   Jo D, 2022, J ELECTROMYOGR KINES, V65, DOI 10.1016/j.jelekin.2022.102676
   Johnston W, 2018, J SCI MED SPORT, V21, P103, DOI 10.1016/j.jsams.2017.06.007
   Kimmel M., 2013, Integral Review, V9, P300
   Kitayama S, 2006, J PERS SOC PSYCHOL, V91, P890, DOI 10.1037/0022-3514.91.5.890
   Körding KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Lagopoulos AP, 2019, SEMIOTICA, P193, DOI 10.1515/sem-2018-0041
   Lamb KL, 1999, BRIT J SPORT MED, V33, P336, DOI 10.1136/bjsm.33.5.336
   Larson DJ, 2018, HUM MOVEMENT SCI, V57, P13, DOI 10.1016/j.humov.2017.10.019
   Li L, 2019, J SPORT HEALTH SCI, V8, P218, DOI 10.1016/j.jshs.2018.09.010
   Longo MR, 2015, EUR PSYCHOL, V20, P6, DOI 10.1027/1016-9040/a000198
   Longo MR, 2010, P NATL ACAD SCI USA, V107, P11727, DOI 10.1073/pnas.1003483107
   Longo MR, 2010, NEUROPSYCHOLOGIA, V48, P655, DOI 10.1016/j.neuropsychologia.2009.08.022
   Maciejewski M, 2020, METROL MEAS SYST, V27, P601, DOI 10.24425/mms.2020.134841
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   Mohammadi F, 2013, J ATHL TRAINING, V48, P790, DOI 10.4085/1062-6050-48.3.06
   MonWilliams M, 1997, P ROY SOC B-BIOL SCI, V264, P1007, DOI 10.1098/rspb.1997.0139
   Myers JB, 1999, J ATHL TRAINING, V34, P362
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nieto-Guisado A, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010103
   Paillard J., 1968, The Neuropsychology of Spatially Oriented Behavior, P37
   Proske U, 2019, EXP BRAIN RES, V237, P2447, DOI 10.1007/s00221-019-05634-8
   Proske U, 2012, PHYSIOL REV, V92, P1651, DOI 10.1152/physrev.00048.2011
   Radziun D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24496-8
   Rand D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195043
   Rohe T, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002073
   Röijezon U, 2015, MANUAL THER, V20, P368, DOI 10.1016/j.math.2015.01.008
   Romero-Franco N, 2017, J MOTOR BEHAV, V49, P117, DOI 10.1080/00222895.2016.1152222
   ROSSETTI Y, 1995, J NEUROPHYSIOL, V74, P457, DOI 10.1152/jn.1995.74.1.457
   Samad M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117178
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sansone LG, 2022, VIRTUAL REAL-LONDON, V26, P903, DOI 10.1007/s10055-021-00584-5
   Spurgas AK, 2005, SOCIOL INQ, V75, P297, DOI 10.1111/j.1475-682X.2005.00124.x
   Steib S, 2013, J ATHL TRAINING, V48, P203, DOI 10.4085/1062-6050-48.1.08
   Stenneken P, 2006, NEUROREPORT, V17, P545, DOI 10.1097/01.wnr.0000209013.01470.f8
   Stenneken P, 2006, BRAIN RES, V1084, P123, DOI 10.1016/j.brainres.2006.02.057
   Stone KD, 2018, ACTA PSYCHOL, V185, P22, DOI 10.1016/j.actpsy.2018.01.007
   Touzalin-Chretien P, 2010, CEREB CORTEX, V20, P2007, DOI 10.1093/cercor/bhp271
   Vafadar AK, 2012, MOTOR CONTROL, V16, P265, DOI 10.1123/mcj.16.2.265
   Valori I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0222253
   Verschueren J, 2020, SPORTS MED, V50, P767, DOI 10.1007/s40279-019-01235-1
   von Castell C, 2021, J EXP PSYCHOL HUMAN, V47, P1132, DOI 10.1037/xhp0000933
   Vuillerme N, 2002, MED SCI SPORT EXER, V34, P1907, DOI 10.1097/00005768-200212000-00008
   WANN JP, 1992, EXP BRAIN RES, V91, P162
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wozny DR., 2008, J VISUAL-JAPAN, DOI [10.1167/8.3.2, DOI 10.1167/8.3.2]
NR 66
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2371
EP 2381
DI 10.1007/s10055-023-00809-9
EA JUN 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000999707900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chung, WL
   Barnett-Cowan, M
AF Chung, William
   Barnett-Cowan, Michael
TI Sensory reweighting: a common mechanism for subjective visual vertical
   and cybersickness susceptibility
SO VIRTUAL REALITY
LA English
DT Article
DE Multisensory integration; Sensory conflict; Sensory reweighting;
   Subjective vertical; Virtual reality; Cybersickness
ID MOTION SICKNESS; VIRTUAL-REALITY; HMD; ORIENTATION; SYMPTOMS; DYNAMICS
AB The malaise symptoms of cybersickness are thought to be related to the sensory conflict present in the exposure to virtual reality (VR) content. When there is a sensory mismatch in the process of sensory perception, the perceptual estimate has been shown to change based on a reweighting mechanism between the relative contributions of the individual sensory signals involved. In this study, the reweighting of vestibular and body signals was assessed before and after exposure to different typical VR experiences and sickness severity was measured to investigate the relationship between susceptibility to cybersickness and sensory reweighting. Participants reported whether a visually presented line was rotated clockwise or counterclockwise from vertical while laying on their side in a subjective visual vertical (SVV) task. Task performance was recorded prior to VR exposure and after a low- and high-intensity VR game. The results show that the SVV was significantly shifted away from the body representation of upright and towards the vestibular signal after exposure to the high-intensity VR game. Cybersickness measured using the fast motion sickness (FMS) scale found that sickness severity ratings were higher in the high intensity compared to the low-intensity experience. The change in SVV from baseline after each VR exposure modelled using a simple 3-parameter Gaussian regression fit was found to explain 49.5% of the variance in the FMS ratings. These results highlight the aftereffects of VR for sensory perception and suggest a potential relationship between the susceptibility to cybersickness and sensory reweighting.
C1 [Chung, William; Barnett-Cowan, Michael] Univ Waterloo, Dept Kinesiol, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Chung, WL; Barnett-Cowan, M (corresponding author), Univ Waterloo, Dept Kinesiol, Waterloo, ON N2L 3G1, Canada.
EM w8chung@uwaterloo.ca; mbc@uwaterloo.ca
OI Chung, William/0000-0002-6313-6752
FU Ontario Research Fund; Canadian Foundation for Innovation John R. Evans
   Leaders Fund [32618]; Natural Sciences and Engineering Research Council
   of Canada [RGPIN-03977-2020]
FX This research was supported by an Ontario Research Fund grant and
   Canadian Foundation for Innovation John R. Evans Leaders Fund Grant
   32618 and Natural Sciences and Engineering Research Council of Canada
   Grant RGPIN-03977-2020
CR Alberts BBGT, 2019, J NEUROPHYSIOL, V121, P1279, DOI 10.1152/jn.00481.2018
   Alberts BBGT, 2018, J NEUROPHYSIOL, V119, P1209, DOI 10.1152/jn.00082.2017
   Alberts BBGT, 2016, ENEURO, V3, DOI 10.1523/ENEURO.0093-16.2016
   Alberts BBGT, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12385
   Alberts BBGT, 2016, J NEUROPHYSIOL, V116, P30, DOI 10.1152/jn.00056.2016
   Allen B, 2016, ENTERTAIN COMPUT, V13, P1, DOI 10.1016/j.entcom.2016.01.001
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Assländer L, 2014, J NEUROPHYSIOL, V111, P1852, DOI 10.1152/jn.00669.2013
   Aubert H., 1861, VIRCHOWS ARCH, V20, P381, DOI DOI 10.1007/BF02355256
   Barnett-Cowan M, 2010, EUR J NEUROSCI, V31, P1899, DOI 10.1111/j.1460-9568.2010.07199.x
   BARRETT GV, 1968, J APPL PSYCHOL, V52, P304, DOI 10.1037/h0026013
   Beck B, 2020, NEUROPSYCHOLOGIA, V146, DOI 10.1016/j.neuropsychologia.2020.107546
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bos JE, 1998, BRAIN RES BULL, V47, P537, DOI 10.1016/S0361-9230(98)00088-4
   Carver S, 2006, BIOL CYBERN, V95, P123, DOI 10.1007/s00422-006-0069-5
   Cevette MJ, 2012, AVIAT SPACE ENVIR MD, V83, P549, DOI 10.3357/ASEM.3239.2012
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chardonnet JR, 2021, VIRTUAL REAL-LONDON, V25, P565, DOI 10.1007/s10055-020-00474-2
   Clemens IAH, 2011, J NEUROSCI, V31, P5365, DOI 10.1523/JNEUROSCI.6472-10.2011
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cohen B, 2019, J NEUROPHYSIOL, V121, P973, DOI 10.1152/jn.00674.2018
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Curthoys Ian S, 2012, Front Neurol, V3, P117, DOI 10.3389/fneur.2012.00117
   Dakin CJ, 2018, HAND CLINIC, V159, P43, DOI 10.1016/B978-0-444-63916-5.00003-3
   David-Grignot Stephane, 2014, Proceedings 2014 IEEE International Test Conference (ITC), DOI 10.1109/TEST.2014.7035301
   De Vrijer M, 2009, J VISION, V9, DOI 10.1167/9.2.9
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Dyde RT, 2006, EXP BRAIN RES, V173, P612, DOI 10.1007/s00221-006-0405-y
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Gallagher M, 2020, MULTISENS RES, V33, P625, DOI 10.1163/22134808-20201487
   Gallagher M, 2019, EUR J NEUROSCI, V50, P3557, DOI 10.1111/ejn.14499
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Gálvez-García G, 2015, HUM FACTORS, V57, P649, DOI 10.1177/0018720814554948
   Harris LR, 2017, NPJ MICROGRAVITY, V3, DOI 10.1038/s41526-016-0005-5
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lobel E, 1998, J NEUROPHYSIOL, V80, P2699, DOI 10.1152/jn.1998.80.5.2699
   Marinho AD, 2022, APPL ERGON, V101, DOI 10.1016/j.apergo.2022.103698
   Mayor J, 2021, IEEE T EMERG TOP COM, V9, P1542, DOI 10.1109/TETC.2019.2915287
   MITTELSTAEDT H, 1983, NATURWISSENSCHAFTEN, V70, P272, DOI 10.1007/BF00404833
   Muller GE., 1916, Z PSYCHOL PHYSIOL SI, V49, P109
   Ng AKT, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.08.004
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2023, VIRTUAL REAL-LONDON, V27, P1293, DOI 10.1007/s10055-022-00732-5
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Reason JT., 1975, INT J MAN MACH STUD
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2019, LECT NOTES COMPUT SC, V11574, P500, DOI 10.1007/978-3-030-21607-8_39
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reed-Jones R.J., 2007, P 4 INT DRIVING S HU, P534
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Smith SP, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100010
   Smyth J, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103264
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   Szpak A, 2020, J MED INTERNET RES, V22, DOI 10.2196/19840
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Tarnutzer AA, 2010, J NEUROPHYSIOL, V103, P934, DOI 10.1152/jn.00407.2009
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Toschi N, 2017, AUTON NEUROSCI-BASIC, V202, P108, DOI 10.1016/j.autneu.2016.10.003
   Varmaghani S, 2022, VIRTUAL REAL-LONDON, V26, P659, DOI 10.1007/s10055-021-00535-0
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Weech S, 2017, MULTISENS RES, V30, P65, DOI 10.1163/22134808-00002545
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
NR 80
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2029
EP 2041
DI 10.1007/s10055-023-00786-z
EA APR 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000961752500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Masneri, S
   Domínguez, A
   Sanz, M
   Zorrilla, M
   Larrañaga, M
   Arruarte, A
AF Masneri, Stefano
   Dominguez, Ana
   Sanz, Miguel
   Zorrilla, Mikel
   Larranaga, Mikel
   Arruarte, Ana
TI cleAR: an interoperable architecture for multi-user AR-based school
   curricula
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Multi-user interactions; Collaborative learning;
   Visual learning analytics; Artificial intelligence
ID AUGMENTED REALITY; EDUCATION
AB Although there are some experiences that demonstrate the validity of the use of augmented reality in schools to help students understand and retain complex concepts, augmented reality has not been widely adopted in the education sector yet. This is in part because it is hard to use augmented reality applications in collaborative learning scenarios and to integrate them in the existing school curricula. In this work, we present an interoperable architecture that simplifies the creation of augmented reality applications, enables multi-user student collaboration and provides advanced mechanisms for data analysis and visualization. A review of the literature together with a survey answered by 47 primary and secondary school teachers allowed us to identify the design objectives of cleAR, an architecture for augmented reality-based collaborative educational applications. cleAR has been validated through the development of three proofs of concept. cleAR provides a more mature technological ecosystem that will foster the emergence of augmented reality applications for education and their inclusion in existing school programs.
C1 [Masneri, Stefano; Dominguez, Ana; Larranaga, Mikel; Arruarte, Ana] Univ Basque Country UPV EHU, Comp Languages & Syst Dept, San Sebastian, Spain.
   [Sanz, Miguel; Zorrilla, Mikel] Fdn Vicomtech, Basque Res & Technol Alliance BRTA, San Sebastian, Spain.
C3 University of Basque Country
RP Masneri, S (corresponding author), Univ Basque Country UPV EHU, Comp Languages & Syst Dept, San Sebastian, Spain.
EM smasneri001@ikasle.ehu.eus; adominguez@vicomtech.org;
   msanz@vicomtech.org; mzorrilla@vicomtech.org; mikel.larranaga@ehu.eus;
   a.arruarte@ehu.eus
RI Arruarte, Ana/L-1569-2014; Masneri, Stefano/HZI-3897-2023; Sanz, Miguel
   A/H-1914-2015
OI Masneri, Stefano/0000-0003-1965-5704; 
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature
CR Abriata LA, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.260
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Azorín C, 2020, J PROF CAP COMMUNITY, V5, P381, DOI 10.1108/JPCC-05-2020-0019
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Bodily R, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS, P41, DOI 10.1145/3170358.3170409
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brusilovsky P., 2003, International Journal of Artificial Intelligence in Education (IJAIED), V13, P159, DOI [DOI 10.5555/1434845.1434847, 10.5555/1434845.1434847]
   CARBONEL.JR, 1970, IEEE T MAN MACHINE, VMM11, P190, DOI 10.1109/TMMS.1970.299942
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Chrysafiadi K, 2013, EXPERT SYST APPL, V40, P4715, DOI 10.1016/j.eswa.2013.02.007
   Clarke B, 2020, xAPI-Spec
   Coma-Tatay I, 2019, MULTIMED TOOLS APPL, V78, P6093, DOI 10.1007/s11042-018-6395-5
   Dinis FM, 2017, IEEE GLOB ENG EDUC C, P1683, DOI 10.1109/EDUCON.2017.7943075
   Fette I, 2011, WEBSOCKET PROTOCOL, V6455, P1, DOI [DOI 10.17487/RFC6455, 10.17487/RFC6455]
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Goregaokar M, 2022, WEBXR DEVICE API CAN
   Holmberg C, 2015, 7478 RFC, DOI [10.17487/RFC7478, DOI 10.17487/RFC7478]
   Ibáñez MB, 2018, COMPUT EDUC, V123, P109, DOI 10.1016/j.compedu.2018.05.002
   Johnson D.W., 2018, ACTIVE LEARNING BEYO, DOI DOI 10.5772/INTECHOPEN.81086
   Kuehn BM, 2018, JAMA-J AM MED ASSOC, V319, P756, DOI 10.1001/jama.2017.20800
   Kuh G.D., 2011, Piecing together the student success puzzle: Research, propositions and recommendations
   Lazar J., 2017, RES METHODS HUMAN CO, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   López-Faican L, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2020.103814
   Martin J, 2018, 2018 IEEE 13TH INTERNATIONAL SCIENTIFIC AND TECHNICAL CONFERENCE ON COMPUTER SCIENCES AND INFORMATION TECHNOLOGIES (CSIT), VOL 1, P231, DOI 10.1109/STC-CSIT.2018.8526676
   Masneri S, 2022, J UNIVERS COMPUT SCI, V28, P564, DOI 10.3897/jucs.76535
   Mousavinasab E, 2021, INTERACT LEARN ENVIR, V29, P142, DOI 10.1080/10494820.2018.1558257
   Nkambou R, 2010, STUD COMPUT INTELL, V308, P1
   Oh S, 2018, IEEE T LEARN TECHNOL, V11, P115, DOI 10.1109/TLT.2017.2750673
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Schez-Sobrino S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041518
   Sedlmeier P., 2001, International Encyclopedia of the Social & Behavioral Sciences, P7674, DOI DOI 10.1016/B0-08-043076-7/01618-1
   Theron, 2020, VISUAL LEARNING ANAL, P99, DOI [10.1007/978-981-15-4526-9_7, DOI 10.1007/978-981-15-4526-9_7]
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Vieira C, 2018, COMPUT EDUC, V122, P119, DOI 10.1016/j.compedu.2018.03.018
   Waskom M., 2021, Journal of Open Source Software, V6, P3021, DOI [DOI 10.21105/JOSS.03021, 10.21105/JOSS.03021]
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
NR 38
TC 5
Z9 5
U1 7
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1813
EP 1825
DI 10.1007/s10055-023-00764-5
EA FEB 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000938849100001
PM 37360814
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kállai, J
   Zsidó, AN
   Tamás, I
   Topa, K
   Kállai, KM
   Páll, T
AF Kallai, Janos
   Zsido, Andras Norbert
   Tamas, Istvan
   Topa, Kristof
   Kallai, Kata M.
   Pall, Tamas
TI Postural instability-induced compensative movements in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Attention allocation; Reference taking; Compensative hand drift;
   Immersion; Posture; Hemispace; Virtual reality
ID ILLUSION; EMPATHY
AB During virtual reality usage, two egocentric mental representations are constructed simultaneously. The first representation is rooted in the physical reality in which VR is set up, and the second originates from the mental construction of a computer-generated virtual environment. In both cases, participants configure their posture based on multimodal stimuli while responding to environmental cues. In most cases, the postural cues provided by the digital and real environment may be conflicting. In this study, 50 right-handed volunteers were enrolled. In a pre-test session, attentional focus-related personality bias (perspective-taking) was assessed, and afterward, postural movements and presence experiences were measured while the participants performed a spatial orientation task in VR. Participants were placed in an upright position with their right hands positioned in front of a physically real point on the laboratory wall. Afterward, participants were exposed to a VR environment in which they performed a room-tilting task. Participants with higher hand-related presence scores showed decreased compensatory hand drift in the VR environment. The rate of contralateral hand drift showed a reversed association with the intensity of the perspective-taking trait. VR-induced postural instability can be attenuated by the compensative hand drift that alleviates the conflicts between the two rival inner VR and outer VR environments that compete for attention and provide different reference cues.
C1 [Kallai, Janos; Tamas, Istvan] Univ Pecs, Med Sch, Inst Behav Sci, Szigeti St 12, H-7625 Pecs, Hungary.
   [Zsido, Andras Norbert; Topa, Kristof] Univ Pecs, Arts & Sci Fac, Inst Psychol, Pecs, Hungary.
   [Kallai, Kata M.] MUTO Artist Run Independent Platform & Art Collec, Budapest, Hungary.
   [Pall, Tamas] Univ Appl Arts Vienna, Artist Res, Vienna, Austria.
C3 University of Pecs; University of Pecs; Hungarian Research Network;
   HUN-REN Research Centre for Natural Sciences
RP Kállai, J (corresponding author), Univ Pecs, Med Sch, Inst Behav Sci, Szigeti St 12, H-7625 Pecs, Hungary.
EM janos.kallai@aok.pte.hu; zsido.andras@pte.hu; tamas.pista@gmail.com;
   kristoftopa@gmail.com; kata.mkallai@gmail.com; contact@tamaspall.com
RI Zsido, Andras/AAC-6489-2019
OI Zsido, Andras/0000-0003-0506-6861; Kallai, Janos/0000-0002-5914-0855
FU Ministry for Innovation and Technology [NKFI K-120334, OTKA PD 137588,
   UNKP-21-4]
FX This study was supported by the NKFI K-120334 grant (JK) OTKA PD 137588,
   and UNKP-21-4 New National Excellence Program of the Ministry for
   Innovation and Technology from the source of the National Research,
   Development, and Innovation Fund, (ANZS).
CR Azañón E, 2016, MULTISENS RES, V29, P635, DOI 10.1163/22134808-00002531
   Berniker M, 2011, WIRES COGN SCI, V2, P419, DOI 10.1002/wcs.125
   Blanchard DC, 2008, HBK BEHAV NEUROSCI, V17, P63, DOI 10.1016/S1569-7339(07)00005-7
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Chander H, 2019, BEHAV SCI-BASEL, V9, DOI 10.3390/bs9110113
   Crawford JD, 2004, J NEUROPHYSIOL, V92, P10, DOI 10.1152/jn.00117.2004
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   de Souza CR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221398
   de Vignemont F, 2010, NEUROPSYCHOLOGIA, V48, P669, DOI 10.1016/j.neuropsychologia.2009.09.022
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fransson PA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39104-6
   Freiherr J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00863
   Gallagher S., 2005, BODY SHAPES MIND
   Guerraz M, 2008, NEUROPHYSIOL CLIN, V38, P391, DOI 10.1016/j.neucli.2008.09.007
   Ha H, 2014, J PHYS THER SCI, V26, P121, DOI 10.1589/jpts.26.121
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Horak F., 1996, MD AM PHYSL SOC, P255, DOI DOI 10.1002/CPHY.CP120107
   Ivanenko Y, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00171
   Jacob RG, 2009, J NEUROL NEUROSUR PS, V80, P74, DOI 10.1136/jnnp.2007.136432
   Jacobs WJ, 1999, CAN J EXP PSYCHOL, V53, P92, DOI 10.1037/h0087302
   Kallai J, 2019, HUNGARIAN REV PSYCHO, V74, p181 200
   Kallai J, 2007, BEHAV NEUROSCI, V121, P21, DOI 10.1037/0735-7044.121.1.21
   Kennett S, 2002, PERCEPT PSYCHOPHYS, V64, P1083, DOI 10.3758/BF03194758
   Klatzky R. L., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P1
   Kulcsar ZS, 1998, HLTH PSYCHOL
   Laarni J, 2005, P CYB 2005 4 INT CYB
   Lezak M, 1995, NEUROPSYCHOLOGICAL A
   Meilinger T, 2010, LECT NOTES ARTIF INT, V6222, P207, DOI 10.1007/978-3-642-14749-4_19
   Mishra S, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11010051
   Moseley GL, 2012, NEUROSCI BIOBEHAV R, V36, P34, DOI 10.1016/j.neubiorev.2011.03.013
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   Nijhuis LBO, 2009, J NEUROPHYSIOL, V101, P2802, DOI 10.1152/jn.90945.2008
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Paillard J., 1991, Brain and Science, P163
   Prinz W., 1990, Relationships between perception and action, P167201
   Pulos S, 2004, SOC BEHAV PERSONAL, V32, P355, DOI 10.2224/sbp.2004.32.4.355
   Reitan RM, 1985, COMPREHENSIVE HDB PS, V1985, DOI 10.1016/S1134-5934(06)75362-3.
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2009, VIRTUAL REAL-LONDON, V13, P159, DOI 10.1007/s10055-009-0121-6
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Stamenkovic A, 2018, J NEUROPHYSIOL, V120, P2066, DOI 10.1152/jn.00200.2018
   Stins JF, 2009, BEHAV BRAIN FUNCT, V5, DOI 10.1186/1744-9081-5-42
   Thatcher A, 2005, 4 INT CYB C ERG
   The Jamovi Project, 2021, JAM VERS 2 0 COMP SO
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Wallach HA, 2012, SYSTEMS HLTH CARE US, V3, P123
   Wallach HS, 2009, VIRTUAL REAL-LONDON, V13, P205, DOI 10.1007/s10055-009-0122-5
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wulf G, 2013, INT REV SPORT EXER P, V6, P77, DOI 10.1080/1750984X.2012.723728
   Zaki J, 2014, PSYCHOL BULL, V140, P1608, DOI 10.1037/a0037679
NR 57
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1251
EP 1263
DI 10.1007/s10055-022-00716-5
EA DEC 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000900082400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Dong, Y
   Liu, XY
   Tang, M
   Huo, HQ
   Chen, D
   Wu, ZX
   An, R
   Fan, YB
AF Dong, Ying
   Liu, Xiaoyu
   Tang, Min
   Huo, Hongqiang
   Chen, Duo
   Wu, Zhixin
   An, Ran
   Fan, Yubo
TI A haptic-feedback virtual reality system to improve the Box and Block
   Test (BBT) for upper extremity motor function assessment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Box and Block Test; Haptic device; Stroke; Validity;
   Reliability; Motivation
ID UPPER-LIMB REHABILITATION; ROBOT-ASSISTED THERAPY; STROKE PATIENTS;
   OUTCOME MEASURES; ARM MOVEMENTS; MOTION; DEFICITS; DEVICES; GAME;
   STIMULATION
AB The Box and Block Test (BBT) has been widely used to assess gross upper extremity (UE) motor function. We designed a haptic-feedback virtual reality (VR) system, named the VBBT, to improve the BBT for more specific assessments. The VBBT task required users to move virtual blocks from one compartment of a virtual box to the other within one minute. The focus of this pilot study was to examine the validity, reliability and motivation of the novel assessment. Totally, 113 healthy subjects and 16 post-stroke patients were recruited for a thorough evaluation. We found that scores of the BBT and VBBT were significantly correlated, both of which declined as participants' age. The normative ranges of kinematic metrics in different age groups were used to identify deficiencies in UE motor function involving smoothness, hand dexterity and motion efficiency. Also, a significant correlation between the VBBT and Action Research Arm Test (ARAT) (|r|>= 0.56) indicated concurrent validity of the novel assessment. Test-retest results indicated that the VBBT assessment had high reliability (ICCs = 0.62-0.80). The Intrinsic Motivation Inventory results showed that the VBBT was given higher scores for the enjoyment (p < 0.05) and completion effort (p < 0.05) than that for the BBT, indicating patients have greater motivation in the VBBT assessment. In conclusion, the VBBT can provide validated, reliable and motivative assessment for UE motor function with kinematic metrics. It suggests that the haptic-feedback VR contributes to the BBT in specific assessments of UE motor function.
C1 [Dong, Ying; Liu, Xiaoyu; Tang, Min; Huo, Hongqiang; Chen, Duo; Wu, Zhixin; An, Ran; Fan, Yubo] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Biol Sci & Med Engn, Key Lab Biomech & Mechanobiol,Minist Educ, Beijing 100083, Peoples R China.
   [Fan, Yubo] Beihang Univ, Sch Med Sci & Engn Med, Beijing 100083, Peoples R China.
   [Liu, Xiaoyu; Fan, Yubo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100083, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Liu, XY; Fan, YB (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Biol Sci & Med Engn, Key Lab Biomech & Mechanobiol,Minist Educ, Beijing 100083, Peoples R China.; Fan, YB (corresponding author), Beihang Univ, Sch Med Sci & Engn Med, Beijing 100083, Peoples R China.; Liu, XY; Fan, YB (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100083, Peoples R China.
EM x.y.liu@buaa.edu.cn; yubofan@buaa.edu.cn
RI Tang, Min/KOC-3090-2024
FU National Key R&D Program of China [2020YFC2007904]; National Nature
   Science Foundation of China [U20A20390, 11827803]; State Key Laboratory
   of Virtual Reality Technology and Systems, Beihang University
   [VRLAB2018T01]
FX This work was supported by the National Key R&D Program of China under
   Grant 2020YFC2007904, the National Nature Science Foundation of China
   under Grant U20A20390 and 11827803 and the Open Project Funding from the
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University under Grant VRLAB2018T01.
CR Adomaviciene A, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55040098
   Akay M., 2001, REHABILITATION TREAT
   Al-Sada M, 2020, VIRTUAL REAL-LONDON, V24, P191, DOI 10.1007/s10055-019-00404-x
   Alvarez-Rodriguez M, 2020, World J Neurosci, V10, P79, DOI [DOI 10.4236/WJNS.2020.101009, 10.4236/wjns.2020.101009]
   Arlati S, 2022, VIRTUAL REAL-LONDON, V26, P885, DOI 10.1007/s10055-021-00603-5
   Augenstein TE, 2022, VIRTUAL REAL-LONDON, V26, P525, DOI 10.1007/s10055-021-00593-4
   Bardorfer A, 2001, IEEE-ASME T MECH, V6, P253, DOI 10.1109/3516.951363
   Baur K, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0449-9
   Bortone I, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00771-6
   Bortone I, 2018, IEEE T NEUR SYS REH, V26, P1469, DOI 10.1109/TNSRE.2018.2846814
   BOX GEP, 1982, J AM STAT ASSOC, V77, P209, DOI 10.2307/2287791
   Broeks JG, 1999, DISABIL REHABIL, V21, P357
   Broeren J, 2004, ARCH PHYS MED REHAB, V85, P1247, DOI 10.1016/j.apmr.2003.09.020
   Brown D, 2015, PHYSIOTHERAPY, V101, P126, DOI 10.1016/j.physio.2015.01.002
   Burridge J, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00567
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Alarcón-Aldana AC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20215989
   Chiang VCL, 2017, DISABIL REHABIL-ASSI, V12, P672, DOI 10.1080/17483107.2016.1218554
   Cho S, 2016, IEEE COMPUT GRAPH, V36, P70, DOI 10.1109/MCG.2015.2
   Choi JW, 2020, IEEE T NEUR SYS REH, V28, P1614, DOI 10.1109/TNSRE.2020.2998123
   Chou WH, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14063213
   Choukou MA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083712
   Colombo R, 2005, IEEE T NEUR SYS REH, V13, P311, DOI 10.1109/TNSRE.2005.848352
   Colombo R, 2019, IEEE T NEUR SYS REH, V27, P664, DOI 10.1109/TNSRE.2019.2905076
   Crocetta TB, 2018, VIRTUAL REAL-LONDON, V22, P199, DOI 10.1007/s10055-017-0323-2
   Cuesta-Gómez A, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00718-x
   Cunningham DA, 2015, PHYS MED REH CLIN N, V26, P759, DOI 10.1016/j.pmr.2015.07.001
   Daoud MI, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082416
   Davis GA, 2014, BRIT J SPORT MED, V48, P98, DOI 10.1136/bjsports-2012-092132
   de Vet HCW, 2006, J CLIN EPIDEMIOL, V59, P1033, DOI 10.1016/j.jclinepi.2005.10.015
   DEGRAAF JB, 1991, EXP BRAIN RES, V84, P434, DOI 10.1007/BF00231466
   Dong Y, 2020, DESIGN HAPTIC COMBIN, DOI [10.21203/rs.3.rs-32776/v1, DOI 10.21203/RS.3.RS-32776/V1]
   Escalona F, 2020, VIRTUAL REAL-LONDON, V24, P567, DOI 10.1007/s10055-019-00419-4
   Eskofier BM, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7100986
   Everard G, 2022, J NEUROENG REHABIL, V19, DOI 10.1186/s12984-022-00981-0
   Fei F, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12040362
   Feigin VL, 2018, NEW ENGL J MED, V379, P2429, DOI 10.1056/NEJMoa1804492
   Feix T, 2016, IEEE T HUM-MACH SYST, V46, P66, DOI 10.1109/THMS.2015.2470657
   Fernández-González P, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0593-x
   Feyzioglu O, 2020, SUPPORT CARE CANCER, V28, P4295, DOI 10.1007/s00520-019-05287-x
   Fluet Marie-Christine, 2011, IEEE Int Conf Rehabil Robot, V2011, P5975348, DOI 10.1109/ICORR.2011.5975348
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fong KNK, 2022, VIRTUAL REAL-LONDON, V26, P453, DOI 10.1007/s10055-021-00583-6
   Francisco-Martínez C, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062258
   FUGLMEYER AR, 1975, SCAND J REHABIL MED, V7, P13
   Furmanek MP, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0525-9
   Gagnon C, 2014, J NEUROL SCI, V347, P341, DOI 10.1016/j.jns.2014.09.032
   Garcia-Hernandez N, 2021, VIRTUAL REAL-LONDON, V25, P669, DOI 10.1007/s10055-020-00481-3
   Gerber LH, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-117
   Germanotta M, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0032-6
   Gervasi O, 2010, VIRTUAL REAL-LONDON, V14, P131, DOI 10.1007/s10055-009-0149-7
   Gieser S. N., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P3, DOI 10.1007/978-3-319-39907-2_1
   Gorsic M, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0231-4
   Gutiérrez A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062476
   Han JH, 2017, ADV MECH ENG, V9, DOI 10.1177/1687814017743388
   Hawe RL, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-0654-1
   Hebert JS, 2014, J REHABIL RES DEV, V51, P919, DOI 10.1682/JRRD.2013.10.0228
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Hesse S, 2003, CURR OPIN NEUROL, V16, P705, DOI 10.1097/00019052-200312000-00010
   Hoeg ER, 2023, VIRTUAL REAL-LONDON, V27, P245, DOI 10.1007/s10055-021-00544-z
   Huang XW, 2018, J STROKE CEREBROVASC, V27, P221, DOI 10.1016/j.jstrokecerebrovasdis.2017.08.027
   Hussain N, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0551-7
   Ishikawa R, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103511
   Johnson CO, 2019, LANCET NEUROL, V18, P439, DOI 10.1016/S1474-4422(19)30034-1
   Kantak SS, 2017, PHYS THER, V97, P718, DOI 10.1093/ptj/pzx042
   Kanzler CM, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0286-7
   Knippenberg E, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0270-x
   Knobel SEJ, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00180
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Krabben T, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-15
   Krebs H I, 1998, IEEE Trans Rehabil Eng, V6, P75, DOI 10.1109/86.662623
   Krebs HI, 2014, STROKE, V45, P200, DOI 10.1161/STROKEAHA.113.002296
   Lamers I, 2014, ARCH PHYS MED REHAB, V95, P1184, DOI 10.1016/j.apmr.2014.02.023
   Law LLF, 2018, BRIT J OCCUP THER, V81, P641, DOI 10.1177/0308022618770141
   Lederman SJ, 2009, ATTEN PERCEPT PSYCHO, V71, P1439, DOI 10.3758/APP.71.7.1439
   Lee SI, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2829208
   Levin MF, 2015, IEEE T NEUR SYS REH, V23, P1047, DOI 10.1109/TNSRE.2014.2387412
   Li CG, 2020, CYBERNET SYST, V52, P3, DOI 10.1080/01969722.2020.1827798
   Li KY, 2020, BIOMED J, V43, P484, DOI 10.1016/j.bj.2019.10.004
   Lin KC, 2010, J REHABIL RES DEV, V47, P563, DOI 10.1682/JRRD.2009.09.0155
   Lin LF, 2018, EUR J PHYS REHAB MED, V54, P388, DOI 10.23736/S1973-9087.17.04691-3
   Little CE, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0070-0
   Liu XY, 2019, IEEE T NEUR SYS REH, V27, P984, DOI 10.1109/TNSRE.2019.2909287
   Lupinetti K, 2019, LECT NOTES COMPUT SC, V11613, P43, DOI 10.1007/978-3-030-25965-5_5
   Mani S, 2013, BRAIN, V136, P1288, DOI 10.1093/brain/aws283
   Masiero S, 2011, J REHABIL RES DEV, V48, P355, DOI 10.1682/JRRD.2010.04.0063
   Matamala-Gomez M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01962
   MATHIOWETZ V, 1985, AM J OCCUP THER, V39, P386, DOI 10.5014/ajot.39.6.386
   Mazzoleni S, 2014, IEEE T HAPTICS, V7, P175, DOI 10.1109/TOH.2013.73
   Mesquita IA, 2019, TOP STROKE REHABIL, V26, P464, DOI 10.1080/10749357.2019.1611221
   Mihelj M, 2012, PRESENCE-TELEOP VIRT, V21, P1, DOI 10.1162/PRES_a_00078
   Mochizuki G, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0618-5
   Morita Y, 2006, ICMIT 2005 MECHATRON
   Muller G, 1970, MOVEMENT THERAPY HEM
   Nordin N, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-137
   Norouzi-Gheidari N, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010113
   Novak D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-64
   Okamoto S, 2012, VIRTUAL REAL-LONDON, V16, P141, DOI 10.1007/s10055-011-0192-z
   Oktay AB, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101683
   Olesh EV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104487
   Oña ED, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102773
   Oña ED, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132586
   Ovbiagele B, 2013, STROKE, V44, P2361, DOI 10.1161/STR.0b013e31829734f2
   Ozturk A, 2016, MEASUREMENT, V80, P207, DOI 10.1016/j.measurement.2015.11.026
   Pandyan AD, 2005, DISABIL REHABIL, V27, P2, DOI 10.1080/09638280400014576
   Parish L., 1957, BRIT J EDUC STUD, V5, P191, DOI [10.2307/3118885, DOI 10.2307/3118885]
   Pashley GL, 2021, J BIOMECH, V129, DOI 10.1016/j.jbiomech.2021.110825
   Pieri L, 2022, VIRTUAL REAL-LONDON, V26, P639, DOI 10.1007/s10055-021-00526-1
   Puthenveetil SC, 2015, VIRTUAL REAL-LONDON, V19, P119, DOI 10.1007/s10055-015-0261-9
   Putrino D, 2017, GAMES HEALTH J, V6, P295, DOI 10.1089/g4h.2016.0108
   Qin WT, 2019, NEUROSCI LETT, V712, DOI 10.1016/j.neulet.2019.134479
   Rohrer B, 2002, J NEUROSCI, V22, P8297
   Rojo A, 2023, VIRTUAL REAL-LONDON, V27, P3, DOI 10.1007/s10055-022-00668-w
   Santisteban L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154792
   Saposnik G, 2016, LANCET NEUROL, V15, P1019, DOI 10.1016/S1474-4422(16)30121-1
   Schwarz A, 2019, STROKE, V50, P718, DOI 10.1161/STROKEAHA.118.023531
   Semrau JA, 2017, NEUROREHAB NEURAL RE, V31, P571, DOI 10.1177/1545968317704903
   Semrau JA, 2013, STROKE, V44, P3414, DOI 10.1161/STROKEAHA.113.002058
   Shull PB, 2014, GAIT POSTURE, V40, P11, DOI 10.1016/j.gaitpost.2014.03.189
   Song XY, 2019, IEEE T NEUR SYS REH, V27, P2186, DOI 10.1109/TNSRE.2019.2939587
   Steinisch M, 2012, BIOMED ENG-BIOMED TE, V57, P841, DOI 10.1515/bmt-2012-4160
   Strickland D, 1997, ST HEAL T, V44, P81
   Tarakci E, 2020, J HAND THER, V33, P220, DOI 10.1016/j.jht.2019.03.012
   TAUB E, 1993, ARCH PHYS MED REHAB, V74, P347
   Thompson-Butel AG, 2015, NEUROREHAB NEURAL RE, V29, P341, DOI 10.1177/1545968314547766
   Tobler-Ammann BC, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0116-y
   Tran J, 2013, CANADIAN STROKE C
   Vaisrub N., 2009, JAMA, V302, P2260, DOI DOI 10.1001/JAMA.2009.1734
   Valencia N, 2017, BIOSYST BIOROBOT, V15, P1445, DOI 10.1007/978-3-319-46669-9_237
   van Wijck FMJ, 2001, NEUROREHAB NEURAL RE, V15, P23, DOI 10.1177/154596830101500104
   Velstra IM, 2011, PM&R, V3, P846, DOI 10.1016/j.pmrj.2011.03.014
   Vergnault M., 2017, RETOUR NUM RO, DOI [10.1016/j.kine.2017.02.053, DOI 10.1016/J.KINE.2017.02.053]
   Villa R, 2018, EXP BRAIN RES, V236, P2123, DOI 10.1007/s00221-018-5286-3
   Voinescu A, 2021, J CLIN MED, V10, DOI 10.3390/jcm10071478
   Volpe BT, 2009, ARCH NEUROL-CHICAGO, V66, P1086, DOI 10.1001/archneurol.2009.182
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Wade E, 2011, TOP STROKE REHABIL, V18, P685, DOI 10.1310/tsr1806-685
   Walker RW, 2016, ACTA NEUROL SCAND, V133, P49, DOI 10.1111/ane.12422
   Wann JP, 1997, ST HEAL T, V44, P157
   Wei WXJ, 2019, IEEE T NEUR SYS REH, V27, P51, DOI 10.1109/TNSRE.2018.2882235
   Weir JP, 2005, J STRENGTH COND RES, V19, P231, DOI 10.1519/15184.1
   Cohen MW, 2020, AI SOC, V35, P581, DOI 10.1007/s00146-019-00925-8
   Wilson LR, 1999, BRAIN, V122, P2079, DOI 10.1093/brain/122.11.2079
   Winter C, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00848-w
   Wu YT, 2019, BURNS, V45, P157, DOI 10.1016/j.burns.2018.08.001
   Yildirim Y, 2021, GAMES HEALTH J, V10, P180, DOI 10.1089/g4h.2020.0182
   Yoo DH, 2013, J PHYS THER SCI, V25, P407, DOI 10.1589/jpts.25.407
   Young KJ, 2019, 3D PRINT MED, V5, DOI 10.1186/s41205-019-0044-0
   Yozbatiran N, 2008, NEUROREHAB NEURAL RE, V22, P78, DOI 10.1177/1545968307305353
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
   Zariffa J, 2012, IEEE T NEUR SYS REH, V20, P341, DOI 10.1109/TNSRE.2011.2181537
   Zollo L, 2011, MED BIOL ENG COMPUT, V49, P1131, DOI 10.1007/s11517-011-0808-1
NR 152
TC 6
Z9 6
U1 11
U2 43
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1199
EP 1219
DI 10.1007/s10055-022-00727-2
EA DEC 2022
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000895033800001
DA 2024-07-18
ER

PT J
AU Tian, N
   Lopes, P
   Boulic, R
AF Tian, Nana
   Lopes, Phil
   Boulic, Ronan
TI A review of cybersickness in head-mounted displays: raising attention to
   individual susceptibility
SO VIRTUAL REALITY
LA English
DT Review
DE Cybersickness; Virtual reality; Literature review; Individual
   susceptibility
ID VISUALLY INDUCED MOTION; VIRTUAL-REALITY; SIMULATOR SICKNESS; FREQUENCY
   DYNAMICS; USER EXPERIENCE; VR SICKNESS; QUESTIONNAIRE; ENJOYMENT; TIME;
   ENVIRONMENTS
AB Cybersickness still poses a significant challenge to the widespread usage of virtual reality, leading to different levels of discomfort and potentially breaking the immersive experience. Researchers have attempted to discover the possible fundamental causes of cybersickness for years. Despite the longstanding interest in the research field, inconsistent results have been drawn on the contributing factors and solutions to combating cybersickness. Moreover, little attention has been paid to individual susceptibility. A consolidated explanation remains under development, requiring more empirical studies with robust and reproducible methodologies. This review presents an integrated survey connecting the findings from previous review papers and the state of the art involving empirical studies and participants. A literature review is then presented, focusing on the practical studies of different contributing factors, the pros and cons of measurements, profiles of cybersickness, and solutions to reduce this phenomenon. Our findings suggest a lack of considerations regarding user susceptibility and gender balance in between groups studies. In addition, incongruities among empirical findings raised concerns. We conclude by suggesting points of insights for future empirical investigations.
C1 [Tian, Nana; Boulic, Ronan] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
   [Lopes, Phil] Univ Lusofona, Lisbon, Portugal.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Lusofona University
RP Tian, N (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM nana.tian@epfl.ch
OI Lopes, Phil/0000-0002-9567-5806; Tian, Nana/0000-0002-5615-3378
FU SNF [CRSII5_180319/1]; Fundacao para a Ciencia e Tecnologia (FCT) under
   the HEI-Lab center [UIDB/05380/2020]; EPFL Lausanne; Fundação para a
   Ciência e a Tecnologia [UIDB/05380/2020] Funding Source: FCT
FX This research has been supported by the SNF grant CRSII5_180319/1 and
   Phil Lopes is partially by the Fundacao para a Ciencia e Tecnologia
   (FCT) under the HEI-Lab center (UIDB/05380/2020). Open access funding
   provided by EPFL Lausanne.
CR Adhanom IB, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3448304
   Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Agic A., 2020, VR J GRAPH ENG, V11, P5
   Al Zayer M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300584
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Aldaba CN, 2020, MED BIOL ENG COMPUT, V58, P143, DOI 10.1007/s11517-019-02070-2
   Aldaba CN, 2017, IEEE ENG MED BIO, P4175, DOI 10.1109/EMBC.2017.8037776
   Alexandrovsky D., EXAMINING DESIGN CHO, P1, DOI DOI 10.1145/3313831.3376260
   Almeida A, 2018, ADV INTELL SYST, V588, P26, DOI 10.1007/978-3-319-60582-1_3
   Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   Ang S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P460, DOI [10.1109/VRW50115.2020.00097, 10.1109/VRW50115.2020.0-179]
   Anwar MS, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091530
   Aoyama K, 2015, SCI REP-UK, V5, DOI 10.1038/srep10168
   Arafat IM, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P113, DOI 10.1109/VR.2018.8446194
   Ashiri M, 2020, P 11 AUGM HUM INT C, P1
   Ashiri M, 2021, VIRTUAL REAL-LONDON, V25, P731, DOI 10.1007/s10055-020-00488-w
   Ashiri M, 2020, ANN BIOMED ENG, V48, P1241, DOI 10.1007/s10439-019-02446-3
   Ashiri M, 2019, J MED BIOL ENG, V39, P238, DOI 10.1007/s40846-018-0425-7
   Ashton MC, 2004, J PERS SOC PSYCHOL, V86, P356, DOI 10.1037/0022-3514.86.2.356
   Balaji P, 2021, IEEE INT SM C CONF, DOI 10.1109/ISC253183.2021.9562830
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bingcheng Wang, 2019, Cross-Cultural Design. Methods, Tools and User Experience. 11th International Conference, CCD 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11576), P291, DOI 10.1007/978-3-030-22577-3_21
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Brown DJ, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00034
   Brument Hugo, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P20, DOI 10.1007/978-3-030-62655-6_2
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chattha UA, 2020, IEEE ACCESS, V8, P130486, DOI 10.1109/ACCESS.2020.3007076
   Chen C. Y., 2021, VIRTUAL REAL-LONDON, P1
   Cheung B, 1998, BRAIN RES BULL, V47, P421, DOI 10.1016/S0361-9230(98)00095-1
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364722
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   Cortes CAT, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365694
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis Simon., 2015, 11th Australasian Conference on Interactive Entertainment (IE 2015), P27, DOI DOI 10.17973/MMSJ.2015
   del Cid DA, 2021, ERGONOMICS, V64, P69, DOI 10.1080/00140139.2020.1820083
   Dennison M, 2018, APPL ERGON, V71, P9, DOI 10.1016/j.apergo.2018.03.015
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Elwardy M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P477, DOI [10.1109/VRW50115.2020.00100, 10.1109/VRW50115.2020.0-176]
   Eunhee Chang, 2018, Journal of KIISE, V45, P251, DOI 10.5626/JOK.2018.45.3.251
   Farmani Y, 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Freiwald Jann Philipp, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P115, DOI 10.1145/3404983.3410022
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Gallagher M, 2020, MULTISENS RES, V33, P625, DOI 10.1163/22134808-20201487
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Garcia-Agundez A., 2019, IJVR, V19, P1, DOI DOI 10.20870/IJVR.2019.19.1.2907
   Garcia-Agundez A, 2019, GAMES HEALTH J, V8, P439, DOI 10.1089/g4h.2019.0045
   Garde, 2018, 2018 CHI C HUM FACT, DOI 10.1145/3170427.3188638
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Gersak G, 2020, MULTIMED TOOLS APPL, V79, P14491, DOI 10.1007/s11042-018-6969-2
   Gilbert SB, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P161, DOI 10.1109/VRW52623.2021.00037
   Gonçalves G, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2018)
   Grassini S, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030007
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Greenlee MW, 2016, MULTISENS RES, V29, P525, DOI 10.1163/22134808-00002527
   Gruden T., 2021, SENSORS SWITZERLAND, V21, P1
   Guna J, 2020, MOBILE NETW APPL, V25, P1436, DOI 10.1007/s11036-019-01373-w
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Hakkinen J, 2018, J IMAGING SCI TECHN, V62, DOI 10.2352/J.ImagingSci.Technol.2018.62.6.060403
   Hansen JP, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299048
   Harada T, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.763040
   Heo J, 2020, J ELECTR ENG TECHNOL, V15, P1323, DOI 10.1007/s42835-020-00373-1
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Hopper JE, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1663, DOI [10.1109/VR.2019.8797756, 10.1109/vr.2019.8797756]
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Hsiao CY, 2019, INT C APPL HUM FACT, P34
   Hu P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356490
   Hu Y, 2021, COMPUTERS, V10, DOI 10.3390/computers10060080
   Hunt X, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P598, DOI 10.1145/3292147.3292225
   Hussain R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124006
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Hwang AD., 2018, ELECT IMAG, V2018, P1
   Iskenderova A, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P561, DOI 10.1145/3116595.3116618
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Jabbar AIA, 2015, REV EDUC RES, V85, P740, DOI 10.3102/0034654315577210
   Jacob Habgood M. P., 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P371, DOI 10.1109/VR.2018.8446130
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/VR.2019.8798334, 10.1109/vr.2019.8798334]
   Jin WN, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P382, DOI 10.1109/GEM.2018.8516469
   Jung S, 2021, IEEE T VIS COMPUT GR, V27, P2669, DOI 10.1109/TVCG.2021.3067773
   Kala Nupur, 2017, SID Symposium Digest of Technical Papers, V48, P1645, DOI 10.1002/sdtp.11956
   Käser DP, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085094
   Katsigiannis S, 2019, IEEE T CONSUM ELECTR, V65, P119, DOI 10.1109/TCE.2018.2879065
   Kaufeld M, 2019, LECT NOTES COMPUT SC, V11574, P461, DOI 10.1007/978-3-030-21607-8_36
   Kennedy R.S. Frank., 1985, REV MOTION SICKNESS
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2022, CURR OPIN NEUROL, V35, P107, DOI 10.1097/WCO.0000000000001018
   Keshavarz B, 2023, HUM FACTORS, V65, P107, DOI 10.1177/00187208211008687
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Khaitami, 2019, 2019 International Seminar on Intelligent Technology and Its Applications (ISITIA), P325, DOI 10.1109/ISITIA.2019.8937083
   Khoirunnisaa AZ, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (IBIOMED), P48, DOI 10.1109/IBIOMED.2018.8534877
   Kim HG, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139137
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2004, BRAIN RES BULL, V64, P265, DOI 10.1016/j.brainresbull.2004.07.008
   Kim J, 2022, IEEE T NEUR NET LEAR, V33, P554, DOI 10.1109/TNNLS.2020.3028080
   Kim J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217808
   Kim NG, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091919
   Kim S, 2018, J SOC INF DISPLAY, V26, P376, DOI 10.1002/jsid.669
   Kim S, 2020, IEEE IMAGE PROC, P3433, DOI 10.1109/ICIP40778.2020.9190721
   Kim W, 2021, IEEE T IMAGE PROCESS, V30, P559, DOI 10.1109/TIP.2020.3036782
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Koch KL, 2014, EXP BRAIN RES, V232, P2553, DOI 10.1007/s00221-014-4007-9
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Kuosmanen Toni., 2019, The effect of visual detail on cybersickness: Predicting symptom severity using spatial velocity
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee JY, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145697
   Lee J, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9050078
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Li XL, 2020, COMPUT METH PROG BIO, V188, DOI 10.1016/j.cmpb.2019.105266
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   Lim HK, 2021, NEUROSCI LETT, V743, DOI 10.1016/j.neulet.2020.135589
   Lim K, 2021, VIRTUAL REAL-LONDON, V25, P331, DOI 10.1007/s10055-020-00457-3
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Litleskare S, 2021, PHYSIOL BEHAV, V236, DOI 10.1016/j.physbeh.2021.113422
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Lopes P., 2020, MOTION INTERACTION G, P1
   Lopes P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P795, DOI [10.1109/VRW50115.2020.00-27, 10.1109/VRW50115.2020.00248]
   Luks R, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P280, DOI 10.1145/3316782.3321535
   MacArthur C, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445701
   Magaki T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1072, DOI [10.1109/VR.2019.8797748, 10.1109/vr.2019.8797748]
   Marengo J, 2019, IEEE CONF COMPU INTE
   Martirosov S., 2018, Annals of DAAAM Proceedings, DOI DOI 10.2507/28TH.DAAAM.PROCEEDINGS.101
   Matsuoka Y. R., 2018, 2018 JOINT PROP C JU, P1, DOI DOI 10.2514/6.2018-4595
   Mayor J, 2021, IEEE T EMERG TOP COM, V9, P1542, DOI 10.1109/TETC.2019.2915287
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   McHugh, 2019, MEASURING MINIMIZING
   Melo MC, 2019, IMMERSIVE VIDEO USER, DOI [10.1007/s10209-017-0581-5, DOI 10.1007/S10209-017-0581-5]
   Melo M, 2018, COMPUT GRAPH-UK, V71, P159, DOI 10.1016/j.cag.2017.11.007
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Monteiro P, 2018, COMPUT GRAPH-UK, V77, P80, DOI 10.1016/j.cag.2018.10.003
   Murray M. M, 2011, The neural bases of multisensory processes
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Napadow V, 2013, CEREB CORTEX, V23, P806, DOI 10.1093/cercor/bhs073
   Naqvi SAA, 2015, AUSTRALAS PHYS ENG S, V38, P721, DOI 10.1007/s13246-015-0379-9
   Narciso D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P115, DOI [10.1109/ICGI47575.2019.8955071, 10.1109/icgi47575.2019.8955071]
   Ng AKT, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.08.004
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Niu YF, 2019, J IMAGING SCI TECHN, V63, DOI 10.2352/J.ImagingSci.Technol.2019.63.6.060413
   Norouzi N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225162
   Oman C. M., 1991, PICTORIAL COMMUNICAT, P362
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Pane ES, 2018, INT CONF INTEL INFOR, P170, DOI 10.1109/ICIIBMS.2018.8549968
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Pöhlmann KMT, 2021, MULTISENS RES, V34, P623, DOI 10.1163/22134808-bja10049
   Porcino T, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201649
   Porter J, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P277, DOI 10.1145/3311350.3347159
   Rangelova Stanislava, 2020, HCI in Mobility, Transport, and Automotive Systems. Automated Driving and In-Vehicle Experience Design. Second International Conference, MobiTAS 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12212), P146, DOI 10.1007/978-3-030-50523-3_11
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2019, LECT NOTES COMPUT SC, V11574, P500, DOI 10.1007/978-3-030-21607-8_39
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Recenti M, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.635661
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Ryge AN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P675, DOI 10.1109/VR.2018.8446206
   Sagnier C, 2020, ADV INTELL SYST, V972, P305, DOI 10.1007/978-3-030-19135-1_30
   Sakai H, 2022, HUM BRAIN MAPP, V43, P1103, DOI 10.1002/hbm.25710
   Sakhare AR, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00218
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sarupuri B, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P138, DOI 10.1145/3131277.3132177
   Schöberl F, 2020, FRONT NEURAL CIRCUIT, V14, DOI 10.3389/fncir.2020.00006
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Shi RK, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451255
   Smith SP, 2021, IEEE ACCESS, V9, P68898, DOI 10.1109/ACCESS.2021.3077899
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   So RHY, 2007, LECT NOTES COMPUT SC, V4563, P386
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Stone W. B., 2017, Ph.D. dissertation
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Terenzi L, 2020, AIAA SCITECH 2020 FO, P0171
   Tian N, 2020, 2019 IEEE C GAM COG, P1
   Tian NN, 2020, IEEE CONF COMPU INTE, P359, DOI 10.1109/CoG47356.2020.9231830
   Tiiro A., 2018, EFFECT VISUAL REALIS, V350
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   Vailland G, 2020, ACMIEEE INT CONF HUM, P171, DOI 10.1145/3319502.3374825
   Vasylevska K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P566, DOI [10.1109/VR.2019.8797752, 10.1109/vr.2019.8797752]
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P672, DOI [10.1109/VR46266.2020.00-14, 10.1109/VR46266.2020.1581256520838]
   Wang Y, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0731-5
   Wang YY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P373, DOI 10.1109/VR50410.2021.00060
   Wang YY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1874, DOI [10.1109/VR.2019.8798213, 10.1109/vr.2019.8798213]
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wibirama S, 2018, ENTERTAIN COMPUT, V26, P117, DOI 10.1016/j.entcom.2018.02.003
   Widyanti A, 2022, VIRTUAL REAL-LONDON, V26, P631, DOI 10.1007/s10055-021-00525-2
   Wienrich C., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications, P1, DOI [DOI 10.1109/VS-GAMES.2018.8493408, DOI 10.1109/VS-GAMES.2018, 10.1109/VS-Games.2018.8493408]
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Yamamura H, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P223, DOI 10.1145/3458709.3458994
   Yildirim C, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P351, DOI 10.1109/AIVR50618.2020.00072
   Yildirim C, 2019, DISPLAYS, V59, P35, DOI 10.1016/j.displa.2019.07.002
   Young SD, 2007, IEEE T VIS COMPUT GR, V13, P422, DOI [10.1109/TVCG.2007.1029, 10.1109/TVCG.2007.1041]
   Zhong WX, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22115797
   Zielasko D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P165, DOI 10.1109/VRW52623.2021.00038
   Zukowska M, 2019, LECT N MECH ENG, P137, DOI 10.1007/978-3-030-18715-6_12
NR 229
TC 39
Z9 41
U1 7
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1409
EP 1441
DI 10.1007/s10055-022-00638-2
EA MAR 2022
PG 33
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000767021500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ventura, S
   Cebolla, A
   Latorre, J
   Escrivá-Martínez, T
   Llorens, R
   Baños, R
AF Ventura, Sara
   Cebolla, Ausias
   Latorre, Jorge
   Escriva-Martinez, Tamara
   Llorens, Robert
   Banos, Rosa
TI The benchmark framework and exploratory study to investigate the
   feasibility of 360-degree video-based virtual reality to induce a full
   body illusion
SO VIRTUAL REALITY
LA English
DT Article
DE 360-degree video; Immersive technology; Embodiment; Body illusion; Media
   comparison; Panorama camera
ID RUBBER HAND ILLUSION; EMBODIMENT; EXPERIENCE; OWNERSHIP; AVATAR; SELF
AB The feeling of ownership of a virtual body has been a topic of interest in recent years. In order to observe the mechanisms involved in the perception of the body illusion and its manipulation, the use of virtual reality (VR) has been essential. Various technical VR set-ups have been adopted by different authors to induce the sense of embodiment. Recently, 360-degree technology camera emerged as an innovative instrument to generate an immersive experience, with positive results in terms of involvement with the scenario. The current study aims to test the feasibility of the 360-degree video-based VR to induce a full body illusion. To do this, we evaluated two different groups receiving different levels of immersion: a 3D immersive video and a 2D non-immersive video. Self-reported sense of embodiment and heart rate variability (HRV) measures were analyzed. The results of the embodiment questionnaire showed that the immersive condition can trigger a full body illusion, with significant differences between the 3D and 2D conditions (ownership: p = .003, agency: p = .000, location: p = .013, haptic sensation: p = .027). No difference was found on the Root Mean Square of the Successive Differences (RMSSD) index-the beat-to-beat variance of the heart rate-of the HRV measure (first 90 s: p = .168, last 90 s: p = .401). Based on these results, future studies are needed to investigate the 360-degree video-based VR technology as a medium to generate the sense of embodiment.
C1 [Ventura, Sara] Univ Bologna, Dept Psychol, I-40127 Bologna, Italy.
   [Cebolla, Ausias; Escriva-Martinez, Tamara; Banos, Rosa] Univ Valencia, Fac Psychol, Dept Personal Evaluat & Psychol Treatment, Valencia 46010, Spain.
   [Cebolla, Ausias; Banos, Rosa] Inst Salud Carlos III, CIBERObn Physiopathol Obes & Nutr, Madrid 28029, Spain.
   [Latorre, Jorge; Llorens, Robert] Univ Politecn Valencia, Inst Invest & Innovac Bioingn, Neurorehabil & Brain Res Grp, Valencia 46022, Spain.
   [Escriva-Martinez, Tamara; Banos, Rosa] Univ Valencia, Polibienestar Res Inst, Valencia 46022, Spain.
   [Llorens, Robert] Fdn Hosp NISA, Serv Neurorrehabil & Dano Cerebral Hosp Vithas NI, Valencia, Spain.
C3 University of Bologna; University of Valencia; CIBER - Centro de
   Investigacion Biomedica en Red; CIBEROBN; Instituto de Salud Carlos III;
   Universitat Politecnica de Valencia; University of Valencia
RP Ventura, S (corresponding author), Univ Bologna, Dept Psychol, I-40127 Bologna, Italy.
EM sara9lventura@gmail.com
RI Marti, Ausias Cebolla/E-8410-2012; VENTURA, SARA/ABG-4477-2020; Llorens,
   Roberto/AAL-2604-2021; Escrivá-Martínez, Tamara/ABD-4364-2020; BAÑOS,
   ROSA MARIA/C-6077-2011
OI VENTURA, SARA/0000-0002-3851-7246; Llorens, Roberto/0000-0002-8677-8707;
   Escrivá-Martínez, Tamara/0000-0001-6632-8402; BAÑOS, ROSA
   MARIA/0000-0003-0626-7665
FU Santiago Grisolia program-Generalitat Valenciana (Spain); CIBEROBN, an
   initiative of the ISCIII [ISC III CB06 03/0052]; PROMETEO (Conselleria
   d'Educacio, Investigacio, Cultura I Esport, Generalitat Valenciana)
   [PROMETEO/2018/110/]
FX This work was supported by Santiago Grisolia program-Generalitat
   Valenciana 2017 (Spain), CIBEROBN, an initiative of the ISCIII (ISC III
   CB06 03/0052) and PROMETEO (PROMETEO/2018/110/Conselleria d'Educacio,
   Investigacio, Cultura I Esport, Generalitat Valenciana).
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Berntson GG, 1997, PSYCHOPHYSIOLOGY, V34, P623, DOI 10.1111/j.1469-8986.1997.tb02140.x
   Bertrand P, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00026
   Blanke O, 2004, BRAIN, V127, P243, DOI 10.1093/brain/awh040
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Brysbaert Marc, 2019, J Cogn, V2, P16, DOI 10.5334/joc.72
   Buchman S., 2019, J INTERPROF CARE, V15, P127, DOI DOI 10.1016/J.XJEP.2019.03.010
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Cebolla A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01521
   Cebolla A, 2016, MINDFULNESS, V7, P1297, DOI 10.1007/s12671-016-0569-x
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Gilgen-Ammann R, 2019, EUR J APPL PHYSIOL, V119, P1525, DOI 10.1007/s00421-019-04142-5
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hamilton-Giachritsis C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21036-2
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Hasson Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222342
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Jung SM, 2017, 2017 INTERNATIONAL CONFERENCE ON EMERGING TRENDS & INNOVATION IN ICT (ICEI), P150, DOI 10.1109/ETIICT.2017.7977027
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Laborde S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00213
   Lenggenhager B, 2006, REV NEUROSCIENCE, V17, P643
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Oh SY, 2016, COMPUT HUM BEHAV, V60, P398, DOI 10.1016/j.chb.2016.02.007
   Palomo P, 2018, CONSCIOUS COGN, V58, P90, DOI 10.1016/j.concog.2017.10.014
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Pavone EF, 2016, J NEUROSCI, V36, P268, DOI 10.1523/JNEUROSCI.0494-15.2016
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Petri K., 2020, Am. J. Biomed. Sci, P107, DOI DOI 10.5099/AJ200200107
   Plews DJ, 2017, INT J SPORT PHYSIOL, V12, P1324, DOI 10.1123/ijspp.2016-0668
   Ponzo S, 2018, NEUROPSYCHOLOGIA, V117, P311, DOI 10.1016/j.neuropsychologia.2018.06.020
   Repetto Claudia, 2018, Pervasive Computing Paradigms for Mental Health. 7th International Conference, MindCare 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 253), P56, DOI 10.1007/978-3-030-01093-5_8
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Schutte NS, 2017, MOTIV EMOTION, V41, P708, DOI 10.1007/s11031-017-9641-7
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Serino S, 2019, J CLIN PSYCHOL, V75, P313, DOI 10.1002/jclp.22724
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Sims T, 2015, ANN M GER SOC AM ORL
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Tidoni E, 2017, IEEE T NEUR SYS REH, V25, P1622, DOI 10.1109/TNSRE.2016.2626391
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   VENTURA S, 2020, CYBERPSYCHOL BEHAV S
   Ventura S., 2018, P 12 INT C DIS VIRT
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Waardenburg L, 2022, ORGAN SCI, V33, P59, DOI 10.1287/orsc.2021.1544
   West S. G., 1995, Structural equation modeling: Concepts, issues, and applications, P56, DOI DOI 10.1037/0008-400X.26.2.210
NR 59
TC 10
Z9 10
U1 2
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 323
EP 332
DI 10.1007/s10055-021-00567-6
EA AUG 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000685145700001
DA 2024-07-18
ER

PT J
AU Abich, J IV
   Parker, J
   Murphy, JS
   Eudy, M
AF Abich, Julian
   Parker, Jason
   Murphy, Jennifer S.
   Eudy, Morgan
TI A review of the evidence for training effectiveness with virtual reality
   technology
SO VIRTUAL REALITY
LA English
DT Review
DE Training effectiveness; Virtual reality; Virtual environment;
   Psychomotor; Knowledge acquisition; Spatial ability
ID SIMULATORS; ENVIRONMENT
AB Prior to adopting new technologies for training, evaluations must be executed to demonstrate their benefit. Specifically, the appeal of virtual reality has led to applications across domains. While many evaluations have been conducted on their effectiveness, there has yet been a review to summarize and categorize the evidence on training outcomes. To assess the benefits these new technologies may bring to the trainee, a review of the research on the training effectiveness with virtual reality (VR) technology that was conducted. The goal for this review was to take a domain-agnostic perspective to identify the knowledge, skills, and abilities (KSAs) that have been trained effectively or enhanced with the use of VR. This review searched the related literature within multiple databases and found publications that met the search criteria from 1992 to 2019. A discussion of previous VR training reviews is first presented, followed by an in-depth evaluation of the literature that met the inclusion criteria. Three distinct categories of KSAs were identified consistently: psychomotor performance, knowledge acquisition, and spatial ability. Recommendations to support achievement of training outcomes utilizing VR training systems are provided.
C1 [Abich, Julian; Parker, Jason; Murphy, Jennifer S.; Eudy, Morgan] Quantum Improvements Consulting, 12124 High Tech Ave,Suite 165, Orlando, FL 32817 USA.
RP Abich, J IV (corresponding author), Quantum Improvements Consulting, 12124 High Tech Ave,Suite 165, Orlando, FL 32817 USA.
EM jabich@quantumimprovements.net; jmurphy@quantumimprovements.net
FU  [N6833519-C-0089]
FX This research was accomplished under Contract No. N6833519-C-0089. The
   views and conclusions contained in this document are those of the
   authors and should not be interpreted as representing the official
   policies, either expressed or implied, of NAWCTSD or the US Government.
   The US Government is authorized to reproduce and distribute reprints for
   Government purposes notwithstanding any copyright notation hereon.
CR Aïm F, 2016, ARTHROSCOPY, V32, P224, DOI 10.1016/j.arthro.2015.07.023
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Aldrich C., 2009, Innovate: Journal of Online Education, V5, P1
   [Anonymous], 2004, ED J IND TEACHER ED
   Bailey Shannon KT, 2017, P INTERSERVICEINDUST
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Boud A. C., 1999, 1999 IEEE International Conference on Information Visualization (Cat. No. PR00210), P32, DOI 10.1109/IV.1999.781532
   Boughton KA, 2017, EDUC PSYCHOL HANDB, P177
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Colquitt JA, 2000, J APPL PSYCHOL, V85, P678, DOI 10.1037/0021-9010.85.5.678
   Detmer Felicitas J, 2017, IEEE Rev Biomed Eng, V10, P78, DOI 10.1109/RBME.2017.2749527
   Erel E, 2003, MICROSURG, V23, P147, DOI 10.1002/micr.10106
   Farra SL, 2015, NURSE EDUC PRACT, V15, P53, DOI 10.1016/j.nepr.2013.08.017
   Fitts P. M., 1967, Human performance
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gillespie R, 2019, RESUSCITATION
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Hays RT, 2000, MIL PSYCHOL, V12, P161, DOI 10.1207/S15327876MP1203_1
   Hsu Edbert B, 2013, PLoS Curr, V5, DOI 10.1371/currents.dis.1ea2b2e71237d5337fa53982a38b2aff
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Joda T, 2019, COMPUT BIOL MED, V108, P93, DOI 10.1016/j.compbiomed.2019.03.012
   John NW, 2018, IEEE T VIS COMPUT GR, V24, P1867, DOI 10.1109/TVCG.2017.2700273
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Murcia-López M, 2018, IEEE T VIS COMPUT GR, V24, P1574, DOI 10.1109/TVCG.2018.2793638
   Nagendran M, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub3
   Norris MW., 2019, Professional Safety, V64, P36
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Piromchai P, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010198.pub2
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Stone R, 2001, INT J HUM-COMPUT ST, V55, P699, DOI 10.1006/ijhc.2001.0497
   Stone RT, 2011, WELD J, V90, p136S
   Stroud KJ, 2005, AVIAT SPACE ENVIR MD, V76, P352
   Tate DL, 1997, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VRAIS.1997.583045
   Tichon J., 2011, J HLTH SAFETY RES PR, V3, P33
   Vaughan N, 2016, MED ENG PHYS, V38, P59, DOI 10.1016/j.medengphy.2015.11.021
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Webster RD., 2014, Corrosion Prevention and Control Training in an Immersive Virtual Learning Environment
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
NR 42
TC 67
Z9 72
U1 9
U2 56
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 919
EP 933
DI 10.1007/s10055-020-00498-8
EA JAN 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000606301100001
DA 2024-07-18
ER

PT J
AU Schöne, B
   Sylvester, RS
   Radtke, EL
   Gruber, T
AF Schoene, Benjamin
   Sylvester, Rebecca Sophia
   Radtke, Elise Leila
   Gruber, Thomas
TI Sustained inattentional blindness in virtual reality and under
   conventional laboratory conditions
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Ecological validity; Sustained inattentional blindness;
   Invisible gorilla
ID ATTENTION; MODEL; 3D
AB Virtual reality (VR) might increase the ecological validity of psychological studies as it allows submerging into real-life experiences under controlled laboratory conditions. We intended to provide empirical evidence for this claim at the example of the famous invisible gorilla paradigm (Simons and Chabris in Perception, 28(9), 1059-1074, 1999). To this end, we confronted one group of participants with a conventional 2D-video of two teams passing basketballs. To the second group of participants, we presented the same stimulus material as a 3D360 degrees-VR-video and to a third group as a 2D360 degrees-VR-video. Replicating the original findings, in the video condition, only similar to 30% of the participants noticed the gorilla. However, in both VR-conditions, the detection rate was increased to similar to 70%. The illusion of spatial proximity in VR enhances the salience of the gorilla, thereby enhancing the noticing rate. VR mimics the perceptual characteristics of the real world and provides a useful tool for psychological studies.
C1 [Schoene, Benjamin; Sylvester, Rebecca Sophia; Radtke, Elise Leila; Gruber, Thomas] Osnabruck Univ, Inst Psychol, Expt Psychol 1, Seminarstr 20, D-49074 Osnabruck, Germany.
C3 University Osnabruck
RP Schöne, B (corresponding author), Osnabruck Univ, Inst Psychol, Expt Psychol 1, Seminarstr 20, D-49074 Osnabruck, Germany.
EM benjamin.schoene@uni-osnabrueck.de
RI Schöne, Benjamin/GXW-1484-2022
OI Schöne, Benjamin/0000-0001-7926-7426; Radtke, Elise
   Leila/0000-0002-1436-7036
FU Projekt DEAL
FX Open Access funding provided by Projekt DEAL. We thank Joanna Kisker for
   help in data acquisition and we further would like to thank Daniel
   Simons for his criticism on an earlier version of the manuscript.
CR BECKLEN R, 1983, MEM COGNITION, V11, P601, DOI 10.3758/BF03198284
   Benoni H, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00522
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Chabris CF, 2011, I-PERCEPTION, V2, P150, DOI 10.1068/i0436
   Chen PL, 2018, BMC PUBLIC HEALTH, V18, DOI 10.1186/s12889-018-6163-5
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Furley P, 2010, ATTEN PERCEPT PSYCHO, V72, P1327, DOI 10.3758/APP.72.5.1327
   Gable P, 2010, COGNITION EMOTION, V24, P322, DOI 10.1080/02699930903378305
   Gelman A, 2015, J EDUC BEHAV STAT, V40, P530, DOI 10.3102/1076998615606113
   Gorini A, 2010, ANN GEN PSYCHIATR, V9, DOI 10.1186/1744-859X-9-30
   Greene CM, 2017, APPL COGNITIVE PSYCH, V31, P431, DOI 10.1002/acp.3335
   Hyman IE, 2010, APPL COGNITIVE PSYCH, V24, P597, DOI 10.1002/acp.1638
   Jerath R, 2015, J MED HYPOTHESES IDE, V9, P45, DOI 10.1016/j.jmhi.2015.02.001
   KISKER J, 2019, PSYCHOL RES
   Kisker J., 2019, Current Psychology, P1
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Higuera-Trujillo JL, 2017, APPL ERGON, V65, P398, DOI 10.1016/j.apergo.2017.05.006
   MURDOCK BB, 1969, J VERB LEARN VERB BE, V8, P665, DOI 10.1016/S0022-5371(69)80120-9
   Paletta Lucas., 2013, CHI'13 Extended Abstracts on Human Factors in Computing Systems, P199
   Palmer S., 1999, VISION SCI PHOTONS P
   Pammer K, 2018, HUM FACTORS, V60, P5, DOI 10.1177/0018720817733901
   Parr T, 2017, NEUROPSYCHOLOGIA, V104, P92, DOI 10.1016/j.neuropsychologia.2017.08.003
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   PENNEY CG, 1989, MEM COGNITION, V17, P398, DOI 10.3758/BF03202613
   Posner M.I., 1978, Modes of perceiving and processing information, V137, P2
   Proulx MJ, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0015293
   Rooney B, 2013, MEDIA PSYCHOL, V16, P441, DOI 10.1080/15213269.2013.838905
   Schöne B, 2019, CURR PSYCHOL, V38, P715, DOI 10.1007/s12144-017-9648-y
   Schöne B, 2018, EXP BRAIN RES, V236, P2649, DOI 10.1007/s00221-018-5324-1
   Simons DJ, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0074-3
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   SKORUPKA A, 2009, P INT SPAC SYNT S
   STOFFREGEN TA, 1993, AM J MENT RETARD, V98, P273
   Wickham H, 2017, Package tidyverse. Easily Install and Load the 'Tidyverse
NR 36
TC 22
Z9 24
U1 0
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 209
EP 216
DI 10.1007/s10055-020-00450-w
EA JUN 2020
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000538951700001
OA hybrid
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI VIRTUAL TECHNOLOGIES CHANGE EVERYTHING
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR [Anonymous], 2018, SCIENCEDAILY    0723
   [Anonymous], 2017, LOWES NEXT GENERATIO
   [Anonymous], 2018, ALTSPACEVR      0808
   [Anonymous], 2018, AGENCIA EFE     0626
   [Anonymous], 2016, ENTERING MOL
   [Anonymous], 2016, AUGMENTED VIEW
   [Anonymous], 2020, Training Magazine
   [Anonymous], 2017, SAN FRANCISCO C 0405
   [Anonymous], 2018, CNN             0315
   [Anonymous], 2015, MARRIOTT NEWS C 0909
   Castellanos Sara, 2017, WALL STREET J   0921
   Ekstrand Chelsea, IMMERSIVE INTERACTIV
   Ergurel Deniz, 2016, HAPTICAL        1014
   Feeney Brian, 2016, ARMYS AUGMENTED REAL
   French Kristen, 2018, WIRED           0202
   Javornik Ann, 2016, HARVARD BUSINES 1004
   Katz Miranda, 2018, WIRED 0423
   King Katie, 2016, LEGAL CHEEK     0524
   Koolon Nikhloai, 2018, VR FOCUS        0519
   Kramer Don, 2007, NEW SIMULATORS GET S
   Krokos Erik, 2018, J VIRTUAL REALI 0516
   Lapowsky Issy, 2015, WIRED           0330
   Lewis Tanya, 2014, LIVESCIENCE     0808
   Molteni Megan, 2017, WIRED           1102
   Morris Chris, 2016, CNBC            1201
   Pearson Ben, 2017, FILM            1117
   Robitzski D., 2017, Virtual reality and journalistic ethics: Where are the lines?
   Romeo Claudui, 2017, BUSINESS INSIDE 0528
   Sacco Al, 2016, CIO MAGAZINE    0713
   Sawers Paul, 2016, VIRTUAL REALITY 0305
   Schiller Crew, 2018, NBC SPORTS      0614
   Strauss Paul, 2008, TECHNABOB       1217
   West Presley, 2017, VR SCOUT        0919
   Wilson Jacqueline, 2018, GLOBAL NEWS CAN 0322
NR 34
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 119
EP +
PG 37
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200007
DA 2024-07-18
ER

PT J
AU Wefers, F
   Vorländer, M
AF Wefers, Frank
   Vorlaender, Michael
TI Flexible data structures for dynamic virtual auditory scenes
SO VIRTUAL REALITY
LA English
DT Article
DE Auralization; Virtual acoustics; Virtual reality; Interaction; Audio
   rendering; 3D sound
ID ENVIRONMENTS
AB Virtual environments and their contents are dynamically changing, but also need to respond to the user immediately. While managing a dynamic scene is a common and well-understood problem for visual rendering, additional challenges exist for the high-quality audio rendering of such scenes. Audio rendering differs in a key aspect: Sound waves propagate substantially slower than light. For the acoustics in scenes of large dimensions, it is not sufficient to regard just the state at the current time. The sound propagation times become so significant (perceptible) that the past of the objects matter, making a time history of the scene necessary. Particularly the conjunction of multithreading and low-latency audio processing makes the description of the virtual acoustic scene a problem on its own. This paper presents a novel solution to this acoustic-related problem. We discuss the challenges of realizing a real-time auralization on modern (non-real-time) operating systems and state the main requirements of the data structure. A hierarchical state-based data structure with time history is presented, which not only fulfills the requirements for outdoor auralizations but also has key advantages for indoor simulations-such as room acoustics. A key feature is the integral support of atomic scene modifications, allowing several modifications to be performed at the same time. The presented concept is very modular and beneficial for a wide range of applications.
C1 [Wefers, Frank; Vorlaender, Michael] Rhein Westfal TH Aachen, Inst Tech Acoust, Kopernikusstr 5, D-52074 Aachen, Germany.
C3 RWTH Aachen University
RP Wefers, F (corresponding author), Rhein Westfal TH Aachen, Inst Tech Acoust, Kopernikusstr 5, D-52074 Aachen, Germany.
EM fwe@akustik.rwth-aachen.de; mvo@akustik.rwth-aachen.de
RI Vorlaender, Michael/M-4229-2017
OI Vorlaender, Michael/0000-0002-7010-8370
CR Ahrens J, 2008, P AUD ENG SOC AES CO
   [Anonymous], P 17 ACM INT C MULT
   [Anonymous], 2011, AURALIZATION FUNDAME
   [Anonymous], 1987, Theoretical Acoustics
   Bar-Zeev Avi., 2007, Scenegraphs: Past, present and future
   Begault Durand R, 2000, 3 SOUND VIRTUAL REAL
   Detlefs DL, 2002, DISTRIB COMPUT, V15, P255, DOI 10.1007/s00446-002-0079-z
   Gao H, 2005, DISTRIB COMPUT, V18, P21, DOI 10.1007/s00446-004-0115-2
   Herlihy Maurice, 2012, The Art of Multiprocessor Programming, V1st
   ISRAELI A, 1993, LECT NOTES COMPUT SC, V725, P1
   Kuttruff H., 2007, ACOUSTICS INTRO
   Laakso TI, 1996, IEEE SIGNAL PROC MAG, V13, P30, DOI 10.1109/79.482137
   Michael M. M., 1996, Proceedings of the Fifteenth Annual ACM Symposium on Principles of Distributed Computing, P267, DOI 10.1145/248052.248106
   Michael M. M., 2002, P 14 ANN ACM S PAR A, P73, DOI DOI 10.1145/564870.564881
   Nystrom R., 2014, Game Programming Patterns, V3rd
   Richter J, 1997, ADVANCED WINDOWS
   Rizzi SA, 2003, P INT C AUD DISPL 20
   Rohlf J., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P381, DOI 10.1145/192161.192262
   Sahai A, 2016, APPL ACOUST, V101, P24, DOI 10.1016/j.apacoust.2015.08.002
   Savioja L, 1999, J AUDIO ENG SOC, V47, P675
   Silzle A, 2004, P AUD ENG SOC AES CO
   Smith J.O., 2002, Proceeding Workshop on Digital Audio Effects, DAFx-02, Hamburg, Germany, P188
   Strauss H, 1998, P AUD ANG SOC AES CO
   Tanenbaum AS, 2014, MODERN OPERATING SYS, P148
   Valois J. D., 1994, Seventh International Conference on Parallel and Distributed Computing Systems, P64
   Valois JD, 1995, P 14 ANN ACM S PRINC
   Voss G, 2002, P 4 EUR WORKSH PAR G
   Wefers F, 2014, P EAA JOINT S AUR AM
   Wefers F, 2015, P INT 2015 SAN FRANC
   Wenzel EM, 2000, P AUD ENG SOC AES CO
   Zolzer U, 2008, Digital audio signal processing
NR 31
TC 5
Z9 6
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 281
EP 295
DI 10.1007/s10055-018-0332-9
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600001
DA 2024-07-18
ER

PT J
AU Rebenitsch, L
   Owen, C
AF Rebenitsch, Lisa
   Owen, Charles
TI Review on cybersickness in applications and visual displays
SO VIRTUAL REALITY
LA English
DT Review
DE Visually induced motion sickness; Cybersickness; Stereoscopic; Motion
   sickness; Displays; Head-mounted displays
ID INDUCED MOTION SICKNESS; VIRTUAL ENVIRONMENT EXPOSURE; POSTURAL
   INSTABILITY; SIMULATOR SICKNESS; GAZE ANGLE; SYMPTOMS; HABITUATION;
   PERFORMANCE; IMMERSION; ROTATION
AB Cybersickness is an affliction common to users of virtual environments. Similar in symptoms to motion sickness, cybersickness can result in nausea, headaches, and dizziness. With these systems becoming readily available to the general public, reports of cybersickness have increased and there is a growing concern about the safety of these systems. This review presents the current state of research methods, theories, and known aspects associated with cybersickness. Current measurements of incidence of cybersickness are questionnaires, postural sway, and physiological state. Varying effects due to display and rendering modes, such as visual display type and stereoscopic or monoscopic rendering, are compared. The known and suspected application aspects that induce cybersickness are discussed. There are numerous potential contributing application design aspects, many of which have had limited study, but field of view and navigation are strongly correlated with cybersickness. The effect of visual displays is not well understood, and application design may be of greater importance.
C1 [Rebenitsch, Lisa] Milwaukee Sch Engn, Milwaukee, WI USA.
   [Owen, Charles] Michigan State Univ, E Lansing, MI 48824 USA.
C3 Milwaukee School Engineering; Michigan State University
RP Rebenitsch, L (corresponding author), Milwaukee Sch Engn, Milwaukee, WI USA.
EM rebenitsch@msoe.edu
OI Rebenitsch, Lisa/0000-0002-9640-8670
CR Aykent B., 2013, Journal of Ergonomics, V3, P1
   Benzeroual K, 2013, INT C 3D IM LIEG BEL
   Bilton N., 2012, GOOGLE BEGINS TESTIN
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Bos J, 2007, P 1 INT S VIS IND MO
   Bos JE, 2012, MARITIME AIR SYSTEMS
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bos JE, 2013, ERGONOMICS, V56, P1430, DOI 10.1080/00140139.2013.817614
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Bruck S, 2011, DISPLAYS, V32, P153, DOI 10.1016/j.displa.2011.07.002
   Budhiraja P, 2015, THESIS U ILLINOIS UR
   Casali J.G., 1985, VEHICULAR SIMULATION, V1
   Chang E, 2013, INT WINT WORKSH BRAI
   Chardonnet J., 2015, ICAT EGVE 2015
   Chen D, 2012, CONTEMPORARY ERGONOMICS AND HUMAN FACTORS 2012, P253
   Chen W., 2013, P 19 ACM S VIRT REAL
   Chen W., 2011, CONT ERGONOMICS 2011
   Chen Y.C., 2011, BIO Web of Conferences, V1, P00016, DOI DOI 10.1051/BIOCONF/20110100016
   Cheung R T F, 2011, P 55 ANN M HUM FACT
   Clernes SA, 2005, J BIOL RHYTHM, V20, P71, DOI 10.1177/0748730404272567
   Cobb SVG, 1999, APPL ERGON, V30, P47, DOI 10.1016/S0003-6870(98)00038-6
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Dizio P., 1997, INT C HUM COMP INT S
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Dong Xiao., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P1340, DOI [DOI 10.1177/1541931210054018, 10.1177/154193121005401808, DOI 10.1177/154193121005401808]
   Dorado JL, 2014, IEEE S 3D US INT MIN
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Duh H. B. L., 2001, VIRT REAL P YOK
   Duh H. B. L., 2001, P HUMAN FACTORS ERGO
   Duh HB-L, 2001, P SIGCHI C HUM FACT
   Duh HBL, 2004, HUM FACTORS, V46, P142, DOI 10.1518/hfes.46.1.142.30384
   Dziuda L, 2014, APPL ERGON, V45, P406, DOI 10.1016/j.apergo.2013.05.003
   Ehrlich JA, 1998, HUM FAC ERG SOC P, P1466
   Ehrlich JA, 1997, P C TEL TEL TECHN PI
   Ehrlich SD., 2012, MOTION SICKNESS
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Graeber DA., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2109, DOI [10.1177/154193120204602602, DOI 10.1177/154193120204602602]
   Hakkinen J., 2002, IEEE International Conference on Systems, Man and Cybernetics, V4, P147, DOI [DOI 10.1109/ICSMC.2002.1167964, 10.1109/ICSMC.2002.1167964]
   Hale KS, 2006, APPL ERGON, V37, P329, DOI 10.1016/j.apergo.2005.06.009
   Harm DL, 2007, TECHNICAL REPORT
   Harvey C, 2007, P 1 INT S VIS IND MO
   Hicks J. S., 2011, SUMMARY SIMULATOR SI
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 1999, APPL ERGON, V30, P39, DOI 10.1016/S0003-6870(98)00041-6
   Howarth PA, 1999, APPL ERGON, V1, P30
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Jaeger B.K., 2001, P HUMAN FACTORS ERGO
   Jaekl PM, 2005, EXP BRAIN RES, V163, P388, DOI 10.1007/s00221-004-2191-8
   jQuinn SA, 2013, THESIS U CENTRAL FLO
   Karpicka E, 2013, OPHTHAL PHYSL OPT, V33, P604, DOI 10.1111/opo.12081
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kennedy RS, 2003, TECHNICAL REPORT
   Keshavarz B, 2012, PRESENCE-TELEOP VIRT, V21, P213, DOI 10.1162/PRES_a_00102
   Keshavarz B, 2011, DISPLAYS, V32, P181, DOI 10.1016/j.displa.2011.05.009
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kingdon K. S., 2001, P HUMAN FACTORS ERGO
   Kiryu T, 2007, LECT NOTES COMPUT SC, V4563, P262
   Kolasinski E. M., 1995, SIMULATOR SICKNESS V
   Kolasinski EM, 1998, P HUMAN FACTORS ERGO
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lampton DR., 1994, VIRTUAL ENV PERFORMA
   Lin J. J. - W., 2002, P IEEE VIRT REAL ORL
   Ling Y, 2011, JOINT VIRT REAL C NO
   Liu C-L, 2012, 9 INT C FUZZ SYST KN
   Liu CL., 2011, HUMAN COMPUTER INTER
   Llorach G, 2014, S VIRT REAL SOFTW TE
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Marchal M, 2011, IEEE S 3D US INT SIN
   McCauley ME, 2006, TECHNICAL REPORT
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Mon-Williams M, 1998, ERGONOMICS, V41, P280, DOI 10.1080/001401398187035
   Mon-Williams M., 1995, Journal of the Society for Information Display, V3, P207, DOI 10.1889/1.1984970
   Mon-Williams M, 1998, HUM FACTORS, V40, P42, DOI 10.1518/001872098779480622
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Naqvi SA, 2013, ANN INT C IEEE ENG M
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Oyamada H, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-37
   Parkin S, 2014, WHAT ZUCKERBERG SEES
   Plouzeau J., 2015, INT C ART REAL REL K
   Prothero JD, 1997, AVIAT SPACE ENV MED, V70, P277
   Rainey BB, 1998, OPTOMETRY VISION SCI, V75, P719, DOI 10.1097/00006324-199810000-00016
   Rebenitsch L. R., 2015, THESIS MICHIGAN STAT
   Renkewitz H., 2007, Perceptual Issues of Augmented and Virtual Environments
   Roberts W.K., 2005, P HUM FACTORS ERGON, P2230, DOI [10.1177/154193120504902603, DOI 10.1177/154193120504902603]
   Seay A.F., 2002, CHI 02 EXTENDED ABST, P784, DOI DOI 10.1145/506443.506596
   Serge SR, 2015, P HUM FACT ERG SOC 5
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Singer MJ, 1998, P HUMAN FACTORS ERGO
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Smart LJ, 2007, HUM FACT ERG SOC 51
   So R, 1999, P IEEE VIRT REAL 99
   So R. H. Y., 1998, 1 WORLD C ERG GLOB Q
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   So RHY, 1999, P HCI INT 8 INT C HU
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Stanney K. M., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2114
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Stanney KM, 1998, HUM FAC ERG SOC P, P1476
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P447, DOI 10.1162/105474698565848
   Stanney KM, 1999, APPL ERGON, V30, P27, DOI 10.1016/S0003-6870(98)00039-8
   Stanney KM, 1999, P HUMAN FACTORS ERGO
   Stanney KM, 1997, P HUMAN FACTORS ERGO
   Toet A., 2008, P SPIE ENHANCED SYNT, V6957, P69570
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Ujike H, 2008, DISPLAYS, V29, P81, DOI 10.1016/j.displa.2007.09.003
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   van Emmerik ML, 2011, DISPLAYS, V32, P169, DOI 10.1016/j.displa.2010.11.003
   Viirre E, 1996, IEEE ENG MED BIOL, V15, P41, DOI 10.1109/51.486717
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Vlad R, 2013, 3DTV C TRUE VIS CAPT
   Watanabe H, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P210, DOI 10.1109/ISUC.2008.11
   Wibirama S, 2014, ANN INT C MED BIOL S
   Wilson JR, 1999, SAFETY SCI, V23, P39
   Yang SN, 2011, PROC SPIE, V7863, DOI 10.1117/12.872546
   Young S, 2007, VIRT REAL C AL
NR 126
TC 477
Z9 524
U1 10
U2 143
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2016
VL 20
IS 2
BP 101
EP 125
DI 10.1007/s10055-016-0285-9
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1GA
UT WOS:000376092200002
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Cooke, N
   Stone, R
AF Cooke, Neil
   Stone, Robert
TI RORSIM: a warship collision avoidance 3D simulation designed to
   complement existing Junior Warfare Officer training
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Game-based training; Virtual environments; Defence;
   Simulation
AB Royal Navy Junior Warfare Officers (JWO) undergo a comprehensive training package in order to prepare them to be officers of the watch. One aspect of this training relates to their knowledge of the 'Rules of the Road' or 'COLREGS'; the rules for the manoeuvring and signalling that approaching vessels make in order to avoid collision. The training and assessment exercises undertaken predominantly use non-interactive static materials. These do not exercise the required skill in reconciling information from maritime charts, radar displays and 'out-of-the-window' monitoring. Consequently, performance during assessment on the VR-based bridge simulator falls short. This paper describes The Rules of the Road SIMulator (RORSIM)-a proof of concept interactive 3D (i3D) simulator developed to bridge the training gap between classroom teaching and VR bridge simulator assessment. RORSIM's differentiation and its key functionality in terms of visualisaton, physics/interaction and game mechanics are influenced by the consideration of pedagogical learning models during requirements capture. This capture is formalised by a 'Training Gap Use Case'aEuro"a graphical viewpoint using the Universal Modelling Language which can assist developers in requirements capture and development of i3D tools for existing training programmes. Key functionality, initial JWO feedback and a planned pilot study design are reported.
C1 [Cooke, Neil; Stone, Robert] Univ Birmingham, Birmingham, W Midlands, England.
C3 University of Birmingham
RP Cooke, N (corresponding author), Univ Birmingham, Birmingham, W Midlands, England.
EM n.j.cooke@bham.ac.uk
RI COOKE, NEIL/AAI-1080-2021
OI COOKE, NEIL/0000-0003-2247-0663
FU Human Dimension and Medical Sciences Domain of the UK Ministry of
   Defence Scientific Research Programme
FX The work reported here is part funded by the Human Dimension and Medical
   Sciences Domain of the UK Ministry of Defence Scientific Research
   Programme and was initiated by the Domain Leader. The authors would like
   to acknowledge the invaluable contribution and specialist support
   provided by the technology-based training unit (TBTU) at HMS Collingwood
   in Fareham. Lt Cdr Steve Clark, Lt Cdr David Elsey, Lt Roxane Heaton,
   Cdr Sean Fletcher and Cdr Rob Floyd. Without their contribution,
   hospitality and tolerance, this project would not have been possible.
CR Alexander A., 2005, INTERSERVICE IND TRA
   Ang KH, 2005, IEEE T CONTR SYST T, V13, P559, DOI 10.1109/TCST.2005.847331
   [Anonymous], P HUM PERF SEA 2010
   [Anonymous], 2005, Theory of fun for game design
   Budgen David., 2003, SOFTWARE DESIGN
   Buziak C, 2000, THESIS
   Chau T, 2003, TWELFTH IEEE INTERNATIONAL WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P302
   Cockcroft A.N., 1996, Guide to the Collision Avoidance Rules, Vfifth
   Csikszentmihalyi M., 1997, FLOW PSYCHOL DISCOVE
   Dobing B, 2006, COMMUN ACM, V49, P109, DOI 10.1145/1125944.1125949
   Ertmer P.A., 1993, Performance Improvement Quarterly, V6, P50, DOI [10.1002/piq.21143, DOI 10.1002/PIQ.21143, DOI 10.1111/J.1937-8327.1993.TB00605.X]
   Harrington MCR, 2012, VIRTUAL REAL-LONDON, V16, P105, DOI 10.1007/s10055-011-0189-7
   Hays R, 1997, USER ORIENTED DESIGN
   Hays R.T., 1998, TRAINING EFFECTIVENE
   Karadogan E, 2013, VIRTUAL REAL-LONDON, V17, P45, DOI 10.1007/s10055-013-0220-2
   Kiili K., 2005, Internet and Higher Education, V8, P13, DOI 10.1016/j.iheduc.2004.12.001
   Kolb AY, 2005, ACAD MANAG LEARN EDU, V4, P193, DOI 10.5465/AMLE.2005.17268566
   Norris S. D., 1998, THESIS NAVAL POSTGRA
   Petridis Panagiotis, 2010, 2010 2nd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2010), P27, DOI 10.1109/VS-GAMES.2010.26
   Riedl MO, 2006, IEEE COMPUT GRAPH, V26, P23, DOI 10.1109/MCG.2006.56
   Shyh-Kuang Ueng, 2008, Virtual Reality, V12, P65, DOI 10.1007/s10055-008-0088-8
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   St John M., 2002, New Century, New Trends. Proceedings of the 2002 IEEE 7th Conference on Human Factors and Power Plants (Cat. No.02CH37355), P7, DOI 10.1109/HFPP.2002.1042861
   Stanton N. A., 2005, HUMAN FACTORS METHOD
   Statheros T, 2008, J NAVIGATION, V61, P129, DOI 10.1017/S037346330700447X
   Stone R, 2007, HFIDTCWP4721
   Stone R, 2002, INT IND TRAIN SIM ED, P1
   Stone R, 2008, HUMAN FACTORS UNPUB
   Tam C, 2010, J MAR SCI TECH-JAPAN, V15, P257, DOI 10.1007/s00773-010-0089-7
   Tam C, 2009, J NAVIGATION, V62, P455, DOI 10.1017/S0373463308005134
   Vincenzi DA, 2003, NAV ENG J, V115, P79, DOI 10.1111/j.1559-3584.2003.tb00189.x
NR 31
TC 7
Z9 7
U1 1
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2013
VL 17
IS 3
BP 169
EP 179
DI 10.1007/s10055-013-0223-z
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 214EM
UT WOS:000324113800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kurillo, G
   Bajcsy, R
AF Kurillo, Gregorij
   Bajcsy, Ruzena
TI 3D teleimmersion for collaboration and interaction of geographically
   distributed users
SO VIRTUAL REALITY
LA English
DT Article
DE 3D video; 3D teleimmersion; Human-computer interaction; Remote
   collaboration; Telepresence
ID ENVIRONMENT; VIDEO
AB Teleimmersion is an emerging technology that enables users to collaborate remotely by generating realistic 3D avatars in real time and rendering them inside a shared virtual space. The teleimmersive environment thus provides a venue for collaborative work on 3D data such as medical imaging, scientific data and models, archaeological datasets, architectural or mechanical designs, remote training (e.g., oil rigs, military applications), and remote teaching of physical activities (e.g., rehabilitation, dance). In this paper, we present our research work performed over the course of several years in developing the teleimmersive technology using image-based stereo and more recently Kinect. We outline the issues pertaining to the capture, transmission, rendering, and interaction. We describe several applications where we have explored the use of the 3D teleimmersion for remote interaction and collaboration among professional and scientific users. We believe the presented findings are relevant for future developers in teleimmersion and apply across various 3D video capturing technologies.
C1 [Kurillo, Gregorij; Bajcsy, Ruzena] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
C3 University of California System; University of California Berkeley
RP Kurillo, G (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
EM gregorij@eecs.berkeley.edu; bajcsy@eecs.berkeley.edu
FU National Science Foundation (NSF) [0703787, 0724681, 0840399, 1111965];
   HP Labs; European Aeronautic Defence and Space Company (EADS); Center
   for Information Technology in the Interest of Society (CITRIS) at
   University of California, Berkeley; Direct For Computer & Info Scie &
   Enginr [0703787, 0840399] Funding Source: National Science Foundation;
   Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [0724681] Funding Source: National Science
   Foundation; Division of Computing and Communication Foundations; Direct
   For Computer & Info Scie & Enginr [1111965] Funding Source: National
   Science Foundation; Div Of Information & Intelligent Systems [0703787,
   0840399] Funding Source: National Science Foundation
FX We wish to thank Ram Vasudevan and Edgar Lobaton, University of
   California at Berkeley, for contribution on the stereo reconstruction
   and Zhong Zhou, University of Beijing, for texture compression. We also
   thank Tony Bernardin and Oliver Kreylos, University of California at
   Davis, for the implementation of the rendering and support in
   integration with the Vrui framework. Furthermore, we thank all of our
   past and current collaborators, including Jeremy Bailenson (Stanford
   University), Maurizio Forte (UCM), Jay Han (UCDMC), Louise Kellogg
   (UCD), Klara Nahrstedt (UIUC), and Lisa Wymore (UCB). This work was
   supported in part by the National Science Foundation (NSF grants:
   #0703787, #0724681, #0840399, #1111965), HP Labs, the European
   Aeronautic Defence and Space Company (EADS), and the Center for
   Information Technology in the Interest of Society (CITRIS) at University
   of California, Berkeley. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of the National Science Foundation.
CR [Anonymous], P INT WORKSH IMM TEL
   [Anonymous], P VIS MOD VIS VMV
   [Anonymous], 2011, P ISPRS WORKSH LAS S
   Bailenson J, 2008, MEDIA PSYCHOL, V11, P354, DOI 10.1080/15213260802285214
   Bajcsy P., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P829
   Benford S., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P242
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   CHENG X, 2000, P IEEE C COMP VIS PA
   De Silva DVSX, 2010, IEEE J SEL TOP S NOV
   DEFANTI T, 1999, EC NSF WORKSH RES FR
   Dellaney D, 2006, PRESENCE-VIRTUAL AUG, V15, P218, DOI 10.1162/pres.2006.15.2.218
   Dili Zhang, 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P292, DOI 10.1109/IROS.1991.174465
   DohertySneddon G, 1997, J EXP PSYCHOL-APPL, V3, P105, DOI 10.1037/1076-898X.3.2.105
   Eon, 2009, EON REAL EON COL
   Forte M, 2010, EUROMED 2010 DIGITAL
   FORTE M, 2010, P 16 INT C VIRT SYST
   FRY R, 1975, J SOC PSYCHOL, V96, P145, DOI 10.1080/00224545.1975.9923275
   Gross M, 2003, CHEM BRIT, V39, P22
   Gutwin C, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P299
   Hasenfratz J.-M., 2004, Proceedings of the Tenth Eurographics Conference on Virtual Environments, EGVE'04, (Aire-la-Ville, Switzerland, Switzerland), P147
   IHRKE I., 2004, J WSCG, V12, P537
   Kalra P, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.708560
   Kauff Peter, 2002, P 4 INT C COLLABORAT, P105
   Knoblauch D, 2010, P IEEE VIRT REAL ANN, P279, DOI 10.1109/VR.2010.5444767
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Kreylos O, 2008, LECT NOTES COMPUT SC, V5358, P901, DOI 10.1007/978-3-540-89639-5_86
   Kurillo G, 2008, P 2 ACM IEEE INT C D
   Kurillo G, 2009, P IMMERSCOM 2009 BER, P1
   Kurillo G., 2010, IEEE CVPR WORKSH APP
   Kurillo G, 2010, P 18 MED M VIRT REAL, P290
   Kurillo G, 2008, IEEE INT SYM MULTIM, P111, DOI 10.1109/ISM.2008.32
   Kurillo G, 2009, STUD HEALTH TECHNOL, V142, P148, DOI 10.3233/978-1-58603-964-6-148
   Ladikos Alexander, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563098
   Litos G., 2006, 2006 C COMP VIS PATT, P167, DOI [10.1109/CVPRW.2006.200, DOI 10.1109/CVPRW.2006.200]
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Maimone A, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P51, DOI 10.1109/VR.2012.6180879
   Microsoft kinect, 2010, MICR KIN
   Mulligan J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P959, DOI 10.1109/ICIP.2001.958284
   NAHRSTEDT K, 2007, ACM WORKSH SUPP CREA
   Obdrzalek S, 2012, P 19 MED M VIRT REAL
   OpenWonderland, 2010, SUN SYST
   Petit B, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/247108
   Sang-Hack Jung, 2006, Journal of Multimedia, V1
   Schroder Y., 2011, 0915 ICG
   Sheppard R., 2007, P 15 ACM INT C MULT, P1085
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Vasudevan G.K. R. B. Ramanarayan., 2010, Proceedings of the first annual ACM SIGMM conference on Multimedia systems, MMSys '10, P281
   Vasudevan R, 2010, IEEE INT CON MULTI, P1208, DOI 10.1109/ICME.2010.5582538
   Vasudevan R, 2011, IEEE T MULTIMEDIA, V13, P573, DOI 10.1109/TMM.2011.2123871
   Wang CH, 2010, IEEE INT SYMP INFO, P2028, DOI 10.1109/ISIT.2010.5513368
   Waschbüsch M, 2005, VISUAL COMPUT, V21, P629, DOI 10.1007/s00371-005-0346-7
   Wu W., 2009, MM 09, P481, DOI DOI 10.1145/1631272.1631338
   Wu W., 2011, P ACM MULT
   Yang YJ, 2002, COMPUT SCI ENG, V4, P86, DOI 10.1109/5992.976440
   Yang Z., 2007, Proceedings of the 15th international conference on Multimedia, P882
   Yang ZY, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671963
   Yang ZY, 2005, IEEE INT SYM MULTIM, P112
NR 57
TC 28
Z9 35
U1 0
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2013
VL 17
IS 1
BP 29
EP 43
DI 10.1007/s10055-012-0217-2
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 089NC
UT WOS:000314916300003
DA 2024-07-18
ER

PT J
AU Harrington, MCR
AF Harrington, Maria C. R.
TI The Virtual Trillium Trail and the empirical effects of Freedom and
   Fidelity on discovery-based learning
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Serious games; Educational simulations;
   Child-computer-environment interface; Discovery-based learning; Ecology
   education; User interfaces; Three-dimensional graphics and realism
ID REALITY; ENVIRONMENTS
AB The Virtual Trillium Trail is a new kind of desktop virtual reality application that crosses over into the area of geospatial, educational simulations. Visual fidelity significantly impacts intrinsic learning, activity in situ, and knowledge gained, independent of other factors. The main empirical contribution of this report is on the impact of the user interface design parameters of graphical fidelity and navigational freedom on learning outcomes. A planned orthogonal contrast, Two-way ANOVA with the factors of Visual Fidelity and Navigational Freedom-both scaled, and set to high and low levels-shows significant impacts on the variables of Salient Events, a proxy for discovery-based learning, and Knowledge Gained, as measured between a pre-test and a post-test. Thus, there is strong empirical evidence to support the use of desktop virtual environments, built with high-fidelity, photo-realistic, and free navigational game engine technology, as educational simulations for informal education. The high-level Visual Fidelity combined with the high-level Navigational Freedom condition showed a mean learning gain of 37.44% and is significantly superior to the low-level Visual Fidelity, low-level Navigational Freedom condition, ceteris paribus.
C1 Univ Pittsburgh, Sch Informat Sci, Pittsburgh, PA 15260 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Harrington, MCR (corresponding author), Univ Pittsburgh, Sch Informat Sci, 135 N Bellefield Ave, Pittsburgh, PA 15260 USA.
EM mariaharrington_2000@yahoo.com
CR Aggarwal R, 2007, ANN SURG, V246, P771, DOI 10.1097/SLA.0b013e3180f61b09
   Allison D, 1997, IEEE COMPUT GRAPH, V17, P30, DOI 10.1109/38.626967
   Barab S, 2007, SCI EDUC, V91, P750, DOI 10.1002/sce.20217
   Beechwood Farms Nature Reserve, 2005, BEECHW FARMS OUTD DI
   Bobick AF, 1999, PRESENCE-VIRTUAL AUG, V8, P369, DOI 10.1162/105474699566297
   Bowman D. A., 2003, P ACM S VIRT REAL SO, DOI DOI 10.1145/1008653.1008669
   Brusilovsky P., 2005, Journal on Educational Resources in Computing (JERIC), V5, P6, DOI https://doi.org/10.1145/1163405.1163411
   Darken RP, 1996, INT J HUM-COMPUT INT, V8, P49, DOI 10.1080/10447319609526140
   Dede C, 1996, P IEEE VIRT REAL ANN, P246, DOI 10.1109/VRAIS.1996.490534
   Dede C, 2005, P AERA 2005 AM ED RE
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Dill KE, 1998, AGGRESS VIOLENT BEH, V3, P407, DOI 10.1016/S1359-1789(97)00001-3
   Druin A., 1999, P SIGCHI C HUM FACT, P592, DOI DOI 10.1145/302979.303166
   Gibson J., 1979, The ecological approach to visual perception
   Glass G. V., 1996, Statistical Methods in Education Psychology
   Harrington M CR., 2009, Children Youth Environ, V19
   Harrington MCR, 2010, IEEE T LEARNING 0728
   Jacobson Jeffrey., 2008, ANCIENT ARCHITECTURE
   Johnson A, 1999, IEEE COMPUT GRAPH, V19, P60, DOI 10.1109/38.799741
   Kalisz S, 1996, PLOT STUDY TRI UNPUB
   Mikropoulos TA, 2003, J BIOL EDUC, V37, P176, DOI 10.1080/00219266.2003.9655879
   Morie JF, 2005, APPL PSYCHOPHYS BIOF, V30, P319, DOI 10.1007/s10484-005-6386-y
   Nash EB, 2000, INT J HUM-COMPUT INT, V12, P1, DOI 10.1207/S15327590IJHC1201_1
   Nehring WM, 2009, SIMULAT GAMING, V40, P528, DOI 10.1177/1046878109332282
   Pausch R., 1997, P 24 ANN C COMP GRAP, P13, DOI DOI 10.1145/258734.258744
   Roussos M, 1999, PRESENCE-TELEOP VIRT, V8, P247, DOI 10.1162/105474699566215
   Roussou M., 2006, Virt Real, V10, P227, DOI 10.1007/s10055-006-0035-5
   Scharver C., 2004, COMMUN ACM, V47, P33
   Schell J, 2001, IEEE COMPUT GRAPH, V21, P11, DOI 10.1109/38.933519
   Schell J, 2005, ACM PRES COMPUTERS E, V3
   Winn W., 1993, CONCEPTUAL BASIS ED
   Winn William., 2002, P INT C LEARNING SCI, P497
   Yoon SY, 2008, INT J HUM-COMPUT INT, V24, P288, DOI 10.1080/10447310801920516
NR 33
TC 22
Z9 22
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2012
VL 16
IS 2
BP 105
EP 120
DI 10.1007/s10055-011-0189-7
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 949EO
UT WOS:000304559300002
DA 2024-07-18
ER

PT J
AU Shen, Y
   Gu, PW
   Ong, SK
   Nee, AYC
AF Shen, Y.
   Gu, P. W.
   Ong, S. K.
   Nee, A. Y. C.
TI A novel approach in rehabilitation of hand-eye coordination and finger
   dexterity
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Rehabilitation; Hand-eye coordination; Finger
   dexterity
ID VIRTUAL-REALITY; STROKE
AB Stroke patients or victims who have been involved in serious accidents often suffer from impaired hand-eye coordination and muscle dexterity. Products, such as nine-hole pegboards, have been designed to help rehabilitate various skills, e.g., perceptual accuracy and finger dexterity. Patients who do not have sufficient muscle strength would not be able to carry out such traditional exercises. This paper presents the research aims at providing a fresh and viable approach to physiotherapy for such patients while emulating the rehabilitation capabilities of traditional products. In this paper, a novel approach, AR-Rehab, for the rehabilitation of hand-eye coordination and finger dexterity has been developed incorporating Augmented Reality (AR) technology. In this application, the users can interact with virtual piano keys in a real-life scene by moving the real hands wearing data-gloves to detect the flexing of the fingers and markers to detect the position of the hands.
C1 [Shen, Y.; Gu, P. W.; Ong, S. K.; Nee, A. Y. C.] Natl Univ Singapore, Dept Mech Engn, Fac Engn, Singapore 117576, Singapore.
C3 National University of Singapore
RP Ong, SK (corresponding author), Natl Univ Singapore, Dept Mech Engn, Fac Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
EM mpesy@nus.edu.sg; peiwei@nus.edu.sg; mpeongsk@nus.edu.sg;
   mpeneeyc@nus.edu.sg
RI Nee, Andrew, Y.C./C-9974-2009; Ong, SK/AAP-2918-2021
OI Ong, SK/0000-0002-9569-3350; Nee, Andrew/0000-0002-1029-9988
CR Adamovich SV, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-28
   Barakonyi I, 2005, LECT NOTES COMPUT SC, V3711, P345
   Broeren J, 2008, STUD HEALTH TECHNOL, V136, P77
   Burdea G, 2000, IEEE T REHABIL ENG, V8, P430, DOI 10.1109/86.867886
   Burke JW, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P103, DOI 10.1109/VS-GAMES.2009.17
   Chen YN, 2006, J GLOB INF MANAG, V14, P23, DOI 10.4018/jgim.2006010102
   Choi KS, 2010, LECT NOTES COMPUT SC, V6180, P77, DOI 10.1007/978-3-642-14100-3_13
   Crawford JD, 2004, J NEUROPHYSIOL, V92, P10, DOI 10.1152/jn.00117.2004
   Crosbie JH, 2007, DISABIL REHABIL, V29, P1139, DOI 10.1080/09638280600960909
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Incel NA, 2009, INT J REHABIL RES, V32, P213, DOI 10.1097/MRR.0b013e3283298226
   Jack D, 2001, IEEE T NEUR SYS REH, V9, P308, DOI 10.1109/7333.948460
   Li SQ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P480, DOI 10.1109/ROBIO.2009.5420694
   Luo X, 2005, P ANN INT IEEE EMBS, P6855
   Malouin F, 2003, M S-MED SCI, V19, P994, DOI 10.1051/medsci/20031910994
   Pareto L., 2008, Proceedings of 7th International conference series on disability, virtual reality and associated technologies (ICDVRAT) with ArtAbilitation, Maia, Portugal, 2008 September 8-10, P245
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Popescu VG, 2000, IEEE T INF TECHNOL B, V4, P45, DOI 10.1109/4233.826858
   Riva G, 1998, IEEE Trans Inf Technol Biomed, V2, P275, DOI 10.1109/4233.737583
   Rosenberg BH, 2005, J ENDOUROL, V19, P372, DOI 10.1089/end.2005.19.372
   Sucar LE, 2008, HEALTHINF 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON HEALTH INFORMATICS, VOL 2, P107
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
NR 22
TC 11
Z9 11
U1 2
U2 44
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2012
VL 16
IS 2
BP 161
EP 171
DI 10.1007/s10055-011-0194-x
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 949EO
UT WOS:000304559300006
DA 2024-07-18
ER

PT B
AU Man, DWK
AF Man, D. W. K.
BE Kim, JJ
TI Common Issues of Virtual Reality in Neuro-Rehabilitation
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID BRAIN-DAMAGE REHABILITATION; COGNITIVE REHABILITATION; MEMORY
   REHABILITATION; STROKE PATIENTS; ENVIRONMENTS; RATIONALE; SYSTEM;
   INJURY; TECHNOLOGY; ATTENTION
C1 [Man, D. W. K.] Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Man, DWK (corresponding author), Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Hong Kong, Peoples R China.
CR Aguinis H, 2001, INT J SELECT ASSESS, V9, P70, DOI 10.1111/1468-2389.00164
   Albani G., 2000, NEUROL SCI, V23, pS49
   [Anonymous], VIRTUAL REALITY TRAI
   Astur R, 2005, APPL PSYCHOPHYS BIOF, V30, P307, DOI 10.1007/s10484-005-6385-z
   Bertella L, 2001, PRESENCE-VIRTUAL AUG, V10, P440, DOI 10.1162/1054746011470280
   Brooks BM, 2004, BRAIN INJURY, V18, P391, DOI 10.1080/02699050310001619855
   Brooks BM, 2003, NEUROREHABILITATION, V18, P147
   Brooks BM, 1999, NEUROPSYCHOL REHABIL, V9, P63, DOI 10.1080/713755589
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Castelnuovo G., 2003, PsychNology Journal, V3, P310
   Christiansen C, 1998, ARCH PHYS MED REHAB, V79, P888, DOI 10.1016/S0003-9993(98)90083-1
   Cunningham D, 1999, Cyberpsychol Behav, V2, P19, DOI 10.1089/cpb.1999.2.19
   Da Costa R, 2000, P 3 INT C DIS VIRT R, P221
   Dou ZL, 2006, BRAIN INJURY, V20, P219, DOI 10.1080/02699050500488215
   Gaggioli, 2001, CYBERPSYCHOLOGY MIND, V2, P157
   Galimberti C., 2001, CYBERPSYCHOLOGY MIND, P129
   Gordon WA, 2006, J HEAD TRAUMA REHAB, V21, P156, DOI 10.1097/00001199-200603000-00008
   Gourlay D, 2000, INT J MED INFORM, V60, P255, DOI 10.1016/S1386-5056(00)00100-3
   Grealy MA, 1999, ARCH PHYS MED REHAB, V80, P661, DOI 10.1016/S0003-9993(99)90169-7
   GREALY MA, 2001, PEDIAT REHABILITATIO, V4, P41
   Johnson S., 1997, TRAINING RAPIDLY CHA
   Kalawksy R.S., 1993, SCI VIRTUAL REALITY
   Katz N, 2005, DISABIL REHABIL, V27, P1235, DOI 10.1080/09638280500076079
   Kizony R, 2003, J VISUAL COMP ANIMAT, V14, P261, DOI 10.1002/vis.323
   Kolb A., 2001, EXPERIENTIAL LEARNIN
   Lathan CE, 2002, HUM FAC ER, P403
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P383, DOI 10.1089/109493103322278763
   Lo Priore C, 2003, CYBERPSYCHOL BEHAV, V6, P281, DOI 10.1089/109493103322011579
   Man D.W.K., 2010, EVALUATION IN PRESS
   Man D.W.K., 2010, DEV VALIDAT IN PRESS
   Mantovani F., 2001, Towards cyberpsychology: Mind, cognition and society in the internet age, P207
   McComas J., 1998, CyberPsychology and Behavior, V1, P115, DOI [10.1089/cpb.1998.1.121, DOI 10.1089/CPB.1998.1.121]
   McGeorge P, 2001, PRESENCE-TELEOP VIRT, V10, P375, DOI 10.1162/1054746011470235
   Mendozzi L., 1998, CYBERPSYCHOL BEHAV, V1, P79
   Morganti F, 2006, PSYCHNOLOGY J, V4, P181
   Munro A, 2002, HUM FAC ER, P415
   Myers RL, 2000, CYBERPSYCHOL BEHAV, V3, P465, DOI 10.1089/10949310050078922
   Pugnetti L., 1998, Cyberpsychology Behavior, V1, P151, DOI [10.1089/CPB.1998.1.151, DOI 10.1089/CPB.1998.1.151]
   Reid D., 2003, Physical and Occupational Therapy in Geriatrics, V21, P1
   Reid Denise, 2004, Occup Ther Int, V11, P131, DOI 10.1002/oti.202
   Riva G, 2002, CYBERPSYCHOL BEHAV, V5, P219, DOI 10.1089/109493102760147213
   Rizzo AA, 2004, TELEMED J E-HEALTH, V10, P184, DOI 10.1089/1530562041641336
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Rizzo AA, 1997, J HEAD TRAUMA REHAB, V12, P1, DOI 10.1097/00001199-199712000-00002
   Rizzo AA., 1998, Cyberpsychol Behav, V1, P59, DOI 10.1089/cpb.1998.1.59
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Rose FD, 1998, ST HEAL T, V58, P233
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Saposnik G, 2010, INT J STROKE, V5, P47, DOI 10.1111/j.1747-4949.2009.00404.x
   Schultheis M., 2000, REHABWIRE, V2
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Spiers HJ, 2001, BRAIN, V124, P2476, DOI 10.1093/brain/124.12.2476
   Tam SF, 2005, REHABIL PSYCHOL, V50, P285, DOI 10.1037/0090-5550.50.3.285
   Tam Sing-Fai, 2003, Occup Ther Int, V10, P20, DOI 10.1002/oti.175
   Tarr MJ, 2002, NAT NEUROSCI, V5, P1089, DOI 10.1038/nn948
   Thomas G. P., 1996, P 1 EUR C DIS VIRT R, P5
   Trepagnier CG, 1999, NEUROREHABILITATION, V12, P63
   Tsang M., VIRTUAL REALIT UNPUB
   Tsirlin I, 2009, CYBERPSYCHOL BEHAV, V12, P175, DOI 10.1089/cpb.2008.0208
   Vince J., 1998, ESSENTIAL VIRTUAL RE
   Wann JP, 1997, COMMUN ACM, V40, P49, DOI 10.1145/257874.257885
   Weiss P, 2005, TXB NEURAL REPAIR NE, P182
   Yip B. C.B, 2010, INTELLIGENT IN PRESS
   Yip BCB, 2009, BRAIN INJURY, V23, P1017, DOI 10.3109/02699050903379412
   You SH, 2005, STROKE, V36, P1166, DOI 10.1161/01.STR.0000162715.43417.91
   Zhang L, 2003, ARCH PHYS MED REHAB, V84, P1118, DOI 10.1016/S0003-9993(03)00203-X
NR 66
TC 3
Z9 3
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 419
EP 428
D2 10.5772/553
PG 10
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400020
DA 2024-07-18
ER

PT B
AU Sonar, A
   Kuxhaus, L
   Carroll, J
AF Sonar, Ajay
   Kuxhaus, Laurel
   Carroll, James
BE Kim, JJ
TI Simulation of Subject Specific Bone Remodeling and Virtual Reality
   Visualization
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID TRABECULAR BONE; CANCELLOUS BONE; ARCHITECTURE; MODEL; MECHANISM;
   THICKNESS
C1 [Sonar, Ajay; Kuxhaus, Laurel; Carroll, James] Clarkson Univ, Potsdam, NY 13676 USA.
C3 Clarkson University
RP Sonar, A (corresponding author), Clarkson Univ, Potsdam, NY 13676 USA.
CR Bronckers ALJJ, 1996, J BONE MINER RES, V11, P1281
   Burger EH, 1999, FASEB J, V13, pS101, DOI 10.1096/fasebj.13.9001.s101
   Burr DB, 2002, BONE, V30, P2, DOI 10.1016/S8756-3282(01)00619-6
   BURR DB, 1993, CALCIFIED TISSUE INT, V53, pS75, DOI 10.1007/BF01673407
   FROST HM, 1982, METAB BONE DIS RELAT, V4, P217, DOI 10.1016/0221-8747(82)90031-5
   FROST HM, 1983, CLIN ORTHOP RELAT R, P286
   Hildebrand T, 1997, J MICROSC-OXFORD, V185, P67, DOI 10.1046/j.1365-2818.1997.1340694.x
   Hildebrand T, 1999, J BONE MINER RES, V14, P1167, DOI 10.1359/jbmr.1999.14.7.1167
   Huiskes R, 2000, NATURE, V405, P704, DOI 10.1038/35015116
   Ju T, 2007, COMPUT AIDED DESIGN, V39, P352, DOI 10.1016/j.cad.2007.02.006
   Lemaire V, 2004, J THEOR BIOL, V229, P293, DOI 10.1016/j.jtbi.2004.03.023
   Linden J., 2003, CALCIFIED TISSUE INT, V73, P537
   Liu XS, 2008, BONE, V43, P292, DOI 10.1016/j.bone.2008.04.008
   MOSEKILDE L, 1988, BONE, V9, P247, DOI 10.1016/8756-3282(88)90038-5
   MOSEKILDE L, 1989, BONE, V10, P425, DOI 10.1016/8756-3282(89)90074-4
   MULLENDER MG, 1995, J ORTHOPAED RES, V13, P503, DOI 10.1002/jor.1100130405
   Muller R, 1997, P SOC PHOTO-OPT INS, V3149, P69, DOI 10.1117/12.292727
   Muller R, 1996, J BIOMECH, V29, P1053, DOI 10.1016/0021-9290(96)00006-1
   PARFITT AM, 1984, CALCIFIED TISSUE INT, V36, pS37, DOI 10.1007/BF02406132
   PARFITT AM, 1983, J CLIN INVEST, V72, P1396, DOI 10.1172/JCI111096
   PARFITT AM, 1987, J BONE MINER RES, V2, P595, DOI 10.1002/jbmr.5650020617
   Pivonka P, 2008, BONE, V43, P249, DOI 10.1016/j.bone.2008.03.025
   Ruegsegger P, 1996, CALCIFIED TISSUE INT, V58, P24, DOI 10.1007/s002239900006
   Ruimerman R., 2001, COMPUT METHOD BIOMEC, V4, P433
   Simmons CA, 1997, J BONE MINER RES, V12, P942, DOI 10.1359/jbmr.1997.12.6.942
   Sommerville D., 1959, ANAL GEOMETRY THREE
   Stauber M, 2006, BONE, V38, P475, DOI 10.1016/j.bone.2005.09.019
   Thomsen JS, 2005, J MICROSC-OXFORD, V218, P171, DOI 10.1111/j.1365-2818.2005.01469.x
   Van der Linden JC, 2001, J BONE MINER RES, V16, P688, DOI 10.1359/jbmr.2001.16.4.688
   VANRIETBERGEN B, 1993, J BIOMECH, V26, P369, DOI 10.1016/0021-9290(93)90001-U
   WEINBAUM S, 1994, J BIOMECH, V27, P339, DOI 10.1016/0021-9290(94)90010-8
   Wolff J, 1986, LAW BONE REMODELLING
NR 32
TC 0
Z9 0
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 273
EP 290
D2 10.5772/553
PG 18
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400014
DA 2024-07-18
ER

PT J
AU Carpio, R
   Baumann, O
   Birt, J
AF Carpio, Rudy
   Baumann, Oliver
   Birt, James
TI Evaluating the viewer experience of interactive virtual reality movies
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Filmmaking; Film analysis; Emotion; Objective measures;
   Self-report
ID HEART-RATE-VARIABILITY; EEG ALPHA-ACTIVITY; USER EXPERIENCE; EMOTION;
   STRESS; ENGAGEMENT
AB Significant advances in virtual reality (VR) technology have called into question the traditional methods of cinema storytelling and dissemination. New VR devices, such as the Meta (Oculus) Quest, have expanded the possibilities for viewing movies. The purpose of this study is to compare the emotional and cognitive impacts of VR and traditional 2D movies. In this study, sixty volunteers were divided into two groups and presented a movie (Gala) in 2D or VR format. We employed a multimodal method to assess the cognitive and emotional effects of the film both during and after watching. Our technique combined self-reports, interviews, questionnaires, and objective heart rate and EEG brain activity data. After quantitative and qualitative evaluation, it was discovered, that regardless of media, there was a substantial influence of the movie on the emotional state of the participant's mood. Moreover, compared to the traditional 2D-movie, the VR movie led to more consistent and robust positive effect on all aspects of self-rated affect. The difference in self-reported mood was corroborated by reduced EEG amplitudes in the beta frequency band, indicating higher levels of positive affectivity, which was only observed for the VR movie. Lastly, the VR movie also leads to overall higher self-rated immersion and engagement than the 2D version. Our results highlight the potential of VR movies to engage and emotionally affect audiences beyond traditional cinema. Moreover, our study highlights the value of using a multidisciplinary method for analysing audience impacts.
C1 [Carpio, Rudy; Baumann, Oliver; Birt, James] Bond Univ, Fac Soc & Design, 14 Univ Dr, Gold Coast, Qld 4229, Australia.
C3 Bond University
RP Carpio, R (corresponding author), Bond Univ, Fac Soc & Design, 14 Univ Dr, Gold Coast, Qld 4229, Australia.
EM rudy.carpio-alfsen@student.bond.edu.au
RI Baumann, Oliver/C-8296-2009
OI Carpio-Alfsen, Rudy/0000-0002-1594-3779; Baumann,
   Oliver/0000-0003-3976-5855; Birt, James/0000-0002-0422-4867
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Abdullah SMSA., 2021, Journal of Applied Science and Technology Trends, V2, P52
   [Anonymous], 2004, P 2004 C INT DES CHI
   Azarbarzin A, 2014, SLEEP, V37, P645, DOI 10.5665/sleep.3560
   Bhayee Sheffy, 2016, BMC Psychol, V4, P60
   Billington P, 2018, ACM SIGGRAPH 2018 VI
   Bindman SW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174031
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brylla C, 2018, STUD AUSTRALAS CINE, V12, P150, DOI 10.1080/17503175.2018.1540097
   Caputo A, 2017, UNIV PSYCHOL, V16, DOI [10.11144/Javeriana.upsy16-2.sdsw, 10.11144/javeriana.upsy16-2.sdsw]
   Carpio R, 2022, GALA VR MOVIE
   Carpio R, 2023, CREATIVE IND J, DOI 10.1080/17510694.2023.2171336
   Carpio R, 2022, CREATIVE IND J, V15, P189, DOI 10.1080/17510694.2021.2017634
   Chapman P., 1997, Models of engagement: Intrinsically motivated interaction with multimedia learning software
   CIFF45, 2020, BONF
   COMSTOCK G, 1978, TELEV QUART, V15, P5
   Douglas Y, 2000, P 11 ACM HYP HYP
   Eisenstein S., 2014, Film form: Essays in film theory
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   FORLIZZI J, 2004, P 5 C DES INT SYST P, DOI [10.1145/1013115.1013152, DOI 10.1145/1013115.1013152]
   Girvan C, 2018, ETR&D-EDUC TECH RES, V66, P1087, DOI 10.1007/s11423-018-9577-y
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Güntekin B, 2010, NEUROSCI LETT, V483, P173, DOI 10.1016/j.neulet.2010.08.002
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Hasson U, 2008, PROJECTIONS, V2, P1, DOI 10.3167/proj.2008.020102
   Haywood N, 2006, BCS CONF SERIES, P113, DOI 10.1007/1-84628-249-7_8
   HOROWITZ M, 1976, ARCH GEN PSYCHIAT, V33, P1339
   Hull R, 2018, FUNOLOGY, V2, P469
   Jacques R., 1995, Canadian Journal of Educational Communication, V24, P49
   Kahneman D, 2006, J ECON PERSPECT, V20, P3, DOI 10.1257/089533006776526030
   Kanske P, 2010, BEHAV RES METHODS, V42, P987, DOI 10.3758/BRM.42.4.987
   Kawabata H, 2004, J NEUROPHYSIOL, V91, P1699, DOI 10.1152/jn.00696.2003
   Kim CY, 2007, SPATIAL VISION, V20, P545, DOI 10.1163/156856807782758395
   Kim HG, 2018, PSYCHIAT INVEST, V15, P235, DOI 10.30773/pi.2017.08.17
   Korkut EH, 2023, VIRTUAL REAL-LONDON, V27, P1447, DOI 10.1007/s10055-023-00753-8
   Krigolson OE, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00109
   Laarni J, 2004, P 3 NORD C HUM COMP
   Lim JL, 2013, NEUROIMAGE, V76, P81, DOI 10.1016/j.neuroimage.2013.03.018
   Livingstone M., 2002, Vision and art: The biology of seeing
   Mandryk RL, 2006, BEHAV INFORM TECHNOL, V25, P141, DOI 10.1080/01449290500331156
   Mandryk RL, 2004, CHI 04 HUM FACT COMP
   Maravilla MM, 2019, ICONFERENCE 2019 P, DOI [10.21900/iconf.2019.103338, DOI 10.21900/ICONF.2019.103338]
   Marechal Catherine, 2019, High-Performance Modelling and Simulation for Big Data Applications: Selected Results of the COST Action IC1406 cHiPSet. Lecture Notes in Computer Science (LNCS 11400), P307, DOI 10.1007/978-3-030-16272-6_11
   Mavros P, 2016, APPL SPAT ANAL POLIC, V9, P191, DOI 10.1007/s12061-015-9181-z
   McIver Lopes D, 2002, J AESTHET ART CRITIC, V60, P365
   Nestor PG., 2018, RES METHODS PSYCHOL, DOI [10.2304/plat.2012.11.1.106, DOI 10.2304/PLAT.2012.11.1.106]
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Parkhe V, 2016, SOFT COMPUT, V20, P3373, DOI 10.1007/s00500-015-1779-1
   Parkhe V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2418, DOI 10.1109/ICACCI.2015.7275981
   Raison Kevin, 2012, Advances in Natural Language Processing. Proceedings 8th International Conference on NLP, JapTAL 2012, P289, DOI 10.1007/978-3-642-33983-7_29
   Ramachandran V. S., 1999, Journal of Consciousness Studies, V6, P15
   Rauschnabel PA, 2022, COMPUT HUM BEHAV, V133, DOI 10.1016/j.chb.2022.107289
   RAY WJ, 1985, SCIENCE, V228, P750, DOI 10.1126/science.3992243
   Rebelo F, 2012, HUM FACTORS, V54, P964, DOI 10.1177/0018720812465006
   Roberts D.S. L., 1996, EMPIR STUD ARTS, V14, P33, DOI DOI 10.2190/1L6D-FA7KUQ0V-B7UM
   Roettgers J, 2019, VARIERY
   Rothe S, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010019
   Saganowski S, 2020, INT CONF PERVAS COMP, DOI 10.1109/percomworkshops48775.2020.9156096
   Schraw G, 1998, INSTR SCI, V26, P113, DOI 10.1023/A:1003044231033
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Singh VK, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P712, DOI 10.1109/iMac4s.2013.6526500
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Sloan RP, 2017, HEALTH PSYCHOL, V36, P73, DOI 10.1037/hea0000397
   Smith TJ, 2010, SAGE ENCY PERCEPTION
   Tricart C, 2019, KEY
   Tüzün H, 2016, COMPUT EDUC, V94, P228, DOI 10.1016/j.compedu.2015.12.005
   Urquhart C, 2003, LIBR INFORM SCI RES, V25, P63, DOI 10.1016/S0740-8188(02)00166-4
   Vecchiato G, 2010, BRAIN TOPOGR, V23, P165, DOI 10.1007/s10548-009-0127-0
   Vesely S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01395
   Vrijkotte TGM, 2000, HYPERTENSION, V35, P880, DOI 10.1161/01.HYP.35.4.880
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Webster J, 2006, MIS QUART, V30, P661
   Yetton BD, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01630
   Yu J, 2011, P 49 ANN M ASS COMP, P1496, DOI DOI 10.1109/CC.2013.6488828
   Zhuang L, 2006, INT C INF KNOWL MAN, V2006, P43, DOI [DOI 10.1145/1183614.1183625, 10.1145/1183614.1183625]
NR 76
TC 1
Z9 1
U1 17
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3181
EP 3190
DI 10.1007/s10055-023-00864-2
EA OCT 2023
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001079689600001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU De Luca, V
   Barba, MC
   D'Errico, G
   Nuzzo, BL
   De Paolis, LT
AF De Luca, Valerio
   Barba, Maria Cristina
   D'Errico, Giovanni
   Nuzzo, Benito Luigi
   De Paolis, Lucio Tommaso
TI A user experience analysis for a mobile Mixed Reality application for
   cultural heritage
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed Reality; User experience; Virtual portals; Extended Reality;
   Mobile applications; Presence
ID AUGMENTED REALITY; INTERNAL STRUCTURE
AB Mixed Reality has emerged as a valuable tool for the promotion of cultural heritage. In this context, in particular, the metaphor of virtual portals allows the virtual visit of monuments that are inaccessible or no longer exist in their original form, integrating them into the real environment. This paper presents the development of a Mixed Reality mobile application that proposes a virtual reconstruction of the church of Sant'Elia in Ruggiano, in the southern province of Lecce (Italy). By placing the virtual portal in the same place where the entrance of the church was located, the user can cross this threshold to enter inside and make a virtual journey into the past. The user experience was evaluated by administering a questionnaire to 60 users who tried the application. From the data collected, four user experience factors were identified (interest, focus of attention, presence and usability), which were compared between young and old, male and female users, and between users who had already visited the church in person and all other users. In general, the scores reveal a total independence of the other three factors from usability and a very high level of interest.
C1 [De Luca, Valerio; Barba, Maria Cristina; Nuzzo, Benito Luigi; De Paolis, Lucio Tommaso] Univ Salento, Dept Engn Innovat, Ctr Ecotekne Pal O SP 6, Lecce, Italy.
   [D'Errico, Giovanni] Polytech Univ Turin, Dept Appl Sci & Technol, Corso Duca Abruzzi 24, Turin, Italy.
C3 University of Salento; Polytechnic University of Turin
RP De Luca, V (corresponding author), Univ Salento, Dept Engn Innovat, Ctr Ecotekne Pal O SP 6, Lecce, Italy.
EM valerio.deluca@unisalento.it; cristina.barba@unisalento.it;
   giovanni.derrico@polito.it; benitoluigi.nuzzo@unisalento.it;
   lucio.depaolis@unisalento.it
RI D'Errico, Giovanni/JKI-0447-2023; De Paolis, Lucio Tommaso/R-2421-2016
OI D'Errico, Giovanni/0000-0003-1415-0731; NUZZO, Benito
   Luigi/0009-0000-8974-0459; De Luca, Valerio/0000-0003-3018-7251; De
   Paolis, Lucio Tommaso/0000-0003-1274-9070
CR Assila A., 2016, Electronic Journal of Computer Science and Information Technology, V6, DOI DOI 10.1016/B978-0-12-384968-7.00008-4
   BARTLETT MS, 1951, BIOMETRIKA, V38, P337, DOI 10.2307/2332580
   Blanco-Pons S, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11164268
   Bruno F, 2010, J CULT HERIT, V11, P42, DOI 10.1016/j.culher.2009.02.006
   Caloro A., 2000, ROSSI, V1711, P134
   Cisternino D, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3460657
   Cisternino D, 2019, LECT NOTES COMPUT SC, V11614, P264, DOI 10.1007/978-3-030-25999-0_23
   Cisternino D, 2018, LECT NOTES COMPUT SC, V10851, P370, DOI 10.1007/978-3-319-95282-6_27
   Comes R, 2014, MEDITERR ARCHAEOL AR, V14
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   David A., 2021, Quality Management Journal, V28, P116, DOI [https://doi.org/10.1080/10686967.2021.1920868, DOI 10.1080/10686967.2021.1920868]
   De paolis Lucio Tommaso, 2022, Digital Applications in Archaeology and Cultural Heritage, DOI 10.1016/j.daach.2022.e00243
   De paolis Lucio Tommaso, 2022, Digital Applications in Archaeology and Cultural Heritage, DOI 10.1016/j.daach.2022.e00238
   De Paolis LT, 2023, VIRTUAL REAL-LONDON, V27, P1117, DOI 10.1007/s10055-022-00712-9
   De Paolis LT, 2021, LECT NOTES COMPUT SC, V12980, P326, DOI 10.1007/978-3-030-87595-4_24
   De Paolis LT, 2013, LECT NOTES COMPUT SC, V7971, P632, DOI 10.1007/978-3-642-39637-3_50
   Duguleana M, 2018, COMM COM INF SC, V852, P184, DOI 10.1007/978-3-319-92285-0_26
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Galatis P., 2016, P MOBICASE16 P 8 EAI, P11
   Georgiou Y, 2017, INT J HUM-COMPUT ST, V98, P24, DOI 10.1016/j.ijhcs.2016.09.014
   Gleue T., 2001, P 2001 C VIRTUAL REA, P161, DOI [10.1145/584993.585018, DOI 10.1145/584993.585018]
   Hair J.F., 2022, A primer on partial least squares structural equation modeling (PLS-SEM), V3rd ed.
   Hair JF, 2011, J MARKET THEORY PRAC, V19, P139, DOI 10.2753/MTP1069-6679190202
   Hajesmaeel-Gohari S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01407-y
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Henseler J, 2015, J ACAD MARKET SCI, V43, P115, DOI 10.1007/s11747-014-0403-8
   International Organization for Standardization [ISO], 2019, ISO 9241-210:2019
   KAISER HF, 1970, PSYCHOMETRIKA, V35, P401, DOI 10.1007/BF02291817
   KAISER HF, 1974, EDUC PSYCHOL MEAS, V34, P111, DOI 10.1177/001316447403400115
   Kim JH, 2023, TELEMAT INFORM, V77, DOI 10.1016/j.tele.2022.101936
   Kline RB, 2022, Principles and Practice of Structural Equation Modeling: The Guilford Press; A Division of Guilford Publications, Inc
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P1148, DOI 10.1080/10447318.2017.1418805
   Liu CB, 2018, T GIS, V22, P775, DOI 10.1111/tgis.12345
   Magnelli A, 2021, XR CASE STUDIES, P51
   Marto A, 2022, J IMAGING, V8, DOI 10.3390/jimaging8040091
   McCall R, 2011, PERS UBIQUIT COMPUT, V15, P25, DOI 10.1007/s00779-010-0306-8
   Panou C, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7120463
   Partala T., 2023, USER EXPERIENCE SPAT, DOI [10.1007/978-3-031-25752-0_8, DOI 10.1007/978-3-031-25752-0_8]
   Partala T, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P204, DOI 10.1145/2254556.2254593
   Raeburn G, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.927177
   Raeburn G, 2021, LECT NOTES COMPUT SC, V12980, P209, DOI 10.1007/978-3-030-87595-4_16
   REVELLE W, 1978, BEHAV RES METH INSTR, V10, P739, DOI 10.3758/BF03205389
   Revelle W, 1979, Multivariate Behav Res, V14, P403, DOI 10.1207/s15327906mbr1404_2
   Roemer E, 2021, IND MANAGE DATA SYST, V121, P2637, DOI 10.1108/IMDS-02-2021-0082
   Santos M. E. C., 2014, P 20 ACM S VIRT REAL, P167, DOI DOI 10.1145/2671015.2671019
   Santos MEC, 2015, IEEE COMPUT GRAPH, V35, P66, DOI 10.1109/MCG.2015.94
   Schofield G, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P805, DOI 10.1145/3196709.3196714
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Steuer J., 1995, Communication in the age of virtual reality, V33, P37
   von der Pütten AM, 2012, INTERACT COMPUT, V24, P317, DOI 10.1016/j.intcom.2012.03.004
   Vorderer P., 2004, Mec spatial presence questionnaire
   Wedel M, 2020, INT J RES MARK, V37, P443, DOI 10.1016/j.ijresmar.2020.04.004
   Yang SR, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14759
   Zendjebil I, 2008, 10 ACM IEEE VIRT REA, P177
NR 55
TC 0
Z9 0
U1 13
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2821
EP 2837
DI 10.1007/s10055-023-00840-w
EA AUG 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001042559800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zeuwts, LHRH
   Vanhuele, R
   Vansteenkiste, P
   Deconinck, FJA
   Lenoir, M
AF Zeuwts, Linus H. R. H.
   Vanhuele, Romy
   Vansteenkiste, Pieter
   Deconinck, Frederik J. A.
   Lenoir, Matthieu
TI Using an immersive virtual reality bicycle simulator to evaluate hazard
   detection and anticipation of overt and covert traffic situations in
   young bicyclists
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Child cyclists; Hazard perception; Bicycle simulator
ID PERCEPTION TEST; ADOLESCENT PEDESTRIANS; FILLED INTERSECTIONS;
   HEALTH-BENEFITS; CYCLISTS; BEHAVIOR; DRIVERS; FIELD; RISK; TECHNOLOGY
AB Virtual reality (VR) offers an interactive and more engaging setting for studying hazard anticipation and anticipation in child cyclists who have a considerably higher risk for being involved in a traffic accident. Yet, reliability, validity and usability of VR for scientific purposes remain poorly documented. With the long-term goal in mind of developing fun and interactive training programmes, this study intends to test the effectiveness of a novel VR tool to promote cycling safety in children. A virtual traffic environment that reflects a typical Belgian city was created in Unity3D. Children (n = 130; 11.37 +/- 0.54 years old; 92 girls and 38 boys), equipped with a HTC Vive, cycled on an instrumented bicycle through the virtual environment (VE) in which they had to negotiate 14 hazards in a safe manner. Participants' speed and braking responses for the hazards were reported, while eye movements were recorded by means of the Pupil Labs eye tracking VR add-ons. Following the hazard anticipation test, children were questioned regarding perceived realism, simulator sickness and risky behaviours. After 4 weeks, 15 children performed the VR hazard anticipation test a second time. With respect to validity of the VR simulator, the results demonstrate that the overt hazards were fixated (p = 0.044) and braked for (p < 0.001) more, and fixated (p < 0.001) and braked for earlier (p < 0.001) compared to the covert hazards, which provides evidence for content validity of the VR simulator. The (weak) association between temperamental traits such as "errors and violations" and speed supports convergent validity. Furthermore, participants rated the VE as realistic to highly realistic which reflects face validity. Intraclass correlations suggest moderate test-retest reliability for all variables except first fixation rate. To improve ecological validity of hazard anticipation testing in cyclists, this study allowed the participants to cycle and fully interact with the VE. We found that the simulator provides a fun and realistic tool to document hazard anticipation skills in child bicyclists.
C1 [Zeuwts, Linus H. R. H.; Vanhuele, Romy; Vansteenkiste, Pieter; Deconinck, Frederik J. A.; Lenoir, Matthieu] Univ Ghent, Dept Movement & Sport Sci, Watersportlaan 2, B-9000 Ghent, Belgium.
C3 Ghent University
RP Zeuwts, LHRH (corresponding author), Univ Ghent, Dept Movement & Sport Sci, Watersportlaan 2, B-9000 Ghent, Belgium.
EM Linus.Zeuwts@Ugent.be
RI Deconinck, Frederik J.A./H-1165-2016
FU Research Foundation of Flanders (FWO) [12U5718N]
FX AcknowledgementsWe thank the team of ActiveMe for the development of the
   VE and setting up the bike. This project was funded by the Research
   Foundation of Flanders (FWO) [Grant No: 12U5718N] and the Flemish
   Government-Department of mobility and public works.
CR Agrawal Ravi, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P1995, DOI 10.1177/1541931213601994
   Agrawal R, 2018, TRANSPORT RES REC, V2672, P20, DOI 10.1177/0361198118758311
   Alberti CF, 2014, TRANSPORT RES F-TRAF, V27, P124, DOI 10.1016/j.trf.2014.09.011
   Belgisch Instituut voor de Verkeersveiligheid, 1975, KON BESL 1 DEC 1975
   Butt AL, 2018, CLIN SIMUL NURS, V16, P25, DOI 10.1016/j.ecns.2017.09.010
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Creem-Regehr SH, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00096
   Crundall D, 2018, ACCIDENT ANAL PREV, V121, P335, DOI 10.1016/j.aap.2018.05.013
   Crundall D, 2012, ACCIDENT ANAL PREV, V45, P600, DOI 10.1016/j.aap.2011.09.049
   Davies AG, 2019, BMJ SIMUL TECHNOL EN, V5, P234, DOI 10.1136/bmjstel-2017-000295
   de Hartog JJ, 2010, ENVIRON HEALTH PERSP, V118, P1109, DOI 10.1289/ehp.0901747
   Duchowski A. T., 2017, EYE TRACKING METHODO, DOI [10.1007/978-3-319-57883-5, DOI 10.1007/978-3-319-57883-5]
   Elliott MA, 2004, TRANSPORT RES F-TRAF, V7, P373, DOI 10.1016/j.trf.2004.10.002
   Ellis J., 2014, 811880 DOT HS
   Fisher, 2017, BEHAV RES METHODS, V37, P379
   Fuller R, 2005, ACCIDENT ANAL PREV, V37, P461, DOI 10.1016/j.aap.2004.11.003
   Holmqvist K., 2011, Eye Tracking: A Comprehensive Guide To Methods And Measures
   Horswill MS, 2015, ACCIDENT ANAL PREV, V82, P213, DOI 10.1016/j.aap.2015.05.019
   Ikpeze, 2018, SAF BENEFITS, V9, P1
   Jiang YY, 2019, IEEE T VIS COMPUT GR, V25, P2886, DOI 10.1109/TVCG.2018.2865945
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kooijman JDG, 2013, VEHICLE SYST DYN, V51, P1722, DOI 10.1080/00423114.2013.824990
   Kredel R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01845
   Lehtonen E, 2017, ACCIDENT ANAL PREV, V105, P72, DOI 10.1016/j.aap.2016.07.036
   Lehtonen E, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160823
   Leong SC, 2022, J NEUROENG REHABIL, V19, DOI 10.1186/s12984-022-01071-x
   Malone S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647723
   Mangalore GP, 2019, TRANSPORT RES REC, V2673, P455, DOI 10.1177/0361198119847612
   McKenna FP, 2006, J EXP PSYCHOL-APPL, V12, P1, DOI 10.1037/1076-898X.12.1.1
   Meir A, 2015, ACCIDENT ANAL PREV, V83, P101, DOI 10.1016/j.aap.2015.07.006
   Meir A, 2013, TRANSPORT RES F-TRAF, V20, P90, DOI 10.1016/j.trf.2013.05.004
   Melin MC, 2018, TRANSPORT RES F-TRAF, V58, P292, DOI 10.1016/j.trf.2018.06.017
   Mestre DR, 2011, PRESENCE-VIRTUAL AUG, V20, P1, DOI 10.1162/pres_a_00031
   Meyer S, 2014, TRANSPORT RES F-TRAF, V26, P190, DOI 10.1016/j.trf.2014.07.007
   Nazemi, 2019, 8 INT CYCLING SAFETY
   Nazemi M., 2018, ARBEITSBERICHTE VERK, V1383, P1
   Newbutt N, 2020, CYBERPSYCH BEH SOC N, V23, P23, DOI 10.1089/cyber.2019.0206
   Nieuwkamp, 2018, THEMADOSSIER VERKEER, P72
   Oja P, 2011, SCAND J MED SCI SPOR, V21, P496, DOI 10.1111/j.1600-0838.2011.01299.x
   Orquin Jacob L, 2018, Behav Res Methods, V50, P1645, DOI 10.3758/s13428-017-0998-z
   Parmet Y, 2014, TRANSPORT RES F-TRAF, V25, P98, DOI 10.1016/j.trf.2014.05.007
   Plumert JM, 2011, J EXP CHILD PSYCHOL, V108, P322, DOI 10.1016/j.jecp.2010.07.005
   Pucher J., 2012, City cycling, DOI [10.1253/circj.CJ-11-0870, DOI 10.3145/EPI.2022.ENE.11, 10.7551/mitpress/9434.001.0001, DOI 10.7551/MITPRESS/9434.001.0001]
   Rangelova S, 2018, PRESENCE-TELEOP VIRT, V27, P15, DOI 10.1162/PRES_a_00318
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Rosenbloom T, 2015, ACCIDENT ANAL PREV, V79, P160, DOI 10.1016/j.aap.2015.03.019
   Sahlberg, 2015, INT CYCLING C, P1
   Schiffman HarveyRichard., 2001, SENSATION PERCEPTION
   Schramka F., 2017, ARBEITSBERICHTE VERK, V1244, P1
   Schramka F., 2017, J COMPUT, V1244, P603
   Schwebel DC, 2008, ACCIDENT ANAL PREV, V40, P1394, DOI 10.1016/j.aap.2008.03.005
   Schwebel DC, 2018, J PEDIATR PSYCHOL, V43, P473, DOI 10.1093/jpepsy/jsx147
   Schwebel DC, 2017, VIRTUAL REAL-LONDON, V21, P145, DOI 10.1007/s10055-016-0304-x
   Stevens E, 2013, J PEDIATR PSYCHOL, V38, P285, DOI 10.1093/jpepsy/jss116
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Tang YM, 2022, EDUC RES REV-NETH, V35, DOI 10.1016/j.edurev.2021.100429
   Twisk DAM, 2015, TRANSPORT RES F-TRAF, V30, P45, DOI 10.1016/j.trf.2015.01.011
   Twisk DAM, 2014, ACCIDENT ANAL PREV, V66, P55, DOI 10.1016/j.aap.2014.01.002
   van Paridon K., 2021, SENSORS-BASEL, V21, P1
   van Paridon KN, 2019, TRANSPORT RES F-TRAF, V67, P217, DOI 10.1016/j.trf.2019.10.014
   Vansteenkiste P, 2016, TRANSPORT RES F-TRAF, V41, P182, DOI 10.1016/j.trf.2016.05.001
   Vansteenkiste P, 2015, ACCIDENT ANAL PREV, V78, P8, DOI 10.1016/j.aap.2015.02.010
   Vansteenkiste P, 2014, TRANSPORT RES F-TRAF, V23, P81, DOI 10.1016/j.trf.2013.12.019
   Velichkovsky B.M., 2002, TRANSPORT RES F-TRAF, V5, P145, DOI DOI 10.1016/S1369-8478(02)00013-X
   Vlakveld W., 2011, Hazard Anticipation of Young Novice Drivers : Assessing and Enhancing the Capabilities of Young Novice Drivers to Anticipate Latent Hazards in Road and Traffic Situations
   Vlakveld WP, 2014, TRANSPORT RES F-TRAF, V22, P218, DOI 10.1016/j.trf.2013.12.013
   Walter, 2022, PLOS COMPUT BIOL, V1241, P47
   Warlop G, 2020, HUM MOVEMENT SCI, V71, DOI 10.1016/j.humov.2020.102616
   Wetton MA, 2010, ACCIDENT ANAL PREV, V42, P1232, DOI 10.1016/j.aap.2010.01.017
   Wetton MA, 2011, ACCIDENT ANAL PREV, V43, P1759, DOI 10.1016/j.aap.2011.04.007
   Wolfe B, 2022, HUM FACTORS, V64, P694, DOI 10.1177/0018720820939693
   Wolfe B, 2020, J EXP PSYCHOL GEN, V149, P490, DOI 10.1037/xge0000665
   Zeuwts LHRH, 2020, SAFETY SCI, V123, DOI 10.1016/j.ssci.2019.104562
   Zeuwts LHRH, 2017, ACCIDENT ANAL PREV, V108, P112, DOI 10.1016/j.aap.2017.08.024
   Zeuwts LHRH, 2017, ACCIDENT ANAL PREV, V105, P64, DOI 10.1016/j.aap.2016.04.034
NR 75
TC 4
Z9 4
U1 4
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1507
EP 1527
DI 10.1007/s10055-023-00746-7
EA JAN 2023
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000915679300001
DA 2024-07-18
ER

PT J
AU Rahimi, FB
   Boyd, JE
   Eiserman, JR
   Levy, RM
   Kim, B
AF Rahimi, Farzan Baradaran
   Boyd, Jeffrey E.
   Eiserman, Jennifer R.
   Levy, Richard M.
   Kim, Beaumie
TI Museum beyond physical walls: an exploration of virtual reality-enhanced
   experience in an exhibition-like space
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Hybrid space; Museum experience; Qualitative approach;
   Exploratory research; Commercial VR game
ID ENGAGEMENT; MODEL
AB New media and technology are changing the museum experience in the twenty-first century. One such change is that of hybrid space in museums. A museum hybrid space combines physical artifacts co-located with virtual and augmented reality displays. Although the theory and technology exist to provide museums with hybrid space, there are few efforts to put hybrid space, particularly those that utilize commercial video games, into practice. The goal of this research is to explore how a certain type of museum hybrid space, namely, a virtual reality-enhanced environment relying on a commercial video game, can support and improve audience experiences. To reach this goal, a cognitive model is applied in the design of an experimental context that creates an exhibition-like environment for the viewer-participants. In the experiment, a virtual reality-enhanced environment is compared with two environments relying on commonly used media. Results show improvements in viewer-participants' experiences in terms of cognitive and edutainment aspects. Relying on a commercial video game, the VR-enhanced environment stimulated emotions and increased engagement in viewer-participants while helping them enjoy learning. The experimental context of this research can only approximate the full real-world experience that a museum visitor would have. However, the experimental context does provide the basic elements that a viewer would expect and associate with an exhibition, such as, objects for examination, labels, and didactic supports. Results from this research can encourage further investigations of hybrid space in other environments relying on various media types.
C1 [Rahimi, Farzan Baradaran] Univ Calgary, Computat Media Design, Calgary, AB, Canada.
   [Boyd, Jeffrey E.] Univ Calgary, Dept Comp Sci, Calgary, AB, Canada.
   [Eiserman, Jennifer R.] Univ Calgary, Fac Arts, Calgary, AB, Canada.
   [Levy, Richard M.] Univ Calgary, Sch Architecture Planning & Landscape, Calgary, AB, Canada.
   [Kim, Beaumie] Univ Calgary, Werklund Sch Educ, Calgary, AB, Canada.
C3 University of Calgary; University of Calgary; University of Calgary;
   University of Calgary; University of Calgary
RP Rahimi, FB (corresponding author), Univ Calgary, Computat Media Design, Calgary, AB, Canada.
EM farzan.baradaran@ucalgary.ca
RI Yang, Li/JMP-4403-2023
OI Kim, Beaumie/0000-0001-6726-0040; Baradaran Rahimi,
   Farzan/0000-0001-5938-0181
CR Beale K., 2011, MUSEUMS PLAY GAMES I, P486
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Bedford L., 2001, Curator Mus. J, V44, P27, DOI DOI 10.1111/J.2151-6952.2001.TB00027.X
   BERTRAND JT, 1992, EVALUATION REV, V16, P198, DOI 10.1177/0193841X9201600206
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bo Wang, 2019, Journal of Physics: Conference Series, V1302, DOI 10.1088/1742-6596/1302/4/042049
   Bowen J., 2008, Digital technologies and the museum experience: Handheld guides and other media
   Burton C., 2003, International Journal of Arts Management, V5, P56
   Campbell D. T., 1963, HDB RES TEACHING
   Canadian Heritage Information Network, 2004, SURV VIS MUS
   Carliner S, 2001, TECH COMMUN, V48, P66
   Carlsson Rebecca., 2020, MUSEUM NEXT
   Charr M, 2021, MUSEUM NEXT
   Citizen, 2011, VG24 7
   Coates, 2021, MUSEUM NEXT
   Csikszentmihalyi M., 1998, Finding flow: The psychology of engagement with everyday life
   Dewey J, 1929, QUEST CERTAINTY, V1, P1925
   DuFour R., 2006, Learning by doing: A handbook for professional learning communities at school
   Eiserman, 2019, COMMUNICATION
   Ekman Paul., 2003, EMOTIONS REVEALED
   Entertainment Software Association of Canada, 2018, ESS FACTS CAN VID GA
   Falk J, 2005, SCI EDUC, V89, P744, DOI 10.1002/sce.20078
   Falk J. H., 2009, Identity and the Museum Visitor Experience, DOI 10.4324/9781315427058
   Falk J.H., 1998, CURATOR, V41, P107, DOI [DOI 10.1111/J.2151-6952.1998.TB00822.X, 10.1111/j.2151-6952.1998.tb00822.x]
   Falk JohnH., 2004, REINVENTING MUSEUM H, P139
   Frampton K., 2011, SKETCHES NATL HIST M
   Glas N, 2015, INT CONF AFFECT, P944, DOI 10.1109/ACII.2015.7344688
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Harackiewicz JM, 2017, HANDBOOK OF COMPETENCE AND MOTIVATION, 2 EDITION, P334
   Hill, 2012, STAT INSIGHTS ARTS
   Hooper-Greenhill E., 2004, INT J HERIT STUD, V10, P151, DOI [DOI 10.1080/13527250410001692877, 10/1080/13527250410001692877]
   Hooper-Greenhill E., 2003, MEASURING OUTCOMES I
   Huhtamo Erkki., 2010, Museums in a Digital Age, P121
   Huizinga Johan., 2000, Homo Ludens: A Study of the Play-Element in Culture, DOI [10.1177/0907568202009004005, DOI 10.1177/0907568202009004005]
   Jang HS, 2008, J EDUC PSYCHOL, V100, P798, DOI 10.1037/a0012841
   Lidwell William, 2010, Universal Principles of Design, Revised and Updated: 125 Ways to Enhance Usability, Influence Perception, Increase Appeal, Make Better Design Decisions, and Teach through Design
   Macdonald S., 2006, A Companion to Museum Studies
   McMahan A., 2003, The Video Game Reader, V67, P86
   Metzger SA, 2016, THEOR RES SOC EDUC, V44, P532, DOI 10.1080/00933104.2016.1208596
   Mikropoulos T.A., 2006, VIRTUAL REAL-LONDON, V10, P197, DOI DOI 10.1007/S10055-006-0039-1
   Nacke L., 2008, P 2008 C FUT PLAY, P81
   Naing L, 2006, ARCH OROFAC SCI, V1, P9
   Neufert E., 2019, ARCHITECTS DATA
   Papagiannakis G., 2018, MIXED REALITY GAMIFI
   Rahimi FB, 2020, IEEE T GAMES, V12, P312, DOI 10.1109/TG.2019.2954880
   Rahimi FB, 2018, INT J IND ERGONOM, V68, P245, DOI 10.1016/j.ergon.2018.08.002
   Rahimi FB, 2014, MUS MANAG CURATORSHI, V29, P174, DOI 10.1080/09647775.2014.888821
   RAHIMI FB, 2020, IEEE T VISU COMP GRA
   Roussou M., 2001, Immersive Interactive Virtual Reality in the Museum Maria Roussou, Foundation of the Hellenic World
   Rydell RW., 2006, WORLD FAIRS MUSEUMS
   Schwab Klaus, 2017, 4 IND REVOLUTION, DOI DOI 10.1080/10686967.2018.1436355
   Shields Rob., 2002, The Virtual
   Sikiaridi E., 2000, PLANNING, V6, P6
   Silverstone R., 2012, MUSEUM FUTURE NEW EU, P161
   Stoudt, 2011, LOS ANGELES TIMES
   Whitton N, 2011, SIMULAT GAMING, V42, P596, DOI 10.1177/1046878110378587
   Whyte J., 2002, VIRTUAL REALITY BUIL
   Woods E., 2004, Proceedings of the 2nd international conference on Computer graphics and interactive techniques in Australasia and South East Asia (GRAPHITE '04), P230, DOI DOI 10.1145/988834.988873
   Yu Chen., 2004, In Proc. 8th International Conference on Spoken Language Processing (ICSLP 2004), P1329
NR 59
TC 13
Z9 13
U1 13
U2 73
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1471
EP 1488
DI 10.1007/s10055-022-00643-5
EA MAR 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000773172500001
DA 2024-07-18
ER

PT J
AU Yuviler-Gavish, N
   Horesh, E
   Shamilov, E
   Krisher, H
   Admoni, L
AF Yuviler-Gavish, Nirit
   Horesh, Eran
   Shamilov, Elias
   Krisher, Hagit
   Admoni, Levona
TI The effect of augmented virtuality on financial decision-making among
   adults and children
SO VIRTUAL REALITY
LA English
DT Article
DE Decision making; Augmented virtuality; Virtual system; Financial
ID REALITY
AB The current research examined whether users of an augmented virtuality (AV) system, in which real coins and a real coin machine are integrated within a virtual system, will be less inclined to spend money compared to users in a virtual system. Two studies using a virtual grocery store simulation were performed to answer this question. In the first study, 65 undergraduate students were randomly assigned to two between-participants groups: a virtual system group, in which the coins were virtual, and an AV system group. The results demonstrated that participants in the AV system group invested less money than participants in the virtual system group. In the second study, 51 children aged 5-10 years were randomly assigned to the two above-mentioned groups and assigned the same task. In contrast, the results from this study demonstrated that participants in the AV system group invested much more money than participants in the virtual system group, and their decisions were made more quickly. It is possible that the children enjoyed playing the game in the AV version and did not pay attention to the possible results. The effect of different virtuality levels on financial decision-making processes, however, should be further explored.
C1 [Yuviler-Gavish, Nirit; Admoni, Levona] ORT Braude Coll, Dept Ind Engn & Management, Snunit 51,POB 78, IL-21982 Karmiel, Israel.
   [Horesh, Eran] ORT Braude Coll, Dept Mech Engn, Snunit 51,POB 78, IL-21982 Karmiel, Israel.
   [Shamilov, Elias] Intactio Ltd, Eshchar, Israel.
   [Krisher, Hagit] Technion Israel Inst Technol, Unit Preacad Studies, IL-3200003 Haifa, Israel.
C3 Braude Academic College of Engineering; Braude Academic College of
   Engineering; Technion Israel Institute of Technology
RP Yuviler-Gavish, N; Admoni, L (corresponding author), ORT Braude Coll, Dept Ind Engn & Management, Snunit 51,POB 78, IL-21982 Karmiel, Israel.
EM nirit@braude.ac.il; eranh@braude.ac.il; elias.shamilov@gmail.com;
   hagitkrisher1@gmail.com; levona24@gmail.com
RI Gavish, Nirit/AGN-7159-2022
OI Gavish, Nirit/0000-0002-3769-3141
FU Council for Higher Education Foundation, Israel
FX This research was supported in part by the Council for Higher Education
   Foundation, Israel.
CR Abu-Safieh SF., 2011, Pedestrian and evacuation dynamics, P337, DOI [10.1007/978-1-4419-9725-8_31, DOI 10.1007/978-1-4419-9725-8_31]
   Adegoke AS, 2022, SMART SUSTAIN BUILT, V11, P891, DOI 10.1108/SASBE-09-2020-0135
   Cantlon JF, 2009, J COGNITIVE NEUROSCI, V21, P2217, DOI 10.1162/jocn.2008.21159
   Chown John., 1994, HIST MONEY AD 800
   De Paolis LT, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS (ACHI 2011), P192
   de-Juan-Ripoll C, 2020, CYBERPSYCH BEH SOC N, V23, P773, DOI 10.1089/cyber.2019.0761
   Engert W., 2018, Is a cashless society problematic?
   Gofe TE., 2019, J ASIAN BUS STRATEGY, V9, P120, DOI [10.18488/journal.1006.2019.92.120.132, DOI 10.18488/JOURNAL.1006.2019.92.120.132]
   H WU., 2009, P 6 S APPL PERCEPTIO, P35
   Karlsson I, 2017, WINT SIMUL C PROC, P3988, DOI 10.1109/WSC.2017.8248108
   Keeling G, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00247
   LEA SEG, 1995, J ECON PSYCHOL, V16, P681, DOI 10.1016/0167-4870(95)00013-4
   Lu X., 2015, ISARC PROINT S AUTOM, V32, P1, DOI [10.22260/ISARC2015/0116, DOI 10.22260/ISARC2015/0116]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MILGRAM S, 1963, J ABNORM PSYCHOL, V67, P371, DOI 10.1037/h0040525
   Moura F.T., 2017, CAUTHE 2017: Time for Big Ideas? Re-Thinking the Field for Tomorrow, P619, DOI [10.3316/informit.849643300162597, DOI 10.3316/INFORMIT.849643300162597]
   Neges M, 2018, PROCEDIA MANUF, V19, P171, DOI 10.1016/j.promfg.2018.01.024
   Pigny PO, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P229, DOI 10.1109/AIVR46125.2019.00048
   Quiggin A., 1949, Trade routes, trade, and currency in East Africa
   Regenbrecht H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P290, DOI 10.1109/ISMAR.2003.1240725
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Schor JulietB., 1998, OVERSPENT AM
   Siegler RS, 2004, CHILD DEV, V75, P428, DOI 10.1111/j.1467-8624.2004.00684.x
   Sihi D, 2018, J RES INTERACT MARK, V12, P398, DOI 10.1108/JRIM-01-2018-0019
   Singhal S., 2019, INT J MANAG STUD, VVI, P2231, DOI [10.18843/ijms/v6si1/01, DOI 10.18843/IJMS/V6SI1/01]
   Skulmowski A, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00426
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Sütfeld LR, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00122
   Treepong B., 2017, ADV COMPUTER ENTERTA
   Wang X, 2007, 13 INT C VIRT SYST M
   Xu F, 2000, COGNITION, V74, pB1, DOI 10.1016/S0010-0277(99)00066-9
NR 31
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1001
EP 1008
DI 10.1007/s10055-021-00610-6
EA JAN 2022
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000737088900001
DA 2024-07-18
ER

PT J
AU Firat, HB
   Maffei, L
   Masullo, M
AF Firat, Hasan Baran
   Maffei, Luigi
   Masullo, Massimiliano
TI 3D sound spatialization with game engines: the virtual acoustics
   performance of a game engine and a middleware for interactive audio
   design
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual audio reality; 3D audio; Real-time auralization; Game engines;
   Physically based rendering
ID ROOM; AURALIZATION; SIMULATION
AB This study analyses one of the most popular game engines and an audio middleware to reproduce sound according to sound propagation physics. The analysis focuses on the transmission path between the sound source and the receiver. Even if there are several ready-to-use real-time auralization platforms and software, game engines' use with this aim is a recent study area for acousticians. However, audio design needs with game engines and the limits of their basic releases require additional tools (plugins and middleware) to improve both the quality and realism of sound in virtual environments. The paper discusses the use of Unreal Engine 4 and Wwise's 3D audio production methods in a set of different test environments. It assesses their performance in regard to a commercial geometrical acoustics software. The results show that the investigated version of the game engine and its sound assets are insufficient to simulate real-world cases and that significant improvements can be achieved with use of the middleware.
C1 [Firat, Hasan Baran; Maffei, Luigi; Masullo, Massimiliano] Univ Campania Luigi Vanvitelli, Dept Architecture & Ind Design, Aversa, Italy.
C3 Universita della Campania Vanvitelli
RP Firat, HB (corresponding author), Univ Campania Luigi Vanvitelli, Dept Architecture & Ind Design, Aversa, Italy.
EM hasanbaran.firat@unicampania.it
RI Fırat, Hasan Baran/JVN-0092-2024; Fırat, Hasan Baran/ABI-6575-2020;
   Masullo, Massimiliano/A-1585-2012
OI Fırat, Hasan Baran/0000-0002-3269-4727; Fırat, Hasan
   Baran/0000-0002-3269-4727; 
FU Universita degli Studi della Campania Luigi Vanvitelli
FX Open access funding provided by Universita degli Studi della Campania
   Luigi Vanvitelli within the CRUI-CARE Agreement.
CR AHNERT W, 1993, J AUDIO ENG SOC, V41, P894
   Alary, 2017, AUDIOKINETIC BLOG
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   Ammi M, 2015, VIRTUAL REAL-LONDON, V19, P235, DOI 10.1007/s10055-015-0273-5
   [Anonymous], 2018, ARTIF INTELL EMERG T, DOI DOI 10.5772/INTECHOPEN.75957
   [Anonymous], 2011, PHYSICALLY BASED REA
   Audiokinetic, WWIS HELP
   Audiokinetic, 2020, WWIS 2021 1 WHATS NE
   Audiokinetic,, WWIS 2019 2 IS LIV
   Audiokinetic, 2018, WWIS US GUID
   Audiokinetic, 2018, WWIS HELP
   Beale, 2018, VIKING VR DESIGNING, DOI [10.1145/3196709.3196714, DOI 10.1145/3196709.3196714]
   Beig Mirza, 2019, Computer Games Journal, V8, P199, DOI 10.1007/s40869-019-00086-0
   Berger CC, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00021
   Botteldooren D, 1995, J ACOUST SOC AM, V98, P3302, DOI 10.1121/1.413817
   Brinkmann F, 2019, J ACOUST SOC AM, V145, P2746, DOI 10.1121/1.5096178
   Buffoni L-X, 2020, WWISE APPROACH SPA 1
   Chaigne A., 1991, AES 90 CONV PAR
   Cheok AD, 2018, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-319-73864-2
   Craggs A, 1998, HANDBOOK OF ACOUSTICS, P149
   Cuevas-Rodríguez M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211899
   Dalenback BIL, 1996, J ACOUST SOC AM, V100, P899, DOI 10.1121/1.416249
   DIN, 2005, 18041200405 DIN
   Erkut C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P543, DOI 10.1109/VR.2018.8446230
   Firat, 2021, GITHUB SOURCE GEOMET
   Garí SVA, 2020, J AUDIO ENG SOC, V68, P959, DOI 10.17743/jaes.2020.0063
   Garner TA, 2018, PALGRAVE STUD SOUND, P1, DOI 10.1007/978-3-319-65708-0
   Geronazzo M, 2018, INT SYM MIX AUGMENT, P90, DOI 10.1109/ISMAR.2018.00034
   Grübel J, 2017, LECT NOTES ARTIF INT, V10523, P159, DOI 10.1007/978-3-319-68189-4_10
   Hackman DA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45876-8
   Hamilton B., 2016, FINITE DIFFERENCE FI
   Hargreaves JA, 2009, ACTA ACUST UNITED AC, V95, P678, DOI 10.3813/AAA.918196
   He J, 2017, CONVENTION E BRIEF
   Hu HM, 2008, APPL ACOUST, V69, P163, DOI 10.1016/j.apacoust.2007.05.007
   Institute for Hearing Technology and Acoustics RWTH Aachen University, 2018, VIRT AC REAL TIM AUR
   International Organization for Standardization, 1993, 9835 ISO, P1
   Jiang L, 2016, ENVIRON IMPACT ASSES, V60, P126, DOI 10.1016/j.eiar.2016.03.002
   Keklikian, 2017, AUDIOKINETIC BLOG
   Kerruish E, 2019, SENSES SOC, V14, P31, DOI 10.1080/17458927.2018.1556952
   KLEINER M, 1993, J AUDIO ENG SOC, V41, P861
   KROKSTAD A, 1968, J SOUND VIB, V8, P118, DOI 10.1016/0022-460X(68)90198-3
   Krokstad A, 2015, MOD ACOUST SIGN PROC, P15, DOI 10.1007/978-3-319-05660-9_2
   Lawson Glyn, 2015, Human-Computer Interaction, Users and Contexts. 17th International Conference, HCI International 2015. Proceedings: LNCS 9171, P208, DOI 10.1007/978-3-319-21006-3_21
   LEWERS T, 1993, APPL ACOUST, V38, P161, DOI 10.1016/0003-682X(93)90049-C
   Lokki T., 2002, PHYS BASED AURALIZAT
   Maffei, 2018, ASS IT AC 45 CONV NA, P20
   Maffei L., 2018, INT C SOUND VIBR ICS, P1
   Maffei L, 2015, INT J ENV RES PUB HE, V12, P4306, DOI 10.3390/ijerph120404306
   Manocha D, 2011, P AES INT C
   Mehra R, 2019, C IMM INT AUD
   Moeck T, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P189
   NAYLOR GM, 1993, APPL ACOUST, V38, P131, DOI 10.1016/0003-682X(93)90047-A
   Noisternig M, 2017, P DAFX, V2017, P323
   Noisternig M, 2008, ACTA ACUST UNITED AC, V94, P1000, DOI 10.3813/AAA.918116
   Pharr Matt., 2017, Physically Based Rendering: From Theory to Implementation, VThird
   Postal J., 2018, UNIVERSAL ACCESS HUM, P226
   Reichardt W., 1974, APPL ACOUST, V7, P243, DOI DOI 10.1016/0003-682X(74)90033-4
   Reynolds Dan., 2018, STEAM AUDIO VS RESON
   Richard E., 2006, Virtual Reality, V10, P207, DOI DOI 10.1007/S10055-006-0040-8
   Robinson PW., 2019, 5 INT C SPAT AUD ICS
   Savioja L, 1999, J AUDIO ENG SOC, V47, P675
   Savioja L., 2002, Proc. of the Int'l conf. on auditory display, P1
   Savioja L, 2015, J ACOUST SOC AM, V138, P708, DOI 10.1121/1.4926438
   Savioja Lauri., 1999, MODELING TECHNIQUES
   Schoeffler M, 2015, VIRTUAL REAL-LONDON, V19, P181, DOI 10.1007/s10055-015-0270-8
   Schroder Dirk., 2011, Proceedings of Forum Acusticum, P1541
   SCHROEDER MR, 1970, J ACOUST SOC AM, V47, P424, DOI 10.1121/1.1911541
   Scorpio M, 2020, ENERGIES, V13, DOI 10.3390/en13153809
   Siltanen S, 2014, J ACOUST SOC AM, V135, pEL344, DOI 10.1121/1.4879670
   Siltanen Samuel, 2010, P INT S ROOM AC
   Simmonds B., 2019, ROLE EARLY REFLECTIO
   Spagnol S., 2015, P 18 INT C DIG AUD E, P1
   Str?mberg M, 2006, P I ACOUST, V28, P1
   Taylor MicahT., 2009, MM 09, P271
   Valve Corp, 2017, STEAM AUD UNR ENG 4
   van Maercke D, 1986, P ICA S AC THEATR PL, P74
   Vorländer M, 2015, J BUILD PERFORM SIMU, V8, P15, DOI 10.1080/19401493.2014.888594
   Vorlander M., 2008, AURALIZATION FUNDAME
   Vorlander M, 2020, Auralization: Fundamentals of Acoustics, Modelling, Simulation, Algorithms and Acoustic Virtual Reality, V2nd, DOI [10.1007/978-3-030-51202-6, DOI 10.1007/978-3-030-51202-6]
   Vorlander M., 2016, P 22 INT C AC
NR 80
TC 3
Z9 4
U1 9
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 539
EP 558
DI 10.1007/s10055-021-00589-0
EA OCT 2021
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000712484200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sayis, B
   Ramirez, R
   Pares, N
AF Sayis, Batuhan
   Ramirez, Rafael
   Pares, Narcis
TI Mixed reality or LEGO game play? Fostering social interaction in
   children with Autism
SO VIRTUAL REALITY
LA English
DT Article
DE Children with Autism; Mixed reality; Embodied interaction; Social
   initiation; Psychophysiology; Multi-modal evaluation
ID HIGH-FUNCTIONING AUTISM; HEART-RATE-VARIABILITY; VIRTUAL ENVIRONMENTS;
   SPECTRUM DISORDER; SKILLS; INTERVENTIONS; COMMUNICATION; ADOLESCENTS;
   PHYSIOLOGY; BEHAVIOR
AB This study extends the previous research in which it has been shown that a mixed reality (MR) system fosters social interaction behaviours (SIBs) in children with Autism Spectrum Condition (ASC). When comparing this system to a LEGO-based non-digital intervention, it has been observed that an MR system effectively mediates a face-to-face play session between a child with ASC and a child without ASC providing new specific advantageous properties (e.g. not being a passive tool, not needing to be guided by the therapist). Considering the newly collected multimodal data totaling to 72 children (36 trials of dyads, child with ASC/child without ASC), a first goal of the present study is to apply detailed statistical inference and machine learning techniques to extensively evaluate the overall effect of this MR system, when compared to the LEGO condition. This goal also includes the analysis of psychophysiological data and allows the context-driven triangulation of the multimodal data which is operationalized by (i) video-coding of SIBs, (ii) psychophysiological data, and (iii) system logs of user-system events. A second goal is to show how SIBs, taking place in these experiences, are influenced by the internal states of the users and the system. SIBs were measured by video-coding overt behaviours (Initiation, Response and Externalization) and with self-reports. Internal states were measured using a wearable device designed by the FuBIntLab (Full-Body Interaction Lab) to acquire: Electrocardiogram (ECG) and Electrodermal Activity (EDA) data. Affective sliders and State Trait Anxiety Scale questionnaires were used as self-reports. Repeated-measures design was chosen with two conditions, the MR environment and the traditional therapy LEGO. The results show that the MR system has a positive effect on SIBs when compared to the LEGO condition, with an added advantage of being more flexible.
C1 [Sayis, Batuhan; Ramirez, Rafael; Pares, Narcis] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Spain.
C3 Pompeu Fabra University
RP Sayis, B (corresponding author), Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Spain.
EM batuhan.sayis@upf.edu; rafael.ramirez@upf.edu; narcis.pares@upf.edu
RI Ramirez-Melendez, Rafael/C-9827-2014; Pares, Narcis/C-8339-2017; Sayis,
   Batuhan/S-5577-2018
OI Pares, Narcis/0000-0002-1696-6876; Sayis, Batuhan/0000-0002-8802-9945
FU Spanish Ministry of Economy and Competitiveness under the Maria de
   Maeztu Units of Excellence Program [MDM-2015-0502]
FX This work has been funded by Spanish Ministry of Economy and
   Competitiveness under the Maria de Maeztu Units of Excellence Program
   (MDM-2015-0502).
CR Bauminger N, 2002, J AUTISM DEV DISORD, V32, P283, DOI 10.1023/A:1016378718278
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Bernard-Opitz V, 2001, J AUTISM DEV DISORD, V31, P377, DOI 10.1023/A:1010660502130
   Bernardini S, 2014, INFORM SCIENCES, V264, P41, DOI 10.1016/j.ins.2013.10.027
   Berthoz S, 2005, EUR PSYCHIAT, V20, P291, DOI 10.1016/j.eurpsy.2004.06.013
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Bianchi-Berthouze N, 2007, LECT NOTES COMPUT SC, V4738, P102
   Boettger S, 2010, MED SCI SPORT EXER, V42, P443, DOI 10.1249/MSS.0b013e3181b64db1
   Borghi AM, 2010, NEUROPSYCHOLOGIA, V48, P763, DOI 10.1016/j.neuropsychologia.2009.10.029
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Braithwaite J. J., 2013, PSYCHOPHYSIOLOGY, V1, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Brown J, 2001, EDUC TRAIN MENT RET, V36, P312
   Crowell C, 2020, CYBERPSYCH BEH SOC N, V23, P5, DOI 10.1089/cyber.2019.0115
   D'Mello S, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P31
   Di Paolo E. A., 2010, ENACTION NEW PARADIG, P33, DOI DOI 10.7551/MITPRESS/9780262014601.003.0003
   FELDMAN LA, 1995, J PERS SOC PSYCHOL, V69, P153, DOI 10.1037/0022-3514.69.1.153
   FOWLES DC, 1981, PSYCHOPHYSIOLOGY, V18, P232, DOI 10.1111/j.1469-8986.1981.tb03024.x
   Gallo K., 2009, SCIENCE, V5, P97
   Gessaroli E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074959
   Goffman E, 1955, PSYCHIATR, V18, P213, DOI 10.1080/00332747.1955.11023008
   Golan O, 2006, DEV PSYCHOPATHOL, V18, P591, DOI 10.1017/S0954579406060305
   Goodwin M.S., 2006, FOCUS AUTISM DEV DIS, V21, P100, DOI DOI 10.1177/10883576060210020101
   Gordon N. J., 2010, Effective interviewing and interrogation techniques
   Gupta S., 2014, First steps to preschool inclusion: How to jumpstart your program wide plan
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hernandez J, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P307, DOI 10.1145/2632048.2636065
   Hirstein W, 2001, P ROY SOC B-BIOL SCI, V268, P1883, DOI 10.1098/rspb.2001.1724
   Hourcade J.P., 2013, P SIGCHI C HUMAN FAC, P3197, DOI DOI 10.1145/2470654.2466438
   IBM Corp. Released, 2016, IBM SPSS STAT WINDOW
   Kasari C, 2012, CURR PSYCHIAT REP, V14, P713, DOI 10.1007/s11920-012-0317-4
   Ke FF, 2013, J EDUC RES, V106, P441, DOI 10.1080/00220671.2013.832999
   Kirby AV, 2015, AUTISM, V19, P316, DOI 10.1177/1362361314520756
   Laborde S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00213
   LeGoff DB, 2004, J AUTISM DEV DISORD, V34, P557, DOI 10.1007/s10803-004-2550-0
   Liu CC, 2008, INT J HUM-COMPUT ST, V66, P662, DOI 10.1016/j.ijhcs.2008.04.003
   LORD C, 1989, J AUTISM DEV DISORD, V19, P185, DOI 10.1007/BF02211841
   Malinverni L, 2017, COMPUT HUM BEHAV, V71, P535, DOI 10.1016/j.chb.2016.01.018
   McMahon CM, 2013, J AUTISM DEV DISORD, V43, P1843, DOI 10.1007/s10803-012-1733-3
   Moore M, 2000, J AUTISM DEV DISORD, V30, P359, DOI 10.1023/A:1005535602064
   Mora-Guiard J, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P262, DOI 10.1145/2930674.2930695
   Owens G, 2008, J AUTISM DEV DISORD, V38, P1944, DOI 10.1007/s10803-008-0590-6
   Parés N, 2005, IEEE T VIS COMPUT GR, V11, P734, DOI 10.1109/TVCG.2005.88
   Parsons S, 2006, COMPUT EDUC, V47, P186, DOI 10.1016/j.compedu.2004.10.003
   Paul R, 2008, CHILD ADOL PSYCH CL, V17, P835, DOI 10.1016/j.chc.2008.06.011
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Picard RW, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P90, DOI 10.1109/ISWC.1997.629924
   PLUX Wireless Biosignals SA, 2020, BIOS WELC
   Posada-Quintero HF, 2019, IEEE ACCESS, V7, P22523, DOI 10.1109/ACCESS.2019.2899485
   Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009
   Ramdoss S, 2012, DEV NEUROREHABIL, V15, P119, DOI 10.3109/17518423.2011.651655
   Roussos M, 1999, PRESENCE-TELEOP VIRT, V8, P247, DOI 10.1162/105474699566215
   Ruble L., 2008, Clinical Case Studies, V7, P287, DOI [DOI 10.1177/1534650107309450, 10.1177/1534650107309450]
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Sigman M, 1999, MONOGR SOC RES CHILD, V64, P1, DOI 10.1111/1540-5834.00002
   Spielberger C.D, 1970, CONSULTING PSYCHOL
   Srinivasan SM, 2016, RES AUTISM SPECT DIS, V27, P73, DOI 10.1016/j.rasd.2016.04.001
   STRAIN PS, 1983, ANAL INTERVEN DEVEL, V3, P23, DOI 10.1016/0270-4684(83)90024-1
   Strickland DC, 2007, TOP LANG DISORD, V27, P226, DOI 10.1097/01.TLD.0000285357.95426.72
   Tarvainen MP, 2014, COMPUT METH PROG BIO, V113, P210, DOI 10.1016/j.cmpb.2013.07.024
   Trepagnier CG, 1999, NEUROREHABILITATION, V12, P63
   van Dooren M, 2012, PHYSIOL BEHAV, V106, P298, DOI 10.1016/j.physbeh.2012.01.020
   Wechsler D., 1949, Wechsler intelligence scale for children
   Welch KC, 2010, INT J SOC ROBOT, V2, P391, DOI 10.1007/s12369-010-0063-x
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   WOOSTER JS, 1982, ENGL J, V71, P60, DOI 10.2307/816450
NR 65
TC 6
Z9 6
U1 4
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 771
EP 787
DI 10.1007/s10055-021-00580-9
EA SEP 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000698575700002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Wang, XM
   Blackwell, AF
   Jones, R
   Nguyen, HT
AF Wang, Xiaomeng
   Blackwell, Alan F.
   Jones, Richard
   Nguyen, Hieu T.
TI Scene Walk: a non-photorealistic viewing tool for first-person video
SO VIRTUAL REALITY
LA English
DT Article
DE First-person video; Body-worn camera; Video viewing; 3D scene
   reconstruction; Camera trajectory; Cognitive Map
ID SPATIAL KNOWLEDGE ACQUISITION; VIRTUAL ENVIRONMENTS; REAL; NAVIGATION;
   MAPS
AB Scene Walk is a video viewing technique suited to first-person video recorded from wearable cameras. It integrates a 2D video player and visualisation of the camera trajectory into a non-photorealistic partial rendering of the 3D environment as reconstructed from image content. Applications include forensic analysis of first-person video archives, for example as recorded by emergency response teams. The Scene Walk method is designed to support the viewer's construction and application of a cognitive map of the context in which first-person video was captured. We use methods from wayfinding research to assess the effectiveness of this non-photorealistic approach in comparison to actual physical experience of the scene. We find that Scene Walk does allow viewers to create a more accurate and effective cognitive map of first-person video than is achieved using a conventional video browsing interface and that this model is comparable to actually walking through the original environment.
C1 [Wang, Xiaomeng; Blackwell, Alan F.] Univ Cambridge, Dept Comp Sci & Technol, Cambridge CB3 0FD, England.
   [Jones, Richard] Boeing Def UK, Bristol BS16 1EJ, Avon, England.
   [Nguyen, Hieu T.] Boeing Res & Technol, Huntsville, AL USA.
C3 University of Cambridge; Boeing
RP Wang, XM (corresponding author), Univ Cambridge, Dept Comp Sci & Technol, Cambridge CB3 0FD, England.
EM xw337@cam.ac.uk; afb21@cam.ac.uk; richard.jones16@boeing.com;
   hieu.t.nguyen9@boeing.com
CR [Anonymous], 2005, Geo-Information for Disaster Management, DOI [DOI 10.1007/3-540-27468-563, DOI 10.1007/3-540-27468-5_63]
   Arev I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601198
   Arthur P., 1992, Wayfinding: People, Signs, and Architecture
   Ballan L, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778824
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Bolaños M, 2017, IEEE T HUM-MACH SYST, V47, P77, DOI 10.1109/THMS.2016.2616296
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Chen Y, 2010, PROCEEDINGS OF THE 17TH INTERNATIONAL CONGRESS ON SOUND AND VIBRATION
   Dalton RC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00142
   De D, 2015, IEEE INTERNET COMPUT, V19, P26, DOI 10.1109/MIC.2015.72
   del Molino AG, 2017, IEEE T HUM-MACH SYST, V47, P65, DOI 10.1109/THMS.2016.2623480
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gibson David., 2009, The Wayfinding Handbook: Information Design For Public Spaces
   Golledge R., 1985, J ENVIRON PSYCHOL, V5, P125, DOI DOI 10.1016/S0272-4944(85)80014-1
   Golledge RG, 1999, WAYFINDING BEHAVIOR, P5
   Gröger G, 2012, ISPRS J PHOTOGRAMM, V71, P12, DOI 10.1016/j.isprsjprs.2012.04.004
   HERMAN JF, 1978, J EXP CHILD PSYCHOL, V26, P389, DOI 10.1016/0022-0965(78)90120-0
   Higuch K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6536, DOI 10.1145/3025453.3025821
   Higuch K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5180, DOI 10.1145/2858036.2858438
   Ho HI, 2018, LECT NOTES COMPUT SC, V11219, P72, DOI 10.1007/978-3-030-01267-0_5
   Ishiguro Y, 2012, IEEE INT SYM WRBL CO, P72, DOI 10.1109/ISWC.2012.32
   Jennings WG, 2014, J CRIM JUST, V42, P549, DOI 10.1016/j.jcrimjus.2014.09.008
   Kaplan, 1973, COGNITIVE MAPS PERCE, P63
   KITCHIN RM, 1994, J ENVIRON PSYCHOL, V14, P1, DOI 10.1016/S0272-4944(05)80194-X
   Kono M, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139161
   Kopf J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601195
   Kuliga Saskia, 2020, Spatial Cognition XII. 12th International Conference, Spatial Cognition 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12162), P160, DOI 10.1007/978-3-030-57983-8_13
   Lackner JR, 2005, ANNU REV PSYCHOL, V56, P115, DOI 10.1146/annurev.psych.55.090902.142023
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lin YL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P443, DOI 10.1109/ICCVW.2015.65
   Lynch K., 1960, IMAGE CITY
   MACEACHREN AM, 1992, ANN ASSOC AM GEOGR, V82, P245, DOI 10.1111/j.1467-8306.1992.tb01907.x
   MCNAMARA TP, 1986, COGNITIVE PSYCHOL, V18, P87, DOI 10.1016/0010-0285(86)90016-2
   ONEILL M, 1991, J ENVIRON PSYCHOL, V11, P299, DOI 10.1016/S0272-4944(05)80104-5
   Poleg Y, 2015, PROC CVPR IEEE, P4768, DOI 10.1109/CVPR.2015.7299109
   Qiu XH, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01322
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Ruddle RA, 1997, J EXP PSYCHOL-APPL, V3, P143, DOI 10.1037/1076-898X.3.2.143
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Silva M, 2018, PROC CVPR IEEE, P2383, DOI 10.1109/CVPR.2018.00253
   Smykla JO, 2016, AM J CRIM JUSTICE, V41, P424, DOI 10.1007/s12103-015-9316-4
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sugita Y, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P55, DOI 10.1145/3279778.3279783
   TAYLOR HA, 1992, J MEM LANG, V31, P261, DOI 10.1016/0749-596X(92)90014-O
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Turk M, 2018, HYBRID ORBITING TO P, P1, DOI [10.1145/3281505.3281528, DOI 10.1145/3281505.3281528]
   Tversky B., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT '93 Proceedings, P14
   Wilson PN, 1997, HUM FACTORS, V39, P526, DOI 10.1518/001872097778667988
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yao T, 2016, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2016.112
NR 52
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1171
EP 1191
DI 10.1007/s10055-021-00523-4
EA APR 2021
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000642363700001
DA 2024-07-18
ER

PT J
AU Lin, CJ
   Abreham, BT
   Woldegiorgis, BH
AF Lin, Chiuhsiang J.
   Abreham, Betsha T.
   Woldegiorgis, Bereket H.
TI Kinematics of direct reaching in head-mounted and stereoscopic
   widescreen virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Kinematics; Head-mounted display; Stereoscopic widescreen display
AB This research investigated the effects of virtual displays on kinematic parameters during direct pointing at a virtual target. Two virtual displays, three egocentric distances, and three indices of difficulty (IDs) were the independent variables considered in the study. Twelve participants (M = 29.8 +/- 3.45 years of age) with normal visual acuity performed a pointing movement in the two VR displays, a stereoscopic widescreen display (SWD) and a head-mounted display (HMD). The movement data were compiled using a motion system. The outcomes revealed that peak velocity and reaction time differed significantly between the SWD and HMD conditions; peak velocity was higher and reaction time was shorter with the SWD than with the HMD. Nonetheless, the effective movement time and confirmation time were not significantly different between the two VR displays. In addition, the distance judgment accuracies of the HMD and SWD were 96% and 86%, respectively; distance was underestimated in the HMD and overestimated in the SWD. Moreover, both peak velocity and reaction time were significantly lower at high ID than at low and medium IDs. The results suggested that using an SWD could be more effective and efficient than an HMD for restoring motor function in upper and lower limbs. On the other hand, an HMD might be appropriate for applications which require exocentric distance judgment precision, such as architecture or medical visualization. Moreover, such findings provide valuable information for developers and designers of human interfaces and applications in virtual reality.
C1 [Lin, Chiuhsiang J.; Abreham, Betsha T.; Woldegiorgis, Bereket H.] Natl Taiwan Univ Sci & Technol, Dept Ind Management, 43,Sec 4,Keelung Rd, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Ind Management, 43,Sec 4,Keelung Rd, Taipei 10607, Taiwan.
EM chiuhsiangjoelin@gmail.com
RI Tizazu, Betsha/KII-0764-2024
OI Lin, Chiuhsiang/0000-0001-5549-0527; Haile Woldegiorgis,
   Bereket/0000-0001-5563-7605
FU Ministry of Science and Technology, Taiwan [MOST-107-2218-E-011-019-MY3]
FX This paper was partially funded by the Ministry of Science and
   Technology, Taiwan (MOST-107-2218-E-011-019-MY3).
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   [Anonymous], 2005, Motor Control and Learning: A Behavioral Emphasis
   [Anonymous], 2000, 92419 ISO, DOI [10.3403/BSENISO9241, DOI 10.3403/BSENISO9241]
   Balasubramanian Sivakumar, 2012, Am J Phys Med Rehabil, V91, pS255, DOI 10.1097/PHM.0b013e31826bcdc1
   BEGGS WDA, 1970, NATURE, V225, P752, DOI 10.1038/225752a0
   Bruder G, 2016, PRESENCE-TELEOP VIRT, V25, P1, DOI 10.1162/PRES_a_00241
   Crosbie JH, 2007, DISABIL REHABIL, V29, P1139, DOI 10.1080/09638280600960909
   CROSSMAN ERFW, 1983, Q J EXP PSYCHOL-A, V35, P251, DOI 10.1080/14640748308402133
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Deutch JE, 2002, NEUROLOGY REPORT, V26, P79, DOI [10.1097/01253086-200226020-00005, DOI 10.1097/01253086-200226020-00005]
   Elliott D, 2020, EXP BRAIN RES, V238, P2685, DOI 10.1007/s00221-020-05952-2
   Elliott D, 2010, PSYCHOL BULL, V136, P1023, DOI 10.1037/a0020958
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fernandez L, 2004, EXP BRAIN RES, V159, P458, DOI 10.1007/s00221-004-1964-4
   GANDEVIA SC, 1992, BEHAV BRAIN SCI, V15, P614
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   GREENO JG, 1994, PSYCHOL REV, V101, P336, DOI 10.1037/0033-295X.101.2.336
   HENRY D, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P33, DOI 10.1109/VRAIS.1993.380801
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Kay B., 1985, HASKINS LAB STATUS R, V81, P291
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kim Hae-Young, 2013, Restor Dent Endod, V38, P52, DOI 10.5395/rde.2013.38.1.52
   Kim K, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P143, DOI 10.1109/VR.2012.6180922
   Klein E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P107, DOI 10.1109/VR.2009.4811007
   Kwakkel G, 2017, NEUROREHAB NEURAL RE, V31, P784, DOI 10.1177/1545968317732662
   LANGOLF GD, 1976, J MOTOR BEHAV, V8, P113, DOI 10.1080/00222895.1976.10735061
   Lee YH, 2013, HUM MOVEMENT SCI, V32, P511, DOI 10.1016/j.humov.2012.02.001
   Levin MF, 2009, STUD HEALTH TECHNOL, V145, P94, DOI 10.3233/978-1-60750-018-6-94
   Levin MF, 2008, 2008 VIRTUAL REHABILITATION, P60, DOI 10.1109/ICVR.2008.4625123
   Lin CHJ, 2019, INT J IND ERGONOM, V72, P372, DOI 10.1016/j.ergon.2019.06.013
   Lin CJ, 2017, APPL ERGON, V64, P66, DOI 10.1016/j.apergo.2017.05.007
   Lin CJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041427
   Lin CJ, 2018, HUM MOVEMENT SCI, V57, P21, DOI 10.1016/j.humov.2017.11.002
   Lin CJ, 2015, J SOC INF DISPLAY, V23, P319, DOI 10.1002/jsid.378
   Lin CJ, 2015, HUM FACTOR ERGON MAN, V25, P523, DOI 10.1002/hfm.20566
   Lin CJ, 2015, DISPLAYS, V36, P41, DOI 10.1016/j.displa.2014.11.006
   Magdalon EC, 2011, ACTA PSYCHOL, V138, P126, DOI 10.1016/j.actpsy.2011.05.015
   Marathe AR, 2008, J NEUROSCI METH, V167, P2, DOI 10.1016/j.jneumeth.2007.09.025
   MEYER DE, 1988, PSYCHOL REV, V95, P340, DOI 10.1037/0033-295X.95.3.340
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Naceri A., 2010, International Journal On Advances in Intelligent Systems, V3, P51
   Nordin N, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-137
   Park KS, 2012, INT J IND ERGONOM, V42, P293, DOI 10.1016/j.ergon.2012.02.005
   Rand D, 2005, PRESENCE-TELEOP VIRT, V14, P147, DOI 10.1162/1054746053967012
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   SCHMIDT RA, 1979, PSYCHOL REV, V86, P415, DOI 10.1037//0033-295X.86.5.415
   Schmidt RA, 1985, MOTOR BEHAV PROGRAMM, DOI [10.1007/978-3-642-69749-4, DOI 10.1007/978-3-642-69749-4]
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Subramanian S, 2008, 2008 VIRTUAL REHABILITATION, P181, DOI 10.1109/ICVR.2008.4625157
   Subramanian SK, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-36
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Thompson SG, 2007, HUM MOVEMENT SCI, V26, P11, DOI 10.1016/j.humov.2006.09.001
   Viau Antonin, 2004, J Neuroeng Rehabil, V1, P11, DOI 10.1186/1743-0003-1-11
   Waller D, 1999, PRESENCE-TELEOP VIRT, V8, P657, DOI 10.1162/105474699566549
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
   Wolpert DM, 2012, CURR OPIN NEUROBIOL, V22, P996, DOI 10.1016/j.conb.2012.05.003
   Woodworth RS, 1899, PSYCHOL REV-MONOGR S, V3, P1
   Wright DB, 2011, BEHAV RES METHODS, V43, P8, DOI 10.3758/s13428-010-0044-x
NR 61
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1015
EP 1028
DI 10.1007/s10055-021-00505-6
EA MAR 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000625092600001
DA 2024-07-18
ER

PT J
AU Tosto, C
   Hasegawa, T
   Mangina, E
   Chifari, A
   Treacy, R
   Merlo, G
   Chiazzese, G
AF Tosto, Crispino
   Hasegawa, Tomonori
   Mangina, Eleni
   Chifari, Antonella
   Treacy, Rita
   Merlo, Gianluca
   Chiazzese, Giuseppe
TI Exploring the effect of an augmented reality literacy programme for
   reading and spelling difficulties for children diagnosed with ADHD
SO VIRTUAL REALITY
LA English
DT Article
DE ADHD; Augmented reality; Literacy programme; Behavioural monitoring;
   Reading and spelling difficulties
ID COMORBIDITY; PERFORMANCE; PATHWAYS; BEHAVIOR; IMPACT; CARE
AB Children diagnosed with attention deficit hyperactivity disorder (ADHD) experience a variety of difficulties related to three primary symptoms: hyperactivity, inattention and impulsivity. The most common type of ADHD has a combination of all three symptom areas. These core symptoms may negatively impact the academic and social performance of children throughout their school life. The AHA (ADHD-Augmented) project focused specifically on the impact of digital technologies' intervention on literacy skills of children that participated in the pilot study and were diagnosed with ADHD prior to the intervention. Existing research has shown that augmented reality (AR) can improve academic outcomes by stimulating pupils' attention. AHA project aimed at implementing an evidence-based intervention to improve ADHD children's reading and spelling abilities through the enhancement of an existing literacy programme with AR functionality. The present paper reports preliminary findings of the pilot study aimed at evaluating the effectiveness of the AHA system in promoting the acquisition of literacy skills in a sample of children diagnosed with ADHD compared to the literacy programme as usual. Background information on the main characteristics and difficulties related to the teaching and learning process associated with children diagnosed with ADHD are first introduced; the design and methodology of the AHA project intervention are also described. The preliminary findings have shown that AHA project succeeded in delivering an AR solution within an existing online literacy programme, which integrates a set of specific technologies and supports interactive educational content, services, assessment, and feedback.
C1 [Tosto, Crispino; Chifari, Antonella; Merlo, Gianluca; Chiazzese, Giuseppe] CNR, Ist Tecnol Didatt, Palermo, Italy.
   [Hasegawa, Tomonori; Mangina, Eleni] Univ Coll Dublin, Dublin, Ireland.
   [Treacy, Rita] WordsWorth Learning Ltd, Dublin, Ireland.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto per le Tecnologie
   Didattiche (ITD-CNR); University College Dublin
RP Chiazzese, G (corresponding author), CNR, Ist Tecnol Didatt, Palermo, Italy.
EM giuseppe.chiazzese@itd.cnr.it
OI Chiazzese, Giuseppe/0000-0002-0228-6204; Tosto,
   Crispino/0000-0002-0389-2804
FU European Commission [30-CE-0885096/00-34 (ADHD2016-13)]
FX This publication has been supported from European Commission under the
   funding for the project ADHD-Augmented (AHA) Grant Agreement No.
   30-CE-0885096/00-34 (ADHD2016-13), under the Pilot Project: Technologies
   and Tools for Children and Young People with Attention Deficit
   Hyperactivity Disorder (ADHD). The opinions, findings and conclusions or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of the European Commission.
CR [Anonymous], 2013, DIAGNOSTIC STAT MANU, VFifth, P1000
   [Anonymous], 2011, OECD PROJECT OVERCOM
   Avila-Pesantez D, 2018, IEEE GLOB ENG EDUC C, P843, DOI 10.1109/EDUCON.2018.8363318
   Barkley R.A., 1997, ADHD and the nature of self-control
   Berenguer-Forner C, 2015, REV NEUROLOGIA, V60, pS37
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Carlson CL, 2002, J LEARN DISABIL-US, V35, P104, DOI 10.1177/002221940203500202
   Chafouleas SM, 2009, ASSES EFF INTERV, V34, P195, DOI 10.1177/1534508409340391
   Chafouleas SM, 2005, PSYCHOL SCHOOLS, V42, P669, DOI 10.1002/pits.20102
   Chiazzese G, 2019, LECT NOTES COMPUT SC, V11385, P436, DOI 10.1007/978-3-030-11548-7_44
   Daley D, 2010, CHILD CARE HLTH DEV, V36, P455, DOI 10.1111/j.1365-2214.2009.01046.x
   Demaray MK, 2011, PSYCHOL SCHOOLS, V48, P573, DOI 10.1002/pits.20578
   DuPaul GJ, 2013, J LEARN DISABIL-US, V46, P43, DOI 10.1177/0022219412464351
   Fan M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188459
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Hoza B, 2001, J CONSULT CLIN PSYCH, V69, P271, DOI 10.1037//0022-006X.69.2.271
   Kazdin A.E., 2003, Research design in clinical psychology, V4th
   Khoshnevisan B, 2018, P GLOB C ED RES GLOC, P59
   Kofler MJ, 2010, J ABNORM CHILD PSYCH, V38, P149, DOI 10.1007/s10802-009-9357-6
   Leitner Y, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00268
   Lin CY, 2016, LECT NOTES COMPUT SC, V9739, P103, DOI 10.1007/978-3-319-40238-3_11
   Luman M, 2005, CLIN PSYCHOL REV, V25, P183, DOI 10.1016/j.cpr.2004.11.001
   Mangina E, 2018, AHA PILOT PROJECT EV
   Mangina E, 2017, P I CON VIR SYS MULT, P152
   Mayer R. E., 2001, Multimedia learning, DOI DOI 10.1017/CBO9781139164603
   Neale M., 1997, NEALE ANAL READING A
   Ozdemir M, 2018, EURASIAN J EDUC RES, P165, DOI 10.14689/ejer.2018.74.9
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Saltan F, 2017, EURASIA J MATH SCI T, V13, P503, DOI 10.12973/eurasia.2017.00628a
   Sayal K, 2018, LANCET PSYCHIAT, V5, P175, DOI 10.1016/S2215-0366(17)30167-0
   Shapiro E., 1996, ACAD SKILLS PROBLEMS, V2nd
   Tatlow-Golden M, 2018, EARLY INTERV PSYCHIA, V12, P505, DOI 10.1111/eip.12408
   Treacy R, 2017, DYSLEXIA UNRAVELLED
   Vahabzadeh A, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9631
   Vate-U-Lan P., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P890, DOI 10.1109/ICME.2012.79
   Vernon P. E., 2006, GRADED WORD SPELLING
   Volpe RJ, 2006, SCHOOL PSYCHOL REV, V35, P47
   Wright N, 2015, J CHILD PSYCHOL PSYC, V56, P598, DOI 10.1111/jcpp.12398
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 40
TC 23
Z9 24
U1 11
U2 40
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 879
EP 894
DI 10.1007/s10055-020-00485-z
EA NOV 2020
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000592353800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Osti, F
   de Amicis, R
   Sanchez, CA
   Tilt, AB
   Prather, E
   Liverani, A
AF Osti, Francesco
   de Amicis, Raffaele
   Sanchez, Christopher A.
   Tilt, Azara Betony
   Prather, Eric
   Liverani, Alfredo
TI A VR training system for learning and skills development for
   construction workers
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Human-computer interaction; Workforce development;
   Virtual training
ID VIRTUAL-REALITY; AUGMENTED REALITY
AB There is a looming shortage of well-trained professionals in the wood construction workforce. To challenge this shortage, we developed a simulated learning environment that leverages a novel Virtual Reality (VR) system to train novice workers in wooden wall construction. A comprehensive task analysis was first used to best identify training requirements. Then, a virtual building site was modeled and a 3D video tutorial was implemented using a VR Head-Mounted Display (HMD). To evaluate the effectiveness of this tool, participants who learned via the VR training tool were compared with participants who instead only had simple 2-D instructional video training. VR training resulted in better retention, task performance, learning speed, and engagement than the video training counterpart, maintaining system usability. This demonstrates that VR is a viable training tool for the construction sector and can produce benefits beyond those of traditional video training.
C1 [Osti, Francesco; Liverani, Alfredo] Univ Bologna, Sch Engn, Dept Ind Engn DIN, Bologna, Italy.
   [de Amicis, Raffaele; Prather, Eric] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
   [Sanchez, Christopher A.] Oregon State Univ, Sch Psychol Sci, Corvallis, OR 97331 USA.
   [Tilt, Azara Betony] Oregon State Univ, Sch Mech Engn, Corvallis, OR 97331 USA.
C3 University of Bologna; Oregon State University; Oregon State University;
   Oregon State University
RP de Amicis, R (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
EM raffaele.deamicis@oregonstate.edu
RI Sanchez, Christopher A/A-5267-2010; De+Amicis, Raffaele/AAD-4976-2021
OI De+Amicis, Raffaele/0000-0002-6435-4364
FU project "Development and Evaluation of an Advanced MR Solution for
   Manufacturing Training" - Oregon Manufacturing Innovation Center
   Research and Development; Undergraduate Research, Scholarship, and the
   Arts (URSA) program - Oregon State University; Research and Extension
   Experience for Undergraduates (REEU) via the United States Department of
   Agriculture (USDA)
FX The research presented in this paper was supported by the project
   "Development and Evaluation of an Advanced MR Solution for Manufacturing
   Training" funded by Oregon Manufacturing Innovation Center Research and
   Development. The author Tilt Azara Betony was supported by the
   Undergraduate Research, Scholarship, and the Arts (URSA) program
   sponsored by the Oregon State University. The author Eric Prather was
   supported by the Research and Extension Experience for Undergraduates
   (REEU) via the United States Department of Agriculture (USDA).
CR Anderson L., 2009, TAXONOMY LEARNING TE
   Armstrong P., 2010, BLOOMS TAXONOMY
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   Chalhoub J, 2018, AUTOMAT CONSTR, V86, P1, DOI 10.1016/j.autcon.2017.10.028
   Construction M-H, 2012, CONSTRUCTION IND WOR
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   De Amicis R, 2018, INT J INTERACT DES M, V12, P689, DOI 10.1007/s12008-017-0451-7
   Doil F., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P71, DOI 10.1145/769953.769962
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Friedrich W, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P3, DOI 10.1109/ISMAR.2002.1115059
   Grabowski A, 2015, VIRTUAL REALITY BASE
   Gune A, 2018, IEEE COMPUT GRAPH, V38, P18, DOI 10.1109/MCG.2018.042731655
   Harfield T., 2007, International Journal of Construction Education and Research, V3, P143, DOI [10.1080/15578770701715060, DOI 10.1080/15578770701715060]
   Harviainen JT, 2014, INFORM RES, V19
   HENDERSON S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI DOI 10.1109/TVCG.2010.245
   Hermawati S, 2015, APPL ERGON, V46, P144, DOI 10.1016/j.apergo.2014.07.014
   Ho N, 2018, MULTIMED TOOLS APPL, V77, P30651, DOI 10.1007/s11042-018-6216-x
   Hoedt S, 2017, INT J PROD RES, V55, P7496, DOI 10.1080/00207543.2017.1374572
   Horejsí P, 2015, PROCEDIA ENGINEER, V100, P699, DOI 10.1016/j.proeng.2015.01.422
   Roldán JJ, 2019, ROBOT CIM-INT MANUF, V59, P305, DOI 10.1016/j.rcim.2019.05.004
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kayhani N, 2018, UTILIZATION VIRTUAL
   Kim PW, 2017, BEHAV INFORM TECHNOL, V36, P699, DOI 10.1080/0144929X.2016.1275809
   Kirkpatrick DL, 2006, Perform Improv, V45, P5, DOI [10.1002/PFI.2006.4930450702, DOI 10.1002/PFI.2006.4930450702, 10.1002/pfi.2006.4930450702]
   Langley A, 2016, HUM FACTOR ERGON MAN, V26, P667, DOI 10.1002/hfm.20406
   Merhar L, 2018, DIGITIZATION MANUFAC
   Mualem R, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00100
   Neugebauer R, 2016, PROC CIRP, V57, P2, DOI 10.1016/j.procir.2016.11.002
   Optronique T.-C., 2003, STARMATE USING AUGME
   Paoletti I, 2017, ARCHIT DESIGN, P77
   Peniche A, 2012, COMBINING VIRTUAL AU, P292
   Posada J, 2015, IEEE COMPUT GRAPH, V35, P26, DOI 10.1109/MCG.2015.45
   Sääski J, 2008, INT FED INFO PROC, V260, P395
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Sagnier C, 2019, ADV INTELLIGENT SYST, P305
   Schwald B., 2003, AUGMENTED REALITY SY
   Simoes Bruno, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2040072
   Simoes B, 2016, EXPERIENCE DRIVEN FR, P537
   Tarallo A, 2018, INT J INTERACT DES M, V12, P1235, DOI 10.1007/s12008-018-0493-5
   Toro C, 2007, LECT NOTES COMPUT SC, V4692, P295
   U.S. Department of Labor Bureau of Labor Statistics, 2018, EMPL PROJ OCC OUTL H
   U.S Department of Labor Women's Bureau, 2017, EMPL EARN OCC
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
NR 44
TC 23
Z9 27
U1 5
U2 61
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 523
EP 538
DI 10.1007/s10055-020-00470-6
EA SEP 2020
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000572843600001
DA 2024-07-18
ER

PT J
AU Chirico, A
   Scurati, GW
   Maffi, C
   Huang, SY
   Graziosi, S
   Ferrise, F
   Gaggioli, A
AF Chirico, Alice
   Scurati, Giulia Wally
   Maffi, Chiara
   Huang, Siyuan
   Graziosi, Serena
   Ferrise, Francesco
   Gaggioli, Andrea
TI Designing virtual environments for attitudes and behavioral change in
   plastic consumption: a comparison between concrete and numerical
   information
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Plastic; Format; Statistical evidence; Numerical;
   Concrete
ID CLIMATE-CHANGE; REALITY; VIVIDNESS; SPILLOVER; INTENTION; BAGS; SELF
AB Starting from the pro-environmental potential of virtual reality (VR), the aim was to understand how different statistical information formats can enhance VR persuasive potential for plastic consumption, recycling and waste. Naturalistic, immersive virtual reality environments (VREs) were designed ad hoc to display three kinds of statistical evidence formats, featured as three different formats (i.e., numerical, concrete and mixed). Participants were exposed only to one of the three formats in VR, and their affect, emotions, sense of presence, general attitudes toward the environment, specific attitudes and behavioral intentions toward plastic, use, waste, recycle, as well as their social desirability proneness were measured. Numerical format was the least effective across all dimensions. Concrete and mixed formats were similar. Social desirability only partially affected participants' attitudes and behavioral intentions. Numerical format did not increase the persuasive efficacy of statistical evidence displayed in VR, with respect to visual alone. Implications and future directions for designing effective VRE promoting pro-environmental behaviors were discussed.
C1 [Chirico, Alice; Maffi, Chiara; Gaggioli, Andrea] Univ Cattolica Sacro Cuore, Dept Psychol, Milan, Italy.
   [Scurati, Giulia Wally; Huang, Siyuan; Graziosi, Serena; Ferrise, Francesco] Politecn Milan, Dept Mech Engn, Milan, Italy.
   [Huang, Siyuan] Politecn Milan, Dept Design, Milan, Italy.
   [Gaggioli, Andrea] IRCCS Ist Auxol Italiano, Appl Technol Neuropsychol Lab, Milan, Italy.
C3 Catholic University of the Sacred Heart; Polytechnic University of
   Milan; Polytechnic University of Milan; IRCCS Istituto Auxologico
   Italiano
RP Chirico, A (corresponding author), Univ Cattolica Sacro Cuore, Dept Psychol, Milan, Italy.
EM alice.chirico@unicatt.it
RI Huang, Siyuan/IAR-9556-2023; Gaggioli, Andrea/AAA-2678-2020; Huang,
   Siyuan/AAQ-6784-2020; Ferrise, Francesco/C-6502-2008
OI Huang, Siyuan/0000-0002-2280-9770; Gaggioli, Andrea/0000-0001-7818-7598;
   Huang, Siyuan/0000-0002-2280-9770; Ferrise,
   Francesco/0000-0001-8951-8807; CHIRICO, Alice/0000-0002-4587-0232
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Ahn SJ, 2015, HEALTH COMMUN, V30, P545, DOI 10.1080/10410236.2013.869650
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   [Anonymous], 1991, PRESS
   [Anonymous], 2015, Global Waste Management Outlook, DOI DOI 10.1177/0734242X15616055
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bailey JO, 2015, ENVIRON BEHAV, V47, P570, DOI 10.1177/0013916514551604
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Ballew MT, 2018, ECOPSYCHOLOGY, V10, P26, DOI 10.1089/eco.2017.0044
   Bartolotta JF, 2018, MAR POLLUT BULL, V127, P576, DOI 10.1016/j.marpolbul.2017.12.037
   Blonde J, 2018, BASIC APPL SOC PSYCH, V40, P36, DOI 10.1080/01973533.2017.1412969
   Blondé J, 2016, SOC INFLUENCE, V11, P111, DOI 10.1080/15534510.2016.1157096
   Bobbio A, 2011, TPM-TEST PSYCHOM MET, V18, P117, DOI 10.4473/TPM.18.2.4
   Browning H, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00791
   Cagri A, 2011, J ENVIRON EDUC, V1, P179
   Chao YL, 2011, ENVIRON BEHAV, V43, P53, DOI 10.1177/0013916509350849
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351
   Chirico A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01766
   Clayborn J, 2019, ECOLOGY, V4, P31
   Cózar A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121762
   Etale A, 2018, APPETITE, V121, P138, DOI 10.1016/j.appet.2017.11.090
   European Commission A, 2018, EUR STRAT PLAST CIRC
   Ferdous T, 2014, PROCD SOC BEHV, V116, P3754, DOI 10.1016/j.sbspro.2014.01.836
   Han B., 2012, ARGUMENT ADVOCACY, V49, P39, DOI [DOI 10.1080/00028533.2012.11821779, https://doi.org/10.1080/00028533.2012.11821779]
   Hornikx J, 2018, DISCOURSE PROCESS, V55, P324, DOI 10.1080/0163853X.2017.1312195
   Hsu WC, 2018, EDUC TECHNOL SOC, V21, P187
   Jensen JD, 2012, J COMMUN, V62, P851, DOI 10.1111/j.1460-2466.2012.01668.x
   Joye Y, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01577
   Khashe Saba., 2018, Persuasive effects of immersion in virtual environments for measuring Pro-Environmental behaviors, V35, P1, DOI [10.1007/s10639-017-9676-0, DOI 10.22260/ISARC2018/0167]
   Kim YJ, 2013, INT J HOSP MANAG, V34, P255, DOI 10.1016/j.ijhm.2013.04.004
   Lebreton L, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22939-w
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Nekmat E, 2019, COMMUN RES, V46, P62, DOI 10.1177/0093650215609676
   Nisbett RE, 1980, METHODS DEV SHORTCOM
   Poortinga W, 2013, J ENVIRON PSYCHOL, V36, P240, DOI 10.1016/j.jenvp.2013.09.001
   Queiroz ACM, 2018, IMMERSIVE VIRTUAL EN, P153
   Rad MS, 2018, P NATL ACAD SCI USA, V115, P11401, DOI 10.1073/pnas.1721165115
   Reynolds R.A., 2002, PERSUASION HDB, P427
   Rieke R D., 1984, Argumentation And Decision Making Process, V2
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Riva G, 2011, NEW IDEAS PSYCHOL, V29, P24, DOI 10.1016/j.newideapsych.2009.11.002
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Schutte NS, 2017, ECOPSYCHOLOGY, V9, P1, DOI 10.1089/eco.2016.0042
   Sheppard S.R., 2008, DIGITAL DESIGN LANDS, P29
   Sheppard SRJ, 2005, ENVIRON SCI POLICY, V8, P637, DOI 10.1016/j.envsci.2005.08.002
   Shome D., 2009, PSYCHOL CLIMATE CHAN
   Smith-Sebasto NJ., 1995, J ENVIRON EDUC, V27, P14, DOI DOI 10.1080/00958964.1995.9941967
   Song J, 2017, P HUM FACT ERG SOC A, V1, P1519
   Steg L, 2009, J ENVIRON PSYCHOL, V29, P309, DOI 10.1016/j.jenvp.2008.10.004
   Sun Y, 2017, NAT HAZARDS, V89, P1327, DOI 10.1007/s11069-017-3022-0
   Tam KY, 2006, MIS QUART, V30, P865
   Tatepe T, 2017, EGITIM KURAM VE UYGU, V3, P1
   Terracciano A, 2003, EUR J PSYCHOL ASSESS, V19, P131, DOI 10.1027//1015-5759.19.2.131
   Truelove HB, 2014, GLOBAL ENVIRON CHANG, V29, P127, DOI 10.1016/j.gloenvcha.2014.09.004
   Valmaggia LR, 2016, PSYCHIAT RES, V236, P189, DOI 10.1016/j.psychres.2016.01.015
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Waterworth J.A., 2015, Immersed in media: Telepresence theory, measurement and technology, P35, DOI 10.1007/978-3-319-10190-3_3
   Xanthos D, 2017, MAR POLLUT BULL, V118, P17, DOI 10.1016/j.marpolbul.2017.02.048
   Zaalberg R, 2010, LECT NOTES COMPUT SC, V6137, P205, DOI 10.1007/978-3-642-13226-1_21
NR 60
TC 19
Z9 19
U1 4
U2 48
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 107
EP 121
DI 10.1007/s10055-020-00442-w
EA MAY 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000533072100001
DA 2024-07-18
ER

PT J
AU Kwon, C
AF Kwon, Chongsan
TI A study on the verification of the effect of sensory extension through
   cutaneous sensation on experiential learning using VR
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Authentic virtual reality; Experiential learning;
   Presence; Cutaneous sensation
ID VIRTUAL-REALITY; ENVIRONMENTS
AB This study verifies the effects of learning experiences by measuring the degrees of awareness of direct experience felt by users detecting both temperature and wind occurring within a virtual space as real cutaneous sensations. Learning while using virtual reality (VR)-with a focus on audiovisual vividness, tactile interactivity, and locomotive interactivity-was thus compared to VR utilization learning with the aforementioned wind and temperature sensations. The results show a much higher level of vividness and presence for those that experienced VR learning with cutaneous sensations. This confirms that a user feels an experience more vividly, and therefore as being closer to real life, when his or her senses are engaged, particularly through the use of skin sensations. Furthermore, when asked to describe their experiences, most of the group studied (95.8%) selected the "Exploratory Stage" (allowing users to believe they can feel, touch, and manipulate objects) and the "Spectator Stage" (looking at an object as if it were there). The results demonstrate a difference from previous VR learning that provides no cutaneous sensations and concludes that experiential learning can therefore be enhanced.
C1 [Kwon, Chongsan] Dongseo Univ, Div Comp Engn, Busan, South Korea.
C3 Dongseo University
RP Kwon, C (corresponding author), Dongseo Univ, Div Comp Engn, Busan, South Korea.
EM jazzhana@gmail.com
RI Kwon, Chongsan/ABA-1931-2020
OI Kwon, Chongsan/0000-0002-0736-8786
FU Dongseo University, "Dongseo Cluster Project" Research Fund of 2019
   [DSU-20190012]
FX This work was supported by Dongseo University, "Dongseo Cluster Project"
   Research Fund of 2019 (DSU-20190012).
CR [Anonymous], THIS VIRTUAL LAB WIL
   [Anonymous], 2004, DEMOCRACY ED
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Barfield W., 1995, J VIRTUAL REALITY SO, V1, P3, DOI DOI 10.1007/BF02009709
   Bruno F, 2018, VIRTUAL REAL-LONDON, V22, P91, DOI 10.1007/s10055-017-0318-z
   Cardenas S, 2007, PA STUD HUM RIGHTS, P101
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Debarba HG, 2009, S VIRT AUGM REAL, P133
   Deligiannidis L, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P143, DOI 10.1109/TRIDUI.2006.1618284
   Dewey J., 1959, The child and the curriculum
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Dionisio J, 1997, IEEE COMPUT GRAPH, V17, P11, DOI 10.1109/38.586012
   Gibbons M., 1980, J EXPERIENT EDUC, V3, P32, DOI [10.1177/105382598000300107, DOI 10.1177/105382598000300107]
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heilig M, 1962, Patent No. [3,050,870, 3050870]
   Hoffman DL, 1996, J MARKETING, V60, P50, DOI 10.2307/1251841
   Hulsmann F., 2013, P WORKSH VIRT ERW RE
   Kulkarni SD, 2012, IEEE-ASME T MECH, V17, P635, DOI 10.1109/TMECH.2011.2113353
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Lave J., 1991, SITUATED LEARNING LE, DOI DOI 10.1017/CBO9780511815355
   Moon T., 2004, 11 ACM S VIRTUAL REA, P122, DOI [10.1145/1077534.1077558, DOI 10.1145/1077534.1077558]
   Novak TP, 2000, MARKET SCI, V19, P22, DOI 10.1287/mksc.19.1.22.15184
   Oiwa K, 2009, SINGLE MOLECULE BIOLOGY, P61, DOI 10.1016/B978-0-12-374227-8.00003-1
   Prensky M., 1998, TWITCH SPEED KEEPING
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Slater M., 1993, Presence, V2, P221, DOI [DOI 10.1162/PRES.1993.2.3.221, 10.1162/pres.1993.2.3.221]
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Verlinden JC, 2013, PROCEDIA ENGINEER, V60, P435, DOI 10.1016/j.proeng.2013.07.050
   Zaman M, 2010, COMPUT HUM BEHAV, V26, P1009, DOI 10.1016/j.chb.2010.03.001
NR 29
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 19
EP 30
DI 10.1007/s10055-020-00435-9
EA MAR 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000521863500001
DA 2024-07-18
ER

PT J
AU Sakowitz, SM
   Inglehart, MR
   Ramaswamy, V
   Edwards, S
   Shoukri, B
   Sachs, S
   Kim-Berman, H
AF Sakowitz, Scott M.
   Inglehart, Marita R.
   Ramaswamy, Vidya
   Edwards, Sean
   Shoukri, Brandon
   Sachs, Stephen
   Kim-Berman, Hera
TI A comparison of two-dimensional prediction tracing and a virtual reality
   patient methods for diagnosis and treatment planning of orthognathic
   cases in dental students: a randomized preliminary study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Dental education; Orthognathic surgical prediction;
   Simulated patient; Orthodontics; Oral surgery
ID EDUCATION
AB Virtual reality patient (VR patient), a simulated patient module in a virtual reality environment allowing manipulation of the upper and lower jaws and chin in three planes of space, was developed to help students understand diagnosis and treatment planning of orthognathic surgical procedures. The objective was to compare student understanding in diagnosing and treatment planning complex orthognathic cases using the VR patient versus a conventional 2D prediction tracing method and to determine feasibility of utilizing VR methods. Thirty third year dental students were assigned randomly to an experimental (VR patient) or control (2D tracing) group. The dependent variables were a multiple choice question (MCQ) examination, baseline and exit surveys, and written case analysis of two cases. Student-teacher interactions were recorded for both length and type of interaction. Data were evaluated using descriptive and inferential statistics. The students' performance on the MCQ examinations improved immediately following the educational intervention (p < .05). However, no significant difference was found between the 2 groups on the written case analysis and pre-test, post-test, and follow-up MCQ examinations. The effect size of the intervention ranged from .14 to .90 and differed greatly between the written responses to the two cases. Intra- and inter-rater reliability of the written response scoring was found to be reliable and reproducible (> .928). Dental students were able to improve their understanding of diagnosis and treatment planning of orthognathic cases using both 2D prediction tracing and the VR patient methods. The method of scoring the written responses was reliable and reproducible and should be used for future full-scale studies.
C1 [Sakowitz, Scott M.; Shoukri, Brandon; Kim-Berman, Hera] Univ Michigan, Sch Dent, Dept Orthodont & Pediat Dent, 1011 N Univ Ave, Ann Arbor, MI 48109 USA.
   [Inglehart, Marita R.] Univ Michigan, Sch Dent, Dept Periodont & Oral Med, Ann Arbor, MI 48109 USA.
   [Ramaswamy, Vidya] Univ Michigan, Sch Dent, Ann Arbor, MI 48109 USA.
   [Edwards, Sean] Univ Michigan, Sch Dent, Dept Oral & Maxillofacial Surg, Ann Arbor, MI 48109 USA.
   [Sachs, Stephen] New York Ctr Orthognath & Maxillofacial Surg, Lake Success, NY USA.
C3 University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan
RP Kim-Berman, H (corresponding author), Univ Michigan, Sch Dent, Dept Orthodont & Pediat Dent, 1011 N Univ Ave, Ann Arbor, MI 48109 USA.
EM ssakow@umich.edu; mri@umich.edu; ramaswav@umich.edu; seanedwa@umich.edu;
   bshoukri@umich.edu; drsachs@nycoms.com; bermanh@umich.edu
RI Inglehart, Marita/KMY-7873-2024; Bjelovucic, Ruza/JAN-4995-2023
OI Bjelovucic, Ruza/0009-0003-6265-1984; Kim-Berman,
   Hera/0000-0003-4465-3700; Inglehart, Marita Rohr/0000-0001-6279-9581
FU University of Michigan Le Gro Fund; University of Michigan Center for
   Research on Learning and Teaching, Faculty Development
FX This study was funded in part by The University of Michigan Le Gro Fund
   and University of Michigan Center for Research on Learning and Teaching,
   Faculty Development.
CR Aaker Grant D, 2011, Ophthalmic Surg Lasers Imaging, V42 Suppl, pS116, DOI 10.3928/15428877-20110627-11
   Abdelwahab MG, 2010, MINERVA CHIR, V65, P409
   Abhari K, 2015, IEEE T BIO-MED ENG, V62, P1466, DOI 10.1109/TBME.2014.2385874
   Aebersold M, 2018, CLIN SIMUL NURS, V15, P34, DOI 10.1016/j.ecns.2017.09.008
   Aebersold M, 2012, NURS RES PRACT, V2012, DOI 10.1155/2012/765212
   Akay M, 2001, INFORM TECHNOLOGIES
   Alsofy SZ, 2019, WORLD NEUROSURG, V129, pE857, DOI 10.1016/j.wneu.2019.06.057
   [Anonymous], 2015, OCULUS RIFT HIST HOW
   [Anonymous], 2014, Oculus Rift Development Kit 2
   [Anonymous], 2013, OCULUS RIFT DK1 TEAR
   [Anonymous], VIRTUAL ENV
   [Anonymous], 2016, OCULUS RIFT CV1 TEAR
   Arikatla VS, 2018, P SPIE INT SOC OPT E, P10576
   Badler NI, 2002, COMMUN ACM, V45, P56, DOI 10.1145/514236.514264
   BAROSI G, 2012, BLOOD, V120
   Becker O, 2013, COMPUT SCI SYST BIOL, V6, P6
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cao C, 2019, THORAC SURG CLIN, V29, P329, DOI 10.1016/j.thorsurg.2019.03.010
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chiarovano E, 2015, FRONT NEUROL, V6, DOI 10.3389/fneur.2015.00164
   Dias D. R. C., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P429, DOI 10.1109/VSMM.2012.6365955
   Dyer E, 2018, J MED LIBR ASSOC, V106, P498, DOI 10.5195/jmla.2018.518
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Gateno J, 2003, J ORAL MAXIL SURG, V61, P814, DOI 10.1016/S0278-2391(03)00240-4
   Germans DA, 2008, IEEE T INSTRUM MEAS, V57, P1177, DOI 10.1109/TIM.2008.915952
   Izard SG, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0900-2
   Izard SG, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0723-6
   Grabowski HA., 1999, VIRTUAL REAL-LONDON, V4, P235
   Gutiérrez F, 2007, STUD HEALTH TECHNOL, V125, P155
   Jasinevicius T Roma, 2004, J Dent Educ, V68, P1151
   Julious SA, 2005, PHARM STAT, V4, P287, DOI 10.1002/pst.185
   Khan R, 2019, ENDOSCOPY, V51, P653, DOI 10.1055/a-0894-4400
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Mallari B, 2019, J PAIN RES, V12, P2053, DOI 10.2147/JPR.S200498
   McMillan JH, 2010, RES ED EVIDENCE BASE, P511
   MILLER GE, 1990, ACAD MED, V65, pS63, DOI 10.1097/00001888-199009000-00045
   Minns S, 2018, J ANXIETY DISORD, V58, P1, DOI 10.1016/j.janxdis.2018.05.006
   Mohammed MAA, 2018, J VASC INTERV RADIOL, V29, P971, DOI 10.1016/j.jvir.2018.02.018
   Neumann P., 1999, Virtual Reality, V4, P213, DOI 10.1007/BF01418157
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Proffit WR, 1991, SURG ORTHODONTIC TRE, P722
   Robb Richard, 2008, Virtual Reality, V12, P235, DOI 10.1007/s10055-008-0104-z
   Rothbaum BO, 2000, J CONSULT CLIN PSYCH, V68, P1020, DOI 10.1037/0022-006X.68.6.1020
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Sikka N, 2019, TELEMED E-HEALTH, V25, P1207, DOI 10.1089/tmj.2018.0273
   Smith ML, 2016, OBSTET GYNECOL, V127, P763, DOI 10.1097/AOG.0000000000001356
   Sweta V R, 2019, Ann Maxillofac Surg, V9, P110, DOI 10.4103/ams.ams_263_18
   Triepels CPR, 2020, CLIN ANAT, V33, P25, DOI 10.1002/ca.23405
   UMichDent, 2019, DENT VR JAW SURG SIM
   Uppot RN, 2019, RADIOLOGY, V291, P570, DOI 10.1148/radiol.2019182210
   Vertemati M, 2019, SURG INNOV, V26, P359, DOI 10.1177/1553350618822860
   Walther-Larsen Soren, 2019, Hosp Pediatr, V9, P501, DOI 10.1542/hpeds.2018-0249
   Won AS, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4070052
   Wong DT, 2019, EUR J ANAESTH, V36, P227, DOI 10.1097/EJA.0000000000000890
   Xia J, 2000, Int J Adult Orthodon Orthognath Surg, V15, P265
   Xin BQ, 2019, WORLD NEUROSURG, V124, pE324, DOI 10.1016/j.wneu.2018.12.090
   Zaragoza-Siqueiros J, 2019, COMPUT METHOD BIOMEC, V22, P499, DOI 10.1080/10255842.2019.1566817
   Zheng CS, 2019, WORLD NEUROSURG, V123, pE1, DOI 10.1016/j.wneu.2018.08.082
NR 59
TC 16
Z9 18
U1 0
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 399
EP 409
DI 10.1007/s10055-019-00413-w
EA DEC 2019
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000501159000001
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Jiang, S
   Yang, ZY
   Zhou, L
AF Zhou, Zeyang
   Jiang, Shan
   Yang, Zhiyong
   Zhou, Lin
TI Personalized planning and training system for brachytherapy based on
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality training system; Tumour brachytherapy; Accuracy
   improvement; Simulated surgery
ID INTERSTITIAL BRACHYTHERAPY; CANCER; SEED; RADIOTHERAPY; VALIDATION;
   DESIGN
AB This paper presents a virtual planning and training system for brachytherapy based on virtual reality (VR). The purpose of this system is to facilitate preplanning and help doctors to more quickly and easily improve their skills in brachytherapy surgery. For unskilled doctors, this system can increase confidence and support the successful completion of surgery. The system is based on a VR system that can deliver a fully immersive training environment and involves three functions: simulation of the relocation template, arrangement of the puncture needles and the implantation of the seeds. We used Student's t test to verify the efficiency of the system. Participants were required to complete both the training and a questionnaire to supply feedback. The participants subsequently performed simulation surgery on a dummy and reviewed their cumulative errors compared with the ideal condition. The results demonstrate that this VR system is able to effectively train unskilled doctors, especially young doctors. This system is appreciated by a variety of people, especially inexperienced and younger users, as it is easy to use and provides an enjoyable learning experience.
C1 [Zhou, Zeyang; Jiang, Shan; Yang, Zhiyong; Zhou, Lin] Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.
   [Jiang, Shan] Tianjin Univ, Ctr Adv Mech & Robot, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin University
RP Jiang, S (corresponding author), Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.; Jiang, S (corresponding author), Tianjin Univ, Ctr Adv Mech & Robot, Tianjin 300350, Peoples R China.
EM shanjmri@tju.edu.cn
RI Zhou, Zeyang/AAX-9853-2020
FU National Natural Science Foundation of China [5171101938, 51775368];
   Technology Planning Project of Guangdong Province, China
   [2017B020210004]
FX The authors gratefully acknowledge the research team at the School of
   Mechanical Engineering,Tianjin University, for providing technical
   assistance. Additionally, the Department of Oncology at The Second
   Hospital of Tianjin Medical University provided considerable support
   with the clinical experimental environment and equipment. This research
   was partially supported by the National Natural Science Foundation of
   China (Grant No. 51775368), National Natural Science Foundation of China
   (Grant No. 5171101938) and the Technology Planning Project of Guangdong
   Province, China (Grant No. 2017B020210004).
CR Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Bouhelal AA, 2012, BRIT J SURG, V99, P62
   Bruno F, 2018, VIRTUAL REAL-LONDON, V22, P91, DOI 10.1007/s10055-017-0318-z
   Buckley H, 2017, INT J RADIAT ONCOL, V99, P111, DOI 10.1016/j.ijrobp.2017.05.023
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Cubo N, 2017, BIOFABRICATION, V9, DOI 10.1088/1758-5090/9/1/015006
   DiRaddo R, 2009, NEURO-ONCOLOGY, V11, P698
   Dou HS, 2017, MED PHYS, V44, P4828, DOI 10.1002/mp.12435
   Eschwege F, 1998, ANN ONCOL, V9, P31
   FLEISCHMAN EH, 1992, J SURG ONCOL, V49, P25, DOI 10.1002/jso.2930490107
   Gherman B, 2016, MECH MACH SCI, V38, P109, DOI 10.1007/978-3-319-23832-6_9
   Goksel O, 2011, IEEE T HAPTICS, V4, P188, DOI [10.1109/ToH.2011.34, 10.1109/TOH.2011.34]
   Gu Q, 2015, SCI CHINA LIFE SCI, V58, P411, DOI 10.1007/s11427-015-4850-3
   Halabi T, 2006, MED PHYS, V33, P2089, DOI 10.1118/1.2241101
   Hocking GC, 2000, J ENG MATH, V38, P91, DOI 10.1023/A:1004612117673
   Huo XD, 2016, BRACHYTHERAPY, V15, P370, DOI 10.1016/j.brachy.2016.02.001
   Kanzaki H, 2015, JPN J CLIN ONCOL, V45, P688, DOI 10.1093/jjco/hyv050
   Lawson G, 2016, APPL ERGON, V53, P323, DOI 10.1016/j.apergo.2015.06.024
   Li Z, 2014, MED PHYS, V41, P288, DOI 10.1118/1.4888610
   Luha J, 2003, EKON CAS, V51, P778
   Lv ZH, 2017, NEUROCOMPUTING, V254, P71, DOI 10.1016/j.neucom.2016.07.078
   Miller S., 1999, Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411), P349, DOI 10.1109/CCECE.1999.807223
   Miller S, 1998, UNIVERSITY AND INDUSTRY - PARTNERS IN SUCCESS, CONFERENCE PROCEEDINGS VOLS 1-2, P870, DOI 10.1109/CCECE.1998.685636
   Mohan R, 2011, AM FAM PHYSICIAN, V84, P413
   Nakayama Y, 2009, J THORAC ONCOL, V4, pS174
   Regis J, 2010, NEUROSURGERY, V67, DOI 10.1227/01.NEU.0000384045.64917.0D
   Roy E, 2017, SAUDI DENT J, V29, P41, DOI 10.1016/j.sdentj.2017.02.001
   Saxena SK, 2009, APPL RADIAT ISOTOPES, V67, P1421, DOI 10.1016/j.apradiso.2009.02.040
   Stout R, 2000, RADIOTHER ONCOL, V56, P323, DOI 10.1016/S0167-8140(00)00252-8
   Sutherland JGH, 2013, PHYS MED BIOL, V58, P4763, DOI 10.1088/0031-9155/58/14/4763
   Tanderup K, 2017, ADV DRUG DELIVER REV, V109, P15, DOI 10.1016/j.addr.2016.09.002
   Wang ZM, 2011, LUNG CANCER, V74, P253, DOI 10.1016/j.lungcan.2011.03.006
   Wu CM, 2017, VIRTUAL REAL-LONDON, V21, P19, DOI 10.1007/s10055-016-0296-6
   Zhang GB, 2017, INT J COMPUT ASS RAD, V12, P1985, DOI 10.1007/s11548-017-1632-3
   Zhang SH, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001643
   Zheng MT, 2016, VIRTUAL REAL-LONDON, V20, P221, DOI 10.1007/s10055-016-0297-5
NR 36
TC 13
Z9 13
U1 7
U2 51
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 347
EP 361
DI 10.1007/s10055-018-0350-7
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300003
DA 2024-07-18
ER

PT J
AU Wei, L
   Zhou, HL
   Nahavandi, S
AF Wei, Lei
   Zhou, Hailing
   Nahavandi, Saeid
TI Haptically enabled simulation system for firearm shooting training
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual training simulation; Haptics; Physics engine; Motion capture
ID VIRTUAL-REALITY; KINECT
AB Firearm shooting training is of importance in military and law enforcement training tasks. Traditional training usually uses actual firearms or modified bullets that are dangerous and expensive and difficult to evaluate the performance. Firearm training simulation systems provide risk-free alternatives. However, most existing simulation is visual-only, which lacks the immersion on the force feedback. In this paper, we proposed a new firearm training simulation system, which can provide more realistic training by incorporating physic effects on recoil and trigger pull weight. Dynamic, immersive, and repeatable training experiences while imposes no danger to trainees are provided in our system. The system consists of haptics, physics engine, and motion capture. These three components are carefully combined by developing the corresponding techniques of haptic force rendering, visuo-haptic integration, and synchronisation, physics-based dynamic simulation and motion analysis. Compared with existing systems, our training system has more complete functionalities that include visual firearm shooting, force generation, shooting reactions, result analysis and evaluation. Moreover, it is adaptable to off-the-shelf hardware and software packages and thus it can provide flexibility to system scalability and budget. To evaluate the proposed system, two demonstrations are conducted for users where the systems accuracy, immersion and usability are analysed. The results show the effectiveness of our physics-based shooting model and the proposed system on simulating different shooting scenarios.
C1 [Wei, Lei; Zhou, Hailing; Nahavandi, Saeid] Deakin Univ, IISRI, Waurn Ponds, Vic, Australia.
C3 Deakin University
RP Zhou, HL (corresponding author), Deakin Univ, IISRI, Waurn Ponds, Vic, Australia.
EM lei.wei@deakin.edu.au; hailing.zhou@deakin.edu.au;
   saeid.nahavandi@deakin.edu.au
RI Nahavandi, Saeid/AAE-5536-2022; Zhou, Hailing/JVZ-8405-2024
OI Zhou, Hailing/0000-0001-5009-4330; Wei, Lei/0000-0001-8267-0283
FU Defence Science Institute [50000]
FX Funding was provided by Defence Science Institute (Grant No. 50000).
CR Arioui H, 2010, IEEE-ASME T MECH, V15, P805, DOI 10.1109/TMECH.2009.2035499
   Broeren J, 2004, ARCH PHYS MED REHAB, V85, P1247, DOI 10.1016/j.apmr.2003.09.020
   Buttolo P., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P217, DOI 10.1109/VRAIS.1995.512499
   Conti F.B. Francois., 2005, CHAI 3D OPEN SOURCE
   Dimension F, 2004, FORCE DIMENS LAUSANN, V33, P2006
   Faroque S, 2016, INTELL AUTOM SOFT CO, V22, P509, DOI 10.1080/10798587.2015.1109200
   Guanyang Liu, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P2220, DOI 10.1109/BMEI.2011.6098650
   Kadlecek P, 2011, P CESCG
   Krompiec Przemyslaw Kazimierz, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P19, DOI 10.1109/ICCE.2017.7889214
   Li SL, 2009, 2009 INTERNATIONAL CONFERENCE ON SCALABLE COMPUTING AND COMMUNICATIONS & EIGHTH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING, P566, DOI 10.1109/EmbeddedCom-ScalCom.2009.126
   Luciano C, 2009, VIRTUAL REAL-LONDON, V13, P69, DOI 10.1007/s10055-009-0112-7
   Marin F, 2014, 2014 IEEE INT C IM P
   Martin S, 2009, AUSTR C ROB AUT ACRA
   Melo Leite Junior Antonio Jose, 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P254, DOI 10.1109/SVR.2012.12
   Raisamo J, 2006, BCS CONF SERIES, P337, DOI 10.1007/1-84628-249-7_21
   Rodrigues T, 2017, J FASH MARK MANAG, V21, P88, DOI 10.1108/JFMM-02-2016-0018
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   Salisbury JK, 1997, IEEE COMPUT GRAPH, V17, P6, DOI 10.1109/MCG.1997.1626171
   Sewell C, 2007, 2 JOINT EUROHAPTICS, P22
   Soetedjo A, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON TECHNOLOGY, INFORMATICS, MANAGEMENT, ENGINEERING, AND ENVIRONMENT (TIME-E 2014), P69, DOI 10.1109/TIME-E.2014.7011594
   Sourin A, 2009, VIRTUAL REAL-LONDON, V13, P221, DOI 10.1007/s10055-009-0133-2
   Tong Huan, 2010, 2010 International Conference on Information, Networking and Automation (ICINA 2010), P342, DOI 10.1109/ICINA.2010.5636495
   Wei L, 2008, VISUAL COMPUT, V24, P871, DOI 10.1007/s00371-008-0285-1
   Wei L, 2015, IEEE SYS MAN CYBERN, P436, DOI 10.1109/SMC.2015.87
   Wei L, 2013, IEEE ASME INT C ADV, P1058, DOI 10.1109/AIM.2013.6584234
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xia PJ, 2012, INT J ADV MANUF TECH, V58, P379, DOI 10.1007/s00170-011-3381-8
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 29
TC 10
Z9 10
U1 2
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 217
EP 228
DI 10.1007/s10055-018-0349-0
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500002
DA 2024-07-18
ER

PT J
AU Li, ZC
   Giannini, F
   Pernot, JP
   Véron, P
   Falcidieno, B
AF Li, Zongcheng
   Giannini, Franca
   Pernot, Jean-Philippe
   Veron, Philippe
   Falcidieno, Bianca
TI Reusing heterogeneous data for the conceptual design of shapes in
   virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Conceptual design; Shape and object description;
   Heterogeneous data; Constraint satisfaction problem
ID IMAGE; SURFACES; MESHES; SYSTEM
AB Today, digital data such as 2D images, 3D meshes and 3D point clouds are widely used to design virtual environments (VE). Most of the time, only one type of those multimodal data is used to describe and specify the shapes of the objects. However, a single object can be seen as a combination of components linked with constraints specifying the relationships and the rigid transformations defining their arrangement. Thus, the definition of new methods able to combine any kind of multimodal data in an easy way would allow non-experts of VE to rapidly mock up objects and scenes. In this paper, we propose a new shape description model together with its associated constraints toolbox enabling the description of complex shapes from multimodal data. Not only rigid transformations are considered but also scale modifications according to the specified context of the constraint setting. The heterogeneous virtual objects (i.e., composed by scalable multimodal components) then result from the resolution of a constraint satisfaction problem through an optimization approach. The proposed approach is illustrated and validated with examples obtained using our prototype software.
C1 [Li, Zongcheng; Pernot, Jean-Philippe; Veron, Philippe] Arts & Metiers ParisTech, LSIS UMR CNRS 7296, Aix En Provence, France.
   [Li, Zongcheng; Giannini, Franca; Falcidieno, Bianca] CNR, IMATI, Genoa, Italy.
C3 Arts et Metiers Institute of Technology; Consiglio Nazionale delle
   Ricerche (CNR); Istituto di Matematica Applicata e Tecnologie
   Informatiche "Enrico Magenes" (IMATI-CNR)
RP Pernot, JP (corresponding author), Arts & Metiers ParisTech, LSIS UMR CNRS 7296, Aix En Provence, France.
EM Zongcheng.Li@ensam.eu; Franca.Giannini@ge.imati.cnr.it;
   Jean-Philippe.Pernot@ensam.eu; Philippe.Veron@ensam.eu;
   Bianca.Falcidieno@ge.imati.cnr.it
RI VERON, Philippe/I-3173-2012; LI, Zongcheng/KEI-0514-2024; Giannini,
   Franca/ABA-1893-2020
OI Giannini, Franca/0000-0002-3608-6737; Veron,
   Philippe/0000-0002-4062-2432
FU VISIONAIR project - European Commission [262044]; French National
   project Co-DIVE; Italian National Project "Tecnologie e sistemi
   innovativi per la fabbrica del futuro e Made in Italy"
FX The work has been partially supported by the VISIONAIR project funded by
   the European Commission under Grant Agreement 262044, the French
   National project Co-DIVE and by the Italian National Project "Tecnologie
   e sistemi innovativi per la fabbrica del futuro e Made in Italy.''
CR Allègre R, 2006, GRAPH MODELS, V68, P42, DOI 10.1016/j.gmod.2005.09.001
   [Anonymous], 2011, The Shape Repository
   [Anonymous], 2016, MATHEMATICA9
   [Anonymous], 2001, Linear Programming: Foundations and extensions, Department of Operations Research and Financial Engineering
   Antonelli M, 2013, COMPUT AIDED DESIGN, V45, P1294, DOI 10.1016/j.cad.2013.06.007
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bloch I, 1999, IEEE T PATTERN ANAL, V21, P657, DOI 10.1109/34.777378
   DAFONTOURA CL, 2000, SHAPE ANAL CLASSIFIC
   De Luca L, 2006, COMPUT GRAPH-UK, V30, P160, DOI 10.1016/j.cag.2006.01.020
   Decriteau D, 2016, COMPUT AIDED DESIGN, V13, P737
   ELHAKIM SF, 2002, INT ARCH PHOTOGRAMME, V34, P143
   Falcidieno B, 2004, SEMANTICS DIGITAL SH
   Hudelot C, 2008, FUZZY SET SYST, V159, P1929, DOI 10.1016/j.fss.2008.02.011
   INGBER L, 1993, MATH COMPUT MODEL, V18, P29, DOI 10.1016/0895-7177(93)90204-C
   Jain A, 2012, COMPUT GRAPH FORUM, V31, P631, DOI 10.1111/j.1467-8659.2012.03042.x
   Jiang NJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618459
   LEE J, 2008, EUROGRAPHICS WORKSH
   Mehrotra S, 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Panchetti M, 2010, COMPUT AIDED DESIGN, V42, P693, DOI 10.1016/j.cad.2010.01.004
   Pernot J-P, 2008, ASME 2008 INT DES EN
   Price K, 1997, DR DOBBS J, V22, P18
   Reeb G, 1946, CR HEBD ACAD SCI, P848
   Sawyer K., 2013, ZIG ZAG SURPRISING P
   Smith GF, 1998, J CREATIVE BEHAV, V32, P107, DOI 10.1002/j.2162-6057.1998.tb00810.x
   Takemura CM, 2008, DOUTORADO CIENCIAS C
   Tutenel Tim., 2008, Computers in Entertainment, V6, p57:1, DOI [DOI 10.1145/1461999.1462009, 10.1145/1461999. 1462009]
   Wendrich R, 2009, RAW SHAPING FINDING
   Xie XH, 2013, COMPUT GRAPH FORUM, V32, P233, DOI 10.1111/cgf.12200
NR 29
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2017
VL 21
IS 3
BP 127
EP 144
DI 10.1007/s10055-016-0302-z
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FB8YV
UT WOS:000406427400002
DA 2024-07-18
ER

PT J
AU Okura, F
   Kanbara, M
   Yokoya, N
AF Okura, Fumio
   Kanbara, Masayuki
   Yokoya, Naokazu
TI Aerial full spherical HDR imaging and display
SO VIRTUAL REALITY
LA English
DT Article
DE Omnidirectional camera; High dynamic range image; Immersive panorama;
   Image-based lighting; Tone-mapping
ID TELEPRESENCE; VIDEO
AB This paper describes a framework for aerial imaging of high dynamic range (HDR) scenes for use in virtual reality applications, such as immersive panorama applications and photorealistic superimposition of virtual objects using image-based lighting. We propose a complete and practical system to acquire full spherical HDR images from the sky, using two omnidirectional cameras mounted above and below an unmanned aircraft. The HDR images are generated by combining multiple omnidirectional images captured with different exposures controlled automatically. Our system consists of methods for image completion, alignment, and color correction, as well as a novel approach for automatic exposure control, which selects optimal exposure so as to avoid banding artifacts. Experimental results indicated that our system generated better spherical images compared to an ordinary spherical image completion system in terms of naturalness and accuracy. In addition to proposing an imaging method, we have carried out an experiment about display methods for aerial HDR immersive panoramas utilizing spherical images acquired by the proposed system. The experiment demonstrated HDR imaging is beneficial to immersive panorama using an HMD, in addition to ordinary uses of HDR images.
C1 [Okura, Fumio; Kanbara, Masayuki; Yokoya, Naokazu] Nara Inst Sci & Technol NAIST, Grad Sch Informat Sci, Nara 89165, Japan.
C3 Nara Institute of Science & Technology
RP Okura, F (corresponding author), Nara Inst Sci & Technol NAIST, Grad Sch Informat Sci, Takayama Cho, Nara 89165, Japan.
EM fumio-o@is.naist.jp; kanbara@is.naist.jp; yokoya@is.naist.jp
RI Okura, Fumio/AFT-2018-2022; Kanbara, Masayuki/ABD-7780-2021
OI Okura, Fumio/0000-0001-7595-1300
FU Japan Society for the Promotion of Science (JSPS) [23240024, 25-7448];
   "Ambient Intelligence'' project - Ministry of Education, Culture,
   Sports, Science and Technology (MEXT); Grants-in-Aid for Scientific
   Research [23240024, 13J07448] Funding Source: KAKEN
FX This research was supported by the Japan Society for the Promotion of
   Science (JSPS) Grant-in-Aid for Scientific Research (A), No. 23240024,
   Grant-in-Aid for JSPS Fellows No. 25-7448, and by the "Ambient
   Intelligence'' project funded by Ministry of Education, Culture, Sports,
   Science and Technology (MEXT).
CR Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   [Anonymous], 2004, P 3 INT C COMPUTER G
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   Debevec P., 1996, P SIGGRAPH 96, P11, DOI DOI 10.1145/237170.237191
   Debevec P., 1998, SIGGRAPH98, P189, DOI DOI 10.1145/280814.280864
   GOODNIGHT N, 2003, P 14 EUR WORKSH REND, P26
   Goodrich MA, 2008, J FIELD ROBOT, V25, P89, DOI 10.1002/rob.20226
   Grossberg M.D., 2003, P IEEE C COMP VIS PA, P1
   Hasinoff SW, 2010, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2010.5540167
   Heidrich Wolfgang, ERIK REINHARD
   Herwitz SR, 2004, COMPUT ELECTRON AGR, V44, P49, DOI 10.1016/j.compag.2004.02.006
   Igawa N, 2004, SOL ENERGY, V77, P137, DOI 10.1016/j.solener.2004.04.016
   Ikeda S, 2003, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P155, DOI 10.1109/MFI-2003.2003.1232649
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Kawai Norihiko, 2010, IPSJ Transactions on Computer Vision and Applications, V2, P200, DOI 10.2197/ipsjtcva.2.200
   Kawai N, 2009, LECT NOTES COMPUT SC, V5414, P271, DOI 10.1007/978-3-540-92957-4_24
   Kitaura M, 2012, PROC SPIE, V8292, DOI 10.1117/12.908265
   Kopf J, 2010, CM T GRAPH P ACM SIG, V29
   Moezzi S, 1997, IEEE MULTIMEDIA, V4, P17, DOI 10.1109/MMUL.1997.580996
   Okura F., 2011, P ACM SIGGRAPH 11, P78
   Onoe Y, 1998, COMPUT VIS IMAGE UND, V71, P154, DOI 10.1006/cviu.1998.0705
   Reinhard E., 2002, Journal of Graphics Tools, V7, P45, DOI 10.1080/10867651.2002.10487554
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sato T, 2004, LECT NOTES COMPUT SC, V3022, P326
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shum HY, 2003, IEEE T CIRC SYST VID, V13, P1020, DOI 10.1109/TCSVT.2003.817360
   Ward G., 2003, Journal of Graphics Tools, V8, P17, DOI 10.1080/10867651.2003.10487583
   Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823
NR 30
TC 3
Z9 4
U1 0
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2014
VL 18
IS 4
BP 255
EP 269
DI 10.1007/s10055-014-0249-x
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AT0AZ
UT WOS:000344600500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Haydar, M
   Roussel, D
   Maïdi, M
   Otmane, S
   Mallem, M
AF Haydar, Mahmoud
   Roussel, David
   Maidi, Madjid
   Otmane, Samir
   Mallem, Malik
TI Virtual and augmented reality for cultural computing and heritage: a
   case study of virtual exploration of underwater archaeological sites
   (preprint)
SO VIRTUAL REALITY
LA English
DT Article
DE Underwater archaeology; Mixed reality; Virtual reality; Augmented
   reality; Cultural heritage; Cultural computing
AB The paper presents different issues dealing with both the preservation of cultural heritage using virtual reality (VR) and augmented reality (AR) technologies in a cultural context. While the VR/AR technologies are mentioned, the attention is paid to the 3D visualization, and 3D interaction modalities illustrated through three different demonstrators: the VR demonstrators (immersive and semi-immersive) and the AR demonstrator including tangible user interfaces. To show the benefits of the VR and AR technologies for studying and preserving cultural heritage, we investigated the visualisation and interaction with reconstructed underwater archaeological sites. The base idea behind using VR and AR techniques is to offer archaeologists and general public new insights on the reconstructed archaeological sites allowing archaeologists to study directly from within the virtual site and allowing the general public to immersively explore a realistic reconstruction of the sites. Both activities are based on the same VR engine, but drastically differ in the way they present information and exploit interaction modalities. The visualisation and interaction techniques developed through these demonstrators are the results of the ongoing dialogue between the archaeological requirements and the technological solutions developed.
C1 [Haydar, Mahmoud; Roussel, David; Maidi, Madjid; Otmane, Samir; Mallem, Malik] Univ Evry, Lab IBISC, F-91020 Evry, France.
C3 Universite Paris Saclay
RP Haydar, M (corresponding author), Univ Evry, Lab IBISC, 40 Rue Pelvoux, F-91020 Evry, France.
EM mahmoud.haydar@ibisc.fr; david.roussel@ibisc.fr; madjid.maidi@ibisc.fr;
   samir.otmane@ibisc.fr; malik.mallem@ibisc.fr
RI Maidi, Madjid/GRY-6482-2022; MALLEM, Malik/P-6389-2017
OI Maidi, Madjid/0000-0001-7070-006X; MALLEM, Malik/0000-0002-2471-7028;
   Otmane, Samir/0000-0003-2221-4264
FU European Community [IST-034924]
FX VENUS is partially supported by the European Community under project
   VENUS (Contract IST-034924) of the "Information Society Technologies
   (IST) programme of the 6th FP for RTD". The authors are solely
   responsible for the content of this paper. It does not represent the
   opinion of the European Community, and the European Community is not
   responsible for any use that might be made of data appearing therein.
CR Acevedo D, 2001, IEEE VISUAL, P493, DOI 10.1109/VISUAL.2001.964560
   AlsH, 2009, J NEONATAL PERINATAL, V2
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   BARCELO JA, 2000, BAR INT SERIES, V843, P9
   Bell B., 2002, P 15 ANN ACM S USER, P213
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Billinghurst M, 1998, P IEEE VIRT REAL ANN, P20, DOI 10.1109/VRAIS.1998.658418
   BILLINGHURST M, 2001, HCI 2001
   Bowman A.D., 2005, 3D user interfaces: Theory and practice
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2134
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Burns Don, 2004, VIRTUAL REALITY C, P265
   COSMAS J, 2001, P 2001 C VIRT REAL A, P297, DOI DOI 10.1145/584993.585048
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Domingues C, 2008, EUROGR TECH REP SER, P164
   Drap P, 2000, ISPRS J PHOTOGRAMM, V55, P48, DOI 10.1016/S0924-2716(99)00038-6
   Drap P., 2001, P 2001 C VIRT REAL A, P17
   DRAP P, 2006, JOINT EV C 37 CIPA I
   DUNSER A, 2008, INT C COMP GRAPH INT
   Gaitatzes A., 2001, Proceedings of the 2001 conference on virtual reality, archaeology, and cultural heritage, P103, DOI [10.1145/584993.585011, DOI 10.1145/584993.585011]
   Germs R, 1999, COMPUT GRAPH-UK, V23, P497, DOI 10.1016/S0097-8493(99)00069-2
   Gorbet M.G., 1998, CHI'98: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P49
   Grasset R, 2006, INT SYM MIX AUGMENT, P60
   Hall RA, 1997, INT J NAUT ARCHAEOL, V26, P247
   Haydar M, 2009, AIP CONF PROC, V1107, P190, DOI 10.1063/1.3106472
   Hinckley K., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P1, DOI 10.1145/263407.263408
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   KATO H, 1999, ARTOOLKIT TECHNICAL
   Looser J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P203
   MARK RM, 1997, SIGGRAPH 97, V31, P19
   MCMAHAN RP, 2007, IEEE S 3 US INT
   OTMANE S, 2000, P 33 ANN SIM S SS 20
   POUPYREV I, 2001, INTEACT 01, P334
   Prada R, 2009, VIRTUAL REAL-LONDON, V13, P117, DOI 10.1007/s10055-009-0115-4
   REICHLEN BA, 1993, 1993 IEEE VIRT REAL, P300
   Rheingold H., 1991, VIRTUAL REAL-LONDON
   ROSENBERG LB, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P76, DOI 10.1109/VRAIS.1993.380795
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   TAYLOR II, 2001, VRST 01, P55
   TOSA N, 2009, LECT NOTES COMPUT SC, V3711, P13
   van Dam A, 2002, COMPUT GRAPH-UK, V26, P535, DOI 10.1016/S0097-8493(02)00113-9
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Vote E, 2002, IEEE COMPUT GRAPH, V22, P38, DOI 10.1109/MCG.2002.1028725
   ZENDJEBIL IM, 2008, VIRT REAL INT C VRIC, P177
   2009, ART ADV REALTIME TRA
   [No title captured]
   2009, CC CULTURAL COMPUTIN
NR 48
TC 40
Z9 49
U1 5
U2 72
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2011
VL 15
IS 4
SI SI
BP 311
EP 327
DI 10.1007/s10055-010-0176-4
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IC
UT WOS:000296280300006
DA 2024-07-18
ER

PT J
AU Khoo, ET
   Cheok, AD
   Liu, W
   Hu, XM
   Marini, P
   Saksen, V
   Jiang, JL
   Duh, HBL
AF Khoo, Eng Tat
   Cheok, Adrian David
   Liu, Wei
   Hu, Xiaoming
   Marini, Peter
   Saksen, Vira
   Jiang, Jialei
   Duh, Henry Been-Lirn
TI Confucius Computer: bridging intergenerational communication through
   illogical and cultural computing
SO VIRTUAL REALITY
LA English
DT Article
DE Cultural computing; Intergenerational communication; Illogical
   computing; Confucius
ID MUSIC-THERAPY
AB Confucius Computer is a new form of illogical cultural computing based on the Eastern paradigms of balance and harmony. The system uses new media to revive and model ancient Eastern and Confucius philosophies and teachings, presenting them in new contexts, such as online social chat, music and food. Based on the model of Eastern mind and teaching, the system enables users to have meaningful social network communication with a virtual Confucius. The Confucius Computer system offers a new artistic playground for interactive music-painting creation based on our Confucius music filters and the ancient model of Cycles of Balance. Confucius Computer also allows users to explore the traditional Chinese medicine concept of Yin-Yang through interactive recipe creation. Detailed descriptions of the systems are presented in this paper. Our user studies showed that users gave positive feedbacks to their experience of interacting with Confucius Computer. They believed that this media could improve intergenerational interaction and promote a sense of calmness.
C1 [Khoo, Eng Tat; Cheok, Adrian David; Liu, Wei; Hu, Xiaoming; Marini, Peter; Saksen, Vira; Jiang, Jialei; Duh, Henry Been-Lirn] Natl Univ Singapore, Mixed Real Lab, Singapore 117548, Singapore.
   [Cheok, Adrian David] Keio Univ, Grad Sch Media Design, Kanagawa, Japan.
C3 National University of Singapore; Keio University
RP Khoo, ET (corresponding author), Natl Univ Singapore, Mixed Real Lab, Singapore 117548, Singapore.
EM khooet@mixedrealitylab.org; adriancheok@mixedrealitylab.org;
   wei.liu@mixedrealitylab.org; xiaomingxiaoming@gmail.com;
   petermarini@gmail.com; vsaksen@yahoo.com; jiangjialei@gmail.com;
   eledbl@nus.edu.sg
RI Duh, Henry/O-9514-2019; Hu, Xiao-Ming/D-8085-2011; Cheok, Adrian
   David/AAT-6141-2021; Duh, Henry BL/G-3220-2010
OI Hu, Xiao-Ming/0000-0002-0769-5090; Cheok, Adrian
   David/0000-0001-6316-2339; Duh, Henry BL/0000-0003-4808-6109; Hu, Tim
   Xiaoming/0000-0003-0446-3144
CR Angel Edward., 2009, INTERACTIVE COMPUTER, Vfifth
   Brewer M.B., 2003, Intergroup relations
   COOK PM, 2002, HEALING IMAGES ROLE, pCH6
   DREIKURS R, 1960, PSYCHIAT QUART, V34, P722, DOI 10.1007/BF01562586
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Giles H., 2002, LINKING LIFETIMES, P13
   Giles Howard, 2003, J Cross Cult Gerontol, V18, P1, DOI 10.1023/A:1024854211638
   [Gilford D.M. National Academic Press (US) National Academic Press (US)], 1988, The Aging Population in the Twenty-First Century: Statistics for Health Policy
   Gonzalez Victor M., 2008, 2008 IEEE International Symposium on Technology and Society, P1, DOI 10.1109/ISTAS.2008.4559768
   Hao Huifang, 2007, CHUANSHAN J, V3, P113
   Huang Siu-Chi., 1963, Philosophy East and West, V13, P49, DOI DOI 10.2307/1396785
   Ignizio J.P., 1991, INTRO EXPERT SYSTEMS
   Jing J., 2000, FEEDING CHINAS LITTL
   Kolinski M., 1962, SOC ETHNOMUSICOLOGY, V6, P66
   Kornhaber A., 1981, Grandparents, grandchildren : The vital connection
   Kupiec J., 1992, Computer Speech and Language, V6, P225, DOI 10.1016/0885-2308(92)90019-Z
   LEACOCK C, 1998, WORDNET ELECT LEXICA, V49, P265
   LEVY B, 1994, J PERS SOC PSYCHOL, V66, P989, DOI 10.1037/0022-3514.66.6.989
   MASON R, 2006, ALTERN COMPLEMENT TH, V12, P81
   MUNCH D, 2005, HDB ATOPIC ECZEMA
   NAKASEKO K, 1957, J MUSIC THER, V1, P166
   NG K, 2004, EXPLORATORY COMP STU
   Ng S.H., 1998, ASIAN J SOC PSYCHOL, V1, P99, DOI DOI 10.1111/1467-839X.00007
   NICHOLSON L, 2008, GRANDPARENTS LIVES Y, P129
   ORTIZ VM, 2009, STUDIES ASIAN ART AR, V22
   PALAKANIS KC, 1994, DIS COLON RECTUM, V37, P478, DOI 10.1007/BF02076195
   PRUITT J, 2006, INTERACTIVE TECHNOLO
   RONG JY, 2007, CHIN ARCH TRADIT CHI, V12, P2620
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   SCHELLENBERG EG, 1994, PSYCHON B REV, V1, P191, DOI 10.3758/BF03200773
   Silverstein M, 1997, RES AGING, V19, P108, DOI 10.1177/0164027597191005
   Sing G.O., 2006, Proceedings of international conference on Game research and development, P177
   Soliz J, 2003, J APPL COMMUN RES, V31, P320, DOI 10.1080/1369681032000132582
   Sparck-Jones K, 2004, J DOC, V60, P493, DOI [10.1108/00220410410560573, 10.1108/eb026526]
   VASIL L, 1993, EDUC GERONTOL, V19, P71, DOI 10.1080/0360127930190107
   WEAVER RL, 1997, UNDERSTANDING INTERP
   WU XX, 1984, 32 ANN M ASS COMP LI, P133
   XUEQIN C, 1999, DREAM RED MANSIONS
   Yerby J., 1994, Understanding family communication
   ZHENG Z, 2004, SW CHINA NORM U HUMA, V30, P167
NR 40
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2011
VL 15
IS 4
SI SI
BP 249
EP 265
DI 10.1007/s10055-009-0146-x
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IC
UT WOS:000296280300002
DA 2024-07-18
ER

PT J
AU Lee, H
   Billinghurst, M
   Woo, W
AF Lee, Hyeongmook
   Billinghurst, Mark
   Woo, Woontack
TI Two-handed tangible interaction techniques for composing augmented
   blocks
SO VIRTUAL REALITY
LA English
DT Article
DE Two-handed interaction; Tangible interaction; Augmented reality; 3D
   model assembly; Multi-modal feedback
ID REALITY
AB Modeling tools typically have their own interaction methods for combining virtual objects. For realistic composition in 3D space, many researchers from the fields of virtual and augmented reality have been trying to develop intuitive interactive techniques using novel interfaces. However, many modeling applications require a long learning time for novice users because of unmanageable interfaces. In this paper, we propose two-handed tangible augmented reality interaction techniques that provide an easy-to-learn and natural combination method using simple augmented blocks. We have designed a novel interface called the cubical user interface, which has two tangible cubes that are tracked by marker tracking. Using the interface, we suggest two types of interactions based on familiar metaphors from real object assembly. The first, the screw-driving method, recognizes the user's rotation gestures and allows them to screw virtual objects together. The second, the block-assembly method, adds objects based on their direction and position relative to predefined structures. We evaluate the proposed methods in detail with a user experiment that compares the different methods.
C1 [Lee, Hyeongmook; Woo, Woontack] GIST U VR Lab, Kwangju 500712, South Korea.
   [Billinghurst, Mark] Univ Canterbury, HIT Lab NZ, Christchurch 1, New Zealand.
C3 Gwangju Institute of Science & Technology (GIST); University of
   Canterbury
RP Woo, W (corresponding author), GIST U VR Lab, Kwangju 500712, South Korea.
EM hmooklee@gist.ac.kr; mark.billinghurst@hitlabnz.org; wwoo@gist.ac.kr
RI Billinghurst, Mark/AAJ-4236-2020; Woo, Woontack/C-3696-2012
OI Billinghurst, Mark/0000-0003-4172-6759; Woo,
   Woontack/0000-0002-5501-4421
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA)
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2009.
CR ANDERSON TW, 1952, ANN MATH STAT, V23, P193, DOI 10.1214/aoms/1177729437
   [Anonymous], 2004, ACM INT C P SERIES
   Butterworth J., 1992, Proceeding of the Symposium on Interactive 3D Graphics, P135, DOI DOI 10.1145/147156.147182
   Camarata K., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P31
   CONNACHER H, 1995, P 1995 COMP ENG C BO
   Couture N, 2008, INT J INTERACT DES M, V2, P175, DOI 10.1007/s12008-008-0046-4
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   Depaulis F, 2005, P SOC PHOTO-OPT INS, V5664, P530, DOI 10.1117/12.587163
   Fiala P, 2005, International Symposium on Mixed and Augmented Reality, Proceedings, P196
   GAULIN SJC, 1992, YEARB PHYS ANTHROPOL, V35, P125
   GRIBNAU MW, 1998, C HUM FACT COMP SYST
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Irawati S, 2006, LECT NOTES COMPUT SC, V4282, P272
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   JAYARAM S, 1997, COMPUTER AIDED DESIG, V29
   Kato H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P340, DOI 10.1109/ISMAR.2003.1240750
   KATO H, 2001, SIGGRAPH 2001 COURS
   KIYOKAWA K, 1996, VLEGO SIMPLE 2 HANDE, P27
   Lee GA, 2009, J VISUAL LANG COMPUT, V20, P61, DOI 10.1016/j.jvlc.2008.07.001
   LERSITHICHAI S, 2002, C HUM FACT COMP SYST, P756
   OLKIN I, 1960, CONTRIBUTIONS PROBAB, pCH25
   PARK JY, 2004, LECT NOTE COMPUTER S, P254
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Poupyrev I, 2002, COMPUTER, V35, P44, DOI 10.1109/2.989929
   REUTER P, 2007, VAST2007, P15
   Wang XY, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P170
   Yonemoto S, 2007, IEEE INT CONF INF VI, P781
   ZhiYing Zhou, 2008, International Journal of Virtual Reality, V7, P9
NR 28
TC 16
Z9 21
U1 1
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 133
EP 146
DI 10.1007/s10055-010-0163-9
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200005
DA 2024-07-18
ER

PT J
AU Nagase, M
   Iwai, D
   Sato, K
AF Nagase, Momoyo
   Iwai, Daisuke
   Sato, Kosuke
TI Dynamic defocus and occlusion compensation of projected imagery by
   model-based optimal projector selection in multi-projection environment
SO VIRTUAL REALITY
LA English
DT Article
DE Projection-based mixed reality; Multi-projection environment; Defocus
   compensation; Shadow removal; PSF computation
AB This paper presents a novel model-based approach of dynamic defocus and occlusion compensation method in a multi-projection environment. Conventional defocus compensation research applies appearance-based method, which needs a point spread function (PSF) calibration when either position or orientation of an object to be projected is changed, thus cannot be applied to interactive applications in which the object dynamically moves. On the other hand, we propose a model-based method in which PSF and geometric calibrations are required only once in advance, and projector's PSF is computed online based on geometric relationship between the projector and the object without any additional calibrations. We propose to distinguish the oblique blur (loss of high-spatial-frequency components according to the incidence angle of the projection light) from the defocus blur and to introduce it to the PSF computation. For each part of the object surfaces, we select an optimal projector that preserves the largest amount of high-spatial-frequency components of the original image to realize defocus-free projection. The geometric relationship can also be used to eliminate the cast shadows of the projection images in multi-projection environment. Our method is particularly useful in the interactive systems because the movement of the object (consequently geometric relationship between each projector and the object) is usually measured by an attached tracking sensor. This paper describes details about the proposed approach and a prototype implementation. We performed two proof-of-concept experiments to show the feasibility of our approach.
C1 [Nagase, Momoyo; Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Osaka 5608531, Japan.
C3 Osaka University
RP Iwai, D (corresponding author), Osaka Univ, Grad Sch Engn Sci, 1-3-D554 Machikaneyama, Osaka 5608531, Japan.
EM daisuke.iwai@sys.es.osaka-u.ac.jp
RI Iwai, Daisuke/R-8174-2019
OI Iwai, Daisuke/0000-0002-3493-5635
CR [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2006, P IEEE C COMP VIS PA
   Audet S., 2007, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2007.383470
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bimber O, 2006, IEEE T VIS COMPUT GR, V12, P658, DOI 10.1109/TVCG.2006.75
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Cham TJ, 2003, PROC CVPR IEEE, P513
   GROSSE M, 2008, P ACM EDT IPT 08
   GUPTA S, 2006, P 5 IEEE ACM INT S M, P177, DOI DOI 10.1109/ISMAR.2006.297811
   Jaynes C, 2004, IEEE T VIS COMPUT GR, V10, P290, DOI 10.1109/TVCG.2004.1272728
   Kondo D., 2002, P 8 INT C VIRT SYST, P346
   KONDO D, 2008, P IEEE ACM PROCAMS 0, P31
   Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806
   Low Kok-Lim., 2001, VRST 01, P93, DOI DOI 10.1145/505008.505026
   Majumder Aditi., 2007, Practical multi-projector display design
   Oyamada Y, 2008, LECT NOTES COMPUT SC, V5259, P453, DOI 10.1007/978-3-540-88458-3_41
   PARK H, 2006, P ACCV 06, V2, P892
   Raskar R, 2001, SPRING EUROGRAP, P89
   Sato K., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P657
   Sukthankar R, 2001, PROC CVPR IEEE, P151
   Zhang L, 2006, ACM T GRAPHIC, V25, P907, DOI 10.1145/1141911.1141974
NR 22
TC 22
Z9 24
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 119
EP 132
DI 10.1007/s10055-010-0168-4
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200004
DA 2024-07-18
ER

PT J
AU Turner, P
   Turner, S
AF Turner, Phil
   Turner, Susan
TI Triangulation in practice
SO VIRTUAL REALITY
LA English
DT Article
DE Triangulation; Involvement; Heidegger; Game playing
ID DIFFERENT SCIENTIFIC COMMUNITIES; SHERIDANS ECLECTIC ONTOLOGY; BRIDGE;
   SENSE
AB Triangulation is the means by which an alternate perspective is used to validate, challenge or extend existing findings. It is frequently used when the field of study is difficult, demanding or contentious and presence research meets all of these criteria. We distinguish between the use of hard and soft triangulation-the former emphasising the challenging of findings, the latter being more confirmatory in character. Having reviewed a substantial number of presence papers, we conclude that strong triangulation is not widely used while soft triangulation is routinely employed. We demonstrate the usefulness of hard triangulation by contrasting an ontological analysis of in-ness with an empirical study of (computer) game playing. We conclude that presence research would be well served by the wider use of hard triangulation and for the reporting of anomalous and ill-fitting results.
C1 [Turner, Phil; Turner, Susan] Edinburgh Napier Univ, Ctr Interact Design, Sch Comp, Edinburgh EH10 5DT, Midlothian, Scotland.
C3 Edinburgh Napier University
RP Turner, P (corresponding author), Edinburgh Napier Univ, Ctr Interact Design, Sch Comp, Edinburgh EH10 5DT, Midlothian, Scotland.
EM p.turner@napier.ac.uk; s.turner@napier.ac.uk
CR Abeele M.V., 2007, P 10 INT WORKSHOP PR, P215
   Altrichter H., 1996, Teachers investigate their work; An introduction to the methods of action research
   [Anonymous], UNIVERSE BIOGRAPHY
   [Anonymous], 2003, Quantity and quality in social research
   [Anonymous], J COMP MED COMMUN
   [Anonymous], 1999, P 2 INT WORKSH PRES
   [Anonymous], TEMP SPAT VAR PRES P
   [Anonymous], 1978, SOCIOLOGICAL METHODS
   [Anonymous], P 10 INT WORKSH PRES
   [Anonymous], PRESENCE CONNECT
   [Anonymous], P 10 INT WORKSH PRES
   [Anonymous], J COMP MED COMMUN
   [Anonymous], P 3 INT WORKSH PRES
   [Anonymous], P 10 INT WORKSH PRES
   [Anonymous], P 10 INT WORKSH PRES
   [Anonymous], P 7 INT WORKSH PRES
   [Anonymous], P 10 INT WORKSH PRES
   [Anonymous], P 10 INT WORKSH PRES
   [Anonymous], P 10 INT WORKSH PRES
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Biocca F, 2001, PRESENCE-TELEOP VIRT, V10, P546, DOI 10.1162/105474601753132722
   Biocca F., 2001, NETWORKED MINDS MEAS
   BLAIKIE NWH, 1991, QUAL QUANT, V25, P115, DOI 10.1007/BF00145701
   Bracken C.C., 2007, P 10 INT WORKSHOP PR, P283
   Casey Edward., 1997, FATE PLACE
   Cohen L., 1986, RES METHODS ED
   Davis Marc., 2003, Proceedings of the 2003 ACM SIGMM workshop on Experiential Telepresence, P45, DOI DOI 10.1145/982484.982491
   de Kort YAW, 2007, P 10 ANN INT WORKSHO, P195
   Denzin N.K., 1970, RES ACT SOCIOLOGY
   Di Bias Nicoletta, 2007, Virtual Reality, V11, P129, DOI 10.1007/s10055-006-0060-4
   DZUREC LC, 1993, ADV NURS SCI, V16, P73, DOI 10.1097/00012272-199309000-00009
   Fielding N., 1986, Linking Data
   Freeman J., 2004, P 7 INT WORKSHOP PRE, P67
   Gaver W.W., 1991, P SIGCHI C HUMAN FAC, P79, DOI DOI 10.1145/108844.108856
   Gaver WilliamW., 1992, Proceedings of the 1992 ACM Conference on Computer-Supported Cooperative Work. CSCW '92, P17
   Giles D.C., 2002, Advanced Research Methods, P167
   Gray WD, 1998, HUM-COMPUT INTERACT, V13, P203, DOI 10.1207/s15327051hci1303_2
   Harrison Steve R, 1996, P 1996 ACM C COMP SU, V96, P67, DOI [DOI 10.1145/240080.240193, 10.1145/240080.240193]
   Heidegger M., 1927, BEING TIME
   Heidegger Martin., 1971, Basic Writings
   HINDMARSH J, 1998, P ACM C COMP SUPP CO, P217, DOI DOI 10.1145/289444.289496
   Jones M.T., 2007, Proceedings of the Tenth Annual International Meeting of the Presence Workshop, P115
   Kallinen K., 2007, Presence, P187
   Larsson P, 2001, CYBERPSYCHOL BEHAV, V4, P239, DOI 10.1089/109493101300117929
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lincoln Y.S., 2018, The SAGE handbook of qualitative research, V5th Edn., P213
   Mantovani G, 2001, PRESENCE-TELEOP VIRT, V10, P537, DOI 10.1162/105474601753132704
   Mark G, 2005, PRESENCE-VIRTUAL AUG, V14, P60, DOI 10.1162/1054746053890279
   Nunez D, 2006, PRESENCE-TELEOP VIRT, V15, P373, DOI 10.1162/pres.15.4.373
   Patel K., 2006, Proceedings of 8th Annual International Workshop on Presence, P129
   Provenzo E.F., 1991, Video kids: Making sense of Nintendo
   Relph E., 1976, PLACE PLACELESSNESS
   Robson D, 2009, NEW SCI, V201, P12, DOI 10.1016/S0262-4079(09)60190-1
   Rourke L., 1999, J DISTANCE ED, V14, P50, DOI DOI 10.1080/08923640109527071
   Sheridan TB, 2001, PRESENCE-TELEOP VIRT, V10, P544, DOI 10.1162/105474601753132713
   Silverman D., 2013, DOING QUALITATIVE RE, DOI DOI 10.3917/DS.293.0349
   Silverman David., 2001, Interpreting Qualitative Data: Methods for Analyzing Talk, Text, and Interaction, V2nd
   Skeat W.W., 1879, An Etymological Dictionary of the English Language., VFourth
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Thurmond VA, 2001, J NURS SCHOLARSHIP, V33, P253, DOI 10.1111/j.1547-5069.2001.00253.x
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
NR 65
TC 45
Z9 99
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 171
EP 181
DI 10.1007/s10055-009-0117-2
PN 1
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU De Pace, F
   Kaufmann, H
AF De Pace, Francesco
   Kaufmann, Hannes
TI A systematic evaluation of an RTK-GPS device for wearable augmented
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Outdoor tracking; Real-time kinematic; GPS
ID LOW-COST; NAVIGATION; VISUALIZATION; PRECISION; ACCURACY; BDS
AB Global Positioning Satellite (GPS) systems sample points on the Earth's surface with meter accuracy. Real-Time Kinematic (RTK) devices improve GPS performances by providing real-time correction data from ground stations, achieving centimeter accuracy. Reliable tracking approaches are essential for Augmented Reality (AR) applications, especially for outdoor scenarios, which still present unsolved challenges. AR handheld tracking capabilities have been greatly improved by integrating visual tracking approaches with RTK devices, whereas little is known about combining wearable AR interfaces with RTK systems. Although wearable AR devices are intrinsically designed for AR applications, their performance dramatically reduces in large outdoor areas, comprising the user experience. Hence, this paper provides a rigorous evaluation of a small-size RTK device that does not need any additional software integration to collect positional data. The main goal of the assessment is to verify whether its integration with a wearable AR device is advantageous or not. The evaluation has been performed considering both static and dynamic scenarios in open-sky and urban areas. The results show that the RTK device can achieve 1 cm accuracy when used in open-sky areas. In contrast, its accuracy dramatically reduces in the proximity of buildings and obstacles, showing average errors ranging from 76 to 2561%. Since wearable AR devices have an average accuracy of 2 cm, the outcomes indicate that RTK devices should be combined with wearable AR devices only when the RTK device is far from obstacles. On the contrary, the positional data should be completely avoided when barriers surround the RTK device.
C1 [De Pace, Francesco; Kaufmann, Hannes] TU Wien, Inst Visual Comp & Human Ctr Technol, Favoritenstr 9-11, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP De Pace, F (corresponding author), TU Wien, Inst Visual Comp & Human Ctr Technol, Favoritenstr 9-11, A-1040 Vienna, Austria.
EM francesco.pace@tuwien.ac.at; hannes.kaufmann@tuwien.ac.at
OI De Pace, Francesco/0000-0001-8772-4105
FU The authors acknowledge TU Wien Bibliothek for financial support through
   its Open Access Funding Programme.; TU Wien Bibliothek
FX The authors acknowledge TU Wien Bibliothek for financial support through
   its Open Access Funding Programme.
CR Agrawal M, 2006, INT C PATT RECOG, P1063
   Bakula M, 2015, IEEE T GEOSCI REMOTE, V53, P1029, DOI 10.1109/TGRS.2014.2332372
   Blanco-Pons S, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11164268
   Chiuman N, 2019, 2019 5 INT C SCI TEC, P1
   Fajnerová I, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/2716134
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Gan-Mor S, 2007, COMPUT ELECTRON AGR, V59, P31, DOI 10.1016/j.compag.2007.04.008
   Gleue T., 2001, P 2001 C VIRTUAL REA, P161, DOI [10.1145/584993.585018, DOI 10.1145/584993.585018]
   Han JG, 2013, AASRI PROC, V4, P64, DOI 10.1016/j.aasri.2013.10.011
   Hegarty ChristopherJ., 2017, Springer Handbook of Global Navigation Satellite Systems, P197, DOI [10.1007/978-3-319-42928-1_7, DOI 10.1007/978-3-319-42928-1_7]
   Henkel P, 2016, EUR SIGNAL PR CONF, P1063, DOI 10.1109/EUSIPCO.2016.7760411
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   Isrie S, 2018, IEEE INT SYMP ELEC, P500, DOI 10.1109/EMCEurope.2018.8485116
   Jakus G, 2014, LECT NOTES COMPUT SC, V8511, P254, DOI 10.1007/978-3-319-07230-2_25
   Kamat VR, 2006, LECT NOTES ARTIF INT, V4200, P368
   Kluga A, 2014, 2014 PROCEEDINGS OF THE 14TH BIENNIAL BALTIC ELECTRONICS CONFERENCE (BEC 2014), P141, DOI 10.1109/BEC.2014.7320576
   Kurkovsky S., 2012, International Conference on Communications and Information Technology, P68, DOI [DOI 10.1109/ICCITECHNOL.2012.6285844, https://doi.org/10.1109/ICCITechnol.2012.6285844]
   Ling FF, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1044, DOI [10.1109/VR.2019.8798315, 10.1109/vr.2019.8798315]
   Liu Y, 2018, IEEE MULTIMEDIA, V25, P8, DOI 10.1109/MMUL.2018.2873473
   Lucero-Urresta E, 2021, LECT NOTES COMPUT SC, V12957, P283, DOI 10.1007/978-3-030-87013-3_22
   Guarese RLM, 2019, LECT NOTES COMPUT SC, V11542, P431, DOI 10.1007/978-3-030-22514-8_41
   Mekni M., 2014, APPL COMPUTATIONAL S, P205
   Menozzi A, 2014, IEEE POSITION LOCAT, P760
   Morales Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON INTEGRATION TECHNOLOGY, PROCEEDINGS, P519, DOI 10.1109/ICITECHNOLOGY.2007.4290370
   Muhammed Reyam R., 2018, IRAQI J SCI, V59, P1146
   Nazri N., 2014, Computer and Information Sciences (ICCOINS), P1, DOI DOI 10.1109/ICCOINS.2014.6868425
   Ng KM, 2018, INT C CONTR AUTOMAT, P1424
   Niu Z, 2020, IEEE ACCESS, V8, P185638, DOI 10.1109/ACCESS.2020.3028119
   Odolinski R, 2017, GPS SOLUT, V21, P1315, DOI 10.1007/s10291-017-0613-x
   Odolinski R, 2015, GPS SOLUT, V19, P151, DOI 10.1007/s10291-014-0376-6
   Piekarski W, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P266, DOI 10.1109/ISMAR.2003.1240713
   Pintaric Thomas., 2007, IEEE VR Workshop on Trends and Issues in Tracking for Virtual Environments, P44
   Pombo L, 2019, INT J MOB BLENDED LE, V11, P59, DOI 10.4018/IJMBL.2019100105
   Reitmayr Gerhard, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P109, DOI 10.1109/ISMAR.2006.297801
   Safrel I., 2018, UNNES J, V20, P123, DOI DOI 10.15294/JTSP.V20I2.16284
   Schall G, 2009, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2009.5336489
   Singh S., 2020, arXiv
   Soares I, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5080047
   Speroni EA, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P268, DOI 10.1145/3167132.3167156
   Stranner M, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P37, DOI 10.1109/ISMAR-Adjunct.2019.00025
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tache R, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P99, DOI 10.1109/VR.2012.6180901
   Taketomi T, 2017, IPSJ Trans. Comput. Vis. Appl, V9, P1, DOI [10.1186/s41074-017-0027-2, DOI 10.1186/S41074-017-0027-2]
   Teunissen PJG, 2014, J GEODESY, V88, P335, DOI 10.1007/s00190-013-0686-4
   Thomas B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P139, DOI 10.1109/ISWC.2000.888480
   Tomaszewski D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082293
   Ungureanu D., 2020, ArXiv
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Wisniewski B, 2013, TRANSNAV, V7, P79, DOI 10.12716/1001.07.01.10
   Zari G, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23063040
   Zhang Y, 2019, ADV SPACE RES, V63, P3029, DOI 10.1016/j.asr.2018.10.048
   Zheng Y., 2022, arXiv
NR 52
TC 1
Z9 1
U1 7
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3165
EP 3179
DI 10.1007/s10055-023-00863-3
EA OCT 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001086618000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kim, D
   Kim, S
   Shin, JE
   Yoon, B
   Kim, J
   Lee, J
   Woo, W
AF Kim, Dooyoung
   Kim, Seonji
   Shin, Jae-eun
   Yoon, Boram
   Kim, Jinwook
   Lee, Jeongmi
   Woo, Woontack
TI The effects of spatial configuration on relative translation gain
   thresholds in redirected walking
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Redirected walking; Relative translation gains;
   Threshold; Locomotion; Visual cognition
AB In this study, we explore how spatial configurations can be reflected in determining the threshold range of Relative Translation Gains (RTGs), a translation gain-based Redirected Walking (RDW) technique that scales the user's movement in Virtual Reality (VR) in different ratios for width and depth. While previous works have shown that various cognitive factors influence the RDW threshold, studies investigating the impact of environmental aspects on the RDW threshold with regard to the user's visual perception were lacking. Therefore, we examined the effect of spatial configurations on the RTG threshold by analyzing the participant's responses and gaze distribution data in two user studies. The first study concerned the size of the virtual room and the existence of objects within it, and the second study focused on the combined impact of room size and spatial layout. Our results show that room size, the existence of objects, and spatial layout all significantly affect the RTG threshold range. Based on our findings, we propose virtual space rescaling guidelines to increase the range of adjustable movable space with RTGs for developers: placing distractors in the room, setting the perceived movable space to be larger than the adjusted movable space for an empty room, and avoiding the placement of object clusters in the center of the room. Our findings can be used to adaptively rescale VR users' space according to the target virtual space's configuration with a unified coordinate system that enables the utilization of physical objects in a virtual scene.
C1 [Kim, Dooyoung; Kim, Seonji; Yoon, Boram; Woo, Woontack] KAIST UVR Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Shin, Jae-eun; Woo, Woontack] KAIST KI ITC, Augmented Real Res Ctr, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Kim, Jinwook; Lee, Jeongmi] KAIST Visual Cognit Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Woo, W (corresponding author), KAIST UVR Lab, 291 Daehak Ro, Daejeon 34141, South Korea.; Woo, W (corresponding author), KAIST KI ITC, Augmented Real Res Ctr, 291 Daehak Ro, Daejeon 34141, South Korea.
EM dooyoung.kim@kaist.ac.kr; seonji.kim@kaist.ac.kr;
   jaeeunshin@kaist.ac.kr; boram.yoon1206@kaist.ac.kr;
   jinwook.kim31@kaist.ac.kr; jeongmi@kaist.ac.kr; wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421; Kim, Dooyoung/0000-0002-6003-2181;
   Kim, Jinwook/0000-0002-1962-5815
FU National Research Council of Science and Technology (NST) - Ministry of
   Science and ICT (MSIT), Republic of Korea [CRC 21011]; National Research
   Foundation of Korea (NRF) - Korea government (MSIT) [2021R1A2C2011459]
FX This research was supported by the National Research Council of Science
   and Technology (NST) funded by the Ministry of Science and ICT (MSIT),
   Republic of Korea (Grant No. CRC 21011), and the National Research
   Foundation of Korea (NRF) grant funded by the Korea government (MSIT)
   (No. 2021R1A2C2011459).
CR Nguyen A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI 10.1109/VR.2018.8446225
   [Anonymous], 2005, ACM Transactions on Applied Perception, DOI [DOI 10.1145/1077399.1077403, DOI 10.1145/1077399.10774032,3,9]
   Ash A, 2013, PERCEPTION, V42, P562, DOI 10.1068/p7449
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Banton T, 2005, PRESENCE-TELEOP VIRT, V14, P394, DOI 10.1162/105474605774785262
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Caramenti M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195781
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chen HW, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P523
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Ciumedean CB, 2020, S SPATIAL USER INTER, P1, DOI [10.1145/3385959.3418453, DOI 10.1145/3385959.3418453]
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Grechkin T., 2016, P ACM S APPL PERC, P113
   HILL SG, 1986, HUM FACTORS, V28, P127, DOI 10.1177/001872088602800201
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarzi M., 2022, arXiv
   Keshavarzi M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P353, DOI [10.1109/VR46266.2020.1581131119600, 10.1109/VR46266.2020.00-49]
   Kim D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P379, DOI 10.1109/VR51125.2022.00057
   Kim D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR50410.2021.00091
   Kim HI, 2021, INT SYM MIX AUGMENT, P435, DOI 10.1109/ISMAR-Adjunct54149.2021.00098
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lehment NH, 2014, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2014.6948428
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Nguyen A, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407932
   Selzer MN, 2022, VIRTUAL REAL-LONDON, V26, P1459, DOI 10.1007/s10055-022-00640-8
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Razzaque S, 2005, CITESEER
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Ropelato S, 2022, VIRTUAL REAL-LONDON, V26, P1009, DOI 10.1007/s10055-021-00608-0
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Shin J.-e., 2021, P 2021 CHI C HUMAN F, P1, DOI [10.1145/3411764.3445675, DOI 10.1145/3411764.3445675]
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Zhang J, 2018, IEEE T VIS COMPUT GR, V24, P1671, DOI 10.1109/TVCG.2018.2793679
   Zhang R., 2014, Proc. Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P62
NR 52
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1233
EP 1250
DI 10.1007/s10055-022-00734-3
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA Q0LF9
UT WOS:001054507300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Heffer, N
   Dennie, E
   Ashwin, C
   Petrini, K
   Karl, A
AF Heffer, Naomi
   Dennie, Emma
   Ashwin, Chris
   Petrini, Karin
   Karl, Anke
TI Multisensory processing of emotional cues predicts intrusive memories
   after virtual reality trauma
SO VIRTUAL REALITY
LA English
DT Article
DE Multisensory processing; Emotion recognition; Trauma film; Virtual
   reality; Intrusive memories
ID POSTTRAUMATIC-STRESS; GREATER SENSITIVITY; BETA REGRESSION; FILM
   PARADIGM; PERCEPTION; VOICE; MODEL; FACE; RECOGNITION; INTEGRATION
AB Research has shown that high trait anxiety can alter multisensory processing of threat cues (by amplifying integration of angry faces and voices); however, it remains unknown whether differences in multisensory processing play a role in the psychological response to trauma. This study examined the relationship between multisensory emotion processing and intrusive memories over seven days following exposure to an analogue trauma in a sample of 55 healthy young adults. We used an adapted version of the trauma film paradigm, where scenes showing a car accident trauma were presented using virtual reality, rather than a conventional 2D film. Multisensory processing was assessed prior to the trauma simulation using a forced choice emotion recognition paradigm with happy, sad and angry voice-only, face-only, audiovisual congruent (face and voice expressed matching emotions) and audiovisual incongruent expressions (face and voice expressed different emotions). We found that increased accuracy in recognising anger (but not happiness and sadness) in the audiovisual condition relative to the voice- and face-only conditions was associated with more intrusions following VR trauma. Despite previous results linking trait anxiety and intrusion development, no significant influence of trait anxiety on intrusion frequency was observed. Enhanced integration of threat-related information (i.e. angry faces and voices) could lead to overly threatening appraisals of stressful life events and result in greater intrusion development after trauma.
C1 [Heffer, Naomi; Ashwin, Chris; Petrini, Karin] Univ Bath, Dept Psychol, Claverton Down, Bath BA2 7AY, England.
   [Heffer, Naomi] Bath Spa Univ, Sch Sci, Bath, England.
   [Dennie, Emma; Karl, Anke] Univ Exeter, Mood Disorders Ctr, Exeter, England.
   [Ashwin, Chris] Ctr Appl Autism Res CAAR, Bath, England.
   [Petrini, Karin] Ctr Anal Mot Entertainment Res & Applicat CAMERA, Bath, England.
C3 University of Bath; Bath Spa University; University of Exeter
RP Heffer, N (corresponding author), Univ Bath, Dept Psychol, Claverton Down, Bath BA2 7AY, England.; Heffer, N (corresponding author), Bath Spa Univ, Sch Sci, Bath, England.
EM n.r.heffer@bath.ac.uk
OI Heffer, Naomi/0000-0002-6597-0134; Ashwin, Chris/0000-0003-4606-7318;
   Dennie, Emma/0000-0001-8826-7735; Petrini, Karin/0000-0001-5354-5600
FU Medical Research Council [MR/N0137941/1]
FX NH was funded by the Medical Research Council, MR/N0137941/1.
CR Admon R, 2013, TRENDS COGN SCI, V17, P337, DOI 10.1016/j.tics.2013.05.005
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Araneda R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120387
   Asiain J, 2022, BRIT J GUID COUNS, V50, P1, DOI 10.1080/03069885.2021.1885008
   Baptie G, 2021, CYBERPSYCHOLOGY, V15, DOI 10.5817/CP2021-1-6
   Belcher J, 2015, STRESS HEALTH, V31, P419, DOI 10.1002/smi.2567
   Brewin CR, 2001, INT REV PSYCHIATR, V13, P159, DOI 10.1080/09540260120074019
   CAMERON AC, 1990, J ECONOMETRICS, V46, P347, DOI 10.1016/0304-4076(90)90014-K
   Campanella S, 2012, CLIN NEUROPHYSIOL, V123, P937, DOI 10.1016/j.clinph.2011.10.041
   Campanella S, 2010, CLIN NEUROPHYSIOL, V121, P1855, DOI 10.1016/j.clinph.2010.04.004
   Canty A, 2002, R NEWS, V2, P2, DOI DOI 10.1159/000323281
   Clark IA, 2015, COGNITION EMOTION, V29, P702, DOI 10.1080/02699931.2014.926861
   Collignon O, 2010, NEUROPSYCHOLOGIA, V48, P220, DOI 10.1016/j.neuropsychologia.2009.09.007
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Cribari-Neto F, 2010, J STAT SOFTW, V34, P1
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Gelder B, 1999, NEUROSCI LETT, V260, P133, DOI 10.1016/S0304-3940(98)00963-X
   de Gelder B, 2002, P NATL ACAD SCI USA, V99, P4121, DOI 10.1073/pnas.062018499
   de Jong JJ, 2009, SCHIZOPHR RES, V107, P286, DOI 10.1016/j.schres.2008.10.001
   Delle-Vigne D, 2015, CLIN NEUROPHYSIOL, V126, P2108, DOI 10.1016/j.clinph.2015.01.012
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Dibbets P, 2020, J BEHAV THER EXP PSY, V67, DOI 10.1016/j.jbtep.2019.01.001
   Ehlers A, 2000, BEHAV RES THER, V38, P319, DOI 10.1016/S0005-7967(99)00123-0
   Ehlers A, 1995, Behav Cogn Psychother, V23, P217, DOI 10.1017/S135246580001585X
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fagel S, 2006, P INT C SPEECH PROS, V1
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   Ferrari SLP, 2004, J APPL STAT, V31, P799, DOI 10.1080/0266476042000214501
   FirstCar & Leicestershire Fire and Rescue Service, 2017, VF4360 VIRT REAL FIL
   Gao CJ, 2018, BIOL PSYCHOL, V139, P59, DOI 10.1016/j.biopsycho.2018.10.001
   Heffer N, 2022, J BEHAV THER EXP PSY, V74, DOI 10.1016/j.jbtep.2021.101693
   Heffer N, 2021, BEHAV BRAIN RES, V410, DOI 10.1016/j.bbr.2021.113346
   Hirst RJ, 2019, J EXP PSYCHOL HUMAN, V45, P553, DOI 10.1037/xhp0000608
   Holmes EA, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013706
   Holmes EA, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004153
   James EL, 2016, CLIN PSYCHOL REV, V47, P106, DOI 10.1016/j.cpr.2016.04.010
   Klasen M, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00822
   Klasen M, 2012, REV NEUROSCIENCE, V23, P381, DOI 10.1515/revneuro-2012-0040
   Kleiber C, 2008, USE R, P1, DOI 10.1007/978-0-387-77318-6_1
   Kleim B, 2012, PSYCHOL MED, V42, P173, DOI 10.1017/S0033291711001048
   Koizumi A, 2011, EXP BRAIN RES, V213, P275, DOI 10.1007/s00221-011-2668-1
   Kroenke K, 2009, J AFFECT DISORDERS, V114, P163, DOI 10.1016/j.jad.2008.06.026
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Logan S, 2012, J BEHAV THER EXP PSY, V43, P815, DOI 10.1016/j.jbtep.2011.12.003
   Long J. Scott., 1997, REGRESSION MODELS CA
   Malik A, 2014, CLIN PSYCHOL SCI, V2, P675, DOI 10.1177/2167702614527433
   Mancini AD, 2021, ANXIETY STRESS COPIN, V34, P66, DOI 10.1080/10615806.2020.1825693
   Maurage P, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00394
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   Nielsen NP, 2020, J APPL RES MEM COGN, V9, P370, DOI 10.1016/j.jarmac.2020.06.004
   Nitschke JB, 2001, COGNITIVE THER RES, V25, P1, DOI 10.1023/A:1026485530405
   Nixon RDV, 2007, BEHAV RES THER, V45, P2652, DOI 10.1016/j.brat.2007.06.010
   Piwek L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00611
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Prins A, 2016, J GEN INTERN MED, V31, P1206, DOI 10.1007/s11606-016-3703-5
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Schweizer T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190360
   Smithson M, 2006, PSYCHOL METHODS, V11, P54, DOI 10.1037/1082-989X.11.1.54
   Spagna A, 2020, CORTEX, V133, P266, DOI 10.1016/j.cortex.2020.09.018
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Taylor S, 2007, PSYCHOL ASSESSMENT, V19, P176, DOI 10.1037/1040-3590.19.2.176
   Tolin DF, 2006, PSYCHOL BULL, V132, P959, DOI 10.1037/0033-2909.132.6.959
   Venables WN., 2002, MODERN APPL STAT S
   Verwoerd J, 2011, COGNITIVE THER RES, V35, P161, DOI 10.1007/s10608-010-9335-x
   Weidmann A, 2009, ANXIETY STRESS COPIN, V22, P549, DOI 10.1080/10615800802541986
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [10.1007/978-3-319-24277-4, DOI 10.1007/978-3-319-24277-4]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Woud ML, 2017, CLIN PSYCHOL REV, V54, P81, DOI 10.1016/j.cpr.2017.04.003
   Yoon KL, 2020, J BEHAV THER EXP PSY, V69, DOI 10.1016/j.jbtep.2020.101597
   Zeileis A, 2008, J STAT SOFTW, V27, P1, DOI 10.18637/jss.v027.i08
NR 70
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2043
EP 2057
DI 10.1007/s10055-023-00784-1
EA APR 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000963008400001
PM 37614716
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Lee, JJ
AF Lee, Jungjin
TI Wand: 360<SUP>?</SUP> video projection mapping using a 360<SUP>?</SUP>
   camera
SO VIRTUAL REALITY
LA English
DT Article
DE Video projection; Projection mapping; Virtual reality; Multi-projector
   display; Automatic geometric registration; 360-degree camera
ID REGISTRATION
AB In a surrounding projection-based display environment (e.g., a dome theater), the viewers can enjoy a 360(?) video with a strong sense of immersion. Building a thriving immersive environment requires two sophisticated steps. First, to generate a single seamless screen, multiple projectors constituting the surrounding display should be carefully registered to the surface. Second, a 360(?) video should be mapped to the projection area by considering the display surface geometry and a sweet spot (i.e., a reference viewing position) to allow viewers to perceive the correct perspectives. In this study, Wand, a novel system utilizing a consumer 360(?) spherical camera as a calibration device, is proposed to efficiently solve these two issues. Wand first establishes correspondences between the 360(?) camera and projectors using structured light patterns, and then filters out any outliers using heuristic criteria. Next, by assuming that the camera is positioned in a sweet spot, Wand solves the geometric registration of the projectors by formulating it as a simple 2D grid mesh parameterization with the correspondence constraints. Consequently, each projector mesh is directly registered into the spherical coordinates, allowing each projector to easily render a perspective-correct view from a 360(?) video. We applied Wand to various environments of different dimensions and shapes. The results demonstrate that our method can be used to successfully build seamless and immersive displays and provide correct perspectives at a sweet spot.
C1 [Lee, Jungjin] Soongsil Univ, Global Sch Media, Seoul, South Korea.
C3 Soongsil University
RP Lee, JJ (corresponding author), Soongsil Univ, Global Sch Media, Seoul, South Korea.
EM jungjinlee@ssu.ac.kr
OI Lee, Jungjin/0000-0003-3471-4848
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2021R1C1C1014153]; IITP(Institute for Information & communications
   Technology Planning Evaluation) [IITP-2023-RS-2022-00156360]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2021R1C1C1014153), and in part by the MSIT(Ministry of Science and
   ICT), Korea, under the Innovative Human Resource Development for Local
   Intellectualization support program(IITP-2023-RS-2022-00156360)
   supervised by the IITP(Institute for Infor-mation & communications
   Technology Planning & Evaluation).
CR Anderson R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980257
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   Argyriou L, 2020, PERS UBIQUIT COMPUT, V24, P843, DOI 10.1007/s00779-020-01373-8
   Bertel T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417770
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Cruz S, 2021, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR46437.2021.00217
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Fernandez-Labrador C, 2018, IEEE ROBOT AUTOM LET, V3, P3153, DOI 10.1109/LRA.2018.2850532
   Gallego G, 2015, J MATH IMAGING VIS, V51, P378, DOI 10.1007/s10851-014-0528-x
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Hasker ES, 2006, IEEE T VIS COMPUT GR, V12, P1101, DOI 10.1109/TVCG.2006.121
   Hormann K., 2007, Mesh parameterization: Theory and practice
   Huang Z., 2022, ACM Transactions on Graphics, V41, P1
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Im S, 2016, LECT NOTES COMPUT SC, V9907, P156, DOI 10.1007/978-3-319-46487-9_10
   Jiang W, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301374
   Johnson T, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P147
   Lee J, 2017, IEEE T VIS COMPUT GR, V23, P1124, DOI 10.1109/TVCG.2016.2532327
   Lee J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925983
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3196492
   Li F, 2017, IEEE T COMPUT IMAG, V3, P74, DOI 10.1109/TCI.2017.2652844
   Li JX, 2021, PROC CVPR IEEE, P10586, DOI 10.1109/CVPR46437.2021.01045
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Mine M, 2012, COMPUTER, V45, P32, DOI 10.1109/MC.2012.154
   Mirdehghan P, 2018, PROC CVPR IEEE, P6248, DOI 10.1109/CVPR.2018.00654
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Park S, 2015, 2015 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P65, DOI 10.1109/SciVis.2015.7429493
   Perazzi F, 2015, COMPUT GRAPH FORUM, V34, P57, DOI 10.1111/cgf.12541
   Pintore Giovanni, 2018, Computational Visual Media, V4, P367, DOI 10.1007/s41095-018-0125-9
   Raij A., 2003, IEEE INT WORKSH PROJ, P203
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Raskar R, 2004, COMPUT GRAPH FORUM, V23, P451, DOI 10.1111/j.1467-8659.2004.00776.x
   Rhee T, 2017, IEEE T VIS COMPUT GR, V23, P1302, DOI 10.1109/TVCG.2017.2657178
   Richardt Christian, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P3, DOI 10.1007/978-3-030-41816-8_1
   Sajadi B, 2011, COMPUT GRAPH FORUM, V30, P1161, DOI 10.1111/j.1467-8659.2011.01965.x
   Sajadi B, 2011, IEEE T VIS COMPUT GR, V17, P1209, DOI 10.1109/TVCG.2011.33
   Sajadi B, 2010, COMPUT GRAPH FORUM, V29, P1063, DOI 10.1111/j.1467-8659.2009.01676.x
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1307, DOI 10.1109/TVCG.2009.166
   Shih YC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322948
   Sun Z., 2022, ARXIV
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tehrani MA, 2021, IEEE T VIS COMPUT GR, V27, P2265, DOI 10.1109/TVCG.2019.2950942
   Wang Y.-S., 2010, ACM T GRAPHIC, V29, P1
   Willi S, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P42, DOI 10.1109/ISMAR.2017.21
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
   ZHOU J., 2008, Proc. IET Seminar Cognitive Radio Software Defined Radios :Technol. Techniques, P1
NR 47
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2015
EP 2027
DI 10.1007/s10055-023-00791-2
EA MAR 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000961576000001
DA 2024-07-18
ER

PT J
AU Della Libera, C
   Simon, J
   Laroi, F
   Quertemont, E
   Wagener, A
AF Della Libera, Clara
   Simon, Jessica
   Laroi, Frank
   Quertemont, Etienne
   Wagener, Aurelie
TI Using 360-degree immersive videos to assess multiple transdiagnostic
   symptoms: A study focusing on fear of negative evaluation, paranoid
   thoughts, negative automatic thoughts, and craving
SO VIRTUAL REALITY
LA English
DT Article
DE 360-degree immersive video; Virtual reality; Transdiagnostic; Assessment
ID IDENTIFICATION TEST AUDIT; VIRTUAL-REALITY; SOCIAL PRESENCE; ALCOHOL;
   ENVIRONMENTS; DISORDERS; TOOL; COMPONENTS; BEHAVIOR; ANXIETY
AB Over the last 20 years, virtual reality (VR) has gained a great interest for both assessment and treatment of various psychopathologies. However, due to high costs and material specificity, VR remains disadvantageous for clinicians. Adopting a multiple transdiagnostic approach, this study aims at testing the validity of a 360-degree immersive video (360IV) for the assessment of five common psychological symptoms (fear of negative evaluation, paranoid thoughts, negative automatic thoughts, craving for alcohol and for nicotine). A 360IV was constructed in the Darius Cafe and included actors behaving naturally. One hundred and fifty-eight adults from the general population were assessed in terms of their proneness towards the five symptoms, were then exposed to the 360IV and completed measures for the five state symptoms, four dimensions of presence (place, plausibility, copresence and social presence illusions) and cybersickness. Results revealed that the five symptoms occurred during the immersion and were predicted by the participants' proneness towards these symptoms. The 360IV was also able to elicit various levels of the four dimensions of presence while producing few cybersickness. The present study provides evidence supporting the use of the 360IV as a new accessible, ecological, and standardized tool to assess multiple transdiagnostic symptoms.
C1 [Della Libera, Clara; Simon, Jessica; Laroi, Frank; Quertemont, Etienne; Wagener, Aurelie] Univ Liege, Psychol & Neurosci Cognit Res Unit PsyNCog, Liege, Belgium.
   [Laroi, Frank] Univ Bergen, Dept Biol & Med Psychol, Bergen, Norway.
   [Laroi, Frank] Univ Oslo, Norwegian Ctr Mental Disorders Res, Oslo, Norway.
   [Wagener, Aurelie] Univ Liege, Dept Psychol, Res Unit Life Course Perspect Hlth & Educ RUCHE, Hlth Psychol, Liege, Belgium.
C3 University of Liege; University of Bergen; University of Oslo;
   University of Liege
RP Wagener, A (corresponding author), Univ Liege, Psychol & Neurosci Cognit Res Unit PsyNCog, Liege, Belgium.; Wagener, A (corresponding author), Univ Liege, Dept Psychol, Res Unit Life Course Perspect Hlth & Educ RUCHE, Hlth Psychol, Liege, Belgium.
EM aurelie.wagener@uliege.be
OI Laroi, Frank/0000-0002-9876-7407; Quertemont,
   Etienne/0000-0002-9859-0779; Simon, Jessica/0000-0002-5966-2063;
   Wagener, Aurelie/0000-0001-5279-6547; Della Libera,
   Clara/0000-0001-6075-1912
FU Universite de Liege, BSH: Bourse des Sciences Humaines
FX This work was funded by Universite de Liege, BSH: Bourse des Sciences
   Humaines, Clara Della Libera.
CR [Anonymous], 2017, Saudi. Med. J., V38, P444
   [Anonymous], 2021, jamovi
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Barreda-Angeles M, 2020, VIRTUAL REAL-LONDON, V24, P289, DOI 10.1007/s10055-019-00400-1
   Bell IH, 2020, DIALOGUES CLIN NEURO, V22, P169, DOI 10.31887/DCNS.2020.22.2/lvalmaggia
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Bordnick P. S., 2019, Virtual reality for psychological and neurocognitive interventions, P131
   Bordnick PS, 2004, ADDICT BEHAV, V29, P1889, DOI 10.1016/j.addbeh.2004.06.008
   Bouchard S., 2011, Journal of Computer and Information Technology, V1, P20
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Castillo-Carniglia A, 2019, LANCET PSYCHIAT, V6, P1068, DOI 10.1016/S2215-0366(19)30222-6
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Cho S, 2008, CYBERPSYCHOL BEHAV, V11, P302, DOI 10.1089/cpb.2007.0149
   Cieslik B, 2020, COMPLEMENT THER MED, V52, DOI 10.1016/j.ctim.2020.102480
   Clara D, 2020, COGN NEUROPSYCHIATRY, V25, P387, DOI 10.1080/13546805.2020.1824868
   Dalgleish T, 2020, J CONSULT CLIN PSYCH, V88, P179, DOI 10.1037/ccp0000482
   Della Libera C, 2021, COGN NEUROPSYCHIATRY, V26, P357, DOI 10.1080/13546805.2021.1956885
   Dellazizzo L, 2020, J MED INTERNET RES, V22, DOI 10.2196/20889
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Douilliez C., 2008, REV FRANCOPHONE CLIN, V13, P1
   Emmelkamp PMG, 2020, CURR PSYCHIAT REP, V22, DOI 10.1007/s11920-020-01156-1
   Eurostat, 2019, Daily smokers of cigarettes by sex, age and educational attainment level
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Felnhofer A, 2019, CYBERPSYCH BEH SOC N, V22, P46, DOI 10.1089/cyber.2018.0221
   Field M, 2008, DRUG ALCOHOL DEPEN, V97, P1, DOI 10.1016/j.drugalcdep.2008.03.030
   FLEMING MF, 1991, INT J ADDICT, V26, P1173, DOI 10.3109/10826089109062153
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Freeman D, 2000, BRIT J CLIN PSYCHOL, V39, P407, DOI 10.1348/014466500163400
   Freeman D, 2007, CLIN PSYCHOL REV, V27, P425, DOI 10.1016/j.cpr.2006.10.004
   Freeman D, 2007, J NERV MENT DIS, V195, P781, DOI 10.1097/NMD.0b013e318145a0a9
   Freeman D, 2010, J ABNORM PSYCHOL, V119, P83, DOI 10.1037/a0017514
   FUHRER R, 1989, Psychiatrie and Psychobiologie, V4, P163
   Furmark T, 2002, ACTA PSYCHIAT SCAND, V105, P84, DOI 10.1034/j.1600-0447.2002.1r103.x
   Gache P, 2005, ALCOHOL CLIN EXP RES, V29, P2001, DOI 10.1097/01.alc.0000187034.58955.64
   Gamito P, 2014, CYBERPSYCH BEH SOC N, V17, P556, DOI 10.1089/cyber.2013.0329
   García-Rodríguez O, 2013, DRUG ALCOHOL DEPEN, V132, P479, DOI 10.1016/j.drugalcdep.2013.03.008
   Geraets CNW, 2021, CURR OPIN PSYCHOL, V41, P40, DOI 10.1016/j.copsyc.2021.02.004
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Green CEL, 2008, PSYCHOL MED, V38, P101, DOI 10.1017/S0033291707001638
   Green JA, 2021, HEALTH PSYCHOL BEHAV, V9, P436, DOI 10.1080/21642850.2021.1920416
   Harrington JA, 2002, J APPL SOC PSYCHOL, V32, P465, DOI 10.1111/j.1559-1816.2002.tb00225.x
   Holmberg TT, 2020, CYBERPSYCH BEH SOC N, V23, P495, DOI 10.1089/cyber.2019.0295
   Jung WM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183211
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kittel A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.563474
   Koyuncu Ahmet, 2019, Drugs Context, V8, P212573, DOI 10.7573/dic.212573
   Kreusch F, 2017, PSYCHIAT RES, V249, P232, DOI 10.1016/j.psychres.2017.01.019
   Lebreuilly R., 2019, J R COMPORT COGN, V29, P132, DOI [10.1016/j.jtcc.2019.01.003, DOI 10.1016/J.JTCC.2019.01.003]
   Lee JS, 2008, PSYCHIAT INVEST, V5, P239, DOI 10.4306/pi.2008.5.4.239
   Higuera-Trujillo JL, 2017, APPL ERGON, V65, P398, DOI 10.1016/j.apergo.2017.05.006
   Narciso D, 2019, UNIVERSAL ACCESS INF, V18, P77, DOI 10.1007/s10209-017-0581-5
   Nummenmaa L, 2014, P NATL ACAD SCI USA, V111, P646, DOI 10.1073/pnas.1321664111
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Pan X., 2008, PRESENCE 2008 11 ANN, P100
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pandita S., 2020, Technology and Health, P129, DOI [10.1016/B978- 0-12-816958-2.00007-1, DOI 10.1016/B978-0-12-816958-2.00007-1]
   Parsons TD, 2008, CYBERPSYCHOL BEHAV, V11, P17, DOI 10.1089/cpb.2007.9934
   Philippot P, 2019, CLIN PSYCHOL PSYCHOT, V26, P175, DOI 10.1002/cpp.2340
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   RADLOFF L S, 1977, Applied Psychological Measurement, V1, P385, DOI 10.1177/014662167700100306
   Rana M, 2017, J NEPAL MED ASSOC, V56, P248
   Reiss S., 1985, THEORETICAL ISSUES B, P107, DOI [10.4236/psych.2011.28125, DOI 10.4236/PSYCH.2011.28125]
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robillard G., 2002, 25E CONGRES ANNUEL S
   Robinson E, 2022, J AFFECT DISORDERS, V296, P567, DOI 10.1016/j.jad.2021.09.098
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Rus-Calafell M, 2018, PSYCHOL MED, V48, P362, DOI 10.1017/S0033291717001945
   SAUNDERS JB, 1993, ADDICTION, V88, P791, DOI 10.1111/j.1360-0443.1993.tb02093.x
   Scheveneels S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02849
   Schubert T., 1999, 2 INT WORKSH PRES, V1999
   Schutte NS, 2017, MOTIV EMOTION, V41, P708, DOI 10.1007/s11031-017-9641-7
   Segawa T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01409
   Serrano B., 2019, Virtual Reality and Anxiety Disorders Treatment: Evolution and Future Perspectives, P47, DOI [10.1007/978-1-4939-9482-3_3, DOI 10.1007/978-1-4939-9482-3_3, DOI 10.1007/978-1-4939-9482-3]
   Sigurvinsdottir R, 2021, BEHAV CHANGE, V38, P109, DOI 10.1017/bec.2021.4
   Simon J, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00124
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Spielberger CD., 1993, INVENTAIRE ANXIETE E
   Stupar-Rutenfrans S, 2017, CYBERPSYCH BEH SOC N, V20, P624, DOI 10.1089/cyber.2017.0174
   Tarnawski M., 2017, P SIGRAD 2017, V143, P9
   Thaipisuttikul P, 2014, NEUROPSYCH DIS TREAT, V10, P2097, DOI 10.2147/NDT.S72026
   von der Pütten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   WATSON D, 1969, J CONSULT CLIN PSYCH, V33, P448, DOI 10.1037/h0027806
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Health Organization, 2018, Global status report on alcohol and health 2018
   Yeo NL, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101500
NR 90
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3565
EP 3580
DI 10.1007/s10055-023-00779-y
EA MAR 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000946454000001
PM 37360803
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wang, P
   Wang, Y
   Billinghurst, M
   Yang, HZ
   Xu, P
   Li, YH
AF Wang, Peng
   Wang, Yue
   Billinghurst, Mark
   Yang, Huizhen
   Xu, Peng
   Li, Yanhong
TI BeHere: a VR/SAR remote collaboration system based on virtual replicas
   sharing gesture and avatar in a procedural task
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Spatial augmented reality; Virtual replicas or avatar;
   Remote collaboration; Hand gesture; Human-computer interaction
ID REALITY
AB In this paper, we focus on the significance of remote collaboration using virtual replicas, avatar, and gesture on a procedural task in industry; thus, we present a Virtual Reality (VR)/Spatial Augmented Reality (SAR) remote collaboration system, BeHere, based on 3D virtual replicas and sharing gestures and avatar. BeHere enables a remote expert in VR to guide a local worker in real-time to complete a procedural task in the real-world. For the remote VR site, we construct a 3D virtual environment using virtual replicas, and the user can manipulate them by using gestures in an intuitive interaction and see their partners' 3D virtual avatar. For the local site, we use SAR to enable the local worker to see instructions projected onto the real-world based on the shared virtual replicas and gestures. We conducted a formal user study to evaluate the prototype system in terms of performance, social presence, workload, and ranking and user preference. We found that the combination of visual cues of gestures, avatar, and virtual replicas plays a positive role in improving user experience, especially for remote VR users. More significantly, our study provides useful information and important design implications for further research on the use of gesture-, gaze- and avatar-based cues as well as virtual replicas in VR/AR remote collaboration on a procedural task in industry.
C1 [Wang, Peng; Wang, Yue] Chongqing Univ Posts & Telecommun, Sch Adv Mfg Engn, Chongqing 400065, Peoples R China.
   [Billinghurst, Mark] Univ Auckland, Auckland Bioengn Inst, Auckland, New Zealand.
   [Yang, Huizhen] Beijing Inst Technol, Chongqing Innovat Ctr, Beijing, Peoples R China.
   [Xu, Peng] Jiangsu JARI Technol Grp Co Ltd, Res Inst CSIC 716, Lianyungang, Jiang Su, Peoples R China.
   [Li, Yanhong] Jiuquan Iron & Steel Grp Co Ltd, Jiayuguan 735100, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; University of
   Auckland; Beijing Institute of Technology
RP Wang, P; Wang, Y (corresponding author), Chongqing Univ Posts & Telecommun, Sch Adv Mfg Engn, Chongqing 400065, Peoples R China.
EM ilovemymfandb@163.com; wang_yue@cqupt.edu.cn
RI .., What/IXW-6776-2023; JIN, LIYING/JFB-1980-2023; Liu,
   Yiming/ISU-3780-2023; Zhang, Wenbin/JXX-8070-2024; Yan,
   Jing/JFA-6705-2023; Yang, Jing/JFK-4046-2023; Xi, Yang/KEH-5204-2024;
   Liu, Shao/JFK-0166-2023; Yang, Lili/JTT-5215-2023; lu,
   qian/IUN-7445-2023; li, wl/JJC-0768-2023; Liu, Yuan/JFB-4766-2023; LI,
   YUN/JTV-7108-2023; li, jing/JEF-8436-2023; zhang, wb/JGM-5316-2023;
   Zhou, heng/JCN-6493-2023; xu, lingzhi/JVZ-8748-2024; Lin,
   Kuan-Yu/JXM-6653-2024; LIU, YUTING/JUV-1285-2023; Wang,
   Xingyu/JNE-0602-2023; Yang, Jie/JDM-6213-2023; WANG, HUI/JFA-9683-2023;
   FENG, X/JPL-4188-2023; Liu, Ying/ISU-1216-2023; Ma,
   Xiaodong/JAN-7473-2023; qi, li/JFE-7167-2023; Zhang,
   Zhentao/JQV-7389-2023; Wu, Wenli/IYJ-1598-2023; zhou,
   chen/KBC-4023-2024; Liu, DY/JPL-4171-2023; ying, liu/KEI-0478-2024; yan,
   xiao/JVP-0766-2024; liu, lin/JFK-3401-2023; LIU, LIYING/KAM-4121-2024;
   Jia, Li/JVN-3095-2024; Wang, He/JCO-3900-2023; Billinghurst,
   Mark/AAJ-4236-2020; LI, QI/IUM-8577-2023; lu, yang/IWE-3635-2023; liu,
   bing/JJD-5566-2023; li, jincheng/GQP-6856-2022; Zhang,
   Jinfan/JPK-7588-2023
OI Yang, Jing/0009-0004-8274-9863; Yang, Lili/0009-0008-2926-484X; Yang,
   Jie/0000-0002-3941-0053; Billinghurst, Mark/0000-0003-4172-6759; 
CR Anton D, 2018, FUTURE GENER COMP SY, V82, P77, DOI 10.1016/j.future.2017.12.055
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Barroso J, 2020, EUR 30185 EN, DOI [10.2760/091625, DOI 10.2760/091625, 10.2760/80554, JRC120199]
   Billinghurst M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.578080
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Calandra D, 2021, INT J ADV MANUF TECH, V114, P3147, DOI 10.1007/s00170-021-06871-4
   Chen L., 2021, P 2021 ACM S SPAT US, DOI DOI 10.1145/3485279.3485297
   de Belen R. A. J., 2019, AIMS ELECT ELECT ENG, V3, P181, DOI [DOI 10.3934/ELECTRENG.2019.2.181, 10.3934/electreng.2019.2.181]
   De Pace F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00018
   Elvezio C., 2017, ACM SIGGRAPH 2017 VR Village, SIGGRAPH '17, P1
   Elvezio C, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P180, DOI 10.1109/ISMAR.2015.54
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Gamelin G, 2021, PERS UBIQUIT COMPUT, V25, P467, DOI 10.1007/s00779-020-01431-1
   Garbett J, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103487
   Harms C., 2004, Seventh Annual International Workshop: Presence 2004
   HART S G, 1988, P139
   Hietanen A, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101891
   Higuch K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5180, DOI 10.1145/2858036.2858438
   Huang R, 2015, COMPUT IND, V67, P38, DOI 10.1016/j.compind.2014.12.001
   Huang WD, 2018, J MULTIMODAL USER IN, V12, P77, DOI 10.1007/s12193-017-0250-2
   Jasche Florian, 2021, C&T '21: Proceedings of the 10th International Conference on Communities & Technologies - Wicked Problems in the Age of Tech, P200, DOI 10.1145/3461564.3461566
   Kim S, 2020, IEEE ACCESS, V8, P224145, DOI 10.1109/ACCESS.2020.3043783
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kritzler M, 2016, P 6 INT C INT THINGS, P7, DOI 10.1145/2991561.2991571
   Kurillo G, 2013, VIRTUAL REAL-LONDON, V17, P29, DOI 10.1007/s10055-012-0217-2
   Marques B, 2022, COMPUT GRAPH-UK, V102, P413, DOI 10.1016/j.cag.2021.10.009
   Marques B, 2022, IEEE T VIS COMPUT GR, V28, P5113, DOI 10.1109/TVCG.2021.3101545
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186495
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Pringle A, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P236, DOI 10.1109/ISMAR-Adjunct.2018.00075
   Russo M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156800
   Sukan M, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P89, DOI 10.1145/2983310.2985764
   Teo T, 2020, J MULTIMODAL USER IN, V14, P373, DOI 10.1007/s12193-020-00343-x
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Wang P., 2019, 2019 IEEE 30 ANN INT, P1, DOI DOI 10.1109/ICCE-TW46550.2019.8991949
   Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071
   Wang P, 2020, INTERACT COMPUT, V32, P153, DOI 10.1093/iwcomp/iwaa012
   Wang P, 2020, ENG COMPUT-GERMANY, V36, P1715, DOI 10.1007/s00366-019-00792-3
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P31059, DOI 10.1007/s11042-020-09731-7
   Wang P, 2019, INT J ADV MANUF TECH, V105, P3031, DOI 10.1007/s00170-019-04434-2
   Wang P, 2019, INT J ADV MANUF TECH, V102, P1339, DOI 10.1007/s00170-018-03237-1
   Wang PM, 2020, INTERFACING BIOELECTRONICS AND BIOMEDICAL SENSING, P1, DOI 10.1007/978-3-030-34467-2_1
   Wang Y, 2022, INT J ADV MANUF TECH, V119, P6413, DOI 10.1007/s00170-022-08747-7
   Yang J, 2020, J MULTIMODAL USER IN, V14, P337, DOI 10.1007/s12193-020-00331-1
   Zhang XY, 2022, INT J ADV MANUF TECH, V121, P7697, DOI 10.1007/s00170-022-09654-7
NR 50
TC 7
Z9 7
U1 5
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1409
EP 1430
DI 10.1007/s10055-023-00748-5
EA JAN 2023
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000912383400001
PM 36686612
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU De Paolis, LT
   Gatto, C
   Corchia, L
   De Luca, V
AF De Paolis, Lucio Tommaso
   Gatto, Carola
   Corchia, Laura
   De Luca, Valerio
TI Usability, user experience and mental workload in a mobile Augmented
   Reality application for digital storytelling in cultural heritage
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented Reality; Mobile; Digital storytelling; Cultural heritage;
   Usability; User experience; Mental workload
ID INTERNAL STRUCTURE; ENTERTAINMENT; ROTATION
AB Augmented Reality (AR) has become an increasingly used technology to support and enhance the enjoyment of cultural heritage. Particularly relevant is its importance for digital storytelling: by framing a portion of a fresco or painting with a smartphone, an AR mobile application can provide contextually relevant information, also in the form of multimedia content, that can help the user to understand the story and meaning behind the images. In this type of application, human factors are of fundamental importance for the effectiveness of the narrative: a mobile AR application must avoid distracting the user's attention from the content in order to encourage a good level of concentration and immersion. The case study presented in this paper deals with a mobile AR application developed to guide visitors in the interpretation of the frescoes inside the Basilica of Saint Catherina of Alexandria in Galatina. The aim of the study is the analysis of the relations among usability, user experience and mental workload factors in AR-based digital storytelling.
C1 [De Paolis, Lucio Tommaso; De Luca, Valerio] Univ Salento, Dept Engn Innovat, Lecce, Italy.
   [Gatto, Carola; Corchia, Laura] Univ Salento, Dept Cultural Heritage, Lecce, Italy.
C3 University of Salento; University of Salento
RP De Luca, V (corresponding author), Univ Salento, Dept Engn Innovat, Lecce, Italy.
EM lucio.depaolis@unisalento.it; carola.gatto@unisalento.it;
   laura.corchia1@unisalento.it; valerio.deluca@unisalento.it
RI De Luca, Valerio/HGJ-6239-2022; De Paolis, Lucio Tommaso/R-2421-2016
OI De Paolis, Lucio Tommaso/0000-0003-1274-9070; Gatto,
   Carola/0000-0002-6070-0848; Corchia, Laura/0000-0002-4461-4149; De Luca,
   Valerio/0000-0003-3018-7251
FU Universita del Salento within the CRUI-CARE Agreement
FX Open access funding provided by Universita del Salento within the
   CRUI-CARE Agreement. The authors received no funding for conducting this
   study.
CR [Anonymous], 2021, HALL FRESC PAL COM T
   [Anonymous], 2021, TERR WARR 1 EMP
   [Anonymous], 2009, 9241 210 2010 ERGONO, DOI DOI 10.3403/30388991
   [Anonymous], 2007, RTOTRHFM121 2
   Assila A., 2016, Electronic Journal of Computer Science and Information Technology, V6, DOI DOI 10.1016/B978-0-12-384968-7.00008-4
   Bartsch A, 2014, J MEDIA PSYCHOL-GER, V26, P125, DOI 10.1027/1864-1105/a000118
   Bartsch A, 2012, MEDIA PSYCHOL, V15, P267, DOI 10.1080/15213269.2012.693811
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Bonacini E., 2014, STUDIES VALUE CULTUR, P89
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Boskovic D, 2017, MEASURING IMMERSION, V2017, P1, DOI [10.1109/ICAT.2017.8171604, DOI 10.1109/ICAT.2017.8171604]
   Botrugno MC, 2017, LECT NOTES COMPUT SC, V10325, P261, DOI 10.1007/978-3-319-60928-7_23
   Bozzelli Guido, 2019, Digital Applications in Archaeology and Cultural Heritage, V15, DOI 10.1016/j.daach.2019.e00124
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Busselle R, 2009, MEDIA PSYCHOL, V12, P321, DOI 10.1080/15213260903287259
   Casciaro RDSM., 2017, BASILICA SANTA CATER
   Castaldo D., 2006, IMMAGINI MUSICA TEMP
   Cervellini F, 2011, DISEGNARECON, V4, P48
   Cisternino D, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3460657
   Cisternino D, 2019, LECT NOTES COMPUT SC, V11614, P264, DOI 10.1007/978-3-030-25999-0_23
   Cisternino D, 2018, LECT NOTES COMPUT SC, V10851, P370, DOI 10.1007/978-3-319-95282-6_27
   Cooksey RW, 2006, ORGAN RES METHODS, V9, P78, DOI 10.1177/1094428105283939
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   Cuciniello A., 2014, AGLI INTENDENTI AMMI
   Damala A, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3297717
   De Paolis L. T., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P169, DOI 10.1109/ICCSN.2011.6013802
   De Paolis L. T., 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P524, DOI 10.1109/ICCRD.2011.5763914
   De Paolis LT, 2010, THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS: ACHI 2010, P130, DOI 10.1109/ACHI.2010.29
   De Paolis LT, 2022, INFORMATION, V13, DOI 10.3390/info13030122
   De Paolis LT, 2021, LECT NOTES COMPUT SC, V12980, P326, DOI 10.1007/978-3-030-87595-4_24
   De Paolis LT, 2019, LECT NOTES COMPUT SC, V11614, P348, DOI 10.1007/978-3-030-25999-0_30
   De Paolis LT, 2018, LECT NOTES COMPUT SC, V10851, P320, DOI 10.1007/978-3-319-95282-6_24
   De Paolis LT, 2013, LECT NOTES COMPUT SC, V7971, P632, DOI 10.1007/978-3-642-39637-3_50
   Georgiou Y, 2017, INT J HUM-COMPUT ST, V98, P24, DOI 10.1016/j.ijhcs.2016.09.014
   Hajesmaeel-Gohari S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01407-y
   HENDRICKSON AE, 1964, BRIT J STATIST PSYCH, V17, P65, DOI 10.1111/j.2044-8317.1964.tb00244.x
   Herman David., 2007, Routledge Encyclopedia of Narrative Theory
   International Organisation for Standardisation, 2018, 9241112018E ISO, P2
   Jin YS, 2022, MULTIMED TOOLS APPL, V81, P5795, DOI 10.1007/s11042-021-11723-0
   KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233
   Kline P., 2002, EASY GUIDE FACTOR AN
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P1148, DOI 10.1080/10447318.2017.1418805
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Lin ACH, 2012, DECIS SUPPORT SYST, V53, P846, DOI 10.1016/j.dss.2012.05.020
   MAUA Museum, 2021, MAUA CITTA MUS CIEL
   Miller C.H., 2019, Digital Storytelling 4e: A creator's guide to interactive entertainment
   Montinari M., 1978, BASILICA CATERINIANA
   Moustafa K., 2017, INT S HUM MENT WORKL, P30, DOI [10. 1007/978-3-319-61061-0_3, DOI 10.1007/978-3-319-61061-0_3]
   Murray JH, 2017, HAMLET ON THE HOLODECK: THE FUTURE OF NARRATIVE IN CYBERSPACE, P1
   Nasa NA, 2010, PLANTA MED
   Okanovic V, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031241
   Oliver MB, 2011, J COMMUN, V61, P984, DOI 10.1111/j.1460-2466.2011.01585.x
   Ping J, 2020, STUDY MOBILE AR GUID, P79, DOI [10.1109/ICVRV51359.2020.00027, DOI 10.1109/ICVRV51359.2020.00027]
   PorterAbbott H, 2014, CAMBRIDGE INTRO NARR, DOI [10.1017/CBO9780511816932, DOI 10.1017/CBO9780511816932]
   PTC, 2021, VUF ENG DEV PORT
   REVELLE W, 1978, BEHAV RES METH INSTR, V10, P739, DOI 10.3758/BF03205389
   REVELLE W, 1979, MULTIVAR BEHAV RES, V14, P57, DOI 10.1207/s15327906mbr1401_4
   Roth Christian., 2016, Evaluating the User Experience of Interactive Digital Narrative, DOI DOI 10.1145/2983298.2983302
   Ryan Marie-Laure., 2006, Avatars of Story
   Santos M. E. C., 2014, P 20 ACM S VIRT REAL, P167, DOI DOI 10.1145/2671015.2671019
   Santos MEC, 2015, IEEE COMPUT GRAPH, V35, P66, DOI 10.1109/MCG.2015.94
   Shilkrot R, 2014, INT SYM MIX AUGMENT, P35, DOI 10.1109/ISMAR-AMH.2014.6935436
   Thurstone L. L, 1947, Multiple factor analysis
   Unity Technologies, 2021, UN TECHN
   Vacca N, 1955, NUPTIAE SALLENTINAE
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Vert S, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212678
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Yu Liu, 2021, Intelligent Technologies for Interactive Entertainment. 12th EAI International Conference, INTETAIN 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 377), P229, DOI 10.1007/978-3-030-76426-5_15
   Zoellner M, 2007, 8 INT S VIRT REAL AR, P110
NR 73
TC 5
Z9 6
U1 17
U2 47
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1117
EP 1143
DI 10.1007/s10055-022-00712-9
EA NOV 2022
PG 27
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000884145500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Reese, G
   Stahlberg, J
   Menzel, C
AF Reese, Gerhard
   Stahlberg, Jasmin
   Menzel, Claudia
TI Digital shinrin-yoku: do nature experiences in virtual reality reduce
   stress and increase well-being as strongly as similar experiences in a
   physical forest?
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Restoration; Stress; Shinrin-yoku; Urban forest
ID EXPOSURE; ENVIRONMENTS; RECOVERY; BENEFITS; ATTENTION; SICKNESS; MOTION;
   GREEN; ANGER
AB Shinrin-yoku or forest bathing refers to a therapeutic, immersive nature experience that aids to improve well-being. The goal of the current research was to compare the effects of a physical urban nature versus virtual nature experience on stress, affect, vitality, and restoration. Previous research suggested that an immersive nature experience-such as shinrin-yoku-can be beneficial for health, but direct comparisons between physical and virtual reality (VR) experiences are scarce. In the current study, fifty participants navigated self-paced through a forest scene that was either an urban physical forest or an immersive VR forest with similar characteristics as the physical one. Before and after the intervention, we measured positive and negative affect, subjective vitality, and perceived daily stress. After the intervention, we measured perceived restorative outcomes. Results revealed that both VR and physical nature experience resulted in expected effects on well-being indicators: Affect was more positive and less negative, subjective vitality increased slightly, and stress decreased slightly after both interventions. There were no significant differences between the two settings on any of the variables, but slightly stronger effect sizes over time within the physical condition. Overall, these findings suggest that immersive VR nature experiences can have restoration effects similar to physical nature experiences, suggesting intervention strategies when physical nature options are scarce.
C1 [Reese, Gerhard; Stahlberg, Jasmin; Menzel, Claudia] Univ Koblenz Landau, Dept Social Environm & Econ Psychol, Inst Psychol, Campus Landau,Fortstr 7, D-76829 Landau, Germany.
C3 University of Koblenz & Landau
RP Reese, G (corresponding author), Univ Koblenz Landau, Dept Social Environm & Econ Psychol, Inst Psychol, Campus Landau,Fortstr 7, D-76829 Landau, Germany.
EM reese@uni-landau.de
OI Menzel, Claudia/0000-0003-1156-5392; Reese, Gerhard/0000-0001-6672-3832;
   Stahlberg, Jasmin/0000-0003-3975-7687
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Alvarsson JJ, 2010, INT J ENV RES PUB HE, V7, P1036, DOI 10.3390/ijerph7031036
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   [Anonymous], 2019, BETHESDA SOFTWORKS L
   [Anonymous], 2019, Constitution of the World Health Organization
   Authors, EXPERIENCE CON UNPUB
   Barton J, 2010, ENVIRON SCI TECHNOL, V44, P3947, DOI 10.1021/es903183r
   Becker DA, 2019, URBAN FOR URBAN GREE, V41, P39, DOI 10.1016/j.ufug.2019.02.012
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Berto R, 2005, J ENVIRON PSYCHOL, V25, P249, DOI 10.1016/j.jenvp.2005.07.001
   Bertrams A., 2019, OPEN PSYCHOL, DOI 10.31234/osf.io/c3bwu
   Bratman GN, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aax0903
   Breyer B., 2016, Zusammenstellung sozialwissenschaftlicher Items und Skalen (ZIS), DOI DOI 10.6102/ZIS242
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Brown DK, 2013, ENVIRON SCI TECHNOL, V47, P5562, DOI 10.1021/es305019p
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Chan SHM, VIRTUAL REAL-LONDON
   Chirico A, 2021, VIRTUAL REAL-LONDON, V25, P107, DOI 10.1007/s10055-020-00442-w
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Crone Diane, 2007, Issues Ment Health Nurs, V28, P167, DOI 10.1080/01612840601096453
   de Lange Annet H, 2003, J Occup Health Psychol, V8, P282, DOI 10.1037/1076-8998.8.4.282
   Dziuda L, 2014, APPL ERGON, V45, P406, DOI 10.1016/j.apergo.2013.05.003
   Engemann K, 2019, P NATL ACAD SCI USA, V116, P5188, DOI 10.1073/pnas.1807504116
   Franco LS, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14080864
   Gamble KR, 2014, EXP AGING RES, V40, P513, DOI 10.1080/0361073X.2014.956618
   Gerber SM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13153-1
   Gladwell VF, 2012, EUR J APPL PHYSIOL, V112, P3379, DOI 10.1007/s00421-012-2318-8
   Gross, 2014, 45 NEPS
   Hansen MM, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14080851
   Harth NS, 2013, J ENVIRON PSYCHOL, V34, P18, DOI 10.1016/j.jenvp.2012.12.005
   Hartig T, 1996, SCAND J PSYCHOL, V37, P378, DOI 10.1111/j.1467-9450.1996.tb00670.x
   Hartig T, 2014, ANNU REV PUBL HEALTH, V35, P207, DOI 10.1146/annurev-publhealth-032013-182443
   Hauru K, 2012, LANDSCAPE URBAN PLAN, V107, P361, DOI 10.1016/j.landurbplan.2012.07.002
   Hedblom M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46099-7
   Hu M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85210-9
   Ilies R, 2007, J APPL PSYCHOL, V92, P1368, DOI 10.1037/0021-9010.92.5.1368
   Kabisch N, 2017, ENVIRON RES, V159, P362, DOI 10.1016/j.envres.2017.08.004
   KAPLAN R, 1989, ENVIRON BEHAV, V21, P509, DOI 10.1177/0013916589215001
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Korpela KM, 2008, HEALTH PLACE, V14, P636, DOI 10.1016/j.healthplace.2007.10.008
   Kuo FE, 2001, ENVIRON BEHAV, V33, P543, DOI 10.1177/00139160121973124
   Kuo M, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpg.2015.01093, 10.3389/fpsyg.2015.01093]
   Landmann H, 2020, J ENVIRON PSYCHOL, V71, DOI 10.1016/j.jenvp.2020.101491
   Mackay CML, 2019, J ENVIRON PSYCHOL, V65, DOI 10.1016/j.jenvp.2019.101323
   Mattila O, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106295
   Menardo E, 2021, PSYCHOL REP, V124, P417, DOI 10.1177/0033294119884063
   Mygind L, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00943
   Ohly H, 2016, J TOXICOL ENV HEAL B, V19, P305, DOI 10.1080/10937404.2016.1196155
   Pasini M, 2014, PROCD SOC BEHV, V159, P293, DOI 10.1016/j.sbspro.2014.12.375
   Pritchard A, 2020, J HAPPINESS STUD, V21, P1145, DOI 10.1007/s10902-019-00118-6
   Reese G, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041995
   Reese G, 2015, ENVIRON SCI POLICY, V51, P88, DOI 10.1016/j.envsci.2015.03.011
   Ryan RM, 1997, J PERS, V65, P529, DOI 10.1111/j.1467-6494.1997.tb00326.x
   Rybråten S, 2019, LANDSCAPE RES, V44, P62, DOI 10.1080/01426397.2017.1400527
   Scannell L, 2010, J ENVIRON PSYCHOL, V30, P1, DOI 10.1016/j.jenvp.2009.09.006
   Scates D, 2020, ENVIRON BEHAV, V52, P895, DOI 10.1177/0013916520916259
   Stevenson MP, 2018, J TOXICOL ENV HEAL B, V21, P227, DOI 10.1080/10937404.2018.1505571
   Tanja-Dijkstra K, 2018, ENVIRON BEHAV, V50, P599, DOI 10.1177/0013916517710077
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Valtchanov D., 2010, J Cyber Ther Rehabil, V3, P359
   van den Berg MMHE, 2015, INT J ENV RES PUB HE, V12, P15860, DOI 10.3390/ijerph121215026
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wullenkord MC, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01442
   Yarkoni T, 2009, PERSPECT PSYCHOL SCI, V4, P294, DOI 10.1111/j.1745-6924.2009.01127.x
   Yu CP, 2018, URBAN FOR URBAN GREE, V35, P106, DOI 10.1016/j.ufug.2018.08.013
   Zelenski JM, 2015, J ENVIRON PSYCHOL, V42, P24, DOI 10.1016/j.jenvp.2015.01.005
NR 67
TC 38
Z9 38
U1 16
U2 96
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1245
EP 1255
DI 10.1007/s10055-022-00631-9
EA FEB 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000750684800001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Câmara, J
   Ferreira, R
   Teixeira, L
   Nóbrega, J
   Romeira, C
   Badia, SBI
   Faria, AL
AF Camara, Joana
   Ferreira, Rute
   Teixeira, Liliana
   Nobrega, Joana
   Romeira, Carina
   Badia, Sergi Bermudez, I
   Faria, Ana Lucia
TI Efficacy of adaptive cognitive training through desktop virtual reality
   and paper-and-pencil in the treatment of mental and behavioral disorders
SO VIRTUAL REALITY
LA English
DT Article
DE Cognitive training; Desktop virtual reality; Ecological validity;
   Psychiatric setting; Mental and behavioral disorders
ID MAJOR DEPRESSIVE DISORDER; OLDER-ADULTS; SCHIZOPHRENIA; DYSFUNCTION;
   IMPAIRMENT; DEFICITS; BRAIN
AB Cognitive deficits are a core feature of mental and behavioral disorders, leading to poor treatment adherence and functionality. Virtual reality (VR) methodologies are promising solutions for cognitive interventions in psychiatry once they provide greater ecological validity. This study assessed and compared two content-equivalent cognitive training (CT) interventions, delivered in desktop VR (Reh@City v2.0) and paper-and-pencil (Task Generator (TG)) formats, in patients with mental and behavioral disorders. 30 patients were randomly assigned to the Reh@City v2.0 group and the TG group. Both groups of patients underwent a time-matched 24-sessions intervention. Neuropsychological assessments were performed at baseline, post-intervention, and follow-up. A within-groups analysis revealed significant improvements in visual memory and depressive symptomatology after the Reh@City intervention. The TG group improved in processing speed, verbal memory, and quality of life (social relationships and environmental domains). Between groups, Reh@City led to a greater reduction in depressive symptomatology, whereas the TG group showed higher improvements in social relationships aspects of quality of life. At follow-up, previous gains were maintained and new improvements found in the Reh@City (global cognitive function, language, visuospatial and executive functions) and the TG groups (attention). The Reh@City significantly reduced depressive symptomatology, and the TG led to greater improvements in processing speed, abstraction, and social relationships domain of quality of life at follow-up. Both interventions were associated with important cognitive, emotional, and quality of life benefits, which were maintained after two months. Reh@City and TG should be considered as complementary CT methods for patients with mental and behavioral disorders. Trial registration The trial is registered at ClinicalTrials.gov, number NCT04291586.
C1 [Camara, Joana; Ferreira, Rute; Teixeira, Liliana; Nobrega, Joana; Romeira, Carina] Casa Saude Camara Pestana, Rua Lazareto, P-9060378 Funchal, Madeira, Portugal.
   [Camara, Joana] Univ Coimbra, Fac Psicol & Ciencias Educ, Rua Colegio Novo, P-3000115 Coimbra, Portugal.
   [Camara, Joana; Badia, Sergi Bermudez, I; Faria, Ana Lucia] Univ Nova Lisboa, NOVA Lab Comp Sci & Informat, P-2829516 Caparica, Portugal.
   [Badia, Sergi Bermudez, I] Univ Madeira, Ctr Ciencias Exatas & Engn, P-9020105 Funchal, Portugal.
   [Camara, Joana; Badia, Sergi Bermudez, I; Faria, Ana Lucia] Univ Madeira, Madeira Interact Technol Inst, P-9020105 Funchal, Madeira, Portugal.
C3 Universidade de Coimbra; Universidade Nova de Lisboa; Universidade da
   Madeira; Universidade da Madeira
RP Câmara, J (corresponding author), Casa Saude Camara Pestana, Rua Lazareto, P-9060378 Funchal, Madeira, Portugal.; Câmara, J (corresponding author), Univ Coimbra, Fac Psicol & Ciencias Educ, Rua Colegio Novo, P-3000115 Coimbra, Portugal.; Câmara, J (corresponding author), Univ Nova Lisboa, NOVA Lab Comp Sci & Informat, P-2829516 Caparica, Portugal.; Câmara, J (corresponding author), Univ Madeira, Madeira Interact Technol Inst, P-9020105 Funchal, Madeira, Portugal.
EM joana.fcamara@gmail.com
RI Teixeira, Liliana/M-3097-2019; Ferreira, Rute AS/F-4562-2011; Faria, Ana
   Lúcia/AFL-9137-2022; Badia, Sergi Bermúdez i/C-8681-2018
OI Teixeira, Liliana/0000-0002-2033-1929; Ferreira, Rute
   AS/0000-0003-1085-7836; Faria, Ana Lúcia/0000-0001-5904-0304; Badia,
   Sergi Bermúdez i/0000-0003-4452-0414; Freitas Camara,
   Joana/0000-0002-4330-7702
FU Fundacao para a Ciencia e Tecnologia (FCT) [PTDC/CCICOM/30990/2017,
   SFRH/BD/145919/2019, MAC/1.1.b/098]; NOVA Laboratory of Computer Science
   and Informatics [UID/CEC/04516/2019]; Fundação para a Ciência e a
   Tecnologia [UID/CEC/04516/2019, SFRH/BD/145919/2019] Funding Source: FCT
FX This work was supported by the FundacAo para a Ciencia e Tecnologia
   (FCT) through the Belief Revision applied to Neurorehabilitation (BRaNT)
   project (PTDC/CCICOM/30990/2017), the Development and clinical
   validation of an adaptive cognitive training virtual tool for stroke
   patients project (SFRH/BD/145919/2019), which is a PhD Grant awarded to
   Joana Camara, and the MACBIOIDI projects (MAC/1.1.b/098), and by the
   NOVA Laboratory of Computer Science and Informatics
   (UID/CEC/04516/2019).
CR American Psychological Association, 2010, GLOB MENT HEALTH
   [Anonymous], 2015, P 3 2015 WORKSH ICTS
   [Anonymous], 2009, WECHSLER MEMORY SCAL
   Beck AT., 1996, MANUAL BECK DEPRESSI, P1, DOI DOI 10.1037/T00742-000
   BRAMER G R, 1988, World Health Statistics Quarterly, V41, P32
   Cavaco S, 2013, ARCH CLIN NEUROPSYCH, V28, P262, DOI 10.1093/arclin/act001
   Chan CLF, 2010, INT J GERIATR PSYCH, V25, P643, DOI 10.1002/gps.2403
   Cieslik B, 2020, COMPLEMENT THER MED, V52, DOI 10.1016/j.ctim.2020.102480
   Cohen J., 1988, STAT POWER ANAL BEHA
   Coyle H, 2015, AM J GERIAT PSYCHIAT, V23, P335, DOI 10.1016/j.jagp.2014.04.009
   Faria A.L., 2019, 2019 International Conference on Virtual Rehabilitation, P1, DOI [10.1109/ic vr46560.2019.8994746, DOI 10.1109/ICVR46560.2019.8994746]
   FARIA AL, 2020, IN PRESS
   Faria AL., 2018, JMIR REHABIL ASSIST, V5, DOI 10.2196/10714
   Faria AL, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0204-z
   Freitas S, 2011, J CLIN EXP NEUROPSYC, V33, P989, DOI 10.1080/13803395.2011.589374
   Gamito P, 2017, DISABIL REHABIL, V39, P385, DOI 10.3109/09638288.2014.934925
   Green MF, 2006, J CLIN PSYCHIAT, V67, P3, DOI 10.4088/JCP.1006e12
   Groves SJ, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00382
   Grynszpan O, 2011, PSYCHOL MED, V41, P163, DOI 10.1017/S0033291710000607
   Harvey Philip D, 2011, Innov Clin Neurosci, V8, P14
   Iosifescu DV, 2012, EUR NEUROPSYCHOPHARM, V22, pS499, DOI 10.1016/j.euroneuro.2012.08.002
   Kim BR, 2011, ANN REHABIL MED-ARM, V35, P450, DOI 10.5535/arm.2011.35.4.450
   Kim EJ, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00461
   Maggio MG, 2019, J NEUROSCI NURS, V51, P101, DOI 10.1097/JNN.0000000000000423
   Maier M, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-0652-3
   Marques A, 2008, P INT C DIS VIRT REA, P39
   McCleery A, 2019, DIALOGUES CLIN NEURO, V21, P239, DOI 10.31887/DCNS.2019.21.3/amccleery
   McIntyre RS, 2013, DEPRESS ANXIETY, V30, P515, DOI 10.1002/da.22063
   Millan MJ, 2012, NAT REV DRUG DISCOV, V11, P141, DOI 10.1038/nrd3628
   Motter JN, 2016, J AFFECT DISORDERS, V189, P184, DOI 10.1016/j.jad.2015.09.022
   Oliveira J, 2022, DISABIL REHABIL-ASSI, V17, P298, DOI 10.1080/17483107.2020.1749891
   Ormel J, 2008, BRIT J PSYCHIAT, V192, P368, DOI 10.1192/bjp.bp.107.039107
   Park MJ, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00505
   Parsons T.D., 2016, Clinical Neuropsychology and Technology: What's New and How We Can Use It, DOI DOI 10.1007/978-3-319-31075-6
   Paulino Teresa, 2019, 2019 5th Experiment@ International Conference (exp.at'19). Proceedings, P292, DOI 10.1109/EXPAT.2019.8876539
   Plagia F., 2013, ANN REV CYBER THERAP, DOI 10.3233/978-1-61499-282-0-110
   Prikke M, 2019, SCHIZOPHR RES, V204, P368, DOI 10.1016/j.schres.2018.07.034
   Rand D, 2005, ANN REV CYBERTHERAPY, V3, P193
   Reichenberg A, 2009, SCHIZOPHRENIA BULL, V35, P1022, DOI 10.1093/schbul/sbn044
   Rey A, 1998, TESTE COPIA FIGURAS
   Ritchie H., 2018, PLASTIC POLLUTION
   Robinson LJ, 2006, J AFFECT DISORDERS, V93, P105, DOI 10.1016/j.jad.2006.02.016
   Rock PL, 2014, PSYCHOL MED, V44, P2029, DOI 10.1017/S0033291713002535
   Serra AV, 2006, PSIQUIATRIA CLIN, V27, P41
   Toulouse E, 1986, TOULOUSE PIERON TEST
   Wechsler D., 2008, Wechsler Adult Intelligence Scale, V4th, DOI DOI 10.1037/T15169-000
   Wittchen HU, 2011, EUR NEUROPSYCHOPHARM, V21, P655, DOI 10.1016/j.euroneuro.2011.07.018
   Yang S, 2014, ANN REHABIL MED-ARM, V38, P726, DOI 10.5535/arm.2014.38.6.726
   Zajac-Lamparska L, 2019, BMC RES NOTES, V12, DOI 10.1186/s13104-019-4810-2
NR 49
TC 8
Z9 8
U1 6
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 291
EP 306
DI 10.1007/s10055-021-00559-6
EA AUG 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000682434800001
DA 2024-07-18
ER

PT J
AU Lemmens, JS
   Simon, M
   Sumter, SR
AF Lemmens, Jeroen S.
   Simon, Monika
   Sumter, Sindy R.
TI Fear and loathing in VR: the emotional and physiological effects of
   immersive games
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Video games; Presence; Fear; Aggression; Physiological;
   Measurements
ID REALITY EXPOSURE THERAPY; HEART-RATE-VARIABILITY; VIRTUAL-REALITY; VIDEO
   GAMES; AROUSAL; SENSE; QUESTIONNAIRE; ENVIRONMENTS; ENJOYMENT; FEELINGS
AB Compared to traditional screen-based media, virtual reality (VR) generally leads to stronger feelings of presence. The current study aimed to investigate whether playing games in VR resulted in a stronger sense of presence than playing on a TV, and whether these feelings of presence affected players' emotional and physiological responses to the games. Two experiments were conducted among 128 students, comparing the effects of playing either a survival horror game (N = 59) or a first-person shooter (N = 69) on a TV or in VR on physiological and subjective fear, hostility and enjoyment. Results showed that playing games in VR resulted in a stronger sense of presence, lower heart rate variability and a stronger subjective sense of fear. The feeling of presence thereby mediated the effects of VR on fear. The effects of playing a first-person shooter in VR on hostility were mixed, and gaming in VR was not more enjoyable than on TV. Regardless of the type of game or display medium, hostility increased significantly post-play. This study provides evidence that commercial VR games can affect feelings of presence and the physiological and emotional state of players.
C1 [Lemmens, Jeroen S.; Simon, Monika; Sumter, Sindy R.] Univ Amsterdam, Amsterdam Sch Commun Res, Amsterdam, Netherlands.
C3 University of Amsterdam
RP Lemmens, JS (corresponding author), Univ Amsterdam, Amsterdam Sch Commun Res, Amsterdam, Netherlands.
EM j.s.lemmens@uva.nl; m.simon@uva.nl; s.r.sumter@uva.nl
RI Sumter, S. R./E-7745-2010
CR Alghamdi M, 2017, BEHAV INFORM TECHNOL, V36, P913, DOI 10.1080/0144929X.2017.1311374
   Alshaer A, 2017, APPL ERGON, V58, P1, DOI 10.1016/j.apergo.2016.05.003
   Anderson CA, 2009, J EXP SOC PSYCHOL, V45, P731, DOI 10.1016/j.jesp.2009.04.019
   Andrade EB, 2007, J CONSUM RES, V34, P283, DOI 10.1086/519498
   Appelhans BM, 2006, REV GEN PSYCHOL, V10, P229, DOI 10.1037/1089-2680.10.3.229
   Bardo MT, 1996, BEHAV BRAIN RES, V77, P23, DOI 10.1016/0166-4328(95)00203-0
   Barrett LF, 2007, ANNU REV PSYCHOL, V58, P373, DOI 10.1146/annurev.psych.58.110405.085709
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Botella C, 2015, NEUROPSYCH DIS TREAT, V11, P2533, DOI 10.2147/NDT.S89542
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Cacioppo J.T., 2000, Handbook of Emotions, P173
   Cardos RAI, 2017, COMPUT HUM BEHAV, V72, P371, DOI 10.1016/j.chb.2017.03.007
   Carnagey NL, 2005, PSYCHOL SCI, V16, P882, DOI 10.1111/j.1467-9280.2005.01632.x
   Chang J, 2020, TELEMAT INFORM, V51, DOI 10.1016/j.tele.2020.101407
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Czernuszenko M., 1997, Computer Graphics, V31, P46, DOI 10.1145/271283.271303
   Diemer J, 2016, J ANXIETY DISORD, V37, P30, DOI 10.1016/j.janxdis.2015.10.007
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Emmelkamp PMG, 2020, CURR PSYCHIAT REP, V22, DOI 10.1007/s11920-020-01156-1
   Freeman J., 2005, PRESENCE, P213
   Fritz MS, 2007, PSYCHOL SCI, V18, P233, DOI 10.1111/j.1467-9280.2007.01882.x
   Gamelin FX, 2006, MED SCI SPORT EXER, V38, P887, DOI 10.1249/01.mss.0000218135.79476.9c
   Georgiou Y, 2017, INT J HUM-COMPUT ST, V98, P24, DOI 10.1016/j.ijhcs.2016.09.014
   Hayes A.F., 2012, PROCESS: A Versatile Computational Tool for Observed Variable Mediation, Moderation, and Conditional Process Modeling, V1
   Hoffner C, 2005, MEDIA PSYCHOL, V7, P325, DOI 10.1207/S1532785XMEP0704_2
   Ivory JD, 2007, J COMMUN, V57, P532, DOI 10.1111/j.1460-2466.2007.00356.x
   J Matias Kivikangas, 2018, EVOLUTIONARY PSYCHOL
   Klimmt C, 2010, MEDIA PSYCHOL, V13, P323, DOI 10.1080/15213269.2010.524911
   Kuhne Rinaldo., 2012, Living Reviews in Democracy, V3, P1
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lin JHT, 2018, NEW MEDIA SOC, V20, P3223, DOI 10.1177/1461444817744850
   Lin JHT, 2017, COMPUT HUM BEHAV, V72, P350, DOI 10.1016/j.chb.2017.02.057
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lynch T., 2018, EVOLUTIONARY PSYCHOL
   Lynch T, 2015, J BROADCAST ELECTRON, V59, P298, DOI 10.1080/08838151.2015.1029128
   Martin GN, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02298
   McCall C, 2015, CONSCIOUS COGN, V38, P60, DOI 10.1016/j.concog.2015.09.011
   Nash EB, 2000, INT J HUM-COMPUT INT, V12, P1, DOI 10.1207/S15327590IJHC1201_1
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Perron Bernard, 2004, COSIGN 2004 P, P132
   Persky S, 2008, PRESENCE-TELEOP VIRT, V17, P57, DOI 10.1162/pres.17.1.57
   Perugini M, 2018, INT REV SOC PSYCHOL, V31, DOI 10.5334/irsp.181
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Sacau A., 2005, 8 INT WORKSHOP PRESE, P143
   Scarpa A, 2010, BIOL PSYCHOL, V84, P488, DOI 10.1016/j.biopsycho.2009.11.006
   Sherry JL, 2001, HUM COMMUN RES, V27, P409, DOI 10.1093/hcr/27.3.409
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sparks GG, 2000, LEA COMMUN SER, P73
   Tamborini R, 2004, J BROADCAST ELECTRON, V48, P335
   Tannenbaum P.H., 1975, ADV EXP SOC PSYCHOL, V8, P149
   Thompson HunterS., 1971, FEAR LOATHING LAS VE
   Ventura M, 2013, COMPUT EDUC, V60, P52, DOI 10.1016/j.compedu.2012.07.003
   Vorderer P., 2003, Proceedings of the 2nd International Conference on Entertainment Computing (ICEC 2003), Pittsburgh, P1
   Wang XL, 2009, PSYCHOPHYSIOLOGY, V46, P458, DOI 10.1111/j.1469-8986.2009.00793.x
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zillmann D., 1996, LEA COMMUN SER, P81
NR 65
TC 26
Z9 26
U1 4
U2 59
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 223
EP 234
DI 10.1007/s10055-021-00555-w
EA JUL 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000669747600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Uz-Bilgin, C
   Thompson, M
AF Uz-Bilgin, Cigdem
   Thompson, Meredith
TI Processing presence: how users develop spatial presence through an
   immersive virtual reality game
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Immersive technology; Game-based learning; Spatial
   presence; Learner characteristics; Spatial ability
ID TENDENCIES
AB A primary affordance of virtual reality (VR) headsets is to give the user spatial presence or the illusion of being in the virtual environment. Although considerable research connects VR to spatial presence, spatial awareness, and spatial ability, little is known about how users develop spatial presence in VR learning environments. This study addresses that gap by exploring spatial presence experience construction in a VR educational game and investigating whether users' knowledge, game experience, and VR experience impact the establishment of spatial presence. In this study, 56 high school students played an immersive 3D VR cell biology game where players search for clues within a virtual cell to diagnose the cell. Findings suggest that players' perceptions of spatial presence are linked to how they allocate their attention during the game, their level of interest in cellular biology, and their visual-spatial acuity, but are not linked to their game experience, VR experience, or prior knowledge of the content area. These results indicate that well-scaffolded, engaging virtual environments can foster spatial presence among users, regardless of prior knowledge or experience, and gives practitioners clues about how to design VR learning environments.
C1 [Uz-Bilgin, Cigdem; Thompson, Meredith] MIT, Educ Arcade, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 Massachusetts Institute of Technology (MIT)
RP Uz-Bilgin, C (corresponding author), MIT, Educ Arcade, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM uzcigdem@gmail.com
RI Uz, Çiğdem/AAI-7871-2021
OI Uz, Çiğdem/0000-0001-6997-344X
FU Oculus Education
FX This material is based upon work supported by Oculus Education.
CR Bilgin C.U., 2021, ImplementingAugmented Reality Into Immersive Virtual Learning Environments, P56
   Cheng KH, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103600
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Flores F, 2003, INT J SCI EDUC, V25, P269, DOI 10.1080/09500690210126793
   Gillath O, 2008, MEDIA PSYCHOL, V11, P259, DOI 10.1080/15213260801906489
   Hartman Tilo., 2015, IMMERSED MEDIA TELEP, P115, DOI [DOI 10.1007/978-3-319-10190-3_7, 10.1007/978-3-319-10190-3_7]
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hedge C, 2017, CYBERPSYCH BEH SOC N, V20, P327, DOI 10.1089/cyber.2016.0399
   Hofer M, 2012, MEDIA PSYCHOL, V15, P373, DOI 10.1080/15213269.2012.723118
   Hounsell MDS., 2013, REV BRASILEIRA COMPU, DOI [10.5335/rbca.2013.2816, DOI 10.5335/RBCA.2013.2816]
   Khenak N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1016, DOI [10.1109/vr.2019.8797801, 10.1109/VR.2019.8797801]
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   Larkin DLS, 2015, THESIS U ALABAMA LIB
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lombard M., 2009, P 12 ANN INT WORKSH, P1
   Mayer RE, 2003, WEB-BASED LEARNING: WHAT DO WE KNOW? WHERE DO WE GO?, P23
   Pallant J., 2007, SURVIVAL MANUAL STEP, V3rd
   Parong J, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106290
   Sacau A., 2005, 8 INT WORKSHOP PRESE, P143
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   Stevens JP., 2002, APPL MULTIVARIATE ST
   Vorderer P., 2004, REPORT EUROPEAN COMM
   Wang A, 2020, THESIS MIT CAMBRIDGE
   Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345
   Wirth W., 2003, COMMUNICATION, V2003, P37661
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yildirim Ç, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100308
NR 30
TC 3
Z9 3
U1 18
U2 92
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 649
EP 658
DI 10.1007/s10055-021-00528-z
EA APR 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000645513200001
DA 2024-07-18
ER

PT J
AU Pieri, L
   Serino, S
   Cipresso, P
   Mancuso, V
   Riva, G
   Pedroli, E
AF Pieri, Luca
   Serino, Silvia
   Cipresso, Pietro
   Mancuso, Valentina
   Riva, Giuseppe
   Pedroli, Elisa
TI The ObReco-360°: a new ecological tool to memory assessment using 360°
   immersive technology
SO VIRTUAL REALITY
LA English
DT Article
DE Memory; Assessment; 360&#176; video; Object recognition; Virtual reality
ID FRONTAL ASSESSMENT BATTERY; MINI-MENTAL-STATE; VIRTUAL-REALITY;
   REHABILITATION; ENVIRONMENTS; VALIDATION; DEMENTIA; FAB
AB One important feature of a neuropsychological test is its ecological validity, which defines how much patients' test scores are linked to real-life functioning. However, many of the currently available neuropsychological tools show low to moderate levels of ecological validity. Virtual reality (VR) emerged as a possible solution that might enhance the ecological value of standard paper-and-pencil tests, thanks to the possibility of simulating realistic environments and situations where patients can behave as they do in real life. Moreover, a recent kind of virtual environments, the 360 degrees spherical photos and videos, seems to guarantee high levels of graphical realism and lower technical complexity than standard VR, despite their limitations concerning interactive design. In this pilot study, we tested the possible application of 360 degrees technology for the assessment of memory, developing an adaptation of a standardized test. We focused on Free Recall and Recognition accuracies as indexes of memory function, confronting and correlating the performances obtained by the participants in the standard and in the 360 degrees test. The results, even if preliminary, support the use of 360 degrees technology for enhancing the ecological value of standard memory assessment tests.
C1 [Pieri, Luca] Univ Milano Bicocca, Dept Psychol, Milan, Italy.
   [Pieri, Luca] Univ Milano Bicocca, Mind & Behav Technol Ctr, Milan, Italy.
   [Serino, Silvia; Riva, Giuseppe] Univ Cattolica Sacro Cuore, Dept Psychol, Milan, Italy.
   [Cipresso, Pietro] Univ Turin, Dept Psychol, Turin, Italy.
   [Mancuso, Valentina; Pedroli, Elisa] eCampus Univ, Dept Psychol, Novedrate, Italy.
   [Riva, Giuseppe; Pedroli, Elisa] IRCCS, Ist Auxol Italiano, Appl Technol Neuropsychol Lab, Milan, Italy.
C3 University of Milano-Bicocca; University of Milano-Bicocca; Catholic
   University of the Sacred Heart; University of Turin; Universita Ecampus;
   IRCCS Istituto Auxologico Italiano
RP Pieri, L (corresponding author), Univ Milano Bicocca, Dept Psychol, Milan, Italy.; Pieri, L (corresponding author), Univ Milano Bicocca, Mind & Behav Technol Ctr, Milan, Italy.
EM l.pieri3@campus.unimib.it
RI Cipresso, Pietro/G-4676-2011; Riva, Giuseppe/C-5917-2008; Serino,
   Silvia/AAM-5297-2020; Mancuso, Valentina/AAZ-5090-2020; Pedroli,
   Elisa/AAC-5927-2022; Pedroli, Elisa/K-5751-2016
OI Cipresso, Pietro/0000-0002-0662-7678; Riva,
   Giuseppe/0000-0003-3657-106X; Serino, Silvia/0000-0002-8422-1358;
   Mancuso, Valentina/0000-0002-4198-3723; Pedroli,
   Elisa/0000-0003-4012-262X; Pieri, Luca/0000-0001-7386-7383
FU Universita degli Studi di Milano -Bicocca within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Milano
   -Bicocca within the CRUI-CARE Agreement.
CR [Anonymous], 1987, Ital J Neurol Sci, VSuppl 8, P1
   Appollonio I, 2005, NEUROL SCI, V26, P108, DOI 10.1007/s10072-005-0443-4
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Beschin N, 2013, RBMT 3 RIVERMEAD BEH
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Chirico A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01242-0
   Clare L., 2008, Rivermead behavioural memory test
   Dubois B, 2000, NEUROLOGY, V55, P1621, DOI 10.1212/WNL.55.11.1621
   EFKLIDES A, 2002, EUR J PSYCHOL ASSESS
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Harris D, 2020, VIRTUAL REAL-LONDON, V24, P557, DOI 10.1007/s10055-019-00422-9
   Heeter C., 1995, Communication in the age of virtual reality, P191
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Keefe RSE, 2016, SCHIZOPHR RES, V175, P90, DOI 10.1016/j.schres.2016.03.038
   Larson EB, 2014, NEUROREHABILITATION, V34, P759, DOI 10.3233/NRE-141078
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Makowski D, 2017, CONSCIOUS COGN, V53, P194, DOI 10.1016/j.concog.2017.06.015
   Matheis RJ, 2007, CLIN NEUROPSYCHOL, V21, P146, DOI 10.1080/13854040601100668
   MEASSO G, 1993, DEV NEUROPSYCHOL, V9, P77, DOI 10.1080/87565649109540545
   Mondini S, 2016, SEMEIOTICA DIAGNOSI
   Moreno A, 2019, ALZH DEMENT-TRCI, V5, P834, DOI 10.1016/j.trci.2019.09.016
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Ouellet É, 2018, J NEUROSCI METH, V303, P126, DOI 10.1016/j.jneumeth.2018.03.010
   Parsons TD, 2017, NEUROPSYCHOL REHABIL, V27, P777, DOI 10.1080/09602011.2015.1109524
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pedroli E., 2018, INT J VIRTUAL AUGMEN, V2, P32, DOI [10.4018/IJVAR.2018010103, DOI 10.4018/IJVAR.2018010103]
   Pedroli E, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00226
   Realdon O, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42201-1
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Robertson CE, 2016, CURR BIOL, V26, P2463, DOI 10.1016/j.cub.2016.07.002
   Sbordone R.J., 1996, ECOLOGICAL VALIDITY, P15
   Serino S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01878
   Serino S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16121-x
   Serino S, 2015, FRONT AGING NEUROSCI, V7, DOI [10.3389/fnagi.2015.00038, 10.3389/fnagi.2015.00088]
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slobounov SM, 2015, INT J PSYCHOPHYSIOL, V95, P254, DOI 10.1016/j.ijpsycho.2014.11.003
   Smith G, 2000, MEMORY, V8, P311, DOI 10.1080/09658210050117735
   SNODGRASS JG, 1988, J EXP PSYCHOL GEN, V117, P34, DOI 10.1037/0096-3445.117.1.34
   Sutcliffe A, 2005, INT J HUM-COMPUT ST, V62, P307, DOI 10.1016/j.ijhcs.2004.11.010
   Ventura S., 2019, FRONT PSYCHOL, DOI 10.3389/fpsyg.2019.02509
   WILSON B, 1989, J CLIN EXP NEUROPSYC, V11, P855, DOI 10.1080/01688638908400940
   Yildirim Ç, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100308
NR 45
TC 13
Z9 13
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 639
EP 648
DI 10.1007/s10055-021-00526-1
EA APR 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000644821700001
OA Green Submitted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mossel, A
   Schoenauer, C
   Froeschl, M
   Peer, A
   Goellner, J
   Kaufmann, H
AF Mossel, Annette
   Schoenauer, Christian
   Froeschl, Mario
   Peer, Andreas
   Goellner, Johannes
   Kaufmann, Hannes
TI Immersive training of first responder squad leaders in untethered
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
ID MOTION
AB We present the VROnSite platform that supports immersive training of first responder units' on-site squad leaders. Our training platform is fully immersive, entirely untethered to ease use and provides two means of navigation-abstract and natural walking-to simulate stress and exhaustion, two important factors for decision making. With the platform's capabilities, we close a gap in prior art for first responder training. Our research is closely interlocked with stakeholders from multiple fire brigades to gather early feedback in an iterative design process. In this paper, we present the system's design rationale, provide insight into the process of training scenario development and present results of a user study with 41 squad leaders from the firefighting domain. Virtual disaster environments with two different navigation types were evaluated using quantitative and qualitative measures. Participants considered our platform highly suitable for training of decision making in complex first responder scenarios and results show the importance of the provided navigation technologies in this context.
C1 [Mossel, Annette; Schoenauer, Christian; Froeschl, Mario; Kaufmann, Hannes] Vienna Univ Technol, Inst Visual Comp & Human Ctr Technol, Vienna, Austria.
   [Peer, Andreas; Goellner, Johannes] M2D Mastermind Dev GmbH, Vienna, Austria.
C3 Technische Universitat Wien
RP Schoenauer, C (corresponding author), Vienna Univ Technol, Inst Visual Comp & Human Ctr Technol, Vienna, Austria.
EM annette.mossel@tuwien.ac.at; christian.schoenauer@tuwien.ac.at;
   mario.froeschl@student.tuwien.ac.at; andreas.peer@master-minde.at;
   johannes.goellner@master-minde.at; hannes.kaufmann@tuwien.ac.at
RI Peer, Andreas/JBJ-4602-2023
FU TU Wien (TUW)
FX Open access funding provided by TU Wien (TUW).
CR Administration S, 2010, NASA TLX TASK LOAD I, DOI 10.1055/s-0028-1097222
   [Anonymous], 2020, VIRTSIM
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cone DC, 2011, EUR J EMERG MED, V18, P314, DOI 10.1097/MEJ.0b013e328345d6fd
   Dartmouth-College, 2015, VIRT TERR RESP AC
   De Luca A, 2013, IEEE T CONTR SYST T, V21, P410, DOI 10.1109/TCST.2012.2185051
   Department of Homeland Security, 2020, ENH DYN GEOS ENV EDG
   Djalali A, 2014, PLOS CURR DISASTERS, DOI 10.1371/currents.dis.56cf1c5c1b0deae1595a48e294685d2f
   ETC-Simulation, 2020, ADV DIS MAN SIM
   Freeman K M, 2001, Prehosp Disaster Med, V16, P3
   Hsu EB, 2013, PLOS CURR DISASTERS
   Huang JY, 2003, IEEE T MULTIMEDIA, V5, P39, DOI 10.1109/TMM.2003.808822
   IntelligentDecisions, 2020, DISM SOLD TRAIN SYST
   Ivin3D, 2011, IMM VID INT NETW
   Koutitas G, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P299, DOI 10.1145/3316782.3321542
   Koutitas G, 2021, VIRTUAL REAL-LONDON, V25, P83, DOI 10.1007/s10055-020-00436-8
   Kurenov SN, 2009, STUD HEALTH TECHNOL, V142, P142, DOI 10.3233/978-1-58603-964-6-142
   Liu ZG, 2017, IEEE T MULTIMEDIA, V19, P874, DOI 10.1109/TMM.2016.2636750
   Mills B, 2020, PREHOSP EMERG CARE, V24, P525, DOI 10.1080/10903127.2019.1676345
   Mossel A., 2012, Int. J. Virtual Real, V11, P1, DOI [10.20870/IJVR.2012.11.3.2845, DOI 10.20870/IJVR.2012.11.3.2845]
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   osterreichischer Bundes Feuerwehr Verband, 2011, HDB GRUND FREIW FEUE
   Sauro J., 2011, Measuring Usability Quantitative Usability, Statistics ; Six Sigma by Jeff Sauro
   Schönauer C, 2020, PROC SPIE, V11426, DOI 10.1117/12.2557396
   Sebillo M, 2016, MULTIMED TOOLS APPL, V75, P9609, DOI 10.1007/s11042-015-2955-0
   Stansfield S, 1999, SAND982533C SAND NAT
   University-Of-Southern-Mississippi, 2015, SPORT CHOR STAD STAM
   Wilkerson W, 2008, ACAD EMERG MED, V15, P1152, DOI 10.1111/j.1553-2712.2008.00223.x
   XVR Simulation, 2020, XVR VIRT REAL TRAIN
   Zhang Z, 2013, IEEE T MULTIMEDIA, V15, P106, DOI 10.1109/TMM.2012.2225040
NR 30
TC 15
Z9 16
U1 5
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 745
EP 759
DI 10.1007/s10055-020-00487-x
EA DEC 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000599796100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Medellin-Castillo, HI
   Zaragoza-Siqueiros, J
   Govea-Valladares, EH
   de la Garza-camargo, H
   Lim, T
   Ritchie, JM
AF Medellin-Castillo, Hugo I.
   Zaragoza-Siqueiros, Jorge
   Govea-Valladares, Eder H.
   de la Garza-camargo, Hector
   Lim, Theodore
   Ritchie, James M.
TI Haptic-enabled virtual training in orthognathic surgery
SO VIRTUAL REALITY
LA English
DT Article
DE Orthognathic surgery (OGS); Surgical skills; Surgical training; Virtual
   reality (VR); Haptics; Cephalometry; Osteotomy; Surgery planning
ID MAXILLOFACIAL SURGERY; SKILLS; TOOL
AB Orthognathic surgery (OGS) is a very complex surgical procedure aiming to correct a wide range of skeletal and dental irregularities, including jaws and teeth misalignments. It requires a precise pre-surgical planning and high surgical skills that are traditionally acquired through years of hands-on training in the operating room or in laboratory-based surgical practices using cadavers or models. Although modern engineering technologies have led to the development or computer-aided surgical procedures and systems, surgical training in OGS still relies on the traditional physical hands-on approach. This paper presents the results of an investigation carried out with the aim to evaluate the use of haptics and virtual reality technologies as an OGS training tool. Three case studies corresponding to cephalometry training, osteotomy training and surgery planning training were conducted. Participants comprised novices and experts in the area of OGS. Surgical skills, performance and confidence of trainees, in addition to reducing execution times and errors associated with the traditional OGS process, indicate that the haptic-enabled virtual reality approach is an effective training tool.
C1 [Medellin-Castillo, Hugo I.; Zaragoza-Siqueiros, Jorge; Govea-Valladares, Eder H.] Univ Autonoma San Luis Potosi, Fac Ingn, Zona Univ, Ave Manuel Nava 8, San Luis Potosi 78290, SLP, Mexico.
   [de la Garza-camargo, Hector] Univ Autonoma San Luis Potosi, Fac Estomatol, Zona Univ, Ave Manuel Nava 2, San Luis Potosi 78290, SLP, Mexico.
   [Lim, Theodore; Ritchie, James M.] Heriot Watt Univ, Sch Engn & Phys Sci, Inst Mech Proc & Energy Engn, Edinburgh EH14 4AS, Midlothian, Scotland.
C3 Universidad Autonoma de San Luis Potosi; Universidad Autonoma de San
   Luis Potosi; Heriot Watt University
RP Medellin-Castillo, HI (corresponding author), Univ Autonoma San Luis Potosi, Fac Ingn, Zona Univ, Ave Manuel Nava 8, San Luis Potosi 78290, SLP, Mexico.
EM hugoivanmc@uaslp.mx; jorge.zaragoza@uaslp.mx; ederhazael@hotmail.com;
   hector.delagarza@uaslp.mx; T.Lim@hw.ac.uk; J.M.Ritchie@hw.ac.uk
RI Bjelovucic, Ruza/JAN-4995-2023; Medellin-Castillo, Hugo Ivan/A-3455-2017
OI Bjelovucic, Ruza/0009-0003-6265-1984; Medellin-Castillo, Hugo
   Ivan/0000-0002-2827-9547; Lim, Theodore/0000-0001-8931-2745
FU CONACYT (National Science and Technology Council of Mexico)
   [CB-2010-01-154430]; PRODEP program from SEP; FAI program from UASLP; EU
   Beaconing Project [687676]
FX This research was supported by CONACYT (National Science and Technology
   Council of Mexico), research Grant CB-2010-01-154430. Acknowledgments
   are also given to the PRODEP and FAI programs from SEP and UASLP,
   respectively, for the supplementary financial support. This work was
   also partially supported by the EU Beaconing Project (#687676).
CR Ahmed N, 2019, BRIT J ORAL MAX SURG, V57, P67, DOI 10.1016/j.bjoms.2018.11.009
   Birbe Joan, 2014, Rev Esp Cirug Oral y Maxilofac, V36, P99, DOI 10.1016/j.maxilo.2012.04.007
   Bosc R, 2019, INT J ORAL MAX SURG, V48, P132, DOI 10.1016/j.ijom.2018.09.010
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Elledge R, 2018, BRIT J ORAL MAX SURG, V56, P384, DOI 10.1016/j.bjoms.2018.04.006
   Gas Becca L, 2016, J Surg Educ, V73, pe71, DOI 10.1016/j.jsurg.2016.07.002
   Ghasemloonia A, 2017, J SURG EDUC, V74, P295, DOI 10.1016/j.jsurg.2016.10.006
   Grantcharov TP, 2002, EUR J SURG, V168, P139, DOI 10.1080/110241502320127739
   Lubek JE, 2019, OR SURG OR MED OR PA, V127, P465, DOI 10.1016/j.oooo.2019.03.001
   Maliha SG, 2018, J ORAL MAXIL SURG, V76, DOI 10.1016/j.joms.2018.06.177
   McCormick SU, 2011, J ORAL MAXIL SURG, V69, P638, DOI 10.1016/j.joms.2010.10.047
   Medellín-Castillo HI, 2016, COMPUT METH PROG BIO, V130, P46, DOI 10.1016/j.cmpb.2016.03.014
   MG Agus, 2003, IEEE VIRT REAL P LOS
   Mischkowski RA, 2006, J CRANIO MAXILL SURG, V34, P478, DOI 10.1016/j.jcms.2006.07.862
   Moorthy K, 2003, BMJ-BRIT MED J, V327, P1032, DOI 10.1136/bmj.327.7422.1032
   Olsson P, 2013, INT J COMPUT ASS RAD, V8, P887, DOI 10.1007/s11548-013-0827-5
   Panait L, 2009, J SURG RES, V156, P312, DOI 10.1016/j.jss.2009.04.018
   Posnick J., 2013, PRINCIPLES PRACTICE, V1st
   Proffit WR, 2006, CONT ORTHODONTICS CO
   Pulijala Y, 2018, INT J ORAL MAX SURG, V47, P1199, DOI 10.1016/j.ijom.2018.01.005
   Ranta JF., 1999, P 4 PHANTOM US GROUP, V4, P67
   Reznick RK, 2006, NEW ENGL J MED, V355, P2664, DOI 10.1056/NEJMra054785
   van Hove PD, 2010, BRIT J SURG, V97, P972, DOI 10.1002/bjs.7115
   Vázquez-Mata G., 2008, Educ. méd., V11, P29
   Wang DX, 2012, IEEE T HAPTICS, V5, P332, DOI [10.1109/TOH.2011.59, 10.1109/ToH.2011.59]
   White S.C. P., 2001, Oral radiology: principles and interpretation
   Xia PJ, 2013, VISUAL COMPUT, V29, P433, DOI 10.1007/s00371-012-0748-2
   Zaragoza-Siqueiros J, 2019, COMPUT METHOD BIOMEC, V22, P499, DOI 10.1080/10255842.2019.1566817
   Zinser MJ, 2013, BRIT J ORAL MAX SURG, V51, P827, DOI 10.1016/j.bjoms.2013.06.014
NR 29
TC 9
Z9 9
U1 0
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 53
EP 67
DI 10.1007/s10055-020-00438-6
EA APR 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000523104600001
DA 2024-07-18
ER

PT J
AU Aromaa, S
   Goriachev, V
   Kymäläinen, T
AF Aromaa, Susanna
   Goriachev, Vladimir
   Kymalainen, Tiina
TI Virtual prototyping in the design of see-through features in mobile
   machinery
SO VIRTUAL REALITY
LA English
DT Article
DE See-through technology; Virtual prototyping; Human factors and
   ergonomics; Virtual reality
ID AUGMENTED REALITY APPLICATIONS; OPERATOR VISIBILITY; CABINS
AB Limited visibility from a mobile machine cab can decrease task performance and lead to accidents. Therefore, it is important to consider visibility issues already in the design phase. This paper describes the use of virtual prototyping in the evaluation of see-through features of mobile work machines. The goal is to evaluate whether two different machine boom transparency levels have an effect on task performance. In addition, two alternative placements of overlaid information in the operators' field of view are assessed. A within-subject design was used in this study. Based on the results, there was no significant difference in performance between the transparency levels. However, the test participants preferred a transparency level of 70-80% (where 0% is completely opaque). Similar results were found with the placement of the overlaid information, which had no significant effect on task performance. Both placements, on the windscreen and on the tunnel wall, were equally favoured by the participants. The findings of this study contribute to the design of see-through features for mobile work machines. In addition, the study demonstrates the use of virtual prototyping in the design of novel features in human-machine systems.
C1 [Aromaa, Susanna; Goriachev, Vladimir; Kymalainen, Tiina] VTT Tech Res Ctr Finland Ltd, Visiokatu 4, Tampere 33101, Finland.
C3 VTT Technical Research Center Finland
RP Aromaa, S (corresponding author), VTT Tech Res Ctr Finland Ltd, Visiokatu 4, Tampere 33101, Finland.
EM susanna.aromaa@vtt.fi
OI Aromaa, Susanna/0000-0001-8843-496X; Kymalainen,
   Tiina/0000-0003-0165-7103
FU Technical Research Centre of Finland (VTT); Business Finland (previously
   Tekes-the Finnish Funding Agency for Innovation)
FX Open access funding provided by Technical Research Centre of Finland
   (VTT). This study was funded by Business Finland (previously Tekes-the
   Finnish Funding Agency for Innovation)-and was carried out as part of
   the SeeWork research project with the FIMA (Forum for Intelligent
   Machines) network. The authors are grateful to all the researchers and
   company representatives who contributed to and supported the work
   presented in this publication.
CR Abubakar MS, 2010, PERTANIKA J SCI TECH, V18, P377
   [Anonymous], 2010, 6143 CENTR
   [Anonymous], 2006, 5006 ISO
   Aromaa S, 2012, NEW TASK RELATED DYN
   Aromaa S, 2017, PROCEEDINGS OF THE 21ST INTERNATIONAL ACADEMIC MINDTREK CONFERENCE (ACADEMIC MINDTREK), P110, DOI 10.1145/3131085.3131087
   Aromaa S, 2016, APPL ERGON, V56, P11, DOI 10.1016/j.apergo.2016.02.015
   Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Badler N, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P28, DOI 10.1109/NAMW.1997.609848
   Barron PJ, 2005, INT J IND ERGONOM, V35, P665, DOI 10.1016/j.ergon.2005.02.001
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Bhattacherya I, 2006, J S AFR I MIN METALL, V106, P87
   Boun Vinh Lu, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P109, DOI 10.1109/ISMAR.2010.5643558
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Chen J., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology (VRST), P167, DOI DOI 10.1145/1889863.1889898
   Choi CB, 2009, APPL ERGON, V40, P280, DOI 10.1016/j.apergo.2008.04.012
   Choi S, 2015, CONCURRENT ENG-RES A, V23, P40, DOI 10.1177/1063293X14568814
   Czaja S.J., 2006, Human factors engineering and systems design, VThird, P32, DOI DOI 10.1002/0470048204.CH2
   DEUTZ-FAHR, 2015, DEUTZ FAHR DRIV EXT
   Di Gironimo G, 2012, PROCEEDINGS OF THE ASME 11TH BIENNIAL CONFERENCE ON ENGINEERING SYSTEMS DESIGN AND ANALYSIS, 2012, VOL 3, P801
   Gilad I, 2015, INT J OCCUP SAF ERGO, V21, P20, DOI 10.1080/10803548.2015.1017942
   Godwin A, 2009, INT J IND ERGONOM, V39, P146, DOI 10.1016/j.ergon.2008.04.005
   Godwin AA, 2008, INT J IND ERGONOM, V38, P202, DOI 10.1016/j.ergon.2007.04.002
   Hardin B, 2016, COLORBLIND ACCESSIBI
   Harrison S, 1995, ASA DECEN CONF SER, P81, DOI 10.4324/9780203450901_chapter_4
   Herling J., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P207, DOI 10.1109/ISMAR.2010.5643572
   IEA, 2000, DEF DOM ERG
   Kabir SN, 2015, VISIBILITY EVALUATIO, P19
   Karkee M, 2011, VIRTUAL REAL-LONDON, V15, P83, DOI 10.1007/s10055-009-0150-1
   Kawai N, 2012, INT SYM MIX AUGMENT, P293, DOI 10.1109/ISMAR.2012.6402580
   Kim C, 2011, HUM FACTOR ERGON MAN, V21, P1, DOI 10.1002/hfm.20210
   Kremer K, 1998, VISUALIZATION '98, PROCEEDINGS, P205, DOI 10.1109/VISUAL.1998.745304
   Kuijt-Evers LFM, 2003, APPL ERGON, V34, P265, DOI 10.1016/S0003-6870(03)00032-2
   Kulkarni A., 2011, Built Environment, P12
   Kumar R, 2014, INT J INJ CONTROL SA, V21, P54, DOI 10.1080/17457300.2012.755551
   Kymalainen T, 2017, EAI INT C TECHN INN
   Land Rover, 2014, INV CAR TECHN LAND R
   Lawson G, 2016, APPL ERGON, V53, P323, DOI 10.1016/j.apergo.2015.06.024
   Lee DH, 2016, INT J AGR BIOL ENG, V9, P33, DOI 10.3965/j.ijabe.20160904.1850
   Leino S.-P., 2015, REFRAMING VALUE VIRT
   Lindlbauer D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1705, DOI 10.1145/2858036.2858453
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Ong SK, 2008, INT J PROD RES, V46, P2707, DOI 10.1080/00207540601064773
   Ruff T, 2011, INT J INJ CONTROL SA, V18, P11, DOI 10.1080/17457300.2010.487154
   Sanders MS, 1993, HUMAN FACTORS ENG DE
   Schall G, 2008, P 7 IEEE ACM INT S M
   Schwarz F, 2017, ACCIDENT ANAL PREV, V101, P55, DOI 10.1016/j.aap.2017.01.019
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Summerskill S, 2016, APPL ERGON, V53, P267, DOI 10.1016/j.apergo.2015.10.013
   Tachi S, 2014, IEEE SPECTRUM, V51, P52, DOI 10.1109/MSPEC.2014.6934935
   Wang G. G., 2002, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V2, P232, DOI 10.1115/1.1526508
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
NR 52
TC 4
Z9 5
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 23
EP 37
DI 10.1007/s10055-019-00384-y
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Gourishetti, R
   Manivannan, M
AF Gourishetti, Ravali
   Manivannan, M.
TI Improved force JND in immersive virtual reality needle insertion
   simulation
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Non-immersive virtual reality; Isometric
   probing; Force JND; Psychophysical study; Observer state model
ID MANUAL DISCRIMINATION
AB Haptic feedback in immersive virtual reality (IVR) systems is critical to enable a more intuitive and natural way of interacting with virtual objects. IVR-based haptic medical simulations such as needle insertion procedures have the potential to enhance clinicians' haptic expertise. This work is a preliminary study on the use and implementation of IVR for needle simulators. Although few studies have quantified haptic skills such as force Just Noticeable Difference (JND) with the single finger, none have measured the force JND as recommended in the standard needle insertion protocol in an IVR environment. The hypothesis of this study is that there will be an improvement of force perception in the IVR, compared to that of the non-immersive virtual reality (NIVR) which facilitates the use of IVR for medical simulations. This paper emphasized on two objectives: firstly, the development of the observer state model for both the IVR and NIVR and the theoretical analysis of the psychophysical measures in both of the environments. Secondly, measures of force JND with the three fingers and comparison of these measures in NIVR to that of the IVR using psychophysical study with the force matching task, constant stimuli method, and isometric force probing stimuli to validate the model. Twenty voluntary subjects performed the experiment in both of the environments. Mean force JND and standard deviation of the JND were found to be 9.12% and 3.75% in the NIVR and 5.91% and 3.65% in the IVR (p value < 0.0001) which are in the same range of JNDs found in the literature (5-10%) for the NIVR using a single finger. Surprisingly, the results showed a better force JND in the IVR compared to that of the NIVR. Also, a simple state observer model was proposed to explain the improvement of force JND in the IVR. This study would quantitatively reinforce the use of IVR for the design of various medical simulators.
C1 [Gourishetti, Ravali; Manivannan, M.] Indian Inst Technol Madras, Appl Mech Dept, Chennai, Tamil Nadu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Manivannan, M (corresponding author), Indian Inst Technol Madras, Appl Mech Dept, Chennai, Tamil Nadu, India.
EM ravaligourishetty27@gmail.com; mani@iitm.ac.in
RI Ravali, Gourishetti/AAE-2792-2019; Muniyandi, Manivannan/H-3002-2012
OI Ravali, Gourishetti/0000-0003-0767-8378; Muniyandi,
   Manivannan/0000-0003-1162-1550
CR Allin S, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P299, DOI 10.1109/HAPTIC.2002.998972
   [Anonymous], 2013, Virtual and augmented reality applications in manufacturing
   [Anonymous], VIRTUAL REALITY TECH
   DiMaio SP, 2003, IEEE T ROBOTIC AUTOM, V19, P864, DOI 10.1109/TRA.2003.817044
   Gescheider G. A., 2013, Psychophysics: the fundamentals
   Horiuchi K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184552
   Hungate RE., 1969, METHODS MICROBIOLOGY, V3, P117, DOI [10.1016/S0580-9517(08)70503-8, DOI 10.1016/S0580-9517(08)70503-8]
   JONES LA, 1989, PERCEPTION, V18, P681, DOI 10.1068/p180681
   King H, 2010, PERCEPTUAL THRESHOLD
   PANG XD, 1991, PERCEPT PSYCHOPHYS, V49, P531, DOI 10.3758/BF03212187
   Parmar D, 2016, VIRTUAL REAL-LONDON, V20, P141, DOI 10.1007/s10055-016-0287-7
   Prasad MSR, 2015, SURG ENDOSC, V29, P1927, DOI 10.1007/s00464-014-3887-x
   Prasad R., 2013, ICoRD'13, P365, DOI DOI 10.1007/978-81-322-1050-4_29
   Raja D., 2004, P IMM PROJ TECHN WOR
   Ravali G, 2017, IEEE REV BIOMED ENG, P1, DOI [10.1109/RBME.2017.2706966, DOI 10.1109/RBME.2017.2706966]
   Ready LB, 1999, REGION ANESTH PAIN M, V24, P499, DOI 10.1016/S1098-7339(99)90038-X
   Riva G.)., 1997, Virtual Reality in Neuro-Psycho-Physiology: Cognitive, clinical and methodological issues in assessment and rehabilitation
   TAN HZ, 1995, PERCEPT PSYCHOPHYS, V57, P495, DOI 10.3758/BF03213075
   Taschereau R, 2000, RADIOTHER ONCOL, V55, P59, DOI 10.1016/S0167-8140(00)00162-6
   van Polanen V, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00700
   von der Heyde M., 1998, P 3 PHANTOM US GROUP, P101
   Wu B, 2011, IEEE T HAPTICS, V4, P221, DOI 10.1109/ToH.2011.3
   Wu J, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/50533
   Zwislocki JozefJ., 2009, Sensory Neuroscience: Four Laws of Psychophysics, P1
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 25
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 133
EP 142
DI 10.1007/s10055-018-0369-9
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500002
DA 2024-07-18
ER

PT J
AU Neumann, DL
   Moffitt, RL
   Thomas, PR
   Loveday, K
   Watling, DP
   Lombard, CL
   Antonova, S
   Tremeer, MA
AF Neumann, David L.
   Moffitt, Robyn L.
   Thomas, Patrick R.
   Loveday, Kylie
   Watling, David P.
   Lombard, Chantal L.
   Antonova, Simona
   Tremeer, Michael A.
TI A systematic review of the application of interactive virtual reality to
   sport
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Sport; Exercise; Systematic review
ID SOCIAL FACILITATION; PHYSICAL-ACTIVITY; EXERCISE; ENVIRONMENTS;
   PERFORMANCE; PERCEPTION; STRATEGIES; BENEFITS; BEHAVIOR; TASK
AB Virtual reality (VR) technology is being increasingly used by athletes, coaches, and other sport-related professionals. The present systematic review aimed to document research on the application of VR to sport to better understand the outcomes that have emerged in this work. Research literature databases were searched, and the results screened to identify articles reporting applications of interactive VR to sport with healthy human participants. Twenty articles were identified and coded to document the study aims, research designs, participant characteristics, sport types, VR technology, measures, and key findings. From the review, it was shown that interactive VR applications have enhanced a range of performance, physiological, and psychological outcomes. The specific effects have been influenced by factors related to the athlete and the VR system, which comprise athlete factors, VR environment factors, task factors, and the non-VR environment factors. Important variables include the presence of others in the virtual environment, competitiveness, task autonomy, immersion, attentional focus, and feedback. The majority of research has been conducted on endurance sports, such as running, cycling, and rowing, and more research is required to examine the use of interactive VR in skill-based sports. Additional directions for future research and reporting standards for researchers are suggested.
C1 [Neumann, David L.; Moffitt, Robyn L.; Loveday, Kylie; Watling, David P.; Lombard, Chantal L.; Antonova, Simona; Tremeer, Michael A.] Griffith Univ, Sch Appled Psychol, Gold Coast, Qld 4222, Australia.
   [Neumann, David L.; Moffitt, Robyn L.; Thomas, Patrick R.] Menzies Hlth Inst Queensland, Gold Coast, Qld 4222, Australia.
C3 Griffith University; Griffith University - Gold Coast Campus; Menzies
   Health Institute Queensland
RP Neumann, DL (corresponding author), Griffith Univ, Sch Appled Psychol, Gold Coast, Qld 4222, Australia.; Neumann, DL (corresponding author), Menzies Hlth Inst Queensland, Gold Coast, Qld 4222, Australia.
EM d.neumann@griffith.edu.au
RI Neumann, David/AAD-7018-2020; Moffitt, Robyn/AAL-5149-2020
OI Neumann, David/0000-0001-5400-462X; Moffitt, Robyn/0000-0003-1933-4046
CR Anderson-Hanley C, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00989
   Anderson-Hanley C, 2012, AM J PREV MED, V42, P109, DOI 10.1016/j.amepre.2011.10.016
   Anderson-Hanley C, 2011, CLIN INTERV AGING, V6, P275, DOI 10.2147/CIA.S25337
   Annesi JJ, 1997, PERCEPT MOTOR SKILL, V85, P835, DOI 10.2466/pms.1997.85.3.835
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   [Anonymous], DEF SPORT PHYS ACT C
   [Anonymous], COCHRANE DATABASE SY
   Baca A, 2009, J SPORT SCI, V27, P1335, DOI 10.1080/02640410903277427
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Baños RM, 2016, CYBERPSYCH BEH SOC N, V19, P115, DOI 10.1089/cyber.2015.0283
   Briki W, 2013, PSYCHOL SPORT EXERC, V14, P389, DOI 10.1016/j.psychsport.2012.11.009
   Chen KB, 2015, HUM FACTORS, V57, P658, DOI 10.1177/0018720814562231
   Feltz DL, 2011, J SPORT EXERCISE PSY, V33, P506, DOI 10.1123/jsep.33.4.506
   Guy S, 2011, INT J HYPERTENS, V2011, DOI 10.4061/2011/179124
   Hoffmann CP, 2014, J SPORT SCI, V32, P501, DOI 10.1080/02640414.2013.835435
   IJsselsteijn W, 2004, LECT NOTES COMPUT SC, V3166, P46
   Irwin BC, 2012, ANN BEHAV MED, V44, P151, DOI 10.1007/s12160-012-9367-4
   Kim SY, 2014, COMPUT HUM BEHAV, V36, P376, DOI 10.1016/j.chb.2014.03.067
   Larsen LH, 2013, GAMES HEALTH J, V2, P205, DOI 10.1089/g4h.2013.0036
   Lee HG, 2013, NEW MEDIA SOC, V15, P930, DOI 10.1177/1461444812464033
   Legrand FD, 2011, J APPL SPORT PSYCHOL, V23, P65, DOI 10.1080/10413200.2010.523754
   Meline T., 2006, CONT ISSUES COMMUNIC, V33, P21
   Mestre DR, 2011, STUD HEALTH TECHNOL, V167, P122, DOI 10.3233/978-1-60750-766-6-122
   Meyerbröker K, 2010, DEPRESS ANXIETY, V27, P933, DOI 10.1002/da.20734
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Mueller FF, 2007, PERS UBIQUIT COMPUT, V11, P633, DOI 10.1007/s00779-006-0133-0
   Murray EG, 2016, PSYCHOL SPORT EXERC, V22, P328, DOI 10.1016/j.psychsport.2015.09.007
   Neumann DL, 2013, AUST PSYCHOL, V48, P329, DOI 10.1111/ap.12015
   Neumann DL, 2013, J PSYCHOPHYSIOL, V27, P7, DOI 10.1027/0269-8803/a000081
   Neumann DL, 2011, J PSYCHOPHYSIOL, V25, P1, DOI 10.1027/0269-8803/a000011
   Nunes M., 2014, Proceedings 29th Annual ACM Symposium on Applied Computing - SAC'14. Gyeongju, P970, DOI [DOI 10.1145/2554850.2555009, 10.1145/2554850.2555009]
   Peng W, 2013, HEALTH EDUC BEHAV, V40, P171, DOI 10.1177/1090198112444956
   Plante T.G., 2006, International Journal of Stress Management, V13, P108, DOI [10.1037/1072-5245.13.1.108, DOI 10.1037/1072-5245.13.1.108]
   Plante TG, 2003, J HUM MOVEMENT STUD, V45, P485
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Oliveira BRR, 2015, J SPORT SCI, V33, P777, DOI 10.1080/02640414.2014.968191
   Ranganathan R, 2007, J MOTOR BEHAV, V39, P369, DOI 10.3200/JMBR.39.5.369-380
   Reynolds JE, 2014, HUM MOVEMENT SCI, V34, P1, DOI 10.1016/j.humov.2014.02.007
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Snyder AL, 2012, J SPORT EXERCISE PSY, V34, P252, DOI 10.1123/jsep.34.2.252
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stevinson CD, 1999, SPORT PSYCHOL, V13, P235, DOI 10.1123/tsp.13.2.235
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Tenenbaum G., 2007, Handbook of sport psychology, P560, DOI [10.1002/9781118270011.ch25, DOI 10.1002/9781118270011.CH25]
   Tirp J., 2015, Psychol Test Assess Model, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Vignais N, 2015, HUM MOVEMENT SCI, V39, P12, DOI 10.1016/j.humov.2014.10.006
   Vogt T, 2015, EXP BRAIN RES, V233, P1321, DOI 10.1007/s00221-015-4208-x
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 49
TC 139
Z9 148
U1 17
U2 271
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 183
EP 198
DI 10.1007/s10055-017-0320-5
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900001
OA Green Published
DA 2024-07-18
ER

PT J
AU Bruno, F
   Barbieri, L
   Lagudi, A
   Cozza, M
   Cozza, A
   Peluso, R
   Muzzupappa, M
AF Bruno, Fabio
   Barbieri, Loris
   Lagudi, Antonio
   Cozza, Marco
   Cozza, Alessandro
   Peluso, Raffaele
   Muzzupappa, Maurizio
TI Virtual dives into the underwater archaeological treasures of South
   Italy
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Virtual reality; Virtual diving system; Underwater
   Cultural Heritage; Underwater archaeological sites
ID MUSEUM
AB The paper presents a virtual diving system based on a virtual reality (VR) application for the exploitation of the Underwater Cultural Heritage. The virtual diving experience has been designed to entertain users, but its added pedagogical value is explicitly emphasized too. In fact, the ludic activities, consisting in the simulation of a real diving session from the point of view of a scuba diver, are following a storyline described by a virtual diving companion who guides users during the exploration of the underwater archaeological site. The virtual diving system provides general and historical-cultural contents, but also information about the flora and fauna of the specific submerged site to the users. The results collected through user studies demonstrate that the proposed VR system is able to provide a playful learning experience, with a high emotional impact, and it has been well appreciated by a large variety of audiences, even by younger and inexperienced users.
C1 [Bruno, Fabio; Barbieri, Loris; Lagudi, Antonio; Muzzupappa, Maurizio] Univ Calabria, Dept Mech Energy & Ind Engn DIMEG, P Bucci 46C, I-87036 Arcavacata Di Rende, CS, Italy.
   [Cozza, Marco; Cozza, Alessandro; Peluso, Raffaele] 3D Res Srl, P Bucci 45C, I-87036 Arcavacata Di Rende, CS, Italy.
C3 University of Calabria
RP Bruno, F (corresponding author), Univ Calabria, Dept Mech Energy & Ind Engn DIMEG, P Bucci 46C, I-87036 Arcavacata Di Rende, CS, Italy.
EM fabio.bruno@unical.it
RI Bruno, Fabio/F-5828-2011; Barbieri, Loris/AAH-1095-2021
OI Barbieri, Loris/0000-0001-7771-6582; Cozza,
   Alessandro/0000-0001-8699-5405; Lagudi, Antonio/0000-0002-7478-2864
FU MIUR under the PAC Programme [PAC02L2-00040]
FX The VISAS project (Ref. Start-Up PAC02L2-00040) has been financed by the
   MIUR under the PAC Programme. The authors would like to thank the Marine
   Protected Area of Capo Rizzuto, the Soprintendenza per i Beni culturali
   e ambientali del Mare della Sicilia for the permission to conduct the
   experimentation in the sites of Cala Minnola and the Soprintendenza per
   i Beni Archeologici della Calabria for the site of Punta Scifo.
CR Anderson EF, 2010, VIRTUAL REAL-LONDON, V14, P255, DOI 10.1007/s10055-010-0177-3
   [Anonymous], 2001, P 2001 C VIRTUAL REA, DOI DOI 10.1145/584993.585055
   [Anonymous], 2006, EXPLORING PSYCHOL IN
   [Anonymous], 1999, 13407 ISO
   [Anonymous], 2002, VAST EURCONFORCE
   [Anonymous], 2013, J. Comput. Cult. Herit, DOI DOI 10.1145/2460376.2460379
   Barbieri L, 2017, J CULT HERIT, V26, P101, DOI 10.1016/j.culher.2017.02.005
   Barcelo M, 2000, BAR INT SERIES, V843
   Bellotti F., 2012, ACM J COMPUT CULT HE, V5, P1, DOI [10.1145/2399180.2399185, DOI 10.1145/2399180.2399185]
   BERLYNE DE, 1970, PERCEPT PSYCHOPHYS, V8, P279, DOI 10.3758/BF03212593
   Blue Growth Study, 2013, SPEC SUPP POL MEAS M
   Borsci S, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2506210
   Bruno F., 2016, 6 INT C EUROMED 20 1, P269, DOI DOI 10.1007/978-3-319-48496-9_22
   Bruno F, 2016, MAR TECHNOL SOC J, V50, P119, DOI 10.4031/MTSJ.50.4.4
   Bruno F, 2010, J CULT HERIT, V11, P42, DOI 10.1016/j.culher.2009.02.006
   Chapman P., 2008, P VAST INT S VIRT RE, P141, DOI DOI 10.2312/VAST/VAST08/141-148
   Chapman P., 2006, P JOINT EV CIPA VAST
   De Paolis L. T., 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P524, DOI 10.1109/ICCRD.2011.5763914
   Djaouti D, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P221, DOI 10.1109/VSMM.2009.40
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   ESA, 2016, 2016 SAL DEM US DAT, P3
   Haydar M, 2011, VIRTUAL REAL-LONDON, V15, P311, DOI 10.1007/s10055-010-0176-4
   Huang W. H., 2013, BEHAV EC ACTION REPO
   Hunter JW, 2009, AUSTRALAS HIST ARCHA, V27, P127
   Jacobson J., 2009, DISTANCE EDUC, V9, P7
   Kapp K.M., 2013, GAMIFICATION LEARNIN
   Katsouri I, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2665072
   Lagudi A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040536
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI DOI 10.1007/S10055-004-0141-1
   Lewis J.R., 2006, HDB HUMAN FACTORS ER, P1275
   LEWIS JR, 1994, HUM FACTORS, V36, P368, DOI 10.1177/001872089403600215
   Liarokapis F., 2017, INT ARCH PHOTOGRAMM, P425, DOI 10.1007/s10055-017-0318-z
   Morschheuser B., 2017, 50 ANN HAWAII INT C
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   Pavlidis G, 2007, J CULT HERIT, V8, P93, DOI 10.1016/j.culher.2006.10.007
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Sauro J, 2016, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, 2ND EDITION, P1, DOI 10.1016/B978-0-12-802308-2.00001-1
   Shaffer DW, 2005, PHI DELTA KAPPAN, V87, P104, DOI 10.1177/003172170508700205
   Simon N., 2010, PARTICIPATORY MUSEUM
   Spence C, 2001, PERCEPT PSYCHOPHYS, V63, P330, DOI 10.3758/BF03194473
   Stone R., 1999, WORLD HERIT REV, Vb, P18
   Stone R, 2009, VIRTUAL REAL-LONDON, V13, P13, DOI 10.1007/s10055-008-0111-0
   Turner CW., 2006, INT ENCY ERGONOMICS, V3, P3084, DOI DOI 10.1201/9780849375477.CH597
   van Dam A, 2002, COMPUT GRAPH-UK, V26, P535, DOI 10.1016/S0097-8493(02)00113-9
   Vansteenkiste M, 2006, EDUC PSYCHOL-US, V41, P19, DOI 10.1207/s15326985ep4101_4
   Varinlioglu G, 2011, INT J NAUT ARCHAEOL, V40, P182, DOI 10.1111/j.1095-9270.2010.00304.x
   Virzi R., 1995, P HUM FACT ERG SOC 3, P309, DOI [10.1177%2F154193129503900402, DOI 10.1177/154193129503900402]
   Vote E, 2002, IEEE COMPUT GRAPH, V22, P38, DOI 10.1109/MCG.2002.1028725
   Wei T, 2010, LECT NOTES COMPUT SC, V6250, P266, DOI 10.1007/978-3-642-14484-4_22
NR 49
TC 34
Z9 34
U1 6
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2018
VL 22
IS 2
SI SI
BP 91
EP 102
DI 10.1007/s10055-017-0318-z
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GC5KP
UT WOS:000429826700002
DA 2024-07-18
ER

PT J
AU Turchet, L
AF Turchet, Luca
TI Designing presence for real locomotion in immersive virtual
   environments: an affordance-based experiential approach
SO VIRTUAL REALITY
LA English
DT Article
DE Affordance; Experiential design; Locomotion interfaces; Virtual
   environments; Presence
ID PERCEIVING AFFORDANCES; SCALED INFORMATION; SPATIAL PRESENCE; VISUAL
   GUIDANCE; PERCEPTION; WALKING; ILLUSIONS; DISPLAY; SYSTEMS
AB This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. The main outcome of the present research is a list of design features that the virtual reality technology should have in order to achieve such a goal. To identify these features, an approach based on the combination of two design strategies was followed. The first was based on the theory of affordances and was utilized to design a generic VE in which the affordances of the corresponding real environment could be evoked. The second was the experiential design applied to VEs and was utilized to create an experience of locomotion corresponding to that achievable in a real environment. These design strategies were chosen because of their potential to enhance the sense of presence. The proposed list of features can be utilized as an instrument that allows VE designers to evaluate the maturity of their systems and to pinpoint directions for future developments. A survey analysis was performed using the proposed framework, which involved three case studies to determine how many features of the proposed framework were present and their status. The result of such analysis represented a measure of the completeness of the systems design, of the affordances provided to the user, and a prediction of the sense of presence.
C1 [Turchet, Luca] Aalborg Univ, Dept Architecture Design & Media Technol, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
C3 Aalborg University
RP Turchet, L (corresponding author), Aalborg Univ, Dept Architecture Design & Media Technol, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
EM tur@create.aau.dk
RI Turchet, Luca/M-9679-2013
OI Turchet, Luca/0000-0003-0711-8098
FU Danish Council for Independent Research [12-131985]
FX The research leading to these results has received funding from the
   Danish Council for Independent Research, Grant No. 12-131985.
CR Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Biocca F.A., 2002, PRESENCE, P410
   Bruder G, 2013, DISPLAYS, V34, P132, DOI 10.1016/j.displa.2012.10.007
   Calvert G, 2004, THE HANDBOOK OF MULT
   Chertoff DB, 2008, PRESENCE-TELEOP VIRT, V17, P405, DOI 10.1162/pres.17.4.405
   Chertoff DB, 2010, P IEEE VIRT REAL ANN, P103, DOI 10.1109/VR.2010.5444804
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Fajen B.R., 2013, Human Walking in Virtual Environments, P79, DOI DOI 10.1007/978-1-4419-8432-6_4
   FITZPATRICK P, 1994, ECOL PSYCHOL, V6, P265, DOI 10.1207/s15326969eco0604_2
   Flach JM, 1998, PRESENCE-TELEOP VIRT, V7, P90, DOI 10.1162/105474698565550
   Frissen I., 2013, Human Walking in Virtual Environments: Perception, Technology, and Applications, P113, DOI DOI 10.1007/978-1-4419-8432-6_6
   Frohlich Julia, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P159, DOI 10.1007/978-3-642-39405-8_19
   Gaver W.W., 1991, P SIGCHI C HUMAN FAC, P79, DOI DOI 10.1145/108844.108856
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Giordano B, 2006, P 9 INT C MUS PERC C, P436
   Giordano BL, 2012, J ACOUST SOC AM, V131, P4002, DOI 10.1121/1.3699205
   Grechkin TY, 2014, IEEE T VIS COMPUT GR, V20, P596, DOI 10.1109/TVCG.2014.18
   Gross DC, 2005, PRESENCE-VIRTUAL AUG, V14, P482, DOI 10.1162/105474605774785244
   Hartson HR, 2003, BEHAV INFORM TECHNOL, V22, P315, DOI 10.1080/01449290310001592587
   Harvey MA, 2005, PRESENCE-TELEOP VIRT, V14, P616, DOI 10.1162/105474605774918714
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heeter C., 1995, Communication in the age of virtual reality, P191
   Hermann T., 2011, The sonification handbook
   Hollerbach J.M., 2000, HAPTICS S P ASME DYN, P1293
   Hollerbach JM, 2002, HUM FAC ER, P239
   Hulsmann F, 2014, J VIRTUAL REAL BROAD, V11, P1
   Kulkarni S, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P184, DOI 10.1109/WHC.2009.4810855
   Kulkarni SD, 2012, IEEE-ASME T MECH, V17, P635, DOI 10.1109/TMECH.2011.2113353
   Larsson P, 2010, HUM-COMPUT INT-SPRIN, P143, DOI 10.1007/978-1-84882-733-2_8
   Lee KM, 2004, PRESENCE-TELEOP VIRT, V13, P494, DOI 10.1162/1054746041944830
   Lepecq JC, 2009, VIRTUAL REAL-LONDON, V13, P141, DOI 10.1007/s10055-009-0118-1
   LI XF, 1991, J ACOUST SOC AM, V90, P3036, DOI 10.1121/1.401778
   Maier JRA, 2009, RES ENG DES, V20, P225, DOI 10.1007/s00163-009-0064-7
   Maier JRA, 2009, RES ENG DES, V20, P13, DOI 10.1007/s00163-008-0060-3
   Makela K., 2003, P 2003 INT C AUD DIS, P144
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   MARK LS, 1987, J EXP PSYCHOL HUMAN, V13, P361, DOI 10.1037/0096-1523.13.3.361
   McGrenere J, 2000, PROC GRAPH INTERF, P179
   Nordahl R, 2011, PSYCHNOLOGY J, V9, P245
   Oudejans RRD, 1996, J EXP PSYCHOL HUMAN, V22, P879, DOI 10.1037/0096-1523.22.4.879
   Pastore RE, 2008, PERCEPT PSYCHOPHYS, V70, P13, DOI 10.3758/PP.70.1.13
   Peck TC, 2012, IEEE T VIS COMPUT GR, V18, P1053, DOI 10.1109/TVCG.2011.289
   Pine JosephB., 2011, The Experience Economy
   Ravaja N, 2006, PRESENCE-TELEOP VIRT, V15, P381, DOI 10.1162/pres.15.4.381
   Regia-Corte T, 2013, VIRTUAL REAL-LONDON, V17, P17, DOI 10.1007/s10055-012-0216-3
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Slater M, 2002, PRESENCE-TELEOP VIRT, V11, P435, DOI 10.1162/105474602760204327
   Slater M, 2009, ANU PSICOL, V40, P193
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Spence C, 2007, ACOUST SCI TECHNOL, V28, P61, DOI 10.1250/ast.28.61
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Steinicke F, 2013, Human walking in virtual environments
   Turchet Luca, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P577, DOI 10.1007/978-3-642-31401-8_51
   Turchet Luca, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P269, DOI 10.1109/MMSP.2010.5662031
   Turchet L, 2014, APPL ACOUST, V83, P22, DOI 10.1016/j.apacoust.2014.03.005
   Turchet L, 2013, APPL ACOUST, V75, P59, DOI 10.1016/j.apacoust.2013.06.016
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Van Toller S, 1988, PERFUMERY PSYCHOL BI
   Van Toller S., 1992, Fragrance, the psychology and biology of perfume
   Visell Y, 2009, IEEE T HAPTICS, V2, P148, DOI [10.1109/TOH.2009.31, 10.1109/ToH.2009.31]
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Yanagida Y, 2004, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2004.1310054
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zanotto D, 2014, P IEEE RAS-EMBS INT, P193, DOI 10.1109/BIOROB.2014.6913775
NR 71
TC 17
Z9 19
U1 1
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 277
EP 290
DI 10.1007/s10055-015-0267-3
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800011
DA 2024-07-18
ER

PT J
AU Schwebel, DC
   McClure, LA
   Severson, J
AF Schwebel, David C.
   McClure, Leslie A.
   Severson, Joan
TI Usability and feasibility of an internet-based virtual pedestrian
   environment to teach children to cross streets safely
SO VIRTUAL REALITY
LA English
DT Article
DE Pedestrian; Safety; Injury; Evaluation; Internet
ID ROAD; REALITY; SKILLS; BEHAVIORS; DRIVERS; INJURY; ROUTES
AB Child pedestrian injury is a preventable global health challenge. Successful training efforts focused on child behavior, including individualized streetside training and training in large virtual pedestrian environments, are laborious and expensive. This study considers the usability and feasibility of a virtual pedestrian environment "game" application to teach children safe street-crossing behavior via the internet, a medium that could be broadly disseminated at low cost. Ten 7- and 8-year-old children participated. They engaged in an internet-based virtual pedestrian environment and completed a brief assessment survey. Researchers rated children's behavior while engaged in the game. Both self-report and researcher observations indicated the internet-based system was readily used by the children without adult support. The youth understood how to engage in the system and used it independently and attentively. The program also was feasible. It provided multiple measures of pedestrian safety that could be used for research or training purposes. Finally, the program was rated by children as engaging and educational. Researcher ratings suggested children used the program with minimal fidgeting or boredom. The pilot test suggests an internet-based virtual pedestrian environment offers a usable, feasible, engaging, and educational environment for child pedestrian safety training. If future research finds children learn the cognitive and perceptual skills needed to cross streets safely within it, internet-based training may provide a low-cost medium to broadly disseminate child pedestrian safety training. The concept may be generalized to other domains of health-related functioning such as teen driving safety, adolescent sexual risk-taking, and adolescent substance use.
C1 [Schwebel, David C.] Univ Alabama Birmingham, Dept Psychol, Birmingham, AL 35294 USA.
   [McClure, Leslie A.] Univ Alabama Birmingham, Dept Biostat, Birmingham, AL 35294 USA.
   [Severson, Joan] Digital Artefacts LLC, Iowa City, IA USA.
C3 University of Alabama System; University of Alabama Birmingham;
   University of Alabama System; University of Alabama Birmingham
RP Schwebel, DC (corresponding author), Univ Alabama Birmingham, Dept Psychol, 1300 Univ Blvd,CH 415, Birmingham, AL 35294 USA.
EM schwebel@uab.edu
RI Schwebel, David C./GXH-9944-2022; McClure, Leslie/P-2929-2015
OI Schwebel, David C./0000-0002-2141-8970; McClure,
   Leslie/0000-0002-2465-6739
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development [R01HD058573]
FX The project described was supported by Award Number R01HD058573 from the
   Eunice Kennedy Shriver National Institute of Child Health and Human
   Development. The content is solely the responsibility of the authors and
   does not necessarily represent the official views of the Eunice Kennedy
   Shriver National Institute of Child Health and Human Development or the
   National Institutes of Health. Thanks to Anna Johnston and students in
   the UAB Youth Safety Lab for leading data collection efforts, and to the
   Digital Artefacts staff for developing the virtual environment.
   Correspondence may be sent to David C. Schwebel, Department of
   Psychology, University of Alabama at Birmingham, 1300 University Blvd.,
   CH 415, Birmingham AL 35294 USA, or by email to schwebel@uab.edu.
CR Ameratunga S, 2006, LANCET, V367, P1533, DOI 10.1016/S0140-6736(06)68654-6
   AMPOFOBOATENG K, 1993, BRIT J DEV PSYCHOL, V11, P31, DOI 10.1111/j.2044-835X.1993.tb00586.x
   [Anonymous], ROAD USER BEHAV THEO
   Avis KT, 2012, ANN M ASS PROF SLEEP
   Babu S, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P91, DOI 10.1109/VR.2009.4811004
   Babu SV, 2011, IEEE T VIS COMPUT GR, V17, P14, DOI 10.1109/TVCG.2009.211
   Bart O, 2008, OTJR-OCCUP PART HEAL, V28, P89, DOI 10.3928/15394492-20080301-01
   Barton BK, 2007, J PEDIATR PSYCHOL, V32, P475, DOI 10.1093/jpepsy/jsl028
   Barton BK, 2011, DEV PSYCHOL, V47, P182, DOI 10.1037/a0021308
   Demetre JD, 1997, J APPL DEV PSYCHOL, V18, P263, DOI 10.1016/S0193-3973(97)90040-X
   DEMETRE JD, 1993, BRIT J EDUC PSYCHOL, V63, P349, DOI 10.1111/j.2044-8279.1993.tb01063.x
   Duperrex O, 2002, BRIT MED J, V324, P1129, DOI 10.1136/bmj.324.7346.1129
   Fisher DL, 2006, INJURY PREV, V12, P25, DOI 10.1136/ip.2006.012021
   Fisher DL, 2002, HUM FACTORS, V44, P287, DOI 10.1518/0018720024497853
   Gutiérrez-Maldonado J, 2014, VIRTUAL REAL-LONDON, V18, P61, DOI 10.1007/s10055-013-0236-7
   McComas J, 2002, CYBERPSYCHOL BEHAV, V5, P185, DOI 10.1089/109493102760147150
   National Center for Injury Prevention and Control [NCIPC], 2012, INJ PREV CONTR DAT S
   Plumert JM, 2004, CHILD DEV, V75, P1243, DOI 10.1111/j.1467-8624.2004.00736.x
   Plumert JM, 2007, CURR DIR PSYCHOL SCI, V16, P255, DOI 10.1111/j.1467-8721.2007.00515.x
   Schwebel DC, 2008, ACCIDENT ANAL PREV, V40, P1394, DOI 10.1016/j.aap.2008.03.005
   Schwebel DC, 2012, AM J LIFESTYLE MED, V6, P292, DOI 10.1177/0885066611404876
   Schwebel DC, 2010, INJURY PREV, V16, pE1, DOI 10.1136/ip.2009.025288
   Schwebel DC, HLTH PSYCHOL
   Thompson J.A., 2007, APPL SPATIAL COGNITI, P203
   Thomson JA, 2005, J EXP PSYCHOL-APPL, V11, P175, DOI 10.1037/1076-898X.11.3.175
   THOMSON JA, 1992, BRIT J EDUC PSYCHOL, V62, P173, DOI 10.1111/j.2044-8279.1992.tb01011.x
   Warsh J, 2009, INJURY PREV, V15, P226, DOI 10.1136/ip.2008.020446
   Whitebread D, 2000, BRIT J EDUC PSYCHOL, V70, P539, DOI 10.1348/000709900158290
   World Health Organization, 2008, WORLD REPORT CHILD I
NR 29
TC 18
Z9 19
U1 1
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2014
VL 18
IS 1
SI SI
BP 5
EP 11
DI 10.1007/s10055-013-0238-5
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AB2WI
UT WOS:000331652400002
PM 24678263
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Marini, D
   Folgieri, R
   Gadia, D
   Rizzi, A
AF Marini, Daniele
   Folgieri, Raffaella
   Gadia, Davide
   Rizzi, Alessandro
TI Virtual reality as a communication process
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Semiotics; Communication; Realism
AB In this work, we consider immersive Virtual Reality (VR) as a communication process between humans, mediated by computer systems, which uses interaction, visualization, and other sensory stimuli to convey information. From this viewpoint, it is relevant to understand how VR can solve a given communication problem, what is therefore the expressive power of VR system, i.e., its ability in establishing the communication, what are the guidelines to design an effective system, and what are the more relevant models of VR applications. Firstly, we try to clarify the notion of reality in Virtual Reality systems and conclude that reality is not an intrinsic characteristic of VR, rather the result of a conventional way of coding information. The purpose of coding is to lead the observer to the conclusion that the VR set is what is called in italian as verisimile (from Latin veri similis), i.e., "similar-to-the-real-thing". So the creation of an effective VR application is an artifice or an illusion. But in order to avoid an over-reliance on the creativity of the VR designer, we intend to identify a solid ground on which different kinds of VR solutions can be considered in terms of their ability to solve the desired communication objective. To this aim, we will rely on methods derived from rhetoric to semiotics.
C1 [Marini, Daniele; Gadia, Davide; Rizzi, Alessandro] Univ Milan, Dipartimento Informat & Comunicaz, I-20135 Milan, Italy.
   [Folgieri, Raffaella] Univ Milan, Dipartimento Sci Econ Aziendali & Stat, I-20135 Milan, Italy.
C3 University of Milan; University of Milan
RP Marini, D (corresponding author), Univ Milan, Dipartimento Informat & Comunicaz, Via Comelico 39, I-20135 Milan, Italy.
EM daniele.marini@unimi.it; raffaella.folgieri@unimi.it;
   davide.gadia@unimi.it; alessandro.rizzi@unimi.it
RI Gadia, Davide/P-6309-2016; Folgieri, Raffaella/H-7616-2012; Rizzi,
   Alessandro/I-2138-2012
OI Gadia, Davide/0000-0003-4491-9150; Folgieri,
   Raffaella/0000-0002-0589-5275; 
FU project VIRTHUALIS, VI Framework Program, European Community [515831-2]
FX This work has been partly funded by project VIRTHUALIS, VI Framework
   Program, European Community, contract n. 515831-2. Special thanks to
   Alessandro Giusti, who coordinated the group implementing the industrial
   plant models.
CR Agadir N, 2010, CHEM ENGINEER TRANS, V19, P403, DOI 10.3303/CET1019066
   Alexander A.L., 2005, From gaming to training: A review of studies on fidelity, immersion, presence, and buy-in and their effects on transfer in PC-based simulations and games
   [Anonymous], 1938, Foundations of the Theory of Signs
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Dell'Arco MaurizioFagiolo., 1997, LA FESTA BAROCCA
   Gibson J., 1979, The ecological approach to visual perception
   GOODMAN N, 1968, I LINGUAGGI ARTE
   Hoorn JF, 2002, ACT 3 C INT INT 2002, P154
   Lakoff G., 1993, Truth and Metaphor
   Laurel B., 1991, COMPUTERS THEATRE
   MALDONADO T, 1992, REALE VIRTUALE
   Norman D. A., 1988, PSYCHOL EVERYDAY THI
   Panofsky E, 1927, DIE PERSPEKTIVE ALS
   Slater N, 2003, NOTE PRESENCE TERMIN
NR 14
TC 17
Z9 20
U1 5
U2 65
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2012
VL 16
IS 3
BP 233
EP 241
DI 10.1007/s10055-011-0200-3
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 990MV
UT WOS:000307635900005
DA 2024-07-18
ER

PT J
AU Ha, T
   Lee, Y
   Woo, W
AF Ha, Taejin
   Lee, Youngho
   Woo, Woontack
TI Digilog book for temple bell tolling experience based on interactive
   augmented reality
SO VIRTUAL REALITY
LA English
DT Article
DE Digilog book; Culture technology; User interaction; Multisensory
   experience; Augmented reality
AB We first present the concept of the Digilog Book, an augmented paper book that provides additional multimedia content stimulating readers' five senses using augmented reality (AR) technologies. We also develop a prototype to show the usefulness and effectiveness of the book. The Digilog book has the following characteristics: AR content descriptions for updatable multisensory AR contents; enhanced experience with multisensory feedback; and interactive experience with computerized vision-based manual input methods. As an example of an entertaining and interactive Digilog Book, this paper presents a "temple bell experience" book and its implementation details. Informal user observation and interviews were conducted to verify the feasibility of the prototype book. As a result, this case study of the Digilog book can be useful in guiding the design and implementation of other Digilog applications, including posters, pictures, newspapers, and sign boards.
C1 [Lee, Youngho] MNU U VR Lab, Muan Gun, Jeonnam, South Korea.
   [Ha, Taejin; Woo, Woontack] GIST U VR Lab, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Lee, Y (corresponding author), MNU U VR Lab, 61 Dorim Ri, Muan Gun, Jeonnam, South Korea.
EM tha@gist.ac.kr; youngho@mokpo.ac.kr; wwoo@gist.ac.kr
RI Woo, Woontack/C-3696-2012; Lee, Youngho/R-7938-2019
OI Woo, Woontack/0000-0002-5501-4421; 
FU KOCCA, MCST in S. Korea
FX This research was supported by the CTI development project of KOCCA,
   MCST in S. Korea.
CR [Anonymous], UDAYIV INFORM NUTZBA
   [Anonymous], ACM SIGGRAPH 2003 SK
   [Anonymous], 2007, P 13 INT C VIRT SYST
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   CHEN CH, 2009, 22 CIPA S
   Dunser A., 2007, Proceedings of Technologies for E-Learning and Digital Entertainment 2nd International Conference (Hong Kong, China, June 11-13, P305, DOI [10.1007/978-3-540-73011-8_31, DOI 10.1007/978-3-540-73011-8_31]
   GRASSET R, 2008, INT C ADV COMP ENT T
   HA T, 2006, LNCS ICAT, P207
   Ha T, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P91, DOI 10.1109/3DUI.2010.5444713
   Hollerer T., 1999, ISWC 99, P79
   Irawati S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P201
   LEE G, 2004, ACM SIGGRAPH INT C V, P419
   Lee GA, 2009, J VISUAL LANG COMPUT, V20, P61, DOI 10.1016/j.jvlc.2008.07.001
   LEE J, 2009, DEV PEN TYPE HAPTIC, P402
   McKenzie J., 2004, EYEMAGIC BOOK REPORT
   SCHERRER C, 2008, HAUNTED BOOK, P163
   Sellen A.J., 2003, MYTH PAPERLESS OFFIC
   Shelton B.E., 2002, 1 IEEE INT WORKSHOP
   Shibata F., 2004, 9th VR society of Japan annual conference, P611
   STRICKER D, 2001, INT C AUGM VIRT ENV
   Taketa N., 2007, VIRTUAL POP UP BOOK, P475, DOI [10.1007/978-3-540-73354-6_52, DOI 10.1007/978-3-540-73354-6_52]
   Tosa N, 2005, LECT NOTES COMPUT SC, V3711, P13
   Wagner D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P335, DOI 10.1109/ISMAR.2003.1240747
   WHITE M, 2003, 4 IR WORKSH COMP GRA, P75
   WOODS E, 2004, 2 INT C COMP GRAPH I, P230
   YANG H, 2008, 7 INT C ENT COMP, P161
   ZhiYing Zhou, 2008, International Journal of Virtual Reality, V7, P9
   2007, EYE JUDGEMENT
   OSGART
   2010, ARTOOLKIT
   WIRELESS PRESENTER 3
NR 32
TC 27
Z9 34
U1 2
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2011
VL 15
IS 4
SI SI
BP 295
EP 309
DI 10.1007/s10055-010-0164-8
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IC
UT WOS:000296280300005
DA 2024-07-18
ER

PT B
AU Ilter, T
AF Ilter, Tugrul
BE Kim, JJ
TI The Otherness of Cyberspace, Virtual Reality and Hypertext
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Ilter, Tugrul] Eastern Mediterranean Univ, Nicosia, Cyprus.
C3 Eastern Mediterranean University
RP Ilter, T (corresponding author), Eastern Mediterranean Univ, Nicosia, Cyprus.
CR Agamben G, 1998, REV OCCIDENTE, P63
   Agamben Giorgio., 2005, STATE EXCEPTION
   Althusser Louis., 2009, Reading Capital
   Aronowitz S., 1994, Culture on the brink: Ideologies of technology, P15
   Baudrillard, 1983, SIMULATIONS
   Bauman Z., 1996, MODERNITY HOLOCAUST
   Benedikt Michael., 2000, CYBERCULTURES READER, P29
   Derrida J., 1978, WRITING DIFFERENCE
   Derrida Jacques., 1976, GRAMMATOLOGY
   Derrida Jacques., 2001, TASTE SECRET
   Derrida Jacques., 1982, MARGINS PHILOS
   Foster Hal., 1983, ANTIAESTHETIC, pix
   Grosz E, 1997, ANYBODY, P108
   Haraway D., 2000, CYBERCULTURES READER, P29
   Harlow Barbara., 1999, IMPERIALISM ORIENTAL
   Kroker Arthur., 2000, The Cybercultures Reader, P96
   Kuhn T. S., 1970, STRUCTURE SCI REVOLU
   Landow GeorgeP., 1971, The Aesthetic and Critical Theories of John Ruskin
   Lewis P., 2009, THE GUARDIAN    0302
   Liter T., 1994, Critical Sociology, V20, P51, DOI DOI 10.1177/089692059402000203
   Lyotard Jean-Franois., 1992, POSTMODERN EXPLAINED
   Robins Kevin., 1995, Cyberspace/ Cyberbodies/ Cyberpunk, P135, DOI [10.1177/1357034X95001003008, DOI 10.1177/1357034X95001003008]
   Said Edward, 2003, ORIENTALISM
   Sherman B., 1992, Glimpses of heaven, visions of hell: Virtual reality and its implications
   Spivak G., 1993, OUTSIDE TEACHING MAC
   Spivak Gayatri C., 1988, MARXISM INTERPRETATI, P271
NR 26
TC 1
Z9 1
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 635
EP 646
D2 10.5772/553
PG 12
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400032
DA 2024-07-18
ER

PT B
AU Rey, B
   Alcañiz, M
AF Rey, Beatriz
   Alcaniz, Mariano
BE Kim, JJ
TI Research in Neuroscience and Virtual Reality
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID MORRIS WATER TASK; PATH INTEGRATION; OPTIC FLOW; HIPPOCAMPAL; DISTANCE;
   PERFORMANCE; NAVIGATION; ENVIRONMENT; EXPERIENCE; ADULTS
C1 [Rey, Beatriz; Alcaniz, Mariano] Univ Politecn Valencia, Inst Interuniv Invest Bioingn & Tecnol Orientada, E-46022 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Rey, B (corresponding author), Univ Politecn Valencia, Inst Interuniv Invest Bioingn & Tecnol Orientada, E-46022 Valencia, Spain.
RI Rey, Beatriz/P-6897-2014; Alcañiz, Mariano/CAG-6569-2022
OI Alcañiz, Mariano/0000-0001-9207-0636
CR Alcañiz M, 2009, PRESENCE-TELEOP VIRT, V18, P97, DOI 10.1162/pres.18.2.97
   ARGYLE M, 1965, SOCIOMETRY, V28, P289, DOI 10.2307/2786027
   Astur R, 2005, APPL PSYCHOPHYS BIOF, V30, P307, DOI 10.1007/s10484-005-6385-z
   Astur RS, 2004, BEHAV BRAIN RES, V151, P103, DOI 10.1016/j.bbr.2003.08.024
   Astur RS, 1998, BEHAV BRAIN RES, V93, P185, DOI 10.1016/S0166-4328(98)00019-9
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Cornwell BR, 2008, J NEUROSCI, V28, P5983, DOI 10.1523/JNEUROSCI.5001-07.2008
   Daffertshofer M., 2001, Cerebrovascular ultrasound: theory, practice and future developments, P341
   de Kort YAW, 2003, PRESENCE-TELEOP VIRT, V12, P360, DOI 10.1162/105474603322391604
   Driscoll I, 2003, CEREB CORTEX, V13, P1344, DOI 10.1093/cercor/bhg081
   Duncko R, 2007, LEARN MEMORY, V14, P329, DOI 10.1101/lm.483807
   Foo P, 2005, J EXP PSYCHOL LEARN, V31, P195, DOI 10.1037/0278-7393.31.2.195
   Foo PS., 2004, J. Vis, V4, P892, DOI [10.1167/4.8.892, DOI 10.1167/4.8.892]
   Harvey CD, 2009, NATURE, V461, P941, DOI 10.1038/nature08499
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Hoffman HG, 2003, CYBERPSYCHOL BEHAV, V6, P127, DOI 10.1089/109493103321640310
   Hölscher C, 2005, J EXP BIOL, V208, P561, DOI 10.1242/jeb.01371
   IADECOLA C, 1993, TRENDS NEUROSCI, V16, P206, DOI 10.1016/0166-2236(93)90156-G
   Insko BE, 2003, EMERG COMMUNICAT, V5, P109
   Jacobs WJ, 1998, LEARN MOTIV, V29, P288, DOI 10.1006/lmot.1998.1008
   Jacobs WJ, 1997, LEARN MOTIV, V28, P521, DOI 10.1006/lmot.1997.0977
   Jäncke L, 2009, FRONT NEUROSCI-SWITZ, V3, P52, DOI 10.3389/neuro.01.006.2009
   Kearns MJ, 2002, PERCEPTION, V31, P349, DOI 10.1068/p3311
   Kober S., 2010, P 3 RAVE REAL ACT VI
   LAMPTON DR, 1995, HUM FAC ERG SOC P, P1268
   Leighty KA, 2003, ANIM COGN, V6, P137, DOI 10.1007/s10071-003-0177-8
   LOOMIS JM, 1993, J EXP PSYCHOL GEN, V122, P73, DOI 10.1037/0096-3445.122.1.73
   MILGRAM S, 1963, J ABNORM PSYCHOL, V67, P371, DOI 10.1037/h0040525
   Nishijo H., 2003, SOC NEUR ABSTR, V32, P71714
   OLTON DS, 1976, J EXP PSYCHOL-ANIM B, V2, P97, DOI 10.1037/0097-7403.2.2.97
   Rey B, 2010, VIRTUAL REAL-LONDON, V14, P55, DOI 10.1007/s10055-009-0141-2
   Richardson AR, 2007, HUM FACTORS, V49, P507, DOI 10.1518/001872007X200139
   Schilbach L, 2006, NEUROPSYCHOLOGIA, V44, P718, DOI 10.1016/j.neuropsychologia.2005.07.017
   Schlogl A., 2002, Proceedings of the 5th International Workshop on Presence, V1, P9
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Speckman E. J., 1993, TREATMENT EPILEPSY P, P149
   SUTHERLAND RJ, 1982, NEUROSCI LETT, V31, P271, DOI 10.1016/0304-3940(82)90032-5
   Tarr MJ, 2002, NAT NEUROSCI, V5, P1089, DOI 10.1038/nn948
   Towers D., 2003, SOC NEUR ABSTR, V32, P5186
   Waller D, 2007, BEHAV RES METHODS, V39, P835, DOI 10.3758/BF03192976
   Warren WH, 2001, NAT NEUROSCI, V4, P213, DOI 10.1038/84054
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
NR 46
TC 6
Z9 8
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 377
EP 394
D2 10.5772/553
PG 18
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400018
DA 2024-07-18
ER

PT J
AU Torro, O
   Pirkkalainen, H
AF Torro, Osku
   Pirkkalainen, Henri
TI Design principles for social exchange in social virtual reality-enabled
   virtual teams
SO VIRTUAL REALITY
LA English
DT Article
DE Social virtual reality; Affordance theory; Social exchange theory;
   Trust; Reciprocity; Design theory
ID COMPUTER-MEDIATED COMMUNICATION; FACE-TO-FACE; SELF-REPRESENTATION;
   SCIENCE RESEARCH; WEAK TIES; TRUST; TECHNOLOGY; DISCLOSURE; KNOWLEDGE;
   ONLINE
AB Social virtual reality (SVR) is a novel technology that can simulate and potentially enhance our face-to-face interactions. However, our understanding of interpersonal communication in SVR is still limited. To address this research gap, we describe how SVR enables social exchange (i.e., fundamental communication patterns of trust and reciprocity between individuals), which is closely related to virtual team performance. We present an information systems design theory for social exchange in SVR-enabled virtual teams (SE-SVR). Drawing from affordance theory and social exchange theory, we describe how SVR material properties (i.e., avatars, virtual objects, virtual space, and verbal and nonverbal communication features) enable and foster social exchange in SVR. As a theoretical contribution, we propose design principles for social exchange in SVR and connect them with testable theoretical propositions. Furthermore, we present the concept of interacting with presence, which facilitates users' affordance perceptions in SVR. We conceptually validate our design principles and illustrate our design through an artifact instantiation: XR Campus, which is a minimum viable product of a collaborative platform for the ECIU University. Our SE-SVR theory has important research and practice implications because it explains how critical aspects of organizational remote communication can be considered in SVR design.
C1 [Torro, Osku; Pirkkalainen, Henri] Tampere Univ, Korkeakoulunkatu 7, Tampere 33720, Finland.
C3 Tampere University
RP Torro, O (corresponding author), Tampere Univ, Korkeakoulunkatu 7, Tampere 33720, Finland.
EM osku.torro@tuni.fi; henri.pirkkalainen@tuni.fi
OI Torro, Osku Kalervo Tapio/0000-0003-0706-5010; Pirkkalainen,
   Henri/0000-0002-5389-7363
FU Tampere University including Tampere University Hospital, Tampere
   University of Applied Sciences (TUNI); ECIU University project
   [612521-EPP-1-2019-1-NL-EPPKA2-EUR-UNIV]; European Universities
FX Open access funding provided by Tampere University including Tampere
   University Hospital, Tampere University of Applied Sciences (TUNI). This
   research was co-funded by ECIU University project
   (612521-EPP-1-2019-1-NL-EPPKA2-EUR-UNIV), European Universities funding.
CR Altman I., 1973, Social penetration: The development of interpersonal relationships
   Anthes C, 2016, IEEE AEROSPACE C IEE
   Aral S, 2011, AM J SOCIOL, V117, P90, DOI 10.1086/661238
   Aymerich-Franch L., 2012, Proceedings of the International Society for Presence Research Annual Conference, USA, P24
   Bailenson JN, 2008, COMPUT HUM BEHAV, V24, P66, DOI 10.1016/j.chb.2007.01.015
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Bailenson JN, 2004, PRESENCE-VIRTUAL AUG, V13, P428, DOI 10.1162/1054746041944803
   Bailenson JN, 2002, J VISUAL COMP ANIMAT, V13, P313, DOI 10.1002/vis.297
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Barak A, 2007, CYBERPSYCHOL BEHAV, V10, P407, DOI 10.1089/cpb.2006.9938
   Bargh JA, 1999, AM PSYCHOL, V54, P462, DOI 10.1037/0003-066x.54.7.462
   Baron-Cohen S, 1991, NATURAL THEORIES MIN, P233, DOI DOI 10.1016/J.RIDD.2013.09.027
   Baskerville R, 2018, J ASSOC INF SYST, V19, P358, DOI 10.17705/1jais.00495
   Berg B. L., 2001, QUALITATIVE RES METH
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Bernhard E., 2013, Proceedings of the 34th International Conference on Information Systems (ICIS 2013), P1
   Blau P., 1964, Exchange and power in social life, DOI DOI 10.4324/9780203792643
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   BLUMSTEIN P, 1988, ANNU REV SOCIOL, V14, P467, DOI 10.1146/annurev.so.14.080188.002343
   Bryson S., 1995, VIRTUAL REALITY APPL, P3
   Burgoon J.K., 2011, SAGE HDB INTERPERSON, P239, DOI DOI 10.1177/0149206315621146
   Burgoon JK., 2016, NONVERBAL COMMUNICAT, DOI [10.4324/9781315663425, DOI 10.4324/9781315663425]
   Carruthers P., 1996, Theories of theories of mind
   Colquitt JA, 2007, J APPL PSYCHOL, V92, P909, DOI 10.1037/0021-9010.92.4.909
   Cropanzano R, 2005, J MANAGE, V31, P874, DOI 10.1177/0149206305279602
   Davison RM, 2013, INFORM SYST J, V23, P89, DOI 10.1111/j.1365-2575.2012.00400.x
   de la Rosa S, 2018, BRIT J PSYCHOL, V109, P427, DOI 10.1111/bjop.12302
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dede CJ, 2017, SMART COMPUT INTELL, P1, DOI 10.1007/978-981-10-5490-7_1
   Dennis AR, 2008, MIS QUART, V32, P575
   Derks D, 2008, COMPUT HUM BEHAV, V24, P766, DOI 10.1016/j.chb.2007.04.004
   Dincelli E, 2022, J STRATEGIC INF SYST, V31, DOI 10.1016/j.jsis.2022.101717
   Dubé L, 2009, INFORM SYST J, V19, P3, DOI 10.1111/j.1365-2575.2008.00313.x
   Dugdale M, 2021, VRWORLDTECH MAGAZINE
   ECIU, 2021, BE PART IT EU COMM M
   Elvezio C, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P179, DOI 10.1145/3266037.3271643
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Facebook, 2021, INTRO META SOCIAL TE
   Facebook, 2021, INTRO HORIZON WORKRO
   Faita C, 2015, LECT NOTES COMPUT SC, V9254, P409, DOI 10.1007/978-3-319-22888-4_30
   Faraj S., 2012, Materiality and Organizing, P237, DOI DOI 10.1093/ACPROF:OSO/9780199664054.003.0012
   Faraj S, 2011, ORGAN SCI, V22, P1464, DOI 10.1287/orsc.1100.0600
   Fish R. S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P37, DOI 10.1145/142750.142755
   Fiske S. T., 2010, Handbook of Social Psychology, V2
   Foreman N., 2010, THEMES SCI TECHNOLOG, V2, P225
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Franklin N., 2020, VIRTUAL WORK HAS POT
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Gorlic A, 2020, STANFORD NEWS
   GOULDNER AW, 1960, AM SOCIOL REV, V25, P161, DOI 10.2307/2092623
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   Greenwald S W., 2017, Communications in Computer and Information Science, V725, DOI DOI 10.1007/978-3-319-60633-0_7
   Gregor S, 2007, J ASSOC INF SYST, V8, P312, DOI 10.17705/1jais.00129
   Gregor S, 2020, J ASSOC INF SYST, V21, P1622, DOI 10.17705/1jais.00649
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Gweon H, 2013, COMPREHENSIVE DEVELOPMENTAL NEUROSCIENCE: NEURAL CIRCUIT DEVELOPMENT AND FUNCTION IN THE HEALTHY AND DISEASED BRAIN, P367, DOI 10.1016/B978-0-12-397267-5.00057-1
   Hansen MT, 1999, ADMIN SCI QUART, V44, P82, DOI 10.2307/2667032
   Hasler BS, 2014, CYBERPSYCH BEH SOC N, V17, P766, DOI 10.1089/cyber.2014.0213
   Hatfield E., 1993, CURR DIR PSYCHOL SCI, V2, P96, DOI [DOI 10.1111/1467-8721.EP10770953, 10.1111/1467-8721.ep10770953]
   HOUSE JS, 1988, SCIENCE, V241, P540, DOI 10.1037/0003-066X.59.8.676
   Hung Y.-T. C., 2004, Proceedings of the 37th Annual Hawaii International Conference on System Sciences
   Hung YTC, 2008, IEEE T PROF COMMUN, V51, P352, DOI 10.1109/TPC.2008.2007861
   Iacoboni M., 2009, Mirroring people: The new science of how we connect with others
   Jalo H, 2020, P 28 EUR C INF SYST, P1, DOI DOI 10.1109/ACCESS.2020.3009783
   Jarvenpaa SL, 2004, INFORM SYST RES, V15, P250, DOI 10.1287/isre.1040.0028
   Joinson AN, 2001, EUR J SOC PSYCHOL, V31, P177, DOI 10.1002/ejsp.36
   Kahneman, 2011, THINKING FAST SLOW
   Kock N, 2004, ORGAN SCI, V15, P327, DOI 10.1287/orsc.1040.0071
   Kock N, 2009, MIS QUART, V33, P395
   Konttori U, 2021, TELEPORT ANY REALITY
   KRAUT RE, 1990, CLAR SYMP, V4, P145
   Kunda Z, 1996, PSYCHOL REV, V103, P284, DOI 10.1037/0033-295X.103.2.284
   Lankton NK, 2015, J ASSOC INF SYST, V16, P880, DOI 10.17705/1jais.00411
   Lawler EJ, 2001, AM J SOCIOL, V107, P321, DOI 10.1086/324071
   Levin DZ, 2004, MANAGE SCI, V50, P1477, DOI 10.1287/mnsc.1030.0136
   Lin CP, 2019, REV MANAG SCI, V13, P671, DOI 10.1007/s11846-017-0261-0
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Lowry PB, 2010, INFORM SYST J, V20, P297, DOI 10.1111/j.1365-2575.2009.00334.x
   Markus ML, 2008, J ASSOC INF SYST, V9, P609
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Metzinger TK, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00101
   Minderer M, 2016, NATURE, V533, P324, DOI 10.1038/nature17899
   Molm LD, 2010, SOC PSYCHOL QUART, V73, P119, DOI 10.1177/0190272510369079
   MORAND DA, 1995, ACAD MANAGE REV, V20, P831, DOI 10.2307/258958
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nowak MA, 2005, NATURE, V437, P1291, DOI 10.1038/nature04131
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   OMalley C, 1996, INTERACT COMPUT, V8, P177, DOI 10.1016/0953-5438(96)01027-2
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Ostrom E, 2003, RUSSELL SAGE TRUST, V6, P19
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Peffers K, 2018, EUR J INFORM SYST, V27, P129, DOI 10.1080/0960085X.2018.1458066
   PETTY RE, 1984, ADV CONSUM RES, V11, P668
   Phillippi J, 2018, QUAL HEALTH RES, V28, P381, DOI 10.1177/1049732317697102
   Poeschl S, 2013, P IEEE VIRT REAL ANN, P129, DOI 10.1109/VR.2013.6549396
   Riedl R, 2014, J MANAGE INFORM SYST, V30, P83, DOI 10.2753/MIS0742-1222300404
   Riva G., 2014, Interacting with presence: HCI and the sense of presence in computer-mediated environments
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robert LP, 2009, J MANAGE INFORM SYST, V26, P241, DOI 10.2753/MIS0742-1222260210
   Salas E, 2015, HUM FACTORS, V57, P365, DOI 10.1177/0018720815578267
   Schönbrodt FD, 2011, J MEDIA PSYCHOL-GER, V23, P100, DOI 10.1027/1864-1105/a000040
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Sein MK, 2011, MIS QUART, V35, P37
   Seymour M, 2018, J ASSOC INF SYST, V19, P953, DOI 10.17705/1jais.00515
   Sherrick B, 2014, COMPUT HUM BEHAV, V38, P17, DOI 10.1016/j.chb.2014.05.010
   Skågeby J, 2010, J INF TECHNOL, V25, P170, DOI 10.1057/jit.2010.5
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spagnoletti P, 2015, J INF TECHNOL-UK, V30, P364, DOI 10.1057/jit.2014.37
   Srivastava SC, 2018, MIS QUART, V42, P779, DOI 10.25300/MISQ/2018/11914
   Steed Anthony, 2015, Collaboration in Immersive and Non-immersive Virtual Environments, P263, DOI [DOI 10.1007/978-3-319-10190-3{_}11, 10.1007/978-3-319-10190-3_11, DOI 10.1007/978-3-319-10190-3_11]
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Strong DM, 2014, J ASSOC INF SYST, V15, P53
   Tarr B, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21765-4
   Tidwell LC, 2002, HUM COMMUN RES, V28, P317, DOI 10.1093/hcr/28.3.317
   Torro O, 2022, P 55 HAW INT C SYST
   Torro O, 2021, COMMUN ACM, V64, P48, DOI 10.1145/3440868
   Treem J. W., 2013, COMMUNICATION YB, V36, P143, DOI [https://doi.org/10.1080/23808985.2013.11679130, DOI 10.1080/23808985.2013.11679130]
   van Aken JE, 2004, J MANAGE STUD, V41, P219, DOI 10.1111/j.1467-6486.2004.00430.x
   Vasalou A, 2009, COMPUT HUM BEHAV, V25, P510, DOI 10.1016/j.chb.2008.11.007
   Venable J, 2016, EUR J INFORM SYST, V25, P77, DOI 10.1057/ejis.2014.36
   Volkoff O., 2017, The Routledge Companion to Management Information Systems, P232, DOI DOI 10.4324/9781315619361-18
   Walther J.B., 2011, Handbook of Interpersonal Communication, V4, P443, DOI DOI 10.1016/S0002-9394(03)00123-5
   Walther JB, 1996, COMMUN RES, V23, P3, DOI 10.1177/009365096023001001
   WALTHER JB, 1992, COMMUN RES, V19, P52, DOI 10.1177/009365092019001003
   WALTHER JB, 1995, ORGAN SCI, V6, P186, DOI 10.1287/orsc.6.2.186
   Wasko MM, 2000, J STRATEGIC INF SYST, V9, P155, DOI 10.1016/S0963-8687(00)00045-7
   Weisband S., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P3, DOI 10.1145/238386.238387
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zhao DJ, 2009, GROUP 2009 PROCEEDINGS, P243
NR 135
TC 2
Z9 2
U1 11
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2791
EP 2820
DI 10.1007/s10055-023-00832-w
EA AUG 2023
PG 30
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001049905200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Bahavan, TTN
   Navaratnarajah, S
   Owinda, D
   Akalanka, I
   Peiris, R
   Silva, AD
AF Bahavan, Thiru Thillai Nadarasar
   Navaratnarajah, Suman
   Owinda, Dulindu
   Akalanka, Inoj
   Peiris, Roshan
   Silva, Anjula De
TI Towards an objective measurement of presence, place illusion, and
   plausibility illusion in virtual reality using electroencephalography
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Physiological sensing; Measurement; EEG; Presence;
   Plausibility illusion; Place illusion
ID SPATIAL PRESENCE; POTENTIAL USE; EEG; CORRELATE
AB Presence is a mental state when a user in virtual reality (VR) reacts to events in it as if it is real. Place illusion (PI) and plausibility illusion (PSI) are components of Presence and depend on the Immersion and Coherence of a VR system and the experience. Measuring Presence (PI and PSI) is critical when designing new systems and experiences. However, the traditional questionnaire-based methods of measuring Presence have limitations. Therefore, we propose a method for augmented measurement of Presence, PI, and PSI of VR users with biosignals. For this, we designed a within-subjects experiment that presented VR scenarios with varying levels of Immersion and Coherence while measuring electroencephalography (EEG) of users concurrently. For validation, we took feedback from post-scenario questionnaires presented within the VR environment. The study was conducted with 20 participants. Analyzing the Questionnaire responses revealed that an increase in plausibility illusion or place illusion led to an increase in Presence, confirming the fundamental theory. Analyzing the EEG results revealed that the Envelope Amplitude Correlation features and Spectral Coherence are able to discriminate between the Presence, PI, and PSI of the user. In contrast, there are many entropy features that increase for high PSI.
C1 [Bahavan, Thiru Thillai Nadarasar; Navaratnarajah, Suman; Owinda, Dulindu; Akalanka, Inoj; Silva, Anjula De] Univ Moratuwa, Dept Elect & Telecommun, Bandranayake Mawatha, Colombo 10400, Sri Lanka.
   [Peiris, Roshan] Rochester Inst Technol, Golisano Coll Comp & Informat Sci, 1 Lomb Mem Dr, Rochester, NY 14623 USA.
C3 University Moratuwa; Rochester Institute of Technology
RP Peiris, R (corresponding author), Rochester Inst Technol, Golisano Coll Comp & Informat Sci, 1 Lomb Mem Dr, Rochester, NY 14623 USA.
EM nadarasar.bahavan@gmail.com; roshan.peiris@rit.edu; anjulads@uom.lk
OI De Silva, Anjula/0000-0001-8685-2076; Peiris, Roshan
   Lalintha/0000-0002-4191-3565
CR [Anonymous], 2004, OMNIPRES PROJECT 1 2
   [Anonymous], 2013, BRAIN MAP PARIETAL L
   Athif M, 2020, IEEE ENG MED BIO, P3035, DOI 10.1109/EMBC44109.2020.9176022
   Baka E, 2018, P COMPUTER GRAPHICS, P107, DOI DOI 10.1145/3208159.3208179
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Bouchard S, 2012, INTERACT COMPUT, V24, P227, DOI 10.1016/j.intcom.2012.04.011
   Chang CY, 2020, IEEE T BIO-MED ENG, V67, P1114, DOI 10.1109/TBME.2019.2930186
   Clemente M, 2013, STUD HEALTH TECHNOL, V191, P136, DOI 10.3233/978-1-61499-282-0-136
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P459
   Delgado-Bonal A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060541
   Dey A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P745, DOI [10.1109/VRW50115.2020.00-52, 10.1109/VRW50115.2020.00223]
   Dillon C, 2001, 4 INT WKSHP PRES
   Grassini S, 2021, BRAIN BEHAV, V11, DOI 10.1002/brb3.2269
   Guevara MA, 1996, INT J PSYCHOPHYSIOL, V23, P145, DOI 10.1016/S0167-8760(96)00038-4
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   Kober SE, 2012, INT J HUM-COMPUT ST, V70, P577, DOI 10.1016/j.ijhcs.2012.03.004
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Meehan M, 2005, APPL PSYCHOPHYS BIOF, V30, P239, DOI 10.1007/s10484-005-6381-3
   Moinnereau MA, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.971054
   Morling B, 2011, RES METHODS PSYCHOL, P592
   Palmer J., 2011, TECHNICAL REPORT, P1
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6
   Pion-Tonachini L, 2019, NEUROIMAGE, V198, P181, DOI 10.1016/j.neuroimage.2019.05.026
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Rosakranse C, 2014, 15 INT WORKSHOP PRES
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez Richard T, 2016, PhD thesis
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Terkildsen T, 2019, INT J HUM-COMPUT ST, V126, P64, DOI 10.1016/j.ijhcs.2019.02.006
   Tran Y, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072629
   Vallat R, 2018, INDEPENDENT
   Wang Z, 2021, EFFECT RESTORATIVE E, V55, P293, DOI [10.1007/978-3-030-80091-8_34, DOI 10.1007/978-3-030-80091-8_34]
   Winkler I, 2015, IEEE ENG MED BIO, P4101, DOI 10.1109/EMBC.2015.7319296
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Zhang SF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052647
NR 41
TC 1
Z9 1
U1 6
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2649
EP 2664
DI 10.1007/s10055-023-00815-x
EA JUL 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001031457400001
DA 2024-07-18
ER

PT J
AU Wang, QL
   Zhang, QQ
   Sun, WT
   Boulay, C
   Kim, K
   Barmaki, RL
AF Wang, Qile
   Zhang, Qinqi
   Sun, Weitong
   Boulay, Chadwick
   Kim, Kangsoo
   Barmaki, Roghayeh Leila
TI A scoping review of the use of lab streaming layer framework in virtual
   and augmented reality research
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Augmented reality; Multimodal data collection; Lab
   Streaming layer; Open-source data collection; Literature review
ID BRAIN-COMPUTER INTERFACES; NEUROFEEDBACK; ENVIRONMENTS; STATES; EEG
AB The use of multimodal data allows excellent opportunities for human-computer interaction research and novel techniques regarding virtual and augmented reality (VR/AR) experiences. Collecting, coordinating, and synchronizing a large amount of data from multiple VR/AR hardware while maintaining a high framerate can be a daunting task, despite the compelling nature of multimodal data. The Lab Streaming Layer (LSL) is an open-source framework that enables the synchronous collection of various types of multimodal data, unlike existing expensive alternatives. However, despite its potential, this framework has not been fully adopted by the VR/AR research community. In this paper, we present a guideline of the LSL framework's use in VR/AR research as well as report current trends by performing a comprehensive literature review on the subject. We extract 549 publications using LSL from January 2015 to March 2022. We analyze types of data, displays, and targeted application areas. We describe in-depth reviews of 38 selected papers and provide use of LSL in the VR/AR research community while highlighting benefits, challenges, and future opportunities.
C1 [Wang, Qile; Zhang, Qinqi; Sun, Weitong; Kim, Kangsoo; Barmaki, Roghayeh Leila] Univ Delaware, Newark, DE 19711 USA.
   [Boulay, Chadwick] Ottawa Hosp, Res Inst, Ottawa, ON K1H 8L6, Canada.
   [Kim, Kangsoo] Univ Calgary, Calgary, AB T2N 1N4, Canada.
C3 University of Delaware; University of Ottawa; Ottawa Hospital Research
   Institute; University of Calgary
RP Barmaki, RL (corresponding author), Univ Delaware, Newark, DE 19711 USA.
EM kylewang@udel.edu; qinqi@udel.edu; edwina@udel.edu; chboulay@ohri.ca;
   kangsoo.kim@ucalgary.ca; rlb@udel.edu
RI Kim, Kangsoo/AAL-9592-2020; WANG, QILE/KFA-5783-2024
OI Kim, Kangsoo/0000-0002-0925-378X; WANG, QILE/0000-0003-0308-6033
CR Aukstakalnis S., 2016, PRACTICAL AUGMENTED
   Bablani A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3297713
   Banaei M, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00477
   Berger L.M., 2021, Games and Learning Alliance, P111, DOI [10.1007/978-3-030-92182-811, DOI 10.1007/978-3-030-92182-811]
   Blum S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21238135
   Bustamante S, 2021, IEEE T HUM-MACH SYST, V51, P568, DOI 10.1109/THMS.2021.3106865
   Callahan-Flintoft C, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.650693
   Cruz-Garza JG, 2021, ARXIV
   Cuevas-Rodríguez M, 2012, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON INTERACCION PERSONA-ORDENADOR (INTERACCION'12), DOI 10.1145/2379636.2379667
   Delaux A., 2021, bioRxiv, p2021.01
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Djebbara Z, 2019, P NATL ACAD SCI USA, V116, P14769, DOI 10.1073/pnas.1900648116
   Eckert M, 2021, INT WORK QUAL MULTIM, P73, DOI 10.1109/QoMEX51781.2021.9465417
   Faller J, 2019, P NATL ACAD SCI USA, V116, P6482, DOI 10.1073/pnas.1817207116
   Gorman C, 2021, 2021 IEEE S SERIES C, P1
   Gregory SEA, 2022, DATA BRIEF, V41, DOI 10.1016/j.dib.2022.107827
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.000-5, 10.1109/VR46266.2020.1581313729558]
   Hertweck S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P970, DOI [10.1109/VR.2019.8798369, 10.1109/vr.2019.8798369]
   Huo K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173793
   Insko BE, 2003, EMERG COMMUNICAT, V5, P109
   Jo D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194330
   Sánchez-Cuesta FJ, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57080736
   Kalantari S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89297-y
   Kisker J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.716318
   Klug M, 2021, EUR J NEUROSCI, V54, P8406, DOI 10.1111/ejn.14992
   Kothe C., 2014, Lab streaming layer
   Kroczek LOH, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00561
   Kumar M, 2021, IEEE SYS MAN CYBERN, P2689, DOI 10.1109/SMC52423.2021.9658916
   Langton SRH, 2000, TRENDS COGN SCI, V4, P50, DOI 10.1016/S1364-6613(99)01436-9
   Lapborisuth P, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/ac4593
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lécuyer A, 2008, COMPUTER, V41, P66, DOI 10.1109/MC.2008.410
   Li GH, 2022, IEEE T CYBERNETICS, V52, P5720, DOI 10.1109/TCYB.2021.3061420
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Mane R, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/aba162
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Mavros P, 2016, APPL SPAT ANAL POLIC, V9, P191, DOI 10.1007/s12061-015-9181-z
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Miyakoshi M, 2021, EUR J NEUROSCI
   Mladenovic J, 2022, IEEE T BIO-MED ENG, V69, P1101, DOI 10.1109/TBME.2021.3113854
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Muller CO, 2021, TRIALS, V22, DOI 10.1186/s13063-021-05689-5
   Nagele AN, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.610320
   Nenna F, 2021, EUR J NEUROSCI, V54, P8158, DOI 10.1111/ejn.14956
   Newman J, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P192, DOI 10.1109/ISMAR.2004.62
   Nyomen K., 2015, Proceedings of the International Conference on New Interfaces for Musical Expression, P215
   Park JL, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00361
   Pavlik RA, 2010, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY, P351
   Peterson SM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0207-18.2018
   Plopski A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491207
   Putze F, 2019, IEEE SYS MAN CYBERN, P2812, DOI 10.1109/SMC.2019.8914390
   Quintero L, 2021, INT SYM MIX AUGMENT, P357, DOI 10.1109/ISMAR52148.2021.00052
   Reitmayr G., 2005, VIRTUAL REAL-LONDON, V9, P79, DOI DOI 10.1007/S10055-005-0006-2
   Renard Y, 2010, PRESENCE-VIRTUAL AUG, V19, P35, DOI 10.1162/pres.19.1.35
   Rezaee Z, 2021, CEREBELLUM, V20, P853, DOI 10.1007/s12311-021-01249-4
   Si-Mohammed H, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P653, DOI [10.1109/VR46266.2020.1581262194646, 10.1109/VR46266.2020.00-16]
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Sra M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173914
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Thomas J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P115, DOI 10.1109/VR.2014.6802078
   Torres EP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185083
   Valente A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P158, DOI 10.1109/VR51125.2022.00034
   VIDAL JJ, 1973, ANNU REV BIOPHYS BIO, V2, P157, DOI 10.1146/annurev.bb.02.060173.001105
   Vortmann Lisa-Marie, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382889
   Vortmann LM, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3463507
   Vortmann LM, 2021, INFORMATION, V12, DOI 10.3390/info12060226
   Vortmann LM, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00348
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00210
   Wang Q, 2021, P ACM S SPAT US INT
   Weber D, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.733673
   Welch G.F., 2019, Anticipating widespread augmented reality: Insights from the 2018 ar visioning workshop
   Wunderlich A., 2020, bioRxiv, p2020.06.08.139469
NR 72
TC 3
Z9 3
U1 7
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2195
EP 2210
DI 10.1007/s10055-023-00799-8
EA MAY 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000979223200001
DA 2024-07-18
ER

PT J
AU Palmisano, S
   Allison, RS
   Teixeira, J
   Kim, J
AF Palmisano, Stephen
   Allison, Robert S.
   Teixeira, Joel
   Kim, Juno
TI Differences in virtual and physical head orientation predict sickness
   during active head-mounted display-based virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Head-mounted display; Motion sickness; Cybersickness; Virtual reality;
   Motion-to-photon latency; Sensory conflict
ID VISUALLY INDUCED MOTION; SENSORY CONFLICT; DESK-TOP; CYBERSICKNESS;
   ENVIRONMENTS; SYMPTOMS; ROLL; HMD; HABITUATION; AMPLITUDE
AB During head-mounted display (HMD)-based virtual reality (VR), head movements and motion-to-photon-based display lag generate differences in our virtual and physical head pose (referred to as DVP). We propose that large-amplitude, time-varying patterns of DVP serve as the primary trigger for cybersickness under such conditions. We test this hypothesis by measuring the sickness and estimating the DVP experienced under different levels of experimentally imposed display lag (ranging from 0 to 222 ms on top of the VR system's similar to 4 ms baseline lag). On each trial, seated participants made continuous, oscillatory head rotations in yaw, pitch or roll while viewing a large virtual room with an Oculus Rift CV1 HMD (head movements were timed to a computer-generated metronome set at either 1.0 or 0.5 Hz). After the experiment, their head-tracking data were used to objectively estimate the DVP during each trial. The mean, peak, and standard deviation of these DVP data were then compared to the participant's cybersickness ratings for that trial. Irrespective of the axis, or the speed, of the participant's head movements, the severity of their cybersickness was found to increase with each of these three DVP summary measures. In line with our DVP hypothesis, cybersickness consistently increased with the amplitude and the variability of our participants' DVP. DVP similarly predicted their conscious experiences during HMD VR-such as the strength of their feelings of spatial presence and their perception of the virtual scene's stability.
C1 [Palmisano, Stephen; Teixeira, Joel] Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
   [Allison, Robert S.] York Univ, Ctr Vis Res, Toronto, ON, Canada.
   [Allison, Robert S.] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON, Canada.
   [Kim, Juno] Univ New South Wales, Sch Optometry & Vis Sci, Wollongong, NSW, Australia.
C3 University of Wollongong; York University - Canada; York University -
   Canada; University of New South Wales Sydney
RP Palmisano, S (corresponding author), Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
EM stephenp@uow.edu.au
RI ; Palmisano, Stephen/O-1553-2018
OI Teixeira, Joel/0009-0003-9154-044X; Allison, Robert/0000-0002-4485-2665;
   Palmisano, Stephen/0000-0002-9140-5681
FU Australian Research Council (ARC) Discovery Project [DP210101475]
FX This research was supported by an Australian Research Council (ARC)
   Discovery Project (DP210101475)
CR Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Bles W, 2000, CURR OPIN NEUROL, V13, P19, DOI 10.1097/00019052-200002000-00005
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Bos JE, 2002, BIOL CYBERN, V86, P191, DOI 10.1007/s00422-001-0289-7
   Bos JE, 1998, BRAIN RES BULL, V47, P537, DOI 10.1016/S0361-9230(98)00088-4
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bubka A, 2003, AVIAT SPACE ENVIR MD, V74, P315
   Caserman P, 2019, LECT NOTES COMPUT SC, V11863, P57, DOI 10.1007/978-3-030-34644-7_5
   Claremont CA., 1931, PSYCHE, V11, P86
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de Graaf B, 1998, BRAIN RES BULL, V47, P489, DOI 10.1016/S0361-9230(98)00116-6
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Diels C, 2011, DISPLAYS, V32, P175, DOI 10.1016/j.displa.2011.02.005
   DiZio P, 1997, ADV HUM FACT ERGON, V21, P893
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Golding JF, 2016, HAND CLINIC, V137, P371, DOI 10.1016/B978-0-444-63437-5.00027-3
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   Howarth PA, 1999, APPL ERGON, V30, P39, DOI 10.1016/S0003-6870(98)00041-6
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Irmak T, 2021, EXP BRAIN RES, V239, P515, DOI 10.1007/s00221-020-05986-6
   Jennings S, 2004, J AIRCRAFT, V41, P1327, DOI 10.2514/1.449
   Jennings S., 2000, HUM FACTORS, V44, P69
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kennedy R. S., 1994, AGARD CP VIRTUAL INT, V5412, P1
   Kennedy RS., 1994, Proceedings of "Virtual Reality and Medicine: The Cutting Edge.", P111
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Keshavarz Behrang., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications Issue September, P647, DOI [DOI 10.1201/B17360-32, https://doi.org/10.1201/b17360-32]
   Kim J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.582156
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kingdon KellyS., 2001, PROCEEDINGS ofthe HUMANFACTORS AND ERGONOMICS SOCIETY 45th ANNUAL MEETING, P1906, DOI DOI 10.1177/154193120104502711
   Kinsella A, 2016, AEROSP MED HUM PERF, V87, P604, DOI 10.3357/AMHP.4351.2016
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lackner JR, 2020, J NEUROPHYSIOL, V123, P1206, DOI 10.1152/jn.00139.2019
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   LORCH RF, 1990, J EXP PSYCHOL LEARN, V16, P149, DOI 10.1037/0278-7393.16.1.149
   Luu W., 2019, P SIGGRAPH AS SIGGRA, DOI [10.1145/3355056.3364590, DOI 10.1145/3355056.3364590]
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Oman CM, 2014, EXP BRAIN RES, V232, P2483, DOI 10.1007/s00221-014-3973-2
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2022, VIRTUAL REAL-LONDON, V26, P1373, DOI 10.1007/s10055-022-00634-6
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Pierre MES, 2015, DISPLAYS, V36, P1, DOI 10.1016/j.displa.2014.10.005
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   Stoffregen TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066949
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   van Waveren JMP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P37, DOI 10.1145/2993369.2993375
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yates BJ, 2014, EXP BRAIN RES, V232, P2455, DOI 10.1007/s00221-014-3937-6
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yildirim C, 2019, DISPLAYS, V59, P35, DOI 10.1016/j.displa.2019.07.002
NR 80
TC 10
Z9 10
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1293
EP 1313
DI 10.1007/s10055-022-00732-5
EA DEC 2022
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000900826400001
PM 36567954
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Frydenberg, SG
   Nordby, K
AF Frydenberg, Synne G.
   Nordby, Kjetil
TI Virtual fieldwork on a ship's bridge: virtual reality-reconstructed
   operation scenarios as contextual substitutes for fieldwork in design
   education
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality-reconstructed operation scenarios; VR simulator;
   Contextual support; Interaction design education; Fieldwork; Augmented
   reality
ID INTERNET
AB Designing for professional, high-risk user contexts often implies limited accessibility for interaction designers to conduct field research and field testing, and the measures taken by most universities in Norway in 2020 to prevent COVID-19 spread have further contributed to the problem of achieving the contextual insight needed throughout the design process by severely restricting travel for research purposes. In this paper, we describe the use of virtual reality-reconstructed operation scenarios (VRROS) for Arctic-going vessels implemented in support of and as a substitute for the contextual aspects of fieldwork in the education of master's students studying interaction design. The virtual reality rig contains three scenarios contextualizing ships' bridges and their surroundings originally developed for research on designing navigation and operation applications using augmented reality technology. We evaluate whether aspects of the VRROS can substitute for real fieldwork by evaluating students' use of the VRROS using a student questionnaire. Finally, we discuss the value and potential of using VRROS as a supplement and support when studying how to design for hard-to-reach contexts in the future.
C1 [Frydenberg, Synne G.; Nordby, Kjetil] Oslo Sch Architecture & Design, Oslo, Norway.
C3 Oslo School of Architecture & Design
RP Frydenberg, SG (corresponding author), Oslo Sch Architecture & Design, Oslo, Norway.
EM synne.g.frydenberg@aho.no; kjetil.nordby@aho.no
RI Frydenberg, Synne/HSG-6492-2023
OI Frydenberg, Synne/0000-0001-6422-8678; Nordby,
   Kjetil/0000-0002-9044-8938
FU EU project SEDNA; European Union [723526]; H2020 Societal Challenges
   Programme [723526] Funding Source: H2020 Societal Challenges Programme
FX The research presented in this article was funded by the EU project
   SEDNA. This project received funding from the European Union's Horizon
   2020 programs for research and innovation under Grant Agreement No.
   723526.
CR Adobe, 2021, AD EFF
   Anderson L. W., 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   Bloom B., 1956, Taxonomy of educational objectives: the classification of educational goals, handbook 1, cognitive domain
   Frydenberg S, 2018, RINA INT C HUMAN FAC
   Frydenberg S, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9090996
   GARNAUT R, 1992, ECONOMIC REFORM AND INTERNATIONALISATION: CHINA AND THE PACIFIC REGION, P1
   Getchell K, 2010, IEEE T LEARN TECHNOL, V3, P281, DOI 10.1109/TLT.2010.25
   Gonzaga L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P561, DOI 10.1109/VR.2018.8446511
   Granshaw FD, 2012, GEOL SOC AM SPEC PAP, V492, P285, DOI 10.1130/2012.2492(20)
   Gushima Kota, 2021, Virtual, Augmented and Mixed Reality. 13th International Conference, VAMR 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings, P417, DOI 10.1007/978-3-030-77599-5_29
   Luras Sigrun, 2013, Interactions, V20, P32, DOI 10.1145/2530539
   Lurs S, 2015, INT C MAR DES 2015 L
   Lurs S, 2014, INT C HUM FACT SHIP
   Lurs S, 2016, DISSERTATION
   Mäkelä V, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376796
   Mejías A, 2017, QUAL REP, V22, P3011
   Microsoft hololens, MIX REAL TECHN BUS
   Minocha S., 2018, KNOWLEDGE EXCHANGE S, DOI DOI 10.1111/1751-7915.12804
   Mirauda D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224972
   Mkono M, 2012, TOUR ANAL, V17, P553, DOI 10.3727/108354212X13473157390966
   Nordby K., 2020, 19 C COMP APPL INF T
   Nordby K, 2019, ERGOSHIP 2019 C
   Nordby K, 2018, HUM FACT C 2018 LOND
   NVIDIA, 2021, PROD GEFORCE RTX 309
   Rekittke J., 2021, J DIG LANDSCAPE ARCH, V6, P462, DOI [10.14627/537705041, DOI 10.14627/537705041]
   Robins R.W., 2007, HDB RES METHODS PERS
   Schon D., 1984, The Reflective Practitioner: How Professionals Think in Action
   SEDNA-project.eu, 2017, SEDNA
   Seifan M, 2019, EDUC CHEM ENG, V27, P6, DOI 10.1016/j.ece.2018.11.005
   Tidwell J., 2010, Designing interfaces: Patterns for effective interaction design
   Unity, 2020, 3D SOFTW ARCH ENG SX
   Zeller M., 2019, HOLOLENS 1 GEN HARDW
NR 32
TC 5
Z9 5
U1 2
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3333
EP 3344
DI 10.1007/s10055-022-00655-1
EA JUN 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000804496500001
PM 35669613
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Flotynski, J
AF Flotynski, Jakub
TI Visual aspect-oriented modeling of explorable extended reality
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE Extended reality; 3D web; Exploration; Semantic web; Ontologies;
   Aspect-oriented modeling
ID ONTOLOGY; REPRESENTATION
AB The availability of various extended reality (XR) systems for tracking users' and objects' behavior opens new opportunities for analyzing users' and objects' interactions and autonomous actions. Such analysis can be especially useful and attainable to domain experts when it is based on domain knowledge related to a particular application, liberating the analysts from going into technical details of 3D content. Analysis of XR users' and objects' behavior can provide knowledge about the users' experience, interests and preferences, as well as objects' features, which may be valuable in various domains, e.g., training, design and marketing. However, the available methods and tools for building XR focus on 3D modeling and programming rather than knowledge representation, making them unsuitable for domain-oriented analysis. In this paper, a new visual approach to modeling explorable XR environments is proposed. It is based on a semantic representation of aspects, which extend the primary code of XR environments to register their behavior in a form explorable with reasoning and queries, appropriate for high-level analysis in arbitrary domains. It permits domain experts to comprehend and analyze what happened in an XR environment regarding users' and objects' actions and interactions. The approach has been implemented as an extension to MS Visual Studio and demonstrated in an explorable immersive service guide for household appliances. The evaluation results show that the approach enables efficient development of explorable XR and may be useful for people with limited technical skills.
C1 [Flotynski, Jakub] Poznan Univ Econ & Business, Niepodleglosci 10, PL-61875 Poznan, Poland.
C3 Poznan University of Economics & Business
RP Flotynski, J (corresponding author), Poznan Univ Econ & Business, Niepodleglosci 10, PL-61875 Poznan, Poland.
EM flotynski@kti.ue.poznan.pl
RI Flotyński, Jakub/IWU-8229-2023
OI Flotyński, Jakub/0000-0001-5104-2022
CR [Anonymous], 2015, LECT NOTES BUSINESS
   [Anonymous], 2017, An Introduction to Description Logic, DOI DOI 10.1017/9781139025355
   [Anonymous], 2009, Encyclopedia of Database Systems, DOI DOI 10.1007/978-0-387-39940-91318
   [Anonymous], 3ds max
   Artale A, 2000, ANN MATH ARTIF INTEL, V30, P171, DOI 10.1023/A:1016636131405
   Autodesk, MOT BUILD
   Baader F., 2010, DESCRIPTION LOGIC HD, V2nd
   Baset S, 2018, INT J SOFTW ENG KNOW, V28, P1775, DOI 10.1142/S0218194018400284
   Batsakis S., 2009, SEMANT WEB, V8, P20
   Ben Ellefi M, 2019, INT ARCH PHOTOGRAMM, V42-2, P31, DOI 10.5194/isprs-archives-XLII-2-W10-31-2019
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Chmielewski, 2012, MULTIMED TOOLS APPL, V69, P1
   Chmielewski J, 2008, MOMM 08, P397, DOI DOI 10.1145/1497185.1497270
   Chmielewski J., 2012, Interactive 3D Multimedia Content, P195, DOI [10.1007/978-1-4471-2497-9_8, DOI 10.1007/978-1-4471-2497-9_8]
   Chu Y, 2008, VRCAI 08
   Chu YuLin, 2012, Applications of Virtual Reality
   De Troyer Olga, 2007, Virtual Reality, V11, P89, DOI 10.1007/s10055-006-0058-y
   De Troyer O., 2007, Tutorials, posters, panels and industrial contributions at the 26th international conference on Conceptual modeling-Volume 83, V83, P3
   Divakaran A., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P29
   dotNetRDF, 2020, DOTN OP SOURC NET LI
   Drap P, 2017, IN SY AP IN WE HC, V10577, P3, DOI 10.1007/978-3-319-70407-4_1
   FFmpeg, 2020, COMPL CROSS PLATF SO
   FLOTYNSKI J, 2019, INT C 3D IMMERSION I
   Flotynski J., 2020, KNOWLEDGE BASED EXPL
   Flotynski J, 2019, IEEE ICCE, P370, DOI [10.1109/icce-berlin47944.2019.8966215, 10.1109/ICCE-Berlin47944.2019.8966215]
   Flotynski J, 2018, 2018 INTERNATIONAL CONFERENCE ON 3D IMMERSION (IC3D)
   Flotynski J, 2017, COMPUT GRAPH FORUM, V36, P329, DOI 10.1111/cgf.13083
   Flotynski J, 2014, COMPUT SCI INF SYST, V11, P1555, DOI 10.2298/CSIS131218073F
   Games E, 2020, UNREAL ENGINE
   Garcia-Rojas A, 2006, P 1 INT WORKSH SHAP, P63
   Gayathri R, 2018, ICT EXPRESS, V4, P69, DOI [10.1016/j.icte.2018.04.008, 10.1016/j.jcte.2018.04.008]
   Gownder J., 2016, Breakout vendors: Virtual and augmented reality"
   Gutiérrez M, 2007, VISUAL COMPUT, V23, P207, DOI 10.1007/s00371-006-0093-4
   Gutierrez C, 2005, LECT NOTES COMPUT SC, V3532, P93
   ISO, 2015, 15938132015 ISO IEC
   Kalogerakis E, 2006, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2006.41
   Klein MichelCA., 2001, SWWS, P75
   KLEINERMANN F, 2005, P 2 INTUITION INT WO, P5
   Lugrin JL, 2009, THESIS U TEESSIDE MI
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mkhinini MM, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100223
   Noy N, 2006, PHCW DEFINING N ARY
   Open-Link, 2020, VIRT OP SOURC
   Pellens B, 2005, LECT NOTES COMPUT SC, V3762, P1215
   Pellens B., 2005, P VIRT CONC 2005 BIA, P93, DOI [10.1007/2-287-28773-6, DOI 10.1007/2-287-28773-6]
   PELLENS B, 2006, P ACM S VIRT REAL SO, P334
   Pellens B, 2009, IE 09
   Pellens B, 2008, PROCEEDINGS OF THE 13TH INTERNATIONAL SYMPOSIUM ON 3D WEB TECHNOLOGY (WEB3D 2008), P91, DOI 10.1145/1394209.1394229
   Perez-Gallardo Y, 2017, INTEL SYST REF LIBR, V120, P137, DOI 10.1007/978-3-319-51905-0_7
   Pouriyeh SA, 2018, ARXIV180506051 CORR
   Rabattu PY, 2015, J BIOMED SEMANT, V6, DOI 10.1186/s13326-015-0034-0
   Sikos L., 2017, Description Logics in Multimedia Reasoning
   Sikos LF, 2017, WEB3D 2017, DOI 10.1145/3055624.3075943
   Spring Framework, 2020, ASP OR PROGR SPR
   The Blender Foundation, 2020, BLENDER
   Trellet M, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0004
   Trellet M, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P48, DOI 10.1109/IMMERSIVE.2016.7932383
   Unity 3D, 2020, SCREEN CAPT SCREENSH
   Vasilakis G, 2010, INT J SOFTW ENG KNOW, V20, P739, DOI 10.1142/S0218194010004773
   W3C, 2017, X3D
   W3C, 2012, WEB ONT LANG, V2
   W3C, 2013, SPARQL
   W3C, 2014, RDFS
   W3C, 2012, OWL
   Walczak K, 2015, WEB3D 2015, P123, DOI 10.1145/2775292.2775311
   Web3D Consortium, 2019, X3D ONT SEM WEB
   Web3D Consortium, 2020, X3D SEM WEB
   Welty C, 2006, FRONT ARTIF INTEL AP, V150, P226
   World Wide Web Consortium, 2020, TIM ONT OWL W3C CAND
   World Wide Web Consortium, 2013, RDF 11 JSON ALT SER
   World Wide Web Consortium, 2020, JSON LD 11 A JSON BA
   World Wide Web Consortium, 2014, RDF 11 TURTL
NR 72
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 939
EP 961
DI 10.1007/s10055-021-00601-7
EA NOV 2021
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000722996900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, CH
AF Yang, Chuan Hao
TI Motion control of virtual reality based on an inertia-based sensing
   mechanism and a novel approach to redirected walking
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Motion control; Ranging sensor; Inertial sensor;
   Virtual environment; Redirected walking
ID LOCOMOTION
AB This research presents a motion control algorithm for constructing a portable virtual reality system, which can operate in any indoor or outdoor open space without the need for support from any pre-installed infrastructure. The real head and foot motions continuously measured by inertial sensors during natural walking are used as a part of the inputs to the algorithm to control the virtual walking motions of the user. In conjunction with such control, a novel approach to redirected walking is incorporated in the algorithm to continuously adjust the rotation of the virtual environment to redirect the user away from the boundary (i.e., walls and objects) of the real environment. Such an approach, namely the relative approach, adopts the directions and distances of the boundary relative to the user (i.e., the relative local information) instead of the absolute positions and orientations of the user for performing redirection. A ranging sensor is used for collecting the relative local information. The effectiveness of the algorithm was experimentally verified and demonstrated.
C1 [Yang, Chuan Hao] Natl Def Univ, Dept Informat Management, Taipei, Taiwan.
C3 National Defense University - Taiwan
RP Yang, CH (corresponding author), Natl Def Univ, Dept Informat Management, Taipei, Taiwan.
EM franky051205@gmail.com
CR [Anonymous], [No title captured]
   [Anonymous], 2006, B.B.C. News
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Calusdian, 2012, THESIS NAVAL POSTGRA
   Creagh H, 2003, PROCEEDINGS: ELECTRICAL INSULATION CONFERENCE AND ELECTRICAL MANUFACTURING & COIL WINDING TECHNOLOGY CONFERENCE, P499, DOI 10.1109/EICEMC.2003.1247937
   Cyberith, 2013, PROD VIRT VIRT REAL
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Evans-Thirlwell, 2017, HIST 1 PERSON SHOOTE
   Hirt C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P573, DOI 10.1109/VR.2018.8446262
   Hirt C, 2018, LECT NOTES COMPUT SC, V10850, P35, DOI 10.1007/978-3-319-95270-3_3
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hollerbach J, 2005, INT C REHAB ROBOT, P522
   Iwata H, 1999, IEEE COMPUT GRAPH, V19, P30, DOI 10.1109/38.799737
   Iwata H, 1999, P IEEE VIRT REAL ANN, P286, DOI 10.1109/VR.1999.756964
   Krogh B., 1984, P SME C ROB RES NEXT, P11
   Latombe J.-C, 1991, ROBOT MOTION PLANNIN, P295, DOI [10.1007/978-1-4615-4022-9_7, DOI 10.1007/978-1-4615-4022-9_7]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Microsoft, 2011, KIN XBOX 1
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Onder M, 2005, THESIS NAVAL POSTGRA
   Peck TC, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P121
   Peck Tabitha C, 2009, IEEE Trans Vis Comput Graph, V15, P383, DOI 10.1109/TVCG.2008.191
   Peck TC, 2012, IEEE T VIS COMPUT GR, V18, P1053, DOI 10.1109/TVCG.2011.289
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Quest, 2019, NEXT LEV VR GAM
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Razzaque S., 2005, REDIRECTED WALKING
   Steinicke F, 2018, ENCY COMPUTER GRAPHI
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   University of Utah School of Computing, 2019, LOC DISPL
   Vijayakar A, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P231, DOI 10.1109/HAPTIC.2002.998963
   Virtuix, 2013, OMNI VIRTUIX
   Waller D, 2007, BEHAV RES METHODS, V39, P835, DOI 10.3758/BF03192976
   Whitton M, 2010, IEEE ACM DIS SIM, P3, DOI 10.1109/DS-RT.2010.38
   Yun X, 2007, IEEE INT CONF ROBOT, P2526, DOI 10.1109/ROBOT.2007.363845
   Yun XP, 2012, IEEE T INSTRUM MEAS, V61, P2059, DOI 10.1109/TIM.2011.2179830
   Yuri XP, 2008, IEEE T INSTRUM MEAS, V57, P638, DOI 10.1109/TIM.2007.911646
NR 40
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 479
EP 500
DI 10.1007/s10055-021-00581-8
EA OCT 2021
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000706026900001
DA 2024-07-18
ER

PT J
AU Gomes, A
   Fernandes, K
   Wang, DV
AF Gomes, Adam
   Fernandes, Keegan
   Wang, David
TI Surface Prediction for Spatial Augmented Reality Applications
SO VIRTUAL REALITY
LA English
DT Article
DE Spatial augmented reality; Control theory; Surface representations
ID DEFORMATION; MODEL
AB In spatial augmented reality applications, incorrect projection mapping may occur when projecting images onto moving non-rigid surfaces. This may detract from the user experience, as the image may not be perceived as originally intended. This is especially apparent when using low-cost projectors and cameras or when surfaces are moving quickly. In this paper, an algorithm is developed which predicts the motion of a non-rigid surface, so that when an image is being projected onto the surface, the projection "matches" the surface shape, while using low-cost equipment. Using an interconnected mass-spring-damper system to model the surface, the surface position is predicted using a Kalman filter-based algorithm, which also compensates for the processing delays and fast-moving surfaces. To accurately model real-world materials, the mass-spring system parameters are found using a system identification approach. When the prediction algorithm is implemented experimentally, in real-time, the results show convergent results in the sense that the surface predictions converge to the measured position of a non-rigid surface. The error results show that the algorithm is both accurate and robust and can currently be applied in spatial augmented reality applications.
C1 [Gomes, Adam; Fernandes, Keegan; Wang, David] Univ Waterloo, Waterloo, ON, Canada.
C3 University of Waterloo
RP Gomes, A (corresponding author), Univ Waterloo, Waterloo, ON, Canada.
EM adgomes@uwaterloo.ca
CR [Anonymous], 2012, OPTIMAL FILTERING SE
   [Anonymous], 2013, Proc. CHI 2013, DOI DOI 10.1145/2470654.2470688
   [Anonymous], 2015, INPROCEEDINGS 21 ACM
   Arasaratnam I., 2009, Ph.D. thesis
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698
   Bridson R., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P28
   Chen YQ, 2006, IEEE T PATTERN ANAL, V28, P1525, DOI 10.1109/TPAMI.2006.190
   Daniel Gomes Adam, 2016, THESIS
   Eberhardt B, 1996, IEEE COMPUT GRAPH, V16, P52, DOI 10.1109/38.536275
   Gibson S F, 1997, TECHNICAL REPORT
   Gillette Russell, 2015, P 14 ACM SIGGRAPH EU, P17
   GRANVILLE V, 1994, IEEE T PATTERN ANAL, V16, P652, DOI 10.1109/34.295910
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Hilsmann A, 2010, COMPUT GRAPH-UK, V34, P567, DOI 10.1016/j.cag.2010.05.015
   Kavan Ladislav, 2011, ACM SIGGRAPH 2011 papers
   Kocev B, 2014, INT J COMPUT ASS RAD, V9, P301, DOI 10.1007/s11548-013-0928-1
   Livolsi B, 2015, INPUT LAG PROJECTORS
   Lloyd BA, 2007, IEEE T VIS COMPUT GR, V13, P1081, DOI 10.1109/TVCG.2007.1055
   Natural Point, 2011, OPT
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Park FC, 2005, 2005 12TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, P1
   Piper B., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P355, DOI 10.1145/503376.503439
   PROVOT X, 1995, GRAPH INTER, P147
   Punpongsanon P, 2015, VIRTUAL REAL-LONDON, V19, P45, DOI 10.1007/s10055-014-0256-y
   Sakamaki S, 2013, SIGGRAPH AS 2013, P1
   Teschner M, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P312, DOI 10.1109/CGI.2004.1309227
   Varol A, 2009, IEEE I CONF COMP VIS, P1811, DOI 10.1109/ICCV.2009.5459403
NR 28
TC 0
Z9 1
U1 2
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 761
EP 771
DI 10.1007/s10055-020-00490-2
EA JAN 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000604533200002
DA 2024-07-18
ER

PT J
AU Garcia-Hernandez, N
   Guzman-Alvarado, M
   Parra-Vega, V
AF Garcia-Hernandez, Nadia
   Guzman-Alvarado, Miguel
   Parra-Vega, Vicente
TI Virtual body representation for rehabilitation influences on motor
   performance of cerebral palsy children
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual body representation; Virtual environments; Cerebral palsy;
   Movement analysis; Rehabilitation
ID RANDOMIZED CONTROLLED-TRIAL; MOVEMENT SMOOTHNESS; VIDEO-GAME; REALITY;
   ARM; MOTION; INDIVIDUALS; RECOVERY; EXERCISE
AB Game-based virtual reality systems have been shown to enhance motor function, motivation and therapy adherence in cerebral palsy (CP) children. In these systems, several types of virtual body representations have been implemented, however without conclusive support of guidelines nor the most appropriate choice for enhancing motor performance. Thus, the purpose of this study is to examine how the subjective experience of seeing and controlling a half-body avatar, or an abstract hand representation in a moderate immersion virtual environment (VE), for training upper limb movements may affect CP children's motor performance. To achieve that purpose, a game-like VE for training the reaching-releasing of objects was designed. Unlike previous studies, relevant task performance and cost function metrics were obtained from the analysis of kinematic and kinetic parameters of movement. Results show that visualizing the hand movement through an abstract object makes children perform faster, correct less to produce smoother movements, and use less mechanical energy than visualizing the arm movement through a realistic Avatar. These effects were more noticeable in the reaching than in the releasing phase of the task. Based on these findings, some recommendations are provided for the effective design and use of VE's for upper limb rehabilitation of CP children.
C1 [Garcia-Hernandez, Nadia; Guzman-Alvarado, Miguel; Parra-Vega, Vicente] Natl Polytech Inst CINVESTAV IPN, Ctr Res & Adv Studies, Robot & Adv Mfg Dept, Saltillo, Coahuila, Mexico.
   [Garcia-Hernandez, Nadia] Natl Council Sci & Technol CONACYT, Mexico City, DF, Mexico.
RP Garcia-Hernandez, N (corresponding author), Natl Polytech Inst CINVESTAV IPN, Ctr Res & Adv Studies, Robot & Adv Mfg Dept, Saltillo, Coahuila, Mexico.; Garcia-Hernandez, N (corresponding author), Natl Council Sci & Technol CONACYT, Mexico City, DF, Mexico.
EM nadia.garcia@cinvestav.mx
RI Parra-Vega, Vicente/A-1871-2008
OI Parra-Vega, Vicente/0000-0002-1813-0394; Garcia Hernandez, Nadia
   Vanessa/0000-0003-1944-0519
FU Mexican National Council of Science and Technology (CONACYT) [592022,
   3309]
FX Funding for this work comes from Grant 3309 and Graduate Scholarship
   592022, both from the Mexican National Council of Science and Technology
   (CONACYT) Research Funding.
CR Aboelnasr EA, 2017, BRAIN INJURY, V31, P83, DOI 10.1080/02699052.2016.1210230
   Acosta AM, 2011, J REHABIL RES DEV, V48, P431, DOI 10.1682/JRRD.2010.04.0052
   Adamovich SV, 2009, RESTOR NEUROL NEUROS, V27, P209, DOI 10.3233/RNN-2009-0471
   Adams RJ, 2018, IEEE T NEUR SYS REH, V26, P252, DOI 10.1109/TNSRE.2017.2771272
   Ajami S, 2015, J RES MED SCI, V20, P321
   Aresta M, 2013, DIGITAL IDENTITY AND SOCIAL MEDIA, P176, DOI 10.4018/978-1-4666-1915-9.ch013
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bank PJM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1100-9
   Bartolo M, 2014, FUNCT NEUROL, V29, P15, DOI 10.11138/FNeur/2014.29.1.015
   Bergamasco M, 1996, VIRTUAL REALITY, V2, P129
   Berret B, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002183
   Berret B, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000194
   Bianchi-Berthouze N, 2013, HUM-COMPUT INTERACT, V28, P40, DOI 10.1080/07370024.2012.688468
   Cabrera R, 2017, INT J HUM-COMPUT ST, V108, P62, DOI 10.1016/j.ijhcs.2017.07.004
   Cameirao MS, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-48
   Camporesi C, 2016, IEEE T VIS COMPUT GR, V22, P1592, DOI 10.1109/TVCG.2015.2440231
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Chen YP, 2007, PHYS THER, V87, P1441, DOI 10.2522/ptj.20060062
   Collins KC, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00472
   Coluccini M, 2007, GAIT POSTURE, V25, P493, DOI 10.1016/j.gaitpost.2006.12.015
   Craig JJ., 2004, Introduction to Robotics: Mechanics and Control, V41, P388, DOI 10.7227/IJEEE.41.4.11
   Crocetta TB, 2018, VIRTUAL REAL-LONDON, V22, P199, DOI 10.1007/s10055-017-0323-2
   d'Ornellas MC, 2015, STUD HEALTH TECHNOL, V216, P363, DOI 10.3233/978-1-61499-564-7-363
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   Reyes-Guzmán ADL, 2014, CLIN BIOMECH, V29, P719, DOI 10.1016/j.clinbiomech.2014.06.013
   dos Santos LF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0289-4
   Eckert M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020354
   Escalona F, 2020, VIRTUAL REAL-LONDON, V24, P567, DOI 10.1007/s10055-019-00419-4
   Farshchiansadegh A, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004861
   Formica D, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-106
   Garcia-Hernandez N, 2019, COMPUT METHODS BIOME
   Gerig N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189275
   Hanh N, 2009, J CYBER THER REHABIL, V2, P221
   Heinrich C, 2020, VIRTUAL REAL, P1
   Hernoux F, 2015, VIRTUAL REAL-LONDON, V19, P1, DOI 10.1007/s10055-014-0255-z
   Hinton PR., 2004, SPSS explained, DOI DOI 10.4324/9780203642597
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Hogan N, 2009, J MOTOR BEHAV, V41, P529, DOI 10.3200/35-09-004-RC
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Housman SJ, 2009, NEUROREHAB NEURAL RE, V23, P505, DOI 10.1177/1545968308331148
   Inamura T, 2017, ADV ROBOTICS, V31, P97, DOI 10.1080/01691864.2016.1264885
   Kafri M, 2014, NEUROREHAB NEURAL RE, V28, P56, DOI 10.1177/1545968313497100
   Kim H, 2013, IEEE T NEUR SYS REH, V21, P153, DOI 10.1109/TNSRE.2012.2207462
   LACQUANITI F, 1982, J NEUROSCI, V2, P399, DOI 10.1523/JNEUROSCI.02-04-00399.1982
   Lee S, 2018, KOREAN J ANESTHESIOL, V71, P353, DOI 10.4097/kja.d.18.00242
   Levant A, 1998, AUTOMATICA, V34, P379, DOI 10.1016/S0005-1098(97)00209-4
   Lopes S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01712
   Ma S, 2012, VIRTUAL REAL-LONDON, V16, P325, DOI 10.1007/s10055-012-0209-2
   Mason AH, 2019, INT J HUM-COMPUT INT, V35, P1870, DOI 10.1080/10447318.2019.1574101
   Michie S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7126
   Mobini A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0070-0
   Myrhaug HT, 2014, BMC PEDIATR, V14, DOI 10.1186/s12887-014-0292-5
   Oguz OS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-23792-7
   Ozkaya N, 2016, Fundamentals of biomechanics: equilibrium, motion, and deformation
   Perez-Marcos D, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0461-0
   Qiu QY, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-40
   Reid Denise, 2004, Occup Ther Int, V11, P131, DOI 10.1002/oti.202
   Ren Z, 2019, INT J ENV RES PUBLIC
   Rohrer B, 2002, J NEUROSCI, V22, P8297
   Saavedra S, 2009, EXP BRAIN RES, V192, P155, DOI 10.1007/s00221-008-1549-8
   Samaraweera G, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P23, DOI 10.1109/3DUI.2013.6550192
   Sandlund M, 2011, DEV NEUROREHABIL, V14, P15, DOI 10.3109/17518423.2010.533329
   Schafer AY, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-76
   Sha DH, 2010, J APPL BIOMECH, V26, P32, DOI 10.1123/jab.26.1.32
   Singer M.J., 1998, Effect of a body model on performance in a virtual environment search task (ARI Technical Report 1087)
   Snider L, 2010, DEV NEUROREHABIL, V13, P120, DOI 10.3109/17518420903357753
   Spong M.W., 2020, Robot Modeling and Control
   Subramanian SK, 2013, NEUROREHAB NEURAL RE, V27, P13, DOI 10.1177/1545968312449695
   Syed UE, 2021, DISABIL REHABIL-ASSI, V16, P332, DOI 10.1080/17483107.2019.1679266
   Tyrrell R, 2018, VIRTUAL REAL-LONDON, V22, P211, DOI 10.1007/s10055-017-0324-1
   Van Hedel H. J. A., 2016, J NEUROENG REHABIL, V13, P1
   Vandenberghe A, 2010, GAIT POSTURE, V32, P500, DOI 10.1016/j.gaitpost.2010.07.009
   Viau Antonin, 2004, J Neuroeng Rehabil, V1, P11, DOI 10.1186/1743-0003-1-11
   Wade DT, 2009, CLIN REHABIL, V23, P291, DOI 10.1177/0269215509103551
   Wilson PH, 2006, 2006 INTERNATIONAL WORKSHOP ON VIRTUAL REHABILITATION, P47, DOI 10.1109/IWVR.2006.1707526
   Winter D. A., 2009, Biomechanics and motor control of human movement, DOI 10.1002/9780470549148
   Yildirim C, 2019, VIRTUAL REAL
   Yoon G., 2016, Asiascape: Digital Asia, V3, P79, DOI DOI 10.1163/22142312-12340049
   Zhang JJQ, 2018, NEURAL PLAST, V2018, DOI 10.1155/2018/2321045
   Zoccolillo L, 2015, EUR J PHYS REHAB MED, V51, P669
NR 80
TC 10
Z9 10
U1 1
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 669
EP 680
DI 10.1007/s10055-020-00481-3
EA OCT 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000582808800001
DA 2024-07-18
ER

PT J
AU Lipson-Smith, R
   Bernhardt, J
   Zamuner, E
   Churilov, L
   Busietta, N
   Moratti, D
AF Lipson-Smith, Ruby
   Bernhardt, Julie
   Zamuner, Edoardo
   Churilov, Leonid
   Busietta, Nick
   Moratti, Damian
TI Exploring colour in context using Virtual Reality: Does a room change
   how you feel?
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Colour preference; Healthcare design; Mood
ID SURFACE LIGHTNESS; INTERIOR COLORS; PERFORMANCE; APPEARANCE; DISPLAYS;
   IMPACT; MOOD
AB The colour-in-context theory suggests that our reactions to colour vary depending on the context in which the colour is presented. Our understanding of how colour affects mood in different contexts is not well understood. We used Virtual Reality to explore mood and valence (colour preference) responses to colours in three different contexts: a living room, a hospital waiting room, and an empty cube-shaped room. Our hypothesis was that mood and preference responses to colour would vary depending on the virtual environment in which it was presented. Members of the general public participated in this prospective, within-participant case-crossover experimental study. Participants were randomised to one of the eight clusters, with five different colours presented in each cluster. Forty colours were investigated in total. Participants used a Google Daydream View head-mounted display to view the three virtual room environments, which each appeared 'painted' in one of the five different colours. Participants provided mood and valence responses at each exposure. Random effects logistic regression was used to explore responses to the colours in context. A total of 745 people participated. In one cluster, the mood and valence responses were significantly different in response to the same colour(s) in different rooms, indicating that context can impact mood and valence responses to colours. Virtual Reality is a feasible methodology to study colour in context. We found that the context in which a colour is presented can impact mood and valence responses, but this was not consistent across clusters.
C1 [Lipson-Smith, Ruby; Bernhardt, Julie] Univ Melbourne, Florey Inst Neurosci & Mental Hlth, Heidelberg, Vic, Australia.
   [Lipson-Smith, Ruby; Bernhardt, Julie; Churilov, Leonid] NHMRC Ctr Res Excellence Stroke Rehabil & Brain R, Heidelberg, Vic, Australia.
   [Zamuner, Edoardo; Busietta, Nick; Moratti, Damian] Liminal VR Pty Ltd, Abbotsford, Vic, Australia.
   [Churilov, Leonid] Univ Melbourne, Melbourne Med Sch, Parkville, Vic, Australia.
C3 University of Melbourne; Florey Institute of Neuroscience & Mental
   Health; University of Melbourne
RP Bernhardt, J (corresponding author), Univ Melbourne, Florey Inst Neurosci & Mental Hlth, Heidelberg, Vic, Australia.; Bernhardt, J (corresponding author), NHMRC Ctr Res Excellence Stroke Rehabil & Brain R, Heidelberg, Vic, Australia.
EM julie.bernhardt@florey.edu.au
RI Lipson-Smith, Ruby/AAS-9687-2020; Bernhardt, Julie/F-9538-2015
OI Lipson-Smith, Ruby/0000-0002-1702-8144; Bernhardt,
   Julie/0000-0002-2787-8484
FU Taubmans(R) paints; NHMRC [1154904]; Victorian Government's Operational
   Infrastructure Support Grant; National Health and Medical Research
   Council of Australia [1154904] Funding Source: NHMRC
FX Taubmans (R) paints provided seed funding of AUD$30,000 for this project
   (see conflict of interest statement), which contributed to partial
   salary support for authors EZ and LC to assist with data acquisition and
   analysis. -Taubmans (R) did not have any role in the study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript. The specific roles of all authors are articulated in
   "Author's contributions" section. JB is funded by an NHMRC Research
   Fellowship (1154904). The Florey Institute of Neuroscience and Mental
   Health acknowledges the support of the Victorian Government's
   Operational Infrastructure Support Grant.
CR Al-Rasheed AS, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00030
   Andrade CC, 2016, ENVIRON BEHAV, V48, P299, DOI 10.1177/0013916514536182
   [Anonymous], 2017, R LANG ENV STAT COMP
   Banaei M, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00477
   Cooper EA, 2013, J VISION, V13, DOI 10.1167/13.12.16
   Desmet, 2012, 8 INT DES EM C LOND
   Djebbara Z., 2019, BRAIN ART BRAIN COMP, P265, DOI [10.1007/978-3-030-14323-7_9, DOI 10.1007/978-3-030-14323-7_9]
   Elliot AJ, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00368
   Elliot AJ, 2012, ADV EXP SOC PSYCHOL, V45, P61, DOI 10.1016/B978-0-12-394286-9.00002-0
   Elliot AJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034607
   García-Pérez MA, 2001, SPATIAL VISION, V14, P201, DOI 10.1163/156856801300202931
   Genschow O, 2015, PSYCHOL CRIME LAW, V21, P482, DOI 10.1080/1068316X.2014.989172
   Ghamari H., 2016, Social Anthropology, V4, P1020, DOI [10.13189/sa.2016.041109, DOI 10.13189/SA.2016.041109]
   Gil S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104291
   Jonauskaite D, 2019, COLOR RES APPL, V44, P272, DOI 10.1002/col.22327
   Jonauskaite D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152194
   Kaya N., 2004, COLL STUD J, V38, P396
   Kellert StephenR., 2011, Biophilic Design: The Theory, Science and Practice of Bringing Buildings to Life
   Krenn B, 2015, J SPORT EXERCISE PSY, V37, P207, DOI 10.1123/jsep.2014-0274
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Kwallek N, 1997, COLOR RES APPL, V22, P121, DOI 10.1002/(SICI)1520-6378(199704)22:2<121::AID-COL7>3.0.CO;2-V
   Kwallek N, 1996, COLOR RES APPL, V21, P448, DOI 10.1002/(SICI)1520-6378(199612)21:6<448::AID-COL7>3.0.CO;2-W
   Liu WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090646
   Munshell AH, 1912, AM J PSYCHOL, V23, P236, DOI 10.2307/1412843
   Oberfeld D, 2011, HUM FACTORS, V53, P284, DOI 10.1177/0018720811407331
   Oberfeld D, 2010, Q J EXP PSYCHOL, V63, P1999, DOI 10.1080/17470211003646161
   Pardo PJ, 2004, DISPLAYS, V25, P159, DOI 10.1016/j.displa.2004.09.006
   PELLEGRINI RJ, 1981, J ORTHOMOL MED, V10, P174
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Stamps AE, 2011, ENVIRON BEHAV, V43, P252, DOI 10.1177/0013916509354696
   StataCorp, 2015, STAT STAT SOFTW REL
   Tofle RuthBrent., 2004, Color Healthcare Environments-A Research Report
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   von Castell C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201976
   von Castell C, 2018, HUM FACTORS, V60, P1228, DOI 10.1177/0018720818789524
   von Castell C, 2018, COLOR RES APPL, V43, P65, DOI 10.1002/col.22168
   WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219
   Xiao KD, 2011, COLOR RES APPL, V36, P201, DOI 10.1002/col.20610
   Xiao KD, 2010, COLOR RES APPL, V35, P284, DOI 10.1002/col.20575
   Yildirim K, 2015, INDOOR BUILT ENVIRON, V24, P607, DOI 10.1177/1420326X14526214
   Yildirim K, 2011, PERCEPT MOTOR SKILL, V112, P509, DOI 10.2466/24.27.PMS.112.2.509-524
NR 41
TC 11
Z9 13
U1 3
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 631
EP 645
DI 10.1007/s10055-020-00479-x
EA OCT 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000581014300001
DA 2024-07-18
ER

PT J
AU Zhou, XJ
   Zhang, Y
   Chen, GH
   Zheng, MX
AF Zhou, Xiaojing
   Zhang, Ye
   Chen, Guohua
   Zheng, Minxue
TI A model for physics-based fire simulation and analysis
SO VIRTUAL REALITY
LA English
DT Article
DE Fire; Flame; Physics-based simulation; Navier-stokes equations; Virtual
   reality; Fire detection
ID ANIMATION; SPREAD; SMOKE
AB This paper describes the development of a three-dimensional (3D) physics-based fire simulation model that employs the incompressible Navier-Stokes equations to realistically emulate the combustion process. Then, we animate the 3D interactive burning processes by rendering a flame under a set of influence factors and with various solid boundaries and obstacles. It is insufficient to simply create a virtual reality-based fire model. Instead, evaluating the similarity and accuracy of the models requires data processing for the virtual flames. In this paper, detailed data are extracted from the simulation results to compute the fire's geometrical features and the distribution of the density and velocity fields. Using methods for video-based fire detection, some visual features of the simulated-fire videos are extracted and compared with those of real fires. The results show the capability of the physics-based fire model in representing some features of real flames. The proposed quantitative analysis of virtual flames serves to evaluate the similarity between a virtual and a real fire.
C1 [Zhou, Xiaojing; Zhang, Ye] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
   [Chen, Guohua] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Peoples R China.
   [Zheng, Minxue] Jiangsu Univ, Sch Environm & Safety Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Jiangsu
   University
RP Zhou, XJ (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM xiaojingzhou@seu.edu.cn
CR [Anonymous], 2003, P GAME DEVELOPER C
   [Anonymous], 2002, Computational methods for fluid dynamics
   [Anonymous], 2008, Fluid Simulation for Computer Graphics
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Çetin AE, 2013, DIGIT SIGNAL PROCESS, V23, P1827, DOI 10.1016/j.dsp.2013.07.003
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   CHIBA N, 1994, J VISUAL COMP ANIMAT, V5, P37, DOI 10.1002/vis.4340050104
   Chorin A.J., 1990, A Mathematical Introduction to Fluid Mechanics
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   HARLOW FH, 1965, PHYS FLUIDS, V8, P2182, DOI 10.1063/1.1761178
   Horvath C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531347
   Inakage M, 1990, SIMPLE MODEL FLAMES, P71
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Li J-M, 2007, J SYST SIMUL, V19, P10
   Melek Z, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P431, DOI 10.1109/PCCGA.2002.1167889
   Moreno A, 2014, FIRE SAFETY J, V64, P48, DOI 10.1016/j.firesaf.2014.01.005
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Perry CH, 1994, SYNTHESIZING FLAMES
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J, 2000, COMMUN ACM, V43, P76, DOI 10.1145/341852.341866
   Tannehill J.C., 2011, COMPUTATIONAL FLUID, V3rd
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Wijbenga JAM, 1995, COMPUT CARDIOL, P129, DOI 10.1109/CIC.1995.482589
   Williams-Bell FM, 2015, FIRE TECHNOL, V51, P553, DOI 10.1007/s10694-014-0398-1
NR 27
TC 3
Z9 3
U1 3
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 421
EP 432
DI 10.1007/s10055-020-00465-3
EA AUG 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000558619500001
DA 2024-07-18
ER

PT J
AU Morasse, F
   Vera-Estay, E
   Beauchamp, MH
AF Morasse, Frederick
   Vera-Estay, Evelyn
   Beauchamp, Miriam H.
TI Using virtual reality to optimize assessment of sociomoral skills
SO VIRTUAL REALITY
LA English
DT Article
DE Social cognition; Virtual reality; Assessment; Empathy; Adolescents
ID TRAUMATIC BRAIN-INJURY; SOCIAL COMPETENCE; MORAL DEVELOPMENT;
   ENVIRONMENT TECHNOLOGY; EMPATHY; EMOTIONS; CHILDREN; JUDGMENT;
   INFORMATION; COGNITION
AB Sociocognitive evaluation is an important component of comprehensive neuropsychological assessment. However, concerns have been raised as to whether traditional assessment methods such as paper-and-pencil questionnaire adequately represent real-life abilities. Virtual reality (VR) has the potential to increase ecological value by providing experimental conditions that are similar to those in a real-world environment. This project aimed to explore the potential benefits of using VR in the assessment of adolescent sociocognitive skills, specifically with regard to sociomoral decision-making and reasoning. A computer-based version and a VR version of the So-Moral task were used to compare the performance of adolescents aged 12-25 (n = 30) on sociomoral skills. In both versions, participants were presented with everyday sociomoral dilemmas and were asked to explain how they would react (sociomoral decision-making) and why (sociomoral maturity). The Interpersonal Reactivity Index and the Immersive Tendencies Questionnaire were completed to investigate the association between sociomoral skills, empathy and sense of presence. In both versions of the task, participants provided similar levels of sociomoral decision-making ( F(1,26)=2.05, p = 0.16) and maturity (F(1,26)=1.92 , p = 0.18). Empathy was associated with presence (r = 0.39, p = 0.048) and with sociomoral maturity (r = 0.46, p = 0.01) only when assessed in VR, explaining a significant 21% of the variability in outcome. Together, these results support the notion of a disparity between static and dynamic sociocognitive assessment tools and suggest that the association between sociocognitive skills and underlying social or affective substrates may be susceptible to stimuli saliency and presentation.
C1 [Morasse, Frederick; Vera-Estay, Evelyn; Beauchamp, Miriam H.] Univ Montreal, Dept Psychol, 90 Vincent dIndy, Montreal, PQ H2V 2S9, Canada.
   [Beauchamp, Miriam H.] St Justine Hosp Res Ctr, Montreal, PQ, Canada.
   [Vera-Estay, Evelyn] Pontificia Univ Catolica Chile, Ctr Desarrollo Tecnol Inclus, Escuela Psicol, Av Vicuna Mackenna, Santiago 4860, Chile.
C3 Universite de Montreal; Universite de Montreal; Centre Hospitalier
   Universitaire Sainte-Justine; Pontificia Universidad Catolica de Chile
RP Beauchamp, MH (corresponding author), Univ Montreal, Dept Psychol, 90 Vincent dIndy, Montreal, PQ H2V 2S9, Canada.
EM frederick.morasse@umontreal.ca; ec.vera.estay@umontreal.ca;
   miriam.beauchamp@umontreal.ca
OI Beauchamp, Miriam/0000-0002-8637-6361
FU Natural Sciences and Engineering Research Council of Canada; Fond de
   Recherche du Quebec-Nature et technologies [RGPIN-2018-04542]
FX This study was funded by the Natural Sciences and Engineering Research
   Council of Canada and a master's scholarship to FM from the Fond de
   Recherche du Quebec-Nature et technologies (Grant number
   RGPIN-2018-04542). The funding body was not involved in the study
   design, collection, analysis or interpretation of data, nor in the
   writing of the manuscript and the decision to submit the article for
   publication.
CR Achim AM, 2013, PSYCHOL ASSESSMENT, V25, P117, DOI 10.1037/a0029137
   ADAMS GR, 1983, J YOUTH ADOLESCENCE, V12, P203, DOI 10.1007/BF02090986
   Arsenio WF, 2004, CHILD DEV, V75, P987, DOI 10.1111/j.1467-8624.2004.00720.x
   Beauchamp M, 2012, ADM CODING MANUAL SO
   Beauchamp MH, 2013, BRAIN INJURY, V27, P896, DOI 10.3109/02699052.2013.775486
   Beauchamp MH, 2017, NEUROPSYCHOLOGY, V31, P981, DOI 10.1037/neu0000395
   Beauchamp MH, 2010, PSYCHOL BULL, V136, P39, DOI 10.1037/a0017768
   Bebeau MJ, 2002, J MORAL EDUC, V31, P271, DOI 10.1080/0305724022000008115
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Blair RJR, 1997, PERS INDIV DIFFER, V22, P731, DOI 10.1016/S0191-8869(96)00249-8
   Blakemore SJ, 2008, NAT REV NEUROSCI, V9, P267, DOI 10.1038/nrn2353
   Blanchette I, 2004, PSYCHOL SCI, V15, P745, DOI 10.1111/j.0956-7976.2004.00751.x
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bosacki S, 1999, SOC DEV, V8, P237, DOI 10.1111/1467-9507.00093
   Bouchard S, 2013, CYBERPSYCH BEH SOC N, V16, P61, DOI 10.1089/cyber.2012.1571
   Brüne M, 2005, PSYCHIAT RES, V133, P135, DOI 10.1016/j.psychres.2004.10.007
   BRYANT BK, 1982, CHILD DEV, V53, P413, DOI 10.1111/j.1467-8624.1982.tb01331.x
   Canty AL, 2017, NEUROPSYCHOL REHABIL, V27, P834, DOI 10.1080/09602011.2015.1052820
   Carlo G., 1992, J RES ADOLESCENCE, V2, P331, DOI [10.1207/s15327795jra0204_3, DOI 10.1207/S15327795JRA0204_3]
   Chiasson V, 2017, CLIN NEUROPSYCHOL, V31, P515, DOI 10.1080/13854046.2016.1268650
   CHRISTOFI M, 2017, 23 INT C VIRT SYST M
   Clore GL, 2007, TRENDS COGN SCI, V11, P393, DOI 10.1016/j.tics.2007.08.005
   Cohen J., 1988, STAT POWER ANAL BEHA
   CRICK NR, 1994, PSYCHOL BULL, V115, P74, DOI 10.1037/0033-2909.115.1.74
   Davis M. H., 1980, INTERPERSONAL REACTI, DOI [https://doi.org/10.1037/t01093-000, DOI 10.1037/T01093-000]
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Decety J, 2006, CURR DIR PSYCHOL SCI, V15, P54, DOI 10.1111/j.0963-7214.2006.00406.x
   Dooley JJ, 2010, BRAIN IMPAIR, V11, P152, DOI 10.1375/brim.11.2.152
   Eisenberg N., 2014, PROSOCIAL DEV MULTID, P17
   Fiske S.T., 1991, SOCIAL COGNITION
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Francis KB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164374
   Frijda N. H., 1986, EMOTIONS
   FRIJDA NH, 1988, AM PSYCHOL, V43, P349, DOI 10.1037/0003-066X.43.5.349
   Frith CD, 2008, PHILOS T R SOC B, V363, P3875, DOI 10.1098/rstb.2008.0156
   Gibbs J.C., 2010, MORAL DEV REALITY TH, V2nd
   Gillath O, 2008, MEDIA PSYCHOL, V11, P259, DOI 10.1080/15213260801906489
   Greene JD, 2009, COGNITION, V111, P364, DOI 10.1016/j.cognition.2009.02.001
   Guli LA, 2013, ART PSYCHOTHER, V40, P37, DOI 10.1016/j.aip.2012.09.002
   Hanten G, 2011, NEUROPSYCHOLOGIA, V49, P486, DOI 10.1016/j.neuropsychologia.2010.12.007
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Keltner D., 2014, Understanding Emotions
   Klin A, 2000, J CHILD PSYCHOL PSYC, V41, P831, DOI 10.1111/1469-7610.00671
   Kohlberg L., 1958, The development of modes of moral thinking and choice in the years 10 to 16 (Doctoral dissertation)
   Kohlberg Lawrence., 1983, Moral stages: A current formulation and a response to critics
   Korkman M., 2012, NEPSY 2, VSeconde
   Lalonde G, 2013, J NEUROSCI METH, V219, P76, DOI 10.1016/j.jneumeth.2013.07.005
   Lardén M, 2006, PSYCHOL CRIME LAW, V12, P453, DOI 10.1080/10683160500036855
   Lawrence EJ, 2004, PSYCHOL MED, V34, P911, DOI 10.1017/S0033291703001624
   LECAVALIER NC, 2018, NEUROPSYCHOL REHABIL
   Lerner JS, 2015, ANNU REV PSYCHOL, V66, P799, DOI 10.1146/annurev-psych-010213-115043
   Levenson R.W., 1994, The nature of emotion: Fundamental questions, P123
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Malti T., 2012, Encyclopedia of human behavior, V2nd, P644, DOI DOI 10.1016/B978-0-12-375000-6.00099-9
   Martins AT, 2012, JUDGM DECIS MAK, V7, P478
   Moll J, 2005, NAT REV NEUROSCI, V6, P799, DOI 10.1038/nrn1768
   Morris MW, 2000, RES ORGAN BEHAV, V22, P1, DOI 10.1016/S0191-3085(00)22002-9
   MUUSS RE, 1982, ADOLESCENCE, V17, P499
   Navarrete CD, 2012, EMOTION, V12, P364, DOI 10.1037/a0025561
   Nolin P, 2016, COMPUT HUM BEHAV, V59, P327, DOI 10.1016/j.chb.2016.02.023
   Oatley K, 1992, Annu Rev Psychol, V43, P55, DOI 10.1146/annurev.ps.43.020192.000415
   OSTRUM T, 1984, SOVEREIGNTY SOCIAL C
   Pan X., 2011, P 25 BCS C HUM COMP
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   PARKER JG, 1987, PSYCHOL BULL, V102, P357, DOI 10.1037/0033-2909.102.3.357
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Patil I, 2014, SOC NEUROSCI-UK, V9, P94, DOI 10.1080/17470919.2013.870091
   Pizarro D, 2000, J THEOR SOC BEHAV, V30, P355, DOI 10.1111/1468-5914.00135
   Risko EF, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00143
   Riva G, 2004, CYBERPSYCHOL BEHAV, V7, P402, DOI 10.1089/cpb.2004.7.402
   Robillard G., 2002, P 25IEME CONGRES SOC
   Rubin K.H., 1992, HDB SOCIAL DEV LIFES, P283, DOI [10.1007/978-1-4899-0694-6_12, DOI 10.1007/978-1-4899-0694-6_12]
   Russo-Ponsaran N, 2018, AUTISM RES, V11, P305, DOI 10.1002/aur.1889
   SANNA M, 2018, NEUROPSYCHIAT ENFAN, V66, P315, DOI DOI 10.1016/J.NEURENF.2018.05.004
   Schilbach L, 2015, CURR OPIN BEHAV SCI, V3, P130, DOI 10.1016/j.cobeha.2015.03.006
   Schonfeld AM, 2005, J STUD ALCOHOL, V66, P545, DOI 10.15288/jsa.2005.66.545
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schultheis MT, 2002, J HEAD TRAUMA REHAB, V17, P378, DOI 10.1097/00001199-200210000-00002
   Schutte NS, 2017, MOTIV EMOTION, V41, P708, DOI 10.1007/s11031-017-9641-7
   Scourfield J, 1999, BRIT J PSYCHIAT, V175, P559, DOI 10.1192/bjp.175.6.559
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Skulmowski A, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00426
   SMETANA JG, 1990, MORALITY CONDUCT DIS, P157
   SPITZBERG BH, 2003, HDB COMMUNICATION SO, P111, DOI DOI 10.4324/9781410607133-9
   Stams GJ, 2006, J ABNORM CHILD PSYCH, V34, P697, DOI 10.1007/s10802-006-9056-5
   Sutton J, 1999, SOC DEV, V8, P117, DOI 10.1111/1467-9507.00083
   Tangney JP, 2007, ANNU REV PSYCHOL, V58, P345, DOI 10.1146/annurev.psych.56.091103.070145
   Thoma SJ, 2000, J MIND BEHAV, V21, P129
   Thompson RA, 2012, CHILD DEV PERSPECT, V6, P423, DOI 10.1111/j.1750-8606.2012.00245.x
   Turiel E., 1983, DEV SOCIAL KNOWLEDGE
   van den Bos R, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00301
   Van Vugt E, 2011, INT J OFFENDER THER, V55, P1234, DOI 10.1177/0306624X11396441
   Wechsler D., 1999, WASI: Wechsler Adult Scale - reduced
   WENTZEL KR, 1991, CHILD DEV, V62, P1066, DOI 10.2307/1131152
   Wilson B. A., 1993, APPL PREV PSYCHOL, V2, P209, DOI [10.1016/S0962-1849(05)80091-5, DOI 10.1016/S0962-1849(05)80091-5, https://doi.org/10.1016/S0962-1849(05)80091-5, 10.1016/S0962-1849, DOI 10.1016/S0962-1849]
   Winter K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00745-0
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Young S, 2008, J FORENSIC PSYCHI PS, V19, P191, DOI 10.1080/14789940701740172
NR 99
TC 4
Z9 4
U1 3
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 123
EP 132
DI 10.1007/s10055-020-00443-9
EA MAY 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000534863000002
DA 2024-07-18
ER

PT J
AU Pellas, N
   Fotaris, P
   Kazanidis, I
   Wells, D
AF Pellas, Nikolaos
   Fotaris, Panagiotis
   Kazanidis, Ioannis
   Wells, David
TI Augmenting the learning experience in primary and secondary school
   education: a systematic review of recent trends in augmented reality
   game-based learning
SO VIRTUAL REALITY
LA English
DT Review
DE Augmented reality; Game-based learning; Systematic review; Primary
   education; Secondary education
ID SCIENCE-EDUCATION; ACHIEVEMENTS; INSTRUCTION; CHALLENGES; DESIGN; IMPACT
AB There is a significant body of research relating to augmented reality (AR) uses for learning in the primary and the secondary education sectors across the globe. However, there is not such a substantial amount of work exploring the combination of AR with game-based learning (ARGBL). Although ARGBL has the potential to enable new forms of teaching and transform the learning experience, it remains unclear how ARGBL applications can impact students' motivation, achievements, and learning performance. This study reports a systematic review of the literature on ARGBL approaches in compulsory education considering the advantages, disadvantages, instructional affordances, and/or effectiveness of ARGBL across various primary and secondary education subjects. In total, 21 studies published between 2012 and 2017 in 11 indexed journals were analysed, with 14 studies focusing on primary education and 7 on secondary. The main findings from this review provide the current state of the art research in ARGBL in compulsory education. Trends and the vision towards the future are also discussed, as ARGBL can potentially influence the students' attendance, knowledge transfer, skill acquisition, hands-on digital experience, and positive attitude towards their learning. This review aims to lay the groundwork for educators, technology developers, and other stakeholders involved in the development of literacy programmes for young children by offering new insights with effective advice and suggestions on how to increase student motivation and improve learning outcomes and the learning experience by incorporating ARGBL into their teaching.
C1 [Pellas, Nikolaos] Univ Aegean, Dept Prod & Syst Design Engn, Ermoupolis, Greece.
   [Fotaris, Panagiotis] Univ Brighton, Sch Comp Engn & Math, Brighton, E Sussex, England.
   [Kazanidis, Ioannis] Eastern Macedonia & Thrace Inst Technol, Informat Technol Dept, Adv Educ Technol & Mobile Applicat Lab, Kavala, Greece.
   [Wells, David] Univ East London, Cass Sch Educ & Communities, London, England.
C3 University of Aegean; University of Brighton; University of East London
RP Pellas, N (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Ermoupolis, Greece.
EM npellas@aegean.gr
RI Fotaris, Panagiotis/AAH-1477-2021; Pellas, Nikolaos/S-8996-2016
OI Fotaris, Panagiotis/0000-0001-7757-7746; Pellas,
   Nikolaos/0000-0002-3071-6275; Kazanidis, Ioannis/0000-0002-7199-9945
CR Adams BeckerS., 2016, NMC/ CoSN Horizon Report: 2016 K-12 Edition
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Alakärppä I, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098547
   [Anonymous], WORLDW SEM AUGM VIRT
   [Anonymous], GAM REV
   [Anonymous], THOMSON REUTERS J CI
   [Anonymous], 2007, Journal of Science Education and Technology, DOI [DOI 10.1007/S10956-006-9037-Z, 10.1007/s10956-006-9037-z]
   [Anonymous], 2008, ECOLOGY GAMES CONNEC
   Atwood-Blaine D, 2017, INT J SCI MATH EDUC, V15, pS45, DOI 10.1007/s10763-017-9801-y
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Borowiecki KJ, 2018, RES ECON, V72, P313, DOI 10.1016/j.rie.2017.06.004
   Bressler DM, 2013, J COMPUT ASSIST LEAR, V29, P505, DOI 10.1111/jcal.12008
   Bujak KR, 2013, COMPUT EDUC, V68, P536, DOI 10.1016/j.compedu.2013.02.017
   Cai S, 2017, INTERACT LEARN ENVIR, V25, P778, DOI 10.1080/10494820.2016.1181094
   Cai S, 2014, COMPUT HUM BEHAV, V37, P31, DOI 10.1016/j.chb.2014.04.018
   Juan MC, 2011, WSCG 2011: FULL PAPERS PROCEEDINGS, P25
   Chang HY, 2016, INTERACT LEARN ENVIR, V24, P1148, DOI 10.1080/10494820.2014.961486
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chang RC, 2016, INTERACT LEARN ENVIR, V24, P1245, DOI 10.1080/10494820.2014.982131
   Chen CH, 2016, ASIA-PAC EDUC RES, V25, P567, DOI 10.1007/s40299-016-0284-3
   Chen CM, 2012, COMPUT EDUC, V59, P638, DOI 10.1016/j.compedu.2012.03.001
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Chiang THC, 2014, EDUC TECHNOL SOC, V17, P352
   Colley A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1179, DOI 10.1145/3025453.3025495
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Dunleavy M., 2014, Handbook of Research on Educational Communications and Technology, P735, DOI [DOI 10.1007/978-1-4614-3185-5_59, 10.1007/978-1-4614-3185-5_59]
   Echeverría A, 2012, COMPUT HUM BEHAV, V28, P1170, DOI 10.1016/j.chb.2012.01.027
   Efstathiou I, 2018, INTERACT LEARN ENVIR, V26, P22, DOI 10.1080/10494820.2016.1276076
   Enyedy N, 2012, INT J COMP-SUPP COLL, V7, P347, DOI 10.1007/s11412-012-9150-3
   Fotaris P, 2017, PROC EUR CONF GAME, P181
   Fotaris P, 2016, ELECTRON J E-LEARN, V14, P94
   Furió D, 2013, COMPUT EDUC, V64, P1, DOI 10.1016/j.compedu.2012.12.001
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Hsiao HS, 2016, INTERACT LEARN ENVIR, V24, P205, DOI 10.1080/10494820.2013.834829
   Hsiao KF, 2012, INTERACT LEARN ENVIR, V20, P331, DOI 10.1080/10494820.2010.486682
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   Hung YH, 2017, J COMPUT ASSIST LEAR, V33, P252, DOI 10.1111/jcal.12173
   Hwang GJ, 2015, INTERACT LEARN ENVIR, V23, P127, DOI 10.1080/10494820.2014.998863
   Kamarainen AM, 2013, COMPUT EDUC, V68, P545, DOI 10.1016/j.compedu.2013.02.018
   Kitchenham B., 2007, 23 EBSE, DOI DOI 10.1145/1134285.1134500
   Koutromanos G, 2015, EDUC MEDIA INT, V52, P253, DOI 10.1080/09523987.2015.1125988
   Laine TH, 2016, ETR&D-EDUC TECH RES, V64, P507, DOI 10.1007/s11423-015-9419-0
   Liu TY, 2010, COMPUT EDUC, V55, P630, DOI 10.1016/j.compedu.2010.02.023
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Papastergiou M, 2009, COMPUT EDUC, V52, P1, DOI 10.1016/j.compedu.2008.06.004
   Pellas N, 2018, EDUC INF TECHNOL, V23, P2423, DOI 10.1007/s10639-018-9724-4
   Pellas N, 2017, EDUC INF TECHNOL, V22, P2235, DOI 10.1007/s10639-016-9537-2
   Phipps L., 2016, Mobile Learning Futures-Sustaining Quality Research and Practice in Mobile Learning, P214
   Prensky M., 2006, Learning in the Digital Age, V63, P8
   Punch K., 2005, INTRO SOCIAL RES QUA, V2nd
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Rauschnabel PA, 2018, PROGR IS, P211, DOI 10.1007/978-3-319-64027-3_15
   Ruiz-Ariza A, 2018, COMPUT EDUC, V116, P49, DOI 10.1016/j.compedu.2017.09.002
   Russell Cynthia K, 2003, Evid Based Nurs, V6, P36
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Sommerauer P, 2014, COMPUT EDUC, V79, P59, DOI 10.1016/j.compedu.2014.07.013
   Steinkuehler C, 2014, CAMBRIDGE HANDBOOK OF THE LEARNING SCIENCES, 2ND EDITION, P377
   Tobar-Muñoz H, 2017, J EDUC COMPUT RES, V55, P901, DOI 10.1177/0735633116689789
   Wei XD, 2015, COMPUT EDUC, V81, P221, DOI 10.1016/j.compedu.2014.10.017
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Zhang J, 2014, COMPUT EDUC, V73, P178, DOI 10.1016/j.compedu.2014.01.003
NR 63
TC 131
Z9 140
U1 11
U2 103
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 329
EP 346
DI 10.1007/s10055-018-0347-2
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ahn, E
   Lee, S
   Kim, GJ
AF Ahn, Euijai
   Lee, Sungkil
   Kim, Gerard Jounghyun
TI Real-time adjustment of contrast saliency for improved information
   visibility in mobile augmented reality
SO VIRTUAL REALITY
LA English
DT Article
DE Human perception and performance; Augmented reality; See-through
   display; Saliency; Contrast
AB Augmented reality (AR) "augments" virtual information over the real-world medium and is emerging as an important type of an information visualization technique. As such, the visibility and readability of the augmented information must be as high as possible amidst the dynamically changing real-world surrounding and background. In this work, we present a technique based on image saliency analysis to improve the conspicuity of the foreground augmentation to the background real-world medium by adjusting the local brightness contrast. The proposed technique is implemented on a mobile platform considering the usage nature of AR. The saliency computation is carried out for the augmented object's representative color rather than all the pixels, and searching and adjusting over only a discrete number of brightness levels to produce the highest contrast saliency, thereby making real-time computation possible. While the resulting imagery may not be optimal due to such a simplification, our tests showed that the visibility was still significantly improved without much difference to the "optimal" ground truth in terms of correctly perceiving and recognizing the augmented information. In addition, we also present another experiment that explores in what fashion the proposed algorithm can be applied in actual AR applications. The results suggested that the users clearly preferred the automatic contrast modulation upon large movements in the scenery.
C1 [Ahn, Euijai] Korea Univ, Dept Comp & Radio Commun Engn, Coll Informat & Commun, 145 Anam Ro, Seoul, South Korea.
   [Lee, Sungkil] Sungkyunkwan Univ, Dept Software, Coll Software, 2066 Seobu Ro, Suwon, South Korea.
   [Kim, Gerard Jounghyun] Korea Univ, Coll Informat, Dept Comp Sci & Engn, 145 Anam Ro, Seoul, South Korea.
C3 Korea University; Sungkyunkwan University (SKKU); Korea University
RP Kim, GJ (corresponding author), Korea Univ, Coll Informat, Dept Comp Sci & Engn, 145 Anam Ro, Seoul, South Korea.
EM gjkim@korea.ac.kr
RI LEE, Sungkil/AAJ-8474-2021
OI LEE, Sungkil/0000-0003-0123-9382
FU Basic Science Research Program - National Research Foundation (NRF);
   Ministry of Science, ICT & Future Planning (MSIP) [2011-0030079];
   Institute for Information & communications Technology Promotion (IITP) -
   MSIP [2017-0-00179]
FX This research was supported in part by the Basic Science Research
   Program funded by the National Research Foundation (NRF) and the
   Ministry of Science, ICT & Future Planning (MSIP) - No. 2011-0030079,
   and by the Institute for Information & communications Technology
   Promotion (IITP) grant also funded by MSIP - No. 2017-0-00179, "HD
   Haptic Technology for Hyper Reality Contents".
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ackerman E, 2013, COULD GOOGLE GLASS H
   [Anonymous], 2017, REACTION TIME STAT
   [Anonymous], 2012, INFORM VISUAL
   [Anonymous], 1992, 924131992 ISO
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Baker DH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069536
   Bauer T, 2010, ORG BEHAV 1 1 FLAT W
   Birchfield S, 2007, Klt: An implementation of the Kanade-Lucas-Tomasi feature tracker
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Eadicicco L, 2015, SONY JUST SOLVED BIG
   Ehrenstein Walter H., 2003, Arq. Bras. Oftalmol., V66, P44
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   GOOGLE, 2015, GOOGL GLASS
   Hincapié-Ramos JD, 2014, INT SYM MIX AUGMENT, P187, DOI 10.1109/ISMAR.2014.6948426
   Human Factors and Ergonomics Society (HFES), 2007, ANSI HFES 100 2007 H
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kalkofen D, 2013, INT SYM MIX AUGMENT, P1
   Kosinski R.J., 2008, LIT REV REACTION TIM
   Lee S, 2009, IEEE T VIS COMPUT GR, V15, P6, DOI 10.1109/TVCG.2008.82
   LOOMIS JM, 1973, PERCEPTION, V2, P425, DOI 10.1068/p020425
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Meese TS, 2005, J VISION, V5, P928, DOI 10.1167/5.11.2
   National Geographic, 2015, AFR WILD W
   Navab N, 2007, IEEE COMPUT GRAPH, V27, P10, DOI 10.1109/MCG.2007.117
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Reid B, 2014, GOOGLE GLASS CAUSING
   Sandor C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P27, DOI 10.1109/ISMAR.2010.5643547
   Supan P., 2006, INT J VIRTUAL REALIT, V5, P1, DOI DOI 10.20870/IJVR.2006.5.3.2692
   Tatzgern M, 2013, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2013.6549347
   Veas E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1471
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
NR 34
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 245
EP 262
DI 10.1007/s10055-017-0319-y
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900006
DA 2024-07-18
ER

PT J
AU Vosinakis, S
   Koutsabasis, P
AF Vosinakis, Spyros
   Koutsabasis, Panayiotis
TI Evaluation of visual feedback techniques for virtual grasping with bare
   hands using Leap Motion and Oculus Rift
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual grasping; Visual feedback techniques; Bare hand interaction;
   Leap Motion; Oculus Rift; Usability evaluation
ID CUES; CONTACT
AB Bare hand interaction (BHI) allows users to use their hands and fingers to interact with digital content without any attached devices or accessories. For BHI to realize widespread adoption, interaction techniques for fundamental operations, like grasp-and-release, need to be identified and optimized. This paper presents a controlled usability evaluation of four common visual feedback techniques in grasp-and-release tasks using bare hand interaction (BHI). The techniques are 'object coloring,' 'connecting line,' 'shadow' and 'object halo.' The usability was examined in terms of task time, accuracy, errors and user satisfaction. A software test bed was developed for two interface configurations: using the Leap Motion controller alone (desktop configuration) and using the Leap with Oculus Rift (virtual reality (VR) configuration). Participants (n 32) performed four trials x five feedback techniques x two UI (user interface) configurations, i.e., a total of 1280 trials. The results can be summarized into: (a) user performance is significantly better in the VR configuration compared to the desktop; (b) coloring techniques for visual feedback ('object coloring' and 'object halo') are more usable than 'connecting line' regardless of UI; (c) in the VR, coloring techniques remain more usable, while in the desktop interface the 'shadow' technique is also usable and preferred by users, (d) the 'connecting line' technique often distracts users from grasp-and-release tasks on static targets. (e) Some visual feedback is always preferred by users than none in both VR and desktop. We discuss these findings in terms of design recommendations for bare hands interactions that involve grasp-and-release tasks.
C1 [Vosinakis, Spyros; Koutsabasis, Panayiotis] Univ Aegean, Dept Prod & Syst Design Engn, Interact Syst Design Lab, Hermoupolis 84100, Syros, Greece.
C3 University of Aegean
RP Vosinakis, S (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Interact Syst Design Lab, Hermoupolis 84100, Syros, Greece.
EM spyrosv@aegean.gr; kgp@aegean.gr
RI Koutsabasis, Panayiotis/T-9367-2019
OI Koutsabasis, Panayiotis/0000-0003-0478-7456; Vosinakis,
   Spyros/0000-0003-1735-4297
CR Albert W., 2013, Measuring the User Experience
   Apostolellis P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P153, DOI 10.1109/3DUI.2014.6798866
   Bachmann D, 2015, SENSORS-BASEL, V15, P214, DOI 10.3390/s150100214
   Beattie N, 2015, PROC TECH, V20, P149, DOI 10.1016/j.protcy.2015.07.025
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   Caggianese G, 2016, LECT NOTES COMPUT SC, V9769, P318, DOI 10.1007/978-3-319-40651-0_26
   Codd-Downey R., 2014, Proceedings of the 2Nd ACM Symposium on Spatial User Interaction, SUI '14, New York, NY, USA, P153
   Coelho JoannaC., 2014, CREATING DIFFERENCE, P78
   England D, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-433-3_1
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Hu HH, 2000, IEEE VISUAL, P179, DOI 10.1109/VISUAL.2000.885692
   JAYAKUMAR A, 2015, P 2015 5 INT C ADV C, P350, DOI DOI 10.1109/ICACC.2015.20
   Juncong Lin, 2015, Advances in Web-Based Learning - ICWL 2015. 14th International Conference. Proceedings: LNCS 9412, P258, DOI 10.1007/978-3-319-25515-6_25
   Khademi M., 2014, Conference on Human Factors in Computing Systems - Proceedings, (February 2015), P1663, DOI [10.1145/2559206.2581203, DOI 10.1145/2559206.2581203]
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Nabiyouni M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P139, DOI 10.1109/3DUI.2014.6798859
   Parkin S, OCULUS RIFT 30 YEARS
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Prachyabrued M, 2016, IEEE T VIS COMPUT GR, V22, P1718, DOI 10.1109/TVCG.2015.2456917
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Sauro J., 2012, 10 THINGS KNOW CONFI
   Seixas M, 2015, ACHI 2015, P22
   Song Peng., 2012, P 2012 ACM ANN C HUM, P1297, DOI DOI 10.1145/2207676.2208585
   Sreng J, 2006, IEEE T VIS COMPUT GR, V12, P1013, DOI 10.1109/TVCG.2006.189
   Teather R. J., 2007, P 2007 C FUT PLAY
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   [No title captured]
   [No title captured]
NR 29
TC 37
Z9 42
U1 2
U2 36
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 47
EP 62
DI 10.1007/s10055-017-0313-4
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200005
DA 2024-07-18
ER

PT J
AU Silva, GR
   Donat, JC
   Rigoli, MM
   de Oliveira, FR
   Kristensen, CH
AF Silva, Gustavo R.
   Donat, Julia C.
   Rigoli, Marcelo M.
   de Oliveira, Fernando R.
   Kristensen, Christian H.
TI A questionnaire for measuring presence in virtual environments: factor
   analysis of the presence questionnaire and adaptation into Brazilian
   Portuguese
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Virtual reality; Presence questionnaire; Translation;
   Adaptation
ID REALITY EXPOSURE THERAPY; POSTTRAUMATIC-STRESS-DISORDER; ANXIETY
   DISORDERS; IN-VIVO; FEAR; PHOBIA
AB The increasing use of virtual reality (VR) environments in different domains of research and psychotherapy offers advantages over traditional treatment approaches. However, in order to feel immersed and involved by the VR experience, participants require VR scenarios that promote the subjective feeling of "being there," i.e., presence. The most utilized mean of operationalization of presence is through self-report scales and questionnaires. This article aims to report the translation and adaptation of the presence questionnaire (PQ) into Brazilian Portuguese, comparing the factorial distribution of the adapted version with the original PQ. Translation and back-translations were conducted by a team of Brazilian psychologists and computer science professionals with experience on the field. Participants (n = 100) answered the Brazilian version of the questionnaire after wearing a head-mounted display (HMD) and driving a virtual automobile in a VR scenario. The principal component analysis of the translated version generated factors consistently with the original study; however, items that had equivocal construct adequacy in the original PQ changed factors. The factor structure of the PQ is discussed. The growing use of VR environments requires instruments assessing the presence of immersed individuals, and the Brazilian Portuguese version of the PQ appears to be a viable option.
C1 [Silva, Gustavo R.; Donat, Julia C.; Rigoli, Marcelo M.; de Oliveira, Fernando R.; Kristensen, Christian H.] Pontif Catholic Univ Rio Grande Sul PUCRS, Ctr Studies & Res Traumat Stress NEPTE, Porto Alegre, RS, Brazil.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul
RP Silva, GR (corresponding author), Pontif Catholic Univ Rio Grande Sul PUCRS, Ctr Studies & Res Traumat Stress NEPTE, Porto Alegre, RS, Brazil.
EM silva.gustavoramos@gmail.com
RI Kristensen, Christian H/F-1538-2015; Candia Donat, Julia/F-2915-2017
OI Candia Donat, Julia/0000-0002-4138-5774
FU Pontifical Catholic University of Rio Grande do Sul; Conselho Nacional
   de Desenvolvimento Cientifico e Tecnologico (CNPq); Fundacao de Amparo a
   Pesquisa do Rio Grande do Sul (FAPERGS)
FX The authors acknowledge the support provided by the Pontifical Catholic
   University of Rio Grande do Sul, the Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico (CNPq) and the Fundacao de
   Amparo a Pesquisa do Rio Grande do Sul (FAPERGS).
CR Anderson P, 2003, COGN BEHAV PRACT, V10, P240, DOI 10.1016/S1077-7229(03)80036-6
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Botella C, 2007, CLIN PSYCHOL PSYCHOT, V14, P164, DOI 10.1002/cpp.524
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Cozby P.C., 2003, Metodos de Pesquisa em Ciencias do Comportamento, VEditora
   de Quervain DJF, 2011, P NATL ACAD SCI USA, V108, P6621, DOI 10.1073/pnas.1018214108
   Difede J, 2007, J CLIN PSYCHIAT, V68, P1639, DOI 10.4088/JCP.v68n1102
   dos Santos Nunes FDL, 2011, REV BRAS ENG BIOM, V27, P243
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Fachel J.M., 2000, Psicodiagnostico - V, P158
   Field A., 2009, Discovering statistics with SPSS, V3rd
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Gerardi M, 2010, CURR PSYCHIAT REP, V12, P298, DOI 10.1007/s11920-010-0128-4
   Hoffman HG, 2003, CYBERPSYCHOL BEHAV, V6, P127, DOI 10.1089/109493103321640310
   Klinger E, 2005, CYBERPSYCHOL BEHAV, V8, P76, DOI 10.1089/cpb.2005.8.76
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Krijn M, 2007, AVIAT SPACE ENVIR MD, V78, P121
   Maltby N, 2002, J CONSULT CLIN PSYCH, V70, P1112, DOI 10.1037//0022-006X.70.5.1112
   Murray J, 2013, AGGRESS VIOLENT BEH, V18, P471, DOI 10.1016/j.avb.2013.07.003
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Rizzo A, 2010, ANN NY ACAD SCI, V1208, P114, DOI 10.1111/j.1749-6632.2010.05755.x
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Stevens J.P., 1992, APPL MULTIVARIATE ST
   Takatalo J, 2008, COMPUT HUM BEHAV, V24, P1, DOI 10.1016/j.chb.2006.11.003
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 30
TC 12
Z9 17
U1 3
U2 43
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2016
VL 20
IS 4
BP 237
EP 242
DI 10.1007/s10055-016-0295-7
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DY6FF
UT WOS:000385201100005
OA Green Published
DA 2024-07-18
ER

PT J
AU Vosinakis, S
   Koutsabasis, P
AF Vosinakis, Spyros
   Koutsabasis, Panayiotis
TI Interaction design studio learning in virtual worlds
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual world; Design studio; Interaction design; Learning
AB The paper suggests that virtual worlds (VWs) have many unique advantages for supporting interaction design studio activities, provided that they are designed to include appropriate workplaces and interactive tools to foster collaboration and creativity. We present an approach for employing VWs that proposes the use of prospective tools and workplaces throughout the following key activities of interaction design studio courses: design brief, design thinking, design practice (conceptual and detailed), the desk crit, design review and user evaluation. Then, we describe a blended interaction design studio course on the basis of this approach, which ran through a whole semester. We found that the VW design studio is an engaging and constructive experience for students: In the VW environment, students and tutors held many online meetings, and students constructed several models about their design project, developed a digital prototype and conducted a remote usability evaluation. In addition, the persistence of the environment and the developed VW tools helped students and tutors to achieve careful feedback and reflection during the design project lifetime. Nevertheless, a number of challenges remain for wider implementation: the refinement of the instructional design approach, the usability of VW tools, further integration of VWs to professional design tools and the conduction of other full-scale VW design studio courses.
C1 [Vosinakis, Spyros; Koutsabasis, Panayiotis] Univ Aegean, Dept Prod & Syst Design Engn, Hermoupolis 84100, Syros, Greece.
C3 University of Aegean
RP Vosinakis, S (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Hermoupolis 84100, Syros, Greece.
EM spyrosv@aegean.gr
RI Koutsabasis, Panayiotis/T-9367-2019
OI Koutsabasis, Panayiotis/0000-0003-0478-7456; Vosinakis,
   Spyros/0000-0003-1735-4297
CR [Anonymous], 2008, Measuring the User Experience Collecting, Analyzing, and Presenting Usability Metrics
   BARDZELL J., 2006, P OFTHE 4 NORDIC C H, P433
   Benford S, 2001, COMMUN ACM, V44, P79, DOI 10.1145/379300.379322
   Blevis E., 2010, INTERACTIONS, V17, P64
   Bowman DA, 1998, IEEE COMPUT GRAPH, V18, P9, DOI 10.1109/38.708555
   Broadfoot O., 2003, Design studios: Online? Comparing traditional face-to-face design studio education with modern Internet-based design studios
   Brown D., 2007, COMMUNICATING DESIGN
   Bruno F, 2010, INT J HUM-COMPUT ST, V68, P254, DOI 10.1016/j.ijhcs.2009.12.004
   Castillo C., 1998, CHI 98 Conference Summary on Human Factors in Computing Systems, P253
   Chase S., 2008, P 5 INTUITION INT C
   Cooper A., 2007, FACE 3 ESSENTIALS IN
   Cross N, 1990, Design Studies, V11, P127, DOI DOI 10.1016/0142-694X(90)90002-T
   Cross N., 2021, ENG DESIGN METHODS S
   Cross Nigel., 1996, Analysing design activity
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   De Lucia A, 2009, COMPUT EDUC, V52, P220, DOI 10.1016/j.compedu.2008.08.001
   Dede C., 1995, Educational Technology, V35, P46
   Dix A., 2003, HUM FAC ER
   Ehsani E, 2009, ECAADE 2009: COMPUTATION: THE NEW REALM OF ARCHITECTURAL DESIGN, P523
   Fredrickson M., 1990, Journal of Architectural Education, V43, P22
   Garrett JesseJames., 2003, ELEMENTS USER EXPERI
   Girvan C, 2010, COMPUT EDUC, V55, P342, DOI 10.1016/j.compedu.2010.01.020
   Goldschmidt G, 2010, AI EDAM, V24, P285, DOI 10.1017/S089006041000020X
   Greenberg S, 2009, INT FED INFO PROC, V289, P23
   Gul LF, 2009, P UND DES RES SOC C
   Hew KF, 2010, BRIT J EDUC TECHNOL, V41, P33, DOI 10.1111/j.1467-8535.2008.00900.x
   Hmelo-Silver CE, 2004, EDUC PSYCHOL REV, V16, P235, DOI 10.1023/B:EDPR.0000034022.16470.f3
   Holtzblatt K., 1997, CONTEXTUAL DESIGN DE
   Hundhausen C, 2010, P NEXT GEN HCI ED CH
   Kim HM, 2008, 41 ANN HAW INT C SYS, P110
   Kohler T, 2009, TECHNOVATION, V29, P395, DOI 10.1016/j.technovation.2008.11.004
   Koutsabasis P, 2012, DESIGN STUD, V33, P357, DOI 10.1016/j.destud.2011.11.004
   Lowgren J, 2004, THOUGHTFUL INTERACTION DESIGN: A DESIGN PERSPECTIVE ON INFORMATION TECHNOLOGY, P1
   Maher ML, 1999, PROCEEDINGS OF FOURTH INTERNATIONAL WORKSHOP ON CSCW IN DESIGN, P159
   Prendinger H, 2009, PRESENCE-TELEOP VIRT, V18, P468, DOI 10.1162/pres.18.6.468
   Ragusa JM, 2001, COMMUN ACM, V44, P40, DOI 10.1145/501317.501339
   Rosson MB., 2001, Usability engineering: scenario-based development of human-computer interaction
   Ryd N, 2004, DESIGN STUD, V25, P231, DOI 10.1016/j.destud.2003.10.003
   Saffer Dan., 2007, DESIGNING INTERACTIO
   Schn D.A., 1987, Educating the reflective practitioner: Toward a new design for teaching and learning in the professions
   Shaffer D. W, 2003, 200311 WCER
   Snyder C, 2003, PAPER PROTOTYPING
   Sun Q., 2004, ENG GRAPH J, V68, P13
   Vanderdonckt J, 2004, P 9 ACM INT C 3D WEB, P51
   Wang LH, 2002, COMPUT AIDED DESIGN, V34, P981, DOI 10.1016/S0010-4485(01)00157-9
   Wood DF, 2003, BMJ-BRIT MED J, V326, P328, DOI 10.1136/bmj.326.7384.328
NR 46
TC 14
Z9 17
U1 0
U2 47
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2013
VL 17
IS 1
BP 59
EP 75
DI 10.1007/s10055-013-0221-1
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 089NC
UT WOS:000314916300005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lieberknecht, S
   Benhimane, S
   Meier, P
   Navab, N
AF Lieberknecht, Sebastian
   Benhimane, Selim
   Meier, Peter
   Navab, Nassir
TI Benchmarking template-based tracking algorithms
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Optical tracking; Template-based tracking; Benchmark;
   Evaluation
AB For natural interaction with augmented reality (AR) applications, good tracking technology is key. But unlike dense stereo, optical flow or multi-view stereo, template-based tracking which is most commonly used for AR applications lacks benchmark datasets allowing a fair comparison between state-of-the-art algorithms. Until now, in order to evaluate objectively and quantitatively the performance and the robustness of template-based tracking algorithms, mainly synthetically generated image sequences were used. The evaluation is therefore often intrinsically biased. In this paper, we describe the process we carried out to perform the acquisition of real-scene image sequences with very precise and accurate ground truth poses using an industrial camera rigidly mounted on the end effector of a high-precision robotic measurement arm. For the acquisition, we considered most of the critical parameters that influence the tracking results such as: the texture richness and the texture repeatability of the objects to be tracked, the camera motion and speed, and the changes of the object scale in the images and variations of the lighting conditions over time. We designed an evaluation scheme for object detection and interframe tracking algorithms suited for AR and other computer vision applications and used the image sequences to apply this scheme to several state-of-the-art algorithms. The image sequences are freely available for testing, submitting and evaluating new template-based tracking algorithms, i.e. algorithms that detect or track a planar object in an image sequence given only one image of the object (called the template).
C1 [Lieberknecht, Sebastian; Benhimane, Selim; Meier, Peter] Metaio Gmbh, Munich, Germany.
   [Navab, Nassir] Tech Univ Munich, Munich, Germany.
C3 Apple Inc; Technical University of Munich
RP Lieberknecht, S (corresponding author), Metaio Gmbh, Munich, Germany.
EM Sebastian.Lieberknecht@metaio.com; Selim.Benhimane@metaio.com;
   Peter.Meier@metaio.com; Navab@cs.tum.edu
FU BMBF [Avilus/01 IM08001 P]
FX This work was partially supported by BMBF grant Avilus/01 IM08001 P.
CR [Anonymous], 2006, DRITT WORKSH VIRT EN
   [Anonymous], ICCV, DOI DOI 10.1109/ICCV.2007.4408903
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252
   HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455
   Klein G., 2007, IEEE and ACM Intl. Sym. on Mixed and Augmented Reality (ISMAR), P225, DOI DOI 10.1109/ISMAR.2007.4538852
   Lieberknecht Sebastian, 2009, ISMAR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   Price CJ, 2002, J OPTIMIZ THEORY APP, V113, P5, DOI 10.1023/A:1014849028575
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
   ZIMMERMAN K, 2009, PAMI, V31, P677
NR 19
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 99
EP 108
DI 10.1007/s10055-010-0185-3
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200002
DA 2024-07-18
ER

PT J
AU Ma, L
   Chablat, D
   Bennis, F
   Zhang, W
   Hu, B
   Guillaume, F
AF Ma, Liang
   Chablat, Damien
   Bennis, Fouad
   Zhang, Wei
   Hu, Bo
   Guillaume, Francois
TI Fatigue evaluation in maintenance and assembly operations by digital
   human simulation in virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual human simulation; Muscle fatigue model; Fatigue resistance;
   Physical fatigue evaluation; Human status
ID MUSCLE FATIGUE; ENDURANCE TIMES; MODEL; WORK; MOTION; PREDICTION;
   RECOVERY; LIMB
AB Virtual human techniques have been used a lot in industrial design in order to consider human factors and ergonomics as early as possible, and it has been integrated into VR applications to complete ergonomic evaluation tasks. In order to generalize the evaluation task in VE, especially for physical fatigue evaluation, we integrated a new fatigue model into a virtual environment platform. Virtual Human Status is proposed in this paper in order to assess the difficulty of manual handling operations, especially from the physical perspective. The decrease of the physical capacity before and after an operation is used as an index to indicate the difficulty level. The reduction of physical strength is simulated in a theoretical approach on the basis of a fatigue model in which fatigue resistances of different muscle groups were regressed from 24 existing maximum endurance time models. A framework based on digital human modeling technique is established to realize the comparison of physical status. An assembly case in airplane assembly is simulated and analyzed under the framework in VRHIT experiment platform. The endurance time and the decrease of the joint moment strengths are simulated. The experimental result in simulated operations under laboratory conditions confirms the feasibility of the theoretical approach: integration of virtual human simulation into virtual reality for physical fatigue evaluation.
C1 [Ma, Liang; Chablat, Damien; Bennis, Fouad] IRCCyN, Inst Rech Commun & Cybernet Nantes, UMR 6597, CNRS,Ecole Cent Nantes, F-44321 Nantes 03, France.
   [Zhang, Wei; Hu, Bo] Tsinghua Univ, Dept Ind Engn, Beijing 100084, Peoples R China.
   [Guillaume, Francois] EADS Innovat Works, F-92152 Suresnes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Nantes Universite;
   Ecole Centrale de Nantes; Tsinghua University; Airbus
RP Ma, L (corresponding author), IRCCyN, Inst Rech Commun & Cybernet Nantes, UMR 6597, CNRS,Ecole Cent Nantes, 1 Rue Noe,BP 92 101, F-44321 Nantes 03, France.
EM liang.ma@irccyn.ec-nantes.fr; damien.chablat@irccyn.ec-nantes.fr;
   fouad.bennis@irccyn.ec-nantes.fr; zhangwei@tsinghua.edu.cn;
   b-hu05@mails.tsinghua.edu.cn; francois.guillaume@eads.net
RI Ma, Liang/T-2243-2019; chablat, damien/E-7252-2016
OI chablat, damien/0000-0001-7847-6162; Ma, Liang/0000-0002-9422-814X
FU EADS; Region des Pays de la Loire (France)
FX This research was supported by the EADS and the Region des Pays de la
   Loire (France) in the context of collaboration between the Ecole
   Centrale de Nantes (Nantes, France) and Tsinghua University (Beijing,
   P.R. China).
CR Anderson DE, 2007, J BIOMECH, V40, P3105, DOI 10.1016/j.jbiomech.2007.03.022
   [Anonymous], MODELLING IDENTIFICA
   Arzi Y, 1997, HUM FACTOR ERGON MAN, V7, P79, DOI 10.1002/(SICI)1520-6564(199721)7:2<79::AID-HFM2>3.0.CO;2-F
   Badler N. I., 1993, Simulating humans: computer graphics animation and control
   BALCISOY S, 2001, P INT S MIX REAL CIT, V1, P81
   Ben-Gal I., 2002, IIE Transactions, V34, P375, DOI 10.1080/07408170208928877
   Bubb H., 2006, International Journal of Human Factors Modelling and Simulation, V1, P140, DOI 10.1504/IJHFMS.2006.011686
   Chaffin D. B., 2006, Occupational Biomechanics (Fourth Edition)
   Chaffin DB, 2002, HUM FACTORS ERGONOM, V12, P235, DOI 10.1002/hfm.10018
   Chaffin DB, 2007, HUM FACTOR ERGON MAN, V17, P475, DOI 10.1002/hfm.20087
   Chedmail P, 2003, IEEE T IND ELECTRON, V50, P692, DOI 10.1109/TIE.2003.814760
   Chen YL, 2000, INT J IND ERGONOM, V25, P611, DOI 10.1016/S0169-8141(99)00048-7
   Chryssolouris G, 2000, ROBOT CIM-INT MANUF, V16, P267, DOI 10.1016/S0736-5845(00)00013-2
   Damsgaard M, 2006, SIMUL MODEL PRACT TH, V14, P1100, DOI 10.1016/j.simpat.2006.09.001
   Ding J, 2000, J APPL PHYSIOL, V89, P1322, DOI 10.1152/jappl.2000.89.4.1322
   El Ahrache K, 2006, INT J IND ERGONOM, V36, P99, DOI 10.1016/j.ergon.2005.08.003
   El Ahrache K, 2009, INT J IND ERGONOM, V39, P73, DOI 10.1016/j.ergon.2008.10.012
   Fuller JR, 2009, J ELECTROMYOGR KINES, V19, P1043, DOI 10.1016/j.jelekin.2008.10.009
   Garg A, 2002, INT J IND ERGONOM, V30, P103, DOI 10.1016/S0169-8141(02)00078-1
   GIAT Y, 1993, IEEE T BIO-MED ENG, V40, P664, DOI 10.1109/10.237696
   Hill AV, 1938, PROC R SOC SER B-BIO, V126, P136, DOI 10.1098/rspb.1938.0050
   Honglun H, 2007, COMPUT IND ENG, V53, P350, DOI 10.1016/j.cie.2007.06.027
   HU B, 2008, P INT C APPL HUM FAC
   Iridiastadi H, 2006, ERGONOMICS, V49, P344, DOI 10.1080/00140130500475666
   Komura T, 2000, VISUAL COMPUT, V16, P254, DOI 10.1007/s003719900065
   Li GY, 1999, ERGONOMICS, V42, P674, DOI 10.1080/001401399185388
   Liu JZ, 2002, BIOPHYS J, V82, P2344, DOI 10.1016/S0006-3495(02)75580-X
   MA L, 2010, HUMAN FACTORS ERGONO, V20
   Ma L, 2009, INT J IND ERGONOM, V39, P211, DOI 10.1016/j.ergon.2008.04.004
   Mathiassen SE, 1999, INT J IND ERGONOM, V24, P315
   Ren AZ, 2004, AUTOMAT CONSTR, V13, P639, DOI 10.1016/j.autcon.2004.04.007
   Ritchie James M., 2007, Virtual Reality, V11, P261, DOI 10.1007/s10055-007-0073-7
   ROHMERT W, 1986, ERGONOMICS, V29, P1235, DOI 10.1080/00140138608967237
   Roman-Liu D, 2005, ERGONOMICS, V48, P930, DOI 10.1080/00140130500182312
   SATO H, 1984, Journal of Human Ergology, V13, P147
   Tilley A. R., 2001, The Measure of Man and Woman: Human Factors in Design
   Vignes R. M., 2004, THESIS U IOWA
   VSR Research Group, 2004, TECHN REP PROJ VIRT
   WANG Y, 2006, I IND ENG ANN C ORL
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wood DD, 1997, HUM FACTORS, V39, P83, DOI 10.1518/001872097778940678
   Xia T, 2008, J BIOMECH, V41, P3046, DOI 10.1016/j.jbiomech.2008.07.013
   YANG J, 2006, P SAE DIG HUM MOD DE
   Yang J, 2008, COMPUT IND ENG, V54, P242, DOI 10.1016/j.cie.2007.07.008
NR 44
TC 16
Z9 18
U1 7
U2 64
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2011
VL 15
IS 1
SI SI
BP 55
EP 68
DI 10.1007/s10055-010-0156-8
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HZ
UT WOS:000296280000005
DA 2024-07-18
ER

PT B
AU Eichenberg, C
AF Eichenberg, Christiane
BE Kim, JJ
TI Application of "Virtual Realities" in Psychotherapy: Possibilities,
   Limitations and Effectiveness
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID POSTTRAUMATIC-STRESS-DISORDER; EXPOSURE THERAPY; SPIDER PHOBIA;
   ACROPHOBIA; FEAR
C1 [Eichenberg, Christiane] Univ Cologne, Inst Clin Psychol & Psychol Diag, Cologne, Germany.
C3 University of Cologne
RP Eichenberg, C (corresponding author), Univ Cologne, Inst Clin Psychol & Psychol Diag, Cologne, Germany.
CR Anderson P, 2003, COGN BEHAV PRACT, V10, P240, DOI 10.1016/S1077-7229(03)80036-6
   Angenendt G, 2003, THESIS PHILOS FAKULT
   [Anonymous], 2008, Annu. Rev. CyberTherapy Telemedicine, DOI DOI 10.1007/978-3-540-85483-8_40
   Bauer Stephanie, 2008, E MENTAL HLTH NEUE M
   Bering R., 2005, VERLAUF POSTTRAUMATI
   Botella C, 1998, BEHAV RES THER, V36, P239, DOI 10.1016/S0005-7967(97)10006-7
   BOTELLA C, 2004, CYBERTHERAPY INTERNE
   Carlin AS, 1997, BEHAV RES THER, V35, P153, DOI 10.1016/S0005-7967(96)00085-X
   Curtis GC, 1998, BRIT J PSYCHIAT, V173, P212, DOI 10.1192/bjp.173.3.212
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Difede J, 2006, ANN NY ACAD SCI, V1071, P500, DOI 10.1196/annals.1364.052
   Doring N, 2007, PSYCHOTHERAPEUT, V2, P127
   Eichenberg C, 2005, PSYCHOTHERAPIE DIALO, V4, P452
   Eichenberg C, PSYCHOTHERA IN PRESS
   Eichenberg C, 2008, MEDIENPSYCHOLOGIE, P503
   Eichenberg C, 2007, PSYCHOTHERAPEUT, V5, P362
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Emmelkamp PMG, 2001, CYBERPSYCHOL BEHAV, V4, P335, DOI 10.1089/109493101300210222
   Fischer G, 2006, KAUSALE PSYCHOTHERAP
   Fischer G, 2005, NEUE WEGE NACH TRAUM
   Fischer G, HDB ARBEITS IN PRESS
   Fischer G, 2000, MEHRDIMENSIONALE PSY
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Gerardi M, 2008, J TRAUMA STRESS, V21, P209, DOI 10.1002/jts.20331
   Herbelin B, 2002, 8 INT C VIRT SYST MU
   Hoffman HG, 2003, INT J HUM-COMPUT INT, V16, P283, DOI 10.1207/S15327590IJHC1602_08
   Institut fur Demoskopie Allensbach, 2003, ALL BER
   Jacobi F, 2004, Bundesgesundheitsblatt Gesundheitsforschung Gesundheitsschutz, V47, P736
   Josman N, 2008, CYBERPSYCHOL BEHAV, V11, P775, DOI 10.1089/cpb.2008.0048
   Kaltenborn K-F, 1994, BIOMED J, V39, P4
   Kinnunen P, 1996, FLUGANGST BEWALTIGEN
   Klinger E, 2005, CYBERPSYCHOL BEHAV, V8, P76, DOI 10.1089/cpb.2005.8.76
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Lee JH, 2007, CYBERPSYCHOL BEHAV, V10, P617, DOI 10.1089/cpb.2007.9978
   Magee WJ, 1996, ARCH GEN PSYCHIAT, V53, P159
   Mühlberger A, 2006, PSYCHOTHER RES, V16, P26, DOI 10.1080/10503300500090944
   Muhlberger A, 2008, E MENTAL HLTH, P163
   Muhlberger A, 1997, ALLGEMEINER FL UNPUB
   Nordlund C.L., 1983, Scandinavian Journal of Behaviour Therapy, V12, P150, DOI [https://doi.org/10.1080/16506078309455668, DOI 10.1080/16506078309455668]
   OTT R, 2003, KLIN PSYCHOL INTERNE
   Pertaub DP, 2001, STUD HEALTH TECHNOL, V81, P372
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Riva G, 2001, CYBERPSYCHOL BEHAV, V4, P511, DOI 10.1089/109493101750527079
   Rothbaum BO, 2001, J CLIN PSYCHIAT, V62, P617, DOI 10.4088/JCP.v62n0808
   ROTHBAUM BO, 1995, BEHAV THER, V26, P547, DOI 10.1016/S0005-7894(05)80100-5
   Roy S, 2003, CYBERPSYCHOL BEHAV, V6, P411, DOI 10.1089/109493103322278808
   Sa<ss> H, 1998, DIAGNOSTISCHES STAT
   Schmitt W.J., 2009, Schweizer Archiv fur Neurologie und Psychiatrie, V160, P352
   Schubert T., 2002, VIRTUELLE REALITATEN, P255
   THONES P, 2006, EINSATZ BIBLIOGRAFIS
   Wagner B, 2009, GESUNDHEIT NEUE MEDI, P135
   *WELTG, 1991, INT KLASS PSYCH STOR
   WIEDERHOLD BK, 2003, CYBERPSYCHOLOGY MIND
NR 53
TC 6
Z9 6
U1 1
U2 4
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 469
EP 484
D2 10.5772/553
PG 16
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400023
DA 2024-07-18
ER

PT B
AU Hilla, SB
AF Hilla, Sarig Bahat
BE Kim, JJ
TI Neck Motion Analysis Using a Virtual Environment
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID CERVICOCEPHALIC KINESTHETIC SENSIBILITY; 2000-2010 TASK-FORCE;
   WHIPLASH-ASSOCIATED DISORDERS; MEASURING CERVICAL-SPINE; LOW-BACK-PAIN;
   EXTERNAL FOCUS; ATTENTIONAL FOCUS; SENSORIMOTOR DISTURBANCES; CLINICAL
   EXAMINATION; MOBILITY MEASUREMENT
C1 [Hilla, Sarig Bahat] Univ Haifa, IL-31999 Haifa, Israel.
C3 University of Haifa
RP Hilla, SB (corresponding author), Univ Haifa, IL-31999 Haifa, Israel.
CR Amiri M, 2003, MANUAL THER, V8, P176, DOI 10.1016/S1356-689X(03)00009-2
   Assink N, 2005, J MANIP PHYSIOL THER, V28, P408, DOI 10.1016/j.jmpt.2005.06.009
   BARNSLEY L, 1994, PAIN, V58, P283, DOI 10.1016/0304-3959(94)90123-6
   Bland JM, 2007, J BIOPHARM STAT, V17, P571, DOI 10.1080/10543400701329422
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Breivik EK, 2000, CLIN J PAIN, V16, P22, DOI 10.1097/00002508-200003000-00005
   Brison RJ, 2000, J MUSCULOSKELET PAIN, V8, P97, DOI 10.1300/J094v08n01_08
   Bryanton C, 2006, CYBERPSYCHOL BEHAV, V9, P123, DOI 10.1089/cpb.2006.9.123
   Chappuis G, 2008, EUR SPINE J, V17, P1350, DOI 10.1007/s00586-008-0732-8
   Chen J, 1999, SPINE, V24, P1571, DOI 10.1097/00007632-199908010-00011
   Childs JD, 2008, J ORTHOP SPORT PHYS, V38, pA1, DOI 10.2519/jospt.2008.0303
   Chiu TTW, 2002, CLIN REHABIL, V16, P851, DOI 10.1191/0269215502cr550oa
   Cleland JA, 2008, AM J PHYS MED REHAB, V87, P109, DOI 10.1097/PHM.0b013e31815b61f1
   Coté P, 2001, MED CARE, V39, P956, DOI 10.1097/00005650-200109000-00006
   Cote P. D. C. P., 2008, BURDEN DETERMINANTS, pS60
   Dall'Alba PT, 2001, SPINE, V26, P2090, DOI 10.1097/00007632-200110010-00009
   Day JS, 2000, J BIOMECH, V33, P1039, DOI 10.1016/S0021-9290(00)00044-0
   De Hertogh WJ, 2007, MANUAL THER, V12, P50, DOI 10.1016/j.math.2006.02.007
   Dvir Z, 2000, CLIN BIOMECH, V15, P658, DOI 10.1016/S0268-0033(00)00033-4
   Dvir Z, 2008, J MANIP PHYSIOL THER, V31, P518, DOI 10.1016/j.jmpt.2008.08.008
   Dvir Z, 2006, SPINE, V31, pE394, DOI 10.1097/01.brs.0000219951.79922.df
   Edmondston SJ, 2007, MANUAL THER, V12, P363, DOI 10.1016/j.math.2006.07.007
   Feipel V, 1999, CLIN BIOMECH, V14, P462, DOI 10.1016/S0268-0033(98)90098-5
   Grealy MA, 1999, ARCH PHYS MED REHAB, V80, P661, DOI 10.1016/S0003-9993(99)90169-7
   Gregori B, 2008, CLIN NEUROPHYSIOL, V119, P273, DOI 10.1016/j.clinph.2007.10.007
   Grip H, 2007, CLIN BIOMECH, V22, P865, DOI 10.1016/j.clinbiomech.2007.05.008
   Guzman J, 2008, SPINE, V33, pS14, DOI 10.1097/BRS.0b013e3181643efb
   Harris Kristen, 2005, Can J Occup Ther, V72, P21
   Heikkila HV, 1998, ARCH PHYS MED REHAB, V79, P1089, DOI 10.1016/S0003-9993(98)90176-9
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Hoffman HG, 2008, CLIN J PAIN, V24, P299, DOI 10.1097/AJP.0b013e318164d2cc
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hogg-Johnson S, 2008, SPINE, V33, pS39, DOI 10.1097/BRS.0b013e31816454c8
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Holm LW, 2008, SPINE, V33, pS52, DOI 10.1097/BRS.0b013e3181643ece
   Jordan K, 2000, RHEUMATOLOGY, V39, P382, DOI 10.1093/rheumatology/39.4.382
   Jull GA, 2008, J MANIP PHYSIOL THER, V31, P525, DOI 10.1016/j.jmpt.2008.08.003
   Keshner EA, 2004, ASSIST TECHNOL, V16, P54, DOI 10.1080/10400435.2004.10132074
   Keshner EA, 2004, J VESTIBUL RES-EQUIL, V14, P307
   Keshner EA, 2000, J VESTIBUL RES-EQUIL, V10, P207
   Koerhuis CL, 2003, CLIN BIOMECH, V18, P14, DOI 10.1016/S0268-0033(02)00146-8
   Kristjansson E, 2004, ARCH PHYS MED REHAB, V85, P490, DOI 10.1016/S0003-9993(03)00619-1
   Kristjansson E, 2001, Physiother Res Int, V6, P224, DOI 10.1002/pri.230
   LANGLEY GB, 1985, RHEUMATOL INT, V5, P145, DOI 10.1007/BF00541514
   Lantz CA, 1999, SPINE, V24, P1082, DOI 10.1097/00007632-199906010-00007
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P383, DOI 10.1089/109493103322278763
   Lidgren L, 2008, SPINE, V33, pS1, DOI 10.1097/BRS.0b013e3181643f14
   LIND B, 1989, ARCH PHYS MED REHAB, V70, P692
   LoPresti EF, 2003, J REHABIL RES DEV, V40, P199
   Marcotte J., 2002, J MANIP PHYSIOL THER, V25, pE1
   McNevin NH, 2003, PSYCHOL RES-PSYCH FO, V67, P22, DOI 10.1007/s00426-002-0093-6
   Michaelsen SM, 2001, STROKE, V32, P1875, DOI 10.1161/01.STR.32.8.1875
   Mirelman A, 2009, STROKE, V40, P169, DOI 10.1161/STROKEAHA.108.516328
   Nordin M, 2008, SPINE, V33, pS101, DOI 10.1097/BRS.0b013e3181644ae8
   Ogon M, 1996, PAIN, V64, P425, DOI 10.1016/0304-3959(95)00208-1
   PENNING L, 1987, SPINE, V12, P732, DOI 10.1097/00007632-198710000-00003
   Pietrobon B, 2002, SPINE, V27, P515, DOI 10.1097/00007632-200203010-00012
   REVEL M, 1991, ARCH PHYS MED REHAB, V72, P288
   REVEL M, 1994, ARCH PHYS MED REHAB, V75, P895, DOI 10.1016/0003-9993(94)90115-5
   Riva G, 1999, Cyberpsychol Behav, V2, P577, DOI 10.1089/cpb.1999.2.577
   Rix GD, 2001, ARCH PHYS MED REHAB, V82, P911, DOI 10.1053/apmr.2001.23300
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rizzo AA, 2006, CNS SPECTRUMS, V11, P35, DOI 10.1017/S1092852900024196
   Rydevik B, 2008, EUR SPINE J, V17, pS3, DOI 10.1007/s00586-008-0617-x
   Sarig-Bahat H, 2010, SPINE, V35, pE105, DOI 10.1097/BRS.0b013e3181b79358
   Sarig-Bahat H, 2009, SPINE, V34, P1018, DOI 10.1097/BRS.0b013e31819b3254
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Sjölander P, 2008, MANUAL THER, V13, P122, DOI 10.1016/j.math.2006.10.002
   Spitzer W.O., 1995, SPINE, V20, pS1
   Sterling M, 2003, PAIN, V103, P65, DOI 10.1016/S0304-3959(02)00420-7
   Stiell IG, 2003, NEW ENGL J MED, V349, P2510, DOI 10.1056/NEJMoa031375
   Sullivan Michael J L, 2002, Pain Res Manag, V7, P68
   Treleaven J, 2006, MANUAL THER, V11, P99, DOI 10.1016/j.math.2005.04.003
   Treleaven J, 2003, J REHABIL MED, V35, P36, DOI 10.1080/16501970306109
   Treleaven J, 2008, MANUAL THER, V13, P2, DOI 10.1016/j.math.2007.06.003
   VERNON H, 1991, J MANIP PHYSIOL THER, V14, P409
   Vernon H, 2008, J MANIP PHYSIOL THER, V31, P491, DOI 10.1016/j.jmpt.2008.08.006
   Wainner RS, 2003, SPINE, V28, P52, DOI 10.1097/00007632-200301010-00014
   Weiss Patrice L Tamar, 2003, Occup Ther Int, V10, P39, DOI 10.1002/oti.176
   Wilson PN, 1996, DISABIL REHABIL, V18, P633, DOI 10.3109/09638289609166328
   Woodhouse A, 2008, BMC MUSCULOSKEL DIS, V9, DOI 10.1186/1471-2474-9-90
   Wulf G, 1999, RES Q EXERCISE SPORT, V70, P120, DOI 10.1080/02701367.1999.10608029
   Wulf G, 1998, J MOTOR BEHAV, V30, P169, DOI 10.1080/00222899809601334
   Wulf G, 2001, J SPORT EXERCISE PSY, V23, pS60
   Wulf G, 2008, RES Q EXERCISE SPORT, V79, P319
   Wulf G, 2007, RES Q EXERCISE SPORT, V78, P384, DOI 10.5641/193250307X13082505158336
   YOUDAS JW, 1991, PHYS THER, V71, P98, DOI 10.1093/ptj/71.2.98
   Zachry T, 2005, BRAIN RES BULL, V67, P304, DOI 10.1016/j.brainresbull.2005.06.035
NR 88
TC 0
Z9 0
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 177
EP 202
D2 10.5772/553
PG 26
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400010
DA 2024-07-18
ER

PT B
AU Tang, CH
   Chang, CW
   Chuang, YJ
   Lin, CY
AF Tang, Chieh-Hsin
   Chang, Chin-Wei
   Chuang, Ying-Ji
   Lin, Ching-Yuan
BE Kim, JJ
TI An Exploratory Study on the Relationship between Orientation Map Reading
   and Way-finding in Unfamiliar Environments
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID VIRTUAL ENVIRONMENTS
C1 [Tang, Chieh-Hsin] Tungnan Univ, Taipei, Taiwan.
   [Chang, Chin-Wei; Chuang, Ying-Ji; Lin, Ching-Yuan] Natl Taiwan Univ Sci & Technol, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Tang, CH (corresponding author), Tungnan Univ, Taipei, Taiwan.
RI tang, chieh hsin/ITU-7141-2023; Tang, Chieh-Hsin/IAN-0476-2023
OI tang, chieh hsin/0000-0003-4516-6488; Tang,
   Chieh-Hsin/0000-0003-4516-6488
CR [Anonymous], 2003, HUM FAC ER
   Beaumont P., 1984, ENV DESIGN RES ASS P, V15, P77
   Best G.A., 1970, ARCHITECTURAL PSYCHO, P72
   Booth K. S., 2000, P GRAPH INT 2000 M S
   COLLINS AM, 1969, J VERB LEARN VERB BE, V8, P240, DOI 10.1016/S0022-5371(69)80069-1
   Darken R.P., 1996, P SIGCHI C HUMAN FAC, P142, DOI DOI 10.1145/238386.238459
   Darken R.P., 1995, C COMPANION HUMAN FA, P45, DOI 10.1145/223355.223419
   Elvins T., 1997, Computer Graphics, V31, P15
   EVANS GW, 1980, PSYCHOL BULL, V88, P259, DOI 10.1037/0033-2909.88.2.259
   Golledge R., 1997, SPATIAL BEHAV GEOGRA
   Golledge RG, 1999, WAYFINDING BEHAVIOR, P5
   Grammenos D., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P131
   Jansen-Osmann P, 2002, COMPUT HUM BEHAV, V18, P427, DOI 10.1016/S0747-5632(01)00055-3
   Johns C., 2003, P 2 INT C COMP GRAPH, P7
   KITCHIN RM, 1994, J ENVIRON PSYCHOL, V14, P1, DOI 10.1016/S0272-4944(05)80194-X
   Krieg-Bruckner B., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P373
   Kuipers B., 1983, SPATIAL ORIENTATION, P345, DOI [10.1007/978-1-4615-9325-615, DOI 10.1007/978-1-4615-9325-615, 10.1007/978-1-4615-9325-6, DOI 10.1007/978-1-4615-9325-6]
   LIBEN LYNNS., 1981, SPATIAL REPRESENTATI, P3
   Lynch K., 1960, IMAGE CITY
   MONTELLO DR, 1991, ENVIRON BEHAV, V23, P47, DOI 10.1177/0013916591231003
   Montello DR, 1999, ANN ASSOC AM GEOGR, V89, P515, DOI 10.1111/0004-5608.00160
   Nichols F., 1992, EVALUATING PREDICTIN
   ONEILL MJ, 1991, ENVIRON BEHAV, V23, P553, DOI 10.1177/0013916591235002
   ONEILL MJ, 1991, ENVIRON BEHAV, V23, P259, DOI 10.1177/0013916591233001
   Passini Romedi., 1999, Visual Information for everyday use - Design and research perspectives, P241
   Passini Romedi., 1992, Wayfinding in architecture
   Siegel A. W., 1975, DEV SPATIAL REPRESEN
   Sorrows ME, 1999, LECT NOTES COMPUT SC, V1661, P37
   Tang CH, 2008, APPL ERGON, V39, P209, DOI 10.1016/j.apergo.2007.05.001
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Trowbridge L., 1996, Teaching secondary school science, V6th
   Tversky B, 1999, LECT NOTES COMPUT SC, V1661, P51
   Tversky Barbara., 2000, HDB MEMORY, P363
   WEISMAN J, 1981, ENVIRON BEHAV, V13, P189, DOI 10.1177/0013916581132004
   Weyrich M, 1999, COMPUT IND, V38, P5, DOI 10.1016/S0166-3615(98)00104-3
   Wilson JR, 1999, APPL ERGON, V30, P3, DOI 10.1016/S0003-6870(98)00040-4
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   Zeltzer D., 1994, VIRTUAL ACTORS VIRTU, P229
NR 39
TC 0
Z9 0
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 223
EP 244
D2 10.5772/553
PG 22
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400012
DA 2024-07-18
ER

PT J
AU Frees, S
AF Frees, Scott
TI Context-driven interaction in immersive virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Human-computer interaction; Context-sensitive interaction; Virtual
   reality; Virtual environments, 3DUI, interaction techniques
ID MANIPULATION; FRAMEWORK; INTERFACE
AB There are many interaction tasks a user may wish to accomplish in an immersive virtual environment. A careful examination of these tasks reveals that they are often performed under different contexts. For each task and context, specialized interaction techniques can be developed. We present the context-driven interaction model: a design pattern that represents contextual information as a first-class, quantifiable component within a user interface and supports the development of context-sensitive applications by decoupling context recognition, context representation, and interaction technique development. As a primary contribution, this model provides an enumeration of important representations of contextual information gathered from across the literature and describes how these representations can effect the selection of an appropriate interaction technique. We also identify how several popular 3D interaction techniques adhere to this design pattern and describe how the pattern itself can lead to a more focused development of effective interfaces. We have constructed a formalized programming toolkit and runtime system that serves as a reference implementation of the context-driven model and a discussion is provided explaining how the toolkit can be used to implement a collection of representative 3D interaction interfaces.
C1 Ramapo Coll, Mahwah, NJ USA.
C3 Ramapo College New Jersey (RCNJ)
RP Frees, S (corresponding author), Ramapo Coll, Mahwah, NJ USA.
EM sfrees@ramapo.edu
FU Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [0914976] Funding Source: National Science
   Foundation
CR Albinsson P.A., 2003, Proceedings of CHI 2003, P105, DOI [DOI 10.1145/642611.642631, 10.1145/642611.642631]
   [Anonymous], 1995, ACM Transactions on Computer-Human Interaction (TOCHI), DOI DOI 10.1145/210079.210088
   [Anonymous], 1996, CONTEXT CONSCIOUSNES
   BEIR EA, 1990, P ACM S INT 3D GRAPH, V24, P193
   Bowman D., 2001, Proc. HCII, P629
   Bowman D., 1999, P ACM S VIRT REAL SO, P26
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bowman DA, 2007, LECT NOTES COMPUT SC, V4563, P195
   Bukowski R. W., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P131, DOI 10.1145/199404.199427
   Chen J, 2006, P IEEE VIRT REAL ANN, P103
   Feiner Steven., 1993, Proceedings of the 6th ACM Symposium on User Interface Software and Technology (UIST '93), P145
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   FREES S, 2006, THESIS LEHIGH U
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Grosjean J, 2001, SPRING EUROGRAP, P1
   Kessler GD, 2000, PRESENCE-TELEOP VIRT, V9, P187, DOI 10.1162/105474600566718
   Kessler GD, 1999, P IEEE VIRT REAL ANN, P190, DOI 10.1109/VR.1999.756950
   Koller David R., 1996, P ACM S US INT SOFTW, P81
   MAPES DP, 1995, PRESENCE-TELEOP VIRT, V4, P403, DOI 10.1162/pres.1995.4.4.403
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Pierce JS, 2004, P IEEE VIRT REAL ANN, P173, DOI 10.1109/VR.2004.1310071
   Poupyrev I, 1998, COMPUT GRAPH FORUM, V17, pC41
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Poupyrev I, 1997, P ACM S VIRT REAL SO, P21
   RAY A, 2007, P 2007 ACM S VIRT RE, P187
   Ruddle RA, 2001, PRESENCE-TELEOP VIRT, V10, P511, DOI 10.1162/105474601753132687
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Stuerzlinger W, 2002, P IEEE VIRT REAL ANN, P251, DOI 10.1109/VR.2002.996529
   Tan D.S., 2001, P SIGCHI C HUMAN FAC, P418
   Tanriverdi Vildan, 2001, P ACM S VIRTUAL REAL, P175
   USOH M, 1999, P 26 ANN C COMP GRAP, P259
   WARE C, 2004, P 1 S APPL PERC GRAP
   WESCHE G, 2003, ACM INT C P SERIES, P39
   WINGRAVE C, 2008, IEEE VIRTUAL REAL
NR 36
TC 6
Z9 9
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2010
VL 14
IS 4
BP 277
EP 290
DI 10.1007/s10055-010-0178-2
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HX
UT WOS:000296279800005
DA 2024-07-18
ER

PT J
AU Smith, S
   Ericson, E
AF Smith, Shana
   Ericson, Emily
TI Using immersive game-based virtual reality to teach fire-safety skills
   to children
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); Immersive; CAVE; Game based; Fire safety; Children
AB Virtual reality (VR) has been used both to simulate situations that are too dangerous to practice in real life and as a tool to help children learn. This study was conducted as part of a larger more comprehensive long-term research project which aims to combine the two techniques and demonstrate a novel application of the result, using immersive VR to help children learn about fire hazards and practice escape techniques. In the current study, a CAVE was used to immerse participants in a fire scene. To improve the children's motivation for learning over prior VR fire-safety training methods, game-like interface interaction techniques were used and students were encouraged to explore the virtual world. Rather than being passive viewers, as in prior related studies, the children were given full control to navigate through the virtual environment and to interact with virtual objects using a game pad and a 6DOF wand. Students identified home fire hazards with a partner and then practiced escaping from a simulated fire in the virtual environment. To test for improved motivation, a user study was completed. Results indicate that students were more engaged by the new game-like learning environment and that they reported that they found the experience fun and intriguing. Their enhanced enthusiasm for what is relatively standard fire-safety information demonstrates the promise of using game-based virtual environments for vital but otherwise tedious fire-safety skills training for children.
C1 [Smith, Shana] Natl Taiwan Univ, Dept Mech Engn, Taipei 10764, Taiwan.
   [Ericson, Emily] Raytheon Co, Waltham, MA USA.
C3 National Taiwan University; Raytheon Technologies
RP Smith, S (corresponding author), Natl Taiwan Univ, Dept Mech Engn, Taipei 10764, Taiwan.
EM ssmith@ntu.edu.tw
CR [Anonymous], AM ED RES ASS SAN FR
   Elliott J, 2002, P INT C LEARN SCI 20
   Ericson E, 2008, 3 IASTED INT C HUM C
   Haller M., 1999, IMEKO - XV. World Congress. Measurement to Improve the Quality of Life in the 2st Century - Measurement Helps to Coordinate Nature with Human Activities - Vol. X. TEG-17. ISMCR'99 Topical Workshop on Virtual Reality and Advanced Human-Robot Systems, P291
   Kaufmann H., 2000, Education and Information Technologies, V5, P263, DOI 10.1023/A:1012049406877
   Kizil M.S., 2001, What can virtual reality do for safety
   Li L, 2005, VIRTUAL REALITY, P194
   McAllister D., 2000, The design of an api for particle systems
   Mungai D., 2002, P 18 ANN C DIST TEAC
   Ohlsson S, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P364
   Padgett LS, 2006, J PEDIATR PSYCHOL, V31, P65, DOI 10.1093/jpepsy/jsj030
   Pehrson R, 2004, FUNDAMENTALS FIRE PR, P101
   Randall J, 1993, FIRE TECHNOL, V29, P268
   Roussos M, 1999, PRESENCE-TELEOP VIRT, V8, P247, DOI 10.1162/105474699566215
   ROUSSOU M, 2004, COMPUT ENTERTAIN, V2, DOI [10.1145/973801.973818, DOI 10.1145/973801.973818]
   Roussou M., 2006, Virt Real, V10, P227, DOI 10.1007/s10055-006-0035-5
   Sherman WR, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P243
   Stansfield S, 2005, IEEE COMPUT GRAPH, P12
   Sulbaran T, 2000, ASEE IEEE FRONT ED C, P3
   Tate DL, 1997, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VRAIS.1997.583045
   Thomson JA, 2005, J EXP PSYCHOL-APPL, V11, P175, DOI 10.1037/1076-898X.11.3.175
   United States Fire Administration, 2002, PROT YOUR FAM FIR
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
NR 23
TC 110
Z9 121
U1 5
U2 74
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2009
VL 13
IS 2
BP 87
EP 99
DI 10.1007/s10055-009-0113-6
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XD
UT WOS:000208104200002
DA 2024-07-18
ER

PT J
AU Vindenes, J
   Wasson, B
AF Vindenes, Joakim
   Wasson, Barbara
TI Constructing hermeneutical relations: a postphenomenological inquiry
   into immersive VR memory palaces
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Method of loci; Virtual memory palace;
   Postphenomenology
AB While VR adaptations of the mnemonic Method of Loci (or the 'Memory Palace' technique) show promising results in increasing mnemonic capabilities, little to no research has explored the use and integration of Virtual Memory Palaces over time in a context of self-initiated studying. To explore the use of Virtual Memory Palaces (VMPs) contextually, we conducted an in-the-wild study where we gave ten participants a VR Head-Mounted Display through which they could access and furnish their VMP over eight weeks. We conducted go-along interviews in our participants' VMPs at various intervals throughout the eight-week study, exploring their creations and querying them about their experience. Based on our findings, this article discusses individual and contextual factors that come into play when a VMP is approached as a personal project in the midst of an already-established study routine. We frame our study as a postphenomenological inquiry into the mediating effects of VMPs, where our primary interest lies in what relationship the students developed to the VMP.
C1 [Vindenes, Joakim; Wasson, Barbara] Univ Bergen, Dept Informat Sci & Media Studies, Fosswinckels Gate 6, N-5007 Bergen, Norway.
   [Vindenes, Joakim; Wasson, Barbara] Univ Bergen, Ctr Sci Learning & Technol SLATE, Christiesgate 13, N-5020 Bergen, Norway.
C3 University of Bergen; University of Bergen
RP Vindenes, J (corresponding author), Univ Bergen, Dept Informat Sci & Media Studies, Fosswinckels Gate 6, N-5007 Bergen, Norway.; Vindenes, J (corresponding author), Univ Bergen, Ctr Sci Learning & Technol SLATE, Christiesgate 13, N-5020 Bergen, Norway.
EM joakim@matrise.no
OI Vindenes, Joakim/0000-0002-3983-3208
FU University of Bergen (incl Haukeland University Hospital)
FX Open access funding provided by University of Bergen (incl Haukeland
   University Hospital).
CR [Anonymous], 2012, Proceedings of the Designing Interactive Systems Conference. DIS'12, DOI [DOI 10.1145/2317956.2318078, 10.1145/2317956.2318078]
   Bass WS, 2014, ADV COGN PSYCHOL, V10, DOI 10.5709/acp-0156-3
   Bierig R, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123116
   Dalgleish T, 2013, CLIN PSYCHOL SCI, V1, P156, DOI 10.1177/2167702612468111
   Das S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1109, DOI 10.1145/3332165.3347917
   Fassbender E., 2006, J Comput Inf Syst, V2, P457
   Frauenberger C, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3364998
   Gerard PF, 2021, P 2021 7 INT C IMM L, DOI [10.23919/iLRN52045.2021.9459377, DOI 10.23919/ILRN52045.2021.9459377]
   Hauser S, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P459, DOI 10.1145/3196709.3196745
   Hedman A, 2003, E LEARN WORLD C E LE
   Hutchinson H., 2003, P ACM C HUMAN FACTOR, P17, DOI DOI 10.1145/642611.642616
   Huttner JP, 2017, AMCIS 2017 PROCEEDINGS
   Huttner JP, 2019, P 52 HAW INT C SYST, DOI [10.24251/hicss.2019.011, DOI 10.24251/HICSS.2019.011]
   Ihde D., 1990, Technology and the Lifeworld: From Garden to Earth, DOI DOI 10.5860/CHOICE.28-1535
   Jund T, 2016, IEEE INT CONF ADV LE, P533, DOI 10.1109/ICALT.2016.77
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Legge ELG, 2012, ACTA PSYCHOL, V141, P380, DOI 10.1016/j.actpsy.2012.09.002
   Liu AC, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1046, DOI [10.1109/vr.2019.8797836, 10.1109/VR.2019.8797836]
   Maguire EA, 2003, NAT NEUROSCI, V6, P90, DOI 10.1038/nn988
   Mann J, 2017, P IEEE VIRT REAL ANN, P383, DOI 10.1109/VR.2017.7892337
   Nyberg L, 2003, P NATL ACAD SCI USA, V100, P13728, DOI 10.1073/pnas.1735487100
   Peeters A, 2019, CONSCIOUS COGN, V76, DOI 10.1016/j.concog.2019.102834
   Putnam A. L., 2015, TRANSLATIONAL ISSUES, V1, P130, DOI [DOI 10.1037/TPS0000023, 10.1037/tps0000023]
   Ranpariya VK, 2022, J AM ACAD DERMATOL, V86, P1435, DOI 10.1016/j.jaad.2021.06.859
   Raz A, 2009, NEUROCASE, V15, P361, DOI 10.1080/13554790902776896
   Reggente N, 2020, J COGN ENHANCE, V4, P12, DOI 10.1007/s41465-019-00141-8
   Rosenberger R, 2009, AI SOC, V24, P173, DOI 10.1007/s00146-009-0190-9
   Sandberg P, 2021, J GERONTOL B-PSYCHOL, V76, P681, DOI 10.1093/geronb/gbaa216
   Schooler JN, 2021, MEMORY, V29, P1101, DOI 10.1080/09658211.2021.1962356
   Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745
   Verbeek P-P., 2005, What Things Do: Philosophical Reflections on Technology, Agency, and Design, DOI [10.1515/9780271033228, DOI 10.1515/9780271033228]
   Verbeek PP, 2008, PHENOMENOL COGN SCI, V7, P387, DOI 10.1007/s11097-008-9099-x
   Vetter A, 2020, IEEE CONF COMPU INTE, P642, DOI 10.1109/CoG47356.2020.9231610
   Vindenes J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.656423
   Vindenes J, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P190, DOI 10.1145/3461778.3462014
   Vindenes J, 2018, LECT NOTES COMPUT SC, V10850, P205, DOI 10.1007/978-3-319-95270-3_16
   Wakkary R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173668
   Wellner G., 2017, POSTPHENOMENOLOGY ME
   World Memory Championships, US
   Yang FM, 2021, IEEE T VIS COMPUT GR, V27, P4359, DOI 10.1109/TVCG.2020.3009003
   Yates F. A., 1966, ART MEMORY
NR 41
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3239
EP 3258
DI 10.1007/s10055-023-00868-y
EA OCT 2023
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001100048400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, BM
   Kang, CY
   Li, L
   Rami, FZ
   Chung, YC
AF Lee, Bo Mi
   Kang, Chae Yeong
   Li, Ling
   Rami, Fatima Zahra
   Chung, Young-Chul
TI Physiological responses to the virtual reality-based Trier social stress
   test in patients with psychosis
SO VIRTUAL REALITY
LA English
DT Article
DE Trier social stress test; Virtual reality; Cortisol; Skin conductance
   level; Heart rate; RR interval
ID HPA AXIS RESPONSE; CORTISOL REACTIVITY; SALIVARY CORTISOL; BIPOLAR
   DISORDER; SEX-DIFFERENCES; TEST TSST; SCHIZOPHRENIA; METAANALYSIS;
   MECHANISMS; RELAPSE
AB ObjectivesThe Trier social stress test (TSST) is one of the most reliable and widely used laboratory tests for evaluating the physiological stress response. We developed a virtual reality-based TSST (VR-TSST) and investigated the physiological responses to this test in patients with psychosis and healthy controls (HCs).MethodsThe participants comprised 60 patients with psychosis and 66 HCs. The VR-TSST consisted of three scenarios: a resting phase (baseline; 2 min), a job interview (5 min), and a mental arithmetic task (5 min). Blood cortisol levels were measured at baseline, during the test, and at 5-10 min and 30 min after the test. The skin conductance level, heart rate, and RR intervals were measured at baseline, during the job interview, and during the arithmetic task.ResultsThe VR-TSST produced no discernible cortisol response in patients with psychosis compared to the HCs. However, a higher skin conductance level and heart rate and shorter RR intervals were found in the patients than in the HCs at baseline, during the job interview, and during the arithmetic task.ConclusionThese findings suggest that the current version of the VR-TSST induces stronger autonomic and cardiovascular, but not endocrine, responses in patients with psychosis than in HCs. The VR-TSST could be a valuable tool to evaluate or train the stress response in patients with psychosis.
C1 [Lee, Bo Mi; Kang, Chae Yeong; Li, Ling; Rami, Fatima Zahra; Chung, Young-Chul] Jeonbuk Natl Univ, Dept Psychiat, Med Sch, Keumam Dong 634-18, Jeonju 56907, South Korea.
   [Lee, Bo Mi; Kang, Chae Yeong; Li, Ling; Rami, Fatima Zahra; Chung, Young-Chul] Jeonbuk Natl Univ, Jeonbuk Natl Univ Hosp, Biomed Res Inst, Res Inst Clin Med, Jeonju 54907, South Korea.
C3 Jeonbuk National University; Jeonbuk National University
RP Chung, YC (corresponding author), Jeonbuk Natl Univ, Dept Psychiat, Med Sch, Keumam Dong 634-18, Jeonju 56907, South Korea.; Chung, YC (corresponding author), Jeonbuk Natl Univ, Jeonbuk Natl Univ Hosp, Biomed Res Inst, Res Inst Clin Med, Jeonju 54907, South Korea.
EM chungyc@jbnu.ac.kr
OI Li, Ling/0000-0003-4923-5647; Rami, Fatima Zahra/0000-0003-1706-6113
FU The corresponding author would like to thank all participants in the
   study and family for guidance and support (SDG).
FX The corresponding author would like to thank all participants in the
   study and family for guidance and support (SDG).
CR Billman GE, 2011, FRONT PHYSIOL, V2, DOI 10.3389/fphys.2011.00086
   Brenner K, 2009, PSYCHONEUROENDOCRINO, V34, P859, DOI 10.1016/j.psyneuen.2009.01.002
   Brenner K, 2011, SCHIZOPHR RES, V128, P23, DOI 10.1016/j.schres.2011.01.016
   Butzlaff RL, 1998, ARCH GEN PSYCHIAT, V55, P547, DOI 10.1001/archpsyc.55.6.547
   Castro MN, 2008, SCHIZOPHR RES, V99, P294, DOI 10.1016/j.schres.2007.08.025
   Chaumette B, 2016, PSYCHONEUROENDOCRINO, V63, P262, DOI 10.1016/j.psyneuen.2015.10.007
   Ciufolini S, 2014, NEUROSCI BIOBEHAV R, V47, P359, DOI 10.1016/j.neubiorev.2014.09.004
   Dauvermann MR, 2019, IRISH J PSYCHOL MED, V36, P305, DOI 10.1017/ipm.2019.27
   Dickerson SS, 2004, PSYCHOL BULL, V130, P355, DOI 10.1037/0033-2909.130.3.355
   Dinzeo TJ, 2008, ACTA PSYCHIAT SCAND, V117, P432, DOI 10.1111/j.1600-0447.2008.01185.x
   First M.B., 2002, SCID-I/P)
   Freeman D, 2023, PSYCHOL MED, V53, P4373, DOI 10.1017/S0033291722001167
   Freeman D, 2019, TRIALS, V20, DOI 10.1186/s13063-019-3198-6
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Fujibayashi M, 2009, PSYCHIAT CLIN NEUROS, V63, P538, DOI 10.1111/j.1440-1819.2009.01983.x
   Gilissen R, 2008, DEV PSYCHOBIOL, V50, P615, DOI 10.1002/dev.20314
   Girshkin L, 2014, PSYCHONEUROENDOCRINO, V49, P187, DOI 10.1016/j.psyneuen.2014.07.013
   Gujjar KR, 2019, J ANXIETY DISORD, V62, P100, DOI 10.1016/j.janxdis.2018.12.001
   Jansen LMC, 2000, PSYCHOPHARMACOLOGY, V149, P319, DOI 10.1007/s002130000381
   Jansen LMC, 1998, SCHIZOPHR RES, V33, P87, DOI 10.1016/S0920-9964(98)00066-8
   Jönsson P, 2010, PSYCHONEUROENDOCRINO, V35, P1397, DOI 10.1016/j.psyneuen.2010.04.003
   Kampmann IL, 2016, J ANXIETY DISORD, V42, P71, DOI 10.1016/j.janxdis.2016.06.007
   KAY SR, 1987, SCHIZOPHRENIA BULL, V13, P261, DOI 10.1093/schbul/13.2.261
   KIRSCHBAUM C, 1992, PSYCHOSOM MED, V54, P648, DOI 10.1097/00006842-199211000-00004
   KIRSCHBAUM C, 1993, NEUROPSYCHOBIOLOGY, V28, P76, DOI 10.1159/000119004
   Lange C, 2017, PSYCHONEUROENDOCRINO, V82, P126, DOI 10.1016/j.psyneuen.2017.03.027
   Lange C, 2017, SCHIZOPHR RES, V182, P4, DOI 10.1016/j.schres.2016.10.008
   Leucht S, 2016, SCHIZOPHRENIA BULL, V42, pS90, DOI 10.1093/schbul/sbv167
   Lim CL, 1999, BIOL PSYCHIAT, V45, P127, DOI 10.1016/S0006-3223(98)00056-0
   Liu JJW, 2017, PSYCHONEUROENDOCRINO, V82, P26, DOI 10.1016/j.psyneuen.2017.04.007
   Marcelis M, 1998, PSYCHOL MED, V28, P871, DOI 10.1017/S0033291798006898
   NORMAN RMG, 1994, SOC PSYCH PSYCH EPID, V29, P244, DOI 10.1007/BF00802047
   NORMAN RMG, 1993, BRIT J PSYCHIAT, V162, P161, DOI 10.1192/bjp.162.2.161
   NUECHTERLEIN KH, 1994, ACTA PSYCHIAT SCAND, V89, P58, DOI 10.1111/j.1600-0447.1994.tb05867.x
   Nugent KL, 2015, PSYCHOSOM MED, V77, P733, DOI 10.1097/PSY.0000000000000215
   Pruessner M, 2017, NEUROSCI BIOBEHAV R, V73, P191, DOI 10.1016/j.neubiorev.2016.12.013
   Rubio G, 2015, PSYCHIAT RES, V228, P283, DOI 10.1016/j.psychres.2015.05.097
   Seitz R, 2019, PSYCHONEUROENDOCRINO, V105, P155, DOI 10.1016/j.psyneuen.2019.01.010
   Shevlin M, 2008, SCHIZOPHRENIA BULL, V34, P193, DOI 10.1093/schbul/sbm069
   Shiban Y, 2016, INT J PSYCHOPHYSIOL, V110, P47, DOI 10.1016/j.ijpsycho.2016.10.008
   Steen NE, 2011, PROG NEURO-PSYCHOPH, V35, P1100, DOI 10.1016/j.pnpbp.2011.03.008
   Takano K, 1993, Sangyo Igaku, V35, P257
   Valmaggia LR, 2016, SOC PSYCH PSYCH EPID, V51, P921, DOI 10.1007/s00127-016-1245-0
   van Venrooij JAEM, 2012, SCHIZOPHRENIA BULL, V38, P272, DOI 10.1093/schbul/sbq062
   van Winkel R, 2008, SCHIZOPHRENIA BULL, V34, P1095, DOI 10.1093/schbul/sbn101
   Veling W, 2016, PSYCHOL MED, V46, P3339, DOI 10.1017/S0033291716002208
   Veling W, 2014, SCHIZOPHRENIA BULL, V40, P1194, DOI 10.1093/schbul/sbu125
   Walker EF, 1997, PSYCHOL REV, V104, P667, DOI 10.1037/0033-295X.104.4.667
   Walker E, 2008, ANNU REV CLIN PSYCHO, V4, P189, DOI 10.1146/annurev.clinpsy.4.022007.141248
   Wieck A, 2013, BRAIN BEHAV IMMUN, V34, P47, DOI 10.1016/j.bbi.2013.07.005
   Zimmer P, 2019, PSYCHONEUROENDOCRINO, V101, P186, DOI 10.1016/j.psyneuen.2018.11.010
   Zorn JV, 2017, PSYCHONEUROENDOCRINO, V77, P25, DOI 10.1016/j.psyneuen.2016.11.036
NR 52
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3115
EP 3123
DI 10.1007/s10055-023-00857-1
EA SEP 2023
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001062310100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Feng, S
   He, WP
   Zhang, XT
   Billinghurst, M
   Wang, SX
AF Feng, Shuo
   He, Weiping
   Zhang, Xiaotian
   Billinghurst, Mark
   Wang, Shuxia
TI A comprehensive survey on AR-enabled local collaboration
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality (AR); Computer-supported cooperative work; AR-enabled
   local collaboration; Survey; Literature review
ID AUGMENTED REALITY SIMULATION; MIXED REALITY; PATTERNS; TABLETOP; DESIGN;
   WORK
AB With the rapid development of augmented reality (AR) technology and devices, it is widely used in education, design, industry, game, medicine and other fields. It brings new development opportunities for computer-supported cooperative work. In recent years, there has been an increasing number of studies on AR collaboration. Many professional researchers have also summarized and commented on these local and remote applications. However, to the best of our knowledge, there is no comprehensive review specifically on AR-enabled local collaboration (AR-LoCol). Therefore, this paper presents a comprehensive survey of research between 2012 and 2022 in this domain. We surveyed 133 papers on AR-LoCol in Web of Science, 75% of which were published between 2018 and 2022. Next, we provide an in-depth review of papers in seven areas, including time (synchronous and asynchronous), device (hand-held display, desktop, spatial AR, head-mounted display), participants (double and multiple), place (standing, indoor and outdoor), content (virtual objects, annotations, awareness cues and multi-perspective views), and area (education, industry, medicine, architecture, exhibition, game, exterior design, visualization, interaction, basic tools). We discuss the characteristics and specific work in each category, especially the advantages and disadvantages of different devices and the necessity for shared contents. Following this, we summarize the current state of development of AR-LoCol and discuss possible future research directions. This work will be useful for current and future researchers interested in AR-LoCol systems.
C1 [Feng, Shuo; He, Weiping; Zhang, Xiaotian; Billinghurst, Mark; Wang, Shuxia] Northwestern Polytech Univ, Cyber Phys Interact Lab, Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Billinghurst, Mark] Univ South Australia, STEM, Adelaide, SA 5095, Australia.
C3 Northwestern Polytechnical University; University of South Australia
RP Feng, S; He, WP (corresponding author), Northwestern Polytech Univ, Cyber Phys Interact Lab, Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
EM fengshuo9707@gmail.com; weiping@nwpu.edu.cn;
   2020100882@mail.nwpu.edu.cn; mark.billinghurst@unisa.edu.au;
   shuxiaw@nwpu.edu.cn
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Feng, Shuo/0000-0002-1414-6401;
   Zhang, Xiaotian/0000-0001-9572-4906
FU National Key Ramp;D Program of China [2020YFB1712503]; National Natural
   Science Foundation of China [52275513]
FX AcknowledgementsThis work is supported by the National Key R&D Program
   of China (Grant No. 2020YFB1712503), the National Natural Science
   Foundation of China (Grant No. 52275513). Specifically, we thank all
   authors for their contribution. Moreover, we thank Yu Guo for filtering
   and downloading papers. We also thank Li Zhang, Xinjing He, and Yizhe
   Liu for their invaluable discussion, criticism, and advice for further
   improving this paper. We are equally grateful to the authors of all the
   papers analyzed and mentioned in the review.
CR Afrooz A, 2018, ISPRS ANN PHOTO REM, V4-4, P5, DOI 10.5194/isprs-annals-IV-4-5-2018
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Ali AA, 2019, IEEE T LEARN TECHNOL, V12, P321, DOI 10.1109/TLT.2019.2926727
   Altug MY, 2016, INT J RECENT TRENDS
   Appelbaum SH, 1967, MANAGE DECIS
   Arce-Lopera C, 2019, I C VIRTUAL REALITY, P193, DOI 10.1109/ICVRV47840.2019.00045
   Attfield S., 2011, WSDM WORKSHOP USER M, P9
   Ayyanchira A, 2022, J VISUAL-JAPAN, V25, P1249, DOI 10.1007/s12650-022-00852-9
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baecker R.M., 1993, Readings in Groupware and Computer Cooperative Supported Work, Assisting Human-Human Collaboration
   Ballagas R, 2013, ACM C COMPUTER SUPPO
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Baroroh DK, 2021, J MANUF SYST, V61, P696, DOI 10.1016/j.jmsy.2020.10.017
   Bhattacharyya P, 2019, 2019A CHI C
   Bhattacharyya P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300553
   Boonbrahm P, 2016, LECT NOTES COMPUT SC, V9753, P115, DOI 10.1007/978-3-319-39483-1_11
   Borhani Z, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P950, DOI 10.1109/VRW55335.2022.00326
   Bork F, 2019, 2019 IEEE INT S MIX
   Bork F, 2021, ANAT SCI EDUC, V14, P590, DOI 10.1002/ase.2016
   Botev J, 2021, 2021 4TH IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2021), P215, DOI 10.1109/AIVR52153.2021.00049
   Brunetti D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12167965
   Bschel W., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445651
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Cabral M, 2016, 3D USER INTERFACES
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/vr.2019.8797733, 10.1109/VR.2019.8797733]
   Chabot S., 2020, 2020 6 INT C IMM LEA
   Chang YS, 2020, 2020 INT C INF COMM
   Chen WQ, 2021, IEEE ACCESS, V9, P73948, DOI 10.1109/ACCESS.2021.3080286
   Chen YF, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/22007
   Cheng KH, 2014, COMPUT EDUC, V72, P302, DOI 10.1016/j.compedu.2013.12.003
   Cheng YW, 2019, INTERACT LEARN ENVIR, V27, P782, DOI 10.1080/10494820.2019.1610448
   Chew SW, 2017, COLLABORATIVE LEARNI
   Chiou Y, 2019, MULTIPARTY MIXED REA
   Chiou YM, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P284, DOI 10.1109/VRW55335.2022.00066
   Chiou YM, 2019, 2019 IEEE C VIRT REA
   Chung CY, 2021, AUSTRALAS J EDUC TEC, V37, P17, DOI 10.14742/ajet.7059
   Chung CY, 2021, IEEE INT CONF ADV LE, P395, DOI 10.1109/ICALT52272.2021.00126
   Van CL, 2021, INTELL AUTOM SOFT CO, V27, P853, DOI 10.32604/iasc.2021.013732
   Cortes-Davalos A, 2016, CYTED RITOS INT WORK
   Cortes-Davalos A, 2017, 2016 INT C COLL TECH
   Cortés-Dávalos A, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P640, DOI [10.1109/WI.2016.113, 10.1109/WI.2016.0113]
   Dix A., 2004, Human-computer interaction
   Dolata M, 2019, INT C HUMAN COMPUTER
   Dolinsky M., 2014, INT SOC OPT PHOTONIC, V9012, P204
   Dong SY, 2013, ADV ENG SOFTW, V55, P45, DOI 10.1016/j.advengsoft.2012.09.001
   Druta R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110035
   Dunser A., 2008, A survey of evaluation techniques used in augmented reality studies
   Echeverría A, 2012, COMPUT HUM BEHAV, V28, P1170, DOI 10.1016/j.chb.2012.01.027
   Ens B, 2021, IEEE T VIS COMPUT GR
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Erickson A, 2020, J MULTIMODAL USER IN, V14, P353, DOI 10.1007/s12193-020-00330-2
   Escudero DF, 2013, APPL COMPUTATIONAL M
   Fang W, 2022, ROBOT COMPUT INTEGR
   Farrugia JP, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281568
   Feng S, 2023, INT J HUM-COMPUT INT, V39, P3556, DOI 10.1080/10447318.2022.2099237
   Garay-Cortes J., 2016, INT C INF
   García-Pereira I, 2020, MULTIMED TOOLS APPL, V79, P6483, DOI 10.1007/s11042-019-08419-x
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Giraudeau P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P55, DOI 10.1145/3343055.3359721
   Gorry GA., 1970, INT J ENERG RES, V35, P781
   Grandi JG, 2017, P IEEE VIRT REAL ANN, P419, DOI 10.1109/VR.2017.7892355
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/VR.2019.8798080, 10.1109/vr.2019.8798080]
   Grandi JG, 2017, 3D USER INTERFACES
   Grandi JG, 2018, IEEE VIRTUAL REALITY
   Grasser A, 2019, ECAADE SIGRADI 2019: ARCHITECTURE IN THE AGE OF THE 4TH INDUSTRIAL REVOLUTION, VOL 1, P325
   GRUDIN J, 1994, COMPUTER, V27, P19, DOI 10.1109/2.291294
   Grudin J, 2013, ENCY HUMAN COMPUTER
   Gül LF, 2018, J MULTIMODAL USER IN, V12, P109, DOI 10.1007/s12193-017-0252-0
   Gul LF, 2017, STUDYING ARCHITECTUR
   Gul LF, 2016, 34 ECAADE C
   Hall M, 2018, DS 92 P DESIGN 2018
   Hamadache K, 2009, LECT NOTES COMPUT SC, V5784, P206, DOI 10.1007/978-3-642-04216-4_17
   Harms C., 2004, Seventh Annual International Workshop: Presence 2004
   HART S G, 1988, P139
   He F, 2018, ADV TRANSDISCIP ENG
   He WN, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365699
   Hou HT, 2021, J EDUC COMPUT RES, V59, P547, DOI 10.1177/0735633120969409
   Huo K, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P19, DOI 10.1145/3242587.3242595
   Indrasari W, 2019, 8 NAT PHYS SEM 2019
   Irlitti A, 2016, IEEE INT S MIX AUGM
   Januszka M, 2006, COLLABORATIVE AUGMEN
   Jin Y, 2020, APPL SCI, V10
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Kang S, 2016, INTERACTION DESIGN C
   Kassim MH, 2017, ADV SCI LETT, V23, P890, DOI 10.1166/asl.2017.7549
   Keifert D, 2020, INT J SCI EDUC, V42, P3093, DOI 10.1080/09500693.2020.1851423
   Kim S, 2020, J MULTIMODAL USER IN
   Kim S, 2019, CLIN EXP HYPERTENS, V41, P766, DOI 10.1080/10641963.2018.1557677
   Knoke MQB, 2018, PROC CIRP, V72, P1130, DOI 10.1016/j.procir.2018.03.061
   Kostov G, 2022, PROCEDIA COMPUT SCI, V200, P896, DOI 10.1016/j.procs.2022.01.287
   Kumar A, 2023, ENVIRON SCI POLLUT R, V30, P24890, DOI 10.1007/s11356-022-18794-y
   Kumar P, 2021, J IND INF INTEGR
   Ladwig P, 2019, LECT NOTE NETW SYST, V47, P591, DOI 10.1007/978-3-319-95678-7_65
   Li Y, 2022, IEEE T VIS COMPUT GR, V28, P3896, DOI 10.1109/TVCG.2022.3203094
   Li Y, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357583
   Liao Y, 2014, INT C VIRT REAL VIS
   Lin TJ, 2013, COMPUT EDUC, V68, P314, DOI 10.1016/j.compedu.2013.05.011
   López-Faican L, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2020.103814
   Luo W, 2021, CHI 21 CHI C HUM FAC
   Lupascu AG, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P669, DOI 10.1109/VRW52623.2021.00217
   Ma Y, 2014, P 2014 ACM INT JOINT, P251
   Mackamul EB, 2016, SYMPOSIUM
   Marques B, 2021, IEEE T VIS COMPUT GR
   Marques B, 2021B IEEE C VIRT RE
   Marques B, 2022, COMPUT GRAPH-UK, V102, P413, DOI 10.1016/j.cag.2021.10.009
   Marques B, 2022, COMPUT GRAPH-UK, V102, P619, DOI 10.1016/j.cag.2021.08.006
   Masneri S, 2022, J UNIVERS COMPUT SCI, V28, P564, DOI 10.3897/jucs.76535
   Matcha Wannisa, 2012, 2012 4th International Congress on Engineering Education (ICEED 2012), P64, DOI 10.1109/ICEED.2012.6779271
   Matcha W, 2013, PROCEDIA COMPUT SCI, V25, P144, DOI 10.1016/j.procs.2013.11.018
   Me FF, 2015, INTERNET HIGH EDUC, V26, P33, DOI 10.1016/j.iheduc.2015.04.003
   Mendoza S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237881
   Michna A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14148844
   Miller J, 2022, 2022 21ST ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2022), P428, DOI 10.1109/IPSN54338.2022.00041
   Murnane M, 2019, COMP 2020 ACM INT C
   Naidoo D, 2020, ICINCO: PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, P385, DOI 10.5220/0009779103850393
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376330
   Nicola R, 2019, SCI REP-UK
   Nikimaleki M, 2022, J COMPUT ASSIST LEAR, V38, P758, DOI 10.1111/jcal.12646
   Ntagiantas A, 2022, APPL SCI
   Oda O, 2012, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2012.6402558
   Ogawa S, 2021, COMM COM INF SC, V1498, P451, DOI 10.1007/978-3-030-90176-9_58
   Oh S, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P539, DOI 10.1145/2839462.2856521
   Pan XY, 2021, IEEE ACCESS, V9, P164742, DOI 10.1109/ACCESS.2021.3134589
   Papadopoulos T, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188752
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Piumsomboon Thammathip, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P38, DOI 10.1109/ISUVR.2017.20
   Radu I, 2023, IEEE T VIS COMPUT GR, V29, P3734, DOI 10.1109/TVCG.2022.3169980
   Ratcliffe J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445170
   Regenbrecht H. T., 2002, Virtual Reality, V6, P151, DOI 10.1007/s100550200016
   Ren P, 2020, IEEE NETWORK, V34, P254, DOI 10.1109/MNET.011.1900305
   Rompapas DC, 2019, COMPUT GRAPH-UK
   Ruth K, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P141
   Rydvanskiy R, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020082
   Salas J, 2021, IEEE T GAMES, V13, P216, DOI 10.1109/TG.2021.3068426
   Sarkar P, 2018, IEEE CONF TECHNOL ED, P8, DOI 10.1109/T4E.2018.00010
   Schattel D, 2014, P INT S MIX AUGM REA
   Schiffeler N, 2021, BASIC REQUIREMENTS D
   Schiffeler N, 2020, LECT NOTE NETW SYST, V80, P719, DOI 10.1007/978-3-030-23162-0_65
   Schmidt S, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P279, DOI 10.1145/3279778.3279806
   Schott D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P296, DOI 10.1109/VR50410.2021.00052
   Schwede C, 2015, INT CONF COGN INFO, P517, DOI 10.1109/CogInfoCom.2015.7390647
   Sereno M, 2022, VIRTUAL REAL-LONDON, V26, P1317, DOI 10.1007/s10055-021-00614-2
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Shaikh A, 2019, 2019 IEEE INT C ARTI
   Sharma VS, 2020, 2020 IEEE C VIRT REA
   Shin JG, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174930
   Sikorski B, 2020, LECT NOTES COMPUT SC, V12242, P343, DOI 10.1007/978-3-030-58465-8_26
   Simon S, 2022, LECT NOTES COMPUT SC, V13450, P601, DOI 10.1007/978-3-031-16290-9_56
   Son K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376452
   Song TY, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P551, DOI 10.1109/VRW55335.2022.00131
   Sun TC, 2019, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis.2019.00010
   Tan Y, 2024, ENG CONSTR ARCHIT MA, V31, P1100, DOI 10.1108/ECAM-06-2022-0557
   Tayeh R, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000847
   Teo T, 2021, EXPLORING TEACHER IM
   TERVEEN LG, 1995, KNOWL-BASED SYST, V8, P67, DOI 10.1016/0950-7051(95)98369-H
   Timmerman M, 2020, 2020 IEEE C VIRT REA
   Tissenbaum M, 2019, INSTR SCI, V47, P423, DOI 10.1007/s11251-019-09486-1
   Touel S, 2017, COLLOCATED LEARNING, P1, DOI [10.1109/ICEE-B.2017.8192219, DOI 10.1109/ICEE-B.2017.8192219]
   Tsamis G, 2021, IEEE ROMAN, P520, DOI 10.1109/RO-MAN50785.2021.9515474
   Tucker AO, 2020, PROC SPIE, V11426, DOI 10.1117/12.2558753
   Valente A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P158, DOI 10.1109/VR51125.2022.00034
   van der Stappen A, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P731, DOI 10.1145/3341215.3356295
   Wang HY, 2014, J SCI EDUC TECHNOL, V23, P682, DOI 10.1007/s10956-014-9494-8
   Wang J., 2022, INT C HUM COMP INT
   Wang JY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041319
   Wang P, 2021, ROBOT CIM-INT MANUF, V72
   Wang P, 2020, ENG COMPUT-GERMANY, V36, P1715, DOI 10.1007/s00366-019-00792-3
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Wang X, 2006, JOINT INT C COMPUTIN
   Wang ZL, 2021, INT J ADV MANUF TECH, V116, P3193, DOI 10.1007/s00170-021-07624-z
   Wells T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376541
   Wen Y, 2018, CHINESE CHARACTER CO, V70
   Wen Y, 2021, ETR&D-EDUC TECH RES, V69, P843, DOI 10.1007/s11423-020-09893-z
   Wen Y, 2020, IEEE T LEARN TECHNOL, V13, P259, DOI 10.1109/TLT.2019.2924216
   Wiehr F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P1047, DOI 10.1145/3123024.3124446
   Woodward K, 2022, LECT NOTES COMPUT SC, V13334, P652, DOI 10.1007/978-3-031-05637-6_42
   Yabuki N, 2012, LECT NOTES COMPUT SC, V7467, P227, DOI 10.1007/978-3-642-32609-7_32
   Ye P, 2020B IEEE C VIRT RE
   Ye P, 2020, 2020A IEEE C VIRT RE
   Yoon SA, 2018, RES SCI TECHNOL EDUC, V36, P261, DOI 10.1080/02635143.2017.1386645
   Lin YT, 2022, IEEE T EDUC, V65, P617, DOI 10.1109/TE.2022.3155884
   Yusof CS, 2019, IEEE C GRAPH MED
   Zhang JH, 2021, IEEE T IND INFORM, V17, P2081, DOI 10.1109/TII.2020.2999924
   Zhang YX, 2021B IEEE C VIRT RE
   Zheng M, 2021, 7 INT C IMM LEARN RE
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zimmerman HT, 2022, INT J COMP-SUPP COLL, V17, P107, DOI 10.1007/s11412-022-09366-w
NR 187
TC 0
Z9 0
U1 11
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2941
EP 2966
DI 10.1007/s10055-023-00848-2
EA AUG 2023
PG 26
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001050573300001
DA 2024-07-18
ER

PT J
AU Chen, SS
   Hu, G
   Meng, XF
   Guo, J
   Fang, H
   Jiang, HY
   Weng, DD
AF Chen, Shanshan
   Hu, Gang
   Meng, Xiangfeng
   Guo, Jie
   Fang, Hui
   Jiang, Haiyan
   Weng, Dongdong
TI Altered functional connectivity of the hippocampus with the sensorimotor
   cortex induced by long-term experience of virtual hand illusion
SO VIRTUAL REALITY
LA English
DT Article
DE Resting-state fMRI; Virtual hand ownership illusion; Virtual reality;
   Hippocampus; Brain plasticity
ID RUBBER HAND; OWNERSHIP; BODY; PREMOTOR; MEMORY; INFORMATION; NEURONS;
   SPACE; ARM
AB Synchronizing the movement of a virtual hand with an unseen real hand in a virtual environment is an effective method to induce a sense of ownership of the virtual hand. Although several neuroimaging studies have revealed neural mechanisms related to the ongoing process of ownership illusion, the effect of the long-term experience of ownership illusion on brain activity remains to be investigated. Here, we developed an apparatus based on real-time image matting and virtual reality technology which allowed us to use the image of participants' real hands as their virtual hands and synchronize the movement of the virtual hands with the unseen real hands in a virtual scene. Resting-state functional imaging data were acquired immediately after participants completed several light office tasks with the virtual hands in either the virtual environment (virtual hand condition) or real environment (real hand condition). Significant positive functional connectivity of the hippocampus with the primary somatosensory and motor cortex was only observed in the virtual hand condition. The results provided novel evidence for the involvement of hippocampal-sensorimotor connection in the long-term experience of virtual hand ownership. The functional connection reorganization of the hippocampus might promote multi-sensory information integration into memory and updated the sense of body ownership, which offered important insights into the neural network underlying the availability of long-term use of VR technology in healthcare and rehabilitation.
C1 [Chen, Shanshan; Guo, Jie; Fang, Hui; Jiang, Haiyan; Weng, Dongdong] Beijing Inst Technol, Beijing Engn Res Ctr Mixed Real & Adv Display, Sch Opt & Photon, Beijing, Peoples R China.
   [Weng, Dongdong] AICFVE Beijing Film Acad, Beijing, Peoples R China.
   [Hu, Gang; Meng, Xiangfeng] 7Th Med Ctr PLA Gen Hosp, Dept Radiol, Beijing, Peoples R China.
C3 Beijing Institute of Technology
RP Chen, SS; Weng, DD (corresponding author), Beijing Inst Technol, Beijing Engn Res Ctr Mixed Real & Adv Display, Sch Opt & Photon, Beijing, Peoples R China.; Weng, DD (corresponding author), AICFVE Beijing Film Acad, Beijing, Peoples R China.
EM shanchen0923@gmail.com; crgj@bit.edu.cn
RI Chen, Shanshan/ABE-7657-2021
OI Chen, Shanshan/0000-0003-2160-0083
FU National Natural Science Foundation of China [61902026]; National Key
   Research and Development Program of China [2018YFF0300802]; Key-Area
   Research and Development Program of Guangdong Province [2019B010149001];
   111 Project [B18005]
FX This study was supported by National Natural Science Foundation of China
   (No.61902026), National Key Research and Development Program of China
   (No.2018YFF0300802), Key-Area Research and Development Program of
   Guangdong Province (No.2019B010149001), and the 111 Project (B18005).
CR Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bekrater-Bodmann R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087013
   Bland BH, 2001, BEHAV BRAIN RES, V127, P119, DOI 10.1016/S0166-4328(01)00358-8
   Blanke O, 2015, NEURON, V88, P145, DOI 10.1016/j.neuron.2015.09.029
   Di Pino G, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00109
   Duan XJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032532
   Dykes RW, 1997, CAN J PHYSIOL PHARM, V75, P535, DOI 10.1139/cjpp-75-5-535
   Dypvik AT, 2004, J NEUROPHYSIOL, V92, P2040, DOI 10.1152/jn.01081.2003
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Fortin NJ, 2002, NAT NEUROSCI, V5, P458, DOI 10.1038/nn834
   Gould E, 1999, NAT NEUROSCI, V2, P260, DOI 10.1038/6365
   GRAZIANO MSA, 1994, SCIENCE, V266, P1054, DOI 10.1126/science.7973661
   Grion N, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002384
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   Guterstam A, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00412
   Hassabis D, 2009, CURR BIOL, V19, P546, DOI 10.1016/j.cub.2009.02.033
   Honma M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085734
   Jiang H., 2018, 2018 IEEE INT S MIX
   Lev-Ari L, 2015, EUR PSYCHIAT, V30, P868, DOI 10.1016/j.eurpsy.2015.06.008
   Lewisa CM, 2009, P NATL ACAD SCI USA, V106, P17558, DOI 10.1073/pnas.0902455106
   Limanowski J, 2016, J NEUROSCI, V36, P2582, DOI 10.1523/JNEUROSCI.3987-15.2016
   Ma K, 2015, CONSCIOUS COGN, V36, P277, DOI 10.1016/j.concog.2015.07.008
   Ma K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00604
   Pyasik M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62394-0
   Raichle ME, 1998, PHILOS T R SOC B, V353, P1889, DOI 10.1098/rstb.1998.0341
   Rodriguez PF, 2010, HUM BRAIN MAPP, V31, P391, DOI 10.1002/hbm.20873
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Schaefer M, 2007, NEUROIMAGE, V36, P700, DOI 10.1016/j.neuroimage.2007.03.046
   Schaefer M, 2009, HUM BRAIN MAPP, V30, P1413, DOI 10.1002/hbm.20609
   Schiller D, 2015, J NEUROSCI, V35, P13904, DOI 10.1523/JNEUROSCI.2618-15.2015
   Shibuya S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02242
   Shokur S, 2013, P NATL ACAD SCI USA, V110, P15121, DOI 10.1073/pnas.1308459110
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Wirth S, 2003, SCIENCE, V300, P1578, DOI 10.1126/science.1084324
   Wong CW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109622
   Wood ER, 2000, NEURON, V27, P623, DOI 10.1016/S0896-6273(00)00071-4
NR 39
TC 0
Z9 0
U1 7
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2703
EP 2710
DI 10.1007/s10055-023-00838-4
EA AUG 2023
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001041432300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Jimenez, M
   Becerra, I
   Ruiz, U
AF Jimenez, Mauricio
   Becerra, Israel
   Ruiz, Ubaldo
TI Toward inertial position tracking for head-mounted displays: a dataset
   and a deep learning approach evaluation
SO VIRTUAL REALITY
LA English
DT Article
DE Drift error; Position estimation; Virtual reality; Deep learning;
   Tracking
AB This work addresses the problem of correcting the drift error produced by inertial sensors for tracking the position of a Head-Mounted Display in virtual reality applications. Unlike state-of-the-art works, which use exteroceptive sensors to address the problem, this work introduces a novel approach to virtual reality based on deep learning and using data exclusively from proprioceptive sensors. The main contributions of this work are: (1) generating a database with readings taken from an inertial measurement unit located on a virtual reality headset while the users perform different activities and (2) testing deep neural networks based on bidirectional LSTM layers to predict trajectories of the user's head in virtual environments. Additionally, the results show that, compared to previous approaches based only on inertial readings, the proposed approach improves the estimation of the coordinate of the virtual reality headset corresponding to the user's height.
C1 [Jimenez, Mauricio; Ruiz, Ubaldo] Ctr Invest Cient & Educ Super Ensenada CICESE, Ensenada, Mexico.
   [Becerra, Israel] Ctr Invest Matemat CIMAT, Guanajuato, Mexico.
   [Becerra, Israel; Ruiz, Ubaldo] Consejo Nacl Ciencia & Tecnol CONACYT, Mexico City, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada; CIMAT - Centro de Investigacion en Matematicas
RP Ruiz, U (corresponding author), Ctr Invest Cient & Educ Super Ensenada CICESE, Ensenada, Mexico.; Ruiz, U (corresponding author), Consejo Nacl Ciencia & Tecnol CONACYT, Mexico City, Mexico.
EM jmjimenez@cicese.edu.mx; israelb@cimat.mx; uruiz@cicese.mx
RI ; Ruiz, Ubaldo/A-4376-2015
OI becerra, israel/0000-0002-9788-1128; Ruiz, Ubaldo/0000-0001-6857-1115
FU CONACYT [A1 -S-21934]; Catedras CONACYT [1850, 745]
FX & nbsp;This work was supported in part by CONACYT Grant A1 -S-21934, in
   part by Catedras CONACYT project 1850, and in part by Catedras CONACYT
   project 745.
CR Asraf O, 2022, IEEE SENS J, V22, P4932, DOI 10.1109/JSEN.2021.3066840
   Chen CH, 2018, AAAI CONF ARTIF INTE, P6468
   Chen C, 2018, LECT NOTES COMPUT SC, V11046, P143, DOI 10.1007/978-3-030-00919-9_17
   Clark R, 2017, AAAI CONF ARTIF INTE, P3995
   Cortés S, 2018, LECT NOTES COMPUT SC, V11214, P425, DOI 10.1007/978-3-030-01249-6_26
   Desai P.Rajesh., 2014, International Journal of Engineering Trends and Technology, V13, P175, DOI [10.14445/22315381/IJETT-V13P237, DOI 10.14445/22315381/IJETT-V13P237]
   Lima JPSD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173777
   Esfahani MA, 2020, IEEE T INTELL TRANSP, V21, P1941, DOI 10.1109/TITS.2019.2909064
   Herath S, 2020, IEEE INT CONF ROBOT, P3146, DOI 10.1109/icra40945.2020.9196860
   Jost TA, 2021, DISABIL REHABIL-ASSI, V16, P632, DOI 10.1080/17483107.2019.1688398
   Kovalenko D, 2021, 2021 INT C IND POS I, P1
   LaValle S, 2016, VIRTUAL REALITY NATL
   Lim H, 2019, IEEE INT C INT ROBOT, P3241, DOI [10.1109/IROS40897.2019.8968551, 10.1109/iros40897.2019.8968551]
   Liu WX, 2020, IEEE ROBOT AUTOM LET, V5, P5653, DOI 10.1109/LRA.2020.3007421
   Monica R, 2022, VIRTUAL REAL-LONDON, V26, P1335, DOI 10.1007/s10055-022-00637-3
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Razzaque S., 2001, PROC EUROGRAPHICS, P5
   Sun S, 2021, AAAI CONF ARTIF INTE, V35, P6128
   Wu JW, 2020, IEEE ACCESS, V8, P13078, DOI 10.1109/ACCESS.2019.2949878
   Yan K, 2016, IEEE T INSTRUM MEAS, V65, P2012, DOI 10.1109/TIM.2016.2573078
   Yao SC, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P351, DOI 10.1145/3038912.3052577
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2605
EP 2621
DI 10.1007/s10055-023-00831-x
EA JUL 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001026338500001
DA 2024-07-18
ER

PT J
AU Ponton, JL
   Ceballos, V
   Acosta, L
   Ríos, A
   Monclús, E
   Pelechano, N
AF Ponton, Jose Luis
   Ceballos, Victor
   Acosta, Lesly
   Rios, Alejandro
   Monclus, Eva
   Pelechano, Nuria
TI Fitted avatars: automatic skeleton adjustment for self-avatars in
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Avatar; User representation; Embodiment; Inverse kinematics; Virtual
   reality; Full-body tracking
ID EMBODIMENT
AB In the era of the metaverse, self-avatars are gaining popularity, as they can enhance presence and provide embodiment when a user is immersed in Virtual Reality. They are also very important in collaborative Virtual Reality to improve communication through gestures. Whether we are using a complex motion capture solution or a few trackers with inverse kinematics (IK), it is essential to have a good match in size between the avatar and the user, as otherwise mismatches in self-avatar posture could be noticeable for the user. To achieve such a correct match in dimensions, a manual process is often required, with the need for a second person to take measurements of body limbs and introduce them into the system. This process can be time-consuming, and prone to errors. In this paper, we propose an automatic measuring method that simply requires the user to do a small set of exercises while wearing a Head-Mounted Display (HMD), two hand controllers, and three trackers. Our work provides an affordable and quick method to automatically extract user measurements and adjust the virtual humanoid skeleton to the exact dimensions. Our results show that our method can reduce the misalignment produced by the IK system when compared to other solutions that simply apply a uniform scaling to an avatar based on the height of the HMD, and make assumptions about the locations of joints with respect to the trackers.
C1 [Ponton, Jose Luis; Rios, Alejandro; Monclus, Eva; Pelechano, Nuria] Univ Politecn Cataluna, Res Ctr Visualizat Virtual Real & G Interact ViRVI, Barcelona, Spain.
   [Ceballos, Victor] King Abdullah Univ Sci & Technol, Visual Comp Ctr VCC, Thuwal, Saudi Arabia.
   [Acosta, Lesly] Univ Politecn Cataluna, Estadist & Invest Operat EIO, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya; King Abdullah University of
   Science & Technology; Universitat Politecnica de Catalunya
RP Pelechano, N (corresponding author), Univ Politecn Cataluna, Res Ctr Visualizat Virtual Real & G Interact ViRVI, Barcelona, Spain.
EM jose.luis.ponton@upc.edu; victor.ceballosinza@kaust.edu.sa;
   lesly.acosta@upc.edu; arios@cs.upc.edu; emonclus@cs.upc.edu;
   npelechano@cs.upc.edu
RI Ponton, Jose Luis/HTN-5598-2023; Acosta, Lesly/GLT-4431-2022; Ceballos
   Inza, Victor/Y-9602-2018; Monclus, Eva/K-7786-2014; Pelechano,
   Nuria/K-4288-2014
OI Ponton, Jose Luis/0000-0001-6576-4528; Acosta,
   Lesly/0000-0002-5859-2120; Ceballos Inza, Victor/0000-0002-7927-9803;
   Monclus, Eva/0000-0002-9645-0510; Rios Jerez,
   Alejandro/0000-0003-1210-8951; Pelechano, Nuria/0000-0002-1437-245X
FU Spanish Ministry of Science and Innovation [PID2021-122136OB-C21];
   Spanish Ministry of Universities [FPU21/01927]
FX AcknowledgementsThis work was funded by the Spanish Ministry of Science
   and Innovation (PID2021-122136OB-C21). Jose Luis Ponton was also funded
   by the Spanish Ministry of Universities (FPU21/01927).
CR Andujar C, 2018, EUROGRAPHICS WORKSH, DOI 10.2312/gch.20181340.Eurographics
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Cohen J., 1988, STAT POWER ANAL BEHA
   Fröst P, 2000, IEEE INFOR VIS, P568, DOI 10.1109/IV.2000.859814
   Gamage SSHU, 2002, J BIOMECH, V35, P87, DOI 10.1016/S0021-9290(01)00160-9
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Magazù S, 2019, FOUND SCI, V24, P751, DOI 10.1007/s10699-019-09616-5
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Ponton Jose Luis, 2022, P EUR 2022 SHORT PAP, P77, DOI [10.2312/egs20221037, DOI 10.2312/EGS20221037]
   Pujades S, 2019, IEEE T VIS COMPUT GR, V25, P1887, DOI 10.1109/TVCG.2019.2898748
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   Sheppard J., 2013, ANATOMY COMPLETE GUI
   Shi MY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3407659
   Slater M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00091
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Thaler A., 2018, FRONT ICT, V5, P18, DOI [DOI 10.3389/FICT.2018.00018, 10.3389/fict.2018, DOI 10.3389/FICT.2018]
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Wobbrock J.O., 2011, ALIGNED RANK TRANSFO, DOI [DOI 10.1145/1978942.1978963, 10.1145/1978942.1978963, 10.1145/1978942, DOI 10.1145/1978942]
   Yun HR, 2023, Symposium Virtual Re, P286, DOI 10.1109/VR55154.2023.00044
   Zeng Q, 2022, VIRTUAL REAL-LONDON, V26, P1391, DOI 10.1007/s10055-022-00635-5
NR 28
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2541
EP 2560
DI 10.1007/s10055-023-00821-z
EA JUL 2023
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001023420900001
OA hybrid, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU McCluskey, A
   Al-Amri, M
AF McCluskey, Andrew
   Al-Amri, Mohammad
TI The potential of using virtual reality-based self-paced treadmill to
   assess road-crossing safety and self-evaluation with traumatic brain
   injuries: a series case study
SO VIRTUAL REALITY
LA English
DT Article
DE Traumatic brain injury; Impaired self-awareness; Virtual reality;
   Road-crossing; Self-evaluation; Feedback
ID VIDEO FEEDBACK; AWARENESS; INTERVENTIONS; PERFORMANCE
AB Impaired self-awareness (ISA) is common following traumatic brain injury (TBI) and can significantly impact safe road-crossing. Road-crossing interventions are variable and involve high-risk real-world situations. Virtual reality (VR)-based road-crossing can elicit changes in real-world functioning but has not been trialled in the TBI population. The primary objective of this research was to explore whether VR-based self-paced treadmill technology offers a safe road-crossing assessment mechanism for people with TBI. Three participants with TBI completed two road-crossing pilot-trials using a VR-based self-paced treadmill. Avatar feedback and verbal feedback were provided between trials. Participants were provided with a safe road-crossing strategy for the second pilot-trial. The Researcher and Participant evaluated road-crossing following each trial using the Mayo-Portland Adaptability Inventory and the number of safe road-crossings to assess changes in self-evaluation and performance between trials. One of the participants perceived improvements in self-evaluation and performance in the second pilot-trial. All participants attempted to apply the safe road-crossing strategy advised. No safety issues were identified using the VR-based self-paced treadmill within this study's protocol thereby supporting the primary objective of the work. Future research is warranted to strengthen the evidence-base for using VR to elicit improvements in ISA in road-crossing and in generalising findings to the wider TBI population.
C1 [McCluskey, Andrew; Al-Amri, Mohammad] Cardiff Univ, Coll Biomed & Life Sci, Sch Healthcare Sci, Cardiff CF24 0AB, Wales.
C3 Cardiff University
RP Al-Amri, M (corresponding author), Cardiff Univ, Coll Biomed & Life Sci, Sch Healthcare Sci, Cardiff CF24 0AB, Wales.
EM McCluskeyAJ1@Cardiff.ac.uk; Al-AmriM@cardiff.ac.uk
OI , Mohammad/0000-0003-2806-0462
CR Al Banna M, 2016, J NEUROL NEUROSUR PS, V87, P161, DOI 10.1136/jnnp-2015-310305
   Al-Amri M, 2017, COMPUT METHOD BIOMEC, V20, P1669, DOI 10.1080/10255842.2017.1404994
   Barber S., 2018, Acquired brain injury
   Butler AA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152617
   Clancy TA, 2006, J CLIN CHILD ADOLESC, V35, P203, DOI 10.1207/s15374424jccp3502_4
   DePoy E., 2005, Introduction to research: Understanding and applying multiple strategies
   Doig E, 2014, AM J OCCUP THER, V68, P578, DOI 10.5014/ajot.2014.010785
   FitzGerald MCC, 2019, NEUROPSYCHOL REHABIL, V29, P821, DOI 10.1080/09602011.2017.1336102
   Foloppe DA, 2018, NEUROPSYCHOL REHABIL, V28, P709, DOI 10.1080/09602011.2015.1094394
   Ford KJ, 2017, MOVEMENT DISORD, V32, P1748, DOI 10.1002/mds.27124
   Guerrette MC, 2022, DISABIL REHABIL, V44, P5250, DOI 10.1080/09638288.2021.1924882
   Headway, 2017, ACQ BRAIN INJ STAT B
   Headway, 2023, FAT BRAIN INJ
   Jeffay E, 2023, J HEAD TRAUMA REHAB, V38, P52, DOI 10.1097/HTR.0000000000000834
   Jonasson A, 2018, BRAIN BEHAV, V8, DOI 10.1002/brb3.1056
   Kooistra B, 2009, J BONE JOINT SURG AM, V91A, P21, DOI 10.2106/JBJS.H.01573
   Kwon JH, 2022, ACCIDENT ANAL PREV, V174, DOI 10.1016/j.aap.2022.106757
   Lansink ILBO, 2017, GAIT POSTURE, V58, P121, DOI 10.1016/j.gaitpost.2017.07.040
   Lewis Frank D, 2013, J Spec Oper Med, V13, P56, DOI 10.55460/ATYP-5WSB
   Lucas SE., 2005, Austr Occup Ther J, V52, P160, DOI [DOI 10.1111/J.1440-1630.2005.00485.X, 10.1111/j.1440-1630.2005.00485.x]
   Malec J., 1994, J HEAD TRAUMA REHAB, V9, P1, DOI [10. 1097/ 00001199- 199412000- 00003, DOI 10.1097/00001199-199412000-00003]
   Malec J., 2008, Manual for the Mayo-Portland Adaptability Inventory (MPAI-4) for adults, children, and adolescents
   Malec JF, 2017, J HEAD TRAUMA REHAB, V32, pE47, DOI 10.1097/HTR.0000000000000268
   Malik J, 2024, HUM FACTORS, V66, P1520, DOI 10.1177/00187208231151280
   McDonald BC, 2002, NEUROREHABILITATION, V17, P333
   Mckee Ann C, 2015, Handb Clin Neurol, V127, P45, DOI 10.1016/B978-0-444-52892-6.00004-0
   Muratore M, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00062
   National Institute for Health and Care Excellence, 2017, HEAD INJ ASS EARL MA
   Pettemeridou E, 2020, NEUROREHABILITATION, V46, P109, DOI 10.3233/NRE-192963
   Rotenberg-Shpigelman S, 2014, NEUROREHABILITATION, V35, P47, DOI 10.3233/NRE-141101
   Saiano M, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0010-z
   Schmidt J, 2015, CAN J OCCUP THER, V82, P54, DOI 10.1177/0008417414550999
   Schmidt J, 2013, NEUROREHAB NEURAL RE, V27, P316, DOI 10.1177/1545968312469838
   Schmidt J, 2011, J REHABIL MED, V43, P673, DOI 10.2340/16501977-0846
   Schwebel DC, 2018, J PEDIATR PSYCHOL, V43, P473, DOI 10.1093/jpepsy/jsx147
   Stratton ME, 2017, TRAFFIC INJ PREV, V18, P47, DOI 10.1080/15389588.2016.1195494
   Teasell R., 2016, Ischemic Stroke Therapeutics, P195, DOI 10.1007/978-3-319-17750-2_18
   Tellis W., 1997, The Qualitative Report, V3, P1, DOI [10.46743/2160-3715/1997.2024, DOI 10.46743/2160-3715/1997.2024]
   Toglia J, 2000, NEUROREHABILITATION, V15, P57
   Torbaghan ME, 2022, ACCIDENT ANAL PREV, V166, DOI 10.1016/j.aap.2021.106543
   van den Bogert AJ, 2013, MED BIOL ENG COMPUT, V51, P1069, DOI 10.1007/s11517-013-1076-z
   Weber E, 2018, REHABIL PSYCHOL, V63, P383, DOI 10.1037/rep0000208
   Wright T, 2011, RES DEV DISABIL, V32, P1455, DOI 10.1016/j.ridd.2011.03.019
NR 43
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3621
EP 3631
DI 10.1007/s10055-023-00823-x
EA JUN 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001011889800001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Woodworth, JW
   Borst, CW
AF Woodworth, Jason W.
   Borst, Christoph W.
TI Pointing in the third-person: an exploration of human motion and visual
   pointing aids for 3D virtual mirrors
SO VIRTUAL REALITY
LA English
DT Article
DE Human factors; Virtual mirrors; Pointing and selection
ID PERFORMANCE
AB A "virtual mirror" is a promising interface for virtual or augmented reality applications in which users benefit from seeing themselves within the environment, such as serious games for rehabilitation exercise or biological education. While there is extensive work analyzing pointing and providing assistance for first-person perspectives, mirrored third-person perspectives have been minimally considered, limiting the quality of user interactions in current virtual mirror applications. We address this gap with two user studies aimed at understanding pointing motions with a mirror view and assessing visual cues that assist pointing. An initial two-phase preliminary study had users tune and test nine different visual aids. This was followed by in-depth testing of the best four of those visual aids compared with unaided pointing. Results give insight into both aided and unaided pointing with this mirrored third-person view, and compare visual cues. We note a pattern of consistently pointing far in front of targets when first introduced to the pointing task, but that initial unaided motion improves after practice with visual aids. We found that the presence of stereoscopy is not sufficient for enhancing accuracy, supporting the use of other visual cues that we developed. We show that users perform pointing differently when pointing behind and in front of themselves. We finally suggest which visual aids are most promising for 3D pointing in virtual mirror interfaces.
C1 [Woodworth, Jason W.; Borst, Christoph W.] Univ Louisiana Lafayette, CACS VR Lab, Lafayette, LA 70504 USA.
C3 University of Louisiana Lafayette
RP Woodworth, JW (corresponding author), Univ Louisiana Lafayette, CACS VR Lab, Lafayette, LA 70504 USA.
EM jason.woodworth1@louisiana.edu; cwborst@gmail.com
OI Woodworth, Jason/0000-0002-4808-6777
CR Ahn SJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.648575
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Banakou D, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14620-5
   Blum T, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P115, DOI 10.1109/VR.2012.6180909
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Bork F, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P169, DOI 10.1109/ISMAR.2017.33
   Borst CW, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P467, DOI 10.1109/VR.2018.8448286
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Eisert P., 2008, 2008 IEEE C COMPUTER, P1
   Ekong Sam, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P246, DOI 10.1007/978-3-319-50832-0_24
   Grossman T., 2006, P UIST 2006, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   HILSMANN A, 2009, TRACKING RETEXTURING, P94
   Hülsmann F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00043
   KRUEGER MW, 1985, LEONARDO, V18, P145, DOI 10.2307/1578043
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Lin CJ, 2017, APPL ERGON, V64, P66, DOI 10.1016/j.apergo.2017.05.007
   Liu L, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P219, DOI 10.1109/VR.2009.4811026
   Lubos P, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P13, DOI 10.1145/2983310.2985753
   Machuca MDB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300437
   Malinverni L, 2017, COMPUT HUM BEHAV, V71, P535, DOI 10.1016/j.chb.2016.01.018
   Mendes D, 2017, COMPUT GRAPH-UK, V67, P95, DOI 10.1016/j.cag.2017.06.003
   MEYER DE, 1988, PSYCHOL REV, V95, P340, DOI 10.1037/0033-295X.95.3.340
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Pazhayedath P, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P264, DOI 10.1109/VRW52623.2021.00055
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Preston C, 2015, SCI REP-UK, V5, DOI 10.1038/srep18345
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Straka M, 2011, LECT NOTES COMPUT SC, V6688, P635, DOI 10.1007/978-3-642-21227-7_59
   Stuerzlinger Wolfgang., 2014, Proceedings of HCI Korea (HCIK '15), P162
   Thanyadit S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P92, DOI 10.1145/3132272.3134131
   Vincent VJ, 1993, P 3 ANN VIRT REAL C, P167
   Woodworth JW, 2017, 2017 IEEE 3 WORKSH E, P1
   Woodworth JW, 2022, 2022 IEEE C VIRT REA
   Yoshimura A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.648619
NR 39
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2099
EP 2116
DI 10.1007/s10055-023-00796-x
EA APR 2023
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000967799800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Yang, ZY
   Jiang, S
   Zhuo, J
   Li, YH
   Zhu, T
   Ma, SX
   Zhang, JQ
AF Zhou, Zeyang
   Yang, Zhiyong
   Jiang, Shan
   Zhuo, Jie
   Li, Yuhua
   Zhu, Tao
   Ma, Shixing
   Zhang, Jingqi
TI Validation of a surgical navigation system for hypertensive
   intracerebral hemorrhage based on mixed reality using an automatic
   registration method
SO VIRTUAL REALITY
LA English
DT Article
DE Surgical navigation; Mixed reality; Hypertensive intracerebral
   hemorrhage; Automatically registration
ID MINIMALLY INVASIVE SURGERY
AB Hypertensive intracerebral hemorrhage (HICH) is a kind of intracerebral bleeding disease that affects 2.5 per 10,000 people world wide each year. An effective way of curing this disease is to perform a puncture procedure through the dura with a brain puncture drill and tube. The insertion accuracy determines the quality of surgery. Currently, augmented reality-and mixed reality (MR)-based surgical navigation is a promising new technology for surgical navigation in the clinic, aiming to improve the safety and accuracy of surgery. In this study, we present a novel multimodel MR navigation system for HICH surgery. With multi-information fusion technology, organs and hematoma data extracted from CT images can be fused with real patient, which allows surgeons to perform punctures easily. An automatic registration method with a 3D-printed fiducial marker was performed to significantly decrease the time required for surgery preparation.Phantom experiments and user tests were performed in this study, the results of these phantom experiments demonstrated that the mean registration error was 1.18 mm, the insertion error was 1.74 and the average time consumption was 15.9 min, which indicating that this approach was sufficient for clinical application. All the experimental results indicated that this system shows particular promise for use in training inexperienced surgeons, and the next steps would be to refine the system based on the findings with more experienced surgeons.
C1 [Zhou, Zeyang; Yang, Zhiyong; Jiang, Shan; Li, Yuhua; Zhu, Tao; Ma, Shixing; Zhang, Jingqi] Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.
   [Jiang, Shan] Tianjin Univ, Ctr Adv Mech & Robot, Tianjin 300350, Peoples R China.
   [Zhuo, Jie] Huanhu Hosp, Dept Neurosurg, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin University
RP Jiang, S (corresponding author), Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.; Jiang, S (corresponding author), Tianjin Univ, Ctr Adv Mech & Robot, Tianjin 300350, Peoples R China.
EM shanjmri@tju.edu.cn
RI Zhou, Zeyang/AAX-9853-2020; zhu, tao/KHY-3114-2024; Zhu,
   Tao/JEF-1129-2023; Zhang, Jingqi/AAE-7997-2022
OI Zhu, Tao/0009-0001-1499-8700; 
FU National Key R&D Program of China [2022YFB4702600, 2022YFB4702601];
   National Natural Science Foundation of China [81871457, 8167071354];
   Scientific and Technology Project of Jinnan District, Tianjin, China
   [20200110]; 2022 Excellent Doctoral Dissertation Fund of Tianjin
   University [1019201065]
FX AcknowledgementsThis work was supported by the National Key R&D Program
   of China (No. 2022YFB4702600, 2022YFB4702601), the National Natural
   Science Foundation of China (No. 81871457, 8167071354) ,the Scientific
   and Technology Project of Jinnan District, Tianjin, China (No. 20200110)
   and the 2022 Excellent Doctoral Dissertation Fund of Tianjin University
   (No.1019201065).
CR Asberg S, 2020, INT J STROKE, V15, P61, DOI 10.1177/1747493018816476
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bichlmeier C, 2008, 7 IEEE ACM INT S MIX
   Brand M, 2020, Ann Sci Soc Assem, Handl Ind Robot, P21, DOI [10.1007/978-3-662-61755-73, DOI 10.1007/978-3-662-61755-73]
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   Colley Ashley, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P317, DOI 10.1145/3428361.3432076
   Daisuke S, 2020, J ORTHOPAEDIC SURG, V28
   Dou HS, 2017, MED PHYS, V44, P4828, DOI 10.1002/mp.12435
   Duliu A, 2010, P SPIE, V7624
   Feng YY, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419885700
   Fida B, 2018, UPDATES SURG, V70, P389, DOI 10.1007/s13304-018-0567-8
   Frantz T, 2018, HEALTHC TECHNOL LETT, V5, P221, DOI 10.1049/htl.2018.5079
   Hersch M, 2012, J MATH IMAGING VIS, V43, P1, DOI 10.1007/s10851-011-0279-x
   Itamiya T., 2018, EPIC SERIES ENG, V1, P26, DOI DOI 10.29007/WJJX
   Jing LM, 2012, APPL MECH MATER, V159, P1, DOI 10.4028/www.scientific.net/AMM.159.1
   Kedilioglu O, 2021, INT C CONTR AUTOMAT, P878, DOI 10.23919/ICCAS52745.2021.9650050
   Li K, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.608403
   Li YQ, 2021, TRANSL STROKE RES, V12, P1035, DOI 10.1007/s12975-021-00893-6
   Lin CC, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0435-y
   Muschelli J, 2015, STROKE, V46, P3270, DOI 10.1161/STROKEAHA.115.010369
   Pandey AS, 2020, J CEREBR BLOOD F MET, V40, P456, DOI 10.1177/0271678X19892660
   Ramanan M, 2013, J CLIN NEUROSCI, V20, P1650, DOI 10.1016/j.jocn.2013.03.022
   Schlunk F, 2016, INT J STROKE, V11, P898, DOI 10.1177/1747493016658300
   Teatini A, 2021, INT J COMPUT ASS RAD, V16, P407, DOI 10.1007/s11548-020-02302-z
   Wang T, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.2024
   Wang WJ, 2017, WORLD NEUROSURG, V105, P348, DOI 10.1016/j.wneu.2017.05.158
   Wendler T, 2009, EUR J NUCL MED MOL I, V36, pS170
   [张金锋 Zhang Jinfeng], 2012, [中华神经医学杂志, Chinese Journal of Neuromedicine], V11, P401
NR 28
TC 4
Z9 4
U1 10
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2059
EP 2071
DI 10.1007/s10055-023-00790-3
EA APR 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000965016400001
DA 2024-07-18
ER

PT J
AU Ramadan, Z
AF Ramadan, Zahy
TI Marketing in the metaverse era: toward an integrative channel approach
SO VIRTUAL REALITY
LA English
DT Article
DE Metaverse; Omnichannel; Multichannel; Virtual reality; Platform
ID WEB 3.0; BRAND ADDICTION; CUSTOMER ENGAGEMENT; VIRTUAL WORLD; SOCIAL
   MEDIA; PERCEIVED VALUE; SPECIAL-ISSUE; 2ND LIFE; REALITY; OPPORTUNITIES
AB The development pace of digital socialization has accelerated drastically in the past decade, especially with the COVID-19 pandemic. Through that continuing digital shift, the idea of the metaverse, a virtual parallel world that can digitally replicate people's lives, is developing fast through Meta's (previously known as Facebook) announcement in October 2021 that it will dedicate sizeable investments in it. While the metaverse provides immense opportunities to brands, the primary concern will be on how integrate it with current media and retail channels, whether they are offline or online. Accordingly, using an exploratory qualitative approach, this study examined the potential strategic channel-based marketing routes that companies would face in the presence of the metaverse. The findings show that the route to market will become much more complex given the metaverse's own platform setup. Strategic multichannel and omnichannel routes are examined through a proposed framework that takes into consideration the expected evolution of the metaverse platform.
C1 [Ramadan, Zahy] Lebanese Amer Univ, POB 13-5053, Beirut 11022801, Lebanon.
C3 Lebanese American University
RP Ramadan, Z (corresponding author), Lebanese Amer Univ, POB 13-5053, Beirut 11022801, Lebanon.
EM zahy.ramadan@lau.edu.lb
RI Shamim, Nida/IXD-8527-2023; Ramadan, Zahy/O-2521-2016
OI Ramadan, Zahy/0000-0001-8368-3617
CR Abebe MA, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.025
   Abosedra Salah, 2021, J Econ Asymmetries, V24, pe00227, DOI 10.1016/j.jeca.2021.e00227
   Abu-Khzam FN, 2018, IEEE CONF COMPUT, P610, DOI 10.1109/INFCOMW.2018.8406851
   Atzori M, 2020, FUTURE GENER COMP SY, V112, P1177, DOI 10.1016/j.future.2020.07.059
   Aw ECX, 2019, INT J RETAIL DISTRIB, V47, P1074, DOI 10.1108/IJRDM-01-2019-0026
   Baker S.E., 2012, NATL CTR RES METHODS
   Barassi V, 2012, NEW MEDIA SOC, V14, P1269, DOI 10.1177/1461444812445878
   Barnes SJ, 2011, J MARKET MANAG-UK, V27, P934, DOI 10.1080/0267257X.2011.565686
   Beck N, 2015, J RETAIL CONSUM SERV, V27, P170, DOI 10.1016/j.jretconser.2015.08.001
   Belk RW, 2013, J CONSUM RES, V40, P477, DOI 10.1086/671052
   Berger M, 2016, J PRAGMATICS, V101, P83, DOI 10.1016/j.pragma.2016.05.009
   Bernhardt JM, 2012, J SOC MARKET, V2, P130, DOI 10.1108/20426761211243964
   Berthon P, 2010, J PERS SELL SALES M, V30, P195, DOI 10.2753/PSS0885-3134300301
   Boellstorff T, 2008, COMING OF AGE IN SECOND LIFE: AN ANTHROPOLOGIST EXPLORES THE VIRTUALLY HUMAN, P1
   Boyatzis R.E., 1998, TRANSFORMING QUALITA
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brown Abram., 2021, Forbes
   Chaker NN, 2022, IND MARKET MANAG, V100, P127, DOI 10.1016/j.indmarman.2021.10.006
   Choi HS, 2017, INT J INFORM MANAGE, V37, P1519, DOI 10.1016/j.ijinfomgt.2016.04.017
   Cook G., 2014, J DIRECT DATA DIGIT, V15, P262
   Loureiro SMC, 2021, J BUS RES, V134, P288, DOI 10.1016/j.jbusres.2021.05.035
   Craig A.B., 2013, UNDERSTANDING AUGMEN, DOI DOI 10.1016/B978-0-240-82408-6.00001-1
   Creswell J.W., 1998, Qualitative enquiry and research design: Choosing among five traditions
   Cruz M, 2018, P 2018 INT C COMP DA, P88
   Cui CC, 2018, J BUS RES, V87, P118, DOI 10.1016/j.jbusres.2018.02.028
   Culliford E, 2021, REUTERS         0819
   Dabbous A, 2019, TECHNOL FORECAST SOC, V149, DOI 10.1016/j.techfore.2019.119775
   De Lucia A, 2009, COMPUT EDUC, V52, P220, DOI 10.1016/j.compedu.2008.08.001
   Diehl WC, 2008, LANG INTERCULT COMM, V8, P101, DOI 10.1080/14708470802139619
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Earnshaw RaeA., 2014, VIRTUAL REALITY SYST
   Eisenbeck N, 2022, INT J CLIN HLTH PSYC, V22, DOI 10.1016/j.ijchp.2021.100256
   Farah MF, 2022, INT J CONSUM STUD, V46, P1413, DOI 10.1111/ijcs.12768
   Farah MF, 2019, J RETAIL CONSUM SERV, V48, P136, DOI 10.1016/j.jretconser.2019.02.016
   Farah MF, 2022, ADV NATL BRAND PRIVA, P142
   Gadalla E, 2013, J MARKET MANAG-UK, V29, P1493, DOI 10.1080/0267257X.2013.835742
   Gajendra Sharma, 2012, International Journal of Web Based Communities, V8, P223
   Garrigos-Simon FJ, 2012, MANAGE DECIS, V50, P1880, DOI 10.1108/00251741211279657
   Gilliland, 2021, 14 EXAMPLES AUGMENTE
   Ginzarly M, 2021, J CULT HERIT MANAG S, V11, P361, DOI 10.1108/JCHMSD-02-2020-0023
   Grabner-Kräuter S, 2009, J BUS ETHICS, V90, P505, DOI 10.1007/s10551-010-0603-1
   Guesalaga R, 2016, IND MARKET MANAG, V54, P71, DOI 10.1016/j.indmarman.2015.12.002
   Gummerus J, 2012, MANAG RES REV, V35, P857, DOI 10.1108/01409171211256578
   Hajdas M, 2022, J RETAIL CONSUM SERV, V65, DOI 10.1016/j.jretconser.2020.102131
   Hendler J, 2009, COMPUTER, V42, P111, DOI 10.1109/MC.2009.30
   Herrman J., 2021, The New York Times
   Islam T, 2021, J RETAIL CONSUM SERV, V59, DOI 10.1016/j.jretconser.2020.102357
   Itani OS, 2023, INT J RETAIL DISTRIB, V51, P238, DOI 10.1108/IJRDM-02-2022-0044
   Itani OS, 2021, IND MARKET MANAG, V98, P283, DOI 10.1016/j.indmarman.2021.09.004
   Itani OS, 2021, TOURISM MANAGE, V84, DOI 10.1016/j.tourman.2021.104290
   Itani OS, 2020, IND MARKET MANAG, V90, P264, DOI 10.1016/j.indmarman.2020.07.015
   Itani OS, 2019, INT J HOSP MANAG, V80, P78, DOI 10.1016/j.ijhm.2019.01.014
   Kaplan AM, 2009, JMM-INT J MEDIA MANA, V11, P93, DOI 10.1080/14241270903047008
   Kouatli Issam, 2020, 2020 International Conference on Decision Aid Sciences and Application (DASA), P756, DOI 10.1109/DASA51403.2020.9317097
   Kreps D, 2015, INFORM TECHNOL PEOPL, V28, P726, DOI 10.1108/ITP-09-2015-0223
   Krishnan A, 2022, TOP METAVERSE INVEST
   Lemon KN, 2016, J MARKETING, V80, P69, DOI 10.1509/jm.15.0420
   Lik-Hang LEE, 2021, FELLOW
   Lombardi J, 2010, HUM-COMPUT INT-SPRIN, P111, DOI 10.1007/978-1-84882-825-4_9
   Lorenzo-Alvarez R, 2020, ANAT SCI EDUC, V13, P602, DOI 10.1002/ase.1927
   Lythreatis S, 2022, TECHNOL FORECAST SOC, V175, DOI 10.1016/j.techfore.2021.121359
   Melero I, 2016, UNIVERSIA BUS REV, P18, DOI 10.3232/UBR.2016.V13.N2.01
   Mrad M, 2022, MARK INTELL PLAN, V40, P589, DOI 10.1108/MIP-12-2021-0423
   Mrad M, 2020, J RETAIL CONSUM SERV, V55, DOI 10.1016/j.jretconser.2020.102089
   Mrad M, 2020, J BUS RES, V113, P399, DOI 10.1016/j.jbusres.2019.09.023
   Mrad M, 2018, QUAL MARK RES, V21, P18, DOI 10.1108/QMR-06-2016-0050
   Mrad M, 2017, EUR J MARKETING, V51, P1938, DOI 10.1108/EJM-10-2016-0571
   Msaed C, 2017, J PROD BRAND MANAG, V26, P102, DOI 10.1108/JPBM-06-2015-0915
   Neslin SA, 2006, J SERV RES-US, V9, P95, DOI 10.1177/1094670506293559
   Neuman W. L., 2003, Social Research Methods: qualitative and quantitative approaches
   Newman R, 2016, INT J INFORM MANAGE, V36, P591, DOI 10.1016/j.ijinfomgt.2016.03.010
   Nieroda ME, 2018, J BUS RES, V89, P159, DOI 10.1016/j.jbusres.2018.04.024
   Nosek MA, 2019, DISABIL REHABIL, V41, P2718, DOI 10.1080/09638288.2018.1473511
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Pantano E., 2010, INT J DIGIT CONTENT, V4, P8
   Quadri-Felitti DL, 2013, TOUR HOSP RES, V13, P47, DOI 10.1177/1467358413510017
   Ramadan Z, 2016, LETS GET ENGAGED CRO, P491
   Ramadan Zahy B., 2020, International Journal of Web Based Communities, V16, P279
   Ramadan Zahy B., 2017, International Journal of Web Based Communities, V13, P262
   Ramadan Z, 2022, J FASH MARK MANAG, V26, P247, DOI 10.1108/JFMM-10-2020-0222
   Ramadan ZB, 2021, J RETAIL CONSUM SERV, V62, DOI 10.1016/j.jretconser.2021.102610
   Ramadan ZB, 2018, EUR J MARKETING, V52, P1704, DOI 10.1108/EJM-03-2017-0189
   Rangaswamy A, 2005, J INTERACT MARK, V19, P5, DOI 10.1002/dir.20037
   Rauschnabel PA, 2018, PSYCHOL MARKET, V35, P557, DOI 10.1002/mar.21106
   Romo M, 2017, ANU PSICOL, V47, P57, DOI 10.1016/j.anpsic.2017.04.003
   Sashi CM, 2012, MANAGE DECIS, V50, P253, DOI 10.1108/00251741211203551
   Schoenbachler DD, 2002, J CONSUM MARK, V19, P42, DOI 10.1108/07363760210414943
   Schroeder R, 2002, COMP SUPP COMP W SER, P1
   Sgobbi FS, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P676, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.106
   Sharma G, 2013, INFORM SYST FRONT, V15, P677, DOI 10.1007/s10796-012-9347-z
   Srivastava Kalpana, 2014, Ind Psychiatry J, V23, P83, DOI 10.4103/0972-6748.151666
   Sutcliffe C., 2022, The Drum
   Tarhini A, 2022, PAC ASIA J ASSOC INF, V14, P1, DOI 10.17705/1pais.14201
   Thackeray R, 2008, HEALTH PROMOT PRACT, V9, P338, DOI 10.1177/1524839908325335
   Thaichon P, 2022, J RETAIL CONSUM SERV, V65, DOI 10.1016/j.jretconser.2020.102311
   Toth Z, 2022, IND MARKET MANAG, V104, P226, DOI 10.1016/j.indmarman.2022.04.019
   Tredinnick L., 2018, Business Information Review, V35, P39, DOI DOI 10.1177/0266382118762257
   Tukachinsky R., 2010, AM J MEDIA PSYCHOL, V3, P73
   Verhoef PC, 2015, J RETAILING, V91, P174, DOI 10.1016/j.jretai.2015.02.005
   Walker R, 2022, ROBLOX IS ONE BIGGES
   Warmelink H, 2008, GAMES VIRTUAL WORLDS
   Winkelmann K, 2017, J CHEM EDUC, V94, P849, DOI 10.1021/acs.jchemed.6b00733
   Wirtz BW, 2010, LONG RANGE PLANN, V43, P272, DOI 10.1016/j.lrp.2010.01.005
   Yaoyuneyong G., 2016, J INTERACTIVE ADVERT, V16, P16
   Yunis M, 2018, J BUS RES, V88, P344, DOI 10.1016/j.jbusres.2017.12.030
NR 105
TC 6
Z9 6
U1 10
U2 83
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1905
EP 1918
DI 10.1007/s10055-023-00783-2
EA MAR 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000951298500001
PM 37360809
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kelly, JW
   Powell, N
   Hoover, M
   Gilbert, SB
AF Kelly, Jonathan W.
   Powell, Nicole
   Hoover, Melynda
   Gilbert, Stephen B.
TI Teleporting through virtual environments: benefits of navigational
   feedback and practice
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Locomotion interface; Teleporting; Navigation;
   Feedback; Remote data collection
ID PATH-INTEGRATION; COMBINATION; TRAVEL
AB Virtual environments (VEs) can be infinitely large, but movement of the virtual reality (VR) user is constrained by the surrounding real environment. Teleporting has become a popular locomotion interface to allow complete exploration of the VE. To teleport, the user selects the intended position (and sometimes orientation) before being instantly transported to that location. However, locomotion interfaces such as teleporting can cause disorientation. This experiment explored whether practice and feedback when using the teleporting interface can reduce disorientation. VR headset owners participated remotely. On each trial of a triangle completion task, the participant traveled along two path legs through a VE before attempting to point to the path origin. Travel was completed with one of two teleporting interfaces that differed in the availability of rotational self-motion cues. Participants in the feedback condition received feedback about their pointing accuracy. For both teleporting interfaces tested, feedback caused significant improvement in pointing performance, and practice alone caused only marginal improvement. These results suggest that disorientation in VR can be reduced through feedback-based training.
C1 [Kelly, Jonathan W.] Iowa State Univ, Dept Psychol, 1347 Lagomarcino Hall,901 Stange Rd, Ames, IA 50011 USA.
   [Powell, Nicole; Hoover, Melynda; Gilbert, Stephen B.] Iowa State Univ, Virtual Real Applicat Ctr, 1620 Howe Hall,537 Bissell Rd, Ames, IA 50011 USA.
C3 Iowa State University; Iowa State University
RP Kelly, JW (corresponding author), Iowa State Univ, Dept Psychol, 1347 Lagomarcino Hall,901 Stange Rd, Ames, IA 50011 USA.
EM jonkelly@iastate.edu; nrpowell@iastate.edu; mhoover@iastate.edu;
   gilbert@iastate.edu
RI Gilbert, Stephen/F-3138-2018; Kelly, Jonathan/A-4793-2013
OI Gilbert, Stephen/0000-0002-5332-029X; Kelly,
   Jonathan/0000-0002-4317-273X
FU National Science Foundation [CHS-1816029]
FX This material is based upon work supported by the National Science
   Foundation under Grant Number CHS-1816029.
CR Barhorst-Cates EM, 2020, EXP BRAIN RES, V238, P1911, DOI 10.1007/s00221-020-05851-6
   Bhandari J., 2018, P 44 GRAPHICS INTERF, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018.223, DOI 10.20380/GI2018.223]
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chen XL, 2017, COGNITIVE PSYCHOL, V95, P105, DOI 10.1016/j.cogpsych.2017.04.003
   Cherep LA, 2023, J EXP PSYCHOL-APPL, V29, P111, DOI 10.1037/xap0000396
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Ekwaru JP, 2018, STAT BIOPHARM RES, V10, P26, DOI 10.1080/19466315.2017.1369900
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   HART S G, 1988, P139
   Kearns MJ, 2002, PERCEPTION, V31, P349, DOI 10.1068/p3311
   Kelly J. W., 2022, Frontiers in Virtual Reality, V3, P1, DOI [10.3389/fvir.2022.882526, DOI 10.3389/FRVIR.2022.882526]
   Kelly JW, 2022, IEEE T VIS COMPUT GR, V28, P2037, DOI 10.1109/TVCG.2022.3150475
   Kelly JW, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P391, DOI 10.1109/VRW52623.2021.00082
   Kelly JW, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P687, DOI 10.1109/VR50410.2021.00095
   Kelly JW, 2020, IEEE T VIS COMPUT GR, V26, P1841, DOI 10.1109/TVCG.2020.2973051
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lim Alex F., 2020, SUI '20: Symposium on Spatial User Interaction, DOI 10.1145/3385959.3418443
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Nielsen, 2018, NIELS GAM 360 US REP
   Osborne J.W., 2008, Best Practices in Quantitative Methods, P596
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Philbeck J.W., 2013, Handbook of spatial cognition p, P99, DOI DOI 10.1037/13936-006
   Photiou M, 2021, LECT NOTES ARTIFICIA
   Popov AG, 2013, OPEN SPORTS SCI J, DOI [10.2174/18753, DOI 10.2174/18753]
   Sayyad E, 2020, INT SYM MIX AUGMENT, P608, DOI 10.1109/ISMAR50242.2020.00088
   Sjolund LA, 2018, MEM COGNITION, V46, P89, DOI 10.3758/s13421-017-0747-7
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Wang RF, 2016, PSYCHON B REV, V23, P692, DOI 10.3758/s13423-015-0952-y
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wiener J.M., 2006, Spatial Cognition and Computation, V6, P333, DOI [DOI 10.1207/S15427633SCC0604_3, 10.1207/s15427633scc06043, DOI 10.1207/S15427633SCC06043]
   Wraga M, 2004, MEM COGNITION, V32, P399, DOI 10.3758/BF03195834
NR 38
TC 0
Z9 1
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1315
EP 1326
DI 10.1007/s10055-022-00737-0
EA DEC 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000900826400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Juan, MC
   Elexpuru, J
   Dias, P
   Santos, BS
   Amorim, P
AF Juan, M-Carmen
   Elexpuru, Julen
   Dias, Paulo
   Santos, Beatriz Sousa
   Amorim, Paula
TI Immersive virtual reality for upper limb rehabilitation: comparing hand
   and controller interaction
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Virtual reality; Hand gestures; Hand tracking; Standalone
   headsets; Motor rehabilitation
ID STROKE; RECOVERY; INTERVENTION; DISEASE; GAMES
AB Virtual reality shows great potential as an alternative to traditional therapies for motor rehabilitation given its ability to immerse the user in engaging scenarios that abstract them from medical facilities and tedious rehabilitation exercises. This paper presents a virtual reality application that includes three serious games and that was developed for motor rehabilitation. It uses a standalone headset and the user's hands without the need for any controller for interaction. Interacting with an immersive virtual reality environment using only natural hand gestures involves an interaction that is similar to that of real life, which would be especially desirable for patients with motor problems. A study involving 28 participants (4 with motor problems) was carried out to compare two types of interaction (hands vs. controllers). All of the participants completed the exercises. No significant differences were found in the number of attempts necessary to complete the games using the two types of interaction. The group that used controllers required less time to complete the exercise. The performance outcomes were independent of the gender and age of the participants. The subjective assessment of the participants with motor problems was not significantly different from the rest of the participants. With regard to the interaction type, the participants mostly preferred the interaction using their hands (78.5%). All four participants with motor problems preferred the hand interaction. These results suggest that the interaction with the user's hands together with standalone headsets could improve motivation, be well accepted by motor rehabilitation patients, and help to complete exercise therapy at home.
C1 [Juan, M-Carmen; Elexpuru, Julen] Univ Politecn Valencia, Inst Univ Automat & Informat Ind, C Camino Vera S-N, Valencia 46022, Spain.
   [Dias, Paulo; Santos, Beatriz Sousa] Univ Aveiro, Dept Elect Telecommun & Informat DETI, Aveiro, Portugal.
   [Amorim, Paula] Ctr Reg Rehabil Med Ctr Rovisco Pais CMRRC RP, Tocha, Portugal.
C3 Universitat Politecnica de Valencia; Universidade de Aveiro
RP Juan, MC (corresponding author), Univ Politecn Valencia, Inst Univ Automat & Informat Ind, C Camino Vera S-N, Valencia 46022, Spain.
EM mcarmen@dsic.upv.es
RI Juan, M.-Carmen/I-3585-2015; Dias, Paulo PMD/G-3681-2013
OI Dias, Paulo PMD/0000-0002-3754-2749; Amorim, Paula/0000-0003-4908-5642;
   Juan, M.-Carmen/0000-0002-8764-1470
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Amirthalingam J, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.16763
   Amorim P, 2020, INT J TELEREHABILITA, V12, P65, DOI 10.5195/ijt.2020.6326
   Askin A, 2018, SOMATOSENS MOT RES, V35, P25, DOI 10.1080/08990220.2018.1444599
   Baños RM, 2013, SUPPORT CARE CANCER, V21, P263, DOI 10.1007/s00520-012-1520-x
   Boian RF, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P247, DOI 10.1109/HAPTIC.2003.1191289
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Calabrò RS, 2019, CLIN NEUROPHYSIOL, V130, P767, DOI 10.1016/j.clinph.2019.02.013
   Cho S, 2014, COMPUT METH PROG BIO, V113, P258, DOI 10.1016/j.cmpb.2013.09.006
   Cho S, 2016, IEEE COMPUT GRAPH, V36, P70, DOI 10.1109/MCG.2015.2
   Colombo R, 2019, IEEE T NEUR SYS REH, V27, P664, DOI 10.1109/TNSRE.2019.2905076
   Covarrubias M., 2015, Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology - VRST'15, P117, DOI [10.1145/2821592.2821619, DOI 10.1145/2821592.2821619]
   Dias P, 2019, IEEE COMPUT GRAPH, V39, P64, DOI 10.1109/MCG.2018.2875630
   Dimbwadyo-Terrer I, 2016, DISABIL REHABIL-ASSI, V11, P462, DOI 10.3109/17483107.2015.1027293
   ENJALBERT M, 1988, Annales de Readaptation et de Medecine Physique, V31, P147
   Go AS, 2013, CIRCULATION, V127, pE6, DOI 10.1161/CIR.0b013e31828124ad
   Hoeg ER, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647993
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Jonsdottir J, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.601131
   Jurkiewicz MT, 2011, TOP STROKE REHABIL, V18, P277, DOI 10.1310/tsr1803-277
   Kim Ju-Hong, 2018, J Phys Ther Sci, V30, P1408, DOI 10.1589/jpts.30.1408
   Kim WS, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103369
   Krishnamurthi RV, 2013, LANCET GLOB HEALTH, V1, pE259, DOI 10.1016/S2214-109X(13)70089-5
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lawrence ES, 2001, STROKE, V32, P1279, DOI 10.1161/01.STR.32.6.1279
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   MATHIOWETZ V, 1985, AM J OCCUP THER, V39, P386, DOI 10.5014/ajot.39.6.386
   Munoz-Montoya F, 2019, IEEE ACCESS, V7, P2453, DOI 10.1109/ACCESS.2018.2886627
   Ona E. D., 2018, 2018 IEEE 6 INT C SE, P1
   Patrício M, 2017, COMMUN STAT-SIMUL C, V46, P7535, DOI 10.1080/03610918.2016.1241410
   Patterson DR, 2010, INT J CLIN EXP HYP, V58, P288, DOI 10.1080/00207141003760595
   Piron L, 2009, J REHABIL MED, V41, P1016, DOI 10.2340/16501977-0459
   Prisco GM, 1998, IEEE INT CONF ROBOT, P3721, DOI 10.1109/ROBOT.1998.681418
   Reggente N, 2020, J COGN ENHANCE, V4, P12, DOI 10.1007/s41465-019-00141-8
   Rodriguez-Andres D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00451
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Ballester BR, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.6773
   Schneider SM, 2007, ONCOL NURS FORUM, V34, P39, DOI 10.1188/07.ONF.39-46
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Takeo Y, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00903-6
   Wang ZR, 2017, NEURAL REGEN RES, V12, P1823, DOI 10.4103/1673-5374.219043
   Wen X, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2412, DOI 10.1109/WCICA.2014.7053099
   Zhejun Liu, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P512, DOI 10.1007/978-3-319-39907-2_49
NR 43
TC 11
Z9 12
U1 4
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1157
EP 1171
DI 10.1007/s10055-022-00722-7
EA DEC 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000893050900001
PM 36475065
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Laera, F
   Manghisi, VM
   Evangelista, A
   Uva, AE
   Foglia, MM
   Fiorentino, M
AF Laera, Francesco
   Manghisi, Vito Modesto
   Evangelista, Alessandro
   Uva, Antonio Emmanuele
   Foglia, Mario Massimo
   Fiorentino, Michele
TI Evaluating an augmented reality interface for sailing navigation: a
   comparative study with a immersive virtual reality simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Sailing; Nautical; Human-computer interaction;
   Cognitive load; User study
ID DATA VISUALIZATION; COGNITIVE LOAD; ISSUES
AB Sailing navigation is an activity that requires acquiring and processing information from the surrounding environment. The advancement of technology has enabled sailboats to have an increasing number of onboard sensors that make sailing more user-friendly. However, data provided by these sensors are still visualized on 2D digital displays that imitate traditional analog interfaces. Although these displays are strategically placed on the sailboat, the user needs to divert attention from the primary navigation task to look at them, thus spending a significant amount of cognitive resources. AR-based technologies have the potential to overcome these limitations by displaying information registered in the real environment, but there are no studies in the literature for validating the effectiveness of this technology in the field of sailing. Thus, we designed a head-mounted display AR-based interface to assist users in monitoring wind data to avoid user diversion from the primary task of sailing. We conducted a user study involving 45 participants in an Immersive Virtual Reality simulated environment. We collected objective and subjective measures to compare the AR-based interface with a traditional data visualization system. The AR-based interface outperformed the traditional data visualization system regarding reaction time, cognitive load, system usability, and user experience.
C1 [Laera, Francesco; Manghisi, Vito Modesto; Evangelista, Alessandro; Uva, Antonio Emmanuele; Foglia, Mario Massimo; Fiorentino, Michele] Polytech Univ Bari, Dept Mech Math & Management, Via Orabona 4, Bari, Italy.
C3 Politecnico di Bari
RP Evangelista, A (corresponding author), Polytech Univ Bari, Dept Mech Math & Management, Via Orabona 4, Bari, Italy.
EM alessandro.evangelista@poliba.it
RI Uva, Antonio Emmanuele/A-9673-2012
OI Uva, Antonio Emmanuele/0000-0001-7271-6137; Evangelista,
   Alessandro/0000-0003-2045-1768; Laera, Francesco/0000-0001-5244-5405
FU Politecnico di Bari within the CRUI-CARE Agreement; Italian Ministry of
   Education, University and Research [C-D94I18000260001]
FX Open access funding provided by Politecnico di Bari within the CRUI-CARE
   Agreement. This work was supported by the Italian Ministry of Education,
   University and Research under the Programmes "Department of Excellence,"
   Legge 232/2016 (Grant No. C-D94I18000260001).
CR Anderson B, 2008, PHYS TODAY, V61, P38, DOI 10.1063/1.2883908
   Bai L, 2019, J PHYS CONF SER, V1215, DOI 10.1088/1742-6596/1215/1/012032
   Bernard ML, 2003, INT J HUM-COMPUT ST, V59, P823, DOI 10.1016/S1071-5819(03)00121-6
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Butkiewicz T, 2017, OCEANS-IEEE
   Byers J.C, 1989, Advances in Industrial Ergonomics and Safety (1), V3, P22
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   Expedition, 2021, EXP NAV SAIL SOFTW
   Fiorentino M, 2021, MAR TECHNOL SOC J, V55, P64
   GATEHOUSE RN, 1970, J INST NAVIG, V23, P60, DOI 10.1017/S0373463300030575
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Irby GL., 2016, COMPANION SCI TECHNO, DOI [10.1002/9781118373057, DOI 10.1002/9781118373057]
   Jose R, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010918
   Kirschner PA, 2002, LEARN INSTR, V12, P1, DOI 10.1016/S0959-4752(01)00014-7
   Kirwan R., 1810, T R IRISH ACAD, V11, P61
   Laera F, 2020, Augmented Reality for Easy Sailing
   Laera F, 2021, INT SYM MIX AUGMENT, P260, DOI 10.1109/ISMAR-Adjunct54149.2021.00060
   Laera F, 2021, J NAVIGATION, V74, P1073, DOI 10.1017/S0373463321000412
   Laera F, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P269, DOI 10.1109/ISMAR-Adjunct51615.2020.00076
   Lee C, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P77, DOI 10.1109/VR.2012.6180890
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P577, DOI 10.1080/10447318.2018.1455307
   Morgére JC, 2014, OCEANS-IEEE
   Morgère JC, 2014, 2014 12TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (EUC 2014), P287, DOI 10.1109/EUC.2014.49
   MORONEY WF, 1992, PROC NAECON IEEE NAT, P734, DOI 10.1109/NAECON.1992.220513
   Perondi L., 2017, MD J, V3, P88
   Rasch D, 2011, STAT PAP, V52, P219, DOI 10.1007/s00362-009-0224-x
   Robertson C, 2011, US
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   SWELLER J, 1990, J EXP PSYCHOL GEN, V119, P176, DOI 10.1037/0096-3445.119.2.176
   Uva AE, 2018, INT J ADV MANUF TECH, V94, P509, DOI 10.1007/s00170-017-0846-4
   Uva AE, 2019, IEEE T HUM-MACH SYST, V49, P421, DOI 10.1109/THMS.2019.2919719
   Wisernig E, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P61, DOI 10.1109/CW.2015.74
   Xiong DQ, 2016, LECT NOTES ELECTR EN, V406, P389, DOI 10.1007/978-981-10-2323-1_44
   Xu Manfei, 2017, Shanghai Arch Psychiatry, V29, P184, DOI 10.11919/j.issn.1002-0829.217070
NR 36
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 929
EP 940
DI 10.1007/s10055-022-00706-7
EA OCT 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000864051600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Hammady, R
   Ma, MH
   AL-Kalha, Z
   Strathearn, C
AF Hammady, Ramy
   Ma, Minhua
   AL-Kalha, Ziad
   Strathearn, Carl
TI A framework for constructing and evaluating the role of MR as a
   holographic virtual guide in museums
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Virtual guide; Museums; Holographic system; Microsoft
   HoloLens
ID TECHNOLOGY ACCEPTANCE MODEL; AUGMENTED REALITY; MIXED REALITY;
   TOUR-GUIDE; EXPERIENCES; INTENTION; ENJOYMENT; VISITORS
AB Mixed reality (MR) is a cutting-edge technology at the forefront of many new applications in the tourism and cultural heritage sector. This study aims to reshape the museum experience by creating a highly engaging and immersive museum experience for visitors combing real-time visual, audio information and computer-generated images with museum artefacts and customer displays. This research introduces a theoretical framework that assesses the potential of MR guidance system in usefulness, ease of use, enjoyment, interactivity, touring and future applications. The evaluation introduces the MuseumEye MR application in the Egyptian Museum, Cairo using mixed method surveys and a sample of 171 participants. The results of the questionnaire highlighted the importance of the mediating the role of the tour guide in enhancing the relationship between perceived usefulness, ease of use, multimedia, UI design, interactivity and the intention of use. Furthermore, the results of this study revealed the potential future use of MR in museums and ensured sustainability and engagement past the traditional visitor museum experience, which heightens the economic state of museums and cultural heritage sectors.
C1 [Hammady, Ramy] Solent Univ, E Pk Terrace, Southampton SO14 0YN, Hants, England.
   [Hammady, Ramy] Helwan Univ, Helwan, Cairo Governora, Egypt.
   [Ma, Minhua] Falmouth Univ, Penryn Campus,Treliever Rd, Penryn TR10 9FE, Egypt.
   [AL-Kalha, Ziad] Univ Jordan, Sch Business, Queen Rania St, Amman, Jordan.
   [Strathearn, Carl] Edinburgh Napier Univ, Unit 4,10 Bankhead Terrace, Edinburgh EH11 4DY, Midlothian, Scotland.
C3 Egyptian Knowledge Bank (EKB); Helwan University; University of Jordan;
   Edinburgh Napier University
RP Hammady, R (corresponding author), Solent Univ, E Pk Terrace, Southampton SO14 0YN, Hants, England.; Hammady, R (corresponding author), Helwan Univ, Helwan, Cairo Governora, Egypt.
EM Ramy.Hammady@solent.ac.uk; m.ma@falmouth.ac.uk; Z.kalha@ju.edu.jo;
   C.strathearn@napier.ac.uk
RI Strathearn, Carl/CAA-2747-2022; AlKalha, Ziad/AAW-1795-2021
OI AlKalha, Ziad/0000-0001-8321-3252; HAMMADY, Ramy/0000-0003-4764-6039;
   Ma, Minhua/0000-0001-7451-546X
FU Newton-Mosharafa scholarship
FX This project was funded by Newton-Mosharafa scholarship which was
   managed by the British council in Egypt.
CR Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI 10.1007/978-3-642-69746-3_2
   Albrecht UV, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2497
   Alizadehsalehi Sepehr, 2019, AEI 2019 Integrated Building SolutionsThe National Agenda, P193
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   Allison C, 2018, ASUS MIXED REALITY H
   ALMAGOR U, 1985, ANN TOURISM RES, V12, P31, DOI 10.1016/0160-7383(85)90038-6
   [Anonymous], 2015, Microsoft HoloLens
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], 1994, The Educational Role of the Museum
   [Anonymous], 2000, Dare 2000, DOI DOI 10.1145/354666.354667
   Antlej K, 2018, 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM 2018), P128
   Antón C, 2018, CURR ISSUES TOUR, V21, P1406, DOI 10.1080/13683500.2017.1373753
   Antoniou Angeliki, 2019, Games and Learning Alliance. 8th International Conference (GALA 2019). Proceedings. Lecture Notes in Computer Science (LNCS 11899), P342, DOI 10.1007/978-3-030-34350-7_33
   Ardito C, 2018, INT J HUM-COMPUT ST, V114, P51, DOI 10.1016/j.ijhcs.2017.12.002
   Atkinson T, 2018, PRODUCT REV DELL VIS
   Avramova V, 2017, INT C INT VIRT AG
   Ayeh J.K., 2013, Information and Communication Technologies in Tourism 2013, P254, DOI [https://doi.org/10.1007/978-3-642-36309-2_22, DOI 10.1007/978-3-642-36309-2_22]
   Balog A, 2010, STUD INFORM CONTROL, V19, P319
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Bellotti F., 2002, IEEE Pervasive Computing, V1, P33, DOI 10.1109/MPRV.2002.1012335
   Best K, 2012, MUS MANAGE CURATOR, V27, P35, DOI 10.1080/09647775.2012.644695
   Boland P., 1996, IMAGE PAST ELECT IMA, V114, P227
   Bray MZB, 2018, WHAT IS MIXED REALIT
   Bruha L, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9100604
   Burgard W, 1999, ARTIF INTELL-AMST, V114, P3, DOI 10.1016/S0004-3702(99)00070-3
   Cameron D.F., 1968, CURATOR, V11, P33, DOI DOI 10.1111/J.2151-6952.1968.TB00883.X
   Cantatore E, 2020, INT ARCH PHOTOGRAMM, V44, P465, DOI [10.5194/isprs-archives-XLIV-M-1-2020-465-2020, DOI 10.5194/ISPRS-ARCHIVES-XLIV-M-1-2020-465-2020]
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Cho V, 2009, COMPUT EDUC, V53, P216, DOI 10.1016/j.compedu.2009.01.014
   Choi H-S, 2014, INT J SMART HOME, V8, P217, DOI DOI 10.14257/IJSH.2014.8.1.23
   Chung N, 2015, COMPUT HUM BEHAV, V50, P588, DOI 10.1016/j.chb.2015.02.068
   Claudy MC, 2016, J PROD INNOVAT MANAG, V33, P72, DOI 10.1111/jpim.12343
   Clini P, 2017, HDB RES EMERGING TEC, P201, DOI DOI 10.4018/978-1-5225-0680-5
   COHEN E, 1985, ANN TOURISM RES, V12, P5, DOI 10.1016/0160-7383(85)90037-4
   Comrey A. L., 1992, A first course in factor analysis, DOI DOI 10.4324/9781315827506-16
   Cortana J, 2017, FUTURE HOLOGRAMS MUS
   Costello AB, 2005, Practical Assessment, Research, & Evaluation, V10, P1, DOI DOI 10.7275/JYJ1-4868
   Craig A.B., 2013, AUGMENTED REALITY CO, DOI [10.1016/B978-0-240-82408-6.00002-3, DOI 10.1016/B978-0-240-82408-6.00002-3]
   Cultnat, 2016, PART EG MUS CEL ITS
   Damala A, 2012, INT SYM MIX AUGMENT
   Davis F D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x
   Dean D., 2002, Museum exhibition: Theory and practice, DOI [10.4324/9780203039366, DOI 10.4324/9780203039366]
   Doering Z.D., 1996, J MUS EDUC, V23, P20, DOI DOI 10.1080/10598650.1996.11510333
   Ducey AJ, 2016, HEALTH POLICY TECHN, V5, P268, DOI 10.1016/j.hlpt.2016.03.010
   Duffy C, 1989, MUS ED ASS AUS UNPUB
   Falk JH, 2013, MUSEUM EXPERIENCE REVISITED, P1
   Fenu C, 2018, INT J HUM-COMPUT ST, V114, P20, DOI 10.1016/j.ijhcs.2018.01.009
   Fevgas A, 2014, IISA 2014 5 INT C IN
   FINE EC, 1985, ANN TOURISM RES, V12, P73, DOI 10.1016/0160-7383(85)90040-4
   Fishbein Martin., 1975, Attitude, Intention and Behavior: An Introduction to Theory and Research
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Goode L, 2019, MICROSOFTS HOLOLENS
   Goodwin C, 2007, DISCOURSE SOC, V18, P53, DOI 10.1177/0957926507069457
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Gorman P J, 2000, Comput Aided Surg, V5, P120, DOI 10.1002/1097-0150(2000)5:2<120::AID-IGS6>3.0.CO;2-L
   Gorsuch R.L., 1983, FACTOR ANAL
   Guerra JP, 2015, EUROPEAN SCI J, V11, P49, DOI DOI 10.19044/ESJ.2015.V11N9P%25P
   Hain V, 2019, INTECHOPEN, DOI [10.5772/intechopen.90679, DOI 10.5772/INTECHOPEN.90679]
   Hair JF, 2010, Multivariate data analysis
   Hammady R, 2019, VIRTUAL GUIDANCE USI
   Haugstvedt AC, 2012, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2012.6402563
   Hayes, 2012, PROCESS VERSATILE CO
   Hayes A, 2013, SERIES EDITORS NOTES
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   Hayes AF, 2017, AUSTRALAS MARK J, V25, P76, DOI 10.1016/j.ausmj.2017.02.001
   HODGE R, 1979, MUSEUM, V31, P251, DOI 10.1111/j.1468-0033.1979.tb01899.x
   Holloway J. C., 1981, Annals of Tourism Research, V8, P377, DOI 10.1016/0160-7383(81)90005-0
   Hong JC, 2011, COMPUT EDUC, V57, P2086, DOI 10.1016/j.compedu.2011.04.011
   Hooper-Greenhill Eilean., 1994, Museums and Their Visitors, DOI DOI 10.4324/9780203415160
   Horn A., 1980, CURATOR, V23, P105, DOI [10.1111/j.2151-6952.1980.tb00558.x, DOI 10.1111/J.2151-6952.1980.TB00558.X]
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Hughes CE, 2004, P KSCE 2004
   HUGHES K, 1991, AUST PSYCHOL, V26, P166, DOI 10.1080/00050069108257243
   Hurter C., 2017, ACM siggraph 2017 emerging technologies, P1
   Ingleby, 2016, ARXIV161004281
   Ioannidis, 2012, 40 ANN C COMP APPL Q
   Jan D, 2009, INT WORKSH INT VIRT
   Joachims T, 1997, INT JOINT CONF ARTIF, P770
   John B, 2020, HEALTHC DELIV INFORM, P375, DOI 10.1007/978-3-030-17347-0_18
   Jung Timothy., 2016, INFORM COMMUNICATION, P621, DOI [DOI 10.1007/978-3-319-28231-2_45, 10.1007/978-3-319-28231-245, DOI 10.1007/978-3-319-28231-245]
   Karoulis A, 2006, INFORMATICA-LITHUAN, V17, P363
   Kateros S., 2015, INT J HERITAGE DIGIT, V4, P221, DOI DOI 10.1260/2047-4970.4.2.221
   Keil J., 2013, Digital Heritage International Congress (Digital Heritage). IEEE, V2, P685, DOI [10.1109/DigitalHeritage.2013.6744836, DOI 10.1109/DIGITALHERITAGE.2013.6744836]
   Kim S, 2020, TOUR MANAG PERSPECT, V36, DOI 10.1016/j.tmp.2020.100749
   Knez E., 1970, CURATOR, V13, P204, DOI DOI 10.1111/J.2151-6952.1970.TB00404.X
   Koenig-Lewis N, 2015, SERV IND J, V35, P537, DOI 10.1080/02642069.2015.1043278
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kress Bernard C., 2017, SID Symposium Digest of Technical Papers, V48, P127, DOI 10.1002/sdtp.11586
   Lanir J, 2013, INTERACT COMPUT, V25, P443, DOI 10.1093/iwc/iwt002
   Lee H., 2015, Information and communication technologies in tourism 2015, P477, DOI [DOI 10.1007/978-3-319-14343-9_35, 10.1007/978-3-319-14343-9_35, DOI 10.1007/978-3-319-14343-935]
   Lee H, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103229
   Lee KC, 2017, IOP CONF SER-MAT SCI, V223, DOI 10.1088/1757-899X/223/1/012017
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI DOI 10.1007/S10055-004-0141-1
   Leue M, 2014, e-Review of Tourism Res., V5, P1
   Liarokapis F, 2008, VAST
   Liu IF, 2010, COMPUT EDUC, V54, P600, DOI 10.1016/j.compedu.2009.09.009
   Loizides F, 2014, LECT NOTES COMPUT SC, V8740, P572, DOI 10.1007/978-3-319-13695-0_57
   Luarn P, 2005, COMPUT HUM BEHAV, V21, P873, DOI 10.1016/j.chb.2004.03.003
   Madsen JB, 2016, ACM J COMPUT CULT HE, V9, DOI 10.1145/2822899
   Mancini M, 2000, CONDUCTING TOURS PRA
   Marchal, 2008, P 3 INT C DIG INT ME
   Microsoft, 2019, HOL 2 NEW VIS COMP
   Mihelj M, 2014, INTEL SYST CONTR AUT, V68, P1, DOI 10.1007/978-94-007-6910-6
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miyashita T, 2008, 7 IEEE ACM INT S MIX
   Munodawafa D, 2008, HEALTH EDUC RES, V23, P369, DOI 10.1093/her/cyn024
   Munoz A, 2020, COMMUNICATING DIGITA
   Pietroszek K, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811547
   Pletinckx D, 2005, VAST
   Pollalis C, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P565, DOI 10.1145/3024969.3025094
   Pollefeys M, 2017, 2 VERSION HOLOLENS H
   Pond K.L., 1993, PROFESSIONAL GUIDE D
   Prasuethsut L, 2016, META 2 1 IMPRESSIONS
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Pujol L, 2004, REV DIGITAL HUMANIDA
   Rahimian FP, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103012
   Raptis GE, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P343, DOI 10.1145/3099023.3099090
   Raptis GE, 2018, INT J HUM-COMPUT ST, V114, P69, DOI 10.1016/j.ijhcs.2018.02.003
   Rauschnabel Philipp A., 2016, International Journal of Technology Marketing, V11, P123
   Rift O, 2020, OCULUS RIFT
   Rosentraub MS, 2009, TOURISM MANAGE, V30, P759, DOI 10.1016/j.tourman.2008.11.014
   Roussou M, 2013, CHI 13 HUM FACT COMP
   Rubino I, 2013, SENSORS-BASEL, V13, P17445, DOI 10.3390/s131217445
   Ryffel M, 2017, ACM T GRAPHIC, V36, P19
   Rzayev R, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3344395
   Sampaio AZ, 2014, AUTOMAT CONSTR, V37, P58, DOI 10.1016/j.autcon.2013.10.015
   Schaper MM, 2018, INT J HUM-COMPUT ST, V114, P36, DOI 10.1016/j.ijhcs.2018.01.003
   Serubugo S, 2017, VISIGRAPP 1 GRAPP
   Shang DW, 2017, IND MANAGE DATA SYST, V117, P213, DOI 10.1108/IMDS-02-2016-0052
   Shneiderman B., 2010, DESIGNING USER INTER
   Siebert JN, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7379
   Sparacino F, 2002, P MUS WEB MW2002
   Sugiura A, 2019, ANAT SCI EDUC, V12, P561, DOI 10.1002/ase.1822
   Sylaiou Stella, 2019, Augmented Reality, Virtual Reality, and Computer Graphics. 6th International Conference, AVR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11614), P230, DOI 10.1007/978-3-030-25999-0_20
   Sylaiou S, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P595, DOI 10.1109/IS.2018.8710530
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Teo T.S.H., 1997, EQUAL OPPOR INT, V16, P1, DOI DOI 10.1108/EB010696
   TOMDIECK MC, 2016, J HOSP TOUR MANAG, V7, P230
   Trunfio M, 2020, CURR ISSUES TOUR, V23, P1990, DOI 10.1080/13683500.2019.1703914
   Van Hage WR, 2010, EXT SEM WEB C
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Vlahakis Vassilios., 2001, VIRTUAL REALITY ARCH, V9, P584993
   Vo MLH, 2019, CURR OPIN PSYCHOL, V29, P205, DOI 10.1016/j.copsyc.2019.03.009
   Wagner D, 2007, ANDHELD AUGMENTED RE
   Wagner D, 2007, 6 IEEE ACM INT S MIX
   Wang N, 2019, INT J HOSP MANAG, V77, P292, DOI 10.1016/j.ijhm.2018.07.009
   Warren JSA, 2018, CANCERS, V10, DOI 10.3390/cancers10040115
   Weeks M, 2002, J APPL ECONOMET, V17, P191, DOI 10.1002/jae.665
   Weiler B., 2015, TOUR GUIDING RES INS
   Weng E., 2011, International Journal of Computer Science and Information Security, V9, P174
   Wojciechowski R, 2013, COMPUT EDUC, V68, P570, DOI 10.1016/j.compedu.2013.02.014
   Xu Y, 2012, P 6 ACM INT C DISTR
   Yalowitz SS, 2009, VISIT STUD, V12, P47, DOI 10.1080/10645570902769134
   Yilmaz RM, 2016, COMPUT HUM BEHAV, V54, P240, DOI 10.1016/j.chb.2015.07.040
   Yusoff Rasimah Che Mohd, 2011, Australasian Journal of Educational Technology, V27, P1369
   Zhang HQ, 2004, TOURISM MANAGE, V25, P81, DOI 10.1016/S0261-5177(03)00064-5
   Zuk T, 2005, VAST
NR 160
TC 21
Z9 22
U1 22
U2 136
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 895
EP 918
DI 10.1007/s10055-020-00497-9
EA JAN 2021
PG 24
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000605101200003
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Liang, CJ
   Start, C
   Boley, H
   Kamat, VR
   Menassa, CC
   Aebersold, M
AF Liang, Ci-Jyun
   Start, Charles
   Boley, Hanna
   Kamat, Vineet R.
   Menassa, Carol C.
   Aebersold, Michelle
TI Enhancing stroke assessment simulation experience in clinical training
   using augmented reality
SO VIRTUAL REALITY
LA English
DT Article
DE Clinical training; Stroke simulation; FAST stroke assessment; Augmented
   reality
ID ACUTE ISCHEMIC-STROKE; MIXED REALITY; VIRTUAL SIMULATION; HEALTH-CARE;
   EDUCATION; VISUALIZATION; REGISTRATION; MANAGEMENT; KNOWLEDGE; SYSTEM
AB The development of extended reality in recent years is opening doors for using extended reality devices (virtual reality, augmented, and mixed reality devices) in education and healthcare. The purpose of this pilot study was to test the use of augmented reality in teaching healthcare practitioners in a stroke assessment simulation designed for clinical training, where students at nursing school are targets in the study. To conduct our feasibility, a simulation application was developed for the mixed reality device that projects a human face displaying facial drooping (a symptom of stroke) onto a computerized training mannequin. Nursing students were then placed in a clinical simulation wherein they wore the mixed reality device and performed an assessment of their mannequin patient to identify the symptom of stroke and act accordingly. The students completed a survey following their simulations, and then provided feedback on the device and the quality of their experience. The results of the study show that most students enjoyed the simulation and felt that extended reality would be a very useful educational tool for clinical training and healthcare. Further development of the program and device is underway, and future tests will be conducted. The results from this study will be helpful in further progressing the development of extended reality, and the use of these devices in healthcare training.
C1 [Liang, Ci-Jyun; Kamat, Vineet R.; Menassa, Carol C.] Univ Michigan, Dept Civil & Environm Engn, 2350 Hayward St,2340 GG Brown Bldg, Ann Arbor, MI 48109 USA.
   [Start, Charles] Univ Michigan, Sch Kinesiol, 1402 Washington Hts, Ann Arbor, MI 48109 USA.
   [Boley, Hanna] Univ Michigan, Sch Nursing, 400 N Ingalls St, Ann Arbor, MI 48109 USA.
   [Aebersold, Michelle] Univ Michigan, Sch Nursing, 426 North Ingalls Bldg, Ann Arbor, MI 48109 USA.
C3 University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan
RP Liang, CJ (corresponding author), Univ Michigan, Dept Civil & Environm Engn, 2350 Hayward St,2340 GG Brown Bldg, Ann Arbor, MI 48109 USA.
EM cjliang@umich.edu
RI Liang, Ci-Jyun/GVS-4561-2022; /AAR-1995-2021; Liang,
   Ci-Jyun/AAW-4052-2021
OI Liang, Ci-Jyun/0000-0002-0213-8471; Liang, Ci-Jyun/0000-0002-0213-8471;
   Kamat, Vineet/0000-0003-0788-5588; Aebersold,
   Michelle/0000-0001-8109-5643
CR Aebersold M., 2012, CLIN SIMUL NURS, V8, pe469, DOI DOI 10.1016/J.ECNS.2011.05.002
   Aebersold M., 2018, ONLINE J ISSUES NURS, V23, P1, DOI [10.3912/OJIN.Vol23No02PPT39, DOI 10.3912/OJIN.VOL23NO02PPT39]
   Aebersold M, 2018, CLIN SIMUL NURS, V15, P34, DOI 10.1016/j.ecns.2017.09.008
   Aebersold M, 2015, JMIR SERIOUS GAMES, V3, DOI 10.2196/games.4293
   Aebersold M, 2011, J NEUROSCI NURS, V43, P349, DOI 10.1097/JNN.0b013e318234e9ca
   Aebersold M, 2011, WESTERN J NURS RES, V33, P296, DOI 10.1177/0193945910379791
   Akaike M, 2012, J MED INVESTIG, V59, P28, DOI 10.2152/jmi.59.28
   Akula M, 2013, AUTOMAT CONSTR, V36, P1, DOI 10.1016/j.autcon.2013.08.010
   American Heart Association, 2018, STROK WARN SIGNS SYM
   [Anonymous], 2018, ARXIV180408386CS
   [Anonymous], 2012, P CONSTR RES C CRC A
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Balian S, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02205
   Behzadan A. H., 2012, 12 INT C CONSTR APPL, P292
   Behzadan A.H., 2006, P 11 JOINT INT C COM, P1135
   Behzadan AH, 2015, ADV ENG INFORM, V29, P252, DOI 10.1016/j.aei.2015.03.005
   Behzadan AH, 2011, WINT SIMUL C PROC, P3568, DOI 10.1109/WSC.2011.6148051
   Behzadan AH, 2011, J INF TECHNOL CONSTR, V16, P259
   Behzadan AmirH., 2009, CONSTRUCTION RES C 2, P1214, DOI DOI 10.1061/41020(339)123
   Benjamin EJ, 2017, CIRCULATION, V135, pE146, DOI [10.1161/CIR.0000000000000485, 10.1161/CIR.0000000000000558, 10.1161/CIR.0000000000000530]
   Bunch ME, 2012, J STROKE CEREBROVASC, V21, P808, DOI 10.1016/j.jstrokecerebrovasdis.2011.04.012
   Cavallini A, 2003, STROKE, V34, P2599, DOI 10.1161/01.STR.0000094423.34841.BB
   Caylor S, 2015, CLIN SIMUL NURS, V11, P163, DOI 10.1016/j.ecns.2014.12.003
   Chalhoub J, 2018, AUTOMAT CONSTR, V86, P1, DOI 10.1016/j.autcon.2017.10.028
   Chang A, 2018, STROKE, V49, P1521, DOI 10.1161/STROKEAHA.118.021398
   Cooper JB, 2008, POSTGRAD MED J, V84, P563, DOI 10.1136/qshc.2004.009886
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Freitas S, 2009, COMPUT EDUC, V52, P343, DOI 10.1016/j.compedu.2008.09.010
   de Ribaupierre S., 2014, VIRTUAL, P9, DOI DOI 10.1007/978-3-642-54816-1_2
   Dev Parvati, 2008, Virtual Reality, V12, P215, DOI 10.1007/s10055-008-0099-5
   Dong SY, 2013, ADV ENG SOFTW, V55, P45, DOI 10.1016/j.advengsoft.2012.09.001
   Dulli D, 2007, NEUROEPIDEMIOLOGY, V28, P86, DOI 10.1159/000098551
   Dunston PS, 2011, INTEL SYST CONTR AUT, V48, P167, DOI 10.1007/978-94-007-0605-7_15
   Fast-Berglund Å, 2018, PROCEDIA MANUF, V25, P31, DOI 10.1016/j.promfg.2018.06.054
   Feng C, 2013, COMPUT-AIDED CIV INF, V28, P325, DOI 10.1111/j.1467-8667.2012.00795.x
   Freeland TR, 2016, DYSPHAGIA, V31, P104, DOI 10.1007/s00455-015-9666-6
   Fussman C, 2010, STROKE, V41, P1501, DOI 10.1161/STROKEAHA.110.578195
   Harbison J, 2003, STROKE, V34, P71, DOI 10.1161/01.STR.0000044170.46643.5E
   Harrington CM, 2018, AM J SURG, V215, P42, DOI 10.1016/j.amjsurg.2017.02.011
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   HTC, 2019, VIVE TM DISC VIRT RE
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Hung WH, 2016, AUTOMAT CONSTR, V62, P1, DOI 10.1016/j.autcon.2015.10.008
   Jauch EC, 2013, STROKE, V44, P870, DOI 10.1161/STR.0b013e318284056a
   Kamat VR, 2006, LECT NOTES ARTIF INT, V4200, P368
   Kawulich BB, 2019, VIRTUAL REAL-LONDON, V23, P375, DOI 10.1007/s10055-018-0353-4
   Kim JS, 2015, P INT CONF INTELL, P132, DOI 10.1109/ISMS.2015.25
   Kobayashi L, 2018, WEST J EMERG MED, V19, P158, DOI 10.5811/westjem.2017.10.35026
   Köhrmann M, 2011, INT J STROKE, V6, P493, DOI 10.1111/j.1747-4949.2011.00585.x
   Laerdal Medical, 2019, SIMMAN 3G
   Tran L, 2022, CHRONIC ILLN, V18, P119, DOI 10.1177/1742395320905650
   Liang C.-J., 2018, P INT S AUT ROB CONS, P859, DOI [DOI 10.22260/ISARC2018/0120, 10.22260/ISARC2018/0120]
   Liang CJ, 2019, AUTOMAT CONSTR, V104, P80, DOI 10.1016/j.autcon.2019.04.004
   Liang CJ, 2018, CONSTRUCTION RESEARCH CONGRESS 2018: CONSTRUCTION INFORMATION TECHNOLOGY, P64
   Linden Lab, 2018, 2 LIF VIRT WORLDS VI
   Matsumoto K, 2019, IEEE ENG MED BIO, P7049, DOI [10.1109/EMBC.2019.8856821, 10.1109/embc.2019.8856821]
   Microsoft, 2020, MICR HOL MIX REAL TE
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Moskowitz MA, 2010, NEURON, V67, P181, DOI 10.1016/j.neuron.2010.07.002
   Oculus, 2020, OCULUS RIFT
   Olson E, 2011, IEEE INT CONF ROBOT
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Rochlen LR, 2017, SIMUL HEALTHC, V12, P57, DOI 10.1097/SIH.0000000000000185
   Roots Angela, 2011, Br J Nurs, V20, P1352
   Roquer J, 2008, J NEUROL, V255, P1012, DOI 10.1007/s00415-008-0820-z
   Saposnik G, 2009, STROKE, V40, P3321, DOI 10.1161/STROKEAHA.109.554907
   Schwamm LH, 2004, ACAD EMERG MED, V11, P1193, DOI 10.1197/j.aem.2004.08.014
   Shirer M, 2018, IDC PREMIER GLOBAL M
   Singular Inversions, 2019, FACEGEN 3D HUM FAC
   Talmaki S, 2014, J COMPUT CIVIL ENG, V28, DOI 10.1061/(ASCE)CP.1943-5487.0000269
   Teng C.-C., 2018, P 2 INT C MED HLTH I, P143
   Teng C C., 2019, Proceedings of the 3rd International Conference on Medical and Health Informatics. ICMHI'19. Association for Computing Machinery, P49, DOI DOI 10.1145/3340037.3340050
   Weiner E, 2010, STUD HEALTH TECHNOL, V160, P615, DOI 10.3233/978-1-60750-588-4-615
   Wu TH, 2019, UNIVERSAL ACCESS INF, V18, P243, DOI 10.1007/s10209-017-0594-0
   Wüller H, 2019, BMC NURS, V18, DOI 10.1186/s12912-019-0342-2
   Yamal JM, 2018, INT J STROKE, V13, P321, DOI 10.1177/1747493017711950
   Yang SJ, 2019, J STROKE CEREBROVASC, V28, DOI 10.1016/j.jstrokecerebrovasdis.2019.104398
   Yoon SS, 2001, STROKE, V32, P1926, DOI 10.1161/01.STR.32.8.1926
   You S, 2018, AUTOMAT CONSTR, V96, P161, DOI 10.1016/j.autcon.2018.09.008
   Zhu EG, 2014, PEERJ, V2, DOI 10.7717/peerj.469
NR 82
TC 21
Z9 24
U1 12
U2 63
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 575
EP 584
DI 10.1007/s10055-020-00475-1
EA OCT 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000578410800002
DA 2024-07-18
ER

PT J
AU Fanini, B
   Cinque, L
AF Fanini, Bruno
   Cinque, Luigi
TI Encoding immersive sessions for online, interactive VR analytics
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Immersive analytics; Session encoding; Data
   quantization; WebVR; WebXR
AB Capturing and recording immersive VR sessions performed through HMDs in explorative virtual environments may offer valuable insights on users' behavior, scene saliency and spatial affordances. Collected data can support effort prioritization in 3D modeling workflow or allow fine-tuning of locomotion models for time-constrained experiences. The web with its recent specifications (WebVR/WebXR) represents a valid solution to enable accessible, interactive and usable tools for remote VR analysis of recorded sessions. Performing immersive analytics through common browsers however presents different challenges, including limited rendering capabilities. Furthermore, interactive inspection of large session records is often problematic due to network bandwidth or may involve computationally intensive encoding/decoding routines. This work proposes, formalizes and investigates flexible dynamic models to volumetrically capture user states and scene saliency during running VR sessions using compact approaches. We investigate image-based encoding techniques and layouts targeting interactive and immersive WebVR remote inspection. We performed several experiments to validate and assess proposed encoding models applied to existing records and within networked scenarios through direct server-side encoding, using limited storage and computational resources.
C1 [Fanini, Bruno] CNR ISPC ITABC, Rome, Italy.
   [Fanini, Bruno; Cinque, Luigi] Sapienza Univ, Dept Comp Sci, Rome, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienze del
   Patrimonio Culturale (ISPC-CNR); Sapienza University Rome
RP Fanini, B (corresponding author), CNR ISPC ITABC, Rome, Italy.; Fanini, B (corresponding author), Sapienza Univ, Dept Comp Sci, Rome, Italy.
EM bruno.fanini@gmail.com; cinque@di.uniroma1.it
RI Fanini, Bruno/J-6629-2019
OI Fanini, Bruno/0000-0003-4058-877X
CR Agus Marco, 2016, P 13 EUR WORKSH GRAP
   Anné J, 2015, PEERJ, V3, DOI 10.7717/peerj.1130
   [Anonymous], 2005, TECHNICAL REPORT
   [Anonymous], 2017, HMD BASED IMMERSIVE
   Antal Adriana, 2016, COMPLETE WORKFLOW DA
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Butcher PW, 2016, POSTER IEEE VIS
   Butcher PW, 2018, FRAMEWORK IMMERSIVE
   Chen K. B., 2014, P 58 HUMAN FACTORS E, V58, P693, DOI DOI 10.1177/1541931214581162
   Dibbern Christian., 2018, Mensch und Computer 2018-Usability Professionals
   Dworak D, 2015, ADV INTELL SYST, V314, P15, DOI 10.1007/978-3-319-10383-9_2
   Fanini Bruno, 2019, Digital Applications in Archaeology and Cultural Heritage, V14, DOI 10.1016/j.daach.2019.e00100
   Fanini B., 2016, EUROGRAPHICS WORKSHO, P33, DOI [10.2312/GCH.20161380, DOI 10.2312/GCH.20161380]
   Ferri F, 2018, SPRINGERBRIEF RES IN, P1, DOI 10.1007/978-3-319-73207-7
   Gonizzi Barsanti S., 2018, Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci, VXLII-2, P371
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Hadjar H, 2018, WS.2 2018: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON WEB STUDIES, P56, DOI 10.1145/3240431.3240442
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jankowski P, 2010, T GIS, V14, P833, DOI 10.1111/j.1467-9671.2010.01235.x
   Knorr S, 2018, DIRECTORS CUT COMBIN
   Limper M, 2013, IEEE COMPUT GRAPH, V33, P26, DOI 10.1109/MCG.2013.52
   Maclntyre B, 2019, 2018 IEEE INT S MIX, P338
   Meghini C, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3064527
   Singh Manku G., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P346
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Smith T.J., 2008, J. Vis., V8, P773, DOI DOI 10.1167/8.6.773
   Upenik E, 2017, IEEE INT CONF MULTI
   Vincent C, 2018, SCAND WORKSH APPL EY
   Wagner Filho JA, 2018, P 25 IEEE C VIRT REA, V2, P4
   Wiggins RH, 2001, RADIOGRAPHICS, V21, P789, DOI 10.1148/radiographics.21.3.g01ma25789
   Wille Matthias, 2014, P 2014 ACM INT S WEA, P221
   Wong PC, 2004, IEEE COMPUT GRAPH, V24, P20
NR 32
TC 12
Z9 13
U1 0
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 423
EP 438
DI 10.1007/s10055-019-00405-w
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000565033400006
DA 2024-07-18
ER

PT J
AU Weber, S
   Mast, FW
   Weibel, D
AF Weber, Stefan
   Mast, Fred W.
   Weibel, David
TI Body size illusions influence perceived size of objects: a validation of
   previous research in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Own-body-size effect; Ownership; Virtual reality; Size perception;
   Embodiment; Avatars
ID RUBBER HAND ILLUSION; OWNERSHIP; REPRESENTATION; EMBODIMENT; LIMB
AB Previous research indicates that the size of the own body affects the judgment of objects' size, depending on the amount of subjective ownership toward the body (Van der Hoort et al. in PLOS ONE 6(5):e20195,2011). We are the first to transfer this own-body-size effect into a virtual environment. In a series of three experiments, participants (N = 68) had to embody small, medium, and large avatars and judge the size of objects. Body ownership was manipulated using synchronous and asynchronous touch. We also included a new paradigm with an additional change of perspective to induce stronger ownership (Experiment 2). Additionally, we assessed whether the visibility of the body during the judgment phase influenced the results (Experiment 3). In all three experiments, we found an overestimation in a small and an underestimation in a large body compared to a medium body. However, size estimation did not depend on the degree of ownership despite clear differences in self-reported ownership. Our results show that a virtual reality scenario does not require a visuotactile manipulation of ownership in order to evoke the own-body-size effect. Our validation of the effect in a virtual setting may be helpful for the design of clinical applications.
C1 [Weber, Stefan; Mast, Fred W.; Weibel, David] Univ Bern, Inst Psychol, Fabrikstr 8, CH-3012 Bern, Switzerland.
   [Weber, Stefan] Swiss Distance Learning Univ, Uberlandstr 12,POB 265, CH-3900 Brig, Switzerland.
C3 University of Bern
RP Weber, S (corresponding author), Univ Bern, Inst Psychol, Fabrikstr 8, CH-3012 Bern, Switzerland.; Weber, S (corresponding author), Swiss Distance Learning Univ, Uberlandstr 12,POB 265, CH-3900 Brig, Switzerland.
EM stefan.weber@psy.unibe.ch
RI Weber, Stefan A.L./F-1508-2013
OI Weber, Stefan A.L./0000-0003-3052-326X; Weibel,
   David/0000-0002-1848-9065; Mast, Fred/0000-0002-0665-4457
CR [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   [Anonymous], 1989, Bias in quantifying judgments
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Cox PF, 1999, HONEY SHRUNK KIDS
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Dobricki M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083840
   Ferrer-García M, 2012, BODY IMAGE, V9, P1, DOI 10.1016/j.bodyim.2011.10.001
   First MB, 2005, PSYCHOL MED, V35, P919, DOI 10.1017/S0033291704003320
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Harris LR, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00819
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Keizer A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163921
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Klevjer R, 2012, PHILOS COMPUTER GAME
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Longo MR, 2012, CURR DIR PSYCHOL SCI, V21, P140, DOI 10.1177/0963721411434982
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Martini M, 2014, EUR J PAIN, V18, P1040, DOI 10.1002/j.1532-2149.2014.00451.x
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Murray CD, 2007, DISABIL REHABIL, V29, P1465, DOI 10.1080/09638280601107385
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Palomo P, 2018, CONSCIOUS COGN, V58, P90, DOI 10.1016/j.concog.2017.10.014
   Petkova VI, 2011, CURR BIOL, V21, P1118, DOI 10.1016/j.cub.2011.05.022
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Proffitt DR, 2013, ACTION SCIENCE: FOUNDATIONS OF AN EMERGING DISCIPLINE, P171
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rohde M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021659
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   van der Hoort B, 2016, SCI REP-UK, V6, DOI 10.1038/srep34530
   van der Hoort B, 2014, ATTEN PERCEPT PSYCHO, V76, P1414, DOI 10.3758/s13414-014-0664-9
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Weibel D, 2015, PRESENCE-TELEOP VIRT, V24, P44, DOI 10.1162/PRES_a_00214
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 42
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 385
EP 397
DI 10.1007/s10055-019-00402-z
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000565033400003
OA Green Published
DA 2024-07-18
ER

PT J
AU Lim, K
   Lee, J
   Won, K
   Kala, N
   Lee, T
AF Lim, Kyungmin
   Lee, Jaesung
   Won, Kwanghyun
   Kala, Nupur
   Lee, Tammy
TI A novel method for VR sickness reduction based on dynamic field of view
   processing
SO VIRTUAL REALITY
LA English
DT Article
DE Dynamic FOV processing; Sickness measurement; VR contents motion
   analysis; VR sickness
AB In this paper, we proposed a novel method for virtual reality (VR) sickness reduction based on dynamic field of view (FOV) processing. Dynamic FOV processing is performed based on the estimated VR sickness for each video frame. The level of sickness is estimated using VR sickness model, which is obtained by defining the relationship between the motion information and the measured VR sickness. For motion information analysis, subregion-based correspondence points tracking is used to efficiently remove outliers and prevent prediction error propagation. Amount of head dispersion is used as a quantitative VR sickness measure, which can be calculated from inertial measurement unit sensor in VR devices. The optimal FOV range was determined by experimentally validating a minimum FOV that can effectively reduce VR sickness with almost negligible loss in presence. The simulation results show a significant decrease of 37% compared to full FOV viewing, when FOV is dynamically varied between full and 60 degrees.
C1 [Lim, Kyungmin; Lee, Jaesung; Won, Kwanghyun; Lee, Tammy] Samsung Elect, Visual Technol Team, Samsung Res, Seoul, South Korea.
   [Kala, Nupur] Pratham Educ Fdn, New Delhi, India.
C3 Samsung; Samsung Electronics
RP Lim, K (corresponding author), Samsung Elect, Visual Technol Team, Samsung Res, Seoul, South Korea.
EM km1216.lim@samsung.com; js213.lee@samsung.com; kwang.won@samsung.com;
   nupurkala15@gmail.com; tammy.lee@samsung.com
OI Lim, Kyungmin/0000-0002-5131-2966
FU SAMSUNG Research, Samsung Electronics Co., Ltd.
FX This work is/was supported by SAMSUNG Research, Samsung Electronics Co.,
   Ltd.
CR [Anonymous], 1999, TECHNICAL REPORT
   Bertin RJV, 2005, P DRIV SIM C
   Chardonnet J-R, 2015, P 25 INT C ART REAL
   Dahlman J, 2009, THESIS
   Duh HBL, 2001, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2001.913791
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Hanada M, 2012, PERCEPTION, V41, P791, DOI 10.1068/p7070
   HATADA T, 1980, SMPTE J, V89, P560, DOI 10.5594/J01582
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   KOLASINSKI EM, 1995, 1027 US ARM RES I
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   MCCAULEY M.E., 1984, Research issues in Simulator Sickness
   Nupur K, 2017, SID 2017 DIGEST
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Whittinghill D., 2015, P OD GAM DEV C
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
NR 18
TC 16
Z9 19
U1 3
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 331
EP 340
DI 10.1007/s10055-020-00457-3
EA JUL 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000549681200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Harris, D
   Wilson, M
   Vine, S
AF Harris, David
   Wilson, Mark
   Vine, Samuel
TI Development and validation of a simulation workload measure: the
   simulation task load index (SIM-TLX)
SO VIRTUAL REALITY
LA English
DT Article
DE Workload; Cognitive load; Learning; Virtual reality; Training
ID VIRTUAL-REALITY; COGNITIVE LOAD; MENTAL WORKLOAD; SURGERY; ENVIRONMENTS;
   EXPERIENCE; DESIGN
AB Virtual reality (VR) simulation offers significant potential for human factors training as it provides a novel approach which enables training in environments that are otherwise dangerous, impractical or expensive to simulate. While VR training has been adopted in many environments, such as heavy industry, surgery and aviation, there remains an inadequate understanding of how virtual simulations impact cognitive factors. One such factor, which needs careful consideration during the design of VR simulations, is the degree of mental or cognitive load experienced during training. This study aimed to validate a newly developed measure of workload, based on existing instruments (e.g. the NASA-TLX), but tailored to the specific demands placed on users of simulated environments. While participants completed a VR puzzle game, a series of experimental manipulations of workload were used to assess the sensitivity of the new instrument. The manipulations affected the questionnaire subscales (mental demands; physical demands; temporal demands; frustration; task complexity; situational stress; distraction; perceptual strain; task control; presence) as predicted in all cases (ps < .05), except for presence, which displayed little relationship with other aspects of task load. The scale was also found to have good convergent validity with an alternate index of task load. The findings support the sensitivity of the new instrument for assessing task load in virtual reality. Overall, this study contributes to the understanding of mental workload in simulated environments and provides a practical tool for use in both future research and applications in the field.
C1 [Harris, David; Wilson, Mark; Vine, Samuel] Univ Exeter, Exeter, Devon, England.
C3 University of Exeter
RP Harris, D (corresponding author), Univ Exeter, Exeter, Devon, England.
EM d.j.harris@exeter.ac.uk
RI Harris, David/H-9114-2019
OI Harris, David/0000-0003-3880-3856
FU Royal Academy of Engineering Postdoctoral Fellowship; NVIDIA equipment
   grant
FX This work was supported by a Royal Academy of Engineering Postdoctoral
   Fellowship and an NVIDIA equipment grant awarded to D Harris.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   [Anonymous], 1999, INSTRUCTIONAL DESIGN
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bharathan R, 2013, EUR J OBSTET GYN R B, V169, P347, DOI 10.1016/j.ejogrb.2013.03.017
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Burdea G. C., 2003, Virtual reality technology
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   DiDomenico A, 2008, INT J IND ERGONOM, V38, P977, DOI 10.1016/j.ergon.2008.01.012
   Dunston PS, 2014, THEOR ISS ERGON SCI, V15, P354, DOI 10.1080/1463922X.2011.624647
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Guadagnoli MA, 2004, J MOTOR BEHAV, V36, P212, DOI 10.3200/JMBR.36.2.212-224
   HART S G, 1988, P139
   Hashimoto DA, 2018, SURG ENDOSC, V32, P1397, DOI 10.1007/s00464-017-5821-5
   Kirschner PA, 2002, LEARN INSTR, V12, P1, DOI 10.1016/S0959-4752(01)00014-7
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Lackey SJ, 2016, ERGONOMICS, V59, P1060, DOI 10.1080/00140139.2015.1122234
   MCAULEY E, 1989, RES Q EXERCISE SPORT, V60, P48, DOI 10.1080/02701367.1989.10607413
   Mestre D.R., 2006, Le traite de la realite virtuelle, P309
   Mulder JM, 2004, HDB ERGONOMICS HUMAN
   Naismith LM, 2015, MED EDUC, V49, P805, DOI 10.1111/medu.12732
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Pauzié A, 2008, IET INTELL TRANSP SY, V2, P315, DOI 10.1049/iet-its:20080023
   Pollock E, 2002, LEARN INSTR, V12, P61, DOI 10.1016/S0959-4752(01)00016-0
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Renkl A, 2003, EDUC PSYCHOL-US, V38, P15, DOI 10.1207/S15326985EP3801_3
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Stanney KM, 2003, INT J HUM-COMPUT ST, V58, P447, DOI 10.1016/S1071-5819(03)00015-6
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Sutherland LM, 2006, ANN SURG, V243, P291, DOI 10.1097/01.sla.0000200839.93965.26
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Buuren S., 2011, MICE MULTIVARIATE IM
   van Gog T, 2005, ETR&D-EDUC TECH RES, V53, P73, DOI 10.1007/BF02504799
   WICKENS CD, 1992, 1992 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1 AND 2, P842, DOI 10.1109/ICSMC.1992.271688
   Wilson MR, 2011, WORLD J SURG, V35, P1961, DOI 10.1007/s00268-011-1141-4
   Zijlstra F.R.H., 1993, Efficiency in Work Behavior
NR 39
TC 50
Z9 55
U1 5
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 557
EP 566
DI 10.1007/s10055-019-00422-9
EA DEC 2019
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000542936700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Liu, SG
AF Zhang, Xiaoyong
   Liu, Shiguang
TI SPH haptic interaction with multiple-fluid simulation
SO VIRTUAL REALITY
LA English
DT Article
DE Haptics; Multiple fluid; Virtual reality; Real time
AB Physics-based fluid interaction plays an important role in computer animation, with wide applications in virtual reality, computer games, digital entertainment, etc. For example, in virtual reality education and games, we often need fluid interactions like acting as an alchemist to create a potion by stirring fluid in a crucible. The traditional input devices such as a mouse and keyboard can basically input 2D information without feedback. In recent years, the continuous development of haptic device not only can achieve six degrees-of-freedom input, but also can calculate the force in virtual scenes and feedback to the user to make a better virtual experience. How to use haptic device in different kinds of virtual fluid scenarios to provide better experience is an important issue in the field of virtual reality. On the other hand, the researches on multiple-fluid interaction especially based on smoothed particle hydrodynamics (SPH) method are very lacking. Therefore, we study the key techniques of haptic interaction with SPH multiple-fluid to compensate this defect in computer graphics community. Different from the single-phase flow, interaction with multiple-fluid flow has difficulties in the realization of properties of different phases. After adding the multiple-fluid simulation, it is also important to keep haptic interaction real time. Our research is based on the mixture model. We guarantee the authenticity of multiple-fluid mixing effect while changing the drift velocity solver to improve efficiency. We employ a unified particle model to achieve rigid body-liquid coupling, and use FIR filter to smooth feedback force to the haptic device. Our novel multiple-fluid haptic simulation can provide an interactive experience for mixing liquid in virtual reality.
C1 [Zhang, Xiaoyong; Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
   [Liu, Shiguang] Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.; Liu, SG (corresponding author), Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
EM shgliu@126.com
FU Natural Science Foundation of China [61672375, 61170118]; Application
   Foundation Research Plan Project of Tianjin [14JCQNJC00100]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments. This work was supported by the Natural Science
   Foundation of China under Grant nos. 61672375 and 61170118, and the
   Application Foundation Research Plan Project of Tianjin under Grant no.
   14JCQNJC00100.
CR Amada T., 2004, P ACM WORKSH GEN PUR, P342
   Bao K, 2010, COMPUT ANIMAT VIRT W, V21, P401, DOI 10.1002/cav.356
   Baxter W, 2004, PROC GRAPH INTERF, P81
   Cirio G, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P157, DOI 10.1109/WHC.2013.6548401
   Cirio G, 2011, IEEE T VIS COMPUT GR, V17, P1714, DOI 10.1109/TVCG.2010.271
   Dobashi Y, 2007, IEEE COMPUT GRAPH, V27, P90, DOI 10.1109/MCG.2007.52
   Hanqiu Sun, 2007, Virtual Reality, V11, P45, DOI 10.1007/s10055-006-0065-z
   Harada T., 2007, P COMP GRAPH INT
   Höver R, 2009, IEEE T HAPTICS, V2, P15, DOI 10.1109/ToH.2009.2
   Karadogan E, 2013, VIRTUAL REAL-LONDON, V17, P45, DOI 10.1007/s10055-013-0220-2
   Kim B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866197
   Liu G., 2008, Virtual Reality, V12, P99, DOI DOI 10.1007/S10055-008-0094-X
   Liu SG, 2011, VISUAL COMPUT, V27, P241, DOI 10.1007/s00371-010-0531-1
   Luciano C, 2009, VIRTUAL REAL-LONDON, V13, P69, DOI 10.1007/s10055-009-0112-7
   Pier JM, 2011, ELECT ROBOT AUTO MEC, P391, DOI 10.1109/CERMA.2011.71
   Menelas B, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P232, DOI 10.1109/WHC.2009.4810833
   Misztal MK, 2014, IEEE T VIS COMPUT GR, V20, P4, DOI 10.1109/TVCG.2013.97
   Moore M., 1988, Computer Graphics, V22, P289, DOI 10.1145/378456.378528
   Mora J., 2007, P HAPT AUD VIS ENV G, P160
   Mora J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P75
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Nan Ma, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P1780
   Ren B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2645703
   Tavakoli M., 2006, VIRTUAL REAL-LONDON, V9, P160, DOI [10.1007/s10055-005-0017-z, DOI 10.1007/S10055-005-0017-Z]
   Yang M, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENT AND GAMES, P24, DOI 10.1109/HAVE.2009.5356132
   Yang T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818117
   Yoganandan AR, 2012, VIRTUAL REAL-LONDON, V16, P33, DOI 10.1007/s10055-010-0155-9
   Zhang Yanci., 2008, Proceedings of the Fifth Euro- graphics / IEEE VGTC Conference on Point-Based Graphics, SPBG'08, P137
NR 29
TC 7
Z9 8
U1 1
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2017
VL 21
IS 4
BP 165
EP 175
DI 10.1007/s10055-017-0308-1
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FG6HN
UT WOS:000410473200001
DA 2024-07-18
ER

PT J
AU Zudilova-Seinstra, E
   van Schooten, B
   Suinesiaputra, A
   van der Geest, R
   van Dijk, B
   Reiber, J
   Sloot, P
AF Zudilova-Seinstra, Elena
   van Schooten, Boris
   Suinesiaputra, Avan
   van der Geest, Rob
   van Dijk, Betsy
   Reiber, Johan
   Sloot, Peter
TI Exploring individual user differences in the 2D/3D interaction with
   medical image data
SO VIRTUAL REALITY
LA English
DT Article
DE 2D/3D interaction; Medical segmentation; Virtual environments;
   Multimodal; User study
ID VIRTUAL-REALITY; AGE
AB User-centered design is often performed without regard to individual user differences. In this paper, we report results of an empirical study aimed to evaluate whether computer experience and demographic user characteristics would have an effect on the way people interact with the visualized medical data in a 3D virtual environment using 2D and 3D input devices. We analyzed the interaction through performance data, questionnaires and observations. The results suggest that differences in gender, age and game experience have an effect on people's behavior and task performance, as well as on subjective user preferences.
C1 [Zudilova-Seinstra, Elena; Sloot, Peter] Univ Amsterdam, Fac Sci, Inst Informat, Amsterdam, Netherlands.
   [van Schooten, Boris; van Dijk, Betsy] Univ Twente, Dept Elect Engn Math & Comp Sci, NL-7500 AE Enschede, Netherlands.
   [Suinesiaputra, Avan; van der Geest, Rob; Reiber, Johan] Leiden Univ, Med Ctr, Dept Radiol, Div Image Proc, Leiden, Netherlands.
C3 University of Amsterdam; University of Twente; Leiden University; Leiden
   University Medical Center (LUMC); Leiden University - Excl LUMC
RP Zudilova-Seinstra, E (corresponding author), Univ Amsterdam, Fac Sci, Inst Informat, Amsterdam, Netherlands.
EM E.V.Zudilova-Seinstra@uva.nl
RI van der Geest, Rob J/J-8193-2015; Zudilova-Seinstra,
   Elena/AAL-8351-2020; Suinesiaputra, Avan/W-6730-2019; Sloot,
   Peter/B-3078-2014
OI Suinesiaputra, Avan/0000-0003-1165-458X; Sloot,
   Peter/0000-0002-3848-5395
FU NWO/VIEW
FX This research is funded by the NWO/VIEW project "A Multimodal
   Visualization Environment for Interactive Analysis of Medical Data"
   (http://www.science.uva.nl/research/scs/projects/MultiVis/). We would
   like to acknowledge people, who volunteered to participate in our study,
   and to thank all partners for their contribution to this project and Dr.
   Vanessa Evers for her comments related to this paper.
CR Adame IM, 2004, MAGN RESON MATER PHY, V16, P227, DOI 10.1007/s10334-003-0030-8
   [Anonymous], P VIRT WORLDS SIM C
   [Anonymous], 2001, COGNITION 2 LANGUAGE, DOI DOI 10.1017/CBO9781139524780
   BERG C, 1982, DEV PSYCHOL, V18, P95, DOI 10.1037/0012-1649.18.1.95
   Bornik A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P29, DOI 10.1109/TRIDUI.2006.1618267
   Botella C, 1998, BEHAV RES THER, V36, P239, DOI 10.1016/S0005-7967(97)10006-7
   Bowman D., 1999, P ACM S VIRT REAL SO, P26
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Canas JJ., 2006, International Encyclopedia of Ergonomics and Human Factors-3 Volume Set
   Conner D.B., 1992, P S INTERACTIVE 3D G, P183, DOI 10.1145/147156.147199
   Cramer H. S. M., 2004, Virtual Reality, V7, P177, DOI 10.1007/s10055-004-0130-4
   Dix A, 2004, HUM-COMPUT INTERACT
   Eberts R.E., 1994, User Interface Design
   Egan D., 1985, INDIVIDUAL DIFFERENC, P173
   Egan DE., 1988, Handbook of Human-Computer Interaction, P543
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   GAGNON D, 1985, ECTJ-EDUC COMMUN TEC, V33, P263
   HARTMAN NW, 2006, P INT C COMP GRAPH I
   He T., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P142, DOI 10.1109/VISUAL.1993.398862
   Hinckley K., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P1, DOI 10.1145/263407.263408
   Hodges LF, 2001, IEEE COMPUT GRAPH, V21, P25, DOI 10.1109/38.963458
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Jacobson J., 2001, Proceedings of the ACM symposium on Virtual reality software and technology, P103, DOI DOI 10.1145/505008
   Jin W, 2005, STUD HEALTH TECHNOL, V111, P227
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   KRUGER A, 2007, CURAC2007, P215
   Larson P, 1999, Cyberpsychol Behav, V2, P113, DOI 10.1089/cpb.1999.2.113
   Leitheiser B, 1995, ASSOCIATION FOR INFORMATION SYSTEMS PROCEEDINGS OF THE FIRST AMERICAS CONFERENCE ON INFORMATION SYSTEMS, P122
   Lohman DF, 1996, HUMAN ABILITIES, P97
   Luursema JM, 2008, INTERACT COMPUT, V20, P455, DOI 10.1016/j.intcom.2008.04.003
   MARTENS JB, 2007, P IPT EGVE S
   Moise A, 2005, J DIGIT IMAGING, V18, P116, DOI 10.1007/s10278-004-2192-y
   Myers BradA., 2002, Proceedings of the SIGCHI conference on Human factors in computing systems Changing our world, p33. isbn, DOI [DOI 10.1145/503376.503383, 10.1145/503376.503383]
   Passig D, 2001, CYBERPSYCHOL BEHAV, V4, P681, DOI 10.1089/109493101753376623
   PLICHTA SB, 2008, STAT NURSING ALLIED
   RIZZO A, 2000, HDB VIRTUAL ENV
   ROESSLER A, 1998, P IFIP WORK GROUP 13, V133, P68
   SALTHOUSE TA, 1990, DEV PSYCHOL, V26, P128, DOI 10.1037/0012-1649.26.1.128
   Schroeder W., 2002, VISUALIZATION TOOLKI, VThird
   Sloot P. M. A., 2000, ADV INFRASTRUCTURES, P275
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Strong S., 2001, J IND TECHNOLOGY, V18, P1
   Velez MC, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P511
   VICENTE KJ, 1987, HUM FACTORS, V29, P349, DOI 10.1177/001872088702900308
   Waller D, 2000, J EXP PSYCHOL-APPL, V6, P307, DOI 10.1037//1076-898X.6.4.307
   Waller D, 2001, HUM FACTORS, V43, P147, DOI 10.1518/001872001775992561
   Wingrave CA, 2005, P IEEE VIRT REAL ANN, P163
   Zudilova E, 2005, FUTURE GENER COMP SY, V21, P1167, DOI 10.1016/j.future.2004.04.004
   ZUDILOVASEMSTRA EV, 2006, INTERFACES, V67, P11
NR 50
TC 6
Z9 7
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2010
VL 14
IS 2
BP 105
EP 118
DI 10.1007/s10055-009-0131-4
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HV
UT WOS:000296279600002
OA Green Submitted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Riva, G
AF Riva, Giuseppe
TI Is presence a technology issue? Some insights from cognitive sciences
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Cognitive sciences; Cognition; Action; Activity; Intentions;
   Space
ID SPACE; EXPERIENCE; PERCEPTION; CONSCIOUSNESS; RECOGNITION; INVOLVEMENT;
   SYSTEM
AB The International Society of Presence Research, defines "presence" (a shortened version of the term "telepresence") as a "psychological state in which even though part or all of an individual's current experience is generated by and/or filtered through human-made technology, part or all of the individual's perception fails to accurately acknowledge the role of the technology in the experience" (ISPR 2000, The concept of presence: explication statement. http://ispr.info/Accessed 15 Jan 2009). In this article, we will draw on the recent outcomes of cognitive sciences to offer a broader definition of presence, not related to technology only. Specifically, presence is described here as a core neuropsychological phenomenon whose goal is to produce a sense of agency and control: subjects are "present" if they are able to enact in an external world their intentions. This framework suggests that any environment, virtual or real, does not provide undifferentiated information, ready-made objects equal for everyone. It offers different opportunities and produces presence according to its ability in supporting the users and their intentions. The possible consequences of this approach for the development of presence-inducing virtual environments are also discussed.
C1 Univ Cattolica Sacro Cuore, ICE NET Lab, I-20123 Milan, Italy.
C3 Catholic University of the Sacred Heart
RP Riva, G (corresponding author), Univ Cattolica Sacro Cuore, ICE NET Lab, I-20123 Milan, Italy.
EM giuseppe.riva@unicatt.it
RI Riva, Giuseppe/C-5917-2008
OI Riva, Giuseppe/0000-0003-3657-106X
FU Italian MIUR; European Union [IST-2004-27654, IST-2002-507464]
FX The present study was supported by the Italian MIUR FIRB program
   (Project "IVT2010-Immersive Virtual Telepresence (IVT) for Experiential
   Assessment and Rehabilitation-RBIN04BC5C), and by the European Union IST
   Programm (Projects "PASION-Psychologically Augmented Social Interaction
   Over Networks-IST-2004-27654", and "INTREPID-A Virtual Reality
   Intelligent Multi-sensor Wearable System for Phobias'
   Treatment"-IST-2002-507464).
CR ANOLLI L, 2002, EMERGING COMMUNICATI
   [Anonymous], MODELS COGNITION
   [Anonymous], 1959, UNTERWEGS SPRACHE
   [Anonymous], 2002, IMITATIVE MIND DEV E, DOI DOI 10.1017/CBO9780511489969
   [Anonymous], 2005, Phenomenol. Cognitive Sci., DOI [10.1007/s11097-005-4737-z, DOI 10.1007/S11097-005-4737-Z]
   [Anonymous], HUMAN BODY PERCEPTIO
   [Anonymous], 2001, Intentions and Intentionality
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   BIOCCA F, 1997, JCMC, V3
   Coelho C., 2006, COMMUNICATION PRESEN, P25
   Csibra G, 2006, ATTENTION PERFORM, P249
   Della Sala S, 2005, PSYCHOLOGIST, V18, P606
   Farnè A, 2007, CORTEX, V43, P436, DOI 10.1016/S0010-9452(08)70468-4
   Fletcher PC, 2009, NAT REV NEUROSCI, V10, P48, DOI 10.1038/nrn2536
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   GALLESE V, 2000, PSYCOLOQUY, V11
   Gamberini L, 2003, EMERG COMMUNICAT, V5, P97
   Gamberini L, 2008, NEUROPSYCHOLOGIA, V46, P1298, DOI 10.1016/j.neuropsychologia.2007.12.016
   Gibson J., 1979, The ecological approach to visual perception
   Haggard P, 2003, CONSCIOUS COGN, V12, P695, DOI 10.1016/S1053-8100(03)00052-7
   Haggard P, 2002, NAT NEUROSCI, V5, P382, DOI 10.1038/nn827
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heidegger M., 1926, BEING TIME
   Iacoboni Marco., 2008, MIRRORING PEOPLE, V1st
   International Society for Presence Research, 2000, CONC PRES EXPL STAT
   Kaptelinin V., 2006, Acting with Technology: Activity Theory and Interaction Design
   Kilner JM, 2007, NEUROREPORT, V18, P619, DOI 10.1097/WNR.0b013e3281139ed0
   Kjellgren A, 2004, SOC BEHAV PERSONAL, V32, P103, DOI 10.2224/sbp.2004.32.2.103
   Legerstee M., 2005, INFANTS SENSE PEOPLE
   Leontjev A.N., 1978, Activity, consciousness and personality
   Lombard M., 1997, JCMC, V3
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI 10.1162/pres.1992.1.1.113
   Mantovani G, 2001, PRESENCE-TELEOP VIRT, V10, P537, DOI 10.1162/105474601753132704
   Mantovani G, 1999, PRESENCE-TELEOP VIRT, V8, P540, DOI 10.1162/105474699566459
   Mantovani G., 1996, NEW COMMUNICATION EN
   Matelli M, 2001, NEUROIMAGE, V14, pS27, DOI 10.1006/nimg.2001.0835
   MELTZOFF AN, 1977, SCIENCE, V198, P75, DOI 10.1126/science.198.4312.75
   Meltzoff AN, 2003, PHILOS T R SOC B, V358, P491, DOI 10.1098/rstb.2002.1261
   Meltzoff AN, 1999, J COMMUN DISORD, V32, P251, DOI 10.1016/S0021-9924(99)00009-X
   Oberman LM, 2005, COGNITIVE BRAIN RES, V24, P190, DOI 10.1016/j.cogbrainres.2005.01.014
   Oztop E, 2005, COGNITIVE BRAIN RES, V22, P129, DOI 10.1016/j.cogbrainres.2004.08.004
   Pacherie E., 2006, DOES CONSCIOUSNESS C, P145, DOI DOI 10.7551/MITPRESS/9780262162371.003.0009
   Pacherie E, 2008, COGNITION, V107, P179, DOI 10.1016/j.cognition.2007.09.003
   Postma A, 2005, ACTA PSYCHOL, V118, P1, DOI 10.1016/j.actpsy.2004.10.001
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Riva G, 2004, CYBERPSYCHOL BEHAV, V7, P402, DOI 10.1089/cpb.2004.7.402
   Riva G., 2008, J. Cyber Ther. Rehabil, V1, P7
   RIVA G., 2003, Emerging Communication: Studies on Nerv Technologies and Practices in Communication
   Riva G., 2006, From Communication to Presence: Cognition, Emotions and Culture towards the Ultimate Communicative Experience, P47
   Riva G., 2006, From Communication to Presence: Cognition, Emotions, and Culture Towards the Ultimate Communicative Experience
   Riva G, 2007, SCIENCE, V318, P1240, DOI 10.1126/science.318.5854.1240d
   Riva G, 2008, EMERG COMMUN-STUD NE, V10, P97
   Rizzolatti G, 1997, SCIENCE, V277, P190, DOI 10.1126/science.277.5323.190
   Rizzolatti G, 1998, ELECTROEN CLIN NEURO, V106, P283, DOI 10.1016/S0013-4694(98)00022-4
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Rizzolatti G., 2000, NEW COGNITIVE NEUROS, V2nd, P539
   Russell J., 1996, AGENCY ITS ROLE MENT
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   SCHLOERB DW, 1995, PRESENCE-TELEOP VIRT, V4, P64, DOI 10.1162/pres.1995.4.1.64
   Searle John., 1983, INTENTIONALITY
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   SIRIGU A, 1991, BRAIN, V114, P629, DOI 10.1093/brain/114.1.629
   Slater M, 2002, PRESENCE-TELEOP VIRT, V11, P435, DOI 10.1162/105474602760204327
   Spagnolli A, 2003, INT J HUM-COMPUT ST, V59, P797, DOI 10.1016/S1071-5819(03)00120-4
   Spagnolli A, 2005, PSYCHNOLOGY J, V3, P6
   Trevarthen C, 2001, J CHILD PSYCHOL PSYC, V42, P3, DOI 10.1111/1469-7610.00701
   Trevarthen C, 2001, HANDBOOK OF BRAIN AND BEHAVIOUR IN HUMAN DEVELOPMENT, P841
   Waterworth J.A., 2006, COMMUNICATION PRESEN, P80
   Williams JHG, 2008, AUTISM RES, V1, P73, DOI 10.1002/aur.15
   Wilson M, 2005, PSYCHOL BULL, V131, P460, DOI 10.1037/0033-2909.131.3.460
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
NR 73
TC 63
Z9 67
U1 0
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 159
EP 169
DI 10.1007/s10055-009-0121-6
PN 1
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300004
DA 2024-07-18
ER

PT J
AU Li, ZM
   Wang, AR
   Monteiro, D
   Liang, HN
AF Li, Ziming
   Wang, Airong
   Monteiro, Diego
   Liang, Hai-Ning
TI Virtual reality in academic English writing: exploring factors
   influencing abstract knowledge learning
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Abstract knowledge learning; Prior knowledge; Academic
   English writing; Technology-enhanced learning
ID OUTCOMES; EDUCATION
AB Virtual reality technology has been increasingly used in language education. Its immersive nature can help learners to better focus and understand subjects that can be visualized, such as mechanical design, architectural design, and molecular chemical construction. The novelty of the environment can also stimulate learners' enthusiasm for learning. Nonetheless, little research has focused on how learners' prior knowledge affects their learning experience and learning outcomes in VR environments, especially when they learn abstract conceptual knowledge. In this work, we developed a VR learning system to help learners acquire abstract knowledge of academic English writing. We used both control and experimental groups to evaluate this system and did a comparative analysis between learners with different prior knowledge. Our results show that compared with learning in a traditional way, learning abstract knowledge in a VR environment can provide learners with a better experience. We also found that learners with poor prior knowledge learned more efficiently in a VR environment when compared to learning in a non-VR environment. Our work sheds light on how to design a VR abstract knowledge learning system for learners with/without previous knowledge.
C1 [Li, Ziming; Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Jiangsu, Peoples R China.
   [Wang, Airong] Xian Jiaotong Liverpool Univ, English Language Ctr, Suzhou, Jiangsu, Peoples R China.
   [Monteiro, Diego] ESIEA, Digital Engn Sch, Laval, France.
C3 Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Jiangsu, Peoples R China.
EM haining.liang@xjtlu.edu.cn
OI Li, Ziming/0009-0004-7529-7176; Liang, Hai-Ning/0000-0003-3600-8955
FU Xi'an Jiaotong-Liverpool University (XJTLU) Key Program Special Fund
   [KSF-A-03]; XJTLU Research Development Fund [RDF-17-01-54]; XJTLU
   Teaching Development Fund [TDF22/23-R26-219, TDF2122-R23-163]
FX This research is partly supported by Xi'an Jiaotong-Liverpool University
   (XJTLU) Key Program Special Fund (#KSF-A-03) and XJTLU Research
   Development Fund (#RDF-17-01-54), and XJTLU Teaching Development Fund
   (#TDF22/23-R26-219; #TDF2122-R23-163).
CR Abuhammad A, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030010
   Ahmad A, 2018, INT CONF TEACH LEARN, P90, DOI 10.1109/LaTICE.2018.00004
   Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Alizadehsalehi Sepehr, 2019, AEI 2019 Integrated Building SolutionsThe National Agenda, P193
   Ally M, 2008, THEORY AND PRACTICE OF ONLINE LEARNING, 2ND EDITION, P15
   Ardiny H, 2018, RSI INT CONF ROBOT M, P482, DOI 10.1109/ICRoM.2018.8657615
   Badamdari Z., 2021, LANG RELAT RES, V122, P35
   Barrett A, 2022, EMERGING CONCEPTS TE, P16
   Barrett A, 2024, BEHAV INFORM TECHNOL, V43, P787, DOI 10.1080/0144929X.2023.2186145
   Bashabsheh AK, 2019, ALEX ENG J, V58, P713, DOI 10.1016/j.aej.2019.06.002
   Bian YL, 2022, VIRTUAL REAL-LONDON, V26, P1277, DOI 10.1007/s10055-021-00621-3
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   Bonner E., 2018, ANN REP, V1, P149
   Buentello-Montoya DA, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107287
   Carreras A, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P33, DOI 10.1007/978-1-84882-352-5_4
   Chen CH, 2021, J COMPUT ASSIST LEAR, V37, P851, DOI 10.1111/jcal.12528
   Chen L, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110473
   Dyer E, 2018, J MED LIBR ASSOC, V106, P498, DOI 10.5195/jmla.2018.518
   FUJIKOSHI Y, 1993, DISCRETE MATH, V116, P315, DOI 10.1016/0012-365X(93)90410-U
   Fung FM, 2019, APPL VIRTUAL REALITY
   Hai-Ning Liang, 2010, International Journal of Computers for Mathematical Learning, V15, P191, DOI 10.1007/s10758-010-9165-7
   Hashagen A., 2009, Proceedings of the 8th International Conference on Interaction Design and Children, P234, DOI DOI 10.1145/1551788.1551839
   Hayes JC, 2017, COGN RES, V2, DOI 10.1186/s41235-016-0046-z
   Hicks K, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P185, DOI 10.1145/3311350.3347171
   Hitron T, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P563, DOI 10.1145/3202185.3210776
   Huang CL, 2020, J EDUC COMPUT RES, V58, P596, DOI 10.1177/0735633119867422
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Kaplan-Rakowski R, 2023, EDUC INF TECHNOL, V28, P12505, DOI 10.1007/s10639-023-11686-9
   Lee SJ, 2011, INTERNET HIGH EDUC, V14, P158, DOI 10.1016/j.iheduc.2011.04.001
   Liang H.N., 2010, J INTERACTIVE LEARNI, V21, P5
   Liu Y, 2021, 2021 ANN S COMP HUM, P326, DOI [DOI 10.1145/3450337.3483507, DOI 10.48550/ARXIV.2109.14185, 10.48550/arXiv.2109.14185]
   Lu FY, 2023, J VISUAL-JAPAN, V26, P667, DOI 10.1007/s12650-022-00889-w
   Lu FY, 2018, INT SYM MIX AUGMENT, P143, DOI 10.1109/ISMAR.2018.00050
   Madathil K.C., 2017, Computers in Educational Journal, V8, P1
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Malinverni L, 2014, EDUC TECHNOL SOC, V17, P100
   Maresky HS, 2019, CLIN ANAT, V32, P238, DOI 10.1002/ca.23292
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Min J, 2017, PROC FRONT EDUC CONF
   Mineev G, 2017, THESIS
   Monteiro D, 2024, UNIVERSAL ACCESS INF, V23, P23, DOI 10.1007/s10209-023-00985-0
   Newby T. J., 1987, Journal of Instructional Development, V10, P20
   Niebuhr O., 2018, 9 INT C SPEECH PROSO, P309
   Otero VK, 2008, J RES SCI TEACH, V45, P497, DOI 10.1002/tea.20229
   Pack A, 2020, INT J COMPUT-ASSIST, V10, P27, DOI 10.4018/IJCALLT.2020010103
   Renganayagalu SK, 2021, TECHNOL KNOWL LEARN, V26, P999, DOI 10.1007/s10758-020-09489-9
   Sedig K, 2016, INFORMATICS-BASEL, V3, DOI 10.3390/informatics3040020
   Shapiro AM, 2004, AM EDUC RES J, V41, P159, DOI 10.3102/00028312041001159
   Slavova Y, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P685, DOI 10.1109/VR.2018.8446486
   Statistics L, 2018, INDEPENDENT SAMPLES
   Stender B, 2021, IEEE GLOB ENG EDUC C, P563, DOI 10.1109/EDUCON46332.2021.9453928
   Sutherland IE., 1965, P IFIP C
   Taçgin Z, 2020, EDUC INF TECHNOL, V25, P2791, DOI 10.1007/s10639-019-10088-0
   Tsay CHH, 2020, J COMPUT ASSIST LEAR, V36, P128, DOI 10.1111/jcal.12385
   Vogt A, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.645032
   Wang A., 2013, JALT CALL J, V91, P3, DOI 10.29140/jaltcall.v9n1.146
   WICKENS CD, 1992, 1992 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1 AND 2, P842, DOI 10.1109/ICSMC.1992.271688
   Yeo JAC, 2020, UNDERSTANDING DEV ST
   Zhang I, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12940
NR 59
TC 1
Z9 1
U1 13
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2927
EP 2939
DI 10.1007/s10055-023-00847-3
EA AUG 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001052048800002
DA 2024-07-18
ER

PT J
AU Fajnerová, I
   Francová, A
   Taranzová, K
   Darmová, B
   Kosová, E
   Stopková, P
AF Fajnerova, Iveta
   Francova, Anna
   Taranzova, Katerina
   Darmova, Barbora
   Kosova, Eliska
   Stopkova, Pavla
TI Virtual reality environment for exposure therapy in obsessive-compulsive
   disorder: a validation study
SO VIRTUAL REALITY
LA English
DT Article
DE Obsessive-compulsive disorder; Virtual reality exposure therapy;
   Anxiety; Medical applications; Presence
ID SYMPTOM STRUCTURE; ANXIETY; SCALE
AB IntroductionObsessive-compulsive disorder (OCD) is characterised by recurrent, repetitive, and unwanted thoughts or impulses triggering significant anxiety. Exposure and response prevention is currently the first-line therapy for OCD. The goal of this validation study was to confirm the potential of the VR house environment that incorporates OCD-specific items that cluster around major symptom dimensions: 'contamination', 'symmetry', 'checking' and 'hoarding' to induce anxiety and compulsive behaviour in patients with OCD.MethodWe assessed a sample of OCD patients (n = 44) that was compared to a group of healthy controls (n = 31). The severity of OCD symptoms was assessed in all subjects. During a single session, participants were asked to approach a set of 10 stimuli (covering four OCD dimensions) and rate their current intensity of distress/anxiety and compulsive tendencies (scales 0-5) provoked by observing each stimulus. Before and after the VR exposure, participants completed questionnaires assessing subjective levels of anxiety (before/after VR exposure), their sense of presence in VR and experienced simulator sickness.ResultsThe results show that the OCD group reports elevated levels of distress and compulsive behaviour when confronted with VR exposure stimuli compared to the control group, but no increase in anxiety levels has been observed after the VR exposure. The subjective ratings of provoked distress and compulsive behaviour are not associated with severity of OCD symptoms, perceived sense of presence, association with cybersickness symptoms is weak.ConclusionOur data suggest that the VR house environment is a suitable tool for VR exposure therapy in OCD patients as it demonstrates OCD symptom provocation relevant for individual patients.
C1 [Fajnerova, Iveta; Francova, Anna; Taranzova, Katerina; Darmova, Barbora; Kosova, Eliska; Stopkova, Pavla] Natl Inst Mental Hlth, Klecany, Czech Republic.
   [Fajnerova, Iveta; Francova, Anna; Kosova, Eliska; Stopkova, Pavla] Charles Univ Prague, Fac Med 3, Prague, Czech Republic.
C3 National Institute of Mental Health - Czech Republic; Charles University
   Prague
RP Fajnerová, I (corresponding author), Natl Inst Mental Hlth, Klecany, Czech Republic.; Fajnerová, I (corresponding author), Charles Univ Prague, Fac Med 3, Prague, Czech Republic.
EM iveta.fajnerova@nudz.cz
RI Kosová (Nosková), Eliška/HRC-7597-2023; Fajnerova, Iveta/AAF-1617-2020;
   Darmová, Barbora/JMR-2692-2023; Francova, Anna/KGL-7542-2024; Stopkova,
   Pavla/C-6000-2019
OI Kosová (Nosková), Eliška/0000-0002-7925-6345; Fajnerova,
   Iveta/0000-0002-7399-3029; Darmová, Barbora/0000-0002-6809-9583;
   Francova, Anna/0000-0003-0900-2144; Stopkova, Pavla/0000-0003-2712-3652
CR Abramowitz J. S., 2019, EXPOSURE THERAPY ANX, DOI DOI 10.1007/S10879-011-9187-Z
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Beck A.T., 1993, BECK ANXIETY INVENTO, DOI [10.1037/t02025-000, DOI 10.1037/T02025-000]
   Belloch A., 2014, Journal of Psychopathology and Clinical Psychology, V19, P37, DOI [DOI 10.5944/RPPC.VOL.19.NUM.1.2014.12981, 10.5944/rppc.vol.19.num.1.2014]
   Bloch MH, 2008, AM J PSYCHIAT, V165, P1532, DOI 10.1176/appi.ajp.2008.08020320
   Bouchard S., 2019, VIRTUAL REALITY PSYC, P103, DOI [10.1007/978-1-4939-9482-3_5, DOI 10.1007/978-1-4939-9482-3_5]
   Bouchard S., 2011, Journal of Computer and Information Technology, V1, P20
   C?rdenas G., 2012, REV INVESTIGACION PS, V15, P89, DOI [10.15381/rinvp.v15i2.3690, DOI 10.15381/RINVP.V15I2.3690]
   Craske MG, 2014, BEHAV RES THER, V58, P10, DOI 10.1016/j.brat.2014.04.006
   Cullen AJ, 2021, J ANXIETY DISORD, V80, DOI 10.1016/j.janxdis.2021.102404
   Fajnerova I, 2021, P 13 INT C DIS VIRT, P156
   Fineberg NA, 2020, INT CLIN PSYCHOPHARM, V35, P173, DOI 10.1097/YIC.0000000000000314
   Francova A., 2019, 2019 INT C VIRT REH, P1, DOI DOI 10.1109/ICVR46560.2019.8994404
   GOODMAN WK, 1989, ARCH GEN PSYCHIAT, V46, P1006
   Hezel DM, 2019, INDIAN J PSYCHIAT, V61, pS85, DOI 10.4103/psychiatry.IndianJPsychiatry_516_18
   Hirschtritt ME, 2017, JAMA-J AM MED ASSOC, V317, P1358, DOI 10.1001/jama.2017.2200
   Inozu M, 2021, CYBERPSYCHOLOGY, V15, DOI 10.5817/CP2021-1-7
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim K, 2010, COMPR PSYCHIAT, V51, P86, DOI 10.1016/j.comppsych.2008.12.001
   Kim K, 2008, CYBERPSYCHOL BEHAV, V11, P637, DOI 10.1089/cpb.2008.0003
   Laforest M., 2016, Frontiers in ICT, V3, DOI DOI 10.3389/FICT.2016.00018
   Laforest M, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00099
   Li Y, 2009, CNS NEUROSCI THER, V15, P276, DOI 10.1111/j.1755-5949.2009.00099.x
   Ling Yun, 2014, PLoS One, V9, pe96144, DOI 10.1371/journal.pone.0096144
   Ling Y, 2011, VTT SYMP, V269, P80
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   MARTEAU TM, 1992, BRIT J CLIN PSYCHOL, V31, P301, DOI 10.1111/j.2044-8260.1992.tb00997.x
   Mataix-Cols D, 2006, CURR OPIN PSYCHIATR, V19, P84, DOI 10.1097/01.yco.0000194809.98967.49
   Mataix-Cols D, 2005, AM J PSYCHIAT, V162, P228, DOI 10.1176/appi.ajp.162.2.228
   Matsunaga H, 2008, AM J PSYCHIAT, V165, P251, DOI 10.1176/appi.ajp.2007.07020340
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Mckay D, 2015, PSYCHIAT RES, V225, P236, DOI 10.1016/j.psychres.2014.11.058
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Powers MB., 2007, HDB EXPOSURE THERAPI, P109
   Summerfeldt LJ, 1999, BEHAV RES THER, V37, P297, DOI 10.1016/S0005-7967(98)00134-X
   Takac M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216288
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Bennekom MJ, 2021, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.550165
   van Bennekom MJ, 2017, CYBERPSYCH BEH SOC N, V20, P718, DOI 10.1089/cyber.2017.0107
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   World Health Organization, 2022, ICD 11 MORT MORB STA
   Wu JL, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.575094
NR 45
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2691
EP 2701
DI 10.1007/s10055-023-00837-5
EA JUL 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FZ6P4
UT WOS:001037034300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ünsaler, S
   Hafiz, AM
   Gökler, O
   Özkaya, YS
AF Unsaler, Selin
   Meric Hafiz, Aysenur
   Gokler, Ozan
   Ozkaya, Yasemin Sila
TI Virtual reality simulation-based training in otolaryngology
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Surgical training; Otolaryngology; Surgical simulator
ID CONSTRUCT-VALIDITY; VALIDATION; PERFORMANCE; STATION; ANATOMY; IMPACT;
   FACE
AB VR simulators will gain wider place in medical education in order to ensure high quality surgical training. The integration of VR simulators into residency programs is actually required more than ever in the era after the pandemic. In this review, the literature is reviewed for articles that reported validation results of different VR simulators designed for the field of otolaryngology. A total of 213 articles searched from Pubmed and Web of Science databases with the key words "virtual reality simulation" and "otolaryngology" on January 2022 are retrieved. After removal of duplicates, 190 articles were reviewed by two independent authors. All the accessible articles in english and which report on validation studies of virtual reality systems are included in this review. There were 33 articles reporting validation studies of otolaryngology simulators. Twenty one articles reported on otology simulator validation studies, eight articles reported rhinology simulator validation studies and four articles reported on pharyngeal and laryngeal surgery simulators. Otology simulators are shown to increase the performance of the trainees. In some studies, efficacy of simulators has been found comparable to cadaveric bone dissections and trainees reported that VR simulators was very useful in facilitating the learning process and improved the learning curves. Rhinology simulators designed for endoscopic sinus surgery are shown to have the construct validity to differentiate the surgeons of different level of expertise. Simulators in temporal bone surgery and endoscopic sinus surgery can mimic the surgical environment and anatomy along with different surgical scenarios, thus can be more implemented in surgical training and evaluation of the trainees in the future. Currently there are no validated surgical simulators for pharyngeal and laryngeal surgery.
C1 [Unsaler, Selin; Meric Hafiz, Aysenur; Gokler, Ozan; Ozkaya, Yasemin Sila] Koc Univ Hosp, Koc Univ Sch Med, Dept Otolaryngol & Head & Neck Surg, TR-34010 Istanbul, Turkiye.
C3 Koc University
RP Ünsaler, S (corresponding author), Koc Univ Hosp, Koc Univ Sch Med, Dept Otolaryngol & Head & Neck Surg, TR-34010 Istanbul, Turkiye.
EM sunsaler@ku.edu.tr; aysenurmeric@yahoo.com; ogokler@ku.edu.tr;
   yozkaya15@ku.edu.tr
RI Gökler, Ozan/AAA-6709-2021; UNSALER, SELIN/X-8142-2018
OI Gökler, Ozan/0000-0003-1621-3687; UNSALER, SELIN/0000-0001-7108-9194
CR Aggarwal R, 2010, QUAL SAF HEALTH CARE, V19, DOI 10.1136/qshc.2009.038562
   Andersen SAW, 2015, LARYNGOSCOPE, V125, P431, DOI 10.1002/lary.24838
   Andersen SAW, 2021, LARYNGOSCOPE, V131, P1855, DOI 10.1002/lary.29542
   Arora A, 2012, OTOLARYNG HEAD NECK, V146, P497, DOI 10.1177/0194599811427385
   Arora H, 2005, ARCH OTOLARYNGOL, V131, P217, DOI 10.1001/archotol.131.3.217
   Caversaccio M, 2003, AM J RHINOL, V17, P283, DOI 10.1177/194589240301700506
   Compton EC, 2020, J OTOLARYNGOL-HEAD N, V49, DOI 10.1186/s40463-020-00411-y
   Copson Bridget, 2017, Cochlear Implants Int, V18, P89, DOI 10.1080/14670100.2017.1289299
   Dailey SH, 2004, LARYNGOSCOPE, V114, P878, DOI 10.1097/00005537-200405000-00017
   Dharmawardana N, 2015, CLIN OTOLARYNGOL, V40, P569, DOI 10.1111/coa.12414
   Diment LE, 2016, ANZ J SURG, V86, P990, DOI 10.1111/ans.13418
   Edmond CV, 2002, LARYNGOSCOPE, V112, P1148, DOI 10.1097/00005537-200207000-00002
   Fang TY, 2014, COMPUT METH PROG BIO, V113, P674, DOI 10.1016/j.cmpb.2013.11.005
   Foulad A, 2015, LARYNGOSCOPE, V125, P1169, DOI 10.1002/lary.25091
   Francis HW, 2012, LARYNGOSCOPE, V122, P1385, DOI 10.1002/lary.22378
   Fried Marvin P, 2007, Curr Opin Otolaryngol Head Neck Surg, V15, P163, DOI 10.1097/MOO.0b013e32814b0802
   Fried MP, 2007, ARCH OTOLARYNGOL, V133, P350, DOI 10.1001/archotol.133.4.350
   Gawecki W, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103197
   Holliday MA, 2015, LARYNGOSCOPE, V125, P1409, DOI 10.1002/lary.25143
   Huang CW, 2018, OTOL NEUROTOL, V39, pe601, DOI 10.1097/MAO.0000000000001867
   Huang CW, 2015, J OTOLARYNGOL-HEAD N, V44, DOI 10.1186/s40463-015-0094-2
   Khemani S, 2012, OTOL NEUROTOL, V33, P1225, DOI 10.1097/MAO.0b013e31825e7977
   Locketz GD, 2017, OTOLARYNG HEAD NECK, V156, P1142, DOI 10.1177/0194599817691474
   McDougall EM, 2007, J ENDOUROL, V21, P244, DOI 10.1089/end.2007.9985
   Nash R, 2012, J LARYNGOL OTOL, V126, P663, DOI 10.1017/S0022215112000734
   O'Leary SJ, 2008, LARYNGOSCOPE, V118, P1040, DOI 10.1097/MLG.0b013e3181671b15
   Reddy-Kolanu G, 2011, ANN ROY COLL SURG, V93, P205, DOI 10.1308/003588411X565987
   Richards JP, 2020, INT FORUM ALLERGY RH, V10, P97, DOI 10.1002/alr.22452
   Ruthenbeck GS, 2012, J LARYNGOL OTOL, V126, pS8, DOI 10.1017/S0022215112000199
   Sewell C, 2008, COMPUT AIDED SURG, V13, P63, DOI 10.3109/10929080801957712
   Sowerby LJ, 2010, J OTOLARYNGOL-HEAD N, V39, P122, DOI 10.2310/7070.2009.090079
   Varshney R, 2014, J OTOLARYNGOL-HEAD N, V43, DOI 10.1186/s40463-014-0040-8
   Wheeler B, 2010, COMPUT METH PROG BIO, V98, P130, DOI 10.1016/j.cmpb.2009.09.010
   Wiet GJ, 2012, LARYNGOSCOPE, V122, pS1, DOI 10.1002/lary.22499
   Zhao Yi C, 2010, Otolaryngol Head Neck Surg, V143, pS30, DOI 10.1016/j.otohns.2010.03.008
   Zhao YC, 2011, OTOLARYNG HEAD NECK, V144, P357, DOI 10.1177/0194599810391624
NR 36
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2561
EP 2567
DI 10.1007/s10055-023-00828-6
EA JUL 2023
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001023420900002
DA 2024-07-18
ER

PT J
AU Naylor, W
   Debattista, K
   Chalmers, A
AF Naylor, William
   Debattista, Kurt
   Chalmers, Alan
TI Perception-based high quality distributed virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Networks; Tick rate; Psychophysics
AB Virtual reality has great potential to enable remote collaborative work from anywhere in the world. Developing virtual reality into a platform suitable for natural interaction and immersive collaboration requires the experience to be reliably stable. For a networked collaborative environment, perceived smoothness of motion is limited by the tick rate, that is, the frequency at which information is distributed. As tick rate increases, motion will appear increasingly smooth; however, excessive tick rates may introduce additional load on a network without any perceptible benefit to a user. This paper details two visual psychophysics experiments ( N-1 = 16, N-2 = 11 ) carried out to evaluate participant sensitivity to tick rate in virtual reality. The influence of three variables, velocity, complexity, and digital medium were investigated. Both velocity and digital medium displayed a significant effect, whilst complexity did not show significance. A model was then built and validated from the results of these experiments. The model predicts for average walking speed within the desktop condition, that 90% of the population will perceive motion to be smooth at 56 Hz, whilst this 90% threshold lies at 113 Hz for the VR condition. This model can predict participant perception of tick rate under given conditions, enabling networks to intelligently optimise participant experience without adding unnecessary further load on the network.
C1 [Naylor, William; Debattista, Kurt; Chalmers, Alan] Univ Warwick, WMG, Coventry CV4 7AL, England.
C3 University of Warwick
RP Naylor, W (corresponding author), Univ Warwick, WMG, Coventry CV4 7AL, England.
EM W.Naylor@warwick.ac.uk; K.Debattista@warwick.ac.uk;
   Alan.Chalmers@warwick.ac.uk
OI Naylor, William/0000-0002-6080-5033
FU EPSRC DTP fund; Leete Award from the Worshipful Company of Engineers
FX This research was funded by the EPSRC DTP fund and the Leete Award from
   the Worshipful Company of Engineers
CR Akaike H, 1973, 2 INT S INF THEOR, P267, DOI [DOI 10.1007/978-1-4612-1694-0_15, 10.1007/978-1-4612-0919-5_38, DOI 10.1007/978-1-4612-0919-5_38]
   Almeida T, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P64, DOI [10.1109/icgi47575.2019.8955084, 10.1109/ICGI47575.2019.8955084]
   Altman D., 2000, Statistics with Confidence: Confidence Intervals and Statistical Guidelines, V2nd ed
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bechara A, 1997, SCIENCE, V275, P1293, DOI 10.1126/science.275.5304.1293
   Brennesholtz Matthew S., 2018, SID Symposium Digest of Technical Papers, V49, P1, DOI 10.1002/sdtp.12476
   Cao RC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P729, DOI 10.1109/VR50410.2021.00100
   Carver RA, 1997, PERCEPT PSYCHOPHYS, V59, P534, DOI 10.3758/BF03211862
   Chheang V, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P1, DOI 10.1109/AIVR46125.2019.00011
   Claypool M., 2009, P 4 INT C FDN DIGITA, P42, DOI DOI 10.1145/1536513.1536530
   Debattista K, 2018, COMPUT GRAPH FORUM, V37, P363, DOI 10.1111/cgf.13302
   Denes G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392411
   Dixken M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1299, DOI [10.1109/VR.2019.8797884, 10.1109/vr.2019.8797884]
   DoVale E., 2017, SMPTE Motion Imaging J., V126, P41, DOI [10.5594/JMI.2017.2749919, 10.5594/jmi.2017.2749919, DOI 10.5594/JMI.2017.2749919]
   Dzardanova E, 2022, VIRTUAL REAL-LONDON, V26, P737, DOI 10.1007/s10055-021-00564-9
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   García-Pérez MA, 1998, VISION RES, V38, P1861, DOI 10.1016/S0042-6989(97)00340-4
   Ha G, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P301, DOI 10.1145/2993369.2996306
   Hecht J, 2016, OPT PHOTONICS NEWS, V27, P24
   Herder J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P968, DOI 10.1109/VR.2019.8798132
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hulusic V, 2011, VISUAL COMPUT, V27, P57, DOI 10.1007/s00371-010-0514-2
   Jimenez J, 2011, ACM SIGGRAPH 2011 CO, DOI [10.1145/2037636.2037642, DOI 10.1145/2037636.2037642]
   Jin Woo Kim, 2017, SID Symposium Digest of Technical Papers, V48, P1146, DOI 10.1002/sdtp.11845
   KAERNBACH C, 1991, PERCEPT PSYCHOPHYS, V49, P227, DOI 10.3758/BF03214307
   Kingdom F. A. A., 2016, SCI DIRECT, DOI DOI 10.1016/C2012-0-01278-1
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Lee WH, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY (ICISSP), P270
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   McDonnell R, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P259
   Mohler BJ, 2007, EXP BRAIN RES, V181, P221, DOI 10.1007/s00221-007-0917-0
   Niu MT, 2022, VIRTUAL REAL-LONDON, V26, P1031, DOI 10.1007/s10055-021-00613-3
   Okada K, 2017, BEHAV RES METHODS, V49, P979, DOI 10.3758/s13428-016-0760-y
   ORBAN GA, 1984, VISION RES, V24, P33, DOI 10.1016/0042-6989(84)90141-X
   Parthasarathy V, 2020, INT WIREL COMMUN, P934, DOI 10.1109/IWCMC48107.2020.9148390
   Prins N, 2019, ATTEN PERCEPT PSYCHO, V81, P1725, DOI 10.3758/s13414-019-01706-7
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Strasburger H, 2001, PERCEPT PSYCHOPHYS, V63, P1348, DOI 10.3758/BF03194547
   SWANSON WH, 1992, PERCEPT PSYCHOPHYS, V51, P409, DOI 10.3758/BF03211637
   Treutwein B, 1999, PERCEPT PSYCHOPHYS, V61, P87, DOI 10.3758/BF03211951
   TREUTWEIN B, 1995, VISION RES, V35, P2503, DOI 10.1016/0042-6989(95)00016-X
   Varshney LR, 2013, Significance, V10, P28, DOI [10.1111/j.1740-9713.2013.00636.x, DOI 10.1111/J.1740-9713.2013.00636.X]
   Vaserstein L. N, 1969, Problemy Peredachi Informatsii, V5, P64
   Wagenmakers EJ, 2004, PSYCHON B REV, V11, P192, DOI 10.3758/BF03206482
   Ware C., 1994, ACM T COMPUT-HUM INT, V1, P331, DOI [DOI 10.1145/198425.198426[39]B, DOI 10.1145/198425.198426]
   Warren PA, 2022, PERCEPTION, V51, P681, DOI 10.1177/03010066221116480
   Weibel Nadir, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383169
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Zhao JY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P893, DOI [10.1109/VR46266.2020.00114, 10.1109/VR46266.2020.1581091793502]
   Zielinski DJ, 2015, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2015.7223319
NR 56
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2529
EP 2539
DI 10.1007/s10055-023-00825-9
EA JUL 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001023607600001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Combe, T
   Chardonnet, JR
   Merienne, F
   Ovtcharova, J
AF Combe, Theo
   Chardonnet, Jean-Remy
   Merienne, Frederic
   Ovtcharova, Jivka
TI CAVE and HMD: distance perception comparative study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Distance perception; Interaction paradigms; CAVE; HMD
ID ACCOMMODATION; DISPLAY; REALITY
AB This paper proposes to analyse user experience using two different immersive device categories: a cave automatic virtual environment (CAVE) and a head-mounted display (HMD). While most past studies focused on one of these devices to characterize user experience, we propose to fill the gap in comparative studies by conducting investigations using both devices, considering the same application, method and analysis. Through this study, we want to highlight the differences in user experience induced when using either one of these technologies in terms of visualization and interaction. We performed two experiments, each focusing on a specific aspect of the devices employed. The first one is related to distance perception when walking and the possible influence of the HMD's weight, which does not occur with CAVE systems as they do not require wearing any heavy equipment. Past studies found that weight may impact distance perception. Several walking distances were considered. Results revealed that the HMD's weight does not induce significant differences over short distances (above three meters). In the second experiment, we focused on distance perception over short distances. We considered that the HMD's screen being closer to the user's eyes than in CAVE systems might induce substantial distance perception differences, especially for short-distance interaction. We designed a task in which users had to move an object from one place to another at several distances using the CAVE and an HMD. Results revealed significant underestimation compared to reality as in past work, but no significant differences between the immersive devices. These results provide a better understanding of the differences between the two emblematic virtual reality displays.
C1 [Combe, Theo; Chardonnet, Jean-Remy; Merienne, Frederic] HESAM Univ, Arts & Metiers Inst Technol, LISPEN, UBFC, 2 Rue Thomas Dumorey, F-71100 Chalon Sur Saone, France.
   [Ovtcharova, Jivka] Karlsruhe Inst Technol, IMI, Kriegsstr 77, D-76133 Karlsruhe, Germany.
C3 Universite de Bourgogne; heSam Universite; Helmholtz Association;
   Karlsruhe Institute of Technology
RP Combe, T (corresponding author), HESAM Univ, Arts & Metiers Inst Technol, LISPEN, UBFC, 2 Rue Thomas Dumorey, F-71100 Chalon Sur Saone, France.
EM theo.combe@ensam.eu; jean-remy.chardonnet@ensam.eu;
   frederic.merienne@ensam.eu; jivka.ovtcharova@kit.edu
RI Chardonnet, Jean-Rémy/W-4502-2019
OI Chardonnet, Jean-Rémy/0000-0002-8926-1359; Combe,
   Theo/0000-0003-1209-5580
FU French-German University (UFA-DFH); French government [CDFA 03-19]; 
   [ANR-21-ESRE-0030]
FX This work was supported in part by a grant from the French-German
   University (UFA-DFH) No. CDFA 03-19 and by French government funding
   managed by the National Research Agency under the Investments for the
   Future program (PIA) grant ANR-21-ESRE-0030 (CONTINUUM).
CR Colley A, 2015, LECT NOTES COMPUT SC, V9299, P363, DOI 10.1007/978-3-319-22723-8_29
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Durgin FH, 2012, J EXP PSYCHOL HUMAN, V38, P1582, DOI 10.1037/a0027805
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Galeazzi GM, 2006, NEUROSCI LETT, V410, P71, DOI 10.1016/j.neulet.2006.09.077
   Ghinea M, 2018, LECT NOTES COMPUT SC, V10850, P148, DOI 10.1007/978-3-319-95270-3_10
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Hartle B, 2021, VISION RES, V188, P51, DOI 10.1016/j.visres.2021.07.003
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kenyon RV, 2008, ANN BIOMED ENG, V36, P342, DOI 10.1007/s10439-007-9414-7
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lin CHJ, 2019, INT J IND ERGONOM, V72, P372, DOI 10.1016/j.ergon.2019.06.013
   Marsh William E., 2014, Spatial Cognition IX. International Conference, Spatial Cognition 2014. Proceedings: LNCS 8684, P354, DOI 10.1007/978-3-319-11215-2_25
   Melo M, 2018, COMPUT GRAPH-UK, V71, P159, DOI 10.1016/j.cag.2017.11.007
   Mohler BJ, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P194
   Nilsson NC, 2015, P IEEE VIRT REAL ANN, P249, DOI 10.1109/VR.2015.7223389
   Ooi TL, 2001, NATURE, V414, P197, DOI 10.1038/35102562
   Park H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311510
   Proffitt DR, 2003, PSYCHOL SCI, V14, P106, DOI 10.1111/1467-9280.t01-1-01427
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Ricca A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P103, DOI 10.1109/VR50410.2021.00031
   Ries B, 2006, APGV 2006 P 3 S APPL, DOI [10.1145/1140491.1140534, DOI 10.1145/1140491.1140534]
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Tcha-Tokey K., 2017, ACM International Conference Proceeding Series, Part, VF1311, P1, DOI [DOI 10.1145/3121283.3121284, 10.1145/3121283.3121284]
   Vienne C, 2020, IEEE ACCESS, V8, P29099, DOI 10.1109/ACCESS.2020.2972122
   Willemsen P., 2004, P 1 S APPL PERC GRAP, P35, DOI DOI 10.1145/1012551.1012558
   Witt JK, 2004, PERCEPTION, V33, P577, DOI 10.1068/p5090
   Zhan T, 2020, PHOTONIX, V1, DOI 10.1186/s43074-020-00010-0
NR 28
TC 3
Z9 3
U1 1
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2003
EP 2013
DI 10.1007/s10055-023-00787-y
EA MAR 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000960249000001
PM 37360808
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Aiello, S
   Cochrane, T
   Sevigny, C
AF Aiello, Stephen
   Cochrane, Thomas
   Sevigny, Charles
TI The affordances of clinical simulation immersive technology within
   healthcare education: a scoping review
SO VIRTUAL REALITY
LA English
DT Review
DE Healthcare; Immersive reality; Clinical simulation; Stress; Education
   design
ID VIRTUAL-REALITY; LEARNING ENVIRONMENTS; STUDENTS; EXPERIENCES
AB Whilst clinical simulation is established as an effective education tool within the healthcare community, the inability to offer authentic educational learning environments remains problematic. Advances in technology such as immersive virtual reality offer new opportunities to enhance traditional practice to an extent that may transform learning. However, with traditional clinical simulation stress and anxiety can both hinder performance and learning, yet it is unknown what nuances are applicable within a clinical virtual simulation environment. Determining potential benefits, drawbacks (including related stress and anxiety) and affordances of immersive technology clinical simulation designs may help provide an understanding of its usefulness. The aim of this scoping review is to investigate the range and nature of evidence associated with immersive virtual reality clinical simulation and education design. In addition, the review will describe authentic immersive technology clinical simulation use and reported stress response measurements. A search of seven electronic database and grey literature was performed in accordance with the Joanna Briggs Institute methodology. A key term search strategy was employed with five themes identified and investigated: (1) Healthcare professionals, (2) Clinical simulation, (3) Immersive virtual reality, (4) Stress/anxiety and (5) Authentic learning design. Application of the search strategy resulted in a hit total of 212 articles. Twelve articles met inclusion criteria. With most literature focusing on procedural performance and non-transferable education needs, there was a paucity of research that specifically investigated immersive virtual reality clinical simulation education and related stress. Therefore, this scoping review contributes new understandings by providing valuable insight and potential research gaps into current immersive virtual reality clinical simulation, its relationship to stress and the education design models currently being utilised to develop these concepts.
C1 [Aiello, Stephen] Auckland Univ Technol, Dept Paramed, Auckland, New Zealand.
   [Cochrane, Thomas] Univ Melbourne, Ctr Study Higher Educ, Melbourne, Vic, Australia.
   [Sevigny, Charles] Univ Melbourne, Fac Med, Dept Anat & Physiol, Dent & Hlth Sci, Melbourne, Vic, Australia.
C3 Auckland University of Technology; University of Melbourne; University
   of Melbourne
RP Aiello, S (corresponding author), Auckland Univ Technol, Dept Paramed, Auckland, New Zealand.
EM Stephen.aiello@aut.ac.nz; Cochrane.t@unimelb.edu.au;
   sevignyc@unimelb.edu.au
RI Aiello, Stephen/AAP-9880-2021; Cochrane, Thomas/N-8405-2015
OI Aiello, Stephen/0000-0003-4167-6640; Cochrane,
   Thomas/0000-0002-0192-6118; Sevigny, Charles/0000-0002-7625-6403
CR Aguayo C, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2150
   Ahmed H, 2020, LANCET INFECT DIS, V20, P777, DOI 10.1016/S1473-3099(20)30226-7
   Aiello S, 2021, OPEN SCI FRAMEWORK, DOI [10.17605/OSF.IO/ZP7EC, DOI 10.17605/OSF.IO/ZP7EC]
   Amiel T, 2008, EDUC TECHNOL SOC, V11, P29
   Aromataris E., 2020, JBI MANUAL EVIDENCE, DOI [DOI 10.46658/JBIMES-20-12, 10.46658/JBIMES-20-01]
   Birt J, 2017, AUSTRALAS J EDUC TEC, V33, P69, DOI 10.14742/ajet.3596
   Blaschke L.M., 2018, The digital turn in higher education, DOI 10.1007/978-3-658
   Brown M., 2020, 2020 EDUCAUSE HORIZO, P2
   Chang TP, 2019, SIMUL HEALTHC, V14, P104, DOI 10.1097/SIH.0000000000000356
   Cochrane T, 2020, RES LEARN TECHNOL, V28, DOI 10.25304/rlt.v28.2357
   Concannon BJ, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18313
   Cowling M, 2018, INFORMATION, V9, DOI 10.3390/info9020029
   Crisp N, 2008, LANCET, V371, P689, DOI 10.1016/S0140-6736(08)60309-8
   Edelbring S, 2011, ADV HEALTH SCI EDUC, V16, P331, DOI 10.1007/s10459-010-9265-0
   Fabris CP., 2019, INT J INNOVATION SCI, V27, P69, DOI DOI 10.30722/IJISME.27.08.006
   Fealy S, 2019, NURS EDUC TODAY, V79, P14, DOI 10.1016/j.nedt.2019.05.002
   Hase S, 2007, COMPLICITY, V4, P111
   Hopper Susan I, 2018, JBI Database System Rev Implement Rep, V16, P1367, DOI 10.11124/JBISRIR-2017-003477
   Johnsen K, 2005, P IEEE VIRT REAL ANN, P179
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   King D, 2018, NURS EDUC TODAY, V71, P7, DOI 10.1016/j.nedt.2018.08.002
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Lerner D, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18822
   Lioce L., 2020, Healthcare simulation dictionary, V2nd, DOI DOI 10.23970/SIMULATIONV2
   McCloy R, 2001, BRIT MED J, V323, P912, DOI 10.1136/bmj.323.7318.912
   McKenney S, 2012, CONDUCTING EDUCATIONAL DESIGN RESEARCH, P1
   Meyers NM, 2009, ASSESS EVAL HIGH EDU, V34, P565, DOI 10.1080/02602930802226502
   Mills BW, 2016, SIMUL HEALTHC, V11, P10, DOI 10.1097/SIH.0000000000000119
   O'Meara P, 2015, NURS EDUC TODAY, V35, P1080, DOI 10.1016/j.nedt.2015.06.002
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Papara R, 2020, 2020 12 EL ENG FAC C, P1, DOI DOI 10.1109/BULEF51036.2020.9326055
   Mariana FP, 2018, NURS EDUC TODAY, V71, P48, DOI 10.1016/j.nedt.2018.09.006
   Rushton MA, 2020, CIN-COMPUT INFORM NU, V38, P281, DOI 10.1097/CIN.0000000000000608
   Servotte JC, 2020, CLIN SIMUL NURS, V38, P35, DOI 10.1016/j.ecns.2019.09.006
   Simmons B, 2010, J ADV NURS, V66, P1151, DOI 10.1111/j.1365-2648.2010.05262.x
   Stein SJ, 2004, STUD HIGH EDUC, V29, P239, DOI 10.1080/0307507042000190813
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Vincent C, 2010, BMJ-BRIT MED J, V340, DOI 10.1136/bmj.c84
   Wahyuni, 2020, INT C SCI ED TECHNOL
   Wier GS, 2017, SIMUL HEALTHC, V12, P28, DOI 10.1097/SIH.0000000000000207
   Wright M.C., 2004, QUALITATIVE SAFETY H, V13, P65, DOI DOI 10.1136/qshc.2004.009951
NR 41
TC 3
Z9 3
U1 9
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3485
EP 3503
DI 10.1007/s10055-022-00745-0
EA JAN 2023
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000914408900001
PM 36686614
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Slater, M
   Cabriera, C
   Senel, G
   Banakou, D
   Beacco, A
   Oliva, R
   Gallego, J
AF Slater, Mel
   Cabriera, Carlos
   Senel, Gizem
   Banakou, Domna
   Beacco, Alejandro
   Oliva, Ramon
   Gallego, Jaime
TI The sentiment of a virtual rock concert
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Sentiment analysis; Evaluation; Concert; Performance;
   Plausibility; Presence
ID REALITY EXPOSURE THERAPY; GRADED EXPOSURE; ENVIRONMENTS; FEAR;
   QUESTIONNAIRES; APPEARANCE; SENSE
AB We created a virtual reality version of a 1983 performance by Dire Straits, this being a highly complex scenario consisting of both the virtual band performance and the appearance and behaviour of the virtual audience surrounding the participants. Our goal was to understand the responses of participants, and to learn how this type of scenario might be improved for later reconstructions of other concerts. To understand the responses of participants we carried out two studies which used sentiment analysis of texts written by the participants. Study 1 (n = 25) (Beacco et al. in IEEE Virtual Reality: 538-545, 2021) had the unexpected finding that negative sentiment was caused by the virtual audience, where e.g. some participants were fearful of being harassed by audience members. In Study 2 (n = 26) notwithstanding some changes, the audience again led to negative sentiment-e.g. a feeling of being stared at. For Study 2 we compared sentiment with questionnaire scores, finding that the illusion of being at the concert was associated with positive sentiment for males but negative for females. Overall, we found sentiment was dominated by responses to the audience rather than the band. Participants had been placed in an unusual situation, being alone at a concert, surrounded by strangers, who seemed to pose a social threat for some of them. We relate our findings to the concept of Plausibility, the illusion that events and situations in the VR are really happening. The results indicate high Plausibility, since the negative sentiment, for example in response to being started at, only makes sense if the events are experienced as actually happening. We conclude with the need for co-design of VR scenarios, and the use of sentiment analysis in this process, rather than sole reliance on concepts proposed by researchers, typically expressed through questionnaires, which may not reflect the experiences of participants.
C1 [Slater, Mel; Cabriera, Carlos; Senel, Gizem; Banakou, Domna; Beacco, Alejandro; Oliva, Ramon; Gallego, Jaime] Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.
   [Slater, Mel; Senel, Gizem; Banakou, Domna] Univ Barcelona, Inst Neurosci, Barcelona, Spain.
C3 University of Barcelona; University of Barcelona
RP Slater, M (corresponding author), Univ Barcelona, Fac Psychol, Event Lab, Barcelona, Spain.; Slater, M (corresponding author), Univ Barcelona, Inst Neurosci, Barcelona, Spain.
EM melslater@ub.edu
RI Gallego, Jaime/AAC-3603-2021; Banakou, Domna/HNR-6367-2023; Slater,
   Mel/M-5210-2014
OI Gallego, Jaime/0000-0003-3332-619X; Banakou, Domna/0000-0002-0974-6971;
   Senel, Gizem/0000-0003-3750-6964; Oliva, Ramon/0000-0002-6472-8573;
   Beacco, Alejandro/0000-0001-8192-1431; Slater, Mel/0000-0002-6223-0050
FU European Research Council [742989]; "la Caixa" Foundation [100010434,
   LCF/BQ/DR19/11740007]; European Research Council (ERC) [742989] Funding
   Source: European Research Council (ERC)
FX This research was funded by the European Research Council Advanced Grant
   MoTIVE: Moments in Time in Immersive Virtual Environments (#742989).
   Gizem Senel is supported by "la Caixa" Foundation (ID 100010434) with
   Fellowship code LCF/BQ/DR19/11740007. The authors would like to thank Mr
   Ken Zolot, Prof. Mark Billinghurst, and Prof. Joseph K. Kearney, for
   help with the recruitment of participants.
CR Alamoodi AH, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114155
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P452
   Barfield W., 1995, Virtual Reality: Research, Developments, Applications, V1, P3, DOI [10.1007/BF02009709, DOI 10.1007/BF02009709]
   Beacco A, 2022, 2022 IEEE C VIRTUAL
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   Beacco A, 2020, IEEE IMAGE PROC, P2785, DOI 10.1109/ICIP40778.2020.9191091
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Brassel S, 2021, J MED INTERNET RES, V23, DOI 10.2196/26344
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dietrich T, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.634102
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fagernäs S, 2021, INTERNET INTERV, V24, DOI 10.1016/j.invent.2021.100370
   Feuerriegel S., 2018, Package 'SentimentAnalysis'
   FEUERRIEGEL S, 2019, SENTIMENTANALYSIS DI
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gallego J, 2020, PROCEEDINGS OF 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL PROBLEMS OF ELECTRICAL ENGINEERING (CPEE), DOI 10.1109/cpee50798.2020.9238766
   Galvan Debarba Henrique., 2020, IEEE Transactions on Visualization and Computer Graphics (2020), P1, DOI DOI 10.1109/TVCG.2020.3025175
   García AS, 2023, VIRTUAL REAL-LONDON, V27, P217, DOI 10.1007/s10055-021-00558-7
   Gelman A, 2008, ANN APPL STAT, V2, P1360, DOI 10.1214/08-AOAS191
   HODGES LF, 1995, COMPUTER, V28, P27, DOI 10.1109/2.391038
   Hodges LF, 1996, IEEE COMPUT GRAPH, V16, P42, DOI 10.1109/38.544071
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Jockers M., 2017, Package "syuzhet
   Jorjafki EM, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2018.0335
   Kassambara A, 2017, Practical Guide to Principal Component Methods in R: PCA, M (CA), FAMD, MFA, HCPC, Factoextra
   Kassambara A., 2017, EXTR VIS RESULTS MUL, V76
   KOZAK JJ, 1993, ERGONOMICS, V36, P777, DOI 10.1080/00140139308967941
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Lemoine NP, 2019, OIKOS, V128, P912, DOI 10.1111/oik.05985
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Llobera J, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210537
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Murcia-López M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P747, DOI [10.1109/VR46266.2020.000-6, 10.1109/VR46266.2020.1581156939194]
   Naldi M., 2019, ARXIV
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   O'Regan JK, 2001, SYNTHESE, V129, P79, DOI 10.1023/A:1012699224677
   Pan X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146837
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2
   Poeschl S, 2013, P IEEE VIRT REAL ANN, P129, DOI 10.1109/VR.2013.6549396
   Rinker T., 2021, sentimentr: Calculate text polarity sentiment version 2.9.0
   Ríos A, 2020, VIRTUAL REAL-LONDON, V24, P683, DOI 10.1007/s10055-020-00428-8
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Rothbaum BO, 1996, BEHAV RES THER, V34, P477, DOI 10.1016/0005-7967(96)00007-1
   ROTHBAUM BO, 1995, BEHAV THER, V26, P547, DOI 10.1016/S0005-7894(05)80100-5
   Rothbaum BO, 1999, J TRAUMA STRESS, V12, P263, DOI 10.1023/A:1024772308758
   Rovira A, 2021, SAGE OPEN, V11, DOI 10.1177/21582440211040076
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   Ruhland K., 2015, COMPUT GRAPH FORUM
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 2022, FRONT VIRTUAL REAL
   Slater M, 2007, PRESENCE-TELEOP VIRT, V16, P447, DOI 10.1162/pres.16.4.447
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Steed A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00112
   Straka M., 2017, P CONLL 2017 SHAR TA, P88, DOI DOI 10.18653/V1/K17-3009
   Straka M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4290
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yoon S, 2017, STUD HEALTH TECHNOL, V245, P1292, DOI 10.3233/978-1-61499-830-3-1292
   Zibrek K., 2019, Motion, interaction and games, P1, DOI [DOI 10.1145/3359566.3360064, 10.1145/3359566.3360064]
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 75
TC 7
Z9 8
U1 3
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 651
EP 675
DI 10.1007/s10055-022-00685-9
EA AUG 2022
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000843421200001
PM 36034584
OA Green Published, Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Zhou, XZ
   Teng, F
   Du, XX
   Li, JR
   Jin, MX
   Xue, CQ
AF Zhou, Xiaozhou
   Teng, Fei
   Du, Xiaoxi
   Li, Jiarui
   Jin, Minxin
   Xue, Chengqi
TI H-GOMS: a model for evaluating a virtual-hand interaction system in
   virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Evaluation; GOMS model; Virtual-hand interaction; Virtual environments;
   Task performance
ID GESTURE RECOGNITION; REALITY
AB The virtual-hand interaction technique is a common input technique in virtual environments (VEs). The current application of virtual-hand interaction in VEs lacks specialized objective evaluation methods, making it difficult to establish a systematic functional goal orientation. To achieve a quantitative evaluation of the virtual-hand interaction system in VEs, we developed the modified evaluation method of goals, operators, methods, and selection rules (H-GOMS). The evaluation model contains five modules: analysis, decomposition, configuration, acquisition, and evaluation. To build the H-GOMS model, the relevant temporal parameters of operators in VEs were measured, and interactive rules were formulated for the configuration module. In addition to establishing the H-GOMS evaluation model, this paper demonstrates the development of a performance evaluation software (HI2ET) based on the Unity engine. We realized automatic retrieval and identification of the interactive behavior information from the software and applied the H-GOMS model algorithm for real-time visualization of the interactive process. The proposed method, with modeling of interactive tasks based on expert users, enables feasible and generally quantifiable performance evaluation for virtual-hand interaction systems in VEs.
C1 [Zhou, Xiaozhou; Teng, Fei; Du, Xiaoxi; Li, Jiarui; Jin, Minxin; Xue, Chengqi] Southeast Univ, Mech Engn, Nanjing 211189, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Zhou, XZ (corresponding author), Southeast Univ, Mech Engn, Nanjing 211189, Jiangsu, Peoples R China.
EM zxz@seu.edu.cn
RI teng, fei/HNI-1377-2023
OI ZHOU, XIAOZHOU/0000-0003-0370-2369; Teng, Fei/0000-0002-5362-6440
FU National Natural Science Foundation of China [71901061, 71871056];
   Postgraduate Research&Practice Innovation Program of Jiangsu Province
   [SJCX21_0045]
FX This work has received funding partly from the National Natural Science
   Foundation of China (Nos. 71901061, 71871056) and Postgraduate
   Research&Practice Innovation Program of Jiangsu Province (Grant No.
   SJCX21_0045).
CR Adams JackA., 1970, The American Journal of Psychology, V83, P299, DOI DOI 10.2307/1421343
   Ahir Kunjal, 2019, Augmented Human Research, V5, P1, DOI [DOI 10.1007/S41133-019-0025-2, 10.1007/s41133-019-0025-2]
   Al-Shamayleh AS, 2018, MULTIMED TOOLS APPL, V77, P28121, DOI 10.1007/s11042-018-5971-z
   Anderson JR, 1998, J MEM LANG, V38, P341, DOI 10.1006/jmla.1997.2553
   [Anonymous], 1998, 9241 ISO
   Baber C., 2005, EVALUATION HUMAN WOR, P357, DOI [10.1201/9781420055948, DOI 10.1201/9781420055948]
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Bevan N., 2016, Lecture Notes in Computer Science, DOI [DOI 10.1007/978-3-319, 10.1007/978-3-319-39510-4_25, DOI 10.1007/978-3-319-39510-4_25]
   Chakraborty BK, 2018, IET COMPUT VIS, V12, P3, DOI 10.1049/iet-cvi.2017.0052
   Chang YH, 2019, P ASEE EDGD 73 MIDYE, P99
   Chen R, 2017, IEEE ACCESS, V5, P23413, DOI 10.1109/ACCESS.2017.2761235
   Chrastil ER, 2012, PSYCHON B REV, V19, P1, DOI 10.3758/s13423-011-0182-x
   Cunha D, 2021, LECT NOTES COMPUT SC, V12950, P203, DOI 10.1007/978-3-030-86960-1_15
   Diaper D., 2003, HDB TASK ANAL HUMAN
   Dong Z, 2013, ASSEMBLY AUTOM, V33, P221, DOI 10.1108/AA-12-2013-048
   El-Shawa S, 2017, IEEE INT C INT ROBOT, P341, DOI 10.1109/IROS.2017.8202178
   Sucar LE, 2014, IEEE T NEUR SYS REH, V22, P634, DOI 10.1109/TNSRE.2013.2293673
   Ependi U., 2019, Simetris: Jurnal Teknik Mesin, Elektro dan Ilmu Komputer, V10, P65
   Estes S, 2019, COGULATOR COGNITIVE
   Fang YM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163215
   Fittkau F, 2015, 2015 IEEE 3RD WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P130, DOI 10.1109/VISSOFT.2015.7332423
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Gatti E, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.120
   Habibi P, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102600
   Hald K, 2018, IFIP WORK C HUM WORK, P103, DOI [10.1007/978-3-030-05297-3_7, DOI 10.1007/978-3-030-05297-3_7]
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   Harris D, 2020, VIRTUAL REAL-LONDON, V24, P557, DOI 10.1007/s10055-019-00422-9
   Höll M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P175, DOI 10.1109/VR.2018.8448284
   HUESMANN LR, 1984, AM J PSYCHOL, V97, P625, DOI 10.2307/1422176
   Jenkins D.P., 2008, COGNITIVE WORK ANAL, DOI DOI 10.1201/9781315572543
   John B.E., 2004, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P455, DOI DOI 10.1145/985692.985750
   Joshi S, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103286
   Karafotias G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092840
   Karray F, 2008, INT J SMART SENS INT, V1, P137, DOI 10.21307/ijssis-2017-283
   Katona J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062646
   Katzakis N, 2021, IEEE T VIS COMPUT GR, V27, P1929, DOI 10.1109/TVCG.2019.2947504
   KLEINERMANN F, 2005, P 2 INTUITION INT WO, P5
   Koutsabasis P, 2019, INT J HUM-COMPUT INT, V35, P1747, DOI 10.1080/10447318.2019.1572352
   Kumar N, 2016, PROCEDIA COMPUT SCI, V84, P70, DOI 10.1016/j.procs.2016.04.068
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P577, DOI 10.1080/10447318.2018.1455307
   Li JR, 2021, ADV INTELL SYST COMP, V1322, P187, DOI 10.1007/978-3-030-68017-6_28
   Liapis A, 2015, LECT NOTES COMPUT SC, V9296, P255, DOI 10.1007/978-3-319-22701-6_18
   Lin W., 2017, Human-Computer Interaction. User Interface Design, V10271, P584, DOI [DOI 10.1007/978-3-319-58071-5_44, 10.1007/978-3-319-58071-5_44]
   Longo L, 2017, LECT NOTES COMPUT SC, V10514, P202, DOI 10.1007/978-3-319-67684-5_13
   Lubos P, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P13, DOI 10.1145/2983310.2985753
   Lv XL, 2021, ADV INTELL SYST COMP, V1322, P152, DOI 10.1007/978-3-030-68017-6_23
   Lytvynova S, 2018, ICTERI WORKSHOPS, P278
   Madathil KC, 2017, APPL ERGON, V65, P501, DOI 10.1016/j.apergo.2017.02.011
   Marchiori E, 2018, INF TECHNOL TOUR, V18, P133, DOI 10.1007/s40558-018-0104-0
   Murata A, 2001, HUM MOVEMENT SCI, V20, P791, DOI 10.1016/S0167-9457(01)00058-6
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Park KB, 2019, MULTIMED TOOLS APPL, V78, P6211, DOI 10.1007/s11042-018-6403-9
   Perng SS, 2020, SENSOR MATER, V32, P2007, DOI 10.18494/SAM.2020.2789
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Pike M, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P469, DOI 10.1145/3013971.3014012
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Ramkumar A, 2017, INT J HUM-COMPUT INT, V33, P123, DOI 10.1080/10447318.2016.1220729
   Ramos MA, 2020, RELIAB ENG SYST SAFE, V195, DOI 10.1016/j.ress.2019.106697
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Reinschluessel AnkeVerena., P 2017 CHI C EXTENDE, DOI [DOI 10.1145/3027063.3053173, https://doi.org/10.1145/3027063.3053173]
   Roose KM, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION EXTENDED ABSTRACTS (CHI PLAY 2018), P585, DOI 10.1145/3270316.3271522
   Rosyidah U, 2019, P INT SEM APPL TECHN, P1, DOI [10.1109/ISEMANTIC.2019.8884268, DOI 10.1109/ISEMANTIC.2019.8884268]
   Schwind V, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P477, DOI 10.1145/3242671.3242675
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Strazdins G, 2017, OCEANS-IEEE
   Sudha MR, 2017, INT J AMBIENT COMPUT, V8, P1, DOI 10.4018/IJACI.2017100101
   Sun JH, 2018, 2018 12TH INTERNATIONAL SYMPOSIUM ON ANTENNAS, PROPAGATION AND ELECTROMAGNETIC THEORY (ISAPE)
   Tadeja SK, 2020, AERONAUT J, V124, P1615, DOI 10.1017/aer.2020.49
   Wang KL, 2021, IEEE I C SQRS-C, P691, DOI 10.1109/QRS-C55045.2021.00104
   Weninger Markus, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3394977
   Yang MT, 2013, IEEE INT CONF ADV LE, P439, DOI 10.1109/ICALT.2013.134
   Yu DF, 2018, J UNIVERS COMPUT SCI, V24, P1217
   Ziak P, 2017, BMC OPHTHALMOL, V17, DOI 10.1186/s12886-017-0501-8
NR 76
TC 0
Z9 0
U1 5
U2 65
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 497
EP 522
DI 10.1007/s10055-022-00674-y
EA JUL 2022
PG 26
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000828931800001
DA 2024-07-18
ER

PT J
AU Souchet, AD
   Lourdeaux, D
   Pagani, A
   Rebenitsch, L
AF Souchet, Alexis D.
   Lourdeaux, Domitile
   Pagani, Alain
   Rebenitsch, Lisa
TI A narrative review of immersive virtual reality's ergonomics and risks
   at the workplace: cybersickness, visual fatigue, muscular fatigue, acute
   stress, and mental overload
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Ergonomics; Cybersickness; Visual fatigue; Muscle
   fatigue; Stress; Mental overload; Work
ID COGNITIVE LOAD THEORY; MOUNTED DISPLAY HMD; MOTION SICKNESS;
   WORKING-MEMORY; TIME PRESSURE; INDUCED SYMPTOMS; STEREO DISPLAYS;
   TASK-DIFFICULTY; BLUE-LIGHT; VR
AB This narrative review synthesizes and introduces 386 previous works about virtual reality-induced symptoms and effects by focusing on cybersickness, visual fatigue, muscle fatigue, acute stress, and mental overload. Usually, these VRISE are treated independently in the literature, although virtual reality is increasingly considered an option to replace PCs at the workplace, which encourages us to consider them all at once. We emphasize the context of office-like tasks in VR, gathering 57 articles meeting our inclusion/exclusion criteria. Cybersickness symptoms, influenced by fifty factors, could prevent workers from using VR. It is studied but requires more research to reach a theoretical consensus. VR can lead to more visual fatigue than other screen uses, influenced by fifteen factors, mainly due to vergence-accommodation conflicts. This side effect requires more testing and clarification on how it differs from cybersickness. VR can provoke muscle fatigue and musculoskeletal discomfort, influenced by fifteen factors, depending on tasks and interactions. VR could lead to acute stress due to technostress, task difficulty, time pressure, and public speaking. VR also potentially leads to mental overload, mainly due to task load, time pressure, and intrinsically due interaction and interface of the virtual environment. We propose a research agenda to tackle VR ergonomics and risks issues at the workplace.
C1 [Souchet, Alexis D.; Lourdeaux, Domitile] Univ Technol Compiegne, Alliance Sorbonne Univ, CNRS, Heudiasyc UMR 7253, Compiegne, France.
   [Souchet, Alexis D.] IRBA, Neurosci Dept, Bretigny Sur Orge, France.
   [Pagani, Alain] DFKI, Kaiserslautern, Germany.
   [Rebenitsch, Lisa] South Dakota Mines, Rapid City, SD USA.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Technologie de Compiegne; German Research Center for Artificial
   Intelligence (DFKI)
RP Souchet, AD (corresponding author), Univ Technol Compiegne, Alliance Sorbonne Univ, CNRS, Heudiasyc UMR 7253, Compiegne, France.; Souchet, AD (corresponding author), IRBA, Neurosci Dept, Bretigny Sur Orge, France.
EM contact@alexissouchet.com
RI Pagani, Alain/A-9735-2018
OI Rebenitsch, Lisa/0000-0002-9640-8670; Souchet,
   Alexis/0000-0003-4885-1392
FU European Union [883293]; European Research Council, Domitile Lourdeaux
FX This study was funded by European Union's Horizon 2020 research and
   innovation program under grant agreement No 883293 (INFINITY project).
   H2020 European Research Council, 883293, Domitile Lourdeaux
CR A e PATERNOSTER., 2013, Open Journal of Philosophy, V3, P435, DOI 10.4236/ojpp.2013.34064
   Abdelall ES, 2020, FRONT BEHAV NEUROSCI, V14, DOI 10.3389/fnbeh.2020.00063
   Adams EJ, 2018, LANG SPEECH HEAR SER, V49, P340, DOI 10.1044/2018_LSHSS-17-0114
   Adams F, 2010, PHENOMENOL COGN SCI, V9, P619, DOI 10.1007/s11097-010-9175-x
   Ahmed S., 2017, 2017 23 INT C VIRTUA, P1
   Ahmed SF, 2018, CLIN OPHTHALMOL, V12, P2553, DOI 10.2147/OPTH.S187131
   Aksoy E, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01336
   Alais D., 2019, Springer Handbook of Auditory Research, V68, P9, DOI [10.1007/978-3-030-10461-0_2, DOI 10.1007/978-3-030-10461-0_2, 10.1007/978-3-030-10461-02, DOI 10.1007/978-3-030-10461-02]
   Alhassan M., 2021, Int J Ophthalmol. Vis. Sci, V6, P10, DOI [10.11648/j.ijovs.20210601.12, DOI 10.11648/J.IJOVS.20210601.12]
   Alhusuny A, 2021, SURG ENDOSC, V35, P6660, DOI 10.1007/s00464-020-08167-2
   Allen AP, 2017, NEUROBIOL STRESS, V6, P113, DOI 10.1016/j.ynstr.2016.11.001
   Almeida A, 2018, ADV INTELL SYST, V588, P26, DOI 10.1007/978-3-319-60582-1_3
   Alsuraykh NH, 2019, INT CONF PER COMP, P371, DOI 10.1145/3329189.3329235
   Altena E, 2019, J SLEEP RES, V28, DOI 10.1111/jsr.12677
   Andersen BJH, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P190, DOI 10.23919/elinfocom.2019.8706403
   Anses, 2021, AVIS RAPPORT ANS REL
   Anses, 2019, AVIS RAPPORT ANS REL
   Anses, 2014, EFF SAN POT TECHN AU
   Arafat IM, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P113, DOI 10.1109/VR.2018.8446194
   Armougum A, 2019, J ENVIRON PSYCHOL, V65, DOI 10.1016/j.jenvp.2019.101338
   Arnaldi B., 2018, Virtual Reality and Augmented Reality: Myths and Realities
   Arora S, 2010, SURGERY, V147, P318, DOI 10.1016/j.surg.2009.10.007
   Asarian L., 2012, ENCY HUMAN BEHAV, VSecond, P324, DOI [10.1016/B978-0-12-375000-6.00191-9, DOI 10.1016/B978-0-12-375000-6.00191-9]
   Atanasoff L, 2017, CAREER DEV Q, V65, P326, DOI 10.1002/cdq.12111
   Babiloni F., 2019, 3 INT S H WORKLOAD 1, P3, DOI DOI 10.1007/978-3-030-32423-0_1
   Baceviciute S, 2021, COMPUT EDUC, V164, DOI 10.1016/j.compedu.2020.104122
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Bando T, 2012, DISPLAYS, V33, P76, DOI 10.1016/j.displa.2011.09.001
   Banks MS, 2013, PROC SPIE, V8735, DOI 10.1117/12.2019866
   Banks MS, 2012, SMPTE MOTION IMAG J, V121, P24, DOI 10.5594/j18173
   Barreda-Angeles M, 2020, VIRTUAL REAL-LONDON, V24, P289, DOI 10.1007/s10055-019-00400-1
   Calik BB, 2022, INT J OCCUP SAF ERGO, V28, P269, DOI 10.1080/10803548.2020.1765112
   Basil M.D., 2012, Encyclopedia of the Sciences of Learning, P2384, DOI DOI 10.1007/978-1-4419-1428-6_25
   Bater LR., 2020, ENCY PERSONALITY IND, P4624, DOI [10.1007/978-3-319-24612-3_1904, DOI 10.1007/978-3-319-24612-3_1904]
   Belo J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445349
   Bernard F, 2019, ADV INTELL SYST, V822, P141, DOI 10.1007/978-3-319-96077-7_15
   Bernhardt KA, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103152
   Best S., 1996, Proceedings of the IEEE 1996 National Aerospace and Electronics Conference NAECON 1996 (Cat. No.96CH35934), P429, DOI 10.1109/NAECON.1996.517685
   Biener V, 2020, IEEE T VIS COMPUT GR, V26, P3490, DOI 10.1109/TVCG.2020.3023567
   Bienertova-Vasku J, 2020, BIOESSAYS, V42, DOI 10.1002/bies.201900238
   Biggs A., 2017, HDB STRESS HLTH, P349, DOI DOI 10.1002/9781118993811.CH21
   Biggs A.T., 2018, Adapting virtual reality and augmented reality systems for Naval aviation training (NAMRU-D-19-13)
   Biocca Frank., 1992, Presence: Teleoperators Virtual Environments, V1, P334, DOI [DOI 10.1162/PRES.1992.1.3.334, 10.1162/pres.1992.1.3.334]
   Bishop J. M., 2014, CONT SENSORIMOTOR TH, V15, P1, DOI [10.1007/978-3-319-05107-9_1, DOI 10.1007/978-3-319-05107-9_1]
   Blake R, 2011, VISION RES, V51, P754, DOI 10.1016/j.visres.2010.10.009
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Boges D, 2020, COMPUT GRAPH-UK, V91, P12, DOI 10.1016/j.cag.2020.05.024
   Bondanini G, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17218013
   Borghini G, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65610-z
   Borhany Tasneem, 2018, J Family Med Prim Care, V7, P337, DOI 10.4103/jfmpc.jfmpc_326_17
   Bosten JM, 2015, VISION RES, V110, P34, DOI 10.1016/j.visres.2015.02.017
   Boucher P, 2019, FRONT ENDOCRINOL, V10, DOI 10.3389/fendo.2019.00749
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   BoYu Gao, 2021, Journal of Systems Architecture, V117, DOI 10.1016/j.sysarc.2021.102096
   Bracq MS, 2019, NURS EDUC TODAY, V79, P153, DOI 10.1016/j.nedt.2019.05.026
   BREIER A, 1987, AM J PSYCHIAT, V144, P1419
   Brivio E, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02569
   Brown DMY, 2020, SPORTS MED, V50, P497, DOI 10.1007/s40279-019-01204-8
   Buhrmann T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00285
   Camina E, 2017, FRONT PHARMACOL, V8, DOI 10.3389/fphar.2017.00438
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Castelo-Branco R, 2021, INT J ARCHIT COMPUT, V19, P174, DOI 10.1177/1478077120958164
   Causse M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05378-x
   Caviola S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01488
   Chai WJ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00401
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen XL, 2021, 2021 IEEE 7TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2021), P262, DOI 10.1109/ICVR51878.2021.9483841
   Chen YM, 2021, CCF T PERVAS COMPUT, V3, P99, DOI 10.1007/s42486-021-00062-6
   Chihara T, 2018, APPL ERGON, V68, P204, DOI 10.1016/j.apergo.2017.11.016
   Cho TH, 2017, DISPLAYS, V49, P59, DOI 10.1016/j.displa.2017.07.002
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Coburn J, 2020, COMPUT GRAPH-UK, V92, P44, DOI 10.1016/j.cag.2020.08.003
   Coenen P, 2019, OCCUP ENVIRON MED, V76, P502, DOI 10.1136/oemed-2018-105553
   Coenen P, 2018, BRIT J SPORT MED, V52, P174, DOI 10.1136/bjsports-2016-096795
   Cohen RA., 2011, ENCY CLIN NEUROPSYCH, P247, DOI [10.1007/978-0-387-79948-3_1266, DOI 10.1007/978-0-387-79948-3_1266]
   Coles-Brennan C, 2019, CLIN EXP OPTOM, V102, P18, DOI 10.1111/cxo.12798
   Colligan TW, 2006, J WORKPLACE BEHAV HE, V21, P89, DOI 10.1300/J490v21n02_07
   Collins J, 2019, INT SYM MIX AUGMENT, P351, DOI 10.1109/ISMAR.2019.00033
   Colman AndrewM., 2009, A Dictionary of Psychology
   Çöltekin A, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9070439
   Curtin A., 2019, Neuroergonomics, P133, DOI [DOI 10.1016/B978-0-12-811926-6.00022-1, 10.1016/b978-0-12-811926-6.00022-1]
   Daniel F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37778-y
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   de Dreu MJ, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00286
   Dehais F, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00268
   Dehdashti A., 2017, MIDDLE E J REHABIL H, V4, DOI [10.5812/mejrh.57480, DOI 10.5812/MEJRH.57480]
   Dehghani M, 2022, BEHAV INFORM TECHNOL, V41, P1453, DOI 10.1080/0144929X.2021.1876767
   del Cid DA, 2021, ERGONOMICS, V64, P69, DOI 10.1080/00140139.2020.1820083
   Seguí MD, 2015, J CLIN EPIDEMIOL, V68, P662, DOI 10.1016/j.jclinepi.2015.01.015
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Denovan A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02717
   Descheneaux Charles R., 2020, Virtual, Augmented and Mixed Reality. Design and Interaction. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12190), P410, DOI 10.1007/978-3-030-49695-1_27
   Dewe P., 2017, The Handbook of Stress and Health: A Guide to Research and Practice, Vfirst st, P427, DOI [10.1002/9781118993811.ch26, DOI 10.1002/9781118993811.CH26]
   Dewe P., 2012, Handbook of Occupational Health and Wellness, DOI [DOI 10.1007/978-1-4614-4839-6_2, 10.1007/978-1-4614-4839-6_2]
   Diaz G, 2013, J VISION, V13, DOI 10.1167/13.1.20
   Dodgson NA, 2004, PROC SPIE, V5291, P36, DOI 10.1117/12.529999
   Doherty K, 2018, INT J HUM-COMPUT ST, V110, P63, DOI 10.1016/j.ijhcs.2017.10.006
   Dragano N, 2020, CURR OPIN PSYCHIATR, V33, P407, DOI 10.1097/YCO.0000000000000613
   Dube T. J., 2019, HUMAN COMPUTER INTER, P419, DOI [DOI 10.1007/978-3-030-22643-5, 10.1007/978-3-030-22643-5\33/TABLES/5, https://doi.org/10.1007/978-3-030-22643-5_33, DOI 10.1007/978-3-030-22643-5_33]
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Ebrahimi OV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00488
   Eckstein MK, 2017, DEV COGN NEUROS-NETH, V25, P69, DOI 10.1016/j.dcn.2016.11.001
   Ehrenbrusthoff K, 2018, MUSCULOSKEL SCI PRAC, V35, P73, DOI 10.1016/j.msksp.2018.02.007
   Elias ZM, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102879
   Eltayeb S, 2009, J OCCUP REHABIL, V19, P315, DOI 10.1007/s10926-009-9196-x
   Emoto M, 2005, J DISP TECHNOL, V1, P328, DOI 10.1109/JDT.2005.858938
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Epel ES, 2018, FRONT NEUROENDOCRIN, V49, P146, DOI 10.1016/j.yfrne.2018.03.001
   Epps Julien., 2018, The Wiley Handbook of Human Computer Interaction, V1, P207
   Erickson A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P434, DOI [10.1109/VR46266.2020.1580695145399, 10.1109/VR46266.2020.00-40]
   Eriksson J, 2015, NEURON, V88, P33, DOI 10.1016/j.neuron.2015.09.020
   EU-OSHA, 2019, DIG OCC SAF HLTH, P45
   Eunjee Kim, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P952, DOI 10.1177/1541931218621219
   European Agency for Safety and Health at Work, 2007, INTR WORK REL MUSC D
   Evans BJ., 2007, PICKWELLS BINOCULAR, V5, P12, DOI [10.1016/B978-0-7506-8897-0.50005-6, DOI 10.1016/B978-0-7506-8897-0.50005-6]
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Fink G., 2000, ENCY STRESS, V2nd
   Fink G., 2016, STRESS CONCEPTS COGN, P3, DOI [DOI 10.1016/B978-0-12-800951-2.00001-7, DOI 10.1016/B978-0-12-800951-2.00001-3]
   Flament-Fultot M, 2016, J CONSCIOUSNESS STUD, V23, P153
   Fortuin MF, 2011, OPHTHAL PHYSL OPT, V31, P33, DOI 10.1111/j.1475-1313.2010.00804.x
   Frommel J, 2019, P 2019 CHI C HUM FAC, P1
   Frutiger M, 2021, PAIN PRACT, V21, P100, DOI 10.1111/papr.12940
   Fuchs Philippe, 2017, Virtual Reality Headsets-A Theoretical and Pragmatic Approach, DOI [10.1201/9781315208244, DOI 10.1201/9781315208244]
   Furnham A., 2011, The Journal of Socio-Economics, V40, P35, DOI [10.1016/j.socec.2010.10.008, DOI 10.1016/J.SOCEC.2010.10.008]
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Gallego A, 2022, BEHAV MODIF, V46, P782, DOI 10.1177/0145445521994308
   Galy E, 2012, INT J PSYCHOPHYSIOL, V83, P269, DOI 10.1016/j.ijpsycho.2011.09.023
   Gandevia SC, 2001, PHYSIOL REV, V81, P1725, DOI 10.1152/physrev.2001.81.4.1725
   Ganzel BL, 2010, PSYCHOL REV, V117, P134, DOI 10.1037/a0017773
   Geiger A, 2018, ADV INTELL SYST, V607, P228, DOI 10.1007/978-3-319-60492-3_22
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Godoy LD, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00127
   Goldinger SD, 2016, PSYCHON B REV, V23, P959, DOI 10.3758/s13423-015-0860-1
   Grassini S., 2020, P 30 EUR SAF REL C 1
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Gruet M, 2013, NEUROSCIENCE, V231, P384, DOI 10.1016/j.neuroscience.2012.10.058
   Guangchuan Li, 2020, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V64, P2061, DOI 10.1177/1071181320641498
   Guo J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P443, DOI [10.1109/VR46266.2020.1581306543750, 10.1109/VR46266.2020.00-39]
   Guo J, 2019, J SOC INF DISPLAY, V27, P108, DOI 10.1002/jsid.750
   Guo J, 2017, P IEEE VIRT REAL ANN, P249, DOI 10.1109/VR.2017.7892270
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.000-5, 10.1109/VR46266.2020.1581313729558]
   Halim I, 2012, SAF HEALTH WORK, V3, P31, DOI 10.5491/SHAW.2012.3.1.31
   Han J., 2017, IS. T. Int. Symp. Electron. Imaging Sci. Technol, V29, P212, DOI [10.2352/ISSN.2470-1173.2017.14.HVEI-146, DOI 10.2352/ISSN.2470-1173.2017.14.HVEI-146]
   Heidarimoghadam R, 2020, INT J IND ERGONOM, V80, DOI 10.1016/j.ergon.2020.103030
   Heikoop DD, 2017, APPL ERGON, V60, P116, DOI 10.1016/j.apergo.2016.10.016
   Helminen EC, 2019, PSYCHONEUROENDOCRINO, V110, DOI 10.1016/j.psyneuen.2019.104437
   Heo JY, 2017, J PSYCHIATR RES, V87, P61, DOI 10.1016/j.jpsychires.2016.12.010
   Hess RF, 2015, I-PERCEPTION, V6, DOI 10.1177/2041669515593028
   Hibbard PB, 2020, INT CONF 3D IMAG, DOI 10.1109/IC3D51119.2020.9376369
   Hirota M, 2019, ERGONOMICS, V62, P759, DOI 10.1080/00140139.2019.1582805
   Hodges LarryF., 1993, Presence: Teleoperators Virtual Environments, V2, P34, DOI 10.1162/pres.1993.2.1.34
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Holliman NS, 2011, IEEE T BROADCAST, V57, P362, DOI 10.1109/TBC.2011.2130930
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Iqbal H, 2021, IEEE ACCESS, V9, P64085, DOI 10.1109/ACCESS.2021.3075769
   Iskander J, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102105
   Iskander J, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102883
   Iskander J, 2018, IEEE ACCESS, V6, P19345, DOI 10.1109/ACCESS.2018.2815663
   Iskenderova A, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P561, DOI 10.1145/3116595.3116618
   Ito K, 2019, LECT NOTES COMPUT SC, V11574, P450, DOI 10.1007/978-3-030-21607-8_35
   Jacobs J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3353902
   Jeong-Yeop Kim, 2016, International Journal of Computer Theory and Engineering, V8, P229, DOI 10.7763/IJCTE.2016.V8.1049
   Jiang B.-c., 2002, Models of the visual system, P341
   Jie Guo, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P948, DOI 10.1109/VR.2019.8797972
   Karajeh H, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0026-3
   Karimikia H, 2021, INTERNET RES, V31, P159, DOI 10.1108/INTR-09-2019-0385
   Kartick P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P799, DOI [10.1109/VRW50115.2020.00250, 10.1109/VRW50115.2020.00-25]
   Karwowski W., 2021, Handbook of standards and guidelines in Human Factors and Ergonomics
   Keller K, 1998, P SOC PHOTO-OPT INS, V3362, P46, DOI 10.1117/12.317454
   Kemeny A., 2020, Getting rid of cybersickness, DOI [10.1007/978-3-030-59342-1, DOI 10.1007/978-3-030-59342-1]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keren G., 2015, The Wiley Blackwell Handbook of Judgment Decision Making
   Khakurel J, 2018, INFORM TECHNOL PEOPL, V31, P791, DOI 10.1108/ITP-03-2017-0076
   Kim D., 2011, DSP IEEE, V7, P1
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91573-w
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim JJ, 2002, NAT REV NEUROSCI, V3, P453, DOI 10.1038/nrn849
   Kim J, 2014, VISION RES, V105, P159, DOI 10.1016/j.visres.2014.10.021
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Kim Y, 2017, PERCEPT MOTOR SKILL, V124, P1194, DOI 10.1177/0031512517732851
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kirschner PA, 2017, COMPUT EDUC, V106, P166, DOI 10.1016/j.compedu.2016.12.006
   Klier C, 2020, TRENDS PSYCHIATR PSY, V42, P284, DOI 10.1590/2237-6089-2019-0077
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Koohestani A, 2019, IEEE ACCESS, V7, P85755, DOI 10.1109/ACCESS.2019.2922993
   Kuze J, 2008, DISPLAYS, V29, P159, DOI 10.1016/j.displa.2007.09.007
   Kweon SH, 2018, ADV INTELL SYST, V592, P194, DOI 10.1007/978-3-319-60366-7_19
   Kyo Lim Hyeon, 2013, [Journal of the ergonomics society of Korea, 대한인간공학회지], V32, P125, DOI 10.5143/JESK.2013.32.1.125
   La Torre G, 2019, INT ARCH OCC ENV HEA, V92, P13, DOI 10.1007/s00420-018-1352-1
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Labuschagne I, 2019, NEUROSCI BIOBEHAV R, V107, P686, DOI 10.1016/j.neubiorev.2019.09.032
   Lackner JR, 2014, EXP BRAIN RES, V232, P2493, DOI 10.1007/s00221-014-4008-8
   Lages W. S., 2018, Frontiers in ICT, V5, P1, DOI [DOI 10.3389/FICT.2018.00015, 10.3389/fict.2018.00015]
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lambooij MTM, 2007, PROC SPIE, V6490, DOI 10.1117/12.705527
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lawrenson JG, 2017, OPHTHAL PHYSL OPT, V37, P644, DOI 10.1111/opo.12406
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lazarus R.S., 1991, EMOTION ADAPTATION
   LeBlanc VR, 2009, ACAD MED, V84, pS25, DOI 10.1097/ACM.0b013e3181b37b8f
   Lee DH, 2018, J KOREAN SOC PRECISI, V35, P1107, DOI [10.7736/KSPE.2018.35.11.1107, DOI 10.7736/KSPE.2018.35.11.1107]
   Lee K, 2013, ARTIF INTELL REV, V40, P27, DOI 10.1007/s10462-011-9278-y
   Leppink J, 2017, J TAIBAH UNIV MED SC, V12, P385, DOI 10.1016/j.jtumed.2017.05.003
   Leroy L., 2016, EYESTRAIN REDUCTION, DOI [10.1002/9781119318330, DOI 10.1002/9781119318330]
   Li M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P566, DOI [10.1109/VR46266.2020.00-26, 10.1109/VR46266.2020.1581301697128]
   Li Y, 2021, P 2021 CHI C HUMAN F, P1
   Li YF, 2019, BRAIN IMAGING BEHAV, V13, P1780, DOI 10.1007/s11682-018-9956-3
   Linares NFN, 2020, NEUROBIOL STRESS, V13, DOI 10.1016/j.ynstr.2020.100235
   Long Y, 2020, SEMIN OPHTHALMOL, V35, P170, DOI 10.1080/08820538.2020.1776342
   Lopes P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P795, DOI [10.1109/VRW50115.2020.00-27, 10.1109/VRW50115.2020.00248]
   Luger T, 2014, ERGONOMICS, V57, P162, DOI 10.1080/00140139.2014.885088
   Luong T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P809, DOI [10.1109/VR.2019.8798029, 10.1109/vr.2019.8798029]
   Luu W, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89751-x
   Luu W, 2021, INVEST OPHTH VIS SCI, V62, DOI 10.1167/iovs.62.2.4
   MacArthur C, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445701
   Mahani MAN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-03521-2
   Main LC, 2017, J OCCUP ENVIRON MED, V59, P1078, DOI 10.1097/JOM.0000000000001161
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Marcel M, 2022, INT J BUS COMMUN, V59, P506, DOI 10.1177/2329488419856803
   Marshev V, 2021, J FR OPHTALMOL, V44, P1029, DOI 10.1016/j.jfo.2020.09.032
   Marvan T, 2021, NEW IDEAS PSYCHOL, V61, DOI 10.1016/j.newideapsych.2020.100837
   Matsuura Y, 2019, CURR TOP ENV HEAL PR, P89, DOI 10.1007/978-981-13-1601-2_8
   Mays L., 2009, ENCY NEUROSCIENCE, P10, DOI [10.1007/978-3-540-29678-2_31, DOI 10.1007/978-3-540-29678-2_31]
   McCoy SK, 2014, COGN AFFECT BEHAV NE, V14, P769, DOI 10.3758/s13415-013-0215-1
   McGregor M, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P151, DOI 10.1145/3406522.3446026
   Mehra D, 2020, ASIA-PAC J OPHTHALMO, V9, P491, DOI 10.1097/APO.0000000000000328
   Melzer J.E., 2009, HELMET MOUNTED DISPL, P805
   Merbah J, 2020, ERGONOMICS, V63, P1561, DOI 10.1080/00140139.2020.1808248
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Miglio F, 2021, EXP EYE RES, V210, DOI 10.1016/j.exer.2021.108691
   Mittelstaedt JM, 2020, J VESTIBUL RES-EQUIL, V30, P165, DOI 10.3233/VES-200702
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Modi HN, 2020, ANN SURG, V272, P648, DOI 10.1097/SLA.0000000000004208
   Monroe S.M., 2015, INT ENCY SOCIAL BEHA, V2nd, P583, DOI [10.1016/B978-0-08-097086-8.25038-1, DOI 10.1016/B978-0-08-097086-8.25038-1]
   Monroe SM, 2016, Stress: Concepts, Cognition, Emotion, and Behavior: Handbook of Stress, P109, DOI DOI 10.1016/B978-0-12-800951-2.00013-3
   Monteiro P, 2021, IEEE T VIS COMPUT GR, V27, P2702, DOI 10.1109/TVCG.2021.3067687
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Munsamy AJ, 2020, J OPTOM, V13, P163, DOI 10.1016/j.optom.2020.02.004
   Negut A, 2016, COMPUT HUM BEHAV, V54, P414, DOI 10.1016/j.chb.2015.08.029
   Németh J, 2021, EUR J OPHTHALMOL, V31, P853, DOI 10.1177/1120672121998960
   Nesbitt K., 2018, Encyclopedia of Computer Graphics and Games, P1, DOI [10.1007/978-3-319-08234-9_252-1, DOI 10.1007/978-3-319-08234-9_252-1]
   Neveu P, 2016, INVEST OPHTH VIS SCI, V57, P4321, DOI 10.1167/iovs.15-18854
   Nichols S, 2002, APPL ERGON, V33, P251, DOI 10.1016/S0003-6870(02)00020-0
   Nichols S, 1999, APPL ERGON, V30, P79, DOI 10.1016/S0003-6870(98)00045-3
   Nisafani AS, 2020, J DECIS SYST, V29, P243, DOI 10.1080/12460125.2020.1796286
   Niwano Y, 2019, BMJ OPEN OPHTHALMOL, V4, DOI 10.1136/bmjophth-2018-000217
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Ofek E, 2020, PRACTICAL VIRTUAL OF
   Olson BV., 2020, PALGRAVE HDB WORKPLA, P1, DOI DOI 10.1007/978-3-030-02470-3_3-1
   Orru G., 2019, INT S HUM MENT WORKL, P23, DOI [DOI 10.1007/978-3-030-14273-53, 10.1007/978-3-030- 14273-5_3, DOI 10.1007/978-3-030-14273-5_3, 10.1007/978-3-030-14273-5_3]
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2020, ATTEN PERCEPT PSYCHO, V82, P2098, DOI 10.3758/s13414-019-01886-2
   Panke K, 2019, P 2 INT C APPL INT S, P1, DOI DOI 10.1145/3309772.3309786
   Parent M, 2019, INT J PSYCHOPHYSIOL, V146, P139, DOI 10.1016/j.ijpsycho.2019.09.005
   Park S, 2022, VIRTUAL REAL-LONDON, V26, P979, DOI 10.1007/s10055-021-00600-8
   Park S, 2015, INT J PSYCHOPHYSIOL, V97, P120, DOI 10.1016/j.ijpsycho.2015.04.006
   Parker AJ, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0251
   Parker L., 1983, Proceedings of the SPIE - The International Society for Optical Engineering, V391, P23, DOI 10.1117/12.935066
   Patterson RE., 2015, HUMAN FACTORS STEREO, P9, DOI DOI 10.1007/978-1-4471-6651-1_2
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Patterson R, 2009, J SOC INF DISPLAY, V17, P987, DOI 10.1889/JSID17.12.987
   Patterson R, 2009, J SOC INF DISPLAY, V17, P443, DOI 10.1889/JSID17.5.443
   Pautasso M, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003149
   Penumudi SA, 2020, APPL ERGON, V84, DOI 10.1016/j.apergo.2019.103010
   Peters A, 2017, PROG NEUROBIOL, V156, P164, DOI 10.1016/j.pneurobio.2017.05.004
   Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495
   Prasad K, 2020, J GEN INTERN MED, V35, P465, DOI 10.1007/s11606-019-05343-6
   Prem R, 2018, INT J STRESS MANAGE, V25, P35, DOI 10.1037/str0000044
   Priya DB, 2020, IOP CONF SER-MAT SCI, V912, DOI 10.1088/1757-899X/912/6/062009
   Ragu-Nathan TS, 2008, INFORM SYST RES, V19, P417, DOI 10.1287/isre.1070.0165
   Ramadan MZ, 2018, J SENSORS, V2018, DOI 10.1155/2018/2632157
   Ramsay DS, 2014, PSYCHOL REV, V121, P225, DOI 10.1037/a0035942
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2017, LECT NOTES COMPUT SC, V10280, P544, DOI 10.1007/978-3-319-57987-0_44
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reenen HHHV, 2008, ERGONOMICS, V51, P637, DOI 10.1080/00140130701743433
   Reichelt S, 2010, PROC SPIE, V7690, DOI 10.1117/12.850094
   Roesler R, 2019, REFERENCE MODULE NEU, DOI 10.1016/B978-0-12-809324-5.21493
   Roβing C., 2016, HDB CAMERA MONITOR S, P279, DOI [10.1007/978-3-319-29611-1_9, DOI 10.1007/978-3-319-29611-1_9]
   Rotter P, 2017, IEEE TECHNOL SOC MAG, V36, P81, DOI 10.1109/MTS.2017.2654294
   Rzayev R, 2021, P 2021 CHI C HUM FAC, P1, DOI [10.1145/3411764.3445606, DOI 10.1145/3411764.3445606]
   Saghafian M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.634352
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sasaki K, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P666, DOI 10.1109/GCCE.2015.7398690
   Schleussinger M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246398
   Schmidt M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.611740
   Schneiderman N, 2005, ANNU REV CLIN PSYCHO, V1, P607, DOI 10.1146/annurev.clinpsy.1.102803.144141
   SCHOR CM, 1992, OPTOMETRY VISION SCI, V69, P258, DOI 10.1097/00006324-199204000-00002
   SCHOR CM, 1987, INVEST OPHTH VIS SCI, V28, P1250
   SCHOR CM, 1986, VISION RES, V26, P927, DOI 10.1016/0042-6989(86)90151-3
   Schubert RS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P307, DOI 10.1145/2993369.2996334
   Sepp S, 2019, EDUC PSYCHOL REV, V31, P293, DOI 10.1007/s10648-019-09461-9
   Sesboue B., 2006, Annales de Readaptation et de Medecine Physique, V49, P348, DOI 10.1016/j.annrmp.2006.04.020
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sharples S, 2019, ADV INTELL SYST COMP, V824, P489, DOI 10.1007/978-3-319-96071-5_52
   Shen R., 2019, IMAGE GRAPHICS TECHN, P310, DOI [10.1007/978-981-13-9917-6_30, DOI 10.1007/978-981-13-9917-6_30]
   Shen RY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P124, DOI 10.1109/ISMAR-Adjunct.2019.00-65
   Sheppard AL, 2018, BMJ OPEN OPHTHALMOL, V3, DOI 10.1136/bmjophth-2018-000146
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Shields GS, 2017, PSYCHOL BULL, V143, P636, DOI 10.1037/bul0000100
   Shields GS, 2016, NEUROSCI BIOBEHAV R, V68, P651, DOI 10.1016/j.neubiorev.2016.06.038
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Song J, 2011, COMM COM INF SC, V185, P345
   Song Y., 2019, ADV ERGONOMICS DESIG, P312, DOI [10.1007/978-3-319-94706-8_35, DOI 10.1007/978-3-319-94706-8_35]
   Souchet AD, 2020, THESIS PARIS 8 U
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Souchet AD, 2022, VIRTUAL REAL-LONDON, V26, P583, DOI 10.1007/s10055-021-00548-9
   Souchet AD, 2019, INT SYM MIX AUGMENT, P328, DOI 10.1109/ISMAR.2019.00031
   Souchet AD, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281509
   Speicher M, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206518
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Staresina BP, 2019, TRENDS COGN SCI, V23, P1071, DOI 10.1016/j.tics.2019.09.011
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stephenson E., 2020, The Wiley encyclopedia of health psychology, Volume 2, the social bases of health behavior, P55, DOI [DOI 10.1002/9781119057840.CH50, 10.1002/9781119057840.CH50]
   Stich JF, 2020, INTELL BUILD INT, V12, P208, DOI 10.1080/17508975.2020.1759023
   Stratton SJ, 2016, PREHOSP DISASTER MED, V31, P347, DOI 10.1017/S1049023X16000649
   Sugita N, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P250, DOI 10.1109/GCCE.2014.7031210
   Sweeney LE, 2014, VISION RES, V105, P121, DOI 10.1016/j.visres.2014.10.007
   Szpak A, 2020, J MED INTERNET RES, V22, DOI 10.2196/19840
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Tams S, 2018, J ASSOC INF SYST, V19, P857, DOI 10.17705/1jais.00511
   Tarafdar M, 2020, IT PROF, V22, P82, DOI 10.1109/MITP.2020.2977343
   Tarafdar M, 2019, INFORM SYST J, V29, P6, DOI 10.1111/isj.12169
   Tarafdar M, 2015, INFORM SYST J, V25, P103, DOI 10.1111/isj.12042
   Taylor JL, 2016, MED SCI SPORT EXER, V48, P2294, DOI 10.1249/MSS.0000000000000923
   Terzic K., 2017, CAUSES DISCOMFORT ST, DOI [10.48550/arXiv.1703.04574, DOI 10.48550/ARXIV.1703.04574]
   Thai KTP, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P468, DOI [10.1109/VRW50115.2020.0-177, 10.1109/VRW50115.2020.00099]
   Tian F, 2021, INFORMATION, V12, DOI 10.3390/info12030130
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Tu Y., 2021, SID S DIG TECHN PAP, V52, P108, DOI [10.1002/sdtp.14396, DOI 10.1002/SDTP.14396]
   Turnbull PRK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16320-6
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Valori I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0222253
   Van Acker BB, 2018, COGN TECHNOL WORK, V20, P351, DOI 10.1007/s10111-018-0481-3
   van den Berg MMHE, 2015, INT J ENV RES PUB HE, V12, P15860, DOI 10.3390/ijerph121215026
   van Tulder M, 2007, LANCET, V369, P1815, DOI 10.1016/S0140-6736(07)60820-4
   Vanden Broucke S, 2019, IEEE INT SM C CONF, P685, DOI [10.1109/isc246665.2019.9071699, 10.1109/ISC246665.2019.9071699]
   Vanneste P, 2021, COGN TECHNOL WORK, V23, P567, DOI 10.1007/s10111-020-00641-0
   Varmaghani S., 2021, VIRTUAL REAL-LONDON, DOI [10.1007/s10055-021-00535-0, DOI 10.1007/S10055-021-00535-0]
   Vergari M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P695, DOI 10.1109/VR50410.2021.00096
   Vernazzani A, 2019, SYNTHESE, V196, P4527, DOI 10.1007/s11229-017-1664-9
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wagner JA, 2019, IEEE COMPUT GRAPH, V39, P41, DOI 10.1109/MCG.2019.2898856
   Wahl S, 2019, J BIOPHOTONICS, V12, DOI 10.1002/jbio.201900102
   Walsh KS, 2020, ANN NY ACAD SCI, V1464, P242, DOI 10.1111/nyas.14321
   Wan JJ, 2017, EXP MOL MED, V49, DOI 10.1038/emm.2017.194
   Wang A., 2010, 40 INT C COMPUTERS I, P1, DOI DOI 10.1109/ICCIE.2010.5668318
   Wang B, 2020, ACAD MANAG ANN, V14, P695, DOI 10.5465/annals.2018.0127
   Wang Y, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0731-5
   Waongenngarm P, 2020, APPL ERGON, V89, DOI 10.1016/j.apergo.2020.103225
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weinert C, 2020, L N INF SYST ORGAN, V43, P79, DOI 10.1007/978-3-030-60073-0_10
   Weingarten E, 2016, PSYCHOL BULL, V142, P472, DOI 10.1037/bul0000030
   Weyers B, 2017, 2017 IEEE 3 WORKSH E, P1
   Widyanti A, 2022, VIRTUAL REAL-LONDON, V26, P631, DOI 10.1007/s10055-021-00525-2
   Williams D, 2020, SYNTHESE, V197, P1749, DOI 10.1007/s11229-018-1768-x
   Willingham DT, 2015, TEACH PSYCHOL, V42, P266, DOI 10.1177/0098628315589505
   Wismer Andrew, 2018, Augmented Cognition Users and Contexts. 12th International Conference, AC 2018 Held as Part of HCI International 2018. Proceedings: LNAI 10916, P240, DOI 10.1007/978-3-319-91467-1_20
   Wu HY, 2021, APPL ERGON, V94, DOI 10.1016/j.apergo.2021.103400
   Wulvik AS, 2020, COGN TECHNOL WORK, V22, P95, DOI 10.1007/s10111-019-00553-8
   Yan Y, 2019, ADV INTELL SYST, V777, P239, DOI 10.1007/978-3-319-94706-8_27
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yilu Sun, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P2313, DOI 10.1177/1071181319631023
   Yoon HJ, 2020, BMC OPHTHALMOL, V20, DOI 10.1186/s12886-020-01471-4
   Young MS, 2015, ERGONOMICS, V58, P1, DOI 10.1080/00140139.2014.956151
   Youssef PN, 2011, EYE, V25, P1, DOI 10.1038/eye.2010.149
   Yu XY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P93, DOI 10.1109/ISMAR-Adjunct.2018.00042
   Yuan J., 2018, Int J Ophthalmol Clin Res, V5, P85, DOI 10.23937/2378-346X/1410085
   Yue K, 2020, IEEE T NEUR SYS REH, V28, P2794, DOI 10.1109/TNSRE.2021.3049566
   Yunhong Zhang, 2020, Advances in Physical, Social & Occupational Ergonomics. Proceedings of the AHFE 2020 Virtual Conferences on Physical Ergonomics and Human Factors, Social & Occupational Ergonomics and Cross-Cultural Decision Making. Advances in Intelligent Systems and Computing (AISC 1215), P213, DOI 10.1007/978-3-030-51549-2_28
   Zeri F, 2015, OPHTHAL PHYSL OPT, V35, P271, DOI 10.1111/opo.12194
   Zhang SQ, 2017, IEEE ENG MED BIO, P3957, DOI 10.1109/EMBC.2017.8037722
   Zhao X, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2020.103265
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Zielasko D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1884, DOI [10.1109/vr.2019.8797837, 10.1109/VR.2019.8797837]
   Zimmer P, 2019, PSYCHONEUROENDOCRINO, V101, P186, DOI 10.1016/j.psyneuen.2018.11.010
   Zimmerman ME., 2017, ENCY CLIN NEUROPSYCH, P1
NR 388
TC 39
Z9 40
U1 20
U2 86
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 19
EP 50
DI 10.1007/s10055-022-00672-0
EA JUL 2022
PG 32
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000826139400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Syamlan, A
   Fathurachman
   Denis, K
   Vander Poorten, E
   Pramujati, B
   Tjahjowidodo, T
AF Syamlan, Adlina
   Fathurachman
   Denis, Kathleen
   Vander Poorten, Emmanuel
   Pramujati, Bambang
   Tjahjowidodo, Tegoeh
TI Haptic/virtual reality orthopedic surgical simulators: a literature
   review
SO VIRTUAL REALITY
LA English
DT Review
DE Surgical simulator; Haptics; Training; Muscle memory; Orthopedics
ID TEMPORAL BONE SIMULATOR; HAPTIC FEEDBACK; TRAINING SYSTEM; SURGERY;
   VALIDATION; ANATOMY; MODELS; DISSECTION; SCOLIOSIS; REDUCTION
AB This paper presents a review of surgical simulators, developed to enhance the learning process of surgical procedures, that involves bones, ranging from musculoskeletal system (orthopedics) and the skull (ENT and neurosurgeries). The paper highlights the specific challenges in terms of the extended reality representation of surgical training along with its latest advances. The study gathers journal and conference proceedings from various database sources (bibliographic databases and online search engines) that fulfills a predetermined eligibility criterion. From the search, 185 journals were found but only 144 met the inclusion criteria. Surgical simulators emerge as a promising alternative to aid residents in surgical training. It encompasses surgical procedures done in the craniomaxillofacial, joints, limbs and spine section of the human body. The study was partially supported by internal grant STG/19/047 from KU Leuven.
C1 [Syamlan, Adlina; Tjahjowidodo, Tegoeh] Katholieke Univ Leuven, Dept Mech Engn, De Nayer Campus,Jan Pieter de Nayerlaan 5, B-2860 St Katelijne Waver, Belgium.
   [Fathurachman] Dr Hasan Sadikin Gen Hosp, Dept Orthoped & Traumatol, Jl Pasteur 38, Bandung 40161, Indonesia.
   [Fathurachman] Univ Padjadjaran, Fac Med, Jl Eijckman 38, Bandung 40161, Indonesia.
   [Denis, Kathleen; Vander Poorten, Emmanuel] Katholieke Univ Leuven, Dept Mech Engn, Grp T Leuven Campus,Andreas Vesaliusstr 13, B-3000 Leuven, Belgium.
   [Pramujati, Bambang] Inst Teknol Sepuluh Nopember, Dept Mech Engn, Sukolilo Campus, Surabaya 60111, Indonesia.
C3 KU Leuven; Dr Hasan Sadikin General Hospital; Universitas Padjadjaran;
   KU Leuven; Institut Teknologi Sepuluh Nopember
RP Tjahjowidodo, T (corresponding author), Katholieke Univ Leuven, Dept Mech Engn, De Nayer Campus,Jan Pieter de Nayerlaan 5, B-2860 St Katelijne Waver, Belgium.
EM tegoeh.tjahjowidodo@kuleuven.be
RI Tjahjowidodo, Tegoeh/A-3820-2011; Denis, Kathleen/Y-6316-2018; Vander
   Poorten, Emmanuel/O-7273-2016
OI Tjahjowidodo, Tegoeh/0000-0003-0074-5101; Denis,
   Kathleen/0000-0002-6492-9607; Vander Poorten,
   Emmanuel/0000-0003-3764-9551
CR Acosta E, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P247
   Agus M., 2002, Computing and Visualization in Science, V5, P35, DOI 10.1007/s00791-002-0085-5
   Agus M, 2003, PRESENCE-TELEOP VIRT, V12, P110, DOI 10.1162/105474603763835378
   Agus M, 2002, ST HEAL T, V85, P17
   Al Shahat OA., 2018, EGYPTIAN J PLASTIC R, V42, P405, DOI [10.21608/ejprs.2018.80765, DOI 10.21608/EJPRS.2018.80765]
   Anastakis DJ, 1999, AM J SURG, V177, P167, DOI 10.1016/S0002-9610(98)00327-4
   ANDERSEN S, 2020, ANN OTO RHINOL LARYN
   Andersen SA, 2015, J SURG SIMUL, V2, P68, DOI DOI 10.1102/2051-7726.2015.0014
   Andersen SAW, 2021, LARYNGOSCOPE, V131, P1855, DOI 10.1002/lary.29542
   Armstrong R, 2018, J Surg Simulat, V5, P74
   Arroyo-Berezowsky C., 2019, J MUSCULOSKELET SURG, V3, P326, DOI [10.4103/jmsr.jmsr_78_19, DOI 10.4103/JMSR.JMSR_78_19]
   Assisted Surgery, 2021, SSIST SURG PAG 2 COM
   Badash I, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.12.24
   Ben-Ari R, 2014, AM J MED, V127, P1017, DOI 10.1016/j.amjmed.2014.06.040
   Benyahia S, 2015, ACTES DE LA 27EME CONFERENCE FRANCOPHONE SUR L'INTERACTION HOMME-MACHINE (IHM 2015), DOI 10.1145/2820619.2820637
   Bielsa VF, 2021, J PLAST RECONSTR AES, V74, P2372, DOI 10.1016/j.bjps.2021.03.066
   Blyth P, 2007, INJURY, V38, P1197, DOI 10.1016/j.injury.2007.03.031
   Boian R.F., 2002, Proc. 1st Int. Workshop Virtual Reality Rehabilitation, P77
   Buchanan EP, 2013, SEMIN PLAST SURG, V27, P149, DOI 10.1055/s-0033-1357112
   Cecil J., 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P133, DOI 10.1109/CoASE.2013.6654045
   Chae S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193736
   Chan S, 2016, COMPUT ASSIST SURG, V21, P85, DOI 10.1080/24699322.2016.1189966
   Chen G, 2012, EUR SPINE J, V21, P1151, DOI 10.1007/s00586-011-2065-2
   Chen Y-R, 2016, P 4 IIAE INT C INTEL, P293
   Chen YH, 2013, IEEE INT CONF COMP, P78, DOI 10.1109/CIVEMSA.2013.6617399
   Cho JH, 2007, PROCEEDINGS OF THE FRONTIERS IN THE CONVERGENCE OF BIOSCIENCE AND INFORMATION TECHNOLOGIES, P525, DOI 10.1109/FBIT.2007.61
   Clarke E, 2021, ADV SIMUL, V6, DOI 10.1186/s41077-020-00153-x
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Compton EC, 2020, J OTOLARYNGOL-HEAD N, V49, DOI 10.1186/s40463-020-00411-y
   Condino S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031038
   Copson Bridget, 2017, Cochlear Implants Int, V18, P89, DOI 10.1080/14670100.2017.1289299
   Covaciu F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041537
   Dillon NP, 2013, OTOL NEUROTOL, V34, pE93, DOI 10.1097/MAO.0b013e318291c76b
   Cannon WD, 2006, CLIN ORTHOP RELAT R, P21, DOI 10.1097/01.blo.0000197080.34223.00
   DiMaio S. P., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P253
   Doherty Carolynne M, 2014, Ulster Med J, V83, P93
   DU Z, 2018, LECT NOTES COMPUT SC
   Eriksson M, 2008, P WORLD HAPT
   Escobar-Castillejos D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175752
   Escobar-Castillejos D, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0459-8
   Färber M, 2009, METHOD INFORM MED, V48, P493, DOI 10.3414/ME0566
   Färber M, 2007, PROC SPIE, V6509, DOI 10.1117/12.709253
   Fang TY, 2014, COMPUT METH PROG BIO, V113, P674, DOI 10.1016/j.cmpb.2013.11.005
   Fekri P, 2021, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.586707
   Forsslund Jonas, 2013, Stud Health Technol Inform, V184, P129
   Francis HW, 2012, LARYNGOSCOPE, V122, P1385, DOI 10.1002/lary.22378
   Francone A, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.4.2
   Frendo M, 2022, EUR ARCH OTO-RHINO-L, V279, P127, DOI 10.1007/s00405-021-06632-9
   Frey M, 2006, PRESENCE-VIRTUAL AUG, V15, P570, DOI 10.1162/pres.15.5.570
   Fucentese SF, 2015, KNEE SURG SPORT TR A, V23, P1077, DOI 10.1007/s00167-014-2888-6
   Fujiwara K, 2020, IEEJ T ELECTR ELECTR, V15, P1242, DOI 10.1002/tee.23188
   Gerovich Oleg, 2004, Comput Aided Surg, V9, P243, DOI 10.3109/10929080500190441
   Ghasemloonia A, 2016, COMPUT BIOL MED, V78, P9, DOI 10.1016/j.compbiomed.2016.09.005
   Gibby JT, 2019, INT J COMPUT ASS RAD, V14, P525, DOI 10.1007/s11548-018-1814-7
   Gibson S, 1997, LECT NOTES COMPUT SC, V1205, P369
   Gilbody J, 2011, ANN ROY COLL SURG, V93, P347, DOI 10.1308/147870811X582954
   Girod S, 2016, J REHABIL RES DEV, V53, P561, DOI 10.1682/JRRD.2015.03.0043
   Gopal S., 2021, Wrist fracture. StatPearls
   Govea-Valladares E.H., 2012, Rev. mex. ing. bioméd, V33, P147
   Griffin M, 2012, Open Orthop J, V6, P518, DOI 10.2174/1874325001206010518
   Ha-Van Q, 2020, IEEE T HAPTICS, V13, P655, DOI 10.1109/TOH.2020.2966608
   He X, 2006, PROC EUROHAPTICS, V2006, P1
   Heng PA, 2004, IEEE T INF TECHNOL B, V8, P217, DOI 10.1109/TITB.2004.826720
   Hochman JB, 2015, LARYNGOSCOPE, V125, P2353, DOI 10.1002/lary.24919
   Hochman JB, 2015, OTOLARYNG HEAD NECK, V153, P263, DOI 10.1177/0194599815586756
   Hochman JB, 2014, J OTOLARYNGOL-HEAD N, V43, DOI 10.1186/s40463-014-0023-9
   Hong SM, 2007, AAOMS
   Hsieh MS, 2002, COMPUT MED IMAG GRAP, V26, P91, DOI 10.1016/S0895-6111(01)00034-9
   Hutchins M., 2006, Virtual Reality, V9, P97, DOI DOI 10.1007/s10055-005-0015-1
   Huynh K., 2010, WORLD ACAD SCI ENG T, V64, P278
   Imboden S, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P503
   Jiang D, 2013, SIMUL-T SOC MOD SIM, V89, P1442, DOI 10.1177/0037549713491519
   Jinglu Zhang, 2017, Next Generation Computer Animation Techniques. Third International Workshop, AniNex 2017. Revised Selected Papers: LNCS 10582, P220, DOI 10.1007/978-3-319-69487-0_16
   Johansson R, 2019, 2019 IEEE 15 INT C A, P1
   Kaluschke M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR.2018.8446462
   Kang K, 2022, J IND MANAG OPTIM, V18, P1737, DOI 10.3934/jimo.2021042
   Kerwin T, 2017, INT J COMPUT ASS RAD, V12, P2039, DOI 10.1007/s11548-017-1541-5
   Kerwin T, 2009, IEEE T VIS COMPUT GR, V15, P747, DOI 10.1109/TVCG.2009.31
   Kim GH, 2014, J KOREAN NEUROSURG S, V56, P243, DOI 10.3340/jkns.2014.56.3.243
   KIM H, 2020, APPL SCI
   Kitware, 2021, INTR OST PLANN 3D SL
   Knott, 2015, INT C ART REAL TELEX, V2015, P101
   Kusins JR, 2018, INT J COMPUT ASS RAD, V13, P1049, DOI 10.1007/s11548-018-1734-6
   Larson AN, 2016, J NEUROSURG-SPINE, V24, P116, DOI 10.3171/2015.4.SPINE131119
   Lin YP, 2017, INT J COMPUT ASS RAD, V12, P91, DOI 10.1007/s11548-016-1463-7
   Lin YP, 2014, J BIOMED INFORM, V48, P122, DOI 10.1016/j.jbi.2013.12.010
   Linke R, 2013, ACTA OTORHINOLARYNGO, V33, P273
   Locketz GD, 2017, OTOLARYNG HEAD NECK, V156, P1142, DOI 10.1177/0194599817691474
   Lovquist E, 2008, 5 INTUITION INT C
   Luciano CJ, 2011, NEUROSURGERY, V69, P14, DOI 10.1227/NEU.0b013e31821954ed
   Lyu SR, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-63
   Maier J, 2019, COMPUT BIOL MED, V114, DOI 10.1016/j.compbiomed.2019.103473
   Materialise, 2021, PAT SPEC OST GUID
   MATSUNAGA T, 2021 IEEE INT C MECH, P1
   Mayoral R, 2005, THIRD INTERNATIONAL CONFERENCE ON MEDICAL INFORMATION VISUALISATION - BIOMEDICAL VISUALISATION (MEDIVIS 2005), PROCEEDINGS, P30, DOI 10.1109/MEDIVIS.2005.11
   Medellin-Castillo HI, 2021, VIRTUAL REAL-LONDON, V25, P53, DOI 10.1007/s10055-020-00438-6
   MedicalExpo, 2021, THOR SPIN MOD LD9380
   Meyer C, 2020, MIL MED, V185, pE2026, DOI 10.1093/milmed/usaa178
   Mickiewicz P, 2021, VIRTUAL REAL-LONDON, V25, P1113, DOI 10.1007/s10055-021-00516-3
   Ming-Shium Hsieh, 2006, Biomedical Engineering, Applications Basis Communications, V18, P229
   Moafimadani M., 2019, EC ORTHOP, V10, P73
   Monson LA, 2013, SEMIN PLAST SURG, V27, P145, DOI 10.1055/s-0033-1357111
   Moo-young J, 2015, DEV CONSUMER LEVEL H
   Moody L, 2009, VIRTUAL REAL-LONDON, V13, P59, DOI 10.1007/s10055-008-0106-x
   MOOYOUNG J, 2021, CUREUS J MED SCIENCE
   Morris D, 2006, VIRTUAL AUGMENT REAL, P48
   Mostafa A. E., 2017, DESIGNING NEUROSIMVR
   Negrillo-Cardenas J, 2022, INT J COMPUT ASS RAD, V17, P65, DOI 10.1007/s11548-021-02470-6
   O'Leary SJ, 2008, LARYNGOSCOPE, V118, P1040, DOI 10.1097/MLG.0b013e3181671b15
   Olsson P, 2015, PRS-GLOB OPEN, V3, DOI 10.1097/GOX.0000000000000447
   Olsson P, 2013, INT J COMPUT ASS RAD, V8, P887, DOI 10.1007/s11548-013-0827-5
   Paiva F., 2019, ORTHOP MUSCULAR SYST, DOI 10.4172/2161-0533.1000264
   Panariello D, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P449, DOI 10.1109/IRC.2019.00094
   Patel S, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/2435126
   Pettersson J, 2008, IEEE T BIO-MED ENG, V55, P1255, DOI 10.1109/TBME.2007.908099
   Pfandler M, 2017, SPINE J, V17, P1352, DOI 10.1016/j.spinee.2017.05.016
   Pflesser Bernhard, 2002, Comput Aided Surg, V7, P74
   Pinto ML, 2010, P IEEE RAS-EMBS INT, P221, DOI 10.1109/BIOROB.2010.5626982
   Poorten, 2014, EUROVR 2014 C EXHIBI, P7
   Pople IK, 2002, J NEUROL NEUROSUR PS, V73, pI17
   Pourkand A, 2017, COMPUT BIOL MED, V89, P256, DOI 10.1016/j.compbiomed.2017.06.021
   RACY M, 2020, J SURG EDUC
   Rasool S., 2014, LECT NOTES COMPUT SC, DOI 10.1007/978-3-319-07725-3_44
   Rasool S., 2013, PROC ACM S VIRTUAL R, DOI 10.1145/2503713.2503715
   Rasool Shahzad, 2013, Stud Health Technol Inform, V184, P337
   Reddy-Kolanu G, 2011, ANN ROY COLL SURG, V93, P205, DOI 10.1308/003588411X565987
   Roberts PG, 2017, KNEE SURG SPORT TR A, V25, P616, DOI 10.1007/s00167-016-4114-1
   Salb T, 1999, PROC 1 INT WORK HAPT, P85
   Sanchez-Sotelo Joaquin, 2011, Open Orthop J, V5, P106, DOI 10.2174/1874325001105010106
   Sawbone, 2021, LUMBAR L3 4 GEN 20 P
   Schvartzman SC, 2014, J ORAL MAXIL SURG, V72, P1984, DOI 10.1016/j.joms.2014.05.007
   Sénac T, 2019, CONTROL ENG PRACT, V90, P231, DOI 10.1016/j.conengprac.2019.07.005
   Sewell C, 2007, STUD HEALTH TECHNOL, V125, P427
   Sewell C, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P601
   Shi JG, 2018, WORLD NEUROSURG, V111, pE98, DOI 10.1016/j.wneu.2017.12.015
   Sieber DM, 2021, OTOL NEUROTOL, V42, P1245, DOI 10.1097/MAO.0000000000003175
   Simpson JS, 2014, AM BIOL TEACH, V76, P42, DOI 10.1525/abt.2014.76.1.9
   Slone RM, 2013, RADIOGRAPHICS, V38
   Sohmura T, 2004, INT J ORAL MAX SURG, V33, P740, DOI 10.1016/j.ijom.2004.03.003
   Sourina O, 2007, J MECH MED BIOL, V7, P37, DOI 10.1142/S0219519407002121
   Spillmann J, 2013, IEEE T VIS COMPUT GR, V19, P626, DOI 10.1109/TVCG.2013.23
   Stefan U, 2010, BONE, V47, P1048, DOI 10.1016/j.bone.2010.08.012
   Sutherland C, 2013, IEEE T BIO-MED ENG, V60, P3009, DOI 10.1109/TBME.2012.2236091
   Sutherland C, 2011, IEEE ENG MED BIO, P3459, DOI 10.1109/IEMBS.2011.6090935
   Thon SG, 2020, CURR REV MUSCULOSKE, V13, P11, DOI 10.1007/s12178-019-09582-2
   Todd CA., 2004, IFAC P, V37, P465, DOI [10.1016/S1474-6670(17)31148-5, DOI 10.1016/S1474-6670(17)31148-5]
   Todd CA, 2011, INT J BIOMED BIOL EN, V5, P1
   TOKA, TOKA SURG SIM TOK
   Tolsdorff B, 2009, COMPUT AIDED SURG, V14, P21, DOI 10.3109/10929080903040540
   Topps D, 2018, VIRTUAL SPINAL TAP U, DOI 10.15694/mep.2018.0000076.1
   Treuting R, 2000, Ochsner J, V2, P158
   Tsagarakis NG, 2004, PROC EUROHAPTICS 200
   Tsagarakis NG, 2006, IEEE MULTIMEDIA, V13, P40, DOI 10.1109/MMUL.2006.55
   Tsagarskis NG, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P519
   Tsai MD, 2005, IEEE T INF TECHNOL B, V9, P139, DOI 10.1109/TITB.2004.842409
   Tsai MD, 2001, COMPUT BIOL MED, V31, P333, DOI 10.1016/S0010-4825(01)00014-2
   Tsai ML, 2009, IEEE INT 3D SYST, P170
   Tsai MD, 2007, COMPUT BIOL MED, V37, P1709, DOI 10.1016/j.compbiomed.2007.04.006
   Turini G, 2018, LECT NOTES COMPUT SC, V10851, P201, DOI 10.1007/978-3-319-95282-6_15
   Vankipuram M, 2010, J BIOMED INFORM, V43, P661, DOI 10.1016/j.jbi.2010.05.016
   Vidal FP, 2008, COMPUT ANIMAT VIRT W, V19, P111, DOI 10.1002/cav.217
   Walenkamp MMJ, 2015, STRATEG TRAUMA LIMB, V10, P109, DOI 10.1007/s11751-015-0234-2
   Wang Q, 2012, IEEE T INF TECHNOL B, V16, P1105, DOI 10.1109/TITB.2012.2218114
   Wang YZ, 2013, COMPUT ANIMAT VIRT W, V24, P25, DOI 10.1002/cav.1434
   Wang Z, 2018, 477 EASYCHAIR
   Ward JW, 1998, FUTURE GENER COMP SY, V14, P243, DOI 10.1016/S0167-739X(98)00028-4
   Wiet GJ, 2002, OTOLARYNG HEAD NECK, V127, P79, DOI 10.1067/mhn.2002.126588
   Wijewickrema S, 2015, OTOLARYNG HEAD NECK, V152, P1082, DOI 10.1177/0194599815570880
   Williams R., 2004, HAPTICS, V3, P1
   Wong D, 2014, J OTOLARYNGOL-HEAD N, V43, DOI 10.1186/s40463-014-0031-9
   Wu FL, 2014, INT J MED ROBOT COMP, V10, P78, DOI 10.1002/rcs.1514
   Xing Q., 2015, P 21 ACM S VIRTUAL R, P121
   Yan YY, 2018, J VISUAL-JAPAN, V21, P239, DOI 10.1007/s12650-017-0455-1
   Yiasemidou M, 2017, J SURG EDUC, V74, P108, DOI 10.1016/j.jsurg.2016.07.011
   Zahedi E, 2020, J INTELL ROBOT SYST, V98, P667, DOI 10.1007/s10846-019-01082-2
   Zaragoza-Siqueiros J, 2019, COMPUT METHOD BIOMEC, V22, P499, DOI 10.1080/10255842.2019.1566817
   Zhao YC, 2011, OTOLARYNG HEAD NECK, V144, P357, DOI 10.1177/0194599810391624
   Zheng F, 2011, PROC 5 INT C AUTOM R, P179, DOI [10.1109/ICARA.2011.6144878, DOI 10.1109/ICARA.2011.6144878]
   Zhou M, 2012, SURG ENDOSC, V26, P1128, DOI 10.1007/s00464-011-2011-8
   Zhou Y., 2013, Pattern-based real-time feedback for a temporal bone simulator, P7
   Zirkle M, 2007, LARYNGOSCOPE, V117, P258, DOI 10.1097/01.mlg.0000248246.09498.b4
   Zivanovic A, 2006, INT J HUM ROBOT, V3, P429, DOI 10.1142/S0219843606000849
   Zoller EI, 2020, INT J COMPUT ASS RAD, V15, P1797, DOI 10.1007/s11548-020-02258-0
NR 183
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1795
EP 1825
DI 10.1007/s10055-022-00666-y
EA JUL 2022
PG 31
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000824965500001
DA 2024-07-18
ER

PT J
AU Brunzini, A
   Papetti, A
   Messi, D
   Germani, M
AF Brunzini, Agnese
   Papetti, Alessandra
   Messi, Daniele
   Germani, Michele
TI A comprehensive method to design and assess mixed reality simulations
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Augmented reality; Simulation; Medical education; Stress;
   Cognitive load
ID AUGMENTED REALITY; LEARNING OUTCOMES; COGNITIVE LOAD; EDUCATION;
   FEATURES
AB The scientific literature highlights how Mixed Reality (MR) simulations allow obtaining several benefits in healthcare education. Simulation-based training, boosted by MR, offers an exciting and immersive learning experience that helps health professionals to acquire knowledge and skills, without exposing patients to unnecessary risks. High engagement, informational overload, and unfamiliarity with virtual elements could expose students to cognitive overload and acute stress. The implementation of effective simulation design strategies able to preserve the psychological safety of learners and the investigation of the impacts and effects of simulations are two open challenges to be faced. In this context, the present study proposes a method to design a medical simulation and evaluate its effectiveness, with the final aim to achieve the learning outcomes and do not compromise the students' psychological safety. The method has been applied in the design and development of an MR application to simulate the rachicentesis procedure for diagnostic purposes in adults. The MR application has been tested by involving twenty students of the 6(th) year of Medicine and Surgery of Universita Politecnica delle Marche. Multiple measurement techniques such as self-report, physiological indices, and observer ratings of performance, cognitive and emotional states of learners have been implemented to improve the rigour of the study. Also, a user-experience analysis has been accomplished to discriminate between two different devices: Vox Gear Plus (R) and Microsoft Hololens (R). To compare the results with a reference, students performed the simulation also without using the MR application. The use of MR resulted in increased stress measured by physiological parameters without a high increase in perceived workload. It satisfies the objective to enhance the realism of the simulation without generating cognitive overload, which favours productive learning. The user experience (UX) has found greater benefits in involvement, immersion, and realism; however, it has emphasized the technological limitations of devices such as obstruction, loss of depth (Vox Gear Plus), and narrow FOV (Microsoft Hololens).
C1 [Brunzini, Agnese; Papetti, Alessandra; Germani, Michele] Univ Politecn Marche, Dept Ind Engn & Math Sci, Ancona, Italy.
   [Messi, Daniele] Univ Politecn Marche, Fac Med & Surg, Ancona, Italy.
   [Messi, Daniele] Azienda Osped Univ Ospedali Riuniti, Ancona, Italy.
C3 Marche Polytechnic University; Marche Polytechnic University
RP Brunzini, A (corresponding author), Univ Politecn Marche, Dept Ind Engn & Math Sci, Ancona, Italy.
EM a.brunzini@staff.univpm.it
OI Brunzini, Agnese/0000-0003-0450-2510; Germani,
   Michele/0000-0003-1988-8620
FU Atheneum Strategic Project "StarLab: Simulation Training and
   Advanced-Research Lab" [Universita Politecnica delle Marche]
FX The work was funded by the Atheneum Strategic Project "StarLab:
   Simulation Training and Advanced-Research Lab" [Universita Politecnica
   delle Marche, 2017].
CR Adrario E., 2017, LETT FACOLTA B FACOL, V2, P5
   Adrario E., 2017, LETT FACOLTA B FACOL, V3, P4
   Atalay KD, 2016, J PAK MED ASSOC, V66, P574
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Bertolotto A, 2016, CEPHALALGIA, V36, P131, DOI 10.1177/0333102415583983
   Bosse HM, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0286-5
   Brunzini Agnese, 2021, Advances in Simulation and Digital Human Modeling. Proceedings of the AHFE 2020 Virtual Conferences on Human Factors and Simulation, and Digital Human Modeling and Applied Optimization. Advances in Intelligent Systems and Computing (AISC 1206), P343, DOI 10.1007/978-3-030-51064-0_44
   Brunzini Agnese, 2020, Advances in Human Factors in Training, Education, and Learning Sciences. Proceedings of the AHFE 2019 International Conference on Human Factors in Training, Education, and Learning Sciences. Advances in Intelligent Systems and Computing (AISC 963), P145, DOI 10.1007/978-3-030-20135-7_14
   Campisi C. A., 2020, Augmented Reality in Education. A New Technology for Teaching and Learning, P111, DOI [10.1007/978-3-030-42156-47, DOI 10.1007/978-3-030-42156-47]
   Chaballout Basil, 2016, JMIR Med Educ, V2, pe2
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Coles TR, 2011, IEEE T HAPTICS, V4, P199, DOI [10.1109/TOH.2011.32, 10.1109/ToH.2011.32]
   Cook DA, 2013, MED TEACH, V35, pE844, DOI 10.3109/0142159X.2012.714886
   Curtis MT, 2012, J CONTIN EDUC HEALTH, V32, P255, DOI 10.1002/chp.21153
   Dias RD, 2018, BRIT J SURG, V105, P491, DOI 10.1002/bjs.10795
   François C, 2016, INT J ENV RES PUB HE, V13, DOI 10.3390/ijerph13020174
   Fraser K, 2012, MED EDUC, V46, P1055, DOI 10.1111/j.1365-2923.2012.04355.x
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Garzón J, 2017, LECT NOTES COMPUT SC, V10324, P402, DOI 10.1007/978-3-319-60922-5_31
   Gattullo M, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P172, DOI 10.1109/ISMAR-Adjunct51615.2020.00054
   George A, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0164-z
   Gerup J, 2020, INT J MED EDUC, V11, DOI 10.5116/ijme.5e01.eb1a
   Goldberg MB, 2018, AM J SURG, V216, P618, DOI 10.1016/j.amjsurg.2017.11.040
   Gutierrez-Puerto E, 2015, COMM COM INF SC, V528, P174, DOI 10.1007/978-3-319-21380-4_31
   HART S G, 1988, P139
   Herron Jennifer, 2016, Journal of Electronic Resources in Medical Libraries, V13, P51, DOI 10.1080/15424065.2016.1175987
   Hong MS, 2021, VIRTUAL REAL-LONDON, V25, P491, DOI 10.1007/s10055-020-00469-z
   Kobayashi L, 2018, WEST J EMERG MED, V19, P158, DOI 10.5811/westjem.2017.10.35026
   Kotranza A, 2012, IEEE T VIS COMPUT GR, V18, P1101, DOI 10.1109/TVCG.2011.132
   Lesage FX, 2012, OCCUP MED-OXFORD, V62, P600, DOI 10.1093/occmed/kqs140
   Liang CJ, 2021, VIRTUAL REAL-LONDON, V25, P575, DOI 10.1007/s10055-020-00475-1
   Linde AS, 2019, MIL MED, V184, P72, DOI 10.1093/milmed/usy385
   Magee D, 2007, MED BIOL ENG COMPUT, V45, P957, DOI 10.1007/s11517-007-0231-9
   Mendes HCM, 2020, COMPUT MED IMAG GRAP, V82, DOI 10.1016/j.compmedimag.2020.101731
   Munzer BW, 2019, J MED INTERNET RES, V21, DOI 10.2196/12368
   Naismith LM, 2015, ACAD MED, V90, pS24, DOI 10.1097/ACM.0000000000000893
   Onda E.L., 2012, CLIN SIMUL NURS, V8, pe273, DOI DOI 10.1016/J.ECNS.2010.11.004
   Paul G, 2019, DHM AND POSTUROGRAPHY, P201, DOI 10.1016/B978-0-12-816713-7.00017-9
   Pheasant S., 1999, Body space-Anthropometry. Ergonomics and their Design of Work
   Rochlen LR, 2017, SIMUL HEALTHC, V12, P57, DOI 10.1097/SIH.0000000000000185
   Rodziewicz TL., 2021, STATPEARLS
   Roh YS, 2021, COLLEGIAN, V28, P184, DOI 10.1016/j.colegn.2020.06.007
   Salar R, 2020, J SCI EDUC TECHNOL, V29, P257, DOI 10.1007/s10956-019-09810-x
   Sarfati L, 2019, J EVAL CLIN PRACT, V25, P11, DOI 10.1111/jep.12883
   ScafO M., 2020, ADV INTELLIGENT SYST
   Sherstyuk A, 2011, HANDBOOK OF AUGMENTED REALITY, P479, DOI 10.1007/978-1-4614-0064-6_23
   Spielberger CD, 1983, State-trait anxiety inventory for adults, DOI DOI 10.1037/T06496-000
   Stawarczyk D, 2020, BIOL PSYCHOL, V156, DOI 10.1016/j.biopsycho.2020.107950
   Sugarindra M, 2017, IOP CONF SER-MAT SCI, V277, DOI 10.1088/1757-899X/277/1/012022
   Tai YH, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719840173
   Wang S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102294
   WHO World Health Organization Data and Statistics, 2017, REG OFF EUR
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Zhu EG, 2014, PEERJ, V2, DOI 10.7717/peerj.469
NR 54
TC 7
Z9 7
U1 3
U2 34
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1257
EP 1275
DI 10.1007/s10055-022-00632-8
EA FEB 2022
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000750684800002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Jiménez-Rodríguez, C
   Yélamos-Capel, L
   Salvestrini, P
   Pérez-Fernández, C
   Sánchez-Santed, F
   Nieto-Escámez, F
AF Jimenez-Rodriguez, Carmen
   Yelamos-Capel, Lourdes
   Salvestrini, Patricia
   Perez-Fernandez, Cristian
   Sanchez-Santed, Fernando
   Nieto-Escamez, Francisco
TI Rehabilitation of visual functions in adult amblyopic patients with a
   virtual reality videogame: a case series
SO VIRTUAL REALITY
LA English
DT Article
DE Amblyopia; Visual acuity; Contrast sensitivity; Stereopsis; Videogame;
   Virtual reality
ID IMPROVES CONTRAST SENSITIVITY; BINOCULAR VISION; ACUITY; DEPRIVATION;
   CHILDREN; PLASTICITY; STEREOPSIS; RECOVERY; DEFICITS; BRAIN
AB Amblyopia or lazy eye is a dysfunction of the visual system that appears during childhood and traditionally has been considered untreatable in adults. Its main consequences are the loss of visual acuity and contrast sensitivity of the amblyopic eye and binocular vision impairments. During the last years videogames have been used as a therapeutic tool for amblyopia with the inconclusive results. The present work has assessed the effectiveness of a virtual reality videogame (AmbliOK (R)) in the neurorehabilitation of four adult clinical cases with anisometropic amblyopia. Visual acuity, contrast sensitivity, stereopsis and interocular suppression were assessed before, during, immediately after, one month and one year (in one patient) after the training. The intervention was conducted along four weeks (10 h) and yielded the variable results. In general, all patients showed an improvement in visual functions although not all ameliorated in the same way. Visual acuity measures improved in all patients, falling outside the amblyopia criterion at the end of the treatment. However, the improvement was not maintained one month later in two patients. Contrast sensitivity progressively improved for the amblyopic and the fellow eyes with all patients showing better results one month after the treatment. The patient assessed one year after still showed better results than in the baseline. Patients showing bad stereopsis in the baseline reached a performance considered normal one month and even one year after the treatment. The effectiveness of the treatment seems to be related to the characteristics of patients.
C1 [Jimenez-Rodriguez, Carmen; Yelamos-Capel, Lourdes; Perez-Fernandez, Cristian; Sanchez-Santed, Fernando; Nieto-Escamez, Francisco] Univ Almeria, Dept Psychol, Ctra Sacramento S-N, Almeria 04120, Spain.
   [Nieto-Escamez, Francisco] Ctr Neurorehabil & Neuropsychol Assessment CERNEP, Ctra Sacramento S-N, Almeria 04120, Spain.
   [Sanchez-Santed, Fernando] Ctr Hlth Res CEINSA, Ctra Sacramento S-N, Almeria 04120, Spain.
   [Salvestrini, Patricia] Vithas Virgen del Mar Hosp, QVis, Ctra Mami Km 1, Almeria 04120, Spain.
   [Nieto-Escamez, Francisco] NeuroDigital Technol SL, Plaza Dalias S-N, Almeria 04007, Spain.
   [Sanchez-Santed, Fernando] Inst Child Neurohabilitat INPAULA, C Angel Gomez Fuentes 11, Almeria 04007, Spain.
C3 Universidad de Almeria
RP Nieto-Escámez, F (corresponding author), Univ Almeria, Dept Psychol, Ctra Sacramento S-N, Almeria 04120, Spain.; Nieto-Escámez, F (corresponding author), Ctr Neurorehabil & Neuropsychol Assessment CERNEP, Ctra Sacramento S-N, Almeria 04120, Spain.; Nieto-Escámez, F (corresponding author), NeuroDigital Technol SL, Plaza Dalias S-N, Almeria 04007, Spain.
EM pnieto@ual.es
RI Pérez-Fernández, Cristian Antonio/ABG-6514-2021; Nieto-Escamez,
   Francisco Antonio/L-4460-2014
OI Pérez-Fernández, Cristian Antonio/0000-0001-6675-2086; Nieto-Escamez,
   Francisco Antonio/0000-0001-5301-9475
FU CRUE-CSIC agreement; Springer Nature; FIS [PS09-01,163]; MINECO
   [PSI2014-55,785-C2-1-R]; EU FEDER funds [PSI2014-55,785-C2-1-R]; ONCE
   scholarship "Oportunidad al Talento"
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research was supported by research grants
   PS09-01,163 from FIS, and PSI2014-55,785-C2-1-R from MINECO and EU FEDER
   funds. Ms. C.J.R is funded by an ONCE scholarship "Oportunidad al
   Talento" for PhD students.
CR Antonini A, 1999, J NEUROSCI, V19, P4388
   Arlati S, 2017, LECT NOTES COMPUT SC, V10325, P86, DOI 10.1007/978-3-319-60928-7_8
   Barollo M, 2017, RESTOR NEUROL NEUROS, V35, P483, DOI 10.3233/RNN-170731
   Barrett BT, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036611
   Berardi N, 2003, TRENDS NEUROSCI, V26, P369, DOI 10.1016/S0166-2236(03)00168-1
   Bonaccorsi J, 2014, FRONT NEURAL CIRCUIT, V8, DOI 10.3389/fncir.2014.00082
   Capetillo Biart Odalys, 2011, Rev Cubana Pediatr, V83, P372
   Casco C, 2014, RESTOR NEUROL NEUROS, V32, P639, DOI 10.3233/RNN-140389
   Chen YY, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01364
   Cleary M, 2009, EYE, V23, P124, DOI 10.1038/sj.eye.6702977
   Coco-Martin MB, 2020, J OPHTHALMOL, V2020, DOI 10.1155/2020/7067846
   Ding J, 2011, P NATL ACAD SCI USA, V108, pE733, DOI 10.1073/pnas.1105183108
   Fagiolini M, 2000, NATURE, V404, P183, DOI 10.1038/35004582
   Fawcett SL, 2003, J AAPOS, V7, P333, DOI 10.1016/S1091-8531(03)00170-8
   Foss AJE, 2017, CURR OPIN OPHTHALMOL, V28, P276, DOI 10.1097/ICU.0000000000000358
   Gambacorta C, 2018, VISION RES, V148, P1, DOI 10.1016/j.visres.2018.04.005
   Gao TY, 2018, JAMA OPHTHALMOL, V136, P172, DOI 10.1001/jamaophthalmol.2017.6090
   Halicka J, 2020, Cesk Slov Oftalmol, V76, P24, DOI 10.31348/2020/3
   Hamm LM, 2018, CLIN EXP OPTOM, V101, P541, DOI 10.1111/cxo.12630
   Harrad R, 1996, EYE, V10, P270, DOI 10.1038/eye.1996.57
   HARRAD RA, 1992, VISION RES, V32, P2135, DOI 10.1016/0042-6989(92)90075-T
   HARWERTH RS, 1983, AM J OPTOM PHYS OPT, V60, P454
   Hayhoe M, 2009, VISUAL NEUROSCI, V26, P73, DOI 10.1017/S0952523808080838
   He HY, 2007, NAT NEUROSCI, V10, P1134, DOI 10.1038/nn1965
   He HY, 2006, J NEUROSCI, V26, P2951, DOI 10.1523/JNEUROSCI.5554-05.2006
   Herbison N, 2013, EYE, V27, P1077, DOI 10.1038/eye.2013.113
   Hernández-Rodríguez CJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9123985
   Hess RF, 2011, STRABISMUS, V19, P110, DOI 10.3109/09273972.2011.600418
   Hess RF, 2013, J AAPOS, V17, P89, DOI 10.1016/j.jaapos.2012.10.018
   HOLOPIGIAN K, 1986, VISION RES, V26, P621, DOI 10.1016/0042-6989(86)90010-6
   Huang CB, 2008, P NATL ACAD SCI USA, V105, P4068, DOI 10.1073/pnas.0800824105
   Huang CB, 2011, J VISION, V11, DOI 10.1167/11.6.4
   JULESZ B, 1975, PERCEPTION, V4, P125, DOI 10.1068/p040125
   Kanski J J., 2016, Kanski Oftalmologia Clinica: Uma abordagem sistemica
   Levi DM, 2015, VISION RES, V114, P17, DOI 10.1016/j.visres.2015.01.002
   Levi DM, 2009, VISION RES, V49, P2535, DOI 10.1016/j.visres.2009.02.010
   Li JR, 2013, CURR BIOL, V23, pR308, DOI 10.1016/j.cub.2013.01.059
   Li RW, 2007, INVEST OPHTH VIS SCI, V48, P5046, DOI 10.1167/iovs.07-0324
   Mansouri B, 2014, STRABISMUS, V22, P1, DOI 10.3109/09273972.2013.877945
   Mataga N, 2004, NEURON, V44, P1031, DOI 10.1016/j.neuron.2004.11.028
   McColl SL, 2000, VISION RES, V40, P1167, DOI 10.1016/S0042-6989(00)00025-0
   McKee SP, 2003, J VISION, V3, P380, DOI 10.1167/3.5.5
   Meier K, 2017, INVEST OPHTH VIS SCI, V58, P1779, DOI 10.1167/iovs.16-20964
   Merchante Alc?ntara MM, 2013, PEDIAT INTEGR, VXVII, P489
   Mitchell DE, 2003, CURR BIOL, V13, P1704, DOI 10.1016/j.cub.2003.09.026
   Moret B, 2018, NEUROPSYCHOLOGIA, V114, P125, DOI 10.1016/j.neuropsychologia.2018.04.017
   Nabie R, 2019, J OPHTHAL VIS RES, V14, P48, DOI 10.4103/jovr.jovr_189_17
   OGLE KN, 1967, VISION RES, V7, P89, DOI 10.1016/0042-6989(67)90029-6
   Oray S, 2004, NEURON, V44, P1021, DOI 10.1016/j.neuron.2004.12.001
   Paudel N, 2018, TELEMED E-HEALTH, V24, P797, DOI 10.1089/tmj.2017.0220
   Polat U, 1999, SPATIAL VISION, V12, P143, DOI 10.1163/156856899X00094
   Polat U, 2004, P NATL ACAD SCI USA, V101, P6692, DOI 10.1073/pnas.0401200101
   Polat U, 2009, EXPERT REV OPHTHALMO, V4, P573, DOI 10.1586/EOP.09.54
   Robaei D, 2007, J AAPOS, V11, P356, DOI 10.1016/j.jaapos.2006.11.111
   Rodrigo-Guzm?n J., 1997, TRATADO OFTALMOLOGIA
   Saraiva AA, 2018, INFORMATION, V9, DOI 10.3390/info9070175
   Smith SL, 2007, NAT NEUROSCI, V10, P370, DOI 10.1038/nn1844
   Spolidoro M, 2009, EXP BRAIN RES, V192, P335, DOI 10.1007/s00221-008-1509-3
   Sumnall JH, 2000, J OPT SOC AM A, V17, P687, DOI 10.1364/JOSAA.17.000687
   Varadharajan S, 2012, J AAPOS, V16, P41, DOI 10.1016/j.jaapos.2011.09.016
   Vedamurthy I, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0264
   von Noorden G. K., 1996, Binocular vision and ocular motility: Theory and management of strabismus, V5th
   VONNOORDEN GK, 1981, AM J OPHTHALMOL, V92, P416, DOI 10.1016/0002-9394(81)90534-1
   Waddingham PE, 2006, EYE, V20, P375, DOI 10.1038/sj.eye.6701883
   Zhou YF, 2006, VISION RES, V46, P739, DOI 10.1016/j.visres.2005.07.031
   Ziak P, 2017, BMC OPHTHALMOL, V17, DOI 10.1186/s12886-017-0501-8
NR 66
TC 8
Z9 8
U1 3
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 385
EP 396
DI 10.1007/s10055-021-00605-3
EA NOV 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000719734300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Harborth, D
   Kümpers, K
AF Harborth, David
   Kumpers, Katharina
TI Intelligence augmentation: rethinking the future of work by leveraging
   human performance and abilities
SO VIRTUAL REALITY
LA English
DT Article
DE Intelligence augmentation; Artificial intelligence; Future of work;
   Changes in labor markets; Augmented reality; Virtual reality;
   Human-enhancing technologies
ID VIRTUAL-REALITY; MAINTENANCE; SKILLS; DESIGN; ACQUISITION; EMPLOYMENT;
   TRAINER; SYSTEMS; ROBOTS; AIDS
AB Nowadays, digitalization has an immense impact on the landscape of jobs. This technological revolution creates new industries and professions, promises greater efficiency and improves the quality of working life. However, emerging technologies such as robotics and artificial intelligence (AI) are reducing human intervention, thus advancing automation and eliminating thousands of jobs and whole occupational images. To prepare employees for the changing demands of work, adequate and timely training of the workforce and real-time support of workers in new positions is necessary. Therefore, it is investigated whether user-oriented technologies, such as augmented reality (AR) and virtual reality (VR) can be applied "on-the-job" for such training and support-also known as intelligence augmentation (IA). To address this problem, this work synthesizes results of a systematic literature review as well as a practically oriented search on augmented reality and virtual reality use cases within the IA context. A total of 150 papers and use cases are analyzed to identify suitable areas of application in which it is possible to enhance employees' capabilities. The results of both, theoretical and practical work, show that VR is primarily used to train employees without prior knowledge, whereas AR is used to expand the scope of competence of individuals in their field of expertise while on the job. Based on these results, a framework is derived which provides practitioners with guidelines as to how AR or VR can support workers at their job so that they can keep up with anticipated skill demands. Furthermore, it shows for which application areas AR or VR can provide workers with sufficient training to learn new job tasks. By that, this research provides practical recommendations in order to accompany the imminent distortions caused by AI and similar technologies and to alleviate associated negative effects on the German labor market.
C1 [Harborth, David; Kumpers, Katharina] Goethe Univ, Theodor W Adorno Pl 4, D-60323 Frankfurt, Germany.
C3 Goethe University Frankfurt
RP Harborth, D (corresponding author), Goethe Univ, Theodor W Adorno Pl 4, D-60323 Frankfurt, Germany.
EM dayid.harborth@m-chair.de
RI Buttree, Matthew/JSK-8811-2023
OI Harborth, David/0000-0001-9554-7567
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR 8ninths, 2016, 8NINTHS HOM
   ACEMOGLU D, 2011, HBK ECON, V4, P1043, DOI [DOI 10.1016/S0169-7218(11)02410-5, 10.1016/S0169-7218(11)02410-5]
   Acemoglu D, 2018, NATL BUR EC RES
   Acosta, 2019, AUSTRALAS J EDUC TEC
   Aehnelt M, 2016, IWOAR 2018 5 INT WOR
   Agrawal R, 2020, ISS '20 COMPANION: COMPANION PROCEEDINGS OF THE 2020 CONFERENCE ON INTERACTIVE SURFACES AND SPACES, P23, DOI 10.1145/3380867.3426199
   Alaraj A, 2013, NEUROSURGERY, V72, pA115, DOI 10.1227/NEU.0b013e3182753093
   Anastassova M, 2009, APPL ERGON, V40, P713, DOI 10.1016/j.apergo.2008.06.008
   [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450608
   [Anonymous], 2017, MICROSOFT HOLOLENS
   AR Check, 2020, REV GAM CHANG NEW SY
   Aromaa S., 2016, Proceedings of the 20th International Academic Mindtrek Conference, P235, DOI DOI 10.1145/2994310.2994321
   García AA, 2016, VIRTUAL REAL-LONDON, V20, P27, DOI 10.1007/s10055-015-0280-6
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Babu AR, 2017, LECT NOTES COMPUT SC, V10280, P203, DOI 10.1007/978-3-319-57987-0_16
   Bacca J, 2015, PROCEDIA COMPUT SCI, V75, P49, DOI 10.1016/j.procs.2015.12.203
   Baechler A, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769528
   Behzadan AH, 2011, WINT SIMUL C PROC, P3568, DOI 10.1109/WSC.2011.6148051
   Belani M, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375027
   Berufenet, 2020, BERUFSINFORMATION
   Berufenet, 2020, DATA SCI
   Bluemel E., 2009, INT J ADV CORPORATE, DOI [10.3991/ijac.v2i2.870, DOI 10.3991/IJAC.V2I2.870]
   BMW, 2018, VID HER BMW IS US MI
   Boboc RG, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124259
   Boell SK, 2014, COMMUN ASSOC INF SYS, V34, P257
   Boing, 2018, BOEING TESTS AUGM RE
   Bonin H., 2015, Ubertragung der Studie von Frey/Osborne (2013) auf Deutschland
   Bosch T, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P412, DOI 10.1145/3056540.3076189
   Bosche F, 2018, MIXED REALITY SYSTEM
   Bosché F, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000479
   Bossler M, 2017, LAGE ENTWICKLUNG ARB
   Boud A. C., 1999, 1999 IEEE International Conference on Information Visualization (Cat. No. PR00210), P32, DOI 10.1109/IV.1999.781532
   Boud AC, 1998, P ICAT 98, P124
   Brouwer N., 2014, BEITRAGE LEHRERINNEN, V32, P176, DOI [10.36950/bzl.32.2014.9611, DOI 10.25656/01:13864]
   Brynjolfsson E., 2011, RACE MACHINE DIGITAL
   Büttner S, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P433, DOI 10.1145/3056540.3076193
   Büttner S, 2017, LECT NOTES COMPUT SC, V10217, P33, DOI 10.1007/978-3-319-56997-0_3
   Buslei H, 2018, ARBEITSKRAFTE ARBEIT
   Butte Sujata, 2016, 2016 IEEE Workshop on Microelectronics and Electron Devices (WMED), P1, DOI 10.1109/WMED.2016.7458273
   Camilleri V, 2013, P 3 INT C LEARN AN K, P230, DOI DOI 10.1145/2460296.2460341
   Carruth DW, 2017, 2017 15TH IEEE INTERNATIONAL CONFERENCE ON EMERGING ELEARNING TECHNOLOGIES AND APPLICATIONS (ICETA 2017), P75
   Caterpillar, 2019, CAT VIRT REAL TRAIN
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   CHASE RC, 1958, VOCAT GUID QUART, V7, P77, DOI 10.1002/j.2164-585X.1958.tb00378.x
   Cheung, 2016, DEV PRACTICAL VOCATI
   Chunxia Li, 2010, 2010 9th International Conference on Information Technology Based Higher Education and Training (ITHET 2010), P232, DOI 10.1109/ITHET.2010.5480076
   Daqri, 2016, DAQRI AUGM WORLD EXP
   DAVIS MM, 1991, DECISION SCI, V22, P421, DOI 10.1111/j.1540-5915.1991.tb00356.x
   Dayagdag CV, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ENVIRONMENT, ENERGY AND APPLICATIONS (IAEA 2019), P253, DOI 10.1145/3323716.3323755
   DDI, VIRT REAL INCL EXP
   de Ribaupierre S., 2014, VIRTUAL, P9, DOI DOI 10.1007/978-3-642-54816-1_2
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   Degryse C., 2016, SSRN Electronic Journal, DOI [10.2139/ssrn.2730550, DOI 10.2139/SSRN.2730550, 10.2139/SSRN.2730550]
   Dengler K., 2015, 112015 IAB
   Dengler K, 2018, TECHNOL FORECAST SOC, V137, P304, DOI 10.1016/j.techfore.2018.09.024
   Deutsche Bahn, 2018, IMM TECHN DTSCH BAHN
   DHL Coca-Cola, 2019, AUGM REAL LOG CHANG
   Dong Zhao, 2009, Proceedings of the 2009 Winter Simulation Conference (WSC 2009), P2679, DOI 10.1109/WSC.2009.5429258
   ELLIOTT SN, 1993, BEHAV MODIF, V17, P287, DOI 10.1177/01454455930173004
   Enel, 2017, EN SANT PIS 3D SIM S
   Engadget, 2019, ENG IS NOW PART VER
   Engelbart, 1962, AUGMENTING HUMAN INT, DOI DOI 10.21236/AD0289565
   Esen H., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3631
   Fang XD, 1998, COMPUT APPL ENG EDUC, V6, P89, DOI 10.1002/(SICI)1099-0542(1998)6:2<89::AID-CAE4>3.0.CO;2-W
   Federal Statistical Office, 2020, ERW ALT MENCH
   Ford, 2019, FORD COLL GRAV SKETC
   Ford, 2017, HOL BEIM FAHR DES FO
   Fred, 2020, UN RAT AG 15 74 ALL
   Freiherr von Lukas U., 2019, J MOBILITAT VERKEHR, V4, P32, DOI [10.34647/jmv.nr4.id30, DOI 10.34647/JMV.NR4.ID30]
   Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019
   Friedrich W, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P3, DOI 10.1109/ISMAR.2002.1115059
   Funk, 2016, MOTIONEAP OVERVIEW 4
   Funk M., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments-PETRA '16, P1, DOI [DOI 10.1145/2910674.2910730, 10.1145/2910674.2910683, DOI 10.1145/2910674.2910683]
   Funk M, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P222, DOI 10.1145/3056540.3056548
   Funk M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P185, DOI 10.1145/2700648.2809853
   Funk M, 2015, IEEE PERVAS COMPUT, V14, P53, DOI 10.1109/MPRV.2015.53
   Gallagher AG, 1999, ENDOSCOPY, V31, P310
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Girman M., 2009, MANAGEMENT SERVICES, V53, P44
   Glockner H., 2014, Augmented reality in logistics: Changing the way we see logistics--a DHL Perspective
   Goulding J, 2012, ADV ENG INFORM, V26, P103, DOI 10.1016/j.aei.2011.09.004
   Gouthier M, 2007, HALLESCHE SCHRIFTEN
   Guanyang Liu, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P2220, DOI 10.1109/BMEI.2011.6098650
   Guo F, 2015, ACSR ADV COMPUT, P615
   Gupta S, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P411, DOI 10.1145/3316782.3324016
   Gutiérrez T, 2010, 2010 IEEE RO-MAN, P428, DOI 10.1109/ROMAN.2010.5598643
   Hamilton EC, 2002, SURG ENDOSC, V16, P406, DOI 10.1007/s00464-001-8149-z
   Haslwanter JDH, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P333, DOI 10.1145/3316782.3322746
   Hertzfeld E., 2019, Hotel Management
   Hofmann, 2018, ARBT AUGMENTED REALI, DOI [10.18420/muc2018-ws07-0415, DOI 10.18420/MUC2018-WS07-0415]
   Horejsí P, 2015, PROCEDIA ENGINEER, V100, P699, DOI 10.1016/j.proeng.2015.01.422
   Huber T, 2017, SURG ENDOSC, V31, P4472, DOI 10.1007/s00464-017-5500-6
   Hughes K., 2005, P 2005 C DES US EXPE
   Immerse, 2019, DHL CARG LOAD TRAIN
   Irizarry J., 2005, P 2005 ASCE INT C CO, P1, DOI [10.1061/40794(179)148, DOI 10.1061/40794(179)148]
   JANIN AL, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P246, DOI 10.1109/VRAIS.1993.380772
   Jantjies M, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY MANAGEMENT (ICETM 2018), P42, DOI 10.1145/3300942.3300956
   JAYARAM J.S.R., 1999, INT J QUALITY RELIAB, V12, P826
   Jose J, 2015, IEEE INT S HAPT AUD, P65
   Karabegovic I, 2015, ADV PROD ENG MANAG, V10, P185, DOI 10.14743/apem2015.4.201
   Keke Lu, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P1449, DOI 10.1109/ICMA.2010.5588998
   Kenn H, 2014, INT S WEAR COMP ISWC, P209
   Kessler T, 2016, PHANTOM EXMACHINA DI, P107
   Keynes J.M., 1930, Essays in Persuasion, P358, DOI DOI 10.1007/978-1-349-59072-8_25
   Klinger, 2014, Wirtschaftsdienst, V10, P756, DOI DOI 10.1007/S10273-014-1744-0
   Knopp S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P607, DOI 10.1109/VR.2018.8446614
   Kohn Vanessa, 2018, 26 EUROPEAN C INFORM, P1
   Korn O, 2015, P 7 ACM SIGCHI S ENG, ppp84, DOI DOI 10.1145/2774225.2774834
   Lafreniere B, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P15, DOI 10.1145/2984511.2984553
   Lai C.L., 2019, ACM INT C PROCEEDING, P57, DOI [10.1145/3369199.3369230, DOI 10.1145/3369199.3369230]
   Lau CW, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290722
   Lee IJ, 2023, INTERACT LEARN ENVIR, V31, P1448, DOI 10.1080/10494820.2020.1841799
   Lin Patrick., 2008, Autonomous Military Robotics: Risk, Ethics, and Design, DOI DOI 10.21236/ADA534697
   Makridakis S, 2017, FUTURES, V90, P46, DOI 10.1016/j.futures.2017.03.006
   Manyika J., 2017, JOBS LOST JOBS GAIN, P1
   Matsas E, 2017, INT J INTERACT DES M, V11, P139, DOI 10.1007/s12008-015-0259-2
   Matthes B, 2015, METHODENBERICHT BERU
   Mayer RE, 2002, LEARN INSTR, V12, P107, DOI 10.1016/S0959-4752(01)00018-4
   McCarthy, 2015, VIRT REAL IS CHANG C
   McClean Phillip, 2005, Cell Biol Educ, V4, P169, DOI 10.1187/cbe.04-07-0047
   McLellan H., 1996, Handbook of research for educational communications and technology, P457
   Mekacher L., 2019, Int. J. Teach. Educ. Learn., V3, P118
   Mesaros P., 2016, 2016 International Conference on Emerging eLearning Technologies and Applications (ICETA). Proceedings, P211, DOI 10.1109/ICETA.2016.7802094
   Michahelles F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P697, DOI 10.1145/3123024.3129270
   Mitsubishi Electric Corporation, 2016, MITS EL ENTW AR TECH
   Mizutani I, 2017, 7 INT C INT THINGS, P1
   MLM Group, 2018, MLM GROUP EXP AUGM R
   Mohammed MI, 2018, VIRTUAL PHYS PROTOTY, V13, P164, DOI 10.1080/17452759.2018.1446122
   Mostafa AE, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P20, DOI 10.1145/3131277.3132174
   Muller, 2005, MARVEL MECHATRONICS
   Muller, 2007, MIXED REALITY LEARNI
   Nedelkoska L., 2018, OECD SOCIAL EMPLOYME, DOI [10.1787/2e2f4eea-en, DOI 10.1787/2E2F4EEA-EN]
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   O'Hare, 2018, AUGM REAL HELPS SURG
   Ong SK, 2007, CIRP ANN-MANUF TECHN, V56, P49, DOI 10.1016/j.cirp.2007.05.014
   Pan JJ, 2015, INT J MED ROBOT COMP, V11, P194, DOI 10.1002/rcs.1582
   Parks JA, 2010, HYPATIA, V25, P100, DOI 10.1111/j.1527-2001.2009.01086.x
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Pena-Rios A, 2017, 2017 IEEE INT C FUZZ, P1
   Peña-Rios A, 2016, IEEE INT FUZZY SYST, P408, DOI 10.1109/FUZZ-IEEE.2016.7737716
   Pilgrim M, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P369, DOI 10.1109/IV.2001.942084
   Ponder M, 2003, P WORKSH VIRT ENV, P97, DOI DOI 10.1145/769953.769965
   Rajeswaran P, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1345, DOI [10.1109/vr.2019.8797998, 10.1109/VR.2019.8797998]
   Rajeswaran P, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1130, DOI 10.1109/VR.2019.8798249
   Ramioul M, 2007, TATUP Z TECH THEOR P, V16, P13, DOI [10.14512/tatup.16.2.13, DOI 10.14512/TATUP.16.2.13]
   Re'flekt GmbH, 2019, UNS KUND ERZ MESS RE
   Regenbrecht H, 2005, IEEE COMPUT GRAPH, V25, P48, DOI 10.1109/MCG.2005.124
   Reif R, 2008, VISUAL COMPUT, V24, P987, DOI 10.1007/s00371-008-0271-7
   Rhein, 2010, 192010 IAB KURZB, V19
   RIEBER LP, 1990, ETR&D-EDUC TECH RES, V38, P77, DOI 10.1007/BF02298250
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robert Bosch Gmbh, 2019, BOSCH BRINGT SEIN AU
   ROBERTSON GG, 1993, COMPUTER, V26, P81, DOI 10.1109/2.192002
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Saggiomo M, 2016, P ANN HICSS, P560, DOI 10.1109/HICSS.2016.76
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sarupuri B, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P59, DOI [10.1109/ISMAR-Adjunct.2016.32, 10.1109/ISMAR-Adjunct.2016.0039]
   Sastry L., 1998, Virtual Reality, V3, P235, DOI 10.1007/BF01408704
   Schild J, 2018, IEEE INT CONF SERIOU
   Schmudlach, 2000, INTERACTIVE POSTERS
   Schuster, 2015, PREPARING IND 4 0 CO
   Schwald B, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P425
   Schwerdtfeger B, 2008, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2008.4637331
   SentiAR, 2018, SENTIAR REALT CLIN A
   Sievers TS, 2020, Procedia Manufacturing, V45, P19, DOI [10.1016/j.promfg.2020.04.034, DOI 10.1016/J.PROMFG.2020.04.034]
   Simon, 2014, DEV ADV MAINTENANCE, DOI [10.13140/2.1.5103.9685, DOI 10.13140/2.1.5103.9685]
   Sivanathan A, 2017, PROC ASME DES ENG TE
   Smith Group, 2018, AR IS IND DES CONSTR
   Spilski, 2019, POTENTIAL VR VOCATIO
   SQUIRE LR, 1992, J COGNITIVE NEUROSCI, V4, P232, DOI 10.1162/jocn.1992.4.3.232
   Steuerwald, 2019, NEUE AR APP IKEA PLA
   Tang Kevin S, 2020, Can Med Educ J, V11, pe81, DOI 10.36834/cmej.61705
   Thomas BH, 2009, IEEE PERVAS COMPUT, V8, P8, DOI 10.1109/MPRV.2009.38
   Thyssenkrupp, 2017, MOB BIS INS HOH ALT
   Tzafestas CS, 2008, PRESENCE-VIRTUAL AUG, V17, P212, DOI 10.1162/pres.17.2.212
   UK Commission for Employment and Accounts, 2016, UK COMM EMPL SKILLS
   UPS, 2019, UPS ENH DRIV SAF TRA
   Van Wyk E., 2009, P 6 INT C COMP GRAPH, P53, DOI DOI 10.1145/1503454.1503465
   Van Wyk E, 2014, P SO AFR I COMP SCI, P70, DOI DOI 10.1145/2664591.2664627
   van Wyk E., 2008, Proceedings of the 2008 Annual Research Conference of the South African institute of Computer Scientists and information Technologists on IT Research in Developing Countries: Riding the Wave of Technology (Wilderness, South Africa, October 06 - 08, V338, P276, DOI [DOI 10.1145/1456659.1456691, 10.1145/1456659.1456691]
   Viscopic, 2019, VISC UNS ANS
   Vom BrockeJ., 2009, ECIS, P2206
   VW, 2019, VOLKSW UNV MARTA IOS
   Wakingapp, 2019, PROFESSIONAL AUGMENT
   Walker Z, 2019, J VOCAT REHABIL, V51, P87, DOI 10.3233/JVR-191028
   Walmart, 2018, VR IS TRANSF WAY WE
   Wang XY, 2006, J COMPUT CIVIL ENG, V20, P437, DOI 10.1061/(ASCE)0887-3801(2006)20:6(437)
   Wang XY, 2007, J INF TECHNOL CONSTR, V12, P363
   Warning A, 2017, 122017 IAB KURZB
   Watanuki K, 2007, J ADV MECH DES SYST, V1, P48, DOI 10.1299/jamdsm.1.48
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Webster A, 1996, COMPUTING IN CIVIL ENGINEERING, P913
   Webster J, 2002, MIS QUART, V26, pXIII
   Werrlich S., 2017, International Journal of Computer and Information Engineering, V11, P1068
   Williams, 2019, REALITY CHECK AR CAN
   Wilschut ES, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P376, DOI 10.1145/3316782.3322750
   Wolter MI, 2016, EC 4 0 ITS LABOUR MA, V201613
   Woyke, 2019, AUGMENTED REALITY CO
   Wu W, 2018, PROC FRONT EDUC CONF
   Xia C., 2013, ACM INT C PROCEEDING, P154, DOI [https://doi.org/10.1145/2459236.2459263, DOI 10.1145/2459236.2459263]
   Yin, 2017, INT C INT US INT, P193
   Zhang JL, 2018, PROCEEDINGS CVMP 2018: THE 15TH ACM SIGGRAPH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/3278471.3278474
   Zheng XJS, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2125, DOI 10.1145/2702123.2702305
   Zinn B., 2015, J TECHNICAL ED JOTED, V3
NR 205
TC 8
Z9 8
U1 12
U2 72
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 849
EP 870
DI 10.1007/s10055-021-00590-7
EA NOV 2021
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000716292800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Rohrbach, N
   Hermsdörfer, J
   Huber, LM
   Thierfelder, A
   Buckingham, G
AF Rohrbach, Nina
   Hermsdoerfer, Joachim
   Huber, Lisa-Marie
   Thierfelder, Annika
   Buckingham, Gavin
TI Fooling the size-weight illusion-Using augmented reality to eliminate
   the effect of size on perceptions of heaviness and sensorimotor
   prediction
SO VIRTUAL REALITY
LA English
DT Article
DE Weight illusions; Perception; Sensorimotor control; Virtual reality;
   Holograms
AB Augmented reality, whereby computer-generated images are overlaid onto the physical environment, is becoming significant part of the world of education and training. Little is known, however, about how these external images are treated by the sensorimotor system of the user - are they fully integrated into the external environmental cues, or largely ignored by low-level perceptual and motor processes? Here, we examined this question in the context of the size-weight illusion (SWI). Thirty-two participants repeatedly lifted and reported the heaviness of two cubes of unequal volume but equal mass in alternation. Half of the participants saw semi-transparent equally sized holographic cubes superimposed onto the physical cubes through a head-mounted display. Fingertip force rates were measured prior to lift-off to determine how the holograms influenced sensorimotor prediction, while verbal reports of heaviness after each lift indicated how the holographic size cues influenced the SWI. As expected, participants who lifted without augmented visual cues lifted the large object at a higher rate of force than the small object on early lifts and experienced a robust SWI across all trials. In contrast, participants who lifted the (apparently equal-sized) augmented cubes used similar force rates for each object. Furthermore, they experienced no SWI during the first lifts of the objects, with a SWI developing over repeated trials. These results indicate that holographic cues initially dominate physical cues and cognitive knowledge, but are dismissed when conflicting with cues from other senses.
C1 [Rohrbach, Nina; Hermsdoerfer, Joachim; Huber, Lisa-Marie; Thierfelder, Annika] Tech Univ Munich, Dept Sport & Hlth Sci, Chair Human Movement Sci, Munich, Germany.
   [Buckingham, Gavin] Univ Exeter, Dept Sport & Hlth Sci, Exeter, Devon, England.
C3 Technical University of Munich; University of Exeter
RP Rohrbach, N (corresponding author), Tech Univ Munich, Dept Sport & Hlth Sci, Chair Human Movement Sci, Munich, Germany.
EM nina.rohrbach@tum.de
RI Buckingham, Gavin/A-8715-2008
OI Thierfelder, Annika/0000-0001-6095-6942; Rohrbach,
   Nina/0000-0003-4474-9999
FU Bavarian State Ministry of Science and the Arts; Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. NR
   acknowledges support through a fellowship of the Bavarian State Ministry
   of Science and the Arts and coordinated by the Bavarian Research
   Institute for Digital Transformation (bidt).
CR Ahn J-g, 2019, INT C HUM COMP INT, P337
   Al-Issa H, 2012, PHYS THER REV, V17, P16, DOI 10.1179/1743288X11Y.0000000051
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Amazeen EL, 1996, J EXP PSYCHOL HUMAN, V22, P213, DOI 10.1037/0096-1523.22.1.213
   [Anonymous], 1891, Archiv Physiol Norm Pathol
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Buckingham G, 2019, Q J EXP PSYCHOL, V72, P2168, DOI 10.1177/1747021819835808
   Buckingham G, 2016, Q J EXP PSYCHOL, V69, P1831, DOI 10.1080/17470218.2015.1100642
   Buckingham G, 2015, PSYCHOL SCI, V26, P237, DOI 10.1177/0956797614561267
   Buckingham G, 2014, EXP BRAIN RES, V232, P1623, DOI 10.1007/s00221-014-3926-9
   Buckingham G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054709
   Buckingham G, 2011, J VISION, V11, DOI 10.1167/11.1.4
   DAVIS CM, 1976, PERCEPT PSYCHOPHYS, V20, P33, DOI 10.3758/BF03198701
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dijker AJM, 2014, PSYCHON B REV, V21, P1404, DOI 10.3758/s13423-014-0634-1
   Flanagan JR, 2000, NAT NEUROSCI, V3, P737, DOI 10.1038/76701
   Freeman CG, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222564
   GORDON AM, 1991, EXP BRAIN RES, V83, P477
   Grandy MS, 2006, J NEUROPHYSIOL, V95, P3887, DOI 10.1152/jn.00851.2005
   Heineken E, 2007, HUM FACTORS, V49, P136, DOI 10.1518/001872007779598028
   Kawai S, 2007, EXP BRAIN RES, V179, P443, DOI 10.1007/s00221-006-0803-1
   Li Y, 2011, NEUROPSYCHOLOGIA, V49, P914, DOI 10.1016/j.neuropsychologia.2011.02.018
   Metcalfe R.W., 2007, The size-weight illusion in a natural and augmented environment
   Naylor Caitlin Elisabeth, 2020, J Cogn, V3, P3, DOI 10.5334/joc.93
   Nowak D. A., 2009, Sensorimotor control of grasping: Physiology and pathophysiology, DOI [https://doi.org/10.1017/CBO9780511581267, DOI 10.1017/CBO9780511581267, 10.1017/CBO9780511581267]
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peters MAK, 2016, PEERJ, V4, DOI 10.7717/peerj.2124
   Plaisier MA, 2019, PSYCHOL SCI, V30, P822, DOI 10.1177/0956797619837981
   Regenbrecht H., 2002, P 5 ANN INT WORKSH P
   Rohrbach, 2020, OPEN SCI FRAMEWORK
   Rohrbach, 2020, GITHUB REPOSITORY
   Rohrbach N, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0546-4
   Rohrbach N, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0530-z
   Saccone EJ, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.104038
   The Jamovi project, 2020, JAMOVI VERSION 1216
   Therapy Lens, AUGM REAL REH
   Valdez AB, 2008, PERCEPT PSYCHOPHYS, V70, P647, DOI 10.3758/PP.70.4.647
   van Polanen V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52102-y
   van Polanen V, 2019, J NEUROPHYSIOL, V121, P1398, DOI 10.1152/jn.00396.2018
   Weser V, 2018, PRESENCE-VIRTUAL AUG, V27, P68, DOI 10.1162/PRES_a_00319
   Wolf C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190624
NR 41
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1061
EP 1070
DI 10.1007/s10055-021-00508-3
EA MAR 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000630829000001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Banerjee, NT
   Baughman, AJ
   Lin, SY
   Witte, ZA
   Klaus, DM
   Anderson, AP
AF Banerjee, Neil T.
   Baughman, Alex J.
   Lin, Shu-Yu
   Witte, Zoe A.
   Klaus, David M.
   Anderson, Allison P.
TI Development of alternative reality environments for spacecraft habitat
   design evaluation
SO VIRTUAL REALITY
LA English
DT Article
DE AEC; Mixed reality; Hybrid reality; Virtual reality; Prototyping; Design
   evaluation
ID AUGMENTED REALITY; EXPERIENCE
AB Alternative reality (XR) tools are becoming more commonplace in the realm of architecture, engineering, and construction (AEC); however, these digitally immersive technologies vary greatly in their degree of virtuality and individual capabilities. While many studies detail the performance of one specific XR technology for a particular use case, little work exists comparing numerous modern XR technologies in a side-by-side manner for a single use case. In this work, we construct four equal-fidelity, alternative reality environments for the application of spacecraft habitat design evaluation, starting with a baseline habitat mockup constructed in physical reality (PR). Three digital environments-augmented reality, hybrid reality (HR), and virtual reality-were modeled after the PR environment and developed in parallel. The implementation of each environment was carefully documented, along with relative strengths and weaknesses associated with both development and use. Additionally, we have developed a novel HR implementation that includes realistic and intuitive haptics, hand tracking, a fully virtual audiovisual scene, and responsive habitat elements, all wirelessly synched with a game engine and spatially synched with the PR environment. In sum, this work serves as a resource for those considering XR technologies for any variety of applications, particularly in AEC disciplines.
C1 [Banerjee, Neil T.; Baughman, Alex J.; Lin, Shu-Yu; Witte, Zoe A.; Klaus, David M.; Anderson, Allison P.] Univ Colorado Boulder, Aerosp Engn Sci, 3775 Discovery Dr, Boulder, CO 80303 USA.
C3 University of Colorado System; University of Colorado Boulder
RP Banerjee, NT (corresponding author), Univ Colorado Boulder, Aerosp Engn Sci, 3775 Discovery Dr, Boulder, CO 80303 USA.
EM neil.banerjee@colorado.edu
RI Anderson, Allison/AAY-6536-2020; lin, shuyu/GRF-5383-2022
OI Anderson, Allison/0000-0001-7808-8557; Banerjee,
   Neil/0000-0002-6825-917X
FU NASA Human Research Program [80NSSC18K0198]
FX This work is funded by the NASA Human Research Program, grant number
   80NSSC18K0198.
CR Anderson AP, 2019, COMPLEX SYSTEM UNPUB
   Bell KD, 1995, P SOC PHOTO-OPT INS, V2583, P495, DOI 10.1117/12.228594
   Botden SMBI, 2007, WORLD J SURG, V31, P764, DOI 10.1007/s00268-006-0724-y
   Broll W, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P109, DOI 10.1109/3DUI.2008.4476600
   Cirulis A, 2013, PROCEDIA COMPUT SCI, V25, P71, DOI 10.1016/j.procs.2013.11.009
   Delgado FJN, 2017, GPU TECHN C 2017 SAN
   Dunston PS, 2011, INTEL SYST CONTR AUT, V48, P167, DOI 10.1007/978-94-007-0605-7_15
   Edwards G., 2015, Visualization in Engineering, V3, P1, DOI DOI 10.1186/S40327-015-0018-2
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Fuchs H, 1998, AUGMENTED REALITY VI, P934, DOI DOI 10.1007/BFB0056282
   Ganier F, 2014, ERGONOMICS, V57, P828, DOI 10.1080/00140139.2014.899628
   Gopinath R, 2004, APPL IMMERSIVE VIRTU, V9
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Higdon K. P., 2008, PROC 11 BIENNIAL ASC, P1, DOI [10.1061/40988(323)96, DOI 10.1061/40988(323)96]
   Hilfert Thomas, 2016, Visualization in Engineering, V4, DOI 10.1186/s40327-015-0031-5
   Huang DH, 1992, Mod. Eng. Des. Liq. Rocket Engines, DOI [10.2514/4.866197, DOI 10.2514/4.866197]
   Issa RRA, 2000, CONSTRUCTION CONGRESS VI, PROCEEDING, P1007
   Karasinski JA, 2017, LECT NOTES COMPUT SC, V10280, P248, DOI 10.1007/978-3-319-57987-0_20
   Maldovan KD, 2006, DETERMINING EFFECTS, V10
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nolle Stefan, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P249, DOI 10.1109/ISMAR.2006.297829
   Pamungkas D. S., 2016, International Journal of Computer Theory and Engineering, V8, P465, DOI 10.7763/IJCTE.2016.V8.1090
   Patel RS, 2006, J APPL PHYS, V100, DOI 10.1063/1.2405733
   Pour Rahimian F., 2014, Visualization in Engineering, V2, DOI [10.1186/2213-7459-2-4, DOI 10.1186/2213-7459-2-4]
   Roupé M, 2014, COMPUT ENVIRON URBAN, V43, P42, DOI 10.1016/j.compenvurbsys.2013.10.003
   Sabriansyah R., 2017, INT J ELECT COMPUTER, V7, P1012
   Seo DW, 2016, COMPUT IND, V76, P11, DOI 10.1016/j.compind.2015.11.003
   Thomas B, 1999, USING AUGMENTED REAL, V8
   Valcasara N., 2015, UNREAL ENGINE GAME D
   Vassallo R, 2017, PROC SPIE, V10136, DOI 10.1117/12.2255831
   Vasseur JP, 2010, INTERCONNECTING SMART OBJECTS WITH IP: THE NEXT INTERNET, P1
   Wang Xiangyu., 2008, Mixed reality in architecture, design, and construction
   Wang ZB, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P21, DOI 10.1109/CW.2009.15
   Westerdahl B, 2006, AUTOMAT CONSTR, V15, P150, DOI 10.1016/j.autcon.2005.02.010
   Woksepp S, 2008, ADV ENG INFORM, V22, P520, DOI 10.1016/j.aei.2008.06.007
   Woodward C., 2011, Augmented Reality: Some Emerging Application Areas, P115
NR 36
TC 4
Z9 5
U1 1
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 399
EP 408
DI 10.1007/s10055-020-00462-6
EA AUG 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000555387800001
DA 2024-07-18
ER

PT J
AU Su, KW
   Chen, SC
   Lin, PH
   Hsieh, CI
AF Su, Kuo-Wei
   Chen, Shih-Chih
   Lin, Po-Hung
   Hsieh, Ching-, I
TI Evaluating the user interface and experience of VR in the electronic
   commerce environment: a hybrid approach
SO VIRTUAL REALITY
LA English
DT Article
DE User interface (UI); User experience (UX); Virtual reality (VR);
   Electronic commerce (E-commerce)
ID THINK-ALOUD; DELPHI; USABILITY; PERCEPTION; CONSENSUS; PROTOCOL
AB In recent years, to attract global manufacturers, media reporters, and consumer attention, a popular term in search engines has been virtual reality (VR). In addition to video, entertainment, education, and medical, VR can be used in electronic commerce (E-commerce). Currently, most E-commerce platforms present products using 2D images, text-based interface or animation. However, consumers want to know more about the products while online shopping and compare the product's material, color, and other elements. Therefore, combining VR with E-commerce can improve the user's shopping experience. This study will focus on the characteristics of VR and E-commerce. This feature can be used to interactively study UI and UX between users and designers to generate design criteria. Experimental design is carried out through the modified SEM-CPU method. Then, we use the think-aloud protocols, Questionnaire for User Interaction Satisfaction, and User Experience Questionnaire to understand the user's thoughts on UI and UX. Moreover, this study uses focus group to interview experts to obtain expert opinions on VR E-commerce. Induction and integration of data is carried out to produce design criteria by experimental results. Finally, the Delphi method is utilized to validate and evaluate the practicability of the design criterion. Through the "UI and UX design criteria of VR" generated by this study, many important design elements can be proposed and assessed in VR E-commerce. In closing, this study provides design and development suggestions for VR developers to improve the positive influence of UX.
C1 [Su, Kuo-Wei; Chen, Shih-Chih; Hsieh, Ching-, I] Natl Kaohsiung Univ Sci & Technol, Dept Informat Management, 1 Univ Rd, Kaohsiung 824, Taiwan.
   [Lin, Po-Hung] Ming Chi Univ Technol, Dept Ind Engn & Management, 84 Gungjuan Rd, New Taipei 24301, Taiwan.
C3 National Kaohsiung University of Science & Technology; Ming Chi
   University of Technology
RP Chen, SC (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Informat Management, 1 Univ Rd, Kaohsiung 824, Taiwan.
EM kwsu@nkust.edu.tw; scchen@nkust.edu.tw; frank.phlin@gmail.com;
   u0524804@nkfust.edu.tw
RI Chen, Shih-Chih/ABC-7705-2020
OI Chen, Shih-Chih/0000-0002-0039-421X
FU Ministry of Science and Technology, Taiwan [MOST 106-2221-E-327-022,
   MOST 107-2410-H-992-011]
FX Funding was provided by Ministry of Science and Technology, Taiwan (MOST
   106-2221-E-327-022 and MOST 107-2410-H-992-011).
CR Acun V, 2018, APPL ACOUST, V131, P28, DOI 10.1016/j.apacoust.2017.09.018
   [Anonymous], 2012 9 INT C INF TEC
   [Anonymous], INTRO BEST PRACTICES
   [Anonymous], IKEA VR EXPERIENCE
   [Anonymous], INT J ELECT MARKETS
   [Anonymous], GOOGLE I O 2015 DESI
   [Anonymous], WELCOME USER EXPERIE
   Cheng LK, 2014, VIRTUAL REAL-LONDON, V18, P173, DOI 10.1007/s10055-014-0244-2
   Cooke L, 2010, IEEE T PROF COMMUN, V53, P202, DOI 10.1109/TPC.2010.2052859
   Loureiro SMC, 2019, J BUS RES, V100, P514, DOI 10.1016/j.jbusres.2018.10.055
   Ercikan K., 2010, Educational Measurement: Issues and Practice, V29, P24, DOI DOI 10.1111/J.1745-3992.2010.00173.X
   ERICSSON KA, 1980, PSYCHOL REV, V87, P215, DOI 10.1037/0033-295X.87.3.215
   Fox AR, 2016, AM J OPHTHALMOL, V168, P183, DOI 10.1016/j.ajo.2016.05.013
   Grewal D, 2017, J RETAILING, V93, P1, DOI 10.1016/j.jretai.2016.12.008
   Hasan B, 2016, COMPUT HUM BEHAV, V54, P224, DOI 10.1016/j.chb.2015.07.056
   Hasson F, 2011, TECHNOL FORECAST SOC, V78, P1695, DOI 10.1016/j.techfore.2011.04.005
   Haverila M, 2013, TELEMAT INFORM, V30, P177, DOI 10.1016/j.tele.2012.05.002
   Ho LW, 2018, ENERG POLICY, V113, P53, DOI 10.1016/j.enpol.2017.10.049
   Inostroza R, 2016, COMPUT STAND INTER, V43, P40, DOI 10.1016/j.csi.2015.08.007
   Kuniavsky M, 2010, SMART THINGS: UBIQUITOUS COMPUTING USER EXPERIENCE DESIGN, P1
   Laurel Brenda., 1990, ART HUMAN COMPUTER I
   Lee SM, 2005, J ELECTRON COMMER OR, V3, P13, DOI 10.4018/jeco.2005010102
   Lee W., 2003, ELECTRON COMMER R A, V2, P240, DOI DOI 10.1016/S1567-4223(03)00026-7
   Lee YS, 2006, INTERACT COMPUT, V18, P304, DOI 10.1016/j.intcom.2005.04.002
   Lin CC, 2013, INFORM TECHNOL MANAG, V14, P243, DOI 10.1007/s10799-013-0162-0
   Lundgrén-Laine H, 2010, QUAL HEALTH RES, V20, P565, DOI 10.1177/1049732309354278
   Martínez-Navarro J, 2019, J BUS RES, V100, P475, DOI 10.1016/j.jbusres.2018.10.054
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   Paes D, 2017, AUTOMAT CONSTR, V84, P292, DOI 10.1016/j.autcon.2017.09.016
   Paré G, 2013, INFORM MANAGE-AMSTER, V50, P207, DOI 10.1016/j.im.2013.03.003
   Pottier P, 2010, MED EDUC, V44, P926, DOI 10.1111/j.1365-2923.2010.03748.x
   Schnack A, 2019, FOOD RES INT, V117, P40, DOI 10.1016/j.foodres.2018.01.028
   Stewart P., 2014, Focus Groups: Theory and Practice
   Sun HM, 2015, APPL ERGON, V50, P126, DOI 10.1016/j.apergo.2015.03.006
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   von der Gracht HA, 2012, TECHNOL FORECAST SOC, V79, P1525, DOI 10.1016/j.techfore.2012.04.013
   Wu YC, 2019, VIRTUAL REAL-LONDON, V23, P187, DOI 10.1007/s10055-018-0373-0
NR 37
TC 18
Z9 19
U1 17
U2 139
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 241
EP 254
DI 10.1007/s10055-019-00394-w
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800005
DA 2024-07-18
ER

PT J
AU Zahabi, M
   Razak, AMA
AF Zahabi, Maryam
   Abdul Razak, Ashiq Mohammed
TI Adaptive virtual reality-based training: a systematic literature review
   and framework
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Adaptive training; Framework; Personalization
ID DECISION-MAKING; STROKE PATIENTS; COGNITIVE LOAD; VR SYSTEM; DESK-TOP;
   SIMULATION; REHABILITATION; PERFORMANCE; FEEDBACK; EVALUATE
AB Virtual reality (VR) provides the capability to train individuals to deal with complex situations by immersing them in a virtual environment. VR-based training has been used in many domains; however, in order to be effective, the training should be adapted based on user's capabilities, performance, and needs. This study provided a framework for adaptive VR-based training including performance measures, adaptive logic, and adaptive variables. A systematic review of literature was conducted using Compendex, Web of Science, and Google Scholar databases to identify the adaptive VR-based training approaches used in different domains. Results revealed that adaptive VR-based training can be improved by using real-time kinematic/kinetic data and physiological measures from the user, incorporating offline measures such as trainee's profile information, providing adaptations on controlled elements in the simulation, adjusting feedback content, type, and timing, and using reinforcement learning algorithms. The recommendations provided in this study need to be further validated using longitudinal studies comparing adaptive and non-adaptive training approaches.
C1 [Zahabi, Maryam; Abdul Razak, Ashiq Mohammed] Texas A&M Univ, Ind & Syst Engn Dept, Emerging Technol Bldg, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Zahabi, M (corresponding author), Texas A&M Univ, Ind & Syst Engn Dept, Emerging Technol Bldg, College Stn, TX 77843 USA.
EM mzahabi@tamu.edu
CR Adamovich SV, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-28
   Amat AZ, 2018, LECT NOTES COMPUT SC, V10907, P463, DOI 10.1007/978-3-319-92049-8_33
   Antonacopoulou EP, 2001, J MANAGE STUD, V38, P327, DOI 10.1111/1467-6486.00239
   Aoki H, 2008, ACTA ASTRONAUT, V63, P841, DOI 10.1016/j.actaastro.2007.11.001
   Barzilay O, 2009, WORLD C MED PHYS BIO
   Barzilay O, 2013, J ELECTROMYOGR KINES, V23, P182, DOI 10.1016/j.jelekin.2012.09.004
   Bayart B, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P51
   Bekele E, 2013, INT C UN ACC HUM COM
   Ben Abdessalem H, 2017, LECT NOTES ARTIF INT, V10512, P133, DOI 10.1007/978-3-319-67615-9_12
   Badia SBI, 2013, IEEE T NEUR SYS REH, V21, P174, DOI 10.1109/TNSRE.2012.2229295
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Bian Dayi, 2016, Universal Access in Human-Computer Interaction: Users and Context Diversity. 10th International Conference, UAHCI 2016, held as part of HCI International 2016. Proceedings: LNCS 9739, P538, DOI 10.1007/978-3-319-40238-3_51
   Billings DR, 2012, MIL PSYCHOL, V24, P114, DOI 10.1080/08995605.2012.672905
   Birk MV, 2019, J MED INTERNET RES, V21, DOI 10.2196/10133
   Blankendaal RAM, 2018, LECT NOTES ARTIF INT, V10978, P97, DOI 10.1007/978-3-319-94580-4_8
   Bosse T, 2014, ART LIF INT AG S
   Bosse T, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P40, DOI 10.1109/WI-IAT.2014.148
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Cameirao MS, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-48
   Cameirao MS, 2008, 2008 VIRTUAL REHABILITATION, P2, DOI 10.1109/ICVR.2008.4625112
   Carpentier K, 2013, INT C AG ART INT
   Cesta A, 2014, KNOWL-BASED SYST, V58, P98, DOI 10.1016/j.knosys.2013.11.011
   Chan CLF, 2010, INT J GERIATR PSYCH, V25, P643, DOI 10.1002/gps.2403
   Chemuturi R, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-102
   Chen YP, 2011, IEEE ENG MED BIO, P1827, DOI 10.1109/IEMBS.2011.6090520
   Christie R, 2001, ROAD SAF RES POL ED
   Cosic K, 2010, STUD HEALTH TECHNOL, V154, P14, DOI 10.3233/978-1-60750-561-7-14
   Cox DJ, 2017, J AUTISM DEV DISORD, V47, P2544, DOI 10.1007/s10803-017-3164-7
   Dey A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P220, DOI [10.1109/vr.2019.8797840, 10.1109/VR.2019.8797840]
   Dhiman A, 2016, 2016 6 IEEE INT C BI
   Feidakis M, 2016, FORMATIVE ASSESSMENT, P217, DOI [10.1016/B978-0-12-803637-2.00011-7, DOI 10.1016/B978-0-12-803637-2.00011-7]
   Fricoteaux L, 2011, VTT SYMP, V269, P67
   Fricoteaux L, 2014, ENG APPL ARTIF INTEL, V33, P47, DOI 10.1016/j.engappai.2014.03.005
   Fricoteaux L, 2012, ADV INTEL SOFT COMPU, V164, P417
   Gao XQ, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 5, PROCEEDINGS, P85, DOI 10.1109/FSKD.2008.455
   Garcia-Vergara Sergio, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P40, DOI 10.1007/978-3-642-39420-1_5
   Gerbaud S, 2009, LECT NOTES COMPUT SC, V5670, P316, DOI 10.1007/978-3-642-03364-3_40
   Grimm F, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00518
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Gurusamy KS, 2009, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub2
   Hancock PA, 2019, P NATL ACAD SCI USA, V116, P7684, DOI 10.1073/pnas.1805770115
   Haringer M, 2012, PRESENCE-VIRTUAL AUG, V21, P96
   Heloir A, 2014, INT WORKSH ICTS IMPR
   Hernandez Y, 2016, P 8 INT C COMP SUPP
   Huang XW, 2018, J STROKE CEREBROVASC, V27, P221, DOI 10.1016/j.jstrokecerebrovasdis.2017.08.027
   Jeelani I, 2017, COMPUTING IN CIVIL ENGINEERING 2017: SENSING, SIMULATION, AND VISUALIZATION, P407
   Johnson A, 2014, IEEE INT C NETW SENS, P457, DOI 10.1109/ICNSC.2014.6819669
   Jones D, 2016, LECT NOTES ARTIF INT, V9744, P23, DOI 10.1007/978-3-319-39952-2_3
   Jones N, 2016, BIOL SPORT, V33, P117, DOI 10.5604/20831862.1198210
   Kalyuga S, 2003, EDUC PSYCHOL-US, V38, P23, DOI 10.1207/S15326985EP3801_4
   KELLEY CR, 1969, HUM FACTORS, V11, P547, DOI 10.1177/001872086901100602
   Kizony R, 2003, J VISUAL COMP ANIMAT, V14, P261, DOI 10.1002/vis.323
   Knowles M., 1990, ADULT LEARNER NEGLEC, V4th
   Koenig A, 2011, IEEE T NEUR SYS REH, V19, P453, DOI 10.1109/TNSRE.2011.2160460
   Kommalapati R, 2016, 2016 38 ANN INT C IE
   Kühnapfel U, 2000, COMPUT GRAPH-UK, V24, P671, DOI 10.1016/S0097-8493(00)00070-4
   Kumar D, 2018, FRONT BIOENG BIOTECH, V5, DOI 10.3389/fbioe.2017.00085
   Lafond I, 2010, NORTHEAST BIOENGIN C
   Lahiri U, 2013, IEEE T NEUR SYS REH, V21, P55, DOI 10.1109/TNSRE.2012.2218618
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   Larsen CR., 2009, Bmj, V338, pb1802, DOI DOI 10.1136/BMJ.B1802
   Liu P, 2016, 2016 6 INT C IT CONV
   Loftin R, 1994, IND TRAIN SYST ED C
   Lopez-Garate M, 2008, P 7 INT JOINT C AUT, V3
   Luo LB, 2013, COMPUT ANIMAT VIRT W, V24, P345, DOI 10.1002/cav.1525
   Ma MH, 2007, LECT NOTES COMPUT SC, V4555, P681
   Magerko B., 2005, INT IND TRAIN SIM ED
   Malik H, 2015, IEEE T INTELL TRANSP, V16, P1728, DOI 10.1109/TITS.2014.2371061
   Mariani A, 2018, IEEE ENG MED BIO, P2162, DOI 10.1109/EMBC.2018.8512728
   Merians AS, 2009, STUD HEALTH TECHNOL, V145, P109, DOI 10.3233/978-1-60750-018-6-109
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mohamed F, 2017, PERSONALIZATION LEAR
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Mourning R, 2016, 2016 IEEE INT C SYST
   NAE, 2017, NAE GRAND CHALL ENG
   Nazemi K, 2007, EDMEDIA INN LEARN
   NIH, 2019, REHABILITATION
   Nirme J, 2011, IEEE ENG MED BIO, P6749, DOI 10.1109/IEMBS.2011.6091665
   Nowak Kristen., 2001, PRESENCE 2001 C PHIL, P1, DOI 10.1.1.19.5482
   Ohno N, 2007, PHYS EARTH PLANET IN, V163, P305, DOI 10.1016/j.pepi.2007.02.013
   Padilla-Castaneda MA, 2013, 2013 IEEE RSJ INT C
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Peck RC, 2011, IATSS RES, V34, P63, DOI 10.1016/j.iatssr.2011.01.001
   Peretz C, 2011, NEUROEPIDEMIOLOGY, V36, P91, DOI 10.1159/000323950
   Pham T, 2005, ST HEAL T, V111, P385
   POPOVIC S, 2009, STRESS INOCULATION T
   Pozueco L, 2015, INT CONF COMP INFO
   Pradhan AK, 2006, TRANSPORT RES REC, P58, DOI 10.3141/1969-10
   Rezazadeh IM, 2011, AUTOMAT CONSTR, V20, P289, DOI 10.1016/j.autcon.2010.10.005
   Ritter F., 2013, The Oxford Handbook of cognitive engineering, P125, DOI [DOI 10.1093/OXFORDHB/9780199757183.001.0001, 10.1093/oxfordhb/9780199757183.001.0001]
   Roenker DL, 2003, HUM FACTORS, V45, P218, DOI 10.1518/hfes.45.2.218.27241
   Rossol N., 2011, Proceedings of the 10th International Conference on Virtual Reality Continuum and Its Applications in Industry, P343, DOI DOI 10.1145/2087756.2087810
   Sarasin L.C., 1999, LEARNING STYLE PERSP
   Saurav Kumar, 2018, 2018 IEEE ACIS 17 IN
   Schatz S, 2012, P HUM FACT ERG SOC A
   Schwaninger A, 2007, CAR C SECUR, P117
   Serge SR, 2013, COMPUT HUM BEHAV, V29, P1150, DOI 10.1016/j.chb.2012.10.007
   Sharma Dhara A, 2016, J Phys Ther Sci, V28, P1482, DOI 10.1589/jpts.28.1482
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Shochat G, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Siu KC, 2016, MIL MED, V181, P214, DOI 10.7205/MILMED-D-15-00164
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Stansfield S, 2000, PRESENCE-TELEOP VIRT, V9, P524, DOI 10.1162/105474600300040376
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stetz MC., 2008, J CYBERTHERAPY REHAB, V1, P239
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Strickland D, 1997, ST HEAL T, V44, P81
   Stroud KJ, 2005, AVIAT SPACE ENVIR MD, V76, P352
   Summa S, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0009-5
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Tsiakas K, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769507
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
   Vaughan N, 2016, MED ENG PHYS, V38, P59, DOI 10.1016/j.medengphy.2015.11.021
   Verma S, 2017, IEEE T NEUR SYS REH, V25, P935, DOI 10.1109/TNSRE.2017.2667406
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang L, 2017, 2017 CHIN AUT C CAC
   Wiederhold B.K., 2008, Journal of CyberTherapy Rehabilitation, V1, P23
   Wilkerson W, 2008, ACAD EMERG MED, V15, P1152, DOI 10.1111/j.1553-2712.2008.00223.x
   Wu W, 2016, ROB BIOM ROBIO 2016
   Yang X, 2016, INT C HUM HAPT SENS
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
   Yovanoff M, 2017, P HUM FACT ERG SOC M
   Yovanoff MA, 2018, J SURG EDUC, V75, P1410, DOI 10.1016/j.jsurg.2018.02.018
   Zahabi M, 2020, THEOR ISS ERGON SCI, V21, P537, DOI 10.1080/1463922X.2019.1698673
   Zhu BW, 2020, BEHAV INFORM TECHNOL, V39, P431, DOI 10.1080/0144929X.2019.1599068
   Zhu XQ, 2015, LECT NOTES ELECTR EN, V356, P653, DOI 10.1007/978-3-662-48224-7_78
NR 128
TC 64
Z9 69
U1 8
U2 79
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 725
EP 752
DI 10.1007/s10055-020-00434-w
EA MAR 2020
PG 28
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000564448900001
DA 2024-07-18
ER

PT J
AU Negrón, APP
   Muñoz, E
   López, GL
AF Pena Perez Negron, Adriana
   Munoz, Edrisi
   Lara Lopez, Graciela
TI A model for nonverbal interaction cues in collaborative virtual
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE CVE; Avatars; Nonverbal communication; HCI
ID RECOGNITION; AUDIO
AB People's social interaction is a complex process that involves our verbal and nonverbal behavior. In collaborative virtual environments (CVEs) technologies, interaction is achieved employing a graphical representation, namely avatar. In this primarily visual media, interactions are constrained by the available possibilities linked to technical and design issues. The focus of this work is the automatic analysis of collaborative interaction among actors in CVEs, based on basic action units of study. For that, a designed domain ontology to establish the basis for the definition and automation of nonverbal interaction cues is presented. Also, for the analysis of collaboration, a structure to infer higher indicators through individual interaction cues was developed. Finally, a case of study applying this proposal is presented.
C1 [Pena Perez Negron, Adriana; Lara Lopez, Graciela] Univ Guadalajara, CUCEI, Blvd Marcelino Garcia Barragan 1421, Guadalajara 44430, Jalisco, Mexico.
   [Munoz, Edrisi] Ctr Invest Matemat AC, Unidad Zacatecas, Parque Quantum,Ave Lassec,Manzana 3,Lote 7, Zacatecas 98160, Zacatecas, Mexico.
C3 Universidad de Guadalajara
RP López, GL (corresponding author), Univ Guadalajara, CUCEI, Blvd Marcelino Garcia Barragan 1421, Guadalajara 44430, Jalisco, Mexico.
EM adriana.pena@cucei.udg.mx; emunoz@cimat.mx;
   graciela.lara@academicos.udg.mx
RI Peña Pérez Negrón, Adriana/AFK-8243-2022
OI Peña Pérez Negrón, Adriana/0000-0001-6823-2367; Lara Lopez,
   Graciela/0000-0003-2766-8134
CR Ammi M, 2015, VIRTUAL REAL-LONDON, V19, P235, DOI 10.1007/s10055-015-0273-5
   [Anonymous], 2010, Nonverbal communication in human interaction
   [Anonymous], 2003, P INT C AUD VIS SPEE
   [Anonymous], INT IND TRAIN SIM ED
   Aylett R, 2013, LECT NOTES COMPUTER, V8108
   BRDICZKA O, 2005, ICMI
   Breazeal C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Capin TK, 1997, DESKTOP WEBTOP VIRTU
   Casillas L, 2016, INT J E-COLLAB, V12, P7, DOI 10.4018/IJeC.2016100102
   DABBS JM, 1987, ADV EXP SOC PSYCHOL, V20, P123, DOI 10.1016/S0065-2601(08)60413-X
   Ellis S, 1995, ORIGINS ELEMENTS VIR
   Gobron S, 2012, LECT NOTES COMPUT SC, V7378, P58, DOI 10.1007/978-3-642-31567-1_6
   HALL ET, 1968, CURR ANTHROPOL, V9, P83, DOI 10.1086/200975
   Hanna Nader, 2015, COMMUN COMPUT PHYS, P31
   Hayashi Y, 2014, PROCEDIA COMPUT SCI, V35, P986, DOI 10.1016/j.procs.2014.08.184
   Heath C., 1994, Computer Supported Cooperative Work (CSCW), V3, P147, DOI 10.1007/BF00773445
   Honold F., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P243, DOI 10.1109/IE.2012.13
   Jofré LN, 2016, IEEE CACIDI 2016 - IEEE CONFERENCE ON COMPUTER SCIENCES
   Johar Swati., 2015, Emotion, affect and personality in speech: The Bias of language and paralanguage
   Jovanov E, 2009, IEEE ENG MED BIO, P2462, DOI 10.1109/IEMBS.2009.5334774
   Juslin P N, 2005, NEW HDB METHODS NONV, V65, P135
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Muñoz E, 2010, COMPUT CHEM ENG, V34, P668, DOI 10.1016/j.compchemeng.2009.12.009
   Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020
   Pena A, 2014, COMPUT SCI INF TECHN, V2, P100
   Negrón APP, 2015, J MULTIMODAL USER IN, V9, P253, DOI 10.1007/s12193-015-0193-4
   Schroeder Ralph, 2010, Being There Together: Social interaction in shared virtual environments
   Shahrour GJ, 2015, WORLD ACAD SCI ENG T, V9, P311
   Spante M, 2003, HOME ORIENTED INFORM
   Wolff R, 2005, INT J COMPUTER APPL
   WOLFF R, 2008, 12 IEEE INT S DISTR
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 32
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 605
EP 618
DI 10.1007/s10055-019-00421-w
EA DEC 2019
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000542936700003
DA 2024-07-18
ER

PT J
AU Escalona, F
   Martinez-Martin, E
   Cruz, E
   Cazorla, M
   Gomez-Donoso, F
AF Escalona, Felix
   Martinez-Martin, Ester
   Cruz, Edmanuel
   Cazorla, Miguel
   Gomez-Donoso, Francisco
TI EVA: EVAluating at-home rehabilitation exercises using augmented reality
   and low-cost sensors
SO VIRTUAL REALITY
LA English
DT Article
DE Rehabilitation exercises; Deep learning; Augmented reality;
   Human-computer interaction; 3D visualization; Low-cost sensors
ID UPPER-LIMB REHABILITATION; STROKE; FIT
AB Over one billion people in the world live with some form of disability. This is incessantly increasing due to aging population and chronic diseases. Among the emerging social needs, rehabilitation services are the most required. However, they are scarce and expensive what considerably limits access to them. In this paper, we propose EVA, an augmented reality platform to engage and supervise rehabilitation sessions at home using low-cost sensors. It also stores the user's statistics and allows therapists to tailor the exercise programs according to their performance. This system has been evaluated in both qualitative and quantitative ways obtaining very promising results.
C1 [Escalona, Felix; Martinez-Martin, Ester; Cruz, Edmanuel; Cazorla, Miguel; Gomez-Donoso, Francisco] Univ Alicante, Univ Inst Comp Res, Alicante, Spain.
C3 Universitat d'Alacant
RP Gomez-Donoso, F (corresponding author), Univ Alicante, Univ Inst Comp Res, Alicante, Spain.
EM fgomez@dccia.ua.es
RI Escalona, Felix/W-9378-2019; Martinez-Martin, Ester/M-7374-2016; Cruz,
   Edmanuel/AAC-4552-2019; Cazorla, Miguel/B-4464-2013; Gomez-Donoso,
   Francisco/H-7539-2016
OI Escalona, Felix/0000-0003-2245-601X; Martinez-Martin,
   Ester/0000-0003-4495-6912; Cruz, Edmanuel/0000-0002-7988-3293; Cazorla,
   Miguel/0000-0001-6805-3633; Gomez-Donoso, Francisco/0000-0002-7830-2661
FU Spanish Government [TIN2016-76515R]; Feder funds; IFARHU; SENACYT
   [270-2016-207];  [ACIF/2017/243];  [FPU16/00887]
FX This work has been supported by the Spanish Government TIN2016-76515R
   Grant, supported with Feder funds. Edmanuel Cruz is funded by a
   Panamenian grant for Ph.D. studies IFARHU and SENACYT 270-2016-207. This
   work has also been supported by a Spanish grant for PhD studies
   ACIF/2017/243 and FPU16/00887. Thanks also to Nvidia for the generous
   donation of a Titan Xp and a Quadro P6000.
CR Al-Issa H, 2012, PHYS THER REV, V17, P16, DOI 10.1179/1743288X11Y.0000000051
   [Anonymous], 2018, BRIT NAT HLTH SEC
   [Anonymous], 2010, TECHNICAL REPORT
   [Anonymous], 2008, WII FIT
   [Anonymous], 2015, GLOBAL STATUS REPORT
   Aung YM, 2014, IEEE ENG MED BIO, P3614, DOI 10.1109/EMBC.2014.6944405
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Barcala L, 2013, J PHYS THER SCI, V25, P1027, DOI 10.1589/jpts.25.1027
   Berndt D.J., 1994, AAAI 94 WORKSH KNOWL, V10, P359, DOI [10.5555/3000850.3000887, DOI 10.5555/3000850.3000887]
   Bleser G, 2013, J AMB INTEL SMART EN, V5, P547, DOI 10.3233/AIS-130234
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cao Z, 2017, COMPUTER VISION PATT
   Costa A, 2018, INTEL SYST REF LIBR, V132, P77, DOI 10.1007/978-3-319-62530-0_5
   Costa A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082633
   de Assis GA, 2016, DISABIL REHABIL-ASSI, V11, P521, DOI 10.3109/17483107.2014.979330
   Desai K, 2016, 7 INT C MULT SYST KL
   Mendes FAD, 2012, PHYSIOTHERAPY, V98, P217, DOI 10.1016/j.physio.2012.06.001
   Fung V, 2012, PHYSIOTHERAPY, V98, P183, DOI 10.1016/j.physio.2012.04.001
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Gazzoni M, 2018, ANN PHYS REHABIL MED, V61, pe483, DOI [10.1016/j.rehab.2018.05.1129, DOI 10.1016/J.REHAB.2018.05.1129]
   Gomez-Donoso F, 2017, PATTERN RECOGN LETT, V99, P105, DOI 10.1016/j.patrec.2017.05.027
   Hocoma, 2018, HOCOMA LOKOMAT
   Indra, 2019, TOYRA
   Jack D, 2001, IEEE T NEUR SYS REH, V9, P308, DOI 10.1109/7333.948460
   Kanazawa A, 2018, COMPUTER VISION PATT
   Levy-Tzedek S, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Meldrum D, 2012, DISABIL REHABIL-ASSI, V7, P205, DOI 10.3109/17483107.2011.616922
   Monge J, 2018, INT CONF EXPO ELECTR, P1010, DOI 10.1109/ICEPE.2018.8559935
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   PTC Inc, 2019, VUF
   Redmon J., 2018, IEEE C COMPUTER VISI
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   SilverFit, 2019, SILV 3D
   Sousa M, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P175, DOI 10.1145/2856767.2856773
   Stefano M, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/265634
   Tyromotion, 2018, AM
   Yang SC, 2016, IEEE INT CONF ROBOT, P2183, DOI 10.1109/ICRA.2016.7487368
   Yee Mon Aung, 2014, International Journal of Mechatronics and Automation, V4, P52, DOI 10.1504/IJMA.2014.059774
NR 39
TC 13
Z9 13
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 567
EP 581
DI 10.1007/s10055-019-00419-4
EA DEC 2019
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000542936000001
DA 2024-07-18
ER

PT J
AU Yang, CK
   Chen, YH
   Chuang, TJ
   Shankhwar, K
   Smith, S
AF Yang, Chih-Kai
   Chen, Yu-Hsi
   Chuang, Tung-Jui
   Shankhwar, Kalpana
   Smith, Shana
TI An augmented reality-based training system with a natural user interface
   for manual milling operations
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Natural operation behavior; Manual milling operation;
   Occlusion
AB This study developed an augmented reality (AR)-based training system for conventional manual milling operations. An Intel RealSense R200 depth camera and a Leap Motion controller were mounted on an HTC Vive head-mounted display to allow users freely walk around in a room-size AR environment to operate a full-size virtual milling machine with their barehands, using their natural operation behaviors, as if they were operating a real milling machine in the real world, without additional worn or handheld devices. GPU parallel computing was used to handle dynamic occlusions and accelerate the machining simulation to achieve a real-time simulation. Using the developed AR-based training system, novices can receive a hands-on training in a safe environment, without any injury or damage. User test results showed that using the developed AR-based training resulted in lower failure rates and inquiry times than using video training. Users also commented that the AR-based training was interesting and helpful for novices to learn the basic manual milling operation techniques.
C1 [Yang, Chih-Kai; Chen, Yu-Hsi; Chuang, Tung-Jui; Shankhwar, Kalpana; Smith, Shana] Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
C3 National Taiwan University
RP Smith, S (corresponding author), Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
EM ssmith@ntu.edu.tw
RI Shankhwar, Dr. Kalpana/HGA-6640-2022; YANG, Chih Kai/JXL-6184-2024
FU Ministry of Science and Technology, Taiwan, Republic of China [MOST
   108-2221-E-002-161-MY2]
FX The authors would like to thank the Ministry of Science and Technology,
   Taiwan, Republic of China for financially supporting this research under
   Contract MOST 108-2221-E-002-161-MY2.
CR Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Charlier J, 2018, TRANSBOUND EMERG DIS, V65, P217, DOI 10.1111/tbed.12707
   CORBETTDAVIES S, 2012, P 27 C IM VIS COMP D, P210
   Gheorghe C, 2015, LECT NOTES COMPUT SC, V9179, P438, DOI 10.1007/978-3-319-21067-4_45
   Khattak S, 2014, 2014 IEEE GAMES, MEDIA, ENTERTAINMENT (GEM)
   Kiswanto G, 2013, INT C ADV COMP SCI I, P143, DOI 10.1109/ICACSIS.2013.6761566
   Leal-Melendrez J.A., 2013, PROGR PATTERN RECOGN, P447
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Lu YZ, 2009, J COMPUT INF SCI ENG, V9, DOI 10.1115/1.3130144
   NEUGEBAUER R, 2011, GLOB PROD DEV P 20 C, P697
   Penelle B, 2014, ACM INT C P SER
   Qiu SG, 2013, INT J ADV MANUF TECH, V69, P2355, DOI 10.1007/s00170-013-5207-3
   REGAZZONI D, 2018, P ASME 2018 INT DES
   Shim J, 2016, VIRTUAL REAL-LONDON, V20, P57, DOI 10.1007/s10055-016-0282-z
   Sportillo D, 2015, LECT NOTES COMPUT SC, V9254, P332, DOI 10.1007/978-3-319-22888-4_24
   Tullis TS., 2004, Usability Professional Association Conference, P1
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Zhang JX, 2008, MOBICOM'08: PROCEEDINGS OF THE FOURTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P26, DOI 10.1145/1409944.1409949
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 19
TC 16
Z9 18
U1 5
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 527
EP 539
DI 10.1007/s10055-019-00415-8
EA DEC 2019
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000500292700001
DA 2024-07-18
ER

PT J
AU Prendinger, H
   Jain, R
   Imbert, T
   Oliveira, J
   Li, RJ
   Madruga, M
AF Prendinger, Helmut
   Jain, Raghvendra
   Imbert, Tristian
   Oliveira, Joao
   Li, Ruijiao
   Madruga, Marconi
TI Evaluation of 2D and 3D interest management techniques in the
   distributed virtual environment DiVE
SO VIRTUAL REALITY
LA English
DT Article
DE Distributed virtual environments; Interest management
ID DRIVING BEHAVIOR; WORLDS
AB We present DiVE, a networking framework for the rapid development of massively multiuser three-dimensional (3D) virtual world applications. The primary contribution of the paper is twofold. First, we investigate zone-based area of interest (AOI) techniques aimed at improving DiVE's scalability. Specifically, we present an interest management technique that is based on dividing the world into two-dimensional (2D) zones and a 'double' (inner/outer) AOI concept. Here the novelty is the investigation of different movement patterns of client entities to determine the optimal AOI/zone ratio. The empirical evaluation of our approach shows promising results on four metrics: bandwidth, frames per second, CPU, and RAM. Second, we extend the AOI concept from 2D space to 3D space, which has not yet been addressed in the literature. Among others, 3D space suggests interesting applications for the safety of unmanned aerial vehicles. Besides the investigation of the optimal size of volumetric AOI, we also consider different forms of volumetric zone alignment. The secondary contribution consists in a technical description of the DiVE framework, which has already been used successfully in multiuser applications in the traffic and evacuation domains.
C1 [Prendinger, Helmut; Jain, Raghvendra; Imbert, Tristian] Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
   [Oliveira, Joao] Univ Lisbon, INESC ID, Lisbon, Portugal.
   [Oliveira, Joao] Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.
   [Li, Ruijiao] Univ Essex, Wivenhoe Pk, Colchester CO4 3SQ, Essex, England.
   [Madruga, Marconi] Manifesto Games, New York, NY USA.
C3 Research Organization of Information & Systems (ROIS); National
   Institute of Informatics (NII) - Japan; INESC-ID; Universidade de
   Lisboa; Universidade de Lisboa; University of Essex
RP Prendinger, H (corresponding author), Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
EM helmut@nii.ac.jp
FU 'Global Lab' NII Grand Challenge grant; Kiban Kenkyu B grant from the
   Japan Society of the Promotion of Science (JSPS); FCT (INESC-ID
   multiannual funding) through the PIDDAC Program [PEst-
   OE/EEI/LA0021/2011]
FX We would like to thank Martin Lindner for implementing several
   components of DiVE. We would also like to thank Artur Goncalves for
   strengthening the literature review of this paper. This work was partly
   supported by the 'Global Lab' NII Grand Challenge grant, a Kiban Kenkyu
   B grant from the Japan Society of the Promotion of Science (JSPS), and
   by FCT (INESC-ID multiannual funding) through the PIDDAC Program PEst-
   OE/EEI/LA0021/2011.
CR Ayani R, 2000, P 14 WORKSH PAR DIST, P3
   BENFORD S, 1993, PROCEEDINGS OF THE THIRD EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK ( ECSCW 93 ), P109
   Boulanger J.-S., 2006, P 5 ACM SIGCOMM WORK, P6
   Cheslack-Postava E., 2012, Proceedings of the 2012 USENIX conference on Annual Technical Conference, P20
   Deen G, 2006, IBM SYST J, V45, P21, DOI 10.1147/sj.451.0021
   Frecon E., 1998, Distributed Systems Engineering, V5, P91, DOI 10.1088/0967-1846/5/3/002
   Gajananan K, 2013, IEEE T HUM-MACH SYST, V43, P345, DOI 10.1109/TSMC.2013.2265876
   Gu Y, 2012, IEEE T PARALL DISTR, V23, P1643, DOI 10.1109/TPDS.2012.99
   He SB, 2012, IEEE T PARALL DISTR, V23, P1657, DOI 10.1109/TPDS.2012.100
   Hosseini M., 2002, Proceedings of the 4th international conference on collaborative virtual environments, P143
   Kaplan J, 2011, IEEE INTERNET COMPUT, V15, P38, DOI 10.1109/MIC.2011.76
   Kumar S, 2008, COMPUTER, V41, P46, DOI 10.1109/MC.2008.398
   Lake D., 2010, PROC 9 ANN WORKSHOP, P1
   Liu ES, 2014, ACM T MODEL COMPUT S, V24, DOI 10.1145/2567922
   Liu ES, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2535417
   Liu HY, 2010, WINT SIMUL C PROC, P778, DOI 10.1109/WSC.2010.5679112
   Lopes CV, 2011, IEEE INTERNET COMPUT, V15, P22, DOI 10.1109/MIC.2011.77
   Madruga M., 2013, P 12 INT C AUT AG MU, P925
   Madruga M. F., 2012, P ACM SIGCHI C HUM F, P2147
   Prendinger H, 2014, COMPUT-AIDED CIV INF, V29, P480, DOI 10.1111/mice.12068
   Prendinger H, 2014, IEEE INTERNET COMPUT, V18, P28, DOI 10.1109/MIC.2014.21
   RAK SJ, 1996, P 14 DIS WORKSH STAN, P739
   Rao A. S., 1996, Agents Breaking Away. 7th European Workshop on Modelling Autonomous Agents in a Multi-Agent World, MAAMAW '96 Proceedings, P42, DOI 10.1007/BFb0031845
   Schmitt O. H., 1938, J SCI INSTRUM, V15, P24, DOI DOI 10.1088/0950-7671/15/1/305
   Smith DA, 2003, FIRST CONFERENCE ON CREATING, CONNECTING AND COLLABORATING THROUGH COMPUTING, PROCEEDINGS, P2, DOI 10.1109/C5.2003.1222325
   Tan G, 2000, P 33 ANN SIMULATION
   Teng J, 2011, INT CON DISTR COMP S, P909, DOI 10.1109/ICDCS.2011.48
   van den Berg M, 2012, P 13 INT C INT ASS T
   Waldo J, 2008, COMMUN ACM, V51, P38, DOI 10.1145/1378704.1378716
   [No title captured]
   [No title captured]
NR 31
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 263
EP 280
DI 10.1007/s10055-017-0322-3
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900007
DA 2024-07-18
ER

PT J
AU Chen, G
   Li, JT
   Zeng, JP
   Wang, B
   Lu, GD
AF Chen, Guang
   Li, Jituo
   Zeng, Jiping
   Wang, Bei
   Lu, Guodong
TI Optimizing human model reconstruction from RGB-D images based on skin
   detection
SO VIRTUAL REALITY
LA English
DT Article
DE Human model reconstruction; Kinect; RGB-D image; Skin detection
ID SHAPE; ANIMATION
AB This paper reconstructs human model from multi-view RGB-D images of an Xbox One Kinect. We preprocess the depth images by implicit surface de-noising and then part-wisely register them into a point cloud. A template model is selected from the human model database to fit the registered point cloud of a human body by Laplacian deformation. Skin detection of RGB-D images helps to tightly constrain the skin parts of human body in template fitting step in order to get more precise and lifelike human model. We propose a robust skin detection method that is not affected by clothing pattern and background. Experiments demonstrate the effectiveness of our method.
C1 [Chen, Guang; Li, Jituo; Zeng, Jiping; Wang, Bei; Lu, Guodong] Zhejiang Univ, Coll Mech Engn, Res Ctr Design & Prod Innovat, Room 416,1 Teaching Bldg,Yuquan Campus, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Li, JT (corresponding author), Zhejiang Univ, Coll Mech Engn, Res Ctr Design & Prod Innovat, Room 416,1 Teaching Bldg,Yuquan Campus, Hangzhou 310027, Zhejiang, Peoples R China.
EM jituo_li@zju.edu.cn
FU National Natural Science Foundation of China [51575481, 61379096];
   Project of Public Technology Research in Industry of Zhejiang Province
   [2014C31048]
FX This work was partially supported by National Natural Science Foundation
   of China (51575481, 61379096) and Project of Public Technology Research
   in Industry of Zhejiang Province (2014C31048).
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2007, Symposium on Geometry Processing
   Balan AO, 2008, LECT NOTES COMPUT SC, V5303, P15, DOI 10.1007/978-3-540-88688-4_2
   BOX GEP, 1958, ANN MATH STAT, V29, P610, DOI 10.1214/aoms/1177706645
   Chang W, 2011, ACM T GRAPHIC, V30, P171
   Chen G, 2016, COMPUT ANIMAT VIRT W, V27, P72, DOI 10.1002/cav.1632
   Chen XW, 2013, VISUAL COMPUT, V29, P1187, DOI 10.1007/s00371-013-0775-7
   Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x
   Hasler N, 2010, PROC CVPR IEEE, P1823, DOI 10.1109/CVPR.2010.5539853
   Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Lee JY, 2002, P 2002 INT C IM SCI
   Li J, 2007, P 25 COMP GRAPH INT
   Li JT, 2011, COMPUT GRAPH-UK, V35, P945, DOI 10.1016/j.cag.2011.07.005
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Zeng M, 2015, NEUROCOMPUTING, V151, P626, DOI 10.1016/j.neucom.2014.06.087
   Zeng M, 2013, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2013.26
NR 21
TC 7
Z9 11
U1 1
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2016
VL 20
IS 3
BP 159
EP 172
DI 10.1007/s10055-016-0291-y
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DV0XZ
UT WOS:000382645300002
DA 2024-07-18
ER

PT B
AU Bittermann, MS
   Sariyildiz, IS
AF Bittermann, Michael S.
   Sariyildiz, I. Sevil
BE Kim, JJ
TI Virtual Reality and Computational Design
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID NETWORKS
C1 [Bittermann, Michael S.; Sariyildiz, I. Sevil] Delft Univ Technol, NL-2600 AA Delft, Netherlands.
C3 Delft University of Technology
RP Bittermann, MS (corresponding author), Delft Univ Technol, NL-2600 AA Delft, Netherlands.
RI Bittermann, Michael S./AAX-7926-2020
OI Bittermann, Michael S./0000-0003-3640-0754
CR [Anonymous], 2006, INT J COMPUT INTELL, DOI DOI 10.5019/J.IJCIR.2006.67
   [Anonymous], VIRTUAL REALITY AUGM
   Bittermann M. S., 2009, COGNITIVE APPROACH P, P235
   Bittermann M. S., 2009, IEEE C EV COMP EC 20
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Branke J, 2000, GUIDING MULTIOBJECTI
   Ciftcioglu O., 2009, EVOL COMPUT, P417
   Ciftcioglu Ö, 2006, IEEE SYS MAN CYBERN, P5152, DOI 10.1109/ICSMC.2006.385126
   Ciftcioglu O, 2007, IEEE C EVOL COMPUTAT, P859, DOI 10.1109/CEC.2007.4424560
   COELLO CAC, 2003, EVOLUTIONARY ALGORIT
   Deb K., 2003, 9 ANN C GEN EV COMP, P532
   Deb K., 2010, MULTIOBJECTIVE OPTIM
   Feist W., 2007, PASSIVHAUS PROJEKTIE
   Hettinger LJ, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P1, DOI 10.1201/9781410608888.ch1
   Hopper E, 2001, EUR J OPER RES, V128, P34, DOI 10.1016/S0377-2217(99)00357-4
   Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37
   Hughes EJ, 2005, IEEE C EVOL COMPUTAT, P222
   Jaszkiewicz A, 2004, EUR J OPER RES, V158, P418, DOI 10.1016/j.ejor.2003.06.015
   Whyte J., 2002, VIRTUAL REALITY BUIL
   Wise J. A., 1992, VERIFICATION VALIDAT, P705
   Yang YT, 2005, BIOINFORMATICS, V21, P3645, DOI 10.1093/bioinformatics/bti581
   ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255
NR 22
TC 0
Z9 0
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 547
EP 578
D2 10.5772/553
PG 32
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400028
DA 2024-07-18
ER

PT J
AU Vafai, NM
   Payandeh, S
AF Vafai, Nasim Melony
   Payandeh, Shahram
TI Toward the development of interactive virtual dissection with haptic
   feedback
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Object deformation; Cutting; Dissection; Collision
   detection; Haptics; Force feedback
ID MODEL
AB Traditional, hands-on dissection of an animal is common practice in many classrooms to aid in the study of anatomy and biology. More specifically, virtual dissection environments have been developed making it possible to study the inner workings of animals without cutting them up. In this paper, we present a novel virtual reality dissection simulator, where a user can dissect an animal (i.e. frog) and its organs using a 3D force feedback haptic device. The simulator uses force feedback as part of a multimodal cue to provide guidance and performance feedback to the user. This paper highlights methodologies which are used for addressing some of the key challenges involved in designing and developing simulators, such as: modelling and mechanics of deformation, collision detection between multiple deformable bodies, and haptic feedback.
C1 [Vafai, Nasim Melony; Payandeh, Shahram] Simon Fraser Univ, Expt Robot & Graph Lab, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Vafai, NM (corresponding author), Simon Fraser Univ, Expt Robot & Graph Lab, Burnaby, BC V5A 1S6, Canada.
EM nmvafai@alumni.sfu.ca; shahram@cs.sfu.ca
RI Payandeh, Shahram/IZQ-1865-2023
OI Payandeh, Shahram/0000-0001-6846-7289
CR [Anonymous], 1997, TR9719 MITS EL RES L
   [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   [Anonymous], 2000, Numerical Analysis
   Basdogan C, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1274062
   Basdogan C., 2001, VIRTUAL ENV HDB, P117
   Brown J, 2001, COMP ANIM CONF PROC, P228, DOI 10.1109/CA.2001.982397
   COVER SA, 1993, P ICRA, P68
   Crossan A, 2001, LECT NOTES COMPUT SC, V2058, P157
   DOO D, 1978, COMPUT AIDED DESIGN, V10, P356, DOI 10.1016/0010-4485(78)90111-2
   France L, 2005, MED IMAGE ANAL, V9, P123, DOI 10.1016/j.media.2004.11.006
   Georgii J, 2006, COMPUT GRAPH-UK, V30, P408, DOI 10.1016/j.cag.2006.02.016
   Laugier C, 2003, SPRINGER TRAC ADV RO, V6, P289
   LAWLOR OS, 2002, P 6 INT C SUP JUN, P285
   LIN M, 1999, P IMA C MATH SURF, P37
   Lundin Karljohan, 2007, Virtual Reality, V11, P1, DOI 10.1007/s10055-006-0033-7
   Mendoza C, 2003, SPR TRA ADV ROBOT, V5, P414
   MONTGOMERY K, 2001, VIS 2001
   Palmerius KL, 2008, IEEE T VIS COMPUT GR, V14, P263, DOI 10.1109/TVCG.2007.70409
   PAULY M, 2004, EUR ACM SIGGRAPH S C
   Payandeh S, 2001, 2001 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P224, DOI 10.1109/CIRA.2001.1013201
   PICINBONO G, 1999, INT SCI WORKSH VIRT, P117
   Segerlind L. J., 1976, Applied finite element analysis, V316
   SUNDARAJ K, 2004, THESIS I NATL POLYTE
   Suzuki S, 2004, IEEE T MED IMAGING, V23, P714, DOI 10.1109/TMI.2004.826947
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   TONG C, 2007, P ICMA 2007
   Zhang H, 2004, IEEE INT CONF ROBOT, P3908
   ZHANG J, 2005, ACM T APPL PERCEPT, V2, P15
   ZHENNAN Y, 2007, P 29 ANN INT C IEEE
   ZHOU M, 2006, P ICRA06, P2896
NR 30
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2010
VL 14
IS 2
BP 85
EP 103
DI 10.1007/s10055-009-0132-3
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HV
UT WOS:000296279600001
DA 2024-07-18
ER

PT J
AU Gabay, M
   Schonberg, T
AF Gabay, Michal
   Schonberg, Tom
TI Passive identification of subjective preferences toward individual items
   using eye-tracking in a virtual reality environment
SO VIRTUAL REALITY
LA English
DT Article
DE Eye-tracking; Preferences; Virtual reality (VR); Personalization;
   Internal state; Head-mounted display (HMD)
ID EMOTION RECOGNITION; VISUAL FIXATIONS; MERE EXPOSURE; TECHNOLOGY;
   MOVEMENTS; ATTENTION; MODEL; PAIN
AB The usage of virtual reality (VR) has been growing in many fields of research and therapy thanks to its immersive and gamified nature. Detection of the users' subjective experience is thus essential for the effective personalization of content. Eye-tracking (ET) data and specifically gaze, in two-dimensional tasks, has been linked to value-based choices and emotional states. Therefore, here we aimed to develop a method for passive identification of subjective preferences based on ET data collected during a VR experience. For this purpose, we developed a naturalistic dynamic VR task where participants searched and looked at complex objects of pets and their control shapes that appeared in pre-defined locations in random order. At the end of the task, participants ranked their preference, valence, and arousal of the items they saw during the task. ET data was recorded using a built-in binocular eye-tracker within the VR headset. We found that the gaze behavior features of the median distance of gaze from the center of objects and the median gaze scan speed showed a significant interaction with object type (pets/shapes), as well as a significant positive relation to preference and valence rankings of pets. Our results suggest that these gaze behavior features could be used as passive biomarkers for detecting individual preferences and pleasantness, and in the future may enable successful personalization of VR content in real-time for various applications such as optimization of psychiatric diagnosis and treatment sessions.
C1 [Gabay, Michal; Schonberg, Tom] Tel Aviv Univ, Fac Life Sci, Sch Neurobiol Biochem & Biophys, Tel Aviv, Israel.
   [Gabay, Michal; Schonberg, Tom] Tel Aviv Univ, Sagol Sch Neurosci, Tel Aviv, Israel.
C3 Tel Aviv University; Tel Aviv University
RP Schonberg, T (corresponding author), Tel Aviv Univ, Fac Life Sci, Sch Neurobiol Biochem & Biophys, Tel Aviv, Israel.; Schonberg, T (corresponding author), Tel Aviv Univ, Sagol Sch Neurosci, Tel Aviv, Israel.
EM schonberg@tauex.tau.ac.il
RI Schonberg, Tom/JBS-4839-2023
OI Schonberg, Tom/0000-0002-4485-816X; Gabay, Michal/0000-0002-7377-7385
CR Aracena C, 2015, IEEE SYS MAN CYBERN, P2632, DOI 10.1109/SMC.2015.460
   Areces D, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9100274
   Balcombe K, 2015, J APPL ECONOMET, V30, P447, DOI 10.1002/jae.2383
   Bashiardes S, 2018, CURR OPIN BIOTECH, V51, P57, DOI 10.1016/j.copbio.2017.11.013
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Bernacki ML, 2018, J EDUC PSYCHOL, V110, P864, DOI 10.1037/edu0000250
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bogicevic V, 2019, TOURISM MANAGE, V74, P55, DOI 10.1016/j.tourman.2019.02.009
   Burdea G. C., 2003, Virtual reality technology
   Carter BT, 2020, INT J PSYCHOPHYSIOL, V155, P49, DOI 10.1016/j.ijpsycho.2020.05.010
   Castelhano MS, 2009, J VISION, V9, DOI 10.1167/9.3.6
   Cesa GL, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2441
   Chirico A, 2016, J CELL PHYSIOL, V231, P275, DOI 10.1002/jcp.25117
   Loureiro SMC, 2019, J BUS RES, V100, P514, DOI 10.1016/j.jbusres.2018.10.055
   Coutrot A, 2018, BEHAV RES METHODS, V50, P362, DOI 10.3758/s13428-017-0876-8
   Dahlquist LM, 2010, J PEDIATR PSYCHOL, V35, P617, DOI 10.1093/jpepsy/jsp082
   Dixson BJ, 2011, ARCH SEX BEHAV, V40, P51, DOI 10.1007/s10508-010-9601-8
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Freeman D, 2022, LANCET PSYCHIAT, V9, P375, DOI 10.1016/S2215-0366(22)00060-8
   Freeman D, 2019, TRIALS, V20, DOI 10.1186/s13063-019-3198-6
   Graham DJ, 2012, PUBLIC HEALTH NUTR, V15, P189, DOI 10.1017/S1368980011001303
   Hasson Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222342
   Herrero R, 2014, CYBERPSYCH BEH SOC N, V17, P379, DOI 10.1089/cyber.2014.0052
   Huang JP, 2021, J BUS RES, V123, P604, DOI 10.1016/j.jbusres.2020.10.031
   Hwang GJ, 2012, ETR&D-EDUC TECH RES, V60, P623, DOI 10.1007/s11423-012-9241-x
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jeffs D, 2014, J BURN CARE RES, V35, P395, DOI 10.1097/BCR.0000000000000019
   Khamis M, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206522
   Kim J, 2020, BEHAV RES METHODS, V52, P1225, DOI 10.3758/s13428-019-01313-2
   Kim M., 2013, INT J SUSTAIN TROP D, V6, P85
   Krajbich I, 2011, P NATL ACAD SCI USA, V108, P13852, DOI 10.1073/pnas.1101328108
   Krajbich I, 2010, NAT NEUROSCI, V13, P1292, DOI 10.1038/nn.2635
   Lanatà A, 2013, J AMB INTEL HUM COMP, V4, P705, DOI 10.1007/s12652-012-0147-6
   Lang P.J., 1997, INT AFFECTIVE PICTUR, P39, DOI DOI 10.1027/0269-8803/A000147
   Lappi O, 2016, NEUROSCI BIOBEHAV R, V69, P49, DOI 10.1016/j.neubiorev.2016.06.006
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Liao D, 2020, IEEE J ELECTROMAG RF, V4, P216, DOI 10.1109/JERM.2019.2948767
   Lim JZ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082384
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Mathot Sebastiaan, 2018, J Cogn, V1, P16, DOI 10.5334/joc.18
   Meissner M., 2017, J BUS RES, DOI [DOI 10.1016/J.JBUSRES.2017.09.028, 10.1016/j.jbusres.2017.09.028]
   Melendrez-Ruiz J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.655273
   Mikhailenko M, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.697032
   Ng ICL, 2017, INT J RES MARK, V34, P3, DOI 10.1016/j.ijresmar.2016.11.003
   Noland RobertB., 2017, J URBANISM INT RES P, V10, P98, DOI DOI 10.1080/17549175.2016.1187197
   Oren S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00988
   Orlosky J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P66, DOI 10.1109/AIVR46125.2019.00019
   Ossmy O, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168520
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pfeiffer J, 2020, INFORM SYST RES, V31, P675, DOI 10.1287/isre.2019.0907
   Pietrock C, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13463
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   R-Tavakoli H, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138198
   Raudonis V, 2013, INT J ADV COMPUT SC, V4, P79
   Ravyse WS, 2017, VIRTUAL REAL-LONDON, V21, P31, DOI 10.1007/s10055-016-0298-4
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   Reggente N, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00408
   Rodrigues J, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19736-3
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sacks LD, 2020, CURR OPIN CARDIOL, V35, P37, DOI 10.1097/HCO.0000000000000694
   Salomon T, 2020, HUM BRAIN MAPP, V41, P1043, DOI 10.1002/hbm.24859
   Sato Shumpei, 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968869
   Schleidgen S, 2013, BMC MED ETHICS, V14, DOI 10.1186/1472-6939-14-55
   Schork NJ, 2015, NATURE, V520, P609, DOI 10.1038/520609a
   Seamon JG, 1997, MEM COGNITION, V25, P367, DOI 10.3758/BF03211292
   Shimojo S, 2003, NAT NEUROSCI, V6, P1317, DOI 10.1038/nn1150
   Shu Y., 2019, VIRTUAL REAL-LONDON, V23, P437, DOI [DOI 10.1007/S10055-018-0376-X., DOI 10.1007/S10055-018-0376-X]
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Soler-Dominguez JL, 2017, LECT NOTES COMPUT SC, V10280, P369, DOI 10.1007/978-3-319-57987-0_30
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Sugano Y, 2014, EYE MOVEMENT RES, V7, DOI [10.16910/jemr.7.3.5, DOI 10.16910/JEMR.7.3.5]
   Susskind JM, 2008, NAT NEUROSCI, V11, P843, DOI 10.1038/nn.2138
   Tabbaa L, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3495002
   Van Loo EJ, 2015, ECOL ECON, V118, P215, DOI 10.1016/j.ecolecon.2015.07.011
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [10.1007/978-3-319-24277-4, DOI 10.1007/978-3-319-24277-4]
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Wu D., 2016, ELECT IMAGING, V28, P1, DOI [10.2352/ISSN.2470-1173.2016.4.ERVR-419, DOI 10.2352/ISSN.2470-1173.2016.4.ERVR-419]
   Wu Y, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182010944
   Xiao Jun., 2018, J AMB INTEL HUM COMP, V9, P667, DOI [DOI 10.1155/2017/8147075, DOI 10.1007/S12652-017-0466-8]
   ZAJONC RB, 1982, J CONSUM RES, V9, P123, DOI 10.1086/208905
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
   Zajonc RB, 2001, CURR DIR PSYCHOL SCI, V10, P224, DOI 10.1111/1467-8721.00154
   Zandonai T, 2021, J SUBST ABUSE TREAT, V125, DOI 10.1016/j.jsat.2021.108317
   Zheng LJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING (ICOCO), P315, DOI 10.1109/ICOCO53166.2021.9673503
   Zheng LJ, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00322-9
   Ziho Kang, 2020, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V64, P821, DOI 10.1177/1071181320641191
NR 90
TC 0
Z9 0
U1 10
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2723
EP 2743
DI 10.1007/s10055-023-00839-3
EA AUG 2023
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001042081700001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Qi, M
   Liu, YQ
   Cui, J
AF Qi, Meng
   Liu, Yunqiu
   Cui, Jia
TI A mapping-based redirected walking algorithm for large-scale VR
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Real Walking; Redirected Walking; Internal Energy
ID SPEED
AB In VR, the size mismatch between virtual and real space is one of the difficulties, so walking through a large-scale VR scene in a real small area (tracking space) is a challenging problem. We design a novel redirected walking (RDW) algorithm based on a mapping approach to direct users away from the boundary of the tracking area with low rotational distortion. First, the virtual path is decomposed into a set of segments. Then, each segment is mapped into curves and stitched together by minimizing the internal energy with smoothness constraints between adjacent curves. Ultimately, we obtain continuous and smooth curves in the real space. We conduct both simulated and live-user studies to validate the algorithm. Experimental results show that our algorithm has no reset compared with other RDW methods, can significantly speed up and smooth the navigation, reduce perceptual distortion, and show the potential to steer multi-user simultaneously in realtime.
C1 [Qi, Meng; Liu, Yunqiu] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Cui, Jia] South China Univ Technol, Sch Design, Guangzhou, Peoples R China.
C3 Shandong Normal University; South China University of Technology
RP Qi, M (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
EM qimeng@sdnu.edu.cn; yql@stu.sdnu.edu.cn; cuijia1247@scut.edu.cn
FU National Natural Science Foundation of China [61902225]; Natural Science
   Foundation of Shandong Province [ZR2021LZL011]
FX The funding was provided by National Natural Science Foundation of China
   (Grant no. 61902225); Natural Science Foundation of Shandong Province
   (Grant no. ZR2021LZL011)
CR Azmandian M, 2017, EVERYDAY VIRTUAL REA
   Azmandian M., 2015, ICAT-EGVE), P93
   Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Azmandian M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P65, DOI 10.1109/VR.2014.6802053
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Browning RC, 2006, J APPL PHYSIOL, V100, P390, DOI 10.1152/japplphysiol.00767.2005
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Dong ZC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3345554
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Escobar JM, 2003, COMPUT METHOD APPL M, V192, P2775, DOI 10.1016/S0045-7825(03)00299-8
   Fu XM, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766938
   Grechkin T., 2016, P ACM S APPL PERC, P113
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hollerbach JM, 2000, DESIGN SPECIFICATION
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Le Moan S, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P89, DOI 10.1109/SITIS.2015.20
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Mohler BJ, 2007, EXP BRAIN RES, V181, P221, DOI 10.1007/s00221-007-0917-0
   Neth CT, 2011, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2011.5759454
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Poranne R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601123
   Qi Sun, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P285, DOI 10.1007/978-3-030-41816-8_12
   Razzaque S., 2001, Proc. Eurogr, P289, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Robinett R., 1992, P 1992 S INT 3D GRAP, P189, DOI 10.1145/147156.1472012
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   VELTKAMP RC, 1995, COMPUT GRAPH FORUM, V14, pC97, DOI 10.1111/j.1467-8659.1995.cgf143_0097.x
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   You C, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3358757
NR 34
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2745
EP 2756
DI 10.1007/s10055-023-00841-9
EA AUG 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001042081700002
DA 2024-07-18
ER

PT J
AU Serino, S
   Sansoni, M
   Di Lernia, D
   Parisi, A
   Tuena, C
   Riva, G
AF Serino, Silvia
   Sansoni, Maria
   Di Lernia, Daniele
   Parisi, Alessandra
   Tuena, Cosimo
   Riva, Giuseppe
TI 360-degree video-based body-ownership illusion for inducing embodiment:
   development and feasibility results
SO VIRTUAL REALITY
LA English
DT Article
DE Bodily Illusion; 360-degree videos; Body Ownership; Embodiment
ID VIRTUAL-REALITY; OBJECTIFICATION; METAVERSE
AB Illusions that create a sense of ownership over a virtual body have been widely used to investigate the characteristics of our bodily experience. Despite the great potential of 360-degree videos to implement full-body ownership illusion, research is in its early stages, and no validated tools-neither commercial nor free-are available for the scientific and clinical community. In the current study, we present and discuss the development and feasibility results of a free 360-degree video-based body ownership illusion that researchers and scholars can experience using a cardboard headset with their smartphones. Forty-six participants underwent the 360-degree video-based full-body ownership illusion, visualizing in a first-person perspective (1PP) or in a mirror view the pre-recorded body of a young female performer. All participants were exposed to a congruent visuo-tactile condition (embodiment condition) and to an incongruent visuo-tactile condition (control condition). Participants completed the Embodiment Questionnaire and the Objectified Body Consciousness (OBC) scale. Results revealed that in the congruent visuo-tactile condition (compared to the control one), participants experienced a strong illusion in terms of body ownership, self-location, and agency. In terms of visual perspective, there was no difference in embodiment feelings between participants who experienced the illusion in 1PP and those who underwent a mirror perspective. Lastly, the control beliefs subscale (i.e., OBC scale) displayed a positive correlation with the self-location illusion susceptibility. Overall, these results point to the feasibility of this novel tool as immersive 360-degree video-based scenarios to deliver bodily illusions, and they open new avenues for future clinical interventions.
C1 [Serino, Silvia; Sansoni, Maria; Di Lernia, Daniele; Parisi, Alessandra] Univ Cattolica Sacro Cuore, Dept Psychol, Largo Gemelli 1, I-20100 Milan, Italy.
   [Riva, Giuseppe] Univ Cattolica Sacro Cuore, Humane Technol Lab, Largo Gemelli 1, I-20100 Milan, Italy.
   [Tuena, Cosimo; Riva, Giuseppe] Ist Auxol Italiano IRCCS, Appl Technol Neuropsychol Lab, Via Magnasco 2, I-20149 Milan, Italy.
   [Serino, Silvia] Univ Milano Bicocca, Dept Psychol, Piazza Ateneo Nuovo 1, I-20126 Milan, MI, Italy.
C3 Catholic University of the Sacred Heart; Catholic University of the
   Sacred Heart; IRCCS Istituto Auxologico Italiano; University of
   Milano-Bicocca
RP Serino, S (corresponding author), Univ Cattolica Sacro Cuore, Dept Psychol, Largo Gemelli 1, I-20100 Milan, Italy.; Serino, S (corresponding author), Univ Milano Bicocca, Dept Psychol, Piazza Ateneo Nuovo 1, I-20126 Milan, MI, Italy.
EM silvia.serino@unicatt.it
RI DI LERNIA, Daniele/JXL-9957-2024; Serino, Silvia/K-5142-2016
OI DI LERNIA, Daniele/0000-0001-6850-6866; Serino,
   Silvia/0000-0002-8422-1358; Parisi, Alessandra/0000-0002-8570-4175
FU project Arcadia VR - Assistenza e Riabilitazione del Comportamento
   Alimentare tramite Dispositivi basati sull'Intelligenza Artificiale e
   sulla Realta Virtuale; Italian Ministry of Health; Universita degli
   Studi di Milano - Bicocca within the CRUI-CARE Agreement
FX The work in this paper was partially supported by the project Arcadia VR
   - Assistenza e Riabilitazione del Comportamento Alimentare tramite
   Dispositivi basati sull'Intelligenza Artificiale e sulla Realta Virtuale
   (Assistance and Rehabilitation of Eating Behavior through Devices Based
   on Artificial Intelligence and Virtual Reality) - MINISTERIAL DECREE
   DECEMBER 31, 2021 - INNOVATION AGREEMENTS and by the Italian Ministry of
   Health.Open access funding provided by Universita degli Studi di Milano
   - Bicocca within the CRUI-CARE Agreement
CR Adams-Clark AA, 2019, EQUAL DIVERS INCL, V39, P38, DOI 10.1108/EDI-11-2018-0211
   Aitamurto T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174119
   Blanke O, 2015, NEURON, V88, P145, DOI 10.1016/j.neuron.2015.09.029
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Dakanalis A, 2017, ARCH WOMEN MENT HLTH, V20, P721, DOI 10.1007/s00737-017-0761-6
   Dakanalis A, 2017, ASSESSMENT, V24, P252, DOI 10.1177/1073191115602553
   Fredrickson BL, 1997, PSYCHOL WOMEN QUART, V21, P173, DOI 10.1111/j.1471-6402.1997.tb00108.x
   Kaplan RA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099981
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Orsmond GI, 2015, OTJR-OCCUP PART HEAL, V35, P169, DOI 10.1177/1539449215578649
   Peat CM, 2011, PSYCHOL WOMEN QUART, V35, P441, DOI 10.1177/0361684311400389
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Preston C, 2015, SCI REP-UK, V5, DOI 10.1038/srep18345
   Rabellino D, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00163
   Riva G, 2021, ANN REV CYBERTHERAPY, V19, P3, DOI 10.3390/Fijerph19031525
   Riva G, 2022, CYBERPSYCH BEH SOC N, V25, P355, DOI 10.1089/cyber.2022.0124
   Riva G, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18158188
   Riva G, 2018, ANN REV CYBERTHERAPY, V16, P3
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Riva G, 2018, CORTEX, V104, P241, DOI 10.1016/j.cortex.2017.07.013
   Riva G, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00120
   Riva G, 2015, EUR PSYCHOL, V20, P34, DOI 10.1027/1016-9040/a000190
   Riva G, 2014, EAT WEIGHT DISORD-ST, V19, P133, DOI 10.1007/s40519-013-0066-3
   Sansoni M., 2022, LECT NOTES COMPUTER
   Sansoni Maria, 2022, Cyberpsychol Behav Soc Netw, V25, P620, DOI 10.1089/cyber.2022.29255.ceu
   Sansoni M, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.916227
   Serino S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01878
   Serino S, 2017, ANN PHYS REHABIL MED, V60, P217, DOI 10.1016/j.rehab.2016.10.002
   Serino S, 2016, CYBERPSYCH BEH SOC N, V19, P127, DOI 10.1089/cyber.2015.0229
   Sierra M, 2011, CONSCIOUS COGN, V20, P99, DOI 10.1016/j.concog.2010.10.018
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Tian Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376557
   Valzolgher C, 2018, ACTA PSYCHOL, V191, P261, DOI 10.1016/j.actpsy.2018.09.009
   Ventura S, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.845508
   Ventura S, 2022, VIRTUAL REAL-LONDON, V26, P323, DOI 10.1007/s10055-021-00567-6
   Ventura S, 2021, CYBERPSYCH BEH SOC N, V24, P258, DOI 10.1089/cyber.2020.0209
NR 39
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2665
EP 2672
DI 10.1007/s10055-023-00836-6
EA JUL 2023
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001034243100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zaidi, SFM
   Shafiabady, N
   Beilby, J
AF Zaidi, Syed Fawad M.
   Shafiabady, Niusha
   Beilby, Justin
TI Identifying presence of cybersickness symptoms using AI-based predictive
   learning algorithms
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness (CS); Virtual reality (VR); Head-mounted displays (HMDs);
   Machine learning (ML); Artificial intelligence (AI); Support vector
   machines (SVMs); Decision trees (DTs); K-nearest neighbours (KNNs)
ID VIRTUAL-REALITY; MACHINE
AB Cybersickness (CS) affects a large proportion of virtual reality (VR) users causing a combination of nausea, headaches and dizziness which would create barriers to the users, VR designers/developers and the stakeholders in the production industry. Although design principles suggest methods to avoid CS, challenges remain as new demands and systems continue to penetrate the competitive market. The dilemma is whether to use VR technology by experiencing the ultimate virtual world using a head-mounted display (HMD) with possible CS triggers or to avoid the triggers by avoiding using VR. With the huge success and potential in the entertainment industry, it is very important to focus on the solutions to handling CS dilemmas. Therefore, the main observation for the developers is to have a guide around the set of established design principles aiming to broadly reduce CS. In this paper, we provide a method to apply artificial intelligence (AI) techniques and use machine learning (ML) algorithms including support vector machines (SVMs), decision trees (DTs) and K-nearest neighbours (KNNs) to predict CS outcomes. Based on our findings, we have observed that DT and SVM surpassed KNN in test accuracy. Additionally, DT exhibited better results than both SVM and KNN in train accuracy. By exploiting the power of ML, developers will be able to predict the potential occurrence of CS while developing VR projects to find ways to alleviate CS more effectively.
C1 [Zaidi, Syed Fawad M.] Torrens Univ Australia, Dept Business Informat Syst, Surry Hills, NSW 2000, Australia.
   [Shafiabady, Niusha] Charles Darwin Univ, Fac Sci & Technol, Haymarket, NSW 2000, Australia.
   [Beilby, Justin] Torrens Univ Australia, Adelaide, SA 5000, Australia.
C3 Torrens University Australia; Charles Darwin University; Torrens
   University Australia
RP Shafiabady, N (corresponding author), Charles Darwin Univ, Fac Sci & Technol, Haymarket, NSW 2000, Australia.
EM fawad.zaidi@torrens.edu.au; niusha.shafiabady@cdu.edu.au;
   jbeilby@adj.torrens.edu.au
OI Shafiabady, Niusha/0000-0001-7668-8524
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Agic A., 2020, VR J GRAPH ENG, V11, P5
   Ambagtsheer RC, 2020, INT J MED INFORM, V136, DOI 10.1016/j.ijmedinf.2020.104094
   Batista GEAPA., 2009, ARGENTINE S ARTIFICI, P1
   Bishop I, 2018, 2ND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2018), P151, DOI 10.1145/3206098.3206108
   Boletsis C, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6090072
   Budhiraja P, 2017, ARXIV
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Choros K, 2019, LECT NOTES ARTIF INT, V11431, P638, DOI 10.1007/978-3-030-14799-0_55
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Curry C, 2019, APAL 2019 POSTURAL D
   David-Grignot Stephane, 2014, Proceedings 2014 IEEE International Test Conference (ITC), DOI 10.1109/TEST.2014.7035301
   Díaz-Pérez E, 2018, REV NEUROLOGIA, V66, P344, DOI 10.33588/rn.6610.2017438
   Dichgans Johannes, 1978, Perception, P755, DOI [DOI 10.1007/978-3-642-46354-9253F, DOI 10.1007/978-3-642-46354-9_25, DOI 10.1007/978-3-642-46354-925]
   Donabauer J, 2019, THESIS WIEN
   El Beheiry M, 2019, J MOL BIOL, V431, P1315, DOI 10.1016/j.jmb.2019.01.033
   Fagernäs S, 2021, INTERNET INTERV, V24, DOI 10.1016/j.invent.2021.100370
   Gandedkar NH, 2021, SEMIN ORTHOD, V27, P69, DOI 10.1053/j.sodo.2021.05.003
   Garcia-Agundez A, 2019, GAMES HEALTH J, V8, P439, DOI 10.1089/g4h.2019.0045
   Garcia-Agundez A, 2017, LECT NOTES COMPUT SC, V10622, P203, DOI 10.1007/978-3-319-70111-0_19
   Geraci RM., 2010, APOCALYPTIC AI VISIO, DOI [10.1093/acprof:oso/9780195393026.001.0001, DOI 10.1093/ACPROF:OSO/9780195393026.001.0001]
   Hadadi A, 2022, PREDICTION CYBERSICK
   Iskander J, 2019, TRANSPORT RES F-TRAF, V62, P716, DOI 10.1016/j.trf.2019.02.020
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Jin WN, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P382, DOI 10.1109/GEM.2018.8516469
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kwok KKK, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P91, DOI 10.1109/ISMAR-Adjunct.2018.00041
   Laukkanen S, 2004, FRONT ARTIF INTEL AP, V110, P1136
   Li M, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/6243085
   Lou RD, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1058, DOI [10.1109/vr.2019.8798164, 10.1109/VR.2019.8798164]
   Louis T, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P5, DOI 10.1145/3343055.3359710
   Malini N., 2017, 2017 Third International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB). Proceedings, P255, DOI 10.1109/AEEICB.2017.7972424
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Mayor J, 2021, IEEE T EMERG TOP COM, V9, P1542, DOI 10.1109/TETC.2019.2915287
   Mustafa Zaidi Syed Fawad., 2018, Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology, P1, DOI DOI 10.1145/3284398.3284431
   Navada A., 2011, 2011 IEEE Control and System Graduate Research Colloquium (ICSGRC), P37, DOI 10.1109/ICSGRC.2011.5991826
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Oh S, 2021, CYBERPSYCH BEH SOC N, V24, P729, DOI 10.1089/cyber.2020.0613
   Pallavicini F, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/15635
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Paroz A, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P582, DOI 10.1145/3292147.3292229
   Pastel S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0263112
   Porcino T, 2022, ENTERTAIN COMPUT, V41, DOI 10.1016/j.entcom.2021.100473
   Porcino T, 2020, SYMP VIRTUAL AUGMENT, P154, DOI 10.1109/SVR51698.2020.00035
   Prithul A, 2021, FRONTIERS VIRTUAL RE, V138
   Qi D, 2021, SURG ENDOSC, V35, P779, DOI 10.1007/s00464-020-07447-1
   Chandra ARN, 2022, COMPUTERS, V11, DOI 10.3390/computers11040051
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Shafiabady N, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0283066
   Shamrat F.M., 2019, International Journal of Scientific & Technology Research, V8, P2576
   Shin D, 2019, INFORM COMMUN SOC, V22, P1212, DOI 10.1080/1369118X.2017.1411519
   Shirvan R. A., 2011, 2011 18th Iranian Conference of Biomedical Engineering (ICBME), P278, DOI 10.1109/ICBME.2011.6168572
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Sutherland IE, 1965, P IFIP C
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Widodo A, 2007, MECH SYST SIGNAL PR, V21, P2560, DOI 10.1016/j.ymssp.2006.12.007
   Wu FJ, 2021, POLYM ENG SCI, V61, P1415, DOI 10.1002/pen.25658
   Yamamura Hiroo, 2020, UIST '20: 33rd Annual ACM Symposium on User Interface Software and Technology, P56, DOI 10.1145/3379350.3416184
   Yang Z.R., 2010, Machine learning approaches to bioinformatics, V4
   Yeh SC, 2014, COMPUT METH PROG BIO, V116, P311, DOI 10.1016/j.cmpb.2014.04.014
   Zaidi SFM, 2020, P 26 ACM S VIRT REAL, P1
   Zaidi SFM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010142
   Zaidi SFM, 2019, ICIGP 2019: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING / 2019 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, P140, DOI 10.1145/3313950.3313977
   Zhao JC, 2023, EUR BUS ORGAN LAW RE, V24, P1, DOI 10.1007/s40804-022-00262-2
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P398, DOI [10.1109/VR46266.2020.00-44, 10.1109/VR46266.2020.1581426770550]
NR 69
TC 1
Z9 1
U1 6
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3613
EP 3620
DI 10.1007/s10055-023-00813-z
EA MAY 2023
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001033240100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Kabuye, E
   LeDuc, P
   Cagan, J
AF Kabuye, Ernest
   LeDuc, Philip
   Cagan, Jonathan
TI A mixed reality system combining augmented reality, 3D bio-printed
   physical environments and inertial measurement unit sensors for task
   planning
SO VIRTUAL REALITY
LA English
DT Article
DE Task planning; Augmented reality; Three-dimensional biological printing;
   Inertial measurement unit
ID SURGERY; SCALE; SKIN
AB Successful surgical operations are characterized by preplanning routines to be executed during actual surgical operations. To achieve this, surgeons rely on the experience acquired from the use of cadavers, enabling technologies like virtual reality (VR) and clinical years of practice. However, cadavers, having no dynamism and realism as they lack blood, can exhibit limited tissue degradation and shrinkage, while current VR systems do not provide amplified haptic feedback. This can impact surgical training increasing the likelihood of medical errors. This work proposes a novel Mixed Reality Combination System (MRCS) that pairs Augmented Reality (AR) technology and an inertial measurement unit (IMU) sensor with 3D printed, collagen-based specimens that can enhance task performance like planning and execution. To achieve this, the MRCS charts out a path prior to a user task execution based on a visual, physical, and dynamic environment on the state of a target object by utilizing surgeon-created virtual imagery that, when projected onto a 3D printed biospecimen as AR, reacts visually to user input on its actual physical state. This allows a real-time user reaction of the MRCS by displaying new multi-sensory virtual states of an object prior to performing on the actual physical state of that same object enabling effective task planning. Tracked user actions using an integrated 9-Degree of Freedom IMU demonstrate task execution This demonstrates that a user, with limited knowledge of specific anatomy, can, under guidance, execute a preplanned task. In addition, to surgical planning, this system can be generally applied in areas such as construction, maintenance, and education.
C1 [Kabuye, Ernest; LeDuc, Philip; Cagan, Jonathan] Carnegie Mellon Univ, Dept Mech Engn, 5000 Forbes Ave, Pittsburgh, PA 15232 USA.
C3 Carnegie Mellon University
RP LeDuc, P; Cagan, J (corresponding author), Carnegie Mellon Univ, Dept Mech Engn, 5000 Forbes Ave, Pittsburgh, PA 15232 USA.
EM ekabuye@andrew.cmu.edu; prl@andrew.cmu.edu; cagan@cmu.edu
OI Kabuye, Ernest/0000-0003-0314-9946; Cagan, Jonathan/0000-0002-3935-9219;
   Leduc, Philip/0000-0002-5342-8567
FU Office of Naval Research [N00014-17-1- 2566]; National Institute of
   Health [R21AR08105201A1, R01AG06100501A1]; Air Force Office of
   Scientific Research [FA9550-18-1- 0262]; National Science Foundation
   [CMMI-1946456]
FX The authors would like to thank Anatomage, Inc., for providing their
   digital cadaver models. The authors also thank Andres Arias Rosales and
   Joshua Gyory for their comments on this manuscript. This work was
   partially supported by the Office of Naval Research (Grant N00014-17-1-
   2566), the National Institute of Health (R21AR08105201A1;
   R01AG06100501A1), the Air Force Office of Scientific Research
   (FA9550-18-1- 0262), and the National Science Foundation (CMMI-1946456)
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Al Janabi HF, 2020, SURG ENDOSC, V34, P1143, DOI 10.1007/s00464-019-06862-3
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Alves JB, 2021, INT J ADV MANUF TECH, V115, P105, DOI 10.1007/s00170-021-07049-8
   Baird K. M., 1999, Virtual Reality, V4, P250, DOI 10.1007/BF01421808
   Balta JY, 2015, ANAT SCI EDUC, V8, P86, DOI 10.1002/ase.1470
   Buchner J, 2022, J COMPUT ASSIST LEAR, V38, P285, DOI 10.1111/jcal.12617
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Clymer D.R., J ENG SCI MED DIAGN, V2020, P011004, DOI DOI 10.1115/1.4044645
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   Curtis NJ, 2020, JAMA SURG, V155, P590, DOI 10.1001/jamasurg.2020.1004
   Deutschmann H, 2008, STRAHLENTHER ONKOL, V184, P93, DOI 10.1007/s00066-008-1742-5
   Dilley J, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2075
   Efanov JI, 2018, PRS-GLOB OPEN, V6, DOI 10.1097/GOX.0000000000001443
   Egan P, 2015, DES SCI, V1, DOI 10.1017/dsj.2015.3
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Fan MQ, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9999654
   Fan Z., 2018, Mixed and Augmented Reality in Medicine, P251, DOI DOI 10.1201/9781315157702-17
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Geuss MN, 2015, HUM FACTORS, V57, P1235, DOI 10.1177/0018720815590300
   Grushko S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113673
   Hosseini-Farid M, 2019, SCI IRAN, V26, P2047, DOI 10.24200/sci.2019.21314
   Jannin P., 2018, Mixed and Augmented Reality in Medicine, P115, DOI DOI 10.1201/9781315157702-8
   Jeffri NFS, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06277
   Joodaki H, 2018, P I MECH ENG H, V232, P323, DOI 10.1177/0954411918759801
   Kabuye E, 2022, IEEE SENS J, V22, P4651, DOI 10.1109/JSEN.2022.3145312
   Kennel L, 2018, ANAT SCI EDUC, V11, P166, DOI 10.1002/ase.1715
   Kersten-Oertel M, 2013, COMPUT MED IMAG GRAP, V37, P98, DOI 10.1016/j.compmedimag.2013.01.009
   Kim DH, 2019, CLIN EXP OTORHINOLAR, V12, P12
   Lam CK, 2014, VIRTUAL REAL-LONDON, V18, P281, DOI 10.1007/s10055-014-0251-3
   Lee A, 2019, SCIENCE, V365, P482, DOI 10.1126/science.aav9051
   Lee Randy, 2013, Augmented Environments for Computer-Assisted Interventions. 7th International Workshop, AE-CAI 2012. Held in Conjunction with MICCAI 2012. Revised Selected Papers, P77, DOI 10.1007/978-3-642-38085-3_9
   Li CH, 2012, J R SOC INTERFACE, V9, P831, DOI 10.1098/rsif.2011.0583
   Liberatore MJ, 2021, VIRTUAL REAL-LONDON, V25, P773, DOI 10.1007/s10055-020-00492-0
   Lin W, 2022, VIRTUAL REAL-LONDON, V26, P399, DOI 10.1007/s10055-021-00578-3
   Luo ZQ, 2011, FRONT MECH ENG-PRC, V6, P23, DOI 10.1007/s11465-011-0202-6
   Marquez P, 2021, INT J COMPUT ASS RAD, V16, P331, DOI 10.1007/s11548-020-02288-8
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Mirdamadi E, 2020, ACS BIOMATER SCI ENG, V6, P6453, DOI 10.1021/acsbiomaterials.0c01133
   Mutasim AK, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382924
   Neumann P., 1999, Virtual Reality, V4, P213, DOI 10.1007/BF01418157
   Pereira N, 2019, J PLAST RECONSTR AES, V72, P759, DOI 10.1016/j.bjps.2018.12.023
   Pfeiffer M, 2018, INT J COMPUT ASS RAD, V13, P741, DOI 10.1007/s11548-018-1730-x
   Pulijala Y, 2018, INT J ORAL MAX SURG, V47, P1199, DOI 10.1016/j.ijom.2018.01.005
   Qiu KJ, 2019, IEEE T ROBOT, V35, P799, DOI 10.1109/TRO.2019.2909085
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rho G, 2020, IEEE INT SYM MED MEA, DOI 10.1109/memea49120.2020.9137171
   Ritchie J, 2021, 5TH ASIAN CHI SYMPOSIUM PROCEEDINGS, P210, DOI 10.1145/3429360.3468214
   Rodrigues DaniloGasques., 2017, Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P2591, DOI DOI 10.1145/3027063.3053273
   Sei Y, 2014, MICROFLUID NANOFLUID, V16, P907, DOI 10.1007/s10404-014-1341-y
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Tamam C, 2014, SPORTS MED ARTHROSC, V22, P219, DOI 10.1097/JSA.0000000000000043
   Tan S, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P697, DOI 10.1109/WHC49131.2021.9517185
   Tejo-Otero A, 2020, ANN BIOMED ENG, V48, P536, DOI 10.1007/s10439-019-02411-0
   Tovares N, 2014, J MECH DESIGN, V136, DOI 10.1115/1.4027985
   Vedbhushan ST, 2013, INDIAN J SURG, V75, P440, DOI 10.1007/s12262-012-0520-x
   Vishniakou I, 2019, J NEUROSCI METH, V327, DOI 10.1016/j.jneumeth.2019.108403
   Wan L, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16458-3
   Xi NN, 2023, INFORM SYST FRONT, V25, P659, DOI 10.1007/s10796-022-10244-x
   Yeung AWK, 2021, J MED INTERNET RES, V23, DOI 10.2196/25499
   Yu JZ, 2017, BIOMATERIALS, V128, P109, DOI 10.1016/j.biomaterials.2017.02.014
NR 61
TC 1
Z9 2
U1 1
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1845
EP 1858
DI 10.1007/s10055-023-00777-0
EA MAR 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000942708400001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Lee, CMS
   Fong, KNK
   Mok, MMY
   Lam, MK
   Kung, Y
   Chan, PPW
   Ma, MKM
   Lui, SL
   Kwan, LPY
   Chu, WL
   Hui, PC
   Yau, CSF
   Kwan, IWL
   Chan, KYM
   Chan, TM
AF Lee, Connie M. S.
   Fong, Kenneth N. K.
   Mok, Maggie M. Y.
   Lam, M. K.
   Kung, Y.
   Chan, Paven P. W.
   Ma, Maggie K. M.
   Lui, S. L.
   Kwan, Lorraine P. Y.
   Chu, W. L.
   Hui, P. C.
   Yau, Christina S. F.
   Kwan, Ivan W. L.
   Chan, Kelsey Y. M.
   Chan, T. M.
TI Application of virtual reality for peritoneal dialysis exchange learning
   in patients with end-stage renal disease and cognitive impairment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; End-stage renal disease; Peritoneal dialysis; Cognitive
   impairment
ID CHRONIC KIDNEY-DISEASE; HONG-KONG; OLDER-ADULTS; REHABILITATION; IMPACT;
   RELIABILITY; PREVALENCE; VALIDATION
AB Cognitive impairment is not uncommon in patients with end-stage renal disease and can make it more difficult for these patients to carry out peritoneal dialysis (PD) on their own. Their attempts to do so may result in adverse consequences such as peritonitis. PD exchange is a complex procedure demanding knowledge and skill which requires close supervision and guidance by a renal nurse specialist. In this study, a non-immersive virtual reality (VR) training program using a Leap motion hand tracking device was developed to facilitate patients' understanding and learning of the PD exchange procedure before attempting real task practice. This study was a two-center single-blinded randomized controlled trial on 23 incident PD patients. Patients in the experimental group received 8 sessions of VR training, while patients in the control were provided with printed educational materials. The results showed that there were significant differences between the two groups in performance of the overall PD exchange sequence, especially on the crucial steps. VR had a patient satisfaction rate of 89%, and all patients preferred to have the VR aid incorporated in PD training. Our findings conclude VR can be a useful aid in the training and reinforcement of PD exchange procedures, with distinct merits of being free from restrictions of time, space, and manpower.
C1 [Lee, Connie M. S.; Fong, Kenneth N. K.] Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Peoples R China.
   [Lee, Connie M. S.] Queen Mary Hosp, Dept Occupat Therapy, Hong Kong, Peoples R China.
   [Mok, Maggie M. Y.; Lui, S. L.; Kwan, Lorraine P. Y.; Chu, W. L.; Hui, P. C.] Tung Wah Hosp, Dept Med, Hong Kong, Peoples R China.
   [Lam, M. K.; Kung, Y.; Chan, Paven P. W.; Ma, Maggie K. M.; Chan, T. M.] Queen Mary Hosp, Dept Med, Hong Kong, Peoples R China.
   [Yau, Christina S. F.; Kwan, Ivan W. L.; Chan, Kelsey Y. M.] Tung Wah Hosp, Dept Occupat Therapy, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; University of Hong Kong; University of
   Hong Kong
RP Fong, KNK (corresponding author), Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Peoples R China.
EM rsnkfong@polyu.edu.hk
RI Fong, Kenneth N. K./F-9608-2014
OI Fong, Kenneth N. K./0000-0001-5909-4847
FU Training and Research Assistance Scheme of Queen Mary Hospital, Hospital
   Authority, Hong Kong SAR [TRAS-18-03 (01/18/213)]
FX This research was partially funded by the Training and Research
   Assistance Scheme of Queen Mary Hospital, Hospital Authority, Hong Kong
   SAR (Reference Number: TRAS-18-03 (01/18/213)).
CR BADDELEY A, 1994, NEUROPSYCHOLOGIA, V32, P53, DOI 10.1016/0028-3932(94)90068-X
   Chiu FPF, 2004, INT J REHABIL RES, V27, P159, DOI 10.1097/01.mrr.0000127640.55118.6b
   Christiansen C, 1998, ARCH PHYS MED REHAB, V79, P888, DOI 10.1016/S0003-9993(98)90083-1
   Clare L., 2008, Rivermead behavioural memory test
   Costa RMEM, 2000, P 3 INT C DIS VIRT R, P299
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Etgen T, 2012, AM J NEPHROL, V35, P474, DOI 10.1159/000338135
   Faria AL, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0204-z
   Fong KNK, 2019, NEUROPSYCHOL REHABIL, V29, P144, DOI 10.1080/09602011.2016.1272467
   Fong KNK, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-19
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Heaton R.K., 1993, Wisconsin Card Sorting Test manual: Revised and expanded
   Hwang Jungha, 2017, J Phys Ther Sci, V29, P1283, DOI 10.1589/jpts.29.1283
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Joseph PA, 2012, P 9 INT C DIS VIRT R, P1
   Kalirao P, 2011, AM J KIDNEY DIS, V57, P612, DOI 10.1053/j.ajkd.2010.11.026
   Kurella M, 2005, AM J KIDNEY DIS, V45, P66, DOI 10.1053/j.ajkd.2004.08.044
   Kwong VWK, 2015, KIDNEY DIS-BASEL, V1, P147, DOI 10.1159/000439193
   Leung CB, 2015, KIDNEY INT SUPPL, V5, P33, DOI 10.1038/kisup.2015.7
   Levey AS, 2005, KIDNEY INT, V67, P2089, DOI 10.1111/j.1523-1755.2005.00365.x
   Murray AM, 2010, AM J KIDNEY DIS, V56, P615, DOI 10.1053/j.ajkd.2010.08.003
   Panerai Simonetta, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P692, DOI 10.1007/978-3-030-26766-7_63
   Panerai S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175751
   PERRINE K, 1993, J CLIN EXP NEUROPSYC, V15, P461, DOI 10.1080/01688639308402571
   Radic J, 2010, NETH J MED, V68, P153
   Raw RK, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211706
   Riva G, 2017, NEUROSCIENCE VIRTUAL
   Rizzo AA, 1997, J HEAD TRAUMA REHAB, V12, P1, DOI 10.1097/00001199-199712000-00002
   Sharda R, 2004, J MANAGE INFORM SYST, V20, P31, DOI 10.1080/07421222.2004.11045780
   Shea YF, 2016, PERITON DIALYSIS INT, V36, P284, DOI 10.3747/pdi.2014.00247
   Shea YF, 2016, CLIN EXP NEPHROL, V20, P126, DOI 10.1007/s10157-015-1127-x
   SHUTE GE, 1990, DEV NEUROPSYCHOL, V6, P1, DOI 10.1080/87565649009540445
   Yeung PY, 2014, HONG KONG MED J, V20, P504, DOI 10.12809/hkmj144219
   Zhang L, 2003, ARCH PHYS MED REHAB, V84, P1118, DOI 10.1016/S0003-9993(03)00203-X
   Zhang X, 2017, BEHAV INFORM TECHNOL, V36, P548, DOI 10.1080/0144929X.2016.1268647
NR 35
TC 2
Z9 3
U1 4
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1571
EP 1583
DI 10.1007/s10055-022-00728-1
EA DEC 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001054892500001
PM 36533192
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Lee, CG
   Kang, D
   Hwang, S
   Kwon, O
AF Lee, Chang-Gyu
   Kang, DaeSeok
   Hwang, SunGeun
   Kwon, Ohung
TI User-centered redirected walking and resetting with virtual feelers
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Redirected walking; Resetting; Virtual feeler
AB With redirected walking (RDW), the exploration of an infinite virtual world with a small physical space has been enabled. This paper proposes a user-centered RDW (UC-RDW) and user-centered resetting (UC-R) that incorporates virtual feelers. This method performs redirection and resetting by only considering a user and obstacles. This means that the UC-RDW and UC-R perform redirection without complex prediction/optimization. If the virtual feelers collide with obstacle, the method redirects the user in the opposite direction from the obstacle. The following simulations obtained one condition (diamond-shaped with area ratio of 0.9, 1.0, and 1.2, angle between feelers of 10, and a length ratio of 0.5 between the major and minor axes of the diamond shape) that yields the best performance under various ray conditions. Then, the performance of the UC-RDW and UC-R were verified through live user experiments. Consequently, a lesser 10-m reset number, lesser increase in total simulator-sickness score, and shorter time to walk 10 m were obtained with the UC-RDW and UC-R. Furthermore, participants who were redirected through the UC-RDW and UC-R applied a larger redirection than other methods and stayed closer to the center of the tracked space than those using other methods. In addition, UC-RDW showed comparable performance to APF-RDW in medium and large-tracked space. Future works include verification of the UC-RDW and UC-R using a tracked space of irregular shape and multiple users.
C1 [Lee, Chang-Gyu; Kang, DaeSeok; Hwang, SunGeun; Kwon, Ohung] Korea Inst Ind Technol, Gyeonggi Do, South Korea.
C3 Korea Institute of Industrial Technology (KITECH)
RP Kwon, O (corresponding author), Korea Inst Ind Technol, Gyeonggi Do, South Korea.
EM cglee@kitech.re.kr; kds60513@kitech.re.kr; zoowx321@kitech.re.kr;
   ohung@kitech.re.kr
RI Lee, Chang-Gyu/GYU-1905-2022
OI Lee, Chang-Gyu/0000-0002-7500-1150
FU Korea Institute of Industrial Technology [KITECH EO220009]; Korea
   Institute of Industrial Technology (KITECH)
FX This study has been conducted with the support of the Korea Institute of
   Industrial Technology as "Development of Core Technologies for a Working
   Partner Robot in the Manufacturing Field (KITECH EO220009)". The
   experiment was conducted with the support of the "Korea Institute of
   Industrial Technology (KITECH) and the overall experiment was approved
   by "Korea National Institute for Bioethics Policy (KoNIBP)". In
   addition, the authors got an informed consent for each participant after
   describing details of the experiments
CR Nguyen A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281515
   Azmandian M., 2015, ICAT-EGVE), P93
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Cao AT, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P137, DOI [10.1109/VR46266.2020.1581044610731, 10.1109/VR46266.2020.00-72]
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Cho YH, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P527, DOI 10.1109/VR.2018.8446442
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Grechkin T., 2016, P ACM S APPL PERC, P113
   Haiwei Chen, 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P523, DOI 10.1109/VR.2018.8446563
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Matsumoto K, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365705
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Millington I., 2018, Artificial Intelligence for Games
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Peck Tabitha C, 2009, IEEE Trans Vis Comput Graph, V15, P383, DOI 10.1109/TVCG.2008.191
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Razzaque S., 2001, Proc. Eurogr, P289, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Saber RF, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P2022
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Zank M, 2017, IEEE SYMP 3D USER, P120, DOI 10.1109/3DUI.2017.7893328
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 40
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 717
EP 734
DI 10.1007/s10055-022-00682-y
EA AUG 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000844459000002
DA 2024-07-18
ER

PT J
AU Kroon, R
   Neumann, DL
   Piatkowski, TM
   Moffitt, RL
AF Kroon, Rianca
   Neumann, David L.
   Piatkowski, Timothy M.
   Moffitt, Robyn L.
TI How the physical appearance of companions affects females with high or
   low social physique anxiety: a virtual reality exercise study
SO VIRTUAL REALITY
LA English
DT Article
DE Exercise; Health promotion; Social physique anxiety; Virtual reality
ID SELF-PRESENTATION; AEROBIC EXERCISE; BODY-IMAGE; PROGRAM; INTERVENTION;
   METAANALYSIS; SAMPLE; PERCEPTIONS; PERFORMANCE; OVERWEIGHT
AB Technologies such as virtual reality (VR), an immersive computer-based environment that induces a feeling of mental and physical presence, are becoming increasingly popular for promoting participation in exercise. The purpose of this study was to explore changes in motivation and other psychological states when the physique of an exercise companion was altered during a VR-based exercise task, and whether trait social physique anxiety (SPA) altered these effects. Using a mixed experimental design, female participants (N = 43) categorised as high or low in SPA participated in two counterbalanced 10-min running tasks within a VR environment where the exercise companion was either overweight or in-shape. Across both running tasks, individuals with high SPA reported higher negative affect, pressure and tension, and lower perceived competencies, than those with low SPA. Pressure and tension were also higher when exercising with an in-shape companion than with an overweight companion for all participants. In addition, participants with high SPA reported a stronger preference to exercise with an overweight companion than those with low SPA in a real exercise setting, but not in a VR setting. The findings suggest that the physique of an exercise companion and the SPA of an exerciser have important, but independent, psychosocial effects during exercise. That an in-shape physique of a virtual exercise companion was not a deterrent among those with high SPA has provided preliminary evidence that VR-based exercise may be helpful among females who worry about their appearance or feel self-conscious while exercising.
C1 [Kroon, Rianca; Neumann, David L.; Piatkowski, Timothy M.] Griffith Univ, Sch Appl Psychol, Brisbane, Qld 4222, Australia.
   [Piatkowski, Timothy M.] Charles Darwin Univ, Coll Hlth & Human Sci, Casuarina, NT, Australia.
   [Moffitt, Robyn L.] Deakin Univ, Sch Psychol, Burwood, Vic, Australia.
C3 Griffith University; Charles Darwin University; Deakin University
RP Neumann, DL (corresponding author), Griffith Univ, Sch Appl Psychol, Brisbane, Qld 4222, Australia.
EM d.neumann@griffith.edu.au
RI Piatkowski, Tim/AAW-1571-2021; Neumann, David/AAD-7018-2020
OI Piatkowski, Tim/0000-0002-6177-0266; Neumann, David/0000-0001-5400-462X;
   Moffitt, Robyn L./0000-0003-1933-4046
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Bauman AE, 2012, LANCET, V380, P258, DOI 10.1016/S0140-6736(12)60735-1
   Botella C., 2014, REV PSICOPATOLOG A P, V19, P157, DOI DOI 10.5944/RPPC.VOL.19.NUM.3.2014.13898
   CASH TF, 1983, PERS SOC PSYCHOL B, V9, P351, DOI 10.1177/0146167283093004
   Cho H, 2014, J PHYS THER SCI, V26, P1661, DOI 10.1589/jpts.26.1661
   Cohen-Mansfield J, 2004, PREV MED, V38, P804, DOI 10.1016/j.ypmed.2004.01.007
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   CRAWFORD S, 1994, J SPORT EXERCISE PSY, V16, P70, DOI 10.1123/jsep.16.1.70
   Dunlop WL, 2014, INT J BEHAV MED, V21, P139, DOI 10.1007/s12529-012-9281-y
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferreira D, 2015, J INTERN MED, V278, P277, DOI 10.1111/joim.12358
   Festinger L, 1954, HUM RELAT, V7, P117, DOI 10.1177/001872675400700202
   Focht BC, 2004, J APPL SPORT PSYCHOL, V16, P361, DOI 10.1080/10413200490517968
   Fraser SN, 2002, J BEHAV MED, V25, P233, DOI 10.1023/A:1015328627304
   Gao Z, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061986
   Ginis KAM, 2008, BODY IMAGE, V5, P164, DOI 10.1016/j.bodyim.2007.11.005
   Ginis KAM, 2007, PSYCHOL HEALTH, V22, P945, DOI 10.1080/14768320601070571
   Haas JP, 2012, AM J INFECT CONTROL, V40, P766, DOI 10.1016/j.ajic.2012.05.020
   HART EA, 1989, J SPORT EXERCISE PSY, V11, P94, DOI 10.1123/jsep.11.1.94
   Hausenblas HA, 2004, J APPL SPORT PSYCHOL, V16, P3, DOI 10.1080/10413200490260026
   Iacobucci D, 2015, J CONSUM PSYCHOL, V25, P690, DOI 10.1016/j.jcps.2015.06.014
   Iacobucci D, 2015, J CONSUM PSYCHOL, V25, P652, DOI 10.1016/j.jcps.2014.12.002
   Irwin BC, 2012, ANN BEHAV MED, V44, P151, DOI 10.1007/s12160-012-9367-4
   Ismail I, 2012, OBES REV, V13, P68, DOI 10.1111/j.1467-789X.2011.00931.x
   Johns DJ, 2014, J ACAD NUTR DIET, V114, P1557, DOI 10.1016/j.jand.2014.07.005
   KENDZIERSKI D, 1991, J SPORT EXERCISE PSY, V13, P50, DOI 10.1123/jsep.13.1.50
   Kowalski Kent C, 2006, J Adolesc Health, V39, DOI 10.1016/j.jadohealth.2005.12.015
   Kruisselbrink LD, 2004, J SPORT EXERCISE PSY, V26, P616, DOI 10.1123/jsep.26.4.616
   Lee HG, 2013, NEW MEDIA SOC, V15, P930, DOI 10.1177/1461444812464033
   Lindwall M, 2005, PSYCHOL SPORT EXERC, V6, P643, DOI 10.1016/j.psychsport.2005.03.003
   Loney T, 2008, J HEALTH PSYCHOL, V13, P47, DOI 10.1177/1359105307084311
   Lotan M, 2009, RES DEV DISABIL, V30, P229, DOI 10.1016/j.ridd.2008.03.005
   Martin JJ, 2006, SEX ROLES, V55, P151, DOI 10.1007/s11199-006-9069-0
   McAuley E, 2000, PREV MED, V31, P608, DOI 10.1006/pmed.2000.0740
   MCAULEY E, 1995, PREV MED, V24, P319, DOI 10.1006/pmed.1995.1053
   Mischner IHS, 2013, BODY IMAGE, V10, P26, DOI 10.1016/j.bodyim.2012.08.004
   Murray EG, 2016, PSYCHOL SPORT EXERC, V22, P328, DOI 10.1016/j.psychsport.2015.09.007
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Ng YL, 2019, COMPUT HUM BEHAV, V99, P278, DOI 10.1016/j.chb.2019.05.026
   Norton K, 2010, J SCI MED SPORT, V13, P496, DOI 10.1016/j.jsams.2009.09.008
   Nunes M., 2014, Proceedings 29th Annual ACM Symposium on Applied Computing - SAC'14. Gyeongju, P970, DOI [DOI 10.1145/2554850.2555009, 10.1145/2554850.2555009]
   Ohkawara K, 2007, INT J OBESITY, V31, P1786, DOI 10.1038/sj.ijo.0803683
   Pearson ES, 2013, EUR J SPORT SCI, V13, P407, DOI 10.1080/17461391.2012.660504
   Plante TG, 2011, AM J HEALTH BEHAV, V35, P199
   Rackow P, 2015, BRIT J HEALTH PSYCH, V20, P763, DOI 10.1111/bjhp.12139
   Raedeke TD, 2007, PSYCHOL SPORT EXERC, V8, P463, DOI 10.1016/j.psychsport.2006.10.005
   Rhodes RE, 2006, EXERC SPORT SCI REV, V34, P83, DOI 10.1249/00003677-200604000-00008
   RYAN RM, 1982, J PERS SOC PSYCHOL, V43, P450, DOI 10.1037/0022-3514.43.3.450
   Sabiston CM, 2007, J ADOLESCENT RES, V22, P78, DOI 10.1177/0743558406294628
   Scott L. A., 2005, ELECT THESES DISSERT, V82
   Sheps S, 1993, J Invest Surg, V6, P469, DOI 10.3109/08941939309141636
   Song H, 2014, COMPUT HUM BEHAV, V36, P282, DOI 10.1016/j.chb.2014.03.059
   Thogersen-Ntoumani C, 2007, J HEALTH PSYCHOL, V12, P301, DOI 10.1177/1359105307074267
   Thompson AM, 2002, J ADOLESCENT HEALTH, V31, P183, DOI 10.1016/S1054-139X(01)00397-4
   Thornton B, 1999, SEX ROLES, V40, P379, DOI 10.1023/A:1018867409265
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wu T, 2009, OBES REV, V10, P313, DOI 10.1111/j.1467-789X.2008.00547.x
   Zeng N, 2017, CYBERPSYCH BEH SOC N, V20, P453, DOI 10.1089/cyber.2017.0042
   Zimmerman M, 2004, INT CLIN PSYCHOPHARM, V19, P215, DOI 10.1097/01.yic.0000130232.57629.46
NR 58
TC 2
Z9 3
U1 3
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 541
EP 551
DI 10.1007/s10055-022-00676-w
EA JUL 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000829693400001
PM 35910716
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Jalo, H
   Pirkkalainen, H
   Torro, O
   Pessot, E
   Zangiacomi, A
   Tepljakov, A
AF Jalo, Henri
   Pirkkalainen, Henri
   Torro, Osku
   Pessot, Elena
   Zangiacomi, Andrea
   Tepljakov, Aleksei
TI Extended reality technologies in small and medium-sized European
   industrial companies: level of awareness, diffusion and enablers of
   adoption
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Virtual reality; Extended reality; Technology
   adoption; Industry 4; 0; Small and medium-sized enterprises
ID AUGMENTED REALITY; EMPIRICAL-ANALYSIS; VIRTUAL-REALITY; BIAS
AB Augmented reality (AR) and virtual reality (VR), collectively referred to as "extended reality" (XR), have begun to diffuse in industry. However, the current levels of awareness, perceived limitations, and use of AR and VR, as well as the potential differences on these aspects between these technologies are still not well known. Moreover, it is unknown whether small and medium-sized enterprises (SMEs) differ from large companies on these issues. This research employed a mixed methods research design to address this gap by carrying out a cross-sectional survey (n = 208) to gauge European industrial companies' level of AR and VR awareness and adoption, and by interviewing 45 companies in nine European countries in order to identify critical enabling factors in the adoption of XR for SMEs. Results show no statistical difference between the respondents' perceptions toward AR and VR or in their use levels. Thus, examining AR and VR under the umbrella term XR seems justified, especially in the context of their organizational use. However, larger companies were found to be using XR more than SMEs. Analysis of interviews based on the technology-organization-environment framework also yielded several enabling factors affecting XR adoption and specified whether they are particularly highlighted in the SME context. Overall, this paper contributes to XR research by providing a holistic multi-country overview that highlights key issues for managers aiming to invest in these technologies, as well as critical organizational perspectives to be considered by scholars.
C1 [Jalo, Henri; Pirkkalainen, Henri; Torro, Osku] Tampere Univ, Tampere, Finland.
   [Pessot, Elena; Zangiacomi, Andrea] Natl Res Council Italy, Milan, Italy.
   [Tepljakov, Aleksei] Tallinn Univ Technol, Tallinn, Estonia.
C3 Tampere University; Consiglio Nazionale delle Ricerche (CNR); Tallinn
   University of Technology
RP Jalo, H (corresponding author), Tampere Univ, Tampere, Finland.
EM henri.jalo@tuni.fi; henri.pirkkalainen@tuni.fi; osku.torro@tuni.fi;
   elena.pessot@stiima.cnr.it; andrea.zangiacomi@stiima.cnr.it;
   aleksei.tepljakov@taltech.ee
RI Tepljakov, Aleksei/F-1632-2017
OI Tepljakov, Aleksei/0000-0002-7158-8484; ZANGIACOMI,
   ANDREA/0000-0002-2298-8481; Pessot, Elena/0000-0002-0072-8881;
   Pirkkalainen, Henri/0000-0002-5389-7363; Torro, Osku Kalervo
   Tapio/0000-0003-0706-5010; Jalo, Henri/0000-0003-1438-700X
FU European Commission [612618-EPP-1-2019-1-DE-EPPKA2-KA]
FX This research has been funded with support from the European Commission.
   This publication [communication] reflects the views only of the author,
   and the Commission cannot be held responsible for any use which may be
   made of the information contained therein. [Project number:
   612618-EPP-1-2019-1-DE-EPPKA2-KA].
CR Alam Syed Shah., 2021, Journal of Open Innovation: Technology, Market, and Complexity, V7, DOI DOI 10.3390/JOITMC7020142
   [Anonymous], 2015, TECHCRUNCH
   [Anonymous], 2013, Virtual and augmented reality applications in manufacturing
   [Anonymous], 2021, European Central Bank
   [Anonymous], 2017, Top Trends in the Gartner Hype Cycle for Emerging Technologies
   ARMSTRONG JS, 1977, J MARKETING RES, V14, P396, DOI 10.2307/3150783
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Badamasi AA, 2022, ENG CONSTR ARCHIT MA, V29, P1307, DOI 10.1108/ECAM-09-2020-0685
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   BLAIR RC, 1985, PSYCHOL BULL, V97, P119, DOI 10.1037/0033-2909.97.1.119
   Borgman HP, 2013, P ANN HICSS, P4425, DOI 10.1109/HICSS.2013.132
   Bryson S., 1995, VIRTUAL REALITY APPL, P3
   Bujic M., 2021, P 54 HI INT C SYST S, P628, DOI DOI 10.24251/HICSS.2021.077
   Chandra S, 2018, J ELECTRON COMMER RE, V19, P237
   Chuah S.H. W., 2019, International Journal of Technology Marketing, V13, P205, DOI DOI 10.1504/IJTMKT.2019.104586
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Cohen J., 1988, STAT POWER ANAL BEHA
   Creswell JW, 2000, THEOR PRACT, V39, P124, DOI 10.1207/s15430421tip3903_2
   Creswell JW., 2016, 30 Essential Skills for the Qualitative Researcher
   Dancey C. P., 2007, Statistics Without Maths for Psychology, V4th
   Delgado JMD, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001844
   Denicolai S, 2021, TECHNOL FORECAST SOC, V166, DOI 10.1016/j.techfore.2021.120650
   Denning PJ, 2020, COMMUN ACM, V63, P27, DOI 10.1145/3396265
   Depietro R., 1990, PROCESSES TECHNOLOGI, V199, P151
   Dwivedi YK, 2021, INT J INFORM MANAGE, V59, DOI 10.1016/j.ijinfomgt.2020.102168
   George D., 2019, IBM SPSS STAT 26 STE, DOI [10.4324/9780429056765, DOI 10.4324/9780429056765]
   Gillham B., 2005, RES INTERVIEWING RAN
   Gong L, 2021, IEEE ACCESS, V9, P24796, DOI 10.1109/ACCESS.2021.3056752
   Grand View Research, VIRT REAL MARK SIZ S
   Hammond E, 2020, BLOOMBERG
   IDC, 2020, WORLDW SPEND AUGM VI
   Jalo H, 2020, P 28 EUR C INF SYST, P1, DOI DOI 10.1109/ACCESS.2020.3009783
   Jalo H., 2018, P 10 INT JOINT C KNO, P41, DOI [10.5220/0006889800410051, DOI 10.5220/0006889800410051]
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Kim HW, 2009, MIS QUART, V33, P567
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Martins R, 2016, COMPUT HUM BEHAV, V62, P19, DOI 10.1016/j.chb.2016.03.049
   Masood T, 2020, COMPUT IND, V115, DOI 10.1016/j.compind.2019.07.002
   Masood T, 2019, ROBOT CIM-INT MANUF, V58, P181, DOI 10.1016/j.rcim.2019.02.003
   NEDERHOF AJ, 1985, EUR J SOC PSYCHOL, V15, P263, DOI 10.1002/ejsp.2420150303
   Noghabaei M, 2020, DATA, V5, DOI 10.3390/data5010026
   OECD, 2021, The Digital Transformation of SMEs. OECD studies on SMEs and entrepreneurship, DOI [DOI 10.1787/BDB9256A-EN, 10.1787/cd08-ac8-fr]
   Patton M. Q., 2002, QUALITATIVE RES EVAL
   Porter ME, 2017, HARVARD BUS REV, V95, P45
   RASMUSSEN JL, 1991, EDUC PSYCHOL MEAS, V51, P809, DOI 10.1177/001316449105100402
   Schiavone F, 2022, TECHNOL FORECAST SOC, V175, DOI 10.1016/j.techfore.2021.121325
   Serlin RC, 2004, PSYCHOL METHODS, V9, P492, DOI 10.1037/1082-989X.9.4.492
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Torro O, 2021, COMMUN ACM, V64, P48, DOI 10.1145/3440868
   Venkatesh V, 2013, MIS QUART, V37, P21
   Walsh K.R., 2002, Communications of the Associations of the Information Systems, V8 issue1, p, P20, DOI DOI 10.17705/1CAIS.00820
   WALSHAM G, 1995, EUR J INFORM SYST, V4, P74, DOI 10.1057/ejis.1995.9
   Wolf M, 2012, J INF TECHNOL-UK, V27, P213, DOI 10.1057/jit.2012.13
   Yin R. K., 2017, CASE STUDY RES DESIG
   Yoon TE, 2013, COMPUT HUM BEHAV, V29, P772, DOI 10.1016/j.chb.2012.12.003
NR 55
TC 16
Z9 16
U1 2
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1745
EP 1761
DI 10.1007/s10055-022-00662-2
EA JUN 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000818599000001
PM 35789651
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Modi, N
   Singh, J
AF Modi, Nandini
   Singh, Jaiteg
TI Real-time camera-based eye gaze tracking using convolutional neural
   network: a case study on social media website
SO VIRTUAL REALITY
LA English
DT Article
DE Eye gaze tracking; Vision research; Webcam; Social media;
   Video-oculography advertisement; Consumer attention; Consumer behavior;
   Non-intrusive; Virtual reality
ID ALGORITHM; SYSTEM; ATTENTION; DIRECTION; MACHINE; PEOPLE
AB Eye gaze tracking plays an important role in various fields including, human computer interaction, virtual and augmented reality and in identifying effective marketing solutions in affective manner. This paper addresses real-time eye gaze estimation problem using low resolution ordinary camera available in almost every desktop environment as opposed to gaze tracking technologies requiring costly equipment and infrared light sources. In this research, a camera based non-invasive technique has been proposed for tracking and recording gaze points. Further, the proposed framework was used to analyze gaze behavior of users on advertisements displayed on social media website. Eye gaze fixations data of 32 participants were recorded, and gaze patterns were plotted using Heat maps. In addition, the gaze driven interface was designed for virtual interaction tasks to assess the performance, and usability of our proposed framework.
C1 [Modi, Nandini; Singh, Jaiteg] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Singh, J (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM jaitegkhaira@gmail.com
RI Modi, Nandini/AAZ-5551-2020
OI Modi, Nandini/0000-0003-2786-1145; Singh, Jaiteg/0000-0002-2370-9384
CR Ahmed M, 2021, MULTIMEDIA SYST, V27, P429, DOI 10.1007/s00530-020-00744-8
   Anderson C, 2013, J CLIN SLEEP MED, V9, P907, DOI 10.5664/jcsm.2992
   [Anonymous], 2010, TOB EYE TRACK INTR E
   Bamidele AA, 2019, INT J ADV COMPUT SC, V10, P549
   Biswas P, 2011, J ASSIST TECHNOL, V5, P58, DOI 10.1108/17549451111149269
   Cai H, 2012, VIRTUAL REAL-LONDON, V16, P25, DOI 10.1007/s10055-010-0171-9
   Cecotti H, 2016, IEEE T HUM-MACH SYST, V46, P601, DOI 10.1109/THMS.2016.2537749
   Cerrolaza JJ, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2240156.2240158
   Cheng YH, 2020, IEEE T IMAGE PROCESS, V29, P5259, DOI 10.1109/TIP.2020.2982828
   Choe KW, 2016, VISION RES, V118, P48, DOI 10.1016/j.visres.2014.12.018
   Cognolato M, 2018, J REHABIL ASSIST TER, V5, DOI 10.1177/2055668318773991
   Dimpfel W., 2015, J. Behav. Brain Sci, V5, P137, DOI [10.4236/jbbs.2015.54014, DOI 10.4236/JBBS.2015.54014]
   Dongare H., 2016, INT J INNOV RES ELEC, V4, P154
   Ebisawa Y, 2013, IEEE T BIO-MED ENG, V60, P2952, DOI 10.1109/TBME.2013.2266478
   Farnsworth B., 2019, EYE TRACKER PRICES
   Fenko A, 2018, FOOD QUAL PREFER, V69, P57, DOI 10.1016/j.foodqual.2018.05.012
   Georgakarakou C, 2020, Int J Technol Mark, V14, P93, DOI DOI 10.1504/IJTMKT.2020.110124
   George A., 2016, 2016 IEEE High Performance Extreme Computing Conference (HPEC), P1, DOI DOI 10.1109/HPEC.2016.7761639
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Glaholt MG., 2011, J NEUROSCI PSYCHOL E, V4, P125, DOI DOI 10.1037/A0020692
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hornof A., 2004, ASSETS 2004. The Sixth International ACM SIGACCESS Conference on Computers and Accessibility, P86
   Huang Q, 2017, MACH VISION APPL, V28, P445, DOI 10.1007/s00138-017-0852-4
   Hwang YM, 2022, BEHAV INFORM TECHNOL, V41, P535, DOI 10.1080/0144929X.2020.1813330
   Ince IF, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-40
   Jin YH, 2020, MILITARY MED RES, V7, DOI 10.1186/s40779-020-0233-6
   Kang ZH, 2015, IEEE T HUM-MACH SYST, V45, P13, DOI 10.1109/THMS.2014.2363121
   Kaur Amanpreet, 2021, Journal of Medical Engineering & Technology, V45, P61, DOI 10.1080/03091902.2020.1853838
   Klaib A F., 2019, Journal of Communications, V14, P614, DOI [10.12720/jcm.14.7.614-621, DOI 10.12720/JCM.14.7.614-621]
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Kumar D, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2358, DOI 10.1109/ICACCI.2016.7732407
   Kurilovas E, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106274
   Laddi A, 2018, IETE J RES, V64, P596, DOI 10.1080/03772063.2017.1367264
   Larumbe-Bergera A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21206847
   Li JF, 2014, IEEE COMPUT SOC CONF, P606, DOI 10.1109/CVPRW.2014.93
   Liu SS, 2012, J MED BIOL ENG, V32, P111, DOI 10.5405/jmbe.836
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Mason MF, 2004, MEMORY, V12, P637, DOI 10.1080/09658210344000152
   Mazhar O, 2015, INT SYM DES TECH ELE, P139, DOI 10.1109/SIITME.2015.7342312
   Mele ML, 2012, COGN PROCESS, V13, pS261, DOI 10.1007/s10339-012-0499-z
   Meng CN, 2017, IEEE ACCESS, V5, P19581, DOI 10.1109/ACCESS.2017.2754299
   Mimura Y, 2020, ADV INTELLIGENT SYST, V1202, P641, DOI [10.1007/978-3-030-51194-4_84, DOI 10.1007/978-3-030-51194-4_84]
   Modi Nandini, 2021, Advances in Computational Intelligence and Communication Technology. Proceedings of CICT 2019. Advances in Intelligent Systems and Computing (AISC 1086), P501, DOI 10.1007/978-981-15-1275-9_41
   Modi N, 2022, DISABIL REHABIL-ASSI, V17, P605, DOI 10.1080/17483107.2020.1817992
   Mou J, 2018, COMPUT HUM BEHAV, V78, P74, DOI 10.1016/j.chb.2017.08.049
   Nagamatsu T, 2011, IEICE T INF SYST, VE94D, P1817, DOI 10.1587/transinf.E94.D.1817
   Ou WL, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020851
   Padilla R., 2012, World Academy of Science, Engineering and Technology, V64, P362
   Pai YS, 2022, VIRTUAL REAL-LONDON, V26, P437, DOI 10.1007/s10055-021-00571-w
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Pastel S, 2021, VIRTUAL REAL-LONDON, V25, P175, DOI 10.1007/s10055-020-00449-3
   Perez-Llamas C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019541
   Rahman Ziaur, 2019, International Journal of Computers and Applications, V41, P207, DOI 10.1080/1206212X.2017.1422358
   Raj R, 2016, PROCEDIA COMPUT SCI, V93, P375, DOI 10.1016/j.procs.2016.07.223
   Satriya T, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P253, DOI 10.1109/ISESD.2016.7886728
   Sattar H, 2020, NEUROCOMPUTING, V387, P369, DOI 10.1016/j.neucom.2020.01.028
   Scherer MJ, 2015, NEUROREHABILITATION, V37, P315, DOI 10.3233/NRE-151264
   Schneider T, 2014, INT C PATT RECOG, P1167, DOI 10.1109/ICPR.2014.210
   Singh J, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e03033
   Skodras E, 2015, SIGNAL PROCESS-IMAGE, V36, P29, DOI 10.1016/j.image.2015.05.007
   Spiller M, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3446638
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101
   Teiwes W, 2020, 3 DIMENSIONAL KINEMA, P429
   Toreini P, 2020, L N INF SYST ORGAN, V32, P261, DOI 10.1007/978-3-030-28144-1_29
   Turner J., 2012, P S EYE TRACK RES AP, P269, DOI [10.1145/2168556.2168613, DOI 10.1145/2168556.2168613]
   Tzafilkou K, 2017, COMPUT HUM BEHAV, V72, P23, DOI 10.1016/j.chb.2017.02.035
   Valenti R, 2008, PROC CVPR IEEE, P1452
   Valliappan N, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18360-5
   Valtakari NV, 2021, BEHAV RES METHODS, V53, P1592, DOI 10.3758/s13428-020-01517-x
   Vicente F, 2015, IEEE T INTELL TRANSP, V16, P2014, DOI 10.1109/TITS.2015.2396031
   Wang YF, 2016, KNOWL-BASED SYST, V110, P293, DOI 10.1016/j.knosys.2016.07.038
   Wen J, 2021, J TRAVEL RES, V60, P846, DOI 10.1177/0047287520912330
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Wood E., 2014, P S EYE TRACK RES AP, P207, DOI DOI 10.1145/2578153.2578185
   Wood E, 2016, LECT NOTES COMPUT SC, V9905, P297, DOI 10.1007/978-3-319-46448-0_18
   Wu YL, 2014, MULTIMED TOOLS APPL, V70, P2037, DOI 10.1007/s11042-012-1220-z
   Xiong J, 2020, INFORM SYST, V89, DOI 10.1016/j.is.2019.101462
   Xiong XH, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1113, DOI 10.1145/2638728.2641694
   Xu Q, 2014, IEEE T IMAGE PROCESS, V23, P2944, DOI 10.1109/TIP.2014.2311656
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Yunrui Zhuang, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P609, DOI 10.1109/IAEAC50856.2021.9390807
   Zhang C, 2018, MULTIMED TOOLS APPL, V77, P19679, DOI 10.1007/s11042-017-5426-y
   Zhang R, 2019, IEEE T BIO-MED ENG, V66, P89, DOI 10.1109/TBME.2018.2834555
   Zhang X., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI 10.1109/CVPR.2015.7299081
   Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284
   Zhou XL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P369, DOI 10.1109/ROBIO.2016.7866350
NR 89
TC 5
Z9 5
U1 6
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1489
EP 1506
DI 10.1007/s10055-022-00642-6
EA MAR 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000775830800002
DA 2024-07-18
ER

PT J
AU Cadet, LB
   Reynaud, E
   Chainay, H
AF Cadet, Lenaic B.
   Reynaud, Emanuelle
   Chainay, Hanna
TI Memory for a virtual reality experience in children and adults according
   to image quality, emotion, and sense of presence
SO VIRTUAL REALITY
LA English
DT Article
DE Children; Adults; Virtual reality; Memory; Emotion; Presence;
   Physiology; Head-mounted display
ID AROUSAL; IMMERSION; ENVIRONMENTS; METAANALYSIS; RECOGNITION; ATTENTION;
   VALENCE; SUPPORT; MEDIA; PUPIL
AB Numerous studies have explored the effects of virtual reality (VR) on adults' cognition. Little is known, however, of these effects in children. The aim of this study was to explore, in both children and adults, the respective roles of the specific factors of VR, such as immersion, sense of presence and emotion, on memory performance. To do so, we used a head-mounted display to present a VR experience in which we manipulated immersion by varying 3D asset quality (High and Low) and emotion by presenting negative, neutral and positive stimuli. 48 adults (M-age = 20.65) and 40 children (M-age = 11.63) were both divided into two experimental groups (High vs. Low 3D model quality). Valence, arousal, and sense of presence were self-assessed by means of questionnaires, while memory of the presented stimuli was assessed using a free recall task. We also performed physiological measurements to provide objective support for our data. Results showed that memory performance was better for emotional than for neutral stimuli regardless of age group, even though children seemed to avoid looking at negative stimuli compared to neutral ones. Memory was predicted by arousal and presence in adults and only by arousal in children. Memory was not impaired by using poor image quality when highly arousing content was displayed. This study revealed that, contrary to adults, the use of poor image quality did not protect children from strong emotional experiences in VR. The roles of familiarity and arousal are discussed to help explain these results.
C1 [Cadet, Lenaic B.; Reynaud, Emanuelle; Chainay, Hanna] Univ Lyon 2, Lab Etud Mecanismes Cognitifs, 5 Ave Pierre Mendes, F-69676 Bron, France.
C3 Universite Lyon 2
RP Cadet, LB (corresponding author), Univ Lyon 2, Lab Etud Mecanismes Cognitifs, 5 Ave Pierre Mendes, F-69676 Bron, France.
EM lenaic.cadet@univ-lyon2.fr; emanuelle.reynaud@univ-lyon2.fr;
   hanna.chainay@univ-lyon2.fr
RI Reynaud, Emanuelle/H-1578-2017; Chainay, Hanna/H-1580-2017
OI Chainay, Hanna/0000-0001-5754-033X
FU Region Auvergne-Rhone-Alpes Grant [28/06]; Direction de la Recherche et
   des Ecoles Doctorales grant from the Universite Lumiere Lyon 2
   [13-2019]; Institute for Psychology of the Universite Lumiere Lyon 2;
   Association Nationale de la Recherche et de la Technologie (ANRT)
   [2017/0582]; company VR Connection
FX The present study was supported by a Region Auvergne-Rhone-Alpes Grant
   (Direction des Finances 28/06) and a Direction de la Recherche et des
   Ecoles Doctorales grant from the Universite Lumiere Lyon 2 (DRED No.
   13-2019). Finally, it was also financially supported by the Institute
   for Psychology of the Universite Lumiere Lyon 2, and the Association
   Nationale de la Recherche et de la Technologie (ANRT-Grant No.
   2017/0582). We thank the native English copy editor for proofreading the
   manuscript, Mrs. Nakouri, Assistant Director of the Cite Internationnale
   de Lyon middle school, for her help in recruiting the child volunteers
   for the study and the company VR Connection for their support. We also
   warmly thank Thomas Fugier for designing the virtual environments.
CR Bailey JO, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P181, DOI 10.1016/B978-0-12-809481-5.00009-2
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Bellani M, 2011, EPIDEMIOL PSYCH SCI, V20, P235, DOI 10.1017/S2045796011000448
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cadet L. B., 2021, International Journal of Child-Computer Interaction, V29, P100299, DOI [10.1016/j.ijcci.2021.100299, DOI 10.1016/J.IJCCI.2021.100299]
   Cadet LB, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102506
   Cahill L, 1998, TRENDS NEUROSCI, V21, P294, DOI 10.1016/S0166-2236(97)01214-9
   Chen HB, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0795-x
   Cordon IM, 2013, J EXP CHILD PSYCHOL, V114, P339, DOI 10.1016/j.jecp.2012.08.004
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Davidson PSR, 2006, COGN AFFECT BEHAV NE, V6, P306, DOI 10.3758/CABN.6.4.306
   Davis ET, 1999, HUM FAC ERG SOC P, P1197
   Detenber BH, 1998, J BROADCAST ELECTRON, V42, P113
   Dolcos F, 2002, COGN AFFECT BEHAV NE, V2, P252, DOI 10.3758/CABN.2.3.252
   Duc AH, 2008, PROG BRAIN RES, V171, P403, DOI 10.1016/S0079-6123(08)00659-6
   Eerland A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031291
   Fan YC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030451
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   Fuchs Philippe, 2018, Theorie de la realite virtuelle-Les veritables usages
   Gates M, 2020, PEDIATRICS, V145, DOI 10.1542/peds.2019-1139
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Hajcak G, 2009, BIOL PSYCHOL, V80, P333, DOI 10.1016/j.biopsycho.2008.11.006
   Hamann S., 2014, The Wiley handbook on the development of children's memory, VI, P724, DOI DOI 10.1002/9781118597705.CH32
   Hawley CA, 2003, BRAIN INJURY, V17, P105, DOI 10.1080/0269905021000010131
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hillman CH, 2004, BIOL PSYCHOL, V66, P51, DOI 10.1016/j.biopsycho.2003.07.005
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Jäncke L, 2009, FRONT NEUROSCI-SWITZ, V3, P52, DOI 10.3389/neuro.01.006.2009
   Joormann J, 2010, COGNITION EMOTION, V24, P281, DOI 10.1080/02699930903407948
   Kensinger E.A., 2016, HDB EMOTIONS, V4th, P564
   Kensinger EA, 2004, P NATL ACAD SCI USA, V101, P3310, DOI 10.1073/pnas.0306408101
   Laurent J, 1999, PSYCHOL ASSESSMENT, V11, P326, DOI 10.1037/1040-3590.11.3.326
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lele A, 2013, J AMB INTEL HUM COMP, V4, P17, DOI 10.1007/s12652-011-0052-4
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Leventon JS, 2014, DEV COGN NEUROS-NETH, V10, P21, DOI 10.1016/j.dcn.2014.07.007
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Makowski D, 2017, CONSCIOUS COGN, V53, P194, DOI 10.1016/j.concog.2017.06.015
   Mania K, 2005, PRESENCE-TELEOP VIRT, V14, P606, DOI 10.1162/105474605774918769
   Maskey M, 2019, AUTISM ADULTHOOD, V1, P134, DOI 10.1089/aut.2018.0019
   Maskey M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100374
   Massol S, 2020, J EXP PSYCHOL GEN, V149, P1684, DOI 10.1037/xge0000744
   Mikropoulos TA, 2004, CYBERPSYCHOL BEHAV, V7, P582
   North MM, 2016, AUSTRALAS J INF SYST, V20
   Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X
   Phaf RH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00378
   Picard L, 2017, INT J BEHAV DEV, V41, P211, DOI 10.1177/0165025415616198
   Quas JA, 2004, CHILD DEV, V75, P797, DOI 10.1111/j.1467-8624.2004.00707.x
   Quas JA, 2007, APPL COGNITIVE PSYCH, V21, P289, DOI 10.1002/acp.1279
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Richert RA, 2011, CHILD DEV, V82, P82, DOI 10.1111/j.1467-8624.2010.01542.x
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Roozendaal B, 2011, BEHAV NEUROSCI, V125, P797, DOI 10.1037/a0026187
   Roussou M., 2006, Virt Real, V10, P227, DOI 10.1007/s10055-006-0035-5
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schwebel DC, 2008, ACCIDENT ANAL PREV, V40, P1394, DOI 10.1016/j.aap.2008.03.005
   Seth A. K., 2011, FRONT PSYCHOL, V2, P395, DOI [DOI 10.3389/FPSYG.2011.00395, 10.3389/fpsyg.2011.00395]
   Sharot T, 2004, COGN AFFECT BEHAV NE, V4, P294, DOI 10.3758/CABN.4.3.294
   Shema-Shiratzky S, 2019, DEV NEUROREHABIL, V22, P431, DOI 10.1080/17518423.2018.1476602
   Sirois S, 2014, WIRES COGN SCI, V5, P679, DOI 10.1002/wcs.1323
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M., 2003, PRESENCE CONNECT
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Stenson AF, 2019, J EXP CHILD PSYCHOL, V178, P121, DOI 10.1016/j.jecp.2018.09.016
   Subrahmanyam K., 2009, Washington and Lee Law Review, V66, P1065, DOI DOI 10.1037/0012-1649.42.3.395
   Talmi D, 2008, LEARN MEMORY, V15, P172, DOI 10.1101/lm.722908
   Talmi D, 2012, J MEM LANG, V66, P93, DOI 10.1016/j.jml.2011.07.009
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Van Schaik P, 2004, CYBERPSYCHOL BEHAV, V7, P540, DOI 10.1089/1094931042403145
   Västfjäll D, 2003, CYBERPSYCHOL BEHAV, V6, P181, DOI 10.1089/109493103321640374
   Vesker M, 2018, EUR J DEV PSYCHOL, V15, P411, DOI 10.1080/17405629.2017.1287073
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Wallet G, 2011, CYBERPSYCH BEH SOC N, V14, P417, DOI 10.1089/cyber.2009.0187
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Won AS, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4070052
   Yildirim Ç, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100308
NR 88
TC 12
Z9 12
U1 2
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 55
EP 75
DI 10.1007/s10055-021-00537-y
EA MAY 2021
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000654953500001
PM 34075297
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wibirama, S
   Santosa, PI
   Widyarani, P
   Brilianto, N
   Hafidh, W
AF Wibirama, Sunu
   Santosa, Paulus Insap
   Widyarani, Putu
   Brilianto, Nanda
   Hafidh, Wina
TI Physical discomfort and eye movements during arbitrary and optical
   flow-like motions in stereo 3D contents
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Stereo 3D; Eye tracking; Human factors in virtual reality
ID VIRTUAL-REALITY; SICKNESS; GAZE
AB Users of stereo 3D technology commonly report physical discomfort during or after exposure of stereo 3D contents. The discomfort has been associated with sensation of arbitrary and optical flow-like self-motion. However, there is no information on whether arbitrary motion induces stronger physical discomfort compared with optical flow-like motion. To address this research gap, we investigate physical discomfort among players and spectators of stereo 3D contents using eye tracking and Simulator Sickness Questionnaire. Thirty participants (N=30) acted as players and spectators of a first-person shooter (FPS) and a car racing game. The FPS and the car racing game produce a sensation of arbitrary and optical flow-like self-motion, respectively. Experimental results show that the FPS game induces more severe physical discomfort than its racing counterpart (p<0.0083, with a Bonferroni correction to the p value). We also found that severeness of oculomotor symptoms can be predicted using two eye movements metrics: the amount of fixational eye movements and viewing duration at the center of the screen. Our study implies that one should pay particular attention to different types of self-motion in stereo 3D contents regardless of whether the user controls or solely watches the contents. Our study also suggests that physical discomfort can be reduced by decreasing the frequency of fixational eye movements while prolonging the duration of each fixation at the center of screen.
C1 [Wibirama, Sunu; Santosa, Paulus Insap; Widyarani, Putu; Brilianto, Nanda; Hafidh, Wina] Univ Gadjah Mada, Dept Elect Engn & Informat Technol, Yogyakarta 55281, Indonesia.
C3 Gadjah Mada University
RP Wibirama, S (corresponding author), Univ Gadjah Mada, Dept Elect Engn & Informat Technol, Yogyakarta 55281, Indonesia.
EM sunu@ugm.ac.id
RI Wibirama, Sunu/L-2241-2019
OI Wibirama, Sunu/0000-0001-9613-7017; Santosa, Paulus
   Insap/0000-0002-0581-2521
FU  [CRA1601]
FX Funding was provided by Japan International Cooperation Agency
   (CRA1601).
CR Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   [Anonymous], CES 2010 LIVIN 3D LI
   [Anonymous], TWICE BRIGHT NVIDIA
   [Anonymous], BBC SHELVES 3D TV PR
   [Anonymous], SKY SHUT ITS 3D TV C
   [Anonymous], P SPIE
   [Anonymous], 2012, P S EYE TRACK RES AP
   [Anonymous], PULLING PLUG HITECH
   [Anonymous], GAZEPOINT CONTROL US
   [Anonymous], EMERGING CONVERGING
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/2470654.2466112
   [Anonymous], J VIRTUAL REAL BROAD
   [Anonymous], DESIGNING IMMERSIVE
   [Anonymous], DESIGNING IMMERSIVE
   [Anonymous], NORSK INF NIK
   [Anonymous], 2007, Eye tracking methodology: Theory and practice, DOI DOI 10.1007/978-3-319-57883-5
   [Anonymous], ALL TIM BOX OFF
   [Anonymous], J VISION
   Bando T, 2012, DISPLAYS, V33, P76, DOI 10.1016/j.displa.2011.09.001
   Biocca Frank., 1992, Presence: Teleoperators Virtual Environments, V1, P334, DOI [DOI 10.1162/PRES.1992.1.3.334, 10.1162/pres.1992.1.3.334]
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   Chambers TL, 2012, VIRTUAL REAL-LONDON, V16, P45, DOI 10.1007/s10055-010-0170-x
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Guo CT, 2013, CONTEMPORARY ERGONOMICS AND HUMAN FACTORS 2013, P51
   Gupta VK, 2005, MED HYPOTHESES, V64, P1177, DOI 10.1016/j.mehy.2004.11.031
   Hennessey C, 2008, IEEE T SYST MAN CY B, V38, P289, DOI 10.1109/TSMCB.2007.911378
   Horne-Moyer HL, 2014, CURR PSYCHIAT REP, V16, DOI 10.1007/s11920-014-0520-6
   Iatsun I, 2015, DISPLAYS, V39, P11, DOI 10.1016/j.displa.2015.07.001
   Karpicka E, 2013, OPHTHAL PHYSL OPT, V33, P604, DOI 10.1111/opo.12081
   Kawamura Y, 2012, IEICE T FUND ELECTR, VE95A, P1306, DOI 10.1587/transfun.E95.A.1306
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   Keshavarz B, 2012, PRESENCE-TELEOP VIRT, V21, P213, DOI 10.1162/PRES_a_00102
   Kim CJ, 2013, SENSORS-BASEL, V13, P13054, DOI 10.3390/s131013054
   Kurillo G, 2013, VIRTUAL REAL-LONDON, V17, P29, DOI 10.1007/s10055-012-0217-2
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Litwiller T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2345
   Ma WQ, 2018, ADV INTELL SYST, V596, P265, DOI 10.1007/978-3-319-60018-5_26
   Matsuura Yasuyuki, 2013, Universal Access in Human-Computer Interaction. User and Context Diversity. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8010, P293, DOI 10.1007/978-3-642-39191-0_33
   Niemann T, 1999, VISION RES, V39, P1359, DOI 10.1016/S0042-6989(98)00236-3
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Obrist M, 2013, ENTERTAIN COMPUT, V4, P71, DOI 10.1016/j.entcom.2012.03.001
   Palmisano S, 2007, AVIAT SPACE ENVIR MD, V78, P951, DOI 10.3357/ASEM.2079.2007
   Pan X, 2017, CHIN CONTR CONF, P11034, DOI 10.23919/ChiCC.2017.8029119
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   ROLNICK A, 1991, ERGONOMICS, V34, P867, DOI 10.1080/00140139108964831
   Scott MacKenzie I., 2013, Human-Computer Interaction: An Empirical Research Perspective, Vfrst
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Takada Hiroki, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P371, DOI 10.1007/978-3-642-22021-0_41
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   VanVoorhis CRW, 2007, TUTOR QUANT METHODS, V3, P43, DOI 10.20982/tqmp.03.2.p043
   [王如松 Wang Rusong], 2014, [生态学报, Acta Ecologica Sinica], V34, P1
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Wibirama Sunu, 2013, 2013 International Conference on Information Technology and Electrical Engineering (ICITEE), P84, DOI 10.1109/ICITEED.2013.6676216
   Wibirama S., 2014, IEEJ T ELECT INF SYS, V134, P345
   Wibirama S, 2018, ENTERTAIN COMPUT, V26, P117, DOI 10.1016/j.entcom.2018.02.003
   Wibirama S, 2017, ENTERTAIN COMPUT, V21, P11, DOI 10.1016/j.entcom.2017.04.003
   Wibirama S, 2015, 2015 INTERNATIONAL CONFERENCE ON DATA AND SOFTWARE ENGINEERING (ICODSE), P191, DOI 10.1109/ICODSE.2015.7436996
   Wibirama S, 2014, IEEE ENG MED BIO, P4803, DOI 10.1109/EMBC.2014.6944698
   Wibirama S, 2013, IEEJ T ELECTR ELECTR, V8, P238, DOI 10.1002/tee.21845
   Yang DS, 2007, VISION RES, V47, P1145, DOI 10.1016/j.visres.2007.02.001
   Yang J.X., 2011, Proceedings of the Human Factors and Ergonomics Society Annual MeetingSeptember, V55, P1220, DOI [10.1177/1071181311551254, DOI 10.1177/1071181311551254]
   Yang SN, 2012, OPTOMETRY VISION SCI, V89, P1068, DOI 10.1097/OPX.0b013e31825da430
   Young SD, 2007, IEEE T VIS COMPUT GR, V13, P422, DOI [10.1109/TVCG.2007.1029, 10.1109/TVCG.2007.1041]
   Zhu MX, 2008, J VISION, V8, DOI 10.1167/8.9.11
NR 65
TC 14
Z9 16
U1 2
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 39
EP 51
DI 10.1007/s10055-019-00386-w
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800003
OA Bronze
DA 2024-07-18
ER

PT J
AU Sagayam, KM
   Hemanth, DJ
AF Sagayam, K. Martin
   Hemanth, D. Jude
TI Hand posture and gesture recognition techniques for virtual reality
   applications: a survey
SO VIRTUAL REALITY
LA English
DT Article
DE Human computer interaction (HCI); Gesture; Posture; Graphical user
   interface (GUI); HMM
ID HUMAN MOTION ANALYSIS; NEURAL-NETWORK INTERFACE; SYSTEM; IDENTIFICATION;
   SEGMENTATION; TRAJECTORIES; FEATURES; IMAGES; GLOVE
AB Motion recognition is a topic in software engineering and dialect innovation with a goal of interpreting human signals through mathematical algorithm. Hand gesture is a strategy for nonverbal communication for individuals as it expresses more liberally than body parts. Hand gesture acknowledgment has more prominent significance in planning a proficient human computer interaction framework, utilizing signals as a characteristic interface favorable to circumstance of movements. Regardless, the distinguishing proof and acknowledgment of posture, gait, proxemics and human behaviors is furthermore the subject of motion to appreciate human nonverbal communication, thus building a richer bridge between machines and humans than primitive text user interfaces or even graphical user interfaces, which still limits the majority of input to electronics gadget. In this paper, a study on various motion recognition methodologies is given specific accentuation on available motions. A survey on hand posture and gesture is clarified with a detailed comparative analysis of hidden Markov model approach with other classifier techniques. Difficulties and future investigation bearing are also examined.
C1 [Sagayam, K. Martin; Hemanth, D. Jude] Karunya Univ, Dept ECE, Coimbatore 641114, Tamil Nadu, India.
C3 Karunya Institute of Technology & Sciences
RP Hemanth, DJ (corresponding author), Karunya Univ, Dept ECE, Coimbatore 641114, Tamil Nadu, India.
EM martinsagayam.k@gmail.com; jude_hemanth@rediffmail.com
RI Kulandairaj, Martin Sagayam/J-7374-2019; Karunya,
   Librarian/HHS-3630-2022
OI Kulandairaj, Martin Sagayam/0000-0003-2080-0497; Karunya,
   Librarian/0009-0006-0726-2507; HEMANTH, JUDE/0000-0002-6091-1880
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal J. K., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P2, DOI 10.1109/MNRAO.1994.346261
   [Anonymous], HDB VIRTUAL ENV DESI
   [Anonymous], P 5 INT C E LEARN GA
   [Anonymous], INT C COMP DES APPL
   [Anonymous], P BIOM
   [Anonymous], IEEE P 9 INT C NEUR
   [Anonymous], 2011, THESIS
   [Anonymous], 6931998 U DORTM
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2003, P JOINT INT C ICANN
   [Anonymous], INTELLIGENT USER INT
   [Anonymous], 1997, THESIS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], FS9605 AAAI MED LAB
   [Anonymous], 4 POSTGR C IPGCON 20
   [Anonymous], P IEEE INT C COMP CO
   [Anonymous], INT J ADV ROBOT SYST
   [Anonymous], P IEEE 2 INT C AUT F
   [Anonymous], INT J ENG SCI TECHNO
   [Anonymous], P INT GEST WORKSH GI
   [Anonymous], P JOINT ACM WORKSH H
   [Anonymous], J ENGAPPLARTIF INTEL
   [Anonymous], P IEEE NONGR ART MOT
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], INT J COMPUT SCI INF
   [Anonymous], VIRTUAL GLOVE BOX VG
   [Anonymous], THESIS RUSS COLL ENG
   [Anonymous], 1999, THESIS
   [Anonymous], 1995, P INT WORKSH AUT FAC
   [Anonymous], P INT C CONTR AUT RO
   [Anonymous], P INT C IM PROC
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Billinghurst M., 1998, Computer Graphics, V32, P60, DOI 10.1145/307710.307730
   BOLT RA, 1980, P 7 ANN C COMP GRAPH, P262, DOI [DOI 10.1145/800250.807503, 10.1145/965105.807503, DOI 10.1145/965105.807503]
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   CHONG Y, 2016, J SOFTW ENG APPL, V9, P103, DOI DOI 10.4236/JSEA.2016.94009
   Chung WK, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P336
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   ELMEZAI M, 2007, P IEEE INT S SIGN PR
   Fang YK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P995
   FELS SS, 1993, IEEE T NEURAL NETWOR, V4, P2, DOI 10.1109/72.182690
   Fels SS, 1998, IEEE T NEURAL NETWOR, V9, P205, DOI 10.1109/72.655042
   Feng ZQ, 2011, PATTERN RECOGN, V44, P1089, DOI 10.1016/j.patcog.2010.08.007
   Foxlin E, 2002, HUM FAC ER, P163
   Freeman W. T., 1995, IEEE INT WORKSH AUT
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Gupta A, 2012, PROC TECH, V1, P98, DOI 10.1016/j.protcy.2012.10.013
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Ibarguren A, 2010, ENG APPL ARTIF INTEL, V23, P1216, DOI 10.1016/j.engappai.2010.06.001
   Jain A.K., 1999, Proceedings of Second International Conference on Audio and Video-Based Biometric Person Authentication (AVBPA), P166
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Joshi A, 2017, IMAGE VISION COMPUT, V58, P86, DOI 10.1016/j.imavis.2016.06.001
   Just A, 2009, COMPUT VIS IMAGE UND, V113, P532, DOI 10.1016/j.cviu.2008.12.001
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Khaled H, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/741068
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Koike H., 2001, ACM Transactions on Computer-Human Interaction, V8, P307, DOI 10.1145/504704.504706
   Kölsch M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P614, DOI 10.1109/AFGR.2004.1301601
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lay YL, 2000, OPT LASER TECHNOL, V32, P1, DOI 10.1016/S0030-3992(99)00105-X
   Lee D, 2014, ROBOT AUTON SYST, V62, P818, DOI 10.1016/j.robot.2014.02.002
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Lenman S., 2002, Proc. of the Second Nordic Conference on Human-Computer Interaction, P239, DOI DOI 10.1145/572020.572055
   Letessier Julien., 2004, P 17 ANN ACM S USER, P119, DOI DOI 10.1145/1029632.1029652
   Li C., 2004, P ACM MULTIMEDIA C 2, P836
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Li X., 2003, Gesture recognition based on fuzzy C-Means clustering algorithm
   Li YT, 2014, PATTERN RECOGN, V47, P80, DOI 10.1016/j.patcog.2013.05.028
   Licsár A, 2005, IMAGE VISION COMPUT, V23, P1102, DOI 10.1016/j.imavis.2005.07.016
   Licsár A, 2004, INT C PATT RECOG, P971, DOI 10.1109/ICPR.2004.1333935
   Lim CH, 2015, PATTERN RECOGN, V48, P1773, DOI 10.1016/j.patcog.2014.11.016
   Liu A, 2003, PRESENCE-VIRTUAL AUG, V12, P599, DOI 10.1162/105474603322955905
   Liu Yun, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P72, DOI 10.1109/WCSE.2009.769
   Malik S., 2004, ACM INT C MULTIMODAL, P289, DOI DOI 10.1145/1027933.1027980
   Maraqa M, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P485
   Martin J, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P573, DOI 10.1109/AFGR.1998.671009
   Maung T.H. H., 2009, Proceedings of World Academy of Science: Engineering Technology, V50, P466
   Mitra S., 2003, Data mining: multimedia, soft computing, and bioinformatics
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Murakami K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P237, DOI 10.1145/108844.108900
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Nielsen M, 2003, LECT NOTES ARTIF INT, V2915, P409
   Oden C, 2003, PATTERN RECOGN LETT, V24, P2145, DOI 10.1016/S0167-8655(03)00087-4
   Oka K, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P429, DOI 10.1109/AFGR.2002.1004191
   Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889
   Patwardhan KS, 2007, PATTERN RECOGN LETT, V28, P329, DOI 10.1016/j.patrec.2006.04.002
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qin SX, 2014, J SIGNAL PROCESS SYS, V74, P47, DOI 10.1007/s11265-013-0778-7
   Quek F., 2002, ACM Transactions on Computer-Human Interaction, V9, P171, DOI 10.1145/568513.568514
   Quek FKH, 1996, IEEE MULTIMEDIA, V3, P36, DOI 10.1109/93.556459
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Segen J., 1998, Proceedings ACM Multimedia 98, P455, DOI 10.1145/290747.290822
   Shin MC, 2004, PATTERN RECOGN, V37, P1011, DOI 10.1016/j.patcog.2003.11.007
   Stenger B., 2004, Int. Workshop on Human-Computer Interaction, P102
   Sturman David Joel, 1992, THESIS
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Su CJ, 2014, APPL SOFT COMPUT, V22, P652, DOI 10.1016/j.asoc.2014.04.020
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Teng XL, 2005, J VISUAL LANG COMPUT, V16, P442, DOI 10.1016/j.jvlc.2005.04.003
   Travieso CM, 2014, INFORM SCIENCES, V275, P45, DOI 10.1016/j.ins.2014.02.031
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Turk M, 2002, HUM FAC ER, P223
   Ueda E, 2003, IEEE T IND ELECTRON, V50, P676, DOI 10.1109/TIE.2003.814758
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang L, 2008, IMAGE VISION COMPUT, V26, P820, DOI 10.1016/j.imavis.2007.09.002
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wexelblatt A., 1995, ACM Trans. on Computer-Human Interaction, V2, P179
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   WYSOSKI SG, 2003, THESIS
   Xu WY, 2009, COMM COM INF SC, V61, P90
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yeasin M, 2000, PATTERN RECOGN, V33, P1805, DOI 10.1016/S0031-3203(99)00175-2
   Yin XM, 2003, PATTERN RECOGN, V36, P567, DOI 10.1016/S0031-3203(02)00072-9
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Zaidan AA, 2014, ENG APPL ARTIF INTEL, V32, P136, DOI 10.1016/j.engappai.2014.03.002
   Zhao M, 1998, IEEE T PATTERN ANAL, V20, P1174, DOI 10.1109/34.730553
   Zhu C, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2415, DOI 10.1109/IROS.2009.5354657
NR 144
TC 92
Z9 102
U1 2
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2017
VL 21
IS 2
BP 91
EP 107
DI 10.1007/s10055-016-0301-0
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA EV3ZT
UT WOS:000401698600003
DA 2024-07-18
ER

PT J
AU Carlson, P
   Vance, JM
   Berg, M
AF Carlson, Patrick
   Vance, Judy M.
   Berg, Meisha
TI An evaluation of asymmetric interfaces for bimanual virtual assembly
   with haptics
SO VIRTUAL REALITY
LA English
DT Article
DE Haptic devices; Virtual reality; Interaction devices; Interaction
   techniques; Human-computer interaction (HCI); Bimanual interaction
ID INFORMATION
AB Immersive computing technology provides a human-computer interface to support natural human interaction with digital data and models. One application for this technology is product assembly methods planning and validation. This paper presents the results of a user study which explores the effectiveness of various bimanual interaction device configurations for virtual assembly tasks. Participants completed two assembly tasks with two device configurations in five randomized bimanual treatment conditions (within subjects). A Phantom Omni(A (R)) with and without haptics enabled and a 5DT Data Glove were used. Participant performance, as measured by time to assemble, was the evaluation metric. The results revealed that there was no significant difference in performance between the five treatment conditions. However, half of the participants chose the 5DT Data Glove and the haptic-enabled Phantom Omni(A (R)) as their preferred device configuration. In addition, qualitative comments support both the preference of haptics during the assembly process and comments confirming Guiard's kinematic chain model.
C1 [Carlson, Patrick; Vance, Judy M.; Berg, Meisha] Iowa State Univ, Human Comp Interact, 1620 Howe Hall, Ames, IA 50011 USA.
C3 Iowa State University
RP Vance, JM (corresponding author), Iowa State Univ, Human Comp Interact, 1620 Howe Hall, Ames, IA 50011 USA.
EM carlson2442@gmail.com; jmvance@iastate.edu; meisha.berg@gmail.com
OI Carlson, Patrick/0000-0001-9580-5749
FU National Science Foundation [CMMI-0928774]
FX This work was performed at the Virtual Reality Applications Center at
   Iowa State University as part of research funded by the National Science
   Foundation award CMMI-0928774.
CR [Anonymous], WORKSH SOFTW ENG ARC
   [Anonymous], 37 INT MATADOR C MAN
   [Anonymous], P ASME 2013 INT DES
   [Anonymous], P 18 INT C ART REAL
   [Anonymous], ASME 2011 WORLD C IN, DOI DOI 10.1115/WINVR2011-5585
   [Anonymous], P ASME 2012 INT DES
   [Anonymous], P EM TECHN C 2009
   [Anonymous], 1999, P CHI ACM
   [Anonymous], SPRINGER SERIES TOUC
   Balakrishnan R., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P33, DOI 10.1145/332040.332404
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Crossan A., 2006, CHI'06 Extended Abstracts on Human Factors in Computing Systems - CHI EA'06, P676, DOI DOI 10.1145/1125451.1125589
   Dominjon L, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P639
   Fiorentino M, 2010, COMPUT AIDED DESIGN, V42, P462, DOI 10.1016/j.cad.2008.12.002
   Fischer A., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P225, DOI 10.1145/769953.769979
   Giachritsis C, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P629, DOI 10.1109/WHC.2009.4810836
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Gunn C., 2006, VIRTUAL REAL-LONDON, V10, P73
   Hinckley K., 1998, ACM Transactions on Computer-Human Interaction, V5, P260, DOI 10.1145/292834.292849
   Hinckley K., 1997, Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, P27, DOI [DOI 10.1145/258549.258571, 10.1145/258549]
   Kron A, 2004, IEEE INT CONF ROBOT, P1968, DOI 10.1109/ROBOT.2004.1308112
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   LOFTUS EF, 1989, J EXP PSYCHOL GEN, V118, P100, DOI 10.1037/0096-3445.118.1.100
   LOFTUS EF, 1978, J EXP PSYCHOL-HUM L, V4, P19, DOI 10.1037/0278-7393.4.1.19
   MARTENIUK RG, 1984, Q J EXP PSYCHOL-A, V36, P335, DOI 10.1080/14640748408402163
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Owen R., 2005, Proceedings of Graphics Interface 2005, P17
   Pavlik RA, 2015, J COMPUT INF SCI ENG, V15, DOI 10.1115/1.4031826
   PETERS M, 1985, Q J EXP PSYCHOL-A, V37, P171, DOI 10.1080/14640748508400929
   Poupyrev I, 1999, J VISUAL LANG COMPUT, V10, P19, DOI 10.1006/jvlc.1998.0112
   Shaw C., 1994, UIST '94. Seventh Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P205, DOI 10.1145/192426.197517
   Vélaz Y, 2014, VIRTUAL REAL-LONDON, V18, P161, DOI 10.1007/s10055-013-0240-y
NR 32
TC 6
Z9 6
U1 1
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2016
VL 20
IS 4
BP 193
EP 201
DI 10.1007/s10055-016-0290-z
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DY6FF
UT WOS:000385201100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dimbwadyo-Terrer, I
   Trincado-Alonso, F
   De los Reyes-Guzmán, A
   López-Monteagudo, P
   Polonio-López, B
   Gil-Agudo, A
AF Dimbwadyo-Terrer, I.
   Trincado-Alonso, F.
   De los Reyes-Guzman, A.
   Lopez-Monteagudo, P.
   Polonio-Lopez, B.
   Gil-Agudo, A.
TI Activities of daily living assessment in spinal cord injury using the
   virtual reality system Toyra®: functional and kinematic correlations
SO VIRTUAL REALITY
LA English
DT Article
DE Assessment; Activities of daily living; Correlations; Kinematic;
   Tetraplegia; Virtual reality
ID INDEPENDENCE MEASURE SCIM; REHABILITATION; PERFORMANCE; MOTION; STROKE
AB The main objective of this study was to analyze the correlations between functional scales and kinematic data collected during the execution of upper limb (UL) basic activities of daily living in an immersive virtual reality (VR) environment. Fifteen people with tetraplegia participated in the study. Moreover, we also want to confirm if changes in UL functional performance detected by functional scales are also detected by the VR system Toyra (R). Patients were assessed before and after 4 weeks of daily conventional rehabilitation treatment complemented with a training with the VR system. Significant positive correlations between kinematic and functional parameters were found in the post assessment, verifying that changes in UL functional performance detected by functional scales are also measured by the VR system Toyra (R), concretely the related to shoulder movements. Additionally, a predefined Agility metric has been applied, showing inversely proportional results to the level of injury, as we expected. The self-care category of the Spinal Cord Independence Measure (SCIM III) and the ranges of motion (ROM) captured with the VR system were analyzed, showing statistical significance changes between pre-post evaluations, supporting the hypothesis that kinematic analysis complements clinical and functional assessments of patients with tetraplegia.
C1 [Dimbwadyo-Terrer, I.; Trincado-Alonso, F.; De los Reyes-Guzman, A.; Gil-Agudo, A.] Natl Hosp Spinal Cord Injury, Biomech & Tech Aids Dept, Toledo, Spain.
   [Dimbwadyo-Terrer, I.] Ctr Super Estudios Univ La Salle UAM, Occupat Thinks Res Grp, La Salle Campus, Madrid, Spain.
   [Lopez-Monteagudo, P.] Indra Syst, Madrid, Spain.
   [Polonio-Lopez, B.] Univ Castilla La Mancha, Talavera De La Reina, Spain.
C3 Indra; Universidad de Castilla-La Mancha
RP Dimbwadyo-Terrer, I (corresponding author), Natl Hosp Spinal Cord Injury, Biomech & Tech Aids Dept, Toledo, Spain.; Dimbwadyo-Terrer, I (corresponding author), Ctr Super Estudios Univ La Salle UAM, Occupat Thinks Res Grp, La Salle Campus, Madrid, Spain.
EM i.dimbwadyo@gmail.com
RI Polonio-López, Begoña/D-3878-2009; Gil-Agudo, Ángel/ABD-3065-2021; de
   los Reyes Guzmán, Ana/K-9960-2014; Coish, Elizabeth/AAU-1245-2020
OI Polonio-López, Begoña/0000-0003-2922-7519; Gil-Agudo,
   Ángel/0000-0001-5082-4225; de los Reyes-Guzman, Ana/0000-0003-2905-2405
CR Alt Murphy M, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-18
   [Anonymous], ACTIVITIES DAILY LIV
   [Anonymous], 2006, TXB NEURAL REPAIR RE, DOI DOI 10.1017/CBO9780511545078.015
   Cacho EWA, 2011, INT J REHABIL RES, V34, P65, DOI 10.1097/MRR.0b013e32833d6cf3
   Burdea GC, 2003, METHOD INFORM MED, V42, P519
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Catz A, 1997, SPINAL CORD, V35, P850, DOI 10.1038/sj.sc.3100504
   Catz A, 2001, SPINAL CORD, V39, P97, DOI 10.1038/sj.sc.3101118
   Chang JJ, 2005, CLIN BIOMECH, V20, P381, DOI 10.1016/j.clinbiomech.2004.11.015
   Cameirao MDS, 2011, RESTOR NEUROL NEUROS, V29, P287, DOI 10.3233/RNN-2011-0599
   de los Reyes-Guzmán AD, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-41
   Dimbwadyo-Terrer I, 2013, INT C NEUR EL INF VI, P81
   Gil-Agudo A., 2011, BIOMECHANICS APPL, P127
   Gil-Agudo A, 2012, REHABILITACION, V46, P41
   Gil-Agudo A, 2013, NEURAL REGEN RES, V8, P1773, DOI 10.3969/j.issn.1673-5374.2013.19.005
   Harvey LA, 2001, SPINAL CORD, V39, P37, DOI 10.1038/sj.sc.3101101
   Hazard-Munro B, 2014, STAT METHODS HLTH CA
   Itzkovich M, 2007, DISABIL REHABIL, V29, P1926, DOI 10.1080/09638280601046302
   Lang CE, 2009, ARCH PHYS MED REHAB, V90, P1692, DOI 10.1016/j.apmr.2009.04.005
   Lee D, 2012, GERONTOLOGY, V58, P269, DOI 10.1159/000329892
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P383, DOI 10.1089/109493103322278763
   Rudhe C, 2009, NEUROREHAB NEURAL RE, V23, P413, DOI 10.1177/1545968308331143
   SAFAEERAD R, 1990, ARCH PHYS MED REHAB, V71, P505
   Spooren AIF, 2008, J REHABIL MED, V40, P637, DOI 10.2340/16501977-0231
   Trincado-Alonso F, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/904985
   Tsao CC, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-45
   van Tuijl JH, 2002, SPINAL CORD, V40, P51, DOI 10.1038/sj.sc.3101261
   Weiss Patrice L, 2004, J Neuroeng Rehabil, V1, P12, DOI 10.1186/1743-0003-1-12
   Zariffa J, 2012, IEEE T NEUR SYS REH, V20, P341, DOI 10.1109/TNSRE.2011.2181537
NR 29
TC 8
Z9 8
U1 0
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2016
VL 20
IS 1
BP 17
EP 26
DI 10.1007/s10055-015-0276-2
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1FY
UT WOS:000376092000002
DA 2024-07-18
ER

PT J
AU Aiken, MP
   Berry, MJ
AF Aiken, Mary P.
   Berry, Mike J.
TI Posttraumatic stress disorder: possibilities for olfaction and virtual
   reality exposure therapy
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality exposure therapy; Posttraumatic stress disorder;
   Olfaction; Odor; Memory
ID VIETNAM VETERANS; DISPLAY; ODOR; SENSE; IDENTIFICATION; AMYGDALA;
   RECALL; SMELL; LONG; IRAQ
AB Visual and auditory information has dominated the field of virtual reality (VR). Evaluation of the role of sensory stimulation in VR has highlighted olfactory stimulation as a potentially powerful yet underutilized therapeutic tool. Early studies of immersive environments, which were run as experiments, incorporated smell in the virtual experience; however, olfaction in virtual environment design and development has arguably failed to maintain a position commensurate with its sensory capacity, exemplified by the paucity of research and possible application. A review of the literature suggests that olfaction as a component of virtual environment exposure therapy may be a useful addition in the treatment of posttraumatic stress disorder (PTSD) a mental health condition triggered by a terrifying event, either experiencing or witnessing it. Symptoms may include flashbacks, nightmares and anxiety, as well as uncontrollable thoughts about the event. However, to investigate the role of olfaction further research is required in the formulation, display, staging and customization of scent, coupled with an in-depth analysis of the role of olfaction in cognitive function, memory, emotion and creation of presence, particularly in the context of VR treatment of PTSD. Benefits of olfactory therapy may, however, be compromised by the fact that olfactory identification deficit has been noted as a component of PTSD. Investigation is required into causative or reactive mechanisms that may underlie olfactory deficits and into suitable VR therapeutic protocols that could be designed to address these deficits. Additionally, ongoing VR technological developments may deliver increasing affordability and portability in terms of VR treatment options, particularly regarding head-mounted display units. A cyberpsychological consideration of the problem of PTSD, that is, an inter-disciplinary approach combining technology and psychology learning's may merit consideration. A review of findings suggests that research protocols focused on olfaction as a variable in a multi-sensory VR exposure therapeutic program may positively impact on treatment outcomes in PTSD population.
C1 [Aiken, Mary P.; Berry, Mike J.] Royal Coll Surgeons Ireland, Inst Leadership, CyberPsychol Res Ctr, Dublin 18, Ireland.
   [Aiken, Mary P.] Hawaii Pacific Univ, Asia Pacific Inst Resilience & Sustainabil AIRS, Dr Steve Chan Ctr Sensemaking, Honolulu, HI USA.
   [Aiken, Mary P.] Swansea Univ, Swansea, W Glam, Wales.
   [Aiken, Mary P.] Europol, European Cyber Crime Ctr EC3, The Hague, Netherlands.
   [Aiken, Mary P.] Middlesex Univ, Sch Law, London N17 8HR, England.
C3 Royal College of Surgeons - Ireland; Swansea University; Middlesex
   University
RP Aiken, MP (corresponding author), Royal Coll Surgeons Ireland, Inst Leadership, CyberPsychol Res Ctr, Reservoir House,Ballymoss Rd, Dublin 18, Ireland.
EM maryaiken@rcsi.ie
OI Aiken, Mary/0000-0001-9800-3952
CR Adams P, 2015, JORDAN PILOT HOSTAGE
   Aiken MP, 2014, PRIMER RES MEDIATED
   American Chemical Society, 2001, SCI DAILY
   AMSTERDAM JD, 1987, BIOL PSYCHIAT, V22, P1481, DOI 10.1016/0006-3223(87)90108-9
   [Anonymous], P SIGGRAPH
   [Anonymous], 1992, PRESENCE
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Bakker GM, 2013, CLIN PSYCHOL-UK, V17, P91, DOI 10.1111/cp.12020
   Barak A, 2008, PSYCHOLOGICAL ASPECTS OF CYBERSPACE: THEORY, RESEARCH, APPLICATIONS, P1, DOI 10.1017/CBO9780511813740
   Barfield W, 1995, PRESENCE-TELEOP VIRT, V5, P109, DOI 10.1162/pres.1996.5.1.109
   Baston J, 2014, OCULUS RIFT MADE ME
   Basu M, 2013, CNN NEWS
   Bennetto L, 2007, BIOL PSYCHIAT, V62, P1015, DOI 10.1016/j.biopsych.2007.04.019
   Biocca F, 1997, J COMPUT MED COMMUN, V3
   Botella C, 2010, CYBERPSYCH BEH SOC N, V13, P67, DOI 10.1089/cyber.2009.0353
   Bushdid C, 2014, SCIENCE, V343, P1370, DOI 10.1126/science.1249168
   BUXTON W, 1994, INTERACTING VIRTUAL
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Cahill L, 1996, P NATL ACAD SCI USA, V93, P8016, DOI 10.1073/pnas.93.15.8016
   Carlson N.R., 2010, PSYCHOL SCI BEHAV
   Chen A, 2014, CONTENT MODERATION
   Chen Y, 2006, ICAT 2006: 16TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE - WORSHOPS, PROCEEDINGS, P580
   Chu S, 2000, CHEM SENSES, V25, P111, DOI 10.1093/chemse/25.1.111
   Church D, 2014, EXPLORE-NY, V10, P24, DOI 10.1016/j.explore.2013.10.006
   Craig AlanB., 2009, Developing Virtual Reality Applications: Foundations of Effective Design
   Crocker EC, 1927, AM PERFUMERY ESSENT, V22, P325
   Davis N, 2014, HUMAN NOSE CAN DETEC
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Dileo JF, 2008, PSYCHOL MED, V38, P523, DOI 10.1017/S0033291707001456
   Discalfani JM, 2012, THESIS HOFSTRA U
   Doty RL, 1997, ARCH NEUROL-CHICAGO, V54, P1131, DOI 10.1001/archneur.1997.00550210061014
   Dredge S, 2014, FACEBOOK CLOSES ITS
   FitzGerald BJ, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00081
   Fogg Brian J, 2009, P 4 INT C PERS TECHN, P1, DOI [10.1145/1541948.1541999, DOI 10.1145/1541948.1541999]
   Gerardi M, 2008, J TRAUMA STRESS, V21, P209, DOI 10.1002/jts.20331
   Glantz K, 2003, PSYCHOTHERAPY, V40, P55, DOI 10.1037/0033-3204.40.1-2.55
   Heilig M, 1962, Patent No. [3,050,870, 3050870]
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Ischer M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00736
   Jackson JH, 1864, LOND HOSP REP, V1, P470
   Jaycox LH, 1998, J CONSULT CLIN PSYCH, V66, P185, DOI 10.1037/0022-006X.66.1.185
   Josman N, 2008, CYBERPSYCHOL BEHAV, V11, P775, DOI 10.1089/cpb.2008.0048
   Kandel E., 2013, PRINCIPLES NEURAL SC
   Larsson M, 1997, CHEM SENSES, V22, P623, DOI 10.1093/chemse/22.6.623
   Lehrner J, 2000, PHYSIOL BEHAV, V10, P1
   Locke B, 1949, J APPL PSYCHOL, V33, P167, DOI 10.1037/h0062514
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Majid A, 2014, COGNITION, V130, P266, DOI 10.1016/j.cognition.2013.11.004
   Matsukura H, 2013, IEEE T VIS COMPUT GR, V19, P606, DOI 10.1109/TVCG.2013.40
   McLay RN, 2012, MIL MED, V177, P635, DOI 10.7205/MILMED-D-11-00221
   Moberg PJ, 1997, AM J PSYCHIAT, V154, P1016
   Mortonheilig.com, 2010, INV FIELD VIRT REAL
   Mujica-Parodi LR, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006415
   Murray G, 2002, GLOBE MAIL
   Myers CS, 1915, LANCET, V1, P316
   Nakalzumi F, 2006, P IEEE VIRT REAL ANN, P207, DOI 10.1109/VR.2006.122
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   National Academies of Science Institute of Medicine Committee on Treatment of Posttraumatic Stress Disorder, 2007, TREATM POSTTR STRESS
   Olatunji BO, 2009, COGN BEHAV PRACT, V16, P172, DOI 10.1016/j.cbpra.2008.07.003
   Phillips L, 2012, PRESENCE-VIRTUAL AUG, V21, P119, DOI 10.1162/PRES_a_00100
   Pointer MR, 1998, COLOR RES APPL, V23, P52, DOI 10.1002/(SICI)1520-6378(199802)23:1<52::AID-COL8>3.0.CO;2-2
   Reger GM, 2011, J TRAUMA STRESS, V24, P93, DOI 10.1002/jts.20574
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rizzo A., 2006, NATO Security through Science Series E Human and Societal Dynamics, V6, P235
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Rothbaum BO, 2002, AM J PSYCHOTHER, V56, P59, DOI 10.1176/appi.psychotherapy.2002.56.1.59
   Rothbaum BO, 2000, EFFECTIVE TREATMENTS FOR PTSD, P60
   Rothbaum BO, 2001, J CLIN PSYCHIAT, V62, P617, DOI 10.4088/JCP.v62n0808
   Rothbaum BO, 1999, J TRAUMA STRESS, V12, P263, DOI 10.1023/A:1024772308758
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Sense of Smell Institute, 2010, QUAL LIF OLF DYSF
   Spence C, 2011, PSYCHOL MARKET, V28, P267, DOI 10.1002/mar.20392
   Spencer BS, 2006, IEEE T INF TECHNOL B, V10, P168, DOI 10.1109/TITB.2005.856851
   Spooner DM, 2006, ARCH CLIN NEUROPSYCH, V21, P327, DOI 10.1016/j.acn.2006.04.004
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stevens SS, 1938, HEARING, P152
   University of California San Diego Jacobs School of Engineering, 2011, COM TV SCREENS FUT S
   Vasterling JJ, 2000, J TRAUMA STRESS, V13, P241, DOI 10.1023/A:1007754611030
   Vermetten E, 2007, PSYCHOPHARMACOL BULL, V40, P8
   Vlahos J., 2006, Popular Sci, V8
   Walshe DG, 2003, CYBERPSYCHOL BEHAV, V6, P329, DOI 10.1089/109493103322011641
   Wesson DW, 2011, NEUROSCI BIOBEHAV R, V35, P655, DOI 10.1016/j.neubiorev.2010.08.004
   Wilson JAB, 2008, CYBERPSYCHOL BEHAV, V11, P767, DOI 10.1089/cpb.2008.0071
   Winkler Cathy., 1991, Anthropology Today, V7, P12, DOI DOI 10.2307/3033155
   Yamada T, 2006, P IEEE VIRT REAL ANN, P199, DOI 10.1109/VR.2006.147
   Yan Z., 2012, Encyclopedia of cyber behavior
   Yanagida Y, 2004, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2004.1310054
   Yehuda R, 2005, J CLIN ENDOCR METAB, V90, P4115, DOI 10.1210/jc.2005-0550
NR 88
TC 32
Z9 39
U1 2
U2 96
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2015
VL 19
IS 2
BP 95
EP 109
DI 10.1007/s10055-015-0260-x
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CJ9MO
UT WOS:000355826700003
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Elner, KW
   Wright, H
AF Elner, Kevin W.
   Wright, Helen
TI Phenomenal regression to the real object in physical and virtual worlds
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual environments; Depth and size perception; Depth compression;
   Index of phenomenal regression; Thouless ratio; Brunswik ratio
ID EGOCENTRIC DISTANCE PERCEPTION; VIEWING CONDITIONS; ENVIRONMENTS;
   DISPLAYS; FIELD
AB In this paper, we investigate a new approach to comparing physical and virtual size and depth percepts that captures the involuntary responses of participants to different stimuli in their field of view, rather than relying on their skill at judging size, reaching or directed walking. We show, via an effect first observed in the 1930s, that participants asked to equate the perspective projections of disc objects at different distances make a systematic error that is both individual in its extent and comparable in the particular physical and virtual setting we have tested. Prior work has shown that this systematic error is difficult to correct, even when participants are knowledgeable of its likelihood of occurring. In fact, in the real world, the error only reduces as the available cues to depth are artificially reduced. This makes the effect we describe a potentially powerful, intrinsic measure of VE quality that ultimately may contribute to our understanding of VE depth compression phenomena.
C1 [Elner, Kevin W.; Wright, Helen] Univ Hull, Dept Comp Sci, Kingston Upon Hull HU6 7RX, N Humberside, England.
C3 University of Hull
RP Elner, KW (corresponding author), Univ Hull, Dept Comp Sci, Kingston Upon Hull HU6 7RX, N Humberside, England.
EM k.elner@hull.ac.uk; h.wright@hull.ac.uk
FU Department of Computer Science at the University of Hull
FX We acknowledge useful discussions with Derek Wills and James Ward of the
   Department of Computer Science at the University of Hull. KWE was
   supported by a doctoral student scholarship funded by the Department of
   Computer Science at the University of Hull.
CR [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   Creem-Regehr SH, 2005, PERCEPTION, V34, P191, DOI 10.1068/p5144
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Ellis SR, 1998, HUM FACTORS, V40, P415, DOI 10.1518/001872098779591278
   GILINSKY A S, 1955, Am J Psychol, V68, P173
   Interrante V, 2008, PRESENCE-TELEOP VIRT, V17, P176, DOI 10.1162/pres.17.2.176
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Kuhl SA, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1577755.1577762
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Mohler BJ, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P194
   Murgia Alessio, 2009, International Journal of Virtual Reality, V8, P67
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Piryankova IV, 2013, DISPLAYS, V34, P153, DOI 10.1016/j.displa.2013.01.001
   Ponto K, 2013, IEEE T VIS COMPUT GR, V19, P691, DOI 10.1109/TVCG.2013.36
   Press W.H, 1992, NUMERICAL RECIPES C, P666
   Sedgwick HA, 1986, HDB PERCEPTION HUMAN, V1, P129
   Singh Gurjot., 2010, Proceedings of the 7th Symposium on Applied Perception in Graphics and Visualization, P149, DOI DOI 10.1145/1836248.1836277
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   Thouless RH, 1931, B J PSYCHOL-GEN SECT, V21, P339, DOI 10.1111/j.2044-8295.1931.tb00597.x
   Thouless RH, 1931, B J PSYCHOL-GEN SECT, V22, P1, DOI 10.1111/j.2044-8295.1931.tb00609.x
   Willemsen P, 2002, EXPT COMP PERCEIVED
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
NR 25
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2015
VL 19
IS 1
BP 21
EP 31
DI 10.1007/s10055-014-0257-x
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CB5CS
UT WOS:000349645700002
DA 2024-07-18
ER

PT J
AU Cheng, LK
   Chieng, MH
   Chieng, WH
AF Cheng, Li-Keng
   Chieng, Ming-Hua
   Chieng, Wei-Hua
TI Measuring virtual experience in a three-dimensional virtual reality
   interactive simulator environment: a structural equation modeling
   approach
SO VIRTUAL REALITY
LA English
DT Article
DE Flow; Telepresence; Interactivity; Vividness; Virtual experience
ID CONFIRMATORY FACTOR-ANALYSIS; OF-FIT INDEXES; FLOW EXPERIENCE; SOCIAL
   PRESENCE; TELEPRESENCE; CONSUMER; INVOLVEMENT; SENSE; COMMUNICATION;
   CONSEQUENCES
AB With the rapid development of the VR market, virtual experience has increasingly been the object of study in recent years. A growing number of studies have reported the positive effect that virtual experience can have on a user's mood and loyalty. However, few studies have investigated the influence of the mechanism of virtual experience on users' mood and loyalty. To compensate for this research gap, this study aims to evaluate consumers' virtual experience by examining the flow state in a virtual environment. A total of 368 valid questionnaires were collected, and a structural equation modeling approach was employed in the data analysis. The study reveals that forming flow involves many factors: the intrinsic characteristics of the mediated environment, the consumer's assumptions and perceptions prior to entering the flow state, the stage at which the customer enters the flow state, and the consequences of the flow experience.
C1 [Cheng, Li-Keng] Natl Chengchi Univ, Dept Business Adm, Taipei 11605, Taiwan.
   [Chieng, Ming-Hua] Natl Chiao Tung Univ, Inst Business & Management, Taipei 100, Taiwan.
   [Chieng, Wei-Hua] Natl Chiao Tung Univ, Dept Mech Engn, Hsinchu 300, Taiwan.
C3 National Chengchi University; National Yang Ming Chiao Tung University;
   National Yang Ming Chiao Tung University
RP Cheng, LK (corresponding author), Natl Chengchi Univ, Dept Business Adm, 64,Sec 2,ZhiNan Rd, Taipei 11605, Taiwan.
EM zerowa@msn.com; herrowa@yahoo.com.tw
RI Cheng, Li-Keng/HTM-9949-2023
OI Cheng, Li-Keng/0000-0001-9742-5782
CR Alba J, 1997, J MARKETING, V61, P38, DOI 10.2307/1251788
   ANDERSON JC, 1988, PSYCHOL BULL, V103, P411, DOI 10.1037/0033-2909.103.3.411
   Animesh A, 2011, MIS QUART, V35, P789
   [Anonymous], EVOLVING ITSELF PSYC
   [Anonymous], VISUAL REPRESENTATIO
   [Anonymous], J BUSINESS LOGISTICS
   [Anonymous], PRESENCE TELEOPER VI
   [Anonymous], 1990, PSYCHOL OPTIMAL EXPE
   [Anonymous], STUDY EFFECT WWW INT
   [Anonymous], 2010, Multivariate data analysis: A global perspective, DOI DOI 10.1002/9781119409137.CH4
   [Anonymous], 2012, FLOW EXPERIENCE CONT
   Bae S, 2012, INTERACT COMPUT, V24, P251, DOI 10.1016/j.intcom.2012.04.009
   BAGOZZI RP, 1982, ADMIN SCI QUART, V27, P459, DOI 10.2307/2392322
   Bagozzi RP, 1998, Journal of the academy of marketing science, V16, P76
   Beatty SE, 1998, J RETAILING, V74, P169, DOI 10.1016/S0022-4359(99)80092-X
   Benyon D, 2012, INTERACT COMPUT, V24, P219, DOI 10.1016/j.intcom.2012.04.005
   Biocca Frank., 1992, Presence: Teleoperators Virtual Environments, V1, P334, DOI [DOI 10.1162/PRES.1992.1.3.334, 10.1162/pres.1992.1.3.334]
   BONE PF, 1992, J CONSUM RES, V19, P93, DOI 10.1086/209289
   Bouchard S, 2012, INTERACT COMPUT, V24, P227, DOI 10.1016/j.intcom.2012.04.011
   Browne M.W., 1993, TESTING STRUCTURAL E, P35
   CELSI RL, 1988, J CONSUM RES, V15, P210, DOI 10.1086/209158
   Chanel G, 2012, INTERACT COMPUT, V24, P306, DOI 10.1016/j.intcom.2012.04.012
   Choi DH, 2007, INT J HUM-COMPUT ST, V65, P223, DOI 10.1016/j.ijhcs.2006.10.002
   Chou TJ, 2003, CYBERPSYCHOL BEHAV, V6, P663, DOI 10.1089/109493103322725469
   Coyle JR, 2001, J ADVERTISING, V30, P65, DOI 10.1080/00913367.2001.10673646
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   Csikszentmihalyi Mihaly., 1988, OPTIMAL EXPERIENCE
   Dix A, 2004, HUM-COMPUT INTERACT
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Durlach N., 1995, Virtual Reality: Scientific and Technological Challenges, DOI 10.17226/4761
   ELLIS GD, 1994, J LEISURE RES, V26, P337, DOI 10.1080/00222216.1994.11969966
   Faiola A, 2013, COMPUT HUM BEHAV, V29, P1113, DOI 10.1016/j.chb.2012.10.003
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Fortin DR, 2005, J BUS RES, V58, P387, DOI 10.1016/S0148-2963(03)00106-1
   Franzen G., 1999, Brands and Advertising: How Advertising Effectiveness Influences Brand Equity
   Friedl M., 2002, ONLINE GAME INTERACT, V1st
   GERBING DW, 1992, SOCIOL METHOD RES, V21, P132, DOI 10.1177/0049124192021002002
   Gerrig R. J., 1993, EXPERIENCING NARRATI, DOI DOI 10.12987/9780300159240
   Gervasi O, 2010, VIRTUAL REAL-LONDON, V14, P153, DOI 10.1007/s10055-010-0161-y
   GHANI JA, 1994, J PSYCHOL, V128, P381, DOI 10.1080/00223980.1994.9712742
   Guo YM, 2009, INFORM SYST J, V19, P369, DOI 10.1111/j.1365-2575.2007.00292.x
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hoffman DL, 1996, J MARKETING, V60, P50, DOI 10.2307/1251841
   Hoffman DL, 2009, J INTERACT MARK, V23, P23, DOI 10.1016/j.intmar.2008.10.003
   Hsu CL, 2004, INFORM MANAGE-AMSTER, V41, P853, DOI 10.1016/j.im.2003.08.014
   Huang LT, 2011, CYBERPSYCH BEH SOC N, V14, P3, DOI 10.1089/cyber.2009.0256
   Huang MH, 2006, PSYCHOL MARKET, V23, P383, DOI 10.1002/mar.20118
   Huang MH, 2003, COMPUT HUM BEHAV, V19, P425, DOI 10.1016/S0747-5632(02)00080-8
   Jung Y, 2011, J COMPUT-MEDIAT COMM, V16, P492, DOI 10.1111/j.1083-6101.2011.01540.x
   Karapanos E, 2012, INTERACT COMPUT, V24, P273, DOI 10.1016/j.intcom.2012.03.005
   Kettanurak V, 2001, INT J HUM-COMPUT ST, V54, P541, DOI 10.1006/ijhc.2001.0457
   Kim T., 1997, J COMPUT MED COMMUN, V3, pJCMC325
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Korzaan ML, 2003, J COMPUT INFORM SYST, V43, P25
   Koufaris M, 2002, INFORM SYST RES, V13, P205, DOI 10.1287/isre.13.2.205.83
   LAURENT G, 1985, J MARKETING RES, V22, P41, DOI 10.2307/3151549
   Lee KY, 2012, COMPUT HUM BEHAV, V28, P2134, DOI 10.1016/j.chb.2012.06.018
   Lee KY, 2012, INT J ADVERT, V31, P377, DOI 10.2501/IJA-31-2-377-396
   Lee M, 2007, J ADVERTISING, V36, P75, DOI 10.2753/JOA0091-3367360406
   Li H., 2001, Journal of Interactive Marketing, V15, P13, DOI [10.1002/dir.1013, DOI 10.1002/DIR.1013]
   Lutz R., 1980, The Role of Attitude Theory in Marketing
   Macredie R, 1996, 1996 WINTER SIMULATION CONFERENCE PROCEEDINGS, P669, DOI 10.1145/256562.256782
   Marsh H. W., 1996, ADV STRUCTURAL EQUAT, P315
   MARSH HW, 1988, PSYCHOL BULL, V103, P391, DOI 10.1037/0033-2909.103.3.391
   MARSH HW, 1985, PSYCHOL BULL, V97, P562, DOI 10.1037/0033-2909.97.3.562
   McConville KMV, 2012, VIRTUAL REAL-LONDON, V16, P315, DOI 10.1007/s10055-012-0212-7
   McMillan SJ, 2002, J ADVERTISING, V31, P29, DOI 10.1080/00913367.2002.10673674
   Minsky M., 1980, OMNI, V2, P45, DOI DOI 10.1145/566654.566630
   Mollen A, 2010, J BUS RES, V63, P919, DOI 10.1016/j.jbusres.2009.05.014
   Nah FFH, 2011, MIS QUART, V35, P731
   Nelson MR, 2006, J ADVERTISING, V35, P87, DOI 10.2753/JOA0091-3367350406
   Nijs L, 2012, INTERACT COMPUT, V24, P237, DOI 10.1016/j.intcom.2012.05.002
   Novak TP, 2000, MARKET SCI, V19, P22, DOI 10.1287/mksc.19.1.22.15184
   Nowak K., 2001, 4 ANN INT WORKSH COM, P686
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   O'Cass A, 2010, INTERNET RES, V20, P115, DOI 10.1108/10662241011032209
   Park SH, 1996, J LEISURE RES, V28, P233, DOI 10.1080/00222216.1996.11949774
   Perugini M, 2001, BRIT J SOC PSYCHOL, V40, P79, DOI 10.1348/014466601164704
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Reid D, 2002, CYBERPSYCHOL BEHAV, V5, P559, DOI 10.1089/109493102321018204
   Rheingold H., 1991, VIRTUAL REAL-LONDON
   Riva G., 1998, Virtual Reality, V3, P259, DOI 10.1007/BF01408706
   Riva G, 2012, INTERACT COMPUT, V24, P203, DOI 10.1016/j.intcom.2012.04.007
   Rothschild M.L., 1987, Marketing communications: From fundamentals to strategies
   Sánchez-Franco MJ, 2006, BEHAV INFORM TECHNOL, V25, P19, DOI 10.1080/01449290500124536
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   SEGARS AH, 1993, MIS QUART, V17, P517, DOI 10.2307/249590
   Shahid S, 2012, INTERACT COMPUT, V24, P292, DOI 10.1016/j.intcom.2012.04.006
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   SHIH C.F., 1998, EUR J MARKETING, V32, P655
   Siriaraya P, 2012, INTERACT COMPUT, V24, P280, DOI 10.1016/j.intcom.2012.03.003
   Sjölie D, 2012, INTERACT COMPUT, V24, P193, DOI 10.1016/j.intcom.2012.04.004
   Skadberg YX, 2004, COMPUT HUM BEHAV, V20, P403, DOI 10.1016/S0747-5632(03)00050-5
   St Amant K, 2002, J BUS TECH COMMUN, V16, P196, DOI 10.1177/1050651902016002003
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Stavropoulos V, 2013, COMPUT HUM BEHAV, V29, P1941, DOI 10.1016/j.chb.2013.03.011
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sukoco BM, 2011, EXPERT SYST APPL, V38, P7396, DOI 10.1016/j.eswa.2010.12.085
   Suntornpithug N, 2010, J ELECTRON COMMER RE, V11, P299
   TREVINO LK, 1992, COMMUN RES, V19, P539, DOI 10.1177/009365092019005001
   Villani D, 2012, INTERACT COMPUT, V24, P265, DOI 10.1016/j.intcom.2012.04.008
   von der Pütten AM, 2012, INTERACT COMPUT, V24, P317, DOI 10.1016/j.intcom.2012.03.004
   WEBSTER J, 1993, COMPUT HUM BEHAV, V9, P411, DOI 10.1016/0747-5632(93)90032-N
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Welch RB, 1999, PRESENCE-TELEOP VIRT, V8, P574, DOI 10.1162/105474699566387
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zaman M, 2010, COMPUT HUM BEHAV, V26, P1009, DOI 10.1016/j.chb.2010.03.001
   Zeff RobinLee., 1999, Advertising on the Internet
   Zeithaml VA, 1996, J MARKETING, V60, P31, DOI 10.2307/1251929
NR 111
TC 52
Z9 60
U1 6
U2 80
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2014
VL 18
IS 3
BP 173
EP 188
DI 10.1007/s10055-014-0244-2
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HR
UT WOS:000340621900002
DA 2024-07-18
ER

PT J
AU Spagnolli, A
   Bracken, CC
   Orso, V
AF Spagnolli, Anna
   Bracken, Cheryl Campanella
   Orso, Valeria
TI The role played by the concept of presence in validating the efficacy of
   a cybertherapy treatment: a literature review
SO VIRTUAL REALITY
LA English
DT Review
DE Presence; Cybertherapy; Validation
ID REALITY EXPOSURE THERAPY; VIRTUAL-REALITY; YOUNG-ADULTS; ENVIRONMENTS;
   ANXIETY; SENSE; IMMERSION; DISTRACTION; REACTIVITY; ACROPHOBIA
AB The present paper considers the existing research in cybertherapy, which is a psychological therapy carried out with the use of a mediated environment, and examines the way in which the users' sense of presence in the mediated environment can be of relevance for the validation of the intervention. With this purpose, a collection of 41 papers reporting the measurement of presence in the context of a cybertherapy treatment has been identified and examined. The general relevance of presence in cybertherapy and the measurement techniques adopted in the studies collected here are described and discussed. The way in which presence corresponds to establishing internal validity, convergent or predictive validity and external validity of a treatment is examined. In conclusion, a checklist to apply when planning a validation study is proposed, to improve the way in which presence is used.
C1 [Spagnolli, Anna; Orso, Valeria] Univ Padua, Dept Gen Psychol, I-35131 Padua, Italy.
   [Bracken, Cheryl Campanella] Cleveland State Univ, Sch Commun, Cleveland, OH 44115 USA.
C3 University of Padua; University System of Ohio; Cleveland State
   University
RP Spagnolli, A (corresponding author), Univ Padua, Dept Gen Psychol, Via Venezia 8, I-35131 Padua, Italy.
EM anna.spagnolli@unipd.it
RI Spagnolli, Anna/D-1868-2014; Orso, Valeria/KUD-5651-2024
CR Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   [Anonymous], ADV QUASIEXPERIMENTA
   [Anonymous], J CYBER THERAPY REHA
   [Anonymous], ANN M INT COMM ASS N
   [Anonymous], CYBER PSYCHOL BEHAV
   [Anonymous], 1992, PRESENCE-VIRTUAL AUG, DOI [10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   [Anonymous], ISPR 2011 INT SOC PR
   [Anonymous], 2008, J CYBERTHERAPY REHAB
   [Anonymous], 1991, BEING THERE TE UNPUB
   [Anonymous], 1979, RELIABILITY VALIDITY
   [Anonymous], MED BEC REAL C BERN
   [Anonymous], J CYBERTHERAPY REHAB
   [Anonymous], P 7 ANN INT WORKSH P
   [Anonymous], 2003, EU FUT EM TECHN PRES
   [Anonymous], P 11 ANN INT WORKSH
   [Anonymous], PSYCHIAT TIMES
   [Anonymous], J CYBERTHERAPY REHAB
   [Anonymous], 1998, Health Technology Assessment, DOI DOI 10.3310/HTA2160
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Basil M., 1994, MEASURING PSYCHOL RE, P85
   Belloni G, 2007, ANN REV CYBERTHERAPY, V5, P9
   Bordnick PS, 2008, ADDICT BEHAV, V33, P743, DOI 10.1016/j.addbeh.2007.12.010
   Botella C, 2009, PSYCHNOLOGY J, V7, P77
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bracken C.C., 2010, J MEDIA PSYCHOL-GER, V22, P125
   Bracken CC, 2005, MEDIA PSYCHOL, V7, P191, DOI 10.1207/S1532785XMEP0702_4
   Brewer MB, 2000, Handbook of Research Methods in Social and Personality Psychology, P3, DOI DOI 10.1017/CBO9780511996481.005
   Juan MC, 2011, INT J HUM-COMPUT ST, V69, P440, DOI 10.1016/j.ijhcs.2011.03.002
   Juan MC, 2009, PRESENCE-VIRTUAL AUG, V18, P232, DOI 10.1162/pres.18.3.232
   Chittaro Luca, 2012, Persuasive Technology. Design for Health and Safety. Proceedings 7th International Conference, PERSUASIVE 2012, P43, DOI 10.1007/978-3-642-31037-9_4
   Dusenbury L, 2003, HEALTH EDUC RES, V18, P237, DOI 10.1093/her/18.2.237
   Fogg B. J., 2003, PERSUASIVE TECHNOLOG, P89
   Fornells-Ambrojo M, 2008, SCHIZOPHR RES, V104, P228, DOI 10.1016/j.schres.2008.05.013
   Grassi A, 2009, CYBERPSYCHOL BEHAV, V12, P155, DOI 10.1089/cpb.2008.0156
   Gutiérrez-Maldonado J, 2006, CYBERPSYCHOL BEHAV, V9, P507, DOI 10.1089/cpb.2006.9.507
   Hesse-Biber S, 2012, QUAL INQ, V18, P876, DOI 10.1177/1077800412456964
   Juan MC, 2006, PRESENCE-VIRTUAL AUG, V15, P393, DOI 10.1162/pres.15.4.393
   Kim K, 2008, CYBERPSYCHOL BEHAV, V11, P637, DOI 10.1089/cpb.2008.0003
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Krijn M, 2007, CYBERPSYCHOL BEHAV, V10, P362, DOI 10.1089/cpb.2006.9943
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Laarni J., 2004, P 7 ANN INT WORKSHOP, P88
   Lallart E, 2009, CYBERPSYCHOL BEHAV, V12, P139, DOI 10.1089/cpb.2008.0070
   Lee J, 2004, CYBERPSYCHOL BEHAV, V7, P705, DOI 10.1089/cpb.2004.7.705
   Lepecq JC, 2009, VIRTUAL REAL-LONDON, V13, P141, DOI 10.1007/s10055-009-0118-1
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lombard M., 2009, 12 ANN INT WORKSH PR, P1
   Malbos E, 2008, CYBERPSYCHOL BEHAV, V11, P695, DOI 10.1089/cpb.2007.0246
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Mays N, 2000, BMJ-BRIT MED J, V320, P50, DOI 10.1136/bmj.320.7226.50
   Murray CD, 2007, COMPUT HUM BEHAV, V23, P1347, DOI 10.1016/j.chb.2004.12.010
   PAN X, 2007, PRESENCE 2007, P101
   Patterson DR, 2006, J ABNORM PSYCHOL, V115, P834, DOI 10.1037/0021-843X.115.4.834
   Pegden CD., 1995, INTRO SIMULATION USI
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   Rand D, 2005, PRESENCE-TELEOP VIRT, V14, P147, DOI 10.1162/1054746053967012
   Riva G, 2008, STUD HEALTH TECHNOL, V132, P417
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Schneider SM, 2007, ONCOL NURS FORUM, V34, P39, DOI 10.1188/07.ONF.39-46
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Scozzari S, 2011, STUD COMPUT INTELL, V337, P63
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Spagnolli A., 2002, Proceedings of the 5th Annual International Conference on Presence, P421
   Spagnolli A, 2005, PSYCHNOLOGY J, V3, P6
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Thorn BE, 2007, J CLIN PSYCHOL, V63, P607, DOI 10.1002/jclp.20384
   Tichon J, 2006, CYBERPSYCHOL BEHAV, V9, P480, DOI 10.1089/cpb.2006.9.480
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Van Baren J., 2004, OmniPres Project IST-2001-39237
   Viciana-Abad R., 2004, Annu. Rev. Cyberther Telemed, V2, P111
   Villani D., 2007, Int. J. Stress Manag. Copyr, V14, P260, DOI [DOI 10.1037/1072-5245.14.3.260, 10.1037/1072-5245.14.3.260https://dx.doi.org/10.1037/1072-5245.14.3.260, DOI 10.1037/1072-5245.14.3.260HTTPS://DX.DOI.ORG/10.1037/1072-5245.14.3.260]
   Wald J, 2003, CYBERPSYCHOL BEHAV, V6, P459, DOI 10.1089/109493103769710488
   Wallach HS, 2009, VIRTUAL REAL-LONDON, V13, P205, DOI 10.1007/s10055-009-0122-5
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Waterworth EL, 2001, CYBERPSYCHOL BEHAV, V4, P203, DOI 10.1089/109493101300117893
   Weibel D, 2010, CYBERPSYCH BEH SOC N, V13, P251, DOI 10.1089/cyber.2009.0171
   Weiss PL, 2003, CYBERPSYCHOL BEHAV, V6, P335, DOI 10.1089/109493103322011650
   Wiederhold BK, 2004, ST HEAL T, V99, P263
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yalon-Chamovitz S, 2008, RES DEV DISABIL, V29, P273, DOI 10.1016/j.ridd.2007.05.004
NR 91
TC 10
Z9 11
U1 2
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2014
VL 18
IS 1
SI SI
BP 13
EP 36
DI 10.1007/s10055-013-0241-x
PG 24
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AB2WI
UT WOS:000331652400003
DA 2024-07-18
ER

PT J
AU Kolic, I
   Mihajlovic, Z
AF Kolic, Ivica
   Mihajlovic, Zeljka
TI Camera space shadow maps for large virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Shadow maps; Real-time shadows; Dynamic shadows; Virtual environments
AB This paper presents a new single-pass shadow mapping technique that achieves better quality than the approaches based on perspective warping, such as perspective, light-space, and trapezoidal shadow maps. The proposed technique is appropriate for real-time rendering of large virtual environments that include dynamic objects. By performing operations in camera space, this solution successfully handles the general and the dueling frustum cases and produces high-quality shadows even for extremely large scenes. This paper also presents a fast nonlinear projection technique for shadow map stretching that enables complete utilization of the shadow map by eliminating wastage. The application of stretching results in a significant reduction in unwanted perspective aliasing, commonly found in all shadow mapping techniques. Technique is compared with other shadow mapping techniques, and the benefits of the proposed method are presented. The proposed shadow mapping technique is simple and flexible enough to handle most of the special scenarios. An API for a generic shadow mapping solution is presented. This API simplifies the generation of fast and high-quality shadows.
C1 [Mihajlovic, Zeljka] Univ Zagreb, Fac Elect Engn & Comp, Zagreb 10000, Croatia.
   [Kolic, Ivica] Systemcom Doo, Zagreb, Croatia.
C3 University of Zagreb
RP Mihajlovic, Z (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Unska 3, Zagreb 10000, Croatia.
EM ivica.kolic@systemcom.hr; zeljka.mihajlovic@fer.hr
RI Mihajlovic, Zeljka/KLZ-8450-2024
OI Mihajlovic, Zeljka/0000-0002-4866-1399
CR Chong H, 2004, P 15 EUR WORKSH REND
   Crow F.C., 1977, ACM SIGGRAPH COMPUT, V11, P242, DOI [DOI 10.1145/965141.563901, DOI 10.1145/563858.563901]
   Dimitrov R., 2007, Cascaded shadow maps
   King G, 2004, TECHNICAL REPORT
   Kolic I, 2010, CAMERA SPACE SHADOW
   Kozlov Simon., 2004, GPU GEMS, P217
   Lauritzen A., 2011, Symposium on Interactive 3D graphics and games (I3D' 11), P97
   Lefohn AE, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289611
   Martin T, 2008, TRAPEZOIDAL SHADOW M
   MARTIN T, 2004, P EUR S REND
   Mo Q, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P189, DOI 10.1109/PG.2007.23
   Nealen AV, 2002, SHADOW MAPPING SHADO
   Stamminger M, 2002, ACM T GRAPHIC, V21, P557, DOI 10.1145/566570.566616
   WILLIAMS L, 1978, P SIGGRAPH, V12, P270
   WIMMER M, 2004, P EUR S REND
   Zhang F., 2006, Proceedings of the 2006 ACM international conference on virtual reality continuum and its applications, ACM Press, P311, DOI 10.1145/1128923.1128975
NR 16
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2012
VL 16
IS 4
BP 289
EP 299
DI 10.1007/s10055-012-0207-4
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 025YG
UT WOS:000310233000003
DA 2024-07-18
ER

PT J
AU Okamoto, S
   Konyo, M
   Tadokoro, S
AF Okamoto, Shogo
   Konyo, Masashi
   Tadokoro, Satoshi
TI Discriminability-based evaluation of transmission capability of tactile
   transmission systems
SO VIRTUAL REALITY
LA English
DT Article
DE Assessment of man-machine system; Discriminability index; Performance
   measurement; Tactile display; Tactile sensor
ID SENSOR; FREQUENCY; DISPLAY; ARRAY
AB Tactile transmission systems deliver tactile information such as texture roughness to operators of robotic systems. Such systems are typically composed of tactile sensors that sense the physical characteristics of textures and tactile displays that present tactile stimuli to operators. One problem associated with tactile transmission systems is that when the system has a bottleneck, it is difficult to identify whether the tactile sensor, tactile display, or perceptual ability of the user is the cause because they have different performance criteria. To solve this problem, this study established an evaluation method that uses the discriminability index as an evaluation criterion. The method lets tactile sensors, displays, and human tactile perception be assessed in terms of the ability to transmit physical quantities; the same criterion is used for all three possible causes so that their abilities can be directly compared. The developed method was applied to a tactile-roughness transmission system (Okamoto et al. 2009), and its tactile sensor was identified as the bottleneck of the system.
C1 [Okamoto, Shogo] Nagoya Univ, Grad Sch Engn, Chikusa Ku, Nagoya, Aichi 4648601, Japan.
   [Konyo, Masashi; Tadokoro, Satoshi] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 980, Japan.
C3 Nagoya University; Tohoku University
RP Okamoto, S (corresponding author), Nagoya Univ, Grad Sch Engn, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM okamoto-shogo@mech.nagoya-u.ac.jp
RI Konyo, Masashi/T-2730-2019
OI Konyo, Masashi/0000-0002-6826-9722
FU MIC SCOPE [082102006]; MEXT Kakenhi [19360120, 07J01804]; Grants-in-Aid
   for Scientific Research [19360120, 07J01804] Funding Source: KAKEN
FX This work was supported by grants from MIC SCOPE (082102006) and MEXT
   Kakenhi (19360120) and (07J01804).
CR [Anonymous], 2009, BT50012 ITUR
   Dev P, 2002, AMIA 2002 SYMPOSIUM, PROCEEDINGS, P205
   Fan RE, 2008, IEEE T NEUR SYS REH, V16, P270, DOI 10.1109/TNSRE.2008.920075
   Goethals P, 2008, LECT NOTES COMPUT SC, V5024, P447, DOI 10.1007/978-3-540-69057-3_58
   GOFF GD, 1967, J EXP PSYCHOL, V74, P294, DOI 10.1037/h0024561
   Green D., 1966, SIGNAL DETECTION THE
   GULLIKSEN H, 1956, PSYCHOMETRIKA, V21, P125, DOI 10.1007/BF02289093
   HIKICHI K, 2006, P 5 WORKSH NETW SYST
   HOWE RD, 1995, IEEE ENG MED BIOL, V14, P318, DOI 10.1109/51.391770
   International Telecommunication Union, 2004, BS5623 ITUR
   Jones L. A., 2006, HUMAN HAND FUNCTION
   Killebrew JH, 2007, J NEUROSCI METH, V161, P62, DOI 10.1016/j.jneumeth.2006.10.012
   KONTARINIS DA, 1995, PRESENCE-TELEOP VIRT, V4, P387, DOI 10.1162/pres.1995.4.4.387
   Macmillan N. A., 2005, Detection theory: A user's guide, V2nd
   Motoo K, 2007, IEEE SENS J, V7, P1044, DOI 10.1109/JSEN.2007.895973
   Mukaibo Y, 2005, IEEE INT CONF ROBOT, P2565
   Okamoto S, 2009, IEEE INT CONF ROBOT, P1486
   Ottermo M. V., 2006, THESIS NORWEGIAN U S
   Pawluk DTV, 1998, J BIOMECH ENG-T ASME, V120, P302, DOI 10.1115/1.2798317
   Peine W. J., 1997, Proceedings of the ASME Dynamic Systems and Control Division, P107
   ROTHENBERG M, 1977, J ACOUST SOC AM, V62, P1003, DOI 10.1121/1.381610
   Shirado H, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P629
   Summers IR, 2002, J ACOUST SOC AM, V112, P2118, DOI 10.1121/1.1510140
   Thurstone LL, 1927, AM J PSYCHOL, V38, P368, DOI 10.2307/1415006
   VERRILLO RT, 1969, PERCEPT PSYCHOPHYS, V6, P366, DOI 10.3758/BF03212793
   Warwick K, 2003, ARCH NEUROL-CHICAGO, V60, P1369, DOI 10.1001/archneur.60.10.1369
   Yamamoto A, 2006, IEEE T VIS COMPUT GR, V12, P168, DOI 10.1109/TVCG.2006.28
   Yamauchi T, 2010, P 2010 IEEE INT C RO
   Yao Hsin-Yun, 2005, Comput Aided Surg, V10, P233
   Yoshioka T, 2007, SOMATOSENS MOT RES, V24, P53, DOI 10.1080/08990220701318163
NR 30
TC 2
Z9 2
U1 1
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2012
VL 16
IS 2
BP 141
EP 150
DI 10.1007/s10055-011-0192-z
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 949EO
UT WOS:000304559300004
DA 2024-07-18
ER

PT J
AU Seth, A
   Vance, JM
   Oliver, JH
AF Seth, Abhishek
   Vance, Judy M.
   Oliver, James H.
TI Virtual reality for assembly methods prototyping: a review
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual assembly; Collision detection; Physics-based modeling;
   Constraint-based modeling; Virtual reality; Haptics; Human-computer
   interaction
ID COLLISION DETECTION; DESIGN; GENERATION
AB Assembly planning and evaluation is an important component of the product design process in which details about how parts of a new product will be put together are formalized. A well designed assembly process should take into account various factors such as optimum assembly time and sequence, tooling and fixture requirements, ergonomics, operator safety, and accessibility, among others. Existing computer-based tools to support virtual assembly either concentrate solely on representation of the geometry of parts and fixtures and evaluation of clearances and tolerances or use simulated human mannequins to approximate human interaction in the assembly process. Virtual reality technology has the potential to support integration of natural human motions into the computer aided assembly planning environment (Ritchie et al. in Proc I MECH E Part B J Eng 213(5):461-474, 1999). This would allow evaluations of an assembler's ability to manipulate and assemble parts and result in reduced time and cost for product design. This paper provides a review of the research in virtual assembly and categorizes the different approaches. Finally, critical requirements and directions for future research are presented.
C1 [Seth, Abhishek] Caterpillar Inc, Appl Res, Prod Dev Ctr Excellence, Peoria, IL 61629 USA.
   [Vance, Judy M.; Oliver, James H.] Iowa State Univ, Dept Mech Engn, Virtual Real Applicat Ctr, Ames, IA 50011 USA.
C3 Caterpillar Inc; Iowa State University
RP Seth, A (corresponding author), Caterpillar Inc, Appl Res, Prod Dev Ctr Excellence, Peoria, IL 61629 USA.
EM abhishekseth@gmail.com; jmvance@iastate.edu; oliver@iastate.edu
RI Oliver, James/A-4590-2014
OI Oliver, James/0000-0003-2815-4928; Vance, Judy/0000-0001-9801-191X
CR [Anonymous], 1994, P ASME WINT ANN M S
   [Anonymous], 1998, P IMA C MATH SURF
   [Anonymous], 2008, PRODUCT ENG, DOI DOI 10.1007/978-1-4020-8200-9_27
   [Anonymous], 1989, PRODUCT DESIGN ASSEM
   [Anonymous], P ACM SIGGRAPH EUROG
   [Anonymous], 2001, J COMPUT INF SCI ENG
   [Anonymous], 1996, ASME DES ENG TECHN C
   BALDWIN DF, 1991, IEEE T ROBOTIC AUTOM, V7, P78, DOI 10.1109/70.68072
   BARAFF D, 1995, IEEE COMPUT GRAPH, V15, P63, DOI 10.1109/38.376615
   Baraff D., 1990, Computer Graphics, V24, P19, DOI 10.1145/97880.97881
   Baraff D., 1989, Computer Graphics, V23, P223, DOI 10.1145/74334.74356
   Baraff D., 1997, Physically Based Modeling: Principles and Practice (Online SIGGRAPH '97 Course notes)
   Boothroyd G., 1994, PRODUCT DESIGN MANUF
   BORRO D, 2005, P 9 INT C INF VIS IV
   BOUMA W, 1995, COMPUT AIDED DESIGN, V27, P487, DOI 10.1016/0010-4485(94)00013-4
   BOUZIT M, 2002, HAPTICS 2002 HAPTIC
   Brough John E., 2007, Virtual Reality, V11, P189, DOI 10.1007/s10055-007-0076-4
   Bryson S, 1996, COMMUN ACM, V39, P62, DOI 10.1145/229459.229467
   Bullinger HJ, 2000, HUM FACTORS ERGONOM, V10, P331, DOI 10.1002/1520-6564(200022)10:3<331::AID-HFM7>3.0.CO;2-D
   Burdea GC, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P295, DOI 10.1109/CGI.2000.852345
   Burdea GC, 1999, IEEE T ROBOTIC AUTOM, V15, P400, DOI 10.1109/70.768174
   BUTTOLO P, 1995, IEEE VIRT REAL ANN I
   Chen X., 2005, 2 INT C EMB SOFTW SY
   Chryssolouris G, 2000, ROBOT CIM-INT MANUF, V16, P267, DOI 10.1016/S0736-5845(00)00013-2
   Cohen J. D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P189, DOI 10.1145/199404.199437
   COUTEE AS, 2002, DETC2002CIE34385
   Coutee AS, 2004, ASME DES ENG TECHN C
   COUTEE AS, 2001, ASME J COMPUTING INF, V1, P113
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Czernuszenko M., 1997, Computer Graphics, V31, P46, DOI 10.1145/271283.271303
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   DEFAZIO TL, 1987, IEEE T ROBOTIC AUTOM, V3, P640, DOI 10.1109/JRA.1987.1087132
   DEMELLO LSH, 1989, IEEE INT C ROB AUT S
   DEWAR RG, 1997, P PORTL INT C MAN EN
   EDDY J, 2002, DETC2002DAC34130
   Ehmann S., 2000, Swift: Accelerated proximity queries between convex polyhedra by multilevel voronoi marching
   EHMANN SA, 2001, EUROGRAPH COMPUT GRA, V20
   ERLEBEN K, 2005, PHYS BASED ANIMATION, P817
   FA M, 1993, COMP GRAPH FOR C ISS, V12, P237
   FERNANDO T, 1999, P ACM S VIRT REAL SO
   FROHLICH B, 2000, IEEE VIRT REAL C
   Fudos I, 1997, ACM T GRAPHIC, V16, P179, DOI 10.1145/248210.248223
   Fudos I, 1996, INT J COMPUT GEOM AP, V6, P405, DOI 10.1142/S0218195996000253
   FUDOS I, 1995, COMPUTER SCI, P107
   Garbaya Samir, 2007, Virtual Reality, V11, P287, DOI 10.1007/s10055-007-0075-5
   GARCIAALONSO A, 1994, IEEE COMPUT GRAPH, V14, P36, DOI 10.1109/38.279041
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   GOTTSCHALK S, 1996, 23 ANN C COMP GRAPH
   Guendelman E, 2003, ACM T GRAPHIC, V22, P871, DOI 10.1145/882262.882358
   Gupta R, 1997, COMPUT AIDED DESIGN, V29, P585, DOI 10.1016/S0010-4485(96)00093-0
   GUPTA R, 1995, P ASME COMP ENG C EN
   GUROCAK H, 2002, ASME DES ENG TECHN C
   GUY A, 1995, IMPLICIT SURFACES
   Hahn J. K., 1988, Computer Graphics, V22, P299, DOI 10.1145/378456.378530
   Holt PO, 2004, J COMPUT INF SCI ENG, V4, P161, DOI 10.1115/1.1759696
   Hudson T.C., 1997, Proceedings of the 2nd Symposium of Virtual Reality Modeling Language, V1997, P119
   Jayaram S, 1997, COMPUT AIDED DESIGN, V29, P575, DOI 10.1016/S0010-4485(96)00094-2
   Jayaram Sankar, 2007, Virtual Reality, V11, P217, DOI 10.1007/s10055-007-0070-x
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   JAYARAM S, 2006, ASME DES ENG TECHN C
   JAYARAM S, 2000, ASME DES ENG TECHN C
   Jayaram U, 2006, COMPUT IND, V57, P283, DOI 10.1016/j.compind.2005.12.005
   JAYARAM U, 2000, ASME DES ENG TECHN C
   Jiménez P, 2001, COMPUT GRAPH-UK, V25, P269, DOI 10.1016/S0097-8493(00)00130-8
   JIN X, 2000, COMPUT GRAPH, V24
   JUNG B, 1998, P 24 ANN C IEEE IND
   JUST C, 1998, 2 IMM PROJ TECHN WOR
   KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942
   Kim C., 2003, ASME DES ENG TECHN C
   Kim C. E., 2004, ASME DES ENG TECHN C
   Kim CE, 2004, J COMPUT INF SCI ENG, V4, P83, DOI 10.1115/1.1738125
   KRUGER W, 1994, COMPUT GRAPH APPL, V14, P12
   KUEHNE R, 1995, P ASME DES AUT C BOS
   LIGHT R, 1982, COMPUT AIDED DESIGN, V14, P209, DOI 10.1016/0010-4485(82)90292-5
   Lim T., 2007, Virtual Reality, V11, P241, DOI 10.1007/s10055-007-0072-8
   LIM T, 2007, P 2007 IEEE INT S AS
   LIU Z, 2005, 9 INT C COMP SUPP CO
   Liu ZY, 2007, INT J ADV MANUF TECH, V32, P797, DOI 10.1007/s00170-005-0382-5
   Marcelino L, 2003, COMPUT GRAPH-UK, V27, P19, DOI 10.1016/S0097-8493(02)00228-5
   MCNEELY WA, 1999, SIGGRAPH 99 C P ANN
   MILLMAN PA, 1993, IEEE VIRT REAL ANN I
   Mirtich B, 1998, ACM T GRAPHIC, V17, P177, DOI 10.1145/285857.285860
   MIRTICH B, 1995, S INT 3D GRAPH
   MIRTICH BV, 1996, COMPUTER SCI, P246
   OWEN JC, 1991, ACM S FDN SOL MOD AC
   REGNBRECHT H, 2005, P 3 INT C COMP GRAPH
   Ritchie JM, 1999, P I MECH ENG B-J ENG, V213, P461, DOI 10.1243/0954405991516930
   RITCHIE JM, 1995, P 12 C IR MAN COMM
   SCHWARTZ M, 2007, PERF METR INT SYST W
   SETH A, 2005, ASME INT MECH ENG C
   SETH A, 2007, ASME DES ENG TECHN C
   Seth A, 2006, ASME DES ENG TECHN C
   SHAIKH I, 2004, 2004 WINT SIM C WASH
   Singh P, 2004, J COMPUT INF SCI ENG, V4, P197, DOI 10.1115/1.1779659
   Smith SSF, 2001, J MANUF SYST, V20, P225, DOI 10.1016/S0278-6125(01)80043-1
   SUNDE G, 1988, GEOMETRIC MODELING C
   Sung R. C. W., 2001, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V1, P291, DOI 10.1115/1.1429931
   SUZUKI H, 1990, COMPUT GRAPH, V14, P211, DOI 10.1016/0097-8493(90)90033-T
   TAYLOR F, 2000, ASME DES ENG TECHN C
   VERROUST A, 1992, COMPUT AIDED DESIGN, V24, P531, DOI 10.1016/0010-4485(92)90040-H
   WAN H, 2004, 2004 ACM SIGGRAPH IN, P81
   Wan H., 2004, ASME DES ENG TECHN C
   Wang QH, 2006, INT J PROD RES, V44, P467, DOI 10.1080/00207540500319294
   Wang Y., 2001, ASME DES ENG TECHN C
   Wang Yong., 2003, Virtual Reality, V6, P229, DOI DOI 10.1007/S10055-003-0106-9
   Witkin A., 1990, Computer Graphics, V24, P11, DOI 10.1145/91394.91400
   XIANGLONG Y, 2001, WINT SIM C P ARL VIR
   Yang RD, 2007, FRONT MECH ENG-PRC, V2, P243, DOI 10.1007/s11465-007-0043-5
   Ye N, 1999, IEEE T SYST MAN CY C, V29, P546, DOI 10.1109/5326.798768
   ZACHMANN G, 2001, 8 ISPE INT C CONC EN
   Zha XF, 1998, INT J ADV MANUF TECH, V14, P664, DOI 10.1007/BF01192287
   ZHANG Y, 2005, P 221 SPRING C COMP
   ZHU Z, 2004, ASME DES ENG TECHN C
   Zorriassatine F, 2003, P I MECH ENG B-J ENG, V217, P513, DOI 10.1243/095440503321628189
NR 115
TC 216
Z9 235
U1 2
U2 162
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2011
VL 15
IS 1
SI SI
BP 5
EP 20
DI 10.1007/s10055-009-0153-y
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HZ
UT WOS:000296280000002
DA 2024-07-18
ER

PT B
AU Parti, K
AF Parti, Katalin
BE Kim, JJ
TI Actual Policing in Virtual Reality - A Cause of Moral Panic or a
   Justified Need?
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID INTERNET; PORNOGRAPHY
C1 [Parti, Katalin] Natl Inst Criminol, Budapest, Hungary.
RP Parti, K (corresponding author), Natl Inst Criminol, Budapest, Hungary.
OI Parti, Katalin/0000-0002-8484-3237
CR ABCNews. com, 2000, ABCNEWS         0728
   [Anonymous], CULTURE OF FEAR
   [Anonymous], 2010, HDB INTERNET CRIMES
   [Anonymous], NEW WORLD NOTES 0308
   [Anonymous], 2003, DEV ONLINE GAMES INS
   [Anonymous], HDB INTERNET CRIME
   [Anonymous], 1999, GREAT GOOD PLACE
   [Anonymous], 2007, KINDERPORNOGRAPHIE 1
   [Anonymous], 2006, Virtually criminal: Crime, deviance and regulation online
   [Anonymous], 2018, Words that wound: Critical race theory, assaultive speech, and the first amendment
   [Anonymous], 2008, ICMEC ANN REPORTS CH
   [Anonymous], CRIME INTERNET
   [Anonymous], HDB INTERNET CRIME
   [Anonymous], J COMPUTER MEDIATED
   [Anonymous], 1995, LIFE SCREEN IDENTITY
   [Anonymous], 1999, Communities in Cyberspace
   [Anonymous], 1975, DO THINGS WORDS
   [Anonymous], P OTH PLAYERS C COP
   [Anonymous], INFORM WEEK 0416
   Becker P.J., 2000, International Review of Law, Computers Technology, V14, P33, DOI [10.1080/13600860054872, DOI 10.1080/13600860054872]
   Bell Daniel, 1999, COMING POSTINDUSTRIA
   Bocij P., 2004, CYBERSTALING HARASSM
   Boellstorff T, 2008, COMING OF AGE IN SECOND LIFE: AN ANTHROPOLOGIST EXPLORES THE VIRTUALLY HUMAN, P1
   Boyle J, 1997, U CINCI LAW REV, V66, P177
   Braithwaite J., 1989, Crime
   Butler J., 1997, PSYCHIC LIFE POWER T
   Casey Eoghan., 2004, DIGITAL EVIDENCE COM, V2nd
   Castells M., 2002, The Internet Galaxy: Reflections on the Internet, Business, and Society
   CEOP Center film, 2009, VICT ID
   Chun Wendy Hui Kyong, 2006, Control and Freedom: Power and Paranoia in the Age of Fiber Optics
   Clark N., 2009, Game addiction: The experience and the effects
   Curtis Pavel., 1992, Culture of the Internet, P121
   Delgado R., 1993, WORDS WOUND CRITICAL, P131
   Dibbel J., 1998, A RAPE IN CYBERSPACE
   Ellsberg Daniel., 2001, Risk, ambiguity and decision
   HARMON D, 1997, ELECT J SOCIOLOGY
   Hirschi T., 2017, Causes of delinquency
   Hosein I., 2003, INT REV LAW COMPUTER, V17, P85
   Innes M., 2004, Criminal Justice, V4, P151, DOI DOI 10.1177/1466802504044914
   Jenkins Philip., 1998, Moral Panic: Changing Concepts of the Child Molester in Modern America
   Joinson A.N., 2003, Understanding the psychology of Internet behaviour
   Kiesler S, 2000, HUM-COMPUT INTERACT, V15, P323, DOI 10.1207/S15327051HCI1504_2
   Korinek L., 2006, BUNOZESI ELMELETEK
   Krone T., 2004, A typology of online child pornography offending
   Krone T., 2005, DOES THINKING MAKE I
   LESSIG L, 1999, CODE OTHER LAWS CYBE
   MacKinnon Catharine., 1997, HARMS WAY PORNOGRAPH
   Mann D., 2003, INTERNET J CRIMINOLO
   Markham A., 1998, Life Online: Researching Real Experiences in Virtual Space
   Mehta M.D., 1997, CULTURE INTERNET, P53
   Meloy J.R., 1998, PSYCHOL STALKING, P1, DOI [10.1016/B978-012490560-3/50020-7, DOI 10.1016/B978-012490560-3/50020-7]
   Michelet I., 2003, OUR CHILDREN RISK ON, P7
   Mitchell KJ, 2003, YOUTH SOC, V34, P330, DOI 10.1177/0044118X02250123
   Moitra S.D., 2003, ANAL MODELLING CYBER
   Murff K. N., 2007, DIGITAL CRIME INVEST
   NeoWin, 2009, IRS TAX 2 LIF WORLD
   Ondrejka C.R., 2004, ESCAPING GUILDED CAG
   Parti K., 2010, CURRENT ISSUES IT SE, P91
   Parti K., 2009, GYERMEKPORNOGRAFIA A
   Quayle E, 2002, BRIT J SOC WORK, V32, P863, DOI 10.1093/bjsw/32.7.863
   Reno J., 1999, CYBERSTALKING NEW CH
   Reynolds R., 2005, 4 WORLDS THEORY
   RIMM M, 1995, GEORGETOWN LAW J, V83, P1849
   SCHECHNER R, 1988, PLAY CULTURE, V1, P3
   Second Life Insider, 2007, 2 LIFE INSIDER  0511
   Sieber U., 2009, JURISTENZEITUNG, V64, P653
   Sieber U., 2008, SPERRVERFUGUNGEN INT
   Simon Jonathan., 2007, GOVERNING CRIME
   Sullivan J., 2007, PROC CHILD EXPL ONL
   Suter-Zurcher S., 2003, STRAFBARKEIT SEXUELL
   Taipale Kim, 2006, CYBERCRIME DIGITAL C
   Talin, 2003, DEV ONLINE GAMES INS, P347
   Tous J., 2009, E NEWSLETTER FIGHT C, V1, P14
   Turow J., 2000, INTERNET FAMILY 2000
   Wall D.S., 2008, INT REV LAW COMPUTER, V22, P45
   Wall S.D., 2007, CYBERCRIME TRANSFORM
   Wall S.David., 2010, Handbook of Internet Crime, P88
   Williams M., 2010, HDB INTERNET CRIME, P562
   Williams M., 2004, INTERNET J CRIMINOLO
   Yar M., 2010, HDB INTERNET CRIME, P546
   Zavrsnik A., 2010, CURRENT ISSUES IT SE, P117
   Zavrsnik A., 2007, P 7 ANN C EUR SOC CR
NR 82
TC 0
Z9 0
U1 0
U2 4
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 647
EP 672
D2 10.5772/553
PG 26
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400033
DA 2024-07-18
ER

PT J
AU Happa, J
   Mudge, M
   Debattista, K
   Artusi, A
   Gonçalves, A
   Chalmers, A
AF Happa, Jassim
   Mudge, Mark
   Debattista, Kurt
   Artusi, Alessandro
   Goncalves, Alexandrino
   Chalmers, Alan
TI Illuminating the past: state of the art
SO VIRTUAL REALITY
LA English
DT Article
DE Cultural heritage; Computer graphics; Image-processing; Rendering;
   Global illumination; Reflectance transformation imaging; High dynamic
   range imaging; Sky modelling; Flame modelling; Colour science; Visual
   perception
ID MODEL
AB Virtual reconstruction and representation of historical environments and objects have been of research interest for nearly two decades. Physically based and historically accurate illumination allows archaeologists and historians to authentically visualise a past environment to deduce new knowledge. This report reviews the current state of illuminating cultural heritage sites and objects using computer graphics for scientific, preservation and research purposes. We present the most noteworthy and up-to-date examples of reconstructions employing appropriate illumination models in object and image space, and in the visual perception domain. Finally, we also discuss the difficulties in rendering, documentation, validation and identify probable research challenges for the future. The report is aimed for researchers new to cultural heritage reconstruction who wish to learn about methods to illuminate the past.
C1 [Happa, Jassim; Debattista, Kurt; Chalmers, Alan] Univ Warwick, Int Digital Lab, Coventry CV4 7AL, W Midlands, England.
   [Mudge, Mark] Cultural Heritage Imaging, San Francisco, CA USA.
   [Artusi, Alessandro] CASToRC Cyprus Inst, Nicosia, Cyprus.
   [Goncalves, Alexandrino] Polytech Inst Leiria, Res Ctr Informat & Commun, Leiria, Portugal.
C3 University of Warwick
RP Happa, J (corresponding author), Univ Warwick, Int Digital Lab, Coventry CV4 7AL, W Midlands, England.
EM j.happa@warwick.ac.uk; mark@c-h-i.org; debattista@warwick.ac.uk;
   artusialessandro4@googlemail.com; alex@estg.ipleiria.pt;
   a.g.chalmers@warwick.ac.uk
RI Artusi, Alessandro/H-4102-2019
OI Artusi, Alessandro/0000-0002-4502-663X; Jose Marques Goncalves,
   Alexandrino/0000-0002-5966-3218
FU EPSRC [EP/E024998/2, EP/E024998/1] Funding Source: UKRI
CR Aliaga D.G., 2008, P ACM SIGGRAPH AS 20, DOI [10.1145/1457515.1409113, DOI 10.1145/1457515.1409113, DOI 10.1145/1409060.1409113]
   [Anonymous], 2018, Real-Time Rendering
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 1999, IEEE C COMP VIS PATT
   [Anonymous], 1978, Recovering intrinsic scene characteristics.
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], SHADOW IDENTIFICATIO
   [Anonymous], EUROGRAPHICS TUTORIA
   APPEL A, 1968, P SPRING JOINT COMP
   Arnold D., 2007, RES AGENDA APPL ICT
   ARTUSI A, 2007, SURVEY SPECULARITY R
   *AUT, 2009, 3DS MAX WEBS
   *AUT, 2009, MAYA WEBS
   BABA M, 2003, SIGGRAPH 03 ACM SIGG
   BABA M, 2004, SIGGRAPH 04 ACM SIGG
   BARBOSA J, 2007, VAST 07
   BEAUDOIN P, 2001, GRIN 01 NO DESCRIPTI
   BERALDIN JA, 2002, P ISPRS CIPA INT WOR
   BLINN JF, 1976, COMMUN ACM
   Blythe D, 2006, ACM T GRAPHIC, V25, P724, DOI 10.1145/1141911.1141947
   BRIDAULT F, 2007, P 3 EUR WORKSH NAT P
   BRIDAULTLOUCHEZ F, 2006, AFRIGRAPH 06
   Callieri M, 2006, COMPUT GRAPH-UK, V30, P368, DOI 10.1016/j.cag.2006.02.015
   CHALMERS A, 2002, SIGGRAPH COURSE
   CHALMERS A, 2000, SIGGRAPH ELECT THEAT
   CHALMERS A, 2006, CGIV 2006
   CHALMERS A, 2002, P 18 SPRING C COMP G
   Chandrasekhar S., 1950, RAD TRANSFER
   CLINE D, 2005, SIGGRAPH 05
   Cohen Michael F., 1993, Radiosity and realistic image synthesis
   COOK RL, 1982, ACM T GRAPH
   COOK RL, 1984, SIGGRAPH 84
   Corsini M, 2008, COMPUT GRAPH FORUM, V27, P291, DOI 10.1111/j.1467-8659.2008.01126.x
   CUCCHIARA R, 2001, P INT TRANSP SYST
   DACHSBACHER C, 2007, SIGGRAPH 07
   DAUBERT K, 1997, P EUR WORKSH REND
   Debattista K, 2009, COMPUT GRAPH FORUM, V28, P2216, DOI 10.1111/j.1467-8659.2009.01435.x
   Debevec P, 2002, IEEE COMPUT GRAPH, V22, P26, DOI 10.1109/38.988744
   DEBEVEC P, 1998, SIGGRAPH 98
   DEBEVEC P, 2001, LIGHT PROBE IMAGE GA
   DEBEVEC P, 2000, SIGGRAPH 00
   DEBEVEC P, 2004, ICTTR062004 USC
   DEBEVEC P, 2006, HIGH RESOLUTION LIGH
   DEBEVEC P, 2003, 3DIM 4 INT C 3 D DIG
   DEBEVEC P, 2005, VAST 05 INT S VIRT R
   DEBEVEC P, 1997, SIGGRAPH 97
   DELLEPIANE M, 2006, VAST 06
   Devlin K., 2002, UNESCO WORLD HER DIG
   Devlin K., 2002, Eurographics
   DEVLIN K, 2001, AFRIGRAPH 01
   DICARLO JC, 2000, SPIE C
   DORSEY J, 2008, DIGITAL MODELING APP
   Dubla P, 2009, COMPUT GRAPH FORUM, V28, P2117, DOI 10.1111/j.1467-8659.2009.01419.x
   EARL CPG, 2009, VAST 09
   EARL GP, 2005, VAST 05
   EARL GP, 2008, P EARSEL SIG REM SEN
   EARL GP, 2009, PLEN SESS FUND TER A
   EARL GP, 2009, P EVA LOND C
   EGAN F, 1999, FINE BRONZE OIL LAMP
   EINARSSON P, 2004, SIGGRAPH 04 ACM SIG
   FONI A, 2002, UNESCO WORLD HER C
   FORBES JR, 1966, STUDIES ANCIENT TECH
   Forte Maurizio., 1997, VIRTUAL ARCHAEOLOGY
   Freeth T, 2006, NATURE, V444, P587, DOI 10.1038/nature05357
   FRISCHER B, 2008, SIGGRAPH 08 ACM SIGG
   GARDNER A, 2003, SIGGRAPH 03 P 30 ANN
   GAUTRON P, 2007, IEEE T VIS COMPUT GR
   GAUTRON P, 2004, RENDERING TECHNIQUES
   Glassner A.S., 1994, PRINCIPLES DIGITAL I
   GLENCROSS M, 2008, SIGGRAPH 08
   GONCALVES A, 2007, P INT ASS SCI KNOWL
   GONCALVES A, 2008, VAST 08
   GONCALVES A, 2009, ACM J COMPUT CULT HE
   GOODRICK G, 2000, CONSTRUCTS SIMULATIO
   Goral C., 1984, SIGGRAPH '84
   GUTIERREZ D, 2006, J CULT HERIT
   GUTIERREZ D, 2004, J CULT HERIT
   GUTIERREZ D, 2008, J COMPUT CULT HERIT
   HACHISUKA T, 2008, SIGGRAPH ASIA 08 ACM
   HAPPA J, 2009, VAST 09
   HAPPA J, 2009, AFRIGRAPH 09
   HASINOFF SW, 2003, ICCV 03
   HAWKINS T, 2001, VAST 01
   HAWKINS T, 2005, SIGGRAPH 05
   *HDRSHOP, 2001, EX SOFTW RES HDRI
   *HEWL PACK, 2009, POL TEXT MAPP INT RE
   Hood D., 1986, HDB PERCEPTION HUMAN
   IGAWA N, 2004, MODELS SKY RADIANCE
   IHRKE I, 2004, SCA 04
   INAKAGE M, 1990, CG INT 90
   IWASAKI K, 2007, EUR S REND
   Jarosz W, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330518
   Jensen HW., 2001, REALISTIC IMAGE SYNT, DOI [10.1201/9780429294907, DOI 10.1201/9780429294907]
   JENSEN HW, 1998, SIGGRAPH 98
   JENSEN HW, 2001, SIGGRAPH 01
   Kajiya J.T., 1986, SIGGRAPH 86
   KANG SB, 2003, ACM T GRAPH
   KELLER A, 1997, SIGGRAPH 97
   KENG SL, 2006, VIS COMPUT INT J COM
   KIDER JT, 2009, VAST 09
   KIM D, 2002, IAPR WORKSH MACH VIS
   Kimpe K, 2001, J CHROMATOGR A, V937, P87, DOI 10.1016/S0021-9673(01)01304-8
   KLINKER GJ, 1990, INT J COMPUT VIS
   KLINKER GJ, 1987, P 1 INT C COMP VIS I
   KOLLER D, 2004, SIGGRAPH 04
   Krivánek J, 2005, IEEE T VIS COMPUT GR, V11, P550, DOI 10.1109/TVCG.2005.83
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   LAFORTUNE E, 1997, SIGGRAPH 97
   LAI YC, 2007, PHOTOREALISTIC IMAGE
   LAMORLETTE A, 2002, SIGGRAPH 02
   LEDDA P, 2004, AFRIGRAPH 04
   LIN S, 2006, IEEE C COMP VIS PATT
   LIN S, 2002, EUR C COMP VIS
   MALLICK SP, 2006, P EUR C COMP VIS
   MALZBENDER T, 2006, T MALZBENDER PUBLICA
   MALZBENDER T, 2001, SIGGRAPH 01
   MALZBENDER T, 2005, HPL200568
   MANN S, 1995, P IS T 46 ANN C
   MARTINEZ P, 2001, VAST 01
   MELEK Z, 2002, 200271 TEX AM U DEP
   *MENT IM, 2009, MENT RAY CO WEBS
   MUDGE M, 2004, SIGGRAPH 04 C PRES C
   MUDGE M, 2005, VAST 05
   MUDGE M, 2006, VAST 06 P S VIRT REA
   NAYAR S, 2003, IEEE INT C COMP VIS
   NAYAR SK, 1997, INT J COMPUT VIS
   NGUYEN DQ, 2002, SIGGRAPH 02 P 29 ANN
   *PAN, 2002, PAN MK 3
   Pan M, 2007, COMPUT GRAPH FORUM, V26, P485, DOI 10.1111/j.1467-8659.2007.01071.x
   PEGORARO V, 2006, P 2 EUR WORKSH NAT P
   PEREZ R, 1993, SOLAR ENERGY
   PERRY CH, 1994, P 5 EUR WORKSH AN SI
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   PREETHAM A, 1999, SIGGRAPH 99
   RACZKOWSKI J, 1996, INT C IM PROC COMP G
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   REILLY P, 1991, COMPUT APPL QUANT ME
   RITSCHEL T, 2009, EUROGRAPHICS
   RITSCHEL T, 2008, SIGGRAPH ASIA 08 ACM
   ROBERTS J, 1997, P 4 UK VIRT REAL SPE
   Robertson MA, 2003, J ELECTRON IMAGING, V12, P219, DOI 10.1117/1.1557695
   ROBERTSON MA, 1999, P 1999 INT C IM PROC
   ROUSSOS I, 2003, VAST 03
   RUSHMEIER H, 1995, P 5 EUR WORKSH REND
   SANDER P, 2006, SIGGRAPH
   SCHLNS K, 1995, P 3 COL IM C
   SCHLNS K, 1995, P ACCV
   SEETZEN H, 2004, SIGGRAPH 04 ACM SIGG, P8
   Shafer S.A., 1984, Using Color to Separate Reflection Components
   SHREINER D, 2004, OPENGL R 1 4 REFEREN
   SLOAN PP, 2002, SIGGRAPH 02
   Spencer B, 2009, COMPUT GRAPH FORUM, V28, P319, DOI 10.1111/j.1467-8659.2009.01371.x
   *SPHER, 2002, SPHERON HDR
   STAM J, 1995, SIGGRAPH 95
   STUMPFEL J, 2004, AFRIGRAPH 04
   SUNDSTEDT V, 2005, VAST 05
   SUNDSTEDT V, 2004, AFRIGRAPH 04
   TAKAHASHI JY, 1997, IEICE T INF SYST
   TAN P, 2006, IEEE C COMP VIS PATT
   TAN R, 2004, M IM REC UND MIRU 20
   Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185
   *U SOUTH ARCH COMP, 2009, POL TEXT MAP AM STAT
   UNGER J, 2009, THESIS LINKPING U
   VEACH E, 1997, SIGGRAPH 97
   WALD I, 2007, EUROGRAPHICS
   Walter B, 2005, ACM T GRAPHIC, V24, P1098, DOI 10.1145/1073204.1073318
   WALTER B, 2006, ACM T GRAPH
   Wang O., 2009, IEEE C COMP VIS PATT
   WANG R, 2009, SIGGRAPH 09
   WANG R, 2009, EUROGRAPHICS
   WARD G, 1994, SIGGRAPH 94
   Ward G., 2003, RENDERING RADIANCE
   WARD G, 1988, SIGGRAPH 88
   WARD GJ, 1992, SIGGRAPH 92 P 19 ANN
   WEISS Y, 2001, P IEEE INT C COMP VI
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
   YOON KJ, 2006, IEEE INT C IM PROC I
   ZANYI E, 2007, VAST 07
   ZANYI E, 2007, P 2009 EVA LOND C
NR 179
TC 28
Z9 30
U1 0
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2010
VL 14
IS 3
BP 155
EP 182
DI 10.1007/s10055-010-0154-x
PG 28
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HW
UT WOS:000296279700001
DA 2024-07-18
ER

PT J
AU Gervasi, O
   Magni, R
   Zampolini, M
AF Gervasi, Osvaldo
   Magni, Riccardo
   Zampolini, Mauro
TI Nu!RehaVR: virtual reality in neuro tele-rehabilitation of patients with
   traumatic brain injury and stroke
SO VIRTUAL REALITY
LA English
DT Article
DE Nu!RehaVR; Virtual reality; Tele-rehabilitation; Neurological disease;
   Nu!Reha desk; Traumatic brain Injury; Stroke patients; X3D; Ajax3D
ID UPPER EXTREMITY; TELEREHABILITATION; NEEDS; INTERNET; GLOVE
AB The availability of virtual environments on the Web is fostering new applications of virtual reality in several fields, including some therapeutical applications. We present an application of virtual reality applied to the tele-rehabilitation of patients with traumatic brain injury and stroke. Our system, based on X3D and Ajax3D technologies, enhances the possibility of making tele-rehabilitation exercises aimed at the recovery of the neurological disease. The system, called Nu!RehaVR, has been designed to integrate the activity carried out on a tele-rehabilitation system, Nu!Reha (Nu!Reha is a trademark of Pragma Engineering srl. See http://www.nureha.eu) desk, with the activities performed in the virtual worlds, through some rehabilitation exercises in contexts incompatible with the patients' impairments (not able to move or forced in static positions because of therapies, etc.). The architecture of Nu!RehaVR and the environments associated to two exercises, "Utilising an elevator to reach a given floor" and "Crossing a road using a traffic light", are illustrated. These exercises can be considered as prototypes of a series of tele-rehabilitation exercises which help to stimulate the patients performing actions in relatively dangerous scenarios. The system is designed to allow the remote monitoring and assessment of the patient's activities by the medical staff at the hospital using the communication facilities of the tele-rehabilitation system.
C1 [Gervasi, Osvaldo] Univ Perugia, Dept Math & Comp Sci, I-06123 Perugia, Italy.
   [Magni, Riccardo] Pragma Engn Srl, I-06100 Perugia, Italy.
   [Zampolini, Mauro] Foligno Hosp, Reg Umbria ASL3, Dept Rehabil, I-06034 Foligno, PG, Italy.
C3 University of Perugia
RP Gervasi, O (corresponding author), Univ Perugia, Dept Math & Comp Sci, Via Vanvitelli 1, I-06123 Perugia, Italy.
EM osvaldo@unipg.it; riccardo.magni@pragmaeng.it;
   m.zampolini@als3.umbria.it
RI Magni, Riccardo/IWM-6791-2023; Gervasi, Osvaldo/B-9234-2013; Gervasi,
   Osvaldo/AAH-2792-2019
OI Magni, Riccardo/0009-0005-7734-2740; Gervasi,
   Osvaldo/0000-0003-4327-520X; Gervasi, Osvaldo/0000-0003-4327-520X
FU EU
FX EU projects IST H-CAD and eTen Hellodoc are acknowledged for having
   promoted the concept of tele-rehabilitation applied to
   neuro-rehabilitation practice and for the support provided. The Working
   Group "ELAMS" of the COST D37 Action is acknowledged for the useful
   knowledge and technology contribution provided to the present research.
CR Burdea G, 2000, IEEE T REHABIL ENG, V8, P430, DOI 10.1109/86.867886
   Carey JR, 2007, NEUROREHAB NEURAL RE, V21, P216, DOI 10.1177/1545968306292381
   Hauber RP, 2002, J HEAD TRAUMA REHAB, V17, P535, DOI 10.1097/00001199-200212000-00005
   Heuser A, 2007, IEEE T NEUR SYS REH, V15, P43, DOI 10.1109/TNSRE.2007.891393
   Hill AJ, 2006, AM J SPEECH-LANG PAT, V15, P45, DOI 10.1044/1058-0360(2006/006)
   Holden MK, 2007, IEEE T NEUR SYS REH, V15, P36, DOI 10.1109/TNSRE.2007.891388
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   HUMBLER NR, 2004, TELEMED J E-HEALTH, V10, P129
   HUYGENS B, 2008, J TELEMED TELECARE, V14, P249, DOI DOI 10.1258/JET.2008.080104
   IRON L, 2004, MED INFORM INTERNET, V29, P119
   IRON L, 2001, STUD HLTH TECHNOL IN, V81, P386
   Jack D, 2001, IEEE T NEUR SYS REH, V9, P308, DOI 10.1109/7333.948460
   Nakanishi J, 2004, NEURAL NETWORKS, V17, P1453, DOI 10.1016/j.neunet.2004.05.003
   Page SJ, 2007, ARCH PHYS MED REHAB, V88, P922, DOI 10.1016/j.apmr.2007.03.038
   Placidi G, 2007, COMPUT BIOL MED, V37, P1100, DOI 10.1016/j.compbiomed.2006.09.011
   PRINTABLE DH, 2004, J REHABIL RES DEV, V41, P481
   Reinkensmeyer DJ, 2002, IEEE T NEUR SYS REH, V10, P102, DOI 10.1109/TNSRE.2002.1031978
   Ricker JH, 2002, J HEAD TRAUMA REHAB, V17, P242, DOI 10.1097/00001199-200206000-00005
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Riva G, 2007, LECT NOTES COMPUT SC, V4563, P699
   Rizzo AA, 2004, TELEMED J E-HEALTH, V10, P184, DOI 10.1089/1530562041641336
   Robinson SS, 2003, TELEMED J E-HEALTH, V9, P57, DOI 10.1089/153056203763317657
   Russell TG, 2002, J TELEMED TELECARE, V8, P50, DOI 10.1258/13576330260440853
   Sanford JA, 2004, ASSIST TECHNOL, V16, P43, DOI 10.1080/10400435.2004.10132073
   Sanford JA, 2006, J AM GERIATR SOC, V54, P1641, DOI 10.1111/j.1532-5415.2006.00913.x
   Torsney K, 2003, NEUROREHABILITATION, V18, P183
   Wilson BA, 1996, J HEAD TRAUMA REHAB, V11, P54, DOI 10.1097/00001199-199604000-00006
   ZAMPOLINI M, 2007, IEEE VIRTUAL RE 0927, P83
   Zampolini M, 2008, LECT NOTES COMPUT SC, V5073, P78
NR 29
TC 28
Z9 28
U1 3
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2010
VL 14
IS 2
BP 131
EP 141
DI 10.1007/s10055-009-0149-7
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HV
UT WOS:000296279600004
DA 2024-07-18
ER

PT J
AU Luo, ZQ
   Duh, HBL
AF Luo, Zhiqiang
   Duh, Henry Been-Lirn
TI Effects of perspective elevation and environmental geometry on
   representation of a virtual room space
SO VIRTUAL REALITY
LA English
DT Article
DE Spatial representation; Virtual environment; Perspective elevation
ID SPATIAL ORIENTATION; KNOWLEDGE; DISPLAYS
AB The present study investigated how perspective elevation and room geometry influenced mental representation of spatial layout in virtual rooms. One virtual rectangular and one virtual cylindrical room were constructed. Subjects observed the spatial layout on the floor from five perspectives along the vertical dimension of each virtual room. Then they judged the direction of objects with respect to egocentric and canonical coordinates. The analysis of spatial judgment indicated that judgment accuracy of vertical direction decreased as the perspective elevated, while global situation awareness was best maintained at the 45 degrees elevation angle. The effect of perspective elevation on judgment of horizontal direction was only found in the rectangular room. Moreover, subjects judged the relative direction between objects more quickly in the cylindrical room than in the rectangular room. Applications of these findings to virtual environment design were discussed.
C1 [Luo, Zhiqiang; Duh, Henry Been-Lirn] Nanyang Technol Univ, Div Syst & Engn Management, Sch Mech & Aerosp Engn, Singapore, Singapore.
C3 Nanyang Technological University
RP Luo, ZQ (corresponding author), Nanyang Technol Univ, Div Syst & Engn Management, Sch Mech & Aerosp Engn, Singapore, Singapore.
EM peterluo@pmail.ntu.edu.sg
RI Duh, Henry BL/G-3220-2010; Duh, Henry/O-9514-2019; Luo,
   Zhiqiang/B-8840-2008
OI Duh, Henry BL/0000-0003-4808-6109; 
CR Carlson L.A., 2000, SPAT COGN COMPUT, V1, P365, DOI DOI 10.1023/A:1010071109785
   Colle HA, 1998, PRESENCE-TELEOP VIRT, V7, P116, DOI 10.1162/105474698565622
   Colle HA, 2003, HUM FACTORS, V45, P424, DOI 10.1518/hfes.45.3.424.27257
   Darken RP, 1998, PRESENCE-TELEOP VIRT, V7, P101, DOI 10.1162/105474698565604
   EASTON RD, 1995, J EXP PSYCHOL LEARN, V21, P483, DOI 10.1037/0278-7393.21.2.483
   Hartley T, 2004, COGNITION, V94, P39, DOI 10.1016/j.cognition.2003.12.001
   Hendrix C, 1997, HUM FACTORS, V39, P602, DOI 10.1518/001872097778667915
   Hickox JC, 1999, J EXP PSYCHOL-APPL, V5, P284, DOI 10.1037/1076-898X.5.3.284
   Leigh J., 1996, P IEEE VIRT REAL ANN
   MCGREEVY MW, 1986, HUM FACTORS, V28, P439, DOI 10.1177/001872088602800406
   McNamara TP, 2003, LECT NOTES ARTIF INT, V2685, P174
   Morar S. S., 2002, Virtual Reality, V6, P140, DOI 10.1007/s100550200015
   Sayers H. M., 2004, Virtual Reality, V7, P131, DOI 10.1007/s10055-004-0124-2
   Schafer W. A., 2004, Virtual Reality, V7, P164, DOI 10.1007/s10055-004-0123-3
   Shelton AL, 2004, J EXP PSYCHOL LEARN, V30, P158, DOI 10.1037/0278-7393.30.1.158
   Shelton AL, 2001, COGNITIVE PSYCHOL, V43, P274, DOI 10.1006/cogp.2001.0758
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Werner S, 2003, LECT NOTES ARTIF INT, V2685, P112
   Wickens C.D., 2005, CAMBRIDGE HDB VISUOS, P383, DOI DOI 10.1017/CBO9780511610448.011
   WICKENS CD, 1995, J EXP PSYCHOL-APPL, V1, P110, DOI 10.1037/1076-898X.1.2.110
   Wickens CD, 1999, ATTENTION PERFORM, V17, P113
   1999, SPATIAL COGNITION CO, V1
NR 22
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 27
EP 35
DI 10.1007/s10055-008-0095-9
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100004
DA 2024-07-18
ER

PT J
AU Chang, CY
   Kuo, HC
   Du, ZY
AF Chang, Chu-Yang
   Kuo, Hsu-Chan
   Du, Zhengyi
TI The role of digital literacy in augmented, virtual, and mixed reality in
   popular science education: a review study and an educational framework
   development
SO VIRTUAL REALITY
LA English
DT Review
DE Augmented reality; Mixed reality; Virtual reality; Digital literacy;
   Popular science education
ID TECHNOLOGY; METAANALYSIS; SCAFFOLDS
AB This study aims to bridge the gap between extended reality (XR) and digital literacy (DL) in popular science education and further develop a DL-XR framework. XR includes augmented, virtual, and mixed reality (AR, VR, and MR), which has received increased attention and has been used for educational purposes in recent years. However, the studies of XR in popular science education and its impact on students are scant. It is also challenging to find studies entailing XR and DL in education. This study not only offers an overview of the status quo of XR education but also is the first research presenting a referential framework that systematically integrates the many dimensions of XR and DL for future research and educational practices. XR has been extensively used in museums, benefiting users with immersive, authentic, hands-on, and interactive experiences. In the DL-XR framework, based on the variations of "individual-group" and "passive consumption-active creation", eight dimensions of DL linked to XR are proposed, including "access and understanding", "evaluation", "ethics and well-being", "interaction", "collaboration", "creation", "problem-solving", and "civic engagement and responsibility". In the nurturing of DL, evidence revealed that XR is mostly used for learners to access knowledge/information and interact with virtual items; nonetheless, its applications for active creation, problem-solving, and collaboration are seldom prioritised. This study further proposes integrating project-based learning into XR pedagogical practices, which can maximise its impact on learning and empower the learners to achieve advanced levels of DL.
C1 [Chang, Chu-Yang] Univ Manchester, Manchester Inst Educ, Manchester, England.
   [Kuo, Hsu-Chan] Natl Cheng Kung Univ, Ctr Teacher Educ, Tainan, Taiwan.
   [Kuo, Hsu-Chan] Natl Cheng Kung Univ, Grad Inst Educ, Tainan, Taiwan.
   [Du, Zhengyi] UCL, UCL Inst Educ, London, England.
C3 University of Manchester; National Cheng Kung University; National Cheng
   Kung University; University of London; University College London; UCL
   Institute of Education
RP Du, ZY (corresponding author), UCL, UCL Inst Educ, London, England.
EM zhengyi.du.20@ucl.ac.uk
OI Du, Zhengyi/0009-0009-1783-0119; Chang, Chu-Yang/0000-0002-7155-5279
FU 5G New Technology Learning Demonstration School Program
FX We would like to express our gratitude to Dr Drew Whitworth and Dr
   Amanda Banks Gatenby at the Manchester Institute of Education, the
   University of Manchester, UK. They offered insightful feedback about
   digital, media and information literacy and future~directions for the
   research.~We would like to express our appreciation for the~support
   offered by the 5G New Technology Learning Demonstration School Program.
CR Agostini D, 2019, THESIS N U LILLE
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Alt D., 2021, EQUITY FORMATIVE ASS, DOI [10.1007/978-3-030-71644-8, DOI 10.1007/978-3-030-71644-8]
   Alt D, 2020, INT J EDUC RES, V101, DOI 10.1016/j.ijer.2020.101561
   [Anonymous], 2019, Key Competences for Lifelong Learning
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Bawden D., 2008, Digital literacies: Concepts, policies and practices, P17
   Bekele MK, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5120079
   Bekele MK, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00091
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Besoain F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031341
   Borokhovski E, 2016, COMPUT EDUC, V96, P15, DOI 10.1016/j.compedu.2015.11.004
   Buckingham D, 2006, NORD J DIGIT LIT, V1, P263
   Bye K., 2019, ACM SIGGRAPH 2019 PA, DOI DOI 10.1145/3306212.3328138
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chauhan S, 2017, COMPUT EDUC, V105, P14, DOI 10.1016/j.compedu.2016.11.005
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Clini P, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/597476
   Damala A, 2016, MEDITERR ARCHAEOL AR, V16, P73, DOI 10.5281/zenodo.204970
   Eisenlauer V., 2020, AUGMENTED REALITY VI, P269, DOI [10.1007/978-3-030-37869-1_22, DOI 10.1007/978-3-030-37869-1_22]
   Erbas C, 2019, J COMPUT ASSIST LEAR, V35, P450, DOI 10.1111/jcal.12350
   Errichiello L, 2019, INT J TOUR RES, V21, P590, DOI 10.1002/jtr.2283
   Eshet Yoram, 2012, Journal of Issues in Informing Science and Information Technology, V9, P267
   Feerrar J, 2019, REF SERV REV, V47, P91, DOI 10.1108/RSR-01-2019-0002
   Ferrari A., 2013, DIGCOMP FRAMEWORK DE, DOI [DOI 10.2788/52966, http%3A//dx.doi.org/10.2788/52966]
   Ferrari A., 2012, DIGITAL COMPETENCE P, DOI DOI 10.2791/82116
   Fidan M, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103635
   Ghouaiel N., 2016, Em: The International Journal of Virtual Reality, V17, P21
   Gilster P, 1997, Digital Literacy
   Gong Z., 2022, Digital, V2, P33, DOI [10.3390/digital2010002, DOI 10.3390/DIGITAL2010002]
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Hammady R, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3359590
   Hammady R, 2020, MULTIMED TOOLS APPL, V79, P3465, DOI 10.1007/s11042-019-08026-w
   Heimo OI, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND ENGINEERING
   Hinrichsen J, 2013, RES LEARN TECHNOL, V21, DOI 10.3402/rlt.v21.21334
   Hirsch Peter Buell, 2022, Journal of Business Strategy, P332, DOI 10.1108/JBS-06-2022-0101
   Hsu HP, 2019, J EDUC COMPUT RES, V57, P1400, DOI 10.1177/0735633118794515
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Hung YH, 2017, J COMPUT ASSIST LEAR, V33, P252, DOI 10.1111/jcal.12173
   Ibáñez MB, 2018, COMPUT EDUC, V123, P109, DOI 10.1016/j.compedu.2018.05.002
   Johnston N, 2020, J AUST LIB INF ASSOC, V69, P93, DOI 10.1080/24750158.2020.1712638
   Joint Information Systems Committee (JISC), 2022, BUILD DIG CAP FRAMEW
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kennedy AAU, 2021, INT J SCI EDUC PART, V11, P242, DOI 10.1080/21548455.2021.1946619
   Kimbell-Lopez K, 2016, COMPUT SCH, V33, P211, DOI 10.1080/07380569.2016.1249731
   Kitsa M., 2021, INT J MEDIA INFO LIT, DOI [10.13187/ijmil.2021.1.119, DOI 10.13187/IJMIL.2021.1.119]
   Kokotsaki D, 2016, IMPROV SCH, V19, P267, DOI 10.1177/1365480216659733
   Lazonder AW, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103681
   Liu W, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P389, DOI 10.1109/DMAMH.2007.61
   Loizzo J., 2018, NACTA Journal, V62, P142
   Loscos C, 2003, 2 IEEE ACM INT S MIX, DOI [10.1109/ismar.2003, DOI 10.1109/ISMAR.2003]
   Maas MJ, 2020, TECHNOL PEDAGOG EDUC, V29, P231, DOI 10.1080/1475939X.2020.1737210
   Ministry of Education (Taiwan), 2020, 5G SUPP SELF REG LEA
   Ministry of Education (Taiwan), 2017, DIG LEARN PROJ
   Moorhouse N, 2019, MUS MANAGE CURATOR, V34, P402, DOI 10.1080/09647775.2019.1578991
   Morales TM, 2013, J SCI EDUC TECHNOL, V22, P791, DOI 10.1007/s10956-012-9431-7
   Mystakidis S., 2022, ENCYCLOPEDIA, V2, P486, DOI [10.3390/encyclopedia2010031, DOI 10.3390/ENCYCLOPEDIA2010031]
   Neuburger L, 2018, PROGR IS, P65, DOI 10.1007/978-3-319-64027-3_5
   Ng W, 2012, COMPUT EDUC, V59, P1065, DOI 10.1016/j.compedu.2012.04.016
   Park S, 2013, EDUC MEDIA INT, V50, P266, DOI 10.1080/09523987.2013.862365
   Pellas N, 2020, EDUC INF TECHNOL, V25, P2481, DOI 10.1007/s10639-019-10076-4
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Polizzi G, 2020, COMPUT EDUC, V152, DOI 10.1016/j.compedu.2020.103859
   Porat E, 2018, COMPUT EDUC, V126, P23, DOI 10.1016/j.compedu.2018.06.030
   Reddy P, 2022, J COMPUT HIGH EDUC, V34, P83, DOI 10.1007/s12528-021-09280-4
   Redecker C., 2017, Digital Competence Framework for Educators (DigCompEdu)
   Reynolds R, 2016, ETR&D-EDUC TECH RES, V64, P735, DOI 10.1007/s11423-015-9423-4
   Rob M, 2018, J INT EDUC BUS, V11, P273, DOI 10.1108/JIEB-01-2018-0002
   Sánchez-Cruzado C, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041858
   Southgate Erica, 2019, International Journal of Child-Computer Interaction, V19, P19, DOI 10.1016/j.ijcci.2018.10.002
   Southgate E., 2022, IMMERSIVE ED DESIGNI, P189, DOI [10.1007/978-3-031-18138-2_12, DOI 10.1007/978-3-031-18138-2_12]
   Southgate E, 2017, P IEEE VIRT REAL ANN, P12, DOI 10.1109/VR.2017.7892226
   Sugiura A, 2019, ANAT SCI EDUC, V12, P561, DOI 10.1002/ase.1822
   Sun LY, 2018, MULTIMED TOOLS APPL, V77, P29013, DOI 10.1007/s11042-018-6091-5
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Trunfio M, 2022, J HERIT TOUR, V17, P1, DOI 10.1080/1743873X.2020.1850742
   Wang X., 2013, VIS ENG, V1, P8, DOI [DOI 10.1186/2213-7459-1-8, 10.1186/2213-7459-1-8]
   Wang YH, 2020, EDUC TECHNOL SOC, V23, P53
   Wiederhold BK, 2022, CYBERPSYCH BEH SOC N, V25, P479, DOI 10.1089/cyber.2022.29253.editorial
   Yoon S, 2017, EDUC TECHNOL SOC, V20, P156
   Yoon SA, 2018, RES SCI TECHNOL EDUC, V36, P261, DOI 10.1080/02635143.2017.1386645
   Yoon SA, 2012, INT J COMP-SUPP COLL, V7, P519, DOI 10.1007/s11412-012-9156-x
   Yu Fu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3472303
   Zhou YT, 2022, EDUC RES REV-NETH, V36, DOI 10.1016/j.edurev.2022.100454
NR 85
TC 6
Z9 6
U1 27
U2 73
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2461
EP 2479
DI 10.1007/s10055-023-00817-9
EA JUN 2023
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001011668500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Jurado-Rodriguez, D
   Muñoz-Salinas, R
   Garrido-Jurado, S
   Medina-Carnicer, R
AF Jurado-Rodriguez, David
   Munoz-Salinas, Rafael
   Garrido-Jurado, Sergio
   Medina-Carnicer, Rafael
TI Planar fiducial markers: a comparative study
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Fiducial planar fiducial markers; Pose estimation;
   Marker system comparison
ID PLACE RECOGNITION; LOCALIZATION; GENERATION; VISION; SLAM
AB Fiducial markers are a cost-effective solution for solving labeling and monocular localization problems, making them valuable tools for augmented reality (AR), robot navigation, and 3D modeling applications. However, with the development of many marker detection systems in the last decade, it has become challenging for new users to determine which is best suited for their needs. This paper presents a qualitative and quantitative evaluation of the most relevant marker systems. We analyze the available alternatives in the literature, describe their differences and limitations, and conduct detailed experiments to compare them in terms of sensitivity, specificity, accuracy, computational cost, and performance under occlusion. To our knowledge, this study provides the most comprehensive and updated comparison of fiducial markers. In the Conclusion section, we offer recommendations on which method to use based on the application requirements.
C1 [Jurado-Rodriguez, David; Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein Campus Rabanales, Cordoba 14071, Spain.
   [Jurado-Rodriguez, David; Garrido-Jurado, Sergio] Seabery R&D, Doctor Emilio Haya Prats 13, Huelva 21005, Spain.
   [Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Inst Maimonides Invest Biomed IMIB, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
C3 Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein Campus Rabanales, Cordoba 14071, Spain.; Muñoz-Salinas, R (corresponding author), Inst Maimonides Invest Biomed IMIB, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
EM jrdavidrj@gmail.com; rmsalinas@uco.es; sgj@seaberyat.com; rmedina@uco.es
RI Medina-Carnicer, Rafael RM/G-3401-2015; Jurado Rodríguez,
   David/JXM-5045-2024; Munoz-Salinas, Rafael/K-5999-2014
OI Jurado Rodríguez, David/0000-0003-2408-4926; Munoz-Salinas,
   Rafael/0000-0002-8773-8571
FU Industrial Ph.D. Program of Cordoba University with Seabery R D of
   Andalusia [1380047-F UCOFEDER-2021]; Spanish Ministry of Economy,
   Industry and Competitiveness [PID2019-103871GB-I00]; FEDER
FX This project has been funded under the Industrial Ph.D. Program of
   Cordoba University with Seabery R &D, Project 1380047-F UCOFEDER-2021 of
   Andalusia and Project PID2019-103871GB-I00 of Spanish Ministry of
   Economy, Industry and Competitiveness, and FEDER.
CR Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Atcheson B., 2010, CALTag: High Precision Fiducial Markers for Camera Calibration, P41
   Benligiray B, 2019, IMAGE VISION COMPUT, V89, P158, DOI 10.1016/j.imavis.2019.06.007
   Bergamasco F, 2011, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2011.5995544
   Bhargavapuri M, 2019, CONTROL ENG PRACT, V89, P113, DOI 10.1016/j.conengprac.2019.05.015
   Cai S, 2014, COMPUT HUM BEHAV, V37, P31, DOI 10.1016/j.chb.2014.04.018
   Calvet L, 2016, PROC CVPR IEEE, P562, DOI 10.1109/CVPR.2016.67
   Cejka J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040459
   Chen J, 2021, IEEE INT CONF ROBOT, P9298, DOI 10.1109/ICRA48506.2021.9561419
   Costanza E., 2003, P VISION VIDEO GRAPH, P63
   Dash AK, 2018, DISPLAYS, V55, P46, DOI 10.1016/j.displa.2018.10.003
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Degol J, 2017, IEEE I CONF COMP VIS, P1481, DOI 10.1109/ICCV.2017.164
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   El-Sheimy N, 2021, SATELLITE NAVIG, V2, DOI 10.1186/s43020-021-00041-3
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Fiala M, 2005, PROC CVPR IEEE, P590
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Heng L, 2019, IEEE INT CONF ROBOT, P4695, DOI [10.1109/ICRA.2019.8793949, 10.1109/icra.2019.8793949]
   Iocolano M, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00203
   Jurado D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041123
   Jurado-Rodriguez D, 2021, IEEE ACCESS, V9, P140066, DOI 10.1109/ACCESS.2021.3118049
   Kalaitzakis M, 2021, J INTELL ROBOT SYST, V101, DOI 10.1007/s10846-020-01307-9
   Kaltenbrunner M., 2007, TEI'07 Proceedings, P69
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kato I., 2000, ARtoolkit user manual
   Khattak S, 2018, LECT NOTES COMPUT SC, V11241, P565, DOI 10.1007/978-3-030-03801-4_49
   Klein G., 2007, IEEE and ACM Intl. Sym. on Mixed and Augmented Reality (ISMAR), P225, DOI DOI 10.1109/ISMAR.2007.4538852
   Klopschitz M, 2007, ISMAR, P1
   Krogius M, 2019, IEEE INT C INT ROBOT, P1898, DOI [10.1109/iros40897.2019.8967787, 10.1109/IROS40897.2019.8967787]
   Kunz C, 2019, PROC SPIE, V10951, DOI 10.1117/12.2511720
   Kunze L, 2018, IEEE ROBOT AUTOM LET, V3, P4023, DOI 10.1109/LRA.2018.2860628
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Li B, 2012, IEEE COMMUN LETT, V16, P2044, DOI 10.1109/LCOMM.2012.111612.121898
   Marchand É, 2005, IEEE ROBOT AUTOM MAG, V12, P40, DOI 10.1109/MRA.2005.1577023
   Muñoz-Salinas R, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107193
   Muñoz-Salinas R, 2019, PATTERN RECOGN, V86, P156, DOI 10.1016/j.patcog.2018.09.003
   Muñoz-Salinas R, 2018, PATTERN RECOGN, V73, P158, DOI 10.1016/j.patcog.2017.08.010
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nahangi M, 2018, P 35 ISARC BERL GERM, P88, DOI [DOI 10.22260/ISARC2018/0012, 10.22260/ISARC2018/0012]
   Naimark L, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P27, DOI 10.1109/ISMAR.2002.1115065
   Neunert M, 2015, ARXIV
   Olson E, 2011, IEEE INT CONF ROBOT
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Reuter A, 2012, WSCG'2012, CONFERENCE PROCEEDINGS, PTS I & II, P239
   Rigter LS, 2019, ENDOSC INT OPEN, V7, pE1357, DOI 10.1055/a-0958-2148
   Rohs M, 2004, ADV PERVASIVE COMPUT, P265
   Romero-Ramirez FJ, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2020.104094
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y
   Sagitov A, 2017, 2017 INTERNATIONAL CONFERENCE ON MECHANICAL, SYSTEM AND CONTROL ENGINEERING (ICMSC), P377, DOI 10.1109/ICMSC.2017.7959505
   Sarmadi H, 2019, COMPUT METH PROG BIO, V180, DOI 10.1016/j.cmpb.2019.105004
   Sattar J, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P165, DOI 10.1109/CRV.2007.34
   Sattler T, 2019, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR.2019.00342
   Shaya Karam, 2012, Intelligent Robotics and Applications. Proceedings of the 5th International Conference, ICIRA 2012, P13, DOI 10.1007/978-3-642-33503-7_2
   Thomas G, 2018, IEEE INT CONF ROBOT, P3524
   Tiwari S., 2016, 2016 INT C INF TECHN, P39, DOI DOI 10.1109/ICIT.2016.021
   Torii A, 2015, IEEE T PATTERN ANAL, V37, P2346, DOI 10.1109/TPAMI.2015.2409868
   Tsoukalas A, 2018, MED C CONTR AUTOMAT, P155, DOI 10.1109/MED.2018.8442959
   Wagner D, 2005, P COMP VIS WINT WORK, P147
   Wang J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4193, DOI 10.1109/IROS.2016.7759617
   Wang P, 2018, COMPUT VIS IMAGE UND, V166, P81, DOI 10.1016/j.cviu.2017.10.005
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010
   Yamada Tatsuya, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P647
   Yang SC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1222, DOI 10.1109/IROS.2016.7759204
   Yu GX, 2021, IEEE T VIS COMPUT GR, V27, P3769, DOI 10.1109/TVCG.2020.2988466
   Zhang Z, 2022, IEEE T PATTERN ANAL
NR 71
TC 1
Z9 1
U1 7
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1733
EP 1749
DI 10.1007/s10055-023-00772-5
EA FEB 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000936041500001
DA 2024-07-18
ER

PT J
AU Calandra, D
   De Lorenzis, F
   Cannavò, A
   Lamberti, F
AF Calandra, Davide
   De Lorenzis, Federico
   Cannavo, Alberto
   Lamberti, Fabrizio
TI Immersive virtual reality and passive haptic interfaces to improve
   procedural learning in a formal training course for first responders
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Passive haptics; Video-based training; First
   responders; Forest firefighting; Fire simulation
ID ENVIRONMENTS
AB One key aspect for the safety and success of first responders' operations is the compliance, during the intervention, with all the safety procedures and prescribed behaviors. Although real-world simulation exercises are considered as the best way to verify if operators are ready to handle emergency situations, they are not always a viable approach. Firefighting courses, for example, do not usually include this kind of activities, due to the numerous hazards related to deploying controlled fires for the simulation. However, traditional training approaches based on class lessons and multimedia learning material may not be particularly effective for teaching practical skills and procedural behaviors. In this work, the use of a Virtual Reality Training Simulation (VRTS) combined with passive haptic interfaces and a real-time fire simulation logic is investigated as a complement to a traditional video-based training approach used in the context of forest firefighting. The teaching of safety concepts and correct use of individual firefighting tools was selected as a use case, and a user study involving 45 trainees was carried out in the context of an existing training course. One third of the trainees attended the traditional video-based lessons of the course, whereas the remaining ones also took part to a practice training session, half of them with the devised VRTS, the others in the real world. Experimental results showed that the additional use of the devised VRTS improved the trainees' procedural learning, as well as their motivation and perceived quality of the overall learning experience.
C1 [Calandra, Davide; De Lorenzis, Federico; Cannavo, Alberto; Lamberti, Fabrizio] Politecn Torino, Dipartimento Automat & Informat, Corso Duca Abruzzi 24, I-10129 Turin, TO, Italy.
C3 Polytechnic University of Turin
RP Calandra, D (corresponding author), Politecn Torino, Dipartimento Automat & Informat, Corso Duca Abruzzi 24, I-10129 Turin, TO, Italy.
EM davide.calandra@polito.it; federico.delorenzis@polito.it;
   alberto.cannavo@polito.it; fabrizio.lamberti@polito.it
RI Calandra, Davide/ABG-3277-2020; Lamberti, Fabrizio/I-9153-2012
OI Calandra, Davide/0000-0003-0449-5752; 
FU Politecnico di Torino within the CRUI-CARE Agreement; Interreg V-A
   Francia-Italia ALCOTRA 2014-2020 PITEM RISK ACT project [4980]
FX Open access funding provided by Politecnico di Torino within the
   CRUI-CARE Agreement. This work was supported by Interreg V-A
   Francia-Italia ALCOTRA 2014-2020 PITEM RISK ACT (4980) project.
CR Andrade M, 2018, P PROB SAF ASS MAN P, P1
   [Anonymous], 2019, 2019 26 IEEE C VIRT
   [Anonymous], 2003, Proceedings of the 2003 conference on Diversity in computing: ACM
   Backlund P, 2007, IEEE INT CONF INF VI, P899
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Buttussi F, 2021, IEEE T LEARN TECHNOL, V14, pC, DOI 10.1109/TLT.2020.3033766
   Çakiroglu Ü, 2019, COMPUT EDUC, V133, P56, DOI 10.1016/j.compedu.2019.01.014
   Calandra D, 2021, GRAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 1: GRAPP, P96, DOI 10.5220/0010319400960105
   Calandra D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1403, DOI 10.1109/vr.2019.8797865
   Cannavò A, 2021, IEEE T VIS COMPUT GR, V27, P1871, DOI 10.1109/TVCG.2020.3032440
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chittaro L., 2014, DESKTOP VIRTUAL REAL, P141, DOI DOI 10.1145/2671015.2671025
   Corelli F, 2020, HUCAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 2: HUCAPP, P146, DOI 10.5220/0008962401460153
   de Carvalho PVR, 2018, APPL ERGON, V68, P28, DOI 10.1016/j.apergo.2017.10.016
   DeLorenzis F, 2022, P 8 INT C IMMERSIVE, P1
   Engelbrecht H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00101
   Fathima S.A., 2019, INT J RECENT TECHNOL, V7, P347
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Gwynne SMV, 2019, FIRE MATER, V43, P613, DOI 10.1002/fam.2448
   Haskins J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P57, DOI [10.1109/VRW50115.2020.0-258, 10.1109/VRW50115.2020.00018]
   Hassenzahl M., 2008, TAGUNGSBAND USABILIT, P78
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jost P, 2020, BEHAV INFORM TECHNOL, V39, P1062, DOI 10.1080/0144929X.2019.1641228
   Joyce R.D., AIAA MODELING SIMULA, DOI DOI 10.2514/6.2017-1313
   Kalawsky RS, 1999, APPL ERGON, V30, P11, DOI 10.1016/S0003-6870(98)00047-7
   Keller JM, 2010, MOTIVATIONAL DESIGN FOR LEARNING AND PERFORMANCE: THE ARCS MODEL APPROACH, P1, DOI 10.1007/978-1-4419-1250-3
   Lamberti F, 2021, P INT COMP SOFTW APP, P133, DOI 10.1109/COMPSAC51774.2021.00030
   Louka MN, 2001, P INT C EM MAN COP G, P1
   Lovreglio R, 2021, VIRTUAL REAL-LONDON, V25, P133, DOI 10.1007/s10055-020-00447-5
   Lu XZ, 2020, ADV ENG SOFTW, V143, DOI 10.1016/j.advengsoft.2020.102792
   Lukosch Heide, 2019, HCI in Games. First International Conference, HCI-Games 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11595), P165, DOI 10.1007/978-3-030-22602-2_14
   Morélot S, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104145
   Nahavandi S., 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P11, DOI 10.1007/978-3-030-22871-2_2
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   Pratticò FG, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167527
   Querrec R., 2003, 5th Virtual Reality International Conference, P169
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Rothermel R. C., 1972, USDA Forests Service Research Paper, Intermountain Forest and Range Experiment Station
   Seo SW, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364725
   Strada F, 2021, IEEE T EMERG TOP COM, V9, P1581, DOI 10.1109/TETC.2019.2925777
   Tate DL, 1997, IEEE COMPUT GRAPH, V17, P23, DOI 10.1109/38.626965
   Wheeler SG, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.671664
NR 46
TC 2
Z9 2
U1 1
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 985
EP 1012
DI 10.1007/s10055-022-00704-9
EA OCT 2022
PG 28
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000865890800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ji, NY
   Zhang, F
   Zhang, HX
   Zhao, YB
   Yu, DG
AF Ji, Naye
   Zhang, Fan
   Zhang, Haoxiang
   Zhao, Youbing
   Yu, Dingguo
TI Mixed reality depth contour occlusion using binocular similarity
   matching and three-dimensional contour optimisation
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Real-virtual occlusion; Binocular camera; Depth contour
   extraction; Occlusion handling
ID AUGMENTED REALITY; RECONSTRUCTION
AB Mixed reality applications often require virtual objects that are partly occluded by real objects. However, previous research and commercial products have limitations in terms of performance and efficiency. To address these challenges, we propose a novel depth contour occlusion (DCO) algorithm. The proposed method is based on the sensitivity of contour occlusion and a binocular stereoscopic vision device. In this method, a depth contour map is combined with a sparse depth map obtained from a two-stage adaptive filter area stereo matching algorithm and the depth contour map of the objects extracted by a digital image stabilisation optical flow method. We also propose a quadratic optimisation model with three constraints to generate an accurate dense map of the depth contour for high-quality real-virtual occlusion. The whole process is accelerated by GPU. To evaluate the effectiveness of the algorithm, we demonstrate a time consumption statistical analysis for each stage of the DCO algorithm execution. To verify the reliability of the real-virtual occlusion effect, we conduct an experimental analysis on single-sided, enclosed, and complex occlusions. Subsequently, we compare it with the occlusion method without quadratic optimisation. With our GPU implementation for real-time DCO, the evaluation indicates that applying the presented DCO algorithm enhances the real-time performance and the visual quality of real-virtual occlusion.
C1 [Ji, Naye; Zhang, Fan; Zhang, Haoxiang; Zhao, Youbing; Yu, Dingguo] Commun Univ Zhejiang, Key Lab Film & TV Media Technol Zhejiang Prov, Hangzhou, Peoples R China.
   [Zhang, Haoxiang] Zhejiang Univ, Sch Software Technol, Ningbo, Peoples R China.
   [Yu, Dingguo] Zhejiang Lab, Hangzhou, Peoples R China.
   [Ji, Naye; Zhang, Fan; Zhang, Haoxiang; Zhao, Youbing; Yu, Dingguo] Commun Univ Zhejiang, Intelligent Media Inst, Hangzhou, Peoples R China.
C3 Communication University of Zhejiang; Zhejiang University; Zhejiang
   Laboratory; Communication University of Zhejiang
RP Zhang, F; Yu, DG (corresponding author), Commun Univ Zhejiang, Key Lab Film & TV Media Technol Zhejiang Prov, Hangzhou, Peoples R China.; Yu, DG (corresponding author), Zhejiang Lab, Hangzhou, Peoples R China.; Zhang, F; Yu, DG (corresponding author), Commun Univ Zhejiang, Intelligent Media Inst, Hangzhou, Peoples R China.
EM fanzhang@cuz.edu.cn; yudg@cuz.edu.cn
RI Ji, Naye/GRF-3137-2022
OI Ji, Naye/0000-0002-6986-3766; Fan, Zhang/0000-0002-9534-1777
FU Key Research and Development Plan of Zhejiang Province, China
   [2021C03137, 2019C03131]; Public Welfare Technology Application Research
   Project of Zhejiang Province, China [LGF21F020004, LGF22F020008]; Key
   Lab of Film and TV Media Technology of Zhejiang Province, China
   [2020E10015]
FX This study is supported by Key Research and Development Plan of Zhejiang
   Province, China (No.2021C03137, 2019C03131), the Public Welfare
   Technology Application Research Project of Zhejiang Province, China (No.
   LGF21F020004, LGF22F020008), Key Lab of Film and TV Media Technology of
   Zhejiang Province, China (No.2020E10015).
CR [Anonymous], 1994, VIRTUAL SPACE TELECO
   Berger MO, 1997, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.1997.609304
   Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715
   Breen DE, 1996, COMPUT GRAPH FORUM, V15, pC11, DOI 10.1111/1467-8659.1530011
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Feng Y, 2007, PHD THESIS
   Fischer J., 2004, Proceedings of the ACM symposium on Virtual reality software and technology, P174
   Guo Z., 2018, ELECT DESIGN ENG, V26, P1, DOI [10.14022/j.cnki.dzsjgc.2018.23.001, DOI 10.14022/J.CNKI.DZSJGC.2018.23.001]
   Hebborn AK, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P62, DOI 10.1109/ISMAR.2017.23
   Holynski A, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275083
   Jorge J, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365700
   Klein G, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P38, DOI 10.1109/ISMAR.2004.54
   Kroeger T, 2016, LECT NOTES COMPUT SC, V9908, P471, DOI 10.1007/978-3-319-46493-0_29
   Li B., 2020, J HENAN POLYTECH U, V39, P125, DOI [10.16186/j.cnki.1673-9787.2020.1.16, DOI 10.16186/J.CNKI.1673-9787.2020.1.16]
   Luo TR, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1068, DOI [10.1109/VR.2019.8797811, 10.1109/vr.2019.8797811]
   Luo X, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392377
   Macedo MCF, 2023, IEEE T VIS COMPUT GR, V29, P1590, DOI 10.1109/TVCG.2021.3117866
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   [倪剑 NI Jian], 2006, [计算机应用, Computer Applications], V26, P132
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schmidt J, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P225, DOI 10.1109/ACV.2002.1182186
   Szeliski R, 2006, ACM T GRAPHIC, V25, P1135, DOI 10.1145/1141911.1142005
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   Walton DR, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139153
   Wloka M. W., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P5, DOI 10.1145/199404.199405
   Xiao Tang, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P697, DOI 10.1145/3379337.3415835
   Xu Weipeng, 2013, Journal of Computer Aided Design & Computer Graphics, V25, P1635
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zheng MT, 2016, VIRTUAL REAL-LONDON, V20, P221, DOI 10.1007/s10055-016-0297-5
NR 31
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 887
EP 901
DI 10.1007/s10055-022-00695-7
EA SEP 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000860375700002
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Jackin, BJ
   Jorissen, L
   Oi, R
   Wakunami, K
   Yamamoto, K
   Ichihashi, Y
   Bekaert, P
   Lafruit, G
AF Jackin, Boaz Jessie
   Jorissen, Lode
   Oi, Ryutaro
   Wakunami, Koki
   Yamamoto, Kenji
   Ichihashi, Yasuyuki
   Bekaert, Philippe
   Lafruit, Gauthier
TI Design and calibration of curved and see-through integral imaging 3D
   display
SO VIRTUAL REALITY
LA English
DT Article
DE Holographic micro-mirror array; Integral imaging; Curved light field
   display; Calibration
ID HOLOGRAPHIC OPTICAL-ELEMENTS; LIGHT-FIELD DISPLAY; SYSTEM
AB Heads-up displays that are `see-through' and `curved' and capable of displaying 3D contents are considered crucial for augmented reality-based navigation in automobiles. Here we report the development, calibration and experimental evaluation of a 3D display system that satisfies the above requirements. Integral imaging is used as the 3D display technique, which is realized using a flexible `concave-micro-mirror array' screen (equivalent of a `micro-lens array', but working in reflection mode). The screen itself is fabricated as a holographic optical element. The holographic nature of the screen enables a `see-through' effect. The 3D content to be displayed is served by a 2D projector as integral images. A novel calibration method is developed which employs diffusive markers, that are invisible to the naked eye, being placed at one corner of each elemental micro-mirror. The calibration enables proper treatment of the effects and artifacts caused by screen `curvature', but the presence of markers itself does not degrade the display characteristics. A curved micro-mirror array screen of size 10 cm x 10 cm consisting of 100 x 200 elemental concave mirrors is fabricated as a flexible holographic optical element with diffusive markers of size 300 mu m x 300 mu m. The screen, when illuminated with a projector (that serves integral images), was able to reconstruct a 3D scene of size 10 cm x 10 cm with a depth of 5 cm. The novel calibration method employing diffusive markers demonstrates significant improvement in calibration accuracy. The curved and see-through nature of the display screen makes it a good choice for windshield displays. The reported system requires further improvements in enlarging the screen size and increasing depth of the 3D scene in order to meet real-world requirements, which can be achieved by scaling-up the system.
C1 [Jackin, Boaz Jessie] Kyoto Inst Technol, Ctr Design Centr Engn, Sakyo Ku, Kyoto 6068585, Japan.
   [Jorissen, Lode; Bekaert, Philippe] Hasselt Univ tUL Flanders Make, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
   [Oi, Ryutaro; Wakunami, Koki; Ichihashi, Yasuyuki] Natl Inst Informat & Commun Technol, Appl Electromagnet Res Ctr, 4-2-1 Nukui Kitamachi, Koganei, Tokyo 1848795, Japan.
   [Yamamoto, Kenji] Tokushima Univ, Fac Engn, 2-1 Minamijousanjima, Tokushima, Tokushima 7708506, Japan.
   [Lafruit, Gauthier] Univ Libre Bruxelles Brussels Univ, Lab Image Synth & Anal LISA, Ave FD Roosevelt 50 CP165-57, B-1050 Brussels, Belgium.
C3 Kyoto Institute of Technology; Hasselt University; National Institute of
   Information & Communications Technology (NICT) - Japan; Tokushima
   University
RP Jackin, BJ (corresponding author), Kyoto Inst Technol, Ctr Design Centr Engn, Sakyo Ku, Kyoto 6068585, Japan.
EM jackin@kit.ac.jp; lode.jorissen@uhasselt.be
OI Boaz Jessie, Jackin/0000-0003-0772-9681
FU Japan Society For Promotion Of Science (JSPS) [18H03281]
FX This research was funded by Japan Society For Promotion Of Science
   (JSPS) Grant No. 18H03281.
CR Alizadehsalehi S, 2023, SMART SUSTAIN BUILT, V12, P200, DOI 10.1108/SASBE-01-2021-0016
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   [Anonymous], NEWSROOM LUXURY CLAS
   Bach, THEIR HOLOLENS 2 PRO
   Bang K, 2019, J INFORM DISPLAY, V20, P9, DOI 10.1080/15980316.2019.1570978
   Blender Online Community, BLEND ONL COMM BLEND
   Çöltekin A, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9070439
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hong K, 2014, OPT LETT, V39, P127, DOI 10.1364/OL.39.000127
   Huang F.-C., 2015, SIGGRAPH EMERGING TE, P24
   Hyun JB, 2007, APPL OPTICS, V46, P7697, DOI 10.1364/AO.46.007697
   Jackin BJ, 2018, OPT LETT, V43, P3738, DOI 10.1364/OL.43.003738
   Jang C, 2016, APPL OPTICS, V55, pA71, DOI 10.1364/AO.55.000A71
   Javidi B, 2020, OPT EXPRESS, V28, P32266, DOI 10.1364/OE.402193
   Jorissen L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207188
   Jorissen L, 2019, APPL OPTICS, V58, P1200, DOI 10.1364/AO.58.001200
   Kawakita M, 2010, J SOC INF DISPLAY, V18, P668, DOI 10.1889/JSID18.9.668
   Kim Y, 2005, APPL OPTICS, V44, P546, DOI 10.1364/AO.44.000546
   Kim Y, 2004, OPT EXPRESS, V12, P421, DOI 10.1364/OPEX.12.000421
   Li WM, 2013, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2013.136
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Martínez-Corral M, 2018, ADV OPT PHOTONICS, V10, P512, DOI 10.1364/AOP.10.000512
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Nakamura T, 2017, APPL OPTICS, V56, P9520, DOI 10.1364/AO.56.009520
   Naydenova I., 2017, Holographic Materials and Optical Systems, DOI DOI 10.5772/67001
   Shin DH, 2006, APPL OPTICS, V45, P7375, DOI 10.1364/AO.45.007375
   Trivino-Tarradas P, 2021, INT C DIGITAL TRANSF, P423
   Wakunami K, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12954
   Wang WW, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68620-z
   Xiao X, 2013, APPL OPTICS, V52, P546, DOI 10.1364/AO.52.000546
   Yamaguchi M, 2016, APPL OPTICS, V55, pA178, DOI 10.1364/AO.55.00A178
   Yang R, 2008, IEEE T VIS COMPUT GR, V14, P84, DOI 10.1109/70410
NR 34
TC 3
Z9 4
U1 6
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 761
EP 775
DI 10.1007/s10055-022-00686-8
EA SEP 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000850051500001
DA 2024-07-18
ER

PT J
AU Kirya, M
   Debattista, K
   Chalmers, A
AF Kirya, Mark
   Debattista, Kurt
   Chalmers, Alan
TI Using virtual environments to facilitate refugee integration in third
   countries
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Virtual experiences; Media; Knowledge transfer; Memory
ID REALITY; EXPERIENCES; RETENTION
AB Virtual experiences (VEs) have significant potential to enrich emotional interactions, to encourage socialisation and improve communication. In education, VEs offer new approaches for delivering content. In this paper we consider the application of VEs for assisting refugees in Senegal to learn how to navigate the complexities of the UK health system; a substantial stumbling block for their integration into society and for their own health. Participants (N = 122), refugees awaiting to be repatriated, were exposed to material presented via three different media text, 360 degrees videos and virtual reality (VR) across a total of seven different modalities. The experiment investigated specific attributes of the media that would facilitate refugees' integration, such as knowledge received and retained, experience, usability and presence. The results show that interactive media, in particular VR, was significantly better across all tested attributes.
C1 [Kirya, Mark; Debattista, Kurt; Chalmers, Alan] Univ Warwick, Warwick Mfg Grp WMG, Coventry CV4 7AL, W Midlands, England.
C3 University of Warwick
RP Kirya, M (corresponding author), Univ Warwick, Warwick Mfg Grp WMG, Coventry CV4 7AL, W Midlands, England.
EM M.Kirya@warwick.ac.uk; k.debattista@warwick.ac.uk;
   alan.chalmers@warwick.ac.uk
OI KIRYA, MARK/0000-0002-1571-3404
FU Warwick Manufacturing Group-WMG (University of Warwick)
FX Partial Financial Support was received from Warwick Manufacturing
   Group-WMG (University of Warwick).
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Achuthan K, 2017, EDUC INF TECHNOL, V22, P2825, DOI 10.1007/s10639-017-9626-x
   Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   [Anonymous], 2016, SCENAR J PERFORM TEA, DOI DOI 10.33178/SCENARIO.10.1.1
   [Anonymous], 2001, USABILITY USER EXPER
   [Anonymous], KERAS KERJA PERSIDAN
   Braun S., 2013, New prospects and perspectives for educating language mediators, P93
   Carlin AS, 1997, BEHAV RES THER, V35, P153, DOI 10.1016/S0005-7967(96)00085-X
   Chiswick BR, 2016, FINANC DEV, V53
   Choi HJ, 2007, BRIT J EDUC TECHNOL, V38, P885, DOI 10.1111/j.1467-8535.2006.00676.x
   Cowan B, 2015, VISUAL COMPUT, V31, P1207, DOI 10.1007/s00371-014-1006-6
   Goodson L.J., 2008, The International Journal of Diversity in Organizations, Communities, and Nations, V7, P181, DOI DOI 10.18848/1447-9532/CGP/V07I06/39510
   Herrick Christine., 2005, RACE EQUAL TEACH, V23, P36, DOI [10.18546/RET.23.3.09, DOI 10.18546/RET.23.3.09]
   Kang C, 2019, BRIT J GEN PRACT, V69, pE537, DOI 10.3399/bjgp19X701309
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   Morie JF, 2005, APPL PSYCHOPHYS BIOF, V30, P319, DOI 10.1007/s10484-005-6386-y
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Palanica A, 2019, PERSPECT MED EDUC, V8, P123, DOI 10.1007/s40037-019-0504-7
   Pimentel K., 1993, VIRTUAL REALITY NEW
   Sauzéon H, 2012, EXP PSYCHOL, V59, P99, DOI 10.1027/1618-3169/a000131
   Schnotz W., 2005, The Cambridge handbook of multimedia learning, P49, DOI DOI 10.1017/CBO9780511816819.005
   Veling W, 2014, CYBERPSYCH BEH SOC N, V17, P191, DOI 10.1089/cyber.2012.0497
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Woon APN, 2021, NURS EDUC TODAY, V98, DOI 10.1016/j.nedt.2020.104655
NR 25
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 97
EP 107
DI 10.1007/s10055-022-00659-x
EA JUL 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000828931800002
PM 35891984
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Feng, S
   He, WP
   Wang, SX
   Billinghurst, M
AF Feng, Shuo
   He, Weiping
   Wang, Shouxia
   Billinghurst, Mark
TI Pressure-sketch: a tablet-based design system in immersive VR
SO VIRTUAL REALITY
LA English
DT Article
DE Integrating touch-based interactions into the design; Paint system;
   Virtual environment modeling; Virtual reality
AB Sketch design is generally a feasible concept within virtual reality (VR). However, VR controllers suffer from a fundamental problem that limits operability and immersion, which is the difficulty of imitating the texture of natural materials. To solve these challenges, we developed a tablet-based design system named Pressure-Sketch (PSK) around the tactile features of the digital tablet and stylus. PSK could provide an intuitive design workflow for VR. The digital tablet is covered with natural wood to give a more realistic feel. In addition, utilizing the pressure property, users can directly touch the material by the stylus to create lines with varying widths. An evaluated user study revealed that PSK could significantly improve designs' accuracy and aesthetic quality. Moreover, the system has a better sense of immersion. We are willing to explore the differences between more types of materials on sketching in VR.
C1 [Feng, Shuo; He, Weiping; Wang, Shouxia] Northwestern Polytech Univ, Sch Mech Engn, Cyber Phys Interact Lab, Xian, Shaanxi, Peoples R China.
   [Billinghurst, Mark] Univ South Australia, Empath Comp Lab, Adelaide, SA, Australia.
C3 Northwestern Polytechnical University; University of South Australia
RP Feng, S; He, WP (corresponding author), Northwestern Polytech Univ, Sch Mech Engn, Cyber Phys Interact Lab, Xian, Shaanxi, Peoples R China.
EM fengshuo9707@gmail.com; weiping@nwpu.edu.cn
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Feng, Shuo/0000-0002-1414-6401
FU National Key R&D Program of China [2019YFB1703800]
FX This work is partly supported by the National Key R&D Program of China
   (Grant No. 2019YFB1703800).
CR [Anonymous], TILT BRUSH TUTORIALS
   [Anonymous], FLYING SHAPES
   [Anonymous], GRAVITY SKETCH BRING
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   [Anonymous], VR INK
   Arora R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3459090
   Callens E, 2018, LECT NOTES COMPUT SC, V10894, P157, DOI 10.1007/978-3-319-93399-3_15
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Deering M.F., 1995, ACM Trans. Comput.-Hum. Interact., V2, P220
   Elsayed Hesham., 2020, Proceedings of the 26th ACM Symposium on Virtual Reality Software and Technology, P1, DOI DOI 10.1145/3385956.3418953
   Emilie Y, 2021, P 2021 CHI C HUM FAC
   Eroglu S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P475, DOI 10.1109/VR.2018.8446595
   Hook J, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P51
   Ishii H, 2004, BT TECHNOL J, V22, P287, DOI 10.1023/B:BTTJ.0000047607.16164.16
   Israel JH, 2009, COMPUT GRAPH-UK, V33, P462, DOI 10.1016/j.cag.2009.05.005
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   KIM Y, 2018, P 2018 CHI C HUM FAC
   Krum DM, 2014, P IEEE VIRT REAL VR
   Kuester F, 1999, WORKSH NEW PAR INF V
   Leal A., 2011, P GRAPH INT 2011 GI, V15, P49
   Massie T, 1998, IEEE COMPUT GRAPH, V18, P62, DOI 10.1109/38.674973
   Meredith H, 2009, SUPER SKETCH SISTERS
   Mizuno S, 1998, VISUAL COMPUT, V14, P39, DOI 10.1007/s003710050122
   Panda P, 2021, CREATIVITY COGNITION
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Rahul A, 2017, P ACM CHI 2017
   Regenbrecht H, 2000, VRAM A VIRTUAL REALI
   Shi L, 2015, THESIS U SCI TECHNOL
   Sugihara K, 2011, P ACM S ADJ US INT S
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300243
   Wang J, 2015, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2015.7223332
   Wang SX, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P156, DOI 10.1109/ISMAR-Adjunct.2019.00-58
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
NR 34
TC 0
Z9 0
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1207
EP 1215
DI 10.1007/s10055-022-00627-5
EA JAN 2022
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000749239600001
DA 2024-07-18
ER

PT J
AU Chen, SS
   Weng, DD
AF Chen, Shanshan
   Weng, Dongdong
TI The temporal pattern of VR sickness during 7.5-h virtual immersion
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality sickness; Virtual immersion; Sickness adaption effect;
   Sensory conflict; Long-duration exposure
ID REALITY-INDUCED SYMPTOMS; MOTION SICKNESS; CYBERSICKNESS; ENVIRONMENTS;
   DURATION; EXPOSURE
AB In this study, we assessed the relationship between exposure duration and VR sickness severity during 7.5-h virtual immersion. First, we showed that the VR sickness severity was positively correlated to the exposure duration: the longer participants were exposed to the VR environment, the more severe sickness symptoms they had. Second, we showed a dynamic sickness adaptation process during a long time of VR exposure: the sickness adaption effect that had already been established could be broken as the exposure duration continued to increase, and a new sickness adaption process would establish. Moreover, we showed a distinguishable symptom profile of HMD compared with LCD, which was insusceptible of exposure duration. This is the first report presenting the temporal pattern of VR sickness during such long-duration exposure. Our study could offer a predictive model of VR sickness severity level during long virtual immersion and provide suggestions for the use of VR technology for scientific study, clinical application, and business entertainment.
C1 [Chen, Shanshan; Weng, Dongdong] Beijing Inst Technol, Sch Opt & Photon, Beijing Engn Res Ctr Mixed Real & Adv Display, 5 Zhongguancun South St, Beijing 100081, Peoples R China.
   [Weng, Dongdong] AICFVE Beijing Film Acad, 8 Xitucheng Rd, Beijing 100088, Peoples R China.
C3 Beijing Institute of Technology
RP Weng, DD (corresponding author), Beijing Inst Technol, Sch Opt & Photon, Beijing Engn Res Ctr Mixed Real & Adv Display, 5 Zhongguancun South St, Beijing 100081, Peoples R China.; Weng, DD (corresponding author), AICFVE Beijing Film Acad, 8 Xitucheng Rd, Beijing 100088, Peoples R China.
EM crgj@bit.edu.cn
RI Chen, Shanshan/ABE-7657-2021
FU National Key Research and Development Program of China [2018YFF0300802];
   National Natural Science Foundation of China [U1605254]; 111 Project
   [B18005]
FX This study was supported by the National Key Research and Development
   Program of China (No. 2018YFF0300802), the National Natural Science
   Foundation of China (No. 61902026), the National Natural Science
   Foundation of China (No. U1605254), and the 111 Project (B18005).
CR Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Chinnavan E, 2018, IMPACT VIRTUAL REALI, V8
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Guna J, 2020, MOBILE NETW APPL, V25, P1436, DOI 10.1007/s11036-019-01373-w
   Guo J, 2019, IEEE VEHICLE POWER, DOI 10.1109/vppc46532.2019.8952510
   Inman V, 2017, SIMULATOR SICKNESS Q
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kiryu T, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-34
   Lampton D.R., 2000, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V44, P530, DOI [DOI 10.1177/154193120004400512, 10.1177/154193120004400512]
   Liu CL, 2014, INT J HUM-COMPUT ST, V72, P796, DOI 10.1016/j.ijhcs.2014.07.002
   Moss Jason, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P1631, DOI 10.1518/107118108X351202
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sinitski EH, 2018, DISPLAYS, V52, P1, DOI 10.1016/j.displa.2018.01.001
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
NR 30
TC 3
Z9 4
U1 3
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 817
EP 822
DI 10.1007/s10055-021-00592-5
EA OCT 2021
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000712929600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kim, J
   Charbel-Salloum, A
   Perry, S
   Palmisano, S
AF Kim, Juno
   Charbel-Salloum, Andrew
   Perry, Stuart
   Palmisano, Stephen
TI Effects of display lag on vection and presence in the Oculus Rift HMD
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Head-mounted display; Presence; Vection
ID VIRTUAL ENVIRONMENTS; VIEWPOINT JITTER; IN-DEPTH; MOTION; SICKNESS;
   LATENCY; CONSISTENT; AMPLITUDE; SIZE
AB Head-mounted display (HMD)-based virtual reality (VR) is ideally suited for presence and generating compelling visual experiences of self-motion, but users can suffer from side effects associated with head-to-display lag. We used the Oculus Rift HMD (consumer release - CV1) to simulate forward self-motion in depth. Observers made continuous yaw head movements at approximately 0.5 Hz or 1.0 Hz while viewing these self-motion simulations. We examined the perceptual effects of increasing the display lag, by adding lag to the baseline lag of the system (estimated to be approximately 5.3 ms or 0.5 frames per second). We found that increasing the head-to-display lag up to 212 ms reduced the presence and the strength of vection. In addition, faster (1.0 Hz) head oscillations were found to generate weaker presence and vection in the virtual environment than the slower (0.5 Hz) head oscillations. We also found that a positive correlation between vection and presence (found previously) persists across a wide range of head-to-display lags, and, increasing lag from a very low baseline level still impaired both experiences. Both vection and presence in virtual environments can therefore be impaired by either increasing head-display lag or making more rapid angular head movements.
C1 [Kim, Juno; Charbel-Salloum, Andrew] Univ New South Wales, Sch Optometry & Vis Sci, Sensory Proc Res Lab, Kensington, NSW 2052, Australia.
   [Perry, Stuart] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW, Australia.
   [Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW, Australia.
C3 University of New South Wales Sydney; University of Technology Sydney;
   University of Wollongong
RP Kim, J (corresponding author), Univ New South Wales, Sch Optometry & Vis Sci, Sensory Proc Res Lab, Kensington, NSW 2052, Australia.
EM juno.kim@unsw.edu.au
RI Palmisano, Stephen/O-1553-2018; Perry, Stuart/H-9545-2016
OI Palmisano, Stephen/0000-0002-9140-5681; Kim, Juno/0000-0003-1300-9875;
   Perry, Stuart/0000-0002-2794-3178
FU Australian Research Council (ARC) [DP210101475]; Sensory Processes
   Innovation Network (SPINet)
FX This research was funded by an Australian Research Council (ARC)
   Discovery Project grant awarded to SP and JK (DP210101475). This
   research was supported in part by the Sensory Processes Innovation
   Network (SPINet).
CR Adelstein B. D., 2003, P HUMAN FACTORS ERGO, V47, P2083, DOI [DOI 10.1177/1541931203047020, DOI 10.1177/154193120304702001]
   Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   Ash A, 2011, AVIAT SPACE ENVIR MD, V82, P763, DOI 10.3357/ASEM.3026.2011
   Ash A, 2011, PERCEPTION, V40, P155, DOI 10.1068/p6837
   BARFIELD W, 1993, ADV HUM FACT ERGON, V19, P699
   Basting O, 2017, IEEE SYMP 3D USER, P225, DOI 10.1109/3DUI.2017.7893353
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Chen E, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00004
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cook R., 1992, COMPUT GRAPH WORLD, V15, P40
   Coyne L, 2019, AM J PHARM EDUC, V83, DOI 10.5688/ajpe7456
   Crump W J, 1995, Arch Fam Med, V4, P796, DOI 10.1001/archfami.4.9.796
   Dichgans J., 1978, Visual-vestibular interaction: Effects on self-motion perception and postural control Perception, P755, DOI [DOI 10.1007/978-3-642-46354-9_25, 10.1007/978-3-642-46354-9-25]
   Freiwald JP, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P49, DOI 10.1109/ISMAR-Adjunct.2018.00032
   Fujii Y, 2018, EXP BRAIN RES, V236, P243, DOI 10.1007/s00221-017-5122-1
   Gobel S, 2017, LECT NOTES COMPUTER, V0622
   HACKMAN MZ, 1990, COMMUN EDUC, V39, P196, DOI 10.1080/03634529009378802
   Hamit F., 1995, ADV IMAGING, V10, P21
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Kim JM, 2015, FRONT PLANT SCI, V6, DOI [10.3389/fpls.2015.00114, 10.3389/fpsyg.2015.00248]
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kim J, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516631695
   Kim J, 2014, J VISION, V14, DOI 10.1167/14.5.5
   Kim J, 2012, PERCEPTION, V41, P402, DOI 10.1068/p6919
   Kim J, 2010, EXP BRAIN RES, V202, P355, DOI 10.1007/s00221-009-2137-2
   Kim J, 2008, BRAIN RES BULL, V77, P335, DOI 10.1016/j.brainresbull.2008.09.011
   Kim S., 2021, FRONT VIRTUAL REAL, V2, DOI [10.3389/frvir.2021.5821561[25]P, DOI 10.3389/FRVIR.2021.582156]
   Kinsella A, 2016, AEROSP MED HUM PERF, V87, P604, DOI 10.3357/AMHP.4351.2016
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee D. N., 1975, Journal of Human Movement Studies, V1, P87, DOI DOI 10.3758/BF03199297
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   LORCH RF, 1990, J EXP PSYCHOL LEARN, V16, P149, DOI 10.1037/0278-7393.16.1.149
   Luu W., 2019, P SIGGRAPH AS SIGGRA, DOI [10.1145/3355056.3364590, DOI 10.1145/3355056.3364590]
   Mania Katerina., 2004, Proceedings of the 1st Symposium on Applied Perception in Graphics and Visualization, APGV '04, P39, DOI [10.1145/1012551.1012559, DOI 10.1145/1012551.1012559]
   Moroz M, 2019, DISPLAYS, V58, P12, DOI 10.1016/j.displa.2018.09.001
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Moss JD, 2010, DISPLAYS, V31, P143, DOI 10.1016/j.displa.2010.04.002
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Palmisano S, 2002, PERCEPTION, V31, P463, DOI 10.1068/p3321
   Palmisano S, 1996, PERCEPT PSYCHOPHYS, V58, P1168, DOI 10.3758/BF03207550
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2016, J VISION, V16, DOI 10.1167/16.14.7
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Palmisano S, 2009, ATTEN PERCEPT PSYCHO, V71, P1842, DOI 10.3758/APP.71.8.1842
   Pedram S, 2020, COMPUT HUM BEHAV, V105, DOI 10.1016/j.chb.2019.106223
   Pierre MES, 2015, DISPLAYS, V36, P1, DOI 10.1016/j.displa.2014.10.005
   Prothero J.D., 1998, The role of rest frames in vection, presence and motion sickness
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Riecke BE, 2015, J VISION, V15, DOI 10.1167/15.2.3
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sakamoto S., 2004, Acoustical Science and Technology, V25, P100, DOI 10.1250/ast.25.100
   Seno T., 2013, Psychology, V4, P566, DOI 10.4236/psych.2013.47081
   Seno T., 2017, PERCEPTION, V8, P24, DOI [10.1177/2041669517742176, DOI 10.1177/2041669517742176]
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steinicke F, 2013, HUMAN WALKING VIRTUA, V56, P976
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu WX, 2013, PRESENCE-TELEOP VIRT, V22, P20, DOI 10.1162/PRES_a_00131
   Yokokohji Y., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P247, DOI 10.1109/VR.2000.840505
NR 70
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 425
EP 436
DI 10.1007/s10055-021-00570-x
EA SEP 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000697087600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kaimara, P
   Oikonomou, A
   Deliyannis, I
AF Kaimara, Polyxeni
   Oikonomou, Andreas
   Deliyannis, Ioannis
TI Could virtual reality applications pose real risks to children and
   adolescents? A systematic review of ethical issues and concerns
SO VIRTUAL REALITY
LA English
DT Review
DE Child development; Ethical issues; Games; Impact of technology; Safety;
   Virtual reality technologies
ID ATTENTION-DEFICIT; SERIOUS GAMES; INTERNET ADDICTION; COMPUTER GAMES;
   VIDEO GAMES; METAANALYSIS; CHALLENGES; SYMPTOMS; BENEFITS; OUTCOMES
AB Virtual reality technologies (VRTs) are high-tech human-computer interfaces used to develop digital content and can be applied to multiple different areas, often offering innovative solutions to existing problems. A wide range of digital games is being also developed with VRTs and together with their components, the games' structural elements are appealing to children and engaging them more in virtual worlds. Our research interest is directed towards children's development and the effects of VRTs within gaming environments. Contemporary psychology studies perceive human development as a holistic and lifelong process with important interrelationships between physical, mental, social and emotional aspects. For the objectives and scope of this work, we examine children development across three domains: physical, cognitive and psychosocial. In this context, the authors review the literature on the impact of VRTs on children, in terms of software and hardware. Since research requires an wide-ranging approach, we study the evidence reported on the brain and neural structure, knowledge, behaviour, pedagogy, academic performance, and wellness. Our main concern is to outline the emerging ethical issues and worries of parents, educators, ophthalmologists, neurologists, psychologists, paediatricians and all relevant scientists, as well as the industry's views and actions. The systematic review was performed on the databases Scopus, IEEE Xplore, PubMed, and Google Scholar from 2010 to 2020 and 85 studies were selected. The review concluded that findings remain contradictory especially for the psychosocial domain. Official recommendations from organizations and well-documented researches by academics on child well-being are reassuring if health and safety specifications and particularly the time limit are met. Research is still ongoing, constantly updated and consist of a priority for the scientific community given that technology evolves.
C1 [Kaimara, Polyxeni; Deliyannis, Ioannis] Ionian Univ, Dept Audio & Visual Arts, Tsirigoti Sq 7, Corfu 49100, Greece.
   [Oikonomou, Andreas] Sch Pedag & Technol Educ ASPETE, Alexandrou Papanastasiou 13, Thessaloniki, Greece.
C3 Ionian University
RP Kaimara, P (corresponding author), Ionian Univ, Dept Audio & Visual Arts, Tsirigoti Sq 7, Corfu 49100, Greece.
EM a16kaim@ionio.gr; aoikonomou@aspete.gr; yiannis@ionio.gr
RI Kaimara, Polyxeni/AAM-5734-2021; Deliyannis, Ioannis/AIE-6430-2022
OI Kaimara, Polyxeni/0000-0002-7053-8186; Deliyannis,
   Ioannis/0000-0001-5397-2258
CR Abt C.C., 1975, Serious Games
   Adjorlu Ali, 2020, Interactivity, Game Creation, Design, Learning, and Innovation. 8th EAI International Conference, ArtsIT 2019, and 4th EAI International Conference, DLI 2019. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 328), P739, DOI 10.1007/978-3-030-53294-9_57
   Adjorlu A, 2019, INTERACTIVITY GAME C, V265
   Adjorlu A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P294, DOI 10.1109/ISMAR-Adjunct.2017.93
   Alha K, 2019, COMPUT HUM BEHAV, V93, P114, DOI 10.1016/j.chb.2018.12.008
   Aliyu M.B., 2017, Am. J. Eng. Res., V6, P216
   American Academy of Ophthalmology, 2018, IS TOO MUCH SCREEN T
   American Academy of Ophthalmology, 2020, OPHTH ANT SCH YEAR M
   American Academy of Pediatrics, 2019, FAM MED PLAN
   American Academy of Pediatrics, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2016-2591
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Ramírez-Granizo IA, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17124243
   [Anonymous], 2011, Serious Games and Edutainment Applications, DOI [10.1007/978-1-4471-2161-9_2, DOI 10.1007/978-1-4471-2161-9_2]
   [Anonymous], 2016, CELL PHON RAD CHILDR
   Aromataris E, 2015, INT J EVID-BASED HEA, V13, P132, DOI 10.1097/XEB.0000000000000055
   AYRES AJ, 1980, AM J OCCUP THER, V34, P375, DOI 10.5014/ajot.34.6.375
   Bailey JO, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P181, DOI 10.1016/B978-0-12-809481-5.00009-2
   Behr KM, 2005, PRESENCE-TELEOP VIRT, V14, P668, DOI 10.1162/105474605775196535
   Bennett CR, 2018, PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18), DOI 10.1145/3183654.3183674
   Blume F, 2017, TRIALS, V18, DOI 10.1186/s13063-016-1769-3
   Boyd K, 2020, COMPUTERS DIGITAL DE
   Boyle EA, 2016, COMPUT EDUC, V94, P178, DOI 10.1016/j.compedu.2015.11.003
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Bruck S, 2009, STUD HEALTH TECHNOL, V144, P169, DOI 10.3233/978-1-60750-017-9-169
   Burdea G. C., 2003, Virtual reality technology
   Calvert SL, 2013, NEW DIR CHILD ADOLES, V139, P51, DOI 10.1002/cad.20031
   Cappuccio FP, 2017, CURR CARDIOL REP, V19, DOI 10.1007/s11886-017-0916-0
   Carbonell X, 2017, J BEHAV ADDICT, V6, P124, DOI 10.1556/2006.6.2017.010
   Carter B, 2012, P 2 EUR IMM IN SUMM, P24
   Chang SC, 2020, BRIT J EDUC TECHNOL, V51, P148, DOI 10.1111/bjet.12790
   CHARROIS T, 2015, CAN J HOSP PHARM
   Chassiakos YR, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2016-2593
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Cho BH, 2004, CYBERPSYCHOL BEHAV, V7, P519, DOI 10.1089/cpb.2004.7.519
   Clark R.E., 2010, Handbook of training and improving workplace performance, Volume I: Instructional design and training delivery, VI, P263, DOI DOI 10.1002/9780470592663.CH8
   Connors EC, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00133
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Davies PL, 2007, AM J OCCUP THER, V61, P176, DOI 10.5014/ajot.61.2.176
   de Freitas S, 2018, EDUC TECHNOL SOC, V21, P74
   Dixon DR, 2020, BEHAV ANAL PRACT, V13, P631, DOI 10.1007/s40617-019-00401-1
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Erhel S, 2019, COMPUT HUM BEHAV, V91, P106, DOI 10.1016/j.chb.2018.09.020
   Fernández C, 2018, ENVIRON RES, V167, P694, DOI 10.1016/j.envres.2018.05.013
   Festl R, 2013, ADDICTION, V108, P592, DOI 10.1111/add.12016
   Fokides E, 2020, PERSP EDUC DIG AGE, P54
   Fokides E, 2020, TECHNOL KNOWL LEARN, V25, P1, DOI 10.1007/s10758-019-09409-6
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fuller C., 2017, GLOB PEDIAT HLTH, DOI 10.1177/2333794X17736972
   Gee JamesPaul., 2008, The Ecology of Games: Connecting Youth, Games, and Learning
   Gent E, 2016, SCI AM
   Gheller BJF, 2019, APPL PHYSIOL NUTR ME, V44, P248, DOI 10.1139/apnm-2018-0281
   Girard C, 2013, J COMPUT ASSIST LEAR, V29, P207, DOI 10.1111/j.1365-2729.2012.00489.x
   González CS, 2016, COMPUT HUM BEHAV, V55, P529, DOI 10.1016/j.chb.2015.08.052
   Gottschalk F., 2019, OECD Education Working Papers, DOI [DOI 10.1787/8296464E-EN, 10.1787/8296464--en, DOI 10.1787/8296464--EN]
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Greuter S, 2020, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2020), DOI 10.1145/3373017.3373070
   Gunter GlendaA., 2006, The Journal of the International Digital Media and Arts Association, V3, P93
   Heilig LM, 1962, SENSORAMA STIMULATOR
   Heilig LM, 1960, STEREOSCOPIC TELEVIS
   Heim Michael., 1998, Virtual Realism
   Hirota M, 2019, ERGONOMICS, V62, P759, DOI 10.1080/00140139.2019.1582805
   HTC, 2019, HLTH SAF GUID VIV LE
   JEONG Soojeong, 2015, Educational Technology International, V16, P31
   Kade D, 2016, PHILOSOPHIES, V1, P73, DOI 10.3390/philosophies1010073
   Kaimara Polyxeni, 2020, International Journal of Smart Education and Urban Society, V11, P75, DOI 10.4018/IJSEUS.2020010106
   Kaimara P., 2019, Didactics of smart pedagogy, P113, DOI 10.1007/978-3-030-01551-0_6
   Kaimara P., 2019, EUR J ENG RES SCI, DOI 10.24018/ejers.2019.0.CIE.1288
   Kaimara P, 2019, Horses! Theory and practice in the sciences of education and training, V5, P36
   Kaimara P, 2020, ADV EXP MED BIOL, V1194, P275, DOI 10.1007/978-3-030-32622-7_25
   Kardefelt-Winther D, 2017, 201702 INN UNICEF OF
   Kelly KR, 2016, JAMA OPHTHALMOL, V134, P1402, DOI 10.1001/jamaophthalmol.2016.4224
   Kenney EL, 2017, J PEDIATR-US, V182, P144, DOI 10.1016/j.jpeds.2016.11.015
   Kenny Robert, 2011, Journal of Interactive Learning Research, V22, P259
   Kenwright B, 2018, IEEE TECHNOL SOC MAG, V37, P20, DOI 10.1109/MTS.2018.2876104
   Kim S, 2020, IEEE ACCESS, V8, P45996, DOI 10.1109/ACCESS.2020.2977688
   King DL, 2020, J BEHAV ADDICT, V9, P184, DOI 10.1556/2006.2020.00016
   Koops MC, 2016, SIMULAT GAMING, V47, P159, DOI 10.1177/1046878116632871
   Koutsos TM, 2019, SCI TOTAL ENVIRON, V682, P106, DOI 10.1016/j.scitotenv.2019.04.354
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Kuss DJ, 2017, J BEHAV ADDICT, V6, P103, DOI 10.1556/2006.5.2016.062
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lamb RL, 2018, COMPUT HUM BEHAV, V80, P158, DOI 10.1016/j.chb.2017.10.040
   LANIER J, 1992, J COMMUN, V42, P150, DOI 10.1111/j.1460-2466.1992.tb00816.x
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lobel A, 2017, J YOUTH ADOLESCENCE, V46, P884, DOI 10.1007/s10964-017-0646-z
   Lombard M., 1997, J COMPUT COMMUN, DOI 10.1111/j.1083-6101.1997.tb00072.x
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   Malihi M, 2020, AUTISM, V24, P1924, DOI 10.1177/1362361320934214
   Männikkö N, 2015, J BEHAV ADDICT, V4, P281, DOI 10.1556/2006.4.2015.040
   MARKER C, 2019, SOC SCI MED
   Mayer RE, 2019, ANNU REV PSYCHOL, V70, P531, DOI 10.1146/annurev-psych-010418-102744
   McLean KJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01739
   Mesa-Gresa P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082486
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Molina-Carmona R, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041074
   Moreau D., 2010, Educ. Sci. Psychol., V17, P21
   National Academies of Sciences Engineering and Medicine, 2018, PEOPL LEARN 2
   Neill Sarah J, 2005, J Child Health Care, V9, P46, DOI 10.1177/1367493505049646
   Newbutt N., 2017, Recent advances in technologies for inclusive well-being: From worn to off-body sensing, virtual worlds, and games for serious applications, P221, DOI 10.1007/978-3-319-49879-9_11
   Newbutt N, 2020, CYBERPSYCH BEH SOC N, V23, P23, DOI 10.1089/cyber.2019.0206
   Nolin P, 2016, COMPUT HUM BEHAV, V59, P327, DOI 10.1016/j.chb.2016.02.023
   Oculus, 2018, OC TERMS SERV
   Oliveira CB, 2020, SCAND J MED SCI SPOR, V30, P4, DOI 10.1111/sms.13539
   Paez Arsenio, 2017, J Evid Based Med, DOI [10.1111/jebm.12266, 10.1111/jebm.12265]
   Palaus M, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00248
   Pallavicini F, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/15635
   Parong J, 2020, APPL COGNITIVE PSYCH, V34, P29, DOI 10.1002/acp.3582
   Parsons TD, 2019, EDUC COMMUN TECHNOL, P195, DOI 10.1007/978-3-030-02631-8_11
   Passig D, 2016, COMPUT EDUC, V95, P296, DOI 10.1016/j.compedu.2016.01.009
   Paulus FW, 2018, DEV MED CHILD NEUROL, V60, P645, DOI 10.1111/dmcn.13754
   Peters M, 2006, CORTEX, V42, P1005, DOI 10.1016/S0010-9452(08)70206-5
   Prensky M., 2007, Digital Game-Based Learning pp, P105
   Przybylski AK, 2017, PSYCHOL SCI, V28, P204, DOI 10.1177/0956797616678438
   Przybylski AK, 2014, PEDIATRICS, V134, pE716, DOI 10.1542/peds.2013-4021
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rechichi C, 2017, J PEDIAT OPHTH STRAB, V54, P346, DOI 10.3928/01913913-20170510-01
   Resilient Educator, 2020, PROS CONS DEB US DIG
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Roley S.Smith., 2007, OT PRACTICE, V12, pCE, DOI 10.1002/deo2.130
   Rossi HS, 2018, IEEE INT CONF SERIOU
   Samsung, 2020, IS GEAR VR SAF CHILD
   Schneider LA, 2017, J BEHAV ADDICT, V6, P321, DOI 10.1556/2006.6.2017.035
   Segovia KY, 2009, MEDIA PSYCHOL, V12, P371, DOI 10.1080/15213260903287267
   Shaffer D.R., 2014, Developmental psychology: Childhood and adolescence, V9th
   Shaffer DW, 2005, PHI DELTA KAPPAN, V87, P104, DOI 10.1177/003172170508700205
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P8
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Sobel K., 2019, IMMERSIVE MEDIA CHIL
   Sony Interactive Entertainment, 2020, HLTH WARN
   Spence I, 2010, REV GEN PSYCHOL, V14, P92, DOI 10.1037/a0019491
   Spielman RM, 2020, PSYCHOLOGY, V2e, P295
   Standen P.J., 2006, VIRTUAL REAL-LONDON, V10, P241, DOI 10.1007/s10055-006-0042-6
   Stavropoulos V, 2017, ADDICT BEHAV, V64, P294, DOI 10.1016/j.addbeh.2015.09.001
   Steve A., 2018, European Scientific Journal, V77, P41, DOI [DOI 10.19044/ESJ.2018.V14N8P41, 10.19044/esj.2018.v np, DOI 10.19044/ESJ.2018.VNP, 10.19044/esj.2018.v14n8p41]
   Tate EB, 2013, TRANSL BEHAV MED, V3, P406, DOI 10.1007/s13142-013-0222-3
   Thierer ΑD Camp J, 2017, PERMISSIONLESS INNOV, DOI 10.2139/ssrn.3038935
   Tosini G, 2016, MOL VIS, V22, P61
   Turel O, 2017, CLIN OBES, V7, P191, DOI 10.1111/cob.12191
   Turel O, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154764
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   UK Department for Business Energy & Industrial Strategy, 2020, SAF DOM VIRT REAL SY
   Van Eck R., 2006, EDUC REV, DOI 10.1145/950566950596
   Vasa RA, 2015, CURR OPIN PSYCHIATR, V28, P83, DOI 10.1097/YCO.0000000000000133
   Viner Russell, 2019, The Health Impacts of Screen Time: A Guide for Clinicians and Parents
   Volkow ND, 2015, CELL, V162, P712, DOI 10.1016/j.cell.2015.07.046
   Wang CG, 2018, JMIR SERIOUS GAMES, V6, DOI 10.2196/games.8908
   Wang J, 2020, J MED INTERNET RES, V22, DOI 10.2196/21923
   Weerdmeester J, 2016, GAMES HEALTH J, V5, P258, DOI 10.1089/g4h.2015.0103
   Weinstein A, 2020, DIALOGUES CLIN NEURO, V22, P113, DOI 10.31887/DCNS.2020.22.2/aweinstein
   Weinstein A, 2012, CURR PSYCHIAT REP, V14, P590, DOI 10.1007/s11920-012-0311-x
   Weinstein AM, 2017, FRONT PSYCHIATRY, V8, DOI 10.3389/fpsyt.2017.00185
   WEISS MD, 2011, ADHD ATTEN DEFICIT H
   Wichstrom L, 2019, J ABNORM CHILD PSYCH, V47, P71, DOI 10.1007/s10802-018-0422-x
   Won Deok Park, 2017, Vibroengineering Procedia. 28th International Conference on Vibroengineering, P260, DOI 10.21595/vp.2017.19170
   Wong CW, 2021, AM J OPHTHALMOL, V223, P333, DOI 10.1016/j.ajo.2020.07.034
   Woolley JD, 2013, CHILD DEV, V84, P1496, DOI 10.1111/cdev.12081
   World Health Organization, 2019, International statistical classification of diseases and related health problems, V11th
   World Health Organization, 2020, Looking After Our Mental Health
   Yen JY, 2007, J ADOLESCENT HEALTH, V41, P93, DOI 10.1016/j.jadohealth.2007.02.002
   Young K, 2009, AM J FAM THER, V37, P355, DOI 10.1080/01926180902942191
   Zaharias P, 2017, INT J GAMING COMPUT-, V9, P28, DOI 10.4018/IJGCMS.2017010102
   2005, 3D VID ALG CONC, P1
NR 165
TC 41
Z9 42
U1 6
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 697
EP 735
DI 10.1007/s10055-021-00563-w
EA AUG 2021
PG 39
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000680812600001
PM 34366688
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wyssenbach, T
   Zeballos, M
   Loosli, S
   Schwaninger, A
AF Wyssenbach, Thomas
   Zeballos, Melina
   Loosli, Stefan
   Schwaninger, Adrian
TI Nonverbal behavior of interviewers influences the competence ratings of
   observers in recruitment interviews: a study investigating social
   influence using 360-degree videos with virtual reality and 2D screen
   displays
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; 360-degree video; Social influence; Nonverbal behavior;
   Immersion; Job recruitment interview
ID FACE-TO-FACE; EMPLOYMENT INTERVIEW; SITUATIONAL INTERVIEW; VALIDITY;
   EDUCATION; TECHNOLOGY; COMMUNICATION; QUESTIONNAIRE; PERSONALITY;
   RELIABILITY
AB This study examined whether an interviewer's nonverbal behavior influences observers' competence ratings in a recruitment interview using 360-degree videos experienced with immersive virtual reality (VR-cardboard) and 2D screen displays. Participants (n = 110) observed a recruitment interview and assessed three competences of the applicant (behavior in a team, customer care, and sales skill). We used a 2 x 2 design with the nonverbal behavior (positive vs. negative) of the interviewer and display type (VR-cardboard vs. 2D screen display) as between-subjects factors. After observing interview sequences and providing competence ratings, participants also rated different aspects of immersion using the augmented reality immersion questionnaire (ARI; Georgiou and Kyza in Int J Hum Comput Stud 98: 24-37, 2017) and their overall satisfaction with the experience. For two of the three competences (customer care and behavior in a team), we found that observers gave higher competence ratings when the interviewer's nonverbal behavior was positive compared to when it was negative. This social influence effect was similar for 360-degree videos experienced with immersive VR and 2D screen displays. VR resulted in higher immersion than 2D screen displays regarding the dimensions of flow and presence. Our results suggest that the ARI questionnaire can be used to reliably assess 360-degree videos experienced with immersive VR and 2D screen displays.
C1 [Wyssenbach, Thomas; Zeballos, Melina; Loosli, Stefan; Schwaninger, Adrian] Univ Appl Sci & Arts Northwestern Switzerland, Sch Appl Psychol, Olten, Switzerland.
C3 FHNW University of Applied Sciences & Arts Northwestern Switzerland
RP Wyssenbach, T (corresponding author), Univ Appl Sci & Arts Northwestern Switzerland, Sch Appl Psychol, Olten, Switzerland.
EM thomas.wyssenbach@fhnw.ch
RI Wyssenbach, Thomas/AEH-5381-2022
OI Wyssenbach, Thomas/0000-0002-1628-6678; Schwaninger,
   Adrian/0000-0001-7753-106X; Loosli, Stefan/0000-0002-5787-1216; ,
   Melina/0000-0002-3648-8058
FU Fachhochschule Nordwestschweiz FHNW; University of Applied Sciences and
   Arts Northwestern Switzerland (FHNW)
FX Open Access funding provided by Fachhochschule Nordwestschweiz FHNW.
   This research was funded by the University of Applied Sciences and Arts
   Northwestern Switzerland (FHNW).
CR Alcañiz M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01658
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   American Psychological Association, 2020, PUBL MAN AM PSYCH AS, DOI DOI 10.1037/0000165-000
   [Anonymous], GOOGLE 2020A GOOGLE
   [Anonymous], GOOGLE 2020B INTERAC
   ARVEY RD, 1982, PERS PSYCHOL, V35, P281, DOI 10.1111/j.1744-6570.1982.tb02197.x
   Barrick MR, 2010, J APPL PSYCHOL, V95, P1163, DOI 10.1037/a0019918
   Beaton DE, 2000, SPINE, V25, P3186, DOI 10.1097/00007632-200012150-00014
   Blackman M. C., 2017, WILEY BLACKWELL HDB, P182, DOI DOI 10.1002/9781118972472.CH9
   Blacksmith N., 2016, Personnel Assessment and Decisions, V2, P12, DOI DOI 10.25035/PAD.2016.002
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bonaccio S, 2016, J MANAGE, V42, P1044, DOI 10.1177/0149206315621146
   BORKENAU P, 1995, J PERS, V63, P1, DOI 10.1111/j.1467-6494.1995.tb00799.x
   Bos N., 2002, CHI 02, P135, DOI DOI 10.1145/503376.503401
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   BUTLER D, 1990, J PERS SOC PSYCHOL, V58, P48, DOI 10.1037/0022-3514.58.1.48
   Campion MA, 1997, PERS PSYCHOL, V50, P655, DOI 10.1111/j.1744-6570.1997.tb00709.x
   CAMPION MA, 1988, PERS PSYCHOL, V41, P25, DOI 10.1111/j.1744-6570.1988.tb00630.x
   CAMPION MA, 1994, J APPL PSYCHOL, V79, P998, DOI 10.1037/0021-9010.79.6.998
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Cheng MT, 2015, J COMPUT ASSIST LEAR, V31, P232, DOI 10.1111/jcal.12066
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   CHURCHILL GA, 1985, J MARKETING RES, V22, P103, DOI 10.2307/3151357
   Cialdini R.B., 2009, INFLUENCE SCI PRACTI
   Cialdini R.B., 1984, INFLUENCE PSYCHOL PE
   Cialdini RB, 2004, ANNU REV PSYCHOL, V55, P591, DOI 10.1146/annurev.psych.55.090902.142015
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Culbertson SS, 2017, HUM RESOUR MANAGE R, V27, P167, DOI 10.1016/j.hrmr.2016.09.009
   DeGroot T, 2009, J BUS PSYCHOL, V24, P179, DOI 10.1007/s10869-009-9098-0
   DeVellis R. F., 2016, Scale development: Theory and applications, DOI DOI 10.1037/CCP0000482
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dipboye R.L., 2017, BLACKWELL HDB PERSON, P119
   Dipboye R.L., 2012, The Oxford Handbook of Personnel Assessment and Selection, P323, DOI DOI 10.1093/OXFORDHB/9780199732579.013.0015
   DohertySneddon G, 1997, J EXP PSYCHOL-APPL, V3, P105, DOI 10.1037/1076-898X.3.2.105
   Doll J.L., 2018, MANAGEMENT TEACHING, V3, P46, DOI DOI 10.1177/2379298117722520
   Elias ZM, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102879
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gallup AC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36570-2
   GARNAUT R, 1992, ECONOMIC REFORM AND INTERNATIONALISATION: CHINA AND THE PACIFIC REGION, P1
   Georgiou Y, 2017, INT J HUM-COMPUT ST, V98, P24, DOI 10.1016/j.ijhcs.2016.09.014
   GIFFORD R, 1985, J APPL PSYCHOL, V70, P729, DOI 10.1037/0021-9010.70.4.729
   Guyer JJ, 2019, J NONVERBAL BEHAV, V43, P203, DOI 10.1007/s10919-018-00291-x
   Hartwell CJ, 2019, J BUS RES, V100, P122, DOI 10.1016/j.jbusres.2019.03.026
   Hausknecht JP, 2004, PERS PSYCHOL, V57, P639, DOI 10.1111/j.1744-6570.2004.00003.x
   HOLM S, 1979, SCAND J STAT, V6, P65
   Huffcutt AI, 2004, INT J SELECT ASSESS, V12, P262, DOI 10.1111/j.0965-075X.2004.280_1.x
   Huffcutt AI, 2013, INT J SELECT ASSESS, V21, P264, DOI 10.1111/ijsa.12036
   Huffcutt AI, 2011, HUM RESOUR MANAGE R, V21, P353, DOI 10.1016/j.hrmr.2011.05.003
   Innocenti A, 2012, 2012 18 INT ICE C EN, P1
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jerald J., 2016, VR BOOK HUMAN CENTER
   Jones B., 2015, DESIGN ANAL CROSS OV
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kinateder M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00043
   Klehe UC, 2006, HUM PERFORM, V19, P357, DOI 10.1207/s15327043hup1904_3
   König CJ, 2010, INT J SELECT ASSESS, V18, P17
   Kumar R., 2017, INT J SCI RES, V6, P204
   Lambert B., 2014, Services Marketing Quarterly, V1, P84, DOI DOI 10.1080/15332969.2014.856746
   Lanier J., 2017, DAWN NEW EVERYTHING, V1st
   Larsen RJ, 1996, PERS INDIV DIFFER, V21, P907, DOI 10.1016/S0191-8869(96)00148-1
   LIDEN RC, 1993, ACAD MANAGE J, V36, P372, DOI 10.5465/256527
   Lubeck AJA, 2015, DISPLAYS, V38, P55, DOI 10.1016/j.displa.2015.03.001
   Macan T, 2009, HUM RESOUR MANAGE R, V19, P203, DOI 10.1016/j.hrmr.2009.03.006
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Martín-Gutiérrez J, 2017, EURASIA J MATH SCI T, V13, P469, DOI 10.12973/eurasia.2017.00626a
   MCDANIEL MA, 1994, J APPL PSYCHOL, V79, P599, DOI 10.1037/0021-9010.79.4.599
   NIU Y, 2019, J IMAGING SCI TECHN, V63, P1
   Owen DJ, 2012, CLIN CHILD FAM PSYCH, V15, P364, DOI 10.1007/s10567-012-0120-0
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Papanastasiou G, 2019, VIRTUAL REAL-LONDON, V23, P425, DOI 10.1007/s10055-018-0363-2
   PARSONS CK, 1984, J APPL PSYCHOL, V69, P557, DOI 10.1037/0021-9010.69.4.557
   Phillips J.F., 1992, Journal of Business and Psychology, V7, P151, DOI DOI 10.1007/BF01013925
   Pirker Johanna, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P321, DOI 10.1007/978-3-030-41816-8_14
   Powell W, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P5, DOI 10.1109/WEVR.2016.7859536
   Proost K, 2021, EUR J WORK ORGAN PSY, V30, P265, DOI 10.1080/1359432X.2020.1817975
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Rentz J.O., 2002, J PERSONAL SELLING S, V22, P13
   Rupp MA, 2019, COMPUT EDUC, V128, P256, DOI 10.1016/j.compedu.2018.09.015
   Ryan AM, 1999, PERS PSYCHOL, V52, P359, DOI 10.1111/j.1744-6570.1999.tb00165.x
   Salgado J., 2004, HDB IND WORK ORG PSY, P375
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Schmidt FL, 1998, PSYCHOL BULL, V124, P262, DOI 10.1037/0033-2909.124.2.262
   Schutte NS, 2017, MOTIV EMOTION, V41, P708, DOI 10.1007/s11031-017-9641-7
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Sears GJ, 2013, MANAGE DECIS, V51, P1733, DOI 10.1108/MD-09-2012-0642
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Sutcliffe A, 2005, INT J HUM-COMPUT ST, V62, P307, DOI 10.1016/j.ijhcs.2004.11.010
   Swider BW, 2016, J APPL PSYCHOL, V101, P625, DOI 10.1037/apl0000077
   Taylor PJ, 2002, J OCCUP ORGAN PSYCH, V75, P277, DOI 10.1348/096317902320369712
   Tennant M, 2020, EUR J ONCOL NURS, V48, DOI 10.1016/j.ejon.2020.101804
   The Jamovi project, 2020, JAM VERS 1 2 27 0
   Theobald EJ, 2020, P NATL ACAD SCI USA, V117, P6476, DOI 10.1073/pnas.1916903117
   Turnbull PRK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16320-6
   Violante MG, 2019, INT J INTERACT DES M, V13, P729, DOI 10.1007/s12008-019-00553-y
   Viswesvaran C., 2018, SAGE HDB IND WORK OR, P451, DOI [10.4135/9781473914940.n16, DOI 10.4135/9781473914940.N16]
   Voit A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300737
   Waimanoo, 2020, SURVEY ED PLATFORM
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   WEEKLEY JA, 1987, J APPL PSYCHOL, V72, P484
   Williamson P, 2013, BEHAV SCI LAW, V31, P607, DOI 10.1002/bsl.2094
   Wood W, 2000, ANNU REV PSYCHOL, V51, P539, DOI 10.1146/annurev.psych.51.1.539
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
NR 105
TC 1
Z9 1
U1 2
U2 38
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 669
EP 686
DI 10.1007/s10055-021-00540-3
EA JUN 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000663493200003
OA hybrid
DA 2024-07-18
ER

PT J
AU Phelan, I
   Furness, PJ
   Matsangidou, M
   Carrion-Plaza, A
   Dunn, H
   Dimitri, P
   Lindley, SA
AF Phelan, Ivan
   Furness, Penny Jayne
   Matsangidou, Maria
   Carrion-Plaza, Alicia
   Dunn, Heather
   Dimitri, Paul
   Lindley, Shirley A.
TI Playing your pain away: designing a virtual reality physical therapy for
   children with upper limb motor impairment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Patient-centred design; Upper limb motor impairment;
   Pain management; Children's rehabilitation
ID ALLIANCE; DISTRACTION; MAGNITUDE
AB Children with upper limb motor impairment often undergo repetitive therapeutic physiotherapy sessions to minimize functional disabilities of the affected area. Even though therapeutic processes can improve functional outcomes and minimize persistent disabilities, patients often neglect to participate fully in physical therapies due to the associated procedural pain. Over recent decades, there has been a growing interest in designing non-pharmacological interventions which aim to minimize pain during physical therapies and improve functional outcomes. Via two interrelated studies, we explored the use of virtual reality (VR) as a tool to provide therapeutic physiotherapy for child patients in an out-patient hospital department. We found that VR is an effective solution for children with upper limb motor impairment undergoing painful therapeutic process within a hospital environment. VR can improve functional disabilities, alleviate perceived pain, reduce the perceived difficulty of rehabilitation exercises, increase exercise duration and produce positive emotions towards the therapy. Trial registration number and date of registration Protocol ID NCT03998995. Release Date: June 25, 2019.
C1 [Phelan, Ivan; Matsangidou, Maria; Carrion-Plaza, Alicia; Dunn, Heather; Lindley, Shirley A.] Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Culture Media & Soc, Sheffield S1 1WB, England.
   [Furness, Penny Jayne; Lindley, Shirley A.] Sheffield Hallam Univ, Coll Social Sci & Arts, Dept Psychol Sociol & Polit, Sheffield S1 1WB, England.
   [Dimitri, Paul] Sheffield Childrens NHS Fdn Trust, Sheffield S10 2TH, England.
C3 Sheffield Hallam University; Sheffield Hallam University; Sheffield
   Children's NHS Foundation Trust
RP Phelan, I (corresponding author), Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Culture Media & Soc, Sheffield S1 1WB, England.
EM I.Phelan@shu.ac.uk
OI phelan, ivan/0000-0001-5120-8256; Matsangidou,
   Maria/0000-0003-3804-5565; Furness, Penny/0000-0003-4916-8800; Dimitri,
   Paul/0000-0001-7625-6713; CARRION-PLAZA, ALICIA/0000-0001-7815-1472
FU Medical Research Council (MRC) [152333]; MRC [MC_PC_16058] Funding
   Source: UKRI
FX This study was funding by the Medical Research Council (MRC)-Grant
   number: 152333.
CR [Anonymous], SUBSTANCE 3D
   Chau Brian, 2020, Innov Clin Neurosci, V17, P47
   Das Debashish A, 2005, BMC Pediatr, V5, P1, DOI 10.1186/1471-2431-5-1
   Desai P.Rajesh., 2014, International Journal of Engineering Trends and Technology, V13, P175, DOI [10.14445/22315381/IJETT-V13P237, DOI 10.14445/22315381/IJETT-V13P237]
   Furness PJ, 2019, J BURN CARE RES, V40, P878, DOI 10.1093/jbcr/irz106
   Gerber CN, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0141-x
   Gold J., 2005, J Pain, V6, pS57, DOI [10.1016/j.jpain.2005.01.224, DOI 10.1016/J.JPAIN.2005.01.224]
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Gorini A, 2007, SCIENCE, V318, P1549
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Hoffman HG, 2004, PAIN, V111, P162, DOI 10.1016/j.pain.2004.06.013
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Horvath AO, 2011, PSYCHOTHERAPY, V48, P9, DOI 10.1037/a0022186
   HORVATH AO, 1991, J COUNS PSYCHOL, V38, P139, DOI 10.1037/0022-0167.38.2.139
   Jannink MJA, 2008, CYBERPSYCHOL BEHAV, V11, P27, DOI 10.1089/cpb.2007.0014
   Khadra C, 2018, J PAIN RES, V11, P343, DOI 10.2147/JPR.S151084
   LaValle SM, 2014, IEEE INT CONF ROBOT, P187, DOI 10.1109/ICRA.2014.6906608
   Ma MH, 2011, STUD COMPUT INTELL, V337, P169
   Mahrer NE, 2009, CURR PAIN HEADACHE R, V13, P100, DOI 10.1007/s11916-009-0019-8
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   Martin DJ, 2000, J CONSULT CLIN PSYCH, V68, P438, DOI 10.1037//0022-006X.68.3.438
   Matsangidou M., 2017, Brit J Neurosci Nurs, V13, P133, DOI [10.12968/bjnn.2017.13.3.133, DOI 10.12968/BJNN.2017.13.3.133]
   Matsangidou M, 2022, HUM-COMPUT INTERACT, V37, P314, DOI 10.1080/07370024.2020.1788945
   Matsangidou M, 2019, PSYCHOL SPORT EXERC, V41, P218, DOI 10.1016/j.psychsport.2018.07.004
   Matsangidou M, 2017, LECT NOTES COMPUT SC, V10516, P273, DOI 10.1007/978-3-319-68059-0_18
   Merskey H., 1994, CLASSIFICATION CHRON
   Norcross J.C., 2002, Psychotherapy relationships that work: Therapist contributions and responsiveness to patients
   Parsons TD, 2009, DEV NEUROREHABIL, V12, P224, DOI 10.1080/17518420902991719
   Phelan I, 2019, J BURN CARE RES, V40, P85, DOI 10.1093/jbcr/iry052
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Schneider S M, 2000, Pediatr Nurs, V26, P593
   Schneider SM, 2004, ONCOL NURS FORUM, V31, P81, DOI 10.1188/04.ONF.81-88
   Schneider SM, 2003, CYBERPSYCHOL BEHAV, V6, P301, DOI 10.1089/109493103322011605
   Schneider S, 2007, ONCOL NURS FORUM, V34, P182
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   Sharan D, 2012, WORK, V41, P3612, DOI 10.3233/WOR-2012-0667-3612
   Wiederhold MD, 2007, PAIN MED, V8, pS182, DOI 10.1111/j.1526-4637.2007.00381.x
NR 38
TC 7
Z9 8
U1 3
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 173
EP 185
DI 10.1007/s10055-021-00522-5
EA JUN 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000659381900001
PM 36915630
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU An, J
   Choi, G
   Chun, W
   Joo, Y
   Park, S
   Ihm, I
AF An, Jaepung
   Choi, Gyujin
   Chun, Wooyoung
   Joo, Yesle
   Park, Sanghun
   Ihm, Insung
TI Accurate and stable alignment of virtual and real spaces using
   consumer-grade trackers
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual and real worlds; Consumer-grade trackers; Space alignment
   algorithms; Numerical accuracy and stability; Extended-reality
   applications
AB The world space defined by a traditional virtual reality application is generally regarded as separate from the real-world space in which users actually exist. In this paper, we present a method that enables such detached spaces to connect in an integrated space. In particular, we show that by using a specially manufactured calibration board and three consumer-grade position tracking devices, a reference coordinate system can easily be set up in the physical space, whose geometric relationship with the virtual reality space is estimated with high numerical accuracy and stability. Then, we demonstrate that, combined with traditional computer vision techniques for marker tracking, the presented technique allows colocated users from virtual, augmented, and mixed realities to cooperate with each other while making effective use of technologies from other realities.
C1 [An, Jaepung; Choi, Gyujin; Chun, Wooyoung; Joo, Yesle; Ihm, Insung] Sogang Univ, Dept Comp Sci & Engn, Seoul 04107, South Korea.
   [Park, Sanghun] Dongguk Univ, Dept Multimedia, Seoul 04620, South Korea.
C3 Sogang University; Dongguk University
RP Ihm, I (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul 04107, South Korea.
EM ajp5050@sogang.ac.kr; chlrbwls95@sogang.ac.kr; dndud0802@sogang.ac.kr;
   jooyeseul@sogang.ac.kr; mshpark@dongguk.edu; ihm@sogang.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2020R1A2C2011709]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2020R1A2C2011709).
CR Azimi E., 2018, ARXIV170305834
   Billinghurst M., 2017, P SIGGRAPH AS 2017 M
   Chun W, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P884, DOI [10.1109/VR.2019.8798228, 10.1109/vr.2019.8798228]
   Claraco J., 2018, 012010 U MAL
   Froehlich B., 2020, P 2020 IEEE C VIRT R
   Gottlieb D., 2018, Mixing reality with virtual reality
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/VR.2019.8798080, 10.1109/vr.2019.8798080]
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Luckett E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1711, DOI [10.1109/vr.2019.8798374, 10.1109/VR.2019.8798374]
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Peer A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR.2018.8446435
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139200
   PTC, 2020, GETT START VUF ENG U
   Roo JS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P787, DOI 10.1145/3126594.3126638
   Solomon J, 2015, NUMER ALGORITHMS, DOI [10.1201/b18657, DOI 10.1201/B18657]
   Todd MJ, 2007, DISCRETE APPL MATH, V155, P1731, DOI 10.1016/j.dam.2007.02.013
NR 16
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 125
EP 141
DI 10.1007/s10055-021-00542-1
EA JUN 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000658081900002
DA 2024-07-18
ER

PT J
AU Krokos, E
   Varshney, A
AF Krokos, Eric
   Varshney, Amitabh
TI Quantifying VR cybersickness using EEG
SO VIRTUAL REALITY
LA English
DT Article
DE Experimental methods; HMD; Visualization; Psychology; User-study;
   Perception
ID REALITY-INDUCED SYMPTOMS; SICKNESS; DYNAMICS; COMPONENTS; SIMULATOR
AB Current techniques for characterizing cybersickness (visually induced motion sickness) in virtual environments rely on qualitative questionnaires. For interactive graphics to create visual experiences that enhance the illusion of presence while mitigating cybersickness, interactive measures are needed to characterize cybersickness. In this paper, we acquire EEG signals from participants as they experience vection-induced cybersickness and compare those signals to a baseline. Our study shows that there is a correlation between the participant-reported cybersickness (as measured by movements of a joystick) and brain EEG signals. Through independent component analysis, we separate those signals which are a result of cybersickness from other sources (such as eye blinks). Our user study finds that there is a highly correlative and statistically significant Delta- (1.0-4.0 Hz), Theta- (4.0-7.0 Hz), and Alpha-wave (7.0-13.0 Hz) increase associated with cybersickness in immersive virtual environments across participants. Establishing a strong correlation between cybersickness and EEG-measured brain activity provides us with the first step toward interactively characterizing and mitigating cybersickness in virtual environments.
C1 [Krokos, Eric; Varshney, Amitabh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Krokos, E (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM EKrokos@umiacs.umd.edu; varshney@umiacs.umd.edu
OI Varshney, Amitabh/0000-0002-9873-2212
FU NSF [18-23321, 15-64212, 14-29404]; State of Maryland's MPower
   initiative
FX We would like to extend our sincere appreciation to the anonymous
   reviewers who helped us refine this paper that significantly improved
   its presentation. We appreciate the support of the NSF Grants 18-23321,
   15-64212, 14-29404 and the State of Maryland's MPower initiative. Any
   opinions, findings, conclusions, or recommendations expressed in this
   article are those of the authors and do not necessarily reflect the
   views of the research sponsors. Lastly, we would like to thank the 44
   study participants.
CR Anderson EW, 2011, COMPUT GRAPH FORUM, V30, P791, DOI 10.1111/j.1467-8659.2011.01928.x
   [Anonymous], 1995, ARITR1027
   Arsalan Naqvi SyedAli., 2014, Intelligent and Advanced Systems (ICIAS), 2014 5th International Conference on, P1
   Aspinall P, 2015, BRIT J SPORT MED, V49, P272, DOI 10.1136/bjsports-2012-091877
   Chen YC, 2010, NEUROIMAGE, V49, P2862, DOI 10.1016/j.neuroimage.2009.10.005
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   COWINGS PS, 1986, PSYCHOPHYSIOLOGY, V23, P542, DOI 10.1111/j.1469-8986.1986.tb00671.x
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Debener S, 2012, PSYCHOPHYSIOLOGY, V49, P1617, DOI 10.1111/j.1469-8986.2012.01471.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Duarte M, 2010, BRAZ J PHYS THER, V14, P183, DOI 10.1590/S1413-35552010000300003
   Ekanayake H., 2010, P300 and Emotiv EPOC: Does Emotiv EPOC capture real EEG?
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fransson PA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39104-6
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Holmes SR, 2001, J PSYCHOPHYSIOL, V15, P35, DOI 10.1027//0269-8803.15.1.35
   Hu SQ, 1999, AVIAT SPACE ENVIR MD, V70, P759
   Huang RS, 2008, NEUROIMAGE, V39, P1896, DOI 10.1016/j.neuroimage.2007.10.036
   Huang RS, 2007, LECT NOTES ARTIF INT, V4565, P65
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Ko LW, 2011, LECT NOTES COMPUT SC, V7062, P717, DOI 10.1007/978-3-642-24955-6_85
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Krokos E, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3150977
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LeClair K, 1996, CLIN BIOMECH, V11, P176, DOI 10.1016/0268-0033(95)00027-5
   Lin CT, 2007, P ANN INT IEEE EMBS, P3872, DOI 10.1109/IEMBS.2007.4353178
   Lin CT, 2008, P IEEE, V96, P1167, DOI 10.1109/JPROC.2008.922561
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Maeda T, 2005, P IEEE VIRT REAL ANN, P289
   Makeig S, 1996, ADV NEUR IN, V8, P145
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Naqvi SAA, 2015, AUSTRALAS PHYS ENG S, V38, P721, DOI 10.1007/s13246-015-0379-9
   Patrick E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P478, DOI 10.1145/332040.332479
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riecke BE, 2005, P IEEE VIRT REAL ANN, P131
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Sun XT, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225160
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   WOOD CD, 1994, J CLIN PHARMACOL, V34, P628, DOI 10.1002/j.1552-4604.1994.tb02016.x
NR 45
TC 39
Z9 43
U1 8
U2 65
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 77
EP 89
DI 10.1007/s10055-021-00517-2
EA MAY 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000656397800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Takac, M
   Collett, J
   Conduit, R
   De Foe, A
AF Takac, Marcel
   Collett, James
   Conduit, Russell
   De Foe, Alexander
TI A cognitive model for emotional regulation in virtual reality exposure
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Virtual reality exposure; Emotional regulation;
   Cognition; Psychotherapy; Presence
ID HEART-RATE-VARIABILITY; ANXIETY DISORDER; SOCIAL ANXIETY; PERCEPTION;
   FEAR; ENVIRONMENTS; ATTENTION; THREAT; INFORMATION; IMMERSION
AB Virtual reality exposure (VRE) is an effective form of psychotherapy. However, theoretical frameworks for user experience of virtual reality (VR) have yet to be fully integrated with psychological theory, limiting optimisation of VRE. Presence, a sense of being in a specific place, is the dominant focus of VR/VRE research into emotion regulation. Critically, presence is subject to limitations that make it an impractical concept where precision is needed. More meaningful insights can be obtained by examining specific cognitive constructs. Additionally, presence is a technology-focused consideration. This review argues that in psychotherapy, it is the personal meaning of an environment, rather than the concrete properties of the environment itself, that informs interventions. Because personal meaning is subject to individual differences and most VRE scenarios are generic by nature, situational plausibility must be managed by the therapist. The cognitive person-focused model has been developed to address the limitations of the existing presence-emotion concepts. This model provides a much-needed psychological framework to inform and guide researchers and therapists. The framework also creates a scaffold to support additional variables of interest. As part of the model justification, an examination of presence literature limitations is included. It is hoped that validation and ongoing development of the model will help advance VRE research and therapy.
C1 [Takac, Marcel; Collett, James; Conduit, Russell; De Foe, Alexander] RMIT Univ, Melbourne, Vic, Australia.
C3 Royal Melbourne Institute of Technology (RMIT)
RP Takac, M (corresponding author), RMIT Univ, Melbourne, Vic, Australia.
EM marcel.takac@rmit.edu.au
RI De Foe, Alexander/HLV-6625-2023
OI De Foe, Alexander/0000-0002-5532-3291; Takac, Marcel/0000-0002-5761-1828
CR Altarriba J, 1999, BEHAV RES METH INS C, V31, P578, DOI 10.3758/BF03200738
   Anderson R.C., 1984, Educational Researcher, V13, P5, DOI [10.3102/0013189X013009005, DOI 10.3102/0013189X013009005]
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   ARNTZ A, 1995, BEHAV RES THER, V33, P917, DOI 10.1016/0005-7967(95)00032-S
   Aylett R., 2003, Virtual Reality, V7, P2, DOI 10.1007/s10055-003-0114-9
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Baldassano C, 2018, J NEUROSCI, V38, P9689, DOI 10.1523/JNEUROSCI.0251-18.2018
   Bargh JA, 2014, HANDBOOK OF RESEARCH METHODS IN SOCIAL AND PERSONALITY PSYCHOLOGY, SECOND EDITION, P311
   Beck A.T., 2005, ANXIETY DISORDERS PH
   Beck AT, 2014, ANNU REV CLIN PSYCHO, V10, P1, DOI 10.1146/annurev-clinpsy-032813-153734
   Biocca F, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P12, DOI 10.1109/CT.1997.617676
   Blake, 2001, COMP GRAPH VIRT REAL
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Calvete E, 2013, J ANXIETY DISORD, V27, P278, DOI 10.1016/j.janxdis.2013.02.011
   Clark D.M., 2005, A cognitive perspective on social phobia, P193
   CLARK DM, 1986, BEHAV RES THER, V24, P461, DOI 10.1016/0005-7967(86)90011-2
   Coelho CM, 2008, PSYCHNOLOGY J, V6, P203
   Darken R P, 1999, Cyberpsychol Behav, V2, P337, DOI 10.1089/cpb.1999.2.337
   Deary IJ, 2010, NAT REV NEUROSCI, V11, P201, DOI 10.1038/nrn2793
   Deen B, 2015, CEREB CORTEX, V25, P4596, DOI 10.1093/cercor/bhv111
   DEERING MF, 1993, GRAPH INTER, P219
   Dimitriev DA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146131
   Durlach NI Mavor AS National Research Council Committee on Virtual Reality Research Development, 1995, VIRTUAL REALITY SCI
   Durlik C, 2014, COGNITION EMOTION, V28, P530, DOI 10.1080/02699931.2013.832654
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   Fink G., 2016, STRESS CONCEPTS COGN, P3, DOI [DOI 10.1016/B978-0-12-800951-2.00001-7, DOI 10.1016/B978-0-12-800951-2.00001-3]
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Freeman A., 2004, CLIN APPL COGNITIVE, DOI [10.1007/978-1-4419-8905-5, DOI 10.1007/978-1-4419-8905-5]
   Freeman D, 2008, SCHIZOPHR RES, V102, P254, DOI 10.1016/j.schres.2008.03.020
   Gamberini L., 2015, Immersed in Media, P101, DOI [10.1007/978-3-319-10190-3_6, DOI 10.1007/978-3-319-10190-3_6]
   Glisky Elizabeth L., 2007, P3
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Gouseti I., 2016, Psychology offear, crime and the media: International perspectives, P22
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Gross J. J., 1998, REV GEN PSYCHOL, P271, DOI [10.1037/1089-2680.2.3.271, DOI 10.1037/1089-2680.2.3.271]
   Gujjar KR, 2018, BEHAV COGN PSYCHOTH, V46, P367, DOI 10.1017/S1352465817000534
   Happé F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Hawton K., 1989, COGNITIVE BEHAV THER
   Hayes SC, 1996, J CONSULT CLIN PSYCH, V64, P1152, DOI 10.1037/0022-006X.64.6.1152
   Hofmann Stefan G., 2007, Cognitive Behaviour Therapy, V36, P193, DOI 10.1080/16506070701421313
   IJsselsteijn WA, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P7
   International Society for Presence Research, CONC PRES EXPL STAT
   Khanna P., 2006, Proceedings of the ACM symposium on Virtual reality software and technology, VRST '06, P364, DOI DOI 10.1145/1180495.1180569
   Kiyonaga A, 2017, TRENDS COGN SCI, V21, P493, DOI 10.1016/j.tics.2017.04.011
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   LAZARUS RS, 1964, J ABNORM SOC PSYCH, V69, P195, DOI 10.1037/h0044635
   LAZARUS RS, 1993, ANNU REV PSYCHOL, V44, P1, DOI 10.1146/annurev.ps.44.020193.000245
   Lazarus RS, 1984, Stress, appraisal, and coping
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Levy F, 2016, NEUROPSYCH DIS TREAT, V12, P877, DOI 10.2147/NDT.S97809
   Liberman N, 1998, J PERS SOC PSYCHOL, V75, P5, DOI 10.1037/0022-3514.75.1.5
   Ling Y, 2012, PRESENCE-TELEOP VIRT, V21, P254, DOI 10.1162/PRES_a_00111
   Liviatan I, 2008, J EXP SOC PSYCHOL, V44, P1256, DOI 10.1016/j.jesp.2008.04.007
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI 10.1162/pres.1992.1.1.113
   Lorenz M, 2015, P IEEE VIRT REAL ANN, P223, DOI 10.1109/VR.2015.7223376
   MacIntyre VA, 2010, COMMUN RES REP, V27, P286, DOI 10.1080/08824096.2010.496323
   MACLEOD C, 1992, BEHAV RES THER, V30, P479, DOI 10.1016/0005-7967(92)90032-C
   Madan CR, 2019, EMOTION, V19, P733, DOI 10.1037/emo0000465
   Maddox SA, 2019, NEURON, V102, P60, DOI 10.1016/j.neuron.2019.03.017
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Marchetti I, 2018, J AFFECT DISORDERS, V225, P404, DOI 10.1016/j.jad.2017.08.037
   Martin A, 2016, PSYCHON B REV, V23, P979, DOI 10.3758/s13423-015-0842-3
   MASON JW, 1968, PSYCHOSOM MED, V30, P631, DOI 10.1097/00006842-196809000-00022
   McShane M, 2013, BIOL INSPIR COGN ARC, V3, P39, DOI 10.1016/j.bica.2012.09.001
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Minsky M., 1980, OMNI, V2, P45, DOI DOI 10.1145/566654.566630
   Nasar JL, 1997, ENVIRON BEHAV, V29, P291, DOI 10.1177/001391659702900301
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Nazligul MD, 2017, COMM COM INF SC, V748, P191, DOI 10.1007/978-3-319-64218-5_15
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   OHare, 2001, 4 INT WORKSH PRES
   Overbeeke C.J., 2002, Pleasure with products: Beyond usability, P9
   Overbeeke K., 2003, FUNOLOGY, P7, DOI [DOI 10.1007/1-4020-2967-5_2, 10.1007/1-4020-2967-52, DOI 10.1007/1-4020-2967-52]
   PEACOCK EJ, 1993, CAN J BEHAV SCI, V25, P64, DOI 10.1037/h0078787
   Philippot P., 1997, POL PSYCHOL BULL, V28, P175
   Piaget J., 1971, BIOL KNOWLEDGE ESSAY
   Rettie Ruth, 2004, 7 ANN INT WORKSH PRE
   Riches S, 2019, CYBERPSYCH BEH SOC N, V22, P288, DOI 10.1089/cyber.2018.0128
   Riva G, 2004, CYBERPSYCHOL BEHAV, V7, P402, DOI 10.1089/cpb.2004.7.402
   Rockstroh C, 2019, INT J HUM-COMPUT ST, V130, P209, DOI 10.1016/j.ijhcs.2019.06.011
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   SantAnna ASS, 2007, P 10 ANN INT WORKSH
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Singh A, 1999, J CLIN ENDOCR METAB, V84, P1944, DOI 10.1210/jc.84.6.1944
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Smith CD, 2005, COMMUN REP, V18, P31, DOI 10.1080/08934210500084206
   Smith PK, 2006, J PERS SOC PSYCHOL, V90, P578, DOI 10.1037/0022-3514.90.4.578
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Struyf D, 2017, BEHAV RES THER, V93, P116, DOI 10.1016/j.brat.2017.04.001
   Sussman TJ, 2016, BIOL PSYCHOL, V121, P160, DOI 10.1016/j.biopsycho.2016.08.006
   Symanzik, 1997, INT C HUM COMP INT S
   Takac M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216288
   Takatalo J, 2010, HUM-COMPUT INT-SPRIN, P23, DOI 10.1007/978-1-84882-963-3_3
   Taylor S., 2014, ANXIETY SENSITIVITY, DOI [DOI 10.4324/9781410603326, 10.4324/9781410603326]
   Teng CY, 2019, NAT HUM BEHAV, V3, P827, DOI 10.1038/s41562-019-0640-4
   THALMANN NM, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P1
   Thayer JF, 1996, BIOL PSYCHIAT, V39, P255, DOI 10.1016/0006-3223(95)00136-0
   Trope Y, 2007, J CONSUM PSYCHOL, V17, P83, DOI 10.1016/S1057-7408(07)70013-X
   Trope Y, 2010, PSYCHOL REV, V117, P440, DOI 10.1037/a0018963
   VandenBos G.R.E., 2015, APA dictionary of psychology, V2nd, DOI DOI 10.1037/14646-000
   Vorderer P., 2004, Mec spatial presence questionnaire
   Waterworth J.A., 2015, Immersed in media: Telepresence theory, measurement and technology, P35, DOI 10.1007/978-3-319-10190-3_3
   Waterworth JA, 2010, J CONSCIOUSNESS STUD, V17, P167
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yadav M, 2019, INT CONF AFFECT, DOI 10.1109/acii.2019.8925509
   Young J.E., 2003, SCHEMA THERAPY PRACT, DOI [DOI 10.1017/, DOI 10.1017/S1352465804211869]
   Youngblut C., 2003, Experience of presence in virtual environments, DOI [10.21236/ada427495, DOI 10.21236/ADA427495]
   Zacarin Marcela Roberta Jacyntho, 2019, Trends Psychol., V27, P491, DOI 10.9788/tp2019.2-14
   Zvolensky MJ, 2006, BEHAV RES THER, V44, P1219, DOI 10.1016/j.brat.2006.06.001
NR 115
TC 3
Z9 3
U1 13
U2 59
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 159
EP 172
DI 10.1007/s10055-021-00531-4
EA MAY 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000656397800002
DA 2024-07-18
ER

PT J
AU Varmaghani, S
   Abbasi, Z
   Weech, S
   Rasti, J
AF Varmaghani, Sina
   Abbasi, Zahra
   Weech, Seamas
   Rasti, Javad
TI Spatial and attentional aftereffects of virtual reality and relations to
   cybersickness
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Cognitive aftereffects; Self-motion; Multisensory
   integration; Virtual reality
ID INDUCED MOTION SICKNESS; TASK-PERFORMANCE; SEX-DIFFERENCES;
   WORKING-MEMORY; CHILDREN; LOAD; AGE
AB Cybersickness describes the nausea and discomfort that frequently emerges upon exposure to a virtual reality (VR) environment. The extent to which cybersickness leads to temporary constraints in cognitive functioning after VR exposure is a critical aspect of evaluating the risk to human safety where VR tasks are used for workforce training. Here, we examined whether VR exposure results in deteriorated cognitive spatial ability and attention, and if this possible deterioration is related to cybersickness. A standardized cognitive test battery consisting of Corsi blocks task (CBT), Manikin spatial task (MST), and color trails test (CTT-A and -B) was administered before and after participants were exposed to virtual reality (VR group), or engaged in interactive board games (control group). The performance of participants in CBT remained unchanged from pre-test to post-test in both groups, while performance in MST improved in the control and remained stable in VR group. Response times in CTT-A remained stable in the VR group but reduced significantly in the control group. Regarding CTT-B, participants from both groups became significantly faster in post-test. We did not observe any significant sex differences, or effects of past VR experience, across measures of cognitive performance or cybersickness. Crucially, no significant correlations were found between cognitive performance changes and cybersickness scores in any cases. The results provide encouragement for the use of VR in professional settings, suggesting that VR and cybersickness may minimally limit subsequent cognitive processing. However, it will be crucial to further examine the aftereffects in other cognitive functions.
C1 [Varmaghani, Sina; Abbasi, Zahra] Univ Isfahan, Dept Psychol, Esfahan, Iran.
   [Weech, Seamas] McGill Univ, Sch Phys & Occupat Therapy, Montreal, PQ, Canada.
   [Rasti, Javad] Univ Isfahan, Dept Biomed Engn, Esfahan, Iran.
C3 University of Isfahan; McGill University; University of Isfahan
RP Rasti, J (corresponding author), Univ Isfahan, Dept Biomed Engn, Esfahan, Iran.
EM rasti@eng.ui.ac.ir
RI Varmaghani, Sina/AAH-1268-2020; Rasti, Javad/D-5278-2019
OI Varmaghani, Sina/0000-0003-3132-8626; Weech, Seamas/0000-0003-2333-3505;
   Rasti, Javad/0000-0001-6269-785X; Abbasi, Zahra/0000-0003-3104-3815
FU University of Isfahan Center of Entertainment Industries
FX This research was supported by grants to Javad Rasti from University of
   Isfahan Center of Entertainment Industries (https://uicvg
   ame.ui.ac.ir/). The industry sponsor had no influence in the design or
   execution of the current research.
CR Andersen RA, 1997, PHILOS T ROY SOC B, V352, P1421, DOI 10.1098/rstb.1997.0128
   [Anonymous], 1975, Motion sickness
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Ball K, 2013, COGNITION, V129, P439, DOI 10.1016/j.cognition.2013.08.006
   Barra J, 2006, EXP BRAIN RES, V174, P734, DOI 10.1007/s00221-006-0519-2
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Benson AJ, 1963, LOGICAL PROCESSES RE
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Botella C, 2015, NEUROPSYCH DIS TREAT, V11, P2533, DOI 10.2147/NDT.S89542
   Corbetta M, 1998, NEURON, V21, P761, DOI 10.1016/S0896-6273(00)80593-0
   Cruz-Neira C., 2018, Multimodal Technol. Interact, V2, DOI [DOI 10.3390/MTI2010008, 10.3390/MTI2010008]
   Dahlman J, 2009, HUM FACTORS, V51, P56, DOI 10.1177/0018720809332848
   David-Grignot Stephane, 2014, Proceedings 2014 IEEE International Test Conference (ITC), DOI 10.1109/TEST.2014.7035301
   De Weerd P, 2003, ATTENTION NEURAL BAS, P238
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Dingler Tilman, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3132025
   Düking P, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00128
   Englund C.E., 1987, Unified Tri-Service Cognitive Performance Assessment Battery (UTC-PAB). 1. Design and Specification of the Battery
   Fischer MH, 2001, BRAIN COGNITION, V45, P143, DOI 10.1006/brcg.2000.1221
   Getso MMA, 2017, INT J INF SYST ENG, V5, P30
   GOULD JH, 1990, NEUROPSYCHOLOGIA, V28, P271, DOI 10.1016/0028-3932(90)90020-O
   Gresty MA, 2008, AVIAT SPACE ENVIR MD, V79, P105, DOI 10.3357/ASEM.2143.2008
   Huang-Pollock CL, 2002, DEV PSYCHOL, V38, P363, DOI 10.1037//0012-1649.38.3.363
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   KERR B, 1985, J EXP PSYCHOL HUMAN, V11, P617, DOI 10.1037/0096-1523.11.5.617
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Levine ME, 2002, PERCEPT MOTOR SKILL, V95, P425, DOI 10.2466/PMS.95.5.425-431
   Lezak MD, 2004, Neuropsychological Assessment, DOI DOI 10.1017/S0033291718001599
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   McCarley JS, 2004, PSYCHOL AGING, V19, P203, DOI 10.1037/0882-7974.19.1.203
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   McCulloch P, 2008, GEN LINEAR MIXED MOD
   Mitrushina M.B., 2005, Handbook of normative data for neuropsychological assessment, V2nd
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Moore T, 2004, J NEUROPHYSIOL, V91, P152, DOI 10.1152/jn.00741.2002
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Nobre AC, 2000, NEUROIMAGE, V11, P210, DOI 10.1006/nimg.2000.0539
   Nooriafshar M, 2004, P 7 AM SOC BUS BEH S
   Oman CM, 2014, EXP BRAIN RES, V232, P2483, DOI 10.1007/s00221-014-3973-2
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Raz A, 2006, NAT REV NEUROSCI, V7, P367, DOI 10.1038/nrn1903
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sandi C, 2013, WIRES COGN SCI, V4, P245, DOI 10.1002/wcs.1222
   Sang FDYP, 2003, AVIAT SPACE ENVIR MD, V74, P998
   Saredakis D, 2019, PSYARXIV, DOI [10.31234/osf.io/7u4hn, DOI 10.31234/OSF.IO/7U4HN]
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Smith SP, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100010
   Sohlberg MM, 1989, INTRO COGNITIVE REHA
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stroak P, 2018, INT J AEROSP PSYCHOL, V138, P102
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Tombaugh TN, 2004, ARCH CLIN NEUROPSYCH, V19, P203, DOI 10.1016/S0887-6177(03)00039-8
   Ventura S, 2018, STATE ART VIRTUAL RE, P99
   Wang G, 2019, P 27 EUR C INF SYST
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Yanaka HT, 2010, NEUROSCI RES, V68, P51, DOI 10.1016/j.neures.2010.05.005
   Yardley L, 2001, J NEUROL NEUROSUR PS, V71, P48, DOI 10.1136/jnnp.71.1.48
   Young SD, 2006, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2006.44
   Zhou C, 2019, 16 INT C MOB AD HOC
NR 77
TC 9
Z9 9
U1 2
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 659
EP 668
DI 10.1007/s10055-021-00535-0
EA MAY 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000651679200001
DA 2024-07-18
ER

PT J
AU Winkler, P
   Stiens, P
   Rauh, N
   Franke, T
   Krems, J
AF Winkler, Paul
   Stiens, Philipp
   Rauh, Nadine
   Franke, Thomas
   Krems, Josef
TI How latency, action modality and display modality influence the sense of
   agency: a virtual reality study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Sense of agency; Voice command; Latency; HMD;
   Human-computer interaction
ID MODEL; TIME
AB The objective of this study was to investigate the influences of latency (i.e., technical system response time), action modality (button press, voice command) and display modality (head-mounted display, monitor) on the sense of agency (SOA). SOA is the experience of controlling one's own actions and their corresponding effects in the environment. TheN = 31 (48% female, with a mean age of 24) participants had to interact repeatedly with three different objects (lamp, tablet and computer) in a virtual environment (presented on a monitor or via a head-mounted display) by using a voice command or pressing a button to turn the objects on. The objects reacted after a specific technical system response delay (150, 450 and 750 ms). Results showed that the SOA was weaker for actions employing voice commands opposed to button presses, except for the explicit SOA in the monitor condition. Higher latencies diminished the explicit, but not the implicit SOA. Neither the explicit nor the implicit SOA was significantly affected by the display modality. The findings in part support the weighting process of different agency cues of the underlying framework, and we propose to extend this model by a sense of presence. Users seem to react as if they have the impression that they are not able to control the technical system properly if they interact through a voice command. Therefore, human-computer interface designers could take account of our findings regarding the modality of an action by providing additional feedback cues to increase the SOA for interactions with voice interfaces.
C1 [Winkler, Paul; Stiens, Philipp; Rauh, Nadine; Franke, Thomas; Krems, Josef] Tech Univ Chemnitz, Fac Behav & Social Sci, D-09107 Chemnitz, Germany.
C3 Technische Universitat Chemnitz
RP Winkler, P (corresponding author), Tech Univ Chemnitz, Fac Behav & Social Sci, D-09107 Chemnitz, Germany.
EM paul.winkler@uni-jena.de; philipp.stiens@uni-jena.de
RI Krems, Josef F/M-7531-2017
OI Krems, Josef F/0000-0001-6156-9944
CR Aylett MP, 2014, P 2014 ACM ANN C HUM, DOI [10.1145/2559206.2578868, DOI 10.1145/2559206.2578868]
   Berberian B, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034075
   Blakemore SJ, 2002, TRENDS COGN SCI, V6, P237, DOI 10.1016/S1364-6613(02)01907-1
   Blom KJ, 2014, VIRTUAL REAL-LONDON, V18, P101, DOI 10.1007/s10055-013-0232-y
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P83, DOI 10.1007/s10055-016-0286-8
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Coyle D, 2012, P 2012 ACM ANN C HUM, DOI [10.1145/2207676.2208350, DOI 10.1145/2207676.2208350]
   Ebert JP, 2010, CONSCIOUS COGN, V19, P481, DOI 10.1016/j.concog.2009.10.002
   Engbert K, 2007, J EXP PSYCHOL HUMAN, V33, P1261, DOI 10.1037/0096-1523.33.6.1261
   Engbert K, 2008, COGNITION, V107, P693, DOI 10.1016/j.cognition.2007.07.021
   Evans N, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130019
   Farrer C, 2013, CONSCIOUS COGN, V22, P1431, DOI 10.1016/j.concog.2013.09.010
   Field A., 2009, Discovering statistics with SPSS, V3rd
   Haggard P, 2002, NAT NEUROSCI, V5, P382, DOI 10.1038/nn827
   Havranek M, 2012, BEHAV BRAIN FUNCT, V8, DOI 10.1186/1744-9081-8-34
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Kawabe T, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0991
   Kawabe T, 2013, CONSCIOUS COGN, V22, P407, DOI 10.1016/j.concog.2013.01.006
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Limerick H, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3967, DOI 10.1145/2702123.2702379
   Moore JW, 2012, CONSCIOUS COGN, V21, P1748, DOI 10.1016/j.concog.2012.10.005
   Moore JW, 2012, CONSCIOUS COGN, V21, P546, DOI 10.1016/j.concog.2011.12.002
   Obhi S, 2011, EXP BRAIN RES, V211, P663, DOI 10.1007/s00221-011-2662-7
   Schoeffler M, 2015, VIRTUAL REAL-LONDON, V19, P181, DOI 10.1007/s10055-015-0270-8
   SHNEIDERMAN B, 2004, DESIGNING USER INTER, P5
   Slater M, 2009, ANU PSICOL, V40, P193
   Synofzik M, 2008, CONSCIOUS COGN, V17, P411, DOI 10.1016/j.concog.2008.03.008
   Synofzik M, 2008, CONSCIOUS COGN, V17, P219, DOI 10.1016/j.concog.2007.03.010
   Synofzik M, 2006, J NEUROPHYSIOL, V96, P1592, DOI 10.1152/jn.00104.2006
   Synofzik M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00127
   Synofzik M, 2009, CONSCIOUS COGN, V18, P1065, DOI 10.1016/j.concog.2009.07.007
   Turchet L, 2015, VIRTUAL REAL-LONDON, V19, P277, DOI 10.1007/s10055-015-0267-3
   Vorderer P., 2004, REPORT EUROPEAN COMM
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
NR 35
TC 12
Z9 12
U1 2
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 411
EP 422
DI 10.1007/s10055-019-00403-y
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000565033400005
DA 2024-07-18
ER

PT J
AU Howie, S
   Gilardi, M
AF Howie, Scott
   Gilardi, Marco
TI Virtual Observations: a software tool for contextual observation and
   assessment of user's actions in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Virtual Observation; Observing; Replaying; Reviewing;
   Simulations
AB In this paper, we present 'Virtual Observation' (VO) a software tool for contextual observation and assessment of user's directly from within the virtual reality (VR) simulation framework. Unlike other recording systems, the VO system described in this paper focuses on recording and reconstructing VR user's positional, rotational and input data to recreate the same experience the user had with a VR simulation. Different from animation-based approaches, VO records user inputs and reconstructs the simulation from them and the user positional data. Moreover, the system allows the broadcast of this information to a remote machine enabling remote live observation of the simulation. Datasets recorded by the system can be shared by exporting them as XML files or, optionally, into a standalone online application, such as browser WebGL, allowing researchers, developers and educators to share and review a VR user simulation through a free-moving camera using a web browser. In this paper, the consistency of the data generated from the software by the client, server and reconstructed datasets acquired during real-time live observations was evaluated. We conclude that this Virtual Observation software offers detailed reconstruction of low-level information and visual information of user actions during simulations for both live and offline observations. We envision that our system will be of benefit for researchers, developers and educators that work with VR applications.
C1 [Howie, Scott; Gilardi, Marco] Univ West Scotland, Paisley, Renfrew, Scotland.
C3 University of West Scotland
RP Howie, S (corresponding author), Univ West Scotland, Paisley, Renfrew, Scotland.
EM Scott.Howie@uws.ac.uk; Marco.Gilardi@uws.ac.uk
RI Gilardi, Marco/AAA-2157-2021
OI Gilardi, Marco/0000-0001-8220-7432; Howie, Scott/0000-0002-4445-670X
CR [Anonymous], 2018, 2018 ANN IEEE INT SY
   [Anonymous], 2016, Interactions, DOI DOI 10.1145/2907069
   Blomberg J., 2003, HUM FAC ER, P964
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   FitzGerald E, 2012, SURF LEARN WORKSH 20
   Goldberg SL, 2003, TECHNICAL REPORT
   Greenberg S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P111
   Greenhalgh C., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P119, DOI 10.1145/351006.351027
   Greenhalgh C, 2002, P IEEE VIRT REAL ANN, P101, DOI 10.1109/VR.2002.996512
   Howie SR, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312836
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jung Bernhard, 2006, P ACM S VIRT REAL SO, P145
   Lang P, 2019, FINAL IK
   Lazar J., 2017, RES METHODS HUMAN CO, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Lopez T, 2017, P 23 ACM S VIRT REAL, P83
   Meissner M., 2017, J BUS RES, DOI [DOI 10.1016/J.JBUSRES.2017.09.028, 10.1016/j.jbusres.2017.09.028]
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Petrie H., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1133
   Reitmayr G., 2005, VIRTUAL REAL-LONDON, V9, P79, DOI DOI 10.1007/S10055-005-0006-2
   Tromp JG, 2003, PRESENCE-TELEOP VIRT, V12, P241, DOI 10.1162/105474603765879512
   von Spiczak J, 2007, PROC SPIE, V6504, DOI 10.1117/12.706079
NR 23
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 447
EP 460
DI 10.1007/s10055-020-00463-5
EA AUG 2020
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000560973600001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Malta, LS
   Giosan, C
   Szkodny, LE
   Altemus, MM
   Rizzo, AA
   Silbersweig, DA
   Difede, J
AF Malta, Loretta S.
   Giosan, Cezar
   Szkodny, Lauren E.
   Altemus, Margaret M.
   Rizzo, Albert A.
   Silbersweig, David A.
   Difede, JoAnn
TI Development of a virtual reality laboratory stressor
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; PTSD; Veterans; Research methods; Experimental
   psychopathology
ID EXPOSURE THERAPY; ANALOG TRAUMA; DISORDER; MEMORIES; PTSD; REACTIVITY;
   DEPLOYMENT; RESPONSES; STIMULI
AB This research report describes the development of a virtual reality (VR) laboratory stressor to study the effects of exposure to stressful events. The aim of the research was to develop a VR simulation that would evoke stressor responses at a level that was tolerable for participants. Veterans with and without warzone-related posttraumatic stress disorder (PTSD) were presented with VR simulations of combat stressors. There was one complaint of feeling hot during simulations but no incidents of simulator sickness. Participants denied experiencing the simulations as overly distressing, and there were no reports of any distress or problems related to study participation when they were contacted two weeks after the VR challenge. Simulations elicited moderate levels of anxiety and mild levels of dissociation that were significantly greater in Veterans with PTSD. Simulations were less successful in eliciting differential heart rate reactivity and stress hormone secretion, though history of civilian trauma exposure was associated with elevated heart rates during the second simulation. The study demonstrated that the VR paradigm was feasible and tolerable and that it holds promise as a new method with which to conduct controlled laboratory research on the effects of exposure to stressful events.
C1 [Malta, Loretta S.; Giosan, Cezar; Szkodny, Lauren E.; Altemus, Margaret M.; Rizzo, Albert A.; Silbersweig, David A.; Difede, JoAnn] Cornell Univ, Weill Med Coll, 1300 York Ave, New York, NY 10065 USA.
   [Giosan, Cezar] Univ Bucharest, Dept Psychol, Str Panduri 90, Bucharest, Romania.
   [Rizzo, Albert A.] Univ Southern Calif, Inst Creat Technol, 12015 Waterfront Dr, Playa Vista, CA 90094 USA.
C3 Cornell University; Weill Cornell Medicine; University of Bucharest;
   University of Southern California
RP Giosan, C (corresponding author), Cornell Univ, Weill Med Coll, 1300 York Ave, New York, NY 10065 USA.; Giosan, C (corresponding author), Univ Bucharest, Dept Psychol, Str Panduri 90, Bucharest, Romania.
EM giosan@outlook.com
RI Giosan, Cezar/J-7426-2015
OI Giosan, Cezar/0000-0002-1260-6830
FU NIH Loan Repayment; Weill Medical College of Cornell University Faculty
   Grants
FX This study was supported by NIH Loan Repayment and Weill Medical College
   of Cornell University Faculty Grants awarded to the first author. These
   agencies had no involvement in the design or execution of the research
   or in the writing of research manuscripts.
CR Assimonis SD, 2014, 2014 IEEE RFID TECHNOLOGY AND APPLICATIONS CONFERENCE (RFID-TA), P1, DOI 10.1109/RFID-TA.2014.6934190
   Barkley, 2005, ATTENTION DEFICIT HY
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Ben-Zion Z, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00477
   Bergouignan L, 2014, P NATL ACAD SCI USA, V111, P4421, DOI 10.1073/pnas.1318801111
   Berntsen D, 2014, CLIN PSYCHOL SCI, V2, P174, DOI 10.1177/2167702613496241
   Blake D.D., 1998, CLIN ADM PTSD SCAL D
   BLANCHARD EB, 1986, BEHAV THER, V17, P592, DOI 10.1016/S0005-7894(86)80097-1
   Bradley MM, 2009, PSYCHOPHYSIOLOGY, V46, P1, DOI 10.1111/j.1469-8986.2008.00702.x
   Brewin CR, 2014, PSYCHOL BULL, V140, P69, DOI 10.1037/a0033722
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Carleton RN, 2019, CAN J BEHAV SCI, V51, P181, DOI 10.1037/cbs0000127
   Difede J, 2002, CYBERPSYCHOL BEHAV, V5, P529, DOI 10.1089/109493102321018169
   Difede J, 2007, J CLIN PSYCHIAT, V68, P1639, DOI 10.4088/JCP.v68n1102
   Elzinga BM, 2003, NEUROPSYCHOPHARMACOL, V28, P1656, DOI 10.1038/sj.npp.1300226
   First M, 1997, STRUCTURED CLIN INTE
   Fortuna L, 2007, ADV IND CONTROL, P183
   Gerardi M, 2010, CURR PSYCHIAT REP, V12, P298, DOI 10.1007/s11920-010-0128-4
   Giosan C, 2009, J ANXIETY DISORD, V23, P557, DOI 10.1016/j.janxdis.2008.11.004
   Green B.L., 1993, Instrumentation in stress, trauma, and adaptation, P366
   Holmes EA, 2008, ACTA PSYCHOL, V127, P553, DOI 10.1016/j.actpsy.2007.11.002
   Iyadurai L, 2019, CLIN PSYCHOL REV, V69, P67, DOI 10.1016/j.cpr.2018.08.005
   James EL, 2016, CLIN PSYCHOL REV, V47, P106, DOI 10.1016/j.cpr.2016.04.010
   Katz LS, 2012, VIOLENCE VICTIMS, V27, P487, DOI 10.1891/0886-6708.27.4.487
   Liberzon I, 1999, NEUROPSYCHOPHARMACOL, V21, P40, DOI 10.1016/S0893-133X(98)00128-6
   Lindner P, 2019, J ANXIETY DISORD, V61, P45, DOI 10.1016/j.janxdis.2018.07.003
   Malta LS, 2020, MEMORY, V28, P724, DOI 10.1080/09658211.2020.1770289
   Malta LS, 2008, INNOVATIONS EXPT PSY
   McEwen BS, 2007, PHYSIOL REV, V87, P873, DOI 10.1152/physrev.00041.2006
   McIsaac HK, 2004, PSYCHOL SCI, V15, P248, DOI 10.1111/j.0956-7976.2004.00660.x
   Mittal VA, 2011, PSYCHIAT RES, V189, P158, DOI 10.1016/j.psychres.2011.06.006
   Norris FH, 2002, PSYCHIATRY, V65, P207, DOI 10.1521/psyc.65.3.207.20173
   Pause BM, 2013, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00033
   Pineles SL, 2018, POSTTRAUMATIC STRES, DOI DOI 10.1093/MED/9780190259440.001.0001/MED-9780190259440-CHAPTER-22
   Pole N, 2007, PSYCHOL BULL, V133, P725, DOI 10.1037/0033-2909.133.5.725
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Reger GM, 2016, J CONSULT CLIN PSYCH, V84, P946, DOI 10.1037/ccp0000134
   Rizzo AA, 2009, STUD HEALTH TECHNOL, V142, P277, DOI 10.3233/978-1-58603-964-6-277
   Roemer L, 1998, J TRAUMA STRESS, V11, P597, DOI 10.1023/A:1024469116047
   Rumball F, 2013, STUDYING INDIVIDUAL
   Rumball F, 2011, PSYCHOPHYSIOLOGY, V48, pS113
   Schweizer T, 2018, J ANXIETY DISORD, V59, P42, DOI 10.1016/j.janxdis.2018.08.005
   Street AE, 2009, CLIN PSYCHOL REV, V29, P685, DOI 10.1016/j.cpr.2009.08.007
   Weathers F., 1993, INT SOC TRAUM STRESS
   Wisco BE, 2015, CLIN PSYCHOL SCI, V3, P956, DOI 10.1177/2167702614560745
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zimand E., 2001, IMMERSION QUESTIONNA
NR 48
TC 11
Z9 11
U1 2
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 293
EP 302
DI 10.1007/s10055-020-00455-5
EA JUL 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000545285900001
DA 2024-07-18
ER

PT J
AU Bunz, U
   Seibert, J
   Hendrickse, J
AF Bunz, Ulla
   Seibert, Jonmichael
   Hendrickse, Joshua
TI From TAM to AVRTS: development and validation of the attitudes toward
   Virtual Reality Technology Scale
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Scale development; Enjoyment; Attitudes; Technology
   Acceptance Model (TAM); Attitudes toward Virtual Reality Technology
   Scale (AVRTS)
ID USER ACCEPTANCE; ENJOYMENT; SATISFACTION; READINESS; MODEL
AB To address a deficiency of scales measuring attitudes toward virtual reality technology, the Attitudes toward Virtual Reality Technology Scale (AVRTS) was developed following a three-step procedure. Items were generated based on literature and in a focus group pilot study (n = 20). Using factor analysis with maximum likelihood extraction and direct oblimin rotation, the initial scale was created after administration of these items (n = 314) and further refined after a second survey (n = 473). In the final solution, a total of 22 items clustered into a three-factor solution with the factors being "ease of use" (alpha = .858), "usefulness" (alpha = .857), and "enjoyment" (alpha = .919) and overall reliability of .910. Construct validity was established by correlating the AVRTS with the Technology Readiness Index and an access barrier scale, and internal validity was established by correlating the scale with its sub-scales.
C1 [Bunz, Ulla; Seibert, Jonmichael; Hendrickse, Joshua] Florida State Univ, Sch Commun, 296 Champ Way,Suite C-3100, Tallahassee, FL 32306 USA.
C3 State University System of Florida; Florida State University
RP Bunz, U (corresponding author), Florida State Univ, Sch Commun, 296 Champ Way,Suite C-3100, Tallahassee, FL 32306 USA.
EM ubunz@fsu.edu; jcs16b@my.fsu.edu; jah14r@my.fsu.edu
OI Bunz, Ulla/0000-0003-1595-8740
CR AJZEN I, 1977, PSYCHOL BULL, V84, P888, DOI 10.1037/0033-2909.84.5.888
   [Anonymous], ANN M AM ED RES ASS
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Bowman ND, 2016, J GAMING VIRTUAL WOR, V8, P83, DOI 10.1386/jgvw.8.1.83_1
   Bracken C., 2010, Immersed in media: Telepresence in everyday life, P5
   Chau PYK, 2002, INFORM MANAGE-AMSTER, V39, P297, DOI 10.1016/S0378-7206(01)00098-2
   Comfrey A., 1992, 1 COURSE FACTOR ANAL
   Davis F. D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results, DOI DOI 10.1016/S0378-7206(01)00143-4
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Fabrigar LR, 1999, PSYCHOL METHODS, V4, P272, DOI 10.1037/1082-989X.4.3.272
   Fetscherin M, 2008, J ELECTRON COMMER RE, V9, P231
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   GIDLEY S, 2017, BBC
   Gorsuch R.L., 1983, FACTOR ANAL
   Hatcher L, 2013, A step-by-step approach to using SAS for factor analysis and structural equation modeling
   HINKING TR, 1997, SCALE CONSTRUCTION D
   Hu PJH, 2005, J AM SOC INF SCI TEC, V56, P235, DOI 10.1002/asi.20124
   Jetter J, 2018, COMPUT HUM BEHAV, V87, P18, DOI 10.1016/j.chb.2018.04.054
   Küçük S, 2014, EGIT BILIM, V39, P383
   Lanier J., 1992, Interactive Learning International, V8, P275
   Liaw SS, 2003, COMPUT HUM BEHAV, V19, P751, DOI 10.1016/S0747-5632(03)00009-8
   Lin JHT, 2018, NEW MEDIA SOC, V20, P3223, DOI 10.1177/1461444817744850
   Lin JSC, 2007, COMPUT HUM BEHAV, V23, P1597, DOI 10.1016/j.chb.2005.07.006
   Mathieson K., 2001, Data Base for Advances in Information Systems, V32, P86
   McGloin R, 2018, MEDIA PSYCHOL, V21, P486, DOI 10.1080/15213269.2017.1311269
   Moon JW, 2001, INFORM MANAGE-AMSTER, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Osborne J.W., 2004, Pract. Assess., Res., Eval., V9, P2, DOI [DOI 10.7275/QF69-7K43, 10.7275/qf69-7k43]
   Parasuraman A., 2000, J SERV RES-US, V2, P307, DOI DOI 10.1177/109467050024001
   Porter CE, 2006, J BUS RES, V59, P999, DOI 10.1016/j.jbusres.2006.06.003
   PULLEN JP, 2016, VIRTUAL REALITY CES
   Raney AA, 2006, LEA COMMUN SER, P165
   Rese A, 2017, TECHNOL FORECAST SOC, V124, P306, DOI 10.1016/j.techfore.2016.10.010
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Tamborini R, 2010, J COMMUN, V60, P758, DOI 10.1111/j.1460-2466.2010.01513.x
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Walczuch R, 2007, INFORM MANAGE-AMSTER, V44, P206, DOI 10.1016/j.im.2006.12.005
   Wang C.-C., 2008, J CONSUM BEHAV, V7, P101, DOI DOI 10.1002/CB
   WEBSTER A, 2019, PLAYSTATION VR SURPA
   Wiederhold BK, 2016, CYBERPSYCH BEH SOC N, V19, P67, DOI 10.1089/cyber.2016.0012
   Wojciechowski R, 2013, COMPUT EDUC, V68, P570, DOI 10.1016/j.compedu.2013.02.014
   Yi MY, 2003, INT J HUM-COMPUT ST, V59, P431, DOI 10.1016/S1071-5819(03)00114-9
   YI Y, 2003, DIGIT 2003 P, V2
   Zhang XY, 2017, HOWARD J COMMUN, V28, P280, DOI 10.1080/10646175.2016.1270860
NR 46
TC 3
Z9 3
U1 3
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 31
EP 41
DI 10.1007/s10055-020-00437-7
EA MAR 2020
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000522598200001
DA 2024-07-18
ER

PT J
AU Cao, S
   Nandakumar, K
   Babu, R
   Thompson, B
AF Cao, Shi
   Nandakumar, Krithika
   Babu, Raiju
   Thompson, Benjamin
TI Game play in virtual reality driving simulation involving head-mounted
   display and comparison to desktop display
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Driving simulation games; User experience; HMD;
   Simulator sickness; Eye symptoms
ID GASTRIC MYOELECTRIC ACTIVITY; MOTION SICKNESS; PERFORMANCE; ENJOYMENT;
   ISSUES
AB Previous studies have reported the effect of driving simulator games on simulator sickness and eye symptoms experienced by users; however, empirical results regarding the game experience using commercial virtual reality head-mounted displays (VR-HMDs) are lacking. We conducted an experiment where participants played a driving simulator game (Live for Speed) displayed through an Oculus Rift DK2 for up to 120 min. Game play duration was recorded. Game experience was surveyed using questionnaires about simulator sickness, eye symptoms, and game engagement. The results showed that the average game play duration for this specific driving simulation game was approximately 50 min. Simulator sickness was negatively correlated with affordable play duration using the VR-HMD. We also found that age was negatively correlated with game play duration. There were no differences between those who did and did not wear frame glasses. In addition, we compared the VR-HMD game play and traditional desktop LCD game play, in terms of simulator sickness, subjective eye symptoms, game engagement, and game performance. The results showed that VR-HMD game play in the driving simulation game was similar to the experience using the desktop LCD display, except for a moderately increased level of simulator sickness. These findings provide new data about VR-HMD's impact on game play and will inform game designers, players, and researchers for their choices and decisions on proper game duration and the type of devices.
C1 [Cao, Shi] Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada.
   [Nandakumar, Krithika; Babu, Raiju; Thompson, Benjamin] Univ Waterloo, Sch Optometry & Vis Sci, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo; University of Waterloo
RP Cao, S (corresponding author), Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada.
EM shi.cao@uwaterloo.ca
RI Cao, Shi/AAQ-9135-2021
OI Cao, Shi/0000-0002-6448-6674
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [RPIN-05394, RGPAS-477166, RGPIN-2015-04134]
FX This research was supported by Natural Sciences and Engineering Research
   Council of Canada (NSERC) Grants RPIN-05394 and RGPAS-477166 to BT, and
   RGPIN-2015-04134 to SC.
CR Andre JT, 1996, AVIAT SPACE ENVIR MD, V67, P30
   [Anonymous], 2006, P 8 C HUMAN COMPUTER, DOI [10.1145/1152215.1152263, DOI 10.1145/1152215.1152263]
   [Anonymous], 2017, SER GAM APPL HLTH SE, DOI [DOI 10.1109/SEGAH.2017.7939283, 10.1109/SeGAH.2017.7939283]
   Badcoe I., 2000, Virtual Reality, V5, P204, DOI 10.1007/BF01408519
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bridgeman B, 2014, HUM FACTORS, V56, P1472, DOI 10.1177/0018720814533992
   Brockmyer JH, 2009, J EXP SOC PSYCHOL, V45, P624, DOI 10.1016/j.jesp.2009.02.016
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Chaumillon R, 2017, TRANSPORT RES F-TRAF, V47, P42, DOI 10.1016/j.trf.2017.04.003
   Chen C., 1998, Virtual Reality, V3, P223, DOI DOI 10.1007/BF01408702
   Classen S, 2011, AM J OCCUP THER, V65, P179, DOI 10.5014/ajot.2011.000802
   Darty K, 2014, 5 INT C WOM ISS TRAN
   Davis J, 2008, J FIELD ROBOT, V25, P880, DOI 10.1002/rob.20263
   Davis S, 2015, P 11 AUSTR C INT ENT, V27, P30
   Domeyer JE, 2013, ACCIDENT ANAL PREV, V53, P127, DOI 10.1016/j.aap.2012.12.039
   Ebenholtz S.M., 1992, Teleoperators and Virtual Environments, V1, P302, DOI DOI 10.1162/PRES.1992.1.3.302
   Gálvez-García G, 2015, HUM FACTORS, V57, P649, DOI 10.1177/0018720814554948
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Guo C. L. M. S., 2014, THESIS
   Hamel J, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00339
   Helland A, 2016, ACCIDENT ANAL PREV, V94, P180, DOI 10.1016/j.aap.2016.05.008
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   HU SQ, 1989, AVIAT SPACE ENVIR MD, V60, P411
   Jäger M, 2014, MED BIOL ENG COMPUT, V52, P601, DOI 10.1007/s11517-014-1162-x
   Karl I, 2013, IEEE INTEL TRANSP SY, V5, P42, DOI 10.1109/MITS.2012.2217995
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2017, J EXP PSYCHOL-APPL, V23, P85, DOI 10.1037/xap0000107
   Kolasinski E. M., 1995, DTIC DOCUMENT
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   MCCAFFREY RJ, 1980, EXP AGING RES, V6, P555, DOI 10.1080/03610738008258387
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Miyazaki J, 2015, EXP BRAIN RES, V233, P2421, DOI 10.1007/s00221-015-4312-y
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Rau PLP, 2006, CYBERPSYCHOL BEHAV, V9, P396, DOI 10.1089/cpb.2006.9.396
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rosenfield M, 2011, OPHTHAL PHYSL OPT, V31, P502, DOI 10.1111/j.1475-1313.2011.00834.x
   Schell J., 2014, The Art of Game Design: A book of lenses
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Shaw LindsayAlexander., 2015, Australasian Workshop on Health Informatics and Knowledge Management (HIKM), P75
   SITU P, 2013, INVEST OPHTH VIS SCI, V54
   Stanney KM, 1999, APPL ERGON, V30, P27, DOI 10.1016/S0003-6870(98)00039-8
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Ueda Y, 2018, LECT NOTES COMPUT SC, V11112, P228, DOI 10.1007/978-3-319-99426-0_22
   Yoo S, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P247, DOI 10.1145/3079628.3079679
NR 54
TC 14
Z9 15
U1 2
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 503
EP 513
DI 10.1007/s10055-019-00412-x
EA NOV 2019
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000499627000001
DA 2024-07-18
ER

PT J
AU Christopoulos, A
   Conrad, M
   Shukla, M
AF Christopoulos, Athanasios
   Conrad, Marc
   Shukla, Mitul
TI Increasing student engagement through virtual interactions: How?
SO VIRTUAL REALITY
LA English
DT Article
DE Architectures for educational technology systems; Collaborative
   learning; Improving classroom teaching; Interactive learning
   environments; Virtual reality
ID AFFORDANCES; REALITY
AB Our ongoing research is focusing on identifying and taxonomising the elements and the factors that affect learner engagement with virtual worlds when hybrid virtual learning models are used. Our main hypothesis links learner engagement with interactions, both in the virtual world and in the physical classroom. In order to examine this subject, there is an elaboration on and consideration of aspects such as the learners' prior experiences in the use of virtual worlds, their preconceptions about using them as a learning tool and the impact that the instructional designers' choices have on enhancing the opportunities for interactions. In this paper, we examine the impact that the orientation process has on university students who study computer science and have almost no experience in the use of virtual worlds. Our findings suggest that the orientation process contributed positively to students' smooth induction and that resulted in having meaningful and engaging interactions. Furthermore, students' simultaneous coexistence in both environments eliminated the drawbacks of each educational approach and broadened the network of interactions.
C1 [Christopoulos, Athanasios; Conrad, Marc; Shukla, Mitul] Univ Bedfordshire, Sch Comp Sci & Technol, Pk Sq, Luton LU1 3JU, Beds, England.
C3 University of Bedfordshire
RP Christopoulos, A (corresponding author), Univ Bedfordshire, Sch Comp Sci & Technol, Pk Sq, Luton LU1 3JU, Beds, England.
EM athanasios.christopoulos@beds.ac.uk; marc.conrad@beds.ac.uk;
   mitul.shukla@beds.ac.uk
RI Christopoulos, Athanasios/AAV-9293-2020
OI Christopoulos, Athanasios/0000-0002-1809-5525; Shukla,
   Mitul/0000-0003-2774-7086; Conrad, Marc/0000-0003-1796-209X
CR Agresti A, 2007, INTRO CATEGORICAL DA, DOI DOI 10.1002/0470114754
   Akkoyunlu B, 2008, INTERNET HIGH EDUC, V11, P26, DOI 10.1016/j.iheduc.2007.12.006
   Allison C., 2012, P 2 EUR IMM ED SUMM, P1
   Anasol P. R, 2012, P 2 EUR IMM ED SUMM, P171
   [Anonymous], 11 ANN C SUBJ CTR IN
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Bartle R., 2003, Designing Virtual Worlds
   Begg Michael., 2005, Innovate: Journal of Online Education, V1, P6
   Bower M., 2010, ASCILITE 2010 - The Australasian Society for Computers in Learning in Tertiary Education, P129, DOI [10.1016/j.compedu.2015.03.006, DOI 10.1016/J.COMPEDU.2015.03.006]
   Bredl Klaus, 2012, Electronic Journal of Knowledge Management, V10, P15
   Camilleri V, 2013, P 3 INT C LEARN AN K, P230, DOI DOI 10.1145/2460296.2460341
   Carter B, 2012, P 2 EUR IMM IN SUMM, P24
   Chafer J, 2008, P RES LEARN VIRT ENV, P94
   Childs M, 2010, LEARNERS EXPERIENCE
   Christopoulos A., 2013, THESIS U BEDFORDSHIR
   Christopoulos A, 2017, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P323, DOI 10.5220/0006316203230330
   Christopoulos A, 2014, EDUC RES INT, V2014, DOI 10.1155/2014/318317
   Christopoulos A, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION, VOL 1 (CSEDU), P43, DOI 10.5220/0005755700430054
   Cohen L., 2011, RES METHODS ED, V7th
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   de Freitas S, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P43, DOI 10.1109/VS-GAMES.2009.41
   de Freitas S, 2010, BRIT J EDUC TECHNOL, V41, P69, DOI 10.1111/j.1467-8535.2009.01024.x
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Dickey MD, 2005, INTERACT LEARN ENVIR, V13, P121, DOI 10.1080/10494820500173714
   Elliott JB., 2012, Proceedings of the 2nd European immersive initiative summit, P63
   Herbet A., 2012, P 2 EUR IMM ED SUMM, P101
   Hockey A., 2010, W089-Special Track 18th CIB World Building Congress May 2010, P200
   Hoshi K, 2009, STUD HEALTH TECHNOL, V144, P91, DOI 10.3233/978-1-60750-017-9-91
   Huiqin Zhao, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P1407, DOI 10.1109/ICALIP.2010.5684986
   Johnson C M., 2009, Journal for Virtual Worlds Research, V2, P3
   Jones D, 2011, RESEARCHING LEARNING
   Khan A, 2002, BLENDED LEARNING LEA
   Levesque J, 2011, IRT REAL INT C LAV V
   Minocha S., 2008, Learning in Virtual Environments International Conference, P216
   Schrader P. G., 2008, Educational Technology Review, V16, P457
   Sharpe R., 2006, The undergraduate experience of blended e-learning: A review of UK literature and practice
   Shukla M, 2011, P IADIS INT C SOC SP
   Singh H.Reed., 2001, A white paper: Achieving success with blended learning
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Strauss E, 1998, CLIN ORTHOP RELAT R, P2
   Vosinakis S., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P112, DOI 10.1109/VS-GAMES.2011.22
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Williams C., 2002, J FURTHER HIGHER ED, V26, P263, DOI DOI 10.1080/03098770220149620
NR 43
TC 46
Z9 50
U1 1
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 353
EP 369
DI 10.1007/s10055-017-0330-3
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600007
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chapoulie, E
   Marchal, M
   Dimara, E
   Roussou, M
   Lombardo, JC
   Drettakis, G
AF Chapoulie, Emmanuelle
   Marchal, Maud
   Dimara, Evanthia
   Roussou, Maria
   Lombardo, Jean-Christophe
   Drettakis, George
TI Evaluation of direct manipulation using finger tracking for complex
   tasks in an immersive cube
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Direct manipulation; Immersive cube; Finger tracking
ID INTERFACES
AB A solution for interaction using finger tracking in a cubic immersive virtual reality system (or immersive cube) is presented. Rather than using a traditional wand device, users can manipulate objects with fingers of both hands in a close-to-natural manner for moderately complex, general purpose tasks. Our solution couples finger tracking with a real-time physics engine, combined with a heuristic approach for hand manipulation, which is robust to tracker noise and simulation instabilities. A first study has been performed to evaluate our interface, with tasks involving complex manipulations, such as balancing objects while walking in the cube. The user's finger-tracked manipulation was compared to manipulation with a 6 degree-of-freedom wand (or flystick), as well as with carrying out the same task in the real world. Users were also asked to perform a free task, allowing us to observe their perceived level of presence in the scene. Our results show that our approach provides a feasible interface for immersive cube environments and is perceived by users as being closer to the real experience compared to the wand. However, the wand outperforms direct manipulation in terms of speed and precision. We conclude with a discussion of the results and implications for further research.
C1 [Chapoulie, Emmanuelle; Drettakis, George] Inria, REVES, Sophia Antipolis, France.
   [Marchal, Maud] Inria, Hybrid, Rennes, France.
   [Marchal, Maud] IRISA INSA, Rennes, France.
   [Dimara, Evanthia; Roussou, Maria] Univ Athens, Athens, Greece.
   [Roussou, Maria] Makebelieve Design & Consulting, Athens, Greece.
   [Lombardo, Jean-Christophe] Inria, Sophia Antipolis, France.
C3 Inria; Inria; Universite de Rennes; Universite de Rennes; National &
   Kapodistrian University of Athens; Inria
RP Chapoulie, E (corresponding author), Inria, REVES, Sophia Antipolis, France.
EM george.drettakis@inria.fr
RI Roussou, Maria/AAD-7828-2019
OI Lombardo, Jean-Christophe/0000-0002-9656-4219; Roussou,
   Maria/0000-0002-2826-162X; Dimara, Evanthia/0000-0001-5212-7888
FU Regional Council of Provence Alpes-Cote d'Azur; EU project VERVE
FX The authors wish to thank Rachid Guerchouche for his help in many
   aspects of the project, also Theophanis Tsandilas, Martin Hachet,
   Anatole Lecuyer, Peter Vangorp and Sylvain Duchene for their help and
   their useful comments. We also thank all the participants of the study.
   This work was supported in part by the Regional Council of Provence
   Alpes-Cote d'Azur and the EU project VERVE
   (http://www.verveconsortium.eu). The textures in the VEs come from the
   following websites: http://archivetextures.net,
   http://www.freestockphotos.biz, http://www.flickr.com,
   http://www.defconx.de, http://www.public-domain-image.com,
   http://images.meredith.com, http://onlyhdwallpapers.com,
   http://www.merveilles-russie.com and http://www.zastavki.com.
CR Agarawala A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1283
   Aleotti J, 2011, VIRTUAL REAL-LONDON, V15, P41, DOI 10.1007/s10055-009-0145-y
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Borst CW, 2005, P IEEE VIRT REAL ANN, P91
   Bowman DA, 2008, IEEE COMPUT GRAPH, V28, P20, DOI 10.1109/MCG.2008.109
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Cabral M.C., 2005, P 2005 LATIN AM C HU, DOI DOI 10.1145/1111360.1111370
   Dipietro L, 2008, IEEE T SYST MAN CY C, V38, P461, DOI 10.1109/TSMCC.2008.923862
   Frohlich B, 2000, IEEE VR 2000
   Heumer G, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P19
   Hilliges O., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '12, P2421
   Hirota K, 2003, P IEEE VIRT REAL ANN, P232, DOI 10.1109/VR.2003.1191144
   Holz D, 2008, J VIRTUAL REAL BROAD, V5, P1860
   Jacobs J., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P43, DOI 10.1109/3DUI.2012.6184183
   Jacobs J, 2011, IEEE VR 2011 IEEE
   Koons D.B., 1994, Conference on Human Factors in Computing Systems (Boston, Massachusetts, USA, April 24-28, 1994), P453, DOI DOI 10.1145/259963.260487
   Latoschik M. E., 2001, Proceedings AFRIGRAPH 2001. 1st International Conference on Computer Graphics, Virtual Reality and Visualisation, P95, DOI 10.1145/513867.513888
   Latoschik ME, 1998, IEEE IND ELEC, P2028, DOI 10.1109/IECON.1998.724030
   McMahan RP, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P11, DOI 10.1109/3DUI.2010.5444727
   Moehring M, 2011, IEEE T VIS COMPUT GR, V17, P1195, DOI 10.1109/TVCG.2011.36
   O'Hagan RG, 2002, INTERACT COMPUT, V14, P231, DOI 10.1016/S0953-5438(01)00050-9
   Ortega M, 2007, IEEE T VIS COMPUT GR, V13, P458, DOI 10.1109/TVCG.2007.1028
   Prachyabrued M., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P39, DOI 10.1109/3DUI.2012.6184182
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sturman D. J., 1989, UIST. Proceedings of the ACM SIGGRAPH Symposium on User Interface Software and Technology, P19, DOI 10.1145/73660.73663
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Ullmann T, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P373, DOI 10.1109/PCCGA.2000.883961
   Wang RY., 2009, ACM transactions on graphics (TOG), V28, P1, DOI DOI 10.1145/1531326.1531369
   Wexelblatt A., 1995, ACM Trans. on Computer-Human Interaction, V2, P179
   Wilson AD, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P67, DOI 10.1145/1449715.1449728
NR 31
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2014
VL 18
IS 3
BP 203
EP 217
DI 10.1007/s10055-014-0246-0
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HR
UT WOS:000340621900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Essabbah, M
   Bouyer, G
   Otmane, S
   Mallem, M
AF Essabbah, Mouna
   Bouyer, Guillaume
   Otmane, Samir
   Mallem, Malik
TI A framework to design 3D interaction assistance in constraints-based
   virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; 3D interaction; Framework; Complex environments;
   Constraints; Assistance model; Virtual fixtures
ID REALITY; MOTION
AB The equilibrium of complex systems often depends on a set of constraints. Thus, credible virtual reality modeling of these systems must respect these constraints, in particular for 3D interactions. In this paper, we propose a generic framework for designing assistance to 3D user interaction in constraints-based virtual environment that associates constraints, interaction tasks and assistance tools, such as virtual fixtures (VFs). This framework is applied to design assistance tools for molecular biology analysis. Evaluation shows that VF designed using our framework improve effectiveness of the manipulation task.
C1 [Essabbah, Mouna] French Natl Res Agcy, Paris, France.
   [Bouyer, Guillaume; Otmane, Samir; Mallem, Malik] Univ Evry Val dEssonne, IBISC, Evry Courcouronnes, France.
C3 Universite Paris Saclay
RP Essabbah, M (corresponding author), French Natl Res Agcy, Paris, France.
EM mouna.essabbah@gmail.com; Guillaume.Bouyer@ibisc.fr;
   Samir.Otmane@ibisc.fr; Malik.Mallem@ibisc.fr
RI MALLEM, Malik/P-6389-2017
OI MALLEM, Malik/0000-0002-2471-7028; Otmane, Samir/0000-0003-2221-4264
CR Abbott JJ, 2007, SPRINGER TRAC ADV RO, V28, P49
   [Anonymous], P 2 INT WORKSH PROC
   Bowman D. A., 1998, Virtual Reality, V3, P120, DOI 10.1007/BF01417673
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman D. A., 1999, Interaction Techniques for Common Tasks in Immersive Virtual Environments: Design, Evaluation, and Application
   BOWMAN DA, 1995, GITGVU9526
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   BROOKS TL, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P886, DOI 10.1109/ROBOT.1992.220184
   Calderon C, 2003, LECT NOTES COMPUT SC, V2733, P112
   Castet J, 2008, LECT NOTES COMPUT SC, V5024, P918, DOI 10.1007/978-3-540-69057-3_115
   Cooper S, 2010, NATURE, V466, P756, DOI 10.1038/nature09304
   Essabbah M, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P880, DOI 10.1109/AICCSA.2009.5069435
   Essabbah M, 2009, LECT NOTES COMPUT SC, V5613, P713, DOI 10.1007/978-3-642-02583-9_77
   Ferey N, 2009, VIRTUAL REAL, V13, P257
   Fernando T., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P147, DOI 10.1145/323663.323686
   Gibson J. J., PERCEIVING ACTING KN
   Gillet A, 2005, STRUCTURE, V13, P483, DOI 10.1016/j.str.2005.01.009
   Guebert C, 2008, P VRIPHYS
   Heyd J, 2009, VIRTUAL REAL-LONDON, V13, P245, DOI 10.1007/s10055-009-0129-y
   JACOBY R, 1994, P SOC PHOTO-OPT INS, V2177, P355, DOI 10.1117/12.173892
   Kalawsky R, 1996, TECHNICAL REPORT
   Kuang AB, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P367, DOI 10.1109/HAPTIC.2004.1287223
   Marayong P, 2003, IEEE INT CONF ROBOT, P1954, DOI 10.1109/ROBOT.2003.1241880
   Marcelino L, 2003, COMPUT GRAPH-UK, V27, P19, DOI 10.1016/S0097-8493(02)00228-5
   Mine M, 1995, TR98018 UNC
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Oakley I, 2002, BCS CONF SERIES, P195
   Otmane S., 2000, Proceedings 33rd Annual Simulation Symposium (SS 2000), P185, DOI 10.1109/SIMSYM.2000.844915
   Ouramdane N., 2006, P 2006 ACM INT C VIR, P137
   Picon F, 2008, LECT NOTES COMPUT SC, V5024, P736, DOI 10.1007/978-3-540-69057-3_95
   Pierce J, 1997, P 1997 S INT 3D GRAP, P33
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Prada R, 2009, VIRTUAL REAL-LONDON, V13, P117, DOI 10.1007/s10055-009-0115-4
   Ren J, 2007, STUD HEALTH TECHNOL, V125, P379
   Rosenberg L, 1992, A054292 USAF
   Simard J, 2012, VIRTUAL REAL-LONDON, V16, P173, DOI 10.1007/s10055-011-0201-2
   Smith G., 2001, P GRAPH INT C OTT ON, P135
   Sternberger L, 2005, IEEE YOUNG VIRT REAL
   Sweller J, 2011, EXPLOR LEARN SCI, P3, DOI 10.1007/978-1-4419-8126-4
NR 39
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2014
VL 18
IS 3
BP 219
EP 234
DI 10.1007/s10055-014-0247-z
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HR
UT WOS:000340621900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Blom, KJ
   Beckhaus, S
AF Blom, Kristopher J.
   Beckhaus, Steffi
TI The design space of dynamic interactive virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual environments; Dynamic interactive VEs; 3D user interaction; VR
   systems
ID REALITY; EXPERIENCE; TIME
AB Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, they can accommodate an infinite number of possibilities. A theoretical work is presented, which decomposes those innumerous possibilities into concepts to help clarify the vast design space and provide insights into future applied research. We propose that what makes environments interesting and engaging is having worlds that are both active and reactive. This article explores the manifestations of those actions and reactions in what we term: dynamic components and interactions. We term worlds containing these dynamic interactive virtual environments (DIVE). An analysis of each component time was performed, with the purpose of providing a theoretical understanding of the respective design spaces. Initially, we collected the myriad possibilities of each component, e. g., the possible kinds of interactions. We point to examples throughout the field to ground and explain concepts presented. We then categorized of each area into taxonomies. The result of the analyses provides insights into the design space of virtual environments, exposes several avenues of research that are yet underexplored, and provides better understandings of ways in which DIVE creation can be supported.
C1 [Blom, Kristopher J.; Beckhaus, Steffi] Univ Hamburg, Dept Informat, D-22527 Hamburg, Germany.
C3 University of Hamburg
RP Blom, KJ (corresponding author), Univ Hamburg, Dept Informat, Vogt Kolln Str 30, D-22527 Hamburg, Germany.
EM blomk@acm.org; sb@steffi.beckhaus.de
RI Beckhaus, Steffi/ABB-2565-2021
OI Blom, Kristopher J./0000-0001-5839-9833
CR [Anonymous], 1992, PRESENCE-VIRTUAL AUG, DOI [10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Beckhaus S., 2007, Concepts and technologies for pervasive games: a reader for pervasive gaming research, V1, P231
   Beckhaus S, 2003, FRAUNHOFER SERIES IN, V6
   Bernier E, 2012, WORKSH SOFTW ENG ARC, P36, DOI [10.1109/SEARIS.2012.6231167, DOI 10.1109/SEARIS.2012.6231167]
   BIERBAUM A, 2000, 4 IMM PROJ TECHN WOR
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Blom K., 2005, IEEE VIRT REAL 2005, P23
   Blom KJ, 2007, IPT EGVE 07 P IPT EU, P295
   Blom KJ, 2009, DYNAMIC INTERACTIVE
   Blom KJ, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P51
   Boussinot F, 2001, WEB3D 01, P69
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Brooks H, 2004, 2004 IEEE SYSTEMS & INFORMATION ENGINEERING DESIGN SYMPOSIUM, P71
   Bryson S, 1997, COMPUT PHYS, V11, P270
   Cavazza M., 2003, VRST 03, P100, DOI [10.1145/1008653.1008672, DOI 10.1145/1008653.1008672]
   Courtney A., 2003, P ACM SIGPLAN WORKSH, P7, DOI DOI 10.1145/871895.871897
   DACHSELT R, 2003, P 8 INT C 3D WEB TEC, P101
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI DOI 10.2312/EGVE/IPT_EGVE2005/201-209
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Difede J, 2007, J CLIN PSYCHIAT, V68, P1639, DOI 10.4088/JCP.v68n1102
   Elliott C, 1997, INT C FUNCT PROGR, P196
   Emond B, 2010, P 2010 SPRING MIL MO, P1
   Freeman D, 2008, BRIT J PSYCHIAT, V192, P258, DOI 10.1192/bjp.bp.107.044677
   Gorini A, 2009, CYBERPSYCHOL BEHAV, V12, P699, DOI 10.1089/cpb.2009.0192
   Guger C, 2009, CYBERPSYCHOL BEHAV, V12, P84
   Haringer M, 2010, IEEE VR 2010 P IEEE
   Haringer M, 2012, PRESENCE-VIRTUAL AUG, V21, P96
   Hassanpour R., 2008, MCCSIS Proc. Interfaces Hum. Comput. Interact, P125
   Hernando J., 2009, 2009 Second International Conference in Visualisation (VIZ), P36, DOI 10.1109/VIZ.2009.21
   Herrlich M, 2011, LECT NOTES COMPUT SC, V6815, P142, DOI 10.1007/978-3-642-22571-0_15
   Hodges L F, 1999, Cyberpsychol Behav, V2, P7, DOI 10.1089/cpb.1999.2.7
   Hoffman HG, 2001, CYBERPSYCHOL BEHAV, V4, P527, DOI 10.1089/109493101750527088
   Jiménez P, 2001, COMPUT GRAPH-UK, V25, P269, DOI 10.1016/S0097-8493(00)00130-8
   Kallmann M., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P124, DOI 10.1145/323663.323683
   Konieczny J, 2008, LECT NOTES COMPUT SC, V5358, P998, DOI 10.1007/978-3-540-89639-5_95
   Kulik A, 2009, IEEE COMPUT GRAPH, V29, P22, DOI 10.1109/MCG.2009.115
   Mateas M., 2003, P GAM DEV C GAM DES, P1
   McLay RN, 2010, CYBERPSYCHOL BEHAV S, V13, P3
   MESING B, 2006, P ACM WEB3D 2006 C
   Misra S, 2008, PRESENCE-VIRTUAL AUG, V17, P463, DOI 10.1162/pres.17.5.463
   Pape D, 1998, SIGGRAPH 98 ACM SIGG, P116
   Rehn GD, 2004, PROCEEDINGS OF THE 2004 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1713
   Reiley CE, 2011, SURG ENDOSC, V25, P356, DOI 10.1007/s00464-010-1190-z
   Richard P, 2012, PRESENCE-TELEOP VIRT, V21, P321, DOI 10.1162/PRES_a_00116
   Rizzo A, 2011, PSYCHOSOC STRES, P183
   Roussos M., 1997, Computer Graphics, V31, P62, DOI 10.1145/262171.262264
   Salzmann H, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P127, DOI 10.1109/VR.2009.4811011
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schroder-Kroll R, 2008, P 5 WORKSH VIRT ERW, P57
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Singhal S., 1999, Networked Virtual Environments
   Slater M, 2009, ANU PSICOL, V40, P193
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steed A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P103, DOI 10.1109/TRIDUI.2006.1618279
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Takatalo J, 2008, COMPUT HUM BEHAV, V24, P1, DOI 10.1016/j.chb.2006.11.003
   van Dam A, 2000, IEEE COMPUT GRAPH, V20, P26, DOI 10.1109/38.888006
   van der Meijden OAJ, 2009, SURG ENDOSC, V23, P1180, DOI 10.1007/s00464-008-0298-x
   Wan ZY, 2000, ACM SIGPLAN NOTICES, V35, P242, DOI 10.1145/358438.349331
   Wu W., 2009, MM 09, P481, DOI DOI 10.1145/1631272.1631338
   Xian-Yi C, 2011, LECT NOTES ELECT ENG, V97, P517
   Yang U, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P150, DOI 10.1109/CW.2010.68
   Yannakakis GN, 2009, IEEE T COMP INTEL AI, V1, P121, DOI 10.1109/TCIAIG.2009.2024533
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
NR 66
TC 15
Z9 16
U1 2
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2014
VL 18
IS 2
BP 101
EP 116
DI 10.1007/s10055-013-0232-y
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HV
UT WOS:000340622300002
DA 2024-07-18
ER

PT B
AU Kim, JJ
   Kim, J
AF Kim, Jae-Jin
   Kim, Joseph
BE Kim, JJ
TI Virtual Reality-Based Assessment of Social Skills and Its Application to
   Mental Illnesses
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID INTERPERSONAL DISTANCE; CLINICAL-TRIAL; SCHIZOPHRENIA; CONSEQUENCES;
   IMPROVEMENT; COMPETENCE; BEHAVIORS; COGNITION; STIGMA; GAZE
C1 [Kim, Jae-Jin] Yonsei Univ, Dept Psychiat, Seoul 120749, South Korea.
   [Kim, Joseph] Vanderbilt Univ, Dept Psychol, Nashville, TN 37240 USA.
C3 Yonsei University; Vanderbilt University
RP Kim, JJ (corresponding author), Yonsei Univ, Dept Psychiat, Seoul 120749, South Korea.
CR Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bedell J, 1998, PSYCHIAT RES, V78, P197, DOI 10.1016/S0165-1781(98)00018-3
   Bellack A.S., 1997, Social skills training for schizophrenia
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Brune M, 2010, PSYCHIAT RES
   Buchanan RW, 2005, SCHIZOPHRENIA BULL, V31, P5, DOI 10.1093/schbul/sbi020
   Chun JY, 2007, KOREAN J SCHIZOPHR R, V10, P62
   Couture SM, 2006, SCHIZOPHRENIA BULL, V32, pS44, DOI 10.1093/schbul/sbl029
   Dreer LE, 2005, WILEY SER FOREN CLIN, P67, DOI 10.1002/9780470713488.ch4
   Han K, 2009, COMPUT BIOL MED, V39, P173, DOI 10.1016/j.compbiomed.2008.12.002
   Harvey PD, 2007, SCHIZOPHRENIA BULL, V33, P1138, DOI 10.1093/schbul/sbm040
   Harvey PD, 2006, AM J PSYCHIAT, V163, P1918, DOI 10.1176/appi.ajp.163.11.1918
   HAYDUK LA, 1983, PSYCHOL BULL, V94, P293, DOI 10.1037/0033-2909.94.2.293
   Kim E, 2009, J NERV MENT DIS, V197, P412, DOI 10.1097/NMD.0b013e3181a61c3d
   Ku J, 2005, CYBERPSYCHOL BEHAV, V8, P493, DOI 10.1089/cpb.2005.8.493
   Ku J, 2007, CYBERPSYCHOL BEHAV, V10, P567, DOI 10.1089/cpb.2007.9989
   Ku J, 2006, CYBERPSYCHOL BEHAV, V9, P531, DOI 10.1089/cpb.2006.9.531
   Link BG, 2001, PSYCHIATR SERV, V52, P1621, DOI 10.1176/appi.ps.52.12.1621
   McKibbin CL, 2004, SCHIZOPHR RES, V72, P53, DOI 10.1016/j.schres.2004.09.011
   Morris JP, 2005, J COGNITIVE NEUROSCI, V17, P1744, DOI 10.1162/089892905774589253
   Nechamkin Y, 2003, INT J SOC PSYCHIATR, V49, P166, DOI 10.1177/00207640030493002
   Nezu AM, 2004, BEHAV THER, V35, P1, DOI 10.1016/S0005-7894(04)80002-9
   Park IH, 2009, PSYCHIATRY, V72, P79, DOI 10.1521/psyc.2009.72.1.79
   Park KM, 2009, HUM PSYCHOPHARM CLIN, V24, P619, DOI 10.1002/hup.1071
   Park KM, 2009, NEUROSCI LETT, V459, P35, DOI 10.1016/j.neulet.2009.04.059
   Park SH, 2009, PSYCHIAT RES, V169, P197, DOI 10.1016/j.psychres.2008.06.039
   Pelphrey KA, 2005, BRAIN, V128, P1038, DOI 10.1093/brain/awh404
   Pelphrey KA, 2004, PSYCHOL SCI, V15, P598, DOI 10.1111/j.0956-7976.2004.00726.x
   Rüsch N, 2005, EUR PSYCHIAT, V20, P529, DOI 10.1016/j.eurpsy.2005.04.004
   Song M, 2010, J KOREAN NE IN PRESS
   Tarr MJ, 2002, NAT NEUROSCI, V5, P1089, DOI 10.1038/nn948
NR 31
TC 6
Z9 8
U1 0
U2 2
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 485
EP 500
D2 10.5772/553
PG 16
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400024
DA 2024-07-18
ER

PT B
AU Klapan, I
   Raos, P
   Galeta, T
   Simicic, L
   Lukinovic, J
   Vranjes, Z
   Males, J
   Belina, S
   Cuk, V
AF Klapan, Ivica
   Raos, Pero
   Galeta, Tomislav
   Simicic, Ljubimko
   Lukinovic, Juraj
   Vranjes, Zeljko
   Males, Josip
   Belina, Stanko
   Cuk, Viseslav
BE Kim, JJ
TI Application of Advanced Virtual Reality and 3D Computer Assisted
   Technologies in Computer Assisted Surgery and Tele-3D-computer Assisted
   Surgery in Rhinology
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID PARANASAL SINUSES; MAXILLOFACIAL SURGERY; ENDOSCOPY; TELESURGERY;
   EXPERIENCE; NOSE
C1 [Klapan, Ivica] Klapan Med Grp Polyclin, Zagreb, Croatia.
   [Klapan, Ivica; Vranjes, Zeljko] Univ Osijek, Fac Med, Osijek, Croatia.
   [Raos, Pero; Galeta, Tomislav] Univ Osijek, Mech Engn Fac Slavonski Brod, Osijek, Croatia.
   [Simicic, Ljubimko] Univ Zagreb, Dept Phys, Zagreb 41000, Croatia.
   [Lukinovic, Juraj] Univ Zagreb, Fac Med, ENT Dept, Zagreb 41000, Croatia.
   [Vranjes, Zeljko; Males, Josip] Univ Osijek, Fac Med, ENT Dept, Osijek, Croatia.
   [Belina, Stanko; Cuk, Viseslav] Gen Hosp Zabok, Div Radiol & Otorhinolaryngol, Zabok, Croatia.
C3 University of JJ Strossmayer Osijek; University of Slavonski Brod;
   University of JJ Strossmayer Osijek; University of Zagreb; University of
   Zagreb; University of JJ Strossmayer Osijek
RP Klapan, I (corresponding author), Klapan Med Grp Polyclin, Zagreb, Croatia.
RI Galeta, Tomislav/I-9196-2012
OI Galeta, Tomislav/0000-0002-0770-5447
CR Aleid W., 2009, BRIT J ORAL IN PRESS
   Anon JB, 1998, LARYNGOSCOPE, V108, P949, DOI 10.1097/00005537-199807000-00001
   Belina S., 2009, COLLEGIUM ANTROPOL, V33, P115
   Belina S, 2008, COLLEGIUM ANTROPOL, V32, P887
   Burtscher J, 1998, Comput Aided Surg, V3, P27, DOI 10.1002/(SICI)1097-0150(1998)3:1<27::AID-IGS4>3.3.CO;2-H
   Caversaccio M, 2003, AM J RHINOL, V17, P283, DOI 10.1177/194589240301700506
   Di Rienzo L, 2003, ANN OTO RHINOL LARYN, V112, P139, DOI 10.1177/000348940311200206
   Ecke U, 1998, Comput Aided Surg, V3, P45, DOI 10.1002/(SICI)1097-0150(1998)3:1<45::AID-IGS7>3.3.CO;2-C
   Elolf E, 1998, Comput Aided Surg, V3, P89, DOI 10.3109/10929089809148134
   Galeta T, 2008, STROJ VESTN-J MECH E, V54, P725
   Hamadeh A, 1998, Comput Aided Surg, V3, P11, DOI 10.3109/10929089809148123
   Hassfeld S, 1998, Comput Aided Surg, V3, P183, DOI 10.3109/10929089809148143
   Hauser R., 1997, MED ROBOTICS COMPUT, P327
   HOLTEL MR, 1999, OTOLARYNGOL HEAD NEC, V121, P181
   Johnson E, 2007, SOC STUD SCI, V37, P585, DOI 10.1177/0306312706072179
   Keeve E, 1998, Comput Aided Surg, V3, P228
   Kenny T., 1999, OTOLARYNGOL HEAD NEC, V121, P111
   Klapan I, 1999, INT CONGR SER, V1191, P784
   Klapan I., 2002, AM J OTOLARYNG, V23, P27
   Klapan I., 2002, OTOLARYNGOL HEAD NEC, V127, P549
   Klapan I., 1997, 16 WORLD C OT HEAD N, P1543
   Klapan I., 1996, 3 EUFOS BOL, V2, P83
   Klapan I., 2002, J TELEMED TELECARE, V8, P125
   Klapan I, 2008, COLLEGIUM ANTROPOL, V32, P217
   Klapan Ivica, 2006, Ear Nose Throat J, V85, P318
   Klapan Ivica, 2001, Orbit, V20, P35, DOI 10.1076/orbi.20.1.35.2645
   Klimek L, 1998, Comput Aided Surg, V3, P194, DOI 10.1002/(SICI)1097-0150(1998)3:4<194::AID-IGS10>3.0.CO;2-R
   KNEZOVIC J, 2007, COLLEGIUM ANTROPOL, V31, P315
   Mann W, 1998, Comput Aided Surg, V3, P202, DOI 10.1002/(SICI)1097-0150(1998)3:4<202::AID-IGS11>3.0.CO;2-F
   MLADINA R, 1995, AM J OTOLARYNG, V16, P276, DOI 10.1016/0196-0709(95)90158-2
   Olson G., 1999, OTOLARYNGOL HEAD NEC, V121, P187
   Petzold R, 1999, COMPUT MED IMAG GRAP, V23, P277, DOI 10.1016/S0895-6111(99)00025-7
   Raos P., 2004, P 2 CROAT C TEL INT, P74
   Risavi R, 1998, INT J PEDIATR OTORHI, V43, P271, DOI 10.1016/S0165-5876(98)00021-4
   Robb RA, 2000, COMPUT MED IMAG GRAP, V24, P133, DOI 10.1016/S0895-6111(00)00014-8
   Rubino F, 2002, BRIT MED J, V324, P612, DOI 10.1136/bmj.324.7337.612
   Satava RM, 1996, ARCH SURG-CHICAGO, V131, P401
   Schlag PM, 1998, CHIRURG, V69, P1134, DOI 10.1007/s001040050550
   Sezeur A, 1998, ANN CHIR, V52, P403
   Simicic LJ, 1998, E.R.S. & I.S.I.A.N. MEETING '98, P281
   Stewart MG., 1999, OTOLARYNGOL HEAD NEC, V121, P110
   Tao XJ, 2003, CHINESE MED J-PEKING, V116, P679
   Thrall JH., 1999, DIAGN IMAGING EUR, V15, P30
   Urban V, 1998, Comput Aided Surg, V3, P205, DOI 10.3109/10929089809148147
   Vannier MW, 1996, RADIOL CLIN N AM, V34, P545
   Vibert E, 2003, ARCH SURG-CHICAGO, V138, P1002, DOI 10.1001/archsurg.138.9.1002
   Vinas F C, 1997, Comput Aided Surg, V2, P257, DOI 10.3109/10929089709148115
   WICKHAM JEA, 1994, BRIT MED J, V308, P193, DOI 10.1136/bmj.308.6922.193
   Winder J, 2005, J ORAL MAXIL SURG, V63, P1006, DOI 10.1016/j.joms.2005.03.016
NR 49
TC 0
Z9 0
U1 0
U2 2
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 291
EP 324
D2 10.5772/553
PG 34
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400015
DA 2024-07-18
ER

PT J
AU Esquer, JEM
   López, GL
AF Esquer, Jesus Emmanuel Montoya
   Lara Lopez, Graciela
TI Wordsphere: virtual reality text input interface
SO VIRTUAL REALITY
LA English
DT Article
DE Text entry; Qwerty paradigm; User input; Virtual reality; Natural
   language processing
AB In recent years, virtual reality has moved from a fantasy or science fiction theme to a reality increasingly closer to our homes and computers. As is the case of various technological advances, from military and scientific use to casual and routine use, which are increasingly adapted to day-to-day use cases, as is observed with the announcement of a new fashionable term, the metaverse. In the same way, this possibility today in the sight of innovators, entrepreneurs, merchants, and businesspeople, among others, begins to generate applications that show benefits in different branches such as education, medicine, psychology, human resources, real estate, tourism. The detail is that within the innovation, very little is being done for an improvement in text input, which generates a stagnation for continuing with a method of capturing text, even already known with lack of intuition and not optimal, such as the provided by the QWERTY keyboard. This article presents a proposal for a new text input method, a three-dimensional (3D) text input prototype focused on immersion in virtual reality, Wordsphere, which takes advantage of the need for technological adoption for novice users in virtual reality and, in turn, leaves on the table future lines of work and research.
C1 [Esquer, Jesus Emmanuel Montoya; Lara Lopez, Graciela] Univ Guadalajara, CUCEI, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
C3 Universidad de Guadalajara
RP López, GL (corresponding author), Univ Guadalajara, CUCEI, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
EM emmanuel.montoyae@gmail.com; graciela.lara@academicos.udg.mx
OI Lara Lopez, Graciela/0000-0003-2766-8134
CR [Anonymous], 2012, Foundations and Trends® in Human-Computer Interaction, DOI [DOI 10.1561/1100000012, 10.1561/1100000012]
   Barrero LA, 2017, GIJON, P1
   Besada J, 2013, DESIGNING BETTER TOU
   Buzing P, 2003, COMP DIFFERENT KEYBO, P901
   Conesa F, 1999, FILOSOFIA LENGUAJE, P19
   Doug Engelbart Institute, 2008, HIST 1S KEYS
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Fashimpaur Jacqui, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382888
   Grossman T., 2015, P 17 INT C HUMAN COM, P144, DOI DOI 10.1145/2785830.2785867
   Jiang HY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143063
   Jimenez JG., 2017, PROTOTYPE TEXT INPUT
   Klima Martin, 2011, Human Interface and the Management of Information. Interacting with Information. Proceedings Symposium on Human Interface 2011. Held as Part of HCI International 2011, P435, DOI 10.1007/978-3-642-21793-7_49
   Lyons K, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P94, DOI 10.1109/ISWC.2004.19
   Markussen A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1073, DOI 10.1145/2556288.2556964
   Merlin Bruno, 2013, Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8009, P205, DOI 10.1007/978-3-642-39188-0_22
   Moreau G., 2018, VIRTUAL REALITY AUGM
   NORMAN DA, 1982, HUM FACTORS, V24, P509, DOI 10.1177/001872088202400502
   Reese S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1418
   Rosenberg R, 1999, IEEE T SYST MAN CY C, V29, P186, DOI 10.1109/5326.760563
   Simeonov, 2020, EC ALTERNAT, V2, P300
   Whitmire Eric, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130978
   Zhenyu Gu, 2015, Human-Computer Interaction. Interaction Technologies. 17th International Conference, HCI International 2015. Proceedings: LNCS 9170, P35, DOI 10.1007/978-3-319-20916-6_4
NR 22
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2769
EP 2785
DI 10.1007/s10055-023-00842-8
EA AUG 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001043654500001
DA 2024-07-18
ER

PT J
AU Badger, JR
   Rovira, A
   Freeman, D
   Bowes, L
AF Badger, Julia R.
   Rovira, Aitor
   Freeman, Daniel
   Bowes, Lucy
TI Developing a virtual reality environment for educational and therapeutic
   application to investigate psychological reactivity to bullying
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Bullying; Adolescents; Psychological reactivity;
   Depression; Anxiety
ID PEER VICTIMIZATION; ANXIETY; CHILDREN; SCHOOL; METAANALYSIS; DEPRESSION;
   VALIDATION; CONTEXTS; SYMPTOMS
AB Understanding how bullying victimisation influences cognitive and emotional processes may help to direct early intervention to prevent the development of psychopathology. In a convenience sample of 67 female adolescents, we assessed the potential of a newly developed classroom-set bullying experience in virtual reality (VR) to evoke psychological reactions. Two VR experiences were co-developed with young people, one neutral and one hostile (bullying). Participants were matched and assigned to a condition based on measures of anxiety, depression, paranoia, and previous bullying, before experiencing either the neutral or hostile scenario. Before and after the VR session, participants completed measures of negative affect and levels of distress. All participants remained immersed for the whole duration, which supports the acceptability of using these VR experiences with more vulnerable participants. Those experiencing the hostile version reported greater negative affect post-immersion compared to those experiencing the neutral version (p = .018; d = 0.61). Although non-significant, a similar outcome was found regarding distress (p = .071; d = 0.37). Whilst we did not find a significant relationship between pre-existing internalisation on negative affect and distress, our sample was limited by containing adolescents with relatively low levels of previous bullying experience. Yet we still found evidence that the VR scenario evoked bullying-related psychological reactions. Further testing with a more representative groups of adolescents, especially those with more experience of bullying, would be advised. The VR scenario could potentially be used in educational and therapeutic settings to enhance empathy towards victimised children or enhance resilience following victimisation.
C1 [Badger, Julia R.; Rovira, Aitor; Freeman, Daniel; Bowes, Lucy] Univ Oxford, Dept Expt Psychol, Oxford, England.
   [Rovira, Aitor; Freeman, Daniel] Oxford Hlth NHS Fdn Trust, Oxford, England.
C3 University of Oxford
RP Badger, JR (corresponding author), Univ Oxford, Dept Expt Psychol, Oxford, England.
EM Julia.badger@psy.ox.ac.uk
RI Bowes, Lucy/K-4373-2012
OI Rovira, Aitor/0000-0001-9308-5784
FU Academy of Medical Sciences [SBF003/1100]; NIHR Oxford Health Biomedical
   Research Centre [BRC-1215-20005]
FX This study was funded by the Academy of Medical Sciences (grant number
   SBF003/1100). AR is supported by the NIHR Oxford Health Biomedical
   Research Centre BRC-1215-20005. DF is an NIHR Senior Investigator.
CR Barreda-Angeles M, 2021, COMPUT EDUC, V161, DOI 10.1016/j.compedu.2020.104065
   Bowes L, 2015, BMJ-BRIT MED J, V350, DOI 10.1136/bmj.h2469
   Chorpita BF, 2000, BEHAV RES THER, V38, P835, DOI 10.1016/S0005-7967(99)00130-8
   Cummings CM, 2014, PSYCHOL BULL, V140, P816, DOI 10.1037/a0034733
   Falconer CJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111933
   Fang D, 2022, CHILD ADOL PSYCH MEN, V16, DOI 10.1186/s13034-022-00490-x
   FENIGSTEIN A, 1992, J PERS SOC PSYCHOL, V62, P129, DOI 10.1037/0022-3514.62.1.129
   Gaffney H., 2019, International Journal of Bullying Prevention, V1, P14, DOI [10.1007/s42380-019-0007-4, DOI 10.1007/S42380-019-0007-4]
   Garandeau CF, 2019, CHILD DEV PERSPECT, V13, P147, DOI 10.1111/cdep.12331
   Gu X, 2023, IEEE T VIS COMPUT GR, V29, P4215, DOI 10.1109/TVCG.2022.3184986
   Hawker DSJ, 2000, J CHILD PSYCHOL PSYC, V41, P441, DOI 10.1111/1469-7610.00629
   Huitsing G, 2020, PREV SCI, V21, P627, DOI 10.1007/s11121-020-01116-4
   Ingram KM, 2019, J ADOLESCENCE, V71, P72, DOI 10.1016/j.adolescence.2018.12.006
   Kalyanaraman S, 2010, J NERV MENT DIS, V198, P437, DOI 10.1097/NMD.0b013e3181e07d66
   Krämer N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00253
   Liu XW, 2021, ACTA PSYCHOL SIN, V53, P170, DOI 10.3724/SP.J.1041.2021.00170
   Modecki KL, 2014, J ADOLESCENT HEALTH, V55, P602, DOI 10.1016/j.jadohealth.2014.06.007
   Nikolaou A, 2022, ANN INT COMMUN ASSOC, V46, P30, DOI 10.1080/23808985.2022.2064324
   Olweus D., 1996, J. Psychopathol. Behav. Assess., DOI [10.1037/t09634-000, DOI 10.1037/T09634-000]
   Przybylski AK, 2017, LANCET CHILD ADOLESC, V1, P19, DOI 10.1016/S2352-4642(17)30011-1
   Ronald A, 2014, SCHIZOPHRENIA BULL, V40, P868, DOI 10.1093/schbul/sbt106
   Sapouna M, 2010, J CHILD PSYCHOL PSYC, V51, P104, DOI 10.1111/j.1469-7610.2009.02137.x
   Schoeler T, 2018, PSYCHOL BULL, V144, P1229, DOI 10.1037/bul0000171
   Stapinski LA, 2014, DEPRESS ANXIETY, V31, P574, DOI 10.1002/da.22270
   Thomas HJ, 2019, BRIT J EDUC PSYCHOL, V89, P75, DOI 10.1111/bjep.12223
   THYER BA, 1984, J BEHAV THER EXP PSY, V15, P3, DOI 10.1016/0005-7916(84)90115-0
   UNICEF, 2019, NUMB END SCH VIOL BU
   Vreeman RC, 2007, ARCH PEDIAT ADOL MED, V161, P78, DOI 10.1001/archpedi.161.1.78
   Wang J, 2009, J ADOLESCENT HEALTH, V45, P368, DOI 10.1016/j.jadohealth.2009.03.021
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Williford A, 2012, J ABNORM CHILD PSYCH, V40, P289, DOI 10.1007/s10802-011-9551-1
   Wolpe J., 1990, PRACTICE BEHAV THERA
   Ye ZX, 2023, BMC PSYCHIATRY, V23, DOI 10.1186/s12888-023-04681-4
NR 33
TC 0
Z9 0
U1 9
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2623
EP 2632
DI 10.1007/s10055-023-00829-5
EA JUL 2023
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001026704200001
PM 37614717
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Buerger, D
   Pastel, S
   Chen, CH
   Petri, K
   Schmitz, M
   Wischerath, L
   Witte, K
AF Buerger, D.
   Pastel, S.
   Chen, C. -h.
   Petri, K.
   Schmitz, M.
   Wischerath, L.
   Witte, K.
TI Suitability test of virtual reality applications for older people
   considering the spatial orientation ability
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Spatial orientation; Age groups; Head-mounted display;
   Sports
ID MEMORY; CHALLENGES; NAVIGATION; DISEASE; AGE
AB Previous studies showed similar spatial orientation ability (SO) between real world (RW) and virtual reality (VR). As the SO deteriorates with age, it is crucial to investigate whether the degradation is similar in VR, as it may affect the use of VR tools for older people, such as in physical therapy. Therefore, we extended our previous study, in which similar SO between RW and VR was measured for younger participants (18-35 years) with a higher age group (> 55 years) to examine the VR's influence on their SO. Two main tests were conducted. In the first test, the participants were blindfolded, asked to rotate (0 degrees, 45 degrees, 180 degrees, 225 degrees) on a fixed starting position, and walk straight to different objects they had memorized before. This test was conducted twice. An ANOVA only revealed a significant interaction between the factors Age (young/old) and Condition (VR/RW) for the 45 degrees-rotation in the second run. Here, both age groups performed similarly in RW, while in VR, greater deviations in the older participants appeared. Nevertheless, the overall Age*Condition-interaction in the first test was not significant. In the second test, subjects were required to walk blindfolded to two objects starting from different positions. The starting position and objects changed three times in each condition but were equal between RW and VR. No interactions between the factors Age and Condition were found (p > 0.05). Both tests showed a similar influence of VR on the SO of both age groups, supporting the usage of VR, regardless of age.
C1 [Buerger, D.; Pastel, S.; Chen, C. -h.; Petri, K.; Schmitz, M.; Wischerath, L.; Witte, K.] Otto von Guericke Univ, Inst Sport Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
C3 Otto von Guericke University
RP Buerger, D (corresponding author), Otto von Guericke Univ, Inst Sport Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
EM dan.buerger@ovgu.de
OI Witte, Kerstin/0000-0001-8711-9335; Burger, Dan/0000-0002-7836-7043
FU Projekt DEAL; German Research Foundation (DFG) [WI 1456/22-1]
FX Open Access funding enabled and organized by Projekt DEAL. Open Access
   funding is enabled and organized by Project DEAL. The study was financed
   by the German Research Foundation (DFG) under Grant No. WI 1456/22-1.
CR Alizadehsalehi S, 2023, SMART SUSTAIN BUILT, V12, P200, DOI 10.1108/SASBE-01-2021-0016
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   Alnagrat A., 2022, J. Hum. Centered Technol, V1, P81, DOI [10.11113/humentech.v1n2.27, DOI 10.11113/HUMENTECH.V1N2.27]
   Battaglia-Mayer A, 2003, CEREB CORTEX, V13, P1009, DOI 10.1093/cercor/13.10.1009
   Bhagavathula Rajaram, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P2056, DOI 10.1177/1541931218621464
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Byrne PA, 2010, J NEUROPHYSIOL, V103, P3054, DOI 10.1152/jn.01008.2009
   Escamilla JC, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10080552
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   de Vries AW, 2018, GAIT POSTURE, V59, P111, DOI 10.1016/j.gaitpost.2017.10.006
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Head D, 2010, BEHAV BRAIN RES, V209, P49, DOI 10.1016/j.bbr.2010.01.012
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Kalová E, 2005, BEHAV BRAIN RES, V159, P175, DOI 10.1016/j.bbr.2004.10.016
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kimura K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18289-8
   Klatzky R. L., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P1
   Luo L, 2008, CAN J PSYCHIAT, V53, P346, DOI 10.1177/070674370805300603
   McAvan AS, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.640188
   McIntyre J, 1998, J NEUROSCI, V18, P8423, DOI 10.1523/JNEUROSCI.18-20-08423.1998
   Merhav M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47971-2
   Mitolo M, 2015, COGN PROCESS, V16, P165, DOI 10.1007/s10339-015-0647-3
   Moffat SD, 2002, BEHAV NEUROSCI, V116, P851, DOI 10.1037//0735-7044.116.5.851
   Morimoto T, 2022, J CLIN MED, V11, DOI 10.3390/jcm11020470
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Newman MC, 2000, AGING NEUROPSYCHOL C, V7, P86, DOI 10.1076/1382-5585(200006)7:2;1-U;FT086
   Pastel S, 2022, VIRTUAL REAL-LONDON, V26, P91, DOI 10.1007/s10055-021-00539-w
   Pastel S, 2021, J MOTOR BEHAV, V53, P693, DOI 10.1080/00222895.2020.1843390
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Pastel S, 2021, VIRTUAL REAL-LONDON, V25, P175, DOI 10.1007/s10055-020-00449-3
   Patterson KK, 2012, GAIT POSTURE, V35, P590, DOI 10.1016/j.gaitpost.2011.11.030
   Petri K., 2020, Am. J. Biomed. Sci, P107, DOI DOI 10.5099/AJ200200107
   Plechatá A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01330
   REGIAN JW, 1992, J COMMUN, V42, P136, DOI 10.1111/j.1460-2466.1992.tb00815.x
   Rodgers M Kirk, 2012, Neurobiol Aging, V33, DOI 10.1016/j.neurobiolaging.2010.07.021
   *Rodrigues J., 2010, J CYBERTHER REHABIL, V3, P275
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Solini HM, 2021, ATTEN PERCEPT PSYCHO, V83, P497, DOI 10.3758/s13414-020-02200-1
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stoyanova S., 2016, EUR SCI J, V12, P88, DOI [10.19044/esj.2016.v12n24p88, DOI 10.19044/ESJ.2016.V12N24P88]
   Taillade M, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02034
   Tuena C, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00093
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Wiener JM, 2020, BEHAV RES METHODS, V52, P630, DOI 10.3758/s13428-019-01264-8
   Wolbers T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00571
   Wolbers T, 2010, TRENDS COGN SCI, V14, P138, DOI 10.1016/j.tics.2010.01.001
NR 48
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1751
EP 1764
DI 10.1007/s10055-023-00775-2
EA FEB 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000937114600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Palmisano, S
   Constable, R
AF Palmisano, Stephen
   Constable, Rikeya
TI Reductions in sickness with repeated exposure to HMD-based virtual
   reality appear to be game-specific
SO VIRTUAL REALITY
LA English
DT Article
DE Motion sickness; Cybersickness; Vection; Virtual reality; Head-mounted
   display; Computer games
ID MOTION SICKNESS; ENVIRONMENT EXPOSURE; INDUCED SYMPTOMS; HABITUATION;
   VECTION; CYBERSICKNESS; ADAPTATION; IMMERSION; DURATION; SIMULATION
AB While head-mounted display (HMD) based gaming is often limited by cybersickness, research suggests that repeated exposure to virtual reality (VR) can reduce the severity of these symptoms. This study was therefore aimed at: (1) examining the exposure conditions required to reduce cybersickness during HMD VR; and (2) learning whether such reductions generalise from one HMD VR game to another. Our participants played two commercially-available HMD VR video games over two consecutive days. Their first exposure to HMD VR on both days was always to a 15-min virtual rollercoaster ride. On Day 1, half of our participants also played a virtual climbing game for 15-min, while the rest of them finished testing early. Participants in the latter group were only exposed to the climbing game late on Day 2. We found that sickness was significantly reduced for our participants on their second exposure to the virtual rollercoaster. However, sickness to the rollercoaster on Day 2 was unaffected by whether they had played the climbing game on Day 1. Sickness during virtual climbing was also unaffected by group differences in exposure to the virtual rollercoaster. This convergent evidence suggested that the reductions in cybersickness produced by repeated exposure to HMD VR were game-specific. While these benefits did not generalise to the second game, two 15-min exposures to the same HMD VR game was sufficient to significantly reduce cybersickness in this study.
C1 [Palmisano, Stephen; Constable, Rikeya] Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
C3 University of Wollongong
RP Palmisano, S (corresponding author), Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
EM stephenp@uow.edu.au
RI Palmisano, Stephen/O-1553-2018
OI Palmisano, Stephen/0000-0002-9140-5681
FU Australian Research Council (ARC) [DP210101475]
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. This research was supported by an Australian Research
   Council (ARC) Discovery Project No. (DP210101475).
CR [Anonymous], 1960, The central Nervous System and Behavior
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Beck J., 2018, P INT C ENTER INFORM, P3
   Bernardo A, 2017, WORLD NEUROSURG, V106, P1015, DOI 10.1016/j.wneu.2017.06.140
   Bharathi Ajay Karthic B., 2015, P ASME 2015 INT DES, V10, DOI [10.1115/detc2015-47388, DOI 10.1115/DETC2015-47388]
   BIOCCA F, 1992, J COMMUN, V42, P23, DOI 10.1111/j.1460-2466.1992.tb00811.x
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Cao S, 2020, VIRTUAL REAL-LONDON, V24, P503, DOI 10.1007/s10055-019-00412-x
   Cha YH, 2021, J VESTIBUL RES-EQUIL, V31, P327, DOI 10.3233/VES-200005
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   DENTON GG, 1980, PERCEPTION, V9, P393, DOI 10.1068/p090393
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Fineschi A, 2015, INT CONF 3D IMAG
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Heutink J, 2019, ERGONOMICS, V62, P65, DOI 10.1080/00140139.2018.1518543
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Ji JTT, 2009, HUM FACTORS, V51, P739, DOI 10.1177/0018720809349708
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Keshavarz Behrang., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications Issue September, P647, DOI [DOI 10.1201/B17360-32, https://doi.org/10.1201/b17360-32]
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kuiper OX, 2019, DISPLAYS, V58, P82, DOI 10.1016/j.displa.2018.10.001
   LAMPTON DR, 1994, HUM FAC ERG SOC P, P1154
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   LORCH RF, 1990, J EXP PSYCHOL LEARN, V16, P149, DOI 10.1037/0278-7393.16.1.149
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Minsky M., 1980, Omni, V2, P44
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nooij SAE, 2018, EXP BRAIN RES, V236, P3031, DOI 10.1007/s00221-018-5340-1
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Palmisano S, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364699
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Pot-Kolder R, 2018, CYBERPSYCH BEH SOC N, V21, P187, DOI 10.1089/cyber.2017.0082
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Rankin CH, 2009, NEUROBIOL LEARN MEM, V92, P135, DOI 10.1016/j.nlm.2008.09.012
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Regan EC, 1995, DISPLAYS, V16, P135, DOI 10.1016/0141-9382(96)81213-3
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2015, Immersed in Media, P187, DOI DOI 10.1007/978-3-319-10190-3_9
   Riecke B. E., 2013, Human walking in virtual environments, P27, DOI 10.1007/978-1-4419-8432-6_2
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI DOI 10.1145/1180495.1180517
   Riecke BE, 2011, VIRTUAL REALITY, P149
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Salvatore S., 1968, HIGHWAY RES REC, V292, P79
   SCHMIDT F, 1969, J APPL PSYCHOL, V53, P536, DOI 10.1037/h0028674
   Seno T, 2011, VISION RES, V51, P2499, DOI 10.1016/j.visres.2011.10.007
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Solomon SG, 2014, CURR BIOL, V24, pR1012, DOI 10.1016/j.cub.2014.09.001
   Stanney K. M., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2114
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Stanney KM, 1998, HUM FAC ERG SOC P, P1476
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   STOFFREGEN T A, 1991, Ecological Psychology, V3, P159, DOI 10.1207/s15326969eco0303_1
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187120
   Stoffregen TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066949
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Thompson RF, 2009, NEUROBIOL LEARN MEM, V92, P127, DOI 10.1016/j.nlm.2008.07.011
   Wagner A.R., 1979, MECH LEARNING MOTIVA, P53
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
NR 89
TC 17
Z9 18
U1 2
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1373
EP 1389
DI 10.1007/s10055-022-00634-6
EA MAR 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000766084800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ferraz-Torres, M
   San Martín-Rodríguez, L
   García-Vivar, C
   Soto-Ruiz, N
   Escalada-Hernández, P
AF Ferraz-Torres, Marta
   San Martin-Rodriguez, Leticia
   Garcia-Vivar, Cristina
   Soto-Ruiz, Nelia
   Escalada-Hernandez, Paula
TI "Passive or interactive virtual reality? The effectiveness for pain and
   anxiety reduction in pediatric patients"
SO VIRTUAL REALITY
LA English
DT Article
DE Anxiety; Pain; Pediatric patients; Phlebotomy; Virtual Reality
ID VASCULAR ACCESS; CHILDREN; RELIABILITY; MANAGEMENT; ULTRASOUND;
   VALIDITY; NURSES; TOOL
AB Invasive techniques such as venipuncture are painful procedures causing stress and anxiety, both in pediatric patients and in their carers. For this reason, efforts are being made to develop mitigating strategies for the patient's pain and anxiety during the performance. To analyze and evaluate the effectiveness of the use of Virtual Reality distraction techniques as a measure of pain and anxiety reduction in pediatric patients and their parents. In addition, the effects of two modes of Virtual Reality (passive vs. interactive) were compared. A quasi-experimental study was carried out in the pediatric emergency department of a tertiary referral hospital in north Spain. The participants were children who underwent venipuncture for blood extraction and vascular cannulation. From the 124 patients, 51.6% (n = 64) were girls and 48.4% (n = 60) were boys (p = 0.574). The mean age was 8.4 years (SD: 4.1). The mean level of pain experienced was 2.33 (SD: 0.76) in the interactive VR group (n = 88) versus 2.67 (SD: 1.35) in patients with passive VR (n = 36) (p = 0.008); being the presence of anxiety in 27.3% (n = 24) of the cases treated with interactive Virtual Reality and in 88.9% (n = 32) of the patients with passive Virtual Reality (p = 0.000). The virtual reality is an effective method to reduce pain and anxiety levels in pediatric patients, with the effectiveness of interactive virtual reality and its use in the population aged 7-15 years being greater.
C1 [Ferraz-Torres, Marta; San Martin-Rodriguez, Leticia; Garcia-Vivar, Cristina; Soto-Ruiz, Nelia; Escalada-Hernandez, Paula] Univ Publ Navarra, Dept Hlth Sci, Avda Baranain S-N, Pamplona 31008, Spain.
   [Ferraz-Torres, Marta; San Martin-Rodriguez, Leticia; Garcia-Vivar, Cristina; Soto-Ruiz, Nelia; Escalada-Hernandez, Paula] Navarra Inst Hlth Res IdiSNA, C Irunlarrea 3, Navarra 31008, Spain.
   [Soto-Ruiz, Nelia] Navarra Hosp Complex, Head Unit Training & Res, C Irunlarrea S-N, Navarra 31008, Spain.
C3 Universidad Publica de Navarra; Servicio Navarro de Salud - Osasunbidea
RP Soto-Ruiz, N (corresponding author), Univ Publ Navarra, Dept Hlth Sci, Avda Baranain S-N, Pamplona 31008, Spain.; Soto-Ruiz, N (corresponding author), Navarra Inst Hlth Res IdiSNA, C Irunlarrea 3, Navarra 31008, Spain.; Soto-Ruiz, N (corresponding author), Navarra Hosp Complex, Head Unit Training & Res, C Irunlarrea S-N, Navarra 31008, Spain.
EM marta.ferraz@unavarra.es; leticia.sanmartin@unavarra.es;
   cristina.garciavivar@unavarra.es; nelia.soto@unavarra.es;
   paula.escalada@unavarra.es
RI Garcia-Vivar, Cristina/H-1038-2018; Soto, Nely/AAE-6457-2021;
   Escalada-Hernández, Paula/GSO-3224-2022; FERRAZ TORRES,
   MARTA/GWR-0213-2022
OI Garcia-Vivar, Cristina/0000-0002-6022-559X; Soto,
   Nely/0000-0002-5161-2272; Escalada-Hernández, Paula/0000-0003-2263-156X;
   FERRAZ TORRES, MARTA/0000-0002-7740-2572
FU CRUE-CSIC agreement; Springer Nature; "Precipita" crowdfunding platform,
   from the Spanish Foundation for Science and Technology (FECYT)
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research is part of the ReVi project, funded by
   the "Precipita" crowdfunding platform, from the Spanish Foundation for
   Science and Technology (FECYT).
CR Ahmadpour N, 2019, INT J BIOCHEM CELL B, V114, DOI 10.1016/j.biocel.2019.105568
   Ali S, 2016, PEDIATR EMERG CARE, V32, P36, DOI 10.1097/PEC.0000000000000669
   Alvarez Garc?a N., 2017, CIRUGIA PEDIAT ORGAN, V30, P216
   Attie GA, 2019, SAO PAULO MED J, V137, P284, DOI 10.1590/1516-3180.2019.0113070519
   Atzori B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02508
   Ballard A, 2019, CLIN J PAIN, V35, P532, DOI 10.1097/AJP.0000000000000690
   Benini F, 2020, ACTA PAEDIATR, V109, P1445, DOI 10.1111/apa.15137
   Berke DS, 2017, PSYCHOL MEN MASCULIN, V18, P62, DOI 10.1037/men0000036
   Cardozo Rodr?gez J., 2020, OSTEOARTHR CARTILAGE, V28, P1
   Casanovas, 2017, ORIGINALES, V20, P15
   Rodríguez MC, 2016, INT J PEDIATR OTORHI, V90, P138, DOI 10.1016/j.ijporl.2016.09.015
   Díaz-Rodríguez M, 2021, J PEDIATR NURS, V61, P15, DOI 10.1016/j.pedn.2021.02.022
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Elkhunovich M, 2017, J VASC ACCESS, V18, P57, DOI 10.5301/jva.5000615
   ENA Clinical Practice Guideline Committee, 2019, J Emerg Nurs, V45, DOI 10.1016/j.jen.2019.05.015
   Ferraz-Torres M, 2021, J PEDIATR NURS, V61, pE35, DOI 10.1016/j.pedn.2021.04.009
   Figueroa Jaramillo, 2015, MODULACION EMOCIONAL
   Fillingim RB, 2017, PRINCIPLES OF GENDER-SPECIFIC MEDICINE: GENDER IN THE GENOMIC ERA, 3RD EDITION, P481, DOI 10.1016/B978-0-12-803506-1.00038-3
   Galvan Guzman E., 2019, EFECTIVIDAD USO DISP
   Gerçeker GÖ, 2018, J VASC ACCESS, V19, P620, DOI 10.1177/1129729818765598
   Gold JI, 2021, J MED INTERNET RES, V23, DOI 10.2196/25504
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Han SH, 2019, JAMA PEDIATR, V173, P1026, DOI 10.1001/jamapediatrics.2019.3000
   Harding M., 2019, CRITICAL CARE MED, V48, P396, DOI [10.1097/01.ccm.0000631468.53581.17, DOI 10.1097/01.CCM.0000631468.53581.17]
   Heden L, 2020, NURS OPEN, V7, P376, DOI 10.1002/nop2.399
   Hummel P, 2010, J PERINATOL, V30, P474, DOI 10.1038/jp.2009.185
   Kleidon TM, 2020, J PAEDIATR CHILD H, V56, P289, DOI 10.1111/jpc.14600
   Krauss BS, 2016, LANCET, V387, P83, DOI 10.1016/S0140-6736(14)61686-X
   Lee SU, 2020, J VASC ACCESS, V21, P180, DOI 10.1177/1129729819865709
   Lier EJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66035-4
   Manworren Renee C B, 2003, Pediatr Nurs, V29, P140
   Mart?n Valbuena S., 2019, TIEMPOS ENFERMERIA S, V1, P32
   Mayordomo-Colunga J, 2019, AN PEDIATR, V91
   Miró J., 2005, Rev. Soc. Esp. Dolor, V12, P407
   Naegeli AN, 2018, J PATIENT-REP OUTCOM, V2, DOI 10.1186/s41687-018-0051-8
   Oulego-Erroz I, 2021, AN PEDIATR, V94, P144, DOI 10.1016/j.anpedi.2019.12.022
   Gerçeker GÖ, 2020, J CLIN NURS, V29, P1151, DOI 10.1111/jocn.15173
   Piskorz J, 2018, J SPEC PEDIATR NURS, V23, DOI 10.1111/jspn.12201
   Sadhasivam S, 2010, ANESTH ANALG, V110, P1109, DOI 10.1213/ANE.0b013e3181d2a509
   Sallam K, 2018, J EGYPT NATL CANCER, V30, P99, DOI 10.1016/j.jnci.2018.07.001
   Santos N, 2020, EMERGENCIAS, V32, P143
   Smith Claire, 2018, Emerg Nurse, V26, P18, DOI 10.7748/en.2018.e1733
   Sorge RE, 2017, J NEUROSCI RES, V95, P1271, DOI 10.1002/jnr.23841
   Svendsen EJ, 2016, J ADV NURS, V72, P620, DOI 10.1111/jan.12852
   Taddio A, 2010, CAN MED ASSOC J, V182, P1989, DOI 10.1503/cmaj.092048
   del Castillo BT, 2019, AN PEDIATR, V91, P80, DOI 10.1016/j.anpedi.2018.10.019
   Voepel-Lewis T, 2010, AM J CRIT CARE, V19, P55, DOI 10.4037/ajcc2010624
   Wieland LS, 2019, EXPLORE-NY, V15, P74, DOI 10.1016/j.explore.2018.10.014
NR 48
TC 12
Z9 12
U1 8
U2 61
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1307
EP 1316
DI 10.1007/s10055-022-00633-7
EA FEB 2022
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000754334800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wähnert, S
   Gerhards, A
AF Waehnert, Svetlana
   Gerhards, Alexander
TI Sensorimotor adaptation in VR: magnitude and persistence of the
   aftereffect increase with the number of interactions
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Sensorimotor adaptation; Aftereffect; Number of
   interactions
ID PRISM ADAPTATION; DISPLACED VISION; BODY; HAND
AB In both prism and virtual reality experiments, it has been observed that visual displacement leads to an adaptation of the sensorimotor system. A characteristic of adaptation is the occurrence of the aftereffect, which is the spatial deviation of the movements in the direction opposite to the visual displacement. Prism adaptation experiments have shown that a higher number of interactions lead to an increased magnitude and persistence of the aftereffect. The aim of the present study was to investigate this relationship in virtual reality. After baseline measurement, the virtual environment was displaced visually. During this adaptation phase, the participants performed either zero, five, or thirty-five pointing movements. Afterwards, all participants performed the pointing movements without the visual displacement in the virtual environment. Performing five pointing movements during the adaptation phase was already sufficient to produce an aftereffect. With thirty-five pointing movements, both magnitude and persistence of the aftereffect increased. These results replicate studies of prism adaptation. Considering this, we briefly discuss the suitability of virtual reality as a research tool to study prism adaptation.
C1 [Waehnert, Svetlana; Gerhards, Alexander] Tech Univ Berlin, Dept Psychol & Ergon Psychol New Media & Methodol, Berlin, Germany.
   [Waehnert, Svetlana] Tech Univ Dresden, Inst Mat Handling & Ind Engn, Chair Ergon, Dresden, Germany.
C3 Technical University of Berlin; Technische Universitat Dresden
RP Wähnert, S (corresponding author), Tech Univ Berlin, Dept Psychol & Ergon Psychol New Media & Methodol, Berlin, Germany.; Wähnert, S (corresponding author), Tech Univ Dresden, Inst Mat Handling & Ind Engn, Chair Ergon, Dresden, Germany.
EM svetlana.waehnert@tu-berlin.de
OI Wahnert, Svetlana/0000-0002-7813-1786
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. No funds,
   grants, or other support were received.
CR Anglin JM, 2017, SCI REP-UK, V7, DOI 10.1038/srep45469
   Aziz JR, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00138
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bastian AJ, 2008, CURR OPIN NEUROL, V21, P628, DOI 10.1097/WCO.0b013e328315a293
   Biocca FA, 1998, PRESENCE-VIRTUAL AUG, V7, P262, DOI 10.1162/105474698565703
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bruggeman H, 2007, CURR BIOL, V17, P2035, DOI 10.1016/j.cub.2007.10.059
   Cho S, 2020, JOVE-J VIS EXP, DOI 10.3791/60639
   DEWAR R, 1970, PERCEPT PSYCHOPHYS, V8, P313, DOI 10.3758/BF03212599
   Facchin A, 2019, CORTEX, V119, P141, DOI 10.1016/j.cortex.2019.04.012
   Fernández-Ruiz J, 1999, LEARN MEMORY, V6, P47
   Fox J., 2016, Applied Regression Analysis, Linear Models, and Related Methods, DOI DOI 10.5860/CHOICE.34-6323
   Gammeri R, 2020, NEUROPSYCHOL REHABIL, V30, P753, DOI 10.1080/09602011.2018.1502672
   Groen J, 1998, PRESENCE-TELEOP VIRT, V7, P429, DOI 10.1162/105474698565839
   HARRIS CS, 1965, PSYCHOL REV, V72, P419, DOI 10.1037/h0022616
   Hartman, 2018, PERCEPTION ACTION SY
   HELD R, 1965, SCI AM, V213, P84, DOI 10.1038/scientificamerican1165-84
   HTC Corporation, 2016, VIVE VR SYST
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   KORNHEISER AS, 1976, PSYCHOL BULL, V83, P783, DOI 10.1037/0033-2909.83.5.783
   KRAVITZ JH, 1972, PERCEPT PSYCHOPHYS, V11, P38, DOI 10.3758/BF03212680
   Lee JH, 2020, VIRTUAL REAL-LONDON, V24, P211, DOI 10.1007/s10055-019-00390-0
   Littman, 2009, PROSPECTIVE CONTROL
   Littman, 2011, THESIS MIAMI U
   Maksimovic S, 2020, J MOTOR BEHAV, V52, P122, DOI 10.1080/00222895.2019.1574258
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Norris SA, 2001, BRAIN RES, V905, P207, DOI 10.1016/S0006-8993(01)02552-5
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Prablanc C, 2020, NEUROSCI RES, V153, P8, DOI 10.1016/j.neures.2019.03.003
   Ramos AA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217074
   Rossetti Y, 1998, NATURE, V395, P166, DOI 10.1038/25988
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Stoffregen TA, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P111, DOI 10.1201/9781410608888.ch6
   UHLARIK JJ, 1970, PERCEPT PSYCHOPHYS, V7, P348, DOI 10.3758/BF03208662
   WELCH RB, 1993, PERCEPT PSYCHOPHYS, V54, P195, DOI 10.3758/BF03211756
   WELCH RB, 1971, PERCEPT PSYCHOPHYS, V9, P102, DOI 10.3758/BF03213039
   Welch RB, 2002, HUM FAC ER, P619
   WELCH RB, 1971, PERCEPT PSYCHOPHYS, V10, P90, DOI 10.3758/BF03214321
   Yang NYH, 2013, FRONT HUM NEUROSCI, V7, P1, DOI 10.3389/fnhum.2013.00187
   Yin PB, 2001, EXP BRAIN RES, V141, P250, DOI 10.1007/s002210100892
NR 40
TC 3
Z9 3
U1 2
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1217
EP 1225
DI 10.1007/s10055-022-00628-4
EA JAN 2022
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000749239600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Chan, SHM
   Qiu, L
   Esposito, G
   Mai, KP
   Tam, KP
   Cui, J
AF Chan, Sarah Hian May
   Qiu, Lin
   Esposito, Gianluca
   Mai, Ky Phong
   Tam, Kim-Pong
   Cui, Jian
TI Nature in virtual reality improves mood and reduces stress: evidence
   from young adults and senior citizens
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Nature; Emotion; Stress; Well-being; Mental health
ID STATISTICAL MEDIATION ANALYSIS; NATURE EXPERIENCE; PUBLIC-HEALTH;
   ENVIRONMENTS; RECOVERY; BENEFITS; FOREST; CONNECTEDNESS; RESTORATION;
   TECHNOLOGY
AB Large populations worldwide have been deprived from nature experiences due to mass quarantines and lockdowns during the COVID-19 pandemic, and face a looming mental health crisis. Virtual reality offers a safe and practical solution to increase nature exposure. This research examined the effects of virtual nature using a within-subject design with young adults (Study 1) and senior citizens (Study 2). Results from the young adult sample showed that walking in a virtual forest reduced negative affect due to enhanced nature connectedness, and reduced stress measured by heart rate. Consistently, the senior citizen sample reported improved positive affect due to enhanced nature connectedness after the virtual nature walk. Our findings unveil the underlying mechanism of how virtual nature may improve psychological well-being and demonstrated how virtual nature can be used as an intervention to promote mental health.
C1 [Chan, Sarah Hian May; Qiu, Lin; Esposito, Gianluca; Mai, Ky Phong] Nanyang Technol Univ, Sch Social Sci, Div Psychol, Singapore, Singapore.
   [Chan, Sarah Hian May] Nanyang Technol Univ, Interdisciplinary Grad Sch, Global Asia, Singapore, Singapore.
   [Tam, Kim-Pong] Hong Kong Univ Sci & Technol, Div Social Sci, Kowloon, Clear Water Bay, Hong Kong, Peoples R China.
   [Cui, Jian] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University; Hong
   Kong University of Science & Technology; Nanyang Technological
   University
RP Qiu, L (corresponding author), Nanyang Technol Univ, Sch Social Sci, Div Psychol, Singapore, Singapore.
EM linqiu@ntu.edu.sg
RI Esposito, Gianluca/B-1374-2012; Tam, Kim-Pong/K-6975-2014; Chan, Sarah
   Hian May/HKN-6441-2023
OI Esposito, Gianluca/0000-0002-9442-0254; Tam,
   Kim-Pong/0000-0003-1485-1343; Qiu, Lin/0000-0002-3587-5371; Chan, Sarah
   Hian May/0000-0003-0804-8239
FU Singapore Ministry of Education AcRF Tier 1 Grant [RG83/17]; NTU ARISE
   Inaugural Grant
FX This work was supported by Singapore Ministry of Education AcRF Tier 1
   Grant RG83/17 and NTU ARISE Inaugural Grant Call 2017 Seed Funding
   awarded to the second author.
CR Abe S, 1996, AM HEART J, V131, P1137, DOI 10.1016/S0002-8703(96)90088-5
   ALESSI SM, 1988, J COMPUT-BASE INSTR, V15, P40
   Andreassi J.L., 2006, PSYCHOPHYSIOLOGY HUM, V5th, DOI DOI 10.4324/9780203880340
   Annerstedt M, 2013, PHYSIOL BEHAV, V118, P240, DOI 10.1016/j.physbeh.2013.05.023
   [Anonymous], 2020, LANCET INFECT DIS, V20, P1217, DOI 10.1016/S1473-3099(20)30797-0
   Banerjee D, 2020, INT J GERIATR PSYCH, V35, P1466, DOI 10.1002/gps.5320
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Berto R, 2014, BEHAV SCI-BASEL, V4, P394, DOI 10.3390/bs4040394
   Bertram C, 2015, ECOL ECON, V120, P139, DOI 10.1016/j.ecolecon.2015.10.013
   Bizzego A, 2019, SOFTWAREX, V10, DOI 10.1016/j.softx.2019.100287
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bolin JH, 2014, J EDUC MEAS, V51, P335, DOI 10.1111/jedm.12050
   Bourdillon N, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242303
   Bratman GN, 2015, LANDSCAPE URBAN PLAN, V138, P41, DOI 10.1016/j.landurbplan.2015.02.005
   Bratman GN, 2012, ANN NY ACAD SCI, V1249, P118, DOI 10.1111/j.1749-6632.2011.06400.x
   Brown DK, 2013, ENVIRON SCI TECHNOL, V47, P5562, DOI 10.1021/es305019p
   Bullock JG, 2010, J PERS SOC PSYCHOL, V98, P550, DOI 10.1037/a0018933
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Capaldi CA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00976
   Cheng JCH, 2012, ENVIRON BEHAV, V44, P31, DOI 10.1177/0013916510385082
   Cherniack EP, 2011, DISABIL REHABIL-ASSI, V6, P283, DOI 10.3109/17483107.2010.542570
   Davis JL, 2009, J ENVIRON PSYCHOL, V29, P173, DOI 10.1016/j.jenvp.2008.11.001
   Delaney JPA, 2000, PERCEPT MOTOR SKILL, V91, P515, DOI 10.2466/PMS.91.6.515-524
   Depledge MH, 2011, ENVIRON SCI TECHNOL, V45, P4660, DOI 10.1021/es103907m
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Ferreira E, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE, COGNITIVE ALGORITHMS, MIND, AND BRAIN (CCMB), P39, DOI 10.1109/CCMB.2014.7020692
   Gabrieli G, 2020, SMART INNOV SYST TEC, V151, P395, DOI 10.1007/978-981-13-8950-4_35
   Gladwell VF, 2012, EUR J APPL PHYSIOL, V112, P3379, DOI 10.1007/s00421-012-2318-8
   Grahn P, 2010, LANDSCAPE URBAN PLAN, V94, P264, DOI 10.1016/j.landurbplan.2009.10.012
   Guger C., 2004, Presence 2004, P240
   Haluza D, 2014, INT J ENV RES PUB HE, V11, P5445, DOI 10.3390/ijerph110505445
   HARTIG T, 1991, ENVIRON BEHAV, V23, P3, DOI 10.1177/0013916591231001
   Hayes AF, 2013, PSYCHOL SCI, V24, P1918, DOI 10.1177/0956797613480187
   Hayes AF, 2009, COMMUN MONOGR, V76, P408, DOI 10.1080/03637750903310360
   Hoot RobertE., 2011, International Journal of Transpersonal Studies, V30, P89
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Judd CM, 2001, PSYCHOL METHODS, V6, P115, DOI 10.1037/1082-989X.6.2.115
   Kahn PH, 2008, J ENVIRON PSYCHOL, V28, P192, DOI 10.1016/j.jenvp.2007.10.008
   Kahn PH, 2009, CURR DIR PSYCHOL SCI, V18, P37, DOI 10.1111/j.1467-8721.2009.01602.x
   Kaplan R., 1989, EXPERIENCE NATURE PS
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kellert S.R., 1993, The biophilia hypothesis
   Kellert S.R., 1997, Kinship to mastery: Biophilia in human evolution and development
   Kharroubi S, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.549692
   Kim TH, 2010, SCI TOTAL ENVIRON, V408, P2600, DOI 10.1016/j.scitotenv.2010.02.025
   Kondo MC, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15030445
   Kothgassner OD, 2018, CYBERPSYCH BEH SOC N, V21, P318, DOI 10.1089/cyber.2017.0691
   Lang, 2021, ROAD VR
   Larson LR, 2019, ENVIRON BEHAV, V51, P966, DOI 10.1177/0013916518806686
   Lee HS, 2021, PSYCHIAT RES, V295, DOI 10.1016/j.psychres.2020.113570
   Lee J, 2011, PUBLIC HEALTH, V125, P93, DOI 10.1016/j.puhe.2010.09.005
   Levi D, 1999, ENVIRON BEHAV, V31, P203, DOI 10.1177/00139169921972065
   Li ZY, 2020, BRAIN BEHAV IMMUN, V88, P916, DOI 10.1016/j.bbi.2020.03.007
   Lindal PJ, 2013, J ENVIRON PSYCHOL, V33, P26, DOI 10.1016/j.jenvp.2012.09.003
   Lindquist M, 2020, LANDSCAPE URBAN PLAN, V202, DOI 10.1016/j.landurbplan.2020.103884
   Liszio S, 2019, ANN REV CYBERTHERAPY, V17, P65
   Litleskare S, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051738
   Liu D., 2009, HUMAN FACTORS SIMULA, P61, DOI [DOI 10.1201/9781420072846.CH4, 10.1201/9781420072846.ch4]
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI DOI 10.1145/2671015.2671120
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Mayer FS, 2009, ENVIRON BEHAV, V41, P607, DOI 10.1177/0013916508319745
   Mayer FS, 2004, J ENVIRON PSYCHOL, V24, P503, DOI 10.1016/j.jenvp.2004.10.001
   McMahan EA, 2015, J POSIT PSYCHOL, V10, P507, DOI 10.1080/17439760.2014.994224
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Micarelli A, 2019, ARCH GERONTOL GERIAT, V83, P246, DOI 10.1016/j.archger.2019.05.008
   Moccia L, 2020, BRAIN BEHAV IMMUN, V87, P75, DOI 10.1016/j.bbi.2020.04.048
   Montoya AK, 2017, PSYCHOL METHODS, V22, P6, DOI 10.1037/met0000086
   Mygind L, 2021, ENVIRON BEHAV, V53, P184, DOI 10.1177/0013916519873376
   Ng AKT, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.08.004
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Nisbet EK, 2009, ENVIRON BEHAV, V41, P715, DOI 10.1177/0013916508318748
   Optale G, 2010, NEUROREHAB NEURAL RE, V24, P348, DOI 10.1177/1545968309353328
   Park Bum Jin, 2010, Environmental Health and Preventive Medicine, V15, P18, DOI 10.1007/s12199-009-0086-9
   Park BJ, 2011, LANDSCAPE URBAN PLAN, V102, P24, DOI 10.1016/j.landurbplan.2011.03.005
   Park MJ, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00505
   Pergams ORW, 2006, J ENVIRON MANAGE, V80, P387, DOI 10.1016/j.jenvman.2006.02.001
   Pouso S, 2021, SCI TOTAL ENVIRON, V756, DOI 10.1016/j.scitotenv.2020.143984
   Pritchard A, 2020, J HAPPINESS STUD, V21, P1145, DOI 10.1007/s10902-019-00118-6
   Ratcliffe E, 2013, J ENVIRON PSYCHOL, V36, P221, DOI 10.1016/j.jenvp.2013.08.004
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riva G, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.563319
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Rogers S., 2018, Forbes
   Satariano WA, 2012, AM J PUBLIC HEALTH, V102, P1508, DOI 10.2105/AJPH.2011.300631
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shrout PE, 2002, PSYCHOL METHODS, V7, P422, DOI 10.1037//1082-989X.7.4.422
   Sibley CG, 2020, AM PSYCHOL, V75, P618, DOI 10.1037/amp0000662
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater SJ, 2020, PREV CHRONIC DIS, V17, DOI 10.5888/pcd17.200204
   Soga M, 2016, FRONT ECOL ENVIRON, V14, P94, DOI 10.1002/fee.1225
   Tang B, 2020, INT J INFECT DIS, V95, P288, DOI 10.1016/j.ijid.2020.03.018
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Ulrich R., 1983, Behavior and the Natural Environment, P85, DOI [DOI 10.1007/978-1-4613-3539-94, DOI 10.1007/978-1-4613-3539-9_4]
   Ulrich R.S., 2002, HLTH BENEFITS GARDEN
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   ULRICH RS, 1984, SCIENCE, V224, P420, DOI 10.1126/science.6143402
   Valtchanov D., 2010, J Cyber Ther Rehabil, V3, P359
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   van den Berg AE, 2003, J ENVIRON PSYCHOL, V23, P135, DOI 10.1016/S0272-4944(02)00111-1
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weinstein N, 2009, PERS SOC PSYCHOL B, V35, P1315, DOI 10.1177/0146167209341649
   Wen C, 2018, SUSTAIN CITIES SOC, V38, P582, DOI 10.1016/j.scs.2018.01.023
   White MP, 2013, PSYCHOL SCI, V24, P920, DOI 10.1177/0956797612464659
   White MP, 2018, NEUROPSYCH DIS TREAT, V14, P3001, DOI 10.2147/NDT.S179038
   White RG, 2020, BJPSYCH OPEN, V6, DOI 10.1192/bjo.2020.79
   Wilson E.O., 1984, P1
   Wyles KJ, 2019, ENVIRON BEHAV, V51, P111, DOI 10.1177/0013916517738312
   Yu CP, 2018, URBAN FOR URBAN GREE, V35, P106, DOI 10.1016/j.ufug.2018.08.013
NR 109
TC 46
Z9 47
U1 33
U2 139
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3285
EP 3300
DI 10.1007/s10055-021-00604-4
EA NOV 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000722794500001
PM 34849087
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Jang, YJ
   Park, E
AF Jang, Yeonju
   Park, Eunil
TI Satisfied or not: user experience of mobile augmented reality in using
   natural language processing techniques on review comments
SO VIRTUAL REALITY
LA English
DT Review
DE Mobile augmented reality; User satisfaction; Two-factor theory; Review
   analysis
ID POKEMON GO; SATISFACTION; FRAMEWORK; SERVICES; DESIGN; AR
AB With the rapid developments and improvements in mobile technologies, mobile devices have become one of the primary interfaces of augmented reality technologies. In this study, we explore how user groups (satisfied vs. dissatisfied users) and domains (game vs. non-game domain) affect user experience, including perceived usefulness, usability, and affection using two-factor theory and analysis of review comments. We employ two linguistic approaches for processing the content of the comments. The results of a series of analyses of variance indicate that both user groups and domains significantly affect user-perceived usability and affection, while there is no effect of user groups on the perceived usefulness of mobile applications. Based on the findings of the study, notable implications and a few limitations are presented.
C1 [Jang, Yeonju; Park, Eunil] Sungkyunkwan Univ, Dept Interact Sci, Seoul 03063, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Park, E (corresponding author), Sungkyunkwan Univ, Dept Interact Sci, Seoul 03063, South Korea.
EM cherish424@g.skku.edu; eunilpark@skku.edu
RI Park, Eunil/S-9770-2019
OI Park, Eunil/0000-0002-3177-3538; Jang, Yeonju/0000-0003-1606-874X
FU National Research Foundation (NRF) of Korea - Korean Government (MSIT)
   [2021R1A4A3022102]; Korea Agency for Infrastructure Technology
   Advancement [21ATOG-C161932-01]
FX This research was supported by National Research Foundation (NRF) of
   Korea Grant funded by the Korean Government (MSIT) (No.
   2021R1A4A3022102), and by Korea Agency for Infrastructure Technology
   Advancement (No. 21ATOG-C161932-01).
CR Aggelidis VP, 2012, J BIOMED INFORM, V45, P566, DOI 10.1016/j.jbi.2012.02.009
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BAILEY JE, 1983, MANAGE SCI, V29, P530, DOI 10.1287/mnsc.29.5.530
   Bevan N, 2009, LECT NOTES COMPUT SC, V5619, P13, DOI 10.1007/978-3-642-02806-9_2
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Demirbilek O, 2003, ERGONOMICS, V46, P1346, DOI 10.1080/00140130310001610874
   Deng L., 2018, DEEP LEARNING NATURA, P1
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dirin A, 2018, COMPUTERS, V7, DOI 10.3390/computers7020033
   DOLL WJ, 1988, MIS QUART, V12, P259, DOI 10.2307/248851
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Farshid M, 2018, BUS HORIZONS, V61, P657, DOI 10.1016/j.bushor.2018.05.009
   Genc-Nayebi N, 2017, J SYST SOFTWARE, V125, P207, DOI 10.1016/j.jss.2016.11.027
   Goebert C, 2020, COMPUT HUM BEHAV, V106, DOI 10.1016/j.chb.2019.106231
   Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257
   Han DI, 2018, PROGR IS, P3, DOI 10.1007/978-3-319-64027-3_1
   Hedegaard S.Simonsen., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P2089, DOI DOI 10.1145/2470654.2481286NULL
   HERZBERG F, 1968, HARVARD BUS REV, V46, P53
   Herzberg F., 1959, MOTIVATION WORK
   Hsu SHY, 2021, J RETAIL CONSUM SERV, V62, DOI 10.1016/j.jretconser.2021.102649
   Huang TL, 2015, ELECTRON COMMER RES, V15, P269, DOI 10.1007/s10660-014-9163-2
   Islam AKMN, 2014, COMPUT HUM BEHAV, V30, P249, DOI 10.1016/j.chb.2013.09.010
   Jang Y, 2019, TELEMAT INFORM, V42, DOI 10.1016/j.tele.2019.101239
   Jung T, 2015, TOURISM MANAGE, V49, P75, DOI 10.1016/j.tourman.2015.02.013
   Kanakaraj M, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Kano N., 1984, Journal of The Japanese Society for Quality Control, V31, P147, DOI [DOI 10.20684/QUALITY.14.2_147, 10.20684/quality.14.2_147]
   Karimi HassanA., 2004, Telegeoinformatics: Location-based computing and services, DOI DOI 10.1201/B12395
   Kim, 2005, HUMAN COMPUTER INTER
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Kosmadoudi Z, 2013, COMPUT AIDED DESIGN, V45, P777, DOI 10.1016/j.cad.2012.08.001
   Lee S, 2009, J ASSOC INF SYST, V10, P860
   Liu CZC, 2014, J MANAGE INFORM SYST, V31, P326, DOI 10.1080/07421222.2014.995564
   Llewellyn C., 2014, Eighth International AAAI Conference on Weblogs and Social Media, P599
   López-Faican L, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2020.103814
   Muylle S, 2004, INFORM MANAGE-AMSTER, V41, P543, DOI 10.1016/S0378-7206(03)00089-2
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Park SC, 2013, COMPUT HUM BEHAV, V29, P160, DOI 10.1016/j.chb.2012.07.032
   Phan MH, 2016, HUM FACTORS, V58, P1217, DOI 10.1177/0018720816669646
   Qin H, 2021, J RETAIL CONSUM SERV, V58, DOI 10.1016/j.jretconser.2020.102337
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Ruiz-Ariza A, 2018, COMPUT EDUC, V116, P49, DOI 10.1016/j.compedu.2017.09.002
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Scholtz J, 2004, IEEE PERVAS COMPUT, V3, P82, DOI 10.1109/MPRV.2004.1316826
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.9781/ijimai.2017.445, DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337]
   Serino M, 2016, CURR OPIN PEDIATR, V28, P673, DOI 10.1097/MOP.0000000000000409
   Sherry JL, 2006, LEA COMMUN SER, P213
   Takacs G., 2008, MIR 08, P427, DOI DOI 10.1145/1460096.1460165
   Takatalo J, 2010, HUM-COMPUT INT-SPRIN, P23, DOI 10.1007/978-1-84882-963-3_3
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Weichbroth Pawel, 2019, 2019 Federated Conference on Computer Science and Information Systems (FedCSIS). Proceedings, P747, DOI 10.15439/2019F289
   Winn Brian M, 2009, Handbook of research on effective electronic gaming in education, P1010, DOI DOI 10.4018/978-1-59904-808-6.CH058
   Wixom BH, 2005, INFORM SYST RES, V16, P85, DOI 10.1287/isre.1050.0042
   Wu LL, 2008, J AM SOC INF SCI TEC, V59, P1829, DOI 10.1002/asi.20889
   Yunqiang Chen, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022082
NR 56
TC 8
Z9 8
U1 6
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 839
EP 848
DI 10.1007/s10055-021-00599-y
EA NOV 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000713563800001
DA 2024-07-18
ER

PT J
AU Toyoda, R
   Abegao, FR
   Gill, S
   Glassey, J
AF Toyoda, Ryo
   Russo Abegao, Fernando
   Gill, Sue
   Glassey, Jarka
TI Drivers of immersive virtual reality adoption intention: a multi-group
   analysis in chemical industry settings
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality adoption; UTAUT 2 multi-group analysis; Chemical
   industry; Training; Adoption intention; PLS-SEM
ID INFORMATION-TECHNOLOGY; MEASUREMENT INVARIANCE; SOCIAL-INFLUENCE;
   UNIFIED THEORY; ACCEPTANCE
AB The present study uses the modified Unified Theory of Acceptance and Use of Technology 2 to examine the effect of factors such as performance expectancy (PE), effort expectancy (EE), social influence (SI), and hedonic motivation (HM) that may motivate operators and employees to adopt IVR-based technology into their training. Results of a multi-group analysis based on nationality, prior IVR experience, and/or length of work experience, to analyse the potential similarities and/or differences in perception and acceptance towards using IVR-based technology are also presented. The quantitative research data were gathered using an online questionnaire from 438 chemical operators and/or employees who either speak German, French, or English. Partial least squares structural equation modelling and multi-group analysis based on SmartPLS (TM) version 3 were used to carry out the path and multi-group analyses. The results show that the behavioural intention (BI) towards adoption of IVR was influenced by PE, EE, and HM for all abovementioned subpopulation. However, the relationship of SI to BI was not supported for respondents with prior IVR experience and for respondents coming from Western region. Although Henseler's-based multi-group PLS analysis reveals that there was no significant difference between the group comparisons, it is still important to take into account these socio-demographic factors as there are definite group differences in terms of the ranking order of each construct for the IVR adoption intentions among each subpopulation. The implications and future directions were discussed.
C1 [Toyoda, Ryo; Russo Abegao, Fernando; Glassey, Jarka] Newcastle Univ, Sch Engn, Newcastle Upon Tyne, England.
   [Gill, Sue] Newcastle Univ, Learning & Teaching Dev Serv, Newcastle Upon Tyne, England.
C3 Newcastle University - UK; Newcastle University - UK
RP Glassey, J (corresponding author), Newcastle Univ, Sch Engn, Newcastle Upon Tyne, England.
EM jarka.glassey@ncl.ac.uk
RI Toyoda, Ryo/JJE-5804-2023
OI Toyoda, Ryo/0000-0003-4709-7535; Russo Abegao,
   Fernando/0000-0003-2911-547X
FU European Union's EU Framework Programme for Research and Innovation
   Horizon 2020 under the Marie Sklodowska-Curie Grant [812716]
FX This project has received funding from the European Union's EU Framework
   Programme for Research and Innovation Horizon 2020 under the Marie
   Sklodowska-Curie Grant Agreement No 812716.
CR Alraja MN, 2016, POL J MANAG STUD, V14, P18, DOI 10.17512/pjms.2016.14.2.02
   Arkorful V., 2015, INT J INSTRUCTIONAL, V12, P29, DOI DOI 10.1016/J.PR0CS.2012.10.037
   Becker, 2015, SMARTPLS 3
   Bissonnette V, 2019, J BONE JOINT SURG AM, V101, DOI 10.2106/JBJS.18.01197
   Bozan K, 2016, P ANN HICSS, P3105, DOI 10.1109/HICSS.2016.391
   Burdea G. C., 2003, Virtual reality technology
   Chiao HM, 2018, J HOSP LEIS SPORT TO, V23, P29, DOI 10.1016/j.jhlste.2018.05.002
   Chomeya R., 2010, Journal of Social Sciences, V6, P399, DOI DOI 10.3844/JSSP.2010.399.403
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   Colombo S, 2011, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2011, P67
   Colombo Simone., 2014, SPE Econ. Manag, V6, P165, DOI [DOI 10.2118/164993-PA, 10.2118/164993-PA]
   Cronin P, 1997, REP APPL VIRT REAL T
   Dholakiya ND, 2019, PROCESS SAF PROG, V38, DOI 10.1002/prs.12005
   Dorer B., 2012, Round 6 translation guidelines
   EFRON B, 1987, J AM STAT ASSOC, V82, P171, DOI 10.2307/2289144
   Elgohary E, 2020, ELECTR J INF SYS DEV, V86, DOI 10.1002/isd2.12139
   Fallman Daniel., 1999, VR in Education: An Introduction to Multisensory Constructivist Learning Environments
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Garcia Fracaro S, 2021, EDUC CHEM ENG, V36, P12, DOI 10.1016/j.ece.2021.01.014
   Gold AH, 2001, J MANAGE INFORM SYST, V18, P185, DOI 10.1080/07421222.2001.11045669
   Hair, 2017, A Primer on Partial Least Squares Structural Equation Modeling (PLS-SEM)
   Han J, 2020, ROBOTICS, V9, DOI 10.3390/robotics9020034
   Hartl E, 2017, P 25 EUR C INF SYST, P2413
   Henseler J, 2016, INT MARKET REV, V33, P405, DOI 10.1108/IMR-09-2014-0304
   HORN JL, 1992, EXP AGING RES, V18, P117, DOI 10.1080/03610739208253916
   Hsu CL, 2008, INFORM MANAGE-AMSTER, V45, P65, DOI 10.1016/j.im.2007.11.001
   Huang FH, 2020, VIRTUAL REAL-LONDON, V24, P635, DOI 10.1007/s10055-019-00424-7
   Kunz RE, 2020, SPORT BUS MANAG, V10, P83, DOI 10.1108/SBM-11-2018-0095
   Manca D, 2013, ADV ENG SOFTW, V55, P1, DOI 10.1016/j.advengsoft.2012.09.002
   Mao E, 2008, INFORM MANAGE-AMSTER, V45, P249, DOI 10.1016/j.im.2008.02.007
   Matthews L., 2017, Partial least squares path modeling, P219, DOI [DOI 10.1007/978-3-319-64069-3_10, 10.1007/978-3-319-64069-310, DOI 10.1007/978-3-319-64069-310]
   Nazir S, 2012, COMPUT-AIDED CHEM EN, V30, P1397
   Patle DS, 2014, REV CHEM ENG, V30, P199, DOI 10.1515/revce-2013-0027
   Pu Li J., 2006, SIGMIS CPR'06. Proceedings of the 2006 ACM SIGMIS CPR Conference. Forty Four Years of Computer Personnel Research: Achievements, Challenges and the Future, P183
   Ramayah T., 2005, Journal of Educators and Education, V20, P131
   Ramírez-Correa PE, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140460
   Sarstedt M, 2011, ADV INT MARKETING, V22, P195, DOI 10.1108/S1474-7979(2011)0000022012
   Shen CW, 2019, VIRTUAL REAL-LONDON, V23, P313, DOI 10.1007/s10055-018-0348-1
   Teo T, 2014, INTERACT LEARN ENVIR, V22, P51, DOI 10.1080/10494820.2011.641674
   Tsai WH, 2013, J INT CONSUM MARK, V25, P80, DOI 10.1080/08961530.2013.759043
   Van Slyke C, 2007, EUR J INFORM SYST, V16, P270, DOI 10.1057/palgrave.ejis.3000680
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2012, MIS QUART, V36, P157
NR 43
TC 7
Z9 7
U1 3
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3273
EP 3284
DI 10.1007/s10055-021-00586-3
EA OCT 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000705798400004
PM 34642566
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Tremblay, L
   Chebbi, B
   Bouchard, S
AF Tremblay, Line
   Chebbi, Brahim
   Bouchard, Stephane
TI The predictive role of body image and anti-fat attitudes on attentional
   bias toward body area in haptic virtual reality environment
SO VIRTUAL REALITY
LA English
DT Article
DE Haptic; Virtual humans; Body image; Anti-fat attitudes; Social
   comparison theory; Avoidance hypothesis
ID GENDER-DIFFERENCES; VISUAL-ATTENTION; EYE TRACKING; DISSATISFACTION;
   EXPOSURE; THINNESS; FEMALES; ESTEEM; IMPACT; DRIVE
AB Evidence suggests that dissatisfaction with body image in women can be enhanced by exposure to media's idealized images. The theory of social comparison and the avoidance hypothesis offer contradictory explanations of this relationship. We compare these two theories using a haptic virtual reality environment. We ask 42 female participants to interact with one of four types of virtual humans (VH) randomly assigned to them. The interaction task involves giving a virtual hug to a normal weight or overweight male or female VH. We verify the hypothesis that participants' satisfaction with particular body parts and their anti-fat attitudes will determine the choice of the body area of the VH they will virtually touch. Our results show that: (1) touching VH lower torso is predicted by less anti-fat attitude, and avoidance of the upper torso and upper limb areas, and (2) touching VH shoulder and upper limbs areas is predicted by concerns with own stomach area and avoidance of VH lower torso and stomach waist areas. Our results tend to support the avoidance hypothesis as well as other research findings on anti-fat attitudes.
C1 [Tremblay, Line; Chebbi, Brahim] Laurentian Univ, Sch Human Kinet, 935 Ramsey Lake Rd, Sudbury, ON P3E 2C6, Canada.
   [Bouchard, Stephane] Univ Quebec Gatineau, Gatineau, PQ, Canada.
C3 Laurentian University
RP Tremblay, L (corresponding author), Laurentian Univ, Sch Human Kinet, 935 Ramsey Lake Rd, Sudbury, ON P3E 2C6, Canada.
EM ltremblay@laurentian.ca; bchebbi@laurentian.ca; Stephane.Bouchard@uqo.ca
OI Bouchard, Stephane/0000-0002-5995-340X
CR Aime A., 2009, Journal of Cybertherapy and Rehabilitation, V2, P111
   ALLISON DB, 1991, INT J EAT DISORDER, V10, P599
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Aruguete M.S., 2006, N AM J PSYCHOL, V8, P183
   Bailenson JN, 2007, HUM-COMPUT INTERACT, V22, P325
   Cash T.F., 2004, Body Image, V1, P363, DOI DOI 10.1016/J.BODYIM.2004.10.001
   Cho A, 2013, BODY IMAGE, V10, P95, DOI 10.1016/j.bodyim.2012.09.005
   Crandall C.S., 2009, Handbook of prejudice, stereotyping, and discrimination, P469
   CRANDALL CS, 1994, J PERS SOC PSYCHOL, V66, P882, DOI 10.1037/0022-3514.66.5.882
   Fardouly J, 2017, BODY IMAGE, V20, P31, DOI 10.1016/j.bodyim.2016.11.002
   Ferrer-García M, 2010, ANN REV CYBERTHERAPY, V8, P36
   Festinger L, 1954, HUM RELAT, V7, P117, DOI 10.1177/001872675400700202
   Frederick D.A., 2012, Encyclopedia of Body Image and Human Appearance, P766, DOI DOI 10.1016/B978-0-12-384925-0.00121-8
   Fuller-Tyszkiewicz M, 2019, BODY IMAGE, V28, P101, DOI 10.1016/j.bodyim.2019.01.002
   Gao X, 2014, EAT BEHAV, V15, P540, DOI 10.1016/j.eatbeh.2014.08.001
   Gardner RM, 1996, BRIT J PSYCHOL, V87, P327, DOI 10.1111/j.2044-8295.1996.tb02593.x
   Garner DM., 2004, BODY IMAGE HDB THEOR, P295
   Garner DM., 2004, Professional Manual
   Gray E.K., 2007, HDB EMOTION ELICITAT
   Greenberg JL, 2014, J PSYCHIATR RES, V57, P125, DOI 10.1016/j.jpsychires.2014.06.015
   Hewig J, 2008, PSYCHOSOM MED, V70, P729, DOI 10.1097/PSY.0b013e31817e41d3
   Hogue JV, 2019, BODY IMAGE, V28, P1, DOI 10.1016/j.bodyim.2018.11.002
   Izydorczyk B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00429
   Jansen A, 2005, BEHAV RES THER, V43, P183, DOI 10.1016/j.brat.2004.01.003
   Kelley CC, 2010, BODY IMAGE, V7, P74, DOI 10.1016/j.bodyim.2009.09.008
   Lieberman DL, 2012, OBESITY, V20, P1803, DOI 10.1038/oby.2011.247
   Lonergan AR, 2019, BODY IMAGE, V28, P39, DOI 10.1016/j.bodyim.2018.12.001
   Lykins AD, 2014, BODY IMAGE, V11, P404, DOI 10.1016/j.bodyim.2014.05.003
   Martz DM, 2009, SEX ROLES, V61, P34, DOI 10.1007/s11199-009-9587-7
   McCabe Marita P, 2006, Body Image, V3, P163, DOI 10.1016/j.bodyim.2006.01.004
   McCreary DR., 2007, The muscular ideal: Psychological, social, and medical perspectives, P87, DOI [10.1037/11581-004, DOI 10.1037/11581-004]
   McKinley NM, 1998, SEX ROLES, V39, P113, DOI 10.1023/A:1018834001203
   Mendelson BK, 2001, J PERS ASSESS, V76, P90, DOI 10.1207/S15327752JPA7601_6
   Miller K, 2019, BODY IMAGE, V28, P44, DOI 10.1016/j.bodyim.2018.12.003
   Oatley K., 2006, Understanding Emotions, P105
   Perez-Lopez MS, 2001, J APPL SOC PSYCHOL, V31, P683, DOI 10.1111/j.1559-1816.2001.tb01408.x
   Phillips KA, 2008, BODY IMAGE, V5, P13, DOI 10.1016/j.bodyim.2007.12.003
   Puhl RM, 2007, PSYCHOL BULL, V133, P557, DOI 10.1037/0033-2909.133.4.557
   Roefs A, 2008, APPETITE, V51, P552, DOI 10.1016/j.appet.2008.04.008
   Schwartz Marlene B, 2004, Body Image, V1, P43, DOI 10.1016/S1740-1445(03)00007-X
   Shafran R, 2004, INT J EAT DISORDER, V35, P93, DOI 10.1002/eat.10228
   Smith J, 2007, INT J HUM-COMPUT ST, V65, P376, DOI 10.1016/j.ijhcs.2006.11.006
   Stanford JN, 2002, J HEALTH PSYCHOL, V7, P675, DOI 10.1177/1359105302007006871
   Tanck JA, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01058
   Tremblay L, 2016, CYBERPSYCH BEH SOC N, V19, P100, DOI 10.1089/cyber.2015.0226
   Tremblay L, 2013, STUD HEALTH TECHNOL, V191, P80, DOI 10.3233/978-1-61499-282-0-80
   Tremblay L, 2009, CURR PSYCHIATRY REV, V5, P62, DOI 10.2174/157340009787315307
   Trottier K, 2007, J SOC CLIN PSYCHOL, V26, P155, DOI 10.1521/jscp.2007.26.2.155
   Tuschen-Caffier B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145886
   Waller G, 2002, J PSYCHOSOM RES, V53, P1037, DOI 10.1016/S0022-3999(02)00492-0
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Yu UJ, 2014, CLOTH TEXT RES J, V32, P153, DOI 10.1177/0887302X14525850
NR 52
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 333
EP 342
DI 10.1007/s10055-021-00569-4
EA AUG 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000687002200001
DA 2024-07-18
ER

PT J
AU Liu, HM
   Qin, HB
AF Liu, Hongmei
   Qin, Huabiao
TI Perceptual self-position estimation based on gaze tracking in virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Gaze tracking; Depth perception; Stereo vision; Human-computer
   interaction; Visual discomfort
ID HEAD-MOUNTED DISPLAYS; DEPTH-PERCEPTION; DISTANCE; ENVIRONMENTS;
   PERFORMANCE
AB The depth perception of human visual system is divergent between virtual and real space; this depth discrepancy affects the spatial judgment of the user in a virtual space, which means the user cannot precisely locate their self-position in a virtual space. Existing localization methods ignore the depth discrepancy and only concentrate on increasing location accuracy in real space. Thus, the discrepancy always exists in virtual space, which induces visual discomfort. In this paper, a localization method based on depth perception is proposed to measure the self-position of the user in a virtual environment. Using binocular gaze tracking, this method estimates perceived depth and constructs an eye matrix by measuring gaze convergence on a target. Comparing the eye matrix and camera matrix, the method can automatically calculate the actual depth of the viewed target. Then, the difference between the actual depth and the perceived depth can be explicitly estimated without markers. The position of the virtual camera is compensated by the depth difference to obtain perceptual self-position. Furthermore, a virtual reality system is redesigned by adjusting the virtual camera position. The redesigned system makes users feel that the distance (from the user to an object) is the same in virtual and real space. Experimental results demonstrate that the redesigned system can improve the user's visual experiences, which validate the superiority of the proposed localization method.
C1 [Liu, Hongmei; Qin, Huabiao] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Qin, HB (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM dameizuida@163.com; eehbqin@scut.edu.cn
CR Ahmed F, 2010, P IEEE VIRT REAL ANN, P195, DOI 10.1109/VR.2010.5444791
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Dierkes K, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204525
   Duchowski A.T., 2000, P 2000 S EYE TRACK R
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Fang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051037
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Hillaire S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P47
   Hua H, 2017, P IEEE, V105, P805, DOI 10.1109/JPROC.2017.2648796
   Huang YF, 2018, LECT NOTES COMPUT SC, V11208, P789, DOI 10.1007/978-3-030-01225-0_46
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kar A, 2017, IEEE ACCESS, V5, P16495, DOI 10.1109/ACCESS.2017.2735633
   Kelly JW, 2014, IEEE T VIS COMPUT GR, V20, P588, DOI 10.1109/TVCG.2014.36
   Kim J, 2018, ROU FOC BUS MANAG, P1, DOI [10.4324/9781351113717, 10.1109/NVMSA.2018.00008]
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Kunz BR, 2009, ATTEN PERCEPT PSYCHO, V71, P1284, DOI 10.3758/APP.71.6.1284
   Lee Y, 2017, 2017 INT S UB VIRT R
   Lin CJ, 2015, J SOC INF DISPLAY, V23, P319, DOI 10.1002/jsid.378
   Mcallister DF, 2002, JANUARY ENCY IMAGING
   Mujahidin S, 2016, 3D GAZE TRACKING REA
   Nescher T., 2016, Simultaneous Mapping and Redirected Walking for ad Hoc Free Walking in Virtual Environments
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Pollock B, 2012, IEEE T VIS COMPUT GR, V18, P581, DOI 10.1109/TVCG.2012.58
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Steinicke F, 2011, IEEE T VIS COMPUT GR, V17, P888, DOI 10.1109/TVCG.2010.248
   Tripathi S, 2017, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2017.101
   Weier M, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204547
   Wood E, 2014, S EYE TRACK RES APPL
   Xia ZP, 2020, VIRTUAL REAL-LONDON, V24, P255, DOI 10.1007/s10055-019-00396-8
   Zhang MM, 2017, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2017.377
NR 34
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 269
EP 278
DI 10.1007/s10055-021-00553-y
EA JUL 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000672257500001
DA 2024-07-18
ER

PT J
AU Ashiri, M
   Lithgow, B
   Suleiman, A
   Mansouri, B
   Moussavi, Z
AF Ashiri, Mehrangiz
   Lithgow, Brian
   Suleiman, Abdelbaset
   Mansouri, Behzad
   Moussavi, Zahra
TI Quantitative measures of the visually evoked sensation of body movement
   in space (Vection) using Electrovestibulography (EVestG)
SO VIRTUAL REALITY
LA English
DT Article
DE EVestG; Virtual reality vection; Vestibular; Visual; Afferent; Efferent
ID RIGHT-HEMISPHERIC DOMINANCE; OPTOKINETIC STIMULATION; SQUIRREL-MONKEY;
   VIRTUAL-REALITY; MOTION; CORTEX; PERCEPTION; DEPRESSION; PATHWAYS;
   NEURONS
AB Vection is defined as an illusory self-motion sensation induced in stationary observers that can be experienced in a real/virtual world. Vection, as a result of immersion in virtual reality (VR) environments, can subsequently lead to a sense of inability to maintain postural control and cause cybersickness symptoms. The multisensory integration of visual and vestibular (balance) information plays a vital role in vection. The etiology of vection perception, as well as, the vestibular response change while experiencing vection is poorly understood. This study explores vestibular response change following vection in 20 individuals (10 females, 26.45 +/- 4.40 (SD) years). Vection was induced in participants using an immersive VR roller-coaster. The vestibular response was measured simultaneously using a noninvasive method called Electrovestibulography (EVestG). The detected field potentials and the time intervals between the field potentials were extracted from the recorded EVestG signals corresponding to four segments of the VR roller-coaster trajectory namely Stationary, Up movement, Down movement, and slopes and turns (Mix). The results show that the Stationary segment is significantly different (P < 0.05) from other dynamic segments when the average field potential of the right and left ear are subtracted. Furthermore, the Stationary segment shows longer time intervals between field potentials compared to those of the other segments in the right ear. These observations suggest that the combined effect of the visually induced sensation of self-motion together with a concurrent/co-occurring stress/anxiety factor can affect the vestibular activity in an excitatory way. Increased excitatory vestibular activity implies increased feeling of imbalance and more likelihood of experiencing cybersickness by the participants.
C1 [Ashiri, Mehrangiz; Lithgow, Brian; Suleiman, Abdelbaset; Moussavi, Zahra] Univ Manitoba, Biomed Engn Program, 66 Chancellors Cir, Winnipeg, MB R3T 2N2, Canada.
   [Mansouri, Behzad] Brain Vis & Concuss Clin, Neurol Sect, Dept Internal Med, 3 St Annes Rd, Winnipeg, MB R2M 2X9, Canada.
C3 University of Manitoba
RP Ashiri, M (corresponding author), Univ Manitoba, Biomed Engn Program, 66 Chancellors Cir, Winnipeg, MB R3T 2N2, Canada.
EM ashirim@myumanitoba.ca
FU Natural science and engineering research council (NSERC) of Canada;
   Mitacs through the Mitacs Accelerate program
FX This study was partly supported by the Natural science and engineering
   research council (NSERC) of Canada as well as Mitacs through the Mitacs
   Accelerate program.
CR Ashiri M, 2020, ANN BIOMED ENG, V48, P1241, DOI 10.1007/s10439-019-02446-3
   Berntson GG, 2011, PSYCHOL SCI, V22, P80, DOI 10.1177/0956797610391097
   Blakley B, 2014, J OTOLARYNGOL-HEAD N, V43, DOI 10.1186/s40463-014-0052-4
   Brandt T, 1998, BRAIN, V121, P1749, DOI 10.1093/brain/121.9.1749
   Brown DJ, 2010, HEARING RES, V267, P12, DOI 10.1016/j.heares.2010.03.091
   Bruder GE, 2016, LATERALITY, V21, P525, DOI 10.1080/1357650X.2015.1105247
   Burdess C, 1996, VESTIBULO OCULAR REF
   Carmeli E, 2015, FRONT PUBLIC HEALTH, V3, DOI 10.3389/fpubh.2015.00216
   Cloherty SL, 2010, VISION RES, V50, P2683, DOI 10.1016/j.visres.2010.08.020
   Cortes C, 2013, SYNAPSE, V67, P374, DOI 10.1002/syn.21646
   Coubard OA, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00089
   DeAngelis G.C., 2012, Visual-Vestibular Integration for Self-Motion Perception
   Dieterich M, 2003, EXP BRAIN RES, V148, P117, DOI 10.1007/s00221-002-1267-6
   Dieterich M, 1998, BRAIN, V121, P1479, DOI 10.1093/brain/121.8.1479
   Euston DR, 2012, NEURON, V76, P1057, DOI 10.1016/j.neuron.2012.12.002
   FERNANDEZ C, 1976, J NEUROPHYSIOL, V39, P996, DOI 10.1152/jn.1976.39.5.996
   FINKE RA, 1986, SCI AM, V254, P88, DOI 10.1038/scientificamerican0386-88
   Galotti KM, 2017, COGNITIVE PSYGHOLOGY
   Gerson AD, 2006, IEEE T NEUR SYS REH, V14, P174, DOI 10.1109/TNSRE.2006.875550
   GOLDBERG JM, 1980, J NEUROPHYSIOL, V43, P986, DOI 10.1152/jn.1980.43.4.986
   Goldberg JM, 2012, VESTIBULAR SYSTEM 6, DOI DOI 10.1093/ACPROF:OSO/9780195167085.001.0001
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Gurvich C, 2013, BRAIN RES, V1537, P244, DOI 10.1016/j.brainres.2013.08.058
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   HOAGLIN DC, 1987, J AM STAT ASSOC, V82, P1147, DOI 10.1080/01621459.1987.10478551
   Hu R, 2014, NEURAL REGEN RES, V9, P143, DOI 10.4103/1673-5374.125343
   It M, 2012, CEREBELLUM BRAIN IMP
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Kleinschmidt A, 2002, NEUROIMAGE, V16, P873, DOI 10.1006/nimg.2002.1181
   Krueger Charlene, 2004, Biol Res Nurs, V6, P151, DOI 10.1177/1099800404267682
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Liao YY, 2020, EUR J PHYS REHAB MED, V56, P47, DOI 10.23736/S1973-9087.19.05899-4
   Lithgow B, 2012, ANN BIOMED ENG, V40, P1835, DOI 10.1007/s10439-012-0526-3
   Lithgow BJ, 2019, EUR ARCH PSY CLIN N, V269, P761, DOI 10.1007/s00406-018-0935-x
   Lithgow BJ, 2015, WORLD J BIOL PSYCHIA, V16, P334, DOI 10.3109/15622975.2015.1014410
   Lithgow BJ, 2015, J NEUROL SCI, V353, P49, DOI 10.1016/j.jns.2015.03.050
   Longstaff A., 2005, Instant notes in neuroscience (BIOS instant notes)
   Mallinson A, 2011, THESIS
   MARLINSKY VV, 1995, NEUROSCIENCE, V69, P661, DOI 10.1016/0306-4522(95)00231-7
   Öhman A, 2005, PSYCHONEUROENDOCRINO, V30, P953, DOI 10.1016/j.psyneuen.2005.03.019
   Oman C.M., 1989, Sensory conflict in motion sickness: an observer theory approach, P1
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   Pisella L, 2011, PHILOS T R SOC B, V366, P572, DOI 10.1098/rstb.2010.0258
   Prakriti Trivedi DNB, 2017, INT J SCI ENG TECHNO, V6, P2278, DOI [10.3389/fnins.2016.00584, DOI 10.3389/FNINS.2016.00584]
   Reschke Millard F, 2017, OTO Open, V1, p2473974X17738767, DOI 10.1177/2473974X17738767
   Saman Yougan, 2012, Front Neurol, V3, P116, DOI 10.3389/fneur.2012.00116
   Sharpe J, 2005, Walsh Hoyt's Clin Neuro Ophthalmol, V16, P809
   Shin LM, 2010, NEUROPSYCHOPHARMACOL, V35, P169, DOI 10.1038/npp.2009.83
   Shinder ME, 2010, J VESTIBUL RES-EQUIL, V20, P3, DOI 10.3233/VES-2010-0344
   SIMES RJ, 1986, BIOMETRIKA, V73, P751, DOI 10.2307/2336545
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Srinivasan V, 1989, IND J PHYSL PHARM, V33
   Suleiman A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32808-1
   Szirmai A, 2011, ANXIETY RELAT DISORD, V1, P191
   Teather R., 2008, COMP 2D 3D DIRECT MA
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Van Essen DC, 2001, VISION RES, V41, P1359, DOI 10.1016/S0042-6989(01)00045-1
   White BJ, 2017, P NATL ACAD SCI USA, V114, P9451, DOI 10.1073/pnas.1701003114
   Yamanaka T, 1994, Nihon Jibiinkoka Gakkai Kaiho, V97, P855
   Zajonc Timothy P, 2005, Ear Nose Throat J, V84, P581
NR 63
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 731
EP 744
DI 10.1007/s10055-020-00488-w
EA NOV 2020
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000592567800001
DA 2024-07-18
ER

PT J
AU Yildirim, C
AF Yildirim, Caglar
TI Don't make me sick: investigating the incidence of cybersickness in
   commercial virtual reality headsets
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cybersickness; Motion sickness; Head-mounted displays;
   HMD; Human factors of VR
ID MOTION SICKNESS
AB The resurgence of interest in the use of virtual reality (VR) technology for research and entertainment purposes has led to an increase in concerns about human factor issues inherent in VR technology. One issue that has received a great deal of attention from researchers and end users is cybersickness, which refers to a constellation of unpleasant physiological symptoms, such as nausea and dizziness, experienced as result of exposure to a virtual environment. While cybersickness is not a new issue, it is expected to become even more prevalent with the recent proliferation of commercially available VR headsets, such as Oculus Rift and HTC Vive, underscoring the importance of investigating the prevalence of cybersickness while using these headsets. Accordingly, in two experiments, the current study examined whether cybersickness was a persistent issue in the state-of-the-art commercial-grade VR headsets and compared the incidence and severity of cybersickness across Oculus Rift CV1, HTC Vive and a desktop display. Consistent with prior work into head-mounted displays and cybersickness, results indicated that participants in the Oculus Rift CV1 and HTC Vive conditions experienced more severe cybersickness symptoms, when compared to those in the desktop display condition. Oculus Rift CV1 and HTC Vive did not significantly differ from each other and were comparable in the severity of cybersickness symptoms they induce. The current study demonstrated that cybersickness was still a prevalent human factor issue in such modern VR headsets as Oculus Rift and HTC Vive, highlighting the importance of devising strategies to mitigate cybersickness in VEs.
C1 [Yildirim, Caglar] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.
C3 Northeastern University
RP Yildirim, C (corresponding author), Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.
EM c.yildirim@northeastern.edu
RI Yildirim, Caglar/AAH-5920-2021
OI Yildirim, Caglar/0000-0002-0346-9299
CR [Anonymous], VIRTUAL REAL
   [Anonymous], P HUM FACT ERG SOC A
   [Anonymous], ASS CORS
   [Anonymous], 2017, P IS T INT S EL IM E, DOI DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-097
   [Anonymous], SERIOUS SAM VR 1 ENC
   [Anonymous], VIVE VR SYST
   [Anonymous], 1968, P DEC 9 11 1968 FALL
   [Anonymous], P 2014 C INT ENT NEW
   [Anonymous], VIRTUAL REALITY IS C
   [Anonymous], INT C HUM COMP INT B
   [Anonymous], SERIOUS SAM HD 1 ENC
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Davis S, 2015, P 11 AUSTR C INT ENT, V27, P30
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Field A., 2013, DISCOVERING STAT USI
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kim JM, 2015, FRONT PLANT SCI, V6, DOI [10.3389/fpls.2015.00114, 10.3389/fpsyg.2015.00248]
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   REASON JT, 1969, INT J MAN MACH STUD, V1, P21, DOI 10.1016/S0020-7373(69)80009-X
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Walker AD, 2010, AVIAT SPACE ENVIR MD, V81, P929, DOI 10.3357/ASEM.2735.2010
   Young SD, 2006, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2006.44
NR 37
TC 71
Z9 78
U1 2
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 231
EP 239
DI 10.1007/s10055-019-00401-0
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800004
DA 2024-07-18
ER

PT J
AU Chandrasiri, A
   Collett, J
   Fassbender, E
   De Foe, A
AF Chandrasiri, Amaya
   Collett, James
   Fassbender, Eric
   De Foe, Alexander
TI A virtual reality approach to mindfulness skills training
SO VIRTUAL REALITY
LA English
DT Article
DE Mindfulness skills; Brief mindfulness intervention; Virtual reality;
   Toronto Mindfulness Scale; Randomised control trial
ID STRESS REDUCTION; COGNITIVE THERAPY; EXPOSURE THERAPY; MEDITATION;
   ANXIETY; AUGMENTATION; BENEFITS
AB Virtual reality (VR) is increasingly incorporated into psychotherapy, with the literature documenting its effectiveness in treating anxiety disorders, pain, and stress. Few studies have incorporated VR into mindfulness interventions. The present study examined the efficacy of VR in facilitating mindfulness. It was hypothesised that a brief mindfulness intervention integrated with VR would lead to a greater elevation in mindfulness than conventional mindfulness practice. Thirty-two adults (16 males) aged 18-65 (M = 27.25, SD = 6.04) were randomly allocated to either a control condition, in which participants listened to a mindfulness audio track, or an experimental condition, in which participants received mindfulness practice in a VR beach environment. The Toronto Mindfulness Scale (Lau et al. J clin psychol 62(12):1445-1467 2006) was used to assess two mindfulness factors: curiosity and decentring. Although participants in the experimental condition experienced an increase in mindfulness, VR was not significantly more effective in facilitating mindfulness overall, although the VR condition was characterised by a significantly greater increase in decentring. Replication and investigation of causative mechanisms is necessary to further understand the distinct increase in decentring observed during VR-enhanced mindfulness training in this study.
C1 [Chandrasiri, Amaya; Collett, James; Fassbender, Eric; De Foe, Alexander] RMIT Univ, Melbourne, Vic, Australia.
   [Fassbender, Eric] Atmosphaeres 360 Stock Videos & VR Experiences, Cologne, Germany.
C3 Royal Melbourne Institute of Technology (RMIT)
RP De Foe, A (corresponding author), RMIT Univ, Melbourne, Vic, Australia.
EM alexander.defoe@rmit.edu.au
RI De Foe, Alexander/HLV-6625-2023
OI De Foe, Alexander/0000-0002-5532-3291; Collett,
   James/0000-0003-1790-0390
CR Aiken MP, 2015, VIRTUAL REAL-LONDON, V19, P95, DOI 10.1007/s10055-015-0260-x
   Broderick P, 2005, COGNITIVE THER RES, V29, P501, DOI 10.1007/s10608-005-3888-0
   Brown KW, 2007, PSYCHOL INQ, V18, P211, DOI 10.1080/10478400701598298
   Burdea G., 1994, VIRTUAL REALITY TECH
   Burdea G.C., 1999, Haptic feedback for virtual reality
   Call D, 2014, MINDFULNESS, V5, P658, DOI 10.1007/s12671-013-0218-6
   Carlin AS, 1997, BEHAV RES THER, V35, P153, DOI 10.1016/S0005-7967(96)00085-X
   Carmody J, 2009, J CLIN PSYCHOL, V65, P613, DOI 10.1002/jclp.20579
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Crescentini C, 2016, COMPUT HUM BEHAV, V59, P304, DOI 10.1016/j.chb.2016.02.031
   da Costa RMEM, 2004, COMPUT METH PROG BIO, V73, P173, DOI 10.1016/S0169-2607(03)00066-X
   Davis DM, 2011, PSYCHOTHERAPY, V48, P198, DOI 10.1037/a0022062
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Difede J, 2014, NEUROPSYCHOPHARMACOL, V39, P1052, DOI 10.1038/npp.2013.317
   Eagle JL, 2008, THESIS
   Evans S, 2008, J ANXIETY DISORD, V22, P716, DOI 10.1016/j.janxdis.2007.07.005
   Garcia-Palacios A, 2007, CYBERPSYCHOL BEHAV, V10, P722, DOI 10.1089/cpb.2007.9962
   Gebara CM, 2016, REV BRAS PSIQUIATR, V38, P24, DOI 10.1590/1516-4446-2014-1560
   Goldin PR, 2010, EMOTION, V10, P83, DOI 10.1037/a0018441
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Grossman P, 2004, J PSYCHOSOM RES, V57, P35, DOI 10.1016/S0022-3999(03)00573-7
   Hayes-Skelton S, 2013, BEHAV COGN PSYCHOTH, V41, P317, DOI 10.1017/S1352465812000902
   Hepburn SR, 2009, BRIT J CLIN PSYCHOL, V48, P209, DOI 10.1348/014466509X414970
   Herrero R, 2014, CYBERPSYCH BEH SOC N, V17, P379, DOI 10.1089/cyber.2014.0052
   Hill C, 2017, BRIT J PSYCHIAT, V211, P65, DOI 10.1192/bjp.bp.115.180372
   Hilton L, 2017, ANN BEHAV MED, V51, P199, DOI 10.1007/s12160-016-9844-2
   Jislin-Goldberg T, 2012, J POSIT PSYCHOL, V7, P349, DOI 10.1080/17439760.2012.700724
   KABATZINN J, 1982, GEN HOSP PSYCHIAT, V4, P33, DOI 10.1016/0163-8343(82)90026-3
   Khoury B, 2013, CLIN PSYCHOL REV, V33, P763, DOI 10.1016/j.cpr.2013.05.005
   Larson MJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00308
   Lau MA, 2006, J CLIN PSYCHOL, V62, P1445, DOI 10.1002/jclp.20326
   Linehan MM, 2006, ARCH GEN PSYCHIAT, V63, P757, DOI 10.1001/archpsyc.63.7.757
   Lutz A, 2008, TRENDS COGN SCI, V12, P163, DOI 10.1016/j.tics.2008.01.005
   Lymeus F, 2017, ENVIRON BEHAV, V49, P536, DOI 10.1177/0013916516657390
   Malinowski P., 2008, The Irish Journal of Psychology, V29, P155, DOI [DOI 10.1080/03033910.2008.10446281, 10.1080/03033910.2008.10446281]
   Nararro-Haro MV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01573
   Nyklícek I, 2014, J BEHAV MED, V37, P135, DOI 10.1007/s10865-012-9475-4
   Rahl HA, 2017, EMOTION, V17, P224, DOI 10.1037/emo0000250
   Rauterberg M., 2004, P IFIP INT WORK C SY, P51
   Ready D.J., 2006, J AGGRESSION MALTREA, V12, P199, DOI [DOI 10.1300/J146V12N01_11, 10.1300/J146v12n01_11]
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Schoultz M, 2015, TRIALS, V16, DOI 10.1186/s13063-015-0909-5
   Shapiro SL, 2008, J CLIN PSYCHOL, V64, P840, DOI 10.1002/jclp.20491
   Tan LBG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110510
   Tang YY, 2015, NAT REV NEUROSCI, V16, P213, DOI 10.1038/nrn3916
   Teasdale JD, 2000, J CONSULT CLIN PSYCH, V68, P615, DOI 10.1037//0022-006X.68.4.615
   University of Melbourne, 2017, COUNS PSYCH SERV
   Wiederhold MD, 2007, PAIN MED, V8, pS182, DOI 10.1111/j.1526-4637.2007.00381.x
   Wolitzky K, 2005, PSYCHOL HEALTH, V20, P817, DOI 10.1080/14768320500143339
NR 50
TC 48
Z9 50
U1 13
U2 110
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 143
EP 149
DI 10.1007/s10055-019-00380-2
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800009
DA 2024-07-18
ER

PT J
AU McGill, M
   Williamson, J
   Ng, A
   Pollick, F
   Brewster, S
AF McGill, Mark
   Williamson, Julie
   Ng, Alexander
   Pollick, Frank
   Brewster, Stephen
TI Challenges in passenger use of mixed reality headsets in cars and other
   transportation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Augmented reality; Mixed reality; Transportation;
   Passenger; In-car; In-flight; Travel
ID MOTION SICKNESS; KNOWLEDGE; SPACE
AB This paper examines key challenges in supporting passenger use of augmented and virtual reality headsets in transit. These headsets will allow passengers to break free from the restraints of physical displays placed in constrained environments such as cars, trains and planes. Moreover, they have the potential to allow passengers to make better use of their time by making travel more productive and enjoyable, supporting both privacy and immersion. However, there are significant barriers to headset usage by passengers in transit contexts. These barriers range from impediments that would entirely prevent safe usage and function (e.g. motion sickness) to those that might impair their adoption (e.g. social acceptability). We identify the key challenges that need to be overcome and discuss the necessary resolutions and research required to facilitate adoption and realize the potential advantages of using mixed reality headsets in transit.
C1 [McGill, Mark; Williamson, Julie; Ng, Alexander; Pollick, Frank; Brewster, Stephen] Univ Glasgow, Sch Comp Sci, Sch Psychol, Glasgow, Lanark, Scotland.
C3 University of Glasgow
RP McGill, M (corresponding author), Univ Glasgow, Sch Comp Sci, Sch Psychol, Glasgow, Lanark, Scotland.
EM mark.mcgill@glasgow.ac.uk
RI Brewster, Stephen A/J-9003-2017; Pollick, Frank/F-3186-2011
OI Pollick, Frank/0000-0002-7212-4622
FU EPSRC IAA [303740]; ESRC IAA [77563/1]; European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   programme [835197 -ViAjeRo]
FX This research was funded in part by the EPSRC IAA (303740) and ESRC IAA
   (77563/1) joint project "CarVR: Immersion in the Journey". This project
   also received funding from the European Research Council (ERC) under the
   European Union's Horizon 2020 research and innovation programme (Grant
   Agreement No. 835197 -ViAjeRo).
CR Ahmadpour N, 2016, WORK, V54, P981, DOI 10.3233/WOR-162346
   Ahmadpour N, 2014, ERGONOMICS, V57, P801, DOI 10.1080/00140139.2014.899632
   Air France, 2017, IMM HEADS BOARD AIR
   [Anonymous], 2014, FLIGHT ENTERTAINMENT
   [Anonymous], 2017, GULLIVER VIRTUAL REA
   [Anonymous], 2016, FORD PATENTS WINDSHI
   [Anonymous], 2016, F015 AUT CONC CAR
   [Anonymous], 2016, LONG COMM 3
   [Anonymous], 2017, HEATHROW FACTS FIGUR
   [Anonymous], 2011, WIND WORLD MULT SYST
   [Anonymous], 2015, PRESS ASS MILLIONS P
   [Anonymous], 2018, INFLYT EXP SEATB DIS
   [Anonymous], 2015, QANT SAMS UNV IND 1
   [Anonymous], 2019, 360 GUY ULTIMATE VR
   [Anonymous], 2018, VRCHAT VRCHAT SOCIAL
   [Anonymous], 2015, NUMB COMM SPEND MOR
   [Anonymous], 1975, Motion sickness
   [Anonymous], 2009, SUMM TRAV TRENDS
   [Anonymous], 2018, SKARREDGHOST VIRTUAL
   [Anonymous], 2017, SKARREDGHOST ALL YOU
   [Anonymous], 2018, VIVE BLOG INTRO LOGI
   [Anonymous], 2018, TECH REP
   Antonov M, 2015, ASYNCHRONOUS TIMEWAR
   Arshad Q, 2015, NEUROLOGY, V85, P1257, DOI 10.1212/WNL.0000000000001989
   Baldwin A, 2017, ROUTL STUD ENV MIGR, P219
   Baseel C, 2014, JAPANESE PEOPLE LEAS
   Bertolini G, 2016, MOVING MOVING WORLD, P14, DOI DOI 10.3389/FNEUR.2016.00014
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Boland Daniel., 2015, XRDS: Crossroads, The ACM Magazine for Students, V22, P40, DOI [10.1145/2810046, DOI 10.1145/2810046]
   Bose, 2019, Wearables by Bose-AR Audio Sunglasses
   Buckley S., 2015, THIS IS VALVES AMAZI
   Burnett G., 2013, Proceedings of the 5th International Conference on Automotive User Interfaces and Interactive Vehicular ApplicationsACM, P22, DOI DOI 10.1145/2516540.2516545
   Cappitelli M, 2014, FINAL ADVISORY BOARD
   Carter L, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188615
   Cevette MJ, 2012, AVIAT SPACE ENVIR MD, V83, P549, DOI 10.3357/ASEM.3239.2012
   Chan LW, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2625
   Chittaro L, 2018, SAFETY SCI, V102, P159, DOI 10.1016/j.ssci.2017.10.012
   Cummings JJ, 2015, IMMERSIVE IS ENOUGH, P1, DOI [10.1080/15213269.2015.1015740, DOI 10.1080/15213269.2015.1015740]
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dent S, 2017, RENAULTS CONCEPT EV
   Diels C., 2014, Contemporary Ergonomics and Human Factors, P301, DOI DOI 10.13140/RG.2.1.1461.0087
   Diels C, 2008, THESIS
   Diels C, 2016, LECT N MOBIL, P121, DOI 10.1007/978-3-319-40503-2_10
   Diels C, 2015, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS (AUTOMOTIVE UI '15), P14, DOI 10.1145/2809730.2809754
   Diels C, 2016, APPL ERGON, V53, P374, DOI 10.1016/j.apergo.2015.09.009
   Durbin J, OCULUS ACQUISITION M
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   Elbanhawi M, 2015, IEEE INTEL TRANSP SY, V7, P4, DOI 10.1109/MITS.2015.2405571
   Feltham J, 2015, PALMER LUCKEY EXPLAI
   Feltham J, 2019, MICROSOFT VR HEADSET
   Frangakis N, 2014, RES ROADMAP
   Frisson C, 2017, ADJ P 2017 ACM S US
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gardner B, 2007, TRANSPORT RES F-TRAF, V10, P187, DOI 10.1016/j.trf.2006.09.004
   Gekhman D, 2006, MASS HUMAN HEAD
   Goedicke D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173739
   Golding JF, 2015, CURR OPIN NEUROL, V28, P83, DOI 10.1097/WCO.0000000000000163
   Groening S, 2016, ONE LIKES BE CAPTIVE
   Groening S, 2013, HIST TECHNOL, V29, P284, DOI 10.1080/07341512.2013.858523
   Guedry FE, 1978, CORIOLIS CROSS COUPL, P29
   Haeuslschmid R, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P319, DOI 10.1145/3025171.3025198
   Haeuslschmid R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5076, DOI 10.1145/2858036.2858336
   Hakkila J., 2014, Adjunct Proceedings of the 6th International Conference on Automotive User Interfaces and Interactive Vehicular Applications, P1
   Hanau E, 2017, AUTOMOTIVEUI'17: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P72, DOI 10.1145/3131726.3131741
   Hauslschmid Renate., 2015, P 20 INT C INTELLIGE, P311, DOI DOI 10.1145/2678025.2701393
   Hecht Tobias, 2019, INT C HUM INT EM, P28
   Hock P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4034, DOI 10.1145/3025453.3025665
   Hoffman M, 2016, MICR BUILD DEV C
   Holly R, 2017, USING VR AIRPLANE IS
   Hong S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P303, DOI 10.1145/2993369.2996309
   Hosseini M, 2015, VESTIBULAR FINDINGS
   International S, 2016, TAX DEF TERMS REL DR
   Ion F, 2016, TOO SICK STAND WHAT
   Kaiser U, 1999, INST PHYS CONF SER, P239
   Karjanto J, 2018, TRANSPORT RES F-TRAF, V58, P678, DOI 10.1016/j.trf.2018.06.046
   Kaya M, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P47, DOI 10.1109/ICAR.2015.7251432
   Kodama R, 2017, IEEE SYMP 3D USER, P130, DOI 10.1109/3DUI.2017.7893329
   Koisaari T, 2017, TRAFFIC INJ PREV, V18, P493, DOI 10.1080/15389588.2016.1271945
   Kuchera B, 2015, IM CREEPY GUY WEARIN
   Kuiper OX, 2018, APPL ERGON, V68, P169, DOI 10.1016/j.apergo.2017.11.002
   Kun AL, 2016, SHIFTING GEARS USER, P32
   Kun AL, 2017, P 9 INT DRIV S HUM F
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Large DR, 2017, INT J MOB HUM COMPUT, V9, P18, DOI 10.4018/IJMHCI.2017040102
   LaValle SM, 2014, IEEE INT CONF ROBOT, P187, DOI 10.1109/ICRA.2014.6906608
   Lewis L, 2017, ERGONOMICS, V60, P1461, DOI 10.1080/00140139.2017.1313456
   Lewis L, 2016, WORK, V54, P963, DOI 10.3233/WOR-162356
   Lucero Andres, 2014, P 11 C ADV COMP ENT, P1, DOI DOI 10.1145/2663806.2663824
   Mangiante S, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P30, DOI 10.1145/3097895.3097901
   Marshall J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300930
   Marshall J, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P215, DOI 10.1145/2901790.2901844
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   McGill M, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2983530
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Ng A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2845, DOI 10.1145/3025453.3025736
   Ng A, 2016, 8TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS (AUTOMOTIVEUI 2016), P121, DOI 10.1145/3003715.3005420
   Ng Alexander, 2017, P 2017 CHI C HUM FAC
   Orlosky J., 2017, J INF PROCESS SYST, V25, P133, DOI [DOI 10.2197/IPSJJIP.25.133, 10.2197/ipsjjip.25.133, DOI 10.2197/IPSJJIP.25, 10.2197/ipsjjip.25]
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Owen N, 1998, BRAIN RES BULL, V47, P471, DOI 10.1016/S0361-9230(98)00101-4
   Paredes Pablo E., 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287062
   Patel H, 2018, TRANSPORT REV, V38, P252, DOI 10.1080/01441647.2017.1307877
   Pauzie A, 2015, LECT NOTES COMPUT SC, V9188, P505, DOI 10.1007/978-3-319-20889-3_47
   Pots J, 2016, COLLABORATING HOLOGR
   Rao Q, 2014, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2014.6948402
   Rao Q, 2014, DES AUT CON, DOI 10.1145/2593069.2602973
   Redlick FP, 2001, VISION RES, V41, P213, DOI 10.1016/S0042-6989(00)00243-1
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rico J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P887
   Rober M, 2018, Immersive virtual display ., Patent No. 20180089901
   ROLNICK A, 1991, ERGONOMICS, V34, P867, DOI 10.1080/00140139108964831
   Russell M, 2011, J PUBLIC TRANSPORT, V14, P123, DOI 10.5038/2375-0901.14.3.7
   Sawabe T, 2017, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2017.7892284
   Shakeri G, 2016, 8TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS (AUTOMOTIVEUI 2016), P129, DOI 10.1145/3003715.3005417
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sivak Michael, 2015, MOTION SICKNESS SELF
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith M, 2016, LONDONERS ARE MOST E
   Soyka F, 2015, P IEEE VIRT REAL ANN, P33, DOI 10.1109/VR.2015.7223321
   Stevens AH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1872, DOI [10.1109/VR.2019.8797800, 10.1109/vr.2019.8797800]
   Studarus Laura., 2018, BBC
   Tervon T, 2014, SPECTACLE WEAR AIRBA
   Toppan R, 2015, ADJ P 7 INT C AUT US
   Wang SW, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P851, DOI 10.1145/2984511.2984565
   Watts L, 2008, ENVIRON PLANN D, V26, P860, DOI 10.1068/d6707
   Wienrich C, 2017, PILOTSTUDIE EINSATZ
   Wilfinger D, 2011, LECT NOTES COMPUT SC, V6947, P657, DOI 10.1007/978-3-642-23771-3_48
   Wiliamson J.R., 2011, P 13 INT C MULTIMODA, P361, DOI [DOI 10.1145/2070481.2070551, 10.1145/2070481.2070551]
   Williamson JR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300310
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Zhang LL, 2016, CNS NEUROSCI THER, V22, P15, DOI 10.1111/cns.12468
   Zuniga AMF, 2017, HUM FACTORS, V59, P546, DOI 10.1177/0018720816684690
NR 133
TC 38
Z9 38
U1 3
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 583
EP 603
DI 10.1007/s10055-019-00420-x
EA DEC 2019
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000542936400001
OA Green Published, hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Shu, Y
   Huang, YZ
   Chang, SH
   Chen, MY
AF Shu, Yu
   Huang, Yen-Zhang
   Chang, Shu-Hsuan
   Chen, Mu-Yen
TI Do virtual reality head-mounted displays make a difference? A comparison
   of presence and self-efficacy between head-mounted displays and desktop
   computer-facilitated virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Head-mounted display; Spatial presence; Immersion;
   Self-efficacy
ID LEARNING OUTCOMES; IMMERSION; EXPERIENCE; EDUCATION
AB Virtual reality (VR) has made it possible for users to access novel digital experiences. An interesting question that arises in the context of VR is whether it appears or feels different to users when different virtual environments are used. This study investigates the effect of VR head-mounted display (HMD) and desktop computer-facilitated VR on users' sense of presence (spatial presence and immersion) and task-oriented self-efficacy when exposed to an earthquake education VR system. A quasi-experiment design was used with a sample of 96 university students. The results revealed that the VR system had positive impacts on the users' earthquake preparedness self-efficacy. Although the experiment group (n = 39) had repeated experiences, as they first used desktop VR followed by VR HMD for the same content, users indicated a higher sense of spatial presence and immersion while using VR HMD than when using desktop VR. In addition, a VR HMD single-group pre- and posttest experimental design was performed with 20 participants, and the differences between the pretest and posttest measurements of earthquake preparedness and self-efficacy were determined to be significant. The qualitative results reveal that the visual stimulus and motion are relevant in composing the VR experience.
C1 [Shu, Yu; Chang, Shu-Hsuan] Natl Changhua Univ Educ, Changhua, Taiwan.
   [Huang, Yen-Zhang; Chen, Mu-Yen] Natl Taichung Univ Sci & Technol, Taichung, Taiwan.
C3 National Changhua University of Education; National Taichung University
   of Science & Technology
RP Chen, MY (corresponding author), Natl Taichung Univ Sci & Technol, Taichung, Taiwan.
EM vera.yushu@gmail.com; jou66jou@gmail.com; shc@cc.ncue.edu.tw;
   mychen@nutc.edu.tw
RI Chen, Mu-Yen/AAO-6568-2021
CR Allen RJ, 2015, MEM COGNITION, V43, P555, DOI 10.3758/s13421-014-0481-3
   Anglin J, 2017, P IEEE VIRT REAL ANN, P401, DOI 10.1109/VR.2017.7892346
   Annetta LA, 2009, COMPUT EDUC, V53, P74, DOI 10.1016/j.compedu.2008.12.020
   BANDURA A, 1986, J SOC CLIN PSYCHOL, V4, P359, DOI 10.1521/jscp.1986.4.3.359
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Bun P, 2015, PROCEDIA COMPUT SCI, V75, P173, DOI 10.1016/j.procs.2015.12.235
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Heeter C., 2000, J. Interact. Advert., V1, P3, DOI [DOI 10.1080/15252019.2000.10722040, 10.1080/15252019.2000.10722040]
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Hou JH, 2012, COMPUT HUM BEHAV, V28, P617, DOI 10.1016/j.chb.2011.11.007
   Huang HM, 2016, INTERACT LEARN ENVIR, V24, P3, DOI 10.1080/10494820.2013.817436
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   KRAIGER K, 1993, J APPL PSYCHOL, V78, P311, DOI 10.1037/0021-9010.78.2.311
   Lan YJ, 2018, EDUC TECHNOL SOC, V21, P213
   LAZAROWITZ R, 1994, J RES SCI TEACH, V31, P1121, DOI 10.1002/tea.3660311006
   Leong A, 2018, J MED RADIAT SCI, V65, P97, DOI 10.1002/jmrs.272
   Lin TJ, 2015, EDUC TECHNOL SOC, V18, P486
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lombard M., 2009, P 12 ANN INT WORKSH, P1
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Messinis I, 2010, 2010 INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING: IC4E 2010, PROCEEDINGS, P428, DOI 10.1109/IC4E.2010.137
   Mikropoulos T.A., 2006, VIRTUAL REAL-LONDON, V10, P197, DOI DOI 10.1007/S10055-006-0039-1
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Mulilis J.P., 1990, NAT HAZARDS, V3, P357, DOI [DOI 10.1007/BF00124393, 10.1007/BF00124393]
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Patrick E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P478, DOI 10.1145/332040.332479
   Persky S, 2009, CYBERPSYCHOL BEHAV, V12, P263, DOI 10.1089/cpb.2008.0262
   Prensky M., 2003, Computers in Entertainment (CIE), V1, P21, DOI DOI 10.1145/950566.950596
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Tamaddon K, 2017, K 12 EMB LEARN VIRT, P1
   Tanes Z, 2013, COMPUT HUM BEHAV, V29, P858, DOI 10.1016/j.chb.2012.11.003
   Toumpaniari K, 2015, EDUC PSYCHOL REV, V27, P445, DOI 10.1007/s10648-015-9316-4
   Wang YF, 2017, BRIT J EDUC TECHNOL, V48, P431, DOI 10.1111/bjet.12388
   Williamson John, 1997, THESIS
   Yi-Shiuan Chou, 2012, 2012 IEEE 4th International Conference on Digital Game and Intelligent Toy Enhanced Learning (DIGITEL 2012), P156, DOI 10.1109/DIGITEL.2012.44
NR 39
TC 104
Z9 105
U1 5
U2 196
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 437
EP 446
DI 10.1007/s10055-018-0376-x
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300010
DA 2024-07-18
ER

PT J
AU Farooq, U
   Glauert, J
AF Farooq, Umar
   Glauert, John
TI Faster dynamic spatial partitioning in OpenSimulator
SO VIRTUAL REALITY
LA English
DT Article
DE Simulation; Virtual world; Second life; OpenSimulator; Scalability
ID MANAGEMENT
AB OpenSimulator has emerged as one of the leading tools to help researchers, developers, and practitioners working in the field of virtual worlds since it is an open-source alternative to second life, the state of the art in virtual worlds. The grid mode of OpenSimulator is highly scalable, and it places no restriction on the number of cooperating OpenSimulator instances, each of which may simulate activity in an arbitrary number of regions. However, like second life, it suffers from both over-provision and under-provision of resources due to static allocation of regions to instances and the lack of an expansion and contraction model which adjusts resource allocation according to workload. We have used OpenSimulator to implement dynamic scalability which is an integral part of our novel infrastructure presented in earlier work. This paper reports timing analysis of the basic capabilities of OpenSimulator that are used to re-locate regions to additional simulators. The focus has been on a conservative extension to OpenSimulator using existing methods. To overcome serious performance issues during reassignment of a region, we present two extended region removal methods. Comparison of timing information for both existing and extended strategies is provided on both a network of Windows systems and a cluster of Linux nodes.
C1 [Farooq, Umar] Univ Sci & Technol Bannu, Bannu, Pakistan.
   [Glauert, John] Univ East Anglia, Sch Comp Sci, Norwich, Norfolk, England.
C3 University of Science & Technology Bannu; University of East Anglia
RP Farooq, U (corresponding author), Univ Sci & Technol Bannu, Bannu, Pakistan.
EM umar@ustb.edu.pk; j.glauert@uea.ac.uk
CR [Anonymous], FAIRIECASTLE ARCH
   [Anonymous], P 9 ANN WORKSH NETW
   [Anonymous], 2000, PARALLEL DISTRIBUTED
   [Anonymous], 2010, 1004 PORTL STAT U DE
   [Anonymous], THESIS
   [Anonymous], CSI VIRTUAL WORLD AR
   [Anonymous], 16 INT WORKSH NETW O
   [Anonymous], 1980, OCTREE ENCODING NEW
   [Anonymous], WORLD OF WARCRAFT
   [Anonymous], J VIRTUAL WORLDS RES
   [Anonymous], EXT VIRT WORLDS WORK
   [Anonymous], OP VIRT COLL ENV OPE
   [Anonymous], TECHNICAL REPORT
   [Anonymous], IEEE INT C VIRT ENV
   [Anonymous], MAYA PYRAMID ARCH
   [Anonymous], 2016, UNITY3D
   [Anonymous], LOAD BALANCER PROJEC
   [Anonymous], 2011, ICCNIT 11
   [Anonymous], J VIRTUAL WORLDS RES
   Balan RK, 2005, LECT NOTES COMPUT SC, V3790, P390
   Chan Luther., 2007, NETGAMES 07, P37, DOI [10.1145/1326257.1326264, DOI 10.1145/1326257.1326264]
   De Vleeschauwer B., 2005, ACM SIGCOMM Workshop on Network and System Support for Games, P1
   Farooq Umar, 2010, Journal of Digital Information Management, V8, P181
   Farooq U, 2009, IEEE ACM DIS SIM, P105, DOI 10.1109/DS-RT.2009.32
   Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933
   Fishwick PA, 2009, WINT SIMUL C PROC, P177, DOI 10.1109/WSC.2009.5429324
   Fujimoto R.M., 2007, NETWORK SIMULATION
   Ge ZH, 2007, MULTIMEDIA SYST, V13, P235, DOI 10.1007/s00530-007-0092-y
   Gupta N, 2009, PROC INT CONF DATA, P1311, DOI 10.1109/ICDE.2009.228
   Hampel T., 2006, PROC 5 ACM SIGCOMM W, P48, DOI [10.1145/1230040.1230058, DOI 10.1145/1230040.1230058]
   Helmer J, 2007, TECH REP
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   Intel Lab, 2015, SCIENCESIM PERF TEST
   Kim BK, 2006, LECT NOTES COMPUT SC, V4331, P813
   Lab Intel, 2010, CISC VIS NETW IND GL
   Lee K., 2003, P ACM S VIRTUAL REAL, P160
   Lesko C. J., 2013, J VIRTUAL WORLDS RES, V6, P1
   Liu HY, 2010, IEEE ACM DIS SIM, P43, DOI 10.1109/DS-RT.2010.14
   Liu HY, 2010, WINT SIMUL C PROC, P778, DOI 10.1109/WSC.2010.5679112
   Louche J-M, 2015, EDUCATIONSIM ARCH
   Lui JCS, 2002, IEEE T PARALL DISTR, V13, P193, DOI 10.1109/71.993202
   Malaby ThomasM., 2009, Making Virtual Worlds: Linden Lab and Second Life
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   OSim-Org, 2015, OPENSIMULATOR GRID
   Prasetya K., 2008, Proc. 7th ACM SIGCOMM Workshop on Network and System Support for Games (NetGames '08), P72
   Rhalibi AE, 2006, ACM SIGCHI INT C ADV
   Rosedale Philip., 2003, Gamasutra
   Schroeder R., 2008, Journal of Virtual Worlds Research: Past, Present Future, V1, P2, DOI 10.4101/jvwr.v1i1.294
   Shirmohammadi S, 2008, SIMUL-T SOC MOD SIM, V84, P215, DOI 10.1177/0037549708092832
   Wang TQ, 2006, J SUPERCOMPUT, V36, P249, DOI 10.1007/s11227-006-8296-z
NR 50
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2017
VL 21
IS 4
BP 193
EP 202
DI 10.1007/s10055-017-0307-2
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FG6HN
UT WOS:000410473200003
DA 2024-07-18
ER

PT J
AU Lam, J
   Kapralos, B
   Kanev, K
   Collins, K
   Hogue, A
   Jenkin, M
AF Lam, Jonathan
   Kapralos, Bill
   Kanev, Kamen
   Collins, Karen
   Hogue, Andrew
   Jenkin, Michael
TI Sound localization on a horizontal surface: virtual and real sound
   source localization
SO VIRTUAL REALITY
LA English
DT Article
DE Tabletop computer; Surface computer; Spatial sound; Amplitude panning
AB As the technology improves and their cost decreases, tabletop computers and their inherent ability to promote collaboration amongst users are gaining in popularity. Their use in virtual reality-based applications including virtual training environments and gaming where multi-user interactions are common is poised to grow. However, before tabletop computers become widely accepted, there are many questions with respect to spatial sound production and reception for these devices that need to be addressed. Previous work (Lam et al. in ACM Comput Entertain 12(2): 4: 1-4: 19, 2014) has seen the development of loudspeaker-based amplitude panning spatial sound techniques to spatialize a sound to a position on a plane just above a tabletop computer's (horizontal) surface. Although it has been established that the localization of these virtual sources is prone to error, there is a lack of ground truth (reference) data with which to compare these earlier results. Here, we present the results of an experiment that measured sound localization of an actual sound source on a horizontal surface, thus providing such ground truth data. This ground truth data were then compared with the results of previous amplitude panning-based spatial sound techniques for tabletop computing displays. Preliminary results reveal that no substantial differences exist between previous amplitude panning results and the ground truth data reported here, indicating that amplitude panning is a viable spatial sound technique for tabletop computing and horizontal displays in general.
C1 [Lam, Jonathan; Kapralos, Bill; Hogue, Andrew] Univ Ontario, Inst Technol, Oshawa, ON, Canada.
   [Kanev, Kamen] Shizuoka Univ, Hamamatsu, Shizuoka, Japan.
   [Collins, Karen] Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
   [Jenkin, Michael] York Univ, Toronto, ON M3J 2R7, Canada.
C3 Ontario Tech University; Shizuoka University; University of Waterloo;
   York University - Canada
RP Kapralos, B (corresponding author), Univ Ontario, Inst Technol, Oshawa, ON, Canada.
EM jonathan.lam@uoit.ca; bill.kapralos@uoit.ca; kanev@rie.shizuoka.ac.jp;
   collinsk@uwaterloo.ca; andrew.hogue@uoit.ca; jenkin@cse.yorku.ca
OI Jenkin, Michael/0000-0002-2969-0012
FU Research Institute of Electronics, Shizuoka University; Social Science
   and Humanities Research Council of Canada; Natural Sciences and
   Engineering Research Council of Canada; Grants-in-Aid for Scientific
   Research [25560109] Funding Source: KAKEN
FX Funding to support this work has been provided by the Research Institute
   of Electronics, Shizuoka University, in the form of a Cooperative
   Research Projects Grant, the Social Science and Humanities Research
   Council of Canada, and the Natural Sciences and Engineering Research
   Council of Canada.
CR Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Algazi VR, 2011, IEEE SIGNAL PROC MAG, V28, P33, DOI 10.1109/MSP.2010.938756
   Anatomage Inc, 2015, AN TABL VIRT DISS
   [Anonymous], P 19 INT COMM CONTR
   Antani L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077348
   Blauert J, 1996, PSYCHOPHYSICS HUMAN
   CHOWNING JM, 1971, J AUDIO ENG SOC, V19, P2
   Cohen M, 2010, P 9 ACM SIGGRAPH C V, P95
   Cohen Michael., 1995, Virtual Environments and Advanced Interface Design, P291
   Dubrowski A, 2015, P 6 INT C INF INT SY
   Gardner WilliamG., 1998, 3 D AUDIO USING LOUD
   Han JY, 2005, P 18 ACM S US INT SO, P235
   Kapralos B, 2008, PRESENCE-VIRTUAL AUG, V17, P527, DOI 10.1162/pres.17.6.527
   Kruger R., 2004, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V13, P501, DOI 10.1007/s10606-004-5062-8
   Lam J., 2014, ACM COMPUT ENTERTAIN, V12, P4
   Makino H., 1996, 18 ANN M IEEE ENG ME
   Nordahl R., 2014, Oxford Handbook of Interactive Audio
   Ohta Y, 2007, P 123 CONV AUD ENG S
   Parise CV, 2014, P NATL ACAD SCI USA, V111, P6104, DOI 10.1073/pnas.1322705111
   PERROTT DR, 1990, J ACOUST SOC AM, V87, P1728, DOI 10.1121/1.399421
   Pulkki V, 1997, J AUDIO ENG SOC, V45, P456
   Pulkki V, 2001, J AUDIO ENG SOC, V49, P739
   Pulkki V., 2001, THESIS HELSINKI U TE
   Pulkki V, 1996, P INT COMP MUS C ICM, P93
   Sasamoto Y, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P713, DOI 10.1109/ICAwST.2013.6765530
   Scott SD, 2010, HUM-COMPUT INT-SPRIN, P357, DOI 10.1007/978-1-84996-113-4_15
   Sodnik J, 2006, P 2000 INT C AUD DIS, P1
   Valjamae A, 2005, R0372005 CHALM U TEC
   Wallace JR, 2009, PERS UBIQUIT COMPUT, V13, P569, DOI 10.1007/s00779-009-0241-8
   Zhou ZY, 2007, IEEE T SYST MAN CY A, V37, P262, DOI 10.1109/TSMCA.2006.886376
NR 30
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 213
EP 222
DI 10.1007/s10055-015-0268-2
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800006
DA 2024-07-18
ER

PT J
AU Treleaven, J
   Battershill, J
   Cole, D
   Fadelli, C
   Freestone, S
   Lang, K
   Sarig-Bahat, H
AF Treleaven, Julia
   Battershill, Jenna
   Cole, Deborah
   Fadelli, Carissa
   Freestone, Simon
   Lang, Katie
   Sarig-Bahat, Hilla
TI Simulator sickness incidence and susceptibility during neck
   motion-controlled virtual reality tasks
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Motion sickness; Velocity; Neck; Rehabilitation
ID POSTURAL INSTABILITY; ENVIRONMENT EXPOSURE; PAIN; MOVEMENT; MUSCLES;
   BALANCE; DISPLAY; CURVES; GENDER
AB To determine the incidence, severity, and predisposing factors to simulator sickness (SS) when using the neck virtual reality (VR) device in asymptomatic individuals to understand the risk of provoking SS in the development of neck VR as a rehabilitation tool. Thirty-two participants used the VR system. Postural stability was measured before and after each VR module [range of motion (ROM), velocity, and accuracy]. The duration of each module was recorded, and participants reported their SS using a visual analogue scale (SS-VAS)/100 mm. Following the VR assessment, participants completed the Motion Sickness Susceptibility Questionnaire (MSSQ) (child and adult subsections) and Simulator Sickness Questionnaire (SSQ). The incidence of motion sickness during the VR immersion was 28 %, and the mean severity was 17.2 mm on VAS. There was a significant difference in ROM time, total time, MSSQ score, and SSQ score (p < 0.05) between those who reported any level of SS-VAS and those with no SS-VAS. The SS-VAS score displayed significant positive correlations with SSQ score, change in postural stability time pre to post, ROM time, and total time. Results indicate a relatively high incidence but low severity of SS which was associated with the MSSQ child subsection score and exposure time.
C1 [Treleaven, Julia; Battershill, Jenna; Cole, Deborah; Fadelli, Carissa; Freestone, Simon; Lang, Katie] Univ Queensland, Dept Physiotherapy, Brisbane, Qld, Australia.
   [Sarig-Bahat, Hilla] Univ Haifa, Dept Phys Therapy, IL-31999 Haifa, Israel.
C3 University of Queensland; University of Haifa
RP Sarig-Bahat, H (corresponding author), Univ Haifa, Dept Phys Therapy, IL-31999 Haifa, Israel.
EM j.treleaven@uq.edu.au; jenna.battershill@uqconnect.edu.au;
   Debcole87@hotmail.com; carissa.fadelli@uqconnect.edu.au;
   simon.freestone@uq.net.au; katie.lang@uq.net.au;
   hbahat@physicalvirtue.co.il
RI Treleaven, Julia/N-1379-2019; Treleaven, Julia M/F-8734-2010
OI Treleaven, Julia/0000-0002-6258-3972; Treleaven, Julia
   M/0000-0002-6258-3972
CR Bahat HS, 2015, MANUAL THER, V20, P68, DOI 10.1016/j.math.2014.06.008
   BOHANNON RW, 1984, PHYS THER, V64, P1067, DOI 10.1093/ptj/64.7.1067
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   BRAITHWAITE MG, 1990, J SOC OCCUP MED, V40, P105
   Brotherton Sandra S, 2005, J Geriatr Phys Ther, V28, P14
   Bryanton C, 2006, CYBERPSYCHOL BEHAV, V9, P123, DOI 10.1089/cpb.2006.9.123
   Cobb SVG, 1999, APPL ERGON, V30, P47, DOI 10.1016/S0003-6870(98)00038-6
   Cobb SVG, 1998, BRAIN RES BULL, V47, P459, DOI 10.1016/S0361-9230(98)00104-X
   Corneil BD, 2002, J NEUROPHYSIOL, V88, P1980, DOI 10.1152/jn.2002.88.4.1980
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Eisenman LM, 2009, MED HYPOTHESES, V73, P790, DOI 10.1016/j.mehy.2009.04.031
   Feipel V, 1999, INT ORTHOP, V23, P205, DOI 10.1007/s002640050351
   FRANK LH, 1988, HUM FACTORS, V30, P201, DOI 10.1177/001872088803000207
   Golding JF, 2005, CURR OPIN NEUROL, V18, P29, DOI 10.1097/00019052-200502000-00007
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Jerome C, 2005, HUM FACTORS, V49, P2258, DOI DOI 10.1177/154193120504902609
   Kennedy R.S., 1990, MOTION SPACE SICKNES, P317, DOI DOI 10.1207/S15327108IJAP0303_3
   Kennedy RS, 1997, AVIAT SPACE ENVIR MD, V68, P13
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Lampton D.R., 2000, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V44, P530, DOI [DOI 10.1177/154193120004400512, 10.1177/154193120004400512]
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Liu JX, 2003, J HISTOCHEM CYTOCHEM, V51, P175, DOI 10.1177/002215540305100206
   Meehan Michael, 2003, VIRT REAL 2003 P IEE
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Mirelman A, 2009, STROKE, V40, P169, DOI 10.1161/STROKEAHA.108.516328
   MONEY KE, 1970, PHYSIOL REV, V50, P1, DOI 10.1152/physrev.1970.50.1.1
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Öhberg F, 2003, IEEE T INF TECHNOL B, V7, P274, DOI 10.1109/TITB.2003.821328
   REGAN EC, 1994, AVIAT SPACE ENVIR MD, V65, P527
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Röijezon U, 2010, BMC MUSCULOSKEL DIS, V11, DOI 10.1186/1471-2474-11-222
   Sarig-Bahat H, 2010, SPINE, V35, pE105, DOI 10.1097/BRS.0b013e3181b79358
   Sarig-Bahat H, 2009, SPINE, V34, P1018, DOI 10.1097/BRS.0b013e31819b3254
   SELBIE WS, 1993, J MORPHOL, V216, P47, DOI 10.1002/jmor.1052160107
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sjölander P, 2008, MANUAL THER, V13, P122, DOI 10.1016/j.math.2006.10.002
   Stanney K. M., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2114
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 1998, HUM FAC ERG SOC P, P1476
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P447, DOI 10.1162/105474698565848
   Stanney KM, 1999, HUM FAC ERG SOC P, P1223
   Stanney KM, 1999, APPL ERGON, V30, P27, DOI 10.1016/S0003-6870(98)00039-8
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Vereeck L, 2008, INT J AUDIOL, V47, P67, DOI 10.1080/14992020701689688
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Warwick-Evans LA, 1998, BRAIN RES BULL, V47, P465, DOI 10.1016/S0361-9230(98)00090-2
   Webb CM, 2009, AVIAT SPACE ENVIR MD, V80, P541, DOI 10.3357/ASEM.2454.2009
   Wulf G, 2007, RES Q EXERCISE SPORT, V78, P384, DOI 10.5641/193250307X13082505158336
   Young SD, 2007, IEEE T VIS COMPUT GR, V13, P422, DOI [10.1109/TVCG.2007.1029, 10.1109/TVCG.2007.1041]
NR 54
TC 41
Z9 49
U1 3
U2 36
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 267
EP 275
DI 10.1007/s10055-015-0266-4
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800010
DA 2024-07-18
ER

PT J
AU Villegas, J
AF Villegas, Julian
TI Locating virtual sound sources at arbitrary distances in real-time
   binaural reproduction
SO VIRTUAL REALITY
LA English
DT Article
DE Headphone reproduction; Binaural hearing; Localization of virtual sound
   sources; Pure-data
ID PERCEPTION; RESOLUTION
AB A real-time system for sound spatialization via headphones is presented. Conventional headphone spatialization techniques effectively place sources on the surface of a virtual sphere around the listener. In the new system, sources can be spatialized at different distances from a listener by interpolating head-related impulse responses (HRIRs) measured between 20 and 160 cm. These HRIRs are stored in different databases depending on the audio sampling rate. To ease the real-time constraints, users can choose the number of HRIR taps used in the convolution, and an alternative interpolation technique (simplex interpolation) was implemented instead of trilinear interpolation. Subjective tests showed that such simplifications yield satisfactory spatialization for some angles and distances.
C1 Univ Aizu, Comp Arts Lab, Aizu Wakamatsu, Fukushima 9658580, Japan.
C3 University of Aizu
RP Villegas, J (corresponding author), Univ Aizu, Comp Arts Lab, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM julian@u-aizu.ac.jp
RI Villegas, Julian/Z-2924-2019
OI Villegas, Julian/0000-0003-1891-1753
FU University of Aizu [P-14]; Grants-in-Aid for Scientific Research
   [15K00134] Funding Source: KAKEN
FX This research was funded by the Competitive Research Funds (P-14) of the
   University of Aizu.
CR Algazi VR, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P99, DOI 10.1109/ASPAA.2001.969552
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   [Anonymous], ITUNES CONN DEV GUID
   ASHMEAD DH, 1990, PERCEPT PSYCHOPHYS, V47, P326, DOI 10.3758/BF03210871
   BEGAULT DR, 1994, J AUDIO ENG SOC, V42, P819
   Bellotti F, 2002, PERS UBIQUIT COMPUT, V6, P155, DOI 10.1007/s007790200016
   BERKHOUT AJ, 1993, J ACOUST SOC AM, V93, P2764, DOI 10.1121/1.405852
   Blauert J., 1997, SPATIAL HEARING PSYC
   Blauert J, 2012, ARCH ACOUST, V37, P5, DOI 10.2478/v10168-012-0002-y
   Bronkhorst AW, 1999, NATURE, V397, P517, DOI 10.1038/17374
   Bruel PV, 1962, 1 BRUEL KJAER
   Chen L, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 6, PROCEEDINGS, P162, DOI 10.1109/ICNC.2008.461
   Cohen M., 2015, Fundamentals of Wearable Computers and Augmented Reality, P309
   Doukhan D, 2009, P 3 PUR DAT INT CONV
   Estrella J., 2010, THESIS TU BERLIN
   Gamper H, 2014, THESIS AALTO U
   Gardner W. G., 1998, 3D AUDIO USING LOUDS
   GARDNER WG, 1995, J ACOUST SOC AM, V97, P3907, DOI 10.1121/1.412407
   Gardner WG, 1995, TECHNICAL REPORT
   Geier M., 2012, 27 TONM VDT INT CONV
   GERZON MA, 1973, J AUDIO ENG SOC, V21, P2
   Grosjean P., 2013, MLEARNING MACHINE LE
   Hawksford MO, 1997, J AUDIO ENG SOC, V45, P37
   Hemingway P, 2002, TECHNICAL REPORT
   Hosoe S., 2005, P FOR ACUST BUD HUNG, P2539
   Ikei Y, 2006, P IEEE VIRT REAL ANN, P183, DOI 10.1109/VR.2006.141
   Jot J.M., 1995, AUDIO ENG SOC CONVEN
   Kan A, 2009, J ACOUST SOC AM, V125, P2233, DOI 10.1121/1.3081395
   Kearney G, 2012, ACTA ACUST UNITED AC, V98, P61, DOI 10.3813/AAA.918492
   Kim S, 2009, AUD ENG SOC CONV 127
   Majdak P., 2013, AUDIO ENG SOC CONVEN
   Martens W. L., 2003, Acoustical Science and Technology, V24, P220, DOI 10.1250/ast.24.220
   McGee R, 2011, THESIS U MICHIGAN
   McKinley RL, 1997, FLIGHT DEMONSTRATION, P683
   Murphy D, 2011, SPATIAL SOUND COMPUT, P287
   Musil T., 2005, P INT C DIG AUD EFF
   Nelson WT, 1998, HUM FACTORS, V40, P452, DOI 10.1518/001872098779591304
   Pei SC, 2006, IEEE T CIRCUITS-II, V53, P1113, DOI 10.1109/TCSII.2006.882193
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Penha R., 2013, P SOUND MUS COMP C
   Pollow M, 2012, ACTA ACUST UNITED AC, V98, P72, DOI 10.3813/AAA.918493
   Qu TS, 2009, IEEE T AUDIO SPEECH, V17, P1124, DOI 10.1109/TASL.2009.2020532
   Sanuki W, 2014, P 136 AUD ENG SOC CO
   SCHROEDER M, 1961, J ACOUST SOC AM, V33, P1061, DOI 10.1121/1.1908892
   Sedes A., 2014, P JOINT ICMC SMC C, P855
   Smith J, 2008, COMPUTATIONAL ACOUST
   Sodnik J, 2005, APPL ACOUST, V66, P1219, DOI 10.1016/j.apacoust.2005.04.003
   Spors S, 2013, P IEEE, V101, P1920, DOI 10.1109/JPROC.2013.2264784
   Villegas J, 2010, P 135 AUD ENG SOC IN
   Villegas J, 2013, P 135 AUD ENG SOC CO
   Villegas J., 2010, P 9 INT C VR CONT IT
   Warusfel O., 2003, Listen HRTF database
   Wenzel E. M., 1993, 1993 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. Final Program and Paper Summaries (Cat. No.93TH0699-9), P102, DOI 10.1109/ASPAA.1993.379986
   Wierstorf Hagen, 2011, J AUDIO ENG SOC
   Wright M., 2005, Organised Sound, V10, P193
   Xiang P, 2005, P 11 INT C AUT DISPL
   Zahorik P, 2005, ACTA ACUST UNITED AC, V91, P409
NR 57
TC 8
Z9 9
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 201
EP 212
DI 10.1007/s10055-015-0278-0
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800005
DA 2024-07-18
ER

PT J
AU Lam, CK
   Sundaraj, K
   Sulaiman, MN
AF Lam, Chee Kiang
   Sundaraj, Kenneth
   Sulaiman, M. Nazri
TI Computer-based virtual reality simulator for phacoemulsification
   cataract surgery training
SO VIRTUAL REALITY
LA English
DT Article
DE Phacoemulsification cataract surgery; Surgical training; Medical
   simulator; Virtual reality; Haptic device
ID TIME; CAPSULORHEXIS; DEFORMATION; EDUCATION; SKILLS
AB Recent research in virtual reality indicates that computer-based simulators are an effective technology to use for surgeons learning to improve their surgical skills in a controlled environment. This article presents the development of a virtual reality simulator for phacoemulsification cataract surgery training, which is the most common surgical technique currently being used to remove cataracts from the patient's eyes. The procedure requires emulsifying the cloudy natural lens of the eye and restoring vision by implanting an artificial lens through a small incision. The four main procedures of cataract surgery, namely corneal incision, capsulorhexis, phacoemulsification, and intraocular lens implantation, are incorporated in the simulator for virtual surgical training by implementing several surgical techniques. The surgical activity that are applied on the anatomy of the human eye, such as incision, grasping, tearing, emulsification, rotation, and implantation, are simulated in the system by using different types of mesh modifications. A virtual reality surgical simulator is developed, and the main procedures of phacoemulsification cataract surgery are successfully simulated in the system. The simulation results of the training system show that the developed simulator is capable of generating a virtual surgical environment with faithful force feedback for medical residents and trainees to conduct their training lessons via the computer using a pair of force-feedback haptic devices. In addition, the successful simulation of the mesh modifications on the human eyeball with visual realism and faithful force feedback throughout the surgical operation shows that the developed simulator is able to serve as a virtual surgical platform for surgeons to train their surgical skills.
C1 [Lam, Chee Kiang; Sundaraj, Kenneth] Univ Malaysia Perlis, Al Rehab Res Grp, Arau 02600, Perlis, Malaysia.
   [Sulaiman, M. Nazri] Hosp Tuanku Fauziah, Dept Ophthalmol, Kangar 01000, Perlis, Malaysia.
C3 Universiti Malaysia Perlis
RP Lam, CK (corresponding author), Univ Malaysia Perlis, Al Rehab Res Grp, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
EM cklam85@gmail.com
RI LAM, CHEE KIANG/AAF-7743-2021; Sundaraj, Kenneth/AAD-1783-2019
OI Sundaraj, Kenneth/0000-0001-7221-0072
FU Prototype Research Grant Scheme (PRGS) of Malaysian Ministry of
   Education (MOE); Department of Ophthalmology, Hospital Tuanku Fauziah
   (HTF), Perlis, Malaysia
FX This project is funded by the Prototype Research Grant Scheme (PRGS) of
   the Malaysian Ministry of Education (MOE) and in collaboration with the
   Department of Ophthalmology, Hospital Tuanku Fauziah (HTF), Perlis,
   Malaysia.
CR Aggarwal R, 2010, QUAL SAF HEALTH CARE, V19, DOI 10.1136/qshc.2009.038562
   Agus M, 2006, 3 WORKSH VIRT REAL I, P91
   Ayoub MI, 1998, J CATARACT REFR SURG, V24, P592, DOI 10.1016/S0886-3350(98)80251-4
   Bharathan R, 2013, EUR J OBSTET GYN R B, V169, P347, DOI 10.1016/j.ejogrb.2013.03.017
   Blaylock JF, 2006, J CATARACT REFR SURG, V32, P1464, DOI 10.1016/j.jcrs.2006.04.011
   Choi KS, 2009, COMPUT BIOL MED, V39, P1020, DOI 10.1016/j.compbiomed.2009.08.003
   Courtecuisse H, 2010, PROG BIOPHYS MOL BIO, V103, P159, DOI 10.1016/j.pbiomolbio.2010.09.016
   GIMBEL HV, 1990, J CATARACT REFR SURG, V16, P246, DOI 10.1016/S0886-3350(13)80739-0
   Haerizadeh H, 2013, BEST PRACT RES CL OB, V27, P339, DOI 10.1016/j.bpobgyn.2012.12.008
   Lam CK, 2013, INT J HUM-COMPUT INT, V29, P661, DOI 10.1080/10447318.2012.758530
   Lam CK, 2013, PROCEDIA COMPUT SCI, V18, P742, DOI 10.1016/j.procs.2013.05.238
   LANGERMAN DW, 1994, J CATARACT REFR SURG, V20, P84, DOI 10.1016/S0886-3350(13)80052-1
   Liu A, 2003, PRESENCE-VIRTUAL AUG, V12, P599, DOI 10.1162/105474603322955905
   Marchesseau S, 2010, PROG BIOPHYS MOL BIO, V103, P185, DOI 10.1016/j.pbiomolbio.2010.09.005
   Meier U, 2005, COMPUT METH PROG BIO, V77, P183, DOI 10.1016/j.cmpb.2004.11.002
   Perez JF, 2008, IFMBE PROC, V20, P429
   Peterlík I, 2010, COMPUT GRAPH-UK, V34, P43, DOI 10.1016/j.cag.2009.10.005
   Pohlenz P, 2010, J CRANIO MAXILL SURG, V38, P560, DOI 10.1016/j.jcms.2010.02.011
   Shen XJ, 2008, IEEE MULTIMEDIA, V15, P64, DOI 10.1109/MMUL.2008.9
   Soderberg PG, 2007, P SOC PHOTO-OPT INS, V6426, P1
   Taylor ZA, 2009, MED IMAGE ANAL, V13, P234, DOI 10.1016/j.media.2008.10.001
   Weber K, 2006, LECT NOTES COMPUT SC, V4072, P113
   Webster R, 2004, PROCEEDINGS OF THE FIFTEENTH IASTED INTERNATIONAL CONFERENCE ON MODELLING AND SIMULATION, P262
   Webster R, 2005, STUD HEALTH TECHNOL, V111, P592
   Wittek A, 2010, PROG BIOPHYS MOL BIO, V103, P292, DOI 10.1016/j.pbiomolbio.2010.09.001
   Yang C, 2013, LECT NOTES COMPUT SC, V7995, P331, DOI 10.1007/978-3-642-39479-9_39
   Yeo CT, 2011, IEEE T BIO-MED ENG, V58, P2031, DOI 10.1109/TBME.2011.2132131
   Zhang ST, 2005, LECT NOTES COMPUT SC, V3765, P419
NR 28
TC 10
Z9 14
U1 0
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2014
VL 18
IS 4
BP 281
EP 293
DI 10.1007/s10055-014-0251-3
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AT0AZ
UT WOS:000344600500005
DA 2024-07-18
ER

PT J
AU Liu, SG
   Xiong, Y
AF Liu, Shiguang
   Xiong, Yuan
TI Fast and stable simulation of virtual water scenes with interactions
SO VIRTUAL REALITY
LA English
DT Article
DE Water; Rigid body; GPU; Perfectly matched layers; Interactions
ID FLUID
AB Simulation of large-scale water interacting with objects is essential in virtual reality, with wide applications in games, movie special effects, etc. As it involves much physical computation, how to achieve fast rendering is still a challenge. This paper proposed a novel Graphics Processing Unit-based method for rapid simulation of water interacting with objects. The interactions between dynamic objects and the surrounding environment were realized with a specially designed simulation grid. Perfectly Matched Layers method was introduced to ensure the continued stability of the simulation grid's boundary fluctuations. To model the rigid body efficiently, a pre-rigid body method was proposed to achieve plausible visual results at higher rendering rates. Various experiment results showed the validity of our method.
C1 [Liu, Shiguang; Xiong, Yuan] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, 92 Weijin Rd, Tianjin 300072, Peoples R China.
EM shgliu@126.com
FU National Natural Science Foundation Council of the People's Republic of
   China [61170118, 60803047]; State Key Lab of CAD&CG, Zhejiang University
   [A1210]
FX The authors would like to acknowledge financial support from the
   National Natural Science Foundation Council of the People's Republic of
   China (Grant nos. 61170118 and 60803047), the Open Project Program of
   the State Key Lab of CAD&CG, Zhejiang University (Grant no. A1210).
CR Baraff D, 1995, SIGGRAPH COURS NOT
   Carlson M, 2004, ACM T GRAPHIC, V23, P377, DOI 10.1145/1015706.1015733
   Chentanez Nuttapong., 2010, P 2010 ACM SIGGRAPH, P197
   Cords H., 2009, P EUR WORKSH NAT PHE
   Darles E, 2011, COMPUT GRAPH FORUM, V30, P43, DOI 10.1111/j.1467-8659.2010.01828.x
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   FOURNIER A, 1986, P SIGGRAPH 86, V20, P75
   Génevaux O, 2003, PROC GRAPH INTERF, P31
   GOMEZ M, 2000, GAME PROGRAMMING GEM, P187
   Grote MJ, 2010, ARXIV10010319V1
   Hillesland K, 2012, SIGGRAPH AS COURS
   Johanson C., 2004, THESIS LUND U LUND
   Johnson S, 2010, NOTES PERFECTLY MATC
   Kass M., 1990, ACM T GRAPHIC, V24, P49
   O'Brien JF, 2005, P COMP AN, P198
   Peachey D, 1992, COMPUT GRAPH, V20, P65
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Tessendorf J., 2001, P ACM SIGGRAPH COURS
   Wei XT, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P75, DOI 10.1109/CSB.2003.1227306
   Yan H, 2009, COMPUT ANIMAT VIRT W, V20, P417, DOI 10.1002/cav.300
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
   [No title captured]
NR 23
TC 11
Z9 15
U1 1
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2013
VL 17
IS 1
BP 77
EP 88
DI 10.1007/s10055-013-0222-0
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 089NC
UT WOS:000314916300006
DA 2024-07-18
ER

PT J
AU Aleotti, J
   Caselli, S
AF Aleotti, Jacopo
   Caselli, Stefano
TI Grasp programming by demonstration in virtual reality with automatic
   environment reconstruction
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Environment modeling; Grasp programming; Glove
   interaction
ID MODELS
AB A virtual reality system enabling high-level programming of robot grasps is described. The system is designed to support programming by demonstration (PbD), an approach aimed at simplifying robot programming and empowering even unexperienced users with the ability to easily transfer knowledge to a robotic system. Programming robot grasps from human demonstrations requires an analysis phase, comprising learning and classification of human grasps, as well as a synthesis phase, where an appropriate human-demonstrated grasp is imitated and adapted to a specific robotic device and object to be grasped. The virtual reality system described in this paper supports both phases, thereby enabling end-to-end imitation-based programming of robot grasps. Moreover, as in the PbD approach robot environment interactions are no longer explicitly programmed, the system includes a method for automatic environment reconstruction that relieves the designer from manually editing the pose of the objects in the scene and enables intelligent manipulation. A workspace modeling technique based on monocular vision and computation of edge-face graphs is proposed. The modeling algorithm works in real time and supports registration of multiple views. Object recognition and workspace reconstruction features, along with grasp analysis and synthesis, have been tested in simulated tasks involving 3D user interaction and programming of assembly operations. Experiments reported in the paper assess the capabilities of the three main components of the system: the grasp recognizer, the vision-based environment modeling system, and the grasp synthesizer.
C1 [Aleotti, Jacopo; Caselli, Stefano] Univ Parma, Dipartimento Ingn dellInformazione, Parma, Italy.
   [Aleotti, Jacopo; Caselli, Stefano] Univ Parma, Dipartimento Ingn Informaz, I-43100 Parma, Italy.
C3 University of Parma; University of Parma
RP Aleotti, J (corresponding author), Univ Parma, Dipartimento Ingn Informaz, I-43100 Parma, Italy.
EM aleotti@ce.unipr.it; caselli@ce.unipr.it
RI Caselli, Stefano/HLX-0917-2023
OI Caselli, Stefano/0000-0003-0774-7871
FU Laboratory AER-TECH of Regione Emilia-Romagna, Italy
FX This research has been partially supported by Laboratory AER-TECH of
   Regione Emilia-Romagna, Italy.
CR Aleotti J, 2004, ROBOT AUTON SYST, V47, P153, DOI 10.1016/j.robot.2004.03.009
   ALEOTTI J, 2006, IEEE INT C ROB AUT I
   ALEOTTI J, 2007, IEEE RSJ INT C INT R
   ALEOTTI J, 2005, IEEE INT C INT ROB S
   [Anonymous], 1985, EXP BRAIN RES
   Bernardin K, 2005, IEEE T ROBOT, V21, P47, DOI 10.1109/TRO.2004.833816
   Calinon S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2769
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   Cutkosky MR, 1990, DEXTROUS ROBOT HANDS, P111
   DEFLORIANI L, 1989, IEEE T PATTERN ANAL, V11, P785, DOI 10.1109/34.31442
   EHRENNMANN M, 2000, IEEE INT C ROB AUT I
   Ekvall S., 2005, IEEE INT C ROB AUT I
   EKVALL S, 2004, IEEE INT C ROB AUT I
   FERRARI C, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P2290, DOI 10.1109/ROBOT.1992.219918
   FRIEDRICH H, 1999, IASTED INT C INT SYS
   Heumer G, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P19
   HIRANO Y, 2005, IEEE RSJ INT C INT R
   Hsiao K., 2006, IEEE RSJ INT C INT R
   Iberall T., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P396
   IKEUCHI K, 1994, IEEE T ROBOTIC AUTOM, V10, P368, DOI 10.1109/70.294211
   JANG H, 2005, IEEE RSJ INT C INT R
   Kang SB, 1997, IEEE T ROBOTIC AUTOM, V13, P81, DOI 10.1109/70.554349
   Kato H., 1999, P 2 INT WORKSH AUGM
   KITAHAMA K, 2006, IEEE RSJ INT C INT R
   LEE S, 2005, IEEE RSJ INT C INT R
   Lloyd JE, 1999, IEEE T ROBOTIC AUTOM, V15, P423, DOI 10.1109/70.768176
   MATAS J, 1997, INT C IM PROC
   Miller AndrewT., 2000, P ASME INT MECH ENG, P1251
   Morales A, 2006, IEEE RSJ INT C INT R
   OGATA H, 1994, IEEE T ROBOTIC AUTOM, V10, P391, DOI 10.1109/70.294213
   PIEGL L, 1991, IEEE COMPUT GRAPH, V11, P55, DOI 10.1109/38.67702
   Takahashi T, 1991, IEEE RSJ INT WORKSH
   Venkataraman S.T., 1990, DEXTROUS ROBOT HANDS
   Wojtara T., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P866
   WONG AKC, 1998, IEEE RSJ INT C INT R
   Zollner R, 2001, IEEE INT C ROB AUT I
   ZOLLNER R, 2002, IEEE RSJ INT C INT R
NR 37
TC 9
Z9 9
U1 0
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2012
VL 16
IS 2
BP 87
EP 104
DI 10.1007/s10055-010-0172-8
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 949EO
UT WOS:000304559300001
DA 2024-07-18
ER

PT J
AU Cai, H
   Lin, YZ
AF Cai, Hua
   Lin, Yingzi
TI An integrated head pose and eye gaze tracking approach to non-intrusive
   visual attention measurement for wide FOV simulators
SO VIRTUAL REALITY
LA English
DT Article
DE Eye gaze tracking; Head pose tracking; Multilayer perceptron (MLP);
   Visual attention
ID SNAKE ALGORITHM; COORDINATION
AB Eye gaze tracking is very useful for quantitatively measuring visual attention in virtual environments. However, most eye trackers have a limited tracking range, e.g., +/- 35A degrees in the horizontal direction. This paper proposed a method to combine head pose tracking and eye gaze tracking together to achieve a large range of tracking in virtual driving simulation environments. Multiple parallel multilayer perceptrons were used to reconstruct the relationship between head images and head poses. Head images were represented with the coefficients extracted from Principal Component Analysis. Eye gaze tracking provides precise results on the front view, while head pose tracking is more suitable for tracking areas of interest than for tracking points of interest on the side view.
C1 [Cai, Hua; Lin, Yingzi] Northeastern Univ, Dept Mech & Ind Engn, Boston, MA 02115 USA.
C3 Northeastern University
RP Lin, YZ (corresponding author), Northeastern Univ, Dept Mech & Ind Engn, Boston, MA 02115 USA.
EM yilin@coe.neu.edu
RI Cai, Hua/B-2011-2014
FU National Science Foundation (NSF) [0954579]; Directorate For
   Engineering; Div Of Civil, Mechanical, & Manufact Inn [0954579] Funding
   Source: National Science Foundation
FX The research has been supported by the National Science Foundation (NSF)
   through a research grant awarded to the corresponding author (Grant #
   0954579).
CR Abe Y., 2001, Systems and Computers in Japan, V32, P36, DOI 10.1002/scj.1024
   Amokrane Kahina, 2008, International Journal of Virtual Reality, V7, P23
   Beverina F, 2006, 2 IET INT C INT ENV, P161
   Cai H, 2007, P HFES 51 ANN M BALT, V5, P1645
   Einhäuser W, 2007, NETWORK-COMP NEURAL, V18, P267, DOI 10.1080/09548980701671094
   Ekman P., 2002, FACIAL ACTION CODING
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Kuratate T, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P430, DOI 10.1109/ROMAN.2001.981942
   Lam SY, 2002, ELECTRON LETT, V38, P452, DOI 10.1049/el:10020335
   LAND MF, 1992, NATURE, V359, P318, DOI 10.1038/359318a0
   Lee YC, 2007, HUM FACTORS, V49, P721, DOI 10.1518/001872007X215791
   Lin Y, 2003, INT J HUM-COMPUT ST, V59, P837, DOI 10.1016/S1071-5819(03)00122-8
   Ma Lihong, 2000, International Journal of Virtual Reality, V4
   Mourant RR, 2007, DISPLAYS, V28, P145, DOI 10.1016/j.displa.2007.04.011
   Oommen BS, 2004, EXP BRAIN RES, V155, P9, DOI 10.1007/s00221-003-1694-z
   Sakalli M, 2006, IEEE T IMAGE PROCESS, V15, P1182, DOI 10.1109/TIP.2006.871401
   Sherrah J, 2001, PATTERN RECOGN, V34, P1565, DOI 10.1016/S0031-3203(00)00091-1
   Shlens J., 2005, ARXIV
   Xu Fupei, 2000, International Journal of Virtual Reality, V4
   Zhang H, 2006, HUM FACTORS, V48, P805, DOI 10.1518/001872006779166307
NR 20
TC 13
Z9 16
U1 2
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 25
EP 32
DI 10.1007/s10055-010-0171-9
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600004
DA 2024-07-18
ER

PT B
AU Figueroa, P
AF Figueroa, Pablo
BE Kim, JJ
TI VR Development with InTml
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID VIRTUAL-REALITY APPLICATIONS; GRAPHICS; PLATFORM; SYSTEM; DESIGN
C1 [Figueroa, Pablo] Univ Los Andes, Los Andes, Colombia.
C3 Universidad de los Andes (Colombia)
RP Figueroa, P (corresponding author), Univ Los Andes, Los Andes, Colombia.
CR Allard J, 2004, LECT NOTES COMPUT SC, V3149, P497
   *AUT, 2006, AUT FBX
   Ava, 2000, AV DISTR VIRT REAL F
   Battacharyya S. S., 1996, Software Synthesis from Dataflow Graphs
   Bierbaum A, 2001, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2001.913774
   Blach R., 1998, USER INTERACTION P V, P54
   Boier-Martin IM, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1159606
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Carey Rikk., 1997, The Annotated VRML 97 Reference Manual
   Clements P., 2002, Software product lines
   *CMU, 1999, AL EAS INT 3D GRAPH
   Dachselt Raimund, 2002, P 7 INT C 3D WEB TEC, P155, DOI [10.1145/504502.504527, DOI 10.1145/504502.504527]
   Eldridge M, 2000, COMP GRAPH, P443, DOI 10.1145/344779.344981
   Figueroa P, 2005, INT J HUM-COMPUT ST, V62, P73, DOI 10.1016/j.ijhcs.2004.08.004
   FIGUEROA P, 2007, INTML DEV TOOLS
   Figueroa P., 2008, P IEEE VIRT REAL 200, P3
   Figueroa P, 2008, PRESENCE-TELEOP VIRT, V17, P492, DOI 10.1162/pres.17.5.492
   Figueroa P, 2010, PRESENCE-VIRTUAL AUG, V19, P118, DOI 10.1162/pres.19.2.118
   Figueroa Pablo, 2004, INTML CONCEPTS
   Humphreys G, 2001, COMP GRAPH, P129, DOI 10.1145/383259.383272
   Kim G.J., 2005, Designing virtual reality systems the structured approach
   Kwok YK, 1999, ACM COMPUT SURV, V31, P406, DOI 10.1145/344588.344618
   MASSO JPM, 2005, WEB3D 05 P 10 INT C, P169
   Molnar S., 1992, Proceedings of the 19th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '92, P231
   Neale H, 2002, P IEEE VIRT REAL ANN, P191, DOI 10.1109/VR.2002.996522
   NISHIMURA S, 1996, P SIGGRAPH 96, P365
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   SASTRY L, 2001, IPT EGVE 2001 JOINT
   *SENSE8, 2000, VIRT REAL DEV TOOLS
   SGI, 2003, IR PERF
   SHAW C, 1992, P SIGCHI C HUM FACT, P321
   SMITH S, 1999, EUROGRAPHICS P, V18, P298
   Spivey M., 1992, The Z Notation: A Reference Manual
   Stahl T., 2006, Model-driven software development: technology, engineering, management
   Sun Microsystems, 1997, JAV 3D
   Tanriverdi Vildan, 2001, P ACM S VIRTUAL REAL, P175
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   The Eclipse Foundation, 2007, ECL
   Trenholme David, 2008, Virtual Reality, V12, P181, DOI 10.1007/s10055-008-0092-z
   *VRCO, 2003, CAV LIB
   *WEB3D CONS, 2003, EXT 3D X3D GRAPH
   *WEB3D CONS, 2005, 1977712005 ISOIEC FD
   WINGRAVE CA, 2005, P IEEE WORKSH NEW DI, P85
NR 43
TC 0
Z9 0
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 127
EP 146
D2 10.5772/553
PG 20
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400008
DA 2024-07-18
ER

PT J
AU Férey, N
   Nelson, J
   Martin, C
   Picinali, L
   Bouyer, G
   Tek, A
   Bourdot, P
   Burkhardt, JM
   Katz, BFG
   Ammi, M
   Etchebest, C
   Autin, L
AF Ferey, N.
   Nelson, J.
   Martin, C.
   Picinali, L.
   Bouyer, G.
   Tek, A.
   Bourdot, P.
   Burkhardt, J. M.
   Katz, B. F. G.
   Ammi, M.
   Etchebest, C.
   Autin, L.
TI Multisensory VR interaction for protein-docking in the <i>CoRSAIRe</i>
   project
SO VIRTUAL REALITY
LA English
DT Article
ID VISUALIZATION; EFFICIENT; SURFACE
AB Proteins take on their function in the cell by interacting with other proteins or biomolecular complexes. To study this process, computational methods, collectively named protein docking, are used to predict the position and orientation of a protein ligand when it is bound to a protein receptor or enzyme, taking into account chemical or physical criteria. This process is intensively studied to discover new biological functions for proteins and to better understand how these macromolecules take on these functions at the molecular scale. Pharmaceutical research also employs docking techniques for a variety of purposes, most notably in the virtual screening of large databases of available chemicals to select likely molecular candidates for drug design. The basic hypothesis of our work is that Virtual Reality (VR) and multimodal interaction can increase efficiency in reaching and analysing docking solutions, in addition to fully a computational docking approach. To this end, we conducted an ergonomic analysis of the protein-protein current docking task as it is carried out today. Using these results, we designed an immersive and multimodal application where VR devices, such as the three-dimensional mouse and haptic devices, are used to interactively manipulate two proteins to explore possible docking solutions. During this exploration, visual, audio, and haptic feedbacks are combined to render and evaluate chemical or physical properties of the current docking configuration.
C1 [Ferey, N.; Martin, C.; Bouyer, G.; Tek, A.; Bourdot, P.; Katz, B. F. G.; Ammi, M.] Univ Paris 11, Lab Informat & Mecan Sci Ingn, F-91403 Orsay, France.
   [Nelson, J.] Arts & Metiers ParisTech, LCPI, F-75013 Paris, France.
   [Picinali, L.] Inst Rech & Coordinat Acoust Mus, F-75004 Paris, France.
   [Burkhardt, J. M.] Univ Paris 05, Lab Ergon Comportement Interact, F-75006 Paris, France.
   [Etchebest, C.; Autin, L.] Univ Paris 07, Inst Natl Sante & Rech Med, Equipe DSIMB, INTS, F-75739 Paris 15, France.
C3 Universite Paris Saclay; heSam Universite; Conservatoire National Arts &
   Metiers (CNAM); Arts et Metiers Institute of Technology; Universite
   Paris Cite; Institut National de la Sante et de la Recherche Medicale
   (Inserm); Universite Paris Cite
RP Férey, N (corresponding author), Univ Paris 11, Lab Informat & Mecan Sci Ingn, BP133, F-91403 Orsay, France.
EM nicolas.ferey@ibpc.fr; julien.nelson@paris.ensam.fr; lorenzo@limsi.fr;
   guillaume.bouyer@ensiie.fr; tek@limsi.fr; pb@limsi.fr;
   jean-marie.burkhardt@univ-paris5.fr; katz@limsi.fr; ammi@limsi.fr;
   catherine.etchebest@univ-paris-diderot.fr; ludovic.autin@gmail.com
RI Katz, Brian F.G./I-3191-2012; etchebest, catherine/O-2485-2019;
   Burkhardt, Jean-Marie/AAF-5544-2020
OI Katz, Brian F.G./0000-0001-5118-0943; etchebest,
   catherine/0000-0002-5871-2372; Burkhardt,
   Jean-Marie/0000-0003-4417-6430; Picinali, Lorenzo/0000-0001-9297-2613;
   Autin, Ludovic/0000-0002-2197-191X
CR ANASTASSOVA M, 2007, P 12 INT C HUM COMP
   Anderson A, 1999, J MOL GRAPH MODEL, V17, P180, DOI 10.1016/S1093-3263(99)00029-7
   Andre Elisabeth., 2000, Handbook ofNatural Language Processing, P305
   Andrusier N, 2007, PROTEINS, V69, P139, DOI 10.1002/prot.21495
   Annett J, 2003, HUM FAC ER, P17
   ARBOUN A, 2007, THESIS ECOLE NATL SU
   Baker NA, 2001, P NATL ACAD SCI USA, V98, P10037, DOI 10.1073/pnas.181342398
   BARASS S, 2000, P INT C AUD DISP ICA
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Birmanns S, 2003, J STRUCT BIOL, V144, P123, DOI 10.1016/j.jsb.2003.09.018
   Borrelli KW, 2005, J CHEM THEORY COMPUT, V1, P1304, DOI 10.1021/ct0501811
   BOURDOT P, 2002, P IEEE VIRT REAL INT
   BOUYER G, 2007, THESIS U PARIS 11 FR
   BOUYER G, 2008, P 13 EUR S VIRT ENV, P49
   Brooks F. P.  Jr., 1990, Computer Graphics, V24, P177, DOI 10.1145/97880.97899
   Comeau SR, 2004, BIOINFORMATICS, V20, P45, DOI 10.1093/bioinformatics/btg371
   CONNOLLY ML, 1983, J APPL CRYSTALLOGR, V16, P548, DOI 10.1107/S0021889883010985
   CONNOLLY ML, 1983, SCIENCE, V221, P709, DOI 10.1126/science.6879170
   COREY RB, 1953, REV SCI INSTRUM, V24, P621, DOI 10.1063/1.1770803
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dominjon L., 2005, P WORLD HAPT C JOINT
   DOMINJON L, 2006, P IEEE INT C VIRT RE
   FEREY N, 2008, P INT C VIRT REAL SO
   Fernandez-Recio J., 2003, ICM DISCO DOCKING GL, V1, P113
   Garcia-Ruiz MA, 2006, INTERACT COMPUT, V18, P853, DOI 10.1016/j.intcom.2005.12.001
   GHIGLIONE R, 1998, ANAL AUTOMATIQUES CO
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   GROSDIDIER A, 2007, THESIS U J FOURIER G
   HART TN, 2004, PROTEIN-STRUCT FUNCT, V13, P206
   Hermann T., 1999, LISTEN YOUR DATA MOD, P189
   Hess B, 2008, J CHEM THEORY COMPUT, V4, P435, DOI 10.1021/ct700301q
   Hinsen K, 2000, J COMPUT CHEM, V21, P79, DOI 10.1002/(SICI)1096-987X(20000130)21:2<79::AID-JCC1>3.0.CO;2-B
   Jacko JulieA., 2003, HUM FAC ER, P1032
   Johnson D., 2003, P 11 S HAPT INT VIRT
   KATZ FGB, 2008, P INT C AUD DISPL IC
   Kitagawa M, 2005, J THORAC CARDIOV SUR, V129, P151, DOI 10.1016/j.jtcvs.2004.05.029
   Levine D, 1997, IEEE COMPUT SCI ENG, V4, P55, DOI 10.1109/99.609834
   LU TC, 2005, P COMP SYST BIOINF C, P271
   Lundin K, 2005, PROC SPIE, V5669, P31, DOI 10.1117/12.587029
   MACIEJEWSKI R, 2005, P 1 JOIT EUR C S HAP
   Magnani L, 2005, SEMIOTICA, V153, P261
   Moore BCJ, 2003, INTRO PSYCHOL HEARIN
   Pipe SW, 2008, THROMB HAEMOSTASIS, V99, P840, DOI 10.1160/TH07-10-0593
   Ray N, 2005, J MOL GRAPH MODEL, V23, P347, DOI 10.1016/j.jmgm.2004.11.004
   Richard P., 2006, The International Journal of Virtual Reality, V2, P37
   Ritchie DW, 2003, PROTEINS, V52, P98, DOI 10.1002/prot.10379
   Rossi R, 2007, BIOINFORMATICS, V23, pI408, DOI 10.1093/bioinformatics/btm191
   Sanner MF, 1996, BIOPOLYMERS, V38, P305, DOI 10.1002/(SICI)1097-0282(199603)38:3<305::AID-BIP4>3.0.CO;2-Y
   Seeger A., 1997, P 2 PHANTOM US GROUP
   TOURAINE D, 2002, P 8 EUROGRAPHICS WOR
   Turk M, 2000, COMMUN ACM, V43, P32, DOI 10.1145/330534.330535
   Villoutreix BO, 2008, CURR PHARM BIOTECHNO, V9, P103, DOI 10.2174/138920108783955218
   Walker B. N., 1994, AUDITORY DISPLAY SON
   WALKER BN, 2008, P INT C AUD DISPL IC
   Wang RX, 2003, J MED CHEM, V46, P2287, DOI 10.1021/jm0203783
   Zacharias M, 2005, PROTEINS, V60, P252, DOI 10.1002/prot.20566
NR 56
TC 36
Z9 37
U1 0
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2009
VL 13
IS 4
SI SI
BP 273
EP 293
DI 10.1007/s10055-009-0136-z
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XF
UT WOS:000208104400006
DA 2024-07-18
ER

PT J
AU Sherbel, J
   Yatabe, M
   Cevidanes, L
   Ruellas, A
   Aronovich, S
   Ehardt, L
   Ames, M
   Kim-Berman, H
AF Sherbel, Jason
   Yatabe, Marilia
   Cevidanes, Lucia
   Ruellas, Antonio
   Aronovich, Sharon
   Ehardt, Lauren
   Ames, Matthew
   Kim-Berman, Hera
TI A method of comparing virtual reality orthognathic surgical predictions
   and postsurgical treatment outcomes
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Jaw surgery; Orthognathic surgical prediction;
   Postsurgical treatment outcomes assessment
ID ACCURACY; SURGERY; SUPERIMPOSITION; RELIABILITY; SYSTEM
AB Background Orthognathic surgical predictions using 2D cephalometric films, 2D computer-assisted planning, and 3D computer-assisted surgical simulation are currently accepted methods to evaluate postsurgical outcomes. Recent advancements have paved the way for a new method of surgical prediction using immersive virtual reality. The objective of the study was to evaluate a method of comparing virtual reality (VR) orthognathic surgical predictions with postsurgical treatment outcomes of patients.
   Methods Pre- and postsurgical cone-beam computed tomography (CBCT) data of 14 patients who underwent one-jaw mandibular advancement surgery were collected. The presurgical CBCTs were rendered for the VR surgical manipulation, and the prediction was exported as a STL file. Skeletal and dental landmarks were placed, and differences were calculated in all dimensions (Right/Left, Anterior/Posterior, Superior/Inferior, 3D distance, pitch, roll, yaw). A one-sample t-test was conducted to determine clinical significance (p < 0.05).
   Results The differences in the linear measurements of component dimensions for VR surgical prediction and actual postsurgical results were less than 2 mm (p < 0.05), with the exceptions of left gonial angle in the right/left dimension; right and left gonial angles, left mental foramen, and gnathion in the anterior/posterior dimension; and all 3D distance measurements. The difference in all angular measurements (pitch, roll, yaw) were less than 4 degrees (p < 0.05).
   Conclusions The described method was successful in evaluating clinically acceptable limits in 3D distance measurements, component (x, y, z) dimensions and for pitch, yaw and roll of virtual reality surgical predictions and the actual surgical outcome.
C1 [Sherbel, Jason; Yatabe, Marilia; Cevidanes, Lucia; Ruellas, Antonio; Ehardt, Lauren; Kim-Berman, Hera] Univ Michigan, Sch Dent, Dept Orthodont & Pediat Dent, 1011 N Univ Ave, Ann Arbor, MI 48109 USA.
   [Ruellas, Antonio] Univ Fed Rio de Janeiro, Sch Dent, Dept Pediat Dent & Orthodont, Rio De Janeiro, Brazil.
   [Aronovich, Sharon] Univ Michigan, Sch Dent, Dept Oral & Maxillofacial Surg, Ann Arbor, MI USA.
C3 University of Michigan System; University of Michigan; Universidade
   Federal do Rio de Janeiro; University of Michigan System; University of
   Michigan
RP Kim-Berman, H (corresponding author), Univ Michigan, Sch Dent, Dept Orthodont & Pediat Dent, 1011 N Univ Ave, Ann Arbor, MI 48109 USA.
EM bermanh@umich.edu
OI Kim-Berman, Hera/0000-0003-4465-3700
FU We thank the Emerging Technology Team at the University of Michigan,
   Duderstadt Center for developing the VR Patient for jaw surgery
   simulation.; VR Patient for jaw surgery simulation
FX We thank the Emerging Technology Team at the University of Michigan,
   Duderstadt Center for developing the VR Patient for jaw surgery
   simulation.
CR Alaraj A, 2013, NEUROSURGERY, V72, pA115, DOI 10.1227/NEU.0b013e3182753093
   Almukhtar A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093402
   Andolfi C, 2017, J LAPAROENDOSC ADV S, V27, P512, DOI 10.1089/lap.2016.0421
   Ayoub A, 2019, BMC ORAL HEALTH, V19, DOI 10.1186/s12903-019-0937-8
   Barrera JE, 2014, LARYNGOSCOPE, V124, P1259, DOI 10.1002/lary.24501
   Bengtsson M, 2018, J CRANIO MAXILL SURG, V46, P1867, DOI 10.1016/j.jcms.2017.01.035
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Cevidanes LHS, 2006, AM J ORTHOD DENTOFAC, V129, P611, DOI 10.1016/j.ajodo.2005.12.008
   Chin SJ, 2017, J CRANIO MAXILL SURG, V45, P1962, DOI 10.1016/j.jcms.2017.07.016
   Choi KS, 2017, STUD HEALTH TECHNOL, V245, P1298, DOI 10.3233/978-1-61499-830-3-1298
   Ferraz FWD, 2021, J CRANIO MAXILL SURG, V49, P84, DOI 10.1016/j.jcms.2020.12.002
   Teixeira AOD, 2020, AM J ORTHOD DENTOFAC, V158, P674, DOI 10.1016/j.ajodo.2019.09.023
   Ruellas ACD, 2016, AM J ORTHOD DENTOFAC, V149, P645, DOI 10.1016/j.ajodo.2015.10.021
   De Riu G, 2018, J CRANIO MAXILL SURG, V46, P293, DOI 10.1016/j.jcms.2017.11.023
   Dobai A, 2018, ORVOSI HETILAP, V159, P1584, DOI 10.1556/650.2018.31168
   Ehardt L, 2021, AM J ORTHOD DENTOFAC, V159, P613, DOI 10.1016/j.ajodo.2019.11.022
   EHMER U, 1989, International Journal of Adult Orthodontics and Orthognathic Surgery, V4, P223
   Ellis E, 2007, J ORAL MAXIL SURG, V65, P2125, DOI 10.1016/j.joms.2007.02.005
   Farrell BB, 2014, ORAL MAXIL SURG CLIN, V26, P459, DOI 10.1016/j.coms.2014.08.011
   FRIEDE H, 1987, J ORAL MAXIL SURG, V45, P754, DOI 10.1016/0278-2391(87)90195-9
   Heymann GC, 2010, AM J ORTHOD DENTOFAC, V137, P274, DOI 10.1016/j.ajodo.2009.07.009
   Hsu SSP, 2013, J ORAL MAXIL SURG, V71, P128, DOI 10.1016/j.joms.2012.03.027
   Joda T, 2019, COMPUT BIOL MED, V108, P93, DOI 10.1016/j.compbiomed.2019.03.012
   Kolokitha OE, 2011, J MAXILLOFAC ORAL SU, V10, P236, DOI 10.1007/s12663-011-0228-7
   Legal S, 2018, J CRANIO MAXILL SURG, V46, P1793, DOI 10.1016/j.jcms.2018.07.006
   Marlière DAA, 2019, MED ORAL PATOL ORAL, V24, pE243, DOI 10.4317/medoral.22724
   Mütterlein J, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P1407
   Paniagua B, 2011, INT J COMPUT ASS RAD, V6, P617, DOI 10.1007/s11548-010-0539-z
   Ponce-Garcia C, 2018, ANGLE ORTHOD, V88, P233, DOI 10.2319/071217-468.1
   Popat H, 2010, J ORTHOD, V37, P62, DOI 10.1179/14653121042885
   POSPISIL OA, 1987, J CRANIO MAXILL SURG, V15, P79, DOI 10.1016/S1010-5182(87)80023-9
   Ritto FG, 2018, INT J ORAL MAX SURG, V47, P160, DOI 10.1016/j.ijom.2017.08.012
   Rustemeyer J, 2010, BRIT J ORAL MAX SURG, V48, P271, DOI 10.1016/j.bjoms.2009.06.018
   Sakowitz SM, 2020, VIRTUAL REAL-LONDON, V24, P399, DOI 10.1007/s10055-019-00413-w
   Shirota T, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02123
   Stokbro K, 2016, INT J ORAL MAX SURG, V45, P8, DOI 10.1016/j.ijom.2015.07.010
   Stokbro K, 2014, INT J ORAL MAX SURG, V43, P957, DOI 10.1016/j.ijom.2014.03.011
   Sytek L, 2021, J DENT EDUC, V85, P1415, DOI 10.1002/jdd.12598
   Tankersley AC, 2019, J ORAL MAXIL SURG, V77, P1675, DOI 10.1016/j.joms.2019.03.004
   Tonin RH, 2020, ORTHOD CRANIOFAC RES, V23, P229, DOI 10.1111/ocr.12363
   Wilson A, 2019, PLAST RECONSTR SURG, V144, p89E, DOI 10.1097/PRS.0000000000005744
   Wu TY, 2017, J PLAST RECONSTR AES, V70, P1101, DOI 10.1016/j.bjps.2017.04.012
   Xia JJ, 2007, J ORAL MAXIL SURG, V65, P248, DOI 10.1016/j.joms.2006.10.005
   Zavattero E, 2019, J CRANIOFAC SURG, V30, P1214, DOI 10.1097/SCS.0000000000005355
   Zhang N, 2016, OR SURG OR MED OR PA, V122, P143, DOI 10.1016/j.oooo.2016.03.004
NR 45
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3089
EP 3099
DI 10.1007/s10055-023-00855-3
EA SEP 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001059891900001
DA 2024-07-18
ER

PT J
AU Reyes, CIA
   Wozniak, D
   Ham, A
   Zahabi, M
AF Reyes, Cesar Ivan Aguilar
   Wozniak, David
   Ham, Angel
   Zahabi, Maryam
TI Design and evaluation of an adaptive virtual reality training system
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Training; Adaptive; Cognitive workload
ID MENTAL WORKLOAD; HEART-RATE; PHYSIOLOGICAL INDEXES; BAYESIAN NETWORK;
   SIMULATOR; RESPIRATION; PERFORMANCE; TECHNOLOGY; PREDICTION; RESPONSES
AB Successful operation of military aviation depends on effective pilot training. The current training capabilities of the United States Air Force might not be sufficient to meet the demand for new pilots. To help resolve this issue, this study focused on developing a prototype of an adaptive virtual reality (VR) training system. The system was built leveraging the three key elements of an adaptive training system including the trainee's performance measures, adaptive logic, and adaptive variables. The prototype was based on a procedure for an F-16 cockpit and included adaptive feedback, temporal display features, and various difficulty levels to help trainees maintain an optimal level of cognitive workload while completing their training. An experiment with 20 human participants was conducted, and a trend favoring the use of adaptive training was identified. Results suggested that adaptive training could improve performance and reduce workload as compared to the traditional non-adaptive VR-based training. Implementation of adaptive VR training has the potential to reduce training time and cost. The results from this study can assist in developing future adaptive VR-training systems.
C1 [Reyes, Cesar Ivan Aguilar; Wozniak, David; Ham, Angel; Zahabi, Maryam] Texas A&M Univ, Wm Michael Barnes Dept Ind & Syst Engn, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Zahabi, M (corresponding author), Texas A&M Univ, Wm Michael Barnes Dept Ind & Syst Engn, College Stn, TX 77843 USA.
EM mzahabi@tamu.edu
OI , Maryam/0000-0002-6375-8113
CR Abdurrahman UA, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5040054
   Abusharha AA, 2017, CLIN OPTOM, V9, P133, DOI 10.2147/OPTO.S142718
   Ariali S, 2021, INT J EMERG TECHNOL, V16, P20, DOI 10.3991/ijet.v16i09.18971
   Backs RichardW., 2000, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V44, P89, DOI [10.1177/154193120004401323, DOI 10.1177/154193120004401323]
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Belani M, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375027
   Besson P, 2013, IEEE T INTELL TRANSP, V14, P1872, DOI 10.1109/TITS.2013.2269679
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Bian DW, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2016, VOL 2A
   Biondi FN, 2021, HUM FACTORS, V63, P813, DOI 10.1177/0018720820929928
   BLOOM BS, 1984, EDUC LEADERSHIP, V41, P4
   Brookings JB, 1996, BIOL PSYCHOL, V42, P361, DOI 10.1016/0301-0511(95)05167-8
   Carretta T.R., 1998, TRANSFER TRAINING EF
   CATER JP, 1995, PRESENCE-TELEOP VIRT, V4, P103, DOI 10.1162/pres.1995.4.2.103
   Causse M, 2010, APPL PSYCHOPHYS BIOF, V35, P115, DOI 10.1007/s10484-009-9115-0
   Charles RL, 2019, APPL ERGON, V74, P221, DOI 10.1016/j.apergo.2018.08.028
   Chemuturi R, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-102
   Colle HA, 1998, HUM FACTORS, V40, P591, DOI 10.1518/001872098779649283
   Collet C, 2014, ERGONOMICS, V57, P886, DOI 10.1080/00140139.2014.899627
   Curtis MT, 2010, HUMAN FACTORS IN AVIATION, 2ND EDITION, P439, DOI 10.1016/B978-0-12-374518-7.00014-6
   Dahlstrom N, 2009, INT J AVIAT PSYCHOL, V19, P309, DOI 10.1080/10508410903187547
   Druzdzel MJ, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P902
   Fairclough SH, 2006, BIOL PSYCHOL, V71, P100, DOI 10.1016/j.biopsycho.2005.03.007
   Feidakis M, 2016, FORMATIVE ASSESSMENT, P217, DOI [10.1016/B978-0-12-803637-2.00011-7, DOI 10.1016/B978-0-12-803637-2.00011-7]
   Fenton N., 2018, Risk Assessment and Decision Analysis With Bayesian networks, DOI [10.1201/b21982, DOI 10.1201/B21982]
   Fenton NE, 2007, IEEE T KNOWL DATA EN, V19, P1420, DOI 10.1109/TKDE.2007.1068
   Fricoteaux L, 2014, ENG APPL ARTIF INTEL, V33, P47, DOI 10.1016/j.engappai.2014.03.005
   Garcia AD, 2020, TRAINING ASTRONAUTS
   Gartner W. B., 1979, SURVEY METHODS ASSES, V3
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gawron VJ., 2008, HUMAN PERFORMANCE WO, DOI [10.1201/9781420064506, DOI 10.1201/9781420064506]
   GOETTL BP, 1993, DESIGNING FOR DIVERSITY, VOLS 1 AND 2, P1257
   Grier R., 2008, The red-line of workload: theory, research, and design
   Hairston WD, 2009, COMPUT METH PROG BIO, V93, P104, DOI 10.1016/j.cmpb.2008.08.003
   HART S G, 1988, P139
   Heloir A, 2014, ICTS IMPROVING PATIE, P196
   HICKS TG, 1979, HUM FACTORS, V21, P129, DOI 10.1177/001872087902100201
   HILL SG, 1992, HUM FACTORS, V34, P429, DOI 10.1177/001872089203400405
   Hoepf M, 2015, PHYSL INDICATORS WOR
   Hunter J, 2021, DRIVE
   Jones N, 2016, BIOL SPORT, V33, P117, DOI 10.5604/20831862.1198210
   JORNA PGAM, 1992, BIOL PSYCHOL, V34, P237, DOI 10.1016/0301-0511(92)90017-O
   KELLEY CR, 1969, HUM FACTORS, V11, P547, DOI 10.1177/001872086901100602
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kramer A. F., 1990, MULTIPLE TASK PERFOR, P279, DOI [10.1080/00140139.2014.956151, DOI 10.1080/00140139.2014.956151]
   Labedan P, 2021, HUCAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 2: HUCAPP, P81, DOI 10.5220/0010296700810088
   Lahiri U, 2013, IEEE T NEUR SYS REH, V21, P55, DOI 10.1109/TNSRE.2012.2218618
   Landsberg CR, 2012, EVALUATION ADAPTIVE
   Landsberg CR, 2010, ADAPTIVE TRAINING CO
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   Losey S, 2021, AIR FORCE IS STILL S
   Luo LB, 2013, COMPUT ANIMAT VIRT W, V24, P345, DOI 10.1002/cav.1525
   Maggio MG, 2019, J CLIN NEUROSCI, V65, P106, DOI 10.1016/j.jocn.2019.03.017
   Mariani A, 2018, IEEE ENG MED BIO, P2162, DOI 10.1109/EMBC.2018.8512728
   Marucci M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84196-8
   MAY JG, 1990, ACTA PSYCHOL, V75, P75, DOI 10.1016/0001-6918(90)90067-P
   Mazloum A, 2008, IND HEALTH, V46, P269, DOI 10.2486/indhealth.46.269
   McCarthy C, 2016, 2016 IEEE EMBS International Student Conference (ISC)
   Metalis S.A., 1991, INT J AVIAT PSYCHOL, V1, P107, DOI [10.1207/s15327108ijap0102_2, DOI 10.1207/S15327108IJAP0102_2]
   Milstein N, 2020, FRONT BEHAV NEUROSCI, V14, DOI 10.3389/fnbeh.2020.00148
   Monfort SS, 2016, PROC SPIE, V9851, DOI 10.1117/12.2219703
   Moray N., 1979, Mental Workload: Its theory and measurement
   Moreno A, 2019, COMBAT JET COCKPIT
   Morrison J.E., 2000, On measuring the effectiveness of large-scale training simulations
   Mühlberger A, 2001, BEHAV RES THER, V39, P1033, DOI 10.1016/S0005-7967(00)00076-0
   MULDER LJM, 1992, BIOL PSYCHOL, V34, P205, DOI 10.1016/0301-0511(92)90016-N
   NASA, 2010, NASA HUM INT DES HDB, V3407
   Oberhauser M., 2018, Aviation Psychology and Applied Human Factors, DOI [DOI 10.1027/2192-0923/A000134, 10.1027/2192-0923/a000134]
   Oberhauser M, 2017, COGN TECHNOL WORK, V19, P263, DOI 10.1007/s10111-017-0421-7
   Orlansky J, 1994, P2982 IDA
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   Peretz C, 2011, NEUROEPIDEMIOLOGY, V36, P91, DOI 10.1159/000323950
   Popovic S, 2009, STUD HEALTH TECHNOL, V144, P50, DOI 10.3233/978-1-60750-017-9-50
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Recarte MA, 2000, J EXP PSYCHOL-APPL, V6, P31, DOI 10.1037/1076-898X.6.1.31
   Rehmann AJ., 1995, HDB HUMAN PERFORMANC
   Rogers RO, 2007, EXPT EVALUATE TRANSF
   ROSCOE AH, 1992, BIOL PSYCHOL, V34, P259, DOI 10.1016/0301-0511(92)90018-P
   Roscoe SN., 1980, Aviation Psychology
   Rossol N, 2011, FRAMEWORK ADAPTIVE T
   Saurav Kumar, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P252, DOI 10.1109/ICIS.2018.8466538
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Schuurmans AAT, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01648-w
   SIREVAAG EJ, 1993, ERGONOMICS, V36, P1121, DOI 10.1080/00140139308967983
   Stetz MC., 2008, J CYBERTHERAPY REHAB, V1, P239
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Summa S, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0009-5
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Tattersall AJ, 1995, HUM FACTORS, V37, P682, DOI 10.1518/001872095778995517
   Unity, 2021, UNITY MANUAL UNITY U
   Veltman JA, 1996, BIOL PSYCHOL, V42, P323, DOI 10.1016/0301-0511(95)05165-1
   Veltman JA, 2002, INT J AVIAT PSYCHOL, V12, P33, DOI 10.1207/S15327108IJAP1201_4
   Wang Z, 2016, AEROSP MED HUM PERF, V87, P375, DOI 10.3357/AMHP.4386.2016
   Wiederhold B.K., 2008, Journal of CyberTherapy Rehabilitation, V1, P23
   Wilson G.F., 1987, Proceedings from the 31st Annual Meeting of the Human Factors Socitey, P779, DOI [10.1177/154193128703100720, DOI 10.1177/154193128703100720]
   Wilson GF, 2003, HUM FACTORS, V45, P635, DOI 10.1518/hfes.45.4.635.27088
   WILSON GF, 1992, BIOL PSYCHOL, V34, P163, DOI 10.1016/0301-0511(92)90014-L
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
   Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
   Zhang J, 2007, J MANIP PHYSIOL THER, V30, P374, DOI 10.1016/j.jmpt.2007.04.001
   Zhang Y, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/8086389
   Zheng B, 2012, SURG ENDOSC, V26, P2746, DOI 10.1007/s00464-012-2268-6
   Zhou J, 2020, SOIL DYN EARTHQ ENG, V139, DOI 10.1016/j.soildyn.2020.106390
NR 105
TC 0
Z9 0
U1 11
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2509
EP 2528
DI 10.1007/s10055-023-00827-7
EA JUL 2023
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001018737000001
DA 2024-07-18
ER

PT J
AU Fang, Y
   Liu, Q
   Xu, YW
   Guo, YM
   Zhao, TS
AF Fang, Ying
   Liu, Qian
   Xu, Yiwen
   Guo, Yanmin
   Zhao, Tiesong
TI Virtual reality interaction based on visual attention and kinesthetic
   information
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality (VR); Multimedia; Haptics; Visual attention;
   Human-Computer Interaction (HCI)
ID RECOGNITION
AB Emerging multimedia technologies significantly enhance the naturalness and immersion of human computer interaction. Currently, research on kinesthetic information has gained increasing attentions of multimedia community. However, effective interaction between kinesthetic and other multimedia signals remains a challenging task. In this paper, we propose a visual-kinesthetic interaction in Virtual Reality (VR) and real-world control tasks. First, we model the correlation between user's visual attention and kinesthetic positions under different tasks. Second, we utilize an attention-based Long Short-Term Memory network to predict the kinesthetic positions. Third, we build a VR system with robotic car control, which validates our model in VR interaction and control tasks. With a high task achievement rate, we envision the implementation of kinesthetic information in a more natural interaction system. The VR interaction system based on the proposed model can also provide guidance for the design of immersive robot teleoperation systems.
C1 [Fang, Ying; Xu, Yiwen; Guo, Yanmin; Zhao, Tiesong] Fuzhou Univ, Fujian Key Lab Intelligent Proc & Wireless Transmi, Fuzhou 350108, Fujian, Peoples R China.
   [Zhao, Tiesong] Peng Cheng Lab, Shenzhen 518038, Guangdong, Peoples R China.
   [Liu, Qian] Dalian Univ Technol, Dept Comp Sci & Technol, Dalian 116081, Liaoning, Peoples R China.
C3 Fuzhou University; Peng Cheng Laboratory; Dalian University of
   Technology
RP Zhao, TS (corresponding author), Fuzhou Univ, Fujian Key Lab Intelligent Proc & Wireless Transmi, Fuzhou 350108, Fujian, Peoples R China.; Zhao, TS (corresponding author), Peng Cheng Lab, Shenzhen 518038, Guangdong, Peoples R China.
EM fangying@fzu.edu.cn; qianliu@dlut.edu.cn; xu_yiwen@fzu.edu.cn;
   221120067@fzu.com; t.zhao@fzu.edu.cn
RI WANG, SHIHAO/KHC-8263-2024; LIU, QIAN/HKF-8604-2023; li,
   xiaomin/KCX-9845-2024
OI LIU, QIAN/0000-0002-0517-7687; 
FU Natural Science Foundation of Fujian Province, China [2022J02015]
FX This work was supported in part by Natural Science Foundation of Fujian
   Province, China (Grants No. 2022J02015).
CR Bhardwaj SK, 2017, 2017 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2017), P1, DOI 10.1109/WIECON-ECE.2017.8468927
   Biswas P, 2014, UNIVERSAL ACCESS HUM, V8513
   Chen DP, 2018, IEEE T HAPTICS, V11, P555, DOI 10.1109/TOH.2018.2826551
   Culbertson H, 2018, ANNU REV CONTR ROBOT, V1, P385, DOI 10.1146/annurev-control-060117-105043
   Falco P, 2019, IEEE T ROBOT, V35, P987, DOI 10.1109/TRO.2019.2914772
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gokhale V, 2016, IEEE HAPTICS SYM, P217, DOI 10.1109/HAPTICS.2016.7463180
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Huang HC, 2019, IEEE ACCESS, V7, P182348, DOI 10.1109/ACCESS.2019.2959906
   Isnard V, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P75, DOI 10.1109/VRW52623.2021.00021
   Low T, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P273, DOI 10.1145/3020165.3022131
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mao L, 2017, IEEE INT C INT TECHN, P1
   Martinez J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P629, DOI 10.1109/VR.2018.8446522
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Pietra A, 2021, VIRTUAL REAL-LONDON, V25, P945, DOI 10.1007/s10055-021-00499-1
   Van Damme S, 2020, PROCEEDINGS OF THE 2020 6TH IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2020): BRIDGING THE GAP BETWEEN AI AND NETWORK SOFTWARIZATION, P57, DOI [10.1109/NetSoft48620.2020.9165335, 10.1109/netsoft48620.2020.9165335]
   Walker ME, 2019, ACMIEEE INT CONF HUM, P202, DOI [10.1109/HRI.2019.8673306, 10.1109/hri.2019.8673306]
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   Xu XN, 2016, IEEE T IND ELECTRON, V63, P6419, DOI 10.1109/TIE.2016.2587239
   Xue H, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P111, DOI [10.1109/BigMM.2019.00026, 10.1109/BigMM.2019.00-36]
   Yang CG, 2019, IEEE T AUTOM SCI ENG, V16, P1512, DOI 10.1109/TASE.2018.2874454
   Yip HM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1900, DOI 10.1109/ROBIO.2016.7866606
   Yu XB, 2021, IEEE T IND ELECTRON, V68, P8657, DOI 10.1109/TIE.2020.3016271
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P957, DOI 10.1109/TMM.2015.2431915
   Zinchenko K, 2017, IEEE T IND INFORM, V13, P607, DOI 10.1109/TII.2016.2625818
NR 26
TC 0
Z9 0
U1 8
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2183
EP 2193
DI 10.1007/s10055-023-00801-3
EA APR 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000978556400001
DA 2024-07-18
ER

PT J
AU Blundell, J
   Harris, D
AF Blundell, James
   Harris, Don
TI Designing augmented reality for future commercial aviation: a
   user-requirement analysis with commercial aviation pilots
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Head-mounted displays; Design requirements;
   User-centred design; Situation awareness
ID HEAD-UP; DIMENSIONALITY; NEUROSURGERY; INFORMATION; AWARENESS; DISPLAYS;
   COSTS; PATH
AB Augmented reality (AR) capable head-mounted displays (HMDs) have been proposed as technological enablers of several complex future flight concepts, which will bring accompanying pilot situation awareness (SA) and operational safety enhancements. However, relevant aviation design guidance concerning the implementation of modern HMD technologies and AR symbology is sparse. Consequently, the current study describes an SA grounded user-requirements analysis of operational applications for HMD technologies and AR symbology, with the intention of providing inputs for future designs of commercial aviation systems. In addition, insights from the study are relevant for AR design more generally. Endsley's three-level SA model (1988) was applied as a framework to focus group discussions with eleven aviation subject matter experts. Thematic analysis highlighted multiple operational scenarios where HMD technology and AR may enhance SA, along with the requirements of the technologies to provide these relevant advantages. In future, more detailed user-centred design recommendations should be sought for the specific applications identified within the current study.
C1 [Blundell, James] Coventry Univ, Inst Clean Growth & Future Mobil, Coventry CV1 5FB, England.
   [Harris, Don] Coventry Univ, Fac Engn Environm & Comp, Coventry CV1 5FB, England.
C3 Coventry University; Coventry University
RP Blundell, J (corresponding author), Coventry Univ, Inst Clean Growth & Future Mobil, Coventry CV1 5FB, England.
EM james.blundell@coventry.ac.uk; don.harris@coventry.ac.uk
RI Blundell, James/JEO-7678-2023; Blundell, James/KII-1193-2024; Harris,
   Don/AEQ-2631-2022
OI Blundell, James/0000-0002-4029-0773; Harris, Don/0000-0002-2113-8848
FU UK Aerospace Technology Institute [113108]
FX The research was supported by the UK Aerospace Technology Institute
   (grant reference number 113108).
CR Agyekum K, 2019, J ENG DES TECHNOL, V17, P1035, DOI 10.1108/JEDT-01-2019-0028
   Akçayir M, 2016, COMPUT HUM BEHAV, V57, P334, DOI 10.1016/j.chb.2015.12.054
   Alexander AL, 2009, INT J AVIAT PSYCHOL, V19, P105, DOI 10.1080/10508410902766192
   Alvarez C, 2021, IEEEAAIA DIGIT AVION, DOI 10.1109/DASC52595.2021.9594307
   Ariansyah D, 2022, APPL ERGON, V98, DOI 10.1016/j.apergo.2021.103597
   Arthur J., 2014, Proceedings of SPIE, P9086
   Babar A, 2018, COMMUN ASSOC INF SYS, V42, P334, DOI 10.17705/1CAIS.04212
   Baber C, 2001, INT J HUM-COMPUT ST, V54, P613, DOI 10.1006/ijhc.2000.0452
   Bayer M.M., 2009, Helmet-mounted displays: Sensation, perception, and cognitive issues, P47
   Blundell J, 2023, AERONAUT J, V127, P581, DOI 10.1017/aer.2022.81
   Blundell James, 2020, Advances in Human Aspects of Transportation. Proceedings of the AHFE 2020 Virtual Conference on Human Aspects of Transportation. Advances in Intelligent Systems and Computing (AISC 1212), P493, DOI 10.1007/978-3-030-50943-9_62
   Blundell J., 2019, AHFE 2019, P786, DOI [10.1007/978-3-319-93885-1_13, DOI 10.1007/978-3-319-93885-1_13]
   Blundell J, 2020, DISPLAYS, V65, DOI 10.1016/j.displa.2020.101973
   Blundell J, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.101932
   Boeing Commercial Airplanes, 2017, STAT SUMM COMM JET A
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Bouamrane MM, 2019, COMP MED SY, P212, DOI 10.1109/CBMS.2019.00051
   Boyer B, 2016, 3 DIMENSIONAL DISPLA, V1, P6, DOI [10.1177/154193129503900103, DOI 10.1177/154193129503900103]
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chien JC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163555
   Dixon BJ, 2014, AM J RHINOL ALLERGY, V28, P433, DOI 10.2500/ajra.2014.28.4067
   Dixon BJ, 2013, SURG ENDOSC, V27, P454, DOI 10.1007/s00464-012-2457-3
   Endsley M, 2012, DESIGNING SITUATION, DOI [10.1080/10686967.2017.11918512, DOI 10.1080/10686967.2017.11918512]
   Endsley M. R., 1988, P HUM FACT SOC ANN M, V32, P97, DOI DOI 10.1177/154193128803200221
   Endsley MicaR., 2001, P 2 INT WORKSHOP SYM, P1
   Fadden S, 2001, HUM FACTORS, V43, P173, DOI 10.1518/001872001775900841
   Fadden S, 1998, HUM FAC ERG SOC P, P16
   Federal Aviation Administration, 2014, 2511 AC FED AV ADM U
   Fischer E, 1980, NASA TECHNICAL PAPER
   Guha D, 2017, CAN J NEUROL SCI, V44, P235, DOI 10.1017/cjn.2016.443
   Li WC, 2020, INT J HUM-COMPUT ST, V135, DOI 10.1016/j.ijhcs.2019.102377
   Marcus HJ, 2015, J NEUROSURG, V123, P307, DOI 10.3171/2014.10.JNS141662
   Melzer J.E., 2009, HELMET MOUNTED DISPL, P805
   Moehle R, 2015, SAE INT J AEROSP, V8, P81, DOI 10.4271/2015-01-2440
   MOLICH R, 1990, COMMUN ACM, V33, P338, DOI 10.1145/77481.77486
   NEISSER U, 1964, SCI AM, V210, P94, DOI 10.1038/scientificamerican0664-94
   Nichol RJ., 2015, INT J EC MANAGE SCI, DOI [10.4172/2162-6359.1000248, DOI 10.4172/2162-6359.1000248]
   Olmos O, 2000, INT J AVIAT PSYCHOL, V10, P247, DOI 10.1207/S15327108IJAP1003_03
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Parnell KJ, 2021, INT J HUM-COMPUT INT
   Poushneh A, 2018, J RETAIL CONSUM SERV, V41, P169, DOI 10.1016/j.jretconser.2017.12.010
   Rash CE, 1988, TECH REP, P88
   Robinson T, 2018, WEARABLE COCKPITS UL
   Safi M, 2019, AIRCR ENG AEROSP TEC, V91, P1187, DOI 10.1108/AEAT-09-2018-0241
   Schulz CM, 2013, ANESTHESIOLOGY, V118, P729, DOI 10.1097/ALN.0b013e318280a40f
   Stanton N.A., 2013, Human Factors Methods: A Practical Guide for Engineering and Design, P145, DOI [10.1201/9781315587394, DOI 10.1201/9781315587394]
   Stanton NA, 2019, ERGONOMICS, V62, P255, DOI 10.1080/00140139.2017.1414301
   Stuart GW., 2001, HUMAN FACTORS AEROSP, V1, P103
   Szajna A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174755
   Tran TT, 2018, INT CONF OPTIC MEMS, P1
   Ververs PM., 1998, INT J AVIAT PSYCHOL, DOI [10.1207/s15327108ijap0804, DOI 10.1207/S15327108IJAP0804]
   Walko C, 2018, INTEGRATION AUGMENTE
   Wickens C., 2014, An Introduction to Human Factors Engineering
   Wickens C. D., 2000, P HUM FACT ERG SOC A, V44, DOI [10.1177/154193120004402119, DOI 10.1177/154193120004402119]
   Wickens CD, 2017, INT J AEROSP PSYCHOL, V27, P44, DOI 10.1080/10508414.2017.1366270
   Wickens CD, 2009, INT J AVIAT PSYCHOL, V19, P182, DOI 10.1080/10508410902766549
   Yeh M, 2003, HUM FACTORS, V45, P390, DOI 10.1518/hfes.45.3.390.27249
NR 59
TC 3
Z9 3
U1 5
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2167
EP 2181
DI 10.1007/s10055-023-00798-9
EA APR 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000978567600001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Ricci, FS
   Boldini, A
   Beheshti, M
   Rizzo, JR
   Porfiri, M
AF Ricci, Fabiana Sofia
   Boldini, Alain
   Beheshti, Mahya
   Rizzo, John-Ross
   Porfiri, Maurizio
TI A virtual reality platform to simulate orientation and mobility training
   for the visually impaired
SO VIRTUAL REALITY
LA English
DT Article
DE Assistive technology; Disability; Human-computer interaction; Travel
   aid; Urban accessibility
ID OLDER-ADULTS; PERFORMANCE; VISION; PEOPLE; GLAUCOMA; BLIND
AB Blindness and low vision are an urgent, steadily increasing public health concern. One of the most dramatic consequences of the debilitating conditions that cause visual impairment (VI) is the loss of mobility. Immobility is a grave impediment to quality of life. Orientation and mobility (O&M) training is a profession specific to VI that teaches safe, efficient, and effective travel skills to persons of all ages and in all types of environments. However, the lack of standardized best practices for objective assessment of performance and the exposure of trainees to harm during training are key hurdles for O&M education success. To partially mitigate these drawbacks, we propose a virtual reality platform that can support O&M trainers in the evaluation and refinement of O&M practice, help O&M trainees learn new O&M techniques in a completely safe, yet realistic, environment, and raise awareness for VI in the general public. The proposed platform is tested with a proof-of-concept experiment that evaluates the clinical utility of a custom VI simulation, the immersivity of the virtual reality experience-a crucial attribute for training and educational purposes-and participants' disability awareness and gained knowledge about the challenges faced by persons with VI in their daily life. The first concept is tested by assessing participants' performance in virtual reality-based wayfinding tasks while the second and third are tested through a series of dedicated questionnaires.
C1 [Ricci, Fabiana Sofia; Rizzo, John-Ross; Porfiri, Maurizio] NYU, MetroTech Ctr 6, Dept Biomed Engn, Tandon Sch Engn, New York, NY 11201 USA.
   [Boldini, Alain; Beheshti, Mahya; Rizzo, John-Ross; Porfiri, Maurizio] NYU, MetroTech Ctr 6, Dept Mech & Aerosp Engn, Tandon Sch Engn, New York, NY 11201 USA.
   [Beheshti, Mahya; Rizzo, John-Ross] New York Univ Langone Hlth, Dept Rehabil Med, 240 East 38th St, New York, NY 10016 USA.
   [Rizzo, John-Ross] New York Univ Langone Hlth, Dept Neurol, 240 East 38th St, New York, NY 10016 USA.
   [Porfiri, Maurizio] NYU, Ctr Urban Sci & Progress, Tandon Sch Engn, 370 Jay St, New York, NY 11201 USA.
C3 New York University; New York University Tandon School of Engineering;
   New York University; New York University Tandon School of Engineering;
   New York University; New York University; New York University; New York
   University Tandon School of Engineering
RP Porfiri, M (corresponding author), NYU, MetroTech Ctr 6, Dept Biomed Engn, Tandon Sch Engn, New York, NY 11201 USA.; Porfiri, M (corresponding author), NYU, MetroTech Ctr 6, Dept Mech & Aerosp Engn, Tandon Sch Engn, New York, NY 11201 USA.; Porfiri, M (corresponding author), NYU, Ctr Urban Sci & Progress, Tandon Sch Engn, 370 Jay St, New York, NY 11201 USA.
EM fsr8343@nyu.edu; alain.boldini@nyu.edu; Mahya.Beheshti@nyulangone.org;
   JohnRoss.Rizzo@nyulangone.org; mporfiri@nyu.edu
RI Porfiri, Maurizio/A-1712-2009
OI Boldini, Alain/0000-0003-2231-7108; Ricci, Fabiana
   Sofia/0009-0002-3818-7395
FU National Science Foundation [CBET-1604355, ECCS-1928614, CNS-1952180]
FX This study was supported by the National Science Foundation under Award
   Number CBET-1604355, ECCS-1928614, and CNS-1952180.
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Allison K, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.18710
   Alma MA, 2011, DISABIL REHABIL, V33, P63, DOI 10.3109/09638288.2010.488711
   [Anonymous], 2008, Proceedings of the 2nd International Conference on Tangible and Embedded Interaction-TEI'08, DOI DOI 10.1145/1347390.1347433
   Ballemans J, 2012, BMC HEALTH SERV RES, V12, DOI 10.1186/1472-6963-12-141
   BarakVentura R, 2020, DYNAMIC SYSTEMS CONT
   Barclay L.A., 2011, LEARNING LISTEN LIST
   Blasch B., 1997, FDN ORIENTATION MOBI, V2nd
   Boldini A, 2021, PROC SPIE, V11590, DOI 10.1117/12.2581441
   Bormann K., 2006, VIRTUAL REAL-LONDON, V9, P226, DOI DOI 10.1007/S10055-006-0019-5
   Bowditch J, 2021, POWER VIRTUAL REALIT, P75
   Brouwer DM., 2008, BRIT J OCCUP THER, DOI DOI 10.1177/030802260807101003
   Burton MJ, 2021, LANCET GLOB HEALTH, V9, pE489, DOI 10.1016/S2214-109X(20)30488-5
   Campisi T, 2021, RES TRANSP BUS MANAG, V40, DOI 10.1016/j.rtbm.2020.100592
   Chou CF, 2013, AM J PREV MED, V45, P29, DOI 10.1016/j.amepre.2013.02.018
   Congdon N, 2004, ARCH OPHTHALMOL-CHIC, V122, P477
   Demmin DL, 2020, CLIN OPHTHALMOL, V14, P4229, DOI 10.2147/OPTH.S258783
   Dowling J., 2003, Proceedings of the Eighth Australian and New Zealand Intelligent Information Systems Conference (ANZIIS 2003), P109
   Figg B, 2021, J CONS HLTH INTERNET, V25, P187, DOI 10.1080/15398285.2021.1911158
   Ghali NI, 2012, INTEL SYST REF LIBR, V26, P363
   Goldschmidt M., 2018, ORIENTATION MOBILITY, P237, DOI [10.1007/978-3-319-54446-5_8, DOI 10.1007/978-3-319-54446-5_8]
   Gopalakrishnan S, 2020, CYBERPSYCH BEH SOC N, V23, P171, DOI 10.1089/cyber.2019.0235
   Gordois A, 2012, GLOB PUBLIC HEALTH, V7, P465, DOI 10.1080/17441692.2011.634815
   Haegele JA, 2022, DISABIL REHABIL, V44, P4361, DOI 10.1080/09638288.2021.1906333
   Haegele JA, 2021, DISABIL REHABIL, V43, P530, DOI 10.1080/09638288.2019.1631397
   Hawkins AS, 2003, J GLAUCOMA, V12, P134, DOI 10.1097/00061198-200304000-00008
   Hill E., 1976, ORIENTATION MOBILITY
   Houzangbe S, 2020, VIRTUAL REAL-LONDON, V24, P665, DOI 10.1007/s10055-020-00429-7
   Hu CX, 2014, AM J MED SCI, V348, P403, DOI 10.1097/MAJ.0000000000000319
   Jones GC, 2010, OPHTHAL EPIDEMIOL, V17, P400, DOI 10.3109/09286586.2010.528137
   Jones PR, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0242-6
   Judd C.M., 2017, DATA ANAL MODEL COMP, DOI [10.4324/9781315744131, DOI 10.4324/9781315744131]
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kim HN, 2021, INT J HUM FACT ERGON, V8, P64, DOI 10.1504/IJHFE.2021.115046
   Klinger E., 2010, RETHINKING PHYS REHA, P203
   Krösl K, 2018, VISUAL COMPUT, V34, P911, DOI 10.1007/s00371-018-1517-7
   Lagrow S.J., 1994, Orientation and mobility: Techniques for independence
   Lahav O., 2005, Disability and Human Development, P231, DOI DOI 10.1515/IJDHD.2005.4.3.231
   Lahav O, 2012, J ASSIST TECHNOL, V6, P38, DOI 10.1108/17549451211214346
   Lahav O, 2015, COMPUT EDUC, V80, P1, DOI 10.1016/j.compedu.2014.08.003
   Lin JH, 2015, INT J TECHNOL HUM IN, V11, P1, DOI 10.4018/ijthi.2015070101
   Marques AP, 2021, ECLINICALMEDICINE, V35, DOI 10.1016/j.eclinm.2021.100852
   Matthews G, 2002, EMOTION, V2, P315, DOI 10.1037//1528-3542.2.4.315
   Mouatt B, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.564664
   Oculus Safety Center, 2021, OCUL QUEST SAFET WAR
   Paliokas I, 2020, ADV EXP MED BIOL, V1196, P127, DOI 10.1007/978-3-030-32637-1_13
   Palmisano S, 2022, VIRTUAL REAL-LONDON, V26, P1373, DOI 10.1007/s10055-022-00634-6
   Rokach A, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.641711
   Sansone LG, 2022, VIRTUAL REAL-LONDON, V26, P903, DOI 10.1007/s10055-021-00584-5
   Shoureshi Rahmat A., 2017, Advances in Science and Technology, V100, P172, DOI 10.4028/www.scientific.net/AST.100.172
   Soong GP, 2001, OPTOMETRY VISION SCI, V78, P657, DOI 10.1097/00006324-200109000-00011
   STAMPER R., 1999, BECKER SHAFFERS DIAG
   Stein JD, 2021, JAMA-J AM MED ASSOC, V325, P164, DOI 10.1001/jama.2020.21899
   Steinmetz JD, 2021, LANCET GLOB HEALTH, V9, pE144, DOI [10.1016/S2214-109X(20)30425-3, 10.1016/S2214-109X(20)30489-7]
   Tao GR, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-020-00801-3
   Ventura RB, 2021, IEEE T GAMES, V13, P23, DOI 10.1109/TG.2019.2928795
   Virgili G, 2010, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003925.pub3
   Wiener G., 1997, Journal of Visual Impairment Blindness, V91, P435, DOI 10.1177/0145482x9709100504
   World Health Organization, 2019, WORLD REP VIS
   Wu Haojie, 2018, Frontiers in ICT, V5, P27, DOI [10.3389/fict.2018.00027, DOI 10.3389/FICT.2018.00027]
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
NR 61
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 797
EP 814
DI 10.1007/s10055-022-00691-x
EA SEP 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000853285000001
DA 2024-07-18
ER

PT J
AU Xu, XH
AF Xu, Xinhao
TI To social with social distance: a case study on a VR-enabled graduation
   celebration amidst the pandemic
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Graduation celebration; Pandemic; Social distance
ID VIRTUAL-REALITY SIMULATION; 2ND LIFE; PERFORMANCE; ENVIRONMENT; GAME;
   CONSTRUCTION; TECHNOLOGY; EXPERIENCE; CHILDREN; MODEL
AB This paper introduces a timely case study on a 3D virtual reality-enabled graduation celebration project that provided an alternative approach to celebrating university graduation amidst the COVID-19 pandemic. The project was carefully designed with fun, engaging, and interactive activities to compensate for the cancelation of the conventional commencement in spring 2020 due to the pandemic. More than 20 graduating students, faculty and staff members participated in a 2-h virtual reality live event appearing as 3D avatars on their own computers. Quantitative and qualitative data collected from 10 participants were analyzed for user experience, cognitive contribution, technology acceptance, and the feasibility. Results revealed that such a project was technologically sound, functionally acceptable, user-friendly, and practically implementable. The results also informed the lessons learned from the current design and the places to improve.
C1 [Xu, Xinhao] Univ Missouri, Sch Informat Sci & Learning Technol, Columbia, MO 65211 USA.
C3 University of Missouri System; University of Missouri Columbia
RP Xu, XH (corresponding author), Univ Missouri, Sch Informat Sci & Learning Technol, Columbia, MO 65211 USA.
EM xuxinhao@missouri.edu
RI Xu, Xinhao/L-2992-2019
OI Xu, Xinhao/0000-0002-4981-4641
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Andersen SAW, 2018, MED TEACH, V40, P684, DOI 10.1080/0142159X.2018.1465182
   Anderson P, 2020, THE VERGE       0331
   Andreas K, 2010, COMPUT EDUC, V55, P603, DOI 10.1016/j.compedu.2010.02.021
   Baker SC, 2009, TEACH PSYCHOL, V36, P59, DOI 10.1080/00986280802529079
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Bouta H, 2013, EDUC INF TECHNOL, V18, P571, DOI 10.1007/s10639-012-9198-8
   Bricken M., 1991, Computer Graphics, V25, P178, DOI 10.1145/126640.126657
   Chang TP, 2016, CLIN PEDIATR EMERG M, V17, P224, DOI 10.1016/j.cpem.2016.05.002
   Chen JC, 2016, COMPUT EDUC, V102, P152, DOI 10.1016/j.compedu.2016.08.004
   Chertoff DB, 2010, P IEEE VIRT REAL ANN, P103, DOI 10.1109/VR.2010.5444804
   Cho JS, 2013, J LAPAROENDOSC ADV S, V23, P992, DOI 10.1089/lap.2012.0396
   Cho YH, 2017, BRIT J EDUC TECHNOL, V48, P202, DOI 10.1111/bjet.12356
   Cox DJ, 2017, J AUTISM DEV DISORD, V47, P2544, DOI 10.1007/s10803-017-3164-7
   Di Blas N, 2014, EDUC TECHNOL SOC, V17, P54
   Fonseca X, 2021, ENTERTAIN COMPUT, V36, DOI 10.1016/j.entcom.2020.100385
   Garris R., 2002, Simulation & Gaming, V33, P441, DOI 10.1177/1046878102238607
   Gregory S, 2012, AUSTRALAS J EDUC TEC, V28, P420
   Halvorson W, 2011, J MARKET EDUC, V33, P217, DOI 10.1177/0273475311410854
   Hamalainen R., 2006, The Internet and Higher Education, V9, P47
   Hämäläinen R, 2011, TECHNOL PEDAGOG EDUC, V20, P61, DOI 10.1080/1475939X.2011.554010
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hsiao HS, 2014, AUSTRALAS J EDUC TEC, V30, P652
   Janssen J, 2012, METACOGN LEARN, V7, P25, DOI 10.1007/s11409-010-9061-5
   Jin SAA, 2012, COMPUT HUM BEHAV, V28, P2160, DOI 10.1016/j.chb.2012.06.022
   Ke FF, 2020, J COMPUT HIGH EDUC, V32, P607, DOI 10.1007/s12528-020-09249-9
   Ke FF, 2020, BRIT J EDUC TECHNOL, V51, P2544, DOI 10.1111/bjet.12936
   Ke FF, 2015, J SPEC EDUC, V48, P290, DOI 10.1177/0022466913498773
   King A, 2008, MUSIC EDUC RES, V10, P422, DOI 10.1080/14613800802280167
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Carrió-Pastor ML, 2015, PROCD SOC BEHV, V178, P32, DOI 10.1016/j.sbspro.2015.03.142
   Magen-Nagar N, 2018, INTERACT LEARN ENVIR, V26, P621, DOI 10.1080/10494820.2017.1376336
   Menck N, 2012, PROC CIRP, V3, P317, DOI 10.1016/j.procir.2012.07.055
   Moon J, 2020, BRIT J EDUC TECHNOL, V51, P1766, DOI 10.1111/bjet.13005
   Muir T, 2013, J INTERACT MEDIA EDU
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   OpenSimulator, 2020, RELEASE0 9 1 1
   Papert S., 1991, CONSTRUCTIONISM, V36, P1
   Park SY, 2009, EDUC TECHNOL SOC, V12, P150
   QSR International Pty Ltd, 2020, NVivo
   Resta P, 2007, EDUC PSYCHOL REV, V19, P65, DOI 10.1007/s10648-007-9042-7
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Smith MJ, 2015, SCHIZOPHR RES, V166, P86, DOI 10.1016/j.schres.2015.05.022
   Smith PC, 2015, CLIN SIMUL NURS, V11, P52, DOI 10.1016/j.ecns.2014.10.001
   Steinkuehler C, 2006, J COMPUT-MEDIAT COMM, V11
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sugden C, 2012, ANN SURG, V256, P188, DOI 10.1097/SLA.0b013e31825b6e9c
   Sumtsova OV, 2018, INT J EMERG TECHNOL, V13, P160, DOI 10.3991/ijet.v13i01.7811
   Sweller J., 1994, Learning and instruction, P295, DOI DOI 10.1016/0959-4752(94)90003-5
   Sweller J, 2010, EDUC PSYCHOL REV, V22, P123, DOI 10.1007/s10648-010-9128-5
   Teoh Jase, 2011, Journal of Educational Technology Systems, V40, P415, DOI 10.2190/ET.40.4.g
   Thorsteinsson G., 2007, B I VOCATIONAL TECHN, V4, P6
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
   Vesga JB, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI 10.1109/VR50410.2021.00090
   Wang XH, 2018, BRIT J EDUC TECHNOL, V49, P742, DOI 10.1111/bjet.12646
   Wang Y., 2009, Journal of Information Systems Education, V20, P235
   Wang YF, 2017, BRIT J EDUC TECHNOL, V48, P431, DOI 10.1111/bjet.12388
   Wendel V, 2013, EDUC INF TECHNOL, V18, P287, DOI 10.1007/s10639-012-9244-6
   Wilson S., 2020, SORANEWS24      0315
   Xu XH, 2022, J EDUC COMPUT RES, V60, P455, DOI 10.1177/07356331211036492
   Zhang HS, 2013, BRIT J EDUC TECHNOL, V44, P243, DOI 10.1111/j.1467-8535.2012.01312.x
   Zhu C, 2012, EDUC TECHNOL SOC, V15, P127
NR 63
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3319
EP 3331
DI 10.1007/s10055-022-00646-2
EA APR 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000783064900001
PM 35464641
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Fong, KNK
   Tang, YM
   Sie, K
   Yu, AKH
   Lo, CCW
   Ma, YWT
AF Fong, Kenneth N. K.
   Tang, Yuk Ming
   Sie, Karen
   Yu, Andy K. H.
   Lo, Cherry C. W.
   Ma, Yuko W. T.
TI Task-specific virtual reality training on hemiparetic upper extremity in
   patients with stroke
SO VIRTUAL REALITY
LA English
DT Article
DE Rehabilitation; Training stroke; Virtual reality; Evaluation; Upper
   limb; Task-specific training; Leap motion controller
ID MOTOR-FUNCTION-TEST; ARM; REHABILITATION; RECOVERY; RELIABILITY; HAND
AB Task-specific training has been proven to be effective in promoting recovery of the hemiparetic upper extremities after a stroke. This study was to develop a task-specific VR (TS-VR) program using a leap motion controller device and the Unity3D game engine to promote recovery of the hemiparetic upper extremity in patients with stroke based on a hierarchy of seven functional tasks in the functional test for the hemiplegic upper extremity (FTHUE). The final version of the TS-VR was tested on 20 patients suffering from chronic stroke with upper-extremity hemiparesis over 2 weeks, 5 sessions per week, 30 min per session. Outcomes were assessed using the Fugl-Meyer assessment-upper extremity score (FMA-UE), the Wolf motor function test (WMFT), and the motor activity log (MAL) at the first (week 0), last (week 2), and follow-up sessions (week 5). Patients' arm impairments were stratified into lower (levels 1-4) and higher (levels 5-7) functioning groups according to the FTHUE. Significant improvements were found after TS-VR training in FMA-UE total score and its subscores, and WFMT score among the three time occasions (p = 0.000), but no significant effect on grip strength was found. The higher-functioning group benefited more from the TS-VR, as indicated in outcome measures as well as amount of use score in MAL, but this was not the case for those in the lower-functioning group. Our findings show the TS-VR training was useful for upper-extremity recovery in patients with chronic stroke. It has potential to be applied in clinical settings in future.
C1 [Fong, Kenneth N. K.; Sie, Karen; Yu, Andy K. H.; Lo, Cherry C. W.; Ma, Yuko W. T.] Hong Kong Polytech Univ, Dept Rehabil Sci, Hung Hom, Hong Kong, Peoples R China.
   [Tang, Yuk Ming] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom, Hong Kong, Peoples R China.
   [Tang, Yuk Ming] City Univ Macau, Fac Business, Taipa, Macao, Peoples R China.
C3 Hong Kong Polytechnic University; Hong Kong Polytechnic University; City
   University of Macau
RP Tang, YM (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom, Hong Kong, Peoples R China.; Tang, YM (corresponding author), City Univ Macau, Fac Business, Taipa, Macao, Peoples R China.
EM yukming.tang@polyu.edu.hk
RI Tang, YM/AAF-2055-2020; Fong, Kenneth N. K./F-9608-2014
OI Tang, YM/0000-0001-8215-4190; Fong, Kenneth N. K./0000-0001-5909-4847
CR Bayona Nestor A, 2005, Top Stroke Rehabil, V12, P58
   BOHANNON RW, 1987, PHYS THER, V67, P206, DOI 10.1093/ptj/67.2.206
   Borschmann KN, 2020, PHYSIOTHERAPY, V107, P216, DOI 10.1016/j.physio.2019.10.001
   Cauraugh JH, 2003, J NEUROL NEUROSUR PS, V74, P1562, DOI 10.1136/jnnp.74.11.1562
   Colgan A, 2017, LEAP MOTION BLOG
   Condino S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101178
   Cortés-Pérez I, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062065
   Cunningham P, 2016, CLIN REHABIL, V30, P731, DOI 10.1177/0269215515603438
   De Mauro A., 2011, P 1 INT WORKSHOP ENG, V727, P48
   Dobkin BH, 2005, NEW ENGL J MED, V352, P1677, DOI 10.1056/NEJMcp043511
   DUNCAN PW, 1983, PHYS THER, V63, P1606, DOI 10.1093/ptj/63.10.1606
   Fernández-González P, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0593-x
   Fong K., 2004, Hong Kong journal of occupational therapy, V14, P21, DOI DOI 10.1016/S1569-1861(09)70025-7
   Fong KN, 2011, ARCH PHYS MED REHAB, V92, P15, DOI 10.1016/j.apmr.2010.09.014
   Fong KNK, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-19
   FUGLMEYER AR, 1980, SCAND J REHABIL MED, P140
   FUGLMEYER AR, 1975, SCAND J REHABIL MED, V7, P13
   Ghassemi M, 2019, IEEE T NEUR SYS REH, V27, P283, DOI 10.1109/TNSRE.2019.2894102
   Hossain MS, 2016, MULTIMEDIA SYST, V22, P659, DOI 10.1007/s00530-015-0481-6
   Kilbreath MP., 2001, MARCH 25 30 2001 ANN
   Kiper P, 2018, ARCH PHYS MED REHAB, V99, P834, DOI 10.1016/j.apmr.2018.01.023
   Krastev Georgi, 2015, International Journal of Computer Science & Information Technology, V7, P145, DOI 10.5121/ijcsit.2015.7612
   Kwakkel G, 2013, INT J STROKE, V8, P25, DOI 10.1111/j.1747-4949.2012.00967.x
   Lee B, 2018, J SENSORS, V2018, DOI 10.1155/2018/6073786
   Magill R.A., 2007, MOTOR LEARNING CONTR, V8th
   Ng AKY, 2008, HONG KONG J OCCUP TH, V18, P20, DOI 10.1016/S1569-1861(08)70009-3
   Okazaki S, 2017, J ERGON TECHNOL, V17, P32
   Page SJ, 2003, AM J PHYS MED REHAB, V82, P730, DOI 10.1097/01.PHM.0000078226.36000.A5
   Renganayagalu SK, 2021, TECHNOL KNOWL LEARN, V26, P999, DOI 10.1007/s10758-020-09489-9
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   Seo NJ, 2016, J REHABIL RES DEV, V53, P321, DOI 10.1682/JRRD.2015.03.0045
   Shin JH, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0125-x
   Syberfeldt A, 2015, PROCEDIA MANUF, V1, P98, DOI 10.1016/j.promfg.2015.09.068
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Tang YM, 2018, INT J ENG BUS MANAG, V10, DOI 10.1177/1847979018809599
   Tang YM, 2021, J COMPUT ASSIST LEAR, V37, P359, DOI 10.1111/jcal.12494
   Timmermans AAA, 2009, DISABIL REHABIL, V31, P1344, DOI 10.1080/09638280902823664
   Turolla A, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-85
   Uswatte G, 2006, NEUROLOGY, V67, P1189, DOI 10.1212/01.wnl.0000238164.90657.c2
   Wang ZR, 2017, NEURAL REGEN RES, V12, P1823, DOI 10.4103/1673-5374.219043
   Wei WXJ, 2019, IEEE T NEUR SYS REH, V27, P51, DOI 10.1109/TNSRE.2018.2882235
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   WILSON DJ, 1984, AM J OCCUP THER, V38, P159, DOI 10.5014/ajot.38.3.159
   Wolf SL, 2005, NEUROREHAB NEURAL RE, V19, P194, DOI 10.1177/1545968305276663
NR 44
TC 25
Z9 25
U1 2
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 453
EP 464
DI 10.1007/s10055-021-00583-6
EA SEP 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000701654300001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Cha, HS
   Im, CH
AF Cha, Ho-Seung
   Im, Chang-Hwan
TI Performance enhancement of facial electromyogram-based facial-expression
   recognition for social virtual reality applications using linear
   discriminant analysis adaptation
SO VIRTUAL REALITY
LA English
DT Article
DE Facial-expression recognition; Facial electromyogram; Riemannian
   manifolds; Social virtual reality; Linear discriminant analysis
   adaptation
ID OF-THE-ART; MYOELECTRIC CONTROL; SIGNALS; STATE; ROBUST; SHIFT
AB Recent studies have indicated that facial electromyogram (fEMG)-based facial-expression recognition (FER) systems are promising alternatives to the conventional camera-based FER systems for virtual reality (VR) environments because they are economical, do not depend on the ambient lighting, and can be readily incorporated into existing VR headsets. In our previous study, we applied a Riemannian manifold-based feature extraction approach to fEMG signals recorded around the eyes and demonstrated that 11 facial expressions could be classified with a high accuracy of 85.01%, with only a single training session. However, the performance of the conventional fEMG-based FER system was not high enough to be applied in practical scenarios. In this study, we developed a new method for improving the FER performance by employing linear discriminant analysis (LDA) adaptation with labeled datasets of other users. Our results indicated that the mean classification accuracy could be increased to 89.40% by using the LDA adaptation method (p < .001, Wilcoxon signed-rank test). Additionally, we demonstrated the potential of a user-independent FER system that could classify 11 facial expressions with a classification accuracy of 82.02% without any training sessions. To the best of our knowledge, this was the first study in which the LDA adaptation approach was employed in a cross-subject manner. It is expected that the proposed LDA adaptation approach would be used as an important method to increase the usability of fEMG-based FER systems for social VR applications.
C1 [Cha, Ho-Seung; Im, Chang-Hwan] Hanyang Univ, Dept Biomed Engn, 222 Wangsimni Ro, Seoul 133791, South Korea.
C3 Hanyang University
RP Im, CH (corresponding author), Hanyang Univ, Dept Biomed Engn, 222 Wangsimni Ro, Seoul 133791, South Korea.
EM hoseungcha@gmail.com; ich@hanyang.ac.kr
RI Im, Chang-Hwan/ABB-4391-2021
OI Cha, Ho-Seung/0000-0002-9492-2318; Im, Chang-Hwan/0000-0003-3795-3318
FU Samsung Science & Technology Foundation [SRFC-TB1703-05]
FX This work was supported by the Samsung Science & Technology Foundation
   [SRFC-TB1703-05, facial electromyogram-based facial-expression
   recognition for interactive VR applications].
CR Agrawal S., 2015, INT J ADV ELECT COMP, V2, P61
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Barachant A, 2013, NEUROCOMPUTING, V112, P172, DOI 10.1016/j.neucom.2012.12.039
   Barachant A, 2010, LECT NOTES COMPUT SC, V6365, P629, DOI 10.1007/978-3-642-15995-4_78
   Buettner R., 2020, 2020 IEEE Symp Ind Electron Appl ISIEA 2020, P1, DOI [10.1109/ISIEA49364.2020.9188211, DOI 10.1109/ISIEA49364.2020.9188211]
   Burgos-Artizzu Xavier P, 2015, Kobe, Japan) 15). SIGGRAPH Asia 2015 Technical Briefs, P1, DOI [DOI 10.1145/2820903.2820910, 10.1145/2820903.2820910]
   Cha HS, 2020, IEEE ACCESS, V8, P62065, DOI 10.1109/ACCESS.2020.2983608
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen YM, 2015, NEUROCOMPUTING, V168, P871, DOI 10.1016/j.neucom.2015.05.037
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ekman P., 2005, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS), VSecond, DOI DOI 10.1093/ACPROF:OSO/9780195179644.001.0001
   Fan YJ, 2020, NANOSCALE, V12, P16053, DOI 10.1039/d0nr03189e
   Forstner W, 2003, Geodesy-the Challenge of the 3rd Millennium, P299, DOI [10.1007/978-3-662-05296-9_31, DOI 10.1007/978-3-662-05296-9_31]
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Geethanjali P, 2016, MED DEVICES-EVID RES, V9, P247, DOI 10.2147/MDER.S91102
   Gunkel SNB, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P498, DOI 10.1145/3204949.3208115
   Hakonen M, 2015, BIOMED SIGNAL PROCES, V18, P334, DOI 10.1016/j.bspc.2015.02.009
   Hamedi Mahyar, 2011, Journal of Computer Sciences, V7, P1407, DOI 10.3844/jcssp.2011.1407.1415
   Hamedi M, 2018, IEEE T AFFECT COMPUT, V9, P102, DOI 10.1109/TAFFC.2016.2569098
   Hamedi M, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-73
   Hornbaek K, 2020, EMOTIONAL AVATARS IN
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Kersting M, 2021, INT J SCI EDUC PART, V11, P17, DOI 10.1080/21548455.2020.1857458
   Khushaba RN, 2014, IEEE T NEUR SYS REH, V22, P745, DOI 10.1109/TNSRE.2014.2304470
   Kim KT, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P788, DOI 10.1109/ACPR.2017.52
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Matsubara T, 2013, IEEE T BIO-MED ENG, V60, P2205, DOI 10.1109/TBME.2013.2250502
   Mavridou I, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P152, DOI 10.1145/3131277.3134366
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   Morerio P., 2017, ARXIV170508180
   MORRISON DG, 1969, J MARKETING RES, V6, P156, DOI 10.2307/3149666
   Muceli S, 2014, IEEE T NEUR SYS REH, V22, P623, DOI 10.1109/TNSRE.2013.2282898
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Oskoei MA, 2007, BIOMED SIGNAL PROCES, V2, P275, DOI 10.1016/j.bspc.2007.07.009
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Patel AN, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00221
   Patel JK, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P1341, DOI 10.1109/ICISC.2018.8399026
   Phinyomark A., 2018, Big Data Cognitive Computing, V2, DOI DOI 10.3390/BDCC2030021
   Qiu Xia Li, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P344, DOI 10.1109/ICMLC.2016.7860925
   Rezazadeh IM, 2011, AUTOMAT CONSTR, V20, P289, DOI 10.1016/j.autcon.2010.10.005
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Sato W, 2007, COGNITION, V104, P1, DOI 10.1016/j.cognition.2006.05.001
   Sbordone, 2020, CEUR WORKSHOP PROC, V2730, P1
   Shanxiao Yang, 2011, Journal of Software, V6, P1529, DOI 10.4304/jsw.6.8.1529-1536
   Thies J., 2016, ARXIV161003151
   Vidovic MMC, 2016, IEEE T NEUR SYS REH, V24, P961, DOI 10.1109/TNSRE.2015.2492619
   Vidovic MMC, 2014, IEEE ENG MED BIO, P4370, DOI 10.1109/EMBC.2014.6944592
   Wakeford N, 2002, SOCIOL RES ONLINE, V7
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wedel M, 2020, INT J RES MARK, V37, P443, DOI 10.1016/j.ijresmar.2020.04.004
   Xiong AB, 2015, IEEE INT C INT ROBOT, P4185, DOI 10.1109/IROS.2015.7353969
   Young AJ, 2012, IEEE T BIO-MED ENG, V59, P645, DOI 10.1109/TBME.2011.2177662
   Zhang HS, 2013, IEEE ENG MED BIO, P4267, DOI 10.1109/EMBC.2013.6610488
   Zhang LG, 2014, NEUROCOMPUTING, V145, P451, DOI 10.1016/j.neucom.2014.05.008
   Zhang T., 2017, ADV INTELLIGENT SYST, P345
NR 58
TC 18
Z9 18
U1 0
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 385
EP 398
DI 10.1007/s10055-021-00575-6
EA SEP 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000692304800002
PM 34493922
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Iqbal, J
   Sidhu, MS
AF Iqbal, Javid
   Sidhu, Manjit Singh
TI Acceptance of dance training system based on augmented reality and
   technology acceptance model (TAM)
SO VIRTUAL REALITY
LA English
DT Article
DE Kinect V2; User acceptance; Dance learning; Augmented reality;
   Interactive system
ID SELF-EFFICACY; RECOGNITION; KINECT; GESTURES
AB The advancement in Computer Vision (CV) has evolved drastically from image processing to object recognition, tracking video, restoration of images, three-dimensional (3D) pose recognition, and emotion analysis. These advancements have eventually led to the birth of Augmented Reality (AR) technology, which means embedding virtual objects into the real-world environment. The primary focus of this research was to solve the long-term learning retention and poor learning efficiency for mastering a dance skill through the AR technology based on constructivism learning theory, Dreyfus model and Technology Acceptance Model (TAM). The problem analysis carried out in this research had major research findings, in which the retention and learning efficiency of a dance training system were predominantly determined through the type of learning theory adopted, learning environment, training tools, skill acquisition technology and type of AR technique. Therefore, the influential factors for the user acceptance of AR-based dance training system (ARDTS) were based on quantitative analysis. These influential factors were determined to address the problem of knowledge gap on acceptance of AR-based systems for dance education through self-learning. The evaluation and testing were conducted to validate the developed and implemented ARDTS system. The Technology Acceptance Model (TAM) as the evaluation model and quantitative analysis was done with a research instrument that encompassed external and internal variables. TAM consisted of 37 items, in which six factors were used to assess the new developed ARDTS by the authors and its acceptability among 86 subjects. The current study had investigated the potential use of AR-based dance training system to promote a particular dance skill among a sample population with various backgrounds and interests. The obtained results support a general acceptance towards ARDTS among the users who are interested in exploring the cutting-edge technology of AR for gaining expertise in a dance skill.
C1 [Iqbal, Javid] UCSI Univ, Inst Comp Sci & Digital Innovat ICSDI, Kuala Lumpur, Malaysia.
   [Sidhu, Manjit Singh] Univ Tenaga Nas, Dept Informat, Coll Comp & Informat CCI, Kajang, Malaysia.
C3 UCSI University; Universiti Tenaga Nasional
RP Iqbal, J (corresponding author), UCSI Univ, Inst Comp Sci & Digital Innovat ICSDI, Kuala Lumpur, Malaysia.
EM javid@ucsiuniversity.edu.my
RI Sidhu, Manjit/GLV-2433-2022; Iqbal, Javid/AAA-3368-2020
OI Sidhu, Manjit/0000-0003-2144-8712; Iqbal, Javid/0000-0002-9503-5446
CR Abiddin WZWZ, 2016, 2016 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P216, DOI 10.1109/ISCAIE.2016.7575066
   Alabbasi H, 2015, E-HEALTH BIOENG CONF
   Alharbi S, 2014, INT J ADV COMPUT SC, V5, P143
   Ambudkar B, 2013, IEEE CONF TECHNOL ED, P123, DOI 10.1109/T4E.2013.37
   Amin Dhiraj, 2015, International Journal on Computational Science & Applications, V5, P11, DOI DOI 10.5121/IJCSA.2015.5102
   Anbarsanti N, 2016, J TEKNOL, V78, P73
   Anderson F., 2013, YOUMOVE ENHANCING MO, DOI 10.1145/2501988.2502045
   Anjos Isabelle de Vasconcellos Corrêa dos, 2018, Rev. paul. pediatr., V36, P337
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Banerjee Arijit, 2014, 2014 15th International Symposium on Quality Electronic Design (ISQED), P1, DOI 10.1109/ISQED.2014.6783299
   Baptista F., 2016, 2016 23 PORT M COMP, P1, DOI [10.1109/EPCGI.2016.7851195, DOI 10.1109/EPCGI.2016.7851195]
   Belbachir, 2012, IEEE COMP SOC C COMP, DOI 10.1109/CVPRW.2012.6238894
   Bloom B., 1956, Taxonomy of educational objectives: the classification of educational goals, handbook 1, cognitive domain
   Boukir S, 2004, PATTERN ANAL APPL, V7, P308, DOI 10.1007/s10044-004-0228-z
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   Choensawat Worawat, 2013, Design, User Experience, and Usability. Health, Learning, Playing, Cultural, and Cross-Cultural User Experience.Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8013, P171, DOI 10.1007/978-3-642-39241-2_20
   Cisneros RE, 2019, RES DANC EDUC, V20, P54, DOI 10.1080/14647893.2019.1566305
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dias JR, 2019, INT J TECHNOL HUM IN, V15, P11, DOI 10.4018/IJTHI.2019040102
   Dreyfus H. L., 1980, A five-stage model of mental activities involved in directed skill acquisition
   Eichner M, 2012, IEEE T PATTERN ANAL, V34, P2282, DOI 10.1109/TPAMI.2012.85
   Fan RK, 2012, IEEE T VIS COMPUT GR, V18, P501, DOI 10.1109/TVCG.2011.73
   Ghidoni S, 2017, ROBOT AUTON SYST, V90, P45, DOI 10.1016/j.robot.2016.10.006
   Guo TC, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P675, DOI 10.1109/CISP.2013.6745251
   Guyon I, 2014, MACH VISION APPL, V25, P1929, DOI 10.1007/s00138-014-0596-3
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Harel, 1991, EPISTEMELOGY LEARNIN, P1985
   Hartson R., 2019, UX BOOK, P227
   Hassan E., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P41, DOI 10.1109/NCVPRIPG.2011.16
   Hergenhahn B.R., 1993, An introduction to theories of learning, V4th
   Heryadi Y, 2013, INT C ADV COMP SCI I, P419, DOI 10.1109/ICACSIS.2013.6761612
   Ho C, 2013, INT CONF ACOUST SPEE, P2429, DOI 10.1109/ICASSP.2013.6638091
   Ibañez R, 2017, PATTERN RECOGN, V62, P73, DOI 10.1016/j.patcog.2016.08.022
   Igbaria M, 1995, OMEGA-INT J MANAGE S, V23, P587, DOI 10.1016/0305-0483(95)00035-6
   Ioan CA, 2012, PROC INT C TOOLS ART, P719, DOI 10.1109/ICTAI.2012.102
   Jeffrey DA., 2015, THESIS ANDREWS U MIC
   Kari T, 2014, P 35 INT C INF SYST, P1
   Kim D, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061261
   Kitsikidis A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P789
   Konar A, 2018, STUD COMPUT INTELL, V724, P65, DOI 10.1007/978-3-319-62212-5_3
   KRAIGER K, 1993, J APPL PSYCHOL, V78, P311, DOI 10.1037/0021-9010.78.2.311
   Kuang HL, 2018, INT CONF MEAS, P187, DOI 10.1109/ICMTMA.2018.00052
   Kuramoto I, 2013, 2013 SECOND IIAI INTERNATIONAL CONFERENCE ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2013), P365, DOI 10.1109/IIAI-AAI.2013.28
   Lee Y., 2003, Communications of the Association for Information Systems, V12, P752, DOI [DOI 10.17705/1CAIS.01250, 10.17705/1CAIS.01250]
   Li JH, 2016, DIGIT HEALTH, V2, DOI 10.1177/2055207616654578
   Majumdar R, 2012, 2012 IEEE FOURTH INTERNATIONAL CONFERENCE ON TECHNOLOGY FOR EDUCATION (T4E), P241, DOI 10.1109/T4E.2012.53
   PREMKUMAR G, 1995, DATA BASE ADV INF SY, V26, P105
   Ramadijanti N, 2016, 2016 INTERNATIONAL CONFERENCE ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (KCIC), P194, DOI 10.1109/KCIC.2016.7883646
   Ren RD, 2012, IEEE T MULTIMEDIA, V14, P1652, DOI 10.1109/TMM.2012.2199971
   Rogers E. M., 1983, Diffusions of innovations, DOI DOI 10.1007/978-3-642-79868-9_2
   ROMANO JG, 2019, SENSORS-BASEL
   Saha S, 2016, IEEE IJCNN, P1754, DOI 10.1109/IJCNN.2016.7727411
   Saha S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, ENERGY & COMMUNICATION (CIEC), P708, DOI 10.1109/CIEC.2014.6959182
   Saha S, 2013, 2013 FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS (CICSYN), P3, DOI 10.1109/CICSYN.2013.11
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Saraydem R, 2016, KINECT SENSOR TABAN, P2
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Shirazi A., 2015, Adv. Eng. Educ, V4, P1
   Skinner, 1974, CAUSES BEHAV BEHAV, P1023
   Teja KVR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Torres R, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON SYSTEMS ENGINEERING (ISSE) PROCEEDINGS, P202, DOI 10.1109/SysEng.2015.7302757
   TRAJKOVA M, 2016, UBICOMPISWC ACM
   Venkatesh P, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1864, DOI 10.1109/ICACCI.2016.7732321
   Vermun K, 2013, IEEE CONF TECHNOL ED, P107, DOI 10.1109/T4E.2013.34
   Wulf G, 2010, MED EDUC, V44, P75, DOI 10.1111/j.1365-2923.2009.03421.x
   Yang Y, 2012, IEEE T LEARN TECHNOL, V5, P191, DOI 10.1109/TLT.2011.31
   Yazaki Y, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P200, DOI 10.1109/CW.2015.26
   Zhu GM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020161
   2010, HDB AUGMENTED REALIT, P1
NR 69
TC 23
Z9 24
U1 8
U2 49
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 33
EP 54
DI 10.1007/s10055-021-00529-y
EA MAY 2021
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000652466500001
DA 2024-07-18
ER

PT J
AU Widyanti, A
   Hafizhah, HN
AF Widyanti, Ari
   Hafizhah, Hana Nadhilah
TI The influence of personality, sound, and content difficulty on virtual
   reality sickness
SO VIRTUAL REALITY
LA English
DT Article
DE VR sickness; Personality; Oculomotor; Disorientation; Level of
   difficulty; Sound
ID MOTION SICKNESS; GAMES; PERCEPTION
AB Virtual reality (VR) sickness is a condition that may occur during or after exposure to a virtual environment and can induce symptoms such as headache and eye strain. VR sickness can be influenced by several factors. One individual factor that might affect VR sickness is personality. Non-individual factors that may influence VR sickness are sound and content difficulty. The aim of this study was to observe the influence of personality, sound, and content difficulties on VR sickness in one specific game. An experiment with a VR game was conducted, involving 60 students representing six different personalities: Honesty-Humility, Emotionality, eXtraversion, Agreeableness, Conscientiousness, and Openness to Experience. Participants were instructed to complete a visual search game with different levels of sound and content difficulty. VR sickness was assessed in each condition using a VR Sickness Questionnaire consisting of two dimensions: oculomotor (consists of general discomfort, fatigue, eye strain, and difficulty in focusing) and disorientation (consists of headache, fullness of head, blurred vision, dizziness with eyes closed, and vertigo). Data were processed using descriptive and separate mixed ANOVA. The results showed that the effect of personality was significant for the VR sickness dimensions oculomotor and disorientation. The Emotionality personality reported the highest oculomotor and disorientation scores. There was no significant difference in oculomotor and disorientation scores based on sound and content difficulty. The implications of the results were discussed.
C1 [Widyanti, Ari; Hafizhah, Hana Nadhilah] Bandung Inst Technol, Dept Ind Engn, Lab Work Syst Design & Ergon, Ganesa 10, Bandung 40132, Indonesia.
C3 Institute Technology of Bandung
RP Widyanti, A (corresponding author), Bandung Inst Technol, Dept Ind Engn, Lab Work Syst Design & Ergon, Ganesa 10, Bandung 40132, Indonesia.
EM widyanti@mail.ti.itb.ac.id
CR [Anonymous], 2017, Personality
   Ashton MC, 2009, J PERS ASSESS, V91, P340, DOI 10.1080/00223890902935878
   Balk S., 2013, SIMULATOR SICKNESS Q, DOI DOI 10.17077/DRIVINGASSESSMENT.1498
   BRISLIN RW, 1970, J CROSS CULT PSYCHOL, V1, P185, DOI 10.1177/135910457000100301
   Chardonnet JR, 2015, INT C ART REAL TEL E
   de Armas C, 2020, MULTIMED TOOLS APPL, V79, P3495, DOI 10.1007/s11042-019-08141-8
   De Gauquier L, 2019, VIRTUAL REAL-LONDON, V23, P235, DOI 10.1007/s10055-018-0344-5
   Delion M, 2020, WORLD NEUROSURG, V134, pE937, DOI 10.1016/j.wneu.2019.11.047
   Dorado JL, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P47, DOI 10.1109/3DUI.2014.6798841
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   Ion A, 2017, J PERS ASSESS, V99, P25, DOI 10.1080/00223891.2016.1187155
   Johnson A, 2011, ERGONOMICS, V54, P509, DOI 10.1080/00140139.2011.570459
   Kang HJ, 2020, J INTERACT MARK, V49, P70, DOI 10.1016/j.intmar.2019.07.002
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Koswara R, 2020, TIMING TIME PERCEPT, V8, P55, DOI 10.1163/22134468-20191168
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LAU KW, 2018, VIRTUAL REAL-LONDON, P1
   LaValle S. M, 2017, VIRTUAL REAL-LONDON
   Lewis GN, 2011, DISABIL REHABIL-ASSI, V6, P453, DOI 10.3109/17483107.2011.574310
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI DOI 10.1145/2671015.2671120
   Mumtaz S, 2001, COMPUT EDUC, V36, P347, DOI 10.1016/S0360-1315(01)00023-9
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nichols S., 2000, P HUMAN FACTORS ERGO, V1, P538, DOI DOI 10.1177/154193120004400514
   Norman KL., 2018, EVALUATION VIRTUAL R
   Nusbaum EC, 2011, PERS INDIV DIFFER, V51, P571, DOI 10.1016/j.paid.2011.05.013
   Onyesolu MO., 2009, WORLD C ENG COMP SCI
   Pietrzak E, 2014, J GERIATR PHYS THER, V37, P166, DOI 10.1519/JPT.0b013e3182abe76e
   Psotka J, 2013, EDUC TECHNOL SOC, V16, P69
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reis AB, 2018, DIGIT JOURNAL, V6, P1090, DOI 10.1080/21670811.2018.1502046
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Stone Lii WB, 2017, THESIS IOWA STATE U
   Thompson ER, 2008, PERS INDIV DIFFER, V45, P542, DOI 10.1016/j.paid.2008.06.013
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   Widyanti A, 2017, J ENG APPL SCI, V12, P3262
   Wiederhold BK, 2014, SER ANXIETY RELAT DI, P1, DOI 10.1007/978-1-4899-8023-6
   WILDING JM, 1972, BRIT J PSYCHOL, V63, P619, DOI 10.1111/j.2044-8295.1972.tb01316.x
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 44
TC 16
Z9 16
U1 3
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 631
EP 637
DI 10.1007/s10055-021-00525-2
EA APR 2021
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000642363700002
DA 2024-07-18
ER

PT J
AU Hornsey, RL
   Hibbard, PB
AF Hornsey, Rebecca L.
   Hibbard, Paul B.
TI Contributions of pictorial and binocular cues to the perception of
   distance in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cue combination; Distance perception; Size constancy
ID PERSPECTIVE; JUDGMENTS
AB We assessed the contribution of binocular disparity and the pictorial cues of linear perspective, texture, and scene clutter to the perception of distance in consumer virtual reality. As additional cues are made available, distance perception is predicted to improve, as measured by a reduction in systematic bias, and an increase in precision. We assessed (1) whether space is nonlinearly distorted; (2) the degree of size constancy across changes in distance; and (3) the weighting of pictorial versus binocular cues in VR. In the first task, participants positioned two spheres so as to divide the egocentric distance to a reference stimulus (presented between 3 and 11 m) into three equal thirds. In the second and third tasks, participants set the size of a sphere, presented at the same distances and at eye-height, to match that of a hand-held football. Each task was performed in four environments varying in the available cues. We measured accuracy by identifying systematic biases in responses and precision as the standard deviation of these responses. While there was no evidence of nonlinear compression of space, participants did tend to underestimate distance linearly, but this bias was reduced with the addition of each cue. The addition of binocular cues, when rich pictorial cues were already available, reduced both the bias and variability of estimates. These results show that linear perspective and binocular cues, in particular, improve the accuracy and precision of distance estimates in virtual reality across a range of distances typical of many indoor environments.
C1 [Hornsey, Rebecca L.; Hibbard, Paul B.] Univ Essex, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Hornsey, RL (corresponding author), Univ Essex, Colchester CO4 3SQ, Essex, England.
EM rlhornsey@outlook.com
OI Hornsey, Rebecca/0000-0001-6888-8155
FU Economic and Social Research Council
FX This study was funded by the Economic and Social Research Council.
CR Banks MS, 2012, SMPTE MOTION IMAG J, V121, P24, DOI 10.5594/j18173
   BARFIELD W, 1995, HUM FACTORS, V37, P173, DOI 10.1518/001872095779049453
   Bingham GP, 2001, J EXP PSYCHOL HUMAN, V27, P1314, DOI 10.1037//0096-1523.27.6.1314
   Bodenheimer B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P35
   Brenner E, 1999, VISION RES, V39, P975, DOI 10.1016/S0042-6989(98)00162-X
   CARLSON VR, 1960, AM J PSYCHOL, V73, P199, DOI 10.2307/1419897
   Creem-Regehr SH, 2005, PERCEPTION, V34, P191, DOI 10.1068/p5144
   Crompton A, 2006, ENVIRON BEHAV, V38, P656, DOI 10.1177/0013916505281571
   Dodgson NA, 2004, PROC SPIE, V5291, P36, DOI 10.1117/12.529999
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Drascic David., 1991, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V35, P1367
   Eggleston RG, 1996, P IEEE VIRT REAL ANN, P139, DOI 10.1109/VRAIS.1996.490521
   Ellis SR, 1998, HUM FACTORS, V40, P415, DOI 10.1518/001872098779591278
   Glennerster A, 2006, CURR BIOL, V16, P428, DOI 10.1016/j.cub.2006.01.019
   HAWKINS DM, 1986, AM STAT, V40, P296, DOI 10.2307/2684608
   Hibbard P., 2017, J VISUAL-JAPAN, V17, P1045, DOI [10.1167/17.10.1045, DOI 10.1167/17.10.1045]
   Hibbard P., 2017, J VIS, V17, P1047, DOI 10.1167/17.10.1047
   Hibbard PB, 2017, PERCEPTION, V46, P1219
   Hornsey R., 2018, J VISUAL-JAPAN, V18, P515, DOI [10.1167/18.10.515, DOI 10.1167/18.10.515]
   Hornsey R, 2019, PERCEPTION, V48, P267
   Hornsey RL, 2020, BEHAV RES METHODS, V52, P1587, DOI 10.3758/s13428-019-01336-9
   Hornsey RL., 2015, 2015 INT C 3D IMAGIN, P1, DOI [10.1109/IC3D.2015.7391812, DOI 10.1109/IC3D.2015.7391812]
   JOHNSTON EB, 1991, VISION RES, V31, P1351, DOI 10.1016/0042-6989(91)90056-B
   KIM WS, 1987, IEEE T SYST MAN CYB, V17, P61, DOI 10.1109/TSMC.1987.289333
   Kline PB, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P1112
   Kopiske KK, 2019, PSYCHOL RES-PSYCH FO, V83, P147, DOI 10.1007/s00426-018-1101-9
   LAMPTON DR, 1995, HUM FAC ERG SOC P, P1268
   Landy M.S., 2011, SENSORY CUE INTEGRAT
   Lappin JS, 2006, PERCEPT PSYCHOPHYS, V68, P571, DOI 10.3758/BF03208759
   Livingston MA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P55, DOI 10.1109/VR.2009.4810999
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Mon-Williams M, 1999, PERCEPTION, V28, P167, DOI 10.1068/p2737
   Mon-Williams M, 2000, ERGONOMICS, V43, P391, DOI 10.1080/001401300184486
   Murgia Alessio, 2009, International Journal of Virtual Reality, V8, P67
   Murray RF, 2010, J VISION, V10, DOI 10.1167/10.11.15
   O'Hare L, 2013, I-PERCEPTION, V4, P156, DOI 10.1068/i0566
   Proffitt DennisR., 2003, Handbook of psychology, P213
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   RIESER JJ, 1990, PERCEPTION, V19, P675, DOI 10.1068/p190675
   Roumes C, 2001, INT J AVIAT PSYCHOL, V11, P381, DOI 10.1207/S15327108IJAP1104_4
   Scarfe P, 2006, VISION RES, V46, P1599, DOI 10.1016/j.visres.2005.11.002
   Scarfe P, 2011, J VISION, V11, DOI 10.1167/11.7.12
   Sedgwick HA, 1986, SPACE PERCEPTION SEN
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Sinai MJ, 1999, HUM FAC ERG SOC P, P1256
   Singh Gurjot., 2010, Proceedings of the 7th Symposium on Applied Perception in Graphics and Visualization, P149, DOI DOI 10.1145/1836248.1836277
   Surdick RT, 1997, PRESENCE-TELEOP VIRT, V6, P513, DOI 10.1162/pres.1997.6.5.513
   Thomas G, 2002, HUM FACTORS, V44, P157, DOI 10.1518/0018720024494766
   Todd JT, 2010, J VISION, V10, DOI 10.1167/10.2.20
   WICKENS CD, 1990, P SOC PHOTO-OPT INS, V1256, P2, DOI 10.1117/12.19883
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   Wu B, 2004, NATURE, V428, P73, DOI 10.1038/nature02350
NR 52
TC 12
Z9 12
U1 1
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1087
EP 1103
DI 10.1007/s10055-021-00500-x
EA MAR 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000633276600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Campo-Prieto, P
   Cancela, JM
   Rodríguez-Fuentes, G
AF Campo-Prieto, Pablo
   Cancela, Jose Maria
   Rodriguez-Fuentes, Gustavo
TI Immersive virtual reality as physical therapy in older adults: present
   or future (systematic review)
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Virtual reality immersion therapy; Virtual reality
   exposure therapy; Aged; Exercise therapy; Rehabilitation
ID AUGMENTED-REALITY; BALANCE; REHABILITATION; STROKE; TECHNOLOGY; GAIT;
   FEASIBILITY; PAIN; PERFORMANCE; POSTSTROKE
AB Increased life expectancy leads to an increase in the number of older adults and in the prevalence of aging-associated diseases and disabilities. Active aging strategies-particularly those based on physical exercise therapy- have great positive impact on older people's health. Virtual reality (VR) represents an innovative approach to involve and motivate patients during therapy sessions. Exergaming programs based on VR technologies and commercially available gaming platforms are amenable to therapeutic use in older adults, according to various systematic reviews and meta-analyses. The use of immersive virtual reality (IVR) in the field of rehabilitation or physical skills training in seniors is understudied.In the present systematic review, we analyze the therapeutic use and application of IVR in older adults through physical activity. We describe the populations studied, the conditions of IVR application (device, session, physical, and virtual environments), its potential benefits, and its limitations. We found that most studies are feasibility pilot experiences, where the use and acceptability of the immersive platform were evaluated. Cumulative data suggest that the use of IVR with therapeutic intent in senior populations is in early stages of clinical development and shows promise as a complementary tool in the fields of health, rehabilitation, and active aging.
C1 [Campo-Prieto, Pablo; Rodriguez-Fuentes, Gustavo] Univ Vigo, Galicia Sur Hlth Res Inst IISGS, HealthyFit Res Grp GHI22, Fac Physiotherapy, Vigo, Spain.
   [Cancela, Jose Maria] Univ Vigo, Galicia Sur Hlth Res Inst IISGS, HealthyFit Res Grp GHI22, Dept Special Didact, Vigo, Spain.
   [Campo-Prieto, Pablo; Rodriguez-Fuentes, Gustavo] Univ Vigo, Galicia Sur Hlth Res Inst IISGS, HealthyFit Res Grp GHI22, Dept Funct Biol & Hlth Sci, Vigo, Spain.
   [Campo-Prieto, Pablo] Fac Physiotherapy, Campus A Xunqueira S-N, Pontevedra 36005, Spain.
C3 Universidade de Vigo; Universidade de Vigo; Universidade de Vigo
RP Campo-Prieto, P (corresponding author), Univ Vigo, Galicia Sur Hlth Res Inst IISGS, HealthyFit Res Grp GHI22, Fac Physiotherapy, Vigo, Spain.; Campo-Prieto, P (corresponding author), Univ Vigo, Galicia Sur Hlth Res Inst IISGS, HealthyFit Res Grp GHI22, Dept Funct Biol & Hlth Sci, Vigo, Spain.; Campo-Prieto, P (corresponding author), Fac Physiotherapy, Campus A Xunqueira S-N, Pontevedra 36005, Spain.
EM pcampo@uvigo.es
RI Rodríguez-Fuentes, Gustavo/O-3192-2016; Campo-Prieto, Pablo/W-3176-2018;
   Cancela Carral, Jose M/P-4603-2015
OI Rodríguez-Fuentes, Gustavo/0000-0003-2720-1497; Campo-Prieto,
   Pablo/0000-0003-1706-5639; Cancela Carral, Jose M/0000-0003-2903-3829; ,
   IIS Galicia Sur/0000-0003-3812-7413
CR Alhasan H, 2017, CLIN INTERV AGING, V12, P487, DOI 10.2147/CIA.S127023
   [Anonymous], 2002, ACT AG POL FRAM WORK
   Anson E, 2018, GAIT POSTURE, V62, P342, DOI 10.1016/j.gaitpost.2018.03.044
   Bahat HS, 2018, EUR SPINE J, V27, P1309, DOI 10.1007/s00586-017-5323-0
   Bank PJM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1100-9
   Benham S, 2019, OTJR-OCCUP PART HEAL, V39, P90, DOI 10.1177/1539449218817291
   Bergmann J, 2018, EUR J PHYS REHAB MED, V54, P397, DOI 10.23736/S1973-9087.17.04735-9
   Bherer Louis, 2013, J Aging Res, V2013, P197326, DOI [10.1155/2013/657508, 10.1155/2013/197326]
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Cacciata M, 2019, INT J NURS STUD, V93, P30, DOI 10.1016/j.ijnurstu.2019.01.010
   Cannell J, 2018, CLIN REHABIL, V32, P191, DOI 10.1177/0269215517720790
   Celnik P, 2006, NEUROIMAGE, V29, P677, DOI 10.1016/j.neuroimage.2005.07.039
   Colomer C, 2013, NEUROLOGIA, V28, P261, DOI 10.1016/j.nrl.2012.04.017
   Corno G, 2014, STUD HEALTH TECHNOL, V199, P168, DOI 10.3233/978-1-61499-401-5-168
   Crocetta TB, 2018, VIRTUAL REAL-LONDON, V22, P199, DOI 10.1007/s10055-017-0323-2
   Crossley C, 2016, IEEE INT CONF SERIOU
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davison SMC, 2018, ACTA NEUROPSYCHIATR, V30, P79, DOI 10.1017/neu.2017.14
   De Oliveira JA., 2017, Manual Ther Posturol Rehabil J, V15, P1, DOI [10.17784/mtprehabjournal2017.15.481, DOI 10.17784/MTPREHABJOURNAL2017.15.481]
   Díaz-Pérez E, 2018, REV NEUROLOGIA, V66, P344, DOI 10.33588/rn.6610.2017438
   Duque G, 2013, CLIN INTERV AGING, V8, P257, DOI 10.2147/CIA.S41453
   Dvorkin AY, 2012, NEUROREHAB NEURAL RE, V26, P120, DOI 10.1177/1545968311410068
   Espay AJ, 2010, J REHABIL RES DEV, V47, P573, DOI 10.1682/JRRD.2009.10.0165
   Fernandez-Ballesteros R., 2005, Rev. Esp. Geriatr. Gerontol, V40, P92, DOI [10.1016/S0211-139X(05)74834-4, DOI 10.1016/S0211-139X(05)74834-4]
   Fordell H, 2016, TOP STROKE REHABIL, V23, P191, DOI 10.1080/10749357.2016.1138670
   Franceschini M, 2012, NEUROREHAB NEURAL RE, V26, P456, DOI 10.1177/1545968311427406
   Fraser LE, 2018, CAN J NEUROL SCI, V45, P405, DOI 10.1017/cjn.2017.297
   Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5
   Garçon L, 2016, GERONTOLOGIST, V56, pS293, DOI 10.1093/geront/gnw005
   Glennon C, 2018, ONCOL NURS FORUM, V45, P545, DOI 10.1188/18.ONF.545-552
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hesse K, 2017, J BEHAV THER EXP PSY, V56, P129, DOI 10.1016/j.jbtep.2016.11.006
   Howes S, 2017, PHYSIOTHERAPY, V103, DOI [10.1016/j.physio.2017.11.155, DOI 10.1016/j.physio.2017.11.155]
   Pérez-Sanpablo AI, 2014, REV INVEST CLIN, V66, pS39
   Jannink MJA, 2009, INT J REHABIL RES, V32, P280, DOI 10.1097/MRR.0b013e3283013b1c
   Jonsdottir J, 2018, MULT SCLER RELAT DIS, V19, P25, DOI 10.1016/j.msard.2017.10.010
   Kalron A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0124-y
   Kennedy R.S., 1965, NSAM-918. Research Report, P1
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1997, PRESENCE-TELEOP VIRT, V6, P638, DOI 10.1162/pres.1997.6.6.638
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0225-2
   Kinne BL, 2015, PHYS OCCUP THER GERI, V33, P363, DOI 10.3109/02703181.2015.1100697
   Kizony R, 2010, PHYS THER, V90, P252, DOI 10.2522/ptj.20090061
   Kwon JS, 2012, NEUROREHABILITATION, V31, P379, DOI 10.3233/NRE-2012-00807
   Laufer Y, 2014, CLIN INTERV AGING, V9, P1803, DOI 10.2147/CIA.S69673
   Lee Y, 2017, J AGING PHYS ACTIV, V25, P621, DOI 10.1123/japa.2015-0271
   McEwen D, 2014, J REHABIL RES DEV, V51, P1069, DOI 10.1682/JRRD.2013.10.0231
   Menendez M. M. C., 2011, TEXTOS CONTEXTOS, V10, P179
   Fernández MDM, 2017, COMPUT HUM BEHAV, V66, P329, DOI 10.1016/j.chb.2016.10.001
   Meyerbroeker K, 2013, PSYCHOTHER PSYCHOSOM, V82, P170, DOI 10.1159/000342715
   Micarelli A, 2019, ARCH GERONTOL GERIAT, V83, P246, DOI 10.1016/j.archger.2019.05.008
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Mitzner TL, 2010, COMPUT HUM BEHAV, V26, P1710, DOI 10.1016/j.chb.2010.06.020
   Moher D, 2009, PHYS THER, V89, P873, DOI 10.1093/ptj/89.9.873
   Morone G, 2016, EXPERT REV MED DEVIC, V13, P785, DOI 10.1080/17434440.2016.1218275
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Murray CD, 2007, DISABIL REHABIL, V29, P1465, DOI 10.1080/09638280601107385
   Oddo-Sommerfeld S, 2018, NEUROPSYCHOLOGIA, V108, P135, DOI 10.1016/j.neuropsychologia.2017.11.025
   Pargaonkar Aishwarya, 2019, Research into Design for a Connected World. Proceedings of ICoRD 2019. Smart Innovation, Systems and Technologies (SIST 135), P723, DOI 10.1007/978-981-13-5977-4_61
   Pedroli E, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072343
   Peek K, 2016, PHYSIOTHERAPY, V102, P127, DOI 10.1016/j.physio.2015.10.003
   Perrier-Melo RJ, 2014, CONSCIENTIAE SAUDE, V13, P289, DOI DOI 10.5585/ConsSaude.v13n2.4551
   Peruzzi A, 2017, DISABIL REHABIL, V39, P1557, DOI 10.1080/09638288.2016.1224935
   Bezerra IMP, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000009612
   Pot-Kolder R, 2018, CYBERPSYCH BEH SOC N, V21, P187, DOI 10.1089/cyber.2017.0082
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Roberts AR, 2019, CLIN GERONTOLOGIST, V42, P27, DOI 10.1080/07317115.2018.1442380
   Robles-García V, 2013, PARKINSONISM RELAT D, V19, P1123, DOI 10.1016/j.parkreldis.2013.08.005
   Rodrigues EV, 2014, TOP GERIATR REHABIL, V30, P238, DOI 10.1097/TGR.0000000000000040
   Soccini AM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1165, DOI [10.1109/VR.2019.8798193, 10.1109/vr.2019.8798193]
   Trombetta M, 2017, COMPUT METH PROG BIO, V151, P15, DOI 10.1016/j.cmpb.2017.08.008
   Van Kerckhoven G, 2014, J LARYNGOL OTOL, V128, P1005, DOI 10.1017/S0022215114002254
   Warland A, 2019, DISABIL REHABIL, V41, P2119, DOI 10.1080/09638288.2018.1459881
   World Health Organization, 2018, Ageing and health
   Xiao X, 2017, BEHAV NEUROL, V2017, DOI 10.1155/2017/6261479
   Yasuda Kazuhiro, 2018, BMJ Case Rep, V2018, DOI 10.1136/bcr-2017-222860
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Zunzunegui MV, 2010, GAC SANIT, V24, P68, DOI 10.1016/j.gaceta.2010.08.004
NR 81
TC 33
Z9 33
U1 12
U2 98
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 801
EP 817
DI 10.1007/s10055-020-00495-x
EA JAN 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000604533200003
DA 2024-07-18
ER

PT J
AU Houzangbe, S
   Christmann, O
   Gorisse, G
   Richir, S
AF Houzangbe, Samory
   Christmann, Olivier
   Gorisse, Geoffrey
   Richir, Simon
TI Effects of voluntary heart rate control on user engagement and agency in
   a virtual reality game
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Biofeedback; User engagement; Agency; User study
ID FEEDBACK-ASSISTED REDUCTION; SELF-EFFICACY; SINUS ARRHYTHMIA;
   BIOFEEDBACK; ENVIRONMENTS; REACTIVITY
AB It has been demonstrated that virtual reality (VR) exposure can affect the subjective experience of different situations, cognitive capabilities or behavior. It is known that there is a link between a person's physiological state and their psychological self-report and user experience. As an immersive experience can affect users' physiological data, it is possible to adapt and enhance the content of a virtual environment in real-time base on physiological data feedback (biofeedback). With the rapid evolution of the physiological monitoring technologies, it is now possible to exploit different modalities of biofeedback, in a cheap and non-cumbersome manner, and study how they can affect user experience. While most of the studies involving physiological data use it as a measuring tool, we want to study its impact when direct and voluntary physiological control becomes a mean of interaction. To do so, we created a two-parts protocol. The first part was designed to categorize the participants on their heart rate control competency. In the second part of the study, we immersed our participants in a VR experience where they must control their heart rate to interact with the elements in the game. The results were analyzed based on the competency distribution. We observed consistent results between our competency scale and the participants' control of the biofeedback game mechanic. We also found that our direct biofeedback mechanic is highly engaging. We observed that it generated a strong feeling of agency, which is linked with users' level of heart rate control. We highlighted the richness of biofeedback as a direct game mechanic, prompting interesting perspective for personalized immersive experiences.
C1 [Houzangbe, Samory; Christmann, Olivier; Gorisse, Geoffrey; Richir, Simon] HESAM Univ, Arts & Metiers Inst Technol, LAMPA, F-53810 Change, France.
C3 heSam Universite
RP Houzangbe, S (corresponding author), HESAM Univ, Arts & Metiers Inst Technol, LAMPA, F-53810 Change, France.
EM samory.houzangbe@ensam.eu; olivier.christmann@ensam.eu;
   geoffrey.gorisse@ensam.eu; simon.richir@ensam.eu
RI Houzangbe, Samory/ITU-8515-2023
OI Houzangbe, Samory/0000-0002-2913-0517; Richir,
   Simon/0000-0003-2075-6609; Gorisse, Geoffrey/0000-0003-1613-927X;
   Christmann, Olivier/0000-0001-8652-5630
FU EON Reality SAS
FX We would like to thank all the participants of our experiment and the
   staff of our laboratories that helped us and took the time and resources
   to push this work to completion. We extend our thanks to EON Reality
   SAS, that financed this Ph.D. thesis work and their teams for their time
   and counsel.
CR Ambinder M, 2011, GAM DEV C
   [Anonymous], 1975, BOREDOM ANXIETY EXPE
   [Anonymous], 1962, STAT PRINCIPLES EXPT
   Argasiski JK, 2018, WORKSH AFFECT CONT A
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   BANDURA A, 1993, EDUC PSYCHOL, V28, P117, DOI 10.1207/s15326985ep2802_3
   BANDURA A, 1982, AM PSYCHOL, V37, P122, DOI 10.1037/0003-066X.37.2.122
   Bandura A., 1997, SELF EFFICACY EXERCI, P1
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Bouchard S, 2019, APPL VIRT REAL CLIN, P1, DOI DOI 10.1007/978-1-4939-9482-3_1
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Bouchard S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036169
   CLYNES M, 1960, J APPL PHYSIOL, V15, P863, DOI 10.1152/jappl.1960.15.5.863
   DAVIES CTM, 1967, J APPL PHYSIOL, V22, P947, DOI 10.1152/jappl.1967.22.5.947
   Dekker A., 2007, DIGRA C
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   Dieleman GC, 2010, PSYCHONEUROENDOCRINO, V35, P1223, DOI 10.1016/j.psyneuen.2010.02.012
   Flowers A, 2018, THESIS
   Gaskin J, 2017, P 50 HAW INT C SYST
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Groenegress C, 2010, VISUAL COMPUT, V26, P649, DOI 10.1007/s00371-010-0471-9
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   HOLMES DS, 1979, PSYCHOPHYSIOLOGY, V16, P432, DOI 10.1111/j.1469-8986.1979.tb01498.x
   Houzangbe S., 2018, P 13 INT C FOUND DIG, P1
   Houzangbe S, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234305
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Ketcheson Mallory., 2015, P 2015 ANN S COMPUTE, P79, DOI [10.1145/ 2793107.2793122, DOI 10.1145/2793107.2793122, https://doi.org/10.1145/2793107.2793122]
   LARKIN KT, 1989, PSYCHOL REC, V39, P365, DOI 10.1007/BF03395888
   LARKIN KT, 1990, BIOFEEDBACK SELF-REG, V15, P285, DOI 10.1007/BF01000024
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   MALCUIT G, 1980, BIOL PSYCHOL, V10, P201, DOI 10.1016/0301-0511(80)90015-0
   MANUCK SB, 1975, PERCEPT MOTOR SKILL, V40, P747, DOI 10.2466/pms.1975.40.3.747
   MCCANNE TR, 1983, BIOFEEDBACK SELF-REG, V8, P9, DOI 10.1007/BF01000533
   Munoz J.E., 2016, e-Health Networking, Applications and Services (Healthcom), 2016 IEEE 18th International Conference on, P1, DOI DOI 10.1109/HEALTHCOM.2016.7749512
   Muris P, 2001, J PSYCHOPATHOL BEHAV, V23, P145, DOI 10.1023/A:1010961119608
   Nacke LE, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P103
   Nenonen V, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P853
   Nogueira PA, 2016, J MULTIMODAL USER IN, V10, P31, DOI 10.1007/s12193-015-0208-1
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   O'Brien HL, 2010, J AM SOC INF SCI TEC, V61, P50, DOI 10.1002/asi.21229
   Obrist PA., 2017, CARDIOVASCULAR PSYCH
   Peira N, 2014, INT J PSYCHOPHYSIOL, V91, P225, DOI 10.1016/j.ijpsycho.2013.12.008
   Phan MH, 2016, HUM FACTORS, V58, P1217, DOI 10.1177/0018720816669646
   Prpa M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P71, DOI 10.1145/3196709.3196765
   Riedl R., 2014, JAIS, V15, P4
   Salminen M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P73, DOI 10.1145/3172944.3172991
   Sarkar A., 2014, IEEE INT JOINT C BIO, P1, DOI DOI 10.1109/BTAS.2014.6996264
   Silva G.A., 2014, P 2014 9 IBERIAN C I, DOI [10.1109/CISTI.2014.6877078, DOI 10.1109/CISTI.2014.6877078]
   Sra M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173914
   SROUFE LA, 1971, PSYCHOPHYSIOLOGY, V8, P648, DOI 10.1111/j.1469-8986.1971.tb00500.x
   STEPHENS JH, 1975, PSYCHOPHYSIOLOGY, V12, P381, DOI 10.1111/j.1469-8986.1975.tb00006.x
   Wang R, 2017, JAMA CARDIOL, V2, P104, DOI 10.1001/jamacardio.2016.3340
   Weerdmeester J, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P453, DOI 10.1145/31308593131299
   WESTCOTT MR, 1961, J EXP PSYCHOL, V61, P353, DOI 10.1037/h0041742
   Wiebe EN, 2014, COMPUT HUM BEHAV, V32, P123, DOI 10.1016/j.chb.2013.12.001
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wollmann T, 2016, IEEE ACCESS, V4, P5531, DOI 10.1109/ACCESS.2016.2601882
   Yoshimasa Ohmoto, 2017, EFFECT VISUAL FEEDBA, P315
NR 60
TC 13
Z9 13
U1 1
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 665
EP 681
DI 10.1007/s10055-020-00429-7
EA MAR 2020
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000560963700001
DA 2024-07-18
ER

PT J
AU Reski, N
   Alissandrakis, A
AF Reski, Nico
   Alissandrakis, Aris
TI Open data exploration in virtual reality: a comparative study of input
   technology
SO VIRTUAL REALITY
LA English
DT Article
DE Comparative study; Gamepad; Room-scale virtual reality; Virtual reality;
   Vision-based motion controls; 3D gestural input
ID SIMULATOR SICKNESS; IMMERSION
AB In this article, we compare three different input technologies (gamepad, vision-based motion controls, room-scale) for an interactive virtual reality (VR) environment. The overall system is able to visualize (open) data from multiple online sources in a unified interface, enabling the user to browse and explore displayed information in an immersive VR setting. We conducted a user interaction study (n=24per input technology, between-group design) to investigate experienced workload and perceived flow of interaction. Log files and observations allowed further insights and comparison of each condition. We have identified trends that indicate user preference of a visual (virtual) representation, but no clear trends regarding the application of physical controllers (over vision-based controls), in a scenario that encouraged exploration with no time limitations.
C1 [Reski, Nico; Alissandrakis, Aris] Linnaeus Univ, Dept Comp Sci & Media Technol, VRxAR Labs, Vaxjo, Sweden.
C3 Linnaeus University
RP Reski, N (corresponding author), Linnaeus Univ, Dept Comp Sci & Media Technol, VRxAR Labs, Vaxjo, Sweden.
EM nico.reski@lnu.se
RI Alissandrakis, Aris/F-2265-2015
OI Alissandrakis, Aris/0000-0003-4162-6475
FU Swedish Knowledge Foundation (KK-stiftelsen) project Real-Time 3D
   Gesture Analysis for Natural Interaction with Smart Devices [2016/0174]
FX This work was partially supported by the Swedish Knowledge Foundation
   (KK-stiftelsen) project Real-Time 3D Gesture Analysis for Natural
   Interaction with Smart Devices (2016/0174).
CR Abrash M, 2014, STEAM DEV DAYS JAN 1
   [Anonymous], 2003, DIAGNOSTIK SELBSTKON
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Bayyari A., 2006, P ACM S VIRTUAL REAL, P368, DOI DOI 10.1145/1180495.1180570
   Betella A, 2014, P 2014 VIRTUAL REALI, V2014, P1
   Biernacki MP, 2016, MED PR, V67, P545, DOI 10.13075/mp.5893.00512
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Bouchard S., 2011, Journal of Computer and Information Technology, V1, P20
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Bowman DA, 2008, IEEE COMPUT GRAPH, V28, P20, DOI 10.1109/MCG.2008.109
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Caggianese Giuseppe, 2019, Intelligent Interactive Multimedia Systems and Services. Proceedings of 2018 Conference. Smart Innovation, Systems and Technologies (SIST 98), P24, DOI 10.1007/978-3-319-92231-7_3
   Cai MJ, 2013, I C SERV SYST SERV M, P113, DOI 10.1109/ICSSSM.2013.6602650
   Cardoso JCS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P319, DOI 10.1145/2993369.2996327
   Carmack J, 2013, COMMUNICATION   1013
   Csikszentmihalyi M., 1988, OPTIMAL EXPERIENCE P, P15, DOI DOI 10.1017/CBO9780511621956.002
   Csikszentmihalyi M, 2014, FLOW PSYCHOL CREATIV
   Figueiredo L, 2018, COMPUT GRAPH-UK, V77, P108, DOI 10.1016/j.cag.2018.10.006
   Gusai E, 2017, LECT NOTES COMPUT SC, V10590, P290, DOI 10.1007/978-3-319-70742-6_27
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Janssen M, 2012, INFORM SYST MANAGE, V29, P258, DOI 10.1080/10580530.2012.716740
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Konrad R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1211, DOI 10.1145/2858036.2858140
   Kovarova Alena, 2014, P 15 INT C COMP SYST, P317, DOI DOI 10.1145/2659532.2659608
   Lackey SJ, 2016, ERGONOMICS, V59, P1060, DOI 10.1080/00140139.2015.1122234
   Lanman D., 2014, ACM SIGGRAPH 2014 CO
   LaValle S.M., 2016, Virtual Reality
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lepouras G, 2018, VIRTUAL REAL-LONDON, V22, P63, DOI 10.1007/s10055-017-0312-5
   McMahan R.P., 2006, Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P108, DOI DOI 10.1145/1180495.1180518
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P327, DOI 10.1145/2993369.2996348
   Murillo RAM, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P759, DOI 10.1145/3126594.3126605
   NASA, 2018, NASA TLX PAP PENC VE
   Olbrich M, 2018, LECT NOTES COMPUT SC, V10909, P438, DOI 10.1007/978-3-319-91581-4_33
   Parkin S, 2013, COMPUTER NEWS   0912
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reski Nico, 2016, 9 INT C ADV COMP HUM, P403
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Streppel B, 2018, LECT NOTES COMPUT SC, V10909, P183, DOI 10.1007/978-3-319-91581-4_14
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tcha-Tokey K., 2017, ACM International Conference Proceeding Series, Part, VF1311, P1, DOI [DOI 10.1145/3121283.3121284, 10.1145/3121283.3121284]
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Ward M., 2015, Interactive data visualization: Foundations, techniques, and applications
   Wegner K, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P323, DOI 10.1145/3130859.3131300
   Wirth M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P867, DOI 10.1145/3242587.3242636
   Wolf K, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P457, DOI 10.1145/3152832.3156625
   Young M. K., 2014, P ACM S APPL PERCEPT, P83
NR 50
TC 21
Z9 20
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 1
EP 22
DI 10.1007/s10055-019-00378-w
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bhama, PRKS
   Hariharasubramanian, V
   Mythili, OP
   Ramachandran, M
AF Sathia Bhama, Ponsy R. K.
   Hariharasubramanian, Vigneshwaran
   Mythili, O. P.
   Ramachandran, Murugesh
TI Users' domain knowledge prediction in e-learning with speech-interfaced
   augmented and virtual reality contents
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Virtual reality; Neural network; Wavelet
   transformation; Fuzzy cognitive maps; Signal processing
ID FUZZY-LOGIC
AB E-learning provides an individualized course path which provides a user the convenience of pacing ones way through a particular course. One of the key privileges it offers is the flexibility of the course and consistent delivery of the material. The proposed system predicts the user's domain knowledge with the help of the lectures knowledge that a particular user completes and also a lecture's knowledge gets updated with respect to the users' knowledge who searches for it. The dependency among the domains also plays a vital role in updating ones' domain knowledge. The dependencies can be determined by constructing a fuzzy cognitive map. This helps in determining the user's knowledge in other domains also. The lectures of the proposed system include Augmented Reality and Virtual Reality contents which give an interactive learning experience to the users. The user commands are accepted as audio signals, processed, classified and mapped to the system commands to make it to respond. This proposed work uses the combination of discrete wavelet transform and wavelet packet decomposition for feature extraction and artificial neural network for classification.
C1 [Sathia Bhama, Ponsy R. K.; Hariharasubramanian, Vigneshwaran; Mythili, O. P.; Ramachandran, Murugesh] Anna Univ, MIT, Chennai, Tamilnadu, India.
C3 Anna University; Madras Institute of Technology; Anna University Chennai
RP Bhama, PRKS (corresponding author), Anna Univ, MIT, Chennai, Tamilnadu, India.
EM ponsy@annauniv.edu
CR [Anonymous], 2014, PROC FRONT EDUC CONF
   Asano F, 2004, EURASIP J APPL SIG P, V2004, P1727, DOI 10.1155/S1110865704402303
   Chrysafiadi K, 2015, IEEE T FUZZY SYST, V23, P164, DOI 10.1109/TFUZZ.2014.2310242
   Creane S, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTERACTIVE MOBILE COMMUNICATION TECHNOLOGIES AND LEARNING (IMCL), P393, DOI 10.1109/IMCTL.2015.7359628
   Fan YD, 2005, ICMB 2005: INTERNATIONAL CONFERENCE ON MOBILE BUSINESS, P445
   Georgopoulos V, 2015, SPRINGER BERLIN HEID, V164, P391, DOI [10.1007/3-540-32365-1_17, DOI 10.1007/3-540-32365-1_17]
   Ghatasheh N, 2015, INT J ADV COMPUT SC, V6, P107
   Gray S. A., 2013, FUZZY COGNITIVE MAPS, P29
   Gray SA, 2013, P ANN HICSS, P965, DOI 10.1109/HICSS.2013.399
   Hagen A, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P186, DOI 10.1109/ASRU.2003.1318426
   Lee Chul Min, 2004, INT C SPOK LANG PROC
   Lee SH, 2009, IEEE T CONSUM ELECTR, V55, P883, DOI 10.1109/TCE.2009.5174470
   Lee S, 2013, IEEE ICCE, P360, DOI 10.1109/ICCE.2013.6486929
   Li J, 2014, PROCEDIA COMPUT SCI, V31, P875, DOI 10.1016/j.procs.2014.05.339
   Ranjan R, 2015, IEEE-ACM T AUDIO SPE, V23, P1988, DOI 10.1109/TASLP.2015.2460459
   Ravichandran M, 2015, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATIONS TECHNOLOGIES (ICCCT 15), P7, DOI 10.1109/ICCCT2.2015.7292711
   Sharma N, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2353, DOI 10.1109/ICACCI.2016.7732406
   Stylios CD, 1997, IEEE MED C CONTR SYS, V34, P409
   Sutton S, 2000, INT C SPOK LANG PROC
   Taylor S, 2016, INTERSPEECH, P1482, DOI 10.21437/Interspeech.2016-483
   Thanda A, 2016, 4 INT WORKSH MULT PA
NR 21
TC 1
Z9 2
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 163
EP 173
DI 10.1007/s10055-017-0321-4
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800011
DA 2024-07-18
ER

PT J
AU Pai, YS
   Dingler, T
   Kunze, K
AF Pai, Yun Suen
   Dingler, Tilman
   Kunze, Kai
TI Assessing hands-free interactions for VR using eye gaze and
   electromyography
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Physiological sensing; Eye gaze; Electromyography
ID TRACKING; INPUT
AB With the increasing popularity of virtual reality (VR) technologies, more efforts have been going into developing new input methods. While physical controllers are widely used, more novel techniques, such as eye tracking, are now commercially available. In our work, we investigate the use of physiological signals as input to enhance VR experiences. We present a system using gaze tracking and electromyography on a user's forearm to make selection tasks in virtual spaces more efficient. In a study with 16 participants, we compared five different input techniques using a Fitts' law task: Using gaze tracking for cursor movement in combination with forearm contractions for making selections was superior to using an HTC Vive controller, Xbox gamepad, dwelling time, and eye-gaze dwelling time. To explore application scenarios and collect qualitative feedback, we further developed and evaluated a game with our input technique. Our findings inform the design of applications that use eye-gaze tracking and forearm muscle movements for effective user input in VR.
C1 [Pai, Yun Suen; Kunze, Kai] Keio Univ, Grad Sch Media Design, Yokohama, Kanagawa, Japan.
   [Dingler, Tilman] Univ Melbourne, Melbourne, Vic, Australia.
C3 Keio University; University of Melbourne
RP Pai, YS (corresponding author), Keio Univ, Grad Sch Media Design, Yokohama, Kanagawa, Japan.
EM yspai1412@gmail.com
RI Dingler, Tilman/AAU-4851-2021
OI Pai, Yun Suen/0000-0002-6090-2837; Dingler, Tilman/0000-0001-6180-7033
FU JSPS KAKENHI [18H03278]; Grants-in-Aid for Scientific Research
   [18H03278] Funding Source: KAKEN
FX This work was supported by the JSPS KAKENHI Grant Number 18H03278.
CR [Anonymous], 1998, 9241111998 ISO, P22
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/2470654.2466112
   [Anonymous], 1986, P SIGCHI GI C HUM FA, DOI DOI 10.1145/29933.275627
   Arieta A. H., 2006, Applied Bionics and Biomechanics, V3, P101, DOI 10.1533/abbi.2005.0060
   BARRY DT, 1990, MUSCLE NERVE, V13, P286, DOI 10.1002/mus.880130403
   Benko Hrvoje, 2009, P ACM INT C INTERACT, P93, DOI [DOI 10.1145/1731903.17319242,3, 10.1145/1731903.1731924, DOI 10.1145/1731903.1731924]
   Cardoso JCS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P319, DOI 10.1145/2993369.2996327
   Chatterjee I, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P131, DOI 10.1145/2818346.2820752
   Chin CA, 2008, J REHABIL RES DEV, V45, P161, DOI 10.1682/JRRD.2007.03.0050
   Cloudhead G, 2015, VR NAV
   Costanza Enrico., 2005, P SIGCHI C HUMAN FAC, P481, DOI [DOI 10.1145/1054972.1055039, 10.1145/1054972.1055039]
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Henze N., 2011, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, MobileHCI '11, P133
   Hernandez-Rebollar J.L., 2002, SIGGRAPH, P259
   Jacob R. J. K., 1990, SIGCHI Bulletin, P11
   Jacobsen SephenC., 1974, ACM 74 P 1974 ANN CO, P149
   Kiguchi K, 2004, IEEE T FUZZY SYST, V12, P481, DOI 10.1109/TFUZZ.2004.832525
   Kim K, 2017, IEEE I CONF COMP VIS, P20, DOI 10.1109/ICCV.2017.12
   Lee JS, 2005, INT GEOSCI REMOTE SE, P284
   MacKenzie IS, 2002, HUM-COMPUT INTERACT, V17, P147, DOI 10.1207/S15327051HCI172&3_2
   Miniotas D., 2000, CHI 00 EXTENDED ABST, P339
   MOSELEY JB, 1992, AM J SPORT MED, V20, P128, DOI 10.1177/036354659202000206
   Myo, 2013, MYO GEST CONTR ARMB
   Oculus, 2015, RIFTS REC SPEC PC SD
   Pai Yun Suen, 2016, ACM SIGGRAPH 2016 posters, P1
   Ramcharitar A, 2017, P 2016 CHI C HUM FAC, P2860, DOI [10.1145/3027063.3053213, DOI 10.1145/3027063.3053213.HTTP://D0I.ACM.0RG/10.1145/3027063.3053213]
   Saponas TS, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Saraiji Y, 2016, PUPILHMDCALIBRATION
   Saraiji Y, 2016, ACM SIGGRAPH 2016, P20
   Slambekova Dana., 2012, P 18 ACM S VIRTUAL R, P203, DOI DOI 10.1145/2407336.2407380
   Unity, 2015, US INT VR
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Wilson AD, 2005, LECT NOTES COMPUT SC, V3585, P565, DOI 10.1007/11555261_46
   Zander TO, 2011, INT J HUM-COMPUT INT, V27, P38, DOI 10.1080/10447318.2011.535752
   Zhang XA, 2007, LECT NOTES COMPUT SC, V4552, P779
NR 35
TC 49
Z9 52
U1 5
U2 51
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 119
EP 131
DI 10.1007/s10055-018-0371-2
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500001
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI WHY AUGMENTED AND VIRTUAL REALITIES MATTER
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR [Anonymous], 2010, SEGA VR
   [Anonymous], 2016, WALDERN VIRTUALITY
   [Anonymous], 2015, MARS IMM NASA CONC B
   [Anonymous], 2018, PATENTLY APPLE  0804
   [Anonymous], HIST VIRT REAL DID I
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   HEILIG M, EXPERIENCE THEATER P
   Heilig Morton, INVENTOR FIELD VIRTU
   IKEA, 2017, IKEA LAUNCH IKEA PLA
   Livingston Mark A., MILITARY APPL AUGMEN
   Selin Shannon, PANORAMAS 19 CENTURY
   Sutherland I., ULTIMATE DISPLAY
   Weinbaum Stanley Grauman, PYGMALIONS SPECTACLE
   Wilson Cole, 2017, WIRED           1121
NR 14
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 1
EP +
PG 38
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200003
DA 2024-07-18
ER

PT J
AU Loyola, M
AF Loyola, Mauricio
TI The influence of the availability of visual cues on the accurate
   perception of spatial dimensions in architectural virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Architectural virtual environments; Head-mounted displays; Distance
   perception
ID EGOCENTRIC DISTANCE PERCEPTION; HEAD-MOUNTED DISPLAYS; VIEWING
   CONDITIONS; SIZE; REAL; GRAPHICS; QUALITY; COLOR
AB Several authors have observed that spatial dimensions tend to be underestimated in virtual environments. In this study, we hypothesize that the availability of visual cues in virtual environments has an influence on the accuracy of perception. An experiment was conducted to compare spatial perception in real and virtual environments that were modeled differently and visualized using a head-mounted display. Results suggest that the greater the availability of visual cues, the greater the level of accuracy in the estimates, especially for egocentric dimensions (p < 0.001). In the end, this study contributes to a better understanding of how architectural virtual environments should be modeled for use in professional or commercial applications where accurate and reliable simulations are required.
C1 [Loyola, Mauricio] Princeton Univ, Princeton, NJ 08544 USA.
C3 Princeton University
RP Loyola, M (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.
EM mloyola@princeton.edu
RI Loyola, Mauricio/I-1962-2013
OI Loyola, Mauricio/0000-0003-3643-9528
CR Andrus S.M., 2014, Proceedings of the ACM Symposium on Applied Perception, P130
   [Anonymous], 2005, ACM Transactions on Applied Perception, DOI [DOI 10.1145/1077399.1077403, DOI 10.1145/1077399.10774032,3,9]
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   BEALL AC, 1995, P SOC PHOTO-OPT INS, V2411, P288, DOI 10.1117/12.207547
   Bruder G., 2012, P ACM S APPL PERC SA, P111
   Bruder G, 2016, PRESENCE-TELEOP VIRT, V25, P1, DOI 10.1162/PRES_a_00241
   Bruder G, 2015, P IEEE VIRT REAL ANN, P27, DOI 10.1109/VR.2015.7223320
   Cidota MA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P172, DOI [10.1109/ISMAR-Adjunct.2016.61, 10.1109/ISMAR-Adjunct.2016.0070]
   Creem-Regehr SH, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P47, DOI 10.1145/2804408.2804422
   Creem-Regehr SH, 2005, PERCEPTION, V34, P191, DOI 10.1068/p5144
   Cutting JamesE., 1995, Perceiving layout and knowing distance: The integration, relative potency and contextual use of different information about depth
   Gabling T, 1970, SCAND J PSYCHOL, V11, P133
   Howard IP, 2012, PERCEIVING IN DEPTH, V5, P187
   Imamoglu V., 1973, Architectural psychology, P314
   Interrante V, 2008, PRESENCE-TELEOP VIRT, V17, P176, DOI 10.1162/pres.17.2.176
   Jones J.A., 2011, Proc. Symposium on Applied perception in Graphics and Visualization, P29
   KAYE SM, 1982, HUM FACTORS, V24, P609, DOI 10.1177/001872088202400511
   Kellner F, 2012, IEEE T VIS COMPUT GR, V18, P589, DOI 10.1109/TVCG.2012.45
   Kenyon RV, 2007, PRESENCE-TELEOP VIRT, V16, P172, DOI 10.1162/pres.16.2.172
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Kuhl S.A., 2006, J VISION, V6, P726
   KUNNAPAS T, 1968, J EXP PSYCHOL, V77, P523, DOI 10.1037/h0026050
   Kunz BR, 2009, ATTEN PERCEPT PSYCHO, V71, P1284, DOI 10.3758/APP.71.6.1284
   Langbehn E, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P241, DOI 10.1145/2993369.2993379
   Lappin JS, 2006, PERCEPT PSYCHOPHYS, V68, P571, DOI 10.3758/BF03208759
   Lin CJ, 2015, DISPLAYS, V36, P41, DOI 10.1016/j.displa.2014.11.006
   Loomis Jack M, 2008, CARN S COGN 2006 PIT
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   LURIA SM, 1967, PERCEPT MOTOR SKILL, V24, P1007, DOI 10.2466/pms.1967.24.3.1007
   Marsh William E., 2014, Spatial Cognition IX. International Conference, Spatial Cognition 2014. Proceedings: LNCS 8684, P354, DOI 10.1007/978-3-319-11215-2_25
   Murgia Alessio, 2009, International Journal of Virtual Reality, V8, P67
   Ng Adrian K. T., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P173, DOI 10.1007/978-3-319-39907-2_17
   Oberfeld D, 2010, Q J EXP PSYCHOL, V63, P1999, DOI 10.1080/17470211003646161
   Philbeck JW, 1997, J EXP PSYCHOL HUMAN, V23, P72, DOI 10.1037/0096-1523.23.1.72
   Piryankova IV, 2013, DISPLAYS, V34, P153, DOI 10.1016/j.displa.2013.01.001
   Proffitt D, 2002, HDB PSYCHOL, V4
   Renner R.S., 2013, Proceedings of the ACM Symposium on Applied Perception, P130
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   RIESER JJ, 1990, PERCEPTION, V19, P675, DOI 10.1068/p190675
   Robinett W., 1992, Presence: Teleoper. Virtual Environ, V1, P45, DOI DOI 10.1162/pres.1992.1.1.45
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Serpa A, 1996, LANDSCAPE URBAN PLAN, V36, P19, DOI 10.1016/S0169-2046(96)00330-1
   Sinai MJ, 1998, NATURE, V395, P497, DOI 10.1038/26747
   Sinisgalli R, 2012, PERSPECTIVE IN THE VISUAL CULTURE OF CLASSICAL ANTIQUITY, P1, DOI 10.1017/CBO9781139198905
   Stamps AE, 2011, ENVIRON BEHAV, V43, P252, DOI 10.1177/0013916509354696
   Steinicke F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019631
   Surdick RT, 1997, PRESENCE-TELEOP VIRT, V6, P513, DOI 10.1162/pres.1997.6.5.513
   Tai N.-C., 2012, J. Light Vis. Environ, V36, P16, DOI DOI 10.2150/JLVE.36.16
   Thomas G, 2002, HUM FACTORS, V44, P157, DOI 10.1518/0018720024494766
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   von Castell C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113267
   Willemsen P, 2002, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2002.996536
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
   Witt JK, 2007, PERCEPTION, V36, P1752, DOI 10.1068/p5617
   Xun Luo, 2009, International Journal of Virtual Reality, V8, P43
   Young M. K., 2014, P ACM S APPL PERCEPT, P83
NR 57
TC 27
Z9 32
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 235
EP 243
DI 10.1007/s10055-017-0331-2
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900005
DA 2024-07-18
ER

PT J
AU Shim, J
   Yang, Y
   Kang, N
   Seo, J
   Han, TD
AF Shim, Jinwook
   Yang, Yoonsik
   Kang, Nahyung
   Seo, Jonghoon
   Han, Tack-Don
TI Gesture-based interactive augmented reality content authoring system
   using HMD
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive augmented reality; Augmented reality authoring; Gesture
   interaction; Tangible interaction
AB This paper proposes an augmented reality content authoring system that enables ordinary users who do not have programming capabilities to easily apply interactive features to virtual objects on a marker via gestures. The purpose of this system is to simplify augmented reality (AR) technology usage for ordinary users, especially parents and preschool children who are unfamiliar with AR technology. The system provides an immersive AR environment with a head-mounted display and recognizes users' gestures via an RGB-D camera. Users can freely create the AR content that they will be using without any special programming ability simply by connecting virtual objects stored in a database to the system. Following recognition of the marker via the system's RGB-D camera worn by the user, he/she can apply various interactive features to the marker-based AR content using simple gestures. Interactive features applied to AR content can enlarge, shrink, rotate, and transfer virtual objects with hand gestures. In addition to this gesture-interactive feature, the proposed system also allows for tangible interaction using markers. The AR content that the user edits is stored in a database, and is retrieved whenever the markers are recognized. The results of comparative experiments conducted indicate that the proposed system is easier to use and has a higher interaction satisfaction level than AR environments such as fixed-monitor and touch-based interaction on mobile screens.
C1 [Shim, Jinwook; Yang, Yoonsik; Kang, Nahyung; Han, Tack-Don] Yonsei Univ, Dept Comp Sci, 50 Yonsei Ro, Seoul 03722, South Korea.
   [Seo, Jonghoon] LG Elect Adv Res Inst, Software Platform R&D Lab, 19,Yangjae Daero 11gil, Seoul 06772, South Korea.
C3 Yonsei University; LG Electronics
RP Han, TD (corresponding author), Yonsei Univ, Dept Comp Sci, 50 Yonsei Ro, Seoul 03722, South Korea.
EM jin99foryou@msl.yonsei.ac.kr; yoonsikyang@msl.yonsei.ac.kr;
   nahyung.kang@msl.yonsei.ac.kr; hantack55@gmail.com
FU National Research Foundation of Korea (NRF) - Korea government (MEST)
   [NRF-2015R1A2A1A10055673]
FX This work was supported by a National Research Foundation of Korea (NRF)
   Grant (No. NRF-2015R1A2A1A10055673) funded by the Korea government
   (MEST).
CR AndAR, 2014, ANDAR ANDR AUGM REAL
   [Anonymous], P 17 ANN ACM S US IN
   [Anonymous], APCHI 12
   Azuma R., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P197, DOI 10.1145/192161.192199
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BAJURA M, 1995, IEEE COMPUT GRAPH, V15, P52, DOI 10.1109/38.403828
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Billinghurst M., 2008, P 7 INT C MOBILE UBI, P84, DOI DOI 10.1145/1543137.1543153
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Bunnun P, 2013, VIRTUAL REAL-LONDON, V17, P137, DOI 10.1007/s10055-011-0206-x
   Coquillart S, 2004, EUR S VIRT ENV, P1
   Doliotis P, 2012, LECT NOTES COMPUT SC, V7431, P148, DOI 10.1007/978-3-642-33179-4_15
   Dorfmüller-Ulhaas K, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P55, DOI 10.1109/ISAR.2001.970515
   Grimm P., 2002, First IEEE International Augmented Reality Toolkit Workshop. Proceedings (Cat. No.02EX632), DOI 10.1109/ART.2002.1107008
   Hackenberg G, 2011, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2011.5759431
   Harviainen T., 2009, P ACE, P307
   HENRYSSON A, 2007, P 7 ACM SIGCHI NZ CH, P9
   Hoff WA, 1996, P SOC PHOTO-OPT INS, V2904, P538, DOI 10.1117/12.256311
   Jinwook Shim, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P47, DOI 10.1109/ICCE.2014.6775902
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kaufmann H, 2003, COMPUT GRAPH-UK, V27, P339, DOI 10.1016/S0097-8493(03)00028-1
   Langlotz T, 2012, PERS UBIQUIT COMPUT, V16, P623, DOI 10.1007/s00779-011-0430-0
   Ledermann F, 2005, P IEEE VIRT REAL ANN, P187
   Lee GA, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P172, DOI 10.1109/ISMAR.2004.34
   Lee T, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P83
   Li D, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P37, DOI 10.1109/ICVRV.2013.14
   Lund A. M., 2001, Usability User Exp. Newsl. STC Usability SIG, V8, P1
   Maier P., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P251, DOI 10.1109/ISMAR.2010.5643592
   Ng LX, 2011, INT J INTERACT DES M, V5, P85, DOI 10.1007/s12008-011-0117-9
   Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Okuma T, 1998, INT C PATT RECOG, P1226, DOI 10.1109/ICPR.1998.711920
   Ong SK, 2011, CIRP ANN-MANUF TECHN, V60, P1, DOI 10.1016/j.cirp.2011.03.001
   Poupyrev I, 2002, COMPUTER, V35, P44, DOI 10.1109/2.989929
   Radu Iulian, 2009, P C INT DES CHILDR C
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Seichter H, 2008, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2008.4637354
   SoftKinetic, 2014, SOFTKINETIC INT IS Y
   State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P439, DOI 10.1145/237170.237283
   Thalmann Daniel., 2012, P 20 ACM INT C MULTI, P785, DOI DOI 10.1145/2393347.2396312
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Wozniewski M, 2011, P ISMAR 2011
   Yuan Yao, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P705, DOI 10.1109/ICME.2012.48
NR 47
TC 14
Z9 16
U1 2
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2016
VL 20
IS 1
BP 57
EP 69
DI 10.1007/s10055-016-0282-z
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1FY
UT WOS:000376092000005
DA 2024-07-18
ER

PT J
AU Tarng, W
   Ou, KL
   Yu, CS
   Liou, FL
   Liou, HH
AF Tarng, Wernhuar
   Ou, Kuo-Liang
   Yu, Chuan-Sheng
   Liou, Fong-Lu
   Liou, Hsin-Hun
TI Development of a virtual butterfly ecological system based on augmented
   reality and mobile learning technologies
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Mobile learning; Context awareness; Butterfly ecology
AB A campus butterfly garden is a useful teaching resource for studying insect ecology because students can learn about a butterfly's life cycle and become familiar with its habitual behavior by breeding and observation activities. However, it requires professional construction and maintenance for sustainable development, so very few schools can afford to own a butterfly garden. In this study, the augmented reality and mobile learning technologies have been used to develop a virtual butterfly ecological system by combining with campus host plants and virtual breeding activities. Students can use smart phones or tablet PCs to breed virtual butterflies on host plants and observe their life cycles at different growing stages. Using the available space in campus, a virtual butterfly garden can also be created as a greenhouse where students are able to observe different species of butterflies using the tracking telescope and catch a butterfly to obtain its information by touch-screen control. The virtual butterfly ecological system can increase the learning motivation and interest of students through virtual breeding and observation activities, so it is a suitable assistant tool for science education. A teaching experiment has been conducted to investigate students' learning effectiveness and attitudes after using the system, and the results show that using the virtual butterfly ecological system can improve their learning effectively.
C1 [Tarng, Wernhuar; Ou, Kuo-Liang; Liou, Fong-Lu] Natl Hsinchu Univ Educ, Grad Inst E Learning, Hsinchu, Taiwan.
   [Yu, Chuan-Sheng] Natl Hsinchu Univ Educ, Grad Inst Comp Sci, Hsinchu, Taiwan.
   [Liou, Hsin-Hun] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
C3 National Tsing Hua University; National Tsing Hua University; National
   Central University
RP Tarng, W (corresponding author), Natl Hsinchu Univ Educ, Grad Inst E Learning, Hsinchu, Taiwan.
EM wtarng@nhcue.edu.tw; klou@nhcue.edu.tw; sheng1012@gmail.com;
   dliou@hotmail.com; viviliu0501@gmail.com
RI Ou, Kuo-Liang/F-9105-2011; Tarng, Wernhuar/KCX-9561-2024
OI Ou, Kuo-Liang/0000-0003-4745-9751; Tarng, Wernhuar/0000-0002-6657-5566
FU National Science Council (NSC), Taiwan, ROC [NSC 100-2511-S-134-003]
FX The authors would like to thank for the financial support of the
   National Science Council (NSC), Taiwan, ROC, under the contract number
   NSC 100-2511-S-134-003.
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Brown J., 1989, Educational Researcher, V18, P32, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032, DOI 10.2307/1176008]
   Campbell T, 2010, J SCI EDUC TECHNOL, V19, P505, DOI 10.1007/s10956-010-9217-8
   Chen WS, 1988, BUTTERFLIES TAIWAN
   Chen YC, 2011, J PROF ISS ENG ED PR, V137, P267, DOI 10.1061/(ASCE)EI.1943-5541.0000078
   Chen YS, 2004, 2ND IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, P11
   Chen YS, 2003, J COMPUT ASSIST LEAR, V19, P347, DOI 10.1046/j.0266-4909.2003.00036.x
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Harris, 2006, GO IN MOBILE
   Hsu TY, 2010, J GEOGR, V109, P141, DOI 10.1080/00221341.2010.480941
   Huang TY, 2010, TECHNICAL REPORT
   Johnson L.F., 2010, Education Digest, V76, P36
   Klopfer Eric, 2010, New Dir Youth Dev, V2010, P85, DOI 10.1002/yd.378
   Lee CY, 1986, OBSERVATION BREEDING
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lin Y-S, 2008, THESIS NATL U TAINAN
   Liu TC, 2003, J COMPUT ASSIST LEAR, V19, P371, DOI 10.1046/j.0266-4909.2003.00038.x
   Martin S, 2011, COMPUT EDUC, V57, P1893, DOI 10.1016/j.compedu.2011.04.003
   Ministry of Education, 2006, GEN GUID GRAD 1 9 SC
   Mistler-Jackson M, 2000, J RES SCI TEACH, V37, P459, DOI 10.1002/(SICI)1098-2736(200005)37:5<459::AID-TEA5>3.3.CO;2-3
   SCHILIT WN, 1995, THESIS COLUMBIA U
   Schiller J., 2004, Location-Based Services
   Shih J.L., 2010, INT J MOBILE LEARNIN, V4, P253, DOI DOI 10.1504/IJMLO.2010.033554
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
NR 27
TC 62
Z9 64
U1 4
U2 127
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 253
EP 266
DI 10.1007/s10055-015-0265-5
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800009
DA 2024-07-18
ER

PT J
AU Qu, C
   Brinkman, WP
   Ling, Y
   Wiggers, P
   Heynderickx, I
AF Qu, Chao
   Brinkman, Willem-Paul
   Ling, Yun
   Wiggers, Pascal
   Heynderickx, Ingrid
TI Human perception of a conversational virtual human: an empirical study
   on the effect of emotion and culture
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Virtual human; Emotion; Affective computing; Culture
ID IN-GROUP ADVANTAGE; FACIAL EXPRESSIONS; UNIVERSALS; REALITY; VOICE;
   CATEGORIZATION; COMMUNICATION; RECOGNITION; ANIMATION; JUDGMENTS
AB Virtual reality applications with virtual humans, such as virtual reality exposure therapy, health coaches and negotiation simulators, are developed for different contexts and usually for users from different countries. The emphasis on a virtual human's emotional expression depends on the application; some virtual reality applications need an emotional expression of the virtual human during the speaking phase, some during the listening phase and some during both speaking and listening phases. Although studies have investigated how humans perceive a virtual human's emotion during each phase separately, few studies carried out a parallel comparison between the two phases. This study aims to fill this gap, and on top of that, includes an investigation of the cultural interpretation of the virtual human's emotion, especially with respect to the emotion's valence. The experiment was conducted with both Chinese and non-Chinese participants. These participants were asked to rate the valence of seven different emotional expressions (ranging from negative to neutral to positive during speaking and listening) of a Chinese virtual lady. The results showed that there was a high correlation in valence rating between both groups of participants, which indicated that the valence of the emotional expressions was as easily recognized by people from a different cultural background as the virtual human. In addition, participants tended to perceive the virtual human's expressed valence as more intense in the speaking phase than in the listening phase. The additional vocal emotional expression in the speaking phase is put forward as a likely cause for this phenomenon.
C1 [Qu, Chao; Brinkman, Willem-Paul; Ling, Yun; Wiggers, Pascal; Heynderickx, Ingrid] Delft Univ Technol, NL-2628 CD Delft, Netherlands.
   [Heynderickx, Ingrid] Philips Res Labs, NL-5656 AE Eindhoven, Netherlands.
C3 Delft University of Technology; Philips; Philips Research
RP Qu, C (corresponding author), Delft Univ Technol, Mekelweg 4, NL-2628 CD Delft, Netherlands.
EM aquchaos@gmail.com
RI Brinkman, Willem-Paul/H-8159-2013
OI Brinkman, Willem-Paul/0000-0001-8485-7092
FU Chinese Scholarship Council [2008609199]; COMMIT project-Interaction for
   Universal Access
FX This study is supported in part by the Chinese Scholarship Council (No.
   2008609199) and the COMMIT project-Interaction for Universal Access.
CR [Anonymous], P ACM SIGGRAPH LOS A
   [Anonymous], HUMAN FACE
   [Anonymous], 1962, Affect imagery consciousness: Volume I: The positive affects
   [Anonymous], 2006, Better Game Characters by Design: A Psychological Approach
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Barrett LF, 2006, PERS SOC PSYCHOL REV, V10, P20, DOI 10.1207/s15327957pspr1001_2
   Bartneck C., 2001, C HUMAN FACTORS COMP, P189, DOI [10.1145/634067.634181, DOI 10.1145/634067.634181]
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Bradley MM., 2007, Technical report B-3
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Brinkman W-P, 2012, CHI 12 HUM FACT COMP
   Brinkman WP, 2011, STUD HEALTH TECHNOL, V167, P86, DOI 10.3233/978-1-60750-766-6-86
   Broekens Joost, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P218, DOI 10.1007/978-3-642-33197-8_23
   Broekens Joost, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P435, DOI 10.1007/978-3-642-23974-8_50
   Broekens J., 2010, P 3 INT WORKSH AFF I, P21, DOI 10.1145/1877826.1877833
   Broekens J, 2012, TECHNICAL REPORT, P1
   Broekens J., 2009, Affectbutton: Towards a standard for dynamic affective user feedback. pages, P1
   Broekens J, 2013, INT J HUM-COMPUT ST, V71, P641, DOI 10.1016/j.ijhcs.2013.02.003
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Cassell J., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P413, DOI 10.1145/192161.192272
   Cd Melo, 2011, 10 INT C AUT AG MULT, P2
   Cerezo Eva, 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P329
   CHUANG E., 2002, PERFORMANCE DRIVEN F
   Church AT, 1998, COGNITION EMOTION, V12, P63
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Core M, 2006, SIMUL-T SOC MOD SIM, V82, P685, DOI 10.1177/0037549706075542
   Cowell AJ, 2003, LECT NOTES ARTIF INT, V2792, P301
   Darwin C., 1979, EXPRESS EMOT MAN
   Dotsch R, 2008, J EXP SOC PSYCHOL, V44, P1194, DOI 10.1016/j.jesp.2008.03.003
   EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Elfenbein HA, 2003, CURR DIR PSYCHOL SCI, V12, P159, DOI 10.1111/1467-8721.01252
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P243, DOI 10.1037//0033-2909.128.2.243
   Elfenbein HA, 2007, EMOTION, V7, P131, DOI 10.1037/1528-3542.7.1.131
   Endrass B., 2011, The 10th Intl. Conf. on Autonomous Agents and Multiagent Systems, V2, P441
   Ersotelos N, 2008, VISUAL COMPUT, V24, P13, DOI 10.1007/s00371-007-0175-y
   Ezzat T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P57, DOI 10.1109/AFGR.2004.1301509
   Fox Elaine., 2008, EMOTION SCI COGNITIV
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   Gross MM, 2010, J NONVERBAL BEHAV, V34, P223, DOI 10.1007/s10919-010-0094-x
   Haring M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P204, DOI 10.1109/ROMAN.2011.6005263
   Hofstede G., 1991, Cultures and organizations, DOI DOI 10.1016/S0005-7967(02)00184-5
   Hudlicka E, 2009, AFF COMP INT INT WOR
   Irtel H., 2007, PXLab: The Psychological Experiments Laboratory (Vers. 2.1.11)
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Jan D, 2007, LECT NOTES ARTIF INT, V4722, P45
   Kahler K., 2001, GRAPHICS INTERFACE 2, P37, DOI DOI 10.20380/GI2001.05
   Keltner D., 2000, Handbook of emotions, Vsecond, P236
   Kleinsmith A, 2006, INTERACT COMPUT, V18, P1371, DOI 10.1016/j.intcom.2006.04.003
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Kulms Philipp, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P80, DOI 10.1007/978-3-642-23974-8_9
   Lance BJ, 2008, AAMAS 08 P 7 INT JOI, V1, P12
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Lang PJ, 1999, PSYCHOLOGY
   Lang PJ, 2008, INT AFFECTIVE PICTUR
   Lee Jina, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P161, DOI 10.1007/978-3-642-33197-8_17
   Lee Jina., 2009, Proceedings of the 3rd International Conference on Affective Computing and Intelligent Interaction (ACII'09), P1
   Link MW, 2006, COMPUT HUM BEHAV, V22, P412, DOI 10.1016/j.chb.2004.09.008
   Litwinowicz P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P409, DOI 10.1145/192161.192270
   MacDorman KF, 2010, PRESENCE-TELEOP VIRT, V19, P213, DOI 10.1162/pres.19.3.213
   Matsumoto D, 2002, PSYCHOL BULL, V128, P236, DOI 10.1037//0033-2909.128.2.236
   Matsumoto D, 2007, INT J PSYCHOL, V42, P207, DOI 10.1080/00207590601050926
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   Moridis CN, 2012, IEEE T AFFECT COMPUT, V3, P260, DOI 10.1109/T-AFFC.2012.6
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   OCHSMAN RB, 1974, INT J MAN MACH STUD, V6, P579, DOI 10.1016/S0020-7373(74)80019-2
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Parke F.I., 1974, THESIS U UTAH
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Petrushin V., 1999, Artificial Neural Networks In Engineering (ANNIE), P7
   Picard RosalindW., 1998, Actes Proceedings IMAGINA, P153
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Platt S., 1981, Computer graphics, V15, P245
   Qiu LY, 2005, INT J HUM-COMPUT INT, V19, P370
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Rizzoa AA, 2011, STUD HEALTH TECHNOL, V163, P503, DOI 10.3233/978-1-60750-706-2-503
   RUSSELL JA, 1991, PSYCHOL BULL, V110, P426, DOI 10.1037/0033-2909.110.3.426
   Ruttkay Z, 2005, BROWS TRUST EVALUATI
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schiano D. J., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P193, DOI 10.1145/332040.332430
   Schroder M., 2004, SPEECH EMOTION RES O
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   Tomkins S., 1963, AFFECT IMAGERY CONSC, V2
   TSAPATSOULIS N, 2002, MPEG 4 FACIAL ANIMAT
   Waters K., 1987, COMPUTER GRAPHICS, V22, P17
   Wei-Ern Joshua Wong, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P419, DOI 10.1007/978-3-642-33197-8_43
   Wierzbicka A, 1995, EMOTIONS LANGUAGES C
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
   Yun C., 2009, COMPUT ENTERTAIN, V7, DOI [10.1145/1541895.1541901, DOI 10.1145/1541895.1541901]
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
NR 93
TC 12
Z9 13
U1 2
U2 38
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2013
VL 17
IS 4
BP 307
EP 321
DI 10.1007/s10055-013-0231-z
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 239BT
UT WOS:000325997200005
DA 2024-07-18
ER

PT J
AU Chellali, A
   Milleville-Pennel, I
   Dumas, C
AF Chellali, Amine
   Milleville-Pennel, Isabelle
   Dumas, Cedric
TI Influence of contextual objects on spatial interactions and viewpoints
   sharing in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Spatial communication; Virtual environment; Collaboration; Common frame
   of reference; Visual landmarks
AB Collaborative virtual environments (CVEs) are 3D spaces in which users share virtual objects, communicate, and work together. To collaborate efficiently, users must develop a common representation of their shared virtual space. In this work, we investigated spatial communication in virtual environments. In order to perform an object co-manipulation task, the users must be able to communicate and exchange spatial information, such as object position, in a virtual environment. We conducted an experiment in which we manipulated the contents of the shared virtual space to understand how users verbally construct a common spatial representation of their environment. Forty-four students participated in the experiment to assess the influence of contextual objects on spatial communication and sharing of viewpoints. The participants were asked to perform in dyads an object co-manipulation task. The results show that the presence of a contextual object such as fixed and lateralized visual landmarks in the virtual environment positively influences the way male operators collaborate to perform this task. These results allow us to provide some design recommendations for CVEs for object manipulation tasks.
C1 [Chellali, Amine] Ecole Mines Nantes IRCCYN, Nantes, France.
   [Milleville-Pennel, Isabelle] CNRS IRCCyN, Nantes, France.
   [Dumas, Cedric] Ecole Mines Nantes, Nantes, France.
   [Dumas, Cedric] CSIRO, Brisbane, Qld, Australia.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; Centre National de la
   Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; IMT
   Atlantique; Commonwealth Scientific & Industrial Research Organisation
   (CSIRO)
RP Chellali, A (corresponding author), 1493 Cambridge St, Cambridge, MA 02139 USA.
EM amine.chellali@gmail.com;
   Isabelle.Milleville-Pennel@irccyn.ec-nantes.fr; Cedric.Dumas@csiro.au
RI Chellali, Amine/K-1059-2019
OI Chellali, Amine/0000-0002-6143-5898
FU Inter-Acteurs project [CRE 43230501]; Orange Labs
FX We would like to thank students from Ecole Centrale de Nantes and Nantes
   University who agreed to participate in this experiment. The research
   was partially funded through Inter-Acteurs project (CRE 43230501) in
   collaboration with Orange Labs.
CR [Anonymous], CERVEAU COMPORTEMENT
   [Anonymous], COMPUT SUPPORT COLLA, DOI DOI 10.1007/978-3-642-85098-1
   [Anonymous], 2001, CERVEAU HOMME CERVEA
   [Anonymous], COGNITIVE CONTRIBUTI
   Chellali A, 2008, P 15 EUR C COGN ERG, V369, P83
   Churcher N., 1996, P 8 ANN C SPATIAL IN, P156
   Clark H, 1991, COGNITION PERSPECTIV, V13, P127
   Clark H., USING LANGUAGE
   Dillenbourg P., 1999, Collaborative-learning: Cognitive and computational approaches, P1
   DILLENBOURG P, 1996, LEARNING, V117, P189
   Erickson T., 1993, P C SPAT INF THEOR
   Gaver B, 1992, P ACM C COMP SUPP CO
   GAVER W, 1993, P INTERCHI 93, P335, DOI DOI 10.1145/169059.169268
   Gibson J., 1979, The ecological approach to visual perception
   Harrison Steve R, 1996, P 1996 ACM C COMP SU, V96, P67, DOI [DOI 10.1145/240080.240193, 10.1145/240080.240193]
   Hindmarsh J., 2000, ACM Transactions on Computer-Human Interaction, V7, P477, DOI 10.1145/365058.365088
   HINDMARSH J, 1998, P ACM C COMP SUPP CO, P217, DOI DOI 10.1145/289444.289496
   Hoc JH, 2001, INT J HUM-COMPUT ST, V54, P509, DOI 10.1006/ijhc.2000.0454
   Klingberg T, 2006, NEUROPSYCHOLOGIA, V44, P2171, DOI 10.1016/j.neuropsychologia.2005.11.019
   Koscik T, 2009, BRAIN COGNITION, V69, P451, DOI 10.1016/j.bandc.2008.09.004
   Lawton CA, 2001, SEX ROLES, V44, P321, DOI 10.1023/A:1010981616842
   Park K, 2000, P 4 IMM PROJ TECHN W
   ROBERTS RJ, 1993, CHILD DEV, V64, P1258, DOI 10.2307/1131338
   Spante M, 2004, P 7 INT WORKSH PRES, P190
   STEFIK M, 1987, ACM T INFORM SYST, V5, P147, DOI 10.1145/27636.28056
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
NR 26
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2013
VL 17
IS 1
BP 1
EP 15
DI 10.1007/s10055-012-0214-5
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 089NC
UT WOS:000314916300001
DA 2024-07-18
ER

PT B
AU Pfurtscheller, G
   Leeb, R
   Faller, J
   Neuper, C
AF Pfurtscheller, Gert
   Leeb, Robert
   Faller, Josef
   Neuper, Christa
BE Kim, JJ
TI Brain-Computer Interface Systems used for Virtual Reality Control
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID MENTAL PROSTHESIS; MOTOR IMAGERY; HEART-RATE; COMMUNICATION;
   CLASSIFICATION; PERFORMANCE; ENVIRONMENT; TECHNOLOGY; MOVEMENT; RHYTHMS
C1 [Pfurtscheller, Gert; Faller, Josef; Neuper, Christa] Graz Univ Technol, Inst Knowledge Discovery, Lab Brain Comp Interfaces BCI Lab, A-8010 Graz, Austria.
   [Leeb, Robert] Ecole Polytech Fed Lausanne, Sch Engn, Chair Noninvas Brain Machine Interface, CH-1015 Lausanne, Switzerland.
C3 Graz University of Technology; Swiss Federal Institutes of Technology
   Domain; Ecole Polytechnique Federale de Lausanne
RP Pfurtscheller, G (corresponding author), Graz Univ Technol, Inst Knowledge Discovery, Lab Brain Comp Interfaces BCI Lab, A-8010 Graz, Austria.
RI Faller, Josef/ABG-2374-2020
OI Faller, Josef/0000-0001-7814-9292
CR Allison BZ, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026007
   Allison BZ, 2008, CLIN NEUROPHYSIOL, V119, P399, DOI 10.1016/j.clinph.2007.09.121
   Allison BZ, 2006, INT J PSYCHOPHYSIOL, V59, P127, DOI 10.1016/j.ijpsycho.2005.02.007
   [Anonymous], 2007, INT J BIOELECTROMAGN
   Bayliss JD, 2003, IEEE T NEUR SYS REH, V11, P113, DOI 10.1109/TNSRE.2003.814438
   Bayliss JD, 2000, IEEE T REHABIL ENG, V8, P188, DOI 10.1109/86.847811
   Bell CJ, 2008, J NEURAL ENG, V5, P214, DOI 10.1088/1741-2560/5/2/012
   Bin GY, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/4/046002
   BioSig, 2003, OP SOURC SOFTW PACK
   Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581
   Birbaumer N, 2007, J PHYSIOL-LONDON, V579, P621, DOI 10.1113/jphysiol.2006.125633
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051
   Brunner C, 2010, J NEUROSCI METH, V188, P165, DOI 10.1016/j.jneumeth.2010.02.002
   DAMEN EJP, 1987, PSYCHOPHYSIOLOGY, V24, P700, DOI 10.1111/j.1469-8986.1987.tb00353.x
   DECETY J, 1991, BEHAV BRAIN RES, V42, P1, DOI 10.1016/S0166-4328(05)80033-6
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808
   Faller J, 2010, PRESENCE-TELEOP VIRT, V19, P25, DOI 10.1162/pres.19.1.25
   FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6
   Gao XR, 2003, IEEE T NEUR SYS REH, V11, P137, DOI 10.1109/TNSRE.2003.814449
   Graimann B, 2010, FRONT COLLECT, P1, DOI 10.1007/978-3-642-02091-9
   Holzner C, 2009, IEEE ENABL TECHNOL, P236, DOI 10.1109/WETICE.2009.41
   Jäncke L, 2009, FRONT NEUROSCI-SWITZ, V3, P52, DOI 10.3389/neuro.01.006.2009
   Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007
   Kübler A, 2005, NEUROLOGY, V64, P1775, DOI 10.1212/01.WNL.0000158616.43002.6D
   Lalor EC, 2005, EURASIP J APPL SIG P, V2005, P3156, DOI 10.1155/ASP.2005.3156
   Lee S, 2008, INTERACT COMPUT, V20, P491, DOI 10.1016/j.intcom.2008.07.003
   Leeb R, 2004, P ANN INT IEEE EMBS, V26, P4503
   LEEB R, 2008, THESIS GRAZ U TECHNO
   Leeb Robert, 2007, Comput Intell Neurosci, P79642, DOI 10.1155/2007/79642
   Leeb R, 2007, IEEE T NEUR SYS REH, V15, P473, DOI 10.1109/TNSRE.2007.906956
   Leeb R, 2006, PRESENCE-TELEOP VIRT, V15, P500, DOI 10.1162/pres.15.5.500
   Leeb Robert., 2007, Toward brain-computer interfacing, P393
   Lotze M, 1999, J COGNITIVE NEUROSCI, V11, P491, DOI 10.1162/089892999563553
   Martinez Pablo, 2007, Comput Intell Neurosci, P94561, DOI 10.1155/2007/94561
   Mason SG, 2007, ANN BIOMED ENG, V35, P137, DOI 10.1007/s10439-006-9170-0
   Müller-Putz GR, 2005, J NEURAL ENG, V2, P123, DOI 10.1088/1741-2560/2/4/008
   Neuper C, 2005, COGNITIVE BRAIN RES, V25, P668, DOI 10.1016/j.cogbrainres.2005.08.014
   Neuper C, 2009, CLIN NEUROPHYSIOL, V120, P239, DOI 10.1016/j.clinph.2008.11.015
   Nijholt A, 2008, IEEE INTELL SYST, V23, P72, DOI 10.1109/MIS.2008.41
   Oishi Kazuo, 2000, Journal of Physiological Anthropology and Applied Human Science, V19, P255, DOI 10.2114/jpa.19.255
   Pfurtscheller G, 2008, INT J PSYCHOPHYSIOL, V68, P1, DOI 10.1016/j.ijpsycho.2007.11.003
   Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3
   Pfurtscheller G, 2006, INT J PSYCHOPHYSIOL, V62, P134, DOI 10.1016/j.ijpsycho.2006.03.001
   Pfurtscheller G, 2006, IEEE T NEUR SYS REH, V14, P205, DOI 10.1109/TNSRE.2006.875528
   Pfurtscheller G, 2006, BRAIN RES, V1071, P145, DOI 10.1016/j.brainres.2005.11.083
   Pfurtscheller G, 2009, CLIN NEUROPHYSIOL, V120, P24, DOI 10.1016/j.clinph.2008.09.027
   Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pfurtscheller G., 2010, IEEE T NEURAL SYST R
   Pfurtscheller G, 2008, COMPUTER, V41, P58, DOI 10.1109/MC.2008.432
   Pfurtscheller G, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnpro.2010.00003
   Pineda JA, 2003, IEEE T NEUR SYS REH, V11, P181, DOI 10.1109/TNSRE.2003.814445
   Ron-Angevin R, 2005, CYBERPSYCHOL BEHAV, V8, P353
   Scherer R., 2004, RTSBCI GRAZ BRAIN CO
   Scherer R, 2008, IEEE T BIO-MED ENG, V55, P675, DOI 10.1109/TBME.2007.903709
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M., 2002, COMPUTER GRAPHICS VI
   Townsend G, 2004, IEEE T NEUR SYS REH, V12, P258, DOI 10.1109/TNSRE.2004.827220
   USOH M, 1995, ENDEAVOUR, V19, P34, DOI 10.1016/0160-9327(95)98892-J
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
NR 62
TC 6
Z9 7
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 3
EP 20
D2 10.5772/553
PG 18
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400002
DA 2024-07-18
ER

PT B
AU Saggio, G
   Pinto, CA
AF Saggio, Giovanni
   Pinto, Carlo Alberto
BE Kim, JJ
TI Virtuality Supports Reality for e-Health Applications
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID REHABILITATION; TOOL; SIMULATION
C1 [Saggio, Giovanni; Pinto, Carlo Alberto] Univ Roma Tor Vergata, Rome, Italy.
C3 University of Rome Tor Vergata
RP Saggio, G (corresponding author), Univ Roma Tor Vergata, Rome, Italy.
CR Algeri D, 2009, ANN REV CYBERTHERAPY, V7, P99
   Angevin R. R, 2009, ANN REV CYBERTERAPHY, V7, P184
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bianchi L., 2008, 30 ANN INT C IEEE EN
   Boechler P, 2009, ANN REV CYBERTHERAPY, V7, P102
   Bro-Nielsen M., 1996, Computer Graphics Forum, V15, pC57, DOI 10.1111/1467-8659.1530057
   BroNielsen M, 1996, LECT NOTES COMPUT SC, V1131, P529, DOI 10.1007/BFb0046994
   Castagnaro A., 2010, 48 C NAZ SOC IT CHIR
   Chaudhry A, 1999, ANN ROY COLL SURG, V81, P281
   Cincotti F, 2009, LECT NOTES COMPUT SC, V5615, P483, DOI 10.1007/978-3-642-02710-9_53
   Cinelli ME, 2008, HUM MOVEMENT SCI, V27, P513, DOI 10.1016/j.humov.2007.10.001
   Costantini G, 2010, INT MULT COMPL INF C
   Costantini G., 2009, WIRN 09 19 IT WORKSH
   COVER SA, 1993, IEEE COMPUT GRAPH, V13, P68, DOI 10.1109/38.252559
   Dawson S, 2006, RADIOLOGY, V241, P17, DOI 10.1148/radiol.2411062581
   Draicchio F, 2010, BIODEVICES 2010: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON BIOMEDICAL ELECTRONICS AND DEVICES, P108
   Fidopiastis C, 2009, ANN REV CYBERTHERAPY, V7, P216
   Geisen S., 2005, SEMINAR MED IMAGES
   Grealy MA, 1999, ARCH PHYS MED REHAB, V80, P661, DOI 10.1016/S0003-9993(99)90169-7
   Haluck RS, 2002, ST HEAL T, V85, P179
   Ho I. K., 2006, AM COLL GASTROENTERO
   Jiménez-Murcia S, 2009, ANN REV CYBERTHERAPY, V7, P163
   Kayyali Ruba, 2007, HAVE 2007 - IEEE International Workshop on Haptic Audio Visual Environments and their Applications, P118
   Koenig ST, 2009, ANN REV CYBERTHERAPY, V7, P105
   Kuhn C, 1996, INT CONGR SER, V1124, P764
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P383, DOI 10.1089/109493103322278763
   Maass H., 2003, SURG SIMULATION SOFT, V2673, P2003
   Marescaux J, 1998, ANN SURG, V228, P627, DOI 10.1097/00000658-199811000-00001
   Menegoni F, 2009, ANN REV CYBERTHERAPY, V7, P72
   Rizzo AA., 1998, Cyberpsychol Behav, V1, P59, DOI 10.1089/cpb.1998.1.59
   Rose F., 1996, P 1 INT C DISABILITY, P5
   Saggio G., 2009, 1 IEEE INT WOWMOM WO
   Saggio G, 2010, BIOSIGNALS 2010: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P174
   Schijven M, 2003, SURG ENDOSC, V17, P1943, DOI 10.1007/s00464-003-9052-6
   Shahrbanian S, 2009, ANN REV CYBERTHERAPY, V7, P40
   Shuhaiber JH, 2004, ARCH SURG-CHICAGO, V139, P170, DOI 10.1001/archsurg.139.2.170
   Soler L., 2010, IFMBE P, P362
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Torner J. C., 1999, TRAUMATIC BRAIN INJU, P990
   Trotti C, 2009, ANN REV CYBERTHERAPY, V7, P257
   Van Herzeele I., 2008, INTERVENTIONAL CARDI, P41
   WANG YF, 2005, THESIS IOWA STATE U
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Zanyi E, 2009, ANN REV CYBERTHERAPY, V7, P138
NR 44
TC 3
Z9 3
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 247
EP 272
D2 10.5772/553
PG 26
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400013
DA 2024-07-18
ER

PT J
AU Rey, B
   Alcañiz, M
   Tembl, J
   Parkhutik, V
AF Rey, Beatriz
   Alcaniz, Mariano
   Tembl, Jose
   Parkhutik, Vera
TI Brain activity and presence: a preliminary study in different immersive
   conditions using transcranial Doppler monitoring
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Brain activity; Transcranial Doppler; Virtual reality;
   Immersion; Navigation
ID FLOW-VELOCITY CHANGES; CEREBRAL-BLOOD-FLOW; VIRTUAL-REALITY; COGNITIVE
   TASKS; HEMODYNAMICS; ENVIRONMENTS; SENSE; LATERALIZATION; ASYMMETRY;
   DOMINANCE
AB Transcranial Doppler (TCD) sonography is a brain activity measurement technique that monitors the hemodynamic characteristics of the major cerebral arteries in normal and pathological conditions. As it is not invasive, it can be easily used in combination with virtual environments (VE). In the present study, TCD has been used to analyze brain activity variations in different presence conditions during the exposure to a VE. Forty-two subjects have taken part in the experience grouped in two different visualization conditions: a CAVE-like and a single screen projection configuration. In each session, two different navigation conditions were used: a free navigation (controlled by the subject) and an automatic navigation (controlled by the system). Results show that these immersion and navigation modifications in the VE generate changes in brain activity that can be detected using TCD techniques. Several factors, one of them being presence, could be having an influence on this behavior.
C1 [Rey, Beatriz; Alcaniz, Mariano] Univ Politecn Valencia, Inst Bioingn & Tecnol Orientada Ser Humano, Valencia 46022, Spain.
   [Tembl, Jose; Parkhutik, Vera] Hosp Univ La Fe, Neurol Serv, Valencia 46009, Spain.
C3 Universitat Politecnica de Valencia; Hospital Universitari i Politecnic
   La Fe
RP Rey, B (corresponding author), Univ Politecn Valencia, Inst Bioingn & Tecnol Orientada Ser Humano, Camino Vera S-N, Valencia 46022, Spain.
EM beareyso@labhuman.upv.es
RI Alcañiz, Mariano/CAG-6569-2022; Rey, Beatriz/P-6897-2014
OI Alcañiz, Mariano/0000-0001-9207-0636; Rey, Beatriz/0000-0001-9213-1443
CR AASLID R, 1982, J NEUROSURG, V57, P769, DOI 10.3171/jns.1982.57.6.0769
   Alcañiz M, 2009, PRESENCE-TELEOP VIRT, V18, P97, DOI 10.1162/pres.18.2.97
   [Anonymous], J COMPUT MEDIAT COMM
   ANTLEY A, 2009, 2 RAVE REAL ACT VIRT
   AXELSSON A, 2000, 3 INT WORKSH PRES 27
   Azevedo E, 2007, J NEUROL, V254, P236, DOI 10.1007/s00415-006-0338-1
   Bäcker M, 2002, NEUROSCI LETT, V333, P203, DOI 10.1016/S0304-3940(02)01109-6
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Baños RM, 2005, PSYCHNOLOGY J, V3, P90
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   BullaHellwig M, 1996, NEUROPSYCHOLOGIA, V34, P987, DOI 10.1016/0028-3932(96)00021-8
   CALLAN A, 2007, 10 INT WORKSH PRES O
   Cupini LM, 1996, BRAIN, V119, P1249, DOI 10.1093/brain/119.4.1249
   Daffertshofer M., 2001, Cerebrovascular ultrasound: theory, practice and future developments, P341
   Deppe M, 1997, J NEUROSCI METH, V75, P147, DOI 10.1016/S0165-0270(97)00067-8
   DILLON C, 2000, 3 INT WORKSH PRES MA
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Friedman D, 2006, PRESENCE-TELEOP VIRT, V15, P599, DOI 10.1162/pres.15.5.599
   HARDERS AG, 1989, INT J NEUROSCI, V47, P91, DOI 10.3109/00207458908987421
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Hoffman HG, 2003, CYBERPSYCHOL BEHAV, V6, P127, DOI 10.1089/109493103321640310
   Holden MK, 2002, HUM FAC ER, P999
   Huang M.P., 1999, MED MEETS VIRTUAL RE
   IADECOLA C, 1993, TRENDS NEUROSCI, V16, P206, DOI 10.1016/0166-2236(93)90156-G
   IJSSELSTEIJN WA, 1998, PRES SHAR VIRT ENV W
   Insko B.E., 2003, BEING THERE CONCEPTS
   KELLEY RE, 1992, STROKE, V23, P9, DOI 10.1161/01.STR.23.1.9
   Knecht S, 1996, NEUROREPORT, V7, P820, DOI 10.1097/00001756-199602290-00033
   Knecht S, 2000, BRAIN, V123, P2512, DOI 10.1093/brain/123.12.2512
   LAARNI J, 2003, 6 INT WORKSH PRES OC
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   LOMBARD M, 2000, 3 INT WORKSH PRES MA
   Matteis M, 2006, EUR J NEUROL, V13, P24, DOI 10.1111/j.1468-1331.2006.01219.x
   Matteis M, 2001, J NEUROL, V248, P104, DOI 10.1007/s004150170243
   McCartney JP., 1997, Hand- book of transcranial doppler
   MEEHAN M, 2001, 4 INT WORKSH PRES MA
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Orlandi G, 1996, INT J NEUROSCI, V84, P45, DOI 10.3109/00207459608987249
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Pugnetti L., 1996, P EUR C DIS VIRT REA, P239
   RAVAJA N, 2002, 5 INT WORKSH PRES OC
   RIHS F, 1995, STROKE, V26, P70, DOI 10.1161/01.STR.26.1.70
   RINGELSTEIN EB, 1990, ULTRASOUND MED BIOL, V16, P745, DOI 10.1016/0301-5629(90)90039-F
   RISBERG J, 1986, NEUROPSYCHOLOGIA, V24, P135, DOI 10.1016/0028-3932(86)90047-3
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Sadowski W, 2002, HUM FAC ER, P791
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   SCHLOGL A, 2002, 5 INT WORKSH PRES OC
   Schmidt P, 1999, STROKE, V30, P939, DOI 10.1161/01.STR.30.5.939
   Schnittger C, 1997, NEUROPSYCHOLOGIA, V35, P1181, DOI 10.1016/S0028-3932(97)00038-9
   SCHUBERT TW, 1999, 2 INT WORKSH PRES AP
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   SILVESTRINI M, 1994, J CEREBR BLOOD F MET, V14, P643, DOI 10.1038/jcbfm.1994.80
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P8
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   Stoll M, 1999, J NEUROL, V246, P127, DOI 10.1007/s004150050319
   Stone RJ, 2002, HUM FAC ER, P827
   Strickland D, 1997, PRESENCE-TELEOP VIRT, V6, P581, DOI 10.1162/pres.1997.6.5.581
   Stroobant N, 2000, NEUROPSYCHOL REV, V10, P213, DOI 10.1023/A:1026412811036
   Tatu L, 1998, NEUROLOGY, V50, P1699, DOI 10.1212/WNL.50.6.1699
   Troisi E, 1999, J NEUROL, V246, P1172, DOI 10.1007/s004150050538
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vingerhoets G, 1999, STROKE, V30, P2152, DOI 10.1161/01.STR.30.10.2152
   Vingerhoets G, 2003, NEUROPSYCHOLOGY, V17, P93, DOI 10.1037/0894-4105.17.1.93
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   YOUNGBLUT C, 2002, IMAGE 2002 C AR
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
NR 76
TC 15
Z9 15
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 55
EP 65
DI 10.1007/s10055-009-0141-2
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400006
DA 2024-07-18
ER

PT J
AU Martingano, AJ
   Duane, JN
   Brown, E
   Persky, S
AF Martingano, Alison Jane
   Duane, Ja-Nae
   Brown, Ellenor
   Persky, Susan
TI Demographic differences in presence across seven studies
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Virtual reality; Age differences; Gender differences; Racial
   differences
ID VIRTUAL-REALITY; SOCIAL PRESENCE; GENDER-DIFFERENCES; ENVIRONMENTS;
   PERCEPTIONS; EXPERIENCE; METAANALYSIS; APPEARANCE; EFFICACY; BEHAVIOR
AB It is often necessary for virtual reality (VR) users to experience a sense of presence for the benefits of VR applications to be realized. However, feelings of presence are subjective and depend not only on the nature of the VR environment but also on the users' unique characteristics. To maximize the likelihood of achieving desired VR outcomes, it is important to understand the user characteristics that impact the likelihood of users' feelings of social and environmental presence. Addressing this knowledge gap is an important first step toward verifying whether all user populations have access to equally efficacious VR experiences. To this end, we report data from seven independent samples collected within one laboratory group (total N = 1145). In these studies, participants were asked to perform tasks in VR such as traversing environments, pointing at and selecting objects, and interacting with virtual humans. Meta-analyses revealed that, on average, feelings of presence were not significantly related to age or gender, but differed by racial group membership. Significant racial differences in presence were found for both environmental and social presence. Black participants reported approximately half a standard deviation more presence than White participants. No overall differences between Asian and White participants' reported presence were found. These findings provide a context for future studies that may explore demographic differences in presence directly.
C1 [Martingano, Alison Jane; Persky, Susan] Natl Human Genome Res Inst, NIH, Social & Behav Res Branch, Bethesda, MD 20894 USA.
   [Martingano, Alison Jane] Univ Wisconsin Green Bay, Dept Psychol, Green Bay, WI 54311 USA.
   [Duane, Ja-Nae] Bentley Univ, Dept Informat & Proc Management, Waltham, MA USA.
   [Brown, Ellenor] US FDA, Ctr Devices & Radiol Hlth, Off Sci & Engn Labs, Silver Spring, MD USA.
C3 National Institutes of Health (NIH) - USA; NIH National Human Genome
   Research Institute (NHGRI); University of Wisconsin System; University
   of Wisconsin Green Bay; Bentley University; US Food & Drug
   Administration (FDA)
RP Persky, S (corresponding author), Natl Human Genome Res Inst, NIH, Social & Behav Res Branch, Bethesda, MD 20894 USA.
EM perskys@mail.nih.gov
RI Duane, Ja-Nae/GRS-5661-2022
OI Duane, Ja-Nae/0000-0002-4091-3264; Martingano, Alison
   Jane/0000-0001-8407-8611
CR Alcalde-Rubio L, 2020, INT J EQUITY HEALTH, V19, DOI 10.1186/s12939-020-01283-4
   Almog I, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P78, DOI 10.1109/ICVR.2009.5174209
   Arns LL., 2005, IEEE P, DOI [10.1145/1140491.1140539, DOI 10.1145/1140491.1140539]
   Athif M, 2020, IEEE ENG MED BIO, P3035, DOI 10.1109/EMBC44109.2020.9176022
   Ausburn L., 2008, J STEM TEACH ED, V45, P6
   Ba├a┬▒os RM., 2005, APPL TECHNOLOGIES ME, P21
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Bailey J., 2011, P INT SOC PRESENCE R
   Barreda-Angeles M, 2020, CYBERPSYCH BEH SOC N, V23, P683, DOI 10.1089/cyber.2019.0665
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Beverly Elizabeth Ann, 2021, JMIR Diabetes, V6, pe23708, DOI 10.2196/23708
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Blackwell Lindsay, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359202
   Blascovich J, 2002, COMP SUPP COMP W SER, P127
   Borenstein M., 2006, COMPREHENSIVE META A
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Chang CW, 2020, IEEE ACCESS, V8, P69566, DOI 10.1109/ACCESS.2020.2966564
   Chirico A, 2016, J CELL PHYSIOL, V231, P275, DOI 10.1002/jcp.25117
   Cho YH, 2015, INTERNET HIGH EDUC, V25, P70, DOI 10.1016/j.iheduc.2015.01.002
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Coburn JQ, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4036921
   Lecavalier NC, 2020, NEUROPSYCHOL REHABIL, V30, P462, DOI 10.1080/09602011.2018.1477684
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   De Carvalho MR, 2010, WORLD J BIOL PSYCHIA, V11, P220, DOI 10.3109/15622970802575985
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   DERSIMONIAN R, 1986, CONTROL CLIN TRIALS, V7, P177, DOI 10.1016/0197-2456(86)90046-2
   Dilanchian AT, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.736793
   Duane JN, 2022, P 55 HAW INT C SYST
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Felnhofer A, 2014, COMPUT HUM BEHAV, V31, P272, DOI 10.1016/j.chb.2013.10.045
   Felton WM, 2022, INT J HUM-COMPUT INT, V38, P1, DOI 10.1080/10447318.2021.1921368
   Fox J, 2009, PRESENCE-TELEOP VIRT, V18, P294, DOI 10.1162/pres.18.4.294
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gamito P., 2008, Annual Review of CyberTherapy and Telemedicine: Changing the Face of Healthcare, P83
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Garrison DR, 2010, INTERNET HIGH EDUC, V13, P31, DOI 10.1016/j.iheduc.2009.10.002
   Giannopoulos E., 2008, EFFECT HAPTIC FEEDBA, DOI [10.1007/978-3-540-69057-3_36, DOI 10.1007/978-3-540-69057-3_36]
   Gonçalves G, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2018)
   Grassini S, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030007
   Hauber J, 2005, P 8 ANN INT WORKSH P
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725
   Hernandez R, 2021, KIDNEY360, V2, P435, DOI 10.34067/KID.0005522020
   Hite RL, 2019, J SCI EDUC TECHNOL, V28, P265, DOI 10.1007/s10956-018-9764-y
   HODGES LF, 1995, COMPUTER, V28, P27, DOI 10.1109/2.391038
   Hoffman KM, 2016, P NATL ACAD SCI USA, V113, P4296, DOI 10.1073/pnas.1516047113
   Iachini T, 2019, COGN PROCESS, V20, P291, DOI 10.1007/s10339-018-0897-y
   IJsselsteijn W.A., 2004, Presence in Depth
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   ISAAC AR, 1994, BRIT J PSYCHOL, V85, P479, DOI 10.1111/j.2044-8295.1994.tb02536.x
   Johnson RD, 2011, J ORGAN END USER COM, V23, P79, DOI 10.4018/joeuc.2011010105
   Jun HS, 2022, IEEE T AFFECT COMPUT, V13, P1416, DOI 10.1109/TAFFC.2020.3004617
   Khashe Saba., 2018, Persuasive effects of immersion in virtual environments for measuring Pro-Environmental behaviors, V35, P1, DOI [10.1007/s10639-017-9676-0, DOI 10.22260/ISARC2018/0167]
   Kim J, 2004, PRESENCE-TELEOP VIRT, V13, P328, DOI 10.1162/1054746041422370
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Knight M. M., 2006, ACM SIGGRAPH 2006 Res Posters, DOI [10.1145/1179622.1179846, DOI 10.1145/1179622.1179846]
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   Landrine H, 2014, FRONT PUBLIC HEALTH, V2, DOI 10.3389/fpubh.2014.00282
   Lee JER, 2011, CYBERPSYCH BEH SOC N, V14, P637, DOI 10.1089/cyber.2010.0501
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lessiter J, 2000, P PRESENCE
   Lim J, 2016, INTERNET HIGH EDUC, V29, P31, DOI 10.1016/j.iheduc.2015.12.001
   Lin MC, 2011, LEARN MEDIA TECHNOL, V36, P399, DOI 10.1080/17439884.2011.629660
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Lombard M., 2015, Immersed in media, P13, DOI [DOI 10.1007/978-3-319-10190-3, https://doi.org/10.1007/978-3-319-10190-32, DOI 10.1007/978-3-319-10190-32, 10.1007/978-3-319-10190-3_2, DOI 10.1007/978-3-319-10190-3_2]
   Martingano AJ, 2022, J MED INTERNET RES, V24, DOI 10.2196/36843
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Melo M., 2021, 2021 International Conference on Graphics and Interaction (ICGI), P1, DOI [DOI 10.1109/ICGI54032.2021.9655281, 10.1109/ICGI54032.2021.9655281]
   Melo M, 2022, MULTIMEDIA SYST, V28, P1027, DOI 10.1007/s00530-022-00898-7
   Mitzner TL., 2021, GERONTECHNOLOGY, V20, P1, DOI [10.4017/gt.2021.20.2.456.12, DOI 10.4017/GT.2021.20.2.456.12]
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Paquay M, 2022, CLIN SIMUL NURS, V62, P1, DOI 10.1016/j.ecns.2021.09.006
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Persky S, 2018, APPETITE, V123, P201, DOI 10.1016/j.appet.2017.12.007
   Petri K., 2020, AM J BIOMED SCI, DOI [10.5099/aj2002001, DOI 10.5099/AJ200200107]
   Rad MS, 2018, P NATL ACAD SCI USA, V115, P11401, DOI 10.1073/pnas.1721165115
   Rahill S, 2020, APPETITE, V147, DOI 10.1016/j.appet.2019.104540
   Richardson J.C., 2003, Examining Social Presence in online courses in relation to students' perceived learning and satisfaction
   Rivers DC, 2009, ORGAN RES METHODS, V12, P529, DOI 10.1177/1094428108315864
   Ross S.P., 2006, VIRTUAL REAL-LONDON, V10, P175, DOI [10.1007/s10055-006-0041-7, DOI 10.1007/S10055-006-0041-7]
   Sagnier C, 2019, ADV INTELLIGENT SYST, P305
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Scheibler CD, 2018, SYMP VIRTUAL AUGMENT, P75, DOI 10.1109/SVR.2018.00022
   Schifter CC, 2012, EDUC TECHNOL SOC, V15, P53
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Short J., 1976, The social psychology of telecommunications
   Siriaraya P, 2012, INTERACT COMPUT, V24, P280, DOI 10.1016/j.intcom.2012.03.003
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 1996, ACM VIRTUAL REALITY
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Taylor VJ, 2020, POL INS BEH BRAIN SC, V7, P132, DOI 10.1177/2372732220943638
   Triberti S, 2014, CYBERPSYCH BEH SOC N, V17, P335, DOI 10.1089/cyber.2014.0054
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Valentine JC, 2010, J EDUC BEHAV STAT, V35, P215, DOI 10.3102/1076998609346961
   Van Schaik P, 2004, CYBERPSYCHOL BEHAV, V7, P540, DOI 10.1089/1094931042403145
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Wallis G, 2013, PRESENCE-VIRTUAL AUG, V22, P67, DOI 10.1162/PRES_a_00135
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wei CW, 2012, ETR&D-EDUC TECH RES, V60, P529, DOI 10.1007/s11423-012-9234-9
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
NR 117
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2297
EP 2313
DI 10.1007/s10055-023-00805-z
EA MAY 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000988990300001
DA 2024-07-18
ER

PT J
AU Cieslik, B
   Juszko, K
   Kiper, P
   Szczepanska-Gieracha, J
AF Cieslik, Blazej
   Juszko, Karolina
   Kiper, Pawel
   Szczepanska-Gieracha, Joanna
TI Immersive virtual reality as support for the mental health of elderly
   women: a randomized controlled trial
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual therapeutic garden; Hypnosis; VRET; Mood disorders; Head-mounted
   display; Exposure therapy
ID DEPRESSIVE SYMPTOMS; POSITIVE TECHNOLOGY; OLDER-ADULTS; INTERVENTIONS;
   SUGGESTIONS; HYPNOSIS; THERAPY; ANXIETY; PROGRAM
AB Several forms of virtual reality (VR) have shown promise in treating mental disorders. However, there is a lack of research investigating the use of multicomponent immersive VR. Therefore, this study aimed to evaluate the effectiveness of an immersive virtual reality (IVR) intervention that incorporated Japanese garden aesthetics, relaxation, and elements of Erickson's psychotherapy in alleviating depression and anxiety symptoms among elderly women. Sixty women with depressive symptoms were randomly assigned to one of two treatment groups. Both groups received eight (twice a week for four weeks) low-intensity general fitness training sessions. The IVR group (n = 30) received eight additional VR-based relaxation sessions, whereas the control group (n = 30) received eight group relaxation. As outcome measures, the geriatric depression scale (GDS; primary) and Hospital Anxiety and Depression Scale (HADS; secondary) were administered before and after the interventions. The protocol was registered in the ClinicalTrials.gov PRS database (Registration number: NCT05285501). Patients receiving IVR therapy exhibited a greater significant reduction in the GDS (adjusted mean post-difference of 4.10; 95% CI = 2.27-5.93) and HADS (2.95; 95% CI = 0.98-4.92) scores than those receiving the control intervention. In conclusion, IVR with elements of psychotherapy, relaxation, and garden aesthetics may alleviate the severity of depression and anxiety symptoms in elderly women.
C1 [Cieslik, Blazej; Kiper, Pawel] IRCCS San Camillo Hosp, Healthcare Innovat Technol Lab, Venice, Lido, Italy.
   [Juszko, Karolina; Szczepanska-Gieracha, Joanna] Wroclaw Univ Hlth & Sport Sci, Fac Physiotherapy, Wroclaw, Poland.
C3 IRCCS Ospedale San Camillo
RP Cieslik, B (corresponding author), IRCCS San Camillo Hosp, Healthcare Innovat Technol Lab, Venice, Lido, Italy.
EM blazej.cieslik@hsancamillo.it
RI Cieślik, Błażej/J-4551-2016; Al-Rahamneh, Moad/JCO-5185-2023; Kiper,
   Pawel/J-8147-2018
OI Cieślik, Błażej/0000-0001-7275-7860; Juszko,
   Karolina/0000-0003-1968-2796; Szczepanska-Gieracha,
   Joanna/0000-0001-5191-3799; Kiper, Pawel/0000-0001-5990-5734
CR Aalbers Sonja, 2017, Cochrane Database Syst Rev, V11, pCD004517, DOI 10.1002/14651858.CD004517.pub3
   Baghaei N, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/29681
   Banay RF, 2019, ENVIRON HEALTH PERSP, V127, DOI 10.1289/EHP1229
   Baños RM, 2013, SUPPORT CARE CANCER, V21, P263, DOI 10.1007/s00520-012-1520-x
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   BJELLAND I, 2002, J PSYCHOSOM RES, V0052
   Boffi M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.927688
   Botella C, 2012, CYBERPSYCH BEH SOC N, V15, P78, DOI 10.1089/cyber.2011.0140
   Campbell G, 2015, INT PSYCHOGERIATR, V27, P1577, DOI 10.1017/S1041610215000769
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chan SHM, 2023, VIRTUAL REAL-LONDON, V27, P3285, DOI 10.1007/s10055-021-00604-4
   Cieslik B, 2020, COMPLEMENT THER MED, V52, DOI 10.1016/j.ctim.2020.102480
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Dominguez-Tellez P, 2020, GAMES HEALTH J, V9, P1, DOI 10.1089/g4h.2019.0043
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Gloster AT, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0244809
   Göksin I, 2021, PSYCHOGERIATRICS, V21, P333, DOI 10.1111/psyg.12673
   Goto S, 2020, HERD-HEALTH ENV RES, V13, P31, DOI 10.1177/1937586720924729
   Goto S, 2013, HERD-HEALTH ENV RES, V6, P27, DOI 10.1177/193758671300600204
   Goudman L, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/34402
   Ji JS, 2019, LANCET PLANET HEALTH, V3, pE17, DOI 10.1016/S2542-5196(18)30264-X
   Józwik S, 2021, J CLIN MED, V10, DOI 10.3390/jcm10102148
   Kalantari S, 2022, INNOV AGING, V6, DOI 10.1093/geroni/igac015
   Kiper P, 2022, CLIN INTERV AGING, V17, P1673, DOI 10.2147/CIA.S375754
   Klainin-Yobas P, 2015, AGING MENT HEALTH, V19, P1043, DOI 10.1080/13607863.2014.997191
   Kuehner C, 2017, LANCET PSYCHIAT, V4, P146, DOI 10.1016/S2215-0366(16)30263-2
   Landeiro F, 2016, OSTEOPOROSIS INT, V27, P737, DOI 10.1007/s00198-015-3293-9
   Larkin DM, 2014, EXPLORE-NY, V10, P380, DOI 10.1016/j.explore.2014.08.005
   Li HS, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.725288
   Li SYH, 2019, INT J MENT HEALTH NU, V28, P635, DOI 10.1111/inm.12568
   Lin YP, 2022, J CLIN NURS, V31, P2087, DOI 10.1111/jocn.16095
   Lopez MN, 2010, EUR J PSYCHOL ASSESS, V26, P55, DOI 10.1027/1015-5759/a000008
   Luppa M, 2012, J AFFECT DISORDERS, V136, P212, DOI 10.1016/j.jad.2010.11.033
   LYNN SJ, 1993, INT J CLIN EXP HYP, V41, P124, DOI 10.1080/00207149308414543
   Malhi GS, 2018, LANCET, V392, P2299, DOI 10.1016/S0140-6736(18)31948-2
   Malighetti C, 2022, ANN REV CYBERTHERAPY, V20, P37
   Matthews WJ, 2000, INT J CLIN EXP HYP, V48, P418, DOI 10.1080/00207140008410370
   Meyer ML, 2022, J CLIN MED, V11, DOI 10.3390/jcm11082080
   Mitchell AJ, 2010, J AFFECT DISORDERS, V125, P10, DOI 10.1016/j.jad.2009.08.019
   Morga P, 2021, J SPORT SCI MED, V20, P222, DOI 10.52082/jssm.2021.222
   Moss D, 2019, AM J CLIN HYPN, V61, P322, DOI 10.1080/00029157.2018.1517082
   Nishigaki M, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17249276
   Pallavicini F, 2022, TRIALS, V23, DOI 10.1186/s13063-022-06337-2
   Perrino T, 2019, BRIT J PSYCHIAT, V215, P476, DOI 10.1192/bjp.2019.129
   Riva G, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.563319
   Riva G, 2012, CYBERPSYCH BEH SOC N, V15, P69, DOI 10.1089/cyber.2011.0139
   Rutkowski S, 2021, J CLIN MED, V10, DOI 10.3390/jcm10020352
   Sassarini DJ, 2016, MATURITAS, V94, P149, DOI 10.1016/j.maturitas.2016.09.004
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Szczepanska-Gieracha J, 2021, J CLIN MED, V10, DOI 10.3390/jcm10091942
   Szczepanska-Gieracha J, 2021, CYBERPSYCH BEH SOC N, V24, P543, DOI 10.1089/cyber.2020.0297
   Szczepanska-Gieracha J, 2019, FAM MED PRIM CARE RE, V21, P381, DOI 10.5114/fmpcr.2019.90172
   Tang QS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240862
   Taylor EM, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19063214
   Wu JL, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.575094
NR 56
TC 6
Z9 6
U1 9
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2227
EP 2235
DI 10.1007/s10055-023-00797-w
EA MAY 2023
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000982785800001
PM 37360811
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Hellum, O
   Kersten-Oertel, M
   Xiao, YM
AF Hellum, Owen
   Kersten-Oertel, Marta
   Xiao, Yiming
TI Assessment of user-interaction strategies for neurosurgical data
   navigation and annotation in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Human-computer interaction; MRI; Neurosurgery; Surgical
   navigation; Eye-tracking
ID SURGERY
AB While virtual-reality (VR) has shown great promise in radiological tasks, effective user-interaction strategies that can improve efficiency and ergonomics are still under-explored and systematic evaluations of VR interaction techniques in the context of complex anatomical models are rare. Therefore, our study aims to identify the most effective interaction techniques for two common neurosurgical planning tasks in VR (point annotation and note-taking) from the state-of-the-arts, and propose a novel technique for efficient sub-volume selection necessary in neuroanatomical navigation. We assessed seven user-interaction methods with multiple input modalities (gaze, head motion, controller, and voice) for point placement and note-taking in the context of annotating brain aneurysms for cerebrovascular surgery. Furthermore, we proposed and evaluated a novel technique, called magnified selection diorama (Maserama) for easy navigation and selection of complex 3D anatomies in VR. Both quantitative and semi-quantitative (i.e., NASA Task Load Index) metrics were employed through user studies to reveal the performance of each interaction scheme in terms of accuracy, efficiency, and usability. Our evaluations demonstrated that controller-based interaction is preferred over eye-tracking-based methods for point placement while voice recording and virtual keyboard typing are better than freehand writing for note-taking. Furthermore, our new Maserama sub-volume selection technique was proven to be highly efficient and easy-to-use. Our study is the first to provide a systematic assessment of existing and new VR interaction schemes for neurosurgical data navigation and annotation. It offers valuable insights and tools to guide the design of future VR systems for radiological and surgical applications.
C1 [Hellum, Owen; Kersten-Oertel, Marta; Xiao, Yiming] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.
   [Kersten-Oertel, Marta; Xiao, Yiming] Concordia Univ, PERFORM Ctr, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Xiao, YM (corresponding author), Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.; Xiao, YM (corresponding author), Concordia Univ, PERFORM Ctr, Montreal, PQ, Canada.
EM yiming.xiao@concordia.ca
CR Alaraj A, 2015, OPER NEUROSURG, V11, P52, DOI 10.1227/NEU.0000000000000583
   Blattgerste J, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206349
   Boletsis Costas., 2019, INT J VIRTUAL REALIT, V19, P2, DOI [DOI 10.20870/IJVR.2019.19.3.2917, 10.20870/IJVR.2019.19.3.2917, DOI 10.20870/IJVR.2019.19.32917]
   Collins MK, 2018, BRAIN STIMUL, V11, P935, DOI 10.1016/j.brs.2018.03.012
   Derby Jessyca L., 2020, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V64, P2102, DOI 10.1177/1071181320641509
   Dube T. J., 2019, HUMAN COMPUTER INTER, P419, DOI [DOI 10.1007/978-3-030-22643-5, 10.1007/978-3-030-22643-5\33/TABLES/5, https://doi.org/10.1007/978-3-030-22643-5_33, DOI 10.1007/978-3-030-22643-5_33]
   Ekstrand Chelsea, 2018, CMAJ Open, V6, pE103, DOI 10.9778/cmajo.20170110
   Eskildsen SF, 2012, NEUROIMAGE, V59, P2362, DOI 10.1016/j.neuroimage.2011.09.012
   Fiani B, 2020, WORLD NEUROSURG, V141, P291, DOI 10.1016/j.wneu.2020.06.066
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Gasques Danilo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445576
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hellum O, 2022, COMP M BIO BIO E-IV, V10, P418, DOI 10.1080/21681163.2021.1997645
   Heredia-Pérez SA, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1953
   Hou WJ, 2021, INT J HUM-COMPUT INT, V37, P484, DOI 10.1080/10447318.2020.1826190
   Isomoto T, 2022, 2022 S EYE TRACKING
   Kim Byeol, 2020, JMIR Cardio, V4, pe20633, DOI 10.2196/20633
   Kockro RA, 2016, WORLD NEUROSURG, V96, P489, DOI 10.1016/j.wneu.2016.08.124
   Louis R, 2020, Neurosurg. Pract, V1, DOI [10.1093/neuopn/okaa004, DOI 10.1093/NEUOPN/OKAA004]
   Luro FL, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318153
   Nukarinen T, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3283382
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Ruan S, 2018, PROC ACM INTERACT MO, V1, P23
   Shao XF, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-019-1911-5
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   van Deursen M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92109-y
   Xiao YM, 2021, IEEE T BIO-MED ENG, V68, P1024, DOI 10.1109/TBME.2020.3006765
   Xiao YM, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0217-0
   Xiao YM, 2018, MULTIMED TOOLS APPL, V77, P27789, DOI 10.1007/s11042-018-5990-9
   Yu K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P392, DOI 10.1109/VR50410.2021.00062
NR 33
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1345
EP 1355
DI 10.1007/s10055-022-00740-5
EA DEC 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000904884000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Désiron, JC
   Petko, D
   Lapaire, V
   Ullrich, C
   Clack, L
AF Desiron, J. C.
   Petko, D.
   Lapaire, V
   Ullrich, C.
   Clack, L.
TI Using virtual reality to train infection prevention: what predicts
   performance and behavioral intention?
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Hand hygiene; Technology acceptance; Engagement;
   Procedure training
ID TECHNOLOGY ACCEPTANCE; HAND HYGIENE; EDUCATION; MOMENTS; GEL
AB Training medical professionals for hand hygiene is challenging, especially due to the invisibility of microorganisms to the human eye. As the use of virtual reality (VR) in medical training is still novel, this exploratory study investigated how preexisting technology acceptance and in-training engagement predict VR hand hygiene performance scores. The effect of training in the VR environment on the behavioral intention to further use this type of training device (a component of technology acceptance) was also investigated. Participants completed a VR hand hygiene training comprising three levels of the same task with increasing difficulty. We measured technology acceptance, composed of performance expectancy, effort expectancy, and behavioral intention, pre- and post-training, and in-training engagement using adaptations of existing questionnaires. We used linear regression models to determine predictors of performance in level-3 and of behavioral intention to further use VR training. Forty-three medical students participated in this exploratory study. In-training performance significantly increased between level-1 and level-3. Performance in level-3 was predicted by prior performance expectancy and engagement during the training session. Intention to further use VR to learn medical procedures was predicted by both prior effort expectancy and engagement. Our results provide clarification on the relationship between VR training, engagement, and technology acceptance. Future research should assess the long-term effectiveness of hand hygiene VR training and the transferability of VR training to actual patient care in natural settings. A more complete VR training could also be developed, with additional levels including more increased difficulty and additional medical tasks.
C1 [Desiron, J. C.; Petko, D.] Univ Zurich, Inst Educ, Zurich, Switzerland.
   [Lapaire, V; Ullrich, C.; Clack, L.] Univ Zurich, Inst Implementat Sci Hlth Care, Zurich, Switzerland.
   [Clack, L.] Univ Hosp Zurich, Dept Infect Dis, Zurich, Switzerland.
   [Clack, L.] Univ Hosp Zurich, Hosp Epidemiol, Zurich, Switzerland.
C3 University of Zurich; University of Zurich; University of Zurich;
   University Zurich Hospital; University of Zurich; University Zurich
   Hospital
RP Désiron, JC (corresponding author), Univ Zurich, Inst Educ, Zurich, Switzerland.
EM juliette.desiron@uzh.ch
RI Clack, Lauren/JAZ-1198-2023; Désiron, Juliette/GNW-2652-2022; Petko,
   Dominik/HHN-4628-2022
OI Clack, Lauren/0000-0002-5162-5188; Désiron,
   Juliette/0000-0002-3074-9018; Petko, Dominik/0000-0003-1569-1302
FU University of Zurich
FX Open access funding provided by University of Zurich. No funding was
   received for conducting this study.
CR Aggelidis VP, 2009, INT J MED INFORM, V78, P115, DOI 10.1016/j.ijmedinf.2008.06.006
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Alhmidi H, 2016, ANTIMICROB RESIST IN, V5, DOI 10.1186/s13756-016-0141-4
   Allegranzi B, 2009, J HOSP INFECT, V73, P305, DOI 10.1016/j.jhin.2009.04.019
   Barteit S, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29080
   Boucheix JM, 2018, COMPUT HUM BEHAV, V89, P418, DOI 10.1016/j.chb.2018.01.017
   Bracq MS, 2019, SIMUL HEALTHC, V14, P188, DOI 10.1097/SIH.0000000000000347
   Chen FQ, 2020, J MED INTERNET RES, V22, DOI 10.2196/18290
   Cheung R, 2013, COMPUT EDUC, V63, P160, DOI 10.1016/j.compedu.2012.12.003
   Clack L., 2021, Recent Advances in Technologies for Inclusive Well-Being: Virtual Patients, Gamication and Simulation, P31
   Clack L, 2018, INT CONF INFORM INTE, P119
   Clack L, 2014, INFECT CONT HOSP EP, V35, P1051, DOI 10.1086/677166
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dobricki M, 2021, RES LEARN TECHNOL, V29, DOI 10.25304/rlt.v29.2453
   Frerejean J, 2019, EUR J EDUC, V54, P513, DOI 10.1111/ejed.12363
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Harbarth S, 2003, J HOSP INFECT, V54, P258, DOI 10.1016/S0195-6701(03)00150-6
   Harbarth S, 2002, PEDIATR INFECT DIS J, V21, P489, DOI 10.1097/00006454-200206000-00002
   Hen L.B., 2019, Augmented reality and virtual reality: the power of AR and VR for business exploring surgeon's acceptance of virtual reality headset for training, DOI [10.1007/978-3-030-06246-0_21, DOI 10.1007/978-3-030-06246-0_21]
   Holden RJ, 2010, J BIOMED INFORM, V43, P159, DOI 10.1016/j.jbi.2009.07.002
   Hopitaux universitaires de Geneve, 2016, HAND HYG DANC WHO HU
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Longtin Y, 2011, NEW ENGL J MED, V364
   Luo H, 2021, J COMPUT ASSIST LEAR, V37, P887, DOI 10.1111/jcal.12538
   Nicholson DT, 2006, MED EDUC, V40, P1081, DOI 10.1111/j.1365-2929.2006.02611.x
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Pellas N, 2021, VIRTUAL REAL-LONDON, V25, P835, DOI 10.1007/s10055-020-00489-9
   Piot MA, 2022, J ADV NURS, V78, P332, DOI 10.1111/jan.14986
   Plotzky C, 2020, DELFI, P79
   Rosen JM, 1996, IEEE ENG MED BIOL, V15, P16, DOI 10.1109/51.486713
   Rourke S, 2020, INT J NURS STUD, V102, DOI 10.1016/j.ijnurstu.2019.103466
   Rupp ME, 2008, INFECT CONT HOSP EP, V29, P8, DOI 10.1086/524333
   Sagnier C, 2019, TRAV HUMAIN, V82, P183, DOI 10.3917/th.823.0183
   Satava RM, 1998, P IEEE, V86, P484, DOI 10.1109/5.662873
   Sax H, 2007, J HOSP INFECT, V67, P9, DOI 10.1016/j.jhin.2007.06.004
   Sax H, 2020, INFECT CONT HOSP EP, V41, P597, DOI 10.1017/ice.2019.351
   Shen CW, 2019, VIRTUAL REAL-LONDON, V23, P313, DOI 10.1007/s10055-018-0348-1
   Van Merrienboer J., 2014, CAMBRIDGE HDB MULTIM, V2nd, P104
   Vazquez-Vazquez M., 2011, 2011 IEEE 1 INT C SE, DOI [10.1109/SeGAH.2011.6165439, DOI 10.1109/SEGAH.2011.6165439]
   Watling C, 2012, MED EDUC, V46, P192, DOI 10.1111/j.1365-2923.2011.04126.x
   Wenk N, 2023, VIRTUAL REAL-LONDON, V27, P307, DOI 10.1007/s10055-021-00565-8
   World Health Organisation, 2017, YOUTUBE
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Zhao GJ, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-20-2785
   Zhao JJ, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-1994-z
NR 46
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1013
EP 1023
DI 10.1007/s10055-022-00708-5
EA OCT 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000876628800001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Rojo, A
   Raya, R
   Moreno, JC
AF Rojo, Ana
   Raya, Rafael
   Moreno, Juan C.
TI Virtual reality application for real-time pedalling cadence estimation
   based on hip ROM tracking with inertial sensors: a pilot study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Low-latency; Real-time tracking; Inertial unit sensor;
   Feedback; Cycling cadence
ID STROKE; GAIT; TREADMILL; EXERCISE; WALKING; MOTION; SYSTEM
AB Virtual reality (VR) applications on rehabilitation a home-base exercise experiences have boomed in the last decade. This is mainly because their entertainment capacity creates a sense of immersion in the users, which enhances adherence to their use. In addition, offering body-related visual feedback is a proven approach to the physical training towards a goal. Recent literature showed the exercise of pedalling has the potential to provide a high number of flexion and extension repetitions of the lower limb in reasonable therapeutic time periods to improve muscle activity, strength and balance in elders, but also motor improvements in patients with neurological injuries. The objective of this work is to present a low-cost wireless application in virtual reality (VR) for pedalling exercises. The platform developed consists of a VR headset and an inertial measurement unit (IMU). The VR headset processes the kinematic information of the IMU to estimate the cadence of the pedalling, while the IMU sensor tracks the angle of hip flexion/extension movement of the user. In order to confirm the suitability of this cadence estimation system, our approach is confronted with a cycling platform developed and validated in a previous study. In the present study, we carried out two repeated sessions with 13 subjects at 3 set speeds: slow (30 rpm), medium (60 rpm) and fast (90 rpm). The Spearman's correlation (PC) between both systems for the 3 speeds and sessions shows high correlation values for low and medium speeds and moderate correlation for high speed. The SEM results for each system show low measurement error (about 1 cycle) for both systems at every target speed, except for the virtual cycling platform at the highest speed (SEM of VCP at 90 rpm = 3.24 cycles). The repeatability analysis based on ICC (3, 1) absolute agreement shows consistency in all measurements for both systems at high speed and also reflects the irregularity in measurements at low and medium speeds, where participants were less stable during testing due to entertainment from the VR system. All in all, it is concluded the validity of the cadence estimation system for pedalling exercises with low intensity. This development allows us to control the virtual environment by adapting the visual stimulus to cycling cadence. The proposed system can generate sensitive inputs to influence the user's pedalling cadence.
C1 [Rojo, Ana; Raya, Rafael] Univ San Pablo CEU, Madrid, Spain.
   [Rojo, Ana; Moreno, Juan C.] Spanish Natl Res Council, Cajal Inst, Madrid, Spain.
C3 San Pablo CEU University; Consejo Superior de Investigaciones
   Cientificas (CSIC); CSIC - Instituto Cajal (IC)
RP Moreno, JC (corresponding author), Spanish Natl Res Council, Cajal Inst, Madrid, Spain.
EM jc.moreno@csic.es
RI Raya, Rafael/AFR-7593-2022; Moreno, Juan C./G-3622-2016
OI Raya, Rafael/0000-0001-7176-6984; Moreno, Juan C./0000-0001-9561-7764;
   Rojo Agusti, Ana/0000-0002-3047-5731
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Bayon M., 2010, REHABILITACION, V44, P256, DOI [10.1016/j.rh.2009.11.005, DOI 10.1016/J.RH.2009.11.005]
   BIKE B, 2022, BOD BIK IND CYCL APP
   Bini R, 2021, P INT C BIOM SPORTS, P1
   Cardoso VF, 2019, IFMBE PROC, V70, P315, DOI 10.1007/978-981-13-2119-1_48
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Chen S, 2017, LECT NOTES ELECTR EN, V399, P211, DOI 10.1007/978-981-10-2404-7_17
   Costa V, 2020, PEERJ, V8, DOI 10.7717/peerj.9687
   De Roeck J, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.696360
   Dimbwadyo-Terrer I, 2016, DISABIL REHABIL-ASSI, V11, P462, DOI 10.3109/17483107.2015.1027293
   Ebrahim S, 2000, BRIT MED BULL, V56, P557, DOI 10.1258/0007142001903201
   ERICSON M O, 1988, Journal of Orthopaedic and Sports Physical Therapy, V9, P273
   Farahani Navid, 2016, J Pathol Inform, V7, P22, DOI 10.4103/2153-3539.181766
   Ferrante S, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-47
   Ferreira J, 2019, MEDITERRANEAN C MEDI, P1696
   Frioriksson F. A., 2016, ICAT EGVE POST DEM, P19
   Fung J, 2006, CYBERPSYCHOL BEHAV, V9, P157, DOI 10.1089/cpb.2006.9.157
   Grani F, 2017, 2017 IEEE 3RD WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR)
   Group IC, 2022, US
   Guo BJ, 2017, LECT NOTES ARTIF INT, V10464, P506, DOI 10.1007/978-3-319-65298-6_46
   Argüello-Prada EJ, 2019, REV FAC ING-UNIV ANT, P42, DOI 10.17533/udea.redin.n90a06
   Johnston TE, 2007, PHYS THER, V87, P1243, DOI 10.2522/ptj.20060210
   Kaplan O, 2019, CVIM216 IPSJ RES REP
   Karashchuk P, 2021, CELL REP, V36, DOI 10.1016/j.celrep.2021.109730
   Kim A, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0584-y
   Larsson L, 2019, PHYSIOL REV, V99, P427, DOI 10.1152/physrev.00061.2017
   Lin SI, 2012, J ELECTROMYOGR KINES, V22, P582, DOI 10.1016/j.jelekin.2012.03.009
   Maillot P, 2012, PSYCHOL AGING, V27, P589, DOI 10.1037/a0026268
   Mirelman A, 2011, J GERONTOL A-BIOL, V66, P234, DOI 10.1093/gerona/glq201
   OneLap, 2022, ON LAP FIT
   Peng CW, 2011, J MED BIOL ENG, V31, P1, DOI 10.5405/jmbe.718
   Piazza S, 2018, MED BIOL ENG COMPUT, V56, P1425, DOI 10.1007/s11517-018-1787-2
   Premerlani W., 2009, Direction Cosine Matrix IMU: Theory, P1
   Ribeiro N.F., 2017, 5 PORTUGUESE M BIOEN, P1, DOI DOI 10.1109/ENBENG.2017.7889458
   Shema SR, 2014, PHYS THER, V94, P1319, DOI 10.2522/ptj.20130305
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Software SC, 2021, US
   Strava, 2022, US
   Valenzuela PL, 2019, COMPR PHYSIOL, V9, P1281, DOI 10.1002/cphy.c190002
   Viñas-Diz S, 2016, NEUROLOGIA, V31, P255, DOI 10.1016/j.nrl.2015.06.012
   Weir JP, 2005, J STRENGTH COND RES, V19, P231, DOI 10.1519/15184.1
   World VC, 2022, VIRT CYCL WORLD APP
   Wu G, 2002, J BIOMECH, V35, P543, DOI 10.1016/S0021-9290(01)00222-6
   Yang HC, 2014, KAOHSIUNG J MED SCI, V30, P35, DOI 10.1016/j.kjms.2013.07.006
   Yang YR, 2008, GAIT POSTURE, V28, P201, DOI 10.1016/j.gaitpost.2007.11.007
NR 44
TC 2
Z9 2
U1 3
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 3
EP 17
DI 10.1007/s10055-022-00668-w
EA JUL 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000825913100001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Benmahdjoub, M
   Niessen, WJ
   Wolvius, EB
   van Walsum, T
AF Benmahdjoub, Mohamed
   Niessen, Wiro J.
   Wolvius, Eppo B.
   van Walsum, Theo
TI Multimodal markers for technology-independent integration of augmented
   reality devices and surgical navigation systems
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Mixed reality; Navigation system; Calibration;
   Alignment; Surgical interventions; Feasibility studies
ID ORTHOGNATHIC SURGERY
AB Augmented reality (AR) permits the visualization of pre-operative data in the surgical field of view of the surgeon. This requires the alignment of the AR device's coordinate system with the used navigation/tracking system. We propose a multimodal marker approach to align an AR device with a tracking system: in our implementation, an electromagnetic tracking system (EMTS). The solution makes use of a calibration method which determines the relationship between a 2D pattern detected by an RGB camera and an electromagnetic sensor of the EMTS. This allowed the projection of a 3D skull model on its physical counterpart. This projection was evaluated using a monocular camera and an optical see-through device (HoloLens 2) (https://www.microsoft.conilen-us/hololens/) achieving an accuracy of less than 2.5 mm in the image plane of the HoloLens 2 (HL2). Additionally, 10 volunteers participated in a user study consisting of an alignment task of a pointer with 25 projections viewed through the HL2. The participants achieved a mean error of 2.7 1.3 mm and 2.9 2.9 degrees in positional and orientation error. This study showcases the feasibility of the approach, provides an evaluation of the alignment, and finally, discusses its advantages and limitations.
C1 [Benmahdjoub, Mohamed; Niessen, Wiro J.; van Walsum, Theo] Erasmus MC, Dept Radiol & Nucl Med, Biomed Imaging Grp Rotterdam, NL-3015 GE Rotterdam, Netherlands.
   [Benmahdjoub, Mohamed; Wolvius, Eppo B.] Erasmus MC, Dept Oral & Maxillofacial Surg, NL-3015 GE Rotterdam, Netherlands.
   [Niessen, Wiro J.] Delft Univ Technol, Fac Appl Sci, Dept Imaging Phys, Delft, Netherlands.
C3 Erasmus University Rotterdam; Erasmus MC; Erasmus University Rotterdam;
   Erasmus MC; Delft University of Technology
RP Benmahdjoub, M (corresponding author), Erasmus MC, Dept Radiol & Nucl Med, Biomed Imaging Grp Rotterdam, NL-3015 GE Rotterdam, Netherlands.; Benmahdjoub, M (corresponding author), Erasmus MC, Dept Oral & Maxillofacial Surg, NL-3015 GE Rotterdam, Netherlands.
EM m.benmandjoub@erasmusmc.nl; w.niessen@erasmusmc.nl;
   e.wovlius@erasmusmc.nl; t.vanwalsum@erasmusmc.nl
RI Benmahdjoub, Mohamed/HNS-5612-2023; van Walsum, Theo/ABM-1912-2022
OI Benmahdjoub, Mohamed/0000-0003-1830-2480; van Walsum,
   Theo/0000-0001-8257-7759
CR Azimi Ehsan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P65, DOI 10.1007/978-3-030-59716-0_7
   Azimi E, 2017, P IEEE VIRT REAL ANN, P219, DOI 10.1109/VR.2017.7892255
   Badiali G, 2014, J CRANIO MAXILL SURG, V42, P1970, DOI 10.1016/j.jcms.2014.09.001
   Banz VM, 2016, LANGENBECK ARCH SURG, V401, P495, DOI 10.1007/s00423-016-1417-0
   Benmahdjoub M, 2021, INT J ORAL MAX SURG, V50, P969, DOI 10.1016/j.ijom.2020.11.015
   Benmahdjoub M, 2021, IEEE T VIS COMPUT GR, V27, P4332, DOI 10.1109/TVCG.2021.3106506
   Berger M, 2015, J CRANIO MAXILL SURG, V43, P1731, DOI 10.1016/j.jcms.2015.08.022
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   Chotanaphuti Thanainit, 2008, Journal of the Medical Association of Thailand, V91, P1382
   Cleary K, 2010, ANNU REV BIOMED ENG, V12, P119, DOI 10.1146/annurev-bioeng-070909-105249
   Do TD, 2020, PROCEEDINGS2020 IEEE, P6472
   Eggers G, 2009, DENTOMAXILLOFAC RAD, V38, P28, DOI 10.1259/dmfr/26098099
   Gavaghan K, 2012, INT J COMPUT ASS RAD, V7, P547, DOI 10.1007/s11548-011-0660-7
   Genc Y, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P169, DOI 10.1109/ISMAR.2002.1115086
   Gsaxner C, 2019, LECT NOTES COMPUT SC, V11768, P236, DOI 10.1007/978-3-030-32254-0_27
   Hara T, 2020, WORLD NEUROSURG, V134, P378, DOI 10.1016/j.wneu.2019.10.176
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Incekara F, 2018, WORLD NEUROSURG, V118, pE422, DOI 10.1016/j.wneu.2018.06.208
   Itoh Y, 2014, INT SYM MIX AUGMENT, P171, DOI 10.1109/ISMAR.2014.6948424
   Jiang TR, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36457-2
   Khenak N, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.588217
   Kuzhagaliyev T, 2018, PROC SPIE, V10576, DOI 10.1117/12.2293671
   Lewis JR, 2011, Aligning interpupillary distance in a near-eye display system, Patent No. [20130050642A1, 20130050642]
   Li Y, 2019, J NEUROSURG, V131, P1599, DOI 10.3171/2018.4.JNS18124
   Makibuchi N, 2013, IEEE IMAGE PROC, P2177, DOI 10.1109/ICIP.2013.6738449
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P217, DOI [10.1109/ISMAR50242.2020.00045, 10.1109/1SMA1R50242.2020.00045]
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P207, DOI [10.1109/ISMAR50242.2020.00044, 10.1109/1SMA1R50242.2020.00044]
   Meulstee JW, 2019, SURG INNOV, V26, P86, DOI 10.1177/1553350618799552
   Mezger U, 2013, LANGENBECK ARCH SURG, V398, P501, DOI 10.1007/s00423-013-1059-4
   Ping JM, 2020, J SOC INF DISPLAY, V28, P892, DOI 10.1002/jsid.947
   Singh Gurjot., 2010, Proceedings of the 7th Symposium on Applied Perception in Graphics and Visualization, P149, DOI DOI 10.1145/1836248.1836277
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Tuceryan M, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P149, DOI 10.1109/ISAR.2000.880938
   Vuforia, 2020, US
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   Zhu M, 2018, J PLAST RECONSTR AES, V71, P1188, DOI 10.1016/j.bjps.2018.03.018
   Zhu M, 2017, SCI REP-UK, V7, DOI 10.1038/srep42365
   Zinser MJ, 2013, BRIT J ORAL MAX SURG, V51, P827, DOI 10.1016/j.bjoms.2013.06.014
NR 39
TC 8
Z9 8
U1 1
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1637
EP 1650
DI 10.1007/s10055-022-00653-3
EA MAY 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000805538800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Park, H
   Shakeri, M
   Jeon, I
   Kim, J
   Sadeghi-Niaraki, A
   Woo, W
AF Park, Hyerim
   Shakeri, Maryam
   Jeon, Ikbeom
   Kim, Jangyoon
   Sadeghi-Niaraki, Abolghasem
   Woo, Woontack
TI Spatial transition management for improving outdoor cinematic augmented
   reality experience of the TV show
SO VIRTUAL REALITY
LA English
DT Article
DE Cinematic augmented reality; Augmented reality; Trajectory; Continuity
ID LOCATION
AB There have been attempts to provide new cinematic experiences by connecting TV or movie content to suitable locations through augmented reality (AR). However, few studies have suggested a method to manage breakdowns in continuity due to spatial transitions. Thus, we propose a method to manage the spatial transition that occurs when we create a TV show trajectory by mapping TV show scenes with spatiotemporal information to the real world. Our approach involved two steps. The first step is to reduce the spatial transition considering the sequence, location, and importance of TV show scenes when creating the TV show trajectory in the authoring tool. The second is to fill the spatial transition with additional TV show scenes considering sequence, importance, and user interest when providing the TV show trajectory in the mobile application. The user study results showed that reducing spatial transition increases narrative engagement by allowing participants to see important content within the trajectory. The additional content in spatial transition decreased the physical demand and effort in terms of the perceived workload, although it increased the task completion time. Integrated spatial transition management improved the overall cinematic augmented reality (CAR) experience of the TV show. Furthermore, we suggest design implications for realizing the CAR of TV shows based on our findings.
C1 [Park, Hyerim; Jeon, Ikbeom; Woo, Woontack] Korea Adv Inst Sci & Technol, UVR Lab, 2325,N5,291 Daehak Ro, Daejeon, South Korea.
   [Shakeri, Maryam; Kim, Jangyoon; Woo, Woontack] Korea Adv Inst Sci & Technol, KI ITC Augmented Real Res Ctr, 303,E4,291 Daehak Ro, Daejeon, South Korea.
   [Shakeri, Maryam] KN Toosi Univ Technol, Geodesy & Geomat Engn, Tehran, Iran.
   [Sadeghi-Niaraki, Abolghasem] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Sadeghi-Niaraki, Abolghasem] Sejong Univ, Convergence Engn Intelligent Drone, Seoul, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); K. N. Toosi University of
   Technology; Sejong University; Sejong University
RP Woo, W (corresponding author), Korea Adv Inst Sci & Technol, UVR Lab, 2325,N5,291 Daehak Ro, Daejeon, South Korea.; Woo, W (corresponding author), Korea Adv Inst Sci & Technol, KI ITC Augmented Real Res Ctr, 303,E4,291 Daehak Ro, Daejeon, South Korea.
EM wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012; Sadeghi-Niaraki, Abolghasem/AAS-8441-2020
OI Woo, Woontack/0000-0002-5501-4421; Sadeghi-Niaraki,
   Abolghasem/0000-0002-0048-8216; PARK, HYERIM/0000-0001-6764-4490
FU Institute of Information & Communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2019-0-01270]; Ministry of
   Culture, Sports and Tourism; Korea Creative Content Agency [R2021080001]
FX This work was supported by the Institute of Information & Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2019-0-01270, WISE AR UI/UX Platform Development
   for Smartglasses).; This research is supported by Ministry of Culture,
   Sports and Tourism and Korea Creative Content Agency (Project Number:
   R2021080001).
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   [Anonymous], 2014, P 2014 C DES INT SYS, DOI DOI 10.1145/2598510.2600881
   Balakrishnan B, 2011, HUM-COMPUT INTERACT, V26, P161, DOI 10.1080/07370024.2011.601689
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Baume, 2017, SMPTE MOTION IMAG J, V126, P1, DOI [10.5594/JMI.2017.2709859, DOI 10.5594/JMI.2017.2709859]
   Beeton S, 2006, COMMUNITY DEVELOPMENT THROUGH TOURISM, P1
   Beeton S, 2008, J TRAVEL TOUR MARK, V24, P107, DOI 10.1080/10548400802092551
   Benford S, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1993060.1993061
   Benford S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P73
   Benford S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P709
   Busselle R, 2009, MEDIA PSYCHOL, V12, P321, DOI 10.1080/15213260903287259
   Cao C, 2020, INT SYM MIX AUGMENT, P600, DOI 10.1109/ISMAR50242.2020.00087
   Caquard S, 2014, J MAPS, V10, P18, DOI 10.1080/17445647.2013.847387
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Dow S., 2006, P ACM SIGCHI INT C A, V1, P28, DOI [10.1145/1178823.1178858, DOI 10.1145/1178823.1178858]
   Du RF, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300915
   Fosh Lesley., 2013, PROC CHI 13, P149, DOI DOI 10.1145/2470654.2470675
   Gao HJ, 2015, AAAI CONF ARTIF INTE, P1721
   Haahr M, 2010, NEW HORIZONS WEB BAS, P11, DOI [10.1007/978-3-642-20539-2_2, DOI 10.1007/978-3-642-20539-2_2]
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Hansen FA, 2012, NEW REV HYPERMEDIA M, V18, P63, DOI 10.1080/13614568.2012.617842
   Hargood C, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P128, DOI 10.1145/3209542.3209559
   Hargood C, 2017, LECT NOTES COMPUT SC, V10345, P85, DOI 10.1007/978-3-319-65849-0_10
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hesham M, 2018, PROCEEDINGS OF 2018 FIRST INTERNATIONAL WORKSHOP ON DEEP AND REPRESENTATION LEARNING (IWDRL), P26, DOI 10.1109/IWDRL.2018.8358211
   Hunter J, 1999, COMPUT NETW, V31, P1431, DOI 10.1016/S1389-1286(99)00053-5
   Hyerim Park, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P388, DOI 10.1109/ICCE.2017.7889365
   Irie G., 2010, P 18 ACM INT C MULTI, P839
   Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Kim S., 2012, International Communication Gazette, V74, P423, DOI DOI 10.1177/1748048512445152
   Kim S, 2016, ASIA PAC J TOUR RES, V21, P524, DOI 10.1080/10941665.2015.1068189
   Kim S, 2012, CURR ISSUES TOUR, V15, P759, DOI 10.1080/13683500.2011.640394
   Kim SH, 2018, INT CONF ADV COMMUN, P664, DOI 10.23919/ICACT.2018.8323876
   Kukka H, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P2422, DOI 10.1145/2998181.2998341
   Leidner J.L., 2011, SIGSPATIAL SPECIAL, V3, P5, DOI [DOI 10.1145/2047296.2047298, 10.1145/2047296.2047298]
   Liestol G, 2014, LECT NOTES COMPUT SC, V8740, P248, DOI 10.1007/978-3-319-13695-0_24
   MacIntyre B, 2003, P INT C TECHN INT DI, P230, DOI DOI 10.1109/ISAR.2001.970538
   MacIntyre Blair, 2002, ACM SIGGRAPH 2002 C, P268, DOI [10.1145/1242073.1242281, DOI 10.1145/1242073.1242281]
   MacQuarrie A, 2017, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2017.7892230
   McKercher B., 2003, International Journal of Tourism Research, V5, P45, DOI 10.1002/jtr.417
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mine M, 2012, COMPUTER, V45, P32, DOI 10.1109/MC.2012.154
   Nisi V, 2017, INTERACT COMPUT, V29, P287, DOI 10.1093/iwc/iww020
   Packer HS, 2017, LECT NOTES COMPUT SC, V10690, P63, DOI 10.1007/978-3-319-71027-3_6
   Park H, 2018, 2018 INT S ANTENNAS, P1
   Park H, 2018, LECT NOTES COMPUT SC, V10905, P167, DOI 10.1007/978-3-319-92046-7_15
   Park H, 2015, INT SYM MIX AUGMENT, P40, DOI 10.1109/ISMAR-MASHD.2015.12
   Pratten R., 2011, GETTING STARTED TRAN
   Russell C, 2014, LECT NOTES COMPUT SC, V8695, P583, DOI 10.1007/978-3-319-10584-0_38
   Shin J, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2966991
   Singh A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P713, DOI 10.1109/VR50410.2021.00098
   Spierling U, 2014, LECT NOTES COMPUT SC, V8832, P196, DOI 10.1007/978-3-319-12337-0_20
   Torchin L., 2002, Tourist Studies, V2, P247, DOI 10.1177/14687976020023002
   Tsai CH, 2018, COMPUT STAND INTER, V55, P171, DOI 10.1016/j.csi.2017.08.003
   Tung W.F., 2015, MOBILE SERVICES TOY, P129, DOI [10.1007/978-3-319-21323-1_7, DOI 10.1007/978-3-319-21323-1_7]
   Vatavu RD, 2020, PROCEEDINGS OF THE 2020 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2020, P1, DOI 10.1145/3391614.3393660
   Vorderer P., 2004, Mec spatial presence questionnaire
   Wither J., 2010, Proceedings of the 2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH). Science and Technology, P39, DOI 10.1109/ISMAR-AMH.2010.5643295
   Woo, 2018 3 DIG HER INT C, P1, DOI [10.1109/DigitalHeritage.2018.8810093, DOI 10.1109/DIGITALHERITAGE.2018.8810093]
NR 62
TC 4
Z9 4
U1 4
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1059
EP 1077
DI 10.1007/s10055-021-00617-z
EA JAN 2022
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000739737800001
PM 35013665
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chen, CY
   Chuang, CH
   Tsai, TL
   Chen, HW
   Wu, PJ
AF Chen, Chen-Yu
   Chuang, Chih-Hao
   Tsai, Ting-Lan
   Chen, Hung-Wei
   Wu, Pei-Jung
TI Reducing cybersickness by implementing texture blur in the virtual
   reality content
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cybersickness; Human factor; Texture blur
ID NAVIGATION; DEPTH
AB Virtual reality facilities have matured in recent years; however, cybersickness has yet remained a major issue in the virtual reality content. The researchers in this study attempt to simulate the different focal points and depth of field of human vision with an eye on reducing cybersickness by implementing blurring. This paper introduces a new type of technology-texture blur, which was tested in three experiments with different contents in this study. The participants were asked to verbally answer two questionnaires: a discomfort level questionnaire and a simulator sickness questionnaire (SSQ). The results were analyzed to compare the seriousness of the participants' cybersickness with and without texture blur in the virtual reality content. The experiment results revealed that the participants with texture blur had lower discomfort level scores. The SSQ results also went in line with the previous questionnaire, showing better results with texture blur. Hence, the researchers concluded that texture blur can effectively reduce users' cybersickness in virtual reality content.
C1 [Chen, Chen-Yu; Tsai, Ting-Lan; Chen, Hung-Wei] Natl Taiwan Univ Sci & Technol, Grad Inst Color & Illuminat Technol, Taipei, Taiwan.
   [Chuang, Chih-Hao] Natl Taiwan Univ, Grad Inst Photon & Optoelect, Taipei, Taiwan.
   [Wu, Pei-Jung] Natl Taichung Univ Sci & Technol, Ctr Gen Educ, Taichung, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University; National Taichung University of Science & Technology
RP Chen, CY (corresponding author), Natl Taiwan Univ Sci & Technol, Grad Inst Color & Illuminat Technol, Taipei, Taiwan.
EM chencyue@mail.ntust.edu.tw
CR Alger M., 2015, Visual Design Methods for Virtual Reality
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Fisher RA, 1936, BMJ-BRIT MED J, V1936, P554
   Hillaire S, 2008, IEEE COMPUT GRAPH, V28, P47, DOI 10.1109/MCG.2008.113
   HU S, 1991, AVIAT SPACE ENVIR MD, V62, P53
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   PONDER ERIC, 1927, QUART JOUR EXP PHYSIOL, V18, P89
   Porcino TM, 2017, IEEE INT CONF SERIOU
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
NR 18
TC 1
Z9 1
U1 2
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 789
EP 800
DI 10.1007/s10055-021-00587-2
EA OCT 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000705798400002
DA 2024-07-18
ER

PT J
AU Mouhou, AA
   Saaidi, A
   Ben Yakhlef, M
   Abbad, K
AF Ait Mouhou, Abderrazzak
   Saaidi, Abderrahim
   Ben Yakhlef, Majid
   Abbad, Khalid
TI 3D garment positioning using Hermite radial basis functions
SO VIRTUAL REALITY
LA English
DT Article
DE Cloth simulation; Garment positioning; Virtual fitting system; Implicit
   modeling; Skeleton-driven deformation
ID DESIGN AUTOMATION
AB Fitting an elegant 3D garment model onto a target 3D human model is crucial for garment design industry and virtual try-on systems. The alignment of the garment onto virtual try-on systems is currently the main limitation to propose an efficient virtual try-on system without use of reference body. We propose a new system of fitting a given garment onto a target human body with various shapes and postures. The key novelty of our work is the use of Hermite radial basis functions to approximate and to deform the garment mesh to fit the posture of the target human body. After the garment deformation, we adjust the global orientation of the garment based on the key joints of the garment skeleton and human skeleton. Thus, the garment model is positioned automatically around human body. We resolve the potential interpenetration between the human model and the garment using collision handling algorithm. We perform wrinkle synthesis of the garment to generate a natural and realistic shape. Our fitting method is effective for garment transfer, and the results obtained demonstrate that it produces believable fitting data and it is very satisfactory in terms of performance.
C1 [Ait Mouhou, Abderrazzak; Saaidi, Abderrahim; Ben Yakhlef, Majid] Sidi Mohamed Ben Abdellah Univ, FP Taza, Fes, Morocco.
   [Abbad, Khalid] Sidi Mohamed Ben Abdellah Univ, FST Fez, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Mouhou, AA (corresponding author), Sidi Mohamed Ben Abdellah Univ, FP Taza, Fes, Morocco.
EM a.aitmouhou@gmail.com; abderrahim.saaidi@usmba.ac.ma;
   majid.benyakhlef@usmba.ac.ma; khalid.abbad@usmba.ac.ma
OI abderrazzak, ait mouhou/0000-0002-6903-0860; khalid,
   abbad/0000-0002-4929-1967; BEN YAKHLEF, Majid/0000-0002-6696-9426
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bartle A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925896
   Berger M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451246
   Bernhardt A, 2010, COMPUT GRAPH FORUM, V29, P367, DOI 10.1111/j.1467-8659.2009.01606.x
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Brouet R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185532
   Clegg A, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275048
   Gourmel O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451238
   Guan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185531
   Gültepe U, 2014, COMPUT GRAPH-UK, V43, P31, DOI 10.1016/j.cag.2014.06.001
   Gundogdu E, 2019, IEEE I CONF COMP VIS, P8738, DOI 10.1109/ICCV.2019.00883
   Hu PP, 2020, TEXT RES J, V90, P2161, DOI 10.1177/0040517520909995
   Huang LC, 2016, VISUAL COMPUT, V32, P705, DOI 10.1007/s00371-016-1236-x
   Jiang LG, 2019, COMPUT AIDED DESIGN, V106, P30, DOI 10.1016/j.cad.2018.08.002
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Lee Y, 2013, COMPUT GRAPH-UK, V37, P911, DOI 10.1016/j.cag.2013.07.005
   Li D, 2019, J ENG FIBER FABR, V14, DOI 10.1177/1558925018825319
   Li JT, 2013, TEXT RES J, V83, P519, DOI 10.1177/0040517512450758
   Li JT, 2011, COMPUT IND, V62, P693, DOI 10.1016/j.compind.2011.04.002
   Li JT, 2010, COMPUT GRAPH-UK, V34, P742, DOI 10.1016/j.cag.2010.07.008
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201310
   Liu JD, 1996, VISUAL COMPUT, V12, P234
   Liu SJ, 2016, COMPUT AIDED DESIGN, V78, P147, DOI 10.1016/j.cad.2016.05.001
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Macêdo I, 2011, COMPUT GRAPH FORUM, V30, P27, DOI 10.1111/j.1467-8659.2010.01785.x
   MakeHuman, Open Source Tool for Making 3D Characters
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P68, DOI 10.1016/j.cad.2010.11.008
   Mouhou AA, 2021, MULTIMED TOOLS APPL, V80, P1583, DOI 10.1007/s11042-020-09743-3
   Narain R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366171
   Parent, 1995, P IMPLICIT SURFACES
   Pasko GI, 2005, IEEE COMPUT GRAPH, V25, P36, DOI 10.1109/MCG.2005.37
   PONSMOLL G, 2017, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/3072959.3073711
   RICCI A, 1973, COMPUT J, V16, P157, DOI 10.1093/comjnl/16.2.157
   Shi GY, 2021, VISUAL COMPUT, V37, P1075, DOI 10.1007/s00371-020-01853-1
   Tisserand Y, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1770
   Umetani N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964985
   Vaillant R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461960
   van Overveld CWAM, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P214, DOI 10.1109/CGI.1999.777957
   Volker L, 2003, AUTOMATIC PREPOSITIO, P99, DOI [10.1145/984952.984970, DOI 10.1145/984952.984970]
   Wang CCL, 2005, COMPUT AIDED DESIGN, V37, P675, DOI 10.1016/j.cad.2004.08.007
   Wang CCL, 2007, IEEE T AUTOM SCI ENG, V4, P11, DOI 10.1109/TASE.2006.872112
   White KB, 2007, RT07: IEEE/EG Symposium on Interactive Ray Tracing 2007, P129, DOI 10.1109/RT.2007.4342600
   Wu NN, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1811
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   Ye JT, 2017, COMPUT GRAPH FORUM, V36, P217, DOI 10.1111/cgf.13287
   Zhang DL, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P328, DOI 10.1109/PCCGA.2000.883956
   Zhong YQ., 2008, J FIBER BIOENGINEERI, V1, P21, DOI [10.3993/jfbi06200804, DOI 10.3993/JFBI06200804]
   Zhong YQ, 2009, TEXT RES J, V79, P792, DOI 10.1177/0040517508090779
NR 49
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 295
EP 322
DI 10.1007/s10055-021-00566-7
EA AUG 2021
PG 28
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000681547600002
DA 2024-07-18
ER

PT J
AU Atsikpasi, P
   Fokides, E
AF Atsikpasi, Penelope
   Fokides, Emmanuel
TI A scoping review of the educational uses of 6DoF HMDs
SO VIRTUAL REALITY
LA English
DT Review
DE Education; Degrees of freedom; Fully immersive virtual reality;
   Head-mounted displays; Scoping review
ID IMMERSIVE VIRTUAL-REALITY; HEAD-MOUNTED DISPLAYS; OF-THE-ART;
   ENVIRONMENTS; EXPERIENCES; GAME
AB Head-mounted displays offering 6 degrees of freedom have not been sufficiently researched in terms of their impact on users' learning and skills. The issue is multi-dimensional, heterogeneous, and complex. The paper presents a scoping review aiming to map and review the existing literature on the matter. The areas in which they have been mostly used, the benefits, and the negative effects they may have had, were examined. Eighty-seven articles were identified and analyzed. Out of them, only fourteen were considered as having adequate statistical power. Most had relatively small sample sizes and number of interventions, while university students were the most frequent target group. The review identified a total of twenty-seven distinct learning domains in which head-mounted displays offering six degrees of freedom were applied, with medical science being the most common one. The results in the reviewed papers (in terms of knowledge or skills) demonstrated that these devices outperform other tools. Moreover, they appear to have a positive effect on users' engagement, motivation to learn, immersion, and enjoyment.
C1 [Atsikpasi, Penelope; Fokides, Emmanuel] Univ Aegean, Dept Primary Educ, Rhodes, Greece.
C3 University of Aegean
RP Fokides, E (corresponding author), Univ Aegean, Dept Primary Educ, Rhodes, Greece.
EM fokides@aegean.gr
OI Fokides, Emmanuel/0000-0003-3962-0314
CR Abdul Rahim E., 2012, P 24 AUSTR COMP HUM, DOI [10.1145/2414536.2414537, DOI 10.1145/2414536.2414537]
   Ahn SJ, 2014, COMPUT HUM BEHAV, V39, P235, DOI 10.1016/j.chb.2014.07.025
   Akbulut A, 2018, COMPUT APPL ENG EDUC, V26, P918, DOI 10.1002/cae.21935
   Almousa O, 2019, SIMULAT GAMING, V50, P6, DOI 10.1177/1046878118820905
   Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [10.1080/1364557032000119616, DOI 10.1080/1364557032000119616]
   Bertrand J, 2017, IEEE SYMP 3D USER, P59, DOI 10.1109/3DUI.2017.7893318
   Bibic L, 2019, J CHEM EDUC, V96, P1486, DOI 10.1021/acs.jchemed.8b00905
   Blignaut, 2016, P EDMEDIA INN LEARN, P1696
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bradley R, 2018, J ENABLING TECHNOL, V12, P101, DOI 10.1108/JET-01-2018-0004
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Budhiraja Pulkit., 2017, Rotation Blurring: Use of Artificial Blurring to Reduce Cybersickness in Virtual Reality First Person Shooters
   Bun P, 2015, PROCEDIA COMPUT SCI, V75, P173, DOI 10.1016/j.procs.2015.12.235
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Calvert J, 2020, COMPUT EDUC, V159, DOI 10.1016/j.compedu.2020.104005
   Checa D, 2020, VIRTUAL REAL-LONDON, V24, P151, DOI 10.1007/s10055-019-00389-7
   Cheung, 2013, HYBRID LEARNING CONT
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Daudt HML, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-48
   de Oliveira EC, 2016, SYMP VIRTUAL AUGMENT, P81, DOI 10.1109/SVR.2016.23
   Duchowski A.T., 2014, P ACM S APPL PERC, P39, DOI DOI 10.1145/2628257.2628259
   Dues J.F., 2017, ASEE ANN C EXP
   Fabola A, 2016, COMM COM INF SC, V621, P59, DOI 10.1007/978-3-319-41769-1_5
   Faiola A, 2013, COMPUT HUM BEHAV, V29, P1113, DOI 10.1016/j.chb.2012.10.003
   Falah J, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P752, DOI 10.1109/SAI.2014.6918271
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferracani A., 2014, P 2014 ACM INT WORKS, P27
   Fokides E, 2020, J INF TECHNOL EDUC-R, V19, P427, DOI 10.28945/4612
   Fokides E, 2018, EDUC INF TECHNOL, V23, P2265, DOI 10.1007/s10639-018-9719-1
   Fokides E, 2017, J INF TECHNOL EDUC-R, V16, P47
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Freina L, 2016, J E-LEARN KNOWL SOC, V12, P101
   GARCIA S, 2019, P C HUM FACT COMP SY, DOI DOI 10.1145/3290607.3313253
   Gerjets P, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00385
   Gieser Shawn N., 2013, P 6 INT C PERVASIVE, P1, DOI [10.1145/2504335.2504367, DOI 10.1145/2504335.2504367]
   Glaser NJ, 2020, TECHNOL KNOWL LEARN, V25, P315, DOI 10.1007/s10758-018-9369-9
   Harrington MCR, 2012, VIRTUAL REAL-LONDON, V16, P105, DOI 10.1007/s10055-011-0189-7
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Juliano J, 2019, PEDIATR NEUROSURG, V54, P173, DOI 10.1159/000493194
   Karageorgakis T., 2018, The Cyprus Review, V30, P381
   Kasahara S., 2014, P ADJUNCT PUBLICATIO, V2, P61
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Klippel Alexander., 2019, Immersive Learning Research Network: Communications in Computer and Information Science, Vvol. 1044, P506, DOI [10.1007/978-3-030-23089-0_1, DOI 10.1007/978-3-030-23089-0_1]
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lin SC, 2018, 2018 7TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2018), P948, DOI 10.1109/IIAI-AAI.2018.00195
   Liu RX, 2020, BRIT J EDUC TECHNOL, V51, P2034, DOI 10.1111/bjet.13028
   Loup G, 2016, LECT NOTES COMPUT SC, V9891, P410, DOI 10.1007/978-3-319-45153-4_35
   Madden J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229788
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   MAYS N., 2001, Studying the organisation and delivery of health services: research methods, P188, DOI DOI 10.4324/9780203481981
   McKenzie S., 2019, ISSUES INFORM SCI IN, V16, P211, DOI [10.28945/4318, DOI 10.28945/4318]
   McLellan H., 2004, Handbook of Research on Educational Communications and Technology
   Moesgaard T, 2015, PROC EUR CONF GAME, P387
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Queiroz ACM, 2018, COMM COM INF SC, V840, P160, DOI 10.1007/978-3-319-93596-6_11
   Munn Z, 2018, BMC MED RES METHODOL, V18, DOI 10.1186/s12874-017-0468-4
   Newbutt N, 2020, CYBERPSYCH BEH SOC N, V23, P23, DOI 10.1089/cyber.2019.0206
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Olmos E., 2018, Mobile and ubiquitous learning, P95, DOI DOI 10.1007/978-981-10-6144-86
   Papadakis G, 2011, P 10 INT C VIRT REAL, P581, DOI [DOI 10.1145/2087756.2087869, 10.1145/2087756.2087869]
   Passig D, 2016, COMPUT EDUC, V95, P296, DOI 10.1016/j.compedu.2016.01.009
   Pirker J, 2018, LECT NOTE NETW SYST, V22, P1029, DOI 10.1007/978-3-319-64352-6_95
   Pirker J, 2017, IEEE INT CONF ADV LE, P482, DOI 10.1109/ICALT.2017.92
   Pollard KA, 2020, VIRTUAL REAL-LONDON, V24, P783, DOI 10.1007/s10055-019-00411-y
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Ray AB, 2016, IEEE CONF TECHNOL ED, P68, DOI [10.1109/T4E.2016.022, 10.1109/T4E.2016.21]
   Reed DA, 2007, JAMA-J AM MED ASSOC, V298, P1002, DOI 10.1001/jama.298.9.1002
   Ritter K., 2018, The ASEE Computers in Education (CoED) Journal, V9, P1
   Ropelato S., 2018, International Series on Information Systems and Management in Creative EMedia (CreMedia), V2017, P12, DOI DOI 10.3929/ETHZ-B-000195951
   Royall R.M., 1997, Statistical Evidence: A likelihood paradigm
   Rupp M., 2016, P HUMAN FACTORS ERGO, V60, P2108, DOI [DOI 10.1177/1541931213601477, 10.1177/1541931213601477, https://doi.org/10.1177/1541931213601477]
   Rupp MA, 2019, COMPUT EDUC, V128, P256, DOI 10.1016/j.compedu.2018.09.015
   Ryan Marie-Laure., 2001, NARRATIVE VIRTUAL RE
   Salamin A. D, 2018, EDMEDIA INNOVATE LEA, P1565
   Schneps MH, 2014, COMPUT EDUC, V70, P269, DOI 10.1016/j.compedu.2013.09.001
   Schwaab J, 2011, ACAD EMERG MED, V18, P558, DOI 10.1111/j.1553-2712.2011.01064.x
   Shackelford L., 2018, E LEARN, P605
   Shaw LindsayAlexander., 2015, Australasian Workshop on Health Informatics and Knowledge Management (HIKM), P75
   Shi YM, 2020, AUTOMAT CONSTR, V119, DOI 10.1016/j.autcon.2020.103367
   Singer LM, 2017, REV EDUC RES, V87, P1007, DOI 10.3102/0034654317722961
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2007, IEEE COMPUT GRAPH, V27, P90, DOI 10.1109/MCG.2007.93
   Slykhuis, 2015, P SOC INF TECHN TEAC, P769
   Smutny P, 2019, 2019 20TH INTERNATIONAL CARPATHIAN CONTROL CONFERENCE (ICCC), P149, DOI 10.1109/carpathiancc.2019.8765930
   Snelson C, 2020, TECHTRENDS, V64, P404, DOI 10.1007/s11528-019-00474-3
   Sportillo D, 2018, ACCIDENT ANAL PREV, V118, P102, DOI 10.1016/j.aap.2018.06.003
   Staurset EM, 2016, SMART INNOV SYST TEC, V59, P423, DOI 10.1007/978-3-319-39690-3_38
   Stepan K, 2017, INT FORUM ALLERGY RH, V7, P1006, DOI 10.1002/alr.21986
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stevens J, 2015, J DEF MODEL SIMUL-AP, V12, P519, DOI 10.1177/1548512915569742
   Stranger-Johannessen E, 2018, LECT NOTES COMPUT SC, V11082, P613, DOI 10.1007/978-3-319-98572-5_57
   Sucharew H, 2019, J HOSP MED, V14, P416, DOI 10.12788/jhm.3248
   Tamaddon K, 2017, 2017 IEEE VIRTUAL REALITY WORKSHOP ON K-12 EMBODIED LEARNING THROUGH VIRTUAL & AUGMENTED REALITY (KELVAR)
   Teranishi S., 2018, J ED MULTIMED HYPERM, V27, P411
   Thompson-Butel AG, 2019, J STROKE CEREBROVASC, V28, P450, DOI 10.1016/j.jstrokecerebrovasdis.2018.10.018
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhang K, 2017, FED CONF COMPUT SCI, P1297, DOI 10.15439/2017F376
   Zhou C, 2020, IEEE ACCESS, V8, P73791, DOI 10.1109/ACCESS.2020.2988678
   Zhou Y, 2018, PROCEDIA COMPUT SCI, V130, P239, DOI 10.1016/j.procs.2018.04.035
NR 105
TC 8
Z9 9
U1 2
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 205
EP 222
DI 10.1007/s10055-021-00556-9
EA JUN 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000668400700001
DA 2024-07-18
ER

PT J
AU Ritter, KA
   Chambers, TL
AF Ritter, K. A., III
   Chambers, Terrence L.
TI Three-dimensional modeled environments versus 360 degree panoramas for
   mobile virtual reality training
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual training; Virtual reality; Virtual laboratories; Virtual field
   trip
ID EDUCATION; SYSTEM; SCIENCE
AB Virtual field trip is a way of providing users with some knowledge and exposure of a facility without requiring them to physically visit the location. Due to the high computational costs that are necessary to produce virtual environments (VEs), the potential for photorealism is sacrificed. Often these three-dimensional (3D) modeled applications use an unrealistic VE and, therefore, do not provide a full depiction of real-world environments. Panoramas can be used to showcase complex scenarios that are difficult to model and are computationally expensive to view in virtual reality (VR). Utilizing 360 degrees panoramas can provide a low-cost and quick-to-capture alternative with photorealistic representations of the actual environment. The advantages of photorealism over 3D models for training and education are not clearly defined. This paper initially summarizes the development of a VR training application and initial pilot study. Quantitative and qualitative study then was conducted to compare the effectiveness of a 360 degrees panorama VR training application and a 3D modeled one. Switching to a mobile VR headset saves money, increases mobility, decreases set-up and breakdown time, and has less spatial requirements. Testing results of the 3D modeled VE group had an average normalized gain of 0.03 and the 360 degrees panorama group, 0.43. Although the 3D modeled group had slightly higher realism according to the presence questionnaire and had slightly higher averages in the comparative analysis questionnaire, the 360 degrees panorama application has shown to be the most effective for training and the quickest to develop.
C1 [Ritter, K. A., III; Chambers, Terrence L.] Univ Louisiana Lafayette, Dept Mech Engn, Lafayette, LA 70504 USA.
C3 University of Louisiana Lafayette
RP Ritter, KA (corresponding author), Univ Louisiana Lafayette, Dept Mech Engn, Lafayette, LA 70504 USA.
EM kritter@louisiana.edu
OI Ritter, Kenneth/0000-0001-9485-0265
CR Abichandani P, 2019, IEEE ACCESS, V7, P147081, DOI 10.1109/ACCESS.2019.2945700
   Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   Babu SK, 2018, IEEE INT CONF ADV LE, P385, DOI 10.1109/ICALT.2018.00094
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Borsci S, 2015, COMPUT IND, V67, P17, DOI 10.1016/j.compind.2014.12.002
   Christopoulos A, 2018, VIRTUAL REAL-LONDON, V22, P353, DOI 10.1007/s10055-017-0330-3
   Cinema Suite, 2018, CINEMA MOCAP 2 MARKE
   Cook M., 2020, MOTIVATIONS DESIGN P, DOI [10.1007/s10055-020-00433-x, DOI 10.1007/S10055-020-00433-X]
   Dassault Systemes SolidWorks Corporation, 2018, SOLIDWORKS 3D CAD DE
   Datallo A, 2018, IMM LEARN RES NETW I, P35, DOI [10.3217/978-3-85125-609-3-09, DOI 10.3217/978-3-85125-609-3-09]
   Eiris R, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.102969
   Eiris R, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15112452
   Hake RR, 1998, AM J PHYS, V66, P64, DOI 10.1119/1.18809
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Klippel A, 2019, J EDUC COMPUT RES, V57, P1745, DOI 10.1177/0735633119854025
   Kolb AY, 2005, ACAD MANAG LEARN EDU, V4, P193, DOI 10.5465/AMLE.2005.17268566
   KryspinExner I, 2012, P INT SO PRES RES PH
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Lee J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925983
   Li H, 2012, J COMPUT CIVIL ENG, V26, P638, DOI 10.1061/(ASCE)CP.1943-5487.0000170
   LOFTUS GR, 1985, J EXP PSYCHOL LEARN, V11, P397, DOI 10.1037/0278-7393.11.2.397
   Higuera-Trujillo JL, 2017, APPL ERGON, V65, P398, DOI 10.1016/j.apergo.2017.05.006
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Microsoft, 2018, MICROSOFT KINECT WIN
   Moore HF, 2019, COMPUTING IN CIVIL ENGINEERING 2019: VISUALIZATION, INFORMATION MODELING, AND SIMULATION, P55
   Pereira RE, 2018, CONSTRUCTION RESEARCH CONGRESS 2018: SAFETY AND DISASTER MANAGEMENT, P29
   Perez-Sabater C., 2011, P 12 S INT COMUNICAC, P75
   Pham HC, 2018, INT J ENG EDUC, V34, P1174
   Potkonjak V, 2016, COMPUT EDUC, V95, P309, DOI 10.1016/j.compedu.2016.02.002
   Redohl S, 2017, EXPLAINING 360 VIDEO
   Reyna J, 2018, INTED PROC, P1448
   Ritter KA., 2018, COMPUT ED J, V9, P7
   Rossetti T, 2020, J CHOICE MODEL, V34, DOI 10.1016/j.jocm.2019.100198
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 37
TC 18
Z9 18
U1 4
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 571
EP 581
DI 10.1007/s10055-021-00502-9
EA MAR 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000627189400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lam, MC
   Suwadi, NA
   Arifien, AHMZ
   Poh, BK
   Safii, NS
   Wong, JE
AF Lam, Meng Chun
   Suwadi, Nur Afyfah
   Arifien, Adibah Huda Mohd Zainul
   Poh, Bee Koon
   Safii, Nik Shanita
   Wong, Jyh Eiin
TI An evaluation of a virtual atlas of portion sizes (VAPS) mobile
   augmented reality for portion size estimation
SO VIRTUAL REALITY
LA English
DT Article
DE Food portion; Portion estimation; Food atlas; Augmented reality;
   Human&#8211; computer interaction
ID FOOD PHOTOGRAPHS; HERITAGE; PHOTOGRAMMETRY; ACCURACY
AB Food portion size estimation is a critical yet challenging task in dietary assessment. Augmented reality technology enables the presentation of food dimensions and volume in a virtual three-dimensional object. It has the potential to improve perception and estimation of portion sizes. This study aims to develop and evaluate a novel mobile augmented reality application, namely Virtual Atlas of Portion Sizes (VAPS), as a portion size estimation aid. The development methodology of VAPS involves food photography, reconstruction of 3D models using photogrammetry method and presenting them in an AR environment. The 3D food models displayed in either semi-transparent or vivid mode for users to perform food portion estimation. Users can then resize and rotate the 3D models to fit the virtual model with the actual food. A total of thirty-six participants were involved in the evaluation and were divided into a health science and a non-health science background group. VAPS received good usability level with 76 SUS score. In terms of task completion time, unsurprisingly, the health science group performed faster. However, both groups have equivalent accuracy on the food portion estimation task using VAPS: 22.5% for non-health science group and 26.6% for health science group. The health science group liked and have better accuracy in vivid 3D food models (37.5%). Meanwhile, the non-health science group preferred semi-transparent 3D food models, but the accuracy is not significantly different between semi-transparent (25%) and vivid 3D food model (20%). Results demonstrate the potential of VAPS to aid in portion size estimation for dietary assessment, and participants' feedback will be incorporated in the future for improvement of the app.
C1 [Lam, Meng Chun; Suwadi, Nur Afyfah] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Mixed Real & Pervas Comp Lab, Bangi 43600, Selangor, Malaysia.
   [Arifien, Adibah Huda Mohd Zainul; Poh, Bee Koon; Safii, Nik Shanita; Wong, Jyh Eiin] Univ Kebangsaan Malaysia, Fac Hlth Sci, Ctr Community Hlth Studies ReaCH, Kuala Lumpur 50300, Malaysia.
C3 Universiti Kebangsaan Malaysia; Universiti Kebangsaan Malaysia
RP Wong, JE (corresponding author), Univ Kebangsaan Malaysia, Fac Hlth Sci, Ctr Community Hlth Studies ReaCH, Kuala Lumpur 50300, Malaysia.
EM wjeiin@ukm.edu.my
RI Wong, Jyh Eiin/AAK-4382-2020; Suwadi, Nur Afyfah/HHN-2490-2022; Chun,
   Lam Meng/H-4105-2019
OI Wong, Jyh Eiin/0000-0002-9206-3257; Chun, Lam Meng/0000-0002-9435-9473;
   SUWADI, NUR AFYFAH/0000-0002-7551-0393
FU Universiti Kebangsaan Malaysia [DIP-2017-018]
FX This study was funded by Universiti Kebangsaan Malaysia (DIP-2017-018).
   We would also like to acknowledge 3DFLOW for providing a six-month 3DF
   Zephyr Aerial Education license.
CR 3DFlow, 2014, 3DF ZEPH
   3DFlow, 2017, 3DFLOW AC VID 1 BAS
   Almiron-Roig E, 2013, APPETITE, V71, P95, DOI 10.1016/j.appet.2013.07.012
   [Anonymous], 2014, ANN COMMUNITY HEAL
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Blender, 2017, BLEND 2 79
   Ch'ng E, 2019, J CULT HERIT MANAG S, V9, P24, DOI 10.1108/JCHMSD-03-2018-0018
   Chandler J.H., 2016, Geoscience Handbook 2016: AGI Data Sheets, V5th ed.
   Chanlin LJ, 2018, LIBRI, V68, P137, DOI 10.1515/libri-2017-0024
   Daneshmand M., 2018, ARXIV180108863
   Dinic R, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P284, DOI 10.1109/ISMAR-Adjunct.2017.90
   Domhardt Michael, 2015, J Diabetes Sci Technol, V9, P516, DOI 10.1177/1932296815578880
   Du J, 2012, MICROBES IN APPLIED RESEARCH: CURRENT ADVANCES AND CHALLENGES, P3
   Fang SB, 2016, IEEE IMAGE PROC, P26, DOI 10.1109/ICIP.2016.7532312
   Fatehah AA, 2018, NUTRIENTS, V10, DOI 10.3390/nu10080984
   Foster E, 2006, PUBLIC HEALTH NUTR, V9, P509, DOI 10.1079/PHN2005872
   Frobisher C, 2003, J HUM NUTR DIET, V16, P181, DOI 10.1046/j.1365-277X.2003.00434.x
   Gibson R.S., 2005, PRINCIPLES NUTR ASSE, V2nd
   HAVEMANN S, 2005, THESIS BRAUNSCHWEIG
   Hernandez A, 2017, PROSTHET ORTHOT INT, V41, P210, DOI 10.1177/0309364616664150
   Hernández T, 2006, J FOOD COMPOS ANAL, V19, pS14, DOI 10.1016/j.jfca.2006.02.010
   Hooper A, 2019, ADV NUTR, V10, P43, DOI 10.1093/advances/nmy060
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Lynch P., 2009, VISUAL DECISION MAKI
   Martin CK, 2009, BRIT J NUTR, V101, P446, DOI 10.1017/S0007114508027438
   Mikhail E.M., 2001, Introduction to modern photogrammetry
   Narumi T., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems (CHI '12), P109, DOI [DOI 10.1145/2207676.2207693, 10.1145/2207676.2207693]
   NELSON M, 1994, BRIT J NUTR, V72, P649, DOI 10.1079/BJN19940069
   Nelson M, 1998, PUBLIC HEALTH NUTR, V1, P231, DOI 10.1079/PHN19980039
   Nikolic M, 2018, FRONT NUTR, V5, DOI 10.3389/fnut.2018.00078
   Nikou SA, 2017, COMPUT EDUC, V109, P56, DOI 10.1016/j.compedu.2017.02.005
   Nizam SSM, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/5320984
   Nizam SS Muhammad., 2018, Int. J. Adv. Sci. Eng. Inf. Technol, V8, P1460, DOI [10.18517/ijaseit.8.4-2.6824, DOI 10.18517/IJASEIT.8.4-2.6824]
   Ovaskainen ML, 2008, EUR J CLIN NUTR, V62, P674, DOI 10.1038/sj.ejcn.1602758
   Owda A, 2018, SENSOR REV, V38, P282, DOI 10.1108/SR-06-2017-0106
   Photogrammetry, 2017, WHAT IS PHOT
   Remondino F, 2005, P SOC PHOTO-OPT INS, V5665, DOI 10.1117/12.586294
   Remondino F, 2011, REMOTE SENS-BASEL, V3, P1104, DOI 10.3390/rs3061104
   Rollo ME, 2017, INT J BEHAV NUTR PHY, V14, DOI 10.1186/s12966-017-0516-9
   Sadik M.J., 2017, Journal of Engineering and Applied Sciences, V12, P2098, DOI DOI 10.36478/JEASCI.2017.2098.2105
   Stütz T, 2014, INT SYM MIX AUGMENT, P51, DOI 10.1109/ISMAR-AMH.2014.6935438
   Tan SY., 2018, INT J ADV SCI ENG IN, V8, P1672, DOI [10.18517/ijaseit.8.4-2.6810, DOI 10.18517/IJASEIT.8.4-2.6810]
   Vuforia, 2019, DES VUM AD ILL
NR 43
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 695
EP 707
DI 10.1007/s10055-020-00484-0
EA NOV 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000585793000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Heinrich, C
   Cook, M
   Langlotz, T
   Regenbrecht, H
AF Heinrich, Chris
   Cook, Matthew
   Langlotz, Tobias
   Regenbrecht, Holger
TI My hands? Importance of personalised virtual hands in a
   neurorehabilitation scenario
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual embodiment; Neurorehabilitation therapy; Virtual reality;
   Virtual hands reconstruction; Virtual interaction
ID PERCEIVED OWNERSHIP; ILLUSORY OWNERSHIP; REHABILITATION; THERAPY;
   FEASIBILITY; STROKE
AB We have developed a novel and affordable way to texture virtual hands from individually taken photographs and integrated the virtual hands into a mixed reality neurorehabilitation system. This mixed reality system allows for serious game play with mirrored and non-mirrored hands, designed for patients with unilateral motor impairments. Before we can ethically have patients use the system, we must show that embodiment can be achieved for healthy users. We compare our approach's results to previous work in the field and present a study with 48 healthy (non-clinical) participants targeting visual fidelity and self-location. We show that embodiment can be achieved for mirrored and non-mirrored hand representations and that the higher realism of virtual hands achieved by our texturing approach alters perceived embodiment. We further evaluate whether using virtual hands resized to the individual's hand size affects embodiment. We present a 16-participant study where we could not find a significant difference with personal resized hands. In addition to rehabilitation contexts, our findings have implications for the design and development of applications where embodiment is of high importance, such as surgical training and remote collaboration.
C1 [Heinrich, Chris; Cook, Matthew; Langlotz, Tobias; Regenbrecht, Holger] Univ Otago, Dept Informat Sci, Dunedin, New Zealand.
C3 University of Otago
RP Heinrich, C (corresponding author), Univ Otago, Dept Informat Sci, Dunedin, New Zealand.
EM heinrich.chris@gmail.com; matthew@cook.run; tobias.langlotz@otago.ac.nz;
   holger.regenbrecht@otago.ac.nz
OI Heinrich, Chris/0000-0002-2686-6051
CR Al-Tairi ZH, 2014, J INF PROCESS SYST, V10, P283, DOI 10.3745/JIPS.02.0002
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   de Assis GA, 2016, DISABIL REHABIL-ASSI, V11, P521, DOI 10.3109/17483107.2014.979330
   Doidge N., 2008, The brain that changes itself
   Freina L., 2015, P INT SCI C ELEARNIN, V1
   Giraux P, 2003, NEUROIMAGE, V20, pS107, DOI 10.1016/j.neuroimage.2003.09.024
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Hoermann S, 2017, DISABIL REHABIL, V39, P1503, DOI 10.1080/09638288.2017.1291765
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Holmes  D., 2016, P 11 INT C DIS VIRT
   Hung YX, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000003032
   IJsselsteijn W, 2005, IS THIS MY HAND I SE, P41
   Iosa M, 2015, TOP STROKE REHABIL, V22, P306, DOI 10.1179/1074935714Z.0000000036
   Khademi M., 2014, Conference on Human Factors in Computing Systems - Proceedings, (February 2015), P1663, DOI [10.1145/2559206.2581203, DOI 10.1145/2559206.2581203]
   Khan H, 2017, ICAT EGVE
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Liu Z, 2015, LECT NOTES COMPUT SC, V9181, P338, DOI 10.1007/978-3-319-20934-0_32
   Ma K, 2015, CONSCIOUS COGN, V36, P277, DOI 10.1016/j.concog.2015.07.008
   Ma K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00604
   MacNeil LB, 2017, THESIS
   Moon S, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P67, DOI 10.1109/ICOIN.2018.8343086
   Mueller F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322958
   Nimcharoen C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P158, DOI 10.1109/ISMAR-Adjunct.2018.00057
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Presti C, 2015, SOCIEDADE BRASILEIRA, P1
   Proença JP, 2018, DISABIL REHABIL-ASSI, V13, P95, DOI 10.1080/17483107.2017.1290702
   Regenbrecht H., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P219, DOI 10.1109/ISMAR.2011.6092389
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubio B, 2013, CONVERGING CLIN ENG, P1037
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Trojan J, 2014, BEHAV RES METHODS, V46, P634, DOI 10.3758/s13428-013-0412-4
   Tung JY, 2015, PHYSIOL MEAS, V36, P1025, DOI 10.1088/0967-3334/36/5/1025
   Weber LM, 2019, AM J PHYS MED REHAB, V98, P783, DOI 10.1097/PHM.0000000000001190
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 43
TC 13
Z9 15
U1 1
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 313
EP 330
DI 10.1007/s10055-020-00456-4
EA JUL 2020
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000549362000001
DA 2024-07-18
ER

PT J
AU Okada, T
   Okamoto, S
   Yamada, Y
AF Okada, Takumu
   Okamoto, Shogo
   Yamada, Yoji
TI Passive haptics: greater impact presented by pulsive damping brake of DC
   motor and physical indices for perceived impact
SO VIRTUAL REALITY
LA English
DT Article
DE Passive haptic interface; Impact perception; Damping brake
ID VIBRATION FEEDBACK; RATE-HARDNESS
AB This study investigated the perceptual characteristics of pulsive brakes presented by passive haptic interfaces. A passive-type haptic interface based on the damping brake of a DC motor was used to generate impact; this has merits of inherent safety and energy efficiency. This haptic interface expresses impacts by resisting the operator's hand via the resistive force generated by a damping brake. In terms of impulse or momentum, maximum impact was achieved by continuously operating the damping brake after colliding with a virtual object. We found that instantaneous release of the brake immediately after collision increases the perceived impact. We computed several physical indices associated with the force against the hand as well as the hand velocity and investigated their relationships with the perceived magnitudes of the impacts. A high correlation was found between the absolute change ratio of the hand velocity and the perceived impact, which suggests that instantaneously releasing the brake is effective in terms of impact perception. Our findings indicate that the performance of passive haptic interfaces can extend physical limits, and the range of applications can be expanded by incorporating human perceptual characteristics.
C1 [Okada, Takumu; Okamoto, Shogo; Yamada, Yoji] Nagoya Univ, Dept Mech Syst Engn, Chikusa Ku, Furo Cho, Nagoya, Aichi, Japan.
C3 Nagoya University
RP Okamoto, S (corresponding author), Nagoya Univ, Dept Mech Syst Engn, Chikusa Ku, Furo Cho, Nagoya, Aichi, Japan.
EM shogo.okamoto@mae.nagoya-u.ac.jp
OI Okamoto, Shogo/0000-0003-2116-7734
FU ImPACT (Tough Robotics Challenge); MEXT Kakenhi [15H05923]
FX This study was in part supported by ImPACT (Tough Robotics Challenge)
   and MEXT Kakenhi (15H05923).
CR Asbeck AT, 2015, INT J ROBOT RES, V34, P744, DOI 10.1177/0278364914562476
   BURKE D, 1976, J PHYSIOL-LONDON, V261, P673, DOI 10.1113/jphysiol.1976.sp011580
   Constantinescu D, 2005, IEEE T ROBOT, V21, P309, DOI 10.1109/TRO.2004.840906
   Culbertson H, 2017, IEEE T HAPTICS, V10, P63, DOI 10.1109/TOH.2016.2598751
   Davis H, 1997, P AMER CONTR CONF, P959, DOI 10.1109/ACC.1997.609669
   Fiene JP, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P170
   Goswami A., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P279, DOI 10.1109/ROBOT.1990.125987
   Hachisu T, 2017, IEEE T HAPTICS, V10, P288, DOI 10.1109/TOH.2016.2628900
   Han G, 2010, LECT NOTES COMPUT SC, V6191, P117
   Hauser SC, 2018, IEEE T HAPTICS, V11, P232, DOI 10.1109/TOH.2017.2715845
   Higashi K, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02654
   Higashi K, 2018, IEEE T HAPTICS, V11, P646, DOI 10.1109/TOH.2018.2841820
   Higashi K, 2016, LECT NOTES COMPUT SC, V9774, P3, DOI 10.1007/978-3-319-42321-0_1
   Hirata Y, 2007, IEEE T ROBOT, V23, P981, DOI 10.1109/TRO.2007.906252
   Hwang JD, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P24, DOI 10.1109/HAPTIC.2004.1287174
   Ikeda S., 2009, P JOINT VIRT REAL EU, P113
   Kikuchi T, 2009, P INT C MACH AUT, P75
   Koyama T, 2002, P IEEE RSJ INT C INT, P2229
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Lawrence DA, 2000, IEEE T ROBOTIC AUTOM, V16, P357, DOI 10.1109/70.864228
   Lim T., 2007, Virtual Reality, V11, P241, DOI 10.1007/s10055-007-0072-8
   McMahan W, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3170, DOI 10.1109/IROS.2009.5354607
   Mehling JS, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P257
   Minsky M., 1990, Computer Graphics, V24, P235, DOI 10.1145/91394.91451
   Ohashi K, 2017, IEEE SYS MAN CYBERN, P1411, DOI 10.1109/SMC.2017.8122811
   Okada T, 2018, T HUM INTERFACE SOC, V20, P205
   Okada T, 2017, P IEEE GLOB C CONS E, P318
   Okada T, 2016, IEEE SYS MAN CYBERN, P2359, DOI 10.1109/SMC.2016.7844591
   Okada Takumu, 2016, LECT NOTES ELECT ENG, V432, P211
   Okamura AM, 2001, IEEE-ASME T MECH, V6, P245, DOI 10.1109/3516.951362
   Poorten EBV, 2007, ADV ROBOTICS, V21, P1411, DOI 10.1163/156855307781746115
   SCHEFFE H, 1952, J AM STAT ASSOC, V47, P381, DOI 10.2307/2281310
   Scilingo EP, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P10, DOI 10.1109/HAPTIC.2003.1191217
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Wellman Parris., 1995, PROC ASME DYNAMIC SY, V57, P713
   Winter SH, 2007, IEEE T NEUR SYS REH, V15, P2, DOI 10.1109/TNSRE.2007.891401
   Wu CM, 2017, VIRTUAL REAL-LONDON, V21, P19, DOI 10.1007/s10055-016-0296-6
NR 37
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 233
EP 245
DI 10.1007/s10055-020-00452-8
EA JUN 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000541320100001
DA 2024-07-18
ER

PT J
AU Barreda-Angeles, M
   Aleix-Guillaume, S
   Pereda-Baños, A
AF Barreda-Angeles, Miguel
   Aleix-Guillaume, Sara
   Pereda-Banos, Alexandre
TI Users' psychophysiological, vocal, and self-reported responses to the
   apparent attitude of a virtual audience in stereoscopic 360°-video
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; 360 degrees-video; Public speaking; Presence;
   Psychophysiology
ID REALITY EXPOSURE THERAPY; PUBLIC SPEAKING; ANXIETY DISORDERS;
   EXPERIENCE; EMOTION; QUALITY; FEAR; METAANALYSIS; BEHAVIOR; IMPACT
AB This research analyzes the psychological reactions of participants to the neutral, positive, or negative attitudes of a virtual audience recorded in 360 degrees-video. Participants were asked to deliver three speeches, each accompanied by a different type of reaction from the virtual audience. Measures of user state included questionnaires, psychophysiological measures, and voice recordings. The results showed that, compared to the neutral audience, the negative audience elicited increases in skin conductance level and heart rate variability, decreases in voice intensity, and a higher ratio of silent parts in the speech, as well as a more negative self-reported valence, higher anxiety, and lower social presence. These findings evidence that, even if some attributes that are considered to be central to immersive experiences are lacking, (i.e., interactivity or avatar representation of the user), 360 degrees-video recreations of virtual environments lead to realistic reactions on users. These results support the effectiveness of 360 degrees-video virtual audiences for public speaking training and social anxiety treatment.
C1 [Barreda-Angeles, Miguel; Aleix-Guillaume, Sara; Pereda-Banos, Alexandre] Eurecat, Ctr Tecnol Catalunya, C Bilbao 72, Barcelona 08018, Spain.
   [Aleix-Guillaume, Sara] Univ Barcelona, Barcelona, Spain.
C3 University of Barcelona
RP Barreda-Angeles, M (corresponding author), Eurecat, Ctr Tecnol Catalunya, C Bilbao 72, Barcelona 08018, Spain.
EM miguel.barreda@eurecat.org
RI Barreda-Ángeles, Miguel/AAX-4359-2020
OI Barreda-Ángeles, Miguel/0000-0002-5056-7633; Pereda-Banos,
   Alexandre/0000-0002-1145-146X
FU Agencia per a la Competivitat de lEmpresa, ACCI [VR360]
FX This research was partially supported by the Agencia per a la
   Competivitat de lEmpresa, ACCI (Grant No. VR360).
CR Anderson PL, 2017, COGNITIVE THER RES, V41, P230, DOI 10.1007/s10608-016-9820-y
   [Anonymous], 2011, ACQKNOWLEDGE 4 2
   [Anonymous], 2018, J Telecommun Electron Comput Engin
   Aymerich-Franch L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00944
   Bailenson Jeremy N., 2004, Proceedings of the 7th Annual International Workshop on PRESENCE, P1864
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Barreda-Angeles, 2018, IEEE COMSOC MMTC COM, V4, P14
   Battisti F, 2018, IEEE T BROADCAST, V64, P392, DOI 10.1109/TBC.2018.2828607
   Baumeister R. F., 2001, Review of General Psychology, V5, P323, DOI [10.1037/1089-2680.5.4.323, DOI 10.1037/1089-2680.5.4.323]
   Biocca F., 2001, 2001 C PHIL PA
   Bliese P.D., 2016, MULTILEVEL MODELING
   Boersma P., 2017, Praat: Doing phonetics by computer
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brunnstrom K., 2013, Qualinet White Paper on Definitions of Quality of Experience
   Bui G, 2018, LANG TEACH RES, V22, P94, DOI 10.1177/1362168816656650
   Carreiras C., 2015, BioSPPy: Biosignal processing in Python
   Carretié L, 2014, COGN AFFECT BEHAV NE, V14, P1228, DOI 10.3758/s13415-014-0270-2
   Craske MG, 2008, BEHAV RES THER, V46, P5, DOI 10.1016/j.brat.2007.10.003
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   Dickerson SS, 2004, PSYCHOL BULL, V130, P355, DOI 10.1037/0033-2909.130.3.355
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Greco A, 2016, IEEE T BIO-MED ENG, V63, P797, DOI 10.1109/TBME.2015.2474131
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Guadagno RE, 2011, COMPUT HUM BEHAV, V27, P2380, DOI 10.1016/j.chb.2011.07.017
   Harris SR, 2002, CYBERPSYCHOL BEHAV, V5, P543, DOI 10.1089/109493102321018187
   Hartanto D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092804
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hofmann SG, 1997, J ANXIETY DISORD, V11, P573, DOI 10.1016/S0887-6185(97)00040-6
   Kang N, 2016, COMPUT HUM BEHAV, V55, P680, DOI 10.1016/j.chb.2015.10.008
   Kim J, 2018, J MEDIA PSYCHOL-GER, V30, P29, DOI 10.1027/1864-1105/a000175
   Kothgassner OD, 2012, LECT NOTES COMPUTER, P53
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Laborde S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00213
   Laghari KUR, 2012, IEEE COMMUN MAG, V50, P58, DOI 10.1109/MCOM.2012.6178834
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lang A, 2009, COMMUN SER, P185
   Lang P.J., 1968, RES PSYCHOTHERAPY, V3, P90, DOI DOI 10.1037/10546-004
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Laukka P, 2008, J NONVERBAL BEHAV, V32, P195, DOI 10.1007/s10919-008-0055-9
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lepecq JC, 2009, VIRTUAL REAL-LONDON, V13, P141, DOI 10.1007/s10055-009-0118-1
   Morewedge CK, 2010, TRENDS COGN SCI, V14, P435, DOI 10.1016/j.tics.2010.07.004
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   NISBETT RE, 1977, J PERS SOC PSYCHOL, V35, P250, DOI 10.1037//0022-3514.35.4.250
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Page-Gould E., 2017, HDB PSYCHOPHYSIOLOGY, P628
   Pan X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146837
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Pinheiro J., 2017, PACKAGE NLME LINEAR
   Poeschl S., 2017, Frontiers in ICT, V4, P13, DOI DOI 10.3389/FICT.2017.00013
   Poeschl S, 2012, STUD HEALTH TECHNOL, V181, P218, DOI 10.3233/978-1-61499-121-2-218
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Qiu XY, 2020, LANG TEACH RES, V24, P745, DOI 10.1177/1362168819829021
   Ravaja N, 2004, MEDIA PSYCHOL, V6, P193, DOI 10.1207/s1532785xmep0602_4
   Revelle W, 2009, PSYCHOMETRIKA, V74, P145, DOI 10.1007/s11336-008-9102-z
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robinson P., 2001, COGNITION 2 LANGUAGE, P287, DOI DOI 10.1017/CBO9781139524780
   Scherer K., 2000, Neuropsychology of Emotion, V137, P137
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2007, PRESENCE-TELEOP VIRT, V16, P447, DOI 10.1162/pres.16.4.447
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stupar-Rutenfrans S, 2017, CYBERPSYCH BEH SOC N, V20, P624, DOI 10.1089/cyber.2017.0174
   Sundar SS, 2017, CYBERPSYCH BEH SOC N, V20, P672, DOI 10.1089/cyber.2017.0271
   Team Audacity, 2015, AUD VERS 2 1 0 AUD E
   Urvoy M, 2013, ANN TELECOMMUN, V68, P641, DOI 10.1007/s12243-013-0394-3
   Wiederhold B.K., 2005, Virtual reality therapy for anxiety disorders: Advances in evaluation and treatment
   Wilhelm FH, 2001, BIOL PSYCHOL, V57, P105, DOI 10.1016/S0301-0511(01)00091-6
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
NR 81
TC 21
Z9 24
U1 2
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 289
EP 302
DI 10.1007/s10055-019-00400-1
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800009
DA 2024-07-18
ER

PT J
AU Rebenitsch, L
   Owen, C
AF Rebenitsch, Lisa
   Owen, Charles
TI Estimating cybersickness from virtual reality applications
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cybersickness; VIMS; Displays
ID MOTION SICKNESS
AB Cybersickness is a known issue in virtual reality affecting a notable percentage of the populations. However, predicting the level and incidence of cybersickness in new systems is difficult. Past publications were analyzed for their factors and resulting cybersickness scores. These factors were then used to develop three predictive models using demographics, software, and hardware factors. Using demographic information alone explained 44.2% of the adjusted variance in a linear model. Using hardware and software factors alone explained 55.3% of the adjusted variance in a linear model. Using demographics, software, and hardware factors did not use a linear model, but rather had an average residual error of 1.03. This residual error is an estimate of how far the predicted cybersickness score is from the actual score.
C1 [Rebenitsch, Lisa] South Dakota Sch Mines & Technol, 501 E St Joseph St, Rapid City, SD 57701 USA.
   [Owen, Charles] Michigan State Univ, Comp Sci & Engn, 1138 Engn Bldg, E Lansing, MI 48824 USA.
C3 South Dakota School Mines & Technology; Michigan State University
RP Rebenitsch, L (corresponding author), South Dakota Sch Mines & Technol, 501 E St Joseph St, Rapid City, SD 57701 USA.
EM Lisa.rebenitsch@sdsmt.edu; cbowen@cse.msu.edu
OI Rebenitsch, Lisa/0000-0002-9640-8670
CR [Anonymous], THESIS
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Chen Y.C., 2011, BIO Web of Conferences, V1, P00016, DOI DOI 10.1051/BIOCONF/20110100016
   Dizio P, 1997, INT C HUM COMP INT
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Dong Xiao., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P1340, DOI [DOI 10.1177/1541931210054018, 10.1177/154193121005401808, DOI 10.1177/154193121005401808]
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Keshavarz B, 2015, EXP BRAIN RES, V233, P1353, DOI 10.1007/s00221-015-4209-9
   Kim YY, 2004, J APPL SIGNAL PROCES, V42, P616
   Kolasinski E. M., 1995, SIMULATOR SICKNESS V
   Kolasinski EM, 1996, THESIS
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Rebenitsch L, 2017, EVALUATING FACTORS A, P544
   Rebenitsch L, 2014, US INT SOFTW TECHN S
   Rebenitsch L. R., 2015, THESIS
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Renkewitz H., 2007, Perceptual Issues of Augmented and Virtual Environments
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   So RHY, 1999, P HCI INT 8 INT C HU
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 1999, P HUMAN FACTORS ERGO
   Toet A, 2008, PROC SPIE, V6957, DOI 10.1117/12.771992
   van Emmerik ML, 2011, DISPLAYS, V32, P169, DOI 10.1016/j.displa.2010.11.003
NR 27
TC 48
Z9 52
U1 8
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 165
EP 174
DI 10.1007/s10055-020-00446-6
EA MAY 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000554746600001
DA 2024-07-18
ER

PT J
AU Edwards, BI
   Bielawski, KS
   Prada, R
   Cheok, AD
AF Edwards, Bosede Iyiade
   Bielawski, Kevin S.
   Prada, Rui
   Cheok, Adrian David
TI Haptic virtual reality and immersive learning for enhanced organic
   chemistry instruction
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Immersive learning; Haptics; Chemistry education;
   Organic chemistry; Hydrocarbons; Middle school science; Introductory
   chemistry; Hands-on learning; Gamification
ID STUDENTS
AB Human-Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to support immersive learning, teaching through simulation, and gamification of learning. These systems can deliver high-level multisensory learning experiences that are important in the teaching of many subjects, especially those involving abstract concepts or requiring spatial skills, such as organic chemistry. Haptic experiences with VR, however, remain a challenge. In addition, development has focused on general entertainment/gaming; VR systems in chemistry implement simulations of the chemistry laboratory and other advanced systems whereas those that support safe, game-like, immersive and multisensory learning of organic chemistry with haptics at pre-university education levels are scarce. We developed the VR Multisensory Classroom (VRMC) as an immersive learning environment within a VR head-mounted display, where learners employ hand movements to build hydrocarbon molecules and experience haptic feedback through gloves with built-in sensors and hand-tracking with the Leap Motion system. We report here the evaluation of the first prototype by learners from diverse backgrounds who reported on the ability of the VRMC to support high engagement, motivation, interest and organic chemistry learning as well as diverse learning styles. The VRMC is a novel VR classroom that supports immersive learning in molecular organic chemistry with haptics for multisensory learning.
C1 [Edwards, Bosede Iyiade; Bielawski, Kevin S.; Cheok, Adrian David] Imagineering Inst, Iskandar Puteri 79200, Johor, Malaysia.
   [Edwards, Bosede Iyiade; Bielawski, Kevin S.; Cheok, Adrian David] City Univ London, Northampton Sq, London EC1V 0HB, England.
   [Prada, Rui] Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.
C3 City University London; Universidade de Lisboa
RP Edwards, BI (corresponding author), Imagineering Inst, Iskandar Puteri 79200, Johor, Malaysia.; Edwards, BI (corresponding author), City Univ London, Northampton Sq, London EC1V 0HB, England.
EM bosede@imagineeringinstitute.org; kevin@imagineeringinstitute.org;
   rui.prada@tecnico.ulisboa.pt; adrian@imagineeringinstitute.org
RI Prada, Rui/AAK-7387-2020; Cheok, Adrian David/AAT-6141-2021; Edwards,
   Bosede Iyiade/GMX-0087-2022; Prada, Rui/A-6835-2012
OI Cheok, Adrian David/0000-0001-6316-2339; Edwards, Bosede
   Iyiade/0000-0002-6922-311X; Prada, Rui/0000-0002-5370-1893
CR Axon VR, 2017, VIRTUAL REALITY YOU
   Bazeley P, 2010, J MIX METHOD RES, V4, P79, DOI 10.1177/1558689809356926
   Buckley P, 2016, INTERACT LEARN ENVIR, V24, P1162, DOI 10.1080/10494820.2014.964263
   Cambridge Dictionary, 2017, DEF IMM
   CAVANAGH SJ, 1995, NURS EDUC TODAY, V15, P177, DOI 10.1016/S0260-6917(95)80103-0
   Choi S, 2015, CONCURRENT ENG-RES A, V23, P40, DOI 10.1177/1063293X14568814
   Christou C., 2010, Affective, Interactive and Cognitive Methods for E-learning Design: Creating an Optimal Education Experience, P228, DOI [10.4018/978-1-60566-940-3.ch012, DOI 10.4018/978-1-60566-940-3, 10.4018/978-1-60566-940-3.ch012., DOI 10.4018/978-1-60566-940-3.CH012]
   Creswell J. W., 2007, DESIGNING CONDUCTING
   Creswell J.W., 2009, Muqarnas, V8, DOI DOI 10.2307/1523157
   Culatta R., 2013, ADDIE Model
   de Jong T, 2010, INSTR SCI, V38, P105, DOI 10.1007/s11251-009-9110-0
   DextaRobotics, 2018, DEXTAROBOTICS BUILDS
   Dunser A., 2006, P 7 ACM SIGCHI NZ CH, P125, DOI 10.1145/1152760.1152776
   Eastwood ML, 2013, J CHEM EDUC, V90, P1038, DOI 10.1021/ed3004462
   Erlandson D.A., 1993, Doing naturalistic enquiry: A guide to methods
   Farra SL, 2015, NURSE EDUC PRACT, V15, P53, DOI 10.1016/j.nepr.2013.08.017
   Fildes N, 2015, RACONTEUR        DEC
   Google, 2017, VIRT REAL EV
   Hamid NSS, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P1034, DOI 10.1109/SAI.2014.6918317
   Hauptman H, 2010, COMPUT EDUC, V54, P123, DOI 10.1016/j.compedu.2009.07.013
   Heinich R, 2002, INSTRUCTIONAL MEDIA, V7
   Hyun E, 2010, ACMIEEE INT CONF HUM, P199, DOI 10.1109/HRI.2010.5453197
   Koedinger Kenneth R., 2015, P 2 2015 ACM C LEARN, P111, DOI DOI 10.1145/2724660.2724681
   Kolb DA., 2014, PERSPECTIVES COGNITI, P227, DOI [DOI 10.5465/AMLE.2005.17268566, DOI 10.4324/9781410605986-9]
   Kuo MS, 2016, COMPUT HUM BEHAV, V55, P16, DOI 10.1016/j.chb.2015.08.025
   Leap Motion, 2017, REACH VIRT REAL YOUR
   Mahatma Chemistry, 2017, MEL CHEM VR
   Mei HH, 2011, INT J INFORM ED TECH, V1, P298, DOI [10.7763/IJIET.2011.V1.48, DOI 10.7763/IJIET.2011.V1.48]
   Merchant Z, 2013, J COMPUT ASSIST LEAR, V29, P579, DOI 10.1111/jcal.12018
   Merriam Webster Dictionary, 2017, DEF IMMERSIVE
   Mestre Daniel, 2011, VIRTUAL REALITY
   Minogue J, 2006, REV EDUC RES, V76, P317, DOI 10.3102/00346543076003317
   Molenda, 2003, ADDIE TIMELINE
   Molenda M, 2003, ADDIE MODEL
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Nakamura J, 2009, HDB POSITIVE PSYCHOL, DOI [10.1093/oxfordhb/9780195187243.013.0018, DOI 10.1093/OXFORDHB/9780195187243.013.0018]
   Norrby M, 2015, J CHEM INF MODEL, V55, P2475, DOI 10.1021/acs.jcim.5b00544
   Ornstein A., 2006, Journal of Science Education and Technology, V15, P285, DOI DOI 10.1007/S10956-006-9015-5
   React! Team, 2017, REACT ORG CHEM BOARD
   Ritter D, 1997, J CHEM EDUC, V74, P120, DOI 10.1021/ed074p120
   Sanders T., 2010, BCS HCI 2010, p, P160
   Schell Games, 2017, SUPERCHEM VR
   Smith C, 2016, CHEM LAB VR
   StohrHunt PM, 1996, J RES SCI TEACH, V33, P101, DOI 10.1002/(SICI)1098-2736(199601)33:1<101::AID-TEA6>3.0.CO;2-Z
   Stone DC, 2007, J CHEM EDUC, V84, P1488, DOI 10.1021/ed084p1488
   Stull AT, 2013, COMPUT HUM BEHAV, V29, P2546, DOI 10.1016/j.chb.2013.06.012
   Turk DJ, 2015, LEARN INSTR, V40, P54, DOI 10.1016/j.learninstruc.2015.08.001
   Tuveri E., 2016, P INT WORKING C ADV, DOI DOI 10.1145/2909132.2909287
   Unimersiv, 2016, CHEM VR
   Whitson C., 2009, Journal of Cross- Disciplinary Perspectives in Education, V2, P40
   Winkelmann K, 2014, J CHEM EDUC, V91, P1432, DOI 10.1021/ed500009e
   Winter J, 2016, J CHEM EDUC, V93, P1657, DOI 10.1021/acs.jchemed.5b00872
   Woolley J, 2010, ORGANIC MOL GAME
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
NR 55
TC 73
Z9 78
U1 15
U2 209
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 363
EP 373
DI 10.1007/s10055-018-0345-4
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300004
DA 2024-07-18
ER

PT J
AU Liu, SG
   Gao, S
AF Liu, Shiguang
   Gao, Si
TI Automatic synthesis of explosion sound synchronized with animation
SO VIRTUAL REALITY
LA English
DT Article
DE Audiovisual synchronization; Explosive sound; Combustion noise; Sound
   synthesis; Immersive virtual reality
ID SIMULATION; TEXTURES; FIRE
AB Sound is an essential element for enhancing the realness of virtual world. Currently, there are some remarkable works on the synthesis of fluid sound, such as fire and water. However, little attention has been paid to synthesizing explosion sound. This paper proposes an automatic method for synthesizing explosion sounds that are synchronized with the visual phenomena of explosion animations, including fireball generation and flame combustion. Such two types of visual animation correspond to two types of sound, which we name as explosive sound and combustion noise, respectively. For the synthesis of explosive sound, firstly, the occurrence time and duration of explosion sound are determined according to the dynamic process of fuel consumption, and then, the corresponding explosive sound is extracted from the recording examples according to the high-frequency content. For the combustion noise, we propose a synthesis method of combustion noise on the basis of the timbre similarity between sound examples and low-frequency combustion noise generated by a physical method. Finally, the two types of sound are blended respecting the occurrence and duration of the explosions and combustions parts detected in the visual stream. Our experiments and the user study show the results of our method and demonstrate the effectiveness of our method.
C1 [Liu, Shiguang; Gao, Si] Sch Comp Sci & Technol, Div Intelligence & Comp, Tianjin, Peoples R China.
RP Liu, SG (corresponding author), Sch Comp Sci & Technol, Div Intelligence & Comp, Tianjin, Peoples R China.
EM shgliu@126.com
FU Natural Science Foundation of China [61672375, 61170118]
FX Funding was provided by Natural Science Foundation of China (Grant Nos.
   61672375 and 61170118).
CR An SS, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185598
   [Anonymous], 1992, Modern Methods in Analytical Acoustics Lecture Notes
   Chadwick JN, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964979
   Di Scipio A., 1999, P 2 COST G 6 WORKSHO, P109
   Dobashi Y, 2004, COMPUT GRAPH FORUM, V23, P539, DOI 10.1111/j.1467-8659.2004.00785.x
   Dobashi Y, 2003, ACM T GRAPHIC, V22, P732, DOI 10.1145/882262.882339
   Dobashi Y, 2000, COMP GRAPH, P19, DOI 10.1145/344779.344795
   Doel K, 2005, ACM Trans. Appl. Percept., V2, P534, DOI [10.1145/1101530.1101554, DOI 10.1145/1101530.1101554]
   Dubnov S, 2002, IEEE COMPUT GRAPH, V22, P38, DOI 10.1109/MCG.2002.1016697
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Feng G, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1781
   Ihme M, 2009, P COMBUST INST, V32, P1545, DOI 10.1016/j.proci.2008.06.137
   Kersten S, 2013, DIGITAL AUDIO EFFECT, P1
   Liu SG, 2015, VIRTUAL REAL-LONDON, V19, P291, DOI 10.1007/s10055-015-0271-7
   Liu SG, 2013, VIRTUAL REAL-LONDON, V17, P77, DOI 10.1007/s10055-013-0222-0
   LONGUETHIGGINS MS, 1990, J FLUID MECH, V214, P395, DOI 10.1017/S0022112090000179
   Marelli D, 2012, IEEE T AUDIO SPEECH, V20, P1400, DOI 10.1109/TASL.2011.2176334
   Moss W, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805965
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Powell A, 2003, THEORY VORTEX SOUND
   Prosperetti A, 1988, BUBBLE DYNAMICS OCEA
   Roads C., 2004, Microsound
   Sato S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1766
   Schreck C., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'16, P211
   Schwarz D, 2011, DIGITAL AUDIO EFFECT, P151
   Schwarz D., 2015, SOUND MUSIC COMPUTIN, P471
   Schwarz D, 2008, SOUND MUSIC COMPUTIN, P510
   Schwarz D, 2014, LECT NOTES COMPUT SC, V8905, P372, DOI 10.1007/978-3-319-12976-1_23
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J, 2000, COMMUN ACM, V43, P76, DOI 10.1145/341852.341866
   Wang K, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1835
   Wang K, 2017, P IEEE VIRT REAL ANN, P303, DOI 10.1109/VR.2017.7892297
   Yin Q, 2018, IEEE T VIS COMPUT GR, V24, P1179, DOI 10.1109/TVCG.2016.2642958
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
NR 37
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 469
EP 481
DI 10.1007/s10055-019-00408-7
EA NOV 2019
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000542937200001
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI EXTENDED REALITY GETS REAL
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR Debevec Paul, 2018, EXPERIMENTING LIGHT
   ElKoura G., 2003, HANDRIX ANIMATING HU
   Fenlon Wesley, 2013, ADAM SAVAGES TE 0104
   Jerald J., 2017, P SIGGRAPH 17 ACM SI
   Jerald Jason, SIGGRAPH 2017 COURSE, DOI DOI 10.1145/3090000/3084900/A19-JERALD.PDF?
   Metz Rachel, 2017, MIT TECHNOLOGY  0131
   Mine Mark R., 2015, COMPUTERS GRAPHICS, V29
   Munyan BG, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157568
   Souman JL, 2009, CURR BIOL, V19, P1538, DOI 10.1016/j.cub.2009.07.053
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Surve Sajid, 2009, BRAINBLOGGER    0609
   Vanderbilt T., 2016, NAUTILUS 0107
NR 12
TC 0
Z9 0
U1 0
U2 1
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 93
EP +
PG 27
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200006
DA 2024-07-18
ER

PT J
AU Napieralski, PE
   Altenhoff, BM
   Bertrand, JW
   Long, LO
   Babu, SV
   Pagano, CC
   Davis, TA
AF Napieralski, Phillip E.
   Altenhoff, Bliss M.
   Bertrand, Jeffrey W.
   Long, Lindsay O.
   Babu, Sabarish V.
   Pagano, Christopher C.
   Davis, Timothy A.
TI An evaluation of immersive viewing on spatial knowledge acquisition in
   spherical panoramic environments
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual environments; Immersive spherical panoramas; Spatial
   updating; 3D human-computer interaction
ID TRAVEL; MAPS
AB We report the results of an experiment conducted to examine the effects of immersive viewing on a common spatial knowledge acquisition task of spatial updating task in a spherical panoramic environment (SPE). A spherical panoramic environment, such as Google Street View, is an environment that is comprised of spherical images captured at regular intervals in a real world setting augmented with virtual navigational aids such as paths, dynamic maps, and textual annotations. Participants navigated the National Mall area of Washington, DC, in Google Street View in one of two viewing conditions; desktop monitor or a head-mounted display with a head orientation tracker. In an exploration phase, participants were first asked to navigate and observe landmarks on a pre-specified path. Then, in a testing phase, participants were asked to travel the same path and to rotate their view in order to look in the direction of the perceived landmarks at certain waypoints. The angular difference between participants' gaze directions and the landmark directions was recorded. We found no significant difference between the immersive and desktop viewing conditions on participants' accuracy of direction to landmarks as well as no difference in their sense of presence scores. However, based on responses to a post-experiment questionnaire, participants in both conditions tended to use a cognitive or procedural technique to inform direction to landmarks. Taken together, these findings suggest that in both conditions where participants experience travel based on teleportation between waypoints, the visual cues available in the SPE, such as street signs, buildings and trees, seem to have a stronger influence in determining the directions to landmarks than the egocentric cues such as first-person perspective and natural head-coupled motion experienced in the immersive viewing condition.
C1 [Napieralski, Phillip E.; Bertrand, Jeffrey W.; Babu, Sabarish V.; Davis, Timothy A.] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
   [Altenhoff, Bliss M.; Long, Lindsay O.; Pagano, Christopher C.] Clemson Univ, Dept Psychol, Clemson, SC 29634 USA.
C3 Clemson University; Clemson University
RP Babu, SV (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM pnapier@clemson.edu; blissw@clemson.edu; jbertra@clemson.edu;
   lindsal@clemson.edu; sbabu@clemson.edu; cpagano@clemson.edu;
   tdavis2@clemson.edu
RI Napieralski, Piotr/K-8490-2019; Napieralski, Piotr/T-4093-2018
OI Napieralski, Piotr/0000-0003-1427-7791; Bertrand,
   Jeffrey/0000-0002-3921-4693
CR Batschelet E., 1978, ANIMAL MIGRATION NAV, P1
   Batschelet E., 1965, STAT METHODS ANAL PR
   Belongie S, 2012, RODRIGUES ROTATION F
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Darken RP, 1996, INT J HUM-COMPUT INT, V8, P49, DOI 10.1080/10447319609526140
   Gallistel CR, 1994, ORG LEARNING
   Guilford JP, 1948, J APPL PSYCHOL, V32, P24, DOI 10.1037/h0063610
   HART S G, 1988, P139
   Hu J, 2011, P 5 INT C ADV RES VI, P699
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   MITTELSTAEDT ML, 1980, NATURWISSENSCHAFTEN, V67, P566, DOI 10.1007/BF00450672
   Point Grey, 2012, LADYBUG2
   POUCET B, 1993, PSYCHOL REV, V100, P163, DOI 10.1037/0033-295X.100.2.163
   Riecke BE, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P3
   Riecke BE, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P35, DOI 10.1109/VR.2012.6180875
   SATALICH G, 1995, THESIS U WASHINGTON
   Sigurdarson S, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P31, DOI 10.1109/VR.2012.6180874
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   TURVEY MT, 1992, J EXP PSYCHOL HUMAN, V18, P714, DOI 10.1037/0096-1523.18.3.714
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Wang RF, 1993, PSYCHON B REV, V13, P281
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
NR 25
TC 9
Z9 9
U1 2
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2014
VL 18
IS 3
BP 189
EP 201
DI 10.1007/s10055-014-0245-1
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HR
UT WOS:000340621900003
DA 2024-07-18
ER

PT J
AU Renaud, P
   Trottier, D
   Rouleau, JL
   Goyette, M
   Saumur, C
   Boukhalfi, T
   Bouchard, S
AF Renaud, Patrice
   Trottier, Dominique
   Rouleau, Joanne-Lucine
   Goyette, Mathieu
   Saumur, Chantal
   Boukhalfi, Tarik
   Bouchard, Stephane
TI Using immersive virtual reality and anatomically correct
   computer-generated characters in the forensic assessment of deviant
   sexual preferences
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Pedophilia; Penile plethysmography;
   Made-to-measure virtual characters; Sexual self-regulation
ID SELF-REGULATION; PEDOPHILIA; HANDEDNESS; OFFENDERS; DYNAMICS; ETIOLOGY;
   FAILURE; RAPISTS; AROUSAL; CURVES
AB Penile plethysmography (PPG) is the gold standard for the assessment of sexual interests, especially among sex offenders of children. Nonetheless, this method faces some ethical limitations inherent to the nature of its stimuli and could benefit from the improvement of its ecological validity. The use of computer-generated characters (CGC) in virtual immersion for PPG assessment might help address these issues. A new application developed to design made-to-measure anatomically correct virtual characters compatible with the Tanner developmental stages is presented. The main purpose of this study was to determine how the virtual reality (VR) modality compares to the standard auditory modality on their capacity to generate sexual arousal profiles and deviance differentials indicative of sexual interests. The erectile responses of 22 sex offenders of children and 42 non-deviant adult males were recorded. While both stimulus modalities generated significantly different genital arousal profiles for sex offenders of children and non-deviant males, deviance differentials calculated from the VR modality allowed for significantly higher classification accuracy. Performing receiver operating characteristic analyses further assessed discriminant potential. Auditory modality yielded an area under the curve (AUC) of 0.79 (SE = 0.059) while CGC in VR yielded an AUC of 0.90 (SE = 0.052). Overall, results suggest that the VR modality allows significantly better group classification accuracy and discriminant validity than audio stimuli, which provide empirical support for the use of this new method for PPG assessment. Additionally, the potential use of VR in interventions pertaining to self-regulation of sexual offending is addressed in conclusion.
C1 [Renaud, Patrice] Univ Quebec Outaouais, Psychol & Psychoeduc Dept, Gatineau, PQ, Canada.
   [Renaud, Patrice; Goyette, Mathieu; Saumur, Chantal; Boukhalfi, Tarik; Bouchard, Stephane] Inst Philippe Pinel, Montreal, PQ, Canada.
   [Renaud, Patrice] Module Psychol, Gatineau, PQ J8X 3X7, Canada.
   [Trottier, Dominique; Rouleau, Joanne-Lucine] Univ Montreal, Dept Psychol, Montreal, PQ H3C 3J7, Canada.
C3 University of Quebec; University Quebec Outaouais; Universite de
   Montreal; Universite de Montreal
RP Renaud, P (corresponding author), Module Psychol, 283 Alexandre Tache Blvd,Room C2803, Gatineau, PQ J8X 3X7, Canada.
EM patrice.renaud@uqo.ca
OI Goyette, Mathieu/0000-0002-6830-6730; Bouchard,
   Stephane/0000-0002-5995-340X
FU Canadian Institute for Health Research; Fonds Quebecois de Recherche sur
   la Societe et la Culture
FX Financial support for this project was provided by Canadian Institute
   for Health Research, and the Fonds Quebecois de Recherche sur la Societe
   et la Culture. We would like to thank the Philippe-Pinel Institute of
   Montreal, BehaVR solutions Inc. as well as our research assistant
   Nicholas Longpre, computer scientist Sylvain Morel, and engineer Tarik
   Boukhalfi.
CR Abel G.G., 1998, Sexual Abuse: A Journal of Research and Treatment, V10, P81, DOI DOI 10.1177/107906329801000202
   Altman DG, 2000, HEART, V83, P236, DOI 10.1136/heart.83.2.236
   Andrews DA, 2006, CRIME DELINQUENCY, V52, P7, DOI 10.1177/0011128705281756
   [Anonymous], ANN C ASS TREATM SEX
   [Anonymous], ARCH SEX BEHAV
   [Anonymous], THESIS U MONTRE MONT
   [Anonymous], SEX ABUSE
   [Anonymous], ANN C ASS TREAM SEX
   [Anonymous], 2010, ICD-10: International statistical classification of diseases and related health problems, V10th
   [Anonymous], ARCH SEX BEHAV
   [Anonymous], J VIRTUAL REAL BROAD
   [Anonymous], 2002, Evaluation of the Western Australian sex offender treatment unit (1987-1999): A quantitative analysis
   [Anonymous], 06061205 WASH STAT I
   [Anonymous], COSTS CRIME
   [Anonymous], C INT FRANC AGR SEX
   [Anonymous], 2000, DIAGN STAT MAN MENT, DOI DOI 10.1176/APPI.BOOKS.9780890425787
   [Anonymous], ANN RES TREATM C ATS
   [Anonymous], 2010, CANADIAN INCIDENCE S, DOI DOI 10.1037/E611832012-001
   [Anonymous], 2012, PROP DRAFT REV DSM D
   Bailenson JM, 2008, PRESENCE-TELEOP VIRT, V17, P242, DOI 10.1162/pres.17.3.242
   Barsetti I, 1998, J INTERPERS VIOLENCE, V13, P275, DOI 10.1177/088626098013002007
   Baumeister RF, 1996, PSYCHOL INQ, V7, P1, DOI 10.1207/s15327965pli0701_1
   Birbaumer N, 2007, J PHYSIOL-LONDON, V579, P621, DOI 10.1113/jphysiol.2006.125633
   BLADER JC, 1989, CLIN PSYCHOL REV, V9, P569, DOI 10.1016/0272-7358(89)90012-3
   Blanchard R, 2003, ARCH SEX BEHAV, V32, P573, DOI 10.1023/A:1026093612434
   Blanchard R, 2001, PSYCHOL ASSESSMENT, V13, P118, DOI 10.1037/1040-3590.13.1.118
   Blanchard R, 2007, SEX ABUSE-J RES TR, V19, P285, DOI 10.1177/107906320701900307
   Blanchard R, 2009, ARCH SEX BEHAV, V38, P335, DOI 10.1007/s10508-008-9399-9
   Brunswick E., 1947, Systematic and representative design of psychological experiments
   Camilleri J.A., 2008, SEXUAL DEVIANCE THEO, V2nd, P183
   Cantor JM, 2007, SEX ABUSE-J RES TR, V19, P395, DOI 10.1007/s11194-007-9060-5
   Cantor JM, 2006, ARCH SEX BEHAV, V35, P743, DOI 10.1007/s10508-006-9018-6
   Cantor JM, 2005, ARCH SEX BEHAV, V34, P447, DOI 10.1007/s10508-005-4344-7
   Cantor JM, 2004, NEUROPSYCHOLOGY, V18, P3, DOI 10.1037/0894-4105.18.1.3
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   EARLS CM, 1983, INT J LAW PSYCHIAT, V6, P431, DOI 10.1016/0160-2527(83)90030-4
   FREUND K, 1965, BEHAV RES THER, V3, P229, DOI 10.1016/0005-7967(65)90031-8
   FREUND K, 1972, CAN J CRIMINOL CORR, V14, P345
   FREUND K, 1963, BEHAV RES THER, V1, P85, DOI 10.1016/0005-7967(63)90012-3
   Freund K., 1990, HDB SEXUAL ASSAULT I, P195, DOI [https://doi.org/10.1007/978-1-4899-0915-212, DOI 10.1007/978-1-4899-0915-212]
   Glasgow D.V., 2003, British Journal of Learning Disabilities, V31, P96, DOI [DOI 10.1046/J.1468-3156.2003.00180.X, 10.1046/j.1468-3156.2003.00180.x]
   Hanson RK, 2000, CRIM JUSTICE BEHAV, V27, P6, DOI 10.1177/0093854800027001002
   Hanson RK, 1998, J CONSULT CLIN PSYCH, V66, P348, DOI 10.1037/0022-006X.66.2.348
   Hanson RK, 2005, J CONSULT CLIN PSYCH, V73, P1154, DOI 10.1037/0022-006X.73.6.1154
   Harris G.T., 1992, PSYCHOL ASSESSMENT, V4, P502, DOI DOI 10.1037/1040-3590.4.4.502
   Hoc J., 2001, THEORETICAL ISSUES E, V2, P278, DOI DOI 10.1080/14639220110104970
   Kalmus E, 2005, AGGRESS VIOLENT BEH, V10, P193, DOI 10.1016/j.avb.2003.12.002
   KAROLY P, 1993, ANNU REV PSYCHOL, V44, P23, DOI 10.1146/annurev.psych.44.1.23
   Konopasky R.J., 2000, Remaking relapse prevention with sex offenders: A sourcebook, P257
   LALUMIERE ML, 1994, CRIM JUSTICE BEHAV, V21, P150, DOI 10.1177/0093854894021001010
   Laws D R, 2003, Sex Abuse, V15, P75, DOI 10.1023/A:1022325231175
   Laws DR, 2004, LEGAL CRIMINOL PSYCH, V9, P183, DOI 10.1348/1355325041719338
   Laws DR, 2000, J INTERPERS VIOLENCE, V15, P1297, DOI 10.1177/088626000015012004
   MALCOLM PB, 1993, J INTERPERS VIOLENCE, V8, P486, DOI 10.1177/088626093008004004
   Marshall W.L., 1999, COGNITIVE BEHAV TREA
   Marshall WL, 2003, AGGRESS VIOLENT BEH, V8, P131, DOI 10.1016/S1359-1789(01)00056-8
   MARSHALL WL, 1989, BEHAV RES THER, V27, P491, DOI 10.1016/0005-7967(89)90083-1
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   ODONOHUE W, 1992, J PSYCHOPATHOL BEHAV, V14, P123, DOI 10.1007/BF00965172
   Proulx J, 1999, Sex Abuse, V11, P117
   PROULX J, 1989, INT J LAW PSYCHIAT, V12, P275, DOI 10.1016/0160-2527(89)90019-8
   Quinsey V.L., 1988, Journal of Interpersonal Violence, V3, P259, DOI [10.1177/088626088003003001, DOI 10.1177/088626088003003001]
   QUINSEY VL, 1988, ANN NY ACAD SCI, V528, P49
   Rasmussen J., 1994, COGNITIVE SYSTEMS EN
   Renaud P, 2002, IEEE T INF TECHNOL B, V6, P235, DOI [10.1109/TITB.2002.802381, 10.1109/TITB.2002.802381.]
   Renaud P, 2002, CYBERPSYCHOL BEHAV, V5, P1, DOI 10.1089/109493102753685836
   Renaud P., 2007, Revue quebecoise de psychologie, V28, P31
   Renaud P., 2009, The Universal access handbook, p52.1
   Renaud P, 2007, CYBERPSYCHOL BEHAV, V10, P122, DOI 10.1089/cpb.2006.9983
   Renaud P, 2013, J SEX AGGRESS, V19, P102, DOI 10.1080/13552600.2011.617014
   Renaud P, 2011, PROG BRAIN RES, V192, P263, DOI 10.1016/B978-0-444-53355-5.00014-2
   Renaud P, 2010, NONLIN DYNAM PSYCHOL, V14, P463
   Seto MC, 2004, ARCH SEX BEHAV, V33, P455, DOI 10.1023/B:ASEB.0000037426.55935.9c
   Seto MC, 2006, J ABNORM PSYCHOL, V115, P610, DOI 10.1037/0021-843X.115.3.610
   Sheskin D., 2004, Handbook of parametric and nonparametric statistical procedures, P633
   Sitaram R, 2009, NEURAL NETWORKS, V22, P1320, DOI 10.1016/j.neunet.2009.05.009
   Streiner DL, 2007, CAN J PSYCHIAT, V52, P121, DOI 10.1177/070674370705200210
   TANNER JM, 1973, SCI AM, V229, P34, DOI 10.1038/scientificamerican0973-34
   Thornton David, 2002, Sex Abuse, V14, P139, DOI 10.1023/A:1014620214905
   Vicente K., 1990, Ecological Psychology, V2, P207, DOI [DOI 10.1207/S15326969ECO02032, 10.1207/s15326969-co02032, DOI 10.1207/S15326969-CO02032, 10.1207/s15326969eco0203_2, DOI 10.1207/s15326969eco0]
   Ward T, 2006, AGGRESS VIOLENT BEH, V11, P44, DOI 10.1016/j.avb.2005.05.002
   Ward T, 2006, AGGRESS VIOLENT BEH, V11, P77, DOI 10.1016/j.avb.2005.06.001
   Ward T, 2004, SEX ABUSE-J RES TR, V16, P271, DOI 10.1177/107906320401600402
   Ward T, 1998, J INTERPERS VIOLENCE, V13, P700, DOI 10.1177/088626098013006003
   WRIGHT LW, 1994, J PSYCHOPATHOL BEHAV, V16, P221, DOI 10.1007/BF02229209
NR 85
TC 38
Z9 40
U1 2
U2 48
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2014
VL 18
IS 1
SI SI
BP 37
EP 47
DI 10.1007/s10055-013-0235-8
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AB2WI
UT WOS:000331652400004
DA 2024-07-18
ER

PT J
AU Katz, BFG
   Kammoun, S
   Parseihian, G
   Gutierrez, O
   Brilhault, A
   Auvray, M
   Truillet, P
   Denis, M
   Thorpe, S
   Jouffrais, C
AF Katz, Brian F. G.
   Kammoun, Slim
   Parseihian, Gaetan
   Gutierrez, Olivier
   Brilhault, Adrien
   Auvray, Malika
   Truillet, Philippe
   Denis, Michel
   Thorpe, Simon
   Jouffrais, Christophe
TI NAVIG: augmented reality guidance system for the visually impaired
   Combining object localization, GNSS, and spatial audio
SO VIRTUAL REALITY
LA English
DT Article
DE Assisted navigation; Guidance; Spatial audio; Visually impaired
   assistive device; Need analysis
ID AUDITORY DISPLAY; ROUTE; BLIND; SUBSTITUTION; EXPLORATION; PEDESTRIANS;
   PERCEPTION; PEOPLE; SOUND; AID
AB Navigating complex routes and finding objects of interest are challenging tasks for the visually impaired. The project NAVIG (Navigation Assisted by artificial VIsion and GNSS) is directed toward increasing personal autonomy via a virtual augmented reality system. The system integrates an adapted geographic information system with different classes of objects useful for improving route selection and guidance. The database also includes models of important geolocated objects that may be detected by real-time embedded vision algorithms. Object localization (relative to the user) may serve both global positioning and sensorimotor actions such as heading, grasping, or piloting. The user is guided to his desired destination through spatialized semantic audio rendering, always maintained in the head-centered reference frame. This paper presents the overall project design and architecture of the NAVIG system. In addition, details of a new type of detection and localization device are presented. This approach combines a bio-inspired vision system that can recognize and locate objects very quickly and a 3D sound rendering system that is able to perceptually position a sound at the location of the recognized object. This system was developed in relation to guidance directives developed through participative design with potential users and educators for the visually impaired.
C1 [Katz, Brian F. G.; Parseihian, Gaetan; Auvray, Malika; Denis, Michel] Univ Paris 11, CNRS, LIMSI, F-91403 Orsay, France.
   [Kammoun, Slim; Gutierrez, Olivier; Brilhault, Adrien; Truillet, Philippe; Jouffrais, Christophe] CNRS, IRIT, Toulouse, France.
   [Kammoun, Slim; Gutierrez, Olivier; Brilhault, Adrien; Truillet, Philippe; Thorpe, Simon; Jouffrais, Christophe] Univ Toulouse 3, F-31062 Toulouse, France.
   [Brilhault, Adrien; Thorpe, Simon] CNRS, CerCo, Toulouse, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); Universite
   de Toulouse; Universite Toulouse III - Paul Sabatier; Universite
   Federale Toulouse Midi-Pyrenees (ComUE); Institut National Polytechnique
   de Toulouse; Universite de Toulouse; Universite Toulouse III - Paul
   Sabatier; Universite de Toulouse; Universite Toulouse III - Paul
   Sabatier; Centre National de la Recherche Scientifique (CNRS)
RP Katz, BFG (corresponding author), Univ Paris 11, CNRS, LIMSI, F-91403 Orsay, France.
EM brian.katz@limsi.fr; kammoun@irit.fr; gaetan.parseihian@limsi.fr;
   gutierrez@irit.fr; adrien.brilhault@cerco.ups-tls.fr;
   malika.auvray@limsi.fr; truillet@irit.fr; michel.denis@limsi.fr;
   simon.thorpe@cerco.ups-tls.fr; jouffrais@irit.fr
RI Auvray, Malika/ABU-4282-2022; Katz, Brian F.G./I-3191-2012; TRUILLET,
   PHILIPPE/AAH-5271-2020; THORPE, Simon/A-5661-2008
OI Katz, Brian F.G./0000-0001-5118-0943; Jouffrais,
   Christophe/0000-0002-0768-1019; THORPE, Simon/0000-0003-4997-3367;
   Brilhault, Adrien/0000-0002-8135-2715; Auvray,
   Malika/0000-0002-4173-8146
FU French National Research Agency (ANR) through the TecSan program [NAVIG
   ANR-08-TECS-011]; Midi-Pyrenees region through the APRRTT program
FX The NAVIG consortium includes IRIT, LIMSI, CerCo, SpikeNet Technology,
   NAVOCAP, CESDV - Institute for Young Blind, and the community of Grand
   Toulouse. This work was supported by the French National Research Agency
   (ANR) through the TecSan program (project NAVIG ANR-08-TECS-011) and the
   Midi-Pyrenees region through the APRRTT program. This research program
   has been labeled by the cluster Aerospace Valley.
CR Afonso A, 2010, MEM COGNITION, V38, P591, DOI 10.3758/MC.38.5.591
   Allen GL, 2000, APPL COGNITIVE PSYCH, V14, P333
   [Anonymous], 1994, P 1 ANN C ASS TECHN, DOI DOI 10.1145/191028.191051
   [Anonymous], 2007, MULTISENSOR DATA FUS
   [Anonymous], 2008, P 14 M INT C AUD DIS
   Auvray M, 2007, PERCEPTION, V36, P416, DOI 10.1068/p5631
   Auvray M, 2009, COGNITIVE SCI, V33, P1036, DOI 10.1111/j.1551-6709.2009.01040.x
   Bar-Shalom Y., 1987, Tracking and data association
   Begault DurandR., 1994, 3-D sound for virtual reality and multimedia
   BENTZEN BL, 1995, J VISUAL IMPAIR BLIN, V89, P494
   Berger J. O., 1985, STAT DECISION THEORY, DOI DOI 10.1007/978-1-4757-4286-2
   Bisseret A, 1999, Techniques pratiques pour l'etude des activites expertes
   BLATTNER M.M., 1989, SIGCHI BULL, V21, P123
   Brilhault A, 2011, INT C NEW TECHN MOB
   Brunet L., 2010, THESIS U PARIS SUD O
   Buisson M., 2002, P IHM 02, P223, DOI DOI 10.1145/777005.777040
   Burrough PA., 1986, MONOGRAPHS SOIL RESO, V12
   Canadian Institute for the Blind, 2005, TECHNICAL REPORT
   Cappelle C, 2010, INT C INF FUS JUN 30, P1
   Denis M, 1997, CAH PSYCHOL COGN, V16, P409
   Dingler T, 2008, LEARNABILITY SOUND C, P1
   Dramas F., 2008, ACM conference on computers and accessibility, ASSETS, Halifax, Canada, P263
   Dramas F, 2010, INT J IMAGE GRAPH, V10, P531, DOI 10.1142/S0219467810003871
   DURRANTWHYTE HF, 1988, INT J ROBOT RES, V7, P97, DOI 10.1177/027836498800700608
   Férey N, 2009, VIRTUAL REAL-LONDON, V13, P273, DOI 10.1007/s10055-009-0136-z
   FLETCHER JF, 1980, J VISUAL IMPAIR BLIN, V74, P381
   Gallay M, 2012, REPRESENTING SPACE C
   Gaunet F, 2005, HUM-COMPUT INTERACT, V20, P267, DOI 10.1207/s15327051hci2003_2
   Gaver William W, 1986, Human-computer interaction, V2, P167, DOI [10.1207/s15327051hci0202_3, DOI 10.1207/S15327051HCI0202_3]
   Golledge RG, 1998, INT J GEOGR INF SCI, V12, P727, DOI 10.1080/136588198241635
   Helal A, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P149, DOI 10.1109/ISWC.2001.962119
   Hub A., 2004, ASSETS 2004. The Sixth International ACM SIGACCESS Conference on Computers and Accessibility, P147
   Kammoun S, 2012, IRBM, V33, P182, DOI 10.1016/j.irbm.2012.01.009
   Kammoun S, 2010, INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010), P2223
   Katz B.F.G., 2010, LIMSI SPATIALISATION
   Katz BFG, 2010, WORKSH MULT LOC BAS
   Katz BFG, 2012, J TECHNOL D IN PRESS, V24
   Klatzky RL, 2006, J EXP PSYCHOL-APPL, V12, P223, DOI 10.1037/1076-898X.12.4.223
   Knapek M., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3771, DOI 10.1109/ROBOT.2000.845319
   Liu X., 2008, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, P305
   Loomis JM, 2005, J VISUAL IMPAIR BLIN, V99, P219, DOI 10.1177/0145482x0509900404
   Loomis JM, 1998, PRESENCE-TELEOP VIRT, V7, P193, DOI 10.1162/105474698565677
   Loomis JM, 2006, APPL SPATIAL COGNITI
   Marston JamesR., 2006, ACM T APPL PERCEPT, V3, P110, DOI [DOI 10.1145/1141897.1141900, 10.1145/1141897.1141900]
   MARSTON R.G., 2004, Journal of Visual Impairment and Blindness, V98, P135, DOI DOI 10.1177/0145482X0409800304
   Ménélas B, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P51, DOI 10.1109/3DUI.2010.5444722
   Noordzij ML, 2006, COGNITION, V100, P321, DOI 10.1016/j.cognition.2005.05.006
   Parlouar R, 2009, ASSETS'09: PROCEEDINGS OF THE 11TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P227
   Parseihian G, 2012, J AUDIO ENG SO UNPUB
   Parseihian G, 2010, WORKSH MULT LOC BAS
   Ran L, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P23, DOI 10.1109/PERCOM.2004.1276842
   RD - J ACOBSON., 1997, - Transactions in Geographic Information Systems, V2, P315, DOI [10.1111/j.1467-9671.1997.tb00060.x, DOI 10.1111/J.1467-9671.1997.TB00060.X]
   Roentgen U.R., 2008, J. Vis. Impair. Blind, V102, P702, DOI [DOI 10.1177/0145482X0810201105, 10.1177/0145482X0810201105]
   Sang-Kyeong Park, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P3970
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   STROTHOTTE T, 1995, ASSIST TECHN RES SER, V1, P348
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Thrun S., 2002, EXPLORING ARTIFICIAL, P1, DOI DOI 10.5555/779343.779345
   Tran TV, 2000, ERGONOMICS, V43, P807, DOI 10.1080/001401300404760
   Vézien JM, 2009, VIRTUAL REAL-LONDON, V13, P257, DOI 10.1007/s10055-009-0134-1
   Völkel T, 2008, LECT NOTES COMPUT SC, V5105, P1085, DOI 10.1007/978-3-540-70540-6_163
   Walker BN., 2005, P INT C AUDITORY DIS, P260
   Walker BN, 2006, P INT C AUD DISPL, P95
   Walker BN, 2006, HUM FACTORS, V48, P265, DOI 10.1518/001872006777724507
   Zheng JH, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P452, DOI 10.1109/MUE.2009.80
NR 65
TC 95
Z9 105
U1 2
U2 58
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2012
VL 16
IS 4
BP 253
EP 269
DI 10.1007/s10055-012-0213-6
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 025YG
UT WOS:000310233000001
DA 2024-07-18
ER

PT J
AU Ma, S
   Varley, M
   Shark, LK
   Richards, J
AF Ma, Sha
   Varley, Martin
   Shark, Lik-Kwan
   Richards, Jim
TI Overcoming the information overload problem in a multiform
   feedback-based virtual reality system for hand motion rehabilitation:
   healthy subject case study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual world; User training for immersive environment; Multiform
   feedback; Hand motion; Function rehabilitation; EMG
ID ELECTRO-MYOGRAPHIC BIOFEEDBACK; LOWER-EXTREMITIES; STROKE; ARM
AB The use of composite multiple feedback in a newly proposed virtual reality system enables the patient to perceive similar real-world performance in the virtual world. However, it might cause information overload, which makes the patient feel confused and distracted during training. The aim of this study is to investigate the effectiveness of having separate function-specific feedback pre-training prior to the final multiform feedback task. During the evaluating tests with thirty healthy subjects, it has been found that effective pre-training set could overcome the problem in the main task. Minor modifications on the pre-training set could overcome or aggravate the problem, which indicates the importance of choosing the correct pre-training parameters.
C1 [Ma, Sha; Varley, Martin; Shark, Lik-Kwan] Univ Cent Lancashire, ADSIP Res Ctr, Sch Comp Engn & Phys Sci, Preston PR1 2HE, Lancs, England.
   [Richards, Jim] Univ Cent Lancashire, Allied Hlth Res Unit, Sch Sport Tourism & Outdoors, Preston PR1 2HE, Lancs, England.
C3 University of Central Lancashire; University of Central Lancashire
RP Ma, S (corresponding author), Univ Cent Lancashire, ADSIP Res Ctr, Sch Comp Engn & Phys Sci, Preston PR1 2HE, Lancs, England.
EM SMa@uclan.ac.uk; MRVarley@uclan.ac.uk; LShark@uclan.ac.uk;
   JRichards@uclan.ac.uk
RI Ma, Sha/AAE-2499-2019; Richards, Jim/AAI-7331-2020
OI Richards, Jim/0000-0002-4004-3115
CR Adamovich SV, 2005, PRESENCE-VIRTUAL AUG, V14, P161, DOI 10.1162/1054746053966996
   [Anonymous], INTRO BIOL STAT
   [Anonymous], 3SPACE FASTRAK US MA
   [Anonymous], MM06 SANT BARB CAL U
   [Anonymous], FUNDAMENTAL CONCEPTS
   BINDER SA, 1981, PHYS THER, V61, P886, DOI 10.1093/ptj/61.6.886
   Broeren J, 2008, STUD HEALTH TECHNOL, V136, P77
   Burdea G. C., 2003, Virtual reality technology
   Crosbie J., 2008, Proc. 7th ICDVRAT with ArtAbilitation, P229
   Dursun E, 2004, DISABIL REHABIL, V26, P116, DOI 10.1080/09638280310001629679
   FRIDLUND AJ, 1986, PSYCHOPHYSIOLOGY, V23, P567, DOI 10.1111/j.1469-8986.1986.tb00676.x
   Holden MK., 2002, Neurol Rep, V26, P62, DOI DOI 10.1097/01253086-200226020-00003
   Huang H, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-11
   Koritnik T, 2008, GAIT POSTURE, V27, P323, DOI 10.1016/j.gaitpost.2007.04.015
   Ma S, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P51, DOI 10.1109/CW.2009.25
   Norman G. R., 2000, BIOSTATISTICS BARE E
   Richards J., 2008, BIOMECHANICS CLIN RE
   Stewart JC, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-21
   Subramanian S, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-20
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Viau Antonin, 2004, J Neuroeng Rehabil, V1, P11, DOI 10.1186/1743-0003-1-11
   WOLF SL, 1983, PHYS THER, V63, P1448, DOI 10.1093/ptj/63.9.1448
   Zardoshti-Kermani M., 1995, IEEE Transactions on Rehabilitation Engineering, V3, P324, DOI 10.1109/86.481972
NR 23
TC 5
Z9 5
U1 0
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2012
VL 16
IS 4
BP 325
EP 334
DI 10.1007/s10055-012-0209-2
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 025YG
UT WOS:000310233000006
DA 2024-07-18
ER

PT J
AU Echegaray, G
   Borro, D
AF Echegaray, G.
   Borro, D.
TI A methodology for optimal voxel size computation in collision detection
   algorithms for virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Collision detection; Voxel size; Uniform spatial partitioning;
   Optimization
AB Real-time Virtual Reality applications require accuracy but are also time dependent; therefore, in these environments, the time consumption is particularly important. For that reason, when facing the problem of Collision Detection for a Virtual Reality application, we firstly focus our attention on optimizing time performance for collisions among objects. Spatial Partitioning algorithms have been broadly used in Collision Detection. In particular, voxel-based methods are simple and quick, but finding the optimum voxel size is not trivial. We propose a methodology to easily determine the optimal voxel size for Collision Detection algorithms. Using an algorithm which represents volumetric objects with tetrahedra as an example, a performance cost function is defined in order to analytically bound the voxel size that gives the best computation times. This is made by inferring and estimating all the parameters involved. Thus, the cost function is delimited to depend only on geometric data. By doing so, it is possible to determine the optimal voxelization for any algorithm and scenario. Several solutions have been researched and compared. Experimental results with theoretical and real 3D models have validated the methodology. The reliability of our research has also been compared with traditional experimental solutions given by previous works.
C1 [Echegaray, G.; Borro, D.] CEIT, Dept Appl Mech, Navarra, Spain.
   [Echegaray, G.; Borro, D.] Tecnun Univ Navarra, Navarra, Spain.
C3 University of Navarra; University of Navarra
RP Echegaray, G (corresponding author), CEIT, Dept Appl Mech, Navarra, Spain.
EM gechegaray@ceit.es; dborro@ceit.es
RI Borro, Diego/J-5433-2019
OI Borro, Diego/0000-0002-8789-4777
FU Government of Navarra within Education department
FX This work has been partially funded by the Government of Navarra within
   the Plan de Formacion y de Investigacion y Desarrollo program that
   belongs to the Education department. The authors are also grateful to
   Prof. Dr. Matthias Teschner (Computer Graphics Laboratory, University of
   Freiburg, Germany) for his support to carry out the collision detection
   algorithm, as well as his suggestions and comments on the subsequent
   study.
CR [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   Bielser D, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P116, DOI 10.1109/PCCGA.2000.883933
   Borro D, 2004, COMPUT GRAPH FORUM, V23, P13, DOI 10.1111/j.1467-8659.2004.00002.x
   Bradshaw G., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P33, DOI DOI 10.1145/545261.545267
   BRUNET P, 1990, ACM T GRAPHIC, V9, P170, DOI 10.1145/78956.78959
   Fünfzig C, 2003, PROC GRAPH INTERF, P257
   GARCIAALONSO A, 1994, IEEE COMPUT GRAPH, V14, P36, DOI 10.1109/38.279041
   Gissler M, 2009, LECT NOTES COMPUT SC, V5875, P79, DOI 10.1007/978-3-642-10331-5_8
   Gissler M, 2009, COMPUT ANIMAT VIRT W, V20, P355, DOI 10.1002/cav.298
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Gregory A, 2000, COMP GEOM-THEOR APPL, V15, P69, DOI 10.1016/S0925-7721(99)00041-3
   Heidelberger B, 2003, VISION, MODELING, AND VISUALIZATION 2003, P461
   Heidelberger B, 2004, VMV 04
   Hubbard P. M., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P24, DOI 10.1109/VRAIS.1993.378267
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   Kockro RA, 2007, NEUROSURGERY, V61, P379, DOI 10.1227/01.neu.0000303997.12645.26
   Kockro RA, 2009, NEUROSURGERY, V64, P216, DOI 10.1227/01.NEU.0000343744.46080.91
   Larsson T., 2001, PROC EUROGRAPHICS, P325, DOI DOI 10.2312/EGS.20011005
   Lin M.C., 1998, PROC IMA C MATH SURF, P37
   Madera FA, 2010, THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS: ACHI 2010, P107, DOI 10.1109/ACHI.2010.11
   Malone HR, 2010, NEUROSURGERY, V67, P1105, DOI 10.1227/NEU.0b013e3181ee46d0
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Melax S, 2000, PROC GRAPH INTERF, P213
   Schmidl H., 2004, Journal of Graphics Tools, V9, P1, DOI 10.1080/10867651.2004.10504891
   Smith A., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P136, DOI 10.1109/VRAIS.1995.512489
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Teschner M., 2004, Eurographics State-of-the-Art Report, P119
   van den Bergen G, 2004, COLLISION DETECTION
   Volino P, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P257, DOI 10.1109/CGI.2000.852341
   Zachmann G, 1998, P IEEE VIRT REAL ANN, P90, DOI 10.1109/VRAIS.1998.658428
NR 30
TC 5
Z9 7
U1 1
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2012
VL 16
IS 3
BP 205
EP 213
DI 10.1007/s10055-011-0199-5
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 990MV
UT WOS:000307635900003
DA 2024-07-18
ER

PT J
AU Champion, E
   Bishop, I
   Dave, B
AF Champion, Erik
   Bishop, Ian
   Dave, Bharat
TI The Palenque project: evaluating interaction in an online virtual
   archaeology site
SO VIRTUAL REALITY
LA English
DT Article
DE Palenque; Virtual heritage; Cultural learning; Mayan
AB This case study evaluated the effect on cultural understanding of three different interaction modes, each teamed with a specific slice of the digitally reconstructed environment. The three interaction modes were derived from an initial descriptive theory of cultural learning as instruction, observation and action. A major aim was to ascertain whether task performance was similar to the development of understanding of the cultural context reached by participation in the virtual environment. A hypothesis was that if task performance is equivalent to understanding and engagement, we might be able to evaluate the success of virtual heritage environments (through engagement and education), without having to annoy the user with post-experience questionnaires. However, results suggest interaction in virtual heritage environments is so contextually embedded; subjective post-test questionnaires can still be more reliable than evaluating task performance.
C1 [Champion, Erik] Massey Univ, Auckland Sch Design, Auckland, New Zealand.
   [Bishop, Ian] Univ Melbourne, Dept Infrastruct Engn, Parkville, Vic 3052, Australia.
   [Dave, Bharat] Univ Melbourne, Fac Architecture Bldg & Planning, Parkville, Vic 3052, Australia.
C3 Massey University; University of Melbourne; University of Melbourne
RP Champion, E (corresponding author), Massey Univ, Auckland Sch Design, Auckland, New Zealand.
EM e.champion@massey.ac.nz; i.bishop@unimelb.edu.au; b.dave@unimelb.edu.au
RI Bishop, Ian/E-7518-2015; Champion, Erik Malcolm/R-7080-2019
OI Bishop, Ian/0000-0003-3604-1042; Champion, Erik
   Malcolm/0000-0002-5362-6176
FU Australian Research Council SPIRT; Lonely Planet Publications
FX An Australian Research Council SPIRT grant in collaboration with Lonely
   Planet Publications supported this research: special thanks to Dr Ron
   Gallagher from Lonely Planet. Dr Graham Hepworth provided valuable
   statistics consulting.
CR Barnhart E. L., 1998, PALENQUE MAPPING PRO
   Barnhart Edwin L., 1999, PALENQUE MAPPING PRO
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Foster LynnV., 2002, HDB LIFE ANCIENT MAY
   Grube Nikolai., 1996, 8 PALENQUE ROUND TAB, P1
   HARTMAN J, 1996, VRML 2 0 HDB
   Kremer J, 1996, 8 PALENQUE ROUND TAB, P1
   Oman C, 2003, EUROLAB SPACELAB MIS, P69
   ReillyIII F. K., 1989, 7 PALENQUE ROUND TAB, P1
   Ruiz R, 2004, VIRT C WORLD HER DIG
   Schele Linda., 1998, CODE KINGS
   Spero J, 1994, 7 PALENQUE ROUND TAB, P1
   Taube Karl., 1985, 5 PALENQUE ROUND TAB, VVII.
NR 13
TC 12
Z9 12
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2012
VL 16
IS 2
BP 121
EP 139
DI 10.1007/s10055-011-0191-0
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 949EO
UT WOS:000304559300003
DA 2024-07-18
ER

PT J
AU Kim, K
   Oh, S
   Lee, J
   Essa, I
AF Kim, Kihwan
   Oh, Sangmin
   Lee, Jeonggyu
   Essa, Irfan
TI Augmenting aerial earth maps with dynamic information from videos
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Augmented virtual reality; Video analysis; Computer
   vision; Computer graphics; Tracking; View synthesis; Procedural
   rendering
AB We introduce methods for augmenting aerial visualizations of Earth (from tools such as Google Earth or Microsoft Virtual Earth) with dynamic information obtained from videos. Our goal is to make Augmented Earth Maps that visualize plausible live views of dynamic scenes in a city. We propose different approaches to analyze videos of pedestrians and cars in real situations, under differing conditions to extract dynamic information. Then, we augment an Aerial Earth Maps (AEMs) with the extracted live and dynamic content. We also analyze natural phenomenon (skies, clouds) and project information from these to the AEMs to add to the visual reality. Our primary contributions are: (1) Analyzing videos with different viewpoints, coverage, and overlaps to extract relevant information about view geometry and movements, with limited user input. (2) Projecting this information appropriately to the viewpoint of the AEMs and modeling the dynamics in the scene from observations to allow inference (in case of missing data) and synthesis. We demonstrate this over a variety of camera configurations and conditions. (3) The modeled information from videos is registered to the AEMs to render appropriate movements and related dynamics. We demonstrate this with traffic flow, people movements, and cloud motions. All of these approaches are brought together as a prototype system for a real-time visualization of a city that is alive and engaging.
C1 [Kim, Kihwan; Oh, Sangmin; Lee, Jeonggyu; Essa, Irfan] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Oh, Sangmin] Kitware Inc, Clifton Pk, NY USA.
   [Lee, Jeonggyu] Intel Corp, Hillsboro, OR 97124 USA.
C3 University System of Georgia; Georgia Institute of Technology; Kitware,
   Inc.; Intel Corporation
RP Kim, K (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM kihwan23@cc.gatech.edu; sangmin.oh@kitware.com; jeonggyu.lee@intel.com;
   irfan@cc.gatech.edu
FU Google Research Award
FX This project was in part funded by a Google Research Award. We would
   like to thank Nick Diakopoulos, Matthias Grundmann, Myungcheol Doo and
   Dongryeol Lee for their help and comments on the work. Thanks also to
   the Georgia Tech Athletic Association (GTAA) for sharing with us videos
   of the college football games for research purposes. Finally, thanks to
   the reviewers for their valuable comments.
CR [Anonymous], IEEE COMP SOC C COMP
   Buhmann M.D., 2003, C MO AP C M, V12, DOI 10.1017/CBO9780511543241
   Chen GN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360702
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Frey BJ, 1998, ADV NEUR IN, V10, P479
   GIRGENSOHN A, 2007, ACM MULTIMEDIA 07, P423
   Harris M.J., 2005, ACM SIGGRAPH 2005 CO, P222
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Horry Y., 1997, SIGGRAPH 97, P225
   KANADE T, 2001, EYEVISION SYSTEM SUP
   Klein G., 2007, 6 IEEE ACM INT S MIX
   KOLLERMEIER EB, 2001, JRAS
   Kosecká J, 2002, LECT NOTES COMPUT SC, V2353, P476
   Lewis J.P., 1989, ALGORITHMS SOLID NOI
   Man P., 2006, CENTRAL EUROPEAN SEM, P1
   Pearl J., 1988, PROBABILISTIC REASON
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Rabaud V., 2006, CVPR 06 P IEEE COMPU, P17
   Ramanan D., 2003, NIPS
   Reynolds C.W., 1999, GDC 99 P GAME DEVELO, P768
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sawhney H., 2002, Thirteenth Eurographics Workshop on Rendering, P157
   Sebe I.O., 2003, IWVS 03 1 ACM SIGMM, P107
   SEITZ SM, 1996, SIGGRAPH, P21
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smart J., 2007, METAVERSE ROADMAP PA
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Wang N., 2004, Journal of Graphics Tools, V9, P21, DOI 10.1080/10867651.2004.10504895
   Wang Y, 2007, IEEE T VIS COMPUT GR, V13, P1568, DOI 10.1109/TVCG.2007.70544
   Wood D.M., 2006, SURVEILLANCE STUDIES
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zotti G, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P9
NR 37
TC 7
Z9 9
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 185
EP 200
DI 10.1007/s10055-010-0186-2
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200009
DA 2024-07-18
ER

PT J
AU Karkee, M
   Steward, BL
   Kelkar, AG
   Kemp, ZT
AF Karkee, Manoj
   Steward, Brian L.
   Kelkar, Atul G.
   Kemp, Zachary T., II
TI Modeling and real-time simulation architectures for virtual prototyping
   of off-road vehicles
SO VIRTUAL REALITY
LA English
DT Article
DE Real-time simulation; Distributed architecture; Virtual reality; Vehicle
   dynamics models; Multi-rate simulation
ID ENVIRONMENT
AB Virtual Reality-based simulation technology has evolved as a useful design and analysis tool at an early stage in the design for evaluating performance of human-operated agricultural and construction machinery. Detecting anomalies in the design prior to building physical prototypes and expensive testing leads to significant cost savings. The efficacy of such simulation technology depends on how realistically the simulation mimics the real-life operation of the machinery. It is therefore necessary to achieve 'real-time' dynamic simulation of such machines with operator-in-the-loop functionality. Such simulation often leads to intensive computational burdens. A distributed architecture was developed for off-road vehicle dynamic models and 3D graphics visualization to distribute the overall computational load of the system across multiple computational platforms. Multi-rate model simulation was also used to simulate various system dynamics with different integration time steps, so that the computational power can be distributed more intelligently. This architecture consisted of three major components: a dynamic model simulator, a virtual reality simulator for 3D graphics, and an interface to the controller and input hardware devices. Several off-road vehicle dynamics models were developed with varying degrees of fidelity, as well as automatic guidance controller models and a controller area network interface to embedded controllers and user input devices. The simulation architecture reduced the computational load to an individual machine and increased the real-time simulation capability with complex off-road vehicle system models and controllers. This architecture provides an environment to test virtual prototypes of the vehicle systems in real-time and the opportunity to test the functionality of newly developed controller software and hardware.
C1 [Karkee, Manoj; Steward, Brian L.] Iowa State Univ, Agr & Biosyst Engn Dept, Ames, IA 50011 USA.
   [Kelkar, Atul G.; Kemp, Zachary T., II] Iowa State Univ, Dept Mech Engn, Ames, IA 50011 USA.
C3 Iowa State University; Iowa State University
RP Steward, BL (corresponding author), Iowa State Univ, Agr & Biosyst Engn Dept, 214B Davidson Hall, Ames, IA 50011 USA.
EM bsteward@iastate.edu
OI Karkee, Manoj/0000-0001-5337-4848
FU Hatch Act fund [3612]; State of Iowa fund [3612]; Deere Co.
FX This research of the Iowa Agriculture and Home Economics Experiment
   Station, Ames, Iowa, Project No. 3612, was supported by Hatch Act and
   State of Iowa funds. The authors would like to thank Deere & Co. for
   their technical and financial support.
CR Antonya Csaba, 2007, Virtual Reality, V11, P275, DOI 10.1007/s10055-007-0074-6
   BOSCH R, 1991, CAN SPECIFICATION VE, V30
   CASTILLOEFFEN MW, 2005, P IEEE INT C SYST MA
   COUTEE AS, 2002, P ASME DES ENG TECHN
   Cremer J, 1996, IEEE COMPUT GRAPH, V16, P16, DOI 10.1109/38.536270
   Cuadrado J, 2004, PRODUCT ENGINEERING: ECO-DESIGN, TECHNOLOGIES AND GREEN ENERGY, P253
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   Eberhard P., 2006, P EUROMECH C 476 FER
   Fales R, 2005, J DYN SYST-T ASME, V127, P415, DOI 10.1115/1.1985437
   Fritzson P, 2002, P 35 ANN SIM S SAN D
   GLINSKY E, 2002, P SUMM COMP SIM C 14
   GRACANIN D, 1999, P IEEE INT S IND EL
   Howard Brad M., 2007, Virtual Reality, V11, P207, DOI 10.1007/s10055-007-0069-3
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   JOHNSON TC, 2001, P ASME DES ENG TECHN
   KANG HS, 2004, P ACM SIGGRAPH INT C
   KARKEE M, 2008, 084761 ASABE
   KIM CE, 2003, SME DES ENG TECHN C
   LIN Q, 1997, P IEEE INT C ROB AUT
   Livani MA, 1999, CONTROL ENG PRACT, V7, P1515, DOI 10.1016/S0967-0661(99)00128-8
   PAZUL K, 2009, CONTROLLER AREA NETW
   Sastry L., 1998, Virtual Reality, V3, P235, DOI 10.1007/BF01408704
   Savall J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2887, DOI 10.1109/IRDS.2002.1041709
   Schulz M, 1998, IEEE COMPUT GRAPH, V18, P46, DOI 10.1109/38.734979
   STANKOVIC JA, 1988, COMPUTER, V21, P10, DOI 10.1109/2.7053
   Wan H., 2004, P ASME DES ENG TECHN
   ZHU Z, 2004, P ASME DES ENG TECHN
NR 27
TC 24
Z9 29
U1 0
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2011
VL 15
IS 1
SI SI
BP 83
EP 96
DI 10.1007/s10055-009-0150-1
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HZ
UT WOS:000296280000007
DA 2024-07-18
ER

PT J
AU Payandeh, S
   Shi, FH
AF Payandeh, Shahram
   Shi, Fuhan
TI Interactive multi-modal suturing
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual suturing; Suture model; Wound closure; Tissue tearing; Haptic
   feedback; Surgical training environment; Serious games
ID SURGERY SIMULATION
AB We present a mechanics-based interactive multi-modal environment designed as part of a serious gaming platform. The specific objectives are to teach basic suturing and knotting techniques for simple skin or soft tissue wound closure. The pre-wound suturing target, skin, or deformable tissue is modeled as a modified mass-spring system. The suturing material is designed as a mechanics-based deformable linear object. Tools involved in a typical suturing procedures are also simulated. Collision management modules between the soft tissue and the needle, the soft tissue and the suture are analyzed. In addition to modeling the interactive environment of a typical suturing procedure, basics of the modeling approaches on the evaluation of a stitch formed by the user are also discussed. For example, if needle insertion points are too close from each other or to the edge of the wound, when the suture is pulled, the suture will tear the soft tissue instead of suturing the incision together. Experiment results show that our simulator can run on a standard personal computer and allow users to perform different suturing patterns with smooth graphics and haptic feedback.
C1 [Payandeh, Shahram; Shi, Fuhan] Simon Fraser Univ, Expt Robot & Graph Lab, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Payandeh, S (corresponding author), Simon Fraser Univ, Expt Robot & Graph Lab, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
EM shahram@cs.sfu.ca
RI Payandeh, Shahram/IZQ-1865-2023
OI Payandeh, Shahram/0000-0001-6846-7289
CR BARAFF D, 1997, ACM SIGGRAPH COURSE
   Berkley J., 1999, Virtual Reality, V4, P203, DOI 10.1007/BF01418156
   Berkley J, 2004, IEEE T VIS COMPUT GR, V10, P314, DOI 10.1109/TVCG.2004.1272730
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   BroNielsen M, 1996, COMPUT GRAPH FORUM, V15, pC57
   Brown J, 2004, VISUAL COMPUT, V20, P165, DOI 10.1007/s00371-003-0226-y
   BROWN J, 2001, P MED IM COMP COMP A
   Cao DQ, 2006, INT J SOLIDS STRUCT, V43, P760, DOI 10.1016/j.ijsolstr.2005.03.059
   Cha JJ, 2007, IEEE INT CONF ROBOT, P2576, DOI 10.1109/ROBOT.2007.363853
   CHEN DT, 1992, COMP GRAPH, V26, P89, DOI 10.1145/142920.134016
   COLGATE JE, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P140, DOI 10.1109/IROS.1995.525875
   Gregoire M., 2006, P 2006 ACM S SOLID P, P95
   HUI Z, 2004, P 2004 IEEE INT C RO, P3908
   Hutchinson D., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P31
   Kahl B, 2005, 2005 12TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, P115
   LeDuc M, 2003, PROC GRAPH INTERF, P273
   LENOIR J, 2004, 2 INT S MED SIM ISMS, P105
   Lenoir Julien., 2002, ESAIM P, V12, P102, DOI DOI 10.1051/PROC:2002017
   Lian L. L., 2006, Computer-Aided Design and Applications, V3, P203
   Marshall P, 2005, IEEE INTL CONF CONTR, P31
   Marshall P, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P241
   Meyer M, 2001, J VISUAL COMP ANIMAT, V12, P1, DOI 10.1002/vis.244
   MOODY L, 2001, P EUR
   Pai DK, 2002, COMPUT GRAPH FORUM, V21, P347, DOI 10.1111/1467-8659.00594
   Payandeh S, 2001, 2001 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P224, DOI 10.1109/CIRA.2001.1013201
   Phillips J, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P841, DOI 10.1109/ROBOT.2002.1013462
   PROVOT X, 1995, GRAPH INTER, P147
   ROBERT VO, 1999, J AM COL SURG, V189, P114
   Saha M, 2006, IEEE INT CONF ROBOT, P2478, DOI 10.1109/ROBOT.2006.1642074
   *SENSABLE TECHN IN, 2005, OPENHAPTICS TOOLK VE
   *SENSABLE TECHN IN, 2005, PENHAPTICS TOOLK VER
   Shi HF, 2007, IEEE INT CONF ROBOT, P2570, DOI 10.1109/ROBOT.2007.363852
   Takamatsu J, 2006, IEEE T ROBOT, V22, P65, DOI 10.1109/TRO.2005.855988
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Vafai NM, 2010, VIRTUAL REAL-LONDON, V14, P85, DOI 10.1007/s10055-009-0132-3
   Wakamatsu H, 2005, IEEE INT CONF ROBOT, P1028
   Wakamatsu H, 2006, INT J ROBOT RES, V25, P371, DOI 10.1177/0278364906064819
   WANG C, 2003, P SPIE DES TEST INT
   WANG F, 2005, P 1 JOINT EUR C S HA
   Webster RW, 2001, ST HEAL T, V81, P567
NR 41
TC 11
Z9 11
U1 0
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2010
VL 14
IS 4
BP 241
EP 253
DI 10.1007/s10055-010-0174-6
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HX
UT WOS:000296279800003
DA 2024-07-18
ER

PT J
AU Gil-López, C
   Guixeres, J
   Moghaddasi, M
   Khatri, J
   Marin-Morales, J
   Alcañiz, M
AF Gil-Lopez, Cristina
   Guixeres, Jaime
   Moghaddasi, Masoud
   Khatri, Jaikishan
   Marin-Morales, Javier
   Alcaniz, Mariano
TI Recognizing shopper demographics from behavioral responses in a virtual
   reality store
SO VIRTUAL REALITY
LA English
DT Article
DE Consumer demographics; Eye-tracking (ET); Navigation; Machine learning;
   Virtual store; Virtual reality; Shopping experience
ID GENDER-DIFFERENCES; EYE-TRACKING; SEX-DIFFERENCES; AGE; ONLINE;
   EXPERIENCE; TIME; NEUROSCIENCE; NAVIGATION; ATTENTION
AB The use of virtual reality (VR) technology in the context of retail is a significant trend in current consumer research, as it offers market researchers a unique opportunity to measure purchase behavior more realistically. Yet, effective methods for assessing the virtual shopping experience based on consumer's demographic characteristics are still lacking. In this study, we examine the validity of behavioral biometrics for recognizing the gender and age of customers in an immersive VR environment. We used behavior measures collected from eye-tracking, body posture (head and hand), and spatial navigation sources. Participants (n = 57) performed three tasks involving two different purchase situations. Specifically, one task focused on free browsing through the virtual store, and two other tasks focused on product search. A set of behavioral features categorized as kinematic, temporal, and spatial domains was processed based on two strategies. First, the relevance of such features in recognizing age and gender with and without including the spatial segmentation of the virtual space was statistically analyzed. Second, a set of implicit behavioral features was processed and demographic characteristics were recognized using a statistical supervised machine learning classifier algorithm via a support vector machine. The results confirmed that both approaches were significantly insightful for determining the gender and age of buyers. Also, the accuracy achieved when applying the machine learning classifier (> 70%) indicated that the combination of all metrics and tasks was the best classification strategy. The contributions of this work include characterizing consumers in v-commerce spaces according to the shopper's profile.
C1 [Gil-Lopez, Cristina; Guixeres, Jaime; Moghaddasi, Masoud; Khatri, Jaikishan; Marin-Morales, Javier; Alcaniz, Mariano] Univ Politecn Valencia, Inst Invest & Innovac Bioingn, Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Gil-López, C (corresponding author), Univ Politecn Valencia, Inst Invest & Innovac Bioingn, Valencia, Spain.
EM cgillop@upvnet.upv.es
RI Marin, Javier/AAL-1463-2020; Alcaniz, Mariano/I-9659-2016
OI Marin, Javier/0000-0003-1271-2892; Gil-Lopez,
   Cristina/0000-0001-5024-1716; Alcaniz, Mariano/0000-0001-9207-0636
FU European Commission [H2020-MSCA-ITN-2018-813234]; Generalitat Valenciana
   [PROMETEU/2019/105]; European Regional Development Fund program of the
   Valencian Community [IDIFEDER/2018/029]
FX This work was supported by the European Commission (Project RHUMBO
   H2020-MSCA-ITN-2018-813234), by the "Rebrand" project funded by the
   Generalitat Valenciana, grant number PROMETEU/2019/105, and by the
   European Regional Development Fund program of the Valencian Community
   2014-2020 project "Interfaces de realidad mixta aplicada a salud y toma
   de decisiones," grant number IDIFEDER/2018/029.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   Alcañiz M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01530
   Alcañiz M, 2009, PRESENCE-TELEOP VIRT, V18, P97, DOI 10.1162/pres.18.2.97
   Andersen NE, 2012, NEUROBIOL LEARN MEM, V97, P81, DOI 10.1016/j.nlm.2011.09.007
   [Anonymous], 2020, bbc
   Arnett J.J., 2006, EMERGING ADULTS AM, P3
   Bailey KO, 2014, COMPUT SECUR, V43, P77, DOI 10.1016/j.cose.2014.03.005
   Barnes S., 2016, UNDERSTANDING VIRTUA, DOI DOI 10.2139/SSRN.2909100
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Bergstrom JCR, 2013, INT J HUM-COMPUT INT, V29, P541, DOI 10.1080/10447318.2012.728493
   Bigné E, 2016, J BUS RES, V69, P1423, DOI 10.1016/j.jbusres.2015.10.119
   Bogomolova S, 2016, AUSTRALAS MARK J, V24, P108, DOI 10.1016/j.ausmj.2016.01.002
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Borges A, 2013, INT J RETAIL DISTRIB, V41, P498, DOI 10.1108/IJRDM-02-2012-0014
   Bressoud E, 2013, J PROD BRAND MANAG, V22, P286, DOI 10.1108/JPBM-05-2012-0141
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   BROWN M., 2003, EUR J MARKETING, V37, P1666, DOI [10.1108/03090560310495401, DOI 10.1108/03090560310495401]
   Burke R.R., 2018, Innovative Research Methodologies in Management: Volume II: Futures, Biometrics and Neuroscience Research, P63, DOI DOI 10.1007/978-3-319-64400-4_3
   Campagne A, 2005, BIOL PSYCHOL, V68, P353, DOI 10.1016/j.biopsycho.2004.05.003
   Chandrasekar KS., 2013, I MANAGERS J MANAGEM, V7, P35, DOI [10.26634/jmgt.7.4.2260, DOI 10.26634/JMGT.7.4.2260]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang TS, 2016, ASIA PAC J MARKET LO, V28, P650, DOI 10.1108/APJML-11-2015-0171
   Chartrand TL, 2005, J CONSUM PSYCHOL, V15, P203, DOI 10.1207/s15327663jcp1503_4
   Chebat JC, 2008, J BUS RES, V61, P1076, DOI 10.1016/j.jbusres.2007.09.021
   Cherubino P, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/1976847
   Cleveland M, 2011, INT MARKET REV, V28, P244, DOI 10.1108/02651331111132848
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Croson R, 2009, J ECON LIT, V47, P448, DOI 10.1257/jel.47.2.448
   Dad AM., 2016, INT J ADV COMPUT SC, DOI [10.14569/IJACSA.2016.070204#sthash.TjZMref4.dpuf, DOI 10.14569/IJACSA.2016.070204#STHASH.TJZMREF4.DPUF]
   DAVIES G, 1991, INT J RETAIL DISTRIB, V19, P25, DOI DOI 10.1108/09590559110143512
   Deary IJ, 2009, BRIT MED BULL, V92, P135, DOI 10.1093/bmb/ldp033
   Del Din S, 2016, PHYSIOL MEAS, V37, P1785, DOI 10.1088/0967-3334/37/10/1785
   Desmet P, 2013, RECH APPL MARKET-ENG, V28, P70, DOI 10.1177/2051570713487473
   Dittmar H, 2004, SEX ROLES, V50, P423, DOI 10.1023/B:SERS.0000018896.35251.c7
   Dotson M, 2004, SALES PROMOTION PREF
   Driscoll I, 2005, HORM BEHAV, V47, P326, DOI 10.1016/j.yhbeh.2004.11.013
   Drolet A., 2019, Consumer Psychology Review, V2, P3
   Du Yanan, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022104
   Elboudali A, 2020, INT J INTERACT DES M, V14, P551, DOI 10.1007/s12008-020-00645-0
   Fang JM, 2016, J ELECTRON COMMER RE, V17, P116
   Farah MF, 2019, J RETAIL CONSUM SERV, V48, P136, DOI 10.1016/j.jretconser.2019.02.016
   Felnhofer A, 2012, P INT SOC PRESENCE R, DOI [10.1016/j.jretconser.2019.02.016, DOI 10.1016/J.JRETCONSER.2019.02.016]
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Flavián C, 2019, J TRAVEL TOUR MARK, V36, P847, DOI 10.1080/10548408.2019.1618781
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373
   Garbarino E, 2004, J BUS RES, V57, P768, DOI 10.1016/S0148-2963(02)00363-6
   Gazova I, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00094
   Ghisletta P, 2012, INTELLIGENCE, V40, P260, DOI 10.1016/j.intell.2012.02.008
   Grewal D, 2017, J RETAILING, V93, P1, DOI 10.1016/j.jretai.2016.12.008
   Guixeres J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01808
   Guo F, 2016, INT J IND ERGONOM, V53, P229, DOI 10.1016/j.ergon.2015.12.001
   Hadnett-Hunter J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3352763
   Halpern D.F., 2000, Sex Differences in Cognitive Abilities, V3rd, DOI DOI 10.4324/9781410605290
   Harmon S. K., 2003, Journal of Product & Brand Management, V12, P166, DOI 10.1108/10610420310476924
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Hasan B, 2010, COMPUT HUM BEHAV, V26, P597, DOI 10.1016/j.chb.2009.12.012
   Hill JeanneC., 2009, Academy of Marketing Studies Journal, V13, P67
   Hsu M, 2015, CURR OPIN BEHAV SCI, V5, P116, DOI 10.1016/j.cobeha.2015.09.005
   HTC Vive Pro, 2020, ABOUT US
   Hwang YM, 2018, INT J HUM-COMPUT INT, V34, P15, DOI 10.1080/10447318.2017.1314611
   Jansen P, 2010, EXP PSYCHOL, V57, P54, DOI 10.1027/1618-3169/a000007
   Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081
   Kang HG, 2009, GAIT POSTURE, V30, P260, DOI 10.1016/j.gaitpost.2009.05.003
   Khatri J., 2020, HCI INT 2020 POSTERS, P64
   Khatri J, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.752073
   Kizony R., 2017, Innovation in Aging, V1, P773
   Köster EP, 2003, FOOD QUAL PREFER, V14, P359, DOI 10.1016/S0950-3293(03)00017-X
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Laroche M, 2000, J CONSUM MARK, V17, P500, DOI 10.1108/07363760010349920
   Lau KW, 2019, VIRTUAL REAL-LONDON, V23, P255, DOI 10.1007/s10055-018-0362-3
   LENI, 2021, LABL
   Lian JW, 2014, COMPUT HUM BEHAV, V37, P133, DOI 10.1016/j.chb.2014.04.028
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Llanes-Jurado J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174956
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   Marín-Morales J, 2019, INTERACT COMPUT, V31, P208, DOI 10.1093/iwc/iwz018
   Martin BAS, 2003, PSYCHOL MARKET, V20, P249, DOI 10.1002/mar.10070
   Martínez-Navarro J, 2019, J BUS RES, V100, P475, DOI 10.1016/j.jbusres.2018.10.054
   Mathias JD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59713-w
   Meissner F, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02483
   Meissner M, 2020, J BUS RES, V117, P219, DOI 10.1016/j.jbusres.2020.06.004
   Meissner M, 2019, J BUS RES, V100, P445, DOI 10.1016/j.jbusres.2017.09.028
   Menon RGV, 2016, J BUS RES, V69, P5008, DOI 10.1016/j.jbusres.2016.04.072
   Moffat SD, 2002, BEHAV NEUROSCI, V116, P851, DOI 10.1037//0735-7044.116.5.851
   Moghaddasi M., 2020, HCI INT 2020 POSTERS, P92
   Moghaddasi M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104399
   Moon J.H., 2013, Journal of Interactive Advertising, V13, P14, DOI DOI 10.1080/15252019.2013.768051
   Moreno R, 2004, J EDUC PSYCHOL, V96, P165, DOI 10.1037/0022-0663.96.1.165
   Mueller SC, 2008, BEHAV BRAIN RES, V193, P209, DOI 10.1016/j.bbr.2008.05.017
   Nazareth A, 2019, PSYCHON B REV, V26, P1503, DOI 10.3758/s13423-019-01633-6
   Needel SP, 1998, J ADVERTISING RES, V38, P61
   Oh H, 2008, CLOTH TEXT RES J, V26, P143, DOI 10.1177/0887302X08314789
   Pantano E, 2012, J RETAIL CONSUM SERV, V19, P279, DOI 10.1016/j.jretconser.2012.02.002
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Petukhov IV, 2020, INT J MED INFORM, V136, DOI 10.1016/j.ijmedinf.2019.103977
   Peukert C, 2019, J MANAGE INFORM SYST, V36, P755, DOI 10.1080/07421222.2019.1628889
   Pfeiffer J, 2020, INFORM SYST RES, V31, P675, DOI 10.1287/isre.2019.0907
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Pizzi G, 2019, COMPUT HUM BEHAV, V96, P1, DOI 10.1016/j.chb.2019.02.008
   Plassmann H, 2015, J MARKETING RES, V52, P427, DOI 10.1509/jmr.14.0048
   Plechatá A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01330
   Pound C., 2000, British Food Journal, V102, P810, DOI 10.1108/00070700010362239
   Radojka K., 2017, Acta Economica Et Turistica, V3, P5, DOI [10.1515/aet-2017-0002, DOI 10.1515/AET-2017-0002]
   Ravaja N, 2013, J NEUROSCI PSYCHOL E, V6, P1, DOI 10.1037/a0029949
   Richards D, 2015, COMPUT EDUC, V86, P157, DOI 10.1016/j.compedu.2015.03.009
   Rodgers M Kirk, 2012, Neurobiol Aging, V33, DOI 10.1016/j.neurobiolaging.2010.07.021
   Salthouse TA, 2009, NEUROBIOL AGING, V30, P507, DOI 10.1016/j.neurobiolaging.2008.09.023
   Salvucci D.D., 2000, P 2000 S EYE TRACK R, P71, DOI [DOI 10.1145/355017.355028, 10.1145/355017.355028]
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sargezeh BA, 2019, PHYSIOL BEHAV, V206, P43, DOI 10.1016/j.physbeh.2019.03.023
   Schnack A, 2020, J CONSUM BEHAV, V19, P182, DOI 10.1002/cb.1803
   Schneider J, 1997, CROSS VALIDATION LOC, V1
   Sebastianelli R, 2008, J INTERNET COMMER, V7, P445, DOI 10.1080/15332860802507164
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Siegrist M, 2019, FOOD RES INT, V117, P50, DOI 10.1016/j.foodres.2018.02.033
   Silva ES, 2021, J RETAIL CONSUM SERV, V60, DOI 10.1016/j.jretconser.2020.102430
   Slater M, 1996, VIRTUAL ANTEROOM ASS
   SOMMER R, 1992, ENVIRON BEHAV, V24, P285, DOI 10.1177/0013916592243001
   Spiers MV, 2008, CYBERPSYCHOL BEHAV, V11, P471, DOI 10.1089/cpb.2007.0058
   Steam, 2020, ABOUT US
   Steinicke F., 2009, Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization, P19, DOI 10.1145/1620993.1620998
   Tlauka M, 2005, J ENVIRON PSYCHOL, V25, P111, DOI 10.1016/j.jenvp.2004.12.002
   TOBII, 2021, ABOUT US
   Tupikovskaja-Omovie Z., 2020, Symposium on Eye Tracking Research and Applications (ETRA'20 Adjunct), P1, DOI DOI 10.1145/3379157.3391305
   Unity, 2020, UN TECHN
   van der Laan LN, 2015, FOOD QUAL PREFER, V39, P46, DOI 10.1016/j.foodqual.2014.06.015
   Velev Dimiter, 2019, International Journal of e-Education, e-Business, e-Management and e-Learning, V9, P131, DOI 10.17706/ijeeee.2019.9.2.131-137
   Vipul PP, 2010, ADV MANAG, V3
   Wagner G, 2020, J BUS RES, V107, P256, DOI 10.1016/j.jbusres.2018.10.048
   Waller D, 2000, J EXP PSYCHOL-APPL, V6, P307, DOI 10.1037//1076-898X.6.4.307
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Wedel M, 2020, INT J RES MARK, V37, P443, DOI 10.1016/j.ijresmar.2020.04.004
   Wenzlaff F, 2016, J SEX RES, V53, P1008, DOI 10.1080/00224499.2015.1107524
   Wolfinbarger M, 2001, CALIF MANAGE REV, V43, P34, DOI 10.2307/41166074
   Woodside AG, 2011, J BRAND MANAG, V18, P451, DOI 10.1057/bm.2011.8
   Xue L., 2020, ENGAGE FASHION RETAI, P23
   Yildirim K, 2015, INT J RETAIL DISTRIB, V43, P712, DOI 10.1108/IJRDM-01-2013-0034
   Yoon HS, 2015, INT J INFORM MANAGE, V35, P352, DOI 10.1016/j.ijinfomgt.2015.02.003
   Zaharia S, 2017, LECT NOTES COMPUT SC, V10294, P143, DOI 10.1007/978-3-319-58484-3_12
NR 140
TC 0
Z9 0
U1 13
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1937
EP 1966
DI 10.1007/s10055-023-00767-2
EA MAR 2023
PG 30
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000955813300001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Casado-Coscolla, A
   Sanchez-Belenguer, C
   Wolfart, E
   Sequeira, V
AF Casado-Coscolla, Alvaro
   Sanchez-Belenguer, Carlos
   Wolfart, Erik
   Sequeira, Vitor
TI Rendering massive indoor point clouds in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Rendering; Point cloud; Laser scanning; Lidar;
   Pre-computed visibility
AB This paper addresses the challenges of rendering massive indoor point clouds in Virtual Reality. In these kind of visualizations the point of view is never static, imposing the need of a one-shot (i.e. non-iterative) rendering strategy, in contrast with progressive refinement approaches that assume that the camera position does not change between most consecutive frames. Our approach benefits from the static nature of indoor environments to pre-compute a visibility map that enables us to boost real-time rendering performance. The key idea behind our visibility map is to exploit the cluttered topology of buildings in order to effectively cull the regions of the space that are occluded by structural elements such as walls. This does not only improve performance but also the visual quality of the final render, allowing us to display in full detail the space and preventing the user to see the contiguous spaces through the walls. Additionally, we introduce a novel hierarchical data structure that enables us to display the point cloud with a continuous level of detail with a minimal impact on performance. Experimental results show that our approach outperforms state-of-the-art techniques in complex indoor environments and achieves comparable results in outdoor ones, proving the generality of our method.
C1 [Casado-Coscolla, Alvaro; Sanchez-Belenguer, Carlos; Wolfart, Erik; Sequeira, Vitor] European Commiss Joint Res Ctr Ispra, Via E Fermi, 2749, I-21027 Ispra, Varese, Italy.
C3 European Commission Joint Research Centre
RP Casado-Coscolla, A; Sanchez-Belenguer, C (corresponding author), European Commiss Joint Res Ctr Ispra, Via E Fermi, 2749, I-21027 Ispra, Varese, Italy.
EM alvaro.casado-coscolla@ext.ec.europa.eu;
   carlos.sanchez-belenguer@ec.europa.eu; erik.wolfart@ec.europa.eu;
   vitor.sequeira@ec.europa.eu
OI Casado Coscolla, Alvaro/0000-0001-5179-1541; Sequeira,
   Vitor/0000-0001-8878-4193
CR Airey J. M., 1990, Computer Graphics, V24, P41, DOI 10.1145/91394.91416
   [Anonymous], 2014, ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., DOI DOI 10.5194/ISPRSANNALS-II-5-9-2014
   Bala K, 1999, ACM T GRAPHIC, V18, P213, DOI 10.1145/336414.336417
   Bittner J, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P207, DOI 10.1109/CGI.1998.694268
   Botsch M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P53
   Calver D, 2002, DIRECTD SHADERX VERT
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Coorg S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P83, DOI 10.1145/253284.253312
   Durand F., 2000, COMP GRAPH, V10
   Futterlieb J, 2016, IADIS-INT J COMPUT S, V11, P146
   Gobbetti E, 2004, COMPUT GRAPH-UK, V28, P815, DOI 10.1016/j.cag.2004.08.010
   Goswami P, 2013, VISUAL COMPUT, V29, P69, DOI 10.1007/s00371-012-0675-2
   Greene N., 1993, Computer Graphics Proceedings, P231, DOI 10.1145/166117.166147
   Hudson T., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P1, DOI 10.1145/262839.262847
   JONES CB, 1971, COMPUT J, V14, P232, DOI 10.1093/comjnl/14.3.232
   Katz S, 2015, IEEE I CONF COMP VIS, P1350, DOI 10.1109/ICCV.2015.159
   Katz S, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276407, 10.1145/1239451.1239475]
   Koltun V, 2000, SPRING COMP SCI, P59
   Loup G, 2016, LECT NOTES COMPUT SC, V9891, P410, DOI 10.1007/978-3-319-45153-4_35
   Mehra R, 2010, COMPUT GRAPH-UK, V34, P219, DOI 10.1016/j.cag.2010.03.002
   NAYLOR BF, 1992, GRAPH INTER, P201
   Pajarola R, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P628
   Parker S, 2005, IEEE J QUANTUM ELECT, P12, DOI [DOI 10.1145/1198555.1198751, 10.1145/1198555.1198751]
   Peng JL, 2005, ACM T GRAPHIC, V24, P609, DOI 10.1145/1073204.1073237
   Peters R, 2015, VISIBILITY ANAL POIN, DOI [10.2312/udmv.20151342, DOI 10.2312/UDMV.20151342]
   Pintus R., 2011, Proceedings of the 12th International conference on Virtual Reality, Archaeology and Cultural Heritage, P105
   Purnomo B., 2005, P ACM SIGGRAPH EUROG, P53, DOI DOI 10.1145/1071866.1071876
   Reiners T, 2014, EXPT STUDY CONSUMER
   Richter R, 2010, OUT OF CORE REAL TIM, P121, DOI [10.1145/1811158.1811178, DOI 10.1145/1811158.1811178]
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Sánchez C, 2016, COMPUT VIS IMAGE UND, V149, P197, DOI 10.1016/j.cviu.2015.11.012
   Schnabel R., 2006, P S POINT BAS GRAPH, V6, P111, DOI DOI 10.2312/SPBG/SPBG06/111-120
   Schütz M, 2020, COMPUT GRAPH FORUM, V39, P51, DOI 10.1111/cgf.13911
   Schütz M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P103, DOI [10.1109/VR.2019.8798284, 10.1109/vr.2019.8798284]
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Strugar Filip, 2009, Journal of Graphics Tools, V14, P57
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   TELLER SJ, 1991, COMP GRAPH, V25, P61, DOI 10.1145/127719.122725
   Tredinnick R, 2016, P IEEE VIRT REAL ANN, P301, DOI 10.1109/VR.2016.7504773
   WIMMER M., 2006, Proceedings of Eurographics Symposium on Point-Based Graphics 2006, P129, DOI DOI 10.2312/SPBG/SPBG06/129-136
   Wonka P, 2001, COMPUT GRAPH FORUM, V20, pC411, DOI 10.1111/1467-8659.00534
   Zhang H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P77, DOI 10.1145/258734.258781
NR 42
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1859
EP 1874
DI 10.1007/s10055-023-00766-3
EA MAR 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000942709800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, CL
   Jeon, S
   Hassan, W
   Kang, H
AF Lee, CheolWoo
   Jeon, Seokhee
   Hassan, Waseem
   Kang, HyeongYeop
TI VR unseen gaze: inducing feeling of being stared at in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Feeling of being stared at; User interfaces;
   Scopaesthesia; Unseen gaze
ID THRESHOLD; HEARING; CUES
AB The main aim of this paper is to investigate a method that can induce a VR user's feeling of being stared at. Contrary to the previous method that directly informs users of unseen gaze with a voice and subtitles, the proposed method provides an indirect subtle stimulus to induce a feeling that they are being watched. Our study began with the observations reported by the previous studies that the feeling of being stared at appears to be highly correlated with hypervigilance, anxiety, and fear of ambient information around people. To clarify this further, we additionally conducted an online survey. Based on the results of the previous studies and our online survey, we defined two types of factors that may effectively induce the user to feel that they are watched: environmental factors (darkness, absence/presence of people, reddish color palette, and suspenseful background music) and stimulative factors (subtle changes in vision, subtle changes in sound, and feeling in the back of the neck). Afterward, two experiments were conducted for in-depth investigation of environmental and stimulative factors, respectively. The purpose was to find out what kinds of factors should be provided at what strength to induce the user's feeling of being watched among the defined factors. Lastly, an application test was performed to not only clarify the advantages and limitations of the proposed method but also propose design guidelines for future use. We expect that our study will serve as a cornerstone for providing a new type of VR experience that the feeling of being watched.
C1 [Lee, CheolWoo; Kang, HyeongYeop] Kyung Hee Univ, IIIXR Lab, Yongin 17104, South Korea.
   [Jeon, Seokhee; Hassan, Waseem] Kyung Hee Univ, Hapt & Virtual Real Lab, Yongin, South Korea.
C3 Kyung Hee University; Kyung Hee University
RP Kang, H (corresponding author), Kyung Hee Univ, IIIXR Lab, Yongin 17104, South Korea.
EM lcwoo0707@khu.ac.kr; jeon@khu.ac.kr; waseem.h@khu.ac.kr;
   siamiz@khu.ac.kr
RI Hassan, Waseem/HTT-2008-2023; Kang, HyeongYeop/AAJ-2471-2020
OI Hassan, Waseem/0000-0003-3922-5648; Kang, HyeongYeop/0000-0001-5292-4342
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2020R1F1A1076528]
FX AcknowledgementsThis work was supported by Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education (NRF-2020R1F1A1076528).
CR [Anonymous], 1998, METAL GEAR SOLID
   [Anonymous], 2004, PRESENCE QUESTIONNAI
   [Anonymous], 2019, EVERYBODYS GOLF VR P
   [Anonymous], 2018, BEAT SABER PLAY STAT
   [Anonymous], 2019, APEX LEGENDS
   Bailey R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559757
   Baker IS, 2007, THESIS U EDINBURGH
   BERGER EH, 1981, J ACOUST SOC AM, V70, P1635, DOI 10.1121/1.387218
   BRAUD W, 1993, J PARAPSYCHOL, V57, P373
   BRAUD W, 1993, J PARAPSYCHOL, V57, P391
   Bruttomesso D, 2003, PATIENT EDUC COUNS, V51, P29, DOI 10.1016/S0738-3991(02)00226-4
   Calahan S, 1996, SIGGRAPH COURSE NOTE
   Campbell AbrahamG., 2019, FUTURE INFORM COMMUN, P463
   Carpenter BC, 2005, J PARAPSYCHOL, V69, P63
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen Y, 2019, LIGHTING RES TECHNOL, V51, P820, DOI 10.1177/1477153518825387
   Chwesiuk M, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343123
   Chwesiuk M, 2018, SMART INNOV SYST TEC, V73, P258, DOI 10.1007/978-3-319-59424-8_24
   Colwell J, 2000, BRIT J PSYCHOL, V91, P71, DOI 10.1348/000712600161682
   Coover JE, 1913, AM J PSYCHOL, V24, P570, DOI 10.2307/1413454
   Cottrell JE, 1996, DEV PSYCHOL, V32, P50
   Delatorre P, 2019, IEEE ACCESS, V7, P85338, DOI 10.1109/ACCESS.2019.2924200
   Dong HW, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56586
   EASTERBROOK JA, 1959, PSYCHOL REV, V66, P183, DOI 10.1037/h0047707
   Eysenck M.W., 2013, ANXIETY COGNITIVE PE
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Graja S, 2021, IEEE T GAMES, V13, P287, DOI 10.1109/TG.2020.3006053
   Joosten E., 2012, J INTELLIGENT COMPUT, V3, P76
   Jung J, 2018, INT SYM MIX AUGMENT, P70, DOI 10.1109/ISMAR.2018.00032
   KROSE BJA, 1989, VISION RES, V29, P1607, DOI 10.1016/0042-6989(89)90142-9
   Kumar S, 2017, CURR BIOL, V27, P527, DOI 10.1016/j.cub.2016.12.048
   Le Prell CG, 2012, EAR HEARING, V33, pE44, DOI 10.1097/AUD.0b013e31825f9d89
   Li R, 2019, ACMIEEE INT CONF HUM, P431, DOI [10.1109/HRI.2019.8673116, 10.1109/hri.2019.8673116]
   Liu YF, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000856
   Logos, 2020, MYSTERIOUS STRANGE T
   MATHEWS A, 1986, J ABNORM PSYCHOL, V95, P131, DOI 10.1037/0021-843X.95.2.131
   Niedenthal S, 2007, SHADOWPLAY SIMULATED
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Pandey M, 2009, P INT MARK TRENDS C, P2
   Perron Bernard, 2004, COSIGN 2004 P, P132
   Peterson D, 1978, THESIS U EDINBURGH S
   Poortman J, 1959, FEELING BEING STARED
   Rabiner LR., 2007, Introduction to digital speech processing, DOI [10.1561/9781601980717, DOI 10.1561/9781601980717]
   RAYNER K, 1975, COGNITIVE PSYCHOL, V7, P65, DOI 10.1016/0010-0285(75)90005-5
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Schaack S, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311840
   Scherer K.R., 1977, Motivation and Emotion, V1, P331, DOI DOI 10.1007/BF00992539
   Schlitz MJ, 1994, P PRES PAP PAR ASS 3, P352
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Sheldrake R, 2005, J CONSCIOUSNESS STUD, V12, P10
   Sheldrake R., 2001, J SOC PSYCHICAL RES, V65, P122
   Sheldrake R., 1996, ALTERNATIVE HLTH PRA, V2, P93
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Smith GregM., 1999, Passionate Views: Film, Cognition and Emotion, P103
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Takemitsu Toru., 1995, Confronting Silence
   TAYLOR SE, 1965, AM EDUC RES J, V2, P187, DOI 10.3102/00028312002004187
   Titchener E B, 1898, Science, V8, P895, DOI 10.1126/science.8.208.895
   Toet A, 2009, CYBERPSYCHOL BEHAV, V12, P363, DOI 10.1089/cpb.2008.0293
   VOGELS R, 1985, VISION RES, V25, P1679, DOI 10.1016/0042-6989(85)90140-3
   Wang MJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2814, DOI 10.1145/3025453.3025634
   WILLIAMS L, 1983, J PARAPSYCHOL, V47, P59
   Wiseman R, 1997, J PARAPSYCHOL, V61, P197
   Wiseman R, 1995, P PRES PAP PAR ASS 3, P480
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xu S, 2007, LECT NOTES COMPUT SC, V4563, P397
NR 66
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1529
EP 1548
DI 10.1007/s10055-023-00751-w
EA JAN 2023
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000916526300001
DA 2024-07-18
ER

PT J
AU Phelan, I
   Carrion-Plaza, A
   Furness, PJ
   Dimitri, P
AF Phelan, Ivan
   Carrion-Plaza, Alicia
   Furness, Penny J.
   Dimitri, Paul
TI Home-based immersive virtual reality physical rehabilitation in
   paediatric patients for upper limb motor impairment: a feasibility study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Patient-centred design; Upper limb motor impairment;
   Pain management; Children's rehabilitation
ID UPPER EXTREMITY FUNCTION; PROCEDURAL PAIN; CEREBRAL-PALSY; LOW-COST;
   CHILDREN; STROKE; THERAPY; MANAGEMENT; SYSTEM; GAMES
AB Upper limb motor impairment (ULMI) rehabilitation is a long-term, demanding and challenging process to recover motor functionality. Children and adolescents may be limited in daily life activities due to reduced functions such as decreased joint movement or muscle weakness. Home-based therapy with Immersive Virtual Reality can offer greater accessibility, delivery and early rehabilitation to significantly optimise functional outcomes and quality of life. This feasibility study aimed to explore the perceptions and impacts of an immersive and interactive VR scenario suitable for ULMI rehabilitation for children at home. It was analysed using mixed methods (quantitative and qualitative) and from a multidirectional perspective (patients, clinicians and family members). Amongst the main results, it was found that IVR for ULMI home rehabilitation (1) is easy to learn and acceptable; (2) improves motor function; (3) reduces the difficulty in the reproduction of therapeutic movements; (4) is motivating and enjoyable and (5) improves quality of life. This study is the first study on the use of IVR applied to home rehabilitation of ULMI in children. These results suggested that similar outcomes may be possible with self-directed IVR home rehabilitation compared to face to face conventional rehabilitation, which can be costly to both the patient and the healthcare system, decreasing the length of stay at the hospital and treatment duration. It has also presented an innovative solution to the Covid-19 emergency where children could not receive their clinic therapy. Further research is recommended to understand better the mechanisms involved in physiotherapeutic recovery and how IVR rehabilitation helps to improve conventional treatments.Trial Registration Protocol ID NCT05272436. Release Date: 9th March 2022.
C1 [Phelan, Ivan; Carrion-Plaza, Alicia] Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Culture Media & Soc, Sheffield S1 1WB, England.
   [Furness, Penny J.] Sheffield Hallam Univ, Coll Social Sci & Arts, Dept Psychol Sociol & Polit, Sheffield S1 1WB, England.
   [Dimitri, Paul] Sheffield Childrens NHS Fdn Trust, Sheffield Childrens, Sheffield S10 2TH, England.
C3 Sheffield Hallam University; Sheffield Hallam University; Sheffield
   Children's NHS Foundation Trust
RP Phelan, I (corresponding author), Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Culture Media & Soc, Sheffield S1 1WB, England.
EM I.Phelan@shu.ac.uk
OI phelan, ivan/0000-0001-5120-8256; Furness, Penny/0000-0003-4916-8800;
   Dimitri, Paul/0000-0001-7625-6713; CARRION-PLAZA,
   ALICIA/0000-0001-7815-1472
FU Medical Research Council (MRC) [152333]
FX This study was funded by the Medical Research Council (MRC)-Grant
   Number: 152333.
CR Aydin AI, 2019, J PERIANESTH NURS, V34, P1215, DOI 10.1016/j.jopan.2019.05.134
   Bortone I, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00771-6
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   CambiasoDaniel, 2017, PEDIATR CRIT CARE ME, V18, P598, DOI 10.1097/PCC.0000000000001347
   Campo-Prieto P, 2021, VIRTUAL REAL-LONDON, V25, P801, DOI 10.1007/s10055-020-00495-x
   Chan E, 2019, J PEDIATR-US, V209, P160, DOI 10.1016/j.jpeds.2019.02.034
   Chau Brian, 2020, Innov Clin Neurosci, V17, P47
   Chen YJ, 2020, J CLIN NURS, V29, P503, DOI 10.1111/jocn.15088
   Chen YP, 2014, PEDIATR PHYS THER, V26, P289, DOI 10.1097/PEP.0000000000000046
   Choi JY, 2021, DEV MED CHILD NEUROL, V63, P480, DOI 10.1111/dmcn.14762
   Choi YH, 2018, JOVE-J VIS EXP, DOI 10.3791/56241
   Crocetta TB, 2018, VIRTUAL REAL-LONDON, V22, P199, DOI 10.1007/s10055-017-0323-2
   Deutsch JE, 2008, PHYS THER, V88, P1196, DOI 10.2522/ptj.20080062
   Dodakian L, 2017, NEUROREHAB NEURAL RE, V31, P923, DOI 10.1177/1545968317733818
   Falvey JR, 2018, J BONE JOINT SURG AM, V100, P1728, DOI 10.2106/JBJS.17.01667
   Field A, 2009, Discovering statistics using SPSS
   Furness PJ, 2019, J BURN CARE RES, V40, P878, DOI 10.1093/jbcr/irz106
   Garrett B, 2014, CLIN J PAIN, V30, P1089, DOI 10.1097/AJP.0000000000000064
   Gerber CN, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0141-x
   Goyal JP, 2021, INDIAN J PEDIATR, V88, P959, DOI 10.1007/s12098-021-03924-0
   Gueye T, 2021, NEUROL NEUROCHIR POL, V55, P91, DOI 10.5603/PJNNS.a2020.0096
   Henderson A, 2007, TOP STROKE REHABIL, V14, P52, DOI 10.1310/tsr1402-52
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Jannink MJA, 2008, CYBERPSYCHOL BEHAV, V11, P27, DOI 10.1089/cpb.2007.0014
   Kiper P, 2018, ARCH PHYS MED REHAB, V99, P834, DOI 10.1016/j.apmr.2018.01.023
   Kitago Tomoko, 2013, Handb Clin Neurol, V110, P93, DOI 10.1016/B978-0-444-52901-5.00008-3
   Kong KH, 2016, TOP STROKE REHABIL, V23, P333, DOI 10.1080/10749357.2016.1139796
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee MM, 2018, MED SCI MONITOR, V24, P2590, DOI 10.12659/MSM.906451
   Levac DE, 2013, PHYSIOTHER THEOR PR, V29, P504, DOI 10.3109/09593985.2012.762078
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Liebs TR, 2020, BONE JOINT J, V102B, P755, DOI 10.1302/0301-620X.102B6.BJJ-2019-1391.R2
   López-Jaquero V, 2019, J AMB INTEL HUM COMP, V10, P2185, DOI 10.1007/s12652-017-0652-8
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Mekbib DB, 2021, ANN NY ACAD SCI, V1493, P75, DOI 10.1111/nyas.14554
   Mekbib DB, 2020, NEUROTHERAPEUTICS, V17, P1919, DOI 10.1007/s13311-020-00882-x
   Menon N, 2020, J ARTHROPLASTY, V35, P1968, DOI 10.1016/j.arth.2020.03.031
   Meyns P, 2018, DEV NEUROREHABIL, V21, P371, DOI 10.1080/17518423.2017.1295286
   National Institute for Health and Care Excellence (NICE), 2017, FRACTURES COMPLEX A
   Neilson AR, 2019, FAM PRACT, V36, P179, DOI 10.1093/fampra/cmy047
   Phelan I, 2021, J PEDIATR REHAB MED, V14, P401, DOI 10.3233/PRM-190635
   Phelan I, 2023, VIRTUAL REAL-LONDON, V27, P173, DOI 10.1007/s10055-021-00522-5
   Phelan I, 2019, J BURN CARE RES, V40, P85, DOI 10.1093/jbcr/iry052
   Piron L, 2009, J REHABIL MED, V41, P1016, DOI 10.2340/16501977-0459
   Pritchard-Wiart L, 2018, CLIN REHABIL, V32, P954, DOI 10.1177/0269215518758484
   Riddell RP, 2011, PAIN RES MANAG, V16, P321, DOI 10.1155/2011/489286
   Sandlund M, 2009, DEV MED CHILD NEUROL, V51, P173, DOI 10.1111/j.1469-8749.2008.03184.x
   Shahmoradi L, 2021, J BODYW MOV THER, V26, P113, DOI 10.1016/j.jbmt.2020.10.006
   Sharan D, 2012, WORK, V41, P3612, DOI 10.3233/WOR-2012-0667-3612
   Simonsen D, 2017, MED BIOL ENG COMPUT, V55, P1927, DOI 10.1007/s11517-017-1640-z
   Su ZH, 2021, SYST REV-LONDON, V10, DOI 10.1186/s13643-021-01592-x
   Sun HC, 2012, RES Q EXERCISE SPORT, V83, P212, DOI 10.1080/02701367.2012.10599852
   Tarakci E, 2020, J HAND THER, V33, P220, DOI 10.1016/j.jht.2019.03.012
   Thielbar KO, 2020, ARCH PHYS MED REHAB, V101, P196, DOI 10.1016/j.apmr.2019.10.182
   Threapleton K, 2016, DIGIT HEALTH, V2, DOI 10.1177/2055207616641302
   Upton Penney, 2005, Health Qual Life Outcomes, V3, P22, DOI 10.1186/1477-7525-3-22
   Walther-Larsen Soren, 2019, Hosp Pediatr, V9, P501, DOI 10.1542/hpeds.2018-0249
   Wang WL, 2019, J ARTHROPLASTY, V34, P2388, DOI 10.1016/j.arth.2019.05.020
   Wenk N, 2023, VIRTUAL REAL-LONDON, V27, P307, DOI 10.1007/s10055-021-00565-8
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P41, DOI 10.2307/3002011
   Wittmann F, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0182-1
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 62
TC 4
Z9 4
U1 4
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3505
EP 3520
DI 10.1007/s10055-023-00747-6
EA JAN 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000914408900002
PM 36686613
OA hybrid, Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, ZN
   Pan, ZG
   Li, WQ
   Su, ZY
AF Zhang, Zhenning
   Pan, Zhigeng
   Li, Weiqing
   Su, Zhiyong
TI X-Board: an egocentric adaptive AR assistant for perception in indoor
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Perception; Human-Computer interaction; X-ray
   visualization-based; Adaptive display; Visual resources
ID VISUALIZATION TECHNIQUES; SITUATION AWARENESS; AUGMENTED REALITY
AB Augmented reality (AR) has the potential to become an effective assistive technology for emergencies in the future. However, raw AR content can confuse users' visual perception and occlude information in the physical world. In this research, we propose X-Board, an X-ray visualization-based AR assistant for perception in indoor environments. In accordance with its design principles, X-Board provides visual-spatial cues by means of a grid mesh corresponding to the occluding surface in front of the target object. Meanwhile, the X-Board interacts with the physical world in real time, improving the coherence between the virtual and real worlds. To ensure the appropriate allocation of the user's visual resources, the user's visual intention is recognized based on gaze data to realize an adaptive display feature. The results of the user evaluation show that X-Board can effectively improve the accuracy and speed of the perception and reduce the cognitive load on users; thus, the usability of X-Board is confirmed. With X-Board, users could effectively perceive the spatial positions of their comrades in an indoor occluded environment in our simulated perception scenario.
C1 [Zhang, Zhenning; Li, Weiqing] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Coll Artificial Intelligence, Nanjing, Peoples R China.
   [Su, Zhiyong] Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Information Science & Technology; Nanjing University of Science &
   Technology
RP Zhang, ZN (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
EM zhenningzhang@njust.edu.cn; zgpan@hznu.edu.cn; li_weiqing@njust.edu.cn
OI Zhang, Zhenning/0000-0001-5989-3593; su, zhiyong/0000-0001-9483-5268
FU Pre-research Project of the 14th Five-Year Plan;  [50904040201]
FX AcknowledgementsThe authors wish to thank the anonymous reviewers for
   their constructive comments and the user evaluation participants for
   their time. This work was supported by the Pre-research Project of the
   14th Five-Year Plan (Grant Number: 50904040201).
CR Alghofaili R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300578
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Barnum P, 2009, INT SYM MIX AUGMENT, P111, DOI 10.1109/ISMAR.2009.5336483
   Dey A., 2011, An evaluation of augmented reality x-ray vision for outdoor navigation
   Dey A, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P127, DOI 10.1109/3DUI.2010.5444706
   Diaz C, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P111, DOI 10.1109/ISMAR.2017.28
   Dominic J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P607, DOI [10.1109/VR46266.2020.00-21, 10.1109/VR46266.2020.1581637338566]
   Endsley M.R, 2017, Situational Awareness, P129, DOI DOI 10.4324/9781315087924-9
   Endsley MR, 2021, HUM FACTORS, V63, P124, DOI 10.1177/0018720819875376
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   Eren MT, 2013, P IEEE VIRT REAL ANN, P117, DOI 10.1109/VR.2013.6549390
   Furmanski C, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P215, DOI 10.1109/ISMAR.2002.1115091
   Gagnon HC, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3449067
   Gebhardt C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P197, DOI 10.1145/3332165.3347933
   Gruenefeld Uwe, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P179, DOI 10.1145/3428361.3428402
   Gruenefeld U, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3365620
   HART S G, 1988, P139
   Hertel J, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P122, DOI 10.1109/VR50410.2021.00033
   Kalkofen D, 2011, HANDBOOK OF AUGMENTED REALITY, P65, DOI 10.1007/978-1-4614-0064-6_3
   Kyto M, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2422105.2422111
   Lilija K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300676
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Liu JJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P196, DOI [10.1109/VRW50115.2020.0-234, 10.1109/VRW50115.2020.00042]
   Livingston MA, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P56, DOI 10.1109/ISMAR.2003.1240688
   Livingston MA, 2011, VIRTUAL REAL-LONDON, V15, P175, DOI 10.1007/s10055-010-0179-1
   Livingston MA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P55, DOI 10.1109/VR.2009.4810999
   Lu FY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P930, DOI [10.1109/VR46266.2020.00118, 10.1109/VR46266.2020.1581100361198]
   Minaskan N, 2021, INT SYM MIX AUGMENT, P397, DOI 10.1109/ISMAR-Adjunct54149.2021.00091
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   Osmers, P 2020 CHI C HUMAN F, P1
   Pascale MT, 2019, HUM FACTORS, V61, P537, DOI 10.1177/0018720818814969
   Peillard E, 2019, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2019.00-13
   Pfeuffer K, 2021, COMPUT GRAPH-UK, V95, P1, DOI 10.1016/j.cag.2021.01.001
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/VR.2019.8798174, 10.1109/vr.2019.8798174]
   Sandor C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P27, DOI 10.1109/ISMAR.2010.5643547
   Sharma A, 2019, SAFETY SCI, V120, P745, DOI 10.1016/j.ssci.2019.08.016
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Tsuda T, 2006, IEICE T INF SYST, VE89D, P1781, DOI 10.1093/ietisy/e89-d.6.1781
   Uratani K, 2005, P IEEE VIRT REAL ANN, P295
   Vaziri K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P336, DOI 10.1109/VR50410.2021.00056
   Winter S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3321516
   Wither J, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P92, DOI 10.1109/ISWC.2005.41
   Zhang JY, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101432
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
   Zollmann S., 2014, Image-based X-ray visualization techniques for spatial understanding in outdoor augmented reality, DOI [10.1145/2686612.2686642, DOI 10.1145/2686612.2686642]
   Zollmann S, 2021, IEEE T VIS COMPUT GR, V27, P3808, DOI 10.1109/TVCG.2020.2986247
NR 50
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1327
EP 1343
DI 10.1007/s10055-022-00742-3
EA DEC 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000904044400002
DA 2024-07-18
ER

PT J
AU Read, T
   Sanchez, CA
   De Amicis, R
AF Read, Tyler
   Sanchez, Christopher A.
   De Amicis, Raffaele
TI The influence of attentional engagement and spatial characteristics on
   time perception in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Time perception; Attention; Spatial environment
ID SUBJECTIVE TIME; MEMORY; PERFORMANCE; COGNITION
AB Virtual reality (VR) is a simulation tool that is being used extensively to study the effects of training and perception. However, several studies have shown that some aspects of perception within VR are not always accurate. The present study investigates the perception of time within a VR environment by asking for retrospective time judgments of the length of VR experiences. These environments varied in both the level of interaction with the VR environment and also the spatial qualities of the environment itself. The judged length of time did not significantly differ between conditions based on the level of activity in the environment, but the spatial characteristics of the VR environment did produce significantly different time estimations. This finding suggests that careful attention should be paid to what and how users are trained or evaluated in VR.
C1 [Read, Tyler; Sanchez, Christopher A.; De Amicis, Raffaele] Oregon State Univ, Corvallis, OR 97331 USA.
C3 Oregon State University
RP De Amicis, R (corresponding author), Oregon State Univ, Corvallis, OR 97331 USA.
EM raffaele.deamicis@oregonstate.edu
RI Sanchez, Christopher A/A-5267-2010
OI de amicis, raffaele/0000-0002-6435-4364
CR Bansal A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40870-6
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Block RA, 2010, ACTA PSYCHOL, V134, P330, DOI 10.1016/j.actpsy.2010.03.006
   Broadway JM, 2011, ACTA PSYCHOL, V137, P115, DOI 10.1016/j.actpsy.2011.03.008
   Csikszentmihalyi M., 1975, BOREDOM ANXIETY EXPE, DOI DOI 10.2307/2065805
   Eagleman DM, 2005, J NEUROSCI, V25, P10369, DOI 10.1523/JNEUROSCI.3487-05.2005
   Filigenzi M T, 2000, Appl Occup Environ Hyg, V15, P465
   Finnegan DJ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P200, DOI 10.1145/2858036.2858065
   FRENCH JW, 1963, HIDDEN FIGURES TEST
   Green CS, 2015, CURR OPIN BEHAV SCI, V4, P103, DOI 10.1016/j.cobeha.2015.04.012
   Igarzabal FA., 2021, TMB, DOI [10.1037/tmb0000038, DOI 10.1037/TMB0000038]
   Khan A., 2006, Journal of the Indian Academy of Applied Psychology, V32, P37
   Kitajima M., 2020, 26 ACM S VIRTUAL REA, P1, DOI [10.1145/3385956.3422104, DOI 10.1145/3385956.3422104]
   Lacquaniti F, 2014, FRONT NEUROROBOTICS, V8, DOI 10.3389/fnbot.2014.00002
   Li XC, 2019, PSYCHOL REP, V122, P117, DOI 10.1177/0033294118755098
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Loomis J.M., 2003, Virtual and adaptive environments, P21
   Matthews WJ, 2016, PSYCHOL BULL, V142, P865, DOI 10.1037/bul0000045
   Matthews WJ, 2011, J EXP PSYCHOL HUMAN, V37, P1617, DOI 10.1037/a0022193
   Plumert Jodie., 2005, ACM Transactions on Applied Perception, V2, P216, DOI DOI 10.1145/1077399.1077402
   Rutrecht H, 2021, TIMING TIME PERCEPT, V9, P353, DOI 10.1163/22134468-bja10033
   Sackett AM, 2010, PSYCHOL SCI, V21, P111, DOI 10.1177/0956797609354832
   Sanchez CA, 2012, PSYCHON B REV, V19, P58, DOI 10.3758/s13423-011-0177-7
   Sander T, 2010, BCS 10 P 24 BCS INTE, P190
   Schatzschneider C, 2016, IEEE T VIS COMPUT GR, V22, P1387, DOI 10.1109/TVCG.2016.2518137
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sucala M., 2010, Cognition, Brain, V14, P231
   Unsworth N, 2009, MEMORY, V17, P635, DOI 10.1080/09658210902998047
   van der Ham IJM, 2019, COMPUT HUM BEHAV, V94, P77, DOI 10.1016/j.chb.2019.01.005
   van Wassenhove V, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001437
   Vogel DHV, 2020, PHENOMENOL COGN SCI, V19, P235, DOI 10.1007/s11097-018-9573-z
   Wittmann M, 2008, TRENDS COGN SCI, V12, P7, DOI 10.1016/j.tics.2007.10.004
   Zhao MG, 2019, LECT NOTES COMPUT SC, V11883, P312, DOI 10.1007/978-3-030-31908-3_21
NR 35
TC 4
Z9 4
U1 5
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1265
EP 1272
DI 10.1007/s10055-022-00723-6
EA DEC 2022
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000900082400001
DA 2024-07-18
ER

PT J
AU Nenna, F
   Orso, V
   Zanardi, D
   Gamberini, L
AF Nenna, Federica
   Orso, Valeria
   Zanardi, Davide
   Gamberini, Luciano
TI The virtualization of human-robot interactions: a user-centric workload
   assessment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Human-robot interaction; Human-robot collaboration;
   Mental workload; Collaborative robotic
ID REALITY APPLICATIONS; COLLABORATION; ACCEPTANCE; MOVEMENT; SYSTEMS;
   DESIGN
AB Interest in the virtualization of human-robot interactions is increasing, yet the impact that collaborating with either virtual or physical robots has on the human operator's mental state is still insufficiently studied. In the present work, we aimed to fill this gap by conducting a systematic assessment of a human-robot collaborative framework from a user-centric perspective. Mental workload was measured in participants working in synergistic co-operation with a physical and a virtual collaborative robot (cobot) under different levels of task demands. Performance and implicit and explicit workload were assessed as a function of pupil size variation and self-reporting questionnaires. In the face of a similar self-reported mental demand when maneuvering the virtual or physical cobot, operators showed shorter operation times and lower implicit workload when interacting with the virtual cobot compared to its physical counterpart. Furthermore, the benefits of collaborating with a virtual cobot most vividly manifested when the user had to position the robotic arm with higher precision. These results shed light on the feasibility and importance of relying on multidimensional assessments in real-life work settings, including implicit workload predictors such as pupillometric measures. From a broader perspective, our findings suggest that virtual simulations have the potential to bring significant advantages for both the user's mental well-being and industrial production, particularly for highly complex and demanding tasks.
C1 [Nenna, Federica; Orso, Valeria; Zanardi, Davide; Gamberini, Luciano] Univ Padua, Dipartimento Psicol Gen, Padua, Italy.
   [Nenna, Federica; Orso, Valeria; Gamberini, Luciano] Univ Padua, HIT Human Inspired Technol Ctr, Padua, Italy.
C3 University of Padua; University of Padua
RP Gamberini, L (corresponding author), Univ Padua, Dipartimento Psicol Gen, Padua, Italy.; Gamberini, L (corresponding author), Univ Padua, HIT Human Inspired Technol Ctr, Padua, Italy.
EM federica.nenna@phd.unipd.it; luciano.gamberini@unipd.it
RI Orso, Valeria/KUD-5651-2024; Nenna, Federica/AHA-0172-2022
OI Nenna, Federica/0000-0003-0353-6014; Orso, Valeria/0000-0003-2334-2882;
   Zanardi, Davide/0009-0004-7714-1060
FU Universita degli Studi di Padova within the CRUI-CARE Agreement;
   European Union [826266]; H2020 Societal Challenges Programme [826266]
   Funding Source: H2020 Societal Challenges Programme
FX Open access funding provided by Universita degli Studi di Padova within
   the CRUI-CARE Agreement. This study was partially supported by the
   European Union's Horizon 2020 programme for research, technological
   development, and demonstration under Grant (ID: 826266; Co-Adapt
   project).
CR Abidi MH, 2019, INT J ADV MANUF TECH, V105, P3743, DOI 10.1007/s00170-019-03801-3
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Berni A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071064
   Bevana N, 1991, P 4 INT C HCI
   Billings Charles E., 2018, Aviation automation: The search for a human-centered approach
   Bonferroni C.E., 1936, Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commericiali diFirenze, V8, P3
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chacon A., 2021, Designs, V5, P35
   Cherubini A, 2016, ROBOT CIM-INT MANUF, V40, P1, DOI 10.1016/j.rcim.2015.12.007
   Chowdhury A., 2020, P 11 NORD C HUM COMP, DOI [10.1145/3419249.3420161, DOI 10.1145/3419249.3420161]
   Damiani L, 2018, IFAC PAPERSONLINE, V51, P624, DOI 10.1016/j.ifacol.2018.08.388
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Greef T, 2009, LECT NOTES ARTIF INT, V5638, P219, DOI 10.1007/978-3-642-02812-0_26
   Fratczak P, 2019, HALFWAY TO THE FUTURE SYMPOSIUM (HTTF 2019), DOI 10.1145/3363384.3363403
   Friard O, 2016, METHODS ECOL EVOL, V7, P1325, DOI 10.1111/2041-210X.12584
   Hansen L. I. N., 2018, INT C HUMAN ROBOT IN
   HART S G, 1988, P139
   Hastie T., 1990, GEN ADDITIVE MODELS, DOI 10.1214/ss/1177013604
   Hockey GRJ, 1997, BIOL PSYCHOL, V45, P73
   Hormaza LA, 2019, IEEE INTL CONF IND I, P841, DOI [10.1109/INDIN41052.2019.8971967, 10.1109/indin41052.2019.8971967]
   Hsieh SY, 2018, C INT ERGONOMICS ASS, P364
   Inoue K, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P73
   Iqbal S. T., 2004, CHI 04 HUM FACT COMP, P1477, DOI [10.1145/985921.986094, DOI 10.1145/985921.986094]
   Roldán JJ, 2019, ROBOT CIM-INT MANUF, V59, P305, DOI 10.1016/j.rcim.2019.05.004
   Jingxin Zhang, 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P812, DOI 10.1109/VR.2018.8446521
   Kagermann Henning., 2015, MANAGEMENT PERMANENT, P23, DOI [10.1007/978-3-658-05014-6_2, DOI 10.1007/978-3-658-05014-6_2]
   Kaufeld Mara, 2019, Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Human Body and Motion.10th International Conference, DHM 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11581), P278, DOI 10.1007/978-3-030-22216-1_21
   Keogh E.J., 2001, P 2001 SIAM INT C DA, P1, DOI [DOI 10.1137/1.9781611972719.1, 10.1137/1.9781611972719.1]
   Kramer AF, 1991, Multiple Task Performance, DOI DOI 10.1201/9781003069447-14/PHYSIOLOGICAL-METRICS-MENTAL-WORKLOAD-REVIEW-RECENT-PROGRESS-ARTHUR-KRAMER
   Krenn B, 2021, ARXIV
   Kret ME, 2019, BEHAV RES METHODS, V51, P1336, DOI 10.3758/s13428-018-1075-y
   Layer-Wagner, 2021, COBOT STUDIO VR VIRT
   Li R, 2019, ACMIEEE INT CONF HUM, P431, DOI [10.1109/HRI.2019.8673116, 10.1109/hri.2019.8673116]
   Linn C, 2017, P I CON VIR SYS MULT, P453
   Lipton JI, 2018, IEEE ROBOT AUTOM LET, V3, P179, DOI 10.1109/LRA.2017.2737046
   Liu HY, 2020, J MANUF SYST, V54, P24, DOI 10.1016/j.jmsy.2019.11.001
   Malik AA, 2020, INT J COMPUT INTEG M, V33, P22, DOI 10.1080/0951192X.2019.1690685
   Marangunic N, 2015, UNIVERSAL ACCESS INF, V14, P81, DOI 10.1007/s10209-014-0348-1
   Martín-Barrio A, 2020, VIRTUAL REAL-LONDON, V24, P541, DOI 10.1007/s10055-019-00414-9
   Mathot S., 2018, J COGN, DOI 10.5334/joc.18
   Mathôt S, 2018, BEHAV RES METHODS, V50, P94, DOI 10.3758/s13428-017-1007-2
   Matsas E, 2018, ROBOT CIM-INT MANUF, V50, P168, DOI 10.1016/j.rcim.2017.09.005
   Matsas E, 2017, INT J INTERACT DES M, V11, P139, DOI 10.1007/s12008-015-0259-2
   Meijman TF., 2013, HDB WORK ORG PSYCHOL, P15
   Melluso N., 2020, ARXIV
   Mingardi M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186416
   Nachreiner F, 2006, SAFETY SCI, V44, P5, DOI 10.1016/j.ssci.2005.09.003
   NAVON D, 1987, J EXP PSYCHOL HUMAN, V13, P435, DOI 10.1037/0096-1523.13.3.435
   Nee A.Y., 2013, IFAC P VOLUMES, V46, P15, DOI [10.3182/20130619-3-RU-3018.00637, DOI 10.3182/20130619-3-RU-3018.00637]
   Oyekan JO, 2019, ROBOT CIM-INT MANUF, V55, P41, DOI 10.1016/j.rcim.2018.07.006
   Peters T, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL WORKSHOP ON HARDWARE AND ARCHITECTURAL SUPPORT FOR SECURITY AND PRIVACY (HASP '18), DOI 10.1145/3214292.3214295
   Pratticò FG, 2021, COMPUT IND, V129, DOI 10.1016/j.compind.2021.103446
   Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek
   Rossato C, 2021, CYBERPSYCH BEH SOC N, V24, P349, DOI 10.1089/cyber.2020.0180
   RStudio Team, 2020, RStudio: Integrated Development for R
   Savur C, 2019, IEEE SYS MAN CYBERN, P385, DOI 10.1109/SMC.2019.8914593
   Schrepp M., 2015, USER EXPERIENCE QUES
   Shirzad N, 2016, J MOTOR BEHAV, V48, P31, DOI 10.1080/00222895.2015.1035430
   Van Acker BB, 2020, INT J IND ERGONOM, V75, DOI 10.1016/j.ergon.2019.102891
   Van Orden KF, 2001, HUM FACTORS, V43, P111, DOI 10.1518/001872001775992570
   van Rij J, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519832483
   Wang HY, 2019, IEEE ANN INT CONF CY, P175, DOI [10.1109/cyber46603.2019.9066493, 10.1109/CYBER46603.2019.9066493]
   Wang LH, 2014, CIRP ANN-MANUF TECHN, V63, P1, DOI 10.1016/j.cirp.2014.03.013
   Weistroffer V, 2014, IEEE ROMAN, P377, DOI 10.1109/ROMAN.2014.6926282
   Whitney D, 2018, IEEE INT C INT ROBOT, P5018, DOI 10.1109/IROS.2018.8593513
   Wieling M, 2018, J PHONETICS, V70, P86, DOI 10.1016/j.wocn.2018.03.002
   Wood S.N., 2017, Generalized Additive Models, DOI 10.1201/9781315370279
   Xiao JH, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420925293
NR 71
TC 5
Z9 6
U1 2
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 553
EP 571
DI 10.1007/s10055-022-00667-x
EA JUL 2022
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000830267400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Pai, YS
   Bait, ML
   Lee, J
   Xu, JJ
   Peiris, RL
   Woo, W
   Billinghurst, M
   Kunze, K
AF Pai, Yun Suen
   Bait, Marsel L.
   Lee, Juyoung
   Xu, Jingjing
   Peiris, Roshan L.
   Woo, Woontack
   Billinghurst, Mark
   Kunze, Kai
TI NapWell: An EOG-based Sleep Assistant Exploring the Effects of Virtual
   Reality on Sleep Onset
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Sleep onset; Electrooculography
ID EXPOSURE THERAPY; STIMULATION; WAKEFULNESS; QUALITY; IMPACT; SOUND;
   TIME; NAP
AB We present NapWell, a Sleep Assistant using virtual reality (VR) to decrease sleep onset latency by providing a realistic imagery distraction prior to sleep onset. Our proposed prototype was built using commercial hardware and with relatively low cost, making it replicable for future works as well as paving the way for more low cost EOG-VR devices for sleep assistance. We conducted a user study (n = 20) by comparing different sleep conditions; no devices, sleeping mask, VR environment of the study room and preferred VR environment by the participant. During this period, we recorded the electrooculography (EOG) signal and sleep onset time using a finger tapping task (FTT). We found that VR was able to significantly decrease sleep onset latency. We also developed a machine learning model based on EOG signals that can predict sleep onset with a cross-validated accuracy of 70.03%. The presented study demonstrates the feasibility of VR to be used as a tool to decrease sleep onset latency, as well as the use of embedded EOG sensors with VR for automatic sleep detection.
C1 [Pai, Yun Suen; Bait, Marsel L.; Xu, Jingjing; Kunze, Kai] Keio Univ, Grad Sch Media Design, Yokohama, Kanagawa, Japan.
   [Lee, Juyoung; Woo, Woontack] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Peiris, Roshan L.] Rochester Inst Technol, New York, NY USA.
   [Billinghurst, Mark] Univ Auckland, Auckland, New Zealand.
C3 Keio University; Korea Advanced Institute of Science & Technology
   (KAIST); Rochester Institute of Technology; University of Auckland
RP Pai, YS (corresponding author), Keio Univ, Grad Sch Media Design, Yokohama, Kanagawa, Japan.
EM pai@kmd.keio.ac.jp
RI Xu, Jingjing/ACJ-3010-2022; Woo, Woontack/C-3696-2012; Billinghurst,
   Mark/AAJ-4236-2020
OI Xu, Jingjing/0000-0002-0443-547X; Woo, Woontack/0000-0002-5501-4421;
   Billinghurst, Mark/0000-0003-4172-6759; Pai, Yun
   Suen/0000-0002-6090-2837; Peiris, Roshan Lalintha/0000-0002-4191-3565
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government(MSIT); Japan Society for the
   Promotion of Science (JSPS) Kakenhi [18H03278]; Grants-in-Aid for
   Scientific Research [18H03278] Funding Source: KAKEN
FX This work was partly supported by Institute of Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government(MSIT) (No., WISE AR UI/UX Platform Development for
   Smartglasses), as well as the Japan Society for the Promotion of Science
   (JSPS) Kakenhi Grant Number 18H03278.
CR Adib F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P837, DOI 10.1145/2702123.2702200
   AKERT K, 1952, AM J PHYSIOL, V168, P260, DOI 10.1152/ajplegacy.1951.168.1.260
   Amores Judith., 2016, P 2016 CHI C EXTENDE, P2
   [Anonymous], 2004, THESIS
   Bait M, 2019, SLEEP SURVEY
   Bernardino C., 2016, Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video, P171, DOI DOI 10.1145/2932206.2933565
   Berry R., 2020, The AASM manual for the scoring of sleep and associated events: rules, terminology and technical specifications
   Blake H., 1939, Factors Influencing Brain Potentials during Sleep
   Borazio Marko., 2012, Proceedings of the 2nd ACM SIGHITInternational Health Informatics Symposium. IHI '12, P71, DOI DOI 10.1145/2110363.2110375
   BOUKADOUM AM, 1986, PSYCHOPHYSIOLOGY, V23, P598, DOI 10.1111/j.1469-8986.1986.tb00678.x
   Brown FC, 2002, BEHAV MED, V28, P33, DOI 10.1080/08964280209596396
   Casagrande M, 1997, SLEEP, V20, P301, DOI 10.1093/sleep/20.4.301
   Choe EK, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P121, DOI 10.1145/2750858.2804266
   Daneshmandi Mohammad, 2012, J Caring Sci, V1, P135, DOI 10.5681/jcs.2012.020
   Davis H, 1939, J NEUROPHYSIOL, V2, P500, DOI 10.1152/jn.1939.2.6.500
   Demoule A, 2017, CRIT CARE, V21, DOI 10.1186/s13054-017-1865-0
   Ehleringer EH, 2013, CHI 13 EXTENDED ABST, P409
   Felsten G, 2009, J ENVIRON PSYCHOL, V29, P160, DOI 10.1016/j.jenvp.2008.11.006
   Ferrer-Garcia M, 2013, J CONTEMP PSYCHOTHER, V43, P207, DOI 10.1007/s10879-013-9240-1
   Green A, 2017, CHRONOBIOL INT, V34, P855, DOI 10.1080/07420528.2017.1324878
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.000-5, 10.1109/VR46266.2020.1581313729558]
   Harvey AG, 2002, BEHAV RES THER, V40, P869, DOI 10.1016/S0005-7967(01)00061-4
   Hu RF, 2010, CRIT CARE, V14, DOI 10.1186/cc8965
   Ibáñez V, 2018, PEERJ, V6, DOI 10.7717/peerj.4849
   Ishimaru S, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P239, DOI 10.1145/2638728.2638795
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Jirakittayakorn N, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00387
   JOHNS MW, 1991, SLEEP, V14, P540, DOI 10.1093/sleep/14.6.540
   Kanady JC, 2011, J SLEEP RES, V20, P214, DOI 10.1111/j.1365-2869.2010.00858.x
   Katsumata K, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P1174, DOI 10.1145/3341162.3347079
   Kitson A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173917
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Krishnan A, 2018, IEEE ENG MED BIO, P1287, DOI 10.1109/EMBC.2018.8512521
   Lack L., 1995, SLEEP RES, V24, P218
   Lee M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00425
   Liang SF, 2015, IEEE T INSTRUM MEAS, V64, P2977, DOI 10.1109/TIM.2015.2433652
   Liang ZL, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010988
   Liberson W T, 1965, Recent Adv Biol Psychiatry, V8, P295
   Masato K., 2018, P INT S COMP NETW C, P1
   Matsui S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P265, DOI 10.1145/3123024.3129264
   Mednick SC, 2002, NAT NEUROSCI, V5, P677, DOI 10.1038/nn864
   Metsis V, 2014, PERS UBIQUIT COMPUT, V18, P19, DOI 10.1007/s00779-012-0623-1
   Milner CE, 2009, J SLEEP RES, V18, P272, DOI 10.1111/j.1365-2869.2008.00718.x
   Min JK, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P477, DOI 10.1145/2556288.2557220
   MoralesCobas G, 1995, J SLEEP RES, V4, P242, DOI 10.1111/j.1365-2869.1995.tb00174.x
   Muzet A, 2007, SLEEP MED REV, V11, P135, DOI 10.1016/j.smrv.2006.09.001
   Nan Zhao, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090096
   NICHOLSON AN, 1987, ERGONOMICS, V30, P1033, DOI 10.1080/00140138708965993
   Ogilvie RD, 2001, SLEEP MED REV, V5, P247, DOI 10.1053/smrv.2001.0145
   OGILVIE RD, 1989, SLEEP, V12, P458, DOI 10.1093/sleep/12.5.458
   OGILVIE RD, 1984, PSYCHOPHYSIOLOGY, V21, P510, DOI 10.1111/j.1469-8986.1984.tb00234.x
   OGILVIE RD, 1988, SLEEP, V11, P139, DOI 10.1093/sleep/11.2.139
   Okamura T, 2016, ADJUNCT PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS: COMPUTING NETWORKING AND SERVICES (MOBIQUITOUS 2016), P47, DOI 10.1145/3004010.3004014
   Pedemonte M, 2014, SLEEP SCI, V7, P143, DOI 10.1016/j.slsci.2014.09.011
   Peña JL, 1999, BRAIN RES, V816, P463, DOI 10.1016/S0006-8993(98)01194-9
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Rahman MM, 2018, COMPUT BIOL MED, V102, P211, DOI 10.1016/j.compbiomed.2018.08.022
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Rothbaum BO, 1999, J TRAUMA STRESS, V12, P263, DOI 10.1023/A:1024772308758
   Rothkrantz L, 2016, COMPUTER SYSTEMS AND TECHNOLOGIES, COMPSYSTECH'16, P214, DOI 10.1145/2983468.2983487
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schmidt A, 2012, IEEE PERVAS COMPUT, V11, P4, DOI 10.1109/MPRV.2012.63
   Scott H., 2017, SM J SLEEP DISORD, V3, P1015
   Scott H, 2018, J SLEEP RES, V27, P90, DOI 10.1111/jsr.12575
   Semertzidis NA, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300804
   Shaw C., 2010, Metaplasticity in Virtual Worlds: Aesthetics and Semantics Concepts, P121, DOI [DOI 10.4018/978-1-60960-077-8.CH007, 10.4018/978-1-60960-077-8, DOI 10.4018/978-1-60960-077-8]
   Shirazi AS, 2013, INT J HUM-COMPUT ST, V71, P878, DOI 10.1016/j.ijhcs.2013.03.001
   Uema Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P297, DOI 10.1145/3123024.3123189
   Wells AS, 1997, PHYSIOL BEHAV, V61, P679, DOI 10.1016/S0031-9384(96)00519-7
   Yazdannik Ahmad Reza, 2014, Iran J Nurs Midwifery Res, V19, P673
   Zhang Z, 2014, IEEE ENG MED BIO, P2265, DOI 10.1109/EMBC.2014.6944071
NR 72
TC 5
Z9 5
U1 2
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 437
EP 451
DI 10.1007/s10055-021-00571-w
EA SEP 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000698072100001
DA 2024-07-18
ER

PT J
AU Ververidis, D
   Migkotzidis, P
   Nikolaidis, E
   Anastasovitis, E
   Chalikias, AP
   Nikolopoulos, S
   Kompatsiaris, I
AF Ververidis, Dimitrios
   Migkotzidis, Panagiotis
   Nikolaidis, Efstathios
   Anastasovitis, Eleftherios
   Papazoglou Chalikias, Anastasios
   Nikolopoulos, Spiros
   Kompatsiaris, Ioannis
TI An authoring tool for democratizing the creation of high-quality VR
   experiences
SO VIRTUAL REALITY
LA English
DT Article
DE VR authoring tools; Transpiling; Culture
AB The contribution of this paper is toward three directions, namely (a) in identifying the advantages and disadvantages of the current state-of-the-art methods that allow laymen in programming to author VR experiences; (b) in examining how easily non-experts in programming can author VR experiences by analysing the responses from several testers toward easiness and usability when using the proposed authoring tool; and (c) in treating a serious disadvantage of state-of-the-art methods, namely the low quality in graphics by proposing a novel methodology for transpiling web-based formats such as three.js into high performance runtime formats like Unity3D. The proposed authoring tool is a plugin for WordPress that exploits its interfaces and database for providing a 3D editor suitable for authoring VR experiences. It embeds the proposed methodology which achieves an one-to-one matching between three.js, WordPress and Unity3D entities to achieve transpiling. Evaluation results indicate the positive adoption of non-experts in programming, but there is still several improvements to be made.
C1 [Ververidis, Dimitrios; Migkotzidis, Panagiotis; Nikolaidis, Efstathios; Anastasovitis, Eleftherios; Papazoglou Chalikias, Anastasios; Nikolopoulos, Spiros; Kompatsiaris, Ioannis] Informat Technol Inst ITI, Ctr Res & Technol Hellas CERTH, 6km Charilaou Thermi St,POB 60361, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Ververidis, D (corresponding author), Informat Technol Inst ITI, Ctr Res & Technol Hellas CERTH, 6km Charilaou Thermi St,POB 60361, Thessaloniki 57001, Greece.
EM ververid@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Ververidis,
   Dimitrios/0000-0001-7799-6502; Nikolopoulos, Spiros/0000-0002-1367-5133;
   Anastasovitis, Eleftherios/0000-0003-1757-5356; Papazoglou Chalikias,
   Anastasios/0000-0002-1063-8337
FU European Union [825585]; H2020 - Industrial Leadership [825585] Funding
   Source: H2020 - Industrial Leadership
FX The research leading to these results has received funding from the
   European Union H2020 Horizon Programme under grant agreement 825585,
   project HELIOS: A Context-aware Distributed Social Networking Framework.
   The authors would like to thank: Dr. Mavromanolakis Georgios and Dr.
   Sofoklis Sotiriou from Ellinogermaniki Agogi School (http://ea.gr), as
   well as Prof. Georgios Yannakakis and Prof. Antonios Liapis from the
   University of MaltaInstitute of Digital Games (http://www.game.edu.mt/)
   for the collaboration during the evaluation of the proposed tool; also
   Prof. Isabelle De Groote from the Anthropology Dept. of Liverpool John
   Moore University (LJMU, https://www.ljmu.ac.uk) for providing a 3D model
   for demonstrating the authoring tool (Figs. 4 and 7).
CR Agilie Company, 2021, MUCH DOES VR APPL DE
   Anastasovitis E, 2017, TRUE VISION CAPTURE, P1
   Anastasovitis E, 2017, DIGIART VIRTUAL MUSE
   Belyaev, 2020, COSPACES DELIGHTEX M
   Bergquist, 2008, SOFTWARE CREATE FLOO
   Bertram D., 2006, Likert Scales: CPSC 681- topic report
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Cabello, 2010, CROSS BROWSER JAVASC
   Cabot J, 2018, IEEE SOFTWARE, V35, P89, DOI 10.1109/MS.2018.2141016
   Chalikias AP, 2016, ENVISAGE AUTHORING T
   Chalikias AP, 2018, ENVISAGE VIRTUAL LAB
   Denard H, 2012, DIGIT RES ARTS HUM, P57
   Druart, 2020, UFI GLOBAL EXHIBITIO
   Eastcott, 2020, PLAYCANVAS WEBGL GAM
   Ebdrup, 2018, ENVISAGE DELIVERABLE
   Ellinogermaniki School, 2018, PLAY CREAT LEARN SUM
   Experizer Software, 2021, MUCH EXP COSTS
   Ferrao, 2018, CREATE INTERACTIVE E
   Fiedler, 2019, P AM C INF SYST AMCI
   Gamble, 2019, EDMEDIA INNOVATE LEA, P1417
   Garfinkel J., 2019, GRANTER IDENTIFIES T
   Gigante MA, 1993, VIRTUAL REALITY SYST, P3, DOI [10.1016/B978-0-12-227748-1.50009-3, DOI 10.1016/B978-0-12-227748-1.50009-3]
   González ANV, 2019, INT SYM MIX AUGMENT, P339, DOI 10.1109/ISMAR.2019.00032
   Haas A, 2017, ACM SIGPLAN NOTICES, V52, P185, DOI [10.1145/3062341.3062363, 10.1145/3140587.3062363]
   Halladay, 2019, WRITING SHADERS GODO, DOI 10.1007/978-1-4842-4457-9_18
   Hooft RWW, 1996, COMPUT APPL BIOSCI, V12, P525
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Institute of Digital Games, 2018, GAM RES ED
   Kán P, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P491, DOI 10.1109/VR.2018.8448291
   Kuntz S, 2018, DEMOCRATIZATION VR A, P73, DOI [10.1002/9781119341031.ch2, DOI 10.1002/9781119341031.CH2]
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Marcos D, 2020, A FRAME VIRTUAL REAL
   MCVEIGHSCHULTZ J, 2019, P CHI C HUM FACT COM
   Medium, 2021, VIRTUAL REALITY APPL
   Migkotzidis P, 2018, P INT C INT COLL LEA, P710
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20
   Mozilla Foundation, 2018, MOZ HUBS SHAR VIRT R
   Nikolaidou, 2018, DIGIART DELIVERABLE
   Pea, 2020, PORTING THREEJS WEBA
   Photon, 2020, PHOT ENG MULT NETW E
   Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779
   Sorrento G, 2018, YOUR REAL TIME 3D CA
   Sotiriou S, 2016, ENVISAGE DELIVERABLE
   Sweeney T, 1998, UNREAL3D GRAPHICS EN
   Torusmedialabs, 2020, CANV 360 PLUG AD PRE
   Turner Aaron, 2018, WebAssembly Is Fast: A Real-World Benchmark of WebAssembly vs. ES6
   Unity Technologies, 2021, INT LANG C
   Unity3D Graphics Engine, 2016, PART SOFTW DOC TEXT
   Vert Silviu, 2019, ITM Web of Conferences, V29, DOI 10.1051/itmconf/20192903008
   Ververidis D, 2020, HELIOSVR MULTIPURPOS
   Ververidis D, 2018, INT C SPRING INT COL, P653
   Ververidis D, 2015, WORDPRESSUNITY3DEDIT
   W3C, 2020, GPU WEB COMM GROUP I
   W3C, 2021, BIN INSTR FORM STACK
   Wallez, 2019, DEVFEST 2019
   Watson Z., 2017, VR for news: The new reality? Digital News Project
   Wavefront Technologies, 1990, OBJ 3D FORM
   Zaiontz C., 2015, REAL STAT USING EXCE
   Zakai A., 2011, Proceedings of the ACM international conference companion on object oriented programming systems languages and applications companion, P301, DOI DOI 10.1145/2048147.2048224
   Zhang W, 2007, P INT COMP SOFTW APP, P601
   Zi Xuan Y, 2020, INT J PSYCH REHAB, V24
NR 62
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 105
EP 124
DI 10.1007/s10055-021-00541-2
EA JUN 2021
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000658081900001
DA 2024-07-18
ER

PT J
AU Howard, MC
   Van Zandt, EC
AF Howard, Matt C.
   Van Zandt, Elise C.
TI A meta-analysis of the virtual reality problem: Unequal effects of
   virtual reality sickness across individual differences
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cybersickness; Virtual reality sickness; Virtual
   reality-induced symptoms and effects; Individual differences; User
   attributes; Head-mounted displays
ID ARTICLE REPORTING STANDARDS; MOTION SICKNESS; POSTURAL INSTABILITY;
   ADOLESCENTS AGGRESSION; SYSTEMATIC REVIEWS; PROSOCIAL BEHAVIOR; EXPOSURE
   THERAPY; APA PUBLICATIONS; ANGRY CHILDREN; VISUAL-MOTION
AB Practical applications of virtual reality (VR), defined as a three-dimensional digital representation of a real or imagined space, have become increasingly popular and are now applied in workplace training, physical rehabilitation, psychological therapy, and many other settings. Feelings akin to motion sickness, called VR sickness, can arise from interacting with VR programs, and researchers have shown that certain aspects of the user, such as gender and age, may predict the occurrence of VR sickness. The unequal effects of VR sickness are a dire concern and the application of VR is unfair to certain users if they are prone to sickness. For instance, a workplace VR training program could result in disparate treatment if women experience more VR sickness than men. To investigate this notion, we perform a meta-analysis on the relationship between VR sickness and a wide array of potential antecedents. The results demonstrate that motion sickness susceptibility, gender, real-world experience, technological experience, possessing a neurological disorder, and possessing a relevant phobia all significantly relate to VR sickness; however, no moderating effects produced recurrent significant results. These results were partially explained by the current dominant framework for VR sickness, postural instability theory, but some findings were not predicted by the theory. Therefore, we support that (a) VR sickness produces unequal effects across multiple individual differences; (b) these effects appear resilient across applications of VR programs, and (c) further research is needed to develop theory and identify explanatory mechanisms that detail these relationships.
C1 [Howard, Matt C.; Van Zandt, Elise C.] Univ S Alabama, Mitchell Coll Business, Mobile, AL 36688 USA.
C3 University of South Alabama
RP Howard, MC (corresponding author), Univ S Alabama, Mitchell Coll Business, Mobile, AL 36688 USA.
EM MHoward@SouthAlabama.edu; ECV1821@jagmail.southalabama.edu
RI Howard, Matt C./ABD-9528-2021
CR Aggarwal R, 2006, ANN SURG, V244, P310, DOI 10.1097/01.sla.0000218094.92650.44
   Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   Akizuki H, 2005, NEUROSCI LETT, V379, P23, DOI 10.1016/j.neulet.2004.12.041
   Altena E, 2019, J SLEEP RES, V28, DOI 10.1111/jsr.12677
   [Anonymous], 1975, Motion sickness
   Appelbaum M, 2018, AM PSYCHOL, V73, P3, DOI 10.1037/amp0000191
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Armstrong M., 2016, Emerging research and trends in gamification, P140, DOI [10.4018/978-1-4666-8651-9.ch007, DOI 10.4018/978-1-4666-8651-9.CH007]
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Assaiante Christine, 2005, Neural Plasticity, V12, P109, DOI 10.1155/NP.2005.109
   Aubrey JS, 2018, CISC VIS NETW IND GL
   Bedwell WL, 2012, SIMULAT GAMING, V43, P729, DOI 10.1177/1046878112439444
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bonato F, 2005, AVIAT SPACE ENVIR MD, V76, P823
   Bonato F, 2004, AVIAT SPACE ENVIR MD, V75, P306
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Borenstein M., 2009, INT STAT REV
   Bos JE, 2004, AVIAT SPACE ENVIR MD, V75, P172
   Bosco FA, 2015, J APPL PSYCHOL, V100, P431, DOI 10.1037/a0038047
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Boxer P, 2015, PERSPECT PSYCHOL SCI, V10, P671, DOI 10.1177/1745691615592239
   Bubka A, 2006, AVIAT SPACE ENVIR MD, V77, P811
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   CARSON KP, 1990, EDUC PSYCHOL MEAS, V50, P233, DOI 10.1177/0013164490502001
   Cavanaugh C., 2001, INT J ED TELECOMMUNI, V7, P73
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chesham RK, 2018, BEHAV CHANGE, V35, P152, DOI 10.1017/bec.2018.15
   Chessa M, 2019, HUM-COMPUT INTERACT, V34, P51, DOI 10.1080/07370024.2016.1243478
   Chiari L, 2002, CLIN BIOMECH, V17, P666, DOI 10.1016/S0268-0033(02)00107-9
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cortina JM, 2003, ORGAN RES METHODS, V6, P415, DOI 10.1177/1094428103257358
   Cumpston M, 2019, COCHRANE DB SYST REV, DOI 10.1002/14651858.ED000142
   Dang BK, 2018, CLIN SIMUL NURS, V19, P30, DOI 10.1016/j.ecns.2018.03.001
   De Kleyn APHA., 1948, ACTA OTOLARYNGOL, V36, P8, DOI [10.3109/00016489.1948.11760809, DOI 10.3109/00016489.1948.11760809]
   Deeks JJ, 2005, J CLIN EPIDEMIOL, V58, P882, DOI 10.1016/j.jclinepi.2005.01.016
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Dennison M, 2018, APPL ERGON, V71, P9, DOI 10.1016/j.apergo.2018.03.015
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Didehbani N, 2016, COMPUT HUM BEHAV, V62, P703, DOI 10.1016/j.chb.2016.04.033
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Duval S, 2000, BIOMETRICS, V56, P455, DOI 10.1111/j.0006-341X.2000.00455.x
   Ebenholtz S.M., 1992, Teleoperators and Virtual Environments, V1, P302, DOI DOI 10.1162/PRES.1992.1.3.302
   Era P, 2006, GERONTOLOGY, V52, P204, DOI 10.1159/000093652
   Fabbri M, 2006, NEUROPSYCHOLOGIA, V44, P2520, DOI 10.1016/j.neuropsychologia.2006.03.033
   Farook SA., 2018, J Neurosci, V8, P16
   Fast K, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P298, DOI 10.1109/ISMAR.2004.65
   Ferguson CJ, 2015, PERSPECT PSYCHOL SCI, V10, P646, DOI 10.1177/1745691615592234
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   FIGURA F, 1991, J SPORT MED PHYS FIT, V31, P235
   Fodor LA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28113-6
   Fransson PA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39104-6
   Furuya-Kanamori L, 2016, PERSPECT PSYCHOL SCI, V11, P408, DOI 10.1177/1745691616635599
   Gignac GE, 2016, PERS INDIV DIFFER, V102, P74, DOI 10.1016/j.paid.2016.06.069
   Golding JF, 2003, AVIAT SPACE ENVIR MD, V74, P220
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Guerraz M, 2008, NEUROPHYSIOL CLIN, V38, P391, DOI 10.1016/j.neucli.2008.09.007
   Hale KS, 2006, APPL ERGON, V37, P329, DOI 10.1016/j.apergo.2005.06.009
   Hemmerich WA, 2019, DISPLAYS, V58, P27, DOI 10.1016/j.displa.2018.11.005
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Higgins JPT, 2003, BMJ-BRIT MED J, V327, P557, DOI 10.1136/bmj.327.7414.557
   Honrubia V, 1968, Acta Otolaryngol, V65, P441, DOI 10.3109/00016486809120986
   Hough LM, 2001, INT J SELECT ASSESS, V9, P152, DOI 10.1111/1468-2389.00171
   Howard MC, 2019, CAMB HANDB PSYCHOL, P347
   Howard MC, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103707
   Howard MC, 2019, HUM-COMPUT INTERACT, V34, P205, DOI 10.1080/07370024.2018.1469408
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   HU SQ, 1991, AVIAT SPACE ENVIR MD, V62, P308
   Ip HHS, 2018, COMPUT EDUC, V117, P1, DOI 10.1016/j.compedu.2017.09.010
   Jacobs M, 2019, TRANSPORT RES F-TRAF, V60, P499, DOI 10.1016/j.trf.2018.11.007
   Johnson D.M., 2007, Simulator Sickness During Emergency Procedures Training in a Helicopter Simulator: Age, Flight Experience, and Amount Learned
   Jung Ji-Young, 2017, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V17, P200, DOI 10.5392/JKCA.2017.17.04.200
   Karita K, 2006, J OCCUP HEALTH, V48, P65, DOI 10.1539/joh.48.65
   Kemeny A., 2017, The Engineering Reality of Virtual Reality, P48
   Kennedy R., 1992, Presence: Teleoperators and Virtual Environments, V1, P295, DOI [DOI 10.1162/PRES.1992.1.3.295, 10.1162/pres.1992.1.3.295]
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   KENNEDY RS, 1992, AVIAT SPACE ENVIR MD, V63, P588
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kepes S, 2013, J BUS PSYCHOL, V28, P123, DOI 10.1007/s10869-013-9300-2
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Knight M. M., 2006, ACM SIGGRAPH 2006 Res Posters, DOI [10.1145/1179622.1179846, DOI 10.1145/1179622.1179846]
   Kolasinski EM, 1998, HUM FAC ERG SOC P, P1511, DOI 10.1177/154193129804202110
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Krieger LH, 2004, J SOC ISSUES, V60, P835, DOI 10.1111/j.0022-4537.2004.00389.x
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LANDAU J, 1995, J ORGAN BEHAV, V16, P391, DOI 10.1002/job.4030160409
   Levitt HM, 2018, AM PSYCHOL, V73, P26, DOI 10.1037/amp0000151
   Li RX, 2018, GAIT POSTURE, V65, P251, DOI 10.1016/j.gaitpost.2018.08.005
   Lim YH, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00433
   Lorenzo G, 2016, COMPUT EDUC, V98, P192, DOI 10.1016/j.compedu.2016.03.018
   Lutz Otto Hans-Martin, 2017, Current Directions in Biomedical Engineering, V3, P53, DOI 10.1515/cdbme-2017-0012
   MANNING GW, 1949, J APPL PHYSIOL, V1, P619, DOI 10.1152/jappl.1949.1.9.619
   Masui T, 2005, ARCH GERONTOL GERIAT, V41, P201, DOI 10.1016/j.archger.2005.02.003
   Mavrikios D, 2006, INT J COMPUT INTEG M, V19, P294, DOI 10.1080/09511920500340916
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Messinger P. R., 2008, Journal of Virtual Worlds Research, V1, P1
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Moher D, 2015, SYST REV-LONDON, V4, DOI 10.1186/s13643-015-0087-2
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   MONWILLIAMS M, 1993, OPHTHAL PHYSL OPT, V13, P387, DOI 10.1111/j.1475-1313.1993.tb00496.x
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Moscoso S, 2000, INT J SELECT ASSESS, V8, P237, DOI 10.1111/1468-2389.00153
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Mussel P, 2015, J RES PERS, V55, P51, DOI 10.1016/j.jrp.2015.01.002
   Nacke LE, 2017, COMPUT HUM BEHAV, V71, P450, DOI 10.1016/j.chb.2016.11.062
   Nakano T, 2001, PSYCHIAT CLIN NEUROS, V55, P277, DOI 10.1046/j.1440-1819.2001.00858.x
   Nichols S, 2002, APPL ERGON, V33, P251, DOI 10.1016/S0003-6870(02)00020-0
   Ohno H, 2004, NEUROSCI LETT, V364, P37, DOI 10.1016/j.neulet.2004.04.014
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Oman CM, 2012, J VESTIBUL RES-EQUIL, V22, P117, DOI 10.3233/VES-2011-0432
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Owen N, 1998, BRAIN RES BULL, V47, P471, DOI 10.1016/S0361-9230(98)00101-4
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Paterson TA, 2016, J LEADERSH ORG STUD, V23, P66, DOI 10.1177/1548051815614321
   Petri K., 2020, Am. J. Biomed. Sci, P107, DOI DOI 10.5099/AJ200200107
   Place I, 2003, FERTIL STERIL, V80, P1388, DOI 10.1016/j.fertnstert.2003.06.004
   Pletzer JL, 2019, J VOCAT BEHAV, V112, P369, DOI 10.1016/j.jvb.2019.04.004
   Rauch SAM, 2018, BEHAV RES THER, V109, P1, DOI 10.1016/j.brat.2018.07.003
   Ravi DK, 2017, PHYSIOTHERAPY, V103, P245, DOI 10.1016/j.physio.2016.08.004
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309
   Reger GM, 2019, TELEMED E-HEALTH, V25, P859, DOI 10.1089/tmj.2018.0175
   Reis L, 2016, ERGONOMICS DESIGN ME, P281
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke BE, 2005, P IEEE VIRT REAL ANN, P131
   Ritchie James M., 2007, Virtual Reality, V11, P261, DOI 10.1007/s10055-007-0073-7
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Rothstein HR, 2015, PERSPECT PSYCHOL SCI, V10, P677, DOI 10.1177/1745691615592235
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Shafer DM., 2017, PSYCHOL REV, V11, P1
   Sharpe D, 1997, CLIN PSYCHOL REV, V17, P881, DOI 10.1016/S0272-7358(97)00056-1
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sherman W.R., 2018, UNDERSTANDING VIRTUA
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Soutter ARB, 2020, PERSPECT PSYCHOL SCI, V15, P913, DOI 10.1177/1745691620903019
   Sparto Patrick J, 2004, J Neuroeng Rehabil, V1, P14, DOI 10.1186/1743-0003-1-14
   Squelch AP, 2001, J S AFR I MIN METALL, V101, P209
   Stein M., 2012, Aviation Psychology and Applied Human Factors, V2, P11, DOI DOI 10.1027/2192-0923/A000022
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stoffregen TA, 2000, HUM FACTORS, V42, P458, DOI 10.1518/001872000779698097
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187120
   Stoffregen TA, 2010, ECOL PSYCHOL, V22, P169, DOI 10.1080/10407413.2010.496645
   Stone RT, 2011, WELD J, V90, p136S
   Sugiura A, 2018, LECT NOTES COMPUT SC, V10908, P122, DOI 10.1007/978-3-319-92052-8_10
   Sutton AJ, 2000, STAT METHODS MED RES, V9, P421, DOI 10.1191/096228000701555244
   SUZUKI J I, 1962, Acta Otolaryngol, V54, P49, DOI 10.3109/00016486209126922
   Takeuchi N, 2018, CYBERPSYCH BEH SOC N, V21, P381, DOI 10.1089/cyber.2017.0499
   Tamim RM, 2011, REV EDUC RES, V81, P4, DOI 10.3102/0034654310393361
   Tett RP, 2003, J APPL PSYCHOL, V88, P500, DOI 10.1037/0021-9010.88.3.500
   Tett RP., 2013, Handbook of personality at work, P71, DOI DOI 10.4324/9780203526910.CH5
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Tyrrell R, 2018, VIRTUAL REAL-LONDON, V22, P211, DOI 10.1007/s10055-017-0324-1
   Valmaggia LR, 2016, PSYCHIAT RES, V236, P189, DOI 10.1016/j.psychres.2016.01.015
   Van Wyk E., 2009, P 6 INT C COMP GRAPH, P53, DOI DOI 10.1145/1503454.1503465
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Wada M, 2001, NEUROSCI LETT, V302, P157, DOI 10.1016/S0304-3940(01)01662-7
   Warwick-Evans LA, 1998, BRAIN RES BULL, V47, P465, DOI 10.1016/S0361-9230(98)00090-2
   WASSERMAN S, 1988, J EDUC STAT, V13, P75
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Zagenczyk TJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01113
   Zettler I, 2020, PERSPECT PSYCHOL SCI, V15, P723, DOI 10.1177/1745691619895036
   Zhang LL, 2016, CNS NEUROSCI THER, V22, P15, DOI 10.1111/cns.12468
   Zhang MWB, 2017, TECHNOL HEALTH CARE, V25, P367, DOI 10.3233/THC-161282
NR 173
TC 42
Z9 42
U1 9
U2 60
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1221
EP 1246
DI 10.1007/s10055-021-00524-3
EA MAY 2021
PG 26
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000649203500001
DA 2024-07-18
ER

PT J
AU Cerda, L
   Fauvarque, A
   Graziani, P
   Del-Monte, J
AF Cerda, Lisa
   Fauvarque, Aurelie
   Graziani, Pierluigi
   Del-Monte, Jonathan
TI Contextual priming to increase the sense of presence in virtual reality:
   exploratory study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; The sense of presence; Priming; Contextual priming; The
   sense of familiarity
AB Sense of presence plays an essential role in realistic answers in virtual reality and is, therefore, relevant to promote. Prior studies suggest that a relationship exists between familiarity and presence through the memory process. Indeed, the recall of memories could reactivate the mental state and emotions associated with their context. The present study thus examined the effectiveness of contextual priming in enhancing the sense of presence in a virtual environment. The reading of an article primed participants. In the university priming condition, the article consisted of a description of the university, place well-known by the participants and relating to the virtual environment used subsequently. In the non-university condition, the article dealt with the organization of household chores. After the reading, the researcher immersed participants in a virtual classroom and had to discuss the article for three minutes. Finally, participants were invited to complete several questionnaires. Participants in the university priming condition reported a higher sense of presence during the virtual task than participants in the neutral priming group, especially regarding reality judgment. These findings suggest that contextual priming can promote a sense of presence through the activation of familiarity.
C1 [Cerda, Lisa; Graziani, Pierluigi; Del-Monte, Jonathan] Social Psychol Lab, 29 Ave Robert Schuman, F-13621 Aix En Provence 1, France.
   [Cerda, Lisa; Fauvarque, Aurelie; Graziani, Pierluigi; Del-Monte, Jonathan] Nimes Univ, 5 Ave Dr Georges Salan, F-30000 Nimes, France.
C3 Universite de Nimes
RP Cerda, L (corresponding author), Social Psychol Lab, 29 Ave Robert Schuman, F-13621 Aix En Provence 1, France.; Cerda, L (corresponding author), Nimes Univ, 5 Ave Dr Georges Salan, F-30000 Nimes, France.
EM lisa.cerda30@gmail.com; aurelie.fauvarque@gmail.com;
   pierluigi.graziani@unimes.fr; jonathan.del-monte@unimes.fr
OI CERDA, Lisa/0000-0003-2897-8193
CR [Anonymous], 2005, ROLE PRESENCE REALIT
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heeter C, 2003, PRESENCE-TELEOP VIRT, V12, P335, DOI 10.1162/105474603322391587
   Keogh E, 2005, PRESENCE EMOTION ARE
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Lambrey S, 2010, ANN MED-PSYCHOL, V168, P44, DOI 10.1016/j.amp.2009.10.003
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Mantovani F, 2003, CYBERPSYCHOL BEHAV, V6, P389, DOI 10.1089/109493103322278772
   Nunez D., 2001, Proceedings AFRIGRAPH 2001. 1st International Conference on Computer Graphics, Virtual Reality and Visualisation, P115, DOI 10.1145/513867.513892
   Nunez D., 2003, P 2 INT C COMPUTER G, P101, DOI [10.1145/602330.602350, DOI 10.1145/602330.602350]
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Riches S, 2019, CYBERPSYCH BEH SOC N, V22, P288, DOI 10.1089/cyber.2018.0128
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Sallnäs EL, 2005, PRESENCE-VIRTUAL AUG, V14, P434, DOI 10.1162/105474605774785253
   Short J., 1976, The social psychology of telecommunications
   Sjölie D, 2012, INTERACT COMPUT, V24, P193, DOI 10.1016/j.intcom.2012.04.004
   Smith SM, 2001, PSYCHON B REV, V8, P203, DOI 10.3758/BF03196157
   Spielberger CD, 1970, MANUAL STATE TRAIT A
   Viaud-Delmon I, 2011, SCI CROISEES, V7
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Widestrom J., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P165, DOI 10.1145/351006.351035
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yonelinas AP, 2002, J MEM LANG, V46, P441, DOI 10.1006/jmla.2002.2864
NR 27
TC 2
Z9 3
U1 3
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1105
EP 1112
DI 10.1007/s10055-021-00515-4
EA MAR 2021
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000634646400001
DA 2024-07-18
ER

PT J
AU Havard, V
   Baudry, D
   Jeanne, B
   Louis, A
   Savatier, X
AF Havard, Vincent
   Baudry, David
   Jeanne, Benoit
   Louis, Anne
   Savatier, Xavier
TI A use case study comparing augmented reality (AR) and electronic
   document-based maintenance instructions considering tasks complexity and
   operator competency level
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Industry 4; 0; Case studies in industry
ID ASSEMBLY OPERATIONS; CHALLENGES; SUPPORT
AB Augmented reality (AR) is more and more used in the industrial context for maintenance, assembly operation. However, owing to the evolution and maturity of the technology, it is still necessary to evaluate the usage and benefits of AR in an industrial context to go further than proof of concept. As such, this paper proposes an analysis of AR case study in the literature. Then, this paper presents a methodology for comparing AR and electronic document-based complex maintenance instructions considering tasks complexity and operator competency level. The main results show that the consultation duration of the AR tablet is 34% statistically faster than the PDF tablet. It also shows that error concerning similar objects is reduced thanks to AR. Moreover, the study specifically focuses on types of task that worth using AR. However, the study shows that usability of the AR device is less well rated than the PDF for "beginner-intermediate" operators. Finally, an in-depth analysis permits extracting recommendations of the different factors to take into account with industrial AR applications.
C1 [Havard, Vincent; Baudry, David; Jeanne, Benoit; Louis, Anne] CESI, LINEACT, 80 Rue Edmund Halley, F-76808 St Etienne Du Rouvray, France.
   [Savatier, Xavier] ESIGELEC, IRSEEM, Ave Galilee,BP 10024, F-76801 St Etienne Du Rouvray, France.
C3 Universite de Rouen Normandie
RP Havard, V (corresponding author), CESI, LINEACT, 80 Rue Edmund Halley, F-76808 St Etienne Du Rouvray, France.
EM vhavard@cesi.fr; xavier.savatier@esigelec.fr
RI Havard, Vincent/HPD-8308-2023
OI Havard, Vincent/0000-0001-8248-3496; Baudry, David/0000-0002-4386-4496
FU FEDER; Normandy region
FX This part of the work is done within the framework of the project "PFPI
   PlateForme de Performances Industrielles" (Industrial Performance
   Platform) and financed by the FEDER and the Normandy region.
CR Aromaa S, 2018, ADV INTELL SYST, V607, P145, DOI 10.1007/978-3-319-60492-3_14
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bergounhoux, 2017, IND JOUE AVEC REALIT
   Bottecchia S., 2010, Proceedings of the 1st Augmented Human International Conference, Megeve, France, April 2-3, P14, DOI [DOI 10.1145/1785455.1785469, 10.1145/ 1785455.1785469]
   Bottecchia S, 2010, SYSTEME TAC TELE ASS
   Chu CH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103383
   Cardoso LFD, 2020, COMPUT IND ENG, V148, DOI 10.1016/j.cie.2020.106712
   Deshpande A, 2018, ADV ENG INFORM, V38, P760, DOI 10.1016/j.aei.2018.10.004
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Friedrich W, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P3, DOI 10.1109/ISMAR.2002.1115059
   Funk, 2016, AUGMENTED REALITY WO
   Funk M., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments-PETRA '16, P1, DOI [DOI 10.1145/2910674.2910730, 10.1145/2910674.2910683, DOI 10.1145/2910674.2910683]
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Funk M, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P253, DOI 10.1145/2836041.2836067
   Gattullo M, 2019, ROBOT CIM-INT MANUF, V56, P276, DOI 10.1016/j.rcim.2018.10.001
   Gonzalez-Franco, 2016, ARXIV PREPRINT ARXIV
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Havard V, 2016, LECT NOTES COMPUT SC, V9768, P302, DOI 10.1007/978-3-319-40621-3_22
   HENDERSON S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI DOI 10.1109/TVCG.2010.245
   Herter, 2014, THESIS
   Hocquard A, 2005, 4 ACM IEEE INT S MIX
   Hoover M., 2018, An evaluation of the Microsoft HoloLens for a manufacturing-guided assembly task
   Koch C, 2014, AUSTRALASIAN J CONST, V2, P23
   Konolige, 2016, GOING FURTHER POINT
   Lai ZH, 2020, J MANUF SYST, V55, P69, DOI 10.1016/j.jmsy.2020.02.010
   Lamberti F, 2014, IEEE T EMERG TOP COM, V2, P411, DOI 10.1109/TETC.2014.2368833
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Masood T, 2019, ROBOT CIM-INT MANUF, V58, P181, DOI 10.1016/j.rcim.2019.02.003
   Mechin, 2007, MAINTENANCE CONCEPTS
   Mourtzis D, 2019, INT J ADV MANUF TECH, V105, P3899, DOI 10.1007/s00170-019-03941-6
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Nielsen, 1994, USABILITY ENG
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Polvi J, 2018, IEEE T VIS COMPUT GR, V24, P2118, DOI 10.1109/TVCG.2017.2709746
   Radkowski R, 2016, J COMPUT INF SCI ENG, V16, DOI 10.1115/1.4031981
   Suárez-Warden F, 2015, PROCEDIA COMPUT SCI, V75, P281, DOI 10.1016/j.procs.2015.12.249
   Syberfeldt A, 2015, PROCEDIA MANUF, V1, P98, DOI 10.1016/j.promfg.2015.09.068
   Tamaazousti M, 2013, THESIS U BLAISE PASC
   Uva AE, 2018, INT J ADV MANUF TECH, V94, P509, DOI 10.1007/s00170-017-0846-4
   Vanneste P, 2020, INT J HUM-COMPUT ST, V143, DOI 10.1016/j.ijhcs.2020.102480
   Wang X, 2016, ADV ENG INFORM, V30, P406, DOI 10.1016/j.aei.2016.05.004
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   XIANG Y, 2018, ARXIV PREPRINT ARXIV
   Zhu J, 2013, INT J ADV MANUF TECH, V66, P1699, DOI 10.1007/s00170-012-4451-2
NR 46
TC 14
Z9 15
U1 2
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 999
EP 1014
DI 10.1007/s10055-020-00493-z
EA FEB 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000622225500001
DA 2024-07-18
ER

PT J
AU Harris, DJ
   Hardcastle, KJ
   Wilson, MR
   Vine, SJ
AF Harris, David J.
   Hardcastle, Kyle J.
   Wilson, Mark R.
   Vine, Samuel J.
TI Assessing the learning and transfer of gaze behaviours in immersive
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Fidelity; Police; Policing; Training; Validity; VR
ID VISUAL-SEARCH; PERFORMANCE; STRATEGIES; EXPERTISE; PSYTOOLKIT;
   ATTENTION; VALIDITY; ANXIETY; SPORT
AB Virtual reality (VR) has clear potential for improving simulation training in many industries. Yet, methods for testing the fidelity, validity and training efficacy of VR environments are, in general, lagging behind their adoption. There is limited understanding of how readily skills learned in VR will transfer, and what features of training design will facilitate effective transfer. Two potentially important elements are the psychological fidelity of the environment, and the stimulus correspondence with the transfer context. In this study, we examined the effectiveness of VR for training police room searching procedures, and assessed the corresponding development of perceptual-cognitive skill through eye-tracking indices of search efficiency. Participants (n = 54) were assigned to a VR rule-learning and search training task (FTG), a search only training task (SG) or a no-practice control group (CG). Both FTG and SG developed more efficient search behaviours during the training task, as indexed by increases in saccade size and reductions in search rate. The FTG performed marginally better than the CG on a novel VR transfer test, but no better than the SG. More efficient gaze behaviours learned during training were not, however, evident during the transfer test. These findings demonstrate how VR can be used to develop perceptual-cognitive skills, but also highlight the challenges of achieving transfer of training.
C1 [Harris, David J.; Wilson, Mark R.; Vine, Samuel J.] Univ Exeter, Sch Sport & Hlth Sci, St Lukes Campus, Exeter EX1 2LU, Devon, England.
   [Hardcastle, Kyle J.] Metropolitan Police Serv, Counter Terrorism Protect Secur Operat, Lambeth HQ, London SE1 7LP, England.
C3 University of Exeter
RP Harris, DJ (corresponding author), Univ Exeter, Sch Sport & Hlth Sci, St Lukes Campus, Exeter EX1 2LU, Devon, England.
EM D.J.Harris@exeter.ac.uk; Kyle.J.Hardcastle@met.police.uk;
   Mark.Wilson@exeter.ac.uk; S.J.Vine@exeter.ac.uk
RI Harris, David/H-9114-2019
OI Harris, David/0000-0003-3880-3856
FU Royal Academy of Engineering UKIC Postdoctoral Fellowship
FX This work was supported by a Royal Academy of Engineering UKIC
   Postdoctoral Fellowship awarded to D. Harris.
CR Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Allsop J, 2014, J APPL RES MEM COGN, V3, P63, DOI 10.1016/j.jarmac.2014.04.010
   Barnett SM, 2002, PSYCHOL BULL, V128, P612, DOI 10.1037//0033-2909.128.4.612
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Biggs AT, 2018, J APPL RES MEM COGN, V7, P189, DOI 10.1016/j.jarmac.2018.04.001
   Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Braun DA, 2010, BEHAV BRAIN RES, V206, P157, DOI 10.1016/j.bbr.2009.08.031
   Bright E, 2014, J SURG EDUC, V71, P434, DOI 10.1016/j.jsurg.2013.11.006
   Brunswick E., 1956, PERCEPTION REPRESENT, DOI 10.1525/9780520350519
   Eckstein MP, 2011, J VISION, V11, DOI 10.1167/11.5.14
   Freeman S, 2014, P NATL ACAD SCI USA, V111, P8410, DOI 10.1073/pnas.1319030111
   Gray R., 2019, Anticipation and Decision Making in Sport
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Green P, 2016, METHODS ECOL EVOL, V7, P493, DOI 10.1111/2041-210X.12504
   Hadlow SM, 2018, J SCI MED SPORT, V21, P950, DOI 10.1016/j.jsams.2018.01.011
   Harris D, 2020, VIRTUAL REAL-LONDON, V24, P557, DOI 10.1007/s10055-019-00422-9
   Harris DJ, 2020, PSYCHOL SPORT EXERC, V50, DOI 10.1016/j.psychsport.2020.101721
   Harris DJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00605
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   HART S G, 1988, P139
   Karlsson P, 2015, ADDICTION, V110, P420, DOI 10.1111/add.12799
   Krassanakis V, 2014, J EYE MOVEMENT RES, V7
   Lele A, 2013, J AMB INTEL HUM COMP, V4, P17, DOI 10.1007/s12652-011-0052-4
   Lintern G, 2021, HUM FACTORS, V63, P531, DOI 10.1177/0018720819879814
   Lowe, 2019, J EXPERT, V3
   Mann DTY, 2007, J SPORT EXERCISE PSY, V29, P457, DOI 10.1123/jsep.29.4.457
   Mannan SK, 2010, J NEUROL, V257, P1812, DOI 10.1007/s00415-010-5615-3
   Marteniuk R.G., 1976, Information processing in motor skills
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Moglia A, 2016, EUR UROL, V69, P1065, DOI 10.1016/j.eururo.2015.09.021
   Moore LJ, 2019, J SPORT SCI, V37, P1778, DOI 10.1080/02640414.2019.1594568
   Murray NP, 2003, J SPORT EXERCISE PSY, V25, P171, DOI 10.1123/jsep.25.2.171
   Najemnik J, 2005, NATURE, V434, P387, DOI 10.1038/nature03390
   Oberhauser M, 2017, COGN TECHNOL WORK, V19, P263, DOI 10.1007/s10111-017-0421-7
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rosalie SM, 2012, RES Q EXERCISE SPORT, V83, P413
   Sala G, 2017, CURR DIR PSYCHOL SCI, V26, P515, DOI 10.1177/0963721417712760
   Salar R, 2020, J SCI EDUC TECHNOL, V29, P257, DOI 10.1007/s10956-019-09810-x
   Salvucci D.D., 2000, P 2000 S EYE TRACK R, P71, DOI [DOI 10.1145/355017.355028, 10.1145/355017.355028]
   Saunders J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1908, DOI [10.1109/vr.2019.8798371, 10.1109/VR.2019.8798371]
   Savelsbergh GJP, 2002, J SPORT SCI, V20, P279, DOI 10.1080/026404102317284826
   Schorer, 2015, PSYCHOL TEST ASSESSM, V57, P13
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Signorell Andri., 2018, DescTools: Tools for descriptive statistics
   SIRETEANU R, 1995, VISION RES, V35, P2037, DOI 10.1016/0042-6989(94)00295-W
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stoet G, 2017, TEACH PSYCHOL, V44, P24, DOI 10.1177/0098628316677643
   Stoet G, 2010, BEHAV RES METHODS, V42, P1096, DOI 10.3758/BRM.42.4.1096
   Subhash S, 2018, COMPUT HUM BEHAV, V87, P192, DOI 10.1016/j.chb.2018.05.028
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Trninic D, 2018, INSTR SCI, V46, P133, DOI 10.1007/s11251-017-9443-z
   Vickers JN, 2007, PERCEPTION COGNITION
   Vine SJ, 2015, ANXIETY STRESS COPIN, V28, P467, DOI 10.1080/10615806.2014.986722
   Vine SJ, 2014, SURG ENDOSC, V28, P1788, DOI 10.1007/s00464-013-3387-4
   Wolfe Jeremy M, 2010, Curr Biol, V20, pR346, DOI 10.1016/j.cub.2010.02.016
   Wood G, 2014, MED DECIS MAKING, V34, P75, DOI 10.1177/0272989X13492016
NR 59
TC 14
Z9 14
U1 7
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 961
EP 973
DI 10.1007/s10055-021-00501-w
EA FEB 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000614665000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yao, YN
   Du, ZB
   Huang, XY
   Li, R
AF Yao, Yannan
   Du, Zhibin
   Huang, Xiaoyan
   Li, Ran
TI Derivation and simulation verification of the relationship between world
   coordinates and local coordinates under virtual reality engine
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Gimbal lock; Coordinate transformation
AB As a new human-computer interaction technology, virtual reality technology has been widely used in education, military, industry, art and entertainment, etc. Unity3D is one of the most popular virtual reality product development engines in the world. Coordinate transformation is the mathematical basis for space transformation in virtual reality technology. This paper explains the mechanism of Euler rotation causing the phenomenon of gimbal lock from the perspective of mathematical principles and derives the importance of Unity3D using quaternion for rotation calculation. Based on the Unity3D quaternion rotation calculation, the world-local coordinate transformation relationship of the child object under the Unity3D engine is deeply deduced and verified, which lays a theoretical foundation for the in-depth development of virtual reality products based on Unity3D.
C1 [Yao, Yannan; Du, Zhibin; Huang, Xiaoyan; Li, Ran] China Automobile Technol & Res Ctr Co Ltd, Tianjin 300000, Peoples R China.
RP Yao, YN (corresponding author), China Automobile Technol & Res Ctr Co Ltd, Tianjin 300000, Peoples R China.
EM yaoyannan@tju.edu.cn; duzhibin@catarc.cn; huangxiaoyan@catarc.cn;
   liran@catarc.cn
OI Yannan, Yao/0000-0002-6180-1835
CR Altmann S.L., 2005, ROTATIONS QUATERNION
   [Anonymous], 2014, VIRTUAL REALITY TECH
   [Anonymous], 2004, VISUALIZATION TOOLKI
   Earnshaw RaeA., 2014, VIRTUAL REALITY SYST
   GROOD ES, 1983, J BIOMECH ENG-T ASME, V105, P136, DOI 10.1115/1.3138397
   Hartung K., 1999, AUD ENG SOC C 16 INT
   Hemingway EG, 2018, MULTIBODY SYST DYN, V44, P31, DOI 10.1007/s11044-018-9620-0
   Huang J, 2015, DESIGN DEV MOBILE GA
   Huynh DQ, 2009, J MATH IMAGING VIS, V35, P155, DOI 10.1007/s10851-009-0161-2
   McClain W. M., 2008, SYMMETRY THEORY MOL
   Messaoudi F, 2015, P 2015 INT WORKSH NE, P4
   Miles J., 2016, Unity 3D and PlayMaker: Essentials Game Development from Concept to Publishing
   Mukundan Ramakrishnan., 2002, Proceedings of the 7th Asian Technology conference in Mathematics, P97
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Rheingold H., 1991, VIRTUAL REALITY EXPL
   ROBINETT W, 1995, PRESENCE-TELEOP VIRT, V4, P1
   Shoemake K., 1994, Graphics Gems IV, P222, DOI [DOI 10.1016/B978-0-12-336156-1.50030-6, 10.1016/B978-0-12-336156-1.50030-6]
   Slabaugh G. G., 1999, Computing Euler angles from a rotation matrix, V6, P39
   Smith M., 2015, UNITY 5 X COOKBOOK
   Vass G, 2009, COMPUT GRAPH WORLD, V32, P10
   Vince J, 2011, QUATERNIONS FOR COMPUTER GRAPHICS, P1, DOI 10.1007/978-0-85729-760-0
   Wexelblat A., 2014, VIRTUAL REALITY APPL
NR 22
TC 4
Z9 4
U1 19
U2 85
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 263
EP 269
DI 10.1007/s10055-019-00397-7
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800007
DA 2024-07-18
ER

PT J
AU Portalés, C
   Casanova-Salas, P
   Casas, S
   Gimeno, J
   Fernandez, M
AF Portales, Cristina
   Casanova-Salas, Pablo
   Casas, Sergio
   Gimeno, Jesus
   Fernandez, Marcos
TI An interactive cameraless projector calibration method
SO VIRTUAL REALITY
LA English
DT Article
DE Projector; Calibration; Augmented reality; DLT; Interactive;
   Photogrammetry; Cameraless
ID AUTOCALIBRATION; SYSTEM
AB The geometric calibration of projectors is a demanding task in many areas related to computer vision, virtual reality or augmented reality, to name some. Up to date, different methods have been proposed to retrieve the intrinsic and extrinsic parameters of projectors. During the last 20 years, researchers have used cameras as means to calibrate projectors in order to automatize the process. However, this might add: (1) complexity in terms of mathematical formulation; (2) restrictions in terms of camera locations relative to projectors; and (3) additional errors (those due to the camera calibration itself). Most of these camera-based methods make use of planar homographies, and others require an extended calibration process (for both the camera and the projector). In this paper, we present an approach that combines a direct transformation method (DLT) with projected augmented reality to perform an interactive calibration of projectors without the need for cameras. This method is based on non-coplanar points and 2D/3D correspondences, which are interactively established. Intrinsic and extrinsic calibration is achieved in a single step, making use of the DLT. The method rescues old approaches to calibrate projectors, but brings the new capabilities of interactive systems, all integrated in a single software solution. We conduct different experiments by considering two projector setups and two different sets of control points, proving that the accuracy of the method in the real space can be between one and two pixels.
C1 [Portales, Cristina; Casanova-Salas, Pablo; Casas, Sergio; Gimeno, Jesus; Fernandez, Marcos] Univ Valencia, Inst Robot & Informat & Commun Technol IRTIC, Valencia, Spain.
C3 University of Valencia
RP Portalés, C (corresponding author), Univ Valencia, Inst Robot & Informat & Commun Technol IRTIC, Valencia, Spain.
EM cristina.portales@uv.es
RI Casas Yrurzum, Sergio/S-3693-2017; Portalés, Cristina/K-2296-2015;
   Fernández, Marcos/JDC-9198-2023
OI Casas Yrurzum, Sergio/0000-0002-0396-4628; Portalés,
   Cristina/0000-0002-4520-2250; Casanova-Salas, Pablo/0000-0003-1588-9888;
   Fernandez Marin, Marcos/0000-0002-0307-0392
CR [Anonymous], 1997, PHOTOGRAMMETRY ADV M
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Ashdown M., 2005, P 2005 IEEE COMP SOC, P8, DOI DOI 10.1109/CVPR.2005.533
   Axholt M., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P2427
   Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27
   Chen BS, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.7.073107
   Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793
   Chen R, 2016, APPL OPTICS, V55, P4293, DOI 10.1364/AO.55.004293
   Chien H.J., 2010, P 25 INT C IM VIS CO, P1
   Deglint J, 2016, J SOC INF DISPLAY, V24, P510, DOI 10.1002/jsid.464
   DERMANIS A, 1994, ISPRS J PHOTOGRAMM, V49, P2, DOI 10.1016/0924-2716(94)90061-2
   Fernandez S, 2011, INT SYMP IMAGE SIG, P633
   Gockel T, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P367, DOI 10.1109/SMI.2004.1314529
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Harville M., 2006, P C COMP VIS PATT RE, P5, DOI DOI 10.1109/CVPRW.2006.161
   Hong W, 2012, IEEE IMAGE PROC, P337, DOI 10.1109/ICIP.2012.6466864
   Huang ZR, 2015, APPL OPTICS, V54, P347, DOI 10.1364/AO.54.000347
   Kimura M., 2007, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383477
   Knyaz VA, 2006, P ISPRS COMM 5 S IM
   Liao JR, 2008, IEEE ASME INT C ADV, P770, DOI 10.1109/AIM.2008.4601757
   MadMapper, 2017, MADMAPPER MAPPING SO
   Martynov I, 2011, LECT NOTES COMPUT SC, V6688, P536, DOI 10.1007/978-3-642-21227-7_50
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Okatani T., 2006, P 2006 C COMP VIS PA, P8, DOI DOI 10.1109/CVPRW.2006.35
   Orghidan R, 2014, MACH VISION APPL, V25, P489, DOI 10.1007/s00138-013-0517-x
   Park S-Y, 2010 20 INT C PATT R, P320, DOI [10.1109/icpr.2010.87, DOI 10.1109/ICPR.2010.87]
   Portalés C, 2019, MULTIMED TOOLS APPL, V78, P1457, DOI 10.1007/s11042-018-6253-5
   Portalés C, 2017, J IMAGING, V3, DOI 10.3390/jimaging3020019
   Portalés C, 2015, PHOTOGRAMM REC, V30, P82, DOI 10.1111/phor.12094
   Qian L, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P154, DOI [10.1109/ISMAR-Adjunct.2016.57, 10.1109/ISMAR-Adjunct.2016.0065]
   Raij A, 2004, INT C PATT RECOG, P14, DOI 10.1109/ICPR.2004.1333994
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Sajadi B, 2010, P IEEE VIRT REAL ANN, P155, DOI 10.1109/VR.2010.5444797
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1307, DOI 10.1109/TVCG.2009.166
   Tao J, 2004, CALIBRATION PROJECTO
   Tardif JP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P217, DOI 10.1109/im.2003.1240253
   Wang Q, 2010, CHIN CONT DECIS CONF, P3354, DOI 10.1109/CCDC.2010.5498574
   Wu TT, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-417
   Zhang B, 2007, PATTERN RECOGN, V40, P1368, DOI 10.1016/j.patcog.2006.04.001
   Zhang JQ, 2003, P SOC PHOTO-OPT INS, V5286, P187, DOI 10.1117/12.538878
   Zhang X, 2015, PROCEEDINGS OF THE 2015 7TH IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P1, DOI 10.1109/ICCIS.2015.7274538
   Zhao L, 2014, J SOC INF DISPLAY, V22, P473, DOI 10.1002/jsid.264
NR 42
TC 3
Z9 3
U1 4
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 109
EP 121
DI 10.1007/s10055-018-00377-3
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800007
DA 2024-07-18
ER

PT J
AU Garzón, J
   Pavón, J
   Baldiris, S
AF Garzon, Juan
   Pavon, Juan
   Baldiris, Silvia
TI Systematic review and meta-analysis of augmented reality in educational
   settings
SO VIRTUAL REALITY
LA English
DT Review
DE Augmented reality; Education; Inclusive learning; Information
   technologies; Literature review; Meta-analysis
ID SCIENCE LABORATORIES; IMPACT; INSTRUCTION; SUPPORT; DESIGN;
   HETEROGENEITY; TECHNOLOGY; CHALLENGES; PATTERNS; SKILLS
AB Augmented reality (AR) is an important technology to enhance learning experiences. Many studies have been conducted to establish the tendencies, affordances and challenges of this technology in educational settings. However, these studies have little analyzed important issues such as the special needs of specific users or the impact of AR on education through the quantitative analysis of the data. This paper presents a literature review that covers 61 studies published between 2012 and 2018 in scientific journals and conference proceedings. As a result, it identifies the status and tendencies in the usage of AR in education, the impact of this technology on learning processes, open questions as well as opportunities and challenges for developers and practitioners. The results indicate that AR has a medium effect on learning effectiveness (d = .64, p < .001). The most reported advantages of AR systems in education are "learning gains" and "motivation." Otherwise, it is also important to mention that only one of the AR systems of the studies includes accessibility features, which represents a setback in terms of social inclusion. Therefore, given the apparent multiple benefits of using AR systems in educational settings, stakeholders have great opportunities to develop new and better systems that benefit all learners. This technology covers a wide range of topics, target groups, academic levels and more. This could be an indicator that AR is achieving maturity and has successfully taken root in educational settings.
C1 [Garzon, Juan] Catholic Univ East, Rionegro, Colombia.
   [Pavon, Juan] Univ Complutense Madrid, Madrid, Spain.
   [Baldiris, Silvia] Int Univ La Rioja, Logrono, La Rioja, Spain.
C3 Complutense University of Madrid; Universidad Internacional de La Rioja
   (UNIR)
RP Garzón, J (corresponding author), Catholic Univ East, Rionegro, Colombia.
EM fgarzon@uco.edu.co; jpavon@fdi.ucm.es; Silvia.baldiris@unir.net
RI Garzón, Juan/G-9537-2019; Navarro, Silvia Margarita SMBN
   Baldiris/C-7146-2019; Mestras, Juan Pavón/AAC-3533-2020
OI Garzón, Juan/0000-0002-0374-8570; Pavon Mestras,
   Juan/0000-0002-9553-8123
FU Universidad Catolica de Oriente [201630]
FX Funding was provided by Universidad Catolica de Oriente
   <BOLD>(</BOLD>201630<BOLD>)</BOLD>.
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Akçayir M, 2016, COMPUT HUM BEHAV, V57, P334, DOI 10.1016/j.chb.2015.12.054
   [Anonymous], SHAR MOB DEV OWN WOR
   Antonioli M., 2014, J TECHNOLOGY STUDIES, V40, P96, DOI [DOI 10.21061/JOTS.V40I2.A.4, 10.21061/jots.v40i2.a.4]
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2015, PROCEDIA COMPUT SCI, V75, P49, DOI 10.1016/j.procs.2015.12.203
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Barma S., 2015, International Journal of Serious Games, V2, DOI DOI 10.17083/IJSG.V2I2.66
   Bernard RM, 2004, REV EDUC RES, V74, P379, DOI 10.3102/00346543074003379
   Blake MB, 2009, COMPUT EDUC, V53, P966, DOI 10.1016/j.compedu.2009.05.014
   Ibáñez MB, 2014, COMPUT EDUC, V71, P1, DOI 10.1016/j.compedu.2013.09.004
   Borenstein M, 2010, RES SYNTH METHODS, V1, P97, DOI 10.1002/jrsm.12
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Bujak KR, 2013, COMPUT EDUC, V68, P536, DOI 10.1016/j.compedu.2013.02.017
   Cai S, 2017, INTERACT LEARN ENVIR, V25, P778, DOI 10.1080/10494820.2016.1181094
   Cai S, 2013, INT J ENG EDUC, V29, P856
   Calle-Bustos AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184645
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chang HY, 2013, BRIT J EDUC TECHNOL, V44, pE95, DOI 10.1111/j.1467-8535.2012.01379.x
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chang YL, 2015, EDUC TECHNOL SOC, V18, P166
   Chauhan S, 2017, COMPUT EDUC, V105, P14, DOI 10.1016/j.compedu.2016.11.005
   Chen CH, 2016, ASIA-PAC EDUC RES, V25, P567, DOI 10.1007/s40299-016-0284-3
   Chen CM, 2012, COMPUT EDUC, V59, P638, DOI 10.1016/j.compedu.2012.03.001
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Chiang THC, 2014, COMPUT EDUC, V78, P97, DOI 10.1016/j.compedu.2014.05.006
   Chiu JL, 2015, COMPUT EDUC, V85, P59, DOI 10.1016/j.compedu.2015.02.007
   COCHRAN WG, 1954, BIOMETRICS, V10, P101, DOI 10.2307/3001666
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   COHEN J, 1968, PSYCHOL BULL, V70, P426, DOI 10.1037/h0026714
   Cuendet S, 2013, COMPUT EDUC, V68, P557, DOI 10.1016/j.compedu.2013.02.015
   De Paolis Lucio Tommaso, 2016, AUGMENTED REALITY VI
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Diegmann P., 2015, Benefits, V3, P6
   Eishita FZ, 2018, ENTERTAIN COMPUT, V27, P137, DOI 10.1016/j.entcom.2018.04.006
   Ferrer-Torregrosa J, 2015, J SCI EDUC TECHNOL, V24, P119, DOI 10.1007/s10956-014-9526-4
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Glass G. V., 1976, ED RES, V5, P3, DOI [DOI 10.3102/0013189X005010003, 10.2307/1174772ISSN0536-1036, 10.3102/0013189x005010003]
   Gün ET, 2017, EGIT BILIM, V42, P31, DOI 10.15390/EB.2017.7140
   Hedges L. V., 2014, STAT METHODS METAANA
   Herpieh F, 2014, SYMP VIRTUAL AUGMENT, P118, DOI 10.1109/SVR.2014.36
   Higgins JPT, 2002, STAT MED, V21, P1539, DOI 10.1002/sim.1186
   Hsiao KF, 2013, MULTIMED TOOLS APPL, V64, P407, DOI 10.1007/s11042-011-0985-9
   Hsiao KF, 2012, INTERACT LEARN ENVIR, V20, P331, DOI 10.1080/10494820.2010.486682
   Huedo-Medina TB, 2006, PSYCHOL METHODS, V11, P193, DOI 10.1037/1082-989X.11.2.193
   Ibáñez MB, 2016, IEEE T LEARN TECHNOL, V9, P46, DOI 10.1109/TLT.2015.2445761
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Joo-Nagata J, 2017, COMPUT EDUC, V111, P1, DOI 10.1016/j.compedu.2017.04.003
   Juan MC, 2016, DIGIT EDUC REV, P234
   Karagozlu D, 2018, QUAL QUANT, V52, P2393, DOI 10.1007/s11135-017-0674-5
   Kelley K, 2012, PSYCHOL METHODS, V17, P137, DOI 10.1037/a0028086
   Kitchenham B., 2007, ENGINEERING, V45, P1051
   Lancaster H.O., 2005, Encyclopedia of biostatistics, V2
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Lin TJ, 2013, COMPUT EDUC, V68, P314, DOI 10.1016/j.compedu.2013.05.011
   Liou HH, 2017, EDUC TECHNOL SOC, V20, P110
   Mekni M, 2014, APPL COMPUT SCI
   Medina AM, 2018, INT J INTERACT MULTI, V5, P53, DOI 10.9781/ijimai.2018.02.005
   Morris SB, 2002, PSYCHOL METHODS, V7, P105, DOI 10.1037//1082-989X.7.1.105
   Morris SB, 2008, ORGAN RES METHODS, V11, P364, DOI 10.1177/1094428106291059
   Mumtaz K, 2017, EURASIA J MATH SCI T, V13, P4419, DOI 10.12973/eurasia.2017.00938a
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Parhizkar B, 2012, INT CONF MULTIMED, P405
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Radu I, 2012, INT SYM MIX AUGMENT, P313, DOI 10.1109/ISMAR.2012.6402590
   Roberto R., 2011, 2011 XIII Symposium on Virtual Reality (SVR), P28, DOI 10.1109/SVR.2011.19
   Rojas-Muñoz E, 2019, ANN SURG, V270, P384, DOI 10.1097/SLA.0000000000002764
   Safar AH, 2017, EURASIA J MATH SCI T, V13, P417, DOI 10.12973/eurasia.2017.00624a
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Schmitz B, 2015, COMPUT EDUC, V81, P35, DOI 10.1016/j.compedu.2014.09.001
   Schneider SL, 2013, COMP SOC RES, V30, P365, DOI 10.1108/S0195-6310(2013)0000030017
   Solomon SR, 2009, J MOD APPL STAT METH, V8, P448, DOI 10.22237/jmasm/1257034080
   Sommerauer P, 2014, COMPUT EDUC, V79, P59, DOI 10.1016/j.compedu.2014.07.013
   Tamim RM, 2011, REV EDUC RES, V81, P4, DOI 10.3102/0034654310393361
   Tarng W, 2016, MOB INF SYST, V2016, P1, DOI [10.1109/IWCMC.2013.6583638, DOI 10.1109/IWCMC.2013.6583638]
   Tarng W, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/5950732
   Tarng W, 2015, VIRTUAL REAL-LONDON, V19, P253, DOI 10.1007/s10055-015-0265-5
   Tekedere H., 2016, International Journal of Environmental Science Education, V11, P9469
   Turan Z, 2018, J GEOGR HIGHER EDUC, V42, P427, DOI 10.1080/03098265.2018.1455174
   Vanderheiden G, 2011, LECT NOTES COMPUT SC, V6765, P517, DOI 10.1007/978-3-642-21672-5_57
   WAI, 2016, WEB ACC IN
   Wang YH, 2017, J COMPUT ASSIST LEAR, V33, P532, DOI 10.1111/jcal.12199
   Wei XD, 2015, COMPUT EDUC, V81, P221, DOI 10.1016/j.compedu.2014.10.017
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
   Zhang J, 2014, COMPUT EDUC, V73, P178, DOI 10.1016/j.compedu.2014.01.003
NR 87
TC 205
Z9 216
U1 8
U2 135
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 447
EP 459
DI 10.1007/s10055-019-00379-9
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300011
DA 2024-07-18
ER

PT J
AU Prudenzi, A
   Rooney, B
   Presti, G
   Lombardo, M
   Lombardo, D
   Messina, C
   McHugh, L
AF Prudenzi, Arianna
   Rooney, Brendan
   Presti, Giovambattista
   Lombardo, Marco
   Lombardo, Daniele
   Messina, Concetta
   McHugh, Louise
TI Testing the effectiveness of virtual reality as a defusion technique for
   coping with unwanted thoughts
SO VIRTUAL REALITY
LA English
DT Article
DE Acceptance and commitment therapy; Cognitive defusion; Virtual reality;
   Negative thoughts; Randomized controlled trial
ID SELF-REFERENTIAL THOUGHTS; COGNITIVE DEFUSION; EXPOSURE THERAPY;
   ANXIETY; FEAR
AB Negative thoughts are experienced by as many as 80-99% of the population. These thoughts are associated with a variety of negative consequences, including negative mood, decreased task performance and the development of psychopathology. One technique employed in contextual behavioral therapies to help cope with negative thoughts is cognitive defusion. Cognitive defusion techniques undermine potential negative effects of thinking by teaching clients to get some distance from their thoughts. Virtual reality (VR) is the computer-generated simulation of a three-dimensional environment that users can interact in. VR is of increasing interest to applied psychologists due to its potential for exposure learning. One area where VR may be effective is helping people to cope with negative thoughts. The current study examined the impact of a VR task as a cognitive defusion technique on participants' relationship with a negative self-referential thought (e.g., I am a failure). Thirty participants were randomly assigned to one of two conditions (i.e., defusion VR and control VR). Participants were tested pre- and post-VR task on a state measure of cognitive defusion and ratings of their self-referential negative thought. The results indicated that a defusion VR task facilitates the management of negative thoughts and leads to an increase in state defusion. The findings are discussed in terms of their implications for the use of VR techniques in dealing with negative thoughts.
C1 [Prudenzi, Arianna; Rooney, Brendan; McHugh, Louise] Univ Coll Dublin, Sch Psychol, Dublin, Ireland.
   [Presti, Giovambattista; Messina, Concetta] Kore Univ, Dept Human & Social Sci, Enna, Italy.
   [Lombardo, Marco; Lombardo, Daniele] Behav Labs Srls, Catania, Italy.
C3 University College Dublin; Universita Kore di ENNA
RP McHugh, L (corresponding author), Univ Coll Dublin, Sch Psychol, Dublin, Ireland.
EM louise.mchugh@ucd.ie
RI rooney, brendan/U-1041-2019; Presti, Giovambattista/O-7233-2015;
   Prudenzi, Arianna/AHA-6638-2022; Presti, Giovambattista/N-1634-2019
OI rooney, brendan/0000-0001-9842-1492; Presti,
   Giovambattista/0000-0002-0891-4558; Prudenzi,
   Arianna/0000-0002-5185-2807; Presti, Giovambattista/0000-0002-0891-4558
CR Atkins PWB, 2016, J CONTEXT BEHAV SCI, V5, P71, DOI 10.1016/j.jcbs.2016.05.001
   Belloch A, 2004, CLIN PSYCHOL PSYCHOT, V11, P100, DOI 10.1002/cpp.397
   Bolderston H, 2018, J CONTEXT BEHAV SCI
   Botella C., 2013, REV ARGENT CLIN PSIC, V22, P111
   Clark DA, 2005, UNWANTED INTRUSIVE T
   Deacon BJ, 2011, J COGN PSYCHOTHER, V25, P218, DOI 10.1891/0889-8391.25.3.218
   Difede J, 2002, PSYCHIAT SERV, V53, P1083, DOI 10.1176/appi.ps.53.9.1083
   Duff H, 2016, J CONTEXT BEHAV SCI, V5, P39, DOI 10.1016/j.jcbs.2015.11.003
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Falconer CJ, 2016, BJPSYCH OPEN, V2, P74, DOI 10.1192/bjpo.bp.115.002147
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Foa EdnaB., 2009, EFFECTIVE TREATMENTS
   Gaudiano B.A., 2011, The International Journal of Behavioral Consultation and Therapy, V7, P54, DOI [10.1037/h0100927, DOI 10.1037/H0100927]
   Hayes S. C., 2012, ACCEPTANCE COMMITMEN
   Hayes SC, 2011, ANNU REV CLIN PSYCHO, V7, P141, DOI 10.1146/annurev-clinpsy-032210-104449
   Healy HA, 2008, PSYCHOL REC, V58, P623, DOI 10.1007/BF03395641
   Krijn M, 2007, AVIAT SPACE ENVIR MD, V78, P121
   LAMSON R, 1994, P 2 ANN C VIRT REAL, P63
   Larsson A, 2016, BEHAV MODIF, V40, P452, DOI 10.1177/0145445515621488
   Mandavia A, 2015, J CONTEXT BEHAV SCI, V4, P86, DOI 10.1016/j.jcbs.2015.02.003
   Masud A, 2010, J BEHAV THER EXP PSY, V41, P11, DOI 10.1016/j.jbtep.2009.08.006
   Masuda A, 2004, BEHAV RES THER, V42, P477, DOI 10.1016/j.brat.2003.10.008
   Montraghi TE, 2014, J CLIN PSYCHOL, V70, P197, DOI [10.1002/jclp.22051, DOI 10.1002/JCLP.22051]
   North MM, 1997, AM J PSYCHIAT, V154, P130
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Peñate W, 2008, INT J CLIN HLTH PSYC, V8, P5
   RACHMAN S, 1978, BEHAV RES THER, V16, P233, DOI 10.1016/0005-7967(78)90022-0
   RIZZO A, 2004, P 3 ANN INT WORKSH V, P35
   Rothbaum B O, 1997, J Psychother Pract Res, V6, P219
   Shiri S, 2013, PAIN MED, V14, P621, DOI 10.1111/pme.12083
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Wiederhold B. K., 2005, Virtual reality therapy for anxiety disorders: Advances in evaluation and treatment, P77, DOI [10.1037/10858-006, DOI 10.1037/10858-006]
NR 33
TC 11
Z9 11
U1 0
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 179
EP 185
DI 10.1007/s10055-018-0372-1
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500006
DA 2024-07-18
ER

PT J
AU Pouliquen-Lardy, L
   Milleville-Pennel, I
   Guillaume, F
   Mars, F
AF Pouliquen-Lardy, Lauriane
   Milleville-Pennel, Isabelle
   Guillaume, Francois
   Mars, Franck
TI Remote collaboration in virtual reality: asymmetrical effects of task
   distribution on spatial processing and mental workload
SO VIRTUAL REALITY
LA English
DT Article
DE Remote collaboration; Spatial common frame of reference; Spatial
   cognition; Virtual reality; Mental workload
ID PERSPECTIVE; REPRESENTATIONS; ORIENTATION; FRAMES
AB In the context of a remote collaboration task in virtual reality, this study aimed to analyze the effects of task distribution on the processing of spatial information and mental workload in spatial dialogs. Pairs of distant participants with specific roles (a guide and a manipulator) had to collaboratively move a virtual object in a plane factory mock-up. The displays allowed the participants to be immersed together in the virtual environment. We analyzed the dialogs that took place according to the frames of reference and the mental transformations required to produce the spatial statements. We also measured the associated mental workload. Results showed that when participants took a perspective, the manipulator's point of view was preferred. Perspective-taking only yielded a moderate increase in mental rotations, which may explain a specifically high mental demand score for the guides' NASA-TLX. Overall, this is in accordance with the least collaborative effort principle. This study reinforces the idea that, in collaboration, operators do not need the same aids as each other. Thus, it is not necessary to develop symmetrical tools, i.e., the same tools for all co-workers; instead, the needs of each operator should be taken into account, according to the task he has to perform. In our case, the guides would be helped with perspective-taking aids, while the manipulators would be helped with action-oriented tools.
C1 [Pouliquen-Lardy, Lauriane] IRT Jules Verne, Bouguenais, France.
   [Pouliquen-Lardy, Lauriane; Milleville-Pennel, Isabelle; Mars, Franck] Inst Rech Commun & Cybernet Nantes IRCCyN, UMR CNRS 6597, Campus Ecole Cent Nantes,1,Rue Noe,BP 92101, F-44321 Nantes 03, France.
   [Guillaume, Francois] Airbus Grp, Suresnes, France.
C3 Nantes Universite; Nantes Universite; Ecole Centrale de Nantes; Centre
   National de la Recherche Scientifique (CNRS); Airbus; Airbus France
   S.A.S.
RP Mars, F (corresponding author), Inst Rech Commun & Cybernet Nantes IRCCyN, UMR CNRS 6597, Campus Ecole Cent Nantes,1,Rue Noe,BP 92101, F-44321 Nantes 03, France.
EM franck.mars@irccyn.ec-nantes.fr
RI Mars, Franck/O-8100-2019
OI Mars, Franck/0000-0002-4140-0049
FU Airbus Group; Airbus; IRCCyN
FX We would like to thank Jeremy Le Thiec, Sidi Set, and Jean- Pierre
   Collet of the Airbus NemoLab who provided the virtual reality setup, as
   well as substantial technical assistance. This study is part of the
   PIVIPP project managed by IRT Jules Verne ( French Institute in Research
   and Technology in Advanced Manufacturing Technologies for Composite,
   Metallic and Hybrid Structures). The authors wish to acknowledge the
   support of the industrial and academic partners of this project,
   respectively, Airbus Group, Airbus and IRCCyN.
CR [Anonymous], CERVEAU COMPORTEMENT
   [Anonymous], 2001, CERVEAU HOMME CERVEA
   [Anonymous], 1991, PERSPECTIVES SOCIALL, DOI DOI 10.1037/10096-006
   BOER LC, 1991, ACTA PSYCHOL, V76, P1, DOI 10.1016/0001-6918(91)90050-A
   Casanueva J, 2000, SPRING COMP SCI, P85
   Chellali AM, 2007, P 10 ANN INT WORKSH, P371
   Chellali A, 2013, VIRTUAL REAL-LONDON, V17, P1, DOI 10.1007/s10055-012-0214-5
   Churchill E. F., 2001, COLLABORATIVE VIRTUA
   Duran ND, 2011, COGNITION, V121, P22, DOI 10.1016/j.cognition.2011.06.009
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Finlay CA, 2007, PSYCHOL RES-PSYCH FO, V71, P265, DOI 10.1007/s00426-006-0082-2
   Foo P, 2007, PSYCHOL RES-PSYCH FO, V71, P240, DOI 10.1007/s00426-006-0080-4
   Garrod S, 2009, TOP COGN SCI, V1, P292, DOI 10.1111/j.1756-8765.2009.01020.x
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   HINTZMAN DL, 1981, COGNITIVE PSYCHOL, V13, P149, DOI 10.1016/0010-0285(81)90007-4
   Hoc JH, 2001, INT J HUM-COMPUT ST, V54, P509, DOI 10.1006/ijhc.2000.0454
   Lawton CA, 2001, SEX ROLES, V44, P321, DOI 10.1023/A:1010981616842
   Michelon P, 2006, PERCEPT PSYCHOPHYS, V68, P327, DOI 10.3758/BF03193680
   NYGREN TE, 1991, HUM FACTORS, V33, P17, DOI 10.1177/001872089103300102
   Pouliquen-Lardy L, 2015, COGN PROCESS, V16, pS337, DOI 10.1007/s10339-015-0672-2
   Riecke BE, 2007, PSYCHOL RES-PSYCH FO, V71, P298, DOI 10.1007/s00426-006-0085-z
   ROBERTS RJ, 1993, CHILD DEV, V64, P1258, DOI 10.2307/1131338
   Roger M, 2013, APPL COGNITIVE PSYCH, V27, P497, DOI 10.1002/acp.2927
   Roskos-Ewoldsen B, 1998, J EXP PSYCHOL LEARN, V24, P215, DOI 10.1037/0278-7393.24.1.215
   SCHOBER MF, 1995, DISCOURSE PROCESS, V20, P219, DOI 10.1080/01638539509544939
   Schouten AP, 2016, COMMUN RES, V43, P180, DOI 10.1177/0093650213509667
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Wang X, 2011, COLLABORATIVE DESIGN
NR 28
TC 31
Z9 36
U1 0
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2016
VL 20
IS 4
BP 213
EP 220
DI 10.1007/s10055-016-0294-8
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DY6FF
UT WOS:000385201100003
DA 2024-07-18
ER

PT J
AU Dehos, J
   Zéghers, É
   Sarry, L
   Rousselle, F
   Renaud, C
AF Dehos, J.
   Zeghers, E.
   Sarry, L.
   Rousselle, F.
   Renaud, C.
TI Immersive front-projection analysis using a radiosity-based simulation
   method
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive environments; Video projection; Radiometric compensation;
   Radiosity
ID INVERSE; SHAPE
AB Video projectors are designed to project onto flat white diffuse screens. Over the last few years, projector-based systems have been used, in virtual reality applications, to light non-specific environments such as the walls of a room. However, in these situations, the images seen by the user are affected by several radiometric disturbances, such as interreflection. Radiometric compensation methods have been proposed to reduce the disturbance caused by interreflection, but nothing has been proposed for evaluating the phenomenon itself and the effectiveness of compensation methods. In this paper, we propose a radiosity-based method to simulate light transfer in immersive environments, from a projector to a camera (the camera gives the image a user would see in a real room). This enables us to evaluate the disturbances resulting from interreflection. We also consider the effectiveness of interreflection compensation and study the influence of several parameters (projected image, projection onto a small or large part of the room, reflectivity of the walls). Our results show that radiometric compensation can reduce the influence of interreflection but is severely limited if we project onto a large part of the walls around the user, or if all the walls are bright.
C1 [Dehos, J.; Rousselle, F.; Renaud, C.] Univ Lille Nord France, LISIC, ULCO, Calais, France.
   [Zeghers, E.; Sarry, L.] Univ Auvergne, ISIT, Clermont Ferrand, France.
C3 Universite de Lille; Universite du Littoral-Cote-d'Opale; Universite
   Clermont Auvergne (UCA)
RP Dehos, J (corresponding author), Univ Lille Nord France, LISIC, ULCO, Calais, France.
EM dehos@lisic.univ-littoral.fr
RI Sarry, Laurent/K-5708-2018
OI Sarry, Laurent/0000-0002-2237-0497; renaud,
   christophe/0000-0002-8350-8824
CR [Anonymous], 2007, 2007 IEEE C COMPUTER
   Ashdown M., 2006, 2006 C COMP VIS PATT, P6
   Astre B, 2008, IEEE COMP SOC C COMP
   Bai JM, 2010, LECT NOTES COMPUT SC, V6312, P294
   Bimber O., 2008, ACM Transactions on Graphics (Proc. SIGGRAPH '08), P1
   Bimber O, 2006, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2006.34
   Bourke P., 2008, Journal of Multimedia, V3, P41
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Fernando R., 2003, CG TUTORIAL
   Glassner A.S., 1994, PRINCIPLES DIGITAL I
   Goral C. M., 1984, Computers & Graphics, V18, P213
   Grossberg MD, 2004, PROC CVPR IEEE, P452
   Howell J. R., 1982, A Catalog of Radiation Configuration Factors
   Langer MS, 2001, COLOR RES APPL, V26, pS218, DOI 10.1002/1520-6378(2001)26:1+<::AID-COL46>3.0.CO;2-7
   Mukaigawa Y., 2006, P ACM S VIRT REAL SO, P265
   Nayar S. K., 2003, ICCV WORKSH PROJ CAM
   Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977
   NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695
   Seitz SM, 2005, IEEE I CONF COMP VIS, P1440
   Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257
   Sheng Y, 2010, COMPUT GRAPH FORUM, V29, P387, DOI 10.1111/j.1467-8659.2009.01608.x
   Wang D., 2005, P IEEE COMP SOC C CO, P100
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yuen NPY, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P237
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
NR 25
TC 0
Z9 1
U1 1
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2014
VL 18
IS 2
BP 117
EP 128
DI 10.1007/s10055-013-0233-x
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HV
UT WOS:000340622300003
DA 2024-07-18
ER

PT J
AU Lee, M
   Billinghurst, M
   Baek, W
   Green, R
   Woo, W
AF Lee, Minkyung
   Billinghurst, Mark
   Baek, Woonhyuk
   Green, Richard
   Woo, Woontack
TI A usability study of multimodal input in an augmented reality
   environment
SO VIRTUAL REALITY
LA English
DT Article
DE Multimodal interface; Augmented reality; Usability; Efficiency;
   Effectiveness; Satisfaction
ID INTERFACE; SPEECH
AB In this paper, we describe a user study evaluating the usability of an augmented reality (AR) multimodal interface (MMI). We have developed an AR MMI that combines free-hand gesture and speech input in a natural way using a multimodal fusion architecture. We describe the system architecture and present a study exploring the usability of the AR MMI compared with speech-only and 3D-hand-gesture-only interaction conditions. The interface was used in an AR application for selecting 3D virtual objects and changing their shape and color. For each interface condition, we measured task completion time, the number of user and system errors, and user satisfactions. We found that the MMI was more usable than the gesture-only interface conditions, and users felt that the MMI was more satisfying to use than the speech-only interface conditions; however, it was neither more effective nor more efficient than the speech-only interface. We discuss the implications of this research for designing AR MMI and outline directions for future work. The findings could also be used to help develop MMIs for a wider range of AR applications, for example, in AR navigation tasks, mobile AR interfaces, or AR game applications.
C1 [Lee, Minkyung] R&D Ctr, Technol Strategy Off, KT, Seoul 137792, South Korea.
   [Billinghurst, Mark] Univ Canterbury, HIT Lab NZ, Christchurch 8140, New Zealand.
   [Baek, Woonhyuk] Daum Commun, Multimedia Res Team, Jeju Si 690140, Jeju Do, South Korea.
   [Green, Richard] Univ Canterbury, Christchurch 8140, New Zealand.
   [Woo, Woontack] Korea Adv Inst Sci & Technol, GSCT UVR Lab, Taejon 305701, South Korea.
C3 University of Canterbury; University of Canterbury; Korea Advanced
   Institute of Science & Technology (KAIST)
RP Lee, M (corresponding author), R&D Ctr, Technol Strategy Off, KT, 17 Woomyeon Dong, Seoul 137792, South Korea.
EM ming2279@gmail.com; mark.billinghurst@hitlabnz.org; wbaek@daumcorp.com;
   richard.green@canterbury.ac.nz; wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012; Billinghurst, Mark/AAJ-4236-2020
OI Woo, Woontack/0000-0002-5501-4421; Billinghurst,
   Mark/0000-0003-4172-6759
FU DigiLog Miniature Augmented Reality Research Program; KAIST Research
   Foundation; Global Frontier R&D Program on <Human-centered Interaction
   for Coexistence>; National Research Foundation of Korea; Korean
   Government (MSIP) [NRF-2010-0029751]
FX This work was supported by the DigiLog Miniature Augmented Reality
   Research Program funded by KAIST Research Foundation. It was supported
   by the Global Frontier R&D Program on <Human-centered Interaction for
   Coexistence> funded by the National Research Foundation of Korea grant
   funded by the Korean Government (MSIP) (NRF-2010-0029751).
CR [Anonymous], P 10 ACM INT S ADV G
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BEVAN N, 1995, SOFTWARE QUAL J, V4, P115, DOI 10.1007/BF00402715
   BOLT RA, 1980, P 7 ANN C COMP GRAPH, P262, DOI [DOI 10.1145/800250.807503, 10.1145/965105.807503, DOI 10.1145/965105.807503]
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Chai D, 2000, TENCON IEEE REGION, pA421
   Chu CCP, 1997, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ROBOT.1997.614321
   Cohen PR, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P31, DOI 10.1145/266180.266328
   COHEN PR, 1989, CHI 89 C P, P227
   FELS S, 1995, CHI 95, P456
   FROKJAER E, 2000, CHI LETT, V2, P345
   Hauptmann A. G., 1989, SIGCHI Bulletin, P241, DOI 10.1145/67450.67496
   Heidemann Gunther, 2004, P 6 INT C MULT INT I, P53, DOI DOI 10.1145/1027933.1027944
   IRAWATI S, 2006, MOVE COUCH DEV AUGME, P1
   Irawati S, 2006, LECT NOTES COMPUT SC, V4282, P272
   Kaiser E., 2003, ICMI 03, P12
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kölsch M, 2006, IEEE COMPUT GRAPH, V26, P62, DOI 10.1109/MCG.2006.66
   Kölsch M, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P86
   Koons D.B., 1994, Conference on Human Factors in Computing Systems (Boston, Massachusetts, USA, April 24-28, 1994), P453, DOI DOI 10.1145/259963.260487
   Krum D.M., 2002, Proceedings of the symposium on Data Visualisation 2002, P195
   LATOSCHIK ME, AFRIGRAPH 2001, P95
   LaViola JJ, 1999, LECT NOTES ARTIF INT, V1739, P303
   Lee Minkyung, 2008, P 10 INT C MULT INT, P249, DOI DOI 10.1145/1452392.1452444
   LUCENTE M, 1998, P AAAI SPRING S INT
   Olwal A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P300, DOI 10.1109/ISMAR.2003.1240730
   Oviatt S., 2004, Proceedings of the 6th International Conference on Multimodal Interfaces, P129, DOI DOI 10.1145/1027933.1027957
   Quek F., 2002, ACM Transactions on Computer-Human Interaction, V9, P171, DOI 10.1145/568513.568514
   Shneiderman B, 2000, COMMUN ACM, V43, P63, DOI 10.1145/348941.348990
   Tse Edward., 2006, Proceedings of the 8th international conference on Multimodal interfaces, ICMI'06, P76, DOI DOI 10.1145/1180995.1181012
   WEIMER D, 1989, P ACM C HUM FACT COM, P235
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 33
TC 57
Z9 70
U1 5
U2 36
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2013
VL 17
IS 4
BP 293
EP 305
DI 10.1007/s10055-013-0230-0
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 239BT
UT WOS:000325997200004
DA 2024-07-18
ER

PT J
AU Mishra, V
   Suresh, K
AF Mishra, Vikalp
   Suresh, Krishnan
TI A dual-representation strategy for the virtual assembly of thin
   deformable objects
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual assembly; Deformation; Thin; Plates; Kirchhoff-Love;
   Dual-representation
AB The two main objectives of virtual assembly are: (1) to train assembly-operators through virtual assembly models, and (2) to simultaneously evaluate products for ease-of-assembly. The focus of this paper is on developing computational techniques for virtual assembly of thin deformable beam and plate-like objects. To meet the objectives of virtual assembly, the underlying computational technique must: (1) be carried out at a high frame-rate (> 20 frames/second), (2) be accurate (< 5% error in deformation and force estimation), (3) be conducive to collision detection, and (4) support rapid design evaluations. We argue in this paper that popular computational techniques such as 3-D finite element analysis, boundary element analysis and classic beam/plate/shell analysis fail to meet these requirements. We therefore propose a new class of dual representation techniques for virtual assembly of thin solids, where the geometry is retained in its full 3-D form, while the underlying physics is dimensionally reduced, delivering: (1) high computational efficiency and accuracy (over 20 frames per second with < 1% deformation error), and (2) direct CAD model processing, i.e., the CAD model is not geometrically simplified, and 3-D finite element mesh is not generated. In particular, a small-size stiffness matrix with about 300 degrees of freedom per deformable object is generated directly from a coarse surface triangulation, and its LU-decomposition is then exploited during real-time simulation. The accuracy and efficiency of the proposed method is established through numerical experiments and a case study.
C1 [Mishra, Vikalp; Suresh, Krishnan] Univ Wisconsin, Madison, WI 53706 USA.
C3 University of Wisconsin System; University of Wisconsin Madison
RP Suresh, K (corresponding author), Univ Wisconsin, Madison, WI 53706 USA.
EM suresh@engr.wisc.edu
FU Directorate For Engineering; Div Of Civil, Mechanical, & Manufact Inn
   [0745398] Funding Source: National Science Foundation
CR [Anonymous], 1959, THEORY PLATES SHELLS
   Antonya Csaba, 2007, Virtual Reality, V11, P275, DOI 10.1007/s10055-007-0074-6
   Becker A., 1992, The boundary element method in engineering: a complete course
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Brough John E., 2007, Virtual Reality, V11, P189, DOI 10.1007/s10055-007-0076-4
   Chapman P. M., 2000, Virtual Reality, V5, P117, DOI 10.1007/BF01409418
   DOW JO, 1988, INT J NUMER METH ENG, V26, P743, DOI 10.1002/nme.1620260316
   EHMANN S, 2001, COMP GRAPH FOR P EUR
   Golub G.H., 1989, MATRIX COMPUTATIONS
   HERMANSEN F, 1995, PHYS MED BIOL, V40, P1909, DOI 10.1088/0031-9155/40/11/010
   HUDSON T, 1997, P 2 S VIRT REAL MOD
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   JEMIELITA G, 1990, J APPL MECH-T ASME, V57, P1088, DOI 10.1115/1.2897635
   Jorabchi K, 2009, J MECH DESIGN, V131, DOI 10.1115/1.3116342
   Kreyszig E., 2006, ADV ENG MATH
   Lawrence Associates Inc, 1994, VIRT MAN TECHN WORKS
   Lee JA, 2007, INFORM SCI STAT, V18
   LEE KY, 2005, P ACM S SOL PHYS MOD
   LONG YQ, 1995, COMPUT STRUCT, V54, P717, DOI 10.1016/0045-7949(94)00362-7
   Mikchevitch A, 2004, J COMPUT INF SCI ENG, V4, P114, DOI 10.1115/1.1736687
   Mikchevitch A, 2003, P DETC 03 ASME 2003
   MOBLEY AV, 1998, 7 INT MESH ROUNDT SA
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   Novint Technologies, 2007, NOV FALC 3D GAM CONT
   Pilkey W.D., 2002, ANAL DESIGN ELASTIC
   Rathod HT, 1998, J AUST MATH SOC B, V39, P355, DOI 10.1017/S0334270000009450
   Reissner E., 1985, APPL MECH REV, V38, P1453, DOI [10.1115/1.3143699, DOI 10.1115/1.3143699]
   RIBELLES J, 2001, 2001 ASME DES ENG TE
   Shames I. H., 1985, Energy and Finite Element Methods in Structural Mechanics
   Taylor RL, 2004, COMMUN NUMER METH EN, V20, P757, DOI 10.1002/cnm.652
   Wang CM, 2000, SHEAR DEFORMABLE BEA
   Wilson A, 1999, COMP GRAPH FOR P EUR
   Yang HTY, 2000, INT J NUMER METH ENG, V47, P101, DOI 10.1002/(SICI)1097-0207(20000110/30)47:1/3<101::AID-NME763>3.0.CO;2-C
   Zhao W., 2006, P 2006 ACM INT C VIR
   Zienkiewicz OC, 2005, FINITE ELEMENT METHOD FOR FLUID DYNAMICS, 6TH EDITION, P1
NR 35
TC 4
Z9 5
U1 0
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 3
EP 14
DI 10.1007/s10055-009-0143-0
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600002
DA 2024-07-18
ER

PT B
AU Koeda, M
   Matsuyama, M
   Sugihashi, M
   Yoshikawa, T
AF Koeda, Masanao
   Matsuyama, Mako
   Sugihashi, Munetaka
   Yoshikawa, Tsuneo
BE Kim, JJ
TI Handedness and Dexterity Evaluation System Using Haptic Virtual Reality
   Technology
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Koeda, Masanao; Matsuyama, Mako; Sugihashi, Munetaka; Yoshikawa, Tsuneo] Ritsumeikan Univ, Kyoto, Japan.
C3 Ritsumeikan University
RP Koeda, M (corresponding author), Ritsumeikan Univ, Kyoto, Japan.
CR [Anonymous], 1996, FORCE TOUCH FEEDBACK
   Bagesteiro LB, 2002, J NEUROPHYSIOL, V88, P2408, DOI 10.1152/jn.00901.2001
   Fujiwara N., 2003, J HLTH SCI HIROSHIMA, V2, P22
   Matsuda I., 2003, J PUBLISHED JAPANESE, V5, P40
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Wu J., 1996, T HUMAN INTERFACE SO, V11, P441
   Yoshikawa T, 1995, J DYN SYST-T ASME, V117, P554, DOI 10.1115/1.2801114
   Yoshikawa Tsuneo, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P298
   Yoshikawa T., 2000, P ASME DYN SYST CONT, P1191
NR 9
TC 0
Z9 0
U1 0
U2 5
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 203
EP 222
D2 10.5772/553
PG 20
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400011
DA 2024-07-18
ER

PT B
AU Szentágotai, A
   Opris, D
   David, D
AF Szentagotai, Aurora
   Opris, David
   David, Daniel
BE Kim, JJ
TI Virtual Reality in Evidence - Based Psychotherapy
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID COGNITIVE-BEHAVIORAL TREATMENT; EXPOSURE THERAPY; ANXIETY DISORDERS;
   ALLIANCE; ENVIRONMENTS; ADOLESCENTS; REHABILITATION; TECHNOLOGY;
   REACTIVITY; INTERVIEW
C1 [Szentagotai, Aurora; Opris, David; David, Daniel] Univ Babes Bolyai, R-3400 Cluj Napoca, Romania.
   [David, Daniel] Mt Sinai Sch Med, New York, NY USA.
C3 Babes Bolyai University from Cluj; Icahn School of Medicine at Mount
   Sinai
RP Szentágotai, A (corresponding author), Univ Babes Bolyai, R-3400 Cluj Napoca, Romania.
RI David, Daniel/N-1285-2014
CR Anderson P, 2004, J CLIN PSYCHOL, V60, P253, DOI 10.1002/jclp.10262
   [Anonymous], THERAPEUTIC PROGRAM
   [Anonymous], 1972, CLASSIFICATION NOMEN
   [Anonymous], 2006, HDB COGNITIVE BEHAV
   Anton R., 2009, J COGN BEHAV PSYCHOT, V9, P935
   Anton R, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P59, DOI 10.1109/ICVR.2009.5174206
   Antony MM, 2005, PSYCHOL ASSESSMENT, V17, P256, DOI 10.1037/1040-3590.17.3.256
   Apa Pesidential Task Force, 2006, AM PSYCHOL, V61, P271, DOI 10.1037/0003-066X.61.4.271
   Baren, 2002, CONT PEDIAT, V19, P124
   Barlow DH, 2004, AM PSYCHOL, V59, P869, DOI 10.1037/0003-066X.59.9.869
   Baumann SB, 2006, PSYCHOL ADDICT BEHAV, V20, P484, DOI 10.1037/0893-164X.20.4.484
   BORDIN ES, 1966, AM PSYCHOL, V21, P116, DOI 10.1037/h0023187
   Bordnick PS, 2009, J PSYCHOACTIVE DRUGS, V41, P105, DOI 10.1080/02791072.2009.10399903
   Brooks BM, 1999, NEUROPSYCHOL REHABIL, V9, P63, DOI 10.1080/713755589
   Bush J, 2008, COMPUT HUM BEHAV, V24, P1032, DOI 10.1016/j.chb.2007.03.006
   Butler AC, 2006, CLIN PSYCHOL REV, V26, P17, DOI 10.1016/j.cpr.2005.07.003
   Chaytor N, 2006, ARCH CLIN NEUROPSYCH, V21, P217, DOI 10.1016/j.acn.2005.12.002
   Christiansen C, 1998, ARCH PHYS MED REHAB, V79, P888, DOI 10.1016/S0003-9993(98)90083-1
   Chronis AM, 2006, CLIN PSYCHOL REV, V26, P486, DOI 10.1016/j.cpr.2006.01.002
   Chu BC, 2004, COGN BEHAV PRACT, V11, P44, DOI 10.1016/S1077-7229(04)80006-3
   Cobb S., 2002, Digital Creativity, V13, P11, DOI 10.1076/digc.13.1.11.3208
   Coelho CM, 2008, PSYCHNOLOGY J, V6, P203
   Coelho CM, 2009, J ANXIETY DISORD, V23, P563, DOI 10.1016/j.janxdis.2009.01.014
   Coelho CM, 2006, CYBERPSYCHOL BEHAV, V9, P336, DOI 10.1089/cpb.2006.9.336
   Creed TA, 2005, J CONSULT CLIN PSYCH, V73, P498, DOI 10.1037/0022-006X.73.3.498
   Culbertson C, 2010, PHARMACOL BIOCHEM BE, V96, P454, DOI 10.1016/j.pbb.2010.07.005
   da Costa RMEM, 2004, COMPUT METH PROG BIO, V73, P173, DOI 10.1016/S0169-2607(03)00066-X
   David D., CLIN PSYCHO IN PRESS
   David D, 2008, J CLIN PSYCHOL, V64, P728, DOI 10.1002/jclp.20487
   David D, 2006, CLIN PSYCHOL REV, V26, P284, DOI 10.1016/j.cpr.2005.09.003
   David D, 2010, J COGN BEHAV PSYCHOT, V10, P115
   Dreier O, 2008, LEARN DOING, P1
   Elliot T. R., 2004, ENCY COGNITIVE BEHAV, P324
   Ellis, 1962, Reason and emotion in psychotherapy, DOI DOI 10.1037//0003-066X.44.1.19
   Ellis A., 1962, REASON EMOTION PSYCH
   Elstein AS, 2002, BRIT MED J, V324, P729, DOI 10.1136/bmj.324.7339.729
   Fornells-Ambrojo M, 2008, SCHIZOPHR RES, V104, P228, DOI 10.1016/j.schres.2008.05.013
   Freeman A, 1998, INTERNATIONAL HANDBOOK OF COGNITIVE AND BEHAVIOURAL TREATMENTS FOR PSYCHOLOGICAL DISORDERS, P489, DOI 10.1016/B978-008043433-9/50018-3
   Goodheart C.D., 2006, EVIDENCE BASED PSYCH, P37, DOI DOI 10.1037/11423-002
   Hilsenroth MJ, 2007, PSYCHOTHERAPY, V44, P205, DOI 10.1037/0033-3204.44.2.205
   Hollon SD, 1998, CURR OPIN NEUROBIOL, V8, P289, DOI 10.1016/S0959-4388(98)80153-0
   Horvath AO, 2006, PSYCHOTHERAPY, V43, P258, DOI 10.1037/0033-3204.43.3.258
   HORVATH AO, 1991, J COUNS PSYCHOL, V38, P139, DOI 10.1037/0022-0167.38.2.139
   Horvath AO, 2001, PSYCHOTHERAPY, V38, P365, DOI 10.1037/0033-3204.38.4.365
   Huppert J.D., 2006, Evidence-based psychotherapy: Where practice and research meet, P131
   Josman N, 2008, INT J DISABIL HUM DE, V7, P49
   Josman N, 2009, SCHIZOPHR RES, V115, P270, DOI 10.1016/j.schres.2009.09.015
   Kopta SM, 1999, ANNU REV PSYCHOL, V50, P441, DOI 10.1146/annurev.psych.50.1.441
   Krijn M, 2007, CYBERPSYCHOL BEHAV, V10, P362, DOI 10.1089/cpb.2006.9943
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Kuntze MF, 2001, CYBERPSYCHOL BEHAV, V4, P497, DOI 10.1089/109493101750527051
   Lam YS, 2006, NEUROREHABILITATION, V21, P245
   Lambert M.J., 1992, Handbook of Psychotherapy Integration, P94
   Lambert M. J., 2004, BERGIN GARFIELDS HDB, V5, P139
   Lee JS, 2007, J BREAST CANCER, V10, P10, DOI 10.4048/jbc.2007.10.1.10
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   National Institute for Health and Clinical Excellence (NICE), REV TECHNOLOGY APPRA, V51
   Norcross JC, 2002, PROF PSYCHOL-RES PR, V33, P316, DOI 10.1037//0735-7028.33.3.316
   North M., 1994, Electronic Journal of Virtual Culture, V2, P37
   Parsons S, 2004, J AUTISM DEV DISORD, V34, P449, DOI 10.1023/B:JADD.0000037421.98517.8d
   Parsons S, 2002, J INTELL DISABIL RES, V46, P430, DOI 10.1046/j.1365-2788.2002.00425.x
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pearson J., 2008, CASE FORMULATION APP
   Peck D., 2007, Psychiatry, V6, P166
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Pugnetti L., 1998, Cyberpsychology Behavior, V1, P151, DOI [10.1089/CPB.1998.1.151, DOI 10.1089/CPB.1998.1.151]
   Riva G, 1999, J BEHAV THER EXP PSY, V30, P221, DOI 10.1016/S0005-7916(99)00018-X
   Riva G, 1998, COMPUT HUM BEHAV, V14, P477, DOI 10.1016/S0747-5632(98)00018-1
   Riva G, 2002, IEEE T INF TECHNOL B, V6, P224, DOI 10.1109/TITB.2002.802372
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rizzo A. A., 1998, CYBERPSYCHOL BEHAV, V1, P107
   Rizzo AA, 2006, CNS SPECTRUMS, V11, P35, DOI 10.1017/S1092852900024196
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Robbins MS, 2003, J FAM PSYCHOL, V17, P534, DOI 10.1037/0893-3200.17.4.534
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Rothbaum BO, 2000, J CONSULT CLIN PSYCH, V68, P1020, DOI 10.1037/0022-006X.68.6.1020
   Saladin ME, 2006, ADDICT BEHAV, V31, P1881, DOI 10.1016/j.addbeh.2006.01.004
   Schubiner H., 2002, ADOLESCENT HLTH CARE, P1124
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Sechrest L., 1998, Comprehensive clinical psychology: Vol. 4. Assessment, V4, P1
   Shirk SR, 2003, J CONSULT CLIN PSYCH, V71, P452, DOI 10.1037/0022-006X.71.3.452
   Sohlberg M.M., 2001, COGNITIVE REHABILITA
   Stinson K, 2010, J BEHAV THER EXP PSY, V41, P179, DOI 10.1016/j.jbtep.2009.12.003
   Tam SF, 2005, REHABIL PSYCHOL, V50, P285, DOI 10.1037/0090-5550.50.3.285
   Wampold BE, 2004, PROF PSYCHOL-RES PR, V35, P563, DOI 10.1037/0735-7028.35.6.563
   Waschbusch D.A., 2003, Science and pseudoscience in clinical psychology, P333, DOI DOI 10.1023/B:JOYO.0000025323.94929.D9
   WINDER CL, 1957, ANNU REV PSYCHOL, V8, P309, DOI 10.1146/annurev.ps.08.020157.001521
   Woolf SH, 2001, AM J PREV MED, V20, P13, DOI 10.1016/S0749-3797(01)00262-8
   Wright J. H., 2004, ENCY COGNITIVE BEHAV, P324
NR 90
TC 3
Z9 3
U1 0
U2 4
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 445
EP 468
D2 10.5772/553
PG 24
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400022
DA 2024-07-18
ER

PT J
AU Nordahl, R
   Korsgaard, D
AF Nordahl, Rolf
   Korsgaard, Dannie
TI Distraction as a measure of presence: using visual and tactile
   adjustable distraction as a measure to determine immersive presence of
   content in mediated environments
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Evaluation; Computer games; Visual; Tactile; Distraction;
   Measurement
ID AGE; RESPONSES; SEX
AB To assess and improve the user experience in entertainment products, developers need results of evaluation methods, which in detail measure the relationship between the mediated content and the resulting media experience. This paper proposes a method applying adjustable distraction (AD) to determine presence as immersion (Lombard and Ditton in At the heart of it all: the concept of presence, Department of Broadcasting, Telecommunications and Mass Media, Temple University, 1997) at selectable events (approximated real-time). Two experiments were conducted to investigate its applicability in computer games and movies with respectively visual and tactile AD. The first experiment examined whether the experienced intensity in a survival-shooter game, measured through questionnaires, was proportional to results from the AD method. The intrusiveness of the AD method was also addressed in the experiment by comparing the immersive presence ratings in a between-groups design. The second experiment investigated whether heart rate measurements, intensity ratings and the results of the AD method with vibration as the distraction signal were proportional when test participants watched a movie clip. The outcome of the first experiment indicated that no significant intrusion is caused by the method. In addition, results showed no proportionality between the AD method and intensity ratings. However, as the AD measurements were supported by flow theory, it might be that the results from the AD method using visual distraction are giving a more comprehensive indication of presence as immersion (rather than just the intensity dimension). The second experiment revealed proportionality between the intensity ratings and the heart rate measurements, while the results from the tactile AD method were not proportional. We suspect that this was caused by the great variance found across the test participants' thresholds of perceivable vibration. Because of this, it is suggested that a thorough screening process is conducted pre-test if the AD method should apply vibration as the distracting stimulus.
C1 [Nordahl, Rolf; Korsgaard, Dannie] Aalborg Univ, DK-2750 Ballerup, Denmark.
C3 Aalborg University
RP Nordahl, R (corresponding author), Aalborg Univ, Lautrupvang 15, DK-2750 Ballerup, Denmark.
EM rn@media.aau.dk
OI Nordahl, Rolf/0000-0002-9550-3529
CR [Anonymous], 2006, Fundamentals of Game Design
   Baren J.V., 2004, Measuring presence: A guide to current measurement approaches
   Bordwell D., 2004, FILM ART INTRO
   Brown E., 2004, 2004 C HUM FACT COMP
   BUCHSBAUM M, 1965, PERCEPT MOTOR SKILL, V20, P961, DOI 10.2466/pms.1965.20.3.961
   CAMERON P, 2002, J APPL SOC PSYCHOL, V32, P2458
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Dane S, 2003, INT J NEUROSCI, V113, P923, DOI 10.1080/00207450390220367
   Darken R P, 1999, Cyberpsychol Behav, V2, P337, DOI 10.1089/cpb.1999.2.337
   DELTORO G, 2006, SPANISH MOVIE EL LAB
   Der G, 2006, PSYCHOL AGING, V21, P62, DOI 10.1037/0882-7974.21.1.62
   ERMI L, 2005, P DIGRA C 2005
   Etnyre B, 2002, RES Q EXERCISE SPORT, V73, P271, DOI 10.1080/02701367.2002.10609020
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Jang DP, 2002, CYBERPSYCHOL BEHAV, V5, P11, DOI 10.1089/109493102753685845
   Klimmt C., 2005, P 8 INT WORKSH PRES
   LAARNI J, 2003, P 6 INT WORKSH PRES
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   LOMBARD MATTHEW., 1997, At the Heart of It All: The Concept of Presence
   Luchies CW, 2002, J GERONTOL A-BIOL, V57, pM246, DOI 10.1093/gerona/57.4.M246
   NORDAHL R, 2008, P 11 INT WORKSH PRES, P174
   Philip P, 2004, J SLEEP RES, V13, P105, DOI 10.1111/j.1365-2869.2004.00399.x
   REEVES B, 1992, MASS COMM DIV INT CO
   REEVES B, 1993, INF SYST DIV C INT C
   ROSE L, 2006, HOLLYWOODS MOST EXPE
   Rosmarin R., 2006, Why gears of war costs $60
   Schlogl A., 2002, P 5 INT WORKSHOP PRE
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   STEED A, 2005, P HCI INT 2005
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   TAN SH, 1995, POETICS, V23, P7
   VERRILLO RT, 1986, J ACOUST SOC AM, V80, P528, DOI 10.1121/1.394047
   VERRILLO RT, 1962, J ACOUST SOC AM, V34, P1768, DOI 10.1121/1.1909124
NR 35
TC 8
Z9 10
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 27
EP 42
DI 10.1007/s10055-009-0140-3
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400004
DA 2024-07-18
ER

PT J
AU Sourin, A
   Wei, L
AF Sourin, Alexei
   Wei, Lei
TI Visual immersive haptic mathematics
SO VIRTUAL REALITY
LA English
DT Article
DE Shape and surface modeling; Virtual reality; Physically based modeling;
   Shape modeling; Haptic collaboration; Shared virtual spaces; Electronic
   education
AB In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching subjects richly infused with mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that would allow for defining complex geometry, visual appearance and tangible physical properties of the virtual objects using language of mathematical functions. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept using our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted to tangible ones as well as augmented with function-defined visual appearances. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail.
C1 [Sourin, Alexei; Wei, Lei] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University
RP Sourin, A (corresponding author), Nanyang Technol Univ, Singapore, Singapore.
EM assourin@ntu.edu.sg; wei10004@ntu.edu.sg
RI Sourin, Alexei/A-3701-2011
OI Wei, Lei/0000-0001-8267-0283; Sourin, Alexei/0000-0003-4051-2927
FU Singapore National Research Foundation [NRF2008IDM-IDM004-002]
FX This work was supported by the Singapore National Research Foundation
   Interactive Digital Media R&D Program, under research Grant
   NRF2008IDM-IDM004-002 "Visual and Haptic Rendering in Co-Space''.
CR Alias M., 2002, International Education Journal, V3, P1
   Guimaraes LC, 2000, COMPUT APPL ENG EDUC, V8, P157, DOI 10.1002/1099-0542(2000)8:3/4<157::AID-CAE4>3.0.CO;2-9
   Kaufmann H, 2006, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VR.2006.48
   KUNIMUNE S, 1996, 8 INT C MATH ED
   Liu Q, 2006, VISUAL COMPUT, V22, P977, DOI 10.1007/s00371-006-0044-0
   Liu Q, 2006, COMPUT GRAPH-UK, V30, P629, DOI 10.1016/j.cag.2006.03.006
   *MIN ED SING, 2009, MATH SYLL PRIM
   Ministry of Education in Singapore, 2009, SEC MATH SYLL
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   Pasqualotti A, 2002, CYBERPSYCHOL BEHAV, V5, P409, DOI 10.1089/109493102761022832
   Scribner S., 2005, J IND TEACHER ED, V42, P38
   Song KS, 2002, J COMPUT ASSIST LEAR, V18, P149, DOI 10.1046/j.0266-4909.2001.00222.x
   SOURIN A, 2008, 7 ACM SIGGRAPH INT C
   *TSG 16, 2004, 10 INT C MATH ED 4 1
   *TSG 20, 2008, 11 INT C MATH ED 6 1
   Wei L, 2008, VISUAL COMPUT, V24, P871, DOI 10.1007/s00371-008-0285-1
   Wei LL, 2009, PROCEEDINGS OF THE 2009 SECOND PACIFIC-ASIA CONFERENCE ON WEB MINING AND WEB-BASED APPLICATION, P15, DOI 10.1109/WMWA.2009.56
   Yeh A, 2004, P WORLD C ED MULT HY
NR 18
TC 11
Z9 12
U1 0
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2009
VL 13
IS 4
SI SI
BP 221
EP 234
DI 10.1007/s10055-009-0133-2
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XF
UT WOS:000208104400002
DA 2024-07-18
ER

PT J
AU Martino, F
   Baù, R
   Spagnolli, A
   Gamberini, L
AF Martino, Francesco
   Bau, Roberto
   Spagnolli, Anna
   Gamberini, Luciano
TI Presence in the age of social networks: augmenting mediated environments
   with feedback on group activity
SO VIRTUAL REALITY
LA English
DT Article
DE Social network analysis; Feedback; Social presence; Behavioral
   engagement; Multiplayer game; Augmented communication
ID PERFORMANCE; COMMUNITY
AB The present study aimed at increasing behavioral engagement in groups of networked people by providing feedback on the group activity. Each participant logged into an on-line virtual environment for four subsequent treasure-hunting sessions along with other nine players. During the game, all players communicated dyadically through textual chats, and searched for the treasures in the virtual environment. In two conditions, the participants received a visual feedback depicting the communication activity with the group based on social network analysis indices (i.e. 'centrality' or 'reciprocity'). Feedback was not provided in the third condition. The underlying assumption was that if the group activity becomes more visible to the individual user through the feedback, then the behavioral engagement with the group increases. The resulting behavioral engagement was measured with two techniques, one based on the amount of messages exchanged and one based on self-reported measures. The results show that feedback improved the exchange of messages with respect to the control condition and that this effect was only partially captured by self-reported measures.
C1 [Martino, Francesco; Bau, Roberto; Spagnolli, Anna; Gamberini, Luciano] Univ Padua, Dept Gen Psychol, Human Technol Lab, Padua, Italy.
C3 University of Padua
RP Gamberini, L (corresponding author), Univ Padua, Dept Gen Psychol, Human Technol Lab, Padua, Italy.
EM luciano.gamberini@gmail.com
RI Spagnolli, Anna/D-1868-2014
FU PASION project (Psychologically Augmented Social Interaction over
   Networks EU IST program) [27654 PASION]
FX The study reported here is partially funded by the PASION project
   (Psychologically Augmented Social Interaction over Networks, reference
   number 27654 PASION, EU IST program).
CR Adamic L, 2005, SOC NETWORKS, V27, P187, DOI 10.1016/j.socnet.2005.01.007
   [Anonymous], 2005, Educational and Psychological Measurement, DOI DOI 10.1177/0013164405278558
   [Anonymous], P 38 HAW INT C SYST
   [Anonymous], P 35 ANN HAW INT C S
   ARMINEN I, 2008, P 11 ANN INT PRES
   BANDURA A, 1978, J COMMUN, V28, P12, DOI 10.1111/j.1460-2466.1978.tb01621.x
   Bender-deMoll S, 2006, J SOC STRUCT, V7
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   BIOCCA F, 2001, P 4 ANN WORKSH PRES
   BORGATTI SP, 2001, UCINET WINDOWS SOFTW
   Brahnam S, 2009, PSYCHNOLOGY J, V7, P9
   Brugnoli MC, 2006, PSYCHNOLOGY J, V4, P103
   Carley KM, 2003, DYNAMIC SOCIAL NETWORK MODELING AND ANALYSIS, P133
   Carver C. S., 1981, ATTENTION SELF REGUL
   Castro LA, 2008, PSYCHNOLOGY J, V6, P61
   Cross R, 2002, CALIF MANAGE REV, V44, P25, DOI 10.2307/41166121
   De Angeli A, 2009, PSYCHNOLOGY J, V7, P49
   DiMicco J. M., 2007, P 2 INT C PERS TECHN
   Freeman L.C., 2000, J SOC STRUCT, V1
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Gamberini L, 2007, LECT NOTES COMPUT SC, V4564, P334
   Hayes AF, 2006, HUM COMMUN RES, V32, P385, DOI 10.1111/j.1468-2958.2006.00281.x
   HEER J, 2005, IEEE S INF VIS
   Holmes J, 1999, LANG SOC, V28, P173, DOI 10.1017/S004740459900202X
   ILGEN DR, 1979, J APPL PSYCHOL, V64, P349, DOI 10.1037/0021-9010.64.4.349
   Katz L, 1955, SOCIOMETRY, V18, P403, DOI 10.2307/2785876
   Kenny DA, 2002, J PERS SOC PSYCHOL, V83, P126, DOI 10.1037/0022-3514.83.1.126
   Kerr NL, 2005, GROUP PROCESS INTERG, V8, P375, DOI 10.1177/1368430205056466
   Kluger AN, 1996, PSYCHOL BULL, V119, P254, DOI 10.1037/0033-2909.119.2.254
   Kossinets G, 2006, SCIENCE, V311, P88, DOI 10.1126/science.1116869
   LICOPPE C, 2006, DOMESTICATING INFORM, P296
   Locke A., 1990, THEORY GOAL SETTING
   Martino F, 2006, PSYCHNOLOGY J, V4, P53
   Morris ME, 2005, IEEE INTERNET COMPUT, V9, P29, DOI 10.1109/MIC.2005.109
   MURREL S, 1983, P ACM SIGCHI C HUM F
   Pandolfo Anna, 2004, P ACM C COMP SUPP CO
   Paolillo J.C., 2001, Journal of Sociolinguistics, V5, P180, DOI DOI 10.1111/1467-9481.00147
   Quené H, 2004, SPEECH COMMUN, V43, P103, DOI 10.1016/j.specom 2004.02.004
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   SCHROEDER R, 2006, PRESENCE, V14, P438
   Short J., 1976, The social psychology of telecommunications
   Snijder T., 1999, MULTILEVEL ANAL
   Southwell BG, 2004, AM BEHAV SCI, V48, P391, DOI 10.1177/0002764204270277
   Spagnolli A., 2008, P 11 ANN INT WORKSH, P107
   Spagnolli A, 2007, BRIT J SOC PSYCHOL, V46, P343, DOI 10.1348/014466606X120482
   Spagnolli A, 2005, PSYCHNOLOGY J, V3, P6
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   Wellman B, 2001, SCIENCE, V293, P2031, DOI 10.1126/science.1065547
   YATES J, 2002, P 36 HAW INT C SYST
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
   Zumbach J, 2005, CSCL 2005: COMPUTER SUPPORTED COLLABORATIVE LEARNING 2005: THE NEXT 10 YEARS, PROCEEDINGS, P758
NR 53
TC 8
Z9 11
U1 0
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 183
EP 194
DI 10.1007/s10055-009-0125-2
PN 1
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300006
DA 2024-07-18
ER

PT J
AU Howard, MC
   Davis, MM
AF Howard, Matt C. C.
   Davis, Maggie M. M.
TI A Meta-analysis of augmented reality programs for education and training
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Mixed reality; Education; Training; Learning;
   Meta-analysis
ID RANDOM-EFFECTS MODELS; MIXED REALITY; FLUID INTELLIGENCE;
   VIRTUAL-REALITY; WORKING-MEMORY; POKEMON GO; GAMIFICATION; HOLOLENS;
   TAXONOMY; RECOGNITION
AB The application of augmented reality (AR) for education and training has grown dramatically in recent years, resulting in an expansive research domain within a relatively short amount of time. Two primary goals of the current article are to (a) summarize this literature by determining the overall effectiveness of AR programs relative to alternative comparisons and (b) assess the extent that AR program effectiveness is influenced by aspects of hardware, software, outcome, context, and methodology. A meta-analysis of over 250 studies supports that AR programs produce learning outcomes that are, on average, three-fifths of a standard deviation larger than alternative comparisons. Our results surprisingly show that AR programs using head-mounted displays produce significantly smaller effects than those using other output hardware (e.g., smartphones and tablets), and programs using image recognition are no more effective than those using alternative input methods (e.g., QR codes). We further find that most other aspects do not significantly influence observed program effectiveness; however, studies with younger participants produced significantly larger effects, and naturalistic studies produced significantly larger effects than laboratory studies. In our discussion, we utilize these findings to suggest promising theoretical perspectives for the study of AR, and we highlight methodological practices that can produce more accurate research moving forward. Thus, the current article summarizes research on AR education and training programs, identifies aspects that do and do not influence program efficacy, and provides several avenues for future research and practice.
C1 [Howard, Matt C. C.] Univ S Alabama, Mitchell Coll Business, Mobile, AL 36688 USA.
   [Davis, Maggie M. M.] Univ West Florida, Coll Business, Pensacola, FL USA.
C3 University of South Alabama; State University System of Florida;
   University of West Florida
RP Howard, MC (corresponding author), Univ S Alabama, Mitchell Coll Business, Mobile, AL 36688 USA.
EM MHoward@SouthAlabama.edu
RI Davis, Maggie/JCO-0245-2023
OI Davis, Maggie/0000-0002-4365-0981
CR Albert A, 2014, J CONSTR ENG M, V140, DOI 10.1061/(ASCE)CO.1943-7862.0000860
   Aromaa S, 2020, APPL ERGON, V88, DOI 10.1016/j.apergo.2020.103145
   Au J, 2015, PSYCHON B REV, V22, P366, DOI 10.3758/s13423-014-0699-x
   Aydogdu F, 2022, BRIT J EDUC TECHNOL, V53, P326, DOI 10.1111/bjet.13168
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baker J, 2015, ROUT INT HANDB, P145
   Baragash RS, 2020, EUR J SPEC NEEDS EDU, V35, P382, DOI 10.1080/08856257.2019.1703548
   Barmaki R, 2019, ANAT SCI EDUC, V12, P599, DOI 10.1002/ase.1858
   Bedwell WL, 2012, SIMULAT GAMING, V43, P729, DOI 10.1177/1046878112439444
   Bell E., 2022, Business research methods
   Bhandari S, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001755
   Bölek KA, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94721-4
   Borenstein M, 2010, RES SYNTH METHODS, V1, P97, DOI 10.1002/jrsm.12
   Borsci S, 2015, COMPUT IND, V67, P17, DOI 10.1016/j.compind.2014.12.002
   Boxer P, 2015, PERSPECT PSYCHOL SCI, V10, P671, DOI 10.1177/1745691615592239
   Buchner J, 2022, J COMPUT ASSIST LEAR, V38, P285, DOI 10.1111/jcal.12617
   Buchner J, 2021, COMPUT EDUC OPEN, V2, DOI 10.1016/j.caeo.2021.100036
   Cai ZH, 2017, COMPUT EDUC, V105, P1, DOI 10.1016/j.compedu.2016.11.003
   Cifuentes SC, 2016, IEEE INT CONF ADV LE, P431, DOI 10.1109/ICALT.2016.23
   Challenor J, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020039
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Cheng LJ, 2020, AIDS BEHAV, V24, P1663, DOI 10.1007/s10461-019-02691-6
   Cheng QY, 2020, IEEE ACCESS, V8, P137370, DOI 10.1109/ACCESS.2020.3012130
   Cheung MWL, 2015, Meta-Analysis: A Structural Equation Modeling Approach, P1, DOI 10.1002/9781118957813
   COHEN NJ, 1985, ANN NY ACAD SCI, V444, P54, DOI 10.1111/j.1749-6632.1985.tb37579.x
   Dalton DR, 2012, PERS PSYCHOL, V65, P221, DOI 10.1111/j.1744-6570.2012.01243.x
   Das P., 2017, Multimodal Technologies and Interaction, V1, P8, DOI [DOI 10.3390/MTI1020008, 10.3390/mti1020008]
   Ferguson CJ, 2015, PERSPECT PSYCHOL SCI, V10, P646, DOI 10.1177/1745691615592234
   Foo CC, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-02575-1
   Garzón J, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5070037
   Garzón J, 2020, EDUC RES REV-NETH, V31, DOI 10.1016/j.edurev.2020.100334
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Garzón J, 2019, EDUC RES REV-NETH, V27, P244, DOI 10.1016/j.edurev.2019.04.001
   Gavish N., 2011, BIOWEB C 2011, P00029, DOI 10.1051/bioconf/20110100029
   Gavish N, 2019, SYSTEMS ENG 4 IND RE, P191, DOI DOI 10.1002/9781119513957.CH8
   Gerup J, 2020, INT J MED EDUC, V11, DOI 10.5116/ijme.5e01.eb1a
   Goh GS, 2021, ARCH ORTHOP TRAUM SU, V141, P2303, DOI 10.1007/s00402-021-04037-1
   Gonzalez DAZ, 2021, INT J HUM-COMPUT ST, V147, DOI 10.1016/j.ijhcs.2020.102579
   GOODHUE DL, 1995, MIS QUART, V19, P213, DOI 10.2307/249689
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Gray JR, 2003, NAT NEUROSCI, V6, P316, DOI 10.1038/nn1014
   Greene JA, 2022, COMPUT EDUC, V177, DOI 10.1016/j.compedu.2021.104362
   Gu WH, 2021, COMP M BIO BIO E-IV, V9, P261, DOI 10.1080/21681163.2020.1835556
   Guinet AL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082697
   Hair J., 2020, Essentials of Business Research Methods. Essentials of Business Research Methods, DOI [DOI 10.4324/9781315716862, 10.4324/9780429203374, DOI 10.4324/9780429203374]
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Harrison TL, 2013, PSYCHOL SCI, V24, P2409, DOI 10.1177/0956797613492984
   Hedges LV, 1998, PSYCHOL METHODS, V3, P486, DOI 10.1037/1082-989X.3.4.486
   Higgins J, 2021, Cochrane Handbook for Systematic Reviews of Interventions version 6.3
   Howard MC, 2022, COMPUT HUM BEHAV, V130, DOI 10.1016/j.chb.2022.107197
   Howard MC, 2021, COMPUT HUM BEHAV, V121, DOI 10.1016/j.chb.2021.106808
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Howard MC, 2020, HUM RESOUR DEV Q, V31, P13, DOI 10.1002/hrdq.21378
   Howard MC, 2019, INFORM MANAGE-AMSTER, V56, DOI 10.1016/j.im.2018.12.002
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   Ibili E, 2020, INT J MATH EDUC SCI, V51, P224, DOI 10.1080/0020739X.2019.1583382
   Innocente C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094295
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Ivan ME, 2021, NEUROSURG FOCUS, V51, DOI 10.3171/2021.5.FOCUS20735
   Jak Suzanne., 2015, META ANAL STRUCTURAL, P1, DOI DOI 10.1007/978-3-319-27174-3_1
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kaufeld M, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102283
   Khamzina M, 2020, AM J PREV MED, V58, P270, DOI 10.1016/j.amepre.2019.09.005
   Kirkpatrick D, 1996, TRAINING DEV, V50, P54
   Kolb DA, 2001, EDUC PSYCHO, P227
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Kozlowski S.W. J., 2004, SCALED WORLDS DEV VA, P75
   Lampropoulos G, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136809
   Landers RN, 2018, SIMULAT GAMING, V49, P315, DOI 10.1177/1046878118774385
   Lauer L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196623
   Le YY, 2021, COMPUT EDUC, V174, DOI 10.1016/j.compedu.2021.104311
   Lee IJ, 2016, COMPUT HUM BEHAV, V65, P488, DOI 10.1016/j.chb.2016.09.014
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Liu D., 2009, HUMAN FACTORS SIMULA, P61, DOI [DOI 10.1201/9781420072846.CH4, 10.1201/9781420072846.ch4]
   Liu ZD, 2020, 2020 19TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2020), P301, DOI 10.1109/IPSN48710.2020.00-26
   Mao CC, 2021, INT J HUM-COMPUT INT, V37, P1899, DOI 10.1080/10447318.2021.1917865
   Marek MW, 2021, INT J DIST EDUC, V19, P40, DOI 10.4018/IJDET.20210101.oa3
   MarketsandMarkets, 2022, AUGM VIRT REAL ED MA
   Mesmer-Magnus J, 2010, HUM RESOUR MANAGE R, V20, P261, DOI 10.1016/j.hrmr.2010.05.001
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milman N.B., 2018, DISTANCE LEARNING, V15, P55
   Moesl B, 2021, AVIAT PSYCHOL APPL H
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moorhouse N, 2019, MUS MANAGE CURATOR, V34, P402, DOI 10.1080/09647775.2019.1578991
   Moreno R, 2006, J COMPUT ASSIST LEAR, V22, P149, DOI 10.1111/j.1365-2729.2006.00170.x
   Morice AHP, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255779
   Moro C, 2021, ANAT SCI EDUC, V14, P368, DOI 10.1002/ase.2049
   Mubin Omar, 2019, JMIR Rehabil Assist Technol, V6, pe12010, DOI 10.2196/12010
   Newbutt N, 2020, CYBERPSYCH BEH SOC N, V23, P23, DOI 10.1089/cyber.2019.0206
   Noll C, 2017, JMIR MHEALTH UHEALTH, V5, DOI 10.2196/mhealth.7943
   Noreikis M, 2019, IEEE ACCESS, V7, P148108, DOI 10.1109/ACCESS.2019.2945819
   Ozdemir M, 2018, EURASIAN J EDUC RES, P165, DOI 10.14689/ejer.2018.74.9
   Page MJ, 2021, INT J SURG, V88, DOI [10.1016/j.ijsu.2021.105906, 10.1016/j.jclinepi.2021.02.003, 10.1186/s13643-021-01626-4]
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Patall EA, 2008, PSYCHOL BULL, V134, P270, DOI 10.1037/0033-2909.134.2.270
   Pettijohn KA, 2020, APPL ERGON, V89, DOI 10.1016/j.apergo.2020.103200
   Plass J.L., 2015, Emotions, Technology, Design, and Learning, P131, DOI DOI 10.1016/B978-0-12-801856-9.00007-4
   Rese A, 2017, TECHNOL FORECAST SOC, V124, P306, DOI 10.1016/j.techfore.2016.10.010
   Rokhsaritalemi S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020636
   Rosen Yigal, 2007, Journal of Educational Computing Research, V36, P1, DOI 10.2190/R8M4-7762-282U-554J
   Rourke Liam, 2010, Int J Nurs Educ Scholarsh, V7, pArticle11, DOI 10.2202/1548-923X.1965
   Ruiz-Ariza A, 2018, COMPUT EDUC, V116, P49, DOI 10.1016/j.compedu.2017.09.002
   Santos Marc Ericson C, 2016, Res Pract Technol Enhanc Learn, V11, P4, DOI 10.1186/s41039-016-0028-2
   Schnepel S, 2022, EUR J SPEC NEEDS EDU, V37, P663, DOI 10.1080/08856257.2021.1943268
   Vergel RS, 2020, IEEE T HUM-MACH SYST, V50, P337, DOI 10.1109/THMS.2020.2984746
   Spellman BA, 2012, PERSPECT PSYCHOL SCI, V7, P58, DOI 10.1177/1745691611432124
   Sternberg RJ, 2008, P NATL ACAD SCI USA, V105, P6791, DOI 10.1073/pnas.0803396105
   Stevens J, 2015, J DEF MODEL SIMUL-AP, V12, P519, DOI 10.1177/1548512915569742
   Stretton T, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2131
   Sundararajan N, 2020, EDUC PSYCHOL REV, V32, P707, DOI 10.1007/s10648-020-09522-4
   Suresh D, 2023, SURG INNOV, V30, P366, DOI 10.1177/15533506221140506
   Tekedere H., 2016, International Journal of Environmental Science Education, V11, P9469
   ten Berge T, 1999, THEOR PSYCHOL, V9, P605, DOI 10.1177/0959354399095002
   Tepper OM, 2017, PLAST RECONSTR SURG, V140, P1066, DOI 10.1097/PRS.0000000000003802
   Tuli Neha, 2022, International Journal of Computer Aided Engineering and Technology, P164, DOI 10.1504/IJCAET.2022.125048
   Uttl B, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001568
   van der Kooij K, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00294
   Vellingiri S, 2022, MULTIMED TOOLS APPL, P1
   Viechtbauer W, 2010, RES SYNTH METHODS, V1, P112, DOI 10.1002/jrsm.11
   Viglialoro RM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052338
   Wang XY, 2007, J INF TECHNOL CONSTR, V12, P363
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Xiao M., 2020, Virtual Reality & Intelligent Hardware, V2, P291
   Xu WP, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-021-00862-2
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yu HY, 2019, WORLD NEUROSURG, V129, pE767, DOI 10.1016/j.wneu.2019.06.020
   Yunqiang Chen, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022082
   Zackoff MW, 2021, SIMUL HEALTHC, V16, P221, DOI 10.1097/SIH.0000000000000486
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhou ZY, 2019, VIRTUAL REAL-LONDON, V23, P347, DOI 10.1007/s10055-018-0350-7
NR 130
TC 1
Z9 1
U1 10
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2871
EP 2894
DI 10.1007/s10055-023-00844-6
EA AUG 2023
PG 24
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001049159700001
DA 2024-07-18
ER

PT J
AU Mahroo, A
   Greci, L
   Mondellini, M
   Sacco, M
AF Mahroo, Atieh
   Greci, Luca
   Mondellini, Marta
   Sacco, Marco
TI Assessment of a mixed reality smart home controller: HoloHome pilot
   study on healthy adults
SO VIRTUAL REALITY
LA English
DT Article
DE Aging; Assistive technology; Internet of things; Microsoft HoloLens;
   Mixed reality; Smart home
ID AUGMENTED REALITY; INTERNET; THINGS; TECHNOLOGY; IOT
AB This work presents HoloHome, a Mixed Reality application that aims to provide a new means of interaction to control the Smart Home components while providing continuous support for the inhabitants, including older adults and people with limited mobility and cognitive skills. HoloHome integrates several technological paradigms such as Mixed Reality, Internet of Things, and Ambient Assisted Living to maximize the tailored domestic comfort for the Smart Home's inhabitants while promoting their comfort, safety, and independence in performing daily activities. It is designed and implemented on Microsoft HoloLens, ensuring the connection of the Mixed Reality environment with the distributed network of domestic sensors through the WiFi-enabled microcontrollers to present an innovative method of interaction with the Smart Home and IoT network. Additionally, HoloHome provides unique services and assistive technologies mainly designed for older adults and people with short-term memory deficits to provide continuous assistance, support, and instruction for household activities. This paper conducts the assessment of HoloHome, where the proposed system's usability, cybersickness, and effectiveness are investigated. The usability of HoloHome is validated on a sample of healthy adults to highlight desirable modifications before further assessments of older adults and people with disabilities. This pilot study demonstrated a good level of perceived usability (71.5%) among healthy adults, leading toward the best possible adjustments prior to proposing the system to the more fragile users.
C1 [Mahroo, Atieh; Mondellini, Marta; Sacco, Marco] Inst Intelligent Ind Technol & Syst Adv Mfg, Natl Res Council, Lecce, Italy.
   [Mahroo, Atieh] Univ Milano Bicocca, Dept Informat Syst & Commun, Milan, Italy.
   [Greci, Luca] Inst Intelligent Ind Technol & Syst Adv Mfg, Natl Res Council, Milan, Italy.
   [Mondellini, Marta] Univ Cattolica Sacro Cuore, Dept Psychol, Milan, Italy.
C3 University of Milano-Bicocca; Catholic University of the Sacred Heart
RP Mahroo, A (corresponding author), Inst Intelligent Ind Technol & Syst Adv Mfg, Natl Res Council, Lecce, Italy.; Mahroo, A (corresponding author), Univ Milano Bicocca, Dept Informat Syst & Commun, Milan, Italy.
EM atieh.mahroo@stiima.cnr.it; luca.greci@stiima.cnr.it;
   marta.mondellini@stiima.cnr.it; marco.sacco@stiima.cnr.it
OI Mahroo, Atieh/0000-0002-2962-3661
FU Convenzione Operativa [19365/RCC]
FX This work was supported by "Convenzione Operativa No. 19365/RCC" in the
   framework of the project "Future Home for Future Communities"
   (http://www.fhffc.it/).
CR Alce G, 2019, LECT NOTES COMPUT SC, V11749, P267, DOI 10.1007/978-3-030-29390-1_15
   Alce G, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P81, DOI 10.1109/ISMAR-Adjunct.2017.37
   Alce G, 2014, PROCEDIA COMPUT SCI, V39, P35, DOI 10.1016/j.procs.2014.11.007
   [Anonymous], 2019, FUTURE HOME FUTURE C
   Arduino, 2023, ARD
   Arduino, 2023, ARD WIFI SHIELD
   Arduino, 2023, ARD IDE
   Ashton K., RFID journal, V22 22, P97, DOI DOI 10.1145/2967977
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baader R, 2005, LECT NOTES ARTIF INT, V2605, P228
   Blanco-Novoa O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113328
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chen L, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P123, DOI 10.1109/ISMAR.2017.29
   Cook A.M., 2014, Assistive Technologies: Principles and Practice
   Cook DJ, 2009, PERVASIVE MOB COMPUT, V5, P277, DOI 10.1016/j.pmcj.2009.04.001
   Croatti A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE WORKSHOPS (ICSAW), P80, DOI 10.1109/ICSAW.2017.49
   Czaja Sara J., 2019, Designing for older adults: Principles and creative human factors approaches, VThird, DOI DOI 10.1201/B22189
   de Belen Ryan Anthony J., 2019, Human Aspects of IT for the Aged Population. Social Media, Games and Assistive Environments. 5th International Conference, ITAP 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11593), P291, DOI 10.1007/978-3-030-22015-0_23
   de Belen R. A. J., 2019, AIMS ELECT ELECT ENG, V3, P181, DOI [DOI 10.3934/ELECTRENG.2019.2.181, 10.3934/electreng.2019.2.181]
   de Belen RAJ, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365742
   de Belen RAJ, 2019, IEEE INT CONF INF VI, P82, DOI 10.1109/IV-2.2019.00025
   De Silva LC, 2012, ENG APPL ARTIF INTEL, V25, P1313, DOI 10.1016/j.engappai.2012.05.002
   Dohr A., 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P804, DOI 10.1109/ITNG.2010.104
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Eseosa O., 2014, INT J ENG TECHNOL, V4, P595
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Gamberini L, 2006, PSYCHNOLOGY J, V4, P285
   Giusto D., 2010, The internet of things: 20th Tyrrhenian workshop on digital communications, DOI DOI 10.1007/978-1-4419-1674-7
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Harper R., 2006, INSIDE SMART HOME
   Jang J., 2018, ACM SIGGRAPH 2018 Appy Hour, P1
   Jo D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194330
   Jo D, 2016, IEEE T CONSUM ELECTR, V62, P334, DOI 10.1109/TCE.2016.7613201
   Kagermann H., 2013, Final report of the Industrie 4.0 Working Group
   KATZ S, 1983, J AM GERIATR SOC, V31, P721, DOI 10.1111/j.1532-5415.1983.tb03391.x
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lee S, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311869
   Leo M, 2017, COMPUT VIS IMAGE UND, V154, P1, DOI 10.1016/j.cviu.2016.09.001
   Lewis C., 1993, TASK CENTERED USER I
   Liu Y, 2018, IEEE MULTIMEDIA, V25, P8, DOI 10.1109/MMUL.2018.2873473
   Mahroo Atieh, 2018, 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P543, DOI 10.1109/PERCOMW.2018.8480414
   Mahroo A, 2019, LECT NOTES COMPUT SC, V11614, P137, DOI 10.1007/978-3-030-25999-0_12
   Malche T, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P65, DOI 10.1109/I-SMAC.2017.8058258
   Microsoft, 2023, MICR HOLOLENS 1 GEN
   Microsoft, 2023, MICR MIX REAL TOOLK
   Microsoft, 2023, UN WIND PLATF DOC
   Microsoft, 2023, HOLOLENS 2
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Min Li, 2018, Procedia Computer Science, V131, P393, DOI 10.1016/j.procs.2018.04.219
   Moosburner S, 2019, ARTIF ORGANS, V43, P694, DOI 10.1111/aor.13396
   Moser T, 2019, LECT NOTES BUS INF P, V338, P95, DOI 10.1007/978-3-030-05767-1_7
   Munsinger B, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI [10.1145/3359996.3364274, 10.1109/vs-games.2019.8864548]
   Nations U, 2020, WORLD POP AG 2020 HI
   Nielsen J., 2012, MANY TEST USERS USAB
   Paez D., 2019, INVERSE
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Park T, 2018, GETMOBILE-MOB COMPU, V22, P10, DOI 10.1145/3229316.3229320
   Pramod Dhanya, 2023, Science & Technology Libraries, V42, P85, DOI 10.1080/0194262X.2021.2024481
   Quint F, 2015, PROCEDIA COMPUT SCI, V75, P43, DOI 10.1016/j.procs.2015.12.199
   Rashid Omer., 2006, COMPUTERS ENTERTAINM, V4, P4
   Rashid Z, 2017, FUTURE GENER COMP SY, V76, P248, DOI 10.1016/j.future.2016.11.030
   Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129
   Rodriguez L, 2015, PROCEDIA COMPUT SCI, V75, P327, DOI 10.1016/j.procs.2015.12.254
   Rosala M., 2020, Task analysis: support users in achieving their goals
   Sahija D, 2022, CRITICAL REV MIXED R, P10
   Sand Oliver, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P643, DOI 10.1007/978-3-319-39907-2_61
   Sauro J., 2018, MEASURINGU
   Shao YY, 2019, PROCEDIA COMPUT SCI, V155, P433, DOI 10.1016/j.procs.2019.08.060
   Sicari S, 2015, COMPUT NETW, V76, P146, DOI 10.1016/j.comnet.2014.11.008
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Spoladore D, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/3185481
   Stapleton C, 2002, COMPUTER, V35, P122, DOI 10.1109/MC.2002.1106186
   Unity, 2023, UN 3D
   van Heek Julia, 2017, P HUMAN ASPECTS IT A, P38, DOI DOI 10.1007/978-3-319-58530-7_4
   Viglialoro RM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052338
   Vuforia, 2023, VUF ENG LIB
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Weber Rolf H., 2010, Computer Law and Security Report, V26, P23, DOI 10.1016/j.clsr.2009.11.008
   Wexelblat A, 1993, VIRTUAL REALITY APPL, P23
   Wilson C, 2017, ENERG POLICY, V103, P72, DOI 10.1016/j.enpol.2016.12.047
   Woolley Benjamin., 1993, Virtual Worlds: A Journey in Hype and Hyperreality
NR 82
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2673
EP 2690
DI 10.1007/s10055-023-00834-8
EA JUL 2023
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001034487100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, X
   Chen, HX
   He, SD
   Chen, XR
   Dong, S
   Yan, P
   Fang, B
AF Li, Xuan
   Chen, Hengxin
   He, Shengdong
   Chen, Xinrun
   Dong, Shuang
   Yan, Ping
   Fang, Bin
TI Action recognition based on multimode fusion for VR online platform
SO VIRTUAL REALITY
LA English
DT Article
DE Data augmentation; Action recognition; Virtual reality online platform;
   Remote education
ID VIRTUAL-REALITY
AB The current popular online communication platforms can convey information only in the form of text, voice, pictures, and other electronic means. The richness and reliability of information is not comparable to traditional face-to-face communication. The use of virtual reality (VR) technology for online communication is a viable alternative to face-to-face communication. In the current VR online communication platform, users are in a virtual world in the form of avatars, which can achieve "face-to-face" communication to a certain extent. However, the actions of the avatar do not follow the user, which makes the communication process less realistic. Decision-makers need to make decisions based on the behavior of VR users, but there are no effective methods for action data collection in VR environments. In our work, three modalities of nine actions from VR users are collected using a virtual reality head-mounted display (VR HMD) built-in sensors, RGB cameras and human pose estimation. Using these data and advanced multimodal fusion action recognition networks, we obtained a high accuracy action recognition model. In addition, we take advantage of the VR HMD to collect 3D position data and design a 2D key point augmentation scheme for VR users. Using the augmented 2D key point data and VR HMD sensor data, we can train action recognition models with high accuracy and strong stability. In data collection and experimental work, we focus our research on classroom scenes, and the results can be extended to other scenes.
C1 [Li, Xuan; Chen, Hengxin; He, Shengdong; Chen, Xinrun; Dong, Shuang; Yan, Ping; Fang, Bin] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Chen, HX (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM lixuan2019@cqu.edu.cn; chenhengxin@cqu.edu.cn
FU Fundamental Research Funds for the Central Universities [2019CDYGZD004];
   National Natural Science Foundation of China (NSFC) [61876026]
FX This research was funding by the Fundamental Research Funds for the
   Central Universities 2019CDYGZD004 and the National Natural Science
   Foundation of China(NSFC) 61876026.
CR Abdel-Salam R, 2021, ARXIV
   Ahmad Z, 2020, IEEE SENS J, V20, P1445, DOI 10.1109/JSEN.2019.2947446
   Baumann C, 2016, INT J EDUC MANAG, V30, P1003, DOI 10.1108/IJEM-09-2015-0118
   Cain T, 2011, INT J RES METHOD EDU, V34, P3, DOI 10.1080/1743727X.2011.552307
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen XR, 2021, COMPUT APPL ENG EDUC, V29, P1702, DOI 10.1002/cae.22418
   Contributors M., 2020, OpenMMLab's Next Generation Video Understanding Toolbox and Benchmark
   Dong M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051656
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan H., 2021, arXiv
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Garcia NC, 2019, ARXIV
   Hssayeni M. D., 2017, Electronic Imaging, V2017, P20, DOI 10.imawm-162
   Islam MM, 2022, INT C INTELLIGENT RO
   Jauhiainen JS, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13073802
   Jing C, 2020, NEURAL COMPUT APPL, V32, P4293, DOI 10.1007/s00521-019-04615-w
   Jun HS, 2022, IEEE T AFFECT COMPUT, V13, P1416, DOI 10.1109/TAFFC.2020.3004617
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim S, 2019, IEEE WINT CONF APPL, P61, DOI 10.1109/WACV.2019.00014
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lalioti V, 1998, P ACM S VIRT REAL SO, P205
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Losilla F, 2019, ICSOFT: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON SOFTWARE TECHNOLOGIES, P643, DOI 10.5220/0007798906430648
   Mahmud S, 2020, ARXIV
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   Memmesheimer R, 2021, INT C PATT RECOG, P4573, DOI 10.1109/ICPR48806.2021.9413336
   Mertler CA, 2013, J PEDAGOG DEV, V3, P38
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Orta-Castañon P, 2018, INT J INTERACT DES M, V12, P15, DOI 10.1007/s12008-017-0372-5
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Peiyi L, China Patent, Patent No. [CN201810628314.4, 2018106283144]
   Phutela D., 2015, IUP J SOFT SKILLS, V9, P43
   Pierce CA, 1997, J ORGAN BEHAV, V18, P407
   Plizzari C, 2020, ARXIV
   Saunders CP, 2019, EDUC MEDIA TECH YEAR, V42, P57, DOI 10.1007/978-3-030-27986-8_6
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shao H, 2020, AAAI CONF ARTIF INTE, V34, P11966
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Varges da Silva Murilo, 2019, 2019 8th Brazilian Conference on Intelligent Systems (BRACIS). Proceedings, P747, DOI 10.1109/BRACIS.2019.00134
   Wang B, 2021, APPL PSYCHOL-INT REV, V70, P16, DOI 10.1111/apps.12290
   Wang Q, 2010, CHIN CONT DECIS CONF, P3354, DOI 10.1109/CCDC.2010.5498574
   Wei JC, 2019, IEEE IMAGE PROC, P300, DOI [10.1109/icip.2019.8802979, 10.1109/ICIP.2019.8802979]
   White J., 2013, CLASSROOM X FACTOR P
   Wood AB, 2017, ENGL TEACH-PRACT CRI, V16, P72, DOI 10.1108/ETPC-08-2016-0100
   Xu CY, 2021, FOOD QUAL PREFER, V87, DOI 10.1016/j.foodqual.2020.104071
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhu JG, 2019, IEEE SIGNAL PROC LET, V26, P1633, DOI 10.1109/LSP.2019.2942739
   Zongya Zhao, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P2441, DOI 10.1109/ICCC51575.2020.9345274
NR 54
TC 3
Z9 3
U1 8
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1797
EP 1812
DI 10.1007/s10055-023-00773-4
EA FEB 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000938127500001
PM 37360810
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Shah, SHH
   Karlsen, AST
   Solberg, M
   Hameed, IA
AF Shah, Syed Hammad Hussain
   Karlsen, Anniken Susanne T.
   Solberg, Mads
   Hameed, Ibrahim A.
TI A social VR-based collaborative exergame for rehabilitation: codesign,
   development and user study
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive healthcare; Virtual reality; Social interaction; Metaverse;
   Exergaming; User-centered design; Eldercare; Motivation; Physical
   rehabilitation
ID QUALITY-OF-LIFE; OLDER-ADULTS; INTRINSIC MOTIVATION; VIRTUAL-REALITY;
   EXERCISE; COMPETITION; USABILITY; THERAPY; HEALTH
AB Immersive virtual reality (VR)-based exercise video games (exergames) are increasingly being employed as a supportive intervention in rehabilitation programs to promote engagement in physical activity, especially for elderly users. A multifaceted and iterative codesign process is essential to develop sustainable exergaming solutions. The social aspect is considered one of the key motivating factors in exergames; however, research on the social aspect of VR exergames has been limited. Previous studies have relied on competitiveness in exergames, but research has shown that competition can lead to adverse effects on users. With the aim of motivating elderly individuals to participate in physical exercise and improving social connectedness during rehabilitation, this work presents a social VR-based collaborative exergame codesigned with elderly participants and therapists. This exergame stimulates full-body exercise and supports social collaboration among users through a collaborative game task. Furthermore, this article presents a user study based on a mixed-methods approach to gather user feedback on exergame design and the effect of social collaboration versus playing alone in a VR exergame in terms of physical exertion and motivation. This study spanned five weeks (99 exergaming sessions) with 14 elderly participants divided into two groups, one playing collaboratively and the other playing individually. Between-group comparisons were performed at baseline (first week) and in the fourth week, and within-group comparisons were performed in the fifth week, when the participants played the exergame in counterbalanced order. In contrast to the first week, the participants exergaming collaboratively in the fourth week reported significantly higher intrinsic motivation on all subscales (enjoyment: p < 0.02, effort: p < 0.002, usefulness: p < 0.01) and physical exertion (p < 0.001) than those playing alone. Thereafter, exergaming in counterbalanced order during the fifth week resulted in significant differences (medium to large effect size) within groups. The participants found the social VR gameplay enjoyable and agreed that collaboration played a vital role in their motivation. They reported various health benefits, a minimal increase in symptoms of simulator sickness, and excellent usability scores (83.75 +/- 13.3). In this work, we also identify various key design principles to support healthcare professionals, researchers and industrial experts in developing ergonomic and sustainable VR-based exergames for senior citizens.
C1 [Shah, Syed Hammad Hussain; Karlsen, Anniken Susanne T.; Hameed, Ibrahim A.] Norwegian Univ Sci & Technol NTNU, Fac Informat Technol & Elect Engn, Dept ICT & Nat Sci, Larsgardsvegen 2, N-6009 Alesund, Norway.
   [Solberg, Mads] Norwegian Univ Sci & Technol NTNU, Fac Med & Hlth Sci, Dept Hlth Sci, Larsgardsvegen 2, N-6009 Alesund, Norway.
C3 Norwegian University of Science & Technology (NTNU); Norwegian
   University of Science & Technology (NTNU)
RP Shah, SHH (corresponding author), Norwegian Univ Sci & Technol NTNU, Fac Informat Technol & Elect Engn, Dept ICT & Nat Sci, Larsgardsvegen 2, N-6009 Alesund, Norway.
EM syed.h.h.shah@ntnu.no; anniken.t.karlsen@ntnu.no; mads.solberg@ntnu.no;
   ibib@ntnu.no
RI Shamim, Nida/IXD-8527-2023; Hameed, Ibrahim A./O-7761-2019
OI Hameed, Ibrahim A./0000-0003-1252-260X; Karlsen,
   Anniken/0000-0002-6322-156X; Shah, Syed Hammad
   Hussain/0000-0003-2324-7623
FU Norwegian University of Science and Technology (NTNU)
FX The authors are grateful to the Norwegian University of Science and
   Technology (NTNU) for supporting the project and all the cordial
   participants and professionals who made this study possible.
CR Da Silva JLA, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/23423
   [Anonymous], 2021, Oculus
   [Anonymous], 2020, OCULUS
   [Anonymous], 2022, META
   [Anonymous], 2021, JUSTCREATE
   [Anonymous], 2021, Microsoft
   Babadi SY, 2021, EXP GERONTOL, V153, DOI 10.1016/j.exger.2021.111498
   Baker Steven, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445752
   Barathi SC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173982
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Bruun-Pedersen J.R., 2018, Journal For Virtual Worlds Research, V9, DOI DOI 10.4101/JVWR.V9I3.7224
   Cacciata M, 2019, INT J NURS STUD, V93, P30, DOI 10.1016/j.ijnurstu.2019.01.010
   Cacioppo John T, 2014, Evid Based Nurs, V17, P59, DOI 10.1136/eb-2013-101379
   Campo-Prieto P, 2021, VIRTUAL REAL-LONDON, V25, P801, DOI 10.1007/s10055-020-00495-x
   Cao LZ, 2021, VIRTUAL REAL-LONDON, V25, P597, DOI 10.1007/s10055-020-00477-z
   Chan SHM, 2023, VIRTUAL REAL-LONDON, V27, P3285, DOI 10.1007/s10055-021-00604-4
   Eckert M, 2017, LECT N BIOINFORMAT, V10209, P434, DOI 10.1007/978-3-319-56154-7_39
   Fraser LE, 2018, CAN J NEUROL SCI, V45, P405, DOI 10.1017/cjn.2017.297
   Gorsic M, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0231-4
   Gorsic M, 2016, IEEE ENG MED BIO, P4690, DOI 10.1109/EMBC.2016.7591774
   Nguyen H, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P3695
   Hamari J, 2015, COMPUT HUM BEHAV, V50, P333, DOI 10.1016/j.chb.2015.04.018
   Hoeg Emil Rosenlund, 2020, Interactivity, Game Creation, Design, Learning, and Innovation. 8th EAI International Conference, ArtsIT 2019, and 4th EAI International Conference, DLI 2019. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 328), P379, DOI 10.1007/978-3-030-53294-9_26
   Hoeg ER, 2023, VIRTUAL REAL-LONDON, V27, P245, DOI 10.1007/s10055-021-00544-z
   Jaarsma T, 2015, EUR J HEART FAIL, V17, P743, DOI 10.1002/ejhf.305
   Jones SA, 2020, ACT ADAPT AGING, V44, P24, DOI 10.1080/01924788.2019.1581022
   Kappen DL, 2019, INT J HUM-COMPUT INT, V35, P140, DOI 10.1080/10447318.2018.1441253
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Komoski SE, 2012, NOVEL APPROACHES OBE
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Li JH, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.552416
   Maclean N, 2000, BMJ-BRIT MED J, V321, P1051, DOI 10.1136/bmj.321.7268.1051
   Marker AM, 2015, GAMES HEALTH J, V4, P25, DOI 10.1089/g4h.2014.0066
   Maslow A.H., 1970, MOTIVATION PERSONALI
   Meekes W, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6841
   Mehra S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01827
   Meldrum D, 2012, DISABIL REHABIL-ASSI, V7, P205, DOI 10.3109/17483107.2011.616922
   Moore CG, 2011, CTS-CLIN TRANSL SCI, V4, P332, DOI 10.1111/j.1752-8062.2011.00347.x
   Nagano Y, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2379-y
   Najafabadi MM, 2019, ARCH PHYS MED REHAB, V100, P401, DOI 10.1016/j.apmr.2018.10.012
   Nawaz A, 2016, HEALTH INFORM J, V22, P911, DOI 10.1177/1460458215598638
   Normal-Inc, 2020, US
   Peiris CL, 2012, J PHYSIOTHER, V58, P261, DOI 10.1016/S1836-9553(12)70128-5
   Pereira F, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0578-9
   Piech J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094098
   Bezerra IMP, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000009612
   Poels K., 2007, D3.3: Game Experience Questionnaire: development of a self-report measure to assess the psychological impact of digital games
   Reis E, 2019, PHYS THER REV, V24, P84, DOI 10.1080/10833196.2019.1639012
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Ryan RM, 2020, CONTEMP EDUC PSYCHOL, V61, DOI 10.1016/j.cedpsych.2020.101860
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Schroeder SA, 2007, NEW ENGL J MED, V357, P1221, DOI 10.1056/NEJMsa073350
   Shah SHH, 2022, LECT NOTES COMPUT SC, V13317, P495, DOI 10.1007/978-3-031-05939-1_34
   Skjæret N, 2016, INT J MED INFORM, V85, P1, DOI 10.1016/j.ijmedinf.2015.10.008
   Song H, 2013, COMPUT HUM BEHAV, V29, P1702, DOI 10.1016/j.chb.2013.01.042
   Stamm O, 2022, VIRTUAL REAL-LONDON, V26, P1291, DOI 10.1007/s10055-022-00629-3
   Tanaka Y., 2016, 2016 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW), P1
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   van Santen J, 2018, J ALZHEIMERS DIS, V63, P741, DOI 10.3233/JAD-170667
   WHO, 2021, about us
   Wu PT, 2015, AM J HEALTH BEHAV, V39, P556, DOI 10.5993/AJHB.39.4.12
   Wu YZ, 2019, GERIATR GERONTOL INT, V19, P147, DOI 10.1111/ggi.13575
   Xiao X, 2017, BEHAV NEUROL, V2017, DOI 10.1155/2017/6261479
NR 63
TC 8
Z9 8
U1 20
U2 67
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3403
EP 3420
DI 10.1007/s10055-022-00721-8
EA NOV 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000889046500001
PM 36465891
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Sadeghi, S
   Daziano, R
   Yoon, SY
   Anderson, AK
AF Sadeghi, Saeedeh
   Daziano, Ricardo
   Yoon, So-Yeon
   Anderson, Adam K.
TI Affective experience in a virtual crowd regulates perceived travel time
SO VIRTUAL REALITY
LA English
DT Article
DE Time perception; Crowding; Virtual reality; Emotion; Heart rate
ID STIMULUS COMPLEXITY; PUBLIC TRANSPORT; HEART-RATE; PERCEPTION; DURATION;
   EMOTION; DISGUST; MODULATION; NUMEROSITY; ATTENTION
AB Time sometimes feels like it is flying by or slowing down. Previous research indicates objective number of items, subjective affect, and heart rate all can influence the experience of time. While these factors are usually tested in isolation with simple stimuli in the laboratory, here we examined them together in the ecological context of a virtual subway ride. We hypothesized that subjective affective experience associated with objective crowding lengthens subjective trip duration. Participants (N = 41) experienced short (1-2 min) immersive virtual reality subway trips with different levels of public crowding. Consistent with the immersive nature of decreased interpersonal virtual space, increased crowding decreased pleasantness and increased the unpleasantness of a trip. Virtual crowding also lengthened perceived trip duration. The presence of one additional person per square meter of the train significantly increased perceived travel time by an average of 1.8 s. Degree of pleasant relative to unpleasant affect mediated why crowded trips felt longer. Independently of crowding and affect, heart rate changes were related to experienced trip time. These results demonstrate socioemotional regulation of the experience of time and that effects of social crowding on perception and affect can be reliably created during a solitary virtual experience. This study demonstrates a novel use of Virtual Reality technology for testing psychological theories in ecologically valid and highly controlled settings.
C1 [Sadeghi, Saeedeh; Anderson, Adam K.] Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA.
   [Daziano, Ricardo] Cornell Univ, Sch Civil & Environm Engn, Ithaca, NY 14853 USA.
   [Yoon, So-Yeon] Cornell Univ, Dept Design & Environm Anal, Ithaca, NY USA.
C3 Cornell University; Cornell University; Cornell University
RP Sadeghi, S (corresponding author), Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA.
EM ss3767@cornell.edu; daziano@cornell.edu; sy492@cornell.edu;
   anderson@cornell.edu
RI Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829
CR Angrilli A, 1997, PERCEPT PSYCHOPHYS, V59, P972, DOI 10.3758/BF03205512
   Arstila V, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00196
   Aubry F, 2008, ACTA PSYCHOL, V128, P63, DOI 10.1016/j.actpsy.2007.09.011
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Bansal P, 2019, J CHOICE MODEL, V31, P124, DOI 10.1016/j.jocm.2019.04.004
   Barrett LF, 2015, NAT REV NEUROSCI, V16, P419, DOI 10.1038/nrn3950
   Basu D, 2012, TRANSPORT RES A-POL, V46, P1465, DOI 10.1016/j.tra.2012.05.010
   BELL CR, 1963, J EXP PSYCHOL, V66, P572, DOI 10.1037/h0048993
   Berrios R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00428
   Bierlaire M, 1999, HDB TRANSPORTATION S, P5, DOI [10.1007/978-1-4615-5203-1{_}2, DOI 10.1007/978-1-4615-5203-1{_}2]
   Brown JF, 1931, PSYCHOL FORSCH, V14, P233, DOI 10.1007/BF00403874
   Brownstone D, 2001, TRAVEL BEHAVIOUR RESEARCH: THE LEADING EDGE, P97, DOI 10.1016/B978-008043924-2/50003-1
   Cacioppo J.T., 2000, Handbook of emotions, V2, P2000
   Chapman HA, 2013, PSYCHOL BULL, V139, P300, DOI 10.1037/a0030964
   Cheng YH, 2010, TRANSPORTATION, V37, P875, DOI 10.1007/s11116-010-9267-z
   Clark J.E., 1982, Transportation Research Record, V890, P7
   Coull JT, 2004, SCIENCE, V303, P1506, DOI 10.1126/science.1091573
   Cox T, 2006, TRANSPORT RES A-POL, V40, P244, DOI 10.1016/j.tra.2005.07.001
   Craig AD, 2009, PHILOS T R SOC B, V364, P1933, DOI 10.1098/rstb.2009.0008
   Curtis V, 2004, P ROY SOC B-BIOL SCI, V271, pS131, DOI 10.1098/rsbl.2003.0144
   Curtis V, 2001, PERSPECT BIOL MED, V44, P17, DOI 10.1353/pbm.2001.0001
   Curtis V, 2011, PHILOS T R SOC B, V366, P389, DOI 10.1098/rstb.2010.0117
   Dormal V, 2006, ACTA PSYCHOL, V121, P109, DOI 10.1016/j.actpsy.2005.06.003
   Droit-Volet S, 2004, COGNITION EMOTION, V18, P849, DOI 10.1080/02699930341000194
   Droit-Volet S, 2007, TRENDS COGN SCI, V11, P504, DOI 10.1016/j.tics.2007.09.008
   Droit-Volet S, 2018, CURR DIR PSYCHOL SCI, V27, P422, DOI 10.1177/0963721418779978
   Droit-Volet S, 2013, J PHYSIOL-PARIS, V107, P255, DOI 10.1016/j.jphysparis.2013.03.005
   Evans GW, 2000, J PERS SOC PSYCHOL, V79, P204, DOI 10.1037//0022-3514.79.2.204
   Graham Frances K., 1991, Passive and Active Attention to Input
   Grondin S, 2010, ATTEN PERCEPT PSYCHO, V72, P561, DOI 10.3758/APP.72.3.561
   Hayashi MJ, 2013, NEUROSCI LETT, V543, P7, DOI 10.1016/j.neulet.2013.02.054
   Haywood L, 2017, TRANSPORT RES A-POL, V100, P215, DOI 10.1016/j.tra.2017.04.022
   Hwang J, 2012, INT J CONT HOSP MANA
   KALB LS, 1981, PERS SOC PSYCHOL B, V7, P650, DOI 10.1177/014616728174022
   KIRSCHBAUM C, 1993, NEUROPSYCHOBIOLOGY, V28, P76, DOI 10.1159/000119004
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Kron A, 2015, EMOTION, V15, P35, DOI 10.1037/a0038474
   Kron A, 2013, PSYCHOL SCI, V24, P1503, DOI 10.1177/0956797613475456
   Lake JI, 2016, CURR OPIN BEHAV SCI, V8, P214, DOI 10.1016/j.cobeha.2016.02.009
   Lake JI, 2016, NEUROSCI BIOBEHAV R, V64, P403, DOI 10.1016/j.neubiorev.2016.03.003
   LONG GM, 1981, PERCEPT PSYCHOPHYS, V29, P389, DOI 10.3758/BF03207349
   Mahudin N.M., 2011, WIT Transactions on The Built Environment, V116, P227, DOI DOI 10.2495/UT110201
   Mahudin NDM, 2012, TRANSPORT RES F-TRAF, V15, P38, DOI 10.1016/j.trf.2011.11.006
   Meissner K, 2011, BIOL PSYCHOL, V86, P289, DOI 10.1016/j.biopsycho.2011.01.001
   Noulhiane M, 2007, EMOTION, V7, P697, DOI 10.1037/1528-3542.7.4.697
   Ogden RS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16198-z
   Oliveri M, 2008, NEUROSCI LETT, V438, P308, DOI 10.1016/j.neulet.2008.04.051
   OSATO E, 1995, PERCEPT MOTOR SKILL, V80, P831, DOI 10.2466/pms.1995.80.3.831
   Otten S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01215
   Post E, 2019, TIME EC
   Rammsayer TH, 2014, J VISION, V14, DOI 10.1167/14.5.17
   Rey AE, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-15982-6
   Riggs L, 2011, EMOTION, V11, P776, DOI 10.1037/a0022591
   Roelofs CO, 1951, ACTA PSYCHOL, V8, P89, DOI 10.1016/0001-6918(51)90007-8
   Sadeghi S, 2023, TRANSPORT RES REC, V2677, P296, DOI 10.1177/03611981221130346
   SCHIFFMAN HR, 1974, J EXP PSYCHOL, V103, P156, DOI 10.1037/h0036794
   Schirmer A, 2011, FRONT INTEGR NEUROSC, V5, DOI 10.3389/fnint.2011.00058
   Schwarz MA, 2013, ATTEN PERCEPT PSYCHO, V75, P182, DOI 10.3758/s13414-012-0387-8
   Freitas JRS, 2021, PSYCHIAT QUART, V92, P1685, DOI 10.1007/s11126-021-09935-6
   STOKOLS D, 1972, PSYCHOL REV, V79, P275, DOI 10.1037/h0032706
   Tirachini A, 2017, TRANSPORT RES A-POL, V103, P311, DOI 10.1016/j.tra.2017.06.008
   Todd RM, 2009, NAT NEUROSCI, V12, P1217, DOI 10.1038/nn1009-1217
   TREISMAN M, 1990, PERCEPTION, V19, P705, DOI 10.1068/p190705
   van de Ven N, 2011, PSYCHON B REV, V18, P827, DOI 10.3758/s13423-011-0150-5
   Varotto SF, 2017, J TRANSP GEOGR, V62, P236, DOI 10.1016/j.jtrangeo.2017.05.016
   Vila J, 2007, INT J PSYCHOPHYSIOL, V66, P169, DOI 10.1016/j.ijpsycho.2007.07.004
   Walsh V, 2003, TRENDS COGN SCI, V7, P483, DOI 10.1016/j.tics.2003.09.002
   Witowska J, 2020, ACTA PSYCHOL, V205, DOI 10.1016/j.actpsy.2020.103061
   Xuan B, 2007, J VISION, V7, DOI 10.1167/7.10.2
   Yáñez MF, 2010, TRANSPORT RES A-POL, V44, P744, DOI 10.1016/j.tra.2010.07.007
NR 70
TC 1
Z9 1
U1 6
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1051
EP 1061
DI 10.1007/s10055-022-00713-8
EA NOV 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000878476000001
PM 36348940
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Pastel, S
   Petri, K
   Chen, CH
   Cáceres, AMW
   Stirnatis, M
   Nübel, C
   Schlotter, L
   Witte, K
AF Pastel, Stefan
   Petri, K.
   Chen, C. H.
   Caceres, Ana Milena Wiegand
   Stirnatis, M.
   Nuebel, C.
   Schlotter, L.
   Witte, K.
TI Training in virtual reality enables learning of a complex sports
   movement
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Motor learning; Head-mounted display; Karate kumite;
   Combat sports; Body visualization
ID VISUAL FEEDBACK; INTEGRATION; TECHNOLOGY; EXPERIENCE
AB Despite the increased use in sports, it is still unclear to what extent VR training tools can be applied for motor learning of complex movements. Previous VR studies primarily relate to realize performances rather than learning motor skills. Therefore, the current study compared VR with video training realizing the acquisition of karate technique, the Soto Uke moving forward in Zenkutsu Dachi, without being accompanied by a trainer or partner. Further analyses showed whether a less lavished forearm compared to a whole-body visualization in VR is necessary to acquire movements' basics sufficiently. Four groups were tested: 2 groups conducted VR training (VR-WB: whole-body visualization, and VR-FA having only visualized the forearms), the third group passed through a video-based learning method (VB), and the control group (C) had no intervention. In consultation with karate experts, a scoring system was developed to determine the movements' quality divided, into upper- and lower body performance and the fist pose. The three-way ANOVA with repeated measurements, including the between-subject factor group [VR-WB, VR-FA, VB, C] and the within-subject factors time [pre, post, retention] and body regions [upper body, lower body, fist pose], shows that all groups improved significantly (except for C) with the similar course after four training sessions in all body regions. Accordingly, VR training seems to be as effective as video training, and the transfer from VR-adapted skills into the natural environment was equally sufficient, although presenting different body visualization types. Further suggestions are made related to the features of future VR training simulations.
C1 [Pastel, Stefan; Petri, K.; Chen, C. H.; Caceres, Ana Milena Wiegand; Stirnatis, M.; Nuebel, C.; Schlotter, L.; Witte, K.] Otto Von Guericke Univ, Inst Sports Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
C3 Otto von Guericke University
RP Pastel, S (corresponding author), Otto Von Guericke Univ, Inst Sports Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
EM stefan.pastel@ovgu.de
OI Pastel, Stefan/0000-0002-3662-2683; Witte, Kerstin/0000-0001-8711-9335;
   Nubel, Carlo/0009-0002-7100-9208
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Ahir Kunjal, 2019, Augmented Human Research, V5, P1, DOI [DOI 10.1007/S41133-019-0025-2, 10.1007/s41133-019-0025-2]
   Burns A.-M., 2011, BIO Web of Conferences, V1, DOI DOI 10.1051/BIOCONF/20110100012
   Checa D, 2020, VIRTUAL REAL-LONDON, V24, P151, DOI 10.1007/s10055-019-00389-7
   Farley ORL, 2020, J HUM SPORT EXERC, V15, P535, DOI 10.14198/jhse.2020.153.06
   Farrow D, 2017, SPORTS MED, V47, P1043, DOI 10.1007/s40279-016-0646-2
   Faure C, 2020, J SPORT SCI, V38, P192, DOI 10.1080/02640414.2019.1689807
   Fischer B., 2020, LEHREN LERNEN DIGITA, DOI [10.1007/978-3-658-25524-4, DOI 10.1007/978-3-658-25524-4]
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Harris DJ, 2020, PSYCHOL SPORT EXERC, V50, DOI 10.1016/j.psychsport.2020.101721
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Hoffmann CP, 2014, J SPORT SCI, V32, P501, DOI 10.1080/02640414.2013.835435
   Huang CY, 2023, MULTIMED TOOLS APPL, V82, DOI 10.1007/s11042-019-7298-9
   Huang Y., 2015, Proceedings of the 2015 Virtual Reality International Conference, p6:1
   Hülsmann F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00043
   Jackson II T., 2021, Implementing Augmented Reality Into Immersive Virtual Learning Environments, P135
   Kallioniemi P, 2017, LECT NOTES COMPUT SC, V10516, P299, DOI 10.1007/978-3-319-68059-0_20
   Khan MS, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020024
   Kim A, 2018, J NEUROPHYSIOL, V120, P839, DOI 10.1152/jn.00931.2017
   Kim D, 2019, COMPUT HUM BEHAV, V93, P346, DOI 10.1016/j.chb.2018.12.040
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Lammfromm R., 2011, BIOWEB C, V1, P00054, DOI [10.1051/bioconf/20110100054, DOI 10.1051/BIOCONF/20110100054]
   Le Noury P, 2021, J SPORT SCI, V39, P412, DOI 10.1080/02640414.2020.1823618
   Liu HM, 2020, INT SYM MIX AUGMENT, P566, DOI 10.1109/ISMAR50242.2020.00084
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.00-32, 10.1109/VR46266.2020.1581086151885]
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Mueller FF, 2007, PERS UBIQUIT COMPUT, V11, P633, DOI 10.1007/s00779-006-0133-0
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Nor N.N., 2020, LECT NOTES I COMPUT, V323, DOI [10.1007/978-3-030-51005-3_36, DOI 10.1007/978-3-030-51005-3_36]
   O J, 2009, J APPL SPORT PSYCHOL, V21, P15, DOI 10.1080/10413200802541892
   Pan LA, 2012, ADV MATER RES-SWITZ, V472-475, P3117, DOI 10.4028/www.scientific.net/AMR.472-475.3117
   Park SH, 2018, HUM MOVEMENT SCI, V58, P88, DOI 10.1016/j.humov.2018.01.002
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Pastel S, 2021, VIRTUAL REAL-LONDON, V25, P175, DOI 10.1007/s10055-020-00449-3
   Petri Katharina, 2019, International Journal of Computer Science in Sport, V18, P20, DOI 10.2478/ijcss-2019-0011
   Petri K., 2019, J. Sport Area, V4, P294, DOI [10.25299/sportarea.2019.vol4(2).3370, DOI 10.25299/SPORTAREA.2019.VOL4(2).3370]
   Petri K, 2019, SPORTS ENG, V22, DOI 10.1007/s12283-019-0299-0
   Rhoads M.C., 2014, Athletic Insight, V6, P17
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Srinivasan Malathi, 2006, J Healthc Inf Manag, V20, P123
   Tauscher JP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1794, DOI [10.1109/VR.2019.8797858, 10.1109/vr.2019.8797858]
   Thurlings M, 2013, EDUC RES REV-NETH, V9, P1, DOI 10.1016/j.edurev.2012.11.004
   Tirp J., 2015, Psychol Test Assess Model, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Unell A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-96876-6
   Vaziri S, 2006, J NEUROSCI, V26, P4188, DOI 10.1523/JNEUROSCI.4747-05.2006
   Vignais N, 2015, HUM MOVEMENT SCI, V39, P12, DOI 10.1016/j.humov.2014.10.006
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Wichmann W-D., 2005, RICHTIG KARATE
   Wong JD, 2012, J NEUROPHYSIOL, V108, P3313, DOI 10.1152/jn.00122.2012
   Wood G, 2021, VIRTUAL REAL-LONDON, V25, P43, DOI 10.1007/s10055-020-00441-x
   Yu CH, 2020, EDUC TECHNOL SOC, V23, P64
NR 54
TC 10
Z9 10
U1 6
U2 46
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 523
EP 540
DI 10.1007/s10055-022-00679-7
EA JUL 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000828931800003
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, MH
   Schulze, JP
   Zhang, D
AF Zhang, Menghe
   Schulze, Juergen P.
   Zhang, Dong
TI E-faceatlasAR: extend atlas of facial acupuncture points with auricular
   maps in augmented reality for self-acupressure
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Acupuncture; Mediapipe; Face alignment; Ear
   morphology
ID EAR ACUPUNCTURE; PAIN
AB Acupuncture is a form of alternative medicine from ancient times and adapted to modern medicine. One typical practice of acupuncture is putting pressure on specific sites (acupuncture points, or acupoints) in the body, called acupressure. Self-acupressure refers to people applying pressure on acupoints using fingers, palms, or special devices to themselves. It has been widely applied because of its convenience and effectiveness. However, localizing the acupoints in any acupuncture practice requires expert knowledge. Novices without any medical background typically find it difficult because of the lack of visual cues. Our previous prototype, FaceAtlasAR, stresses this issue by localizing and overlaying facial acupoints in the augmented reality (AR) context in real-time. This paper will present E-FaceAtlasAR, which extends FaceAtlasAR to show auricular zone maps in the meantime. The system first localizes facial acupoints and auricular zone map in an anatomical yet feasible way. Then, it overlays the requested acupoints and auricular zone maps on the ears in AR. We adopt Mediapipe, a cross-platform machine learning framework, to build the real-time pipeline that runs on desktop and Android phones. Also, we conducted extensive experiments to show its effectiveness and robustness. With this system, users, even not professionals, can position the acupoints quickly for their self-acupressure treatments.
C1 [Zhang, Menghe; Schulze, Juergen P.] Univ Calif San Diego, Comp Sci & Engn, 9500 Gilman Dr, La Jolla, CA 92093 USA.
   [Zhang, Dong] Qilu Univ Technol, Automat, 3501 Daxue Rd, Jinan 250353, Shandong, Peoples R China.
C3 University of California System; University of California San Diego;
   Qilu University of Technology
RP Zhang, MH (corresponding author), Univ Calif San Diego, Comp Sci & Engn, 9500 Gilman Dr, La Jolla, CA 92093 USA.
EM mez071@eng.ucsd.edu; jschulze@ucsd.edu; jnzd156@163.com
OI Zhang, Menghe/0000-0001-8681-4889
CR AACP, EV BAS AC TRAIN AC P
   artyfactory, ARTYFACTORY PROPORTI
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Berman BM, 2004, ANN INTERN MED, V141, P901, DOI 10.7326/0003-4819-141-12-200412210-00006
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chen YZ, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P239, DOI 10.1145/3083187.3083225
   Emersic Z, 2020, NEURAL COMPUT APPL, V32, P15785, DOI 10.1007/s00521-018-3530-1
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Esther Gonzalez Luis Alvarez., 2008, Ami ear database
   Focks C., 2008, Atlas of Acupuncture
   Frejlichowski D, 2010, LECT NOTES COMPUT SC, V6112, P227, DOI 10.1007/978-3-642-13775-4_23
   Godson DR, 2019, J ACUPUNCT MERIDIAN, V12, P52
   Gori L, 2007, EVID-BASED COMPL ALT, V4, P13, DOI 10.1093/ecam/nem106
   Hansley EE, 2018, IET BIOMETRICS, V7, P215, DOI 10.1049/iet-bmt.2017.0210
   Huber Patrik, 2016, P 11 INT JOINT C COM, DOI DOI 10.5220/0005669500790086
   Jiang Haotian., 2015, Proceedings_of_the_10th_EAI International_Conference_on_Body_Area_Networks, P7, DOI [10.4108/eai.28-9-2015.2261520, DOI 10.4108/EAI.28-9-2015.2261520]
   Kanehira R, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P665, DOI 10.1109/FSKD.2008.575
   Kaptchuk TJ, 2002, ANN INTERN MED, V136, P374, DOI 10.7326/0003-4819-136-5-200203050-00010
   Kartynnik Y., 2019, ARXIV PREPRINT ARXIV
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Lan KC, 2018, SENSYS'18: PROCEEDINGS OF THE 16TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P384, DOI 10.1145/3274783.3278480
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Lugaresi C., 2019, Mediapipe: a framework for perceiving and processing reality
   mai, MAI ACUMAP
   Molsberger AF, 2012, EUR J PAIN, V16, P1264, DOI 10.1002/j.1532-2149.2012.00145.x
   Mount DM., 2002, LECT NOTES
   Nogier, 1956, B SOC ACUPUNCTURE, V20, P51
   Nogier Paul MF., 1983, From auriculotherapy to auriculomedicine
   OLESON T, 1993, OBSTET GYNECOL, V82, P906
   OLESON TD, 1980, PAIN, V8, P217, DOI 10.1016/0304-3959(88)90009-7
   Rambau J, 2002, MATHEMATICAL SOFTWARE, PROCEEDINGS, P330, DOI 10.1142/9789812777171_0035
   Raposo Rui., 2011, 2011 IEEE workshop on computational intelligence in biometrics and identity management (CIBIM), P84
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Standard C, 2008, NOMENCLATURE LOCATIO
   Tkachenka A, 2019, ARXIV PREPRINT ARXIV
   Unknown, 2005, NAT STAND PEOPL REP
   Unknown, 2017, YNSA BAS POINTS
   Vickers AJ, 2018, J PAIN, V19, P455, DOI 10.1016/j.jpain.2017.11.005
   White A, 2004, RHEUMATOLOGY, V43, P662, DOI 10.1093/rheumatology/keg005
   Wu CX, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000013845
   Yao JP, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000016959
   Yau Elaine., Virtual reality helps chinese medicine students learn acupuncture and doctors treat cancer
   Yuan J, 2008, SPINE, V33, pE887, DOI 10.1097/BRS.0b013e318186b276
   Zhang Meng., 2021, ARXIV PREPRINT ARXIV
   Zhou YX, 2017, IEEE INT CONF AUTOMA, P626, DOI 10.1109/FG.2017.79
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 48
TC 2
Z9 3
U1 4
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1763
EP 1776
DI 10.1007/s10055-022-00663-1
EA JUL 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000819902500001
DA 2024-07-18
ER

PT J
AU Cavedoni, S
   Cipresso, P
   Mancuso, V
   Bruni, F
   Pedroli, E
AF Cavedoni, S.
   Cipresso, P.
   Mancuso, V.
   Bruni, F.
   Pedroli, E.
TI Virtual reality for the assessment and rehabilitation of neglect: where
   are we now? A 6-year review update
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Technology; Neglect; Assessment; Rehabilitation
ID UNILATERAL SPATIAL NEGLECT; POSTSTROKE COGNITIVE IMPAIRMENT;
   RIGHT-HEMISPHERE STROKE; PRISM ADAPTATION; HEMISPATIAL NEGLECT;
   OPTOKINETIC STIMULATION; VISUAL-ATTENTION; LINE BISECTION; MOTOR
   DEFICITS; FREE-ENERGY
AB Unilateral spatial neglect (USN) is a frequent repercussion of a cerebrovascular accident, typically a stroke. USN patients fail to orient their attention to the contralesional side to detect auditory, visual, and somatosensory stimuli, as well as to collect and purposely use this information. Traditional methods for USN assessment and rehabilitation include paper-and-pencil procedures, which address cognitive functions as isolated from other aspects of patients' functioning within a real-life context. This might compromise the ecological validity of these procedures and limit their generalizability; moreover, USN evaluation and treatment currently lacks a gold standard. The field of technology has provided several promising tools that have been integrated within the clinical practice; over the years, a "first wave" has promoted computerized methods, which cannot provide an ecological and realistic environment and tasks. Thus, a "second wave" has fostered the implementation of virtual reality (VR) devices that, with different degrees of immersiveness, induce a sense of presence and allow patients to actively interact within the life-like setting. The present paper provides an updated, comprehensive picture of VR devices in the assessment and rehabilitation of USN, building on the review of Pedroli et al. (2015). The present paper analyzes the methodological and technological aspects of the studies selected, considering the issue of usability and ecological validity of virtual environments and tasks. Despite the technological advancement, the studies in this field lack methodological rigor as well as a proper evaluation of VR usability and should improve the ecological validity of VR-based assessment and rehabilitation of USN.
C1 [Cavedoni, S.; Cipresso, P.; Pedroli, E.] IRCCS Ist Auxol Italiano, Appl Technol Neuropsychol Lab, Milan, Italy.
   [Cipresso, P.] Univ Turin, Dept Psychol, Via Verdi 10, I-10124 Turin, TO, Italy.
   [Mancuso, V.; Bruni, F.; Pedroli, E.] eCampus Univ, Fac Psychol, Novedrate, Italy.
C3 IRCCS Istituto Auxologico Italiano; University of Turin; Universita
   Ecampus
RP Cipresso, P (corresponding author), IRCCS Ist Auxol Italiano, Appl Technol Neuropsychol Lab, Milan, Italy.; Cipresso, P (corresponding author), Univ Turin, Dept Psychol, Via Verdi 10, I-10124 Turin, TO, Italy.
EM pietro.cipresso@unito.it
RI Pedroli, Elisa/AAC-5927-2022; Cipresso, Pietro/G-4676-2011; Cavedoni,
   Silvia/AAI-6561-2020; Mancuso, Valentina/AAZ-5090-2020; Bruni,
   Francesca/JVZ-5772-2024; Pedroli, Elisa/K-5751-2016
OI Cipresso, Pietro/0000-0002-0662-7678; Mancuso,
   Valentina/0000-0002-4198-3723; Pedroli, Elisa/0000-0003-4012-262X;
   Bruni, Francesca/0000-0001-9911-0573; Cavedoni,
   Silvia/0000-0002-2995-3855
CR Aida J, 2018, NEUROREHABILITATION, V42, P441, DOI 10.3233/NRE-172361
   Alashram AR, 2019, J CLIN NEUROSCI, V66, P209, DOI 10.1016/j.jocn.2019.04.026
   ALBERT ML, 1973, NEUROLOGY, V23, P658, DOI 10.1212/WNL.23.6.658
   Allain P, 2014, J INT NEUROPSYCH SOC, V20, P468, DOI 10.1017/S1355617714000344
   ANTONUCCI G, 1995, J CLIN EXP NEUROPSYC, V17, P383, DOI 10.1080/01688639508405131
   Aravind G, 2018, ANN PHYS REHABIL MED, V61, P197, DOI 10.1016/j.rehab.2017.05.002
   Aravind G, 2015, IEEE T NEUR SYS REH, V23, P179, DOI 10.1109/TNSRE.2014.2369812
   Aravind G, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-38
   Arrington CM, 2000, J COGNITIVE NEUROSCI, V12, P106, DOI 10.1162/089892900563975
   Azouvi P, 2003, ARCH PHYS MED REHAB, V84, P51, DOI 10.1053/apmr.2003.50062
   Azouvi P, 1996, NEUROPSYCHOL REHABIL, V6, P133, DOI 10.1080/713755501
   Azouvi P, 2017, ANN PHYS REHABIL MED, V60, P191, DOI 10.1016/j.rehab.2016.10.006
   Bartolomeo P., 2001, Handbook of Neuropsychology, V2nd, P67
   Baud-Bovy G, 2015, IEEE T HAPTICS, V8, P130, DOI 10.1109/TOH.2014.2369057
   Béjot Y, 2016, REV NEUROL-FRANCE, V172, P59, DOI 10.1016/j.neurol.2015.07.013
   Bergego C, 1995, VALIDATION CHELLE VA
   Bickerton WL, 2011, NEUROPSYCHOLOGY, V25, P567, DOI 10.1037/a0023501
   Booth K, 1982, J Neurosurg Nurs, V14, P38
   Bowen A, 1999, STROKE, V30, P1196, DOI 10.1161/01.STR.30.6.1196
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Burdea G. C., 2003, Virtual reality technology
   Buxbaum LJ, 2008, J CLIN EXP NEUROPSYC, V30, P650, DOI 10.1080/13803390701625821
   Buxbaum LJ, 2012, NEUROPSYCHOLOGY, V26, P430, DOI 10.1037/a0028674
   Buxbaum LJ, 2004, NEUROLOGY, V62, P749, DOI 10.1212/01.WNL.0000113730.73031.F4
   Cassani R, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00780-5
   Chen C, 2013, NEUROLOGY, V80, pS27, DOI 10.1212/WNL.0b013e3182762569
   Cherney LR, 2001, ARCH PHYS MED REHAB, V82, P322, DOI 10.1053/apmr.2001.21511
   Chirico A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01766
   Choi HG, 2021, MEDICINE, V100, DOI 10.1097/MD.0000000000026476
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   de Amorim JSC, 2018, ADV RHEUMATOL, V58, DOI 10.1186/s42358-018-0013-0
   Cogné M, 2020, ANN PHYS REHABIL MED, V63, P12, DOI 10.1016/j.rehab.2019.03.005
   Corbetta M, 2005, NAT NEUROSCI, V8, P1603, DOI 10.1038/nn1574
   Corbetta M, 2011, ANNU REV NEUROSCI, V34, P569, DOI 10.1146/annurev-neuro-061010-113731
   Davis R, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.607219
   Dawson AM, 2008, 2008 VIRTUAL REHABILITATION, P77, DOI 10.1109/ICVR.2008.4625140
   De Luca R, 2019, APPL NEUROPSYCH-ADUL, V26, P96, DOI 10.1080/23279095.2017.1363040
   de Rooij IJM, 2016, PHYS THER, V96, P1905, DOI 10.2522/ptj.20160054
   de Tommaso M, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2978-7
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Di Monaco M, 2011, ARCH PHYS MED REHAB, V92, P1250, DOI 10.1016/j.apmr.2011.03.018
   Dijkerman HC, 2003, EXP BRAIN RES, V153, P220, DOI 10.1007/s00221-003-1595-1
   Diller L, 1977, Adv Neurol, V18, P63
   Dvorkin AY, 2012, NEUROREHAB NEURAL RE, V26, P120, DOI 10.1177/1545968311410068
   Ekman U, 2018, ACTA NEUROL SCAND, V138, P284, DOI 10.1111/ane.12955
   Falco C, 2012, ADV USABILITY EVALUA
   Faria AL, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0204-z
   Farnè A, 2002, NEUROPSYCHOLOGIA, V40, P718, DOI 10.1016/S0028-3932(01)00186-5
   Fordell H, 2011, ACTA NEUROL SCAND, V123, P167, DOI 10.1111/j.1600-0404.2010.01390.x
   Fordell H, 2017, THESIS UME U
   Fordell H, 2016, TOP STROKE REHABIL, V23, P191, DOI 10.1080/10749357.2016.1138670
   Friston KJ, 2007, SYNTHESE, V159, P417, DOI 10.1007/s11229-007-9237-y
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z
   Garcia MP, 1998, NEUROPSYCHOL REV, V8, P203, DOI 10.1023/A:1021622319851
   García-Betances RI, 2015, AM J ALZHEIMERS DIS, V30, P49, DOI 10.1177/1533317514545866
   Gerber SM, 2018, IEEE ENG MED BIO, P3489, DOI 10.1109/EMBC.2018.8513003
   Glize B, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02019
   Grattan ES, 2017, AM J OCCUP THER, V71, DOI 10.5014/ajot.2017.025015
   Guilbert A, 2016, EXP BRAIN RES, V234, P2893, DOI 10.1007/s00221-016-4691-8
   Halligan PW., 1991, NEUROPSYCHOL REHABIL, V1, P5, DOI DOI 10.1080/09602019108401377
   HARTMANMAEIR A, 1995, AM J OCCUP THER, V49, P507, DOI 10.5014/ajot.49.6.507
   He BJ, 2007, NEURON, V53, P905, DOI 10.1016/j.neuron.2007.02.013
   Heilman KM, 2000, SEMIN NEUROL, V20, P463, DOI 10.1055/s-2000-13179
   Henderson A, 2007, TOP STROKE REHABIL, V14, P52, DOI 10.1310/tsr1402-52
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Huygelier H, 2022, APPL NEUROPSYCH-ADUL, V29, P915, DOI 10.1080/23279095.2020.1821030
   Jacquin-Courtois S, 2010, BRAIN, V133, P895, DOI 10.1093/brain/awp327
   Jacquin-Courtois S, 2013, NEUROSCI BIOBEHAV R, V37, P594, DOI 10.1016/j.neubiorev.2013.02.007
   Jang W, 2016, COMPUT METH PROG BIO, V135, P115, DOI 10.1016/j.cmpb.2016.07.026
   Jee H, 2015, APPL CLIN INFORM, V6, P400, DOI 10.4338/ACI-2015-01-RA-0002
   Jokinen H, 2015, EUR J NEUROL, V22, P1288, DOI 10.1111/ene.12743
   Karnath HO, 2011, BRAIN, V134, P903, DOI 10.1093/brain/awq355
   KARNATH HO, 1991, BRAIN, V114, P1997, DOI 10.1093/brain/114.4.1997
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kidd T, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1196-x
   Kim EJ, 2007, NEUROLOGY, V69, P1105, DOI 10.1212/01.wnl.0000276956.65528.d4
   Kim JH, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0094-5
   Kim KI, 2017, EXP GERONTOL, V88, P25, DOI 10.1016/j.exger.2016.11.013
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Kim TL, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00835-1
   Kim YM, 2011, ANN REHABIL MED-ARM, V35, P309, DOI 10.5535/arm.2011.35.3.309
   Kinsbourne M., 1993, UNILATERAL NEGLECT C
   Klinger E, 2006, CYBERPSYCHOL BEHAV, V9, P342, DOI 10.1089/cpb.2006.9.342
   Knobel SEJ, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00180
   Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256
   Lange BS, 2010, PHYS MED REH CLIN N, V21, P339, DOI 10.1016/j.pmr.2009.12.007
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Levick WR, 2010, BRAIN IMPAIR, V11, P144, DOI 10.1375/brim.11.2.144
   Liu KPY, 2019, ARCH PHYS MED REHAB, V100, P956, DOI 10.1016/j.apmr.2018.05.037
   Luis Perez Medina J., 2019, Assistive and Rehabilitation Engineering, DOI [10.5772/intechopen.85869, DOI 10.5772/INTECHOPEN.85869]
   Lunven M, 2015, BRAIN, V138, P746, DOI 10.1093/brain/awu389
   Maggio MG, 2019, J CLIN NEUROSCI, V61, P1, DOI 10.1016/j.jocn.2018.12.020
   Mainetti R, 2013, TECHNOL HEALTH CARE, V21, P97, DOI 10.3233/THC-120712
   Mancuso V, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.566731
   Mansfield A, 2018, HAND CLINIC, V159, P205, DOI 10.1016/B978-0-444-63916-5.00013-6
   Maravita A, 2003, NEUROLOGY, V60, P1829, DOI 10.1212/WNL.60.11.1829
   MARK VW, 1988, NEUROLOGY, V38, P1207, DOI 10.1212/WNL.38.8.1207
   Martirosov S., 2017, ANN DAAAM PROCE, DOI 10.2507/28th.daaam.proceedings.101
   Masrom M., 2007, 12 INT C ED 21 24 MA
   Menon Anita, 2004, Top Stroke Rehabil, V11, P41
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moon Sy, 2006, J Clin Neurol, V2, P12, DOI 10.3988/jcn.2006.2.1.12
   Moreno A, 2019, ALZH DEMENT-TRCI, V5, P834, DOI 10.1016/j.trci.2019.09.016
   Moseley GL, 2012, NEUROSCI BIOBEHAV R, V36, P34, DOI 10.1016/j.neubiorev.2011.03.013
   Mugueta-Aguinaga I, 2017, AGING DIS, V8, P176, DOI 10.14336/AD.2016.0901
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Nijboer TCW, 2008, NEUROREPORT, V19, P293, DOI 10.1097/WNR.0b013e3282f4cb67
   Nijboer TCW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100584
   Ogourtsova T, 2019, DISABIL REHABIL, V41, P284, DOI 10.1080/09638288.2017.1387292
   Ogourtsova T, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0374-y
   Ogourtsova T, 2018, NEUROREHAB NEURAL RE, V32, P46, DOI 10.1177/1545968317751677
   Oh Y., 2010, Proceedings of Meaningful Play 2010, P1
   Pallavicini F, 2015, TECHNOL HEALTH CARE, V23, P795, DOI 10.3233/THC-151039
   Parsons TD, 2013, 2013 1ST WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P27, DOI 10.1109/VAAT.2013.6786190
   Pedroli E, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00226
   Pirovano M, 2016, ENTERTAIN COMPUT, V14, P55, DOI 10.1016/j.entcom.2015.10.002
   PIZZAMIGLIO L, 1990, CORTEX, V26, P535, DOI 10.1016/S0010-9452(13)80303-6
   PIZZAMIGLIO L, 1992, J CLIN EXP NEUROPSYC, V14, P901, DOI 10.1080/01688639208402543
   Plancher G., 2017, The Role of Technology in Clinical Neuropsychology
   Plummer P, 2003, PHYS THER, V83, P732, DOI 10.1093/ptj/83.8.732
   Previc FH, 1998, PSYCHOL BULL, V124, P123, DOI 10.1037/0033-2909.124.2.123
   Rabuffetti M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031511
   Reinhart S., 2016, SENSITIVE NEGLECT TE
   Rey A, 1941, ARCH PSYCHOLOGIE, V28, P286
   Richard C, 2004, NEUROLOGY, V63, P2136, DOI 10.1212/01.WNL.0000145664.09078.83
   Riva G., 2014, Dans Interacting with Presence, P9, DOI DOI 10.2478/9783110409697
   Riva G., 2008, J. Cyber Ther. Rehabil, V1, P7
   Riva G., 2022, Reference Module in Neuroscience and Biobehavioral Psychology
   Riva G, 2020, EXPERT REV MED DEVIC, V17, P1035, DOI 10.1080/17434440.2020.1825939
   Riva G, 2019, ANN REV CYBERTHERAPY, V17, P3
   Riva G, 2018, ANN REV CYBERTHERAPY, V16, P3
   Riva G, 2018, CORTEX, V104, P241, DOI 10.1016/j.cortex.2017.07.013
   Riva G, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P3, DOI 10.5772/46411
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   RIZZOLATTI G, 1990, REV NEUROL, V146, P626
   ROBERTSON IH, 1993, NEUROPSYCHOLOGIA, V31, P293, DOI 10.1016/0028-3932(93)90093-F
   ROBERTSON IH, 1992, NEUROPSYCHOLOGIA, V30, P553, DOI 10.1016/0028-3932(92)90058-T
   Robertson IH, 1998, NATURE, V395, P169, DOI 10.1038/25993
   Rode G, 2017, ANN PHYS REHABIL MED, V60, P177, DOI 10.1016/j.rehab.2016.03.003
   Rode G, 2006, RESTOR NEUROL NEUROS, V24, P347
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   SCHENKENBERG T, 1980, NEUROLOGY, V30, P509, DOI 10.1212/WNL.30.5.509
   Sedda A, 2013, BEHAV NEUROL, V26, P183, DOI [10.1155/2013/810279, 10.3233/BEN-2012-129006]
   Serino S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01541
   Serino S, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00240
   Shulman KI, 2000, INT J GERIATR PSYCH, V15, P548, DOI 10.1002/1099-1166(200006)15:6<548::AID-GPS242>3.3.CO;2-L
   Siddique N, 2021, PAK J MED HEALTH SCI, V15, P549
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smania N, 1998, BRAIN, V121, P1759, DOI 10.1093/brain/121.9.1759
   SPENCE CJ, 1994, J EXP PSYCHOL HUMAN, V20, P555, DOI 10.1037/0096-1523.20.3.555
   Spreij LA, 2020, J NEUROPSYCHOL, V14, P28, DOI 10.1111/jnp.12172
   Stones D, 2016, AGEING SOC, V36, P449, DOI 10.1017/S0144686X14001214
   Sugihara S, 2016, J PHYS THER SCI, V28, P332, DOI 10.1589/jpts.28.332
   Suhr J, 1998, ARCH CLIN NEUROPSYCH, V13, P495, DOI 10.1016/S0887-6177(97)00039-5
   Sun JH, 2014, ANN TRANSL MED, V2, DOI 10.3978/j.issn.2305-5839.2014.08.05
   Sundar U, 2010, ANN INDIAN ACAD NEUR, V13, P42, DOI 10.4103/0972-2327.61276
   Talsma D, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00019
   Tobler-Ammann BC, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.8013
   Tobler-Ammann BC, 2017, JMIR SERIOUS GAMES, V5, DOI 10.2196/games.7923
   Tobler-Ammann BC, 2016, COGN BEHAV NEUROL, V29, P78, DOI 10.1097/WNN.0000000000000094
   Tsirlin I, 2009, CYBERPSYCHOL BEHAV, V12, P175, DOI 10.1089/cpb.2008.0208
   VALLAR G, 1993, NEUROPSYCHOLOGIA, V31, P1191, DOI 10.1016/0028-3932(93)90067-A
   Vallar G, 1997, NEUROLOGY, V49, P1364, DOI 10.1212/WNL.49.5.1364
   VALLAR G, 1986, NEUROPSYCHOLOGIA, V24, P609, DOI 10.1016/0028-3932(86)90001-1
   Vuilleumier P, 2013, ANN NY ACAD SCI, V1296, P50, DOI 10.1111/nyas.12161
   Wåhlin A, 2019, ACTA NEUROL SCAND, V139, P254, DOI 10.1111/ane.13048
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   WEINTRAUB S, 1988, J NEUROL NEUROSUR PS, V51, P1481, DOI 10.1136/jnnp.51.12.1481
   WILSON B, 1987, ARCH PHYS MED REHAB, V68, P98
   Wilson BA, 2010, GIUNTI OS
   Yasuda K., 2018, BMJ CASE REP, DOI 10.1136/bcr-2017-222860
   Yasuda K, 2020, NEUROREHABILITATION, V46, P595, DOI 10.3233/NRE-203014
   Yasuda K, 2017, TOP STROKE REHABIL, V24, P533, DOI 10.1080/10749357.2017.1351069
   Zigiotto L, 2021, NEUROPSYCHOL REHABIL, V31, P1410, DOI 10.1080/09602011.2020.1779754
NR 175
TC 18
Z9 20
U1 2
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1663
EP 1704
DI 10.1007/s10055-022-00648-0
EA MAY 2022
PG 42
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000802865600001
PM 35669614
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dobre, GC
   Gillies, M
   Pan, XN
AF Dobre, Georgiana Cristina
   Gillies, Marco
   Pan, Xueni
TI Immersive machine learning for social attitude detection in virtual
   reality narrative games
SO VIRTUAL REALITY
LA English
DT Article
DE Artificial intelligence; Expressive body language; Gaming;
   Human-computer interaction; Virtual agents; Virtual reality
ID BEHAVIOR
AB People can understand how human interaction unfolds and can pinpoint social attitudes such as showing interest or social engagement with a conversational partner. However, summarising this with a set of rules is difficult, as our judgement is sometimes subtle and subconscious. Hence, it is challenging to program Non-Player Characters (NPCs) to react towards social signals appropriately, which is important for immersive narrative games in Virtual Reality (VR). We collaborated with two game studios to develop an immersive machine learning (ML) pipeline for detecting social engagement. We collected data from participants-NPC interaction in VR, which was then annotated in the same immersive environment. Game design is a creative process and it is vital to respect designer's creative vision and judgement. We therefore view annotation as a key part of the creative process. We trained a reinforcement learning algorithm (PPO) with imitation learning rewards using raw data (e.g. head position) and socially meaningful derived data (e.g. proxemics); we compared different ML configurations including pre-training and a temporal memory (LSTM). The pre-training and LSTM configuration using derived data performed the best (84% F1-score, 83% accuracy). The models using raw data did not generalise. Overall, this work introduces an immersive ML pipeline for detecting social engagement and demonstrates how creatives could use ML and VR to expand their ability to design more engaging experiences. Given the pipeline's results for social engagement detection, we generalise it for detecting human-defined social attitudes.
C1 [Dobre, Georgiana Cristina; Gillies, Marco; Pan, Xueni] Goldsmiths Univ London, Dept Comp, London, England.
C3 University of London; Goldsmiths University London
RP Dobre, GC (corresponding author), Goldsmiths Univ London, Dept Comp, London, England.
EM c.dobre@gold.ac.uk
OI Dobre, Georgiana Cristina/0000-0002-9284-9954
FU Innovate UK [TS/S02221X/1]; UK Engineering and Physical Sciences
   Research Council (EPSRC) [EP/L015846/1]
FX All participants took part in the experiment voluntarily and signed a
   consent form. They were given the freedom to drop at any time. The
   project was approved by the University's ethics board. We worked on this
   project in collaboration with two game studios: Dream Reality
   Interactive (https://www.dreamrealityint eractive.com/) and Maze Theory
   (https://www.maze-theory.com/); the project being supported by Innovate
   UK Grant TS/S02221X/1. This work was also partly supported by Grant
   EP/L015846/1 for the Centre for Doctoral Training in Intelligent Games
   and Game Intelligence (http://www.iggi.org.uk/) from the UK Engineering
   and Physical Sciences Research Council (EPSRC).
CR Ahuja C, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P74, DOI 10.1145/3340555.3353725
   Bailenson Jeremy, 2018, If a possible mass shooter wants to hone his craft, don't hand him a virtual boot camp
   Bee N., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1, DOI [10.1109/ACII.2009.5349573, DOI 10.1109/ACII.2009.5349573]
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bohus Dan, 2014, P 16 INT C MULT INT, P2, DOI DOI 10.1145/2663204.2663241
   Brugel S, 2015, PATIENT EDUC COUNS, V98, P1260, DOI 10.1016/j.pec.2015.08.007
   Burgoon J.K., 1993, Communication Theory, V3, P295, DOI DOI 10.1111/J.1468-2885.1993.TB00076.X
   Cafaro A, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2914796
   CHINCHOR N, 1992, FOURTH MESSAGE UNDERSTANDING CONFERENCE (MUC-4), P22
   Christensen JV, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234297
   Dermouche S, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P375, DOI 10.1145/3340555.3353758
   Dermouche S, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P440, DOI 10.1145/3340555.3353765
   Dhamija S, 2017, INT CONF AFFECT, P1, DOI 10.1109/ACII.2017.8273571
   Feng W, 2017, IEEE INT C INT ROBOT, P4131, DOI 10.1109/IROS.2017.8206272
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Forbes-Riley K, 2012, P 2012 C N AM CHAPT, P91
   Gillies Marco., 2015, INT C INT US INT P I, P181, DOI [10.1145/2678025.2701373, DOI 10.1145/2678025.2701373]
   Glas N, 2015, INT CONF AFFECT, P944, DOI 10.1109/ACII.2015.7344688
   Gordon G, 2016, AAAI CONF ARTIF INTE, P3951
   Greenwood D, 2017, LECT NOTES ARTIF INT, V10498, P160, DOI 10.1007/978-3-319-67401-8_18
   Hale J, 2020, J NONVERBAL BEHAV, V44, P63, DOI 10.1007/s10919-019-00320-3
   Hall Edward T., 1966, The Hidden Dimension
   Ho J, 2016, ADV NEUR IN, V29
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ip B, 2011, GAMES CULT, V6, P103, DOI 10.1177/1555412010364982
   Jin AB, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340250
   Khaki H, 2016, INT CONF ACOUST SPEE, P2762, DOI 10.1109/ICASSP.2016.7472180
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Marsella Stacy, 2013, P 12 ACM SIGGRAPH EU, P25, DOI DOI 10.1145/2485895.2485900
   MaxRoser CA, 2013, HUMAN HEIGHT
   Mota Selene, 2003, P COMP VIS PATT REC, V5, P1, DOI [10.1109/CVPRW.2003.10047, DOI 10.1109/CVPRW.2003.10047]
   Pan XN, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00080
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Sanghvi J, 2011, ACMIEEE INT CONF HUM, P305, DOI 10.1145/1957656.1957781
   Schilbach L, 2013, BEHAV BRAIN SCI, V36, P393, DOI 10.1017/S0140525X12000660
   Schmidt A., 2000, Personal Technologies, V4, P191, DOI 10.1007/BF01324126
   Schulman J., 2017, ARXIV
   Shao K, 2019, arXiv preprint arXiv:1912.10944, V1912, P10944
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steed Anthony, 2015, Collaboration in Immersive and Non-immersive Virtual Environments, P263, DOI [DOI 10.1007/978-3-319-10190-3{_}11, 10.1007/978-3-319-10190-3_11, DOI 10.1007/978-3-319-10190-3_11]
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   Wilson G, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P535, DOI 10.1145/3242671.3242684
   Woolf B, 2009, INT J LEARN TECHNOL, V4, P129, DOI 10.1504/IJLT.2009.028804
   Yu C, 2004, ARXIV PREPRINT ARXIV
NR 45
TC 5
Z9 6
U1 4
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1519
EP 1538
DI 10.1007/s10055-022-00644-4
EA APR 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000779611800001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Chang, E
   Kim, HT
   Yoo, B
AF Chang, Eunhee
   Kim, Hyun Taek
   Yoo, Byounghyun
TI Identifying physiological correlates of cybersickness using
   heartbeat-evoked potential analysis
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Heartbeat-evoked potential; Physiological responses;
   Virtual reality
ID VISUALLY INDUCED MOTION; BRAIN RESPONSES; SICKNESS; HABITUATION;
   COMPONENTS; IMMERSION; DYNAMICS; EEG
AB Many studies have consistently proven that repeatedly watching virtual reality (VR) content can reduce cybersickness. Moreover, the discomfort level decreases when the VR content includes an unusual orientation, such as an inverted scene. However, few studies have investigated the physiological changes during these experiences. The present study aimed to identify psychophysiological correlates, especially the neural processing, of cybersickness. Twenty participants experienced two types of VR orientation (upright and inverted), which were repeated three times. During the experience, we recorded the participants' subjective levels of discomfort, brain waves, cardiac signals, and eye trajectories. We performed a heartbeat-evoked potential (HEP) analysis to elucidate the cortical activity of heartbeats while experiencing cybersickness. The results showed that the severity of cybersickness decreased as the participants repeatedly watched the VR content. The participants also reported less nausea when watching the inverted orientation. We only found a significant suppression at the fronto-central HEP amplitudes in the upright orientation for the physiological changes. This study provides a comprehensive understanding of bodily responses to varying degrees of cybersickness. In addition, the HEP results suggest that this approach might reflect the neural correlates of transient changes in heartbeats caused by cybersickness.
C1 [Chang, Eunhee; Yoo, Byounghyun] Korea Inst Sci & Technol, Ctr Artificial Intelligence, 5 Hwarangrol4 Gil, Seoul 02792, South Korea.
   [Kim, Hyun Taek] Korea Univ, Dept Psychol, 145 Anam Ro, Seoul 02841, South Korea.
   [Yoo, Byounghyun] Korea Univ Sci & Technol, KIST Sch, Artificial Intelligence & Robot, 5 Hwarangro 14 Gil, Seoul 02792, South Korea.
C3 Korea Institute of Science & Technology (KIST); Korea University; Korea
   Institute of Science & Technology (KIST)
RP Yoo, B (corresponding author), Korea Inst Sci & Technol, Ctr Artificial Intelligence, 5 Hwarangrol4 Gil, Seoul 02792, South Korea.; Yoo, B (corresponding author), Korea Univ Sci & Technol, KIST Sch, Artificial Intelligence & Robot, 5 Hwarangro 14 Gil, Seoul 02792, South Korea.
EM eunhee.chang@wrl.onl; neurolab@korea.ac.kr; yoo@byoo.net
RI Yoo, Byounghyun/C-8404-2009
OI Yoo, Byounghyun/0000-0001-9299-349X
FU Industrial Technology Innovation Program - Ministry of Trade, Industry &
   Energy (MOTIE, Korea) [20012462]; National Research Foundation of Korea
   (NRF) Grant - Korea government (MSIT) [NRF-2021R1A2C2093065,
   NRF-2021R1A6A3A14039652]
FX This work was supported by the Industrial Technology Innovation Program
   (20012462) funded by the Ministry of Trade, Industry & Energy (MOTIE,
   Korea) and the National Research Foundation of Korea (NRF) Grant
   (NRF-2021R1A2C2093065 and NRF-2021R1A6A3A14039652) funded by the Korea
   government (MSIT).
CR Ahn MH, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.600839
   Arshad Q, 2015, NEUROLOGY, V85, P1257, DOI 10.1212/WNL.0000000000001989
   Baranauskas M, 2017, PHYSIOL BEHAV, V180, P1, DOI 10.1016/j.physbeh.2017.07.032
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bubka A, 2007, AVIAT SPACE ENVIR MD, V78, P383
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chaumon M, 2015, J NEUROSCI METH, V250, P47, DOI 10.1016/j.jneumeth.2015.02.025
   Coll MP, 2021, NEUROSCI BIOBEHAV R, V122, P190, DOI 10.1016/j.neubiorev.2020.12.012
   Couto B, 2015, AUTON NEUROSCI-BASIC, V193, P132, DOI 10.1016/j.autneu.2015.06.006
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Farmer AD, 2015, J PHYSIOL-LONDON, V593, P1183, DOI 10.1113/jphysiol.2014.284240
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Heutink J, 2019, ERGONOMICS, V62, P65, DOI 10.1080/00140139.2018.1518543
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Khoirunnisaa AZ, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (IBIOMED), P48, DOI 10.1109/IBIOMED.2018.8534877
   Kim JY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122501
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Luft CD, 2015, SCI REP-UK, V5, DOI 10.1038/srep15717
   Marshall AC, 2018, SOC COGN AFFECT NEUR, V13, P677, DOI 10.1093/scan/nsy042
   Mathewson KE, 2014, J COGNITIVE NEUROSCI, V26, P2400, DOI 10.1162/jocn_a_00637
   Noguchi K, 2012, J STAT SOFTW, V50, P1, DOI 10.18637/jss.v050.i12
   Park HD, 2019, NEUROIMAGE, V197, P502, DOI 10.1016/j.neuroimage.2019.04.081
   Park HD, 2016, J NEUROSCI, V36, P8453, DOI 10.1523/JNEUROSCI.0311-16.2016
   Regan EC, 1995, DISPLAYS, V16, P135, DOI 10.1016/0141-9382(96)81213-3
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Schulz A, 2013, PSYCHONEUROENDOCRINO, V38, P2686, DOI 10.1016/j.psyneuen.2013.06.027
   Shao SY, 2011, CLIN NEUROPHYSIOL, V122, P1838, DOI 10.1016/j.clinph.2011.02.014
   Solís-Vivanco R, 2018, J COGNITIVE NEUROSCI, V30, P1157, DOI 10.1162/jocn_a_01280
   Song I, 2018, THESIS KOREA U KOREA
   Takeuchi N, 2018, CYBERPSYCH BEH SOC N, V21, P381, DOI 10.1089/cyber.2017.0499
   Taylor LC, 2013, CYBERSICKNESS FOLLOW
   Wei Y, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116028
   Wu JT, 2020, INT J IND ERGONOM, V78, DOI 10.1016/j.ergon.2020.102981
   Zhang H, 2021, INT J HUM-COMPUT ST, V145, DOI 10.1016/j.ijhcs.2020.102521
NR 41
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1193
EP 1205
DI 10.1007/s10055-021-00622-2
EA JAN 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000746301600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Triviño-Tarradas, P
   Mohedo-Gatón, A
   Fernández, REH
   Mesas-Carrascosa, FJ
   Carranza-Cañadas, P
AF Trivino-Tarradas, Paula
   Mohedo-Gaton, Alejandro
   Hidalgo Fernandez, Rafael Enrique
   Mesas-Carrascosa, Francisco-Javier
   Carranza-Canadas, Pilar
TI Preliminary results of the impact of 3D-visualization resources in the
   area of graphic expression on the motivation of university students
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Augmented reality; Motivation level; ARCS model;
   Expression
ID AUGMENTED REALITY; GENDER-DIFFERENCES; VIRTUAL-REALITY; MIXED REALITY;
   EDUCATION; FRAMEWORK; DESIGN
AB Augmented reality and virtual reality are innovative technologies applied to the area of graphic expression with increasing influence on the teaching-learning process. Although these innovative resources enable new forms of teaching, it remains unclear how these artificial applications can impact students' motivation. The aim of this paper was to evaluate how virtual exercises increase the motivation level in different typologies of university students. The sample was composed of graduate (master's degree) and undergraduate students (three engineering degrees) of the University of Cordoba. These tools were available to students through four devices: mobile phones, tablets, computers and virtual reality goggles. The motivation of the students was evaluated through the modified Instructional Materials Motivation Survey by the attention, relevance, confidence and satisfaction motivational model. The results obtained through a 5-point Likert scale showed that these innovative resources significantly improved the students' motivation level, especially concerning the 'relevance' aspect (M = 4.01; SD = 0.98). The virtual resources also increased the understanding of the exercises and their spatial vision (M = 3.80; SD = 1.14). Of the total sample, 63.83% students considered the virtual reality goggles as the most suitable device to visualize graphic expression exercises.
C1 [Trivino-Tarradas, Paula; Hidalgo Fernandez, Rafael Enrique; Mesas-Carrascosa, Francisco-Javier; Carranza-Canadas, Pilar] Univ Cordoba, Dept Graph Engn & Geomat, Campus Rabanales, Cordoba 14071, Spain.
   [Mohedo-Gaton, Alejandro] Andalusian Publ Educ Agcy, Minist Educ & Sport, Cordoba Delegat, Cordoba, Spain.
C3 Universidad de Cordoba
RP Triviño-Tarradas, P (corresponding author), Univ Cordoba, Dept Graph Engn & Geomat, Campus Rabanales, Cordoba 14071, Spain.
EM ig2trtap@uco.es; alejandro.mohedo@juntadeandalucia.es; rhidalgo@uco.es;
   mesas@uco.es; irlcarr@uco.es
OI Trivino Tarradas, Paula Maria/0000-0003-1212-0926
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research is framed within a teaching innovation
   project entitled `Improvements in the teachinglearning process of
   graphic Representation Systems through the use of virtual and augmented
   reality tools.' The project falls in the field of Engineering and
   Architecture studies, which belongs to the Innovation Plan and Best
   Teaching Practices 2019/2020 of the University of Cordoba (Spain) (UCO
   2020).
CR Adanez G.P., 2002, Journal of Geometry and Graphics, V6, P99
   [Anonymous], 2014, INT J ENG EDUC
   [Anonymous], 1997, J ENG EDUC, DOI [10.1002/j.2168-9830.1997.tb00278.x, DOI 10.1002/J.2168-9830.1997.TB00278.X]
   Atsikpasi P, 2022, VIRTUAL REAL-LONDON, V26, P205, DOI 10.1007/s10055-021-00556-9
   Alvarez FJA, 2017, J VISUAL-JAPAN, V20, P889, DOI 10.1007/s12650-017-0424-8
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01486
   Balsam P, 2019, CARDIOL J, V26, P260, DOI 10.5603/CJ.a2017.0154
   Baranová L, 2018, ANN MATH INFORM, V49, P21, DOI 10.33039/ami.2018.04.001
   Barton BA, 2021, ACT LEARN HIGH EDUC, V22, P11, DOI 10.1177/1469787418782817
   Bazarov SE, 2017, IOP C SER EARTH ENV, V87, DOI 10.1088/1755-1315/87/3/032004
   Bennett S, 2008, BRIT J EDUC TECHNOL, V39, P775, DOI 10.1111/j.1467-8535.2007.00793.x
   Biyun Huang, 2016, International Journal of Information and Education Technology, V9, P759, DOI 10.7763/IJIET.2016.V6.788
   Bolliger DU, 2010, COMPUT EDUC, V55, P714, DOI 10.1016/j.compedu.2010.03.004
   Cabero-Almenara J, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11184990
   Cabero-Almenara J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142907
   Carbonell-Carrera C, 2018, EURASIA J MATH SCI T, V14, P709, DOI 10.12973/ejmste/79171
   Caspi A, 2008, COMPUT EDUC, V50, P718, DOI 10.1016/j.compedu.2006.08.003
   Chang SC, 2018, COMPUT EDUC, V125, P226, DOI 10.1016/j.compedu.2018.06.007
   Chester I, 2007, INT J TECHNOL DES ED, V17, P23, DOI 10.1007/s10798-006-9015-z
   Cook DA, 2009, ACAD MED, V84, P1505, DOI 10.1097/ACM.0b013e3181baf56d
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Duffy G, 2020, J ENG EDUC, V109, P424, DOI 10.1002/jee.20349
   Dunleavy M, 2014, TECHTRENDS, V58, P28, DOI 10.1007/s11528-013-0717-2
   Encheva M, 2017, ICERI PROC, P3703
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Gerson HBP, 2001, COMPUT APPL ENG EDUC, V9, P105, DOI 10.1002/cae.1012
   de Ravé EG, 2016, MULTIMED TOOLS APPL, V75, P9641, DOI 10.1007/s11042-016-3384-4
   Hanafi HF, 2017, IOP CONF SER-MAT SCI, V226, DOI 10.1088/1757-899X/226/1/012114
   Heen Chen, 2011, Proceedings of the 2011 International Symposium on Information Technology in Medicine and Education (ITME 2011), P362, DOI 10.1109/ITiME.2011.6132125
   Herayanti, 2017, INT C TEACH TRAIN ED
   Huerta O., 2019, P CAD 2019, P363, DOI [10.14733/cadconfP.2019.363-366, DOI 10.14733/CADCONFP.2019.363-366]
   Hwang A, 2009, J COMPUT ASSIST LEAR, V25, P280, DOI 10.1111/j.1365-2729.2009.00311.x
   Ibáñez MB, 2018, COMPUT EDUC, V123, P109, DOI 10.1016/j.compedu.2018.05.002
   Johnson M., 2012, Journal of language and culture of Hokkaido, V10, P39
   Kahle JN, 1983, AETS OUTSTANDING PAP
   Keller J. M., 1987, Journal of Instructional Development, V10, P2, DOI [10.1007/BF02905780, DOI 10.1007/BF02905780]
   Keller JM, 2010, MOTIVATIONAL DESIGN FOR LEARNING AND PERFORMANCE: THE ARCS MODEL APPROACH, P43, DOI 10.1007/978-1-4419-1250-3_3
   Kesim M, 2012, PROCD SOC BEHV, V47, P297, DOI 10.1016/j.sbspro.2012.06.654
   Kew SN, 2018, EDUC INF TECHNOL, V23, P2947, DOI 10.1007/s10639-018-9753-z
   Kim Y, 2006, ETR&D-EDUC TECH RES, V54, P569, DOI 10.1007/s11423-006-0637-3
   Kim Y, 2013, J EDUC PSYCHOL, V105, P1164, DOI 10.1037/a0031027
   Koeva M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040829
   Kugelmann D, 2018, ANN ANAT, V215, P71, DOI 10.1016/j.aanat.2017.09.011
   Lau KW, 2021, VIRTUAL REAL-LONDON, V25, P985, DOI 10.1007/s10055-021-00504-7
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Leontitsis A, 2007, MATH COMPUT SIMULAT, V73, P336, DOI 10.1016/j.matcom.2006.08.001
   Lin CF, 2010, NURS ETHICS, V17, P373, DOI 10.1177/0969733009355380
   LORD TR, 1985, J RES SCI TEACH, V22, P395, DOI 10.1002/tea.3660220503
   Mayrose J., 2012, American Journal of Engineering Education (AJEE), V3, P13, DOI DOI 10.19030/AJEE.V3I1.6885
   Me FF, 2015, INTERNET HIGH EDUC, V26, P33, DOI 10.1016/j.iheduc.2015.04.003
   Melian-Melian JA, 2018, COMPUT APPL ENG EDUC, V26, P1134, DOI 10.1002/cae.21946
   Millar R., 2004, ROLE PRACTICAL WORK
   MORRISON GR, 1994, ETR&D-EDUC TECH RES, V42, P41, DOI 10.1007/BF02299090
   Olmedo-Torre N, 2017, PROCD SOC BEHV, V237, P737, DOI 10.1016/j.sbspro.2017.02.115
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Park KB, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101887
   Parras-Burgos D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103632
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Petersen GB, 2020, BRIT J EDUC TECHNOL, V51, P2098, DOI 10.1111/bjet.12991
   Prasolova-Forland E, 2017, PR IEEE INT CONF TEA, P461, DOI 10.1109/TALE.2017.8252380
   Prince M, 2004, J ENG EDUC, V93, P223, DOI 10.1002/j.2168-9830.2004.tb00809.x
   Prince MJ, 2006, J ENG EDUC, V95, P123, DOI 10.1002/j.2168-9830.2006.tb00884.x
   Rodgers D.L., 2005, INT J INSTRUCTIONAL, V32, P333
   Serin H, 2020, AMAZON INVESTIG, V9, P291
   Sha L, 2012, COMPUT HUM BEHAV, V28, P718, DOI 10.1016/j.chb.2011.11.019
   Sorby S.A., 2000, Journal of Engineering Education, V89, P301, DOI [10.1002/j.2168-9830.2000.tb00529.x, DOI 10.1002/J.2168-9830.2000.TB00529.X]
   Sorby S, 2009, INT J SCI EDUC, V31, P459, DOI 10.1080/09500690802595839
   Starr CR, 2019, J SCI EDUC TECHNOL, V28, P493, DOI 10.1007/s10956-019-09781-z
   Stone R.J., 1995, Word Class Design to Manufacture, V2, P11, DOI DOI 10.1108/09642369310091106
   Tallent-Runnels MK, 2006, REV EDUC RES, V76, P93, DOI 10.3102/00346543076001093
   Tang TLP, 2009, COMPUT EDUC, V53, P1241, DOI 10.1016/j.compedu.2009.06.007
   Taran CN, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P617, DOI 10.1109/ICALT.2005.206
   Tumkor S, 2018, COMPUT APPL ENG EDUC, V26, P1734, DOI 10.1002/cae.21942
   UCO, 2020, FIN RES TEACH INN PL
   Viegas C, 2018, COMPUT EDUC, V126, P201, DOI 10.1016/j.compedu.2018.07.012
   Villa V, 2018, COMPUT APPL ENG EDUC, V26, P1293, DOI 10.1002/cae.22022
   Wojciechowski R, 2013, COMPUT EDUC, V68, P570, DOI 10.1016/j.compedu.2013.02.014
   Yukselturk E, 2009, EDUC TECHNOL SOC, V12, P12
   Zgoul MH, 2009, INT J EMERG TECHNOL, V4, P40, DOI 10.3991/ijet.v4i3.639
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   ZIMMERMAN BJ, 1989, J EDUC PSYCHOL, V81, P329, DOI 10.1037/0022-0663.81.3.329
NR 83
TC 1
Z9 1
U1 6
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 963
EP 978
DI 10.1007/s10055-021-00606-2
EA NOV 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000722996900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Hogan, C
   Cornwell, P
   Fleming, J
   Man, DWK
   Shum, DHK
AF Hogan, Christy
   Cornwell, Petrea
   Fleming, Jennifer
   Man, David W. K.
   Shum, David H. K.
TI Assessment of prospective memory after stroke utilizing virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Memory; Stroke; Psychometrics; Neuropsychological test
ID MONTREAL COGNITIVE ASSESSMENT; TRAUMATIC BRAIN-INJURY; RETRIEVAL;
   PEOPLE; TASK; REHABILITATION; IMPAIRMENTS; REALIZATION; VERSION
AB Prospective Memory (PM) is the ability to remember to do something in the future. It is often impaired after stroke and can impact on an individual's level of independence and daily functioning. PM tasks have been criticized for their lack of ecological validity wherein test results may not be related to actual performance in daily life. With ecological validity in mind, the Virtual Reality Prospective Memory Shopping Task (VRPMST) was designed to assess two types of PM, time- and event-based. This study aimed to examine the ecological and convergent validity of the VRPMST in comparison to an experimental (Lexical Decision PM Task) and clinical measure of PM (Cambridge PM Test). Twelve individuals with stroke and 12 controls were administered three PM measures, three neuropsychological measures, and two user-friendliness questionnaires, one for the experimental PM measure and one for the VRPMST. Individuals with stroke showed impairments in PM compared to controls on all three PM measures, particularly time-based PM. Individuals with stroke were found to monitor time significantly less than controls on both the experimental PM measure and the VRPMST. The VRPMST was found to be sensitive in measuring PM, have better ecological validity when compared to the experimental PM measure, and good convergent validity. The findings of this study have helped to clarify that PM impairment does exist after stroke, possibly due to a problem in strategic monitoring. In addition, we have demonstrated how VR technology can be used to design a measure of cognitive function commonly impaired after stroke.
C1 [Hogan, Christy] Griffith Univ, Sch Appl Psychol, Menzies Hlth Inst Queensland, Brisbane, Qld, Australia.
   [Hogan, Christy] Griffith Univ, Hopkins Ctr, Menzies Hlth Inst Queensland, Brisbane, Qld, Australia.
   [Cornwell, Petrea] Griffith Univ, Menzies Hlth Inst Queensland, Sch Hlth Sci & Social Work, Prince Charles Hosp,Metro North Hosp & Hlth Serv, Brisbane, Qld, Australia.
   [Fleming, Jennifer] Univ Queensland, Sch Hlth & Rehabil Sci, Brisbane, Qld, Australia.
   [Man, David W. K.; Shum, David H. K.] Hong Kong Polytech Univ, Dept Rehabil Sci, Hung Hom, Kowloon, Hong Kong, Peoples R China.
   [Shum, David H. K.] Griffith Univ, Sch Appl Psychol, Brisbane, Qld, Australia.
C3 Griffith University; Menzies Health Institute Queensland; Menzies Health
   Institute Queensland; Griffith University; Griffith University; Prince
   Charles Hospital; Menzies Health Institute Queensland; University of
   Queensland; Hong Kong Polytechnic University; Griffith University
RP Man, DWK; Shum, DHK (corresponding author), Hong Kong Polytech Univ, Dept Rehabil Sci, Hung Hom, Kowloon, Hong Kong, Peoples R China.; Shum, DHK (corresponding author), Griffith Univ, Sch Appl Psychol, Brisbane, Qld, Australia.
EM david.shum@polyu.edu.hk
RI Fleming, Jennifer/AAH-5108-2020; Shum, David H. K./A-3914-2008; Man,
   David/H-4976-2014
OI Fleming, Jennifer/0000-0002-5603-2410; Shum, David H.
   K./0000-0002-4810-9262; Man, David/0000-0002-6248-4712; Hogan,
   Christy/0000-0001-7325-9695
FU Griffith University Post-graduate Scholarship
FX This work was supported by a Griffith University Post-graduate
   Scholarship.
CR Andrews G, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01032
   Andrews G, 2014, BRAIN INJURY, V28, P442, DOI 10.3109/02699052.2014.888758
   Banville F., 2012, Journal of CyberTherapy and Rehabilitation, V5, P45
   Barr AC, 2011, THESIS U EDINBURGH
   Benedict RHB, 1998, CLIN NEUROPSYCHOL, V12, P43, DOI 10.1076/clin.12.1.43.1726
   Brooks BM, 2004, BRAIN INJURY, V18, P391, DOI 10.1080/02699050310001619855
   Burgess PW, 2011, NEUROPSYCHOLOGIA, V49, P2246, DOI 10.1016/j.neuropsychologia.2011.02.014
   Canty AL, 2017, NEUROPSYCHOL REHABIL, V27, P834, DOI 10.1080/09602011.2015.1052820
   Canty AL, 2014, NEUROPSYCHOL REHABIL, V24, P238, DOI 10.1080/09602011.2014.881746
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Cheng HD, 2010, BEHAV NEUROSCI, V124, P152, DOI 10.1037/a0018306
   Cohen J., 1988, STAT POWER ANAL BEHA
   Corporation IBM., 2017, IBM SPSS STAT VERS 2
   Cumming TB, 2011, STROKE, V42, P2642, DOI 10.1161/STROKEAHA.111.619486
   Debarnot U, 2015, NEUROBIOL AGING, V36, P2360, DOI 10.1016/j.neurobiolaging.2015.05.001
   EINSTEIN GO, 1995, J EXP PSYCHOL LEARN, V21, P996, DOI 10.1037/0278-7393.21.4.996
   EINSTEIN GO, 1990, J EXP PSYCHOL LEARN, V16, P717, DOI 10.1037/0278-7393.16.4.717
   Ellis J, 1996, Q J EXP PSYCHOL-A, V49, P862, DOI 10.1080/027249896392333
   Fish J, 2007, NEUROPSYCHOLOGIA, V45, P1318, DOI 10.1016/j.neuropsychologia.2006.09.015
   Fleming J, 2008, J INT NEUROPSYCH SOC, V14, P823, DOI 10.1017/S1355617708080971
   Gonneaud J., 2014, INT J CHILD HLTH HUM, V7, P405
   Hogan C, 2020, J INT NEUROPSYCH SOC, V26, P873, DOI 10.1017/S1355617720000405
   Hogan C, 2016, BRAIN IMPAIR, V17, P123, DOI 10.1017/BrImp.2016.12
   Hu Q., 2010, Encyclopedia of Research Design, P408, DOI [DOI 10.4135/9781412961288.N128, DOI 10.4135/9781412961288]
   Kant N, 2014, NEUROPSYCHOLOGIA, V60, P77, DOI 10.1016/j.neuropsychologia.2014.05.015
   Kim HJ, 2009, NEUROCASE, V15, P145, DOI 10.1080/13554790802709039
   Kinsella GJ, 2009, BRAIN IMPAIR, V10, P45, DOI 10.1375/brim.10.1.45
   Kliegel M, 2004, BRAIN COGNITION, V56, P43, DOI 10.1016/j.bandc.2004.05.005
   Knight RG, 2009, BRAIN IMPAIR, V10, P3, DOI 10.1375/brim.10.1.3
   Kurtz MM, 2007, SCHIZOPHRENIA BULL, V33, P1162, DOI 10.1093/schbul/sbl039
   Kvavilashvili L., 1996, PROSPECTIVE MEMORY, P23
   Kvavilashvili L, 2009, MEMORY, V17, P180, DOI 10.1080/09658210802194366
   Man D, 2015, BRAIN INJURY, V29, P329, DOI 10.3109/02699052.2014.974672
   Man DWK, 2018, NEUROPSYCHOL REHABIL, V28, P1197, DOI 10.1080/09602011.2016.1251949
   Man DWK, 2015, NEUROPSYCHOL REHABIL, V25, P895, DOI 10.1080/09602011.2014.997253
   Martin M, 2003, INT J PSYCHOL, V38, P195, DOI 10.1080/00207590344000123
   Maujean A., 2003, Brain Impairment, V4, P135, DOI [10.1375/brim.4.2.135.27024, DOI 10.1375/BRIM.4.2.135.27024]
   McDaniel MA, 2000, APPL COGNITIVE PSYCH, V14, pS127, DOI 10.1002/acp.775
   Mitrovic A, 2014, M US MOD AD PERS DEN
   Mitrovic A, 2016, J APPL RES MEM COGN, V5, P204, DOI 10.1016/j.jarmac.2016.03.006
   Morris R, 2002, M INT C DIS VIRT REA
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nouri FM, 1987, Clin Rehabil, V1, P301, DOI DOI 10.1177/026921558700100409
   Otani H, 1997, MEMORY, V5, P343, DOI 10.1080/741941393
   RANKIN J, 1957, Scott Med J, V2, P200
   Rastle K, 2002, Q J EXP PSYCHOL-A, V55, P1339, DOI 10.1080/02724980244000099
   Reitan R.M., 1992, Trail Making Test: Manual for Administration and Scoring
   Rendell PG, 2009, BRAIN IMPAIR, V10, P14, DOI 10.1375/brim.10.1.14
   Rose FD, 1999, DISABIL REHABIL, V21, P548
   Shum D., 2002, BRAIN IMPAIR, V3, P1, DOI [DOI 10.1375/BRIM.3.1.1, 10.1375/brim.3.1]
   Smith RE, 2003, J EXP PSYCHOL LEARN, V29, P347, DOI 10.1037/0278-7393.29.3.347
   Sweeney S, 2010, NEUROPSYCHOL REHABIL, V20, P239, DOI 10.1080/09602010903080531
   Wechsler D., 2011, Test of Premorbid Functioning, VUK
   Wilson B., 1985, RIVERMEAD BEHAV MEMO
   Wilson BA, 2005, The Cambridge prospective memory test: CAMPROMPT
   WILSON M, 1988, BEHAV RES METH INS C, V20, P6, DOI 10.3758/BF03202594
   Yip BCB, 2013, NEUROREHABILITATION, V32, P103, DOI [10.3233/NRE-130827, 10.3233/NRE-30827]
NR 57
TC 7
Z9 7
U1 5
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 333
EP 346
DI 10.1007/s10055-021-00576-5
EA SEP 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000694787000001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Otsuki, M
   Sugihara, K
   Toda, A
   Shibata, F
   Kimura, A
AF Otsuki, Mai
   Sugihara, Kenji
   Toda, Azusa
   Shibata, Fumihisa
   Kimura, Asako
TI A brush device with visual and haptic feedback for virtual painting of
   3D virtual objects
SO VIRTUAL REALITY
LA English
DT Article
DE Painting system; Mixed reality; Augmented reality; Input device;
   Paintbrush; Visual and haptic feedback
AB We have previously developed a mixed reality (MR) painting system with which a user could take a physical object in the real world and apply virtual paint to it. However, this system could not provide the sensation of painting on virtual objects in MR space. Therefore, we subsequently proposed and developed mechanisms that simulated the effect of touch and movement when a brush device was used to paint on a virtual canvas. In this paper, we use visual and haptic feedback to provide the sensation of painting on virtual three-dimensional objects using a new brush device called the MAI Painting Brush++. We evaluate and confirm its effectiveness through several user studies.
C1 [Otsuki, Mai] Univ Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058571, Japan.
   [Sugihara, Kenji; Toda, Azusa; Shibata, Fumihisa; Kimura, Asako] Ritsumeikan Univ, 1-1-1 Noji Higashi, Kusatsu, Shiga 5258577, Japan.
C3 University of Tsukuba; Ritsumeikan University
RP Otsuki, M (corresponding author), Univ Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058571, Japan.
EM otsuki@emp.tsukuba.ac.jp; fshibata@is.ritsumei.ac.jp;
   asa@rm.is.ritsumei.ac.jp
RI Otsuki, Mai/N-8485-2019
OI Otsuki, Mai/0000-0001-8303-465X
FU Grants-in-Aid for Scientific Research [16H02861] Funding Source: KAKEN
CR Bau Olivier, 2012, ACM SIGGRAPH 2012 EM
   Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Baxter William., 2004, Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, P45
   Chu NS-H, 2005, ACM SIGGRAPH 2005 SK, DOI 10.1145/1187112.1187186
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Foskey M, 2005, ACM SIGGRAPH 2005 CO, DOI 10.1145/1198555.1198619
   Gooch B., 2001, Non-photorealistic rendering
   Iwai D., 2005, Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology, P213
   Kamuro Sho, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P436, DOI 10.1109/ROMAN.2009.5326217
   Kamuro S, 2011, P IEEE VIRT REAL ANN, P217, DOI 10.1109/VR.2011.5759476
   Kato G, 2015, SIGGRAPH ASIA 2015 HAPTIC MEDIA AND CONTENTS DESIGN (SA'15), DOI 10.1145/2818384.2818387
   KIM HJ, 2013, CHI 13 EXTENDED ABST, P94, DOI DOI 10.1145/2468356.2468525
   Liu Xin, 2013, P 8 INT C TANG EMB E, P39, DOI [10.1145/2540930.2540982, DOI 10.1145/2540930.2540982]
   Otsuki M., 2010, Proceedings of the 23nd annual ACM symposium on User interface software and technology, P97, DOI [10.1145/1866029, DOI 10.1145/1866029.1866045]
   Ryokai K., 2004, CHI 04, P303, DOI DOI 10.1145/985692.985731
   Saito Suguru., 1999, SIGGRAPH conference abstracts and applications, P226
   Sandor C, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P292
   Vandoren Peter., 2009, Proceedings of the ACM Conference on Interactive Tabletops and Surfaces, P53
   Yeom Jiho, 2012, P 10 AS PAC C COMP H, P219, DOI [10.1145/2350046.2350091, DOI 10.1145/2350046.2350091]
NR 19
TC 8
Z9 9
U1 2
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2018
VL 22
IS 2
SI SI
BP 167
EP 181
DI 10.1007/s10055-017-0317-0
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GC5KP
UT WOS:000429826700007
DA 2024-07-18
ER

PT J
AU Berg, LP
   Vance, JM
AF Berg, Leif P.
   Vance, Judy M.
TI Industry use of virtual reality in product design and manufacturing: a
   survey
SO VIRTUAL REALITY
LA English
DT Article
AB In 1999, Fred Brooks, virtual reality pioneer and Professor of Computer Science at the University of North Carolina at Chapel Hill, published a seminal paper describing the current state of virtual reality (VR) technologies and applications (Brooks in IEEE Comput Graph Appl 19(6):16, 1999). Through his extensive survey of industry, Brooks concluded that virtual reality had finally arrived and "barely works". His report included a variety of industries which leveraged these technologies to support industry-level innovation. Virtual reality was being employed to empower decision making in design, evaluation, and training processes across multiple disciplines. Over the past two decades, both industrial and academic communities have contributed to a large knowledge base on numerous virtual reality topics. Technical advances have enabled designers and engineers to explore and interact with data in increasingly natural ways. Sixteen years have passed since Brooks original survey. Where are we now? The research presented here seeks to describe the current state of the art of virtual reality as it is used as a decision-making tool in product design, particularly in engineering-focused businesses. To this end, a survey of industry was conducted over several months spanning fall 2014 and spring 2015. Data on virtual reality applications across a variety of industries was gathered through a series of on-site visits. In total, on-site visits with 18 companies using virtual reality were conducted as well as remote conference calls with two others. The authors interviewed 62 people across numerous companies from varying disciplines and perspectives. Success stories and existing challenges were highlighted. While virtual reality hardware has made considerable strides, unique attention was given to applications and the associated decisions that they support. Results suggest that virtual reality has arrived: it works! It is mature, stable, and, most importantly, usable. VR is actively being used in a number of industries to support decision making and enable innovation. Insights from this survey can be leveraged to help guide future research directions in virtual reality technology and applications.
C1 [Berg, Leif P.; Vance, Judy M.] Iowa State Univ, 2644 Howe Hall, Ames, IA 50011 USA.
C3 Iowa State University
RP Vance, JM (corresponding author), Iowa State Univ, 2644 Howe Hall, Ames, IA 50011 USA.
EM leif.berg@gmail.com; jmvance@iastate.edu
OI Vance, Judy/0000-0001-9801-191X
FU National Science Foundation [CMMI-1068926]
FX The authors would like to thank Kurt Hoffmeister for his indispensable
   guidance during the planning, execution, and analysis stages of this
   work and Adam Carlson for his initial data analysis of VR use in
   industry. This material is based upon work supported by the National
   Science Foundation under Grant # CMMI-1068926. Any opinions, findings,
   and conclusions or recommendations expressed in this material are those
   of the authors and do not necessarily reflect the views of the National
   Science Foundation. This work was completed at the Virtual Reality
   Applications Center at Iowa State University.
CR ADAM JA, 1993, IEEE SPECTRUM, V30, P22, DOI 10.1109/6.237580
   [Anonymous], 2014, BASICS QUALITATIVE R
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   BOMAN DK, 1995, COMPUTER, V28, P57, DOI 10.1109/2.386986
   Bowman D., 2001, Proc. HCII, P629
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Bowman DA, 2008, IEEE COMPUT GRAPH, V28, P20, DOI 10.1109/MCG.2008.109
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Dachselt R, 2007, COMPUT GRAPH-UK, V31, P53, DOI 10.1016/j.cag.2006.09.006
   Kindratenko V. V., 2000, Virtual Reality, V5, P169, DOI 10.1007/BF01409422
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Laycock S. D., 2007, Computer Graphics Forum, V26, P50, DOI 10.1111/j.1467-8659.2007.00945.x
   Liu A, 2003, PRESENCE-VIRTUAL AUG, V12, P599, DOI 10.1162/105474603322955905
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Mobach Mark P., 2008, Virtual Reality, V12, P163, DOI 10.1007/s10055-008-0081-2
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Morganti F, 2007, COMPUT HUM BEHAV, V23, P1982, DOI 10.1016/j.chb.2006.02.006
   Ni T, 2006, P IEEE VIRT REAL ANN, P223
   Packer R., 2002, Multimedia: From Wagner to Virtual Reality
   Peter Z., 2008, PRODUCT ENG TOOLS ME, P277
   Pinho M. S., 2002, VRST 02, P171
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rolland JP, 2001, FUNDAMENTALS OF WEARABLE COMPUTERS AND AUGMENTED REALITY, P67
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Subramanian S., 2000, P OZCHI 2000, P330
   van Dam A, 2000, IEEE COMPUT GRAPH, V20, P26, DOI 10.1109/38.888006
   Venugopal K., 2012, INT J COMPUT SCI ISS, V9, P234
   Whyte J., 1999, Engineering, Construction and Architectural Management, V6, P371, DOI [DOI 10.1108/EB021125, 10.1108/eb021125]
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
NR 34
TC 384
Z9 418
U1 21
U2 152
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2017
VL 21
IS 1
BP 1
EP 17
DI 10.1007/s10055-016-0293-9
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA EN6MV
UT WOS:000396119000001
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Postma, BNJ
   Katz, BFG
AF Postma, Barteld N. J.
   Katz, Brian F. G.
TI Creation and calibration method of acoustical models for historic
   virtual reality auralizations
SO VIRTUAL REALITY
LA English
DT Article
DE Auditory VR; Calibration; Acoustic archeology; Auralization; Geometrical
   acoustics; Virtual heritage
AB Virtual reality provides the possibility for interactive visits to historic buildings and sites. The majority of current virtual reconstructions have focused on creating realistic virtual environments, by concentrating on the visual component. However, by incorporating more authentic acoustical properties into visual models, a more realistic rendering of the studied venue is achieved. In historic auralizations, calibration of the studied building's room acoustic simulation model is often necessary to come to a realistic representation of its acoustical environment. This paper presents a methodical calibration procedure for geometrical acoustics models using room acoustics prediction programs based on geometrical acoustics to create realistic virtual audio realities, or auralizations. To develop this procedure, a small unfinished amphitheater was first chosen due to its general simplicity and considerable level of reverberation. A geometrical acoustics model was calibrated according to the results of acoustical measurements. Measures employed during the calibration of this model were analyzed to come to a methodical calibration procedure. The developed procedure was then applied to a more complex building, the abbey church Saint-Germaindes-Pre's. A possible application of the presented procedure is to enable interactive acoustical visits of former configurations of buildings. A test case study was carried out for a typical seventeenth-century configuration of the Saint-Germain-des-Pre's.
C1 [Postma, Barteld N. J.; Katz, Brian F. G.] CNRS, LIMSI, F-91405 Orsay, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS)
RP Postma, BNJ (corresponding author), CNRS, LIMSI, Rue John Neumann,Campus Univ Orsay,Bat 508, F-91405 Orsay, France.
EM postma@limsi.fr
RI Katz, Brian F.G./I-3191-2012
OI Katz, Brian F.G./0000-0001-5118-0943
FU ECHO Project [ANR-13-CULT-0004]; Agence Nationale de la Recherche (ANR)
   [ANR-13-CULT-0004] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX This work was funded in part by the ECHO Project (ANR-13-CULT-0004,
   echo-projet.limsi.fr). Partners include THALIM/ARIAS-CNRS, Bibliotheque
   nationale de France (BnF), and LIMSI-CNRS.
CR [Anonymous], BNAM
   [Anonymous], P FOR AC
   [Anonymous], BALT NORD AC M
   [Anonymous], P IEEE VR
   [Anonymous], EXPLORATION VIRTUAL
   [Anonymous], 95582 NPL
   [Anonymous], ANN ABB SAINT GERM D
   [Anonymous], P I ACOUST
   [Anonymous], PAR 3D
   [Anonymous], BLEND C 2014
   [Anonymous], P ICA
   [Anonymous], PARIS VILLE REMONTER
   [Anonymous], 19 INT C AC
   [Anonymous], 2008, J ACOUST SOC AM
   [Anonymous], 2002, AUD ENG SOC C 21 INT
   [Anonymous], P FOR AC
   [Anonymous], P CIPA S
   [Anonymous], VIRT NEW AMST PROT
   [Anonymous], P 108 AES CONV LOND
   [Anonymous], P FOR AC
   [Anonymous], 2009, ISO 3382-1:2009
   [Anonymous], P INT S ROOM AC
   [Anonymous], P 98 AES CONV
   [Anonymous], P FOR AC
   [Anonymous], BLEND C 2013
   [Anonymous], P FOR AC
   [Anonymous], P FOR AC
   [Anonymous], 17497 ISO
   [Anonymous], P INT C AUD DISPL
   [Anonymous], 128 CONV AUD ENG SOC
   Beranek L.L., 1986, ACOUSTICS
   Beranek Leo., 1996, THEY SOUND CONCERT O
   Bradley JS, 1999, APPL ACOUST, V58, P99, DOI 10.1016/S0003-682X(98)00075-9
   COX TJ, 1993, ACUSTICA, V79, P27
   Dalenback B., 2011, CATT A V9 USERS MANU
   Katz BFG, 2000, J ACOUST SOC AM, V108, P2238, DOI 10.1121/1.1314319
   Katz BFG, 2000, J ACOUST SOC AM, V108, P2231, DOI 10.1121/1.1314318
   Katz BFG, 2004, ACOUST RES LETT ONL, V5, P158, DOI 10.1121/1.1758239
   Katz BFG, 2001, J ACOUST SOC AM, V110, P2449, DOI 10.1121/1.1412441
   KLEINER M, 1993, J AUDIO ENG SOC, V41, P861
   Pulkki V, 2003, ACOUST RES LETT ONL, V4, P118, DOI 10.1121/1.1605131
   Seraphim H., 1958, Acustica, V8, P280
   Vorlander M., 2008, Auralizations: Fundamentals of Acoustics, Modelling, Simulation, Algorithms and Acoustic Virtual Reality
   Wright Craig., 2008, MUSIC CEREMONY NOTRE
   Zeng XY, 2006, APPL ACOUST, V67, P771, DOI 10.1016/j.apacoust.2005.12.001
NR 45
TC 49
Z9 49
U1 1
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 161
EP 180
DI 10.1007/s10055-015-0275-3
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800003
DA 2024-07-18
ER

PT J
AU Tremblay, L
   Chebbi, B
   Bouchard, S
   Cimon-Lambert, K
   Carmichael, J
AF Tremblay, Line
   Chebbi, Brahim
   Bouchard, Stephane
   Cimon-Lambert, Krystel
   Carmichael, Jessica
TI Learning disabilities and visual-motor skills; comparing assessment from
   a hapto-virtual reality tool and Bender-Gestalt test
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Haptics; Learning disability; Visual-motor skills;
   Bender-Gestalt test
ID POSTSECONDARY STUDENTS; ASSISTIVE TECHNOLOGY; DEVELOPMENTAL DYSLEXIA;
   PERFORMANCE; CHILDREN; ENVIRONMENTS; LANGUAGE; IMPAIRMENT; CAFFEINE;
   ADULTS
AB Previous investigations conducted on post-secondary adult students with learning disabilities (LD) suggest that deficits in visual-motor skills contribute to difficulties in written expression which impact academic achievement. Intervention strategies for individuals with LD include assistive computer-based technologies (ATs) to compensate for or maximize performance. However, research fails to assess the impact of ATs on performance, learning, and motivation of students with LD. Also, one of the limitations of ATs is that they cannot be used for assessment and training and there are very few methods to assess or train visual-motor skills in this population. The present study explores the usefulness of a hapto-visual virtual reality motor skills assessment (MSA) device for visual-motor functioning in adults with and without LD. This is a preliminary step of developing an intervention to improve impaired visual-motor skills in adults with LD. A sample of 22 male and female university students with and without LD had their visual-motor skills pretested using a standard paper-and-pencil Bender-Gestalt (BG) test and were compared according to their performance on the MSA tool. We hypothesized that our LD participants' performance would be significantly lower than our control participants on the VR task in terms of number of errors and speed. Results showed that participants without LD performed better and more rapidly on the VR task than participants with LD. There were no correlations between the BG and MSA performance. We did not find significant differences between the groups on the Bender-Gestalt scores, previous experience with video game, arousal, and mood. Our results suggest that a novel 3D virtual reality tool such as the MSA can potentially discriminate motor function of people with and without LD; however, the difference between both may also be due to a lack of problem-solving ability in LD.
C1 [Tremblay, Line; Chebbi, Brahim; Cimon-Lambert, Krystel; Carmichael, Jessica] Laurentian Univ, Sudbury, ON P3E 2C6, Canada.
   [Bouchard, Stephane] Univ Quebec Outaouais, Gatineau, PQ, Canada.
C3 Laurentian University; University of Quebec; University Quebec Outaouais
RP Tremblay, L (corresponding author), Laurentian Univ, Sudbury, ON P3E 2C6, Canada.
EM ltremblay@laurentian.ca
OI Bouchard, Stephane/0000-0002-5995-340X
FU Natural Sciences and Engineering Research Council of Canada, Canada
   Research Chair; Health Canada; Consortium national de formation en sante
   (CNFS)
FX This project was financially supported by the Natural Sciences and
   Engineering Research Council of Canada, Canada Research Chair (S.
   Bouchard), and by Health Canada and the "Consortium national de
   formation en sante (CNFS)." The views are not necessarily Health
   Canada's. The authors thank Jason Morin, learning strategist for
   Laurentian University Accessibility Services, for helping with
   participants' recruitment.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Anastasi A., 1997, Psychological testing, V7e
   [Anonymous], 2006, The Beery-Buktenica Developmental Test of Visual-Motor Integration with supplemental developmental tests of visual perception and motor coordination: Administration, scoring and teaching manual
   APA A.P. A., 2000, Diagnostic and statistical manual of mental disorders: DSM-IV, V4th
   Bahr CM, 1996, J LEARN DISABIL, V29, P355, DOI 10.1177/002221949602900404
   Bara F, 2007, BRIT J DEV PSYCHOL, V25, P643, DOI 10.1348/026151007X186643
   Bara F, 2011, HUM MOVEMENT SCI, V30, P745, DOI 10.1016/j.humov.2010.05.015
   Bazinet P, 2011, J CYBERTHERAPY REHAB, V4, P264
   Beck R.C., 2004, Motivation theories and principles, V5th
   BENDER L, 1970, J SPEC EDUC, V4, P29, DOI 10.1177/002246697000400104
   Brannigan G.G., 2003, Bender Visual-Motor Gestalt Test, VSecond
   Brooks BM, 2002, DISABIL REHABIL, V24, P622, DOI 10.1080/09638280110111397
   Brown SA, 2008, HUM SOC SCI, V69, P177
   Brown T, 2009, AUST OCCUP THER J, V56, P393, DOI 10.1111/j.1440-1630.2009.00811.x
   CARTER JL, 1985, J LEARN DISABIL, V18, P213, DOI 10.1177/002221948501800406
   Chebbi B, 2009, ROBOTICS AUTOMATION, V1, P3
   Cromby J.J., 1996, P 1 ST EUROPEAN C DI, P103
   Dawson D, 1997, NATURE, V388, P235, DOI 10.1038/40775
   Day SL, 1996, J LEARN DISABIL, V29, P486, DOI 10.1177/002221949602900503
   DEMOJA CA, 1985, PERCEPT MOTOR SKILL, V61, P747, DOI 10.2466/pms.1985.61.3.747
   Draffan EA, 2007, DISABIL REHABIL-ASSI, V2, P105, DOI 10.1080/17483100601178492
   Dumas J.E., 2003, ABNORMAL CHILD ADOLE
   Duran LJ, 1996, ARCH PHYS MED REHAB, V77, P1019, DOI 10.1016/S0003-9993(96)90062-3
   Durand M., 2005, Educational and Child Psychology, V22, P90, DOI [10.53841/bpsecp.2005.22.2.90, DOI 10.53841/BPSECP.2005.22.2.90]
   Estil LB, 2003, INFANT CHILD DEV, V12, P253, DOI 10.1002/icd.289
   FREWER LJ, 1991, HUM PSYCHOPHARM CLIN, V6, P119, DOI 10.1002/hup.470060206
   Getchell N, 2005, ADAPT PHYS ACT Q, V22, P21, DOI 10.1123/apaq.22.1.21
   Goncharenko I, 2006, CYBERPSYCHOL BEHAV, V9, P171, DOI 10.1089/cpb.2006.9.171
   Grant AC, 1999, NEUROPSYCHOLOGIA, V37, P1201, DOI 10.1016/S0028-3932(99)00013-5
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Hill EL, 1998, DEV MED CHILD NEUROL, V40, P388
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Human Resources and Skills Development Canada, 2006, CAN CONT PEOPL DIS
   HUNG SS, 1987, AM J OCCUP THER, V41, P790, DOI 10.5014/ajot.41.12.790
   Judelson DA, 2005, PHYSIOL BEHAV, V85, P629, DOI 10.1016/j.physbeh.2005.06.011
   Jung CM, 2011, J SLEEP RES, V20, P348, DOI 10.1111/j.1365-2869.2010.00877.x
   Kirby JR, 2008, J LEARN DISABIL-US, V41, P85, DOI 10.1177/0022219407311040
   Klatzky RL, 2003, J EXP PSYCHOL-APPL, V9, P228, DOI 10.1037/1076-898X.9.4.228
   LEONARD P, 1988, PERCEPT MOTOR SKILL, V67, P423, DOI 10.2466/pms.1988.67.2.423
   LETON DA, 1987, PSYCHOL SCHOOLS, V24, P201, DOI 10.1002/1520-6807(198707)24:3<201::AID-PITS2310240302>3.0.CO;2-F
   Lieberman HR, 2002, PSYCHOPHARMACOLOGY, V164, P250, DOI 10.1007/s00213-002-1217-9
   MacArthur CA, 1998, LEARN DISABILITY Q, V21, P151, DOI 10.2307/1511342
   Martínez-Marrero I, 2008, TECHTRENDS, V52, P56
   MCCUE PM, 1986, J LEARN DISABIL, V19, P233, DOI 10.1177/002221948601900410
   Minogue J, 2006, REV EDUC RES, V76, P317, DOI 10.3102/00346543076003317
   Oatley K, 2006, UNDERSTANDING EMOTIO, P268
   Orr AC, 2009, LEARN DISABILITY Q, V32, P181, DOI 10.2307/27740367
   Owen SE, 1997, CHILD CARE HLTH DEV, V23, P315, DOI 10.1046/j.1365-2214.1997.864864.x
   Piaget Jean, 1969, The Psychology of the Child
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   RASKIND M, 1993, LEARN DISABILITY Q, V16, P185, DOI 10.2307/1511326
   Raskind MH, 1998, J LEARN DISABIL, V31, P27, DOI 10.1177/002221949803100104
   REGIAN JW, 1992, J COMMUN, V42, P136, DOI 10.1111/j.1460-2466.1992.tb00815.x
   Reynolds CR, 2008, J PSYCHOEDUC ASSESS, V26, P195
   Richardson AE, 2011, PERCEPT MOTOR SKILL, V112, P477, DOI 10.2466/22.24.PMS.112.2.477-498
   Riva G, 2003, PSYCHOTHERAPY, V40, P68, DOI 10.1037/0033-3204.40.1-2.68
   Rose F.D., 2000, Proceedings of the 3rd International Conference on Disability, Virtual Reality, and Associated Technology, P129
   San Diego JP, 2012, COMPUT EDUC, V59, P156, DOI 10.1016/j.compedu.2011.11.009
   Smith A, 2005, J PSYCHOPHARMACOL, V19, P620, DOI 10.1177/0269881105056534
   SOBOTKA KR, 1977, J LEARN DISABIL-US, V10, P363, DOI 10.1177/002221947701000611
   Song H, 2013, COMPUT HUM BEHAV, V29, P1702, DOI 10.1016/j.chb.2013.01.042
   Stoodley CJ, 2000, NEUROSCI LETT, V295, P13, DOI 10.1016/S0304-3940(00)01574-3
   Tabachnick, 2007, USING MULTIVARIATE S, V5th
   The Ontario Human Rights Commission, 2002, ED DIS HUM RIGHTS IS
   Tremblay L, 2011, ACHIEVEMENT TESTS TY, P1
   Vogel SA, 2003, DYSLEXIA, V9, P193, DOI 10.1002/dys.244
   VOGEL SA, 1990, J LEARN DISABIL-US, V23, P44, DOI 10.1177/002221949002300111
   Voytecki K, 2009, P SOC INF TECHN TEAC, P3990
   Welch RB, 2008, DISPLAYS, V29, P152, DOI 10.1016/j.displa.2007.09.013
   Wille D, 2009, DEV NEUROREHABIL, V12, P44, DOI 10.1080/17518420902773117
   Woodard RJ, 1997, PERCEPT MOTOR SKILL, V84, P867, DOI 10.2466/pms.1997.84.3.867
NR 71
TC 4
Z9 4
U1 1
U2 66
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2014
VL 18
IS 1
SI SI
BP 49
EP 60
DI 10.1007/s10055-014-0242-4
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AB2WI
UT WOS:000331652400005
DA 2024-07-18
ER

PT J
AU Petit, J
   Brémond, R
   Tom, A
AF Petit, Josselin
   Bremond, Roland
   Tom, Ariane
TI Evaluation of tone mapping operators in night-time virtual worlds
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual environments; Image rendering; Tone mapping; Presence;
   Subjective evaluation
ID REPRODUCTION
AB The subjective quality of a virtual world depends on the quality of displayed images. In the present paper, we address a technical aspect of image quality in virtual environments. Due to the recent development of high dynamic range (HDR) imaging in computer graphics applications, tone mapping operators (TMO) are needed in the graphic pipeline, and their impact on the final image quality needs to be tested. Previous evaluations of such operators have emphasized the fact that the specific merit of a given operator may depend on both the scene and the application. The dynamic behavior of tone mapping operators was not tested before, and we have designed two psychophysical experiments in order to assess the relevance of various TMO for a specific class of virtual worlds, outdoor scenes at night and an interactive application, to explore an outdoor virtual world at night. In a first experiment, 5 HDR video clips were tone-mapped using 8 operators from the literature, resulting in 40 videos. These 40 videos were presented to 14 subjects, which were asked to rate their realism. However, the subject's evaluation was not a direct comparison with the HDR videos. In a second experiment, 9 HDR photographs of urban scenes at night were tone-mapped with the same 8 operators. The resulting 72 photographs were presented to 13 subjects, at the location where the photographs were taken. The subjects were asked to rate the realism of each tone-mapped image, displayed on a laptop, with respect to the physical scene they experienced. The first experiment emphasized the importance of modeling the temporal visual adaptation for a night-time application.
C1 [Petit, Josselin; Bremond, Roland; Tom, Ariane] Univ Paris Est, IFSTTAR, LEPSiS, IM, Paris, France.
C3 Universite Gustave-Eiffel
RP Brémond, R (corresponding author), Univ Paris Est, IFSTTAR, LEPSiS, IM, Paris, France.
EM roland.bremond@ifsttar.fr
RI Bremond, Roland/AAT-1408-2021
OI Bremond, Roland/0000-0003-3150-7624
CR Akyuz AO, 2007, ACM T GRAPHIC, V26
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 1994, Graph. Gems, DOI DOI 10.1016/B978-0-12-336156-1.50054-9
   [Anonymous], P ACM SIGGRAPH 99
   [Anonymous], P IS T SID 12 COL IM
   [Anonymous], 2006, ACM Trans. Appl. Percept.
   [Anonymous], 2002, PROC ACM T GRAPH SIG, DOI DOI 10.1145/566570.566574
   Ashikhmin M., 2006, ACM T APPL PERCEPT, V3, P399
   Bormann K., 2006, VIRTUAL REAL-LONDON, V9, P226, DOI DOI 10.1007/S10055-006-0019-5
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   Choudhury P., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P186
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Drago F, 2003, ACM SIGGRAPH C APPL
   Durand F, 2000, SPRING COMP SCI, P219
   Ferwerda JA, 2003, PROC SPIE, V5007, P290, DOI 10.1117/12.473899
   Giannopulu I, 2008, ADV TRANSP STUD, V14, P49
   Grave J., 2008, ACM T APPL PERCEPT, V5
   Gruyer D, 2010, P FISITA WORLD AUT C
   Hunt R.W. G., 1995, REPROD COLOUR, VSixth
   Irawan P., 2005, Rendering Techniques, P231
   Kuang J, 2005, P IS T SID 13 COL IM
   Kuang J., 2007, ACM T APPL PERCEPT, V3, P286
   Kuang J, 2006, P INT C IM SCI
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Ledda P, 2004, P AFRIGRAPH, P151
   Lepecq JC, 2009, VIRTUAL REAL-LONDON, V13, P141, DOI 10.1007/s10055-009-0118-1
   Pattanaik S. N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P287, DOI 10.1145/280814.280922
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Petit J, 2010, VISUAL COMPUT, V26, P533, DOI 10.1007/s00371-010-0430-5
   Rahman ZU., 1996, SPIE Proceedings: Applications of digital image processing XIX, V2847
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Robertson M. A., 1999, P IEEE INT C IM PROC
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Yoshida A, 2005, PROC SPIE, V5666, P192, DOI 10.1117/12.587782
   Yoshida A, 2006, COMPUT GRAPH FORUM, V25, P415, DOI 10.1111/j.1467-8659.2006.00961.x
NR 40
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2013
VL 17
IS 4
BP 253
EP 262
DI 10.1007/s10055-012-0215-4
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 239BT
UT WOS:000325997200001
DA 2024-07-18
ER

PT J
AU Okamoto, S
   Ishikawa, S
   Nagano, H
   Yamada, Y
AF Okamoto, Shogo
   Ishikawa, Shun
   Nagano, Hikaru
   Yamada, Yoji
TI Spectrum-based synthesis of vibrotactile stimuli: active footstep
   display for crinkle of fragile structures
SO VIRTUAL REALITY
LA English
DT Article
DE Amplitude spectrum; Virtual material; Haptic interface
ID FREQUENCY; SIMULATION; SCISSORS
AB When a human crinkles or scrunches a fragile object, for which the yield force is very small that it is hardly perceived, they identify the material of the object based on tactile stimuli delivered to the skin. In addition, humans are able to recognize materials even when they are crinkled at different speeds. In order to realize these human recognition features of the crinkle of a fragile object, we develop a vibrotactile synthesis method. This method synthesizes the vibrotactile acceleration stimuli in response to a crinkle speed based on the preliminarily measured acceleration spectra. Using this method, we develop an active footstep display that presents a virtual crinkle of fragile structures made of different materials to its users. Experimental participants could identify three of the four types of virtual structure materials at rates significantly higher than the chance level. The four materials were copy and typing paper, aluminum foil, and polypropylene film. Furthermore, the trends of answer ratios exhibit good correspondence with those for the real cylindrical fragile objects. We conclude that the developed method is valid for the virtual crinkle of fragile structures and will enhance the validity of virtual reality systems, such as a virtual walkthrough system.
C1 [Okamoto, Shogo; Ishikawa, Shun; Nagano, Hikaru; Yamada, Yoji] Nagoya Univ, Dept Mech Sci & Engn, Grad Sch Engn, Nagoya, Aichi 4648601, Japan.
C3 Nagoya University
RP Okamoto, S (corresponding author), Nagoya Univ, Dept Mech Sci & Engn, Grad Sch Engn, Nagoya, Aichi 4648601, Japan.
EM okamoto-shogo@mech.nagoya-u.ac.jp
OI Nagano, Hikaru/0000-0001-5230-6288
FU MEXT KAKENHI [23135514]; Hori Sciences and Arts Foundation;
   Grants-in-Aid for Scientific Research [23135514] Funding Source: KAKEN
FX This work was partly supported by MEXT KAKENHI 23135514 and the Hori
   Sciences and Arts Foundation.
CR Agus M, 2003, PRESENCE-TELEOP VIRT, V12, P110, DOI 10.1162/105474603763835378
   Arbabtafti M, 2011, IEEE T HAPTICS, V4, P39, DOI [10.1109/TOH.2010.5, 10.1109/ToH.2010.5]
   Bensmaïa S, 2005, PERCEPT PSYCHOPHYS, V67, P828, DOI 10.3758/BF03193536
   Bensmaïa S, 2005, PERCEPT PSYCHOPHYS, V67, P842, DOI 10.3758/BF03193537
   Bensmaïa SJ, 2000, J ACOUST SOC AM, V108, P1236, DOI 10.1121/1.1288937
   Chim J, 2003, IEEE T MULTIMEDIA, V5, P503, DOI 10.1109/TMM.2003.819094
   Cholewiak SA, 2010, IEEE T HAPTICS, V3, P3, DOI 10.1109/ToH.2009.36
   Fujino S, 2008, IEEE INT CONF ROBOT, P2067
   Gunhyuk Park, 2011, 2011 IEEE World Haptics Conference (WHC 2011), P59, DOI 10.1109/WHC.2011.5945462
   Israr A, 2006, J ACOUST SOC AM, V120, P2789, DOI 10.1121/1.2354022
   Kavounoudias A, 1999, NEUROSCI LETT, V266, P181, DOI 10.1016/S0304-3940(99)00302-X
   Law AW, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P126, DOI 10.1109/HAVE.2008.4685311
   Lurie K. L., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P19, DOI 10.1109/WHC.2011.5945455
   Maki BE, 1999, J GERONTOL A-BIOL, V54, pM281, DOI 10.1093/gerona/54.6.M281
   Morioka M., 2005, P EUR AC ASS FOR AC, P1577
   Okamoto S., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2459, DOI 10.1109/ROBIO.2011.6181674
   Okamoto S, 2011, IEEE INT C INT ROBOT, P3060, DOI 10.1109/IROS.2011.6048298
   Okamura AM, 2003, IEEE INT CONF ROBOT, P828
   Rafferty MM, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.734978
   Roll R, 2002, NEUROREPORT, V13, P1957, DOI 10.1097/00001756-200210280-00025
   VELAZQUEZ R, 2009, P 2009 IEEE RSJ INT, P1235
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Visell Y, 2009, IEEE T HAPTICS, V2, P148, DOI [10.1109/TOH.2009.31, 10.1109/ToH.2009.31]
   Wakamatsu H., 1998, Proceedings of the 3rd Asia-Pacific Conference on Control and Measurement, P312
   Wang D, 2005, IEEE T VIS COMPUT GR, V11, P671, DOI 10.1109/TVCG.2005.97
   Watanabe J., 2005, Proceedings of the 2005 International Conference on Augmentedtele-Existence, P30, DOI [10.1145/1152399.1152406, DOI 10.1145/1152399.1152406]
   Wiertlewski M, 2011, IEEE T ROBOT, V27, P461, DOI 10.1109/TRO.2011.2132830
NR 27
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2013
VL 17
IS 3
BP 181
EP 191
DI 10.1007/s10055-013-0224-y
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 214EM
UT WOS:000324113800002
DA 2024-07-18
ER

PT J
AU Chambers, TL
   Aglawe, A
   Reiners, D
   White, S
   Borst, CW
   Prachyabrued, M
   Bajpayee, A
AF Chambers, Terrence L.
   Aglawe, Amit
   Reiners, Dirk
   White, Steven
   Borst, Christoph W.
   Prachyabrued, Mores
   Bajpayee, Abhishek
TI Real-time simulation for a virtual reality-based MIG welding training
   system
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Welding; Finite difference; Simulation; Training
ID NUMERICAL-ANALYSIS; METAL TRANSFER; FLUID-FLOW; MODEL; HEAT
AB This paper describes a real-time welding simulation method for use in a desktop virtual reality simulated Metal Inert Gas welding training system. The simulation defines the shape of the weld bead, the depth of penetration, and the temperature distribution in the workpiece, based on inputs from the motion-tracking system that tracks the position of the welding gun as a function of time. A finite difference method is used to calculate the temperature distribution, including the width of the weld bead and the depth of penetration. The shape of the weld bead is then calculated at each time step by assuming a semi-spherical volume, based on the width of the weld bead, the welding speed, and the wire feed rate. The real-time performance of the system is examined, and results from the real-time simulation are compared to physical tests and are found to have very good correlation for welding speeds up to 1,000 mm/min.
C1 [Chambers, Terrence L.; Reiners, Dirk; White, Steven; Borst, Christoph W.; Prachyabrued, Mores] Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
C3 University of Louisiana Lafayette
RP Chambers, TL (corresponding author), Univ Louisiana Lafayette, Ctr Adv Comp Studies, POB 42251, Lafayette, LA 70504 USA.
EM tlchambers@louisiana.edu
RI Chambers, Terrence/AAC-8259-2019
OI /0000-0003-2920-7446
FU Louisiana Workforce Commission
FX This work was funded by the Louisiana Workforce Commission, and their
   contribution is gratefully acknowledged.
CR AGLAWE A, 2008, THESIS U LOUISIANA L
   Chan B, 1999, CAN METALL QUART, V38, P43, DOI 10.1016/S0008-4433(98)00037-8
   Davoud MS, 2003, P IMECE 03 WASH DC, P123
   Dorzin E, 2003, PHYS FACTBOOK
   ETB, 2005, MELT TEMP SOM COMM M
   Fan HG, 1998, J PHYS D APPL PHYS, V31, P2929, DOI 10.1088/0022-3727/31/20/029
   Fast K, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P298, DOI 10.1109/ISMAR.2004.65
   Gwan-Hyung Kim, 1999, 1999 Third International Conference on Knowledge-Based Intelligent Information Engineering Systems. Proceedings (Cat. No.99TH8410), P212, DOI 10.1109/KES.1999.820157
   Jones LA, 1997, 9 ANN C IR STEEL TEC
   Kim IS, 1998, J MATER PROCESS TECH, V77, P17, DOI 10.1016/S0924-0136(97)00383-X
   KUMAR S, 1994, METALL MATER TRANS B, V25, P435, DOI 10.1007/BF02663394
   Lee C. K., 2004, International Journal of Computer Applications in Technology, V21, P171, DOI 10.1504/IJCAT.2004.006642
   Mavrikios D, 2006, INT J COMPUT INTEG M, V19, P294, DOI 10.1080/09511920500340916
   Patankar S., 1980, NUMERICAL HEAT TRANS
   Porter N.C., 2006, Journal of Ship Production, V22, P126
   Wang G, 2003, METALL MATER TRANS B, V34, P345, DOI 10.1007/s11663-003-0080-3
   White SA, 2011, VIRTUAL REAL-LONDON, V15, P69, DOI 10.1007/s10055-010-0162-x
   WTIA, 2006, TGNRT04 WTIA
   Wu CS, 2007, COMP MATER SCI, V39, P416, DOI 10.1016/j.commatsci.2006.07.004
   Zeng Z, 2009, COMP MATER SCI, V44, P1153, DOI 10.1016/j.commatsci.2008.07.033
   Zhang W, 2004, J APPL PHYS, V95, P5210, DOI 10.1063/1.1699485
NR 21
TC 14
Z9 20
U1 0
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 45
EP 55
DI 10.1007/s10055-010-0170-x
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600006
DA 2024-07-18
ER

PT J
AU Schwerdtfeger, B
   Reif, R
   Günthner, WA
   Klinker, G
AF Schwerdtfeger, Bjoern
   Reif, Rupert
   Guenthner, Willibald A.
   Klinker, Gudrun
TI Pick-by-vision: there is something to pick at the end of the augmented
   tunnel
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; User studies; Order picking; Logistics; Tracked
   head-mounted display; Guidance
AB We report on the long process of exploring, evaluating and refining augmented reality-based methods to support the order picking process of logistics applications. Order picking means that workers have to pick items out of numbered boxes in a warehouse, according to a work order. To support those workers, we have evaluated different HMD-based visualizations in six user studies, starting in a laboratory setup and continuing later in an industrial environment. This was a challenging task, as we had to conquer different kinds of navigation problems from very coarse to very fine granularity and accuracy. The resulting setup consists of a combined and adaptive visualization to precisely and efficiently guide the user even if the actual picking target is not always in the field of view of the HMD.
C1 [Schwerdtfeger, Bjoern; Reif, Rupert; Guenthner, Willibald A.; Klinker, Gudrun] Tech Univ Munich, Munich, Germany.
C3 Technical University of Munich
RP Klinker, G (corresponding author), Tech Univ Munich, Munich, Germany.
EM klinker@in.tum.de
RI Klinker, Gudrun/JVP-3665-2024
OI Klinker, Gudrun/0000-0003-0971-5726
FU Bayerische Forschungsstiftung (BFS)
FX The authors would like to thank T. Frimor, E. Yukselgil, M. Stadter, X.
   Pan, M. Stadtler, M. Meister and all our test persons. Furthermore, we
   thank ART GmbH, Germany for lending the equipment. This work was
   partially supported by the ForLog and trackframe projects of the
   Bayerische Forschungsstiftung (BFS).
CR [Anonymous], 2007, NEUE WEGE AUTOMOBILL
   Baudisch P., 2003, P CHI 2003 FORT LAUD
   Biocca F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1115
   Bortz J., 2005, Statistik fur Human- und Sozialwissenschaftler
   Curtis D., 1998, P INT WORKSHOP AUGME, P47
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   GABBARD J, 2006, PRESENCE TELEOPER VI, V15
   Gudehus T., 2005, Logistik: Grundlagen, strategien, anwendungen, V3rd
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   KRAMER LJ, 2004, P SPIE, V5424
   SCHWERDTFEGER B, 2006, P 16 INT C ART REAL
   SCHWERDTFEGER B, 2008, P 6 INT S MIX AUGM R
   Schwerdtfeger B., 2008, TUMI0819
   SCHWERDTFEGER B, 2009, P 7 INT S MIX AUGM R
NR 14
TC 49
Z9 54
U1 2
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 213
EP 223
DI 10.1007/s10055-011-0187-9
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200011
DA 2024-07-18
ER

PT J
AU Anderson, EF
   McLoughlin, L
   Liarokapis, F
   Peters, C
   Petridis, P
   de Freitas, S
AF Anderson, Eike Falk
   McLoughlin, Leigh
   Liarokapis, Fotis
   Peters, Christopher
   Petridis, Panagiotis
   de Freitas, Sara
TI Developing serious games for cultural heritage: a state-of-the-art
   review
SO VIRTUAL REALITY
LA English
DT Review
DE Cultural heritage; Serious games; Computer games technology
ID VIRTUAL-REALITY; AUGMENTED REALITY; MIXED REALITY; ANIMATION; HUMANS
AB Although the widespread use of gaming for leisure purposes has been well documented, the use of games to support cultural heritage purposes, such as historical teaching and learning, or for enhancing museum visits, has been less well considered. The state-of-the-art in serious game technology is identical to that of the state-of-the-art in entertainment games technology. As a result, the field of serious heritage games concerns itself with recent advances in computer games, real-time computer graphics, virtual and augmented reality and artificial intelligence. On the other hand, the main strengths of serious gaming applications may be generalised as being in the areas of communication, visual expression of information, collaboration mechanisms, interactivity and entertainment. In this report, we will focus on the state-of-the-art with respect to the theories, methods and technologies used in serious heritage games. We provide an overview of existing literature of relevance to the domain, discuss the strengths and weaknesses of the described methods and point out unsolved problems and challenges. In addition, several case studies illustrating the application of methods and technologies used in cultural heritage are presented.
C1 [Anderson, Eike Falk; Liarokapis, Fotis; Peters, Christopher] Coventry Univ, Interact Worlds Appl Res Grp, Coventry, W Midlands, England.
   [McLoughlin, Leigh] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth, Dorset, England.
   [Petridis, Panagiotis; de Freitas, Sara] Coventry Univ, Serious Games Inst, Coventry, W Midlands, England.
C3 Coventry University; Bournemouth University; Coventry University
RP Anderson, EF (corresponding author), Coventry Univ, Interact Worlds Appl Res Grp, Coventry, W Midlands, England.
EM eikea@siggraph.org
RI Liarokapis, Fotis/AAD-4444-2019; Anderson, Eike Falk/KVY-0951-2024;
   Liarokapis, Fotis/B-7464-2014; Liarokapis, Fotis/AAQ-9498-2021;
   Petridis, Panagiotis/C-4349-2015
OI Liarokapis, Fotis/0000-0003-3617-2261; Anderson, Eike
   Falk/0000-0002-5805-1738; Liarokapis, Fotis/0000-0003-3617-2261;
   Liarokapis, Fotis/0000-0003-3617-2261; Petridis,
   Panagiotis/0000-0003-3593-8261
CR Anderson E F., 2007, ACM SIGGRAPH 2007 educators program, P7
   ANDERSON EF, 2008, FUTURE PLAY 08, P185
   Anderson EF, 2008, P 2008 C FUT PLAY RE, P228, DOI [DOI 10.1145/1496984, DOI 10.1145/1496984.1497031, 10.1145/1496984.1497031]
   ANDERSON EF, 2003, P ZFXCON03 C GAM DEV
   [Anonymous], 2004, GPU GEMS
   [Anonymous], 2018, Real-Time Rendering
   [Anonymous], P 8 INT C VIRT SYST
   [Anonymous], 2007, WHAT IS ARTIFICIAL I
   [Anonymous], 2008, 9 INT S VIRTUAL REAL, DOI DOI 10.2312/VAST/VAST08/055-062
   [Anonymous], 2008, MEASURING IMPACT 2 L
   [Anonymous], 2002, AI GAME PROGRAMMING
   [Anonymous], SHADERX5
   [Anonymous], 2008, ROME REBORN PROJECT
   [Anonymous], 2009, P S INT 3D GRAPH GAM, DOI 10.1145/1507149.1507161.5,7
   APPERLEY TH, 2006, UNAUSTRALIA 2006
   Arnold D., 2008, OPEN DIGITAL CULTURA
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BAVOIL L, 2008, GAM DEV C 2008
   Bavoil L., 2008, Tech. rep
   Bederson B.B., 1995, ACM Human Computer in Computing Systems conference (CHI'95), P210
   Benthin C, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P15
   Bimber O, 2001, IEEE COMPUT GRAPH, V21, P48, DOI 10.1109/38.963460
   BJORKE K, 2004, GPU GEMS, P363
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Blow J., 2004, QUEUE, V1, P28, DOI DOI 10.1145/971564.971590
   Blythe D, 2006, ACM T GRAPHIC, V25, P724, DOI 10.1145/1141911.1141947
   BROGNI B, 1999, RO MAN 99, P206
   BURKERSRODA R, 2005, SHADER X3 ADV RENDER, P357
   Buro Michael., 2004, P AAAI WORKSHOP GAME, P139
   Burton J., 2005, AUSTR J EMERGING TEC, V3, P87
   CALORI L, 2005, P ISPRS WORK GROUP 5
   Cass S, 2002, IEEE SPECTRUM, V39, P40, DOI 10.1109/MSPEC.2002.1088444
   Cerezo E, 2005, VISUAL COMPUT, V21, P303, DOI 10.1007/s00371-005-0287-1
   CHALMERS A, 2009, VS GAMES 2009, P225
   CIECHOMSKI PDH, 2004, 5 INT S VIRT REAL AR
   COMBS N, 2004, DECLARATIVE VERSUS I
   Coombe G., 2005, GPU GEMS, V2, P635
   CORADESCHI S, 1999, LINKOPING ELECT ARTI, V4
   CORNWELL J, 2003, BRIMS 2003
   COSMAS J, 2001, P 2001 C VIRT REAL A, P297, DOI DOI 10.1145/584993.585048
   Crassin C., 2009, P 2009 S INT 3D GRAP, P15, DOI [10.1145/1507149.1507152, DOI 10.1145/1507149.1507152]
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   DARKEN CJ, 2007, AIIDE 2007
   de Freitas S, 2006, COMPUT EDUC, V46, P249, DOI 10.1016/j.compedu.2005.11.007
   DEBEVEC P, 2005, 6 INT S VIRT REAL AR
   Debevec Paul., 2004, ESTIMATING SURFACE R
   DECHTER R, 1985, J ACM, V32, P505, DOI 10.1145/3828.3830
   DELEON VJ, 1999, P VIRT SYST MULT
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Doyle P., 1999, AAAI 99 SPRING S ART
   DOYLE P, 1998, AGENTS 98, P173
   Doyle Patrick., 2002, Proceedings of the first international joint conference on Autonomous agents and multiagent systems: part 1, P342
   DUTR P, 2003, ADV GLOBAL ILLUMINAT
   DYBSAND E, 2004, AI GAME PROGRAMMING, V2, P237
   ELHAKIM S, 2006, INT S VIRT REAL ARCH, P243
   Engel K, 2006, Real-Time Volume Graphics
   ENGEL W, 2008, PROGRAMMING VERTEX G
   ENNIS C, 2010, ACM T APPL IN PRESS
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   EVANS R, 2001, AI COMPUTER GAMES US
   Everitt C, 2001, INTERACTIVE ORDER IN
   Farenc N, 1999, COMPUT GRAPH FORUM, V18, pC309, DOI 10.1111/1467-8659.00351
   Feiner SK, 2002, SCI AM, V286, P48, DOI 10.1038/scientificamerican0402-48
   FEIS A, 2007, SHADER X5 ADV RENDER, P463
   FERNANDO R, 2003, CG TUTORIAL
   Filion D., 2008, SIGGRAPH 08, P133, DOI DOI 10.1145/1404435.1404441
   Forbus K., 2001, Some notes on programming objects inTheSims
   Francis R., 2006, P AM ED RES ASS C
   FRITSCH D, 2004, 5 ISPRS COMM, P621
   Fu Dan., 2004, AI game programming Wisdom, V2, P283
   GAITATZES A, 2004, VAST 2004, P19
   GARDNER R, 2009, EMP TOT WAR GRAPH WO
   GATERMANN H, 2000, SIGRADI 2000 CONSTRU, P254
   Gillham D., 2007, Shader X5: Advanced Rendering Techniques, P163
   Godbersen H, 2008, IEEE MULTIMEDIA, V15, P90, DOI 10.1109/MMUL.2008.74
   Hadwiger Markus., 2006, SIGGRAPH EUROGRAPHIC, P49, DOI [10.1145/1283900.1283908, DOI 10.1145/1283900.1283908]
   HAGELBACK J, 2008, AIIDE 08, P42
   HALL T, 2001, VAST 01, P91
   Hasenfratz J.-M., 2003, A survey of real-time soft shadows algorithms
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   HOBEROCK J, 2008, GPU GEMS, V3, P257
   HOFFMAN N, 2006, PHYS BASED REFLECTAN
   Horn DR, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P167
   HOSTETLER TR, 2002, THESIS U IOWA
   Humphreys G, 2002, ACM T GRAPHIC, V21, P693, DOI 10.1145/566570.566639
   ISIDORO JR, 2006, SIGGRAPH 06, P19
   Jacobson J, 2005, COMPUTER, V38, P79, DOI 10.1109/MC.2005.126
   JACOBSON J, 2005, EDMEDIA
   JACOBSON J, 2009, COMPUTER APPL ARCHAE
   Jones C., 2005, E-Learning, V2, P414
   Jones Greg., 2002, FUTURE VIRTUAL MUSEU
   Kaneko T., 2001, Proceedings of ICAT, V2001, P205
   KAWASE M, 2004, GAM DEV C 2004
   Kawase Masaki, 2003, GAM DEV C 2003
   Kider J.T., 2009, 10 INT S VIRT REAL A, P33
   KIM J, 2009, SCI PROGRAMMING, V17, P173
   KOONCE R, 2008, GPU GEMS, V3, P429
   KRUGER J, 2006, RENDERING TECHNIQUES, P319
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   LEAVY B, 2007, P DIGRA 2007 C, P24
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   LEE KH, 2006, SIGGRAPH 06 ACM SIGG, P898
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI DOI 10.1007/S10055-004-0141-1
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lewis M, 2002, COMMUN ACM, V45, P27
   Liarokapis Fotis, 2007, Virtual Reality, V11, P23, DOI 10.1007/s10055-006-0055-1
   LINAZA MT, 2007, VAST07, P23
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Livingston MA, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.130
   Livingstone D., 2004, P AAAI 04 WORKSH CHA, P6
   Lokovic T, 2000, COMP GRAPH, P385, DOI 10.1145/344779.344958
   LOOSER J, 2006, ISMAR 06
   LUGRIN J, 2010, SEARIS 2010
   MACAGON V, 2003, P IM VIS COMP NZ C P, P378
   Macedonia M, 2000, COMPUTER, V33, P110, DOI 10.1109/2.839327
   Macedonia M, 2002, IEEE SPECTRUM, V39, P32, DOI 10.1109/6.988702
   Maim Jonathan., 2007, Proceedings of the 8th International conference on Virtual Reality, Archaeology and Intelligent Cultural Heritage, P109
   Malone Thomas W, 2021, Aptitude, learning, and instruction, P223, DOI DOI 10.1016/S0037-6337(09)70509-1
   Mase K., 1996, INT C VIRT SYST MULT, P107
   Mateevitsi V., 2008, P 3 INT C DIGITAL IN, P451, DOI [10.1145/1413634.1413714, DOI 10.1145/1413634.1413714]
   Matthews J., 2002, AI Game Programming Wisdom, P105
   McDonnell R, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609969
   McDonnell R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531361
   McDonnell R, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P259
   McGuire ThomasJ., 2006, The Philadelphia Campaign, VI-II.
   MCTAGGART G, 2006, SIGGRAPH 06 ACM SIGG, P7
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MITCHELL J, 2006, SIGGRAPH 06, P129
   Mittring Martin., 2007, SIGGRAPH '07, P97
   Mittring Martin., 2008, ACM SIGGRAPH Games, P23
   Muller P., 2005, RECORDING MODELING V, P287
   MUSSE SR, 1997, COMPUTER ANIMATION S, P39
   Nagy Z, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P429, DOI 10.1109/PCCGA.2003.1238289
   Nareyek A, 2007, IEEE INTELL SYST, V22, P9, DOI 10.1109/MIS.2007.10
   Nienhaus M, 2003, WSCG'2003, VOL 11, NO 2, CONFERENCE PROCEEDINGS, P346
   NOGHANI J, 2010, VS GAMES 2010, P3
   Oliveira MM, 2000, COMP GRAPH, P359, DOI 10.1145/344779.344947
   ORKIN J, 2004, P AAAI 04 WORKSH CHA, P26
   ORKIN J, 2006, P 2006 GAM DEV C
   ORKIN J, 2002, AI GAME PROGRAMMING, P29
   Orkin Jeff., 2004, AI Game Program- ming Wisdom, V2, P217
   Overmars M, 2004, COMPUTER, V37, P81, DOI 10.1109/MC.2004.1297314
   Paquet E., 2001, VAA'01: Proceedings of the International Symposium on Virtual and Augmented Architecture, P182
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Peters C., 2003, P INT C CENTR EUR CO
   PETERS C, 2008, EUROGRAPHICS 2008 SH, P33
   PETERS C, 2009, P AISB 2009 CONV AI, P64
   Pletinckx D, 2000, IEEE MULTIMEDIA, V7, P45, DOI 10.1109/93.848427
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Purcell T., 2003, SIGGRAPHEUROGRAPHICS, P41
   Purcell TJ, 2002, ACM T GRAPHIC, V21, P703, DOI 10.1145/566570.566640
   Reinhard E., 2006, HIGH DYNAMIC RANGE I, DOI 10.1016/B978-012585263-0/50005-1
   Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304
   REMOND M, 2003, P 9 INT ERL OTP US C
   RENEVIER P, 2004, CADUI 2004, P307
   Ropinski T, 2008, WSCG 2008, FULL PAPERS, P17
   ROSADO G, 2008, GPU GEMS, V3, P575
   Rost R.J., 2006, OpenGL Shading Language, V2nd
   RYAN N, 2000, P VAST EUR
   Ryder G., 2005, VAST 2005, P108
   SANCHEZ S, 2004, P 3 IEEE INT S SCH A, P19
   Sander P. V., 2006, ACM SIGGRAPH 2006 CO, P1, DOI [10.1145/1185657.1185826, DOI 10.1145/1185657.1185826]
   SANWAL R, 2000, EUR RES CONSORT INFO, V40, P39
   Sawyer B., 2002, SERIOUS GAMES IMPROV
   Scheuermann T, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P33
   SECUNDUS GPC, EPISTULAE 6 20
   SECUNDUS GPC, EPISTULAE 6 16
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   Shanmugam P, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P73
   SHAO W, 2005, SCA 05, P19
   SHERROD A, 2006, GAME PROGRAMMING GEM, V6, P529
   SHIRLEY P, 2006, ACM SIGGRAPH 2006 CO
   Shreiner D., 2007, OPENGL PROGRAMMING G
   Sinclair P., 2001, P 3 WORKSH AD HYP HY
   Sousa Tiago., 2005, Shader X3: Advanced Rendering with DirectX and OpenGL, P349
   STOUT B, 2000, GAME PROGRAMMING GEM, P254
   Stricker D., 2001, INT C AUGMENTED VIRT, P1
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Tamura H, 2001, IEEE COMPUT GRAPH, V21, P64, DOI 10.1109/38.963462
   Tamura H, 1999, MIXED REALITY, P59
   TATARCHUK N, 2006, EUR WORKSH NAT PHEN
   TCHOU C, 2004, SIGGRAPH 04 ACM SIGG, P80
   Tchou C. D., 2002, THESIS U CALIFORNIA
   Thomas G, 2000, COMP ANIM CONF PROC, P112, DOI 10.1109/CA.2000.889057
   Trenholme David, 2008, Virtual Reality, V12, P181, DOI 10.1007/s10055-008-0092-z
   TROCHE J, 2010, CAA 2010 38 C COMP A
   Ulicny B., 2002, P 1 INT WORKSH 3D VI, P28
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   VANEGAS CA, 2009, EUROGRAPHICS 2009 ST, P1
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   WALLIS A, 2007, GAME CARREER GUIDE 2, P25
   Wand M, 2003, COMPUT GRAPH FORUM, V22, P611, DOI 10.1111/1467-8659.t01-2-00709
   WARING P, 2007, THESIS U MANCHESTER
   Watt A.H., 2005, Advanced game development with programmable graphics hardware
   WRIGHT T, 2008, 200811 U NOTR DAM
   Yin P., 2006, INT J VIRTUAL REAL, V5, P47
   YU JY, 2005, I3D 05, P133
   Zerbst S., 2003, 3D SPIELEPROGRAMMIER
   ZHOU T, 2007, COMPUT GRAPH FORUM, V26, P655
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 203
TC 181
Z9 193
U1 10
U2 264
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2010
VL 14
IS 4
BP 255
EP 275
DI 10.1007/s10055-010-0177-3
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HX
UT WOS:000296279800004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Vézien, JM
   Ménélas, B
   Nelson, J
   Picinali, L
   Bourdot, P
   Ammi, M
   Katz, BFG
   Burkhardt, JM
   Pastur, L
   Lusseyran, F
AF Vezien, J. M.
   Menelas, B.
   Nelson, J.
   Picinali, L.
   Bourdot, P.
   Ammi, M.
   Katz, B. F. G.
   Burkhardt, J. M.
   Pastur, L.
   Lusseyran, F.
TI Multisensory VR exploration for computer fluid dynamics in the CoRSAIRe
   project
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Computer fluid dynamics; Sonification; Haptics;
   Multimodal virtual environment
ID FLOW
AB In the last 30 years, the evolution of digital data processing in terms of processing power, storage capacity, and algorithmic efficiency in the simulation of physical phenomena has allowed the emergence of the discipline known as computational fluid dynamics or CFD. More recently, virtual reality (VR) systems have proven an interesting alternative to conventional user interfaces, in particular, when exploring complex and massive datasets, such as those encountered in scientific visualization applications. Unfortunately, all too often, VR technologies have proven unsatisfactory in providing a true added value compared to standard interfaces, mostly because insufficient attention was given to the activity and needs of the intended user audience. The present work focuses on the design of a multimodal VR environment dedicated to the analysis of non-stationary flows in CFD. Specifically, we report on the identification of relevant strategies of CFD exploration coupled to adapted VR data representation and interaction techniques. Three different contributions will be highlighted. First, we show how placing the CFD expert user at the heart of the system is accomplished through a formalized analysis of work activity and through system evaluation. Second, auditory outputs providing analysis of time-varying phenomena in a spatialized virtual environment are introduced and evaluated. Finally, specific haptic feedbacks are designed and evaluated to enhance classical visual data exploration of CFD simulations.
C1 [Vezien, J. M.; Menelas, B.; Bourdot, P.; Ammi, M.; Katz, B. F. G.; Pastur, L.; Lusseyran, F.] Ctr Natl Rech Sci, Lab Informat & Mecan Sci Ingn, F-91403 Orsay, France.
   [Nelson, J.] Arts & Metiers ParisTech, Lab Concept Prod & Innovat, Paris, France.
   [Picinali, L.] CNRS, Inst Rech & Coordinat Acoust Mus, UMR 9912, F-75004 Paris, France.
   [Burkhardt, J. M.] Univ Paris 05, ECI, Paris, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Arts et Metiers Institute of Technology; heSam Universite;
   Conservatoire National Arts & Metiers (CNAM); Sorbonne Universite;
   Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite
RP Vézien, JM (corresponding author), Ctr Natl Rech Sci, Lab Informat & Mecan Sci Ingn, F-91403 Orsay, France.
EM vezien@limsi.fr; bob@limsi.fr; julien.nelson@paris.ensam.fr;
   picinali@ircam.fr; bourdot@limsi.fr; ammi@limsi.fr; katz@limsi.fr;
   jean-marie.burkhardt@univ-paris5.fr; pastur@limsi.fr; lussey@limsi.fr
RI Katz, Brian F.G./I-3191-2012; Burkhardt, Jean-Marie/AAF-5544-2020
OI Katz, Brian F.G./0000-0001-5118-0943; Burkhardt,
   Jean-Marie/0000-0003-4417-6430; Picinali, Lorenzo/0000-0001-9297-2613
CR Adachi Y., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P203, DOI 10.1109/VRAIS.1995.512497
   ANDRE E, 2000, GENERATION MULTIMEDI, P305
   ANNETT J, 2003, CHAPTER HIERARCHICAL, P17
   [Anonymous], 1998, ANAL AUTOMATIQUE CON
   [Anonymous], 1984, PROTOCOL ANAL VERBAL
   [Anonymous], 1996, FORCE TOUCH FEEDBACK
   Avila RS, 1996, IEEE VISUAL, P197, DOI 10.1109/VISUAL.1996.568108
   Bryson S., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P17, DOI 10.1109/VISUAL.1991.175771
   CHEN KW, 2000, ACM S VIRT REAL SOFT, P188
   CHINN CA, 1993, REV EDUC RES, V63, P1, DOI 10.3102/00346543063001001
   CRAWFIS RA, 2000, 9 INT S FLOW VIS
   DONKER H, 2002, 2 NORD C HUM COMP IN, V31, P149
   DUDAS R, 2002, INT COMP MUS C ICMC, P126
   FAUVET N, 2007, CYB WORLD 2007 HANN, P322
   FLANAGAN JL, 1965, J ACOUST SOC AM, V38, P939, DOI 10.1121/1.1939800
   Gadoin E, 2001, INT J NUMER METH FL, V37, P175, DOI 10.1002/fld.173
   GHERBI R, 2006, EXPLORATIONS DONNCES, pCH4
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   KATZ BFG, 2007, 2 INT WORKSH INT SON
   KATZ BFG, 2008, INT C AUD DISPL ICAD
   Kramer G., 1994, Santa Fe Institute Studies in the Sciences of Complexity. Proceedings, VXVIII.
   KRNER O, 1999, 1 INT WORKSH HAPT DE, P79
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Lynch K., 1960, IMAGE CITY
   Maguire M, 2001, INT J HUM-COMPUT ST, V55, P587, DOI 10.1006/ijhc.2001.0503
   MARK W, 1996, 23 ANN C COMP GRAPH, P447
   MENELAS B, 2009, J VIRTUAL R IN PRESS
   MENELAS B, 2009, S HAPT INT VIRT ENV, P232
   Ménélas B, 2008, LECT NOTES COMPUT SC, V5024, P687, DOI 10.1007/978-3-540-69057-3_87
   Nesbitt Keith, 2003, THESIS U SYDNEY
   Pastur LR, 2008, EXP FLUIDS, V44, P597, DOI 10.1007/s00348-007-0419-7
   Podvin B, 2006, J FLUID ENG-T ASME, V128, P531, DOI 10.1115/1.2175159
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   SCHNELL N, 2000, INT COMP MUS C BERL
   TOURAINE D, 2001, IEEE INT WORKSH ROB
   van Dam A, 2000, IEEE COMPUT GRAPH, V20, P26, DOI 10.1109/38.888006
   WRIGHT M, 2003, INT C NEW INT MUS EX, P153
   ZIEGELER S, 2001, IEEE 12 C VIS VIS 20
NR 38
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2009
VL 13
IS 4
SI SI
BP 257
EP 271
DI 10.1007/s10055-009-0134-1
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XF
UT WOS:000208104400005
DA 2024-07-18
ER

PT J
AU Wallach, HS
   Safir, MP
   Almog, I
AF Wallach, Helene S.
   Safir, Marilyn P.
   Almog, Idan
TI Attachment and sense of presence in a virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Attachment; Avoidance; Anxiety; Virtual reality; Culture
ID ADULT ATTACHMENT; INDIVIDUAL-DIFFERENCES; STYLE; ACCESSIBILITY;
   DIMENSIONS; ACTIVATION; REALITY; FEAR
AB This study is the first to investigate the connection between attachment categories and presence in Virtual Reality (VR) environments. Participants (99) completed an attachment questionnaire, experienced Virtual Reality Exposure (VRE) in a virtual airplane, and completed a presence questionnaire. Twenty-seven participants neglected to look at the virtual window, and reported lower levels of presence. A significant negative correlation between presence and avoidance was found. The correlation between presence and anxiety was not significant. Ethnicity (Jewish/non-Jewish) was found to be an intervening variable. A significant difference between levels of presence of attachment categories was found for participants who viewed the window: those in the Safe category reported the highest levels of presence, followed by the Anxious-Ambivalent group, the Dismissive-Avoidant group, and finally the Fearful-Avoidant group. Our results suggest there is a connection between one's avoidance level and his/her attachment type and ability to experience the VRE as real and vivid.
C1 [Wallach, Helene S.; Safir, Marilyn P.; Almog, Idan] Univ Haifa, Dept Psychol, IL-31905 Haifa, Israel.
C3 University of Haifa
RP Wallach, HS (corresponding author), Univ Haifa, Dept Psychol, IL-31905 Haifa, Israel.
EM helenwa@yahoo.com; marilyn.safir@gmail.com; almogidan@gmail.com
CR Ainsworth M.D. S., 1973, Review of child development research, V3, P1
   Ainsworth M. D. S., 1978, PATTERNS ATTACHMENT
   Ainsworth MD., 1971, The origins of human social relations, P15
   BALDWIN MW, 1995, PERS RELATIONSHIP, V2, P247, DOI 10.1111/j.1475-6811.1995.tb00090.x
   BARTHOLOMEW K, 1991, J PERS SOC PSYCHOL, V61, P226, DOI 10.1037/0022-3514.61.2.226
   Bartholomew K., 1998, ATTACHMENT THEORY CL, P46
   Berant E, 2001, PERS SOC PSYCHOL B, V27, P956, DOI 10.1177/0146167201278004
   Birnbaum GE, 1997, J SOC PERS RELAT, V14, P643, DOI 10.1177/0265407597145004
   Bowlby J., 1982, ATTACHMENT LOSS, VI
   Bowlby J., 1988, SECURE BASE PARENT C, DOI DOI 10.1097/00005053-199001000-00017
   Bowlby J., 1973, ATTACHMENT LOSS, V2
   Brennan K. A., 1998, ATTACHMENT THEORY CL, P46, DOI DOI 10.1016/J.PAIN.2006.07.020
   BRENNAN KA, 1995, PERS SOC PSYCHOL B, V21, P267, DOI 10.1177/0146167295213008
   CARNELLEY KB, 1994, J PERS SOC PSYCHOL, V66, P127, DOI 10.1037/0022-3514.66.1.127
   CARVER CS, 1994, PERSONALITY AD UNPUB
   Casati R, 2005, J VISUAL LANG COMPUT, V16, P428, DOI 10.1016/j.jvlc.2004.12.003
   Cassidy J., 1988, CLIN IMPLICATIONS AT, P300
   Coyle JR, 2001, J ADVERTISING, V30, P65, DOI 10.1080/00913367.2001.10673646
   CUMMINGS EM, 1980, DEV PSYCHOL, V16, P31, DOI 10.1037/0012-1649.16.1.31
   Feeney J. A., 1994, Attachment in adults: Clinical and developmental perspectives, P128, DOI DOI 10.1037/T29439-000
   Fraley R.C., 1998, Attachment theory and close relationships, P77
   Fraley RC, 1998, J PERS SOC PSYCHOL, V75, P1198, DOI 10.1037/0022-3514.75.5.1198
   HAZAN C, 1987, J PERS SOC PSYCHOL, V52, P511, DOI 10.1037/0022-3514.52.3.511
   Held R. M., 1992, Presence: Teleoperators and Virtual Environments, V1, P109, DOI [https://doi.org/10.1162/pres.1992.1.1.109, 10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Keddie N R., 1990, Journal of World History, V1, P77
   KIZONY R, 2006, THESIS HEBREW U JERU
   Laarni J., 2004, P 7 ANN INT WORKSHOP, P88
   Mickelson KD, 1997, J PERS SOC PSYCHOL, V73, P1092, DOI 10.1037/0022-3514.73.5.1092
   Mikulincer M, 2000, J PERS SOC PSYCHOL, V78, P509, DOI 10.1037/0022-3514.78.3.509
   Mikulincer M, 1997, J PERS SOC PSYCHOL, V72, P1217, DOI 10.1037/0022-3514.72.5.1217
   MIKULINCER M, 1990, J PERS SOC PSYCHOL, V58, P273, DOI 10.1037/0022-3514.58.2.273
   Mikulincer M, 1998, J PERS SOC PSYCHOL, V75, P420, DOI 10.1037/0022-3514.75.2.420
   Mikulincer M, 2000, J PERS SOC PSYCHOL, V79, P260, DOI 10.1037//0022-3514.79.2.260
   Mikulincer M, 2002, J PERS SOC PSYCHOL, V83, P881, DOI 10.1037//0022-3514.83.4.881
   Mikulincer M., 2001, BLACKWELL HDB SOCIAL, P537
   Mikulincer M., 1998, Attachment theory and close relationships, P143
   Murray CD, 2007, COMPUT HUM BEHAV, V23, P1347, DOI 10.1016/j.chb.2004.12.010
   Naimark M., 1990, The art of human-computer interface design, P455
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   Pines AM, 2004, WORK STRESS, V18, P66, DOI 10.1080/02678370310001645025
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Semyonov M, 1999, WORK EMPLOY SOC, V13, P117, DOI 10.1017/S0950017099000082
   Shaver R. P., 2002, ATTACH HUM DEV, V4, P133
   Simpson J.A., 1998, ATTACHMENT THEORY CL, P46
   SIMPSON JA, 1992, J PERS SOC PSYCHOL, V62, P434, DOI 10.1037/0022-3514.62.3.434
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   THATCHER A, 2005, P CYBERG 2005 4 INT
   Wegner DM, 1997, J CONSULT CLIN PSYCH, V65, P984, DOI 10.1037/0022-006X.65.6.984
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 54
TC 4
Z9 6
U1 3
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 205
EP 217
DI 10.1007/s10055-009-0122-5
PN 1
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300008
DA 2024-07-18
ER

PT J
AU Adhanom, IB
   MacNeilage, P
   Folmer, E
AF Adhanom, Isayas Berhe
   MacNeilage, Paul
   Folmer, Eelke
TI Eye Tracking in Virtual Reality: a Broad Review of Applications and
   Challenges
SO VIRTUAL REALITY
LA English
DT Review
DE Eye tracking; Virtual reality
ID GAZE; IMMERSION; PERFORMANCE; TECHNOLOGY; PERCEPTION; MOVEMENTS;
   PATTERNS
AB Eye tracking is becoming increasingly available in head-mounted virtual reality displays with various headsets with integrated eye trackers already commercially available. The applications of eye tracking in virtual reality are highly diversified and span multiple disciplines. As a result, the number of peer-reviewed publications that study eye tracking applications has surged in recent years. We performed a broad review to comprehensively search academic literature databases with the aim of assessing the extent of published research dealing with applications of eye tracking in virtual reality, and highlighting challenges, limitations and areas for future research.
C1 [Adhanom, Isayas Berhe; MacNeilage, Paul; Folmer, Eelke] Univ Nevada Reno, 1664 N Virginia St, Reno, NV 89557 USA.
C3 Nevada System of Higher Education (NSHE); University of Nevada Reno
RP Adhanom, IB (corresponding author), Univ Nevada Reno, 1664 N Virginia St, Reno, NV 89557 USA.
EM iadhanom@nevada.unr.edu; pmacneilage@unr.edu; efolmer@unr.edu
OI Adhanom, Isayas/0000-0003-4798-7415
FU NSF [1911041]; NIH COBRE Award [P20GM103650]; Div Of Information &
   Intelligent Systems; Direct For Computer & Info Scie & Enginr [1911041]
   Funding Source: National Science Foundation
FX This project was supported by NSF grant 1911041 and NIH COBRE Award
   P20GM103650.
CR Adams D, 2019, P 14 S USABLE PRIVAC
   Adhanom IB, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391374
   Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Al-Ghamdi NA, 2020, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00467
   Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Albert RA, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343128
   Alcañiz M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01530
   Andersson R, 2010, J EYE MOVEMENT RES, V3
   Nguyen A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281515
   [Anonymous], 2014, EUROGRAPHICS 2014 ST, DOI DOI 10.2312/EGST.20141036.069-091
   [Anonymous], 2003, P ACM SIGCHI C HUM F, DOI [DOI 10.1145/642611.642703, 10.1145/642611.642703]
   Arabadzhiyska E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073642
   Araujo J.M., 2020, ACM S EYE TRACK RES, P1
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Bastani Behnam, 2017, Information Display, V33, P14
   Bian D, 2019, ACM T ACCESS COMPUT, V12, DOI 10.1145/3301498
   Bigné E, 2016, J BUS RES, V69, P1423, DOI 10.1016/j.jbusres.2015.10.119
   Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Blattgerste J, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206349
   Blignaut P, 2017, J EYE MOVEMENT RES, V10, DOI 10.16910/jemr.10.4.1
   Boring S., 2009, P 21 ANN C AUSTR COM, V411, P161, DOI 10.1145/1738826.1738853
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Boyer EO, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00197
   Bulling A, 2009, J AMB INTEL SMART EN, V1, P157, DOI 10.3233/AIS-2009-0020
   Burgoon M., 1994, HUMAN COMMUNICATION
   Chun-Chia Wang, 2019, 2019 8th International Congress on Advanced Applied Informatics (IIAI-AAI), P160, DOI 10.1109/IIAI-AAI.2019.00041
   Clark R, 2019, EYE, V33, P1200, DOI 10.1038/s41433-019-0417-z
   Cockburn A, 2011, INT J HUM-COMPUT ST, V69, P401, DOI 10.1016/j.ijhcs.2011.02.005
   Loureiro SMC, 2019, J BUS RES, V100, P514, DOI 10.1016/j.jbusres.2018.10.055
   Cournia Nathan., 2003, CHI'03 extended abstracts on Human factors in computing systems, P772, DOI DOI 10.1145/765891.765982
   COWEY A, 1974, EXP BRAIN RES, V21, P447
   Creusen MEH, 2005, J PROD INNOVAT MANAG, V22, P63, DOI 10.1111/j.0737-6782.2005.00103.x
   CURCIO CA, 1990, J COMP NEUROL, V292, P497, DOI 10.1002/cne.902920402
   D'Angelo S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2492, DOI 10.1145/2858036.2858499
   Drewes H, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319818
   Duchowski A., 2007, Eye Tracking Methodology", P51, DOI [10.1007/978-1-84628-609-45, DOI 10.1007/978-1-84628-609-4_5]
   Duchowski AT, 2018, COMPUT GRAPH-UK, V73, P59, DOI 10.1016/j.cag.2018.04.002
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Eberz S, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23203
   Ehinger BV, 2019, PEERJ, V7, DOI 10.7717/peerj.7086
   Eivazi S, 2017, ACTA NEUROCHIR, V159, P959, DOI 10.1007/s00701-017-3185-1
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Grillon H., 2006, Int. J. Disability Hum. Develop., V5, P243
   Grudzewski F, 2018, ECON BUS REV-POL, V4, P36, DOI 10.18559/ebr.2018.3.4
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Hackl C., 2017, Marketing new realities: An introduction to virtual reality and augmented reality marketing branding and communications
   Hansen JP, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206344
   Harezlak K, 2014, PROCEDIA COMPUT SCI, V35, P1073, DOI 10.1016/j.procs.2014.08.194
   Harris DJ, 2021, VIRTUAL REAL-LONDON, V25, P961, DOI 10.1007/s10055-021-00501-w
   Harris DJ, 2021, J EXP PSYCHOL HUMAN, V47, P308, DOI 10.1037/xhp0000800
   Harris DJ, 2020, PSYCHOL SPORT EXERC, V50, DOI 10.1016/j.psychsport.2020.101721
   Harris DJ, 2020, COGN PROCESS, V21, P209, DOI 10.1007/s10339-020-00954-y
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Hausamann P, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391365
   Hirzle T, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391313
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Holmqvist K., 2012, P S EYE TRACK RES AP, P45, DOI [DOI 10.1145/2168556.2168563, 10.1145/2168556.2168563]
   Holmqvist K., 2011, Eye Tracking: A Comprehensive Guide To Methods And Measures
   Hu ZM, 2019, IEEE T VIS COMPUT GR, V25, P2002, DOI 10.1109/TVCG.2019.2899187
   Iskander J, 2019, IEEE SYS MAN CYBERN, P1844, DOI 10.1109/SMC.2019.8914577
   Jacob R., 2016, interactions, V23, P62, DOI [DOI 10.1145/2978577, 10.1145/2978577]
   Jacob R.J., 1990, P SIGCHI C HUM FACT, P11, DOI DOI 10.1145/97243.97246
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   John B, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319816
   John B, 2020, IEEE T VIS COMPUT GR, V26, P1880, DOI 10.1109/TVCG.2020.2973052
   Joshi Y, 2020, IEEE ACCESS, V8, P39013, DOI 10.1109/ACCESS.2020.2975032
   Kahn BE, 2017, J RETAILING, V93, P29, DOI 10.1016/j.jretai.2016.11.004
   Katsini C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376840
   Kiili K, 2014, INT J SERIOUS GAMES, V1, P51, DOI 10.17083/ijsg.v1i2.15
   Kinnunen T, 2010, P S EYE TRACK RES AP, P187
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Kothari R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59251-5
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kourkoumelis N, 2011, THESCIENTIFICWORLDJO, V11, P520, DOI 10.1100/tsw.2011.52
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Kroger J. L., 2019, On the Privacy Implications of Eye Tracking, P226, DOI DOI 10.1007/978-3-030-42504-315
   Kudo H, 1998, P ANN INT IEEE EMBS, V20, P3180, DOI 10.1109/IEMBS.1998.746169
   Kumar D, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2358, DOI 10.1109/ICACCI.2016.7732407
   Lai ML, 2013, EDUC RES REV-NETH, V10, P90, DOI 10.1016/j.edurev.2013.10.001
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Leigh R, 2015, The neurology of eye movements, P169, DOI [DOI 10.1093/MED/9780199969289.003.0004, DOI 10.1093/MED/9780199969289.001.0001]
   Lemon KN, 2016, J MARKETING, V80, P69, DOI 10.1509/jm.15.0420
   Liebers J, 2020, ACM S EYE TRACKING R, P1, DOI [10.1145/3379157.3391421, DOI 10.1145/3379157.3391421]
   Lohr D, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3208333
   Lohse GL, 1997, J ADVERTISING, V26, P61, DOI 10.1080/00913367.1997.10673518
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Lungaro P, 2018, IEEE T VIS COMPUT GR, V24, P1535, DOI 10.1109/TVCG.2018.2794119
   Luro FL, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318153
   Lutz Otto Hans-Martin, 2017, Current Directions in Biomedical Engineering, V3, P53, DOI 10.1515/cdbme-2017-0012
   Ma XY, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P263, DOI 10.1145/3172944.3172988
   Majaranta P., 2014, ADV PHYSL COMPUTING, P39, DOI DOI 10.1007/978-1-4471-6392-3_3
   Mann DTY, 2007, J SPORT EXERCISE PSY, V29, P457, DOI 10.1123/jsep.29.4.457
   Mathis Florian, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382827
   Matsuda N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073590
   Mayer S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376340
   Mayer S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174227
   Meissner M, 2019, J BUS RES, V100, P445, DOI 10.1016/j.jbusres.2017.09.028
   Melcher D, 2008, TRENDS COGN SCI, V12, P466, DOI 10.1016/j.tics.2008.09.003
   Miao Y, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105132
   Mohan P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P79, DOI 10.1109/ISMAR-Adjunct.2018.00039
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mowrer OH, 1936, AM J PHYSIOL, V114, P423, DOI 10.1152/ajplegacy.1935.114.2.423
   Orlosky J, 2017, IEEE T VIS COMPUT GR, V23, P1417, DOI 10.1109/TVCG.2017.2657018
   Otero-Millan J, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00052
   Outram BI, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204555
   Ozcinar C, 2019, IEEE J EM SEL TOP C, V9, P217, DOI 10.1109/JETCAS.2019.2895096
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Pai YunSuen., 2017, ACM SIGGRAPH 2017 Posters, P23, DOI 10.1145/3102163.3102183
   Pastel S, 2023, MULTIMED TOOLS APPL, V82, P4181, DOI 10.1007/s11042-022-13474-y
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pejsa T, 2017, LECT NOTES ARTIF INT, V10498, P347, DOI 10.1007/978-3-319-67401-8_45
   Pfeiffer J, 2020, INFORM SYST RES, V31, P675, DOI 10.1287/isre.2019.0907
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Pulay MA, 2015, STUD HEALTH TECHNOL, V217, P840, DOI 10.3233/978-1-61499-566-1-840
   Qian YY, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P130, DOI 10.1145/3267782.3267798
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Rajanna V, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204541
   Ramaioli C, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00321
   Rappa NA, 2022, INTERACT LEARN ENVIR, V30, P1338, DOI 10.1080/10494820.2019.1702560
   Renshaw T, 2009, HORIZON, V17, P408, DOI 10.1108/10748120910998425
   Richard A, 2020, ARXIV
   Richter C., 2019, J VISUAL-JAPAN, V19, p147a, DOI [10.1167/19.10.147a, DOI 10.1167/19.10.147A]
   Roberts D, 2003, PRESENCE-TELEOP VIRT, V12, P644, DOI 10.1162/105474603322955932
   ROBINSON DA, 1965, J PHYSIOL-LONDON, V180, P569, DOI 10.1113/jphysiol.1965.sp007718
   ROBINSON DA, 1963, IEEE T BIO-MED ENG, VBM10, P137, DOI 10.1109/TBMEL.1963.4322822
   Rojas JC, 2015, PACKAG TECHNOL SCI, V28, P1047, DOI 10.1002/pts.2178
   Romero-Rondón MF, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P494, DOI 10.1145/3204949.3208114
   Ruthenbeck GS, 2015, J SIMUL, V9, P16, DOI 10.1057/jos.2014.14
   Schwartz G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392493
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Shimizu J, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1773, DOI 10.1145/2968219.2968274
   Sibert LindaE., 2000, P ACM SIGCHI C HUMAN, P281, DOI DOI 10.1145/332040.332445
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Spakov O., 2014, Proceedings of the Symposium on Eye Tracking Research and Applications, ETRA'14, P35, DOI DOI 10.1145/2578153.2578157
   Steil J, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319915
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Stellmach Sophie., 2012, P S EYE TRACKING RES, P131, DOI [https://doi.org/10.1145/2168556.2168577, DOI 10.1145/2168556.2168577]
   Steptoe W, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1039
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Tafaj E., 2012, P S EYE TRACK RES AP, P285, DOI DOI 10.1145/2168556.2168617
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Tao L, 2020, NEUROL SCI, V41, P1697, DOI 10.1007/s10072-020-04310-y
   Tatiyosyan SA, 2020, RESTOR NEUROL NEUROS, V38, P119, DOI 10.3233/RNN-190937
   Tichon JG, 2014, COGN TECHNOL WORK, V16, P203, DOI 10.1007/s10111-013-0257-8
   TOATES FM, 1974, DOC OPHTHALMOL, V37, P153, DOI 10.1007/BF00149678
   Trillenberg P, 2004, CURR OPIN NEUROL, V17, P43, DOI 10.1097/00019052-200402000-00008
   Turner E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P711, DOI 10.1109/VR.2018.8446142
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Vickers J.N., 2000, INT J SPORTS VISION, V6, P30
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wedel M, 2020, INT J RES MARK, V37, P443, DOI 10.1016/j.ijresmar.2020.04.004
   Weier M, 2017, COMPUT GRAPH FORUM, V36, P611, DOI 10.1111/cgf.13150
   Whitmire E, 2016, IEEE INT SYM WRBL CO, P184, DOI 10.1145/2971763.2971771
   Xiao J, 2019, IEEE ACCESS, V7, P22059, DOI 10.1109/ACCESS.2019.2898324
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Yongtuo Zhang, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161410
   Zank M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P49, DOI 10.1109/3DUI.2016.7460030
   Zeleznik RC, 2005, LOOK THAT THERE EXPL
   Zeng Z, 2020, J EYE MOVEMENT RES, V13, DOI 10.16910/jemr.13.1.3
   Zhang GT, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364707
   Zhang LM, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102639
   Zhen Liang, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P728, DOI 10.1109/ICSPCC.2012.6335584
NR 175
TC 31
Z9 32
U1 55
U2 161
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1481
EP 1505
DI 10.1007/s10055-022-00738-z
EA JAN 2023
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000916172100001
PM 37621305
OA hybrid
DA 2024-07-18
ER

PT J
AU Yilmaz, D
   Sahiner, NC
AF Yilmaz, Diler
   Sahiner, Nejla Canbulat
TI The effects of virtual reality glasses and external cold and vibration
   on procedural pain and anxiety in children during venous phlebotomy:
   randomized controlled trial
SO VIRTUAL REALITY
LA English
DT Article
DE Pain; Distraction; Children; Needle procedures
ID MANAGEMENT; VENIPUNCTURE; STIMULATION
AB Needle-related procedures are among the most feared and painful experiences reported by children and their parent. For this reason, use of effective methods of pain relief is very important during phlebotomy procedures in children. The aim of this study is to research two different distraction methods (external cold and vibration-Buzzy + virtual reality) on relief of procedural pain and anxiety in children during phlebotomy. This study is a prospective, randomized and controlled trial. Sample of the study consisted of a total of 119 children who met the sample selection criteria. Children aged 7 to 12 years who required phlebotomy were divided into three groups: buzzy (n = 40), virtual reality (n = 40), and control (n = 39). Data were collected using the information form, Wong-Baker FACES Pain Rating Scale, and Children's Fear Scale. In the study, 119 children [girls n = 59 (49.6%), boys n = 60 (50.4%)] were included. The children's pain levels were assessed and reported by the parents and observers and the children themselves who self-reported using Wong-Baker FACES. The children's anxiety levels were also assessed using the Children's Fear Scale. A significant difference was found between the groups in terms of the parent-reported and observer-reported assessments (p < 0.05). In the self-reported assessment, the pain levels of the VR and Buzzy group were lower than the control group, but were not statistically significant (p > 0.05). According to the parent-reported and observer-reported assessments, a significant difference was found between procedural anxiety levels. VR is more effective than external cold and vibration-Buzzy in reducing pain during phlebotomy and should be preferred as the first choice.
C1 [Yilmaz, Diler] Bandirma Onyedi Eylul Univ, Fac Hlth Sci, Dept Pediat Nursing, TR-10200 Bandirma, Balikesir, Turkey.
   [Sahiner, Nejla Canbulat] Karamanoglu Mehmetbey Univ, Fac Hlth Sci, Dept Pediat Nursing, Karaman, Turkey.
C3 Bandirma Onyedi Eylul University; Karamanoglu Mehmetbey University
RP Yilmaz, D (corresponding author), Bandirma Onyedi Eylul Univ, Fac Hlth Sci, Dept Pediat Nursing, TR-10200 Bandirma, Balikesir, Turkey.
EM daydin@bandirma.edu.tr; ncanbulat@gmail.com
RI Canbulat Şahiner, Nejla/AAK-5403-2021
OI Canbulat Şahiner, Nejla/0000-0003-3322-5372; Yilmaz,
   Diler/0000-0003-4043-0411
CR Arane K, 2017, CAN FAM PHYSICIAN, V63, P932
   Aydin D, 2016, J CLIN NURS, V25, P2328, DOI 10.1111/jocn.13321
   Ballard A, 2018, SYST REV-LONDON, V7, DOI 10.1186/s13643-018-0738-1
   Bergomi P, 2018, J PEDIATR NURS, V42, pE66, DOI 10.1016/j.pedn.2018.04.011
   Canbulat N, 2015, PAIN MANAG NURS, V16, P33, DOI 10.1016/j.pmn.2014.03.003
   Custódio NB, 2021, BRAZ ORAL RES, V35, DOI 10.1590/1807-3107bor-2021.vol35.0026
   Czarnecki ML, 2011, PAIN MANAG NURS, V12, P154, DOI 10.1016/j.pmn.2010.07.001
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Erdogan B, 2021, J PEDIATR NURS, V58, DOI 10.1016/j.pedn.2021.01.001
   Faul F., 2014, G* Power (Version 3.1. 9.2)[software]
   Gerçeker GÖ, 2018, J PERIANESTH NURS, V33, P981, DOI 10.1016/j.jopan.2017.12.010
   Gerçeker GÖ, 2021, EUR J ONCOL NURS, V50, DOI 10.1016/j.ejon.2020.101886
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Hur Y, 2016, ASIA PACIFIC P APPL, V7, P136, DOI [10.21742/asehl.2016.7.31, DOI 10.21742/ASEHL.2016.7.31]
   Inal S., 2015, Saglik Bilimleri ve Meslekleri Dergisi, V2, P372, DOI [10.17681/hsp.47420, DOI 10.17681/HSP.47420]
   Inal S, 2020, PEDIATR EMERG CARE, V36, P66, DOI 10.1097/PEC.0000000000001264
   Jibb LA, 2018, PEDIATR BLOOD CANCER, V65, DOI 10.1002/pbc.27242
   Kerimoglu B, 2013, ANESTH ANALG, V117, P1373, DOI 10.1213/ANE.0b013e3182a8c18f
   Khadra C, 2018, J PAIN RES, V11, P343, DOI 10.2147/JPR.S151084
   Litwin SP, 2021, CLIN J PAIN, V37, P94, DOI 10.1097/AJP.0000000000000894
   Moadad N, 2016, J PEDIATR NURS, V31, P64, DOI 10.1016/j.pedn.2015.07.010
   Piskorz J, 2018, J SPEC PEDIATR NURS, V23, DOI 10.1111/jspn.12201
   Redfern RE, 2018, J PEDIATR NURS, V38, P1, DOI 10.1016/j.pedn.2017.09.009
   Sahiner NC, 2015, J PERIANESTH NURS, V30, P228, DOI 10.1016/j.jopan.2014.05.011
   Scapin SQ, 2017, REV BRAS ENFERM, V70, P1291, DOI 10.1590/0034-7167-2016-0575
   Schreiber S, 2016, ACTA PAEDIATR, V105, pE12, DOI 10.1111/apa.13224
   Semerci R, 2021, J PEDIATR ONCOL NURS, V38, P142, DOI 10.1177/1043454220975702
   Susam Volkan, 2018, Acta Biomed, V89, P6, DOI 10.23750/abm.v89i6-S.7378
   Tork H. M. M., 2017, American Journal of Nursing Science, V6, P26, DOI [10.11648/j.ajns.20170601.14, DOI 10.11648/J.AJNS.20170601.14]
   Uman LS, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005179
   Wieland LS, 2019, EXPLORE-NY, V15, P74, DOI 10.1016/j.explore.2018.10.014
   Wong D L, 1988, Pediatr Nurs, V14, P9
NR 32
TC 0
Z9 0
U1 7
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3393
EP 3401
DI 10.1007/s10055-022-00714-7
EA NOV 2022
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000879127900001
DA 2024-07-18
ER

PT J
AU Wang, ZH
   He, RK
   Rebelo, F
   Vilar, E
   Noriega, P
AF Wang, Zihao
   He, Renke
   Rebelo, Francisco
   Vilar, Elisangela
   Noriega, Paulo
TI Human interaction with virtual reality: investigating pre-evacuation
   efficiency in building emergency
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Emergency evacuation; Evacuation alarm; VR-based
   evaluation
ID EVACUATION EXPERIMENTS; SOCIAL-INFLUENCE; EXIT CHOICE; BEHAVIOR; FIRE;
   DECISION; TIME
AB The current manuscript verifies the use of virtual reality (VR)-based methodology as a helpful way to study human behavior during the pre-evacuation period, considering the influence of pre-emergency activity (competitive tasks). Two conditions with different engagement levels (i.e., low and high) were set up, and sixty company workers were distributed across conditions randomly. Five types of evacuation behaviors were defined, and compliance behavior results showed most participants (66.7%) evacuated with the ISO-type evacuation alarm in low engagement condition, whereas only 20% of participants evacuated in high engagement situation. Statistical results confirmed the influence of pre-emergency activity on evacuation efficiency. Open-ended questions summarized three levels of knowledge background that justified the reasons/motivations behind pre-evacuation behaviors. simulator sickness, presence, and usability questionnaires confirmed the variable control between conditions. In summary, the VR-based methodology successfully reproduced evacuation behaviors similar to real situations, with the influence of pre-emergency activity. This study added a step to the efficacy of using VR as a tool to study human behavior during the pre-evacuation period and pointed out the need for the next generation of alarms, which will improve human safety in building emergencies.
C1 [Wang, Zihao; He, Renke] Hunan Univ, Sch Design, Changsha 410082, Hunan, Peoples R China.
   [Wang, Zihao] Univ Lisbon, Fac Arquitetura, Rua Sa Nogueira, P-1349055 Lisbon, Portugal.
   [Wang, Zihao] China Acad Art, Hangzhou 310024, Peoples R China.
   [Rebelo, Francisco; Vilar, Elisangela; Noriega, Paulo] Univ Lisbon, Lisbon Sch Architecture, Res Ctr Architecture Urbanism & Design, CIAUD, Rua Sa Nogueira, P-1349063 Lisbon, Portugal.
   [Rebelo, Francisco; Vilar, Elisangela; Noriega, Paulo] Univ Lisbon, Interact Technol Inst, ITI LARSyS, Rua Sa Nogueira, P-1349055 Lisbon, Portugal.
   [Rebelo, Francisco; Vilar, Elisangela; Noriega, Paulo] Univ Lisbon, Fac Arquitetura, ErgoUX Lab, Rua Sa Nogueira, P-1349055 Lisbon, Portugal.
C3 Hunan University; Universidade de Lisboa; China Academy of Art;
   Universidade de Lisboa; Universidade de Lisboa; Universidade de Lisboa
RP Wang, ZH (corresponding author), Hunan Univ, Sch Design, Changsha 410082, Hunan, Peoples R China.; Wang, ZH (corresponding author), Univ Lisbon, Fac Arquitetura, Rua Sa Nogueira, P-1349055 Lisbon, Portugal.; Wang, ZH (corresponding author), China Acad Art, Hangzhou 310024, Peoples R China.
EM wangzihao0716@gmail.com; renke8@163.com; frebelo@fa.ulisboa.pt;
   ebpvilar@edu.ulisboa.pt; pnoriega@edu.ulisboa.pt
RI Vilar, Elisangela/B-4291-2012; Wang, Zihao/AAJ-3541-2020; Rebelo,
   Francisco/C-7805-2011; Noriega, Paulo/D-2470-2017
OI Vilar, Elisangela/0000-0002-3320-7580; Wang, Zihao/0000-0001-6953-0470;
   Rebelo, Francisco/0000-0002-3250-8445; Noriega,
   Paulo/0000-0002-0433-6201; Wang, Zihao/0000-0002-0984-511X
FU FCT-Fundacao para a Ciencia e a Tecnologia, I.P. [UIDB/04008/2020,
   UIDP/04008/2020]; ITI -LARSyS, FCT [UIDB/50009/2020]; China Government
   Scholarship [201906130192]
FX This work is financed by the national funds through FCT-FundacAo para a
   Ciencia e a Tecnologia, I.P., under the Strategic Project with the
   references UIDB/04008/2020 and UIDP/04008/2020 and by ITI -LARSyS, FCT
   Pluriannual funding's 2020-2023 (UIDB/50009/2020); the China Government
   Scholarship [Grant Number 201906130192]; we would like to thank Ms.
   Xinyi Li (Assistant to Chairman) from Sinocare Inc. (Changsha, China,
   Stock Code: 300298) for providing samples and experiment resources.
CR Abdelgawad H, 2009, TRANSP LETT, V1, P41, DOI 10.3328/TL.2009.01.01.41-58
   Andrée K, 2016, FIRE MATER, V40, P554, DOI 10.1002/fam.2310
   Arias S, 2019, FIRE SAFETY J, V109, DOI 10.1016/j.firesaf.2019.102861
   Averill, FEDERAL BUILDING FIR
   Averill JD, 2013, FIRE TECHNOL, V49, P37, DOI 10.1007/s10694-012-0260-2
   Bourhim E, 2020, INT J HUM-COMPUT ST, V142, DOI 10.1016/j.ijhcs.2020.102484
   Bruck D, 2007, HUM FACTORS, V49, P585, DOI 10.1518/001872007X215674
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   DONALD I, 1992, EUR J SOC PSYCHOL, V22, P203, DOI 10.1002/ejsp.2420220302
   Duarte E, 2014, APPL ERGON, V45, P1367, DOI 10.1016/j.apergo.2013.10.004
   Fahy R.F., 2001, Proceedings of the 2nd International Symposium on Human Behavior in Fire, P175
   Galea ER, 2017, FIRE MATER, V41, P467, DOI 10.1002/fam.2424
   Gamberini L, 2015, COMPUT HUM BEHAV, V48, P104, DOI 10.1016/j.chb.2015.01.040
   Gershon RRM, 2012, FIRE MATER, V36, P481, DOI 10.1002/fam.1080
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Guha-Sapir D., 2012, ANN DISASTER STAT RE
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kinateder M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00043
   Kinateder M, 2014, APPL ERGON, V45, P1649, DOI 10.1016/j.apergo.2014.05.014
   Kinateder Max T, 2015, Fire Sci Rev, V4, P1
   Kobes M, 2010, FIRE SAFETY J, V45, P1, DOI 10.1016/j.firesaf.2009.08.005
   Kuligowski, 2010, 1664 NIST TN, V1664, P1, DOI DOI 10.6028/NIST.TN.1664
   Kuligowski ED, 2009, FIRE SAFETY J, V44, P487, DOI 10.1016/j.firesaf.2008.10.001
   Lin J, 2020, SAFETY SCI, V122, DOI 10.1016/j.ssci.2019.104540
   Lindell MK, 2012, RISK ANAL, V32, P616, DOI 10.1111/j.1539-6924.2011.01647.x
   Liu M, 2011, AUTOMAT CONSTR, V20, P620, DOI 10.1016/j.autcon.2010.12.004
   Lovreglio R, 2014, PROCD SOC BEHV, V160, P390, DOI 10.1016/j.sbspro.2014.12.151
   Meng FX, 2014, ERGONOMICS, V57, P816, DOI 10.1080/00140139.2014.904006
   Nilsson D, 2009, FIRE SAFETY J, V44, P71, DOI 10.1016/j.firesaf.2008.03.008
   Proulx G., 2003, J FIRE PROT ENG, V13, P67, DOI [10.1177/1042391503013001004, DOI 10.1177/1042391503013001004]
   Purser DA, 2001, SAFETY SCI, V38, P157, DOI 10.1016/S0925-7535(00)00066-7
   Rahouti A., 2020, Collect. Dyn, V5, pA44, DOI [10.17815/CD.2020.44, DOI 10.17815/CD.2020.44]
   Ronchi E, 2016, FIRE TECHNOL, V52, P623, DOI 10.1007/s10694-015-0462-5
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Smith SP, 2009, FIRE SAFETY J, V44, P559, DOI 10.1016/j.firesaf.2008.11.004
   Society of Fire Protection Engineers, 2019, SFPE GUIDE HUMAN BEH, DOI [10.1007/978-3-319-94697, DOI 10.1007/978-3-319-94697]
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Talbert M, 2013, VALUE HEALTH, V16, pA596, DOI 10.1016/j.jval.2013.08.1674
   TONG D, 1985, FIRE SAFETY J, V9, P257, DOI 10.1016/0379-7112(85)90036-0
   Vilar E, 2014, ERGONOMICS, V57, P511, DOI 10.1080/00140139.2014.895054
   Vilar E, 2013, APPL ERGON, V44, P618, DOI 10.1016/j.apergo.2012.12.002
   Wang B, 2014, SCI WORLD J, DOI 10.1155/2014/589016
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wogalter MS, 2006, HUM FAC ER, P51
   Zhao CM, 2009, FIRE TECHNOL, V45, P71, DOI 10.1007/s10694-007-0040-6
   Zhao JY, 2020, SPAT COGN COMPUT, V20, P328, DOI 10.1080/13875868.2020.1817925
   Zou H, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000679
NR 48
TC 2
Z9 2
U1 19
U2 67
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1039
EP 1050
DI 10.1007/s10055-022-00710-x
EA OCT 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000873355600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Selzer, MN
   Larrea, ML
   Castro, SM
AF Nicolas Selzer, Matias
   Leonardo Larrea, Martin
   Mabel Castro, Silvia
TI Analysis of translation gains in virtual reality: the limits of space
   manipulation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Human-computer interaction; Locomotion techniques;
   Translation gains
ID WALKING; CYBERSICKNESS
AB Physically walking in Virtual Reality (VR) creates a truly compelling user experience. Many navigation techniques for VR have been presented in the literature. The room-scale technique allows a natural and intuitive navigation through physically walking in the virtual environment, but it is limited to the available physical space. The dimensions of the virtual space can be extended by applying translation gains, i.e., a mapping of physical movements to virtual ones. Previous works have studied the threshold at which users detect the spatial manipulation. However, little is known about the user experience and usability beyond this threshold. This paper presents a user study with 110 participants that explores the effect of using translation gains beyond the detection threshold on cybersickness and presence. The objective of this paper is to assess whether translations gains higher than the ones used in redirection techniques can be used for walking in a bigger virtual environment than the tracking area without influencing user comfort and experience. Results showed no difference in presence scores and minimal cybersickness symptoms when using no gain and a 1.5 x gain, but started to be of concern with a 2 x gain. This contribution supports the use of translation gains and the development of novel applications that allow the exploration of bigger virtual environments, thus improving presence and user experience.
C1 [Nicolas Selzer, Matias; Leonardo Larrea, Martin; Mabel Castro, Silvia] Univ Nacl Sur, Inst Comp Sci & Engn UNS CONICET, Dept Comp Sci & Engn, VyGLab Res Lab UNS CICPBA, Blanca, Bahia, Argentina.
C3 National University of the South
RP Selzer, MN (corresponding author), Univ Nacl Sur, Inst Comp Sci & Engn UNS CONICET, Dept Comp Sci & Engn, VyGLab Res Lab UNS CICPBA, Blanca, Bahia, Argentina.
EM matias.selzer@cs.uns.edu.ar; mll@cs.uns.edu.ar; smc@cs.uns.edu.ar
OI Larrea, Martin/0000-0003-3067-464X
CR Aïm F, 2016, ARTHROSCOPY, V32, P224, DOI 10.1016/j.arthro.2015.07.023
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Almeida A, 2018, ADV INTELL SYST, V588, P26, DOI 10.1007/978-3-319-60582-1_3
   [Anonymous], 1975, Motion sickness
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Barbosa L, 2017, 2017 24 ENCONTRO PORTUGUES DE COMPUTACAO GRAFICA E INTERACAO (EPCGI)
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bouguila L, 2002, P IEEE VIRT REAL ANN, P291, DOI 10.1109/VR.2002.996544
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Cheok Adrian David, 2009, International Journal of Virtual Reality, V8, P83
   Cortes CAT, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365694
   Ferracani A, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095728
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   Gromer D, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00372
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Ishak S, 2018, PERCEPTION, V47, P521, DOI 10.1177/0301006618761336
   Iwata H, 2006, INT C COMPUTER GRAPH
   Kaur K, 1997, HUMAN-COMPUTER INTERACTION - INTERACT '97, P636
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Laarni J., 2015, Immersed in Media: Telepresence Theory, Measurement Technology, P139, DOI [DOI 10.1007/978-3-319-10190-3, 10.1007/978-3-319-10190-3, DOI 10.1007/978-3-319-10190-3_8]
   Langbehn E, 2015, EVALUATION OMNIDIREC, P149
   Langbehn E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P767, DOI 10.1109/VR.2018.8446167
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Mayor J, 2021, IEEE T EMERG TOP COM, V9, P1542, DOI 10.1109/TETC.2019.2915287
   Messinis I, 2010, 2010 INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING: IC4E 2010, PROCEEDINGS, P428, DOI 10.1109/IC4E.2010.137
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Oberdorfer S., 2018, P 6 S SPAT US INT OC, P89, DOI [10.1145/3267782.3267787, DOI 10.1145/3267782.3267787]
   Razzaque S., 2005, REDIRECTED WALKING
   Riva G, 2003, IJSSELSTEIJN BEING T
   Ruddle RA, 2004, INT J HUM-COMPUT ST, V60, P299, DOI 10.1016/j.ijhcs.2003.10.001
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Schuemie MJ, 2005, EUROMEDIA '2005: 11TH ANNUAL EUROMEDIA CONFERENCE, P129
   Schwaiger M, 2007, LECT NOTES COMPUT SC, V4551, P926
   Selzer MN, 2019, DISPLAYS, V59, P9, DOI 10.1016/j.displa.2019.04.002
   Selzer MN., 2021, IEEE COMPUT GR APPL, V5, P769
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2010, P IEEE VIRT REAL ANN, P305, DOI 10.1109/VR.2010.5444752
   Tyrrell R, 2018, VIRTUAL REAL-LONDON, V22, P211, DOI 10.1007/s10055-017-0324-1
   Unity, 2021, VRTK
   Unity, 2021, UNITY 3D
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 60
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1459
EP 1469
DI 10.1007/s10055-022-00640-8
EA MAR 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000770720300001
DA 2024-07-18
ER

PT J
AU Zeng, Q
   Zheng, G
   Liu, Q
AF Zeng, Qiang
   Zheng, Gang
   Liu, Qian
TI PE-DLS: a novel method for performing real-time full-body motion
   reconstruction in VR based on Vive trackers
SO VIRTUAL REALITY
LA English
DT Article
DE Motion capture; Virtual reality; Full-body motion reconstruction;
   Inverse kinematics; Vive tracker
ID INVERSE KINEMATICS TECHNIQUES; ANIMATION
AB Real-time full-body motion capture (MoCap) is becoming necessary for enabling natural interactions and creating deeper immersion in virtual reality (VR). To reduce the cost and complexity of MoCap systems, some studies attempt to track only the joint data of root and end effectors and reconstruct full-body motion by solving inverse kinematics (IK) problems. However, ensuring the accuracy of full-body motion reconstruction in real-time is challenging because the problem is inherently under-constrained. In this paper, we propose PE-DLS, a novel method to perform full-body motion reconstruction in two stages: pose estimation (PE) and damped least squares (DLS) optimization. First, we use analytical IK solvers to estimate the spine and limbs in sequence. To further improve model accuracy, we use the DLS method to optimize the results obtained from PE. To evaluate the model performance, we compare it with other methods in terms of the reconstruction error and computational time of full-body reconstruction via testing on publicly available datasets. These results indicate that PE-DLS outperforms other methods in terms of the mean per joint position error (2.11 cm) and mean per joint rotation error (10.75 degrees) with low time cost (1.65 ms per frame). Furthermore, we implement a full-body MoCap system based on an HTC Vive headset and five Vive trackers. Live demos and qualitative comparisons show that our system achieves comparable quality to the commercial MoCap system. With high accuracy and low time cost, PE-DLS contributes to construct a real-time MoCap system in VR.
C1 [Zeng, Qiang] Huazhong Univ Sci & Technol, Wuhan Natl Lab Optoelect, Wuhan 430074, Peoples R China.
   [Zheng, Gang] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
   [Liu, Qian] Hainan Univ, Sch Biomed Engn, Key Lab Biomed Engn Hainan Prov, Haikou 570228, Hainan, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; Hainan University
RP Liu, Q (corresponding author), Hainan Univ, Sch Biomed Engn, Key Lab Biomed Engn Hainan Prov, Haikou 570228, Hainan, Peoples R China.
EM zengqiang18@hust.edu.cn; ZhengGang@hust.edu.cn; qliu@hainanu.edu.cn
RI Liu, Qian/D-8184-2011; liu, qian/HDM-2936-2022; Qian, Liu/GYU-5886-2022;
   zheng, gang/KMX-5568-2024
OI Liu, Qian/0000-0002-8398-1021; 
FU NSF [EIA-0196217]
FX We appreciated Sebastian Starke for sharing the Unity3D implementation
   of the Bio-IK online. The data used in this project was obtained from
   http://mocap.cs.cmu.edu.The database was created with funding from NSF
   EIA-0196217.
CR Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Boulic R., 2006, VIRTUAL REALITY, V10, P48
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   Buss S. R., 2004, IEEE J ROBOTIC AUTOM, V17, P16
   Caserman P, 2019, IEEE INT CONF SERIOU, DOI 10.1109/segah.2019.8882429
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Caserman P, 2020, IEEE T VIS COMPUT GR, V26, P3089, DOI 10.1109/TVCG.2019.2912607
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Genova C, 2022, VIRTUAL REAL-LONDON, V26, P187, DOI 10.1007/s10055-021-00547-w
   Giuberti, 2014, INERTIAL SENSING HUM, P1
   Gonçalves G, 2022, VIRTUAL REAL-LONDON, V26, P1, DOI 10.1007/s10055-021-00530-5
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Harish P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2887740
   Ho ESL, 2013, COMPUT GRAPH FORUM, V32, P61, DOI 10.1111/cgf.12212
   Huang J, 2017, COMPUT GRAPH FORUM, V36, P418, DOI 10.1111/cgf.13089
   Jiang F, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P309, DOI 10.1145/3013971.3013987
   Jongmin Kim, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P31, DOI 10.1007/978-3-642-34710-8_4
   Kallmann M, 2008, COMPUT ANIMAT VIRT W, V19, P79, DOI 10.1002/cav.176
   Kenwright B., 2012, J GRAPHICS TOOLS, V16, P177, DOI DOI 10.1080/2165347X.2013.823362
   Korein JamesU., 1985, GEOMETRIC INVESTIGAT
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Leoncini P, 2017, LECT NOTES COMPUT SC, V10324, P131, DOI 10.1007/978-3-319-60922-5_10
   Liu H, 2011, S INTERACTIVE 3D GRA, P133
   Molla E., 2013, P MOT GAM, V2013, P165, DOI [10.1145/2522628.2522649, DOI 10.1145/2522628.2522649]
   Muller-Cajar R., 2007, P IM VIS COMP NZ, P181
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Seele S, 2017, HERES LOOKING YOU AN, P531, DOI [10.1145/3116595.3116619, DOI 10.1145/3116595.3116619]
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Starke S, 2019, IEEE T EVOLUT COMPUT, V23, P406, DOI 10.1109/TEVC.2018.2867601
   Thomas JS, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2623787
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Tolani D, 1996, PRESENCE-TELEOP VIRT, V5, P393, DOI 10.1162/pres.1996.5.4.393
   Tong LN, 2020, IEEE SENS J, V20, P3667, DOI 10.1109/JSEN.2019.2959639
   Unzueta L, 2008, GRAPH MODELS, V70, P87, DOI 10.1016/j.gmod.2008.03.002
   von Marcard T, 2016, IEEE T PATTERN ANAL, V38, P1533, DOI 10.1109/TPAMI.2016.2522398
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Xia SH, 2017, J COMPUT SCI TECH-CH, V32, P536, DOI 10.1007/s11390-017-1742-y
   Yamane K, 2003, IEEE T VIS COMPUT GR, V9, P352, DOI 10.1109/TVCG.2003.1207443
   Yi XY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459786
NR 41
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1391
EP 1407
DI 10.1007/s10055-022-00635-5
EA MAR 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000766084800002
DA 2024-07-18
ER

PT J
AU Horvat, N
   Martinec, T
   Lukacevic, F
   Perisic, MM
   Skec, S
AF Horvat, Nikola
   Martinec, Tomislav
   Lukacevic, Fanika
   Perisic, Marija Majda
   Skec, Stanko
TI The potential of immersive virtual reality for representations in design
   education
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Design education; Students' expertise;
   Constructivist learning theory; Design understanding; Visualisation
   technology; Design representation
ID SPATIAL PERCEPTION; USER; ENVIRONMENT; THINKING; MODELS; ANOVA
AB This paper examines the potential of immersive virtual reality technology for design education. A quasi-experimental study has been conducted with 40 students of different expertise levels. The students analysed a design representation using one of the two visualisation technologies: immersive virtual reality (IVR) and non-immersive virtual reality (nIVR). The results show that the expertise in the used technology and the expertise in the design domain significantly affect design understanding. On the other hand, the effect of contextual expertise was not found significant. Spatial ability affected design understanding in nIVR but not in the IVR. Visualisation technology did not have an overall effect on understanding, but IVR helped students with lower expertise to understand specific aspects of a design better (e.g. rotation-based mechanisms). The study suggests that researchers and educators control the students' expertise when assessing the effect of technology on design education. Overall, the results support the constructivist learning theory, as IVR can support context-dependent and context-independent understanding.
C1 [Horvat, Nikola; Martinec, Tomislav; Lukacevic, Fanika; Perisic, Marija Majda; Skec, Stanko] Univ Zagreb, Fac Mech Engn & Naval Architecture, Zagreb, Croatia.
C3 University of Zagreb; University of Zagreb Faculty of Mechanical
   Engineering & Naval Architecture
RP Horvat, N (corresponding author), Univ Zagreb, Fac Mech Engn & Naval Architecture, Zagreb, Croatia.
EM nikola.horvat@fsb.hr
RI Horvat, Nikola/B-2886-2018
OI Horvat, Nikola/0000-0002-6354-2734; Skec, Stanko/0000-0001-7549-8972;
   Lukacevic, Fanika/0000-0002-7980-1542
FU Croatian Science Foundation [IP-2018-01-7269]; Erasmus + project
   [2018-1-HR01-KA203-047486]
FX Croatian Science Foundation project IP-2018-01-7269: Team Adaptability
   for Innovation-Oriented Product Development - TAIDE. Erasmus + project
   2018-1-HR01-KA203-047486: ELPID - E-learning Platform for Innovative
   Product Development.
CR Alizadehsalehi S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073225
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   [Anonymous], 2009, Design expertise
   Banerjee P., 2002, J COMPUT INF SCI ENG, V2, P59, DOI [10.1115/ 1.1486218, DOI 10.1115/1.1486218]
   Becattini N., 2020, P DESIGN SOC DESIGN, V1, P1667
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Berg LP, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4034267
   Berni A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071064
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Camburn B, 2017, DES SCI, V3, DOI 10.1017/dsj.2017.10
   Ceylan S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 2, P54, DOI 10.5220/0009346800540063
   Coburn JQ, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4036921
   Concannon BJ, 2019, FRONT EDUC, V4, DOI 10.3389/feduc.2019.00080
   Cross N, 2004, DESIGN STUD, V25, P427, DOI 10.1016/j.destud.2004.06.002
   Cross N, 2007, BOARD INT RES DES, P017
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   D'Astous P, 2004, DESIGN STUD, V25, P625, DOI 10.1016/j.destud.2003.12.002
   de Casenave L, 2017, PROC ASME DES ENG TE
   Dorta T, 2016, DESIGN STUD, V47, P164, DOI 10.1016/j.destud.2016.09.003
   Dym CL, 2005, J ENG EDUC, V94, P103, DOI 10.1002/j.2168-9830.2005.tb00832.x
   Eftekharifar S., 2020, Journal of Perceptual Imaging, V3, p20502, DOI [DOI 10.2352/J.PERCEPT.IMAGING.2020.3.2.020502, 10.2352/J.Percept.Imaging.2020.3.2.020502]
   Fogarty J, 2018, J PROF ISS ENG ED PR, V144, DOI 10.1061/(ASCE)EI.1943-5541.0000349
   Freeman I, 2018, INT J INTERACT DES M, V12, P549, DOI 10.1007/s12008-017-0413-0
   Gero JS, 2004, DESIGN STUD, V25, P373, DOI 10.1016/j.destud.2003.10.010
   Gero JS., 2015, STUDYING VISUAL SPAT, DOI [10.1007/978-94-017-9297-4, DOI 10.1007/978-94-017-9297-4]
   GLASS GV, 1972, REV EDUC RES, V42, P237, DOI 10.3102/00346543042003237
   Goldstone R.L., 2018, Stevens Handbook of Experimental Psychology and Cognitive Neuroscience, VVolume 3, P275, DOI [DOI 10.1002/9781119170174.EPCN308, 10.1002/9781119170174.epcn308]
   Gul L.F., 2012, COMPUTATIONAL DESIGN, P139, DOI [DOI 10.4018/978-1-61350-180-1.CH009, 10.4018/978- 1-61350-180-1.ch009]
   Hamade RF, 2011, COMPUT IND ENG, V61, P709, DOI 10.1016/j.cie.2011.04.024
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Hamurcu A, 2020, J ENG DES TECHNOL, V18, P1889, DOI 10.1108/JEDT-02-2020-0048
   Hamurcu A, 2018, 2018 2ND INTERNATIONAL SYMPOSIUM ON MULTIDISCIPLINARY STUDIES AND INNOVATIVE TECHNOLOGIES (ISMSIT), P155
   Hannah R, 2012, J ENG DESIGN, V23, P443, DOI 10.1080/09544828.2011.615302
   Harasim L., 2017, LEARNING THEORY ONLI, V2nd, DOI DOI 10.4324/9781315716831
   Harasim L., 2018, Learning Theory and Online Technologies, P61, DOI [10.4324/9781315716831-5, DOI 10.4324/9781315716831-5]
   Hein G.E., 1991, CONSTRUCTIVIST LEARN
   Hernández-Chávez M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13179776
   Horvat N., 2020, P DESIGN SOC DESIGN, P187
   Horvat N., 2021, Proceedings of the Design Society, V1, P3329, DOI [10.1017/pds.2021.594, DOI 10.1017/PDS.2021.594]
   Horvat Nikola, 2019, P DES SOC INT C ENG, V1, P1923, DOI 10.1017/dsi.2019.198
   Hu WL, 2018, J MECH DESIGN, V140, DOI 10.1115/1.4040625
   Hu X., 2020, P DES SOC DES C, V1, P1305, DOI [10.1017/dsd.2020.91, DOI 10.1017/DSD.2020.91]
   Hubka V., 1988, Theory of Technical Systems, DOI DOI 10.1007/978-3-642-52121-8
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kandi VR, 2020, J ARCHIT ENG, V26, DOI 10.1061/(ASCE)AE.1943-5568.0000434
   Kinsella EA, 2006, REFLECT PRACT, V7, P277, DOI 10.1080/14623940600837319
   Langsrud Y, 2003, STAT COMPUT, V13, P163, DOI 10.1023/A:1023260610025
   Lee JH, 2021, DES J, V24, P503, DOI 10.1080/14606925.2021.1912902
   Liao KH, 2017, INT J TECHNOL DES ED, V27, P131, DOI 10.1007/s10798-015-9330-3
   Liu YF, 2018, ARCHIT ENG DES MANAG, V14, P457, DOI 10.1080/17452007.2018.1512042
   Lukacevic F, 2020, IEEE ACCESS, V8, P174587, DOI 10.1109/ACCESS.2020.3025634
   Lukacevic F, 2021, FRONT ENG MANAG, V8, P412, DOI 10.1007/s42524-020-0099-z
   MacCallum RC, 2002, PSYCHOL METHODS, V7, P19, DOI 10.1037//1082-989X.7.1.19
   Mahoney MJ, 2004, CONTEMP PSYCHOL, V49, P360, DOI 10.1037/004362
   Mohler B. J., 2013, Handbook of spatial cognition, P81, DOI DOI 10.1037/13936-005
   Morkos Beshoy, 2013, International Journal of Computer Aided Engineering and Technology, V5, P139
   Mosely G, 2018, THINK SKILLS CREAT, V27, P177, DOI 10.1016/j.tsc.2018.02.004
   Neroni MA, 2021, INT J DES CREAT INNO, V9, P139, DOI 10.1080/21650349.2021.1929500
   Newcombe N.S., 2015, STUDYING VISUAL SPAT, P179, DOI DOI 10.1007/978-94-017-9297-4_10
   Newcombe N.S., 2018, Stevens' handbook of experimental psychology and cognitive neuroscience, V3, P1, DOI DOI 10.1002/9781119170174.EPCN315
   Nisha B, 2019, EDUC PSYCHOL-UK, V39, P1233, DOI 10.1080/01443410.2019.1661356
   Obeid S, 2023, INTERACT LEARN ENVIR, V31, P1841, DOI 10.1080/10494820.2020.1858116
   Oh Y, 2013, DESIGN STUD, V34, P302, DOI 10.1016/j.destud.2012.08.004
   Ostrander JK, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4044006
   Özgen DS, 2021, INT J TECHNOL DES ED, V31, P357, DOI 10.1007/s10798-019-09554-0
   Paes D, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103849
   Paes D, 2017, AUTOMAT CONSTR, V84, P292, DOI 10.1016/j.autcon.2017.09.016
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Psenka CE, 2017, J INTEGR DES PROCESS, V21, P3, DOI 10.3233/jid-2017-0004
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Robson C., 2002, Real world research
   Safadel P, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165438
   Satter K, 2015, J COMPUT INF SCI ENG, V15, DOI 10.1115/1.4029750
   Schon D. A., 1983, The reflective practitioner: How professionals think in action
   Sopher H, 2019, BRIT J EDUC TECHNOL, V50, P2109, DOI 10.1111/bjet.12857
   Starkey EM, 2018, J MECH DESIGN, V140, DOI 10.1115/1.4039384
   Starkey EM, 2017, PROC ASME DES ENG TE
   Sun R, 2019, VIRTUAL REAL-LONDON, V23, P385, DOI 10.1007/s10055-018-0355-2
   Teklemariam HG, 2014, INT C ENG PROD DES E
   Tempelman E, 2011, INT J TECHNOL DES ED, V21, P261, DOI 10.1007/s10798-010-9118-4
   Valkenburg R., 1998, DESIGN STUD, V19, P249, DOI DOI 10.1016/S0142-694X(98)00011-8
   Ventura SM, 2020, J INF TECHNOL CONSTR, V25, P233, DOI 10.36680/j.itcon.2020.014
   Waks LJ, 2001, INT J TECHNOL DES ED, V11, P37, DOI 10.1023/A:1011251801044
   Waller D., 2013, Handbook of spatial cognition, DOI [https://doi.org/10.1037/13936-000, DOI 10.1037/13936-000]
   Yilmaz S, 2016, DESIGN STUD, V45, P137, DOI 10.1016/j.destud.2015.12.008
NR 85
TC 9
Z9 9
U1 17
U2 58
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1227
EP 1244
DI 10.1007/s10055-022-00630-w
EA JAN 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000749126900001
DA 2024-07-18
ER

PT J
AU Niu, MT
   Lo, CH
AF Niu, Mutian
   Lo, Cheng-Hung
TI Do we see rendered surface materials differently in virtual reality? A
   psychophysics-based investigation
SO VIRTUAL REALITY
LA English
DT Article
DE Material perception; Immersive viewing environment; Material
   visualization; Virtual reality; Design evaluation
ID VISUAL-PERCEPTION; GLOBAL ILLUMINATION; PROTOTYPING SYSTEM; AUGMENTED
   REALITY; SHAPE; REFLECTANCE; VALIDATION; MODEL; REPRESENTATION;
   VISUALIZATION
AB Synthesized surface materials are an essential visualization element to represent and simulate the appearances of virtual objects such as product prototypes. This paper investigates whether the perception of rendered surface materials would be different between a 3D immersive/VR viewing condition and a traditional 2D one. For rendered surface materials, roughness and specularity are the two major parameters that modulate the rendering outcome. In this study, we vary the two parameters and incorporate psychophysics techniques to derive a scale for measuring the perceivable changes of material appearance. Using the perceptual scale as the basis, we run a series of surface appearance matching tasks and compare the participants' task performances in the VR viewing mode and the 2D viewing mode. The results show that in the VR viewing mode, the participants identify the matching materials at higher levels of accuracy and precision. These findings show that the depth impression in immersive viewing environments may result in a different perceptual response to the rendered surface materials.
C1 [Niu, Mutian; Lo, Cheng-Hung] Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University
RP Lo, CH (corresponding author), Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.
EM ch.lo@xjtlu.edu.cn
RI Niu, Mutian/HTS-5684-2023
OI Lo, Cheng-Hung/0000-0002-7199-9339
FU Research Development Fund provided by Xi'an Jiaotong-Liverpool
   University [RDF 16-22-02]
FX This research is partially funded by the Research Development Fund
   provided by Xi'an Jiaotong-Liverpool University (Project ref. No.: RDF
   16-22-02).
CR Abidi MH., 2013, J MANAGE ENG INTEG, V6, P1
   Adler H.E, 1966, Elemente der Psychophysik Elements of psychophysics, V1
   [Anonymous], 2006, ACM Trans. Appl. Percept.
   Antonya Csaba, 2007, Virtual Reality, V11, P275, DOI 10.1007/s10055-007-0074-6
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Berzhanskaya J, 2005, PERCEPTION, V34, P565, DOI 10.1068/p5401
   Bordegoni M, 2006, COMPUT GRAPH-UK, V30, P377, DOI 10.1016/j.cag.2006.02.012
   Bouguila Laroussi, 2000, PROC 1 WORKSHOP HAPT, P54
   Brewer C. A., 2003, Cartogr. Geogr. Inf. Sci., V30, P5, DOI [10.1559/152304003100010929, DOI 10.1559/152304003100010929]
   Cheslack-Postava E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409081
   Choi SH, 2008, COMPUT IND, V59, P477, DOI 10.1016/j.compind.2007.12.003
   Choi SH, 2004, COMPUT AIDED DESIGN, V36, P401, DOI 10.1016/S0010-4485(03)00110-6
   Collins LM, 2014, AM J PREV MED, V47, P498, DOI 10.1016/j.amepre.2014.06.021
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   da Costa LALF, 2017, SYMP VIRTUAL AUGMENT, P169, DOI 10.1109/SVR.2017.30
   de Sousa MMM, 2020, FOOD QUAL PREFER, V83, DOI 10.1016/j.foodqual.2020.103902
   Deng L, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/9815937
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Do TD, 2020, INT SYM MIX AUGMENT, P64, DOI 10.1109/ISMAR50242.2020.00026
   Doerschner K, 2010, J VISION, V10, DOI 10.1167/10.4.8
   Drago F, 2001, COMPUT GRAPH-UK, V25, P511, DOI 10.1016/S0097-8493(01)00072-3
   Drouhard M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2453, DOI 10.1109/BigData.2015.7364040
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Elliott, 2021, THESIS U BRIT COLUMB
   Erick AO, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P190, DOI 10.1109/saupec/robmech/prasa48453.2020.9041002
   Ferwerda JA, 2001, PROC SPIE, V4299, P291, DOI 10.1117/12.429501
   Filip J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409091
   Fleming RW, 2014, VISION RES, V94, P62, DOI 10.1016/j.visres.2013.11.004
   Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3
   Fulvio JM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16161-3
   Geisler WS, 2008, ANNU REV PSYCHOL, V59, P167, DOI 10.1146/annurev.psych.58.110405.085632
   Gescheider G. A., 2013, Psychophysics: the fundamentals
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Gigilashvili D., 2019, Color and imaging conference, V2019, P37, DOI [10.2352/issn.2169-2629.2019.27.8, DOI 10.2352/ISSN.2169-2629.2019.27.8]
   Gourishetti R, 2019, VIRTUAL REAL-LONDON, V23, P133, DOI 10.1007/s10055-018-0369-9
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Hertel J, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P122, DOI 10.1109/VR50410.2021.00033
   Hiramatsu C, 2011, NEUROIMAGE, V57, P482, DOI 10.1016/j.neuroimage.2011.04.056
   Ho YX, 2006, J VISION, V6, P634, DOI 10.1167/6.5.8
   Hongtae Kim, 2002, Integrated Manufacturing Systems, V13, P295, DOI 10.1108/09576060210429748
   Honson V, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00485
   Horiuchi K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184552
   Hu B, 2011, INT J IND ERGONOM, V41, P64, DOI 10.1016/j.ergon.2010.10.001
   Hu HH, 2000, IEEE VISUAL, P179, DOI 10.1109/VISUAL.2000.885692
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Ijsselsteijn W, 1998, DISPLAYS, V18, P207, DOI 10.1016/S0141-9382(98)00022-5
   Jacobson J, 2005, COMPUTER, V38, P79, DOI 10.1109/MC.2005.126
   Jarabo A, 2014, IEEE T VIS COMPUT GR, V20, P880, DOI 10.1109/TVCG.2014.2312016
   Jo I, 2019, IEEE T HUM-MACH SYST, V49, P430, DOI 10.1109/THMS.2019.2919735
   Johansson P, 2004, J COMPUT INF SCI ENG, V4, P124, DOI 10.1115/1.1740775
   Kerr WB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778772
   Khang BG, 2006, PERCEPTION, V35, P625, DOI 10.1068/p5485
   Lagunas M, 2019, SIMILARITY MEASURE M
   Lagunas M, 2021, J VISION, V21, DOI 10.1167/jov.21.2.2
   Laha Bireswar., 2012, Immersive visualization revisited workshop of the IEEE VR conference, P1
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liang LZ, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P403, DOI 10.1145/3351095.3375623
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   Marlow PJ, 2012, CURR BIOL, V22, P1909, DOI 10.1016/j.cub.2012.08.009
   Martin P, 2017, LECT NOTES COMPUT SC, V10324, P222, DOI 10.1007/978-3-319-60922-5_17
   Matsushima K, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.023002
   McHugh ML, 2013, BIOCHEM MEDICA, V23, P143, DOI 10.11613/BM.2013.018
   MEYER GW, 1986, ACM T GRAPHIC, V5, P30, DOI 10.1145/7529.7920
   MEYER J, 1992, HUM FACTORS, V34, P335, DOI 10.1177/001872089203400307
   MINGOLLA E, 1986, BIOL CYBERN, V53, P137, DOI 10.1007/BF00342882
   Montello D. R., 2002, Cartography and Geographic Information Science, V29, P283, DOI [DOI 10.1559/152304002782008503, 10.1559/152304002782008503]
   Moskowitz, 2020, HDB EATING DRINKING, P1577
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Murray AM, 2003, PRESENCE-TELEOP VIRT, V12, P156, DOI 10.1162/105474603321640923
   Nathanael D, 2016, INT J IND ERGONOM, V53, P274, DOI 10.1016/j.ergon.2016.02.004
   Nefs HT, 2006, ACTA PSYCHOL, V121, P297, DOI 10.1016/j.actpsy.2005.08.001
   Nguyen CH, 2010, COMPUT GRAPH FORUM, V29, P1469, DOI 10.1111/j.1467-8659.2010.01744.x
   Nie W, 2019, IOP C SER EARTH ENV, V218, DOI 10.1088/1755-1315/218/1/012034
   Nishida S, 1998, J OPT SOC AM A, V15, P2951, DOI 10.1364/JOSAA.15.002951
   Norman JF, 2004, PSYCHOL SCI, V15, P565, DOI 10.1111/j.0956-7976.2004.00720.x
   Passig D, 2009, J EDUC COMPUT RES, V40, P263, DOI 10.2190/EC.40.3.a
   Peillard E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P227, DOI [10.1109/VR.2019.8797826, 10.1109/vr.2019.8797826]
   Pellacini F, 2000, COMP GRAPH, P55, DOI 10.1145/344779.344812
   Pessoa S, 2010, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2010.5444836
   Piegl LA, 2005, COMPUT AIDED DESIGN, V37, P461, DOI 10.1016/j.cad.2004.08.012
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   RAO JNK, 1973, BIOMETRIKA, V60, P125, DOI 10.1093/biomet/60.1.125
   Raymond B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925945
   Read JCA, 2015, NEUROSCIENCE, V296, P116, DOI 10.1016/j.neuroscience.2014.05.036
   Reise SP, 2005, CURR DIR PSYCHOL SCI, V14, P95, DOI 10.1111/j.0963-7214.2005.00342.x
   Rensink RA, 2021, J VISION, V21, DOI 10.1167/jov.21.8.3
   Rhiu I, 2020, INT J IND ERGONOM, V79, DOI 10.1016/j.ergon.2020.103002
   RichardWebster B, 2018, LECT NOTES COMPUT SC, V11219, P263, DOI 10.1007/978-3-030-01267-0_16
   Roth RE, 2012, CARTOGR J, V49, P376, DOI 10.1179/1743277412Y.0000000019
   Satter K, 2015, J COMPUT INF SCI ENG, V15, DOI 10.1115/1.4029750
   Schifferstein HNJ, 2005, ACTA PSYCHOL, V118, P293, DOI 10.1016/j.actpsy.2004.10.009
   Schlüter N, 2019, J VISION, V19, DOI 10.1167/19.4.24
   Schnack A, 2019, FOOD RES INT, V117, P40, DOI 10.1016/j.foodres.2018.01.028
   Serrano A, 2018, INTUITIVE CONTROL SP
   SEVE R, 1993, COLOR RES APPL, V18, P241, DOI 10.1002/col.5080180407
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   STEVENS SS, 1946, SCIENCE, V103, P677, DOI 10.1126/science.103.2684.677
   Sun TC, 2017, COMPUT GRAPH FORUM, V36, P47, DOI 10.1111/cgf.13223
   Swapp D, 2006, VIRTUAL REAL, V10, P24, DOI [DOI 10.1007/S10055-006-0027-5, DOI 10.1007/s10055-006-0027-5]
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   te PasS.F., 2005, P ACM S APPL PERCEPT, P75
   Thaler A., 2018, FRONT ICT, V5, P18, DOI [DOI 10.3389/FICT.2018.00018, 10.3389/fict.2018, DOI 10.3389/FICT.2018]
   Tiest WMB, 2007, ACTA PSYCHOL, V124, P177, DOI 10.1016/j.actpsy.2006.03.002
   Todd JT, 1997, PERCEPTION, V26, P807, DOI 10.1068/p260807
   Toma MI, 2012, INT J INTERACT DES M, V6, P179, DOI 10.1007/s12008-012-0144-1
   van Dam A, 2002, COMPUT GRAPH-UK, V26, P535, DOI 10.1016/S0097-8493(02)00113-9
   Vangorp P, 2017, J VISION, V17, DOI 10.1167/17.5.19
   Vangorp P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276473, 10.1145/1239451.1239528]
   Vangorp Peter, 2014, Proc. ACM SAP 2014, P71, DOI 10.1145/2628257.2628258
   Vanhoey K, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3129505
   Ware C, 2010, Visual thinking for design
   Wolfe J. M., 2006, Sensation & perception
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zacks JM, 2020, POL INS BEH BRAIN SC, V7, P52, DOI 10.1177/2372732219893712
   Zielasko D., 2017, 2017 IEEE 3 WORKSHOP, P1
NR 117
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1031
EP 1045
DI 10.1007/s10055-021-00613-3
EA JAN 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000749130300001
DA 2024-07-18
ER

PT J
AU García, AS
   Fernández-Sotos, P
   Vicente-Querol, MA
   Sánchez-Reolid, R
   Rodriguez-Jimenez, R
   Fernández-Caballero, A
AF Garcia, Arturo S.
   Fernandez-Sotos, Patricia
   Vicente-Querol, Miguel A.
   Sanchez-Reolid, Roberto
   Rodriguez-Jimenez, Roberto
   Fernandez-Caballero, Antonio
TI Co-design of avatars to embody auditory hallucinations of patients with
   schizophrenia A study on patients' feeling of satisfaction and
   psychiatrists' intention to adopt the technology
SO VIRTUAL REALITY
LA English
DT Article
DE Schizophrenia; Avatar-based therapy; User evaluation; Usability;
   Technology acceptance
ID COGNITIVE-BEHAVIOR THERAPY; VIRTUAL-REALITY; INTERVENTION; PSYCHOSIS;
   VOICES; MODELS
AB Auditory hallucinations are common and distressing symptoms of the schizophrenia disease. It is commonly treated with pharmacological approaches but, unfortunately, such an approach is not effective in all patients. In the cases in which the use of antipsychotic drugs is not possible or not recommended, psychotherapeutic interventions are used to help patients gain power and control against hearing voices. Recently, virtual reality technologies have been incorporated to this type of therapies. A virtual representation of their voice (avatar) is created in a controlled computer-based environment, and the patient is encouraged to confront it. Unfortunately, the software tools used in these therapies are not described in depth and, even more important, to the best of our knowledge, their usability, utility and intention to use by therapists, and patients have not been evaluated enough. The involvement of end users in the software development is beneficial in obtaining useful and usable tools. Hence, the two contributions of this paper are (1) the description of an avatar creation system and the main technical details of the configuration of auditory hallucination avatars, and (2) its evaluation from both the therapists' and the patients' viewpoints. The evaluation does not only focus on usability, but also assesses the acceptance of the technology as an important indicator of the future use of a new technological tool. Moreover, the most important results, the lessons learned and the main limitations of our study are discussed.
C1 [Garcia, Arturo S.; Vicente-Querol, Miguel A.; Sanchez-Reolid, Roberto; Fernandez-Caballero, Antonio] Univ Castilla La Mancha, Inst Invest Informat Albacete, Albacete, Spain.
   [Fernandez-Sotos, Patricia] Complejo Hosp Univ Albacete, Serv Salud Mental, Albacete, Spain.
   [Fernandez-Sotos, Patricia; Rodriguez-Jimenez, Roberto; Fernandez-Caballero, Antonio] Biomed Res Networking Ctr Mental Hlth CIBERSAM, Madrid, Spain.
   [Rodriguez-Jimenez, Roberto] Hosp 12 Octubre, Imas12, Inst Invest Sanitaria, Madrid, Spain.
   [Rodriguez-Jimenez, Roberto] Univ Complutense Madrid, CogPsy Grp, Madrid, Spain.
C3 Universidad de Castilla-La Mancha; CIBER - Centro de Investigacion
   Biomedica en Red; CIBERSAM; Hospital Universitario 12 de Octubre;
   Complutense University of Madrid
RP García, AS (corresponding author), Univ Castilla La Mancha, Inst Invest Informat Albacete, Albacete, Spain.
EM arturosimon.garcia@uclm.es
RI Fernández-Caballero, Antonio/A-8304-2015; Fernández-Sotos,
   Patricia/E-5288-2016; Jimenez, Arturo S. Garcia/ABH-3849-2020; Sanchez
   Reolid, Roberto/JDD-6767-2023
OI Jimenez, Arturo S. Garcia/0000-0003-0671-324X; Fernandez-Sotos,
   Patricia/0000-0002-6038-956X
FU Spanish Ministerio de Ciencia, Innovacion y Universidades, Agencia
   Estatal de Investigacion (AEI) / European Regional Development Fund
   (FEDER, UE) [EQC2019-006063-P, PID2020-115220RB-C21]; Biomedical
   Research Networking Center in Mental Health (CIBERSAM) of the Instituto
   de Salud Carlos III; Spanish Ministerio de Educacion y Formacion
   Profesional [BES-2017-081958]
FX This work was partially supported by Spanish Ministerio de Ciencia,
   Innovacion y Universidades, Agencia Estatal de Investigacion (AEI) /
   European Regional Development Fund (FEDER, UE) [Grant Nos.
   EQC2019-006063-P and PID2020-115220RB-C21] and by Biomedical Research
   Networking Center in Mental Health (CIBERSAM) of the Instituto de Salud
   Carlos III. Roberto Sanchez-Reolid holds BES-2017-081958 scholarship
   from Spanish Ministerio de Educacion y Formacion Profesional.
CR Aiken MP, 2015, VIRTUAL REAL-LONDON, V19, P95, DOI 10.1007/s10055-015-0260-x
   Bellack AS, 2007, SCHIZOPHRENIA BULL, V33, P805, DOI 10.1093/schbul/sbl035
   Birchwood M, 2014, LANCET PSYCHIAT, V1, P23, DOI 10.1016/S2215-0366(14)70247-0
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Craig TKJ, 2018, LANCET PSYCHIAT, V5, P31, DOI 10.1016/S2215-0366(17)30427-3
   Dellazizzo L, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00131
   du Sert OP, 2018, SCHIZOPHR RES, V197, P176, DOI 10.1016/j.schres.2018.02.031
   Escalona F, 2020, VIRTUAL REAL-LONDON, V24, P567, DOI 10.1007/s10055-019-00419-4
   Fernández-Caballero A, 2017, LECT NOTES COMPUT SC, V10586, P742, DOI 10.1007/978-3-319-67585-5_72
   Fernández-Caballero A, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00064
   Fernández-Sotos P, 2020, EUR J PSYCHIAT, V34, P1, DOI 10.1016/j.ejpsy.2019.12.003
   Fernández-Sotos P, 2020, SCHIZOPHR RES, V220, P297, DOI 10.1016/j.schres.2020.04.011
   Freeman D, 2020, J NEUROL NEUROSUR PS, V91, DOI 10.1136/jnnp-2020-BNPA.7
   Garety PA, 2007, PSYCHOL MED, V37, P1377, DOI 10.1017/S003329170700013X
   Hayward M, 2011, CLIN PSYCHOL REV, V31, P1313, DOI 10.1016/j.cpr.2011.09.001
   Hazell CM, 2018, SCHIZOPHR RES, V195, P441, DOI 10.1016/j.schres.2017.10.004
   Huang FH, 2020, VIRTUAL REAL-LONDON, V24, P635, DOI 10.1007/s10055-019-00424-7
   Jaana M, 2019, HEALTH INFORM J, V25, P1800, DOI 10.1177/1460458218799458
   Kaney S, 1999, BRIT J CLIN PSYCHOL, V38, P97, DOI 10.1348/014466599162692
   Karg R. S., 2015, STRUCTURED CLIN INTE, DOI DOI 10.1002/9781118625392.WBECP351
   Ketchen DJ, 2013, LONG RANGE PLANN, V46, P184, DOI 10.1016/j.lrp.2013.01.002
   Kontogiannatou A, 2019, STUD HEALTH TECHNOL, V262, P210, DOI 10.3233/SHTI190055
   Leff J, 2013, BRIT J PSYCHIAT, V202, P428, DOI 10.1192/bjp.bp.112.124883
   Lin L, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119884
   Lund A M., 2001, USABILITY INTERFACE, V8, P3, DOI DOI 10.1177/1078087402250360
   Marcos S, 2010, INTERACT COMPUT, V22, P176, DOI 10.1016/j.intcom.2009.12.002
   McCarthy-Jones S, 2014, INT J LAW PSYCHIAT, V37, P183, DOI 10.1016/j.ijlp.2013.11.004
   McDonnell R., 2010, ACM SIGGRAPH ASIA 2010 Sketches, P1, DOI [DOI 10.1145/1899950.1899991, 10.1145/1899950, DOI 10.1145/1899950]
   Morrison AP, 2001, BEHAV COGN PSYCHOTH, V29, P257, DOI 10.1017/S1352465801003010
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Prudenzi A, 2019, VIRTUAL REAL-LONDON, V23, P179, DOI 10.1007/s10055-018-0372-1
   Ravyse WS, 2017, VIRTUAL REAL-LONDON, V21, P31, DOI 10.1007/s10055-016-0298-4
   Rehm IC, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00186
   Reski N, 2020, VIRTUAL REAL-LONDON, V24, P1, DOI 10.1007/s10055-019-00378-w
   Romme M., 2009, LIVING VOICE 50 STOR
   Saab MM, 2019, VIRTUAL REAL-LONDON, V23, P169, DOI 10.1007/s10055-018-0368-x
   Salomon JA, 2012, LANCET, V380, P2129, DOI 10.1016/S0140-6736(12)61680-8
   Sezgin E, 2018, INFORM DEV, V34, P182, DOI 10.1177/0266666916684180
   Tao BP, 2015, TRANSL NEUROSCI, V6, P174, DOI 10.1515/tnsci-2015-0018
   Tavares S, 2017, CURR PSYCHIATRY REV, V13, P176, DOI 10.2174/1573400513666170502123654
   van Os J, 2009, LANCET, V374, P635, DOI [10.1016/S0140-6736(09)60995-8, 10.1016/S0140-6736(15)01121-6]
   Venkatesh V, 2012, MIS QUART, V36, P157
   Ward T, 2020, SCHIZOPHRENIA BULL, V46, P1038, DOI 10.1093/schbul/sbaa061
   Waters F., 2010, Psychiatric Times, V27, P54
   Waters F, 2017, SCHIZOPHRENIA BULL, V43, P32, DOI 10.1093/schbul/sbw132
   Wykes T, 2008, SCHIZOPHRENIA BULL, V34, P523, DOI 10.1093/schbul/sbm114
NR 46
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 217
EP 232
DI 10.1007/s10055-021-00558-7
EA JUL 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000670849600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Hartfiel, B
   Stark, R
AF Hartfiel, Bert
   Stark, Rainer
TI Validity of primary driving tasks in head-mounted display-based driving
   simulators
SO VIRTUAL REALITY
LA English
DT Article
DE Driving simulation; Head-mounted display; Behavioural validity; Gaze
   behaviour; Eye tracking
AB The development of new car interior concepts requires tools, particularly in development phases before concept milestones, which enable subjective experiences and evaluations in static and driving situations. On the one hand, variant comparisons are necessary; on the other hand, the level of immersion should be high enough that participants can behave as they would in real cars. Virtual reality technologies and especially head-mounted displays are generally very suitable for such evaluations with the exception being in state-of-the-art driving simulators. Therefore, a validation study was undertaken in which primary driving tasks in two HMD-based simulators were compared with test runs in a real car. The difference between the simulators was only the state of the motion base (enabled vs. disabled). In both simulators and the test runs in the real car, four identical scenarios (straight, curves, overtaking and junction) were carried out. Since the focus is primarily on subjective ratings and gaze behaviour when evaluating new car interior concepts, in this study gaze behaviour was also priority. In addition, driving dynamics parameters were measured. The results reveal that the participants show more valid behaviour in the dynamic system than in the static simulator condition.
C1 [Hartfiel, Bert] Volkswagen AG, Wolfsburg, Germany.
   [Hartfiel, Bert; Stark, Rainer] Tech Univ Berlin, Berlin, Germany.
C3 Volkswagen; Volkswagen Germany; Technical University of Berlin
RP Hartfiel, B (corresponding author), Volkswagen AG, Wolfsburg, Germany.; Hartfiel, B (corresponding author), Tech Univ Berlin, Berlin, Germany.
EM bert.hartfiel@volkswagen.de
OI Hartfiel, Bert/0000-0002-7008-5447; Stark, Rainer/0000-0002-2599-0130
CR [Anonymous], 2002, ISO 15007-1
   Aykent B., 2014, P DRIVING SIMULATION, P65
   Aykent B, 2015, P DSC 2015 DSA TUB G
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   BLAAUW GJ, 1982, HUM FACTORS, V24, P473, DOI 10.1177/001872088202400408
   Blana E., 1996, DRIVING SIMULATOR VA
   Blissing B., 2018, Driving Simulation Association (Hrsg.): Proceedings of the Driving Simulation Conference. Antibes. S, P163
   Brument H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P680, DOI [10.1109/vr.2019.8797721, 10.1109/VR.2019.8797721]
   Burns P-C, 1999, P DSC 1999, P155
   Cao S, 2020, VIRTUAL REAL-LONDON, V24, P503, DOI 10.1007/s10055-019-00412-x
   Colombet F., 2016, Proceedings of the Driving Simulation Conference, P201
   Erler P, 2017, P DSC 2017 VR DSA ST, P2
   Fischer M, 2015, CHALLEN DEMOCR 21ST, P139
   Grabe V., 2010, P DRIVING SIMULATION, P81
   Hartfiel B, 2018, P 19 VDI K SIMVEC 20, P655
   Hartfiel B., 2019, ATZ - Automobiltechnische Zeitschrift. Vol, V2019 No, P16, DOI [10.1007/s38311-019-0125-0, DOI 10.1007/S38311-019-0125-0]
   Hartfiel B, 2019, P DSC 2019 VR DSA ST, P25
   Hirata T., 2007, Tsinghua Science and Technology, V12, P141, DOI 10.1016/S1007-0214(07)70021-4
   MUDD S, 1968, HUM FACTORS, V10, P351, DOI 10.1177/001872086801000405
   Reich D, 2017, THESIS
   Reich D, 2016, INT J ELECT INF ENG, P1887
   Riecke BE, 2005, PROC SPIE, V5666, P344, DOI 10.1117/12.610846
   ROLFE JM, 1970, ERGONOMICS, V13, P761, DOI 10.1080/00140137008931203
   Ropelato S., 2017, 1 WORKSH ART INT MEE
   Ruspa C, 2000, P C HUM FACT AG VIRT, P319
   Schill V, 1997, P DSC 1997 DSA LYON
   Sullivan BT, 2012, J VISION, V12, DOI 10.1167/12.13.19
   Tiemann M, 2019, 5 S DRIV SIM AACH
   Tornros J, 1998, ACCIDENT ANAL PREV, V30, P497, DOI 10.1016/S0001-4575(97)00099-7
   Victor TW, 2005, TRANSPORT RES F-TRAF, V8, P167, DOI 10.1016/j.trf.2005.04.014
   Walch M, 2017, P 2017 CHI C HUM FAC, P2982, DOI [DOI 10.1145/3027063.3053202, 10.1145/3027063.3053202]
   Weidner F, 2017, P IEEE VIRT REAL ANN, P281, DOI 10.1109/VR.2017.7892286
   Zoller I., 2013, Zeitschrift fur Arbeitswissenschaft, V67, P197, DOI [10.1007/BF03374409, DOI 10.1007/BF03374409]
   Zoller I-M, 2015, THESIS
NR 34
TC 3
Z9 4
U1 2
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 819
EP 833
DI 10.1007/s10055-020-00496-w
EA JAN 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000604145500001
DA 2024-07-18
ER

PT J
AU Chardonnet, JR
   Mirzaei, MA
   Merienne, F
AF Chardonnet, Jean-Remy
   Mirzaei, Mohammad Ali
   Merienne, Frederic
TI Influence of navigation parameters on cybersickness in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Navigation; Parameters; Navigation device; Virtual
   reality
ID INDUCED MOTION SICKNESS; SIMULATOR SICKNESS; IMMERSION; VECTION; SPEED
AB Cybersickness remains a major challenge in the virtual reality community. It occurs mainly when navigating in a 3D immersive virtual environment. Several parameters are known to influence the users' cybersickness level while navigating, that can be either technological or neuro-psychological. This study investigates two of these parameters that are the distance from a virtual barrier and the choice of the navigation interface. An experiment was performed for each of these parameters to evaluate their influence on the variation of cybersickness. For each experiment, participants were asked to navigate in a large virtual room with walls that were textured with a black and white lined pattern to voluntarily exacerbate cybersickness. The level of cybersickness was collected through subjective (Simulator Sickness Questionnaire) and behavioral (evolution of postural sway) measurements. Results allow drawing suggestions for optimal navigation, so that cybersickness can be significantly reduced, thus providing with enhanced user experience.
C1 [Chardonnet, Jean-Remy; Merienne, Frederic] HESAM Univ, LISPEN, Arts & Metiers Inst Technol, 2 Rue Thomas Dumorey, F-71100 Chalon Sur Saone, Saone & Loire, France.
   [Mirzaei, Mohammad Ali] Embedded & FPGA Team, Atlas Project, Instrument Technol, Highview House,Stn Rd, Edgware, Middx, England.
C3 heSam Universite
RP Chardonnet, JR (corresponding author), HESAM Univ, LISPEN, Arts & Metiers Inst Technol, 2 Rue Thomas Dumorey, F-71100 Chalon Sur Saone, Saone & Loire, France.
EM jean-remy.chardonnet@ensam.eu
RI Chardonnet, Jean-Rémy/W-4502-2019
OI Chardonnet, Jean-Rémy/0000-0002-8926-1359
CR Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   [Anonymous], 2016, THESIS
   [Anonymous], 1992, Presence, DOI DOI 10.1162/PRES.1992.1.3.344
   [Anonymous], 1975, Motion sickness
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Buker TJ, 2012, HUM FACTORS, V54, P235, DOI 10.1177/0018720811428734
   Cai MJ, 2013, I C SERV SYST SERV M, P113, DOI 10.1109/ICSSSM.2013.6602650
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chardonnet JR, 2017, INT J HUM-COMPUT INT, V33, P771, DOI 10.1080/10447318.2017.1286767
   Cobb SVG, 1999, APPL ERGON, V30, P47, DOI 10.1016/S0003-6870(98)00038-6
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   Farmani Y, 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Hsiao E. W., 2018, UND RES SYMP
   HU S, 1988, PSYCHOPHYSIOLOGY, V25, P456
   Kemeny A, 2015, PROC SPIE, V9392, DOI 10.1117/12.2077080
   Kemeny Andras., 2014, Proceedings of the 2014 Virtual Reality International Conference (VRIC'14), P1
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kolasinski EM, 1995, TECHNICAL REPORT
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LaValle S. M., 2017, Virtual reality
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI DOI 10.1145/2671015.2671120
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Lou RD, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1058, DOI [10.1109/vr.2019.8798164, 10.1109/VR.2019.8798164]
   Mestre DR, 2014, PROC SPIE, V9012, DOI 10.1117/12.2042141
   Mirzaei MA, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P270, DOI 10.1109/AVSS.2013.6636651
   Murata A, 2004, INT J HUM-COMPUT INT, V17, P463, DOI 10.1207/s15327590ijhc1704_2
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Norman Donald A., 2010, interactions, V17, P6, DOI [DOI 10.1145/1744161.1744163, 10.1145/1744161.1744163]
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Plouzeau J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P661, DOI 10.1109/VR.2018.8446192
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Sanz Ferran Argelaguet, 2014, IEEE S 3D US INT, DOI [10.1109/3DUI.2014.7027325, DOI 10.1109/3DUI.2014.7027325]
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   TechnoConcept, 2007, TECHN BAL BOARD MAN
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Valli A, 2008, MULTIMED TOOLS APPL, V38, P295, DOI 10.1007/s11042-007-0190-z
   Young SD, 2006, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2006.44
NR 50
TC 12
Z9 12
U1 1
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 565
EP 574
DI 10.1007/s10055-020-00474-2
EA OCT 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000578410800001
DA 2024-07-18
ER

PT J
AU Lam, MC
   Sadik, MJ
   Elias, NF
AF Lam, Meng Chun
   Sadik, Mohamed Jafar
   Elias, Nur Fazidah
TI The effect of paper-based manual and stereoscopic-based mobile augmented
   reality systems on knowledge retention
SO VIRTUAL REALITY
LA English
DT Article
DE Mobile augmented reality; Knowledge retention; Stereoscopic vision;
   Long-term memory; Human-computer interaction
ID VIRTUAL-REALITY; AR; MAINTENANCE; ISSUES; MEMORY
AB Augmented reality technology is attracting increased attention, given the popularity of the smartphone. The utilisation of the smartphone with AR technology is also enabling mobile augmented reality (MAR) to become accessible. Stereoscopic vision offers users the benefit of depth perception, which can help improve user memory. Therefore, this study aims to investigate the effect on knowledge retention using MAR with stereoscopic vision. An experiment to compare a stereoscopic-based MAR application and a paper-based manual was designed to test the participants' knowledge retention on a product part and disassembly process. The developed MAR adopted a smartphone and headset case to provide a stereoscopic view to the user. The experiment consisted of both pre-test and post-test phases where the pre-test phase examined the participant's knowledge about the product, and the post-test phase focused on how much information the participants could recall. The post-test phase was conducted after 48 h following the pre-test phase since long-term memory required several hours in which to stabilise. The results showed that the MAR group had an advantage over the paper-based manual group for both information retentions having a mean score of 8.89 from the MAR group, compared with 6.33 for the paper-based manual group. Moreover, the MAR group was observed to have fewer errors in the post-test with a mean score of 0.53, whereas the paper-based achieved a score of 2.2. This result indicated that the MAR group and the paper-based manual group had equivalent performance in the completion time without the assistance tool. In addition, MAR had a better mean score for the subjective feedback (usefulness = 4.47, ease of use 4.18 and satisfaction = 4.07).
C1 [Lam, Meng Chun] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Mixed Real & Pervas Comp Lab, Bangi 43600, Selangor, Malaysia.
   [Sadik, Mohamed Jafar] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Parit Raja, Malaysia.
   [Elias, Nur Fazidah] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Software Technol & Management, Bangi 43600, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia; University of Tun Hussein Onn Malaysia;
   Universiti Kebangsaan Malaysia
RP Lam, MC (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Mixed Real & Pervas Comp Lab, Bangi 43600, Selangor, Malaysia.
EM lammc@ukm.edu.my; mohamad.jvp@gmail.com; fazidah@ukm.edu.my
RI Elias, Nur Fazidah/AAK-4379-2020; Chun, Lam Meng/H-4105-2019
OI Chun, Lam Meng/0000-0002-9435-9473; ELIAS, NUR
   FAZIDAH/0000-0002-3509-9704
FU Ministry of Higher Education (MOHE), Malaysia
   [FRGS/1/2018/ICT01/UKM/02/5]
FX This work was supported by the Ministry of Higher Education (MOHE),
   Malaysia Grant (FRGS/1/2018/ICT01/UKM/02/5).
CR [Anonymous], 2016, WORK DIG EYEW UN
   [Anonymous], INT J ADV SCI ENG IN
   [Anonymous], 2002, ASSEMBLY AUTOM
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P5819, DOI 10.1007/s11042-015-2543-3
   Baird K. M., 1999, Virtual Reality, V4, P250, DOI 10.1007/BF01421808
   Bergeron B, 2019, MIL MED, V184, P579, DOI 10.1093/milmed/usy372
   Biocca F, 2001, DO USERS ORGANIZE VI
   Blagg D, 2009, USABLE KNOWL, P18
   BRENNAN L, 1994, INT J OPER PROD MAN, V14, P57, DOI 10.1108/01443579410066767
   Broy N., 2012, Proceedings of the 4th International Conference on Automotive User Interfaces and Interactive Vehicular Applications, P93, DOI [10.1145/2390256.2390270, DOI 10.1145/2390256.2390270]
   Cammarota M, 2007, 10 STUDIES SHORT TER, P193
   Chang MML, 2017, PROC CIRP, V61, P299, DOI 10.1016/j.procir.2016.11.194
   Chun LM, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P59, DOI 10.1109/ICEEI.2015.7352470
   Czerwinski MP, 1999, HUMAN-COMPUTER INTERACTION - INTERACT '99, P163
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Hashim NC, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/9753979
   Holliman N.:., 2005, 3D display systems
   Hossain MS, 2016, MULTIMEDIA SYST, V22, P659, DOI 10.1007/s00530-015-0481-6
   Hou L, 2013, J COMPUT CIVIL ENG, V27, P439, DOI 10.1061/(ASCE)CP.1943-5487.0000184
   Hou L, 2013, AUTOMAT CONSTR, V32, P38, DOI 10.1016/j.autcon.2012.12.007
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Hung YH, 2017, J COMPUT ASSIST LEAR, V33, P252, DOI 10.1111/jcal.12173
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Macchiarella N. D., 2005, P HUMAN FACTORS ERGO, V49, P2174, DOI DOI 10.1177/154193120504902512
   Macchiarella ND, 2004, 23 DIG AV SYST C 200, P5
   Martin T, 2012, CARIBBEAN HISTORY: FROM PRE-COLONIAL ORIGINS TO THE PRESENT, P260
   Marusteri M, 2010, BIOCHEM MEDICA, V20, P15
   Nader K, 2009, NAT REV NEUROSCI, V10, P224, DOI 10.1038/nrn2590
   Neumann U, 1998, P IEEE VIRT REAL ANN, P4, DOI 10.1109/VRAIS.1998.658416
   Nizam SSM, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/5320984
   Noll C, 2017, JMIR MHEALTH UHEALTH, V5, DOI 10.2196/mhealth.7943
   Perez-Lopez D., 2013, Turkish Online Journal of Educational Technology - TOJET, V12, P19
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Rahman H, 2017, ELECT COMPUTER ENG J, V9, P145
   Rios Horacio, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P87, DOI 10.1007/978-3-642-22021-0_11
   Sadik M.J., 2017, Journal of Engineering and Applied Sciences, V12, P2098, DOI DOI 10.36478/JEASCI.2017.2098.2105
   Solak E, 2016, CROAT J EDUC, V18, P1067, DOI 10.15516/cje.v18i4.1729
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Tawadrous M, 2017, MULTIMED TOOLS APPL, V76, P7301, DOI 10.1007/s11042-016-3394-2
   Toet A, 2007, PERCEPT MOTOR SKILL, V105, P1245, DOI 10.2466/PMS.105.4.1245-1256
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wernhuar Tarng, 2012, 2012 IEEE 7th International Conference on Wireless, Mobile and Ubiquitous Technology in Education (WMUTE), P62, DOI 10.1109/WMUTE.2012.17
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   Wook TSMT, 2016, INTERACTION DESIGN M, V5, P71, DOI [10.17576/apjitm-2016-0501-07, DOI 10.17576/APJITM-2016-0501-07]
   Yee TS, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P49, DOI 10.1109/ICEEI.2015.7352468
   Zheng F, 2015, SPATIO TEMPORAL REGI
NR 49
TC 13
Z9 15
U1 0
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 217
EP 232
DI 10.1007/s10055-020-00451-9
EA JUN 2020
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000538951700002
DA 2024-07-18
ER

PT J
AU Ricca, A
   Chellali, A
   Otmane, S
AF Ricca, Aylen
   Chellali, Amine
   Otmane, Samir
TI Comparing touch-based and head-tracking navigation techniques in a
   virtual reality biopsy simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Biopsy trainer; Interaction design; Interaction fidelity; Surgical
   training
ID INTERACTION FIDELITY; PERFORMANCE; CONTINUUM
AB Recently, virtual reality (VR) technologies started gaining momentum in surgical simulation-based training by allowing clinicians to practice their skills before performing real procedures. The design of such simulators is usually focused on the primary operative tasks to be taught, but little attention is paid to secondary tasks that the user needs to perform, such as changing his/her point of view when manipulating the surgical instruments. More particularly, it is not clear how to design appropriate interaction techniques for those tasks, and how the fidelity of these interactions can impact the user's performance on such systems. In this paper, we compare two viewpoint changing techniques having two different levels of interaction fidelity during needle insertion in a semi-immersive VR (SIVR) biopsy trainer. These techniques were designed based on observing clinicians performing actual biopsy procedures. The first technique is based on tracking the user's head position (high interaction fidelity), while the second technique is touch-based with the user utilizing his/her non-dominant hand fingers to manipulate the point of view on a touch screen (moderate interaction fidelity). A user study was carried out to investigate the impact of the interaction fidelity of the viewpoint changing task (secondary task) on the user's performance during the needle insertion task (main task). Twenty-one novice participants were asked to perform several trials of a needle insertion task while using the navigation techniques (within-subject design). Objective and subjective measures were recorded to compare the task performance (time to accomplish the task, precision of the tumor sampling, and errors) and user experience for both techniques. The results show that the touch-based viewpoint changing technique improves the users' task completion performance during needle insertion while maintaining a similar level of needle manipulation accuracy as compared to the head-tracking technique. These results suggest that high interaction fidelity is not always necessary when designing surgical trainers. This also highlights the importance of designing appropriate interactions for secondary tasks because they can influence the user's primary task performance in VR simulators.
C1 [Ricca, Aylen; Chellali, Amine; Otmane, Samir] Univ Evry, Univ Paris Saclay, IBISC, Evry, France.
C3 Universite Paris Cite; Universite Paris Saclay
RP Ricca, A (corresponding author), Univ Evry, Univ Paris Saclay, IBISC, Evry, France.
EM aylen.ricca@ibisc.fr; amine.chellali@ibisc.fr; samir.otmane@ibisc.fr
RI Chellali, Amine/K-1059-2019
OI Chellali, Amine/0000-0002-6143-5898; Ricca, Aylen/0000-0003-3058-9955
FU Paris Ile-de-France Region [17002647]; University of Evry; Genopole
FX This work was supported by the Paris Ile-de-France Region (Grant Number
   17002647). Aylen Ricca received a Ph.D. Grant from the University of
   Evry. We also acknowledge support from Genopole.
CR Akhtar KSN, 2014, CURR REV MUSCULOSKE, V7, P155, DOI 10.1007/s12178-014-9209-z
   [Anonymous], TECHNICAL REPORT
   [Anonymous], SBC J 3D INTERACTIVE
   Arsenault R., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P408, DOI 10.1145/332040.332466
   Balcombe J, 2004, ATLA-ALTERN LAB ANIM, V32, P553, DOI 10.1177/026119290403201s90
   Barbé L, 2006, P AMER CONTR CONF, V1-12, P3209, DOI 10.1109/ACC.2006.1657212
   Barkana-Erol D, 2013, P INT WORKSH HUM SYS
   Bertrand J, 2015, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2015.7223317
   Bhargava A, 2018, IEEE T VIS COMPUT GR, V24, P1418, DOI 10.1109/TVCG.2018.2794639
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Boritz J., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P181, DOI 10.1145/261135.261168
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Buckley CE, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P139, DOI 10.5772/46415
   Chellali A, 2016, INT J HUM-COMPUT ST, V96, P22, DOI 10.1016/j.ijhcs.2016.07.005
   Chellali A, 2012, PRESENCE-VIRTUAL AUG, V21, P470, DOI 10.1162/PRES_a_00128
   Christie M., 2009, ACM SIGGRAPH ASIA 2009 Courses, SIGGRAPH ASIA '09, p3:1, DOI DOI 10.1145/1665817.1665820
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Correa Cleber G., 2014, Virtual, Augmented and Mixed Reality. Applications of Virtual and Augmented Reality. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8526, P267, DOI 10.1007/978-3-319-07464-1_25
   Corrêa CG, 2019, MED ENG PHYS, V63, P6, DOI 10.1016/j.medengphy.2018.11.002
   DENSON JS, 1969, J AMER MED ASSOC, V208, P504, DOI 10.1001/jama.208.3.504
   Dieckmann P, 2009, WORK RES MULTIDISCIP, V3, P1
   Drews F.A., 2013, Reviews of Human Factors and Ergonomics, V8, P191, DOI [10.1177/1557234X13492977, DOI 10.1177/1557234X13492977]
   Nguyen DV, 2015, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2015.7223388
   Edelmann J., 2009, 3DTV Conference: The True Vision - Capture, Transmission and Display of 3D Video, 2009, P1, DOI [10.1109/3DTV.2009.5069671, DOI 10.1109/3DTV.2009.5069671]
   Fortmeier D, 2016, IEEE J BIOMED HEALTH, V20, P355, DOI 10.1109/JBHI.2014.2381772
   Fried GM, 2004, ANN SURG, V240, P518, DOI 10.1097/01.sla.0000136941.46529.56
   Fu CW, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2213
   Gerovich Oleg, 2004, Comput Aided Surg, V9, P243, DOI 10.3109/10929080500190441
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Hamblin C.J., 2005, Transfer of training from virtual reality environments
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Henshall G, 2015, P IEEE VIRT REAL ANN, P191, DOI 10.1109/VR.2015.7223360
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   Jankowski J, 2015, COMPUT GRAPH FORUM, V34, P152, DOI 10.1111/cgf.12466
   Jarc AM, 2017, SURG ENDOSC, V31, P1192, DOI 10.1007/s00464-016-5090-8
   Johnson SJ, 2011, HUM FACTORS, V53, P612, DOI 10.1177/0018720811425042
   Khan A, 2005, IEEE PHOT SPEC CONF, P731, DOI 10.1109/PVSC.2005.1488236
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HK, 2003, LECT NOTES COMPUT SC, V2878, P1
   Kirurobo, 2014, A C NET WRAPP SENS P
   Kulik A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P363, DOI 10.1109/VR.2018.8447554
   Lemole GM, 2007, NEUROSURGERY, V61, P142, DOI 10.1227/01.neu.0000279734.22931.21
   Liu J, 2008, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE OF MODELLING AND SIMULATION, VOL I, P49
   Maran NJ, 2003, MED EDUC, V37, P22, DOI 10.1046/j.1365-2923.37.s1.9.x
   Marchal D, 2013, LECT NOTES COMPUT SC, V8117, P19
   Mastmeyer A, 2014, INT J COMPUT ASS RAD, V9, P421, DOI 10.1007/s11548-013-0959-7
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   McMahan RyanPatrick., 2011, Exploring the effects of higher-fidelity display and interaction for virtual reality games
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nabiyouni M., 2017, DOES INTERACTION FID
   Ortega M, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/2807442.2807496
   Ortega M, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2013.6550208
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Ricca A, 2017, P IEEE VIRT REAL ANN, P227, DOI 10.1109/VR.2017.7892259
   Rodriguez-Paz JM, 2009, POSTGRAD MED J, V85, P244, DOI 10.1136/qshc.2007.023903
   Satava RM, 2001, SURG ENDOSC, V15, P232, DOI 10.1007/s004640000369
   Shin M, 2011, IEEE INT SYMP ELEC, P119, DOI 10.1109/ISEMC.2011.6038295
   Spindler Martin., 2012, Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces ITS '12, P245, DOI DOI 10.1145/2396636.2396674
   Stassen HG, 2005, HUMAN ERROR SAFETY, P272
   Stoffregen TA, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P111, DOI 10.1201/9781410608888.ch6
   Sutherland C, 2013, IEEE T BIO-MED ENG, V60, P3009, DOI 10.1109/TBME.2012.2236091
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tang CY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON INTEGRATION TECHNOLOGY, PROCEEDINGS, P253, DOI 10.1109/ICITECHNOLOGY.2007.4290473
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang X, 2012, ENERG CONVERS MANAGE, V56, P1, DOI 10.1016/j.enconman.2011.11.006
NR 68
TC 4
Z9 5
U1 1
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 191
EP 208
DI 10.1007/s10055-020-00445-7
EA JUN 2020
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000538700700001
DA 2024-07-18
ER

PT J
AU Gaspar, H
   Morgado, L
   Mamede, H
   Oliveira, T
   Manjón, B
   Gütl, C
AF Gaspar, Horacio
   Morgado, Leonel
   Mamede, Henrique
   Oliveira, Teresa
   Manjon, Baltasar
   Gutl, Christian
TI Research priorities in immersive learning technology: the perspectives
   of the iLRN community
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive learning; Immersive technology; Immersive environments;
   Research priorities; iLRN; Immersive learning research network
ID VIRTUAL WORLDS; EDUCATION
AB This paper presents the perspectives of the immersive learning research network community on the relevance of various challenges to the adoption of immersive learning technology, along three dimensions: access, content production, and deployment. Using a previously validated questionnaire, we surveyed this community of 622 researchers and practitioners during the summer of 2018, attaining 54 responses. By ranking the challenges individually and within each dimension, the results point towards higher relevance being placed on aspects that link immersive environments with learning management systems and pedagogical tasks, alongside aspects that empower non-technical users (educational actors) to produce interactive stories, objects, and characters.
C1 [Morgado, Leonel; Mamede, Henrique; Oliveira, Teresa] INESC TEC, Porto, Portugal.
   [Gaspar, Horacio; Morgado, Leonel; Mamede, Henrique] Univ Aberta, Lisbon, Portugal.
   [Manjon, Baltasar] Univ Complutense Madrid, Madrid, Spain.
   [Gutl, Christian] Graz Univ Technol, Graz, Austria.
   [Gutl, Christian] Curtin Univ Technol, Perth, WA, Australia.
   [Gaspar, Horacio] Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.
   [Oliveira, Teresa] Univ Lisbon, CEAUL Ctr Estat & Aplicacoes, Lisbon, Portugal.
C3 INESC TEC; Universidade Aberta; Complutense University of Madrid; Graz
   University of Technology; Curtin University; Universidade de Lisboa;
   Universidade de Lisboa
RP Morgado, L (corresponding author), INESC TEC, Porto, Portugal.; Morgado, L (corresponding author), Univ Aberta, Lisbon, Portugal.
EM leonel.morgado@uab.pt
RI Guetl, Christian/AAD-5918-2021; São Mamede, Henrique/IZE-2347-2023;
   Morgado, Leonel/F-2946-2010; Mamede, Henrique São/ABB-3504-2020
OI Guetl, Christian/0000-0001-9589-1966; São Mamede,
   Henrique/0000-0002-5383-9884; Morgado, Leonel/0000-0001-5517-644X; 
FU European H2020 program H2020-ICT-2015, BEACONING project [687676]
FX The work presented herein has been partially funded under the European
   H2020 program H2020-ICT-2015, BEACONING project, Grant Agreement No.
   687676.
CR [Anonymous], 2015, ILRN US
   [Anonymous], 2007, SCANDINAVIAN J INFOR
   Chidean MI, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2000, DOI 10.1109/PIMRC.2013.6666472
   Clark-Casey J, 2010, THESIS
   Cruz Armando, 2012, Collaboration and Technology. Proceedings of the 18th International Conference, CRIWG 2012, P41, DOI 10.1007/978-3-642-33284-5_4
   Dawley L., 2013, The Handbook of Research for Educational Communications and Technology, V4th, P723, DOI [DOI 10.1007/978-1-4614-3185-558, DOI 10.1007/978-1-4614-3185-5_58]
   Dede C, 2000, J CURRICULUM STUD, V32, P281, DOI 10.1080/002202700182763
   Duncan I, 2012, BRIT J EDUC TECHNOL, V43, P949, DOI 10.1111/j.1467-8535.2011.01263.x
   Dwivedi YK, 2019, INFORM SYST FRONT, V21, P719, DOI 10.1007/s10796-017-9774-y
   Gaspar H., 2018, ILRN 2018 MONT WORKS, P48
   Hall G.E., 2011, IMPLEMENTING CHANGE, V3rd
   Kemp Jeremy, 2006, Proceedings of the Second Life Education Workshop, P13
   Kitchener KS, 2011, FOUNDATIONS OF ETHICAL PRACTICE, RESEARCH, AND TEACHING IN PSYCHOLOGY AND COUNSELING SECOND EDITION, P47
   Lieberman H., 2001, YOUR WISH IS MY COMM
   Maderer J., 2013, P IMM ED IED SUMM IM, P70
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Molen GR, 2002, US 20 CENTURY FOX DR
   Morgado L., 2016, ILRN 2016 SANT BARBK, P18
   Morgado L, 2017, PERS UBIQUIT COMPUT, V21, P965, DOI 10.1007/s00779-017-1063-8
   Morgado L, 2015, EDUC TECHNOL SOC, V18, P1
   Nevelsteen KJL, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1752
   Neves P, 2010, P SBGAMES 2010 9 SBG, P2179
   Reisoglu I, 2017, ASIA PAC EDUC REV, V18, P81, DOI 10.1007/s12564-016-9467-0
   Rogers EM, 2004, J HEALTH COMMUN, V9, P13, DOI 10.1080/10810730490271449
   Schroeder R., 1995, VIRTUAL REAL-LONDON, V1, P33, DOI DOI 10.1007/BF02009711
   Silva E, 2014, INT C MOD DAT ENG, P77
NR 26
TC 11
Z9 11
U1 2
U2 50
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 319
EP 341
DI 10.1007/s10055-019-00393-x
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800011
DA 2024-07-18
ER

PT J
AU Bhargava, A
   Lucaites, KM
   Hartman, LS
   Solini, H
   Bertrand, JW
   Robb, AC
   Pagano, CC
   Babu, SV
AF Bhargava, Ayush
   Lucaites, Kathryn M.
   Hartman, Leah S.
   Solini, Hannah
   Bertrand, Jeffrey W.
   Robb, Andrew C.
   Pagano, Christopher C.
   Babu, Sabarish V.
TI Revisiting affordance perception in contemporary virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Affordances; Passability; Body scaling; Virtual reality
ID PERCEIVING AFFORDANCES; VISUAL GUIDANCE; SIZE; DISTANCE; WALKING; YOUNG;
   BODY; RECALIBRATION; ENVIRONMENTS; INFORMATION
AB Virtual reality (VR) applications have rapidly gained renewed popularity and are extensively employed for replicating real-life scenarios that may otherwise be impractical to recreate. All such VR applications require that the environments being used provide high levels of immersion and mimic their real-world counterpart in terms of size, distance, depth, and action capabilities. Many VR applications being developed for training and entertainment require users to traverse an immersive virtual environment (IVE), where determining whether one can pass through an opening or aperture is one of the most frequently made decisions. In this experiment, we empirically compare passability judgments made in an IVE to those made in the real world. Participants judged whether they could pass through various widths of an adjustable sliding doorway in the real world and in a to-scale virtual replica viewed through an HTC Vive head-mounted display. If uncertain of their initial judgments, participants were permitted to walk towards the doorway. Results indicate that participants accurately perceive their ability to pass through doorways in both the real world and VR. However, participants in VR required more exposure to dynamic information via movement through the IVE in order to reach a real-world level of perceptual accuracy.
C1 [Bhargava, Ayush; Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
   [Lucaites, Kathryn M.; Solini, Hannah; Pagano, Christopher C.] Clemson Univ, Dept Psychol, Clemson, SC 29634 USA.
   [Hartman, Leah S.] Appl Bldg Sci Inc, Charleston, SC USA.
   [Bertrand, Jeffrey W.] Clemson Univ, Ctr Workforce Dev, Clemson, SC USA.
C3 Clemson University; Clemson University; Clemson University
RP Bhargava, A (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
EM ayushb@g.clemson.edu; klucait@g.clemson.edu; leah.hartman218@gmail.com;
   hsolini@clemson.edu; jbertra@clemson.edu; arobb@clemson.edu;
   cpagano@clemson.edu; sbabu@clemson.edu
RI Bhargava, Ayush/AAJ-2387-2021
OI Bhargava, Ayush/0000-0001-8957-1317; Robb, Andrew/0000-0002-0398-5576;
   Bertrand, Jeffrey/0000-0002-3921-4693
CR Balcetis E, 2010, PSYCHOL SCI, V21, P147, DOI 10.1177/0956797609356283
   Bartlett M, 2011, RURAL REMOTE HEALTH, V11
   Bhargava A, 2018, 2018 IEEE C VIRT REA, DOI [10.1109/vr.2018.8446189, DOI 10.1109/VR.2018.8446189]
   Bryk A. S., 1992, HIERARCHICAL LINEAR
   Buck LE, 2019, IEEE T VIS COMPUT GR, V25, P2123, DOI 10.1109/TVCG.2019.2899232
   Cesari P, 2005, EXP AGING RES, V31, P441, DOI 10.1080/03610730500206840
   Cesari P, 2003, HUM MOVEMENT SCI, V22, P111, DOI 10.1016/S0167-9457(03)00003-4
   Creem-Regehr SH, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P47, DOI 10.1145/2804408.2804422
   Fath AJ, 2011, PERCEPTION, V40, P887, DOI 10.1068/p6917
   Franchak JM, 2012, EXP BRAIN RES, V223, P301, DOI 10.1007/s00221-012-3261-y
   Geuss M, 2010, 7 S APPL PERC GRAPH
   Geuss MN, 2015, HUM FACTORS, V57, P1235, DOI 10.1177/0018720815590300
   Gibson J., 1979, The ecological approach to visual perception
   Grechkin TY, 2014, IEEE T VIS COMPUT GR, V20, P596, DOI 10.1109/TVCG.2014.18
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   Ishak S, 2008, J EXP PSYCHOL HUMAN, V34, P1501, DOI 10.1037/a0011393
   Janeh O, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3022731
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Jones JB, 2012, PLANT NUTRITION AND SOIL FERTILITY MANUAL, 2ND EDITION, P119
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kelly JW, 2014, IEEE T VIS COMPUT GR, V20, P588, DOI 10.1109/TVCG.2014.36
   Kelly JW, 2013, ATTEN PERCEPT PSYCHO, V75, P1473, DOI 10.3758/s13414-013-0503-4
   Kenyon RV, 2008, ANN BIOMED ENG, V36, P342, DOI 10.1007/s10439-007-9414-7
   Klein E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P107, DOI 10.1109/VR.2009.4811007
   KONCZAK J, 1992, J EXP PSYCHOL HUMAN, V18, P691, DOI 10.1037/0096-1523.18.3.691
   Kuhl ScottA., 2006, Journal of Vision, V6, P726, DOI DOI 10.1167/6.6.726
   Lappin JS, 2006, PERCEPT PSYCHOPHYS, V68, P571, DOI 10.3758/BF03208759
   Li BC, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165286
   Lin QF, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2720020
   Loomis J. M., 2008, Embodiment, ego-space, and action, P17
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Nguyen T.D., 2009, Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization, APGV '09, P27, DOI [10.1145/1620993.1620999, DOI 10.1145/1620993.1620999]
   Pagano CC, 2008, PSYCHON B REV, V15, P437, DOI 10.3758/PBR.15.2.437
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Pointon Grant., 2018, Proceedings of the 15th ACM Symposium on Applied Perception, P6
   Proffitt DR, 2003, PSYCHOL SCI, V14, P106, DOI 10.1111/1467-9280.t01-1-01427
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Siegel ZD, 2017, ATTEN PERCEPT PSYCHO, V79, P39, DOI 10.3758/s13414-016-1243-z
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Stefanucci JK, 2011, SOC PERSONAL PSYCHOL, V5, P296, DOI 10.1111/j.1751-9004.2011.00352.x
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Stefanucci JK, 2012, P ACM S APPL PERC SA, DOI [DOI 10.1145/2338676.2338692, 10.1145/2338676.2338692]
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Witt JK, 2007, PERCEPTION, V36, P1752, DOI 10.1068/p5617
   Witt JK, 2004, PERCEPTION, V33, P577, DOI 10.1068/p5090
   Woltman H., 2012, TUTORIALS QUANTITATI, V8, P52, DOI DOI 10.20982/TQMP.08.1.P052
NR 51
TC 23
Z9 25
U1 3
U2 40
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 713
EP 724
DI 10.1007/s10055-020-00432-y
EA MAR 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000519413200001
DA 2024-07-18
ER

PT J
AU Heinz, M
   Brunnett, G
AF Heinz, Marcel
   Brunnett, Guido
TI Optimized GPU-based post-processing for stereoscopic multi-projector
   display systems
SO VIRTUAL REALITY
LA English
DT Article
DE Projector; Display; Multi-projector; Tiled display; Calibration;
   Stereoscopy
ID SEAMLESSNESS; COLOR
AB To drive multi-projector display systems, the image content has to be post-processed to apply geometrical and photometrical correction algorithms. Since the optical path is shared for both views of a stereoscopic projector, we propose to eliminate redundant calculations by processing both views at once. We show that by exploiting the color similarities of stereoscopic image pairs, the cache efficiency of LUT-based color correction methods can be improved. Stereoscopic content is often transmitted in different formats where a single frame represents both views in a spatially multiplexed pattern, and display devices typically support only a subset of these formats, so that the need for conversion arises. We propose an algorithm to directly incorporate such format conversions into the post-processing and show that our combined approach can achieve significant performance improvements compared to the naive multi-pass implementation. The reduced overhead of the post-processing step increases the number of projectors which can be driven by a single GPU, which enables building larger or higher resolution displays at lower costs. The flexibility gained by the ability to process different input formats also greatly enhances the usability of powerwalls by allowing to implement the post-processing at different levels and working with unmodified software applications.
C1 [Heinz, Marcel; Brunnett, Guido] Tech Univ Chemnitz, Str Nationen 62, D-09017 Chemnitz, Germany.
C3 Technische Universitat Chemnitz
RP Heinz, M (corresponding author), Tech Univ Chemnitz, Str Nationen 62, D-09017 Chemnitz, Germany.
EM heinm@informatik.tu-chemnitz.de; brunnett@informatik.tu-chemnitz.de
CR Allen W, 2005, P SID S SID BOST MA, P1514
   AMD, 2014, DIRECTGMA AMDS FIREP
   Bimber O, 2005, COMPUTER, V38, P48, DOI 10.1109/MC.2005.17
   Bourke P, 2004, TECHNICAL REPORT
   BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855
   Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793
   Chen MH, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P570, DOI 10.1109/FSKD.2014.6980897
   Frohlich B, 2004, IMPLEMENTING MULTI V
   Frohlich B, 2005, WSCG 2005
   Gaur PK, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P293, DOI 10.1109/IC3I.2014.7019727
   Heinz M, 2015, IEEE COMPUT SOC CONF
   Jaynes C, 2001, IEEE VISUAL, P175, DOI 10.1109/VISUAL.2001.964509
   Jordan Samuel., 2010, 2010 IEEE Conference on Computer Vision and Pattern Recognition Workshops, P72, DOI DOI 10.1109/CVPRW.2010.5543487
   Majumder A, 2005, ACM T GRAPHIC, V24, P118, DOI 10.1145/1037957.1037964
   MAJUMDER A, 2002, P ACM VIRT REAL SOFT, P147
   Martynov I, 2011, LECT NOTES COMPUT SC, V6688, P536, DOI 10.1007/978-3-642-21227-7_50
   Meyer C, 2013, TECHNICAL REPORT
   Okatani T, 2009, INT J COMPUT VISION, V85, P1, DOI 10.1007/s11263-009-0242-0
   Raij A, 2003, PROCEEDINGS OF IEEE
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Raskar R., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P109, DOI 10.1109/VR.2000.840488
   Raskar R, 2005, ACM SIGGRAPH 2005 CO
   Raskar R, 1998, FOURTH INTERNATIONAL
   Sadlo F, 2005, PROCEEDINGS OF THE E
   SAJADI B, 2010, PROCEEDINGS OF THE 1, V11, P72
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1317, DOI 10.1109/TVCG.2009.124
   Stone MC, 2001, IEEE COMPUT GRAPH, V21, P58, DOI 10.1109/38.946632
   Surati Rajeev J., 1999, THESIS
   Wallace G., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P293, DOI 10.1145/769953.769988
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 31
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 45
EP 60
DI 10.1007/s10055-018-0352-5
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500005
DA 2024-07-18
ER

PT J
AU Jiang, M
   Lan, W
   Chang, J
   Dodwell, M
   Jekins, J
   Yang, HJ
   Tong, RF
   Zhang, JJ
AF Jiang, Min
   Lan, Wei
   Chang, Jian
   Dodwell, Mark
   Jekins, Jeremy
   Yang, Hui Jun
   Tong, Ruo Feng
   Zhang, Jian Jun
TI A game prototype for understanding the safety issues of a lifeboat
   launch
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Virtual reality; Lifeboat launch; Game-based training;
   General public
AB Novel, advanced game techniques provide us with new possibilities to mimic a complicated training process, with the added benefit of enhanced safety. In this paper, we design and implement a 3D game with the support of virtual reality equipment which imitates the process of a lifeboat launch, involving both tractor manoeuvres and boat operations. It is a complex but vital process which can save lives at sea but also has many potential hazards. The primary objective of the game is to allow novices to better understand the sequence of the operations and manage the potential risks which may occur during the launch process. Additionally, the game has been promoted to the general public for educational purposes and to raise awareness of the safety issues involved. The key modules of the game are designed based on physical simulations to give the players enhanced plausible cognition and enjoyable interaction. We conducted two case studies for the two purposes of the games: one for training with volunteers without launching experience and the other for public awareness of the potential hazards with young children. The game is proven to be very promising for future professional training, and it serves the educational purpose of awareness of the safety issues for general public while being entertaining.
C1 [Jiang, Min; Chang, Jian; Dodwell, Mark; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Lan, Wei; Tong, Ruo Feng] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Jekins, Jeremy] Royal Natl Lifeboat Inst, Poole, Dorset, England.
   [Yang, Hui Jun] Northwest A&F Univ, Yangling, Peoples R China.
C3 Bournemouth University; Zhejiang University; Northwest A&F University -
   China
RP Chang, J (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
EM jchang@bournemouth.ac.uk
FU HEIF Fund Virtual Prototyping of New Lifeboat Launching System
   [AANM02.X]
FX The research leading to these results has received funding from the HEIF
   Fund (AANM02.X) Virtual Prototyping of New Lifeboat Launching System.
   The authors are grateful for the proofreading by Gabriel Notman and
   valuable inputs of anonymous reviewers.
CR Aloni S., 2012, Int. J. Eng. Sci. Technol., P1351
   [Anonymous], WE KEEP BEACH SAF
   [Anonymous], UN 2017 WORLD LEAD C
   [Anonymous], TEACH PACKS
   [Anonymous], 4 BENEFITS GAME BASE
   [Anonymous], SIGRAD 2006 ANN SIGR
   [Anonymous], BALKAN J ELECT COMPU
   [Anonymous], TIR PASS VEH FUEL EC
   [Anonymous], UNDERSTANDING VIRTUA
   [Anonymous], 2007, SERIOUS GAMES OVERVI
   [Anonymous], YOUTH ED
   [Anonymous], P 4 DRIV SIM C
   [Anonymous], 2004, HDB RES ED COMMUNICA
   [Anonymous], TRAIN SIMUL
   [Anonymous], MED MEETS VIRT REAL
   Backlund P., 2013, P 2013 5 INT C GAM V, P1, DOI [DOI 10.1109/VSGAMES.2013.6624226, DOI 10.1109/VS-GAMES.2013.6624226]
   Baker I.O., 1919, A treatise on roads and pavements
   Bergeron L, 2000, J ABNORM CHILD PSYCH, V28, P47, DOI 10.1023/A:1005170017815
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Burdea G. C., 2003, Virtual reality technology
   Clark C Abt, 1987, Serious Games
   Epper R. M., 2012, RES B
   Fery YA, 2001, ERGONOMICS, V44, P1025, DOI 10.1080/00140130110084773
   Gamberini L, 2003, ERGONOMICS, V46, P842, DOI 10.1080/0014013031000111266
   Gamberini L., 2008, Journal of CyberTherapy Rehabilitation, V1, P127
   Gee J. P., 2003, COMPUTERS ENTERTAINM, V1, P20, DOI [https://doi.org/10.1145/950566.950595, DOI 10.1145/950566.950595]
   Gillespie T. D., 1992, FUNDAMENTALS VEHICLE
   Goldstone W., 2009, Unity game development essentials
   GOPHER D, 1994, HUM FACTORS, V36, P387, DOI 10.1177/001872089403600301
   Greitzer FrankL., 2007, Journal on Educational Resources in Computing, V7, P2, DOI [10.1145/1281320.1281322, DOI 10.1145/1281320.1281322]
   Hibbeler R.C., 2007, ENG MECH STATICS DYN, V11th
   Jonassen D, 1999, INSTRUCTIONAL-DESIGN THEORIES AND MODELS, VOL II, P215
   Macmillan R.H., 2002, The mechanics of tractor-implement performance: theory and worked examples: a textbook for students and engineers
   Menard M., 2011, Game development with unity, V1
   Michael D.R., 2005, Serious games: Games that educate, train, and inform
   Ostlund J., 2006, EFFECTS COGNITIVE VI
   Salen Katie, 2004, RULES PLAY GAME DESI
   SCHNEIDER W, 1985, HUM FACTORS, V27, P285, DOI 10.1177/001872088502700305
   Youngblut C., 1998, TECHNICAL REPORT
NR 39
TC 8
Z9 8
U1 0
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2018
VL 22
IS 2
SI SI
BP 137
EP 148
DI 10.1007/s10055-018-0334-7
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GC5KP
UT WOS:000429826700005
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Koutsabasis, P
   Vosinakis, S
AF Koutsabasis, Panayiotis
   Vosinakis, Spyros
TI Kinesthetic interactions in museums: conveying cultural heritage by
   making use of ancient tools and (re-) constructing artworks
SO VIRTUAL REALITY
LA English
DT Article
DE Cultural heritage; Digital heritage; Kinesthetic interaction; Cycladic
   figurine; User experience; Usability testing; Field study; Leap Motion
AB Kinesthetic interactions allow users to interact with 3D applications through their body movements and hand gestures. When kinesthetic applications are introduced in museums and heritage institutions, they add embodiment to visitor experience. An appropriate fit for kinesthetic technology in museums rests on visitors engaging in purposeful body movements and hand gestures that convey meanings about both intangible and tangible heritage. This paper presents the design, development and evaluation of a kinesthetic application of sculpturing Cycladic figurines, which places the user at the role of an ancient craftsman who creates a figurine with bare-hand movements (translated by Leap Motion to respective sculpting actions) in a simplified virtual environment. The Cycladic sculpture application has been evaluated in laboratory and field testing (as part of a wider educational activity in the museum) with positive results on usability, fun and learning. We identify several benefits as well as challenges of designing kinesthetic interactions in museums and we report on design issues that need to be taken into account in similar applications.
C1 [Koutsabasis, Panayiotis; Vosinakis, Spyros] Univ Aegean, Dept Prod & Syst Design Engn, Interact Syst Design Lab, Ermoupolis, Greece.
C3 University of Aegean
RP Vosinakis, S (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Interact Syst Design Lab, Ermoupolis, Greece.
EM kgp@aegean.gr; spyrosv@aegean.gr
RI Koutsabasis, Panayiotis/T-9367-2019
OI Koutsabasis, Panayiotis/0000-0003-0478-7456; Vosinakis,
   Spyros/0000-0003-1735-4297
CR Anderson EF, 2010, VIRTUAL REAL-LONDON, V14, P255, DOI 10.1007/s10055-010-0177-3
   [Anonymous], 2004, P AAAI WORKSH CHALL
   Csikzentmihalyi M., 1995, Public Institutions for Personal Learning, P67
   De Paolis L. T., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P169, DOI 10.1109/ICCSN.2011.6013802
   England D, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-433-3_1
   Fanini B, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, COMPUTER GRAPHICS & INTERACTION, P263, DOI 10.1109/DigitalHeritage.2015.7413880
   Fogtmann M.H., 2008, Proceedings of the 20th Australasian Conference on Computer-Human Interaction, P89, DOI [10.1145/1517744.1517770, DOI 10.1145/1517744.1517770]
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Gunn C., 2006, VIRTUAL REAL-LONDON, V10, P73
   Hein GeorgeE., 2002, Learning in the Museum
   Hernández-Ibáñez LA, 2016, LECT NOTES COMPUT SC, V9753, P145, DOI 10.1007/978-3-319-39483-1_14
   Hoffman H. G., 1998, Virtual Reality, V3, P226, DOI 10.1007/BF01408703
   Hsu H.M. J., 2011, INT J INFORM ED TECH, V1, P365, DOI [10.7763/IJIET.2011.V1.59, DOI 10.7763/IJIET.2011.V1.59]
   Koutsabasis P., 2016, P EUR MED C NIC CYPR, P350
   Markopoulos P, 2008, MORG KAUF SER INTER, P1, DOI 10.1016/B978-0-12-374111-0.00001-3
   Markussen A, 2013, LECT NOTES COMPUT SC, V8117, P401
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   Nancel M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P177
   Pescarin S., 2013, DIG HER INT C P IEEE, VI, P355
   Pietroni E, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2611375
   Prazina I, 2016, 2016 39TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P358, DOI 10.1109/MIPRO.2016.7522167
   Read Janet C., 2008, Cognition, Technology & Work, V10, P119, DOI 10.1007/s10111-007-0069-9
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Robertson S, 2009, LECT NOTES COMPUT SC, V5622, P235, DOI 10.1007/978-3-642-02771-0_27
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   van Eck W, 2012, INT SYM MIX AUGMENT
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Vosinakis S, 2011, Rethinking technology in Museums
   Wang C.-S., 2013, INFORM TECHNOLOGY CO, P587, DOI DOI 10.1007/978-94-007-6996-0_62
   Wong JPY, 2000, J VISUAL COMP ANIMAT, V11, P155, DOI 10.1002/1099-1778(200007)11:3<155::AID-VIS225>3.0.CO;2-7
   Wyvill G., 2005, VISUAL COMPUT, V1, P3, DOI [10.1007/BF01901265, DOI 10.1007/BF01901265]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 41
TC 29
Z9 32
U1 10
U2 82
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2018
VL 22
IS 2
SI SI
BP 103
EP 118
DI 10.1007/s10055-017-0325-0
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GC5KP
UT WOS:000429826700003
DA 2024-07-18
ER

PT J
AU Frad, M
   Maaref, H
   Otmane, S
   Mtibaa, A
AF Frad, M'hamed
   Maaref, Hichem
   Otmane, Samir
   Mtibaa, Abdellatif
TI A hybrid optical-mechanical calibration procedure for the
   Scalable-SPIDAR haptic device
SO VIRTUAL REALITY
LA English
DT Article
DE Scalable-SPIDAR; Virtual reality; Tracking; Calibration; Neural
   networks; Support vector regression
ID ELECTROMAGNETIC TRACKING; SUPPORT; REGRESSION
AB In this research, a simple, yet, efficient calibration procedure is presented in order to improve the accuracy of the Scalable-SPIDAR haptic device. The two-stage procedure aims to reduce discrepancies between measured and actual values. First, we propose a new semi-automatic procedure for the initialization of the haptic device. To perform this initialization with a high level of accuracy, an infrared optical tracking device was used. Furthermore, audio and haptic cues were used to guide the user during the initialization process. Second, we developed two calibration methods based on regression techniques that effectively compensate for the errors in tracked position. Both neural networks and support vector regression methods were applied to calibrate the position errors present in the haptic device readings. A comparison between these two regression methods was carried out to show the underlying algorithm and to indicate the inherent advantages and limitations for each method. Initial evaluation of the proposed procedure indicated that it is possible to improve accuracy by reducing the Scalable-SPIDAR's average absolute position error to about 6 mm within a 1 m x 1 m x 1 m workspace.
C1 [Frad, M'hamed; Maaref, Hichem; Otmane, Samir] Univ Evry Val dEssonne, IBISC Lab, Evry, France.
   [Frad, M'hamed; Mtibaa, Abdellatif] Univ Monastir, EuE Lab, Monastir, Tunisia.
C3 Universite Paris Saclay; Universite de Monastir
RP Frad, M (corresponding author), Univ Evry Val dEssonne, IBISC Lab, Evry, France.; Frad, M (corresponding author), Univ Monastir, EuE Lab, Monastir, Tunisia.
EM mhamed.frad@gmail.com
OI Otmane, Samir/0000-0003-2221-4264; Frad, M'hamed/0000-0003-2517-7040;
   MAAREF, Hichem/0000-0002-1192-7333; MTIBAA,
   Abdellatif/0000-0001-5180-9975
CR Advanced Realtime Tracking GmbH, 2003, ARTTRACK1 DTRACK MAN
   [Anonymous], 1994, Accuracy trueness and precision of measurement methods and results
   [Anonymous], 1996, FORCE TOUCH FEEDBACK
   [Anonymous], HAPTIC INTERACTION
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Bloch G, 2008, INFORM SCIENCES, V178, P3813, DOI 10.1016/j.ins.2008.05.016
   Boudoin P, 2010, P 6 INT WORKSH ART N, P87
   Bouguila Laroussi, 2000, PROC 1 WORKSHOP HAPT, P54
   Briggs W., 1999, Industrial Virtual Reality: Manufacturing and Design Tool for the Next Millennium. NIST-ASME Industrial Virtual Reality Symposium. Symposium on Virtual Environment for Manufacturing, P27
   BRYSON S, 1992, P SOC PHOTO-OPT INS, V1669, P244, DOI 10.1117/12.60417
   Buoguila L., 2000, MULTIMEDIA 00, P277
   Ellis SR, 1999, P IEEE VIRT REAL ANN, P218, DOI 10.1109/VR.1999.756954
   Fletcher C, 2013, COMPUT IND, V64, P1045, DOI 10.1016/j.compind.2013.07.005
   Fuchs P., 2011, VIRTUAL REALITY CONC
   Ghazisaedy M., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P179, DOI 10.1109/VRAIS.1995.512494
   Group B. T. S. W, 2005, SPIDAR G AHS1 0A US, P1
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   Harders M, 2009, IEEE T VIS COMPUT GR, V15, P138, DOI 10.1109/TVCG.2008.63
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hirata Yukihiro., 1992, Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, V2, P889
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   HWANG JN, 1992, ADV NEUR IN, V4, P1159
   Ikits M., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P247, DOI 10.1145/769953.769982
   Ikits M, 2001, P IEEE VIRT REAL ANN, P63, DOI 10.1109/VR.2001.913771
   Ikits M, 2000, P PHANTOM US GROUP W, P46
   Jayaram U, 2002, J MECH DESIGN, V124, P623, DOI 10.1115/1.1517562
   Kecman V, 2005, STUD FUZZ SOFT COMP, V177, P1
   Kecman V., 2001, LEARNING SOFT COMPUT
   Kenwright DN, 1996, IEEE T VIS COMPUT GR, V2, P120, DOI 10.1109/2945.506224
   Kim S, 2002, P IEEE VIRT REAL ANN, P283, DOI 10.1109/VR.2002.996540
   Kindratenko V., 1999, Virtual Reality, V4, P139, DOI 10.1007/BF01408592
   Kindratenko V, 2000, SPRING COMP SCI, P13
   Kindratenko V. V., 2000, Virtual Reality, V5, P169, DOI 10.1007/BF01409422
   Kindratenko VV., 2005, Virtual Reality, V9, P70, DOI 10.1007/s10055-005-0005-3
   Knoerlein B., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P119, DOI 10.1109/WHC.2011.5945472
   Künzler U, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P551
   Kwiatkowska EJ, 2003, IEEE T GEOSCI REMOTE, V41, P2844, DOI 10.1109/TGRS.2003.818016
   Livingston MA, 1997, PRESENCE-TELEOP VIRT, V6, P532, DOI 10.1162/pres.1997.6.5.532
   Melin P, 2005, SOFT COMPUT, V18, P318
   Meyer K., 1992, Presence: Teleoperators and Virtual Environments, V1, P173
   Moreira AHJ, 2014, IEEE INT SYM MED MEA, P141
   Pao YH., 1989, Adaptive Pattern Recognition and Neural Networks
   Ramsamy P, 2006, LECT NOTES COMPUT SC, V3992, P603, DOI 10.1007/11758525_81
   Reinig K, 1997, P 2 PHANTOM US GROUP, P70
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Srinivasan MA, 1995, REPORT COMMITTEE VIR, P161
   Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0
   Tukey J.W., 1977, Exploratory data analysis, P27
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   Welch G, 2002, IEEE COMPUT GRAPH, V22, P24, DOI 10.1109/MCG.2002.1046626
   Xia PJ, 2012, INT J ADV MANUF TECH, V58, P379, DOI 10.1007/s00170-011-3381-8
   Yu H., 2011, Intelligent Systems, V2, P1, DOI [DOI 10.1201/B10604-15, 10.1201/9781315218427-12, DOI 10.1201/9781315218427-12]
   Zachmann G, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P213, DOI 10.1109/CGI.1997.601306
NR 55
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2017
VL 21
IS 3
BP 109
EP 125
DI 10.1007/s10055-016-0303-y
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FB8YV
UT WOS:000406427400001
DA 2024-07-18
ER

PT J
AU Bissonnette, J
   Dubé, F
   Provencher, MD
   Sala, MTM
AF Bissonnette, Josiane
   Dube, Francis
   Provencher, Martin D.
   Sala, Maria T. Moreno
TI Evolution of music performance anxiety and quality of performance during
   virtual reality exposure training
SO VIRTUAL REALITY
LA English
DT Article
DE Exposure; Music; Performance anxiety; Treatment; Virtual reality;
   Immersion ability
ID BEHAVIORAL-THERAPY; GRADED EXPOSURE; DISORDERS; FEAR
AB Virtual reality exposure is increasingly used as a method of treatment for anxiety disorders. This exploratory study examines a virtual reality exposure training (VRET) conceived for the treatment of music performance anxiety (MPA). The aim is to obtain first-level knowledge in the music field concerning VRET. This article analyzes how MPA, concentration and quality of performance evolve during VRET. Nine music students participated in six 1-h sessions of VRET spread out over 3 weeks. They were exposed to four different virtual environments representing typical audiences for musicians. The findings indicate a significant decrease in MPA between sessions. They also indicate a significant increase in performance quality within sessions and a positive correlation between absorption ability and level of anxiety at the beginning of the VRET. Further studies must be conducted to evaluate the generalizability potential of these results to real performance situations.
C1 [Bissonnette, Josiane; Dube, Francis; Sala, Maria T. Moreno] Univ Laval, Fac Mus, Pavillon Louis Jacques Casault,1055 Ave Seminaire, Quebec City, PQ G1V 0A6, Canada.
   [Provencher, Martin D.] Univ Laval, Sch Psychol, Quebec City, PQ G1V 0A6, Canada.
C3 Laval University; Laval University
RP Bissonnette, J (corresponding author), Univ Laval, Fac Mus, Pavillon Louis Jacques Casault,1055 Ave Seminaire, Quebec City, PQ G1V 0A6, Canada.
EM josiane.bissonnette.1@ulaval.ca
RI Bissonnette, Josiane/ITT-6724-2023; Bissonnette, Josiane/P-4716-2018
OI Bissonnette, Josiane/0000-0002-2947-0087; 
FU Fonds quebecois de la recherche sur la societe et la culture; Social
   Sciences and Humanities Research Council of Canada; Desjardins
   Foundation; Laboratoire de museologie et d'ingenierie de la culture
FX We thank the "Fonds quebecois de la recherche sur la societe et la
   culture," the Social Sciences and Humanities Research Council of Canada,
   and the Desjardins Foundation for their financial contribution to the
   realization of this study. We also thank the "Laboratoire de museologie
   et d'ingenierie de la culture" for its material and financial
   contribution to the study.
CR Anderson P, 2007, COGN BEHAV PRACT, V14, P198, DOI 10.1016/j.cbpra.2006.02.006
   [Anonymous], PSYCHOTHER THEORY RE
   [Anonymous], PROGRAMME COGNITIVO
   [Anonymous], 2011, EFFECTS EXPOSURE VIR
   [Anonymous], PSYCHOL MUSID PERFOR
   [Anonymous], ADV EVALUATION TREAT
   Appel S.S., 1974, MODIFYING SOLO PERFO
   Banos R, 1999, Cyberpsychol Behav, V2, P143, DOI 10.1089/cpb.1999.2.143
   Bissonnette J, 2015, MED PROBL PERFORM AR, V30, P169, DOI 10.21091/mppa.2015.3032
   Bouchard S., 2007, Journal de Therapie Comportementale et Cognitive, V17, P101, DOI DOI 10.1016/S1155-1704(07)73238-X
   Cohen J., 1988, STAT POWER ANAL BEHA
   Deacon BJ, 2004, J CLIN PSYCHOL, V60, P429, DOI 10.1002/jclp.10255
   Emmelkamp P.M. G., 2003, Handbook of psychotherapy and behavior change, V5th, P393
   Foa E.B., 2006, Pathological anxiety: Emotional processing in etiology and treatment, DOI DOI 10.1037/0022-006X.72.5.879
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Harris SR, 2002, CYBERPSYCHOL BEHAV, V5, P543, DOI 10.1089/109493102321018187
   Hayes SA, 2008, BEHAV THER, V39, P286, DOI 10.1016/j.beth.2007.09.001
   KENDRICK MJ, 1982, J CONSULT CLIN PSYCH, V50, P353, DOI 10.1037/0022-006X.50.3.353
   Klinger E, 2005, CYBERPSYCHOL BEHAV, V8, P76, DOI 10.1089/cpb.2005.8.76
   KOSSLYN SM, 1984, COGNITION, V18, P195, DOI 10.1016/0010-0277(84)90025-8
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Lang P. J., 1971, HDB PSYCHOTHERAPY BE
   Mystkowski JL, 2002, BEHAV THER, V33, P399, DOI 10.1016/S0005-7894(02)80035-1
   Orman EK, 2003, J RES MUSIC EDUC, V51, P302, DOI 10.2307/3345657
   Orman EK, 2004, J MUSIC THER, V41, P70, DOI 10.1093/jmt/41.1.70
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Robillard G., 2002, P 25IEME CONGRES SOC
   Roy S, 2003, CYBERPSYCHOL BEHAV, V6, P411, DOI 10.1089/109493103322278808
   SALMON PG, 1990, MED PROBL PERFORM AR, V5, P2
   Steptoe A., 2001, Music and emotion: Theory and research, P291, DOI DOI 10.1111/J.2044-8295.1987.TB02243.X
   TELLEGEN A, 1974, J ABNORM PSYCHOL, V83, P268, DOI 10.1037/h0036681
   VANKEMENADE JFLM, 1995, PSYCHOL REP, V77, P555, DOI 10.2466/pr0.1995.77.2.555
   Wolpe J.Lazarus., 1966, Behavior Therapy Techniques: A Guide to the Treatment of Neuroses
NR 34
TC 33
Z9 36
U1 4
U2 49
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2016
VL 20
IS 1
BP 71
EP 81
DI 10.1007/s10055-016-0283-y
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1FY
UT WOS:000376092000006
DA 2024-07-18
ER

PT J
AU Schoeffler, M
   Gernert, JL
   Neumayer, M
   Westphal, S
   Herre, J
AF Schoeffler, Michael
   Gernert, Jan Lukas
   Neumayer, Maximilian
   Westphal, Susanne
   Herre, Juergen
TI On the validity of virtual reality-based auditory experiments: a case
   study about ratings of the overall listening experience
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality-based experiments; Overall listening experience;
   Convolution engine; Oculus Rift
ID SOUND; CAVE; ENVIRONMENTS; DISPLAYS
AB In recent years, new developments have led to an increasing number of virtual reality (VR)-based experiments, but little is known about their validity compared to real-world experiments. To this end, an experiment was carried out which compares responses given in a real-world environment to responses given in a VR environment. In the experiment, thirty participants rated the overall listening experience of music excerpts while sitting in a cinema and a listening booth being in a real-world environment and in a VR environment. In addition, the VR system that was used to carry out the sessions in the VR environment is presented in detail. Results indicate that there are only minor statistically significant differences between the two environments when the overall listening experience is rated. Furthermore, in the real-world environment, the ratings given in the listening booth were slightly higher than in the cinema.
C1 [Schoeffler, Michael; Gernert, Jan Lukas; Neumayer, Maximilian; Westphal, Susanne; Herre, Juergen] Joint Inst Fraunhofer IIS & Friedrich Alexander U, Int Audio Labs Erlangen, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Schoeffler, M (corresponding author), Joint Inst Fraunhofer IIS & Friedrich Alexander U, Int Audio Labs Erlangen, Wolfsmantel 33, D-91058 Erlangen, Germany.
EM michael.schoeffler@audiolabs-erlangen.de
CR Agresti A., 2002, Categorial data analysis, V2nd
   [Anonymous], 1994, PROC AUDIO ENG SOC C
   [Anonymous], 2013, PROCEEDING EUROPEAN
   [Anonymous], P SOUND MUS COMP C A
   [Anonymous], P AUD MOSTL AALB DEN
   [Anonymous], P INT S ROOM AC SYDN
   [Anonymous], P 18 INT C AC KYOT J
   [Anonymous], P AES 137 CONV LOS A
   [Anonymous], 1 WEB AUD C PAR FRAN
   [Anonymous], AUDIO ENG SOC CONVEN
   [Anonymous], 1966, P APR 26 28 1966 SPR
   [Anonymous], 2008, Journal of the Acoustical Society of America, DOI DOI 10.1121/1.2934364
   [Anonymous], GUI3D V 1 11
   [Anonymous], P AES 113 CONV
   [Anonymous], P INT C SPAT AUD ICS
   [Anonymous], OGRE GAM ENG V 1 9 0
   [Anonymous], PRACT GUID PROD IMPL
   [Anonymous], P 3 INT S AUD AUD RE
   [Anonymous], THESIS TU BERLIN
   [Anonymous], 2 SIIV INT C FLOR IT
   [Anonymous], AUDIO ENG SOC CONVEN
   [Anonymous], 25 UK C AUD ENG SOC
   [Anonymous], P AES 55 C SPAT AUD
   [Anonymous], P 14 INT SOC MUS INF
   [Anonymous], P 7 ANN WORKSH PRES
   Astheimer P., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P100, DOI 10.1109/VRAIS.1993.378256
   BERKHOUT AJ, 1993, J ACOUST SOC AM, V93, P2764, DOI 10.1121/1.405852
   Blauert J., 1997, Spacial Hearing, The Psychophysics of Human Sound Localization
   Blauert J, 2012, J AUDIO ENG SOC, V60, P4
   Bossard Cyril, 2008, Virtual Reality, V12, P151, DOI 10.1007/s10055-008-0093-y
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Cakmakci O, 2006, J DISP TECHNOL, V2, P199, DOI 10.1109/JDT.2006.879846
   Cohen J., 1988, STAT POWER ANAL BEHA
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   DeFanti TA, 2009, FUTURE GENER COMP SY, V25, P169, DOI 10.1016/j.future.2008.07.015
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338
   Gilkey R., 2014, BINAURAL SPATIAL HEA
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   KOZAK JJ, 1993, ERGONOMICS, V36, P777, DOI 10.1080/00140139308967941
   Kuhlen T, 2007, LECT NOTES COMPUT SC, V4563, P270
   Larsson P., 2004, Proceedings of 7th Annual Workshop of Presence, P252
   Lathi B.P., 2014, Essentials of Digital Signal Processing
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   MERSHON DH, 1981, PERCEPTION, V10, P531, DOI 10.1068/p100531
   Müller S, 2001, J AUDIO ENG SOC, V49, P443
   Novo P, 2005, COMMUNICATION ACOUSTICS, P277, DOI 10.1007/3-540-27437-5_11
   Palomäki KJ, 2005, COGNITIVE BRAIN RES, V24, P364, DOI 10.1016/j.cogbrainres.2005.02.013
   Pearson JL, 2004, PERS INDIV DIFFER, V36, P1005, DOI 10.1016/S0191-8869(03)00168-5
   Prince W.F., 1972, Journal of Research in Music Education, V20, P445
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Rumsey F, 2005, J ACOUST SOC AM, V117, P3832, DOI 10.1121/1.1904305
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   SANDEL TT, 1955, J ACOUST SOC AM, V27, P842, DOI 10.1121/1.1908052
   Schoeffler M., 2013, Proc. Sound Music Comput. Conf, P48
   Schoeffler M., 2013, Proc. 10th Int. Symp. Comput. Music Multidiscip. Res, P678
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Stanney K., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P28, DOI 10.1109/VRAIS.1995.512476
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sveistrup H, 2003, CYBERPSYCHOL BEHAV, V6, P245, DOI 10.1089/109493103322011524
   Torger A, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P195, DOI 10.1109/ASPAA.2001.969576
   van Dam A, 2002, COMPUT GRAPH-UK, V26, P535, DOI 10.1016/S0097-8493(02)00113-9
   Västfjäll D, 2003, CYBERPSYCHOL BEHAV, V6, P181, DOI 10.1089/109493103321640374
   Vora J, 2002, APPL ERGON, V33, P559, DOI 10.1016/S0003-6870(02)00039-X
   Welch N, 1996, BEHAV RES METH INSTR, V28, P192, DOI 10.3758/BF03204764
   Werner S, 2012, INT WORK QUAL MULTIM, P133, DOI 10.1109/QoMEX.2012.6263855
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
NR 69
TC 11
Z9 13
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 181
EP 200
DI 10.1007/s10055-015-0270-8
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800004
DA 2024-07-18
ER

PT J
AU Campbell, AG
   Stafford, JW
   Holz, T
   O'Hare, GMP
AF Campbell, Abraham G.
   Stafford, John W.
   Holz, Thomas
   O'Hare, G. M. P.
TI Why, when and how to use augmented reality agents (AuRAs)
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Multi-agent systems; Virtual reality; AR simulation;
   Interaction techniques
ID VALIDITY; ISSUES
AB Over the last number of years, multiple research projects have begun to create augmented reality (AR) applications that use augmented reality agents, or AuRAs, as their principle interaction and development paradigm. This paper aims to address this new and distinct field of AuRAs by asking three questions: why should AuRAs be researched, when are they a useful paradigm, and how can they be developed? The first question explores the motivation behind applying AuRAs to AR. Specifically, it investigates whether AuRAs are purely an interaction paradigm, or whether they can also serve as a development paradigm, by outlining in which circumstances it is appropriate for a project to use AuRAs and where their addition would only add unnecessary complexity. A navigational experiment, performed in simulated AR, explores the second question of when AuRAs can be a useful concept in AR applications. Results from this experiment suggest that an embodied virtual character allows for faster navigation along a shorter route than directional arrows or marking the target with an AR "bubble". An exploration of the limitations of the simulated AR environment illuminates how faithfully the experiment recreated the environmental challenges that AuRAs can help to address. Finally, the question of how to develop such applications is addressed through the introduction of the agent factory augmented reality toolkit that allows the rapid prototyping of such applications. Results from a usability study on the toolkit are also presented.
C1 [Campbell, Abraham G.; Holz, Thomas; O'Hare, G. M. P.] Univ Coll Dublin, CLARITY Ctr Sensor Web Technol, Dublin 4, Ireland.
   [Stafford, John W.] Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 4, Ireland.
C3 University College Dublin; University College Dublin
RP Campbell, AG (corresponding author), Univ Coll Dublin, CLARITY Ctr Sensor Web Technol, Dublin 4, Ireland.
EM abey.campbell@gmail.com; jwstafford@gmail.com; thomas.holz@ucd.ie;
   gregory.ohare@ucd.ie
RI O'Hare, Gregory M.P./AAA-7756-2022; Campbell, Abey/AAU-6764-2021
OI O'Hare, Gregory M.P./0000-0002-5124-1686; Holz,
   Thomas/0000-0001-7782-1999; Campbell, Abraham/0000-0001-6702-9148
FU Science Foundation Ireland [07/CE/I1147]
FX This work is supported by Science Foundation Ireland under Grant No.
   07/CE/I1147. The authors would like to thank the reviewers whose
   suggestions and constructive feedback throughout the review process led
   to a greatly improved paper.
CR Adams D, 1990, HYPERLAND
   Ahrndt S, 2012, ADV INTEL SOFT COMPU, V155, P225
   [Anonymous], 2001, P 2001 C VIRTUAL REA
   Bellifemine F, 2001, SOFTWARE PRACT EXPER, V31, P103, DOI 10.1002/1097-024X(200102)31:2<103::AID-SPE358>3.0.CO;2-O
   Black D., 2009, P 21 ANN C AUSTR COM, P33
   Bratman M.E., 1987, Intention, Plans, and Practical Reason
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   Campbell A, 2012, STUD COMPUT INTELL, V396, P303
   Charles F., 2004, P 2004 ACM SIGCHI IN, P32, DOI DOI 10.1145/1067343.1067347
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dautenhahn K., 1999, Computation for metaphors, analogy, and agents, P102
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Denby B, 2009, PRESENCE-TELEOP VIRT, V18, P409, DOI 10.1162/pres.18.5.409
   Dragone M, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P1154
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Duffy BR, 2005, KYBERNETES, V34, P1404, DOI 10.1108/03684920510614731
   Ferber J., 1999, Multi-agent systems: an introduction to distributed artificial intelligence, V33
   Foner L., 1993, What's An Agent, Anyway? A Sociological Case Study
   Geiger C, 2002, 1 IEEE INT AUGM REAL
   GEISSER S, 1958, ANN MATH STAT, V29, P885, DOI 10.1214/aoms/1177706545
   Gharpure CP, 2008, INTEL SERV ROBOT, V1, P237, DOI 10.1007/s11370-008-0020-9
   Google, 2009, LAYAR AUGM REAL BROW
   Gorgu, 2010, Proc. of the 8th Intl. Conf. on Advances in Mobile Computing and Multimedia, P173
   Haugeland J., 1989, ARTIFICIAL INTELLIGE
   Hedberg SR, 1998, IEEE INTELL SYST APP, V13, P21, DOI 10.1109/5254.671087
   Holz T, 2011, INT J HUM-COMPUT ST, V69, P251, DOI 10.1016/j.ijhcs.2010.10.001
   Horvitz E., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P256
   International Organization For Standardization, 1998, ISO 9241-11
   Iso M., 2007, DENNO COIL
   Ju W, 2005, P CHI, P1509
   Jurdak R, 2010, IEEE T MOBILE COMPUT, V9, P955, DOI 10.1109/TMC.2010.35
   Kanellopoulos Y., 2010, International Journal of Software Engineering and Applications, V1, P17, DOI [DOI 10.5121/IJSEA.2010.1302, 10.5121/ijsea.2010.1302]
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Katz Brian FG, 2012, Technology and Disability, V24, P163, DOI 10.3233/TAD-2012-0344
   KIRAKOWSKI J, 1993, BRIT J EDUC TECHNOL, V24, P210, DOI 10.1111/j.1467-8535.1993.tb00076.x
   Koay K, 2009, P 13 INT C HUM COMP
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lancelle M, 2009, P IEEE VIRT REAL, P1
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Lee C, 2009, INT SYM MIX AUGMENT, P203, DOI 10.1109/ISMAR.2009.5336464
   Lieberman Henry., 1997, P SIGCHI C HUMAN FAC, P67, DOI DOI 10.1145/258549.258592
   Lingley AR, 2011, J MICROMECH MICROENG, V21, DOI 10.1088/0960-1317/21/12/125014
   Littman M. L., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P362
   Maes P, 1995, P COMP AN
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nagao K, 1998, COMMUNITY COMPUTING
   O'Hare G. M. P., 2006, International Journal of Web and Grid Services, V2, P379, DOI 10.1504/IJWGS.2006.011711
   O'Hare G.M.P., 2005, P 18 INT C COMP AN S
   O'Hare GMP, 2003, COMPUT COMMUN, V26, P1177, DOI 10.1016/S0140-3664(02)00252-9
   O'Hare GMP, 1998, P 9 IR C ART INT COG, P249
   Obaid Mohammad, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P363, DOI 10.1007/978-3-642-23974-8_39
   OHare GMP, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON ACTIVE MEDIA TECHNOLOGY (AMT 2005), P481, DOI 10.1109/AMT.2005.1505402
   Pegler MM, 1990, MARKET SUPERMARKET H
   Pustka D, 2011, IEEE PERVAS COMPUT, V10, P68, DOI 10.1109/MPRV.2010.50
   Ragan E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P287, DOI 10.1109/VR.2009.4811058
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312
   Robert D, 2012, ACMIEEE INT CONF HUM, P359
   Russell S., 2016, Artificial intelligence a modern approach
   Saeedi E, 2008, J MICROMECH MICROENG, V18, DOI 10.1088/0960-1317/18/7/075019
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Schmalstieg D, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P176
   Shneiderman B., 2010, DESIGNING USER INTER
   SHOHAM Y, 1993, ARTIF INTELL, V60, P51, DOI 10.1016/0004-3702(93)90034-9
   Slater M, 2002, COMP SUPP COMP W SER, P146
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Sutherland I.E., 1965, P IFIP C, V2
   Syrdal D. S., 2009, P NEW FRONT HUM ROB
   Tan DS, 2006, HUM FACTORS, V48, P318, DOI 10.1518/001872006777724381
   Thrun S., 2005, PROBABILISTIC ROBOTI
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Wei Zhu, 2008, Journal of Organizational and End User Computing, V20, P41, DOI 10.4018/joeuc.2008070103
   Weiser M, 1992, MIT MED LAB S US INT
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   Youngho Lee, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P69, DOI 10.1007/978-3-642-22021-0_9
   Ziemke T, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P1305
NR 76
TC 14
Z9 15
U1 1
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2014
VL 18
IS 2
BP 139
EP 159
DI 10.1007/s10055-013-0239-4
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HV
UT WOS:000340622300005
DA 2024-07-18
ER

PT J
AU Sharma, G
   Schroeder, R
AF Sharma, Geetika
   Schroeder, Ralph
TI Mixing real and virtual conferencing: lessons learned
SO VIRTUAL REALITY
LA English
DT Article
DE Collaborative virtual environments; Real and virtual conferences
ID ENVIRONMENTS; USABILITY; AVATARS; DESIGN; WORLDS; TIME
AB This paper describes a conference which linked several remote location sites via a virtual environment so that the virtual audience could follow the presentations and interact with real presenters. The aim was to assess the feasibility of linking distributed virtual audiences to an ongoing conference event. The conference consisted of an annual gathering of researchers and developers of a global information technology consultancy firm based in India. This firm developed a virtual environment specifically for distributed collaboration across sites. During the conference, researchers gathered various types of data, including participant observations, interviews, capture of the virtual environment and a survey of the audience. These data are analysed in the paper. The main finding is that a number of 'low tech' improvements could be made to the operation of the system that could greatly enhance this type of virtual conferencing. A related finding is that the visual fidelity of the environment and of the avatars plays a lesser role than other factors such as audio quality. Given the paucity of research on how virtual conferencing can substitute for travel, plus the urgency of this topic for environmental reasons, a number of suggestions are made for the implementation of remote virtual conference participation.
C1 [Sharma, Geetika] Tata Consultancy Serv, Gurgaon, Haryana, India.
   [Schroeder, Ralph] Univ Oxford, Oxford Internet Inst, Oxford, England.
C3 Tata Sons; Tata Consultancy Services Limited (TCS); University of Oxford
RP Sharma, G (corresponding author), Tata Consultancy Serv, 249 D&E Udyog Vihar,Phase 4, Gurgaon, Haryana, India.
EM geetikas@gmail.com; ralph.schroeder@oii.ox.ac.uk
OI Sharma, Geetika/0000-0003-1708-0396
CR Anderson J, 2001, CYBERPSYCHOL BEHAV, V4, P287, DOI 10.1089/109493101300117965
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Bailenson JN, 2006, COMP SUPP COMP W SER, V34, P1
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Churchill E. F., 2001, COLLABORATIVE VIRTUA
   Damer B, 2000, LECT NOTES ARTIF INT, V1834, P1
   Finn K.E., 1997, Video-mediated communication, P3
   Garau M, 2006, COMP SUPP COMP W SER, V34, P17
   Gutwin C., 2001, A descriptive framework of workspace awareness for real-time groupware
   Harrison S, 2009, COMPUT SUPP COOP WOR, P1, DOI 10.1007/978-1-84882-483-6
   Hinds P., 2002, Distributed Work
   Hirsh S, 2005, HPL2004140R1
   Kirk D., 2010, P CSCW 2010
   Labhart N, 2012, J UNIVERS COMPUT SCI, V18, P2542
   Lindeman RW, 2009, IEEE COMPUT GRAPH, V29, P80, DOI 10.1109/MCG.2009.28
   Olson GM, 2000, HUM-COMPUT INTERACT, V15, P139, DOI 10.1207/S15327051HCI1523_4
   Penumarthy S, 2006, COMP SUPP COMP W SER, V34, P39
   Rintel S, 2013, ELECT J COM IN PRESS
   Rittenbruch M, 2007, AWARENESS SURVEY HIS
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Schroeder R, 2010, BEING THERE TOGHETER
   Schroeder R, 2011, REINVENTING OURSELVE
   Schroeder R, 2006, PRESENCE-VIRTUAL AUG, V15, P655, DOI 10.1162/pres.15.6.655
   Sharma G., 2011, INT S VR INN
   Shirmohammadi S, 2012, IEE INT WORKHS HAPT
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Sonnenwald DH, 2006, COMP SUPP COMP W SER, V34, P63
   Tay WY, 2012, THESIS OXFORD U
   van der Kleij R, 2005, INT J HUM-COMPUT ST, V62, P521, DOI 10.1016/j.ijhcs.2005.01.003
   Vertegaal R, 1998, THESIS U TWENTE NETH
NR 31
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2013
VL 17
IS 3
BP 193
EP 204
DI 10.1007/s10055-013-0225-x
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 214EM
UT WOS:000324113800003
DA 2024-07-18
ER

PT J
AU Heerink, M
   Kröse, B
   Evers, V
   Wielinga, B
AF Heerink, Marcel
   Krose, Ben
   Evers, Vanessa
   Wielinga, Bob
TI Relating conversational expressiveness to social presence and acceptance
   of an assistive social robot
SO VIRTUAL REALITY
LA English
DT Article
DE Social presence; Technology acceptance; Social robots; Gerontechnology;
   Human-robot interaction
AB Exploring the relationship between social presence, conversational expressiveness, and robot acceptance, we set up an experiment with a robot in an eldercare institution, comparing a more and less social condition. Participants showed more expressiveness with a more social agent and a higher score on expressiveness correlated with higher scores on social presence. Furthermore, scores on social presence correlated with the scores on the intention to use the system in the near future. However, we found no correlation between conversational expressiveness and robot acceptance.
C1 [Heerink, Marcel] Amsterdam Univ Appl Sci, Amsterdam, Netherlands.
   [Krose, Ben; Evers, Vanessa; Wielinga, Bob] Univ Amsterdam, Amsterdam, Netherlands.
C3 University of Amsterdam
RP Heerink, M (corresponding author), Amsterdam Univ Appl Sci, Amsterdam, Netherlands.
EM m.heerink@hva.nl
RI Heerink, Marcel/B-5966-2016
OI Heerink, Marcel/0000-0003-2319-5237
CR [Anonymous], 2005, AAAI SPRING S
   [Anonymous], P AAAI FALL S CAR MA
   [Anonymous], 2002, AAAI WORKSH AUT ELD
   [Anonymous], 2002, P AAAI IAAI
   [Anonymous], P C DES INT SYST PRO
   AXELROD L, 2005, P S CONV INF SUPP SO
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   BARTNECK C, 2005, P IEEE INT WORKSH RO
   Beck A, 2003, ROBOTIC PETS ELDERLY
   Beck A., 1996, PETS PEOPLE
   BICKMORE T, 2004, P CHI VIENN
   Bickmore T, 2006, P CHI
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   CERRATO LA, 2002, P ICSLP
   CESTA A, 2006, P INT C AG DIS IND I
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Clarkson E., 2007, P 20 INT FLORIDA ART, P44
   Dautenhahn K, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1132, DOI 10.1109/IRDS.2002.1043883
   Dautenhahn K, 2002, FROM ANIM ANIMAT, P1
   DAUTENHAHN K, 1994, P PERC ACT C IEEE
   de Ruyter B, 2005, INTERACT COMPUT, V17, P522, DOI 10.1016/j.intcom.2005.03.003
   Dillon A., 2001, ENCY HUMAN FACTORS E
   Forlizzi J., 2005, Interactions, V12, P16, DOI 10.1145/1052438.1052454
   Forlizzi J, 2004, HUM-COMPUT INTERACT, V19, P25, DOI 10.1207/s15327051hci1901&2_3
   Graf B, 2004, AUTON ROBOT, V16, P193, DOI 10.1023/B:AURO.0000016865.35796.e9
   Heerink M., 2006, International Journal of Assistive Robotics and Systems, V7, P33
   Heerink M., 2008, Journal of Physical Agents, V2, P33
   HEERINK M, 2007, P INT C REH ROB ICOR
   HEYLEN D, 2002, P INT CLASS WORKSH N
   HEYLEN D, 2006, P 1 CAL C REC ADV EN
   KAHN PH, 2006, P RO MAN
   Kidd CD, 2006, IEEE INT CONF ROBOT, P3972, DOI 10.1109/ROBOT.2006.1642311
   Lee K. M., 2003, P SIGCHI C HUM FACT
   Lee V, 2002, J NONVERBAL BEHAV, V26, P3, DOI 10.1023/A:1014479919684
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   LINLIK, 2000, BIOMETRICS, V56, P324
   Lombard M, 1997, J COMPUT MEDIAT COMM, V3
   MYNATT ED, 2000, P CUU 2000 C UN US
   NAKANO YI, 2005, AISB 2005 S CONV INF
   Parlitz C, 2007, LECT NOTES COMPUT SC, V4557, P922
   Pineau J, 2003, ROBOT AUTON SYST, V42, P271, DOI 10.1016/S0921-8890(02)00381-0
   Pollack ME, 2005, AI MAG, V26, P9
   Reeves B., 1996, MEDIA EQUATION PEOPL
   SCHERER KR, 1987, GENEVA STUD EMOTION
   Scholtz J., 2004, IEEE PERVASIVE COMPU
   SHIBATA T, 2003, P 2003 IEEE INT C RO
   Taggart W., 2005, INTERACTIVE ROBOT NU, P56
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   WADA K, 2003, P 2003 IEEE RSJ INT
   WADA KAS, 2006, P RO MAN
   WAGNER HL, 1991, J NONVERBAL BEHAV, V15, P201, DOI 10.1007/BF00986922
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yanco HA, 2004, HUM-COMPUT INTERACT, V19, P117, DOI 10.1207/s15327051hci1901&2_6
   [No title captured]
   [No title captured]
   [No title captured]
NR 57
TC 59
Z9 64
U1 2
U2 64
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 77
EP 84
DI 10.1007/s10055-009-0142-1
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400008
OA hybrid, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Heyd, J
   Birmanns, S
AF Heyd, Jochen
   Birmanns, Stefan
TI Immersive structural biology: a new approach to hybrid modeling of
   macromolecular assemblies
SO VIRTUAL REALITY
LA English
DT Article
DE Structural biology; Docking; Multi-resolution modeling; Electron
   microscopy; Haptic rendering; Virtual reality
ID LOW-RESOLUTION MAPS; ATOMIC STRUCTURES; X-RAY; DOCKING; ORC
AB Advanced biophysical imaging techniques, such as cryo-electron microscopy or tomography, enable 3D volumetric reconstructions of large macromolecular complexes in a near-native environment. However, pure volumetric data is insufficient for a detailed understanding of the underlying protein-protein interactions. This obstacle can be overcome by assembling an atomic model of the whole protein complex from known atomic structures, which are available from either X-ray crystallography or homology modeling. Due to many factors such as noise, conformational variability, experimental artifacts, and inexact model structures, existing automatic docking procedures are known to report false positives for a significant number of cases. The present paper focuses on a new technique to combine an offline exhaustive search algorithm with interactive visualization, collision detection, and haptic rendering. The resulting software system is highly immersive and allows the user to efficiently solve even difficult multi-resolution docking problems. Stereoscopic viewing, combined with head tracking and force feedback, generates an ideal virtual environment for true interaction with and solution of hybrid biomolecular modeling problems.
C1 [Heyd, Jochen; Birmanns, Stefan] Univ Texas Houston, Sch Hlth Informat Sci, Houston, TX 77030 USA.
C3 University of Texas System; University of Texas Health Science Center
   Houston
RP Birmanns, S (corresponding author), Univ Texas Houston, Sch Hlth Informat Sci, 7000 Fannin St, Houston, TX 77030 USA.
EM jheyd@biomachina.org; sbirmanns@biomachina.org
FU National Library of Medicine [5T15LM- 07093]; NIH [R01GM62968];
   Gillson-Longenbaugh Foundation; University of Texas at Houston
FX We would like to thank Huilin Li for kindly discussing the ORC-Cdc6
   results with us and Willy Wriggers for his valuable advice regarding
   this project. The present work was supported by a training fellowship
   (to J.H.) from the National Library of Medicine to the Keck Center for
   Interdisciplinary Bioscience Training of the Gulf Coast Consortia (NLM
   Grant No. 5T15LM- 07093), NIH grant R01GM62968, a grant from the
   Gillson-Longenbaugh Foundation, and startup funds from the University of
   Texas at Houston (to S.B.). In addition, we would like to thank the
   reviewers for many helpful comments and suggestions.
CR Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Bayazit OB, 2001, IEEE INT CONF ROBOT, P954, DOI 10.1109/ROBOT.2001.932673
   Birmanns S, 2003, J STRUCT BIOL, V144, P123, DOI 10.1016/j.jsb.2003.09.018
   Birmanns S, 2007, J STRUCT BIOL, V157, P271, DOI 10.1016/j.jsb.2006.08.008
   Ceulemans H, 2004, J MOL BIOL, V338, P783, DOI 10.1016/j.jmb.2004.02.066
   Chacón P, 2002, J MOL BIOL, V317, P375, DOI 10.1006/jmbi.2002.5438
   Frank J, 2002, ANNU REV BIOPH BIOM, V31, P303, DOI 10.1146/annurev.biophys.31.082901.134202
   FRANK J, 2006, 3 DIMENSIONAL ELECT
   Garzón JI, 2007, BIOINFORMATICS, V23, P427, DOI 10.1093/bioinformatics/btl625
   *INT CORP, 1994, INT MATH KERN LIB 10
   Jiang W, 2001, J MOL BIOL, V308, P1033, DOI 10.1006/jmbi.2001.4633
   Källblad P, 2004, PROTEINS, V56, P693, DOI 10.1002/prot.20201
   Kleywegt G.J., 2001, CRYSTALLOGRAPGHY BIO, VF., P353
   LIANG C, 1995, CELL, V81, P667, DOI 10.1016/0092-8674(95)90528-6
   Liu JY, 2000, MOL CELL, V6, P637, DOI 10.1016/S1097-2765(00)00062-9
   Lucic V, 2005, ANNU REV BIOCHEM, V74, P833, DOI 10.1146/annurev.biochem.73.011303.074112
   *NOV TECHN INC, 2008, FALC HAPT DEV
   Ouh-young M., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P1824, DOI 10.1109/ROBOT.1988.12330
   Petoukhov MV, 2007, CURR OPIN STRUC BIOL, V17, P562, DOI 10.1016/j.sbi.2007.06.009
   Roseman AM, 2000, ACTA CRYSTALLOGR D, V56, P1332, DOI 10.1107/S0907444900010908
   Rossmann MG, 2005, STRUCTURE, V13, P355, DOI 10.1016/j.str.2005.01.005
   Rossmann MG, 2000, ACTA CRYSTALLOGR D, V56, P1341, DOI 10.1107/S0907444900009562
   SHORT J, 2006, MRC CAMBRIDGE IMAGE
   Speck C, 2005, NAT STRUCT MOL BIOL, V12, P965, DOI 10.1038/nsmb1002
   Steven AC, 2008, J STRUCT BIOL, V163, P186, DOI 10.1016/j.jsb.2008.06.002
   Volkmann N, 1999, J STRUCT BIOL, V125, P176, DOI 10.1006/jsbi.1998.4074
   *WORLDW PROT DAT B, 2008, PROT DAT BANK CONT G
   Wriggers W, 1999, J STRUCT BIOL, V125, P185, DOI 10.1006/jsbi.1998.4080
   Wriggers W, 2001, STRUCTURE, V9, P779, DOI 10.1016/S0969-2126(01)00648-7
   Wu XW, 2003, J STRUCT BIOL, V141, P63, DOI 10.1016/S1047-8477(02)00570-1
NR 30
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2009
VL 13
IS 4
SI SI
BP 245
EP 255
DI 10.1007/s10055-009-0129-y
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XF
UT WOS:000208104400004
OA hybrid
DA 2024-07-18
ER

PT J
AU Stone, R
   Caird-Daley, A
   Bessell, K
AF Stone, Robert
   Caird-Daley, Antoinette
   Bessell, Kevin
TI <i>SubSafe</i>: a games-based training system for submarine safety and
   spatial awareness (Part 1)
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Games-based training; Submarine safety; Virtual
   environments; Defence simulation
AB Recent advances in hardware and software technologies for computer games have proved to be more than capable of delivering quite detailed virtual environments on PC platforms and gaming consoles for so-called "serious" applications, at a fraction of the cost than was the case 8 years ago. SubSafe is a recent example of what can be achieved in part-task naval training applications using gaming technologies, exploiting freely available, freely distributable software. SubSafe is a proof-of-concept demonstrator that presents end users with an interactive, real-time three-dimensional model of part of a Trafalgar Class submarine. This "Part 1" paper presents the background to the SubSafe project and outlines the experimental design for a pilot study being conducted between August 2008 and January 2009, in conjunction with the Royal Navy's Submarine School in Devonport. The study is investigating knowledge transfer from the classroom to a real submarine environment (during week 7 of the students' "Submarine Qualification Dry" course), together with general usability and interactivity assessments. Part 2 of the paper (to be completed in early 2009) will present the results of these trials and consider future extensions of the research into other submarine training domains, including periscope ranging and look-interval assessment skills, survival systems deployment training and the planning and rehearsal of submersible rescue operations.
C1 [Stone, Robert] Univ Birmingham, Human Interface Technol Team, Sch Elect Elect & Comp Engn, Birmingham B15 2TT, W Midlands, England.
   [Caird-Daley, Antoinette] Cranfield Univ, Dept Syst Engn & Human Factors, Bedford, England.
   [Bessell, Kevin] Aerosyst Int, Yeovil, Somerset, England.
C3 University of Birmingham; Cranfield University
RP Stone, R (corresponding author), Univ Birmingham, Human Interface Technol Team, Sch Elect Elect & Comp Engn, Birmingham B15 2TT, W Midlands, England.
EM r.j.stone@bham.ac.uk; a.caird-daley@cranfield.ac.uk;
   Kevin.A.Bessell@baesystems.com
FU Human Capability Domain of the UK Ministry of Defence Scientific
   Research
FX The work reported here is part-funded by the Human Capability Domain of
   the UK Ministry of Defence Scientific Research Programme, and was
   initiated by the MoD Research Director, Human Capability. The authors
   would like to acknowledge the invaluable contribution and specialist
   support provided by the SMQ (South) Instructor Team at HM Naval Base in
   Devonport-WO (Coxn) Dermot Roberts, CPOMEA Steve McGowan and PO (WSM)
   "Harry" Harris-and the crews of Her Majesty's Submarines Tireless,
   Trenchant and Trafalgar. Without their contribution, hospitality and
   tolerance, this project would not have been possible.
CR [Anonymous], VSMM 2005 C EN BELG
   Biegel PE, 1998, J HOPKINS APL TECH D, V19, P470
   Chen JYC, 2007, IEEE T SYST MAN CY C, V37, P1231, DOI 10.1109/TSMCC.2007.905819
   EDWARDS M, 2000, P UDT PAC 2000
   Gallagher J.M., 2002, LEARNING THEORY PIAG
   GARRETT M, 2007, SUBSPACE ENHAN UNPUB
   GOLLEDGE R, 1988, P INT GEOGR C SYDN
   Moltenbrey K, 2000, COMPUT GRAPH WORLD, V23, P24
   Peuquet D.J., 2002, REPRESENTATIONS SPAC
   REGIAN JW, 1992, J COMMUN, V42, P136, DOI 10.1111/j.1460-2466.1992.tb00815.x
   SEAMON AG, 1999, A565263 NAV AIR WARF
   Sebrechts M.M., 2000, Human Systems IAC Gateway, V11, P1
   SHEMYAKIN F, 1962, US OFFICE TECHNICAL
   SMITH TR, 1982, GEOGR ANAL, V14, P305
   STONE RJ, 2004, P I ITSEC 2004 I ITS
   STONE RJ, 1999, VIRTUAL REALIT UNPUB
   STONE RJ, 2002, INTERACTIVE 3D UNPUB
   STONE RJ, 2002, P HUM FACT SHIP DES
   Stone RobertJ., 2008, Human factors guidelines for interactive 3D and games-based training systems design
   Tate DL, 1997, IEEE COMPUT GRAPH, V17, P23, DOI 10.1109/38.626965
   Unknown photographer, 1975, ADV CHILD DEV BEHAV, V39, P9
   WHYTE J, 2004, VIRTUAL REALITY BUIL
   *WIK, 2008, MAJ SUBM INC 2000
   [No title captured]
NR 24
TC 16
Z9 17
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 3
EP 12
DI 10.1007/s10055-008-0110-1
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100002
DA 2024-07-18
ER

PT J
AU Zhang, HD
   Cao, LZ
   Howell, G
   Schwartz, D
   Peng, C
AF Zhang, Huadong
   Cao, Lizhou
   Howell, Gel
   Schwartz, David
   Peng, Chao
TI An educational virtual reality game for learning historical events
SO VIRTUAL REALITY
LA English
DT Article
DE VR gamification; VR-based learning; Gaming
ID EXPLORATION
AB This work presents the design, development, and evaluation of an exploration-based educational VR game for learning about historical Apollo lunar roving missions. The design and development are conducted with a three-phase progressive methodology that covers Modeling & Simulation, Gamification & Edufication, and VRization. The immersive experience presents the gamified content in an engaging way and enables learning activities through exploratory play. Players are given the choices of active and passive learning modes to explore the virtual lunar environment and learn spatial, factual, and operating knowledge. We run a user study to understand the learning effectiveness and engagement with this VR game and the influence of different learning modes on the learning outcomes. We discuss the findings and pedagogical implications that can be applied to the development of educational VR games for learning about similar historical events.
C1 [Zhang, Huadong; Cao, Lizhou; Howell, Gel; Schwartz, David; Peng, Chao] Rochester Inst Technol, Sch Interact Games & Media, Rochester, NY 14623 USA.
C3 Rochester Institute of Technology
RP Peng, C (corresponding author), Rochester Inst Technol, Sch Interact Games & Media, Rochester, NY 14623 USA.
EM hz2208@rit.edu; lc1248@rit.edu; amh1268@rit.edu; disvks@rit.edu;
   cxpigm@rit.edu
OI Peng, Chao/0000-0001-8838-2469; Zhang, Huadong/0000-0002-5488-5102
CR Badiozaman IFA, 2022, INNOV EDUC TEACH INT, V59, P586, DOI 10.1080/14703297.2021.1899034
   Allison J, 2008, LEARN MEDIA TECHNOL, V33, P343, DOI 10.1080/17439880802497099
   [Anonymous], 1978, Cogn. Sci, DOI [DOI 10.1207/S15516709COG0202_3, DOI 10.1207/S15516709COG02023, 10.1016/S0364-0213(78)80003-2]
   Arnab S, 2015, BRIT J EDUC TECHNOL, V46, P391, DOI 10.1111/bjet.12113
   Brockmyer JH, 2009, J EXP SOC PSYCHOL, V45, P624, DOI 10.1016/j.jesp.2009.02.016
   Buffalo Games Pandasaurus Games, 2020, APOLLO GAME INSPIRED
   Calvert J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P868, DOI [10.1109/VR.2019.8797864, 10.1109/vr.2019.8797864]
   Cao LZ, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6040044
   Cecotti H, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P16, DOI [10.23919/iLRN47897.2020.9155108, 10.23919/ilrn47897.2020.9155108]
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Checa D, 2020, VIRTUAL REAL-LONDON, V24, P151, DOI 10.1007/s10055-019-00389-7
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Cohen BA, 2008, 39 ANN LUN PLAN SCI, P1640
   Collins A., 1991, Educational values and cognitive instruction, P121
   Cornelissen F, 2012, SPACEOPS
   Dunser A., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P107, DOI [10.1145/2414536.2414554, DOI 10.1145/2414536.2414554]
   Eggarxou D., 2007, INT J ED DEV USING I, V3, P115
   Ferguson C, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103671
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Gaunet F, 2001, COGNITIVE BRAIN RES, V11, P409, DOI 10.1016/S0926-6410(01)00013-1
   Bravo-Quezada OG, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P128, DOI 10.1109/SMAP.2016.7753397
   Hartzler-Miller C., 2001, Theory and Research in Social Education, V29, P672
   Hew KF, 2014, SPRINGERBRIEFS EDUC, P97, DOI 10.1007/978-981-287-089-6_6
   Hine Kyoko, 2019, Front Psychol, V10, P2416, DOI 10.3389/fpsyg.2019.02416
   Immersive VR Education Ltd, 2016, AP 11 VR
   ImmersiveTouch Inc, 2019, OKT 2019 IMM LEARN N
   James KH, 2002, BEHAV RES METH INS C, V34, P383, DOI 10.3758/BF03195466
   Keith Clinton., 2010, AGILE GAME DEV SCRUM, V1st
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-2, P361, DOI 10.5194/isprs-archives-XLII-2-W3-361-2017
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kysela J, 2015, PROCD SOC BEHV, V174, P926, DOI 10.1016/j.sbspro.2015.01.713
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Muscat A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P341, DOI 10.1145/3242671.3242705
   Peng C, 2017, ENTERTAIN COMPUT, V19, P53, DOI 10.1016/j.entcom.2016.12.001
   Peng CJ, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401372
   Polcar J., 2013, SCIENCE
   Schiavi B, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P679, DOI 10.1109/VR.2018.8446412
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Sedlacek D, 2019, INT CONF GAMES VIRTU, P206, DOI 10.1109/vs-games.2019.8864540
   Smith P.L., 2004, Instructional design, V3rd
   Soler JL, 2017, LECT NOTES COMPUT SC, V10622, P12, DOI 10.1007/978-3-319-70111-0_2
   van Gernert T, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P380, DOI 10.1109/VRW52623.2021.00078
   Wilson DM., 1988, COMPUT GAMING WORLD, V1, P2021
   Wilson JP, 2012, GEOMORPHOLOGY, V137, P107, DOI 10.1016/j.geomorph.2011.03.012
   YOUNG MF, 1993, ETR&D-EDUC TECH RES, V41, P43, DOI 10.1007/BF02297091
NR 46
TC 0
Z9 0
U1 10
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2895
EP 2909
DI 10.1007/s10055-023-00845-5
EA AUG 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001048019500001
DA 2024-07-18
ER

PT J
AU Ristor, R
   Morélot, S
   Garrigou, A
   N'Kaoua, B
AF Ristor, Rafael
   Morelot, Sarah
   Garrigou, Alain
   N'Kaoua, Bernard
TI Virtual reality for fire safety training: study of factors involved in
   immersive learning
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented and virtual reality; Human-computer interface; Media in
   education; Factor involved in immersive learning
ID COGNITIVE-LOAD; INTRINSIC MOTIVATION; OUTCOMES; ENVIRONMENTS;
   ACHIEVEMENT; EMOTIONS; MEMORY; INFORMATION; PRINCIPLES; SCIENCE
AB For several years, virtual reality (VR) has been increasingly used in many fields, including learning. It has shown many benefits such as increased learner's safety and engagement. However, the effects of factors that can influence the enhancement of knowledge and the development of skills within immersive virtual devices are still debated. This paper explores the impact of the level of immersion on conceptual and procedural learning outcomes within a virtual environment (VE) for fire safety training. Using a moderated mediation model, we investigated the impact that sense of presence, motivation, cognitive load and emotions had on the relationship between immersion and learning. We then identified that immersion exerts a direct positive effect on procedural learning, but does not exert a direct effect on conceptual learning. None of the relationships between immersion and both types of learning by the sense of presence, the cognitive load, the motivation, and the emotions were significant. Finally, we found that immersion affects the sense of presence through motivation.
C1 [Ristor, Rafael; Morelot, Sarah; Garrigou, Alain] Univ Bordeaux, Epidemiol Canc & Exposit Environm, Inserm, 146 Rue Leo Saignat, F-33076 Bordeaux, France.
   [Ristor, Rafael; N'Kaoua, Bernard] Univ Bordeaux, Equipe ACTIVE, BPH, Inserm,U1219, 146 Rue Leo Saignat, F-33076 Bordeaux, France.
   [Morelot, Sarah] IFOPSE, 14 ZA Metairies, F-56130 Nivillac, France.
C3 Universite de Bordeaux; Institut National de la Sante et de la Recherche
   Medicale (Inserm); Institut National de la Sante et de la Recherche
   Medicale (Inserm); Universite de Bordeaux
RP Ristor, R (corresponding author), Univ Bordeaux, Epidemiol Canc & Exposit Environm, Inserm, 146 Rue Leo Saignat, F-33076 Bordeaux, France.; Ristor, R (corresponding author), Univ Bordeaux, Equipe ACTIVE, BPH, Inserm,U1219, 146 Rue Leo Saignat, F-33076 Bordeaux, France.
EM r.risto@orange.fr
RI N'Kaoua, Bernard/T-3577-2019
CR Adamo-Villani N, 2008, EUR S VIRT ENV, DOI [10.2312/PE/VE2008bPOSTERS/017-020, DOI 10.2312/PE/VE2008BPOSTERS/017-020]
   Adamo-Villani N, 2008, IEEE MULTIMEDIA, V15, P38, DOI 10.1109/MMUL.2008.97
   Ahmed W, 2013, J EDUC PSYCHOL, V105, P150, DOI 10.1037/a0030160
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Andersen MS, 2021, J COMPUT ASSIST LEAR, V37, P183, DOI 10.1111/jcal.12478
   [Anonymous], 2018, FIREFIGHTER FATALITI
   Bailey S, 2017, USING VIRTUAL REALIT
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Buchner J., 2018, P 14 INT C MOB LEARN, P55
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Carrera CC, 2018, INT RES GEOGR ENVIRO, V27, P69, DOI 10.1080/10382046.2017.1285135
   Christmann O., 2017, International Journal of Virtual Reality, V17, P27, DOI [DOI 10.20870/IJVR.2017.17.3, 10.20870/ijvr.2017.17.3]
   DECI EL, 1994, J PERS, V62, P119, DOI 10.1111/j.1467-6494.1994.tb00797.x
   Dede C., 1995, Educational Technology, V35, P46
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dengel A, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P163, DOI [10.23919/ilrn47897.2020.9155084, 10.23919/iLRN47897.2020.9155084]
   Dengel A, 2018, PR IEEE INT CONF TEA, P608, DOI 10.1109/TALE.2018.8615281
   Elangovan T., 2014, ASIA PACIFIC FORUM S, V15, P25
   Fonseca D, 2017, ACM INT C P SER, P1, DOI 10.1145/3144826.3145422
   Fraser K, 2012, MED EDUC, V46, P1055, DOI 10.1111/j.1365-2923.2012.04355.x
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Fuchs P., 2006, Le traite de la realite virtuelle-Vol. 1 L'homme et l'environnement virtuel. [Treaty of virtual reality-Vol. 1 The man and the virtual environment]
   Ganotice FA, 2016, SCHOOL PSYCHOL INT, V37, P498, DOI 10.1177/0143034316660147
   Golly-Häring C, 2003, J EXP PSYCHOL LEARN, V29, P965, DOI 10.1037/0278-7393.29.5.965
   Grassini S, 2020, P 30 EUROPEAN SAFETY, P4964, DOI [10.3850/978-981-14-8593-0_3975-cd, DOI 10.3850/978-981-14-8593-0_3975-CD]
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Hamstra SJ, 2014, ACAD MED, V89, P387, DOI 10.1097/ACM.0000000000000130
   Hanafi HF, 2017, IOP CONF SER-MAT SCI, V226, DOI 10.1088/1757-899X/226/1/012114
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   Helmke A, 1997, BEDINGUNGSFAKTOREN S
   Horcik Z, 2011, ACTIVITIES, V8, P173, DOI 10.4000/activites.2613
   Hornstein SL, 2004, PSYCHON B REV, V11, P367, DOI 10.3758/BF03196584
   Huang CL, 2020, J EDUC COMPUT RES, V58, P596, DOI 10.1177/0735633119867422
   Huang YC, 2019, EDUC INF TECHNOL, V24, P591, DOI 10.1007/s10639-018-9784-5
   Jung JK, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1812
   Lawson G, 2020, POLICY PRACT HEALTH, V18, P155, DOI 10.1080/14773996.2020.1796085
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Leng A., 2010, Eurasia Journal of Mathematics, Sciences and Technoloy Education, V6, P215, DOI [10.12973/ejmste/75241, DOI 10.12973/EJMSTE/75242]
   Leppink J, 2013, BEHAV RES METHODS, V45, P1058, DOI 10.3758/s13428-013-0334-1
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Loderer K, 2020, LEARN INSTR, V70, DOI 10.1016/j.learninstruc.2018.08.002
   Lombard M., 2009, MEASURING PRESENCE T
   Lourdeaux Domitile, 2001, REALITE VIRTUELLE FO
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   MCAULEY E, 1989, RES Q EXERCISE SPORT, V60, P48, DOI 10.1080/02701367.1989.10607413
   Mihelj M, 2012, PRESENCE-TELEOP VIRT, V21, P1, DOI 10.1162/PRES_a_00078
   Mikropoulos T.A., 2006, VIRTUAL REAL-LONDON, V10, P197, DOI DOI 10.1007/S10055-006-0039-1
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Morélot S, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104145
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Noteborn G, 2012, INTERNET HIGH EDUC, V15, P176, DOI 10.1016/j.iheduc.2012.03.002
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Olmos-Raya E., 2018, EURASIA Journal of Mathematics, Science and Technology Education, V14, P2045, DOI [DOI 10.29333/EJMSTE, 10.29333/ejmste/85874, DOI 10.29333/EJMSTE/85874]
   Ostrow KS, 2018, LECT NOTES ARTIF INT, V10947, P381, DOI 10.1007/978-3-319-93843-1_28
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Pekrun R, 2002, EDUC PSYCHOL-US, V37, P91, DOI 10.1207/S15326985EP3702_4
   Pekrun R, 2006, EDUC PSYCHOL REV, V18, P315, DOI 10.1007/s10648-006-9029-9
   Pekrun R, 2011, CONTEMP EDUC PSYCHOL, V36, P36, DOI 10.1016/j.cedpsych.2010.10.002
   Pirker J., 2017, Immersive and engaging forms of virtual learning
   Poitras EG, 2019, BRIT J EDUC TECHNOL, V50, P3345, DOI 10.1111/bjet.12738
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   Ranellucci J., 2015, MOTIV SCI, V1, P98, DOI [10.1037/mot0000014, DOI 10.1037/MOT0000014]
   Richards D, 2015, COMPUT EDUC, V86, P157, DOI 10.1016/j.compedu.2015.03.009
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   RYAN RM, 1982, J PERS SOC PSYCHOL, V43, P450, DOI 10.1037/0022-3514.43.3.450
   Scerbo Mark W, 2007, Simul Healthc, V2, P224, DOI 10.1097/SIH.0b013e31815c25f1
   Schrader C, 2012, COMPUT HUM BEHAV, V28, P648, DOI 10.1016/j.chb.2011.11.011
   Schroeder B. L., 2017, Commun. Comput. Inf. Sci, P54, DOI DOI 10.1007/978-3-319-58753-09
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Smith B, 2007, COMPUT HUM BEHAV, V23, P127, DOI 10.1016/j.chb.2004.04.001
   Sowndararajan A., 2008, IPTEDT 08, P1
   Steffens MC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01907
   Stephan M, 2019, FRONT EDUC, V4, DOI 10.3389/feduc.2019.00109
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Sweller J, 2018, PERSPECT MED EDUC, V7, P1, DOI 10.1007/s40037-017-0395-4
   Tate DL, 1997, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VRAIS.1997.583045
   Taylor G, 2009, P HUM FACT ERG SOC, V3
   Tsigilis N, 2003, PERCEPT MOTOR SKILL, V97, P271, DOI 10.2466/PMS.97.4.271-280
   Tze VMC, 2016, EDUC PSYCHOL REV, V28, P119, DOI 10.1007/s10648-015-9301-y
   VALLERAND RJ, 1992, EDUC PSYCHOL MEAS, V52, P1003, DOI 10.1177/0013164492052004025
   van Baren J., 2004, MEASUREMENT, P1
   van Merriënboer JJG, 2010, MED EDUC, V44, P85, DOI 10.1111/j.1365-2923.2009.03498.x
   Williams-Bell FM, 2015, FIRE TECHNOL, V51, P553, DOI 10.1007/s10694-014-0398-1
   Winn William., 2002, P INT C LEARNING SCI, P497
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yildiz E, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P48, DOI [10.1109/ICGI47575.2019.8955033, 10.1109/icgi47575.2019.8955033]
NR 94
TC 2
Z9 2
U1 7
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2237
EP 2254
DI 10.1007/s10055-022-00743-2
EA MAY 2023
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000983907100001
DA 2024-07-18
ER

PT J
AU Morin, DG
   Gonzalez-Sosa, E
   Perez, P
   Villegas, A
AF Morin, Diego Gonzalez
   Gonzalez-Sosa, Ester
   Perez, Pablo
   Villegas, Alvaro
TI Full body video-based self-avatars for mixed reality: from E2E system to
   user study
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Video-based self-avatars; Egocentric vision; Embodiment;
   Offloading
ID PERFORMANCE; CALIBRATION; APPEARANCE; SENSE
AB In this work, we explore the creation of self-avatars through video pass-through in mixed reality (MR) applications. We present our end-to-end system, including custom MR video pass-through implementation on a commercial head-mounted display (HMD), our deep learning-based real-time egocentric body segmentation algorithm, and our optimized offloading architecture, to communicate the segmentation server with the HMD. To validate this technology, we designed an immersive VR experience where the user has to walk through a narrow tile path over an active volcano crater. The study was performed under three-body representation conditions: virtual hands, video pass-through with color-based full-body segmentation, and video pass-through with deep learning full-body segmentation. This immersive experience was carried out by 30 women and 28 men. To the best of our knowledge, this is the first user study focused on evaluating video-based self-avatars to represent the user in a MR scene. Results showed no significant differences between the different body representations in terms of presence, with moderate improvements in some Embodiment components between the virtual hands and full-body representations. Visual Quality results showed better results from the deep-learning algorithms in terms of the whole body perception and overall segmentation quality. In this study, we provide some discussion regarding the use of video-based self-avatars and some reflections on the evaluation methodology. The proposed E2E solution is in the boundary of the state-of-the-art, so there is still room for improvement before it reaches maturity. However, this solution serves as a crucial starting point for MR applications where users can feel immersed and interact with their own bodies.
C1 [Morin, Diego Gonzalez; Gonzalez-Sosa, Ester; Perez, Pablo; Villegas, Alvaro] Nokia Extended Real Lab, Madrid 28045, Spain.
RP Morin, DG (corresponding author), Nokia Extended Real Lab, Madrid 28045, Spain.
EM diego.gonzalez_morin@nokia.com
RI Gonzalez-Sosa, Ester/L-3544-2013
OI Gonzalez-Sosa, Ester/0000-0002-2428-3792
FU Marie Sklodowska-Curie ETN TeamUp5G [813391]; Marie Curie Actions (MSCA)
   [813391] Funding Source: Marie Curie Actions (MSCA)
FX The funding was provide by Marie Sklodowska-Curie ETN TeamUp5G; Grant
   No. 813391
CR Alaee G., 2018, IEEE VRS 4 WORKSH EV, P10
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Arora N, 2022, ARXIV
   Bazarevsky V, 2020, ARXIV
   Bhargava A, 2022, IEEE T VIS COMPUT GR, V28, P4198, DOI 10.1109/TVCG.2021.3083423
   Bonfert M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P711, DOI 10.1109/VR51125.2022.00092
   Bozgeyikli L, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P812, DOI 10.1109/VR51125.2022.00103
   Bruder G, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P43, DOI 10.1109/CW.2009.39
   Chen GJ, 2017, P ICAT EGVE
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Dodds TJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025759
   EA MCMANUS., 2011, P ACM SIGGRAPH S APP, P37, DOI DOI 10.1145/2077451.2077458
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Fiore Loren Puchalla, 2012, International Journal of Virtual Reality, V11, P33
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gisbergen MSv, 2020, AUGMENTED REALITY VI, P401, DOI [DOI 10.1007/978-3-030-37869-1_32, 10.1007/978-3-030-37869-1_32]
   Gonzalez Morin Diego, 2022, 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P790, DOI 10.1109/VRW55335.2022.00246
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Gonzalez-Franco M, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P91, DOI 10.1109/AIVR50618.2020.00026
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.1580500165557, 10.1109/VR46266.2020.00-85]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gonzalez-Morin D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P785, DOI 10.1109/VRW55335.2022.00248
   Gonzalez-Sosa E, 2022, ARXIV
   Gonzalez-Sosa E, 2020, IEEE ACCESS, V8, P146887, DOI 10.1109/ACCESS.2020.3013016
   GonzalezMorin D, ACM INT C INT MED EX, P121
   Gruosso M, 2021, EXPLORING UPPER LIMB
   Gunther Tobias, 2015, 2015 IEEE Virtual Reality (VR), P327, DOI [10.1109/3DUI.2015.7131748, 10.1109/VR.2015.7223428]
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Hossfeld T., 2016, Quality and User Experience, V1, P1, DOI [10.1007/S41233-016-0002-1, DOI 10.1007/S41233-016-0002-1, 10.1007/s41233-016-0002-1]
   Ipsita A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517696
   Izumihara A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1321, DOI [10.1109/VR.2019.8798064, 10.1109/vr.2019.8798064]
   Jayaraj L, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P310, DOI 10.1109/ISMAR-Adjunct.2017.95
   Joachimczak M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P847, DOI 10.1109/VRW55335.2022.00279
   Lee GA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P115, DOI [10.1109/ISMAR-Adjunct.2016.47, 10.1109/ISMAR-Adjunct.2016.0054]
   Lee K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300566
   Li C, 2013, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2013.458
   Lok B, 2003, PRESENCE-VIRTUAL AUG, V12, P615, DOI 10.1162/105474603322955914
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mirzaei FM, 2008, IEEE T ROBOT, V24, P1143, DOI 10.1109/TRO.2008.2004486
   Narwaria M, 2018, IEEE T MULTIMEDIA, V20, P2063, DOI 10.1109/TMM.2018.2794266
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Pérez P, 2022, FRONT SIGNAL PROC-SW, V2, DOI 10.3389/frsip.2022.917684
   Pérez P, 2021, 2021 4TH IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2021), P179, DOI 10.1109/AIVR52153.2021.00040
   Perez P, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809591
   Pigny PO, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P229, DOI 10.1109/AIVR46125.2019.00048
   Rauter M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1134, DOI [10.1109/VR.2019.8797873, 10.1109/vr.2019.8797873]
   Reichheld FF, 2003, HARVARD BUS REV, V81, P46
   Slater M., 1993, VR93 Virtual Reality International 93. Proceedings of the Third Annual Conference on Virtual Reality, P34
   Sommer P, 2018, IEEE INT CON AUTO SC, P1217, DOI 10.1109/COASE.2018.8560493
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Tang YS, 2019, IEEE T CIRC SYST VID, V29, P3001, DOI 10.1109/TCSVT.2018.2875441
   Thaler A., 2018, FRONT ICT, V5, P18, DOI [DOI 10.3389/FICT.2018.00018, 10.3389/fict.2018, DOI 10.3389/FICT.2018]
   Tome D, 2020, ARXIV
   Villegas A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P109, DOI [10.1109/VRW50115.2020.00025, 10.1109/VRW50115.2020.0-251]
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xiang W, 2019, IEEE WINT CONF APPL, P1789, DOI 10.1109/WACV.2019.00195
   Xu C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020142
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 65
TC 1
Z9 1
U1 4
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2129
EP 2147
DI 10.1007/s10055-023-00785-0
EA APR 2023
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000973207300001
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Voinescu, A
   Petrini, K
   Fraser, DS
AF Voinescu, Alexandra
   Petrini, Karin
   Fraser, Danae Stanton
TI Presence and simulator sickness predict the usability of a virtual
   reality attention task
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Usability; Performance; Attention; Presence; Simulator
   sickness; Mental workload
ID CONTINUOUS PERFORMANCE-TEST; CLINICAVR CLASSROOM-CPT; DRIVING
   PERFORMANCE; EXPOSURE THERAPY; ADHD; ENVIRONMENTS; IMPACT;
   REHABILITATION; CYBERSICKNESS; CHILDREN
AB Attention is the ability to actively process specific information within one's environment over longer periods of time while disregarding other details. Attention is an important process that contributes to overall cognitive performance from performing every day basic tasks to complex work activities. The use of virtual reality (VR) allows study of the attention processes in realistic environments using ecological tasks. To date, research has focused on the efficacy of VR attention tasks in detecting attention impairment, while the impact of the combination of variables such as mental workload, presence and simulator sickness on both self-reported usability and objective attention task performance in immersive VR has not been examined. The current study tested 87 participants on an attention task in a virtual aquarium using a cross-sectional design. The VR task followed the continuous performance test paradigm where participants had to respond to correct targets and ignore non-targets over 18 min. Performance was measured using three outcomes: omission (failing to respond to correct targets), commission errors (incorrect responses to targets) and reaction time to correct targets. Measures of self-reported usability, mental workload, presence and simulator sickness were collected. The results showed that only presence and simulator sickness had a significant impact on usability. For performance outcomes, simulator sickness was significantly and weakly associated with omission errors, but not with reaction time and commission errors. Mental workload and presence did not significantly predict performance. Our results suggest that usability is more likely to be negatively impacted by simulator sickness and lack of presence than performance and that usability and attention performance are linked. They highlight the importance of considering factors such as presence and simulator sickness in attention tasks as these variables can impact usability.
C1 [Voinescu, Alexandra; Petrini, Karin; Fraser, Danae Stanton] Univ Bath, Dept Psychol, Bath BA2 7AY, England.
   [Petrini, Karin] Univ Bath, Ctr Anal Mot Entertainment Res & Applicat, Bath, England.
   [Voinescu, Alexandra] Babes Bolyai Univ, Int Inst Adv Studies Psychotherapy & Appl Mental H, Cluj Napoca, Romania.
C3 University of Bath; University of Bath; Babes Bolyai University from
   Cluj
RP Voinescu, A (corresponding author), Univ Bath, Dept Psychol, Bath BA2 7AY, England.; Voinescu, A (corresponding author), Babes Bolyai Univ, Int Inst Adv Studies Psychotherapy & Appl Mental H, Cluj Napoca, Romania.
EM av561@bath.ac.uk; kp504@bath.ac.uk; pssds@bath.ac.uk
OI Petrini, Karin/0000-0001-5354-5600; Voinescu,
   Alexandra/0000-0001-7689-335X; Stanton Fraser, Danae/0000-0002-3062-731X
CR Adams R, 2009, CHILD NEUROPSYCHOL, V15, P120, DOI 10.1080/09297040802169077
   Aïm F, 2016, ARTHROSCOPY, V32, P224, DOI 10.1016/j.arthro.2015.07.023
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   [Anonymous], 2016, IBM SPSS Statistics for Windows (Version Version 24)
   [Anonymous], 2018, ISO 9241-11
   Areces D, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9100274
   Areces D, 2018, J ATTEN DISORD, V22, P1081, DOI 10.1177/1087054716629711
   Arrabito GR, 2015, HUM FACTORS, V57, P1403, DOI 10.1177/0018720815598433
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Beat-Games, 2018, BEAT SAB
   Bioulac S, 2012, EUR J PAEDIATR NEURO, V16, P514, DOI 10.1016/j.ejpn.2012.01.006
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Brade J, 2017, INT J HUM-COMPUT ST, V101, P76, DOI 10.1016/j.ijhcs.2017.01.004
   Brooke J., 1986, Digital equipment co ltd
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Busch M, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P117, DOI 10.1145/2639189.2639224
   Climent G, 2021, APPL NEUROPSYCH-ADUL, V28, P403, DOI 10.1080/23279095.2019.1646745
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Corno G, 2014, STUD HEALTH TECHNOL, V199, P168, DOI 10.3233/978-1-61499-401-5-168
   CROSBIE RE, 1993, EUROSIM 92 - SIMULATION CONGRESS, P1
   Czaja SJ, 2006, PSYCHOL AGING, V21, P333, DOI 10.1037/0882-7974.21.2.333
   Deary IJ, 2009, BRIT MED BULL, V92, P135, DOI 10.1093/bmb/ldp033
   Dermody G, 2020, J MED INTERNET RES, V22, DOI 10.2196/17331
   Díaz-Orueta U, 2014, CHILD NEUROPSYCHOL, V20, P328, DOI 10.1080/09297049.2013.792332
   Fang YM, 2021, BEHAV INFORM TECHNOL, V40, P1250, DOI 10.1080/0144929X.2021.1938680
   Fang YM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163215
   Films EC, 2021, WAITING ROOM VR FILM
   Fisk AD, 2009, Designing for older adults: Principles and creative human factors approaches
   Fox J., 2015, APPL REGRESSION ANAL
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Georgescu R, 2020, PSYCHOL MED, V50, P1795, DOI 10.1017/S0033291719001855
   Gilboa Y, 2021, J ATTEN DISORD, V25, P300, DOI 10.1177/1087054718808590
   Golding JF, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.576871
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Grier R.A., 2015, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P1727, DOI DOI 10.1177/1541931215591373
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Gualtieri C Thomas, 2005, Psychiatry (Edgmont), V2, P44
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Health D, 2020, VIRTUAL REALITY USED
   Helland A, 2016, ACCIDENT ANAL PREV, V94, P180, DOI 10.1016/j.aap.2016.05.008
   Hitchcock EM, 1999, HUM FACTORS, V41, P365, DOI 10.1518/001872099779610987
   Hornbæk K, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P617
   Huang-Pollock CL, 2012, J ABNORM PSYCHOL, V121, P360, DOI 10.1037/a0027205
   Hutton C, 2018, 2018 IEEE C VIRT REA
   Independent T, 2020, FACEBOOK REVEALS VIR
   Iriarte Y, 2016, J ATTEN DISORD, V20, P542, DOI 10.1177/1087054712465335
   Jacko J, 2004, BEHAV INFORM TECHNOL, V23, P247, DOI 10.1080/01449290310001659213
   Karssemeijer EGA, 2019, J AM MED DIR ASSOC, V20, P1502, DOI 10.1016/j.jamda.2019.06.026
   Karssemeijer EGA, 2019, ALZHEIMERS RES THER, V11, DOI 10.1186/s13195-018-0454-z
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP0201_2, 10.1207/s15327108ijap02012, DOI 10.1207/S15327108IJAP02012]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kolasinski Eugenia M, 1995, Simulator Sickness in Virtual Environments, V1027
   Kretschmer Veronika, 2019, Advances in Human Factors in Wearable Technologies and Game Design. Proceedings of the AHFE 2018 International Conferences on Human Factors and Wearable Technologies, and Human Factors in Game Design and Virtual Environments. Advances in Intelligent Systems and Computing (AISC 795), P266, DOI 10.1007/978-3-319-94619-1_26
   Laver K, 2012, PRESENCE-TELEOP VIRT, V21, P183, DOI 10.1162/PRES_a_00098
   Lee HY, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9461960
   Levine ME, 2002, PERCEPT MOTOR SKILL, V95, P425, DOI 10.2466/PMS.95.5.425-431
   Lezak MD, 2004, Neuropsychological Assessment, DOI DOI 10.1017/S0033291718001599
   Li G, 2020, J COGNITIVE NEUROSCI, V32, P1438, DOI 10.1162/jocn_a_01560
   Longo L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199661
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mallinckrodt B, 2006, J COUNS PSYCHOL, V53, P372, DOI 10.1037/0022-0167.53.3.372
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Matheis RJ, 2007, CLIN NEUROPSYCHOL, V21, P146, DOI 10.1080/13854040601100668
   Meldrum D, 2012, DISABIL REHABIL-ASSI, V7, P205, DOI 10.3109/17483107.2011.616922
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Mondellini M, 2018, LECT NOTES COMPUT SC, V10850, P3, DOI 10.1007/978-3-319-95270-3_1
   Morán AL, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0297-0
   Mousavi M, 2013, ADV ENG FORUM, V10, P34, DOI 10.4028/www.scientific.net/AEF.10.34
   Muhlberger A, 2020, J ATTEN DISORD, V24, P277, DOI 10.1177/1087054716647480
   Mullen NW, 2010, AM J OCCUP THER, V64, P288, DOI 10.5014/ajot.64.2.288
   Muttray A, 2013, INT J OCCUP MED ENV, V26, P949, DOI 10.2478/s13382-013-0164-5
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Napa Sandeep, 2019, JMIR Hum Factors, V6, pe12008, DOI 10.2196/12008
   Narciso D, 2019, UNIVERSAL ACCESS INF, V18, P77, DOI 10.1007/s10209-017-0581-5
   Negut A, 2017, CHILD NEUROPSYCHOL, V23, P692, DOI 10.1080/09297049.2016.1186617
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Negut A, 2016, COMPUT HUM BEHAV, V54, P414, DOI 10.1016/j.chb.2015.08.029
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   NIELSEN J, 1994, COMMUN ACM, V37, P66, DOI 10.1145/175276.175282
   Nolin P, 2016, COMPUT HUM BEHAV, V59, P327, DOI 10.1016/j.chb.2016.02.023
   Nolin P, 2009, STUD HEALTH TECHNOL, V144, P240, DOI 10.3233/978-1-60750-017-9-240
   Nwosu AC, 2024, BMJ SUPPORT PALLIAT, V14, P47, DOI 10.1136/bmjspcare-2020-002327
   Opris D, 2012, DEPRESS ANXIETY, V29, P85, DOI 10.1002/da.20910
   Organization W.H., 2015, World Report on Ageing and Health
   Parsons T. D., 2019, Virtual Realityfor Psychological and Neurocognitive Interventions, P247, DOI [10.1007/978-1-4939-9482-3_11, DOI 10.1007/978-1-4939-9482-3_11]
   Parsons TD, 2019, NEUROPSYCHOL REV, V29, P338, DOI 10.1007/s11065-019-09407-6
   Parsons TD, 2017, NEUROPSYCHOL REHABIL, V27, P777, DOI 10.1080/09602011.2015.1109524
   Pedroli E, 2013, INT CONF PER COMP, P453, DOI 10.4108/icst.pervasivehealth.2013.252359
   Piccione J, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02583
   Pollak Y, 2010, CNS SPECTRUMS, V15, P125, DOI 10.1017/S109285290002736X
   Pollak Y, 2009, J DEV BEHAV PEDIATR, V30, P2, DOI 10.1097/DBP.0b013e3181969b22
   de França ACP, 2018, ADV INTELL SYST, V588, P45, DOI 10.1007/978-3-319-60582-1_5
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   Reinhard RT, 2019, TRANSPORT RES F-TRAF, V61, P131, DOI 10.1016/j.trf.2018.01.004
   Rivera-Flor H, 2019, PROCEDIA COMPUT SCI, V160, P641, DOI 10.1016/j.procs.2019.11.034
   Rizzo A A, 1999, Cyberpsychol Behav, V2, P89, DOI 10.1089/cpb.1999.2.89
   Rizzo AA, 2000, CYBERPSYCHOL BEHAV, V3, P483, DOI 10.1089/10949310050078940
   Rizzo A, 2019, PROC SPIE, V11002, DOI 10.1117/12.2524302
   Rodríguez C, 2018, INT J CLIN HLTH PSYC, V18, P254, DOI 10.1016/j.ijchp.2018.06.003
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Rose Tyler, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P2079, DOI 10.1177/1541931218621469
   Sayers H, 2004, INTERACT COMPUT, V16, P939, DOI 10.1016/j.intcom.2004.05.003
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schultheis MT, 2007, ASSIST TECHNOL, V19, P1, DOI 10.1080/10400435.2007.10131860
   Sharples S., 2007, M DIVERSITY ERGONOMI, P173, DOI [10.1016/B978-008045373-6/50012-X, DOI 10.1016/B978-008045373-6/50012-X]
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Skurla MD, 2022, INT PSYCHOGERIATR, V34, P143, DOI 10.1017/S104161022100017X
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Sportillo D, 2018, ACCIDENT ANAL PREV, V118, P102, DOI 10.1016/j.aap.2018.06.003
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Sun HM, 2015, APPL ERGON, V50, P126, DOI 10.1016/j.apergo.2015.03.006
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Tinius TP, 2003, ARCH CLIN NEUROPSYCH, V18, P199, DOI 10.1016/S0887-6177(01)00196-2
   Tripp Inc, 2020, TRIPP
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Voinescu Alexandra, 2020, Advances in Usability, User Experience, Wearable and Assistive Technology. Proceedings of the AHFE 2020 Virtual Conferences on Usability and User Experience, Human Factors and Assistive Technology, Human Factors and Wearable Technologies, and Virtual Environments and Game Design. Advances in Intelligent Systems and Computing (AISC 1217), P677, DOI 10.1007/978-3-030-51828-8_89
   Voinescu A, 2023, VIRTUAL REAL-LONDON, V27, P119, DOI 10.1007/s10055-021-00520-7
   Wagner N, 2014, COMPUT HUM BEHAV, V37, P270, DOI 10.1016/j.chb.2014.05.003
   Wickens CD., 2015, Engineering psychology and human performance, DOI DOI 10.4324/9781315665177
   Wienrich C, 2018, LECT NOTES COMPUT SC, V10918, P573, DOI 10.1007/978-3-319-91797-9_41
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yu FJ, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P219, DOI 10.1145/3013971.3013977
NR 133
TC 2
Z9 2
U1 5
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1967
EP 1983
DI 10.1007/s10055-023-00782-3
EA MAR 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000955813300002
PM 37360806
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Kari, T
   Kosa, M
AF Kari, Tuomas
   Kosa, Mehmet
TI Acceptance and use of virtual reality games: an extension of HMSAM
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Digital games; User behavior; Virtual reality gaming;
   Dual-purposed systems; VR
ID FLOW; TECHNOLOGY; FUN; METAANALYSIS; ENJOYMENT; FRAMEWORK; EXERCISE;
   ADOPTION
AB Virtual reality (VR) is considered as one of the technological megatrends of 2020s, and today, VR systems are used in various settings, digital gaming being among the most popular ones. However, there has been a dearth of understanding regarding the central factors behind VR gaming acceptance and use. The present study therefore aimed to explain the factors that drive the use and acceptance of VR games. We extended the hedonic-motivation system acceptance model with utilitarian and inconvenience factors to capture the pertinent features of VR systems more holistically. We proposed a theoretical model and analyzed it through covariance-based structural equation modeling using an online survey sample of 473 VR gamers. Our findings help explain the role of different antecedents behind VR gaming acceptance and demonstrate that VR gaming is driven more by the hedonic gaming aspects than by the utilitarian health and well-being aspects of VR games, enjoyment being the strongest driver behind VR gaming intention and immersion. Moreover, findings also suggested that use intentions and immersion levels are not significantly diminished by physical discomfort and VR sickness. The findings, which potentially extend to other VR systems as well, also pose important implications for the providers of VR games. As the main contribution, based on our empirical findings, we provide a greater theoretical understanding on VR gaming acceptance and use.
C1 [Kari, Tuomas] Nat Resources Inst Finland Luke, Helsinki, Finland.
   [Kari, Tuomas] Inst Adv Management Syst Res, Turku, Finland.
   [Kosa, Mehmet] Arizona State Univ, Dept Psychol, Tempe, AZ USA.
   [Kosa, Mehmet] Northeastern Univ, Coll Arts Media & Design, Boston, MA USA.
C3 Natural Resources Institute Finland (Luke); Arizona State University;
   Arizona State University-Tempe; Northeastern University
RP Kari, T (corresponding author), Nat Resources Inst Finland Luke, Helsinki, Finland.; Kari, T (corresponding author), Inst Adv Management Syst Res, Turku, Finland.
EM tuomas.kari@luke.fi; m.kosa@northeastern.edu
OI Kari, Tuomas/0000-0002-5755-806X
FU Natural Resources Institute Finland (LUKE)
FX Open access funding provided by Natural Resources Institute Finland
   (LUKE). No funding was received for conducting this study. The datasets
   generated during and/or analyzed during the current study are available
   from the corresponding author on reasonable request.
CR Agarwal R, 2000, MIS QUART, V24, P665, DOI 10.2307/3250951
   Angelov V, 2020, 2ND INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, OPTIMIZATION AND ROBOTIC APPLICATIONS (HORA 2020), P520, DOI 10.1109/hora49412.2020.9152604
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   Arjoranta J, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/15967
   Aulisio MC, 2020, BRAIN INJURY, V34, P1322, DOI 10.1080/02699052.2020.1802779
   Barkley JE., 2009, Journal of Exercise Physiology, V12, P12
   Beat Games, 2021, BEAT SAB
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Berkovsky S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P243
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Bodzin A, 2021, J SCI EDUC TECHNOL, V30, P347, DOI 10.1007/s10956-020-09870-4
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Borstad AL, 2018, J PATIENT-CENTER RES, V5, P6, DOI 10.17294/2330-0698.1550
   Burdea G., 1994, VIRTUAL REALITY TECH
   Burton-Jones A, 2006, INFORM SYST RES, V17, P228, DOI 10.1287/isre.1060.0096
   Chang IC, 2014, INTERNET RES, V24, P21, DOI 10.1108/IntR-02-2012-0025
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Faric N, 2019, J MED INTERNET RES, V21, DOI 10.2196/13833
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Forbes, 2018, FORBES
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Garrido LE, 2022, VIRTUAL REAL-LONDON, V26, P1347, DOI 10.1007/s10055-022-00636-4
   Gefen D, 2011, MIS QUART, V35, pIII
   Gomez DH, 2018, GAMES HEALTH J, V7, P310, DOI 10.1089/g4h.2018.0012
   Grand View Research, 2020, VIRTUAL REALITY HEAD
   Grand View Research, 2020, Virtual Reality in Gaming Market Size Report
   Gregory J., 2017, VIRTUAL REAL-LONDON
   Guo YM, 2009, INFORM SYST J, V19, P369, DOI 10.1111/j.1365-2575.2007.00292.x
   Hair JF, 2010, Multivariate data analysis
   Hamari J, 2015, P ANN HICSS, P3559, DOI 10.1109/HICSS.2015.428
   Hong SJ, 2006, INFORM SYST RES, V17, P162, DOI 10.1287/isre.1060.0088
   Hsu CL, 2004, INFORM MANAGE-AMSTER, V41, P853, DOI 10.1016/j.im.2003.08.014
   Hu B, 2011, INT J IND ERGONOM, V41, P64, DOI 10.1016/j.ergon.2010.10.001
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Huang W, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM)
   Jabil, 2018, FUT AUGM VIRT REAL G
   Jang Y, 2019, TELEMAT INFORM, V42, DOI 10.1016/j.tele.2019.101239
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jyi-Chang Tsai, 2021, International Journal of Organizational Innovation, V13, P160
   Kari T, 2014, P 35 INT C INF SYST, P1
   Kari T, 2019, COMM COM INF SC, V1164, P179, DOI 10.1007/978-3-030-37983-4_14
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236782
   Kock N, 2015, INT J E-COLLAB, V11, P1, DOI 10.4018/ijec.2015040101
   Kosa M., 2020, Game user experience and player-centered design. International series on computer entertainment and media technology, P63, DOI [10.1007/978-3-030-37643-7-4, DOI 10.1007/978-3-030-37643-7_4]
   Kosa M, 2020, INT J GAMING COMPUT-, V12, P43, DOI 10.4018/IJGCMS.2020010103
   Kotaku, 2016, KOTAKU
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Lemmens JS, 2022, VIRTUAL REAL-LONDON, V26, P223, DOI 10.1007/s10055-021-00555-w
   Lin HH, 2012, INT J HUM-COMPUT INT, V28, P445, DOI 10.1080/10447318.2011.618097
   Lin JHT, 2018, NEW MEDIA SOC, V20, P3223, DOI 10.1177/1461444817744850
   Lowry PB, 2015, J ASSOC INF SYST, V16, P515, DOI 10.17705/1jais.00403
   Lowry PB, 2013, J ASSOC INF SYST, V14, P617
   Marre Q, 2021, INT J HUM-COMPUT INT, V37, P1089, DOI 10.1080/10447318.2020.1870819
   Maxint LLC, 2021, SOUNDB
   Michailidis L, 2019, INT C HUMAN COMPUTER, P45
   Mohr DC, 2013, GEN HOSP PSYCHIAT, V35, P332, DOI 10.1016/j.genhosppsych.2013.03.008
   Mostafa AE, 2017, SAUDI J BIOL SCI, P1, DOI DOI 10.11575/PRISM/31003
   Mueller Florian, 2016, Foundations and Trends in Human-Computer Interaction, V10, P1, DOI 10.1561/1100000041
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Navarro R, 2020, ADV INTELL SYST COMP, V973, P233, DOI 10.1007/978-3-030-20476-1_24
   Nichols S, 1999, APPL ERGON, V30, P79, DOI 10.1016/S0003-6870(98)00045-3
   Nunnally J. C., 1994, Psychometric Theory
   Osorio G, 2012, GAMES HEALTH J, V1, P205, DOI 10.1089/g4h.2011.0025
   Oyelere SS, 2020, SMART LEARN ENVIRON, V7, DOI 10.1186/s40561-020-00142-7
   Pallavicini F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.620225
   Pallavicini F, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/15635
   Pallavicini F, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P195, DOI 10.1145/3341215.3355736
   Patibanda R, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P19, DOI 10.1145/3116595.3116621
   Pavlou PA, 2007, MIS QUART, V31, P105
   Peng W, 2011, CYBERPSYCH BEH SOC N, V14, P681, DOI 10.1089/cyber.2010.0578
   Penumudi SA, 2020, APPL ERGON, V84, DOI 10.1016/j.apergo.2019.103010
   Perrin T, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16224406
   Podsakoff PM, 2003, J APPL PSYCHOL, V88, P879, DOI 10.1037/0021-9010.88.5.879
   Rendon AA, 2012, AGE AGEING, V41, P549, DOI 10.1093/ageing/afs053
   Ropelato S, 2021, VIRTUAL REAL-LONDON, P1
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Statista, 2016, VIRT REAL VR VID GAM
   Statista, 2021, VIRT REAL VR GAM REV
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Sweetser Penny, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P55, DOI 10.1145/3441000.3441050
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Tan C.T., 2015, P CHI PLAY 15, P253
   Techopedia, 2017, HEAD MOUNTED DISPLAY
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Toyoda R, 2023, VIRTUAL REAL-LONDON, V27, P3273, DOI 10.1007/s10055-021-00586-3
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   Venkatesh V, 2012, MIS QUART, V36, P157
   Venturebeat, 2018, VR ARC AR PLAYING LE
   Verge, 2021, A guide to platform fees
   VR Fitness Insider, 2017, JOB STAUFFERS STORY
   Wang G., 2019, 27 EUR C INF SYST EC, P1
   Wang YA, 2021, ADV METH PRACT PSYCH, V4, DOI 10.1177/2515245920918253
   WEBSTER J, 1993, COMPUT HUM BEHAV, V9, P411, DOI 10.1016/0747-5632(93)90032-N
   Winkler N, 2020, P 53RD HAWAII INT C, P1510
   Wong J., 2020, J TECHNOL BEHAV SCI, V5, P378, DOI DOI 10.1007/S41347-020-00146-7
   Xi NN, 2021, J BUS RES, V134, P37, DOI 10.1016/j.jbusres.2021.04.075
   Xu WG, 2020, GAMES HEALTH J, V9, P405, DOI 10.1089/g4h.2019.0102
   Yan Y, 2019, ADV INTELL SYST, V777, P239, DOI 10.1007/978-3-319-94706-8_27
NR 106
TC 7
Z9 7
U1 21
U2 70
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1585
EP 1605
DI 10.1007/s10055-023-00749-4
EA JAN 2023
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000922523200002
PM 36742344
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Choi, Y
   Park, DH
   Lee, SH
   Han, I
   Akan, E
   Jeon, HC
   Luo, YY
   Kim, S
   Matusik, W
   Rus, D
   Kim, KJ
AF Choi, Yunho
   Park, Dong-Hyeok
   Lee, Sungha
   Han, Isaac
   Akan, Ecehan
   Jeon, Hyeon-Chang
   Luo, Yiyue
   Kim, SeungJun
   Matusik, Wojciech
   Rus, Daniela
   Kim, Kyung-Joong
TI Seamless-walk: natural and comfortable virtual reality locomotion method
   with a high-resolution tactile sensor
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Interaction paradigms; Human computer interaction;
   Human-centered computing
ID IN-PLACE; BODY; PERCEPTION
AB Efficient locomotion methods have been proposed to compensate for the limited space in real-world environments, and such methods offer users more immersive and natural experiences in relatively large virtual environments. The foot-based locomotion method is one of the best options for implementing natural locomotion using foot movement as an input. However, existing foot-based locomotion methods force users to wear equipment or take a video of the user's body. These actions can cause discomfort, unnatural feelings, or privacy problems. Thus, we propose a Seamless-walk system that can seamlessly translate a real-world gait action to locomotion signals using a high-resolution tactile carpet sensor without requiring wearable equipment. The proposed method captures and analyzes high-resolution footprint information using a machine learning technique and calculates the user's movement direction and speed in a real-time manner. In addition, the modular structure of Seamless-walk enables scalable installation of a tactile sensing platform at reasonable cost. Human tests (n = 80) confirmed that the proposed Seamless-walk system's technical advantage increases usability. A 3D virtual world exploration game experiment revealed that the proposed method significantly increases comfort and overall naturalness. Additionally, The proposed method has no negative effects on exploration suitability, task load, simulator sickness, or the game experience.
C1 [Choi, Yunho; Park, Dong-Hyeok; Han, Isaac; Akan, Ecehan; Kim, SeungJun; Kim, Kyung-Joong] GIST, Sch Integrated Technol, 123 Chem Dan Gwa Gi, Ro 61005, Gwangju, South Korea.
   [Luo, Yiyue; Matusik, Wojciech; Rus, Daniela] MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Lee, Sungha; Jeon, Hyeon-Chang; Kim, Kyung-Joong] GIST, Artificial Intelligence Grad Sch, 123 Chem Dan Gwa Gi, Ro 61005, Gwangju, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Massachusetts
   Institute of Technology (MIT); Gwangju Institute of Science & Technology
   (GIST)
RP Kim, KJ (corresponding author), GIST, Sch Integrated Technol, 123 Chem Dan Gwa Gi, Ro 61005, Gwangju, South Korea.; Kim, KJ (corresponding author), GIST, Artificial Intelligence Grad Sch, 123 Chem Dan Gwa Gi, Ro 61005, Gwangju, South Korea.
EM dbsh070@gmail.com; skypia0906@gmail.com; shlee0414@gm.gist.ac.kr;
   lssac7778@gm.gist.ac.kr; ecehanakan@gm.gist.ac.kr;
   kevinjeon119@gm.gist.ac.kr; yiyueluo@mit.edu; seungjun@gist.ac.kr;
   wojciech@mit.edu; rus@csail.mit.edu; kjkim@gist.ac.kr
OI Kim, Kyung Joong/0000-0002-7732-0817
FU GIST-MIT Research Collaboration grant - GIST; National Research
   Foundation of Korea (NRF) - Korea government (MSIT) [2021R1A4A1030075];
   Institute of Information and communications Technology Planning and
   Evaluation (IITP) - Korea government (MSIT) [2019-0-01842]
FX This work was supported by the GIST-MIT Research Collaboration grant
   funded by the GIST in 2022. This work was partly supported by the
   National Research Foundation of Korea (NRF) grant funded by the Korea
   government (MSIT) (2021R1A4A1030075) and Institute of Information and
   communications Technology Planning and Evaluation (IITP) grant funded by
   the Korea government (MSIT) (2019-0-01842, Artificial Intelligence
   Graduate School Program (GIST)).
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Avila L, 2014, IEEE COMPUT GRAPH, V34, P103, DOI 10.1109/MCG.2014.103
   Balakrishnan R., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P111, DOI 10.1145/300523.300536
   Bouguila L., 2004, P 6 INT C MULT INT, P77, DOI [10.1145/1027933.1027948, DOI 10.1145/1027933.1027948]
   Bouguila L, 2003, ICAT
   Bruno L, 2017, INT J HUM-COMPUT ST, V105, P1, DOI 10.1016/j.ijhcs.2017.03.006
   Cakmak T., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P1, DOI DOI 10.1145/2614066.2614105
   Carrozzino Marcello., 2014, Proc. ACM Symp. on Virtual Reality Software and Technology, P23, DOI DOI 10.1145/2671015.2671121
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Choi I, 1997, IEEE SYS MAN CYBERN, P4248, DOI 10.1109/ICSMC.1997.637367
   Costantini M, 2014, WIRES COGN SCI, V5, P551, DOI 10.1002/wcs.1309
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Elvitigala DS, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P228, DOI 10.1145/3458709.3458958
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Garrett J. J., 2010, The elements of user experience: user-centered design for the web and beyond
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231, DOI DOI 10.1145/2670473.2670512
   HART S G, 1988, P139
   IJsselsteijn Wijnand A, 2013, The Game Experience Questionnaire
   Imai T, 2001, EXP BRAIN RES, V136, P1, DOI 10.1007/s002210000533
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim W, 2022, VIRTUAL REAL-LONDON, V26, P173, DOI 10.1007/s10055-021-00551-0
   Kim W, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102648
   Lee J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092832
   Luo YY, 2021, PROC CVPR IEEE, P11250, DOI 10.1109/CVPR46437.2021.01110
   Luo YY, 2021, NAT ELECTRON, V4, P193, DOI 10.1038/s41928-021-00558-0
   Ohnishi A, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174938
   Pai YS, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P189, DOI 10.1145/3152832.3152864
   Reinhardt J, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311852
   Roy S, 2013, INT J PHARM SCI RES, V4, P3004, DOI 10.13040/IJPSR.0975-8232.4(8).3004-12
   Sato T, 2021, GAMES HEALTH J, V10, P158, DOI 10.1089/g4h.2020.0180
   Schmitz A, 2009, J ELECTROMYOGR KINES, V19, P1085, DOI 10.1016/j.jelekin.2008.10.008
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Slater M., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P45
   Springer J, 1996, INT J IND ERGONOM, V17, P135, DOI 10.1016/0169-8141(95)00045-3
   Srinivasan Prashant., 2005, Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology, ACE '05, P278, DOI DOI 10.1145/1178477.1178526
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tipper SP, 2001, EXP BRAIN RES, V139, P160, DOI 10.1007/s002210100743
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Velloso E, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2816455
   von Willich J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376626
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Williams Betsy., 2013, Proc. ACM Symp. on Applied Perception, P67
   Wilson PrestonTunnell., 2014, P 13 ACM SIGGRAPH IN, P27, DOI DOI 10.1145/2670473.2670492
   Zhang ZX, 2020, NPJ FLEX ELECTRON, V4, DOI 10.1038/s41528-020-00092-7
   Zhao MM, 2018, PROC CVPR IEEE, P7356, DOI 10.1109/CVPR.2018.00768
NR 45
TC 1
Z9 1
U1 5
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1431
EP 1445
DI 10.1007/s10055-023-00750-x
EA JAN 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000914718900002
DA 2024-07-18
ER

PT J
AU Moll, B
   Sykes, E
AF Moll, Brigham
   Sykes, Ed
TI Optimized virtual reality-based <i>Method of Loci</i> memorization
   techniques through increased immersion and effective memory palace
   designs: a feasibility study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Memory; Method of loci; Psychology; Cognitive science;
   Improving memory recall; Memorization
ID ENVIRONMENTS; VARIANCE; ADULTS
AB For most, an improvement in memory would always be desirable, whether from the point of view of an aging individual with declining memory, or from the perspective of someone seeking to memorize large amounts of information in the shortest period of time. One way for people to improve upon their memory performance is by using the Method of Loci (MoL), a famously complex, ancient memorization technique for non-spatial information recall. With the use of virtual reality technology, this technique can finally be easily taught to individuals for use in their daily lives. In this paper, we present an exploration into this avenue of using MoL in virtual reality and report on the design and evaluation of our new virtual memory palace that aims to prove the feasibility of improving upon designs from other studies to optimize memory recall performance. An experiment was conducted to evaluate our VR MoL environment. The results from week 1 on the pre-test (M = 62.55, SD = 24.01) and post-test (M = 82.91, SD = 15.99) memory task showed an increase in the number of words remembered was statistically significant, t(20) = -2.34, p = 0.014 where participants were able to remember approximately 20.4% more non-spatial information, when compared to traditional memorization techniques. After a second use, participants improved, remembering 22.2% more non-spatial information on the pre-test (M = 63.44, SD = 26.64) and post-test (M = 85.67, SD = 16.10) memory task, indicating that the increase in number of words remembered was statistically significant, t(16) = -2.142, p = 0.024. The results suggest that the virtual memory palace experience could be optimized to help participants learn the MoL technique with very little training time and potentially produce significant improvements in recall performance as a result.
C1 [Moll, Brigham; Sykes, Ed] Sheridan Coll, 1430 Trafalgar Rd, Oakville, ON, Canada.
RP Sykes, E (corresponding author), Sheridan Coll, 1430 Trafalgar Rd, Oakville, ON, Canada.
EM brighammoll@hotmail.com; ed.sykes@sheridancollege.ca
OI Sykes, Dr. Edward R/0000-0001-7339-7481
CR Bartlett MS, 1937, PROC R SOC LON SER-A, V160, P0268, DOI 10.1098/rspa.1937.0109
   Bhandari I, 2019, THESIS U DHAKA
   Caplan JB, 2019, Q J EXP PSYCHOL, V72, P2541, DOI 10.1177/1747021819858041
   Lecavalier NC, 2020, NEUROPSYCHOL REHABIL, V30, P462, DOI 10.1080/09602011.2018.1477684
   Dalgleish T, 2013, CLIN PSYCHOL SCI, V1, P156, DOI 10.1177/2167702612468111
   Darken R.P., 1993, Proceedings of ACM User Interface Software and Technology, P157, DOI [10.1145/168642.168658, DOI 10.1145/168642.168658]
   Fettke P, 2019, AMCIS 2019 P
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   Huttner J-P, 2019, AIS E LIB RES PAPERS, V05
   Huttner JP, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P83
   Huttner JP, 2017, AMCIS 2017 PROCEEDINGS
   Huttner JP, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P274
   Ijaz K, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/13887
   Jund T, 2016, IEEE INT CONF ADV LE, P533, DOI 10.1109/ICALT.2016.77
   Kong GQ, 2017, CONSCIOUS COGN, V52, P115, DOI 10.1016/j.concog.2017.04.018
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Legge ELG, 2012, ACTA PSYCHOL, V141, P380, DOI 10.1016/j.actpsy.2012.09.002
   Liu AC, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1046, DOI [10.1109/vr.2019.8797836, 10.1109/VR.2019.8797836]
   Madan CR, 2010, J MEM LANG, V63, P46, DOI 10.1016/j.jml.2010.03.001
   Manivannan S, 2019, J HEAD TRAUMA REHAB, V34, pE52, DOI 10.1097/HTR.0000000000000412
   McCabe JA, 2015, TEACH PSYCHOL, V42, P169, DOI 10.1177/0098628315573143
   Montana JI, 2019, J CLIN MED, V8, DOI 10.3390/jcm8101516
   OGrady T, 2019, HCI INT 2019 POSTERS, P414
   Optale G, 2010, NEUROREHAB NEURAL RE, V24, P348, DOI 10.1177/1545968309353328
   Peeters A, 2019, CONSCIOUS COGN, V76, DOI 10.1016/j.concog.2019.102834
   Perera RM, 2019, UWU EREPOSITORY
   Putnam A. L., 2015, TRANSLATIONAL ISSUES, V1, P130, DOI [DOI 10.1037/TPS0000023, 10.1037/tps0000023]
   Reggente N, 2020, J COGN ENHANCE, V4, P12, DOI 10.1007/s41465-019-00141-8
   ROSS J, 1968, PSYCHON SCI, V13, P107, DOI 10.3758/BF03342433
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sayma M, 2020, GERONTOLOGIST, V60, pE502, DOI 10.1093/geront/gnz132
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Shephard RN, 2018, MENTAL ROTATION TASK
   Steiger JH, 2004, PSYCHOL METHODS, V9, P164, DOI 10.1037/1082-989X.9.2.164
   Verhaeghen P, 1996, PSYCHOL AGING, V11, P164, DOI 10.1037/0882-7974.11.1.164
   Vindenes J, 2018, LECT NOTES COMPUT SC, V10850, P205, DOI 10.1007/978-3-319-95270-3_16
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Wiederhold BK, 2019, CYBERPSYCH BEH SOC N, V22, P3, DOI 10.1089/cyber.2018.29136.bkw
   Yates FrancesAmelia., 1999, ART MEMORY
NR 39
TC 4
Z9 4
U1 4
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 941
EP 966
DI 10.1007/s10055-022-00700-z
EA OCT 2022
PG 26
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000864575700001
PM 36248722
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Fantin, L
   Ceyte, G
   Maïni, E
   Hossu, G
   Ceyte, H
AF Fantin, Luca
   Ceyte, Gwenaelle
   Maini, Elodie
   Hossu, Gabriela
   Ceyte, Hadrien
TI Do individual constraints induce flexibility of visual field dependence
   following a virtual immersion? Effects of perceptive style and
   cybersickness
SO VIRTUAL REALITY
LA English
DT Article
DE Field dependence; Perceptive style; Virtual reality; Cybersickness;
   Virtual immersion; Visual cues
ID POSTURAL CONTROL; COGNITIVE-STYLE; SENSE
AB Accurately perceiving the gravitational direction is key to successful interaction in our terrestrial environment. In this context field dependence (FD), the importance given to static and/or dynamic visual cues has largely been discussed. Although first considered a trait, several studies suggest FD be flexible in response to postural or visual contexts and to poor virtual reality user experience. The aim of this study was therefore to determine the influence of a disruptive virtual immersion on the level of static and dynamic FD. Forty-five participants were exposed to a virtual maritime environment for up to 14 min. Cybersickness and sense of presence were measured. Before and after virtual immersion, the rod and frame test and the rod and disk test were performed to assess static and dynamic FD, respectively. We demonstrated a significant decrease in both levels of FD after immersion in initially more dependent participants. Decrease in static FD was explained by high initial static FD and severe cybersickness, while decrease in dynamic FD was only explained by the initial level of dynamic FD. In this study, we provide evidence confirming FD flexibility, likely reflecting an adaptation process to environmental or individual-related constraints. Yet, static and dynamic FD seems to rely on separate mechanisms, highlighting the necessity to specify which characteristic of visual information (static or dynamic) individuals depend on when assessing their FD. Our results question the reliability of virtual reality for perceptive or motor diagnoses without considering its consequences, specifically in vulnerable populations such as the elderly.
C1 [Fantin, Luca; Maini, Elodie; Ceyte, Hadrien] Univ Lorraine, DevAH, Nancy, France.
   [Fantin, Luca; Hossu, Gabriela] Univ Lorraine, IADI, INSERM, Nancy, France.
   [Ceyte, Gwenaelle; Ceyte, Hadrien] Aix Marseille Univ, ISM, CNRS, Marseille, France.
   [Ceyte, Gwenaelle] Univ Paris Cite, Inst Sci Sport Sante Paris, Paris, France.
   [Hossu, Gabriela] Univ Lorraine, INSERM, CHRU Nancy, CIC 1433 Innovation Technol, Nancy, France.
   [Ceyte, Hadrien] Aix Marseille Univ, Inst Sci Mouvement, UMR 7287 CNRS, 163 Ave Luminy Case 910, F-13009 Marseille, France.
C3 Universite de Lorraine; Institut National de la Sante et de la Recherche
   Medicale (Inserm); Universite de Lorraine; Aix-Marseille Universite;
   Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite; Institut National de la Sante et de la Recherche Medicale
   (Inserm); Universite de Lorraine; CHU de Nancy; Aix-Marseille
   Universite; Centre National de la Recherche Scientifique (CNRS); CNRS -
   National Institute for Biology (INSB)
RP Ceyte, H (corresponding author), Univ Lorraine, DevAH, Nancy, France.; Ceyte, H (corresponding author), Aix Marseille Univ, ISM, CNRS, Marseille, France.; Ceyte, H (corresponding author), Aix Marseille Univ, Inst Sci Mouvement, UMR 7287 CNRS, 163 Ave Luminy Case 910, F-13009 Marseille, France.
EM hadrien.ceyte@univ-amu.fr
RI CEYTE, Hadrien/HGD-8921-2022; Hossu, Gabriela/ABG-2470-2021
OI CEYTE, Hadrien/0000-0003-1746-5026; Hossu, Gabriela/0000-0003-1178-9097;
   Ceyte, Gwenaelle/0000-0003-3196-3742; Fantin, Luca/0000-0003-4359-012X
CR [Anonymous], 1990, PRATIQUES SPORTIVES
   BARRETT GV, 1968, J APPL PSYCHOL, V52, P304, DOI 10.1037/h0026013
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Bray A, 2004, CURR BIOL, V14, pR609, DOI 10.1016/j.cub.2004.07.040
   Brenet F., 1988, B PSYCHOL, V388, P22
   Bringoux L, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00181
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   DICHGANS J, 1972, SCIENCE, V178, P1217, DOI 10.1126/science.178.4066.1217
   Dichgans Johannes, 1978, Perception, P755, DOI [DOI 10.1007/978-3-642-46354-9253F, DOI 10.1007/978-3-642-46354-9_25, DOI 10.1007/978-3-642-46354-925]
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Guerraz M, 1998, PERCEPT PSYCHOPHYS, V60, P287, DOI 10.3758/BF03206037
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   Isableu B, 1997, EXP BRAIN RES, V114, P584, DOI 10.1007/PL00005667
   Isableu B, 2010, NEUROSCIENCE, V169, P1199, DOI 10.1016/j.neuroscience.2010.05.072
   Isableu B, 1998, HUM MOVEMENT SCI, V17, P367, DOI 10.1016/S0167-9457(98)00005-0
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Mahboobin A, 2005, EXP BRAIN RES, V167, P260, DOI 10.1007/s00221-005-0053-7
   Maneuvrier A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.706712
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Messick S., 1976, Individuality in learning
   Niehof N, 2019, J NEUROPHYSIOL, V122, P480, DOI 10.1152/jn.00740.2018
   OHLMANN T, 1991, FIELD DEPENDENCE-INDEPENDENCE, P105
   Ohlmann T, 1988, PERCEPTION VERTICALE
   Pavlou M, 2011, GAIT POSTURE, V33, P113, DOI 10.1016/j.gaitpost.2010.10.085
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reuchlin M., 1978, J PSYCHOL, V2, P133
   Robillard G., 2002, P 25IEME CONGRES SOC
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Tinajero C, 1998, EUR J PSYCHOL EDUC, V13, P227, DOI 10.1007/BF03173091
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   VALLERAND RJ, 1989, CAN PSYCHOL, V30, P662, DOI 10.1037/h0079856
   Weech S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00010
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   WITKIN HA, 1967, J PERS SOC PSYCHOL, V7, P291, DOI 10.1037/h0025070
   WITKIN HA, 1948, J EXP PSYCHOL, V38, P762, DOI 10.1037/h0053671
NR 41
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 917
EP 928
DI 10.1007/s10055-022-00703-w
EA OCT 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000865204300001
DA 2024-07-18
ER

PT J
AU Weerasinghe, M
   Pucihar, KC
   Ducasse, J
   Quigley, A
   Toniolo, A
   Miguel, A
   Caluya, N
   Kljun, M
AF Weerasinghe, Maheshya
   Pucihar, Klen Copic
   Ducasse, Julie
   Quigley, Aaron
   Toniolo, Alice
   Miguel, Angela
   Caluya, Nicko
   Kljun, Matjaz
TI Exploring the future building: representational effects on projecting
   oneself into the future office space
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive VR environments; User engagement; Sense of presence; User
   experience; Job relocation
ID VIRTUAL-REALITY; ENVIRONMENTS; EXPERIENCE; NAVIGATION; EMOTION; DESIGN;
   SENSE; ENGAGEMENT; RELOCATION; EVOLUTION
AB While virtual reality (VR) has been explored in the field of architecture, its implications on people who experience their future office space in such a way has not been extensively studied. In this explorative study, we are interested in how VR and other representation methods support users in projecting themselves into their future office space and how this might influence their willingness to relocate. In order to compare VR with other representations, we used (i) standard paper based floor plans and renders of the future building (as used by architects to present their creations to stakeholders), (ii) a highly-detailed virtual environment of the same building experienced on a computer monitor (desktop condition), and (iii) the same environment experienced on a head mounted display (VR condition). Participants were randomly assigned to conditions and were instructed to freely explore their representation method for up to 15 min without any restrictions or tasks given. The results show, that compared to other representation methods, VR significantly differed for the sense of presence, user experience and engagement, and that these measures are correlated for this condition only. In virtual environments, users were observed looking at the views through the windows, spent time on terraces between trees, explored the surroundings, and even "took a walk" to work. Nevertheless, the results show that representation method influences the exploration of the future building as users in VR spent significantly more time exploring the environment, and provided more positive comments about the building compared to users in either desktop or paper conditions. We show that VR representation used in our explorative study increased users' capability to imagine future scenarios involving their future office spaces, better supported them in projecting themselves into these spaces, and positively affected their attitude towards relocating.
C1 [Weerasinghe, Maheshya; Pucihar, Klen Copic; Ducasse, Julie; Kljun, Matjaz] Univ Primorska, FAMNIT, Koper, Slovenia.
   [Weerasinghe, Maheshya; Toniolo, Alice; Miguel, Angela] Univ St Andrews, Sch Comp Sci, St Andrews, Fife, Scotland.
   [Pucihar, Klen Copic; Kljun, Matjaz] Fac Informat Studies, Novo Mesto, Slovenia.
   [Quigley, Aaron] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
   [Caluya, Nicko] Nara Inst Sci & Technol, Interact Media Design Lab, Nara, Japan.
C3 University of Primorska; University of St Andrews; University of New
   South Wales Sydney; Nara Institute of Science & Technology
RP Weerasinghe, M (corresponding author), Univ Primorska, FAMNIT, Koper, Slovenia.; Weerasinghe, M (corresponding author), Univ St Andrews, Sch Comp Sci, St Andrews, Fife, Scotland.
EM amw31@st-andrews.ac.uk
RI Kljun, Matjaž/G-6415-2015; Quigley, Aaron/JHS-5032-2023
OI Quigley, Aaron/0000-0002-5274-6889; Weerasinghe,
   Maheshya/0000-0003-2691-601X; Caluya, Nicko/0000-0003-4924-958X
FU European Commission [739574]; Republic of Slovenia; Republic of Slovenia
   (European Union of the European Regional Development Fund); Slovenian
   research agency ARRS [P1-0383, J1-9186, J1-1715, J5-1796, J1-1692,
   IO-0035]
FX The authors acknowledge the European Commission for funding the
   InnoRenew CoE project (Grant Agreement 739574) under the Horizon2020
   Widespread-Teaming program and the Republic of Slovenia (Investment
   funding of the Republic of Slovenia and European Union of the European
   Regional Development Fund). We also acknowledge support from the
   Slovenian research agency ARRS (program no. P1-0383, J1-9186, J1-1715,
   J5-1796, J1-1692, and IO-0035).
CR Acock Malcolm., 1985, DAVID MARR MODERN SC, V62, P141, DOI [10.5840/schoolman198562219, DOI 10.5840/SCHOOLMAN198562219]
   Andresen M, 2015, J MANAGE PSYCHOL, V30, P234, DOI 10.1108/JMP-11-2012-0362
   [Anonymous], 2013, EMPLOYEE ENGAGEMENT
   Appleton JJ, 2008, PSYCHOL SCHOOLS, V45, P369, DOI 10.1002/pits.20303
   Aries MBC, 2010, J ENVIRON PSYCHOL, V30, P533, DOI 10.1016/j.jenvp.2009.12.004
   Azhar S., 2011, LEADERSHIP MANAGEMEN, V11, P241, DOI [10.1061/(ASCE)LM.1943-5630.0000127, DOI 10.1061/(ASCE)LM.1943-5630.0000127]
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   BARFIELD W, 1993, ADV HUM FACT ERGON, V19, P699
   Bassanino M, 2010, IEEE INT CONF INF VI, P585, DOI 10.1109/IV.2010.85
   Benyon D, 2014, AI SOC, V29, P521, DOI 10.1007/s00146-013-0493-8
   Berg LP, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4034267
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Bertol D., 1996, Designing digital space: An architect's guide to virtual reality
   Birenboim A, 2019, LANDSCAPE URBAN PLAN, V189, P129, DOI 10.1016/j.landurbplan.2019.04.011
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Boyer P, 2008, TRENDS COGN SCI, V12, P219, DOI 10.1016/j.tics.2008.03.003
   Brade J, 2017, INT J HUM-COMPUT ST, V101, P76, DOI 10.1016/j.ijhcs.2017.01.004
   Brown GP, 2002, ANXIETY STRESS COPIN, V15, P1, DOI 10.1080/10615800290007254
   Cartillier V, 2021, AAAI CONF ARTIF INTE, V35, P964
   Castronovo F., 2013, P 13 INT C CONSTR AP, V47
   Cebeci B, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1893
   Chandrasegaran SK, 2013, COMPUT AIDED DESIGN, V45, P204, DOI 10.1016/j.cad.2012.08.006
   Cho BH, 2002, P IEEE VIRT REAL ANN, P156, DOI 10.1109/VR.2002.996518
   Cohen J., 1988, STAT POWER ANAL BEHA
   Delgado JMD, 2020, ADV ENG INFORM, V45, DOI 10.1016/j.aei.2020.101122
   Dodge Y., 2008, The Concise Encyclopedia of Statistics, P288, DOI [DOI 10.1007/978-0-387-32833-1_216, 10.1007/978-0-387-32833-1_216]
   Du J, 2018, AUTOMAT CONSTR, V85, P51, DOI 10.1016/j.autcon.2017.10.009
   Dunston PS, 2011, INTEL SYST CONTR AUT, V48, P167, DOI 10.1007/978-94-007-0605-7_15
   Eby LT, 2000, J VOCAT BEHAV, V57, P42, DOI 10.1006/jvbe.1999.1724
   Ergan S, 2019, J COMPUT CIVIL ENG, V33, DOI 10.1061/(ASCE)CP.1943-5487.0000812
   Evaggelia Amprasi, 2022, INT J INSTR, V15, P1
   Faas D, 2014, AI EDAM, V28, P139, DOI 10.1017/S0890060414000055
   Farnsworth B., 2019, Imotions
   Fernando T, 2013, J INF TECHNOL CONSTR, V18, P372
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P589, DOI 10.1109/TITB.2010.2041553
   Fredricks J., 2011, Measuring student engagement in upper elementary through high school: A description of 21 instruments
   Fröst P, 2000, IEEE INFOR VIS, P568, DOI 10.1109/IV.2000.859814
   Gifford Robert., 2007, ENV PSYCHOL PRINC PR
   Hassenzahl M., 2000, Synth. Lectures Hum.-Centered Inform., V3, P1, DOI [https://doi.org/10.2200/S00261ED1V01Y201003HCI008, DOI 10.2200/S00261-D1V01Y201003HCI008, DOI 10.2200/S00261ED1V01Y201003HCI008, 10.2200/S00261ED1V01Y201003HCI008]
   HEDGE A, 1989, ENVIRON INT, V15, P143, DOI 10.1016/0160-4120(89)90020-2
   Heydarian A, 2014, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2014), P729
   Hölscher C, 2006, J ENVIRON PSYCHOL, V26, P284, DOI 10.1016/j.jenvp.2006.09.002
   Horvat Nikola, 2019, P DES SOC INT C ENG, V1, P1923, DOI 10.1017/dsi.2019.198
   iMotions, Facial expression analysis: Decode emotional expressionsas they happen
   ISO, 2018, ISO 19650 1 2018
   ISO, 9241210 ISO
   Jaeger B. K., 2001, P HUM FACT ERG SOC A, P1896, DOI DOI 10.1177/154193120104502709
   Juan YK, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8060952
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kapoor A, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P195
   Katsis CD, 2008, IEEE T SYST MAN CY A, V38, P502, DOI 10.1109/TSMCA.2008.918624
   Kearsley G., 1998, Educational Technology, V38, P20
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kini VG, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364719
   Klein SB, 2013, WIRES COGN SCI, V4, P63, DOI 10.1002/wcs.1210
   Koelstra Reinder AL, 2012, AFFECTIVE IMPLICIT T
   Krukar J, 2016, HUMAN COMPU, P17, DOI 10.1007/978-3-319-30028-3_2
   Kuliga Saskia, 2020, Spatial Cognition XII. 12th International Conference, Spatial Cognition 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12162), P126, DOI 10.1007/978-3-030-57983-8_11
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Kuller R, 1996, ENVIRON INT, V22, P33, DOI 10.1016/0160-4120(95)00101-8
   Kunert A, 2020, IEEE T VIS COMPUT GR, V26, P3271, DOI 10.1109/TVCG.2019.2914677
   Kuo HC, 2016, CYBERPSYCH BEH SOC N, V19, P80, DOI 10.1089/cyber.2015.0203
   Law Effie Lai-Chong, 2007, P HCI 2007 21 BRIT H, P1, DOI DOI 10.14236/EWIC/HCI2007.95
   Leon M., 2014, Procedia Environmental Sciences, V22, P108, DOI [10.1016/j.proenv.2014.11.011, DOI 10.1016/J.PROENV.2014.11.011]
   Llorach G, 2014, P ACM S VIRT REAL SO, P137
   LUO LU, 1990, WORK STRESS, V4, P121, DOI 10.1080/02678379008256974
   Majumdar T., 2006, Joint International Conference on Computing and Decision Making in Civil and Building Engineering, P2902, DOI DOI 10.1007/11888598_1
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Marc Busch, 2014, P 8 NORD C HUM COMP, P117, DOI [10.1145/2639189.2639224, DOI 10.1145/2639189.2639224]
   Marlene Weber, 2018, AUTOMOTIVE EMOTIONS
   Martin R, 1999, J OCCUP ORGAN PSYCH, V72, P231, DOI 10.1348/096317999166626
   Martin R, 2000, WORK STRESS, V14, P347, DOI 10.1080/02678370010029186
   Martin Schrepp, 2019, UEQ USER EXPERIENCE
   McDuff D., 2016, P CHI C HUM FACT COM, P3723
   Moghimi M, 2016, PRESENCE-VIRTUAL AUG, V25, P81, DOI 10.1162/PRES_a_00249
   Murugappan M, 2008, IFMBE PROC, V21, P262
   NBS, 2016, WHAT IS BUILD INF MO
   Neuhauser M., 2011, International Encyclopedia of Statistical Science, DOI DOI 10.1007/978-3-642-04898-2615
   Oriane Chevi, 2018, ROLE CHALLENGES HR D
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Parong J, 2021, J COMPUT ASSIST LEAR, V37, P226, DOI 10.1111/jcal.12482
   Pashler H.E., 1999, PSYCHOL ATTENTION
   Pierce Matthew B., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2082, DOI 10.1177/1541931213602003
   PLACKETT RL, 1983, INT STAT REV, V51, P59, DOI 10.2307/1402731
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Regenbrecht HT, 1998, INT J HUM-COMPUT INT, V10, P233, DOI 10.1207/s15327590ijhc1003_2
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Sagie A, 2001, J OCCUP ORGAN PSYCH, V74, P343, DOI 10.1348/096317901167398
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sanorita Dey, 2014, HCI CONSORTIUM, P1
   Schacter DL, 2012, NEURON, V76, P677, DOI 10.1016/j.neuron.2012.11.001
   Schnabel M.A., 2003, Int. J. Archit. Comput, V1, P435, DOI DOI 10.1260/147807703773633455
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sharot T, 2011, CURR BIOL, V21, pR941, DOI 10.1016/j.cub.2011.10.030
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Snopková D, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8060251
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suddendorf T, 2007, BEHAV BRAIN SCI, V30, P299, DOI 10.1017/S0140525X07001975
   Sullivan L., 2016, InterQuartile Range (IQR)
   Szpunar KK, 2010, PERSPECT PSYCHOL SCI, V5, P142, DOI 10.1177/1745691610362350
   Takahashi K, 2003, IEEE SYS MAN CYBERN, P1654
   Topu FB, 2019, COMPUT HUM BEHAV, V92, P1, DOI 10.1016/j.chb.2018.10.022
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Esch E, 2019, J ENVIRON PSYCHOL, V64, P56, DOI 10.1016/j.jenvp.2019.05.006
   Violante MG, 2019, INT J INTERACT DES M, V13, P243, DOI 10.1007/s12008-018-00528-5
   Weber M, 2019, TRANSPORT RES F-TRAF, V65, P107, DOI 10.1016/j.trf.2019.06.001
   Westerdahl B, 2006, AUTOMAT CONSTR, V15, P150, DOI 10.1016/j.autcon.2005.02.010
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wong IL, 2017, RENEW SUST ENERG REV, V74, P959, DOI 10.1016/j.rser.2017.03.061
   Xie H., 2006, Development of a virtual reality safety-training system for construction workers, P1
   Yazdani J.-S. Lee., 2009, Proc. SIGMM Workshop on Social media, P81
   Yildirim K, 2007, J ENVIRON PSYCHOL, V27, P154, DOI 10.1016/j.jenvp.2007.01.004
   Yung R, 2019, CURR ISSUES TOUR, V22, P2056, DOI 10.1080/13683500.2017.1417359
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zhang M., 2020, Digital Twin Driven Smart Design, P3
   Zhao JY, 2020, SPAT COGN COMPUT, V20, P328, DOI 10.1080/13875868.2020.1817925
   Zhao JY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P893, DOI [10.1109/VR46266.2020.00114, 10.1109/VR46266.2020.1581091793502]
NR 125
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 51
EP 70
DI 10.1007/s10055-022-00673-z
EA JUL 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000828460500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sessoms, PH
   Fraser, JJ
   Bodell, DM
   Haluch, KS
   Markham, AE
   Brookfield, JS
   Jameson, J
   Gottshall, KR
AF Sessoms, Pinata H.
   Fraser, John J.
   Bodell, Dawn M.
   Haluch, Kathrine S.
   Markham, Amanda E.
   Brookfield, Jacob S.
   Jameson, Jason
   Gottshall, Kim R.
TI Clinical effectiveness of virtual reality versus conventional
   clinic-based vestibular physical therapy on balance and function in
   active duty service members. A pilot randomized controlled trial
SO VIRTUAL REALITY
LA English
DT Article
DE Therapeutics; Data display; Craniocerebral trauma; Physical therapy
   modalities; Sensation disorders
ID REHABILITATION; DIZZINESS; PERFORMANCE; DEFICITS; GAIT; INDIVIDUALS;
   CONCUSSION; INJURY
AB Virtual reality (VR) may be useful during rehabilitation of service members with persistent vestibular impairment following concussion. Thirty-eight active duty US military service members with persistent balance impairment resulting from concussion were randomized into three groups [Conventional Vestibular Physical Therapy (CVPT, n = 13), Virtual Reality Vestibular Physical Therapy (VRVPT, n = 12), and Hybrid Virtual Reality and Conventional Vestibular Physical Therapy (HybridVPT, n = 13)] and were treated twice weekly for 6 weeks. Changes in clinical measures such as Activities-specific Balance Confidence (ABC) Scale, Dizziness Handicap Inventory (DHI), Functional Gait Assessment (FGA), and Sensory Organization Test (SOT) were assessed from pre-, mid-, and post-treatment scores. A significant main time effect was observed demonstrating clinical improvement over time (ABC: p < .001, eta(2)(p) = .54; DHI: p < .001, eta(2)(p) = .57; FGA: p < .001, eta(2)(p) = .74; SOT: p < .001, eta(2)(p) = .35). Both CVPT and HybridVPT groups demonstrated significant improvements in patient-reported confidence and function earlier in the treatment course (p < .005). FGA significantly and incrementally improved at each assessment time point in all treatment groups. The SOT significantly improved early in treatment in the CVPT group only and pre-to-post-treatment in the CVPT and VRVPT groups only. The HybridVPT group did not demonstrate any significant improvement with time in the instrumented SOT measure. In the comparison of pre-to-post-effects of VRVPT and HybridVPT effects compared to CVPT, there was no clear superiority or inferiority observed in either of the experimental treatments. This preliminary work shows initial efficacy of using VR-based therapy for concussed individuals allowing future work to personalize treatment that may improve adherence and engagement to therapy.
C1 [Sessoms, Pinata H.; Fraser, John J.; Bodell, Dawn M.; Haluch, Kathrine S.; Markham, Amanda E.; Brookfield, Jacob S.; Jameson, Jason] Naval Hlth Res Ctr, Warfighter Performance Dept, 140 Sylvester Rd, San Diego, CA 92106 USA.
   [Fraser, John J.; Bodell, Dawn M.] Navy Med Readiness & Training Command, Phys Therapy Dept, 34800 Bob Wilson Dr, San Diego, CA 92134 USA.
   [Bodell, Dawn M.; Markham, Amanda E.; Brookfield, Jacob S.; Jameson, Jason; Gottshall, Kim R.] Leidos Inc, 4161 Campus Point Court, San Diego, CA 92121 USA.
   [Gottshall, Kim R.] Florida Ear & Balance Ctr, 410 Celebration Pl, Kissimmee, FL 34747 USA.
   [Haluch, Kathrine S.] Eagle Appl Sci, 1826 N Loop 1604 E 350, San Antonio, TX 78248 USA.
C3 United States Department of Defense; United States Navy; Naval Medical
   Research Center (NMRC); Naval Health Research Center (NHRC)
RP Sessoms, PH (corresponding author), Naval Hlth Res Ctr, Warfighter Performance Dept, 140 Sylvester Rd, San Diego, CA 92106 USA.
EM Pinata.H.Sessoms.civ@mail.mil
RI Fraser, John J/H-6714-2016
OI Fraser, John J/0000-0001-9697-3795; Brookfield,
   Jacob/0000-0003-2597-6408
FU U.S. Navy Bureau of Medicine and Surgery's Wounded, Ill, and Injured
   Program [60818, N1703]
FX The authors are military members and employees of the U.S. Government.
   This work was prepared as part of their official duties. Title 17,
   U.S.C. 105 provides that copyright protection under this title is not
   available for any work of the U.S. Government. Title 17, U.S.C. 101
   defines a U.S. Government work as work prepared by a military service
   member or employee of the U.S. Government as part of that person's
   official duties. This work was supported by the U.S. Navy Bureau of
   Medicine and Surgery's Wounded, Ill, and Injured Program under work unit
   no. 60818 and N1703. The views expressed in this article are those of
   the authors and do not necessarily reflect the official policy or
   position of the Department of the Navy, Department of Defense, nor the
   U.S. Government. The study protocol was approved by the Naval Health
   Research Center Institutional Review Board in compliance with all
   applicable Federal regulations governing the protection of human
   subjects. Research data were derived from an approved Naval Health
   Research Center Institutional Review Board protocol number
   NHRC.2011.0027.
CR Alahmari KA, 2014, IEEE T NEUR SYS REH, V22, P389, DOI 10.1109/TNSRE.2013.2294904
   Alsalaheen BA, 2010, J NEUROL PHYS THER, V34, P87, DOI 10.1097/NPT.0b013e3181dde568
   Anderson T., 2006, PRACTICAL NEUROLOGY, V6, P342, DOI [DOI 10.1136/JNNP.2006.106583, 10.1136/jnnp.2006.106583]
   [Anonymous], 2017, R PACKAGE VERSION
   Badke MB, 2005, ANN OTO RHINOL LARYN, V114, P48, DOI 10.1177/000348940511400109
   Basford JR, 2003, ARCH PHYS MED REHAB, V84, P343, DOI 10.1053/apmr.2003.50034
   Bergeron M., 2015, ADV MED, DOI 10.1155/2015/916735
   Cawthorne T., 1944, J. Chart. Soc. Physiother, V3, P106
   CHONG S, 2011, PROCEED SINGAPORE HE
   Covassin T, 2015, CLIN SPORT MED, V34, P199, DOI 10.1016/j.csm.2014.12.004
   Cuthbert JP, 2014, BRAIN INJURY, V28, P181, DOI 10.3109/02699052.2013.860475
   Defense and Veterans Brain Injury Center, 2019, DOD NUMB TRAUM BRAIN
   EFRON B, 1987, J AM STAT ASSOC, V82, P171, DOI 10.2307/2289144
   Gerlanc D., 2015, bootES: Bootstrap Effect Sizes
   Gottshall K, 2003, LARYNGOSCOPE, V113, P1746, DOI 10.1097/00005537-200310000-00016
   Gottshall Kim, 2005, Work, V24, P381
   Gottshall K, 2011, NEUROREHABILITATION, V29, P167, DOI 10.3233/NRE-2011-0691
   Gottshall KR, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00106
   Gottshall KR, 2010, J NEUROL PHYS THER, V34, P94, DOI 10.1097/NPT.0b013e3181dead12
   Hall AM, 2010, PHYS THER, V90, P1099, DOI 10.2522/ptj.20090245
   Haluch K, 2020, FIGSHARE J CONTRIB, DOI 10.6084/m9.figshare.12456683.v1
   Hoffer ME, 2004, OTOL NEUROTOL, V25, P135, DOI 10.1097/00129492-200403000-00009
   Hoffer ME, 2003, OTOL NEUROTOL, V24, P633, DOI 10.1097/00129492-200307000-00017
   HORAK FB, 1992, OTOLARYNG HEAD NECK, V106, P175, DOI 10.1177/019459989210600220
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Kassambara A., 2021, RSTATIX PIPE FRIENDL
   Lajoie Y, 2004, ARCH GERONTOL GERIAT, V38, P11, DOI 10.1016/S0167-4943(03)00082-7
   Lee H, 2013, J SCI MED SPORT, V16, P2, DOI 10.1016/j.jsams.2012.03.013
   Levin MF, 2015, PHYS THER, V95, P415, DOI 10.2522/ptj.20130579
   Newman Craig W., 1993, Seminars in Hearing, V14, P363, DOI 10.1055/s-0028-1085134
   Pape MM, 2020, MIL MED, V185, P428, DOI 10.1093/milmed/usz265
   Pinheiro J, 2021, NLME LINEAR NONLINEA
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   POWELL LE, 1995, J GERONTOL A-BIOL, V50, pM28, DOI 10.1093/gerona/50A.1.M28
   Quatman-Yates CC, 2020, J ORTHOP SPORT PHYS, V50, pCPG1, DOI 10.2519/jospt.2020.0301
   Scherer MR, 2009, PHYS THER, V89, P980, DOI 10.2522/ptj.20080353
   SHEPARD NT, 1993, ANN OTO RHINOL LARYN, V102, P198, DOI 10.1177/000348949310200306
   Teel EF, 2013, J SCI MED SPORT, V16, P190, DOI 10.1016/j.jsams.2012.09.007
   Whitney SL, 2004, OTOL NEUROTOL, V25, P139, DOI 10.1097/00129492-200403000-00010
   Whitney SL, 2006, CYBERPSYCHOL BEHAV, V9, P152, DOI 10.1089/cpb.2006.9.152
   Whitney SL, 2015, CURR OPIN NEUROL, V28, P61, DOI 10.1097/WCO.0000000000000162
   Wrisley DM, 2004, PHYS THER, V84, P906, DOI 10.1093/ptj/84.10.906
NR 42
TC 2
Z9 2
U1 3
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 263
EP 276
DI 10.1007/s10055-021-00546-x
EA JUL 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000679655600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Hoeg, ER
   Bruun-Pedersen, JR
   Cheary, S
   Andersen, LK
   Paisa, R
   Serafin, S
   Lange, B
AF Hoeg, Emil Rosenlund
   Bruun-Pedersen, Jon Ram
   Cheary, Shannon
   Andersen, Lars Koreska
   Paisa, Razvan
   Serafin, Stefania
   Lange, Belinda
TI Buddy biking: a user study on social collaboration in a virtual reality
   exergame for rehabilitation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Social interaction; Physical therapy; Exergaming;
   Motivation; User-centered design; Older adults
ID OLDER-ADULTS; INPATIENT REHABILITATION; INTRINSIC MOTIVATION;
   PHYSICAL-THERAPY; INDUCED SYMPTOMS; STROKE PATIENTS; EXERCISE;
   COMPETITIVENESS; BALANCE; SYSTEM
AB Virtual reality (VR)-based rehabilitation is a growing technological field, which gradually becomes integrated into existing programs. However, technology has to support human behavior and -needs, including social relatedness, to achieve health-related outcomes. Elderly people have high risk of loneliness, and VR has technological affinity for natural social interaction. Previous studies have relied on competitiveness rather than collaborative elements, but research shows that competitiveness can lead to (feelings of) stress and aggressive behavior in some individuals. This article presents a mixed methods study to gather end-user feedback on a social VR scenario that encourages inter-player collaboration on a virtual tandem bike. Outpatients (n = 11, 64% males, 60 +/- 11 years) were invited to participate with a co-player (friend or family). Participants biked on average 10.7 (+/- 3) minutes with a mean speed of 14.8 kmph (+/- 5.8). The results indicate potential and feasibility for the collaborative social biking application. Participants reported excellent usability- scores (85 +/- 5), high intrinsic motivation in all categories: enjoyment (6.5 +/- 0.5), effort/importance (6.4 +/- 0.3), relatedness (6.3 +/- 0.7) and minimal increase in symptoms of nausea, oculomotor and disorientation. Furthermore, participants found the social aspect enjoyable, agreed that collaboration eased tasks and that they lost track of exercise duration. Interpersonal interaction between participants varied, but was mostly positively rated valence, even if the sense of copresence was limited by physical constraints and avatar representation. Most participants expressed that they would use the program again, but future studies should explore how to improve location and appearance of the virtual coactor, as well as implement additional tasks.
C1 [Hoeg, Emil Rosenlund; Bruun-Pedersen, Jon Ram; Andersen, Lars Koreska; Paisa, Razvan; Serafin, Stefania] Aalborg Univ, Dept Architecture Design & Media Technol, Copenhagen, Denmark.
   [Lange, Belinda] Flinders Univ S Australia, Caring Futures Inst, Coll Nursing & Hlth Sci, Adelaide, SA, Australia.
   [Cheary, Shannon] Aged Care & Palliat Care Flinders Med Ctr, Div Rehabil, Adelaide, SA, Australia.
C3 Aalborg University; Flinders University South Australia
RP Hoeg, ER (corresponding author), Aalborg Univ, Dept Architecture Design & Media Technol, Copenhagen, Denmark.
EM erh@create.aau.dk; shannon.cheary@sa.gov.au
RI Lange, Belinda/GPW-9678-2022
OI Paisa, Razvan/0000-0002-3801-3793; Hoeg, Emil
   Rosenlund/0000-0001-9567-4291; Lange, Belinda/0000-0002-2330-2699;
   Cheary, Shannon/0009-0001-3182-8703; Bruun-Pedersen, Jon
   Ram/0000-0001-5710-2014; Bruun-Pedersen, Jon Ram/0000-0002-9477-7253;
   Serafin, Stefania/0000-0001-6971-1132
FU municipality of Frederiksberg in Denmark; Technical Doctoral School of
   IT and Design at Aalborg University
FX The research reported in this publication is part of a PhDstudy
   undertaken by Emil Rosenlund Hoeg, funded by the municipality of
   Frederiksberg in Denmark. PhD travel funds were granted by The Technical
   Doctoral School of IT and Design at Aalborg University. Belinda Lange
   granted additional funding and equipment for the study.
CR Anderson-Hanley C, 2011, CLIN INTERV AGING, V6, P275, DOI 10.2147/CIA.S25337
   [Anonymous], 1924, J ABNORM PSYCHOL SOC, DOI DOI 10.1037/H0067010
   [Anonymous], 2008, P 20 AUSTRALASIAN C, DOI DOI 10.1145/1517744.1517772
   AudioJungle, 2019, SLOW BIK RID GRA ROA
   Bandura A., 1997, SELF EFFICACY EXERCI
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bateni H, 2012, PHYSIOTHERAPY, V98, P211, DOI 10.1016/j.physio.2011.02.004
   BAUMEISTER RF, 1995, PSYCHOL BULL, V117, P497, DOI 10.1037/0033-2909.117.3.497
   Bernhardt J, 2004, STROKE, V35, P1005, DOI 10.1161/01.STR.0000120727.40792.40
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourbeau J, 2008, THORAX, V63, P831, DOI 10.1136/thx.2007.086041
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Bruun-Pedersen J.R., 2018, Journal For Virtual Worlds Research, V9, DOI DOI 10.4101/JVWR.V9I3.7224
   Bruun-Pedersen JR, 2014, 2014 2ND WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2014.6799464
   Burdea GC, 2003, METHOD INFORM MED, V42, P519
   Cacioppo John T, 2014, Evid Based Nurs, V17, P59, DOI 10.1136/eb-2013-101379
   Chen BW, 2015, MOTIV EMOTION, V39, P216, DOI 10.1007/s11031-014-9450-1
   Chen DJ, 2016, ERGONOMICS, V59, P582, DOI 10.1080/00140139.2015.1078501
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   de Bruin ED, 2010, Z GERONTOL GERIATR, V43, P229, DOI 10.1007/s00391-010-0124-7
   DECI EL, 1981, PERS SOC PSYCHOL B, V7, P79, DOI 10.1177/014616728171012
   DECI EL, 1971, J PERS SOC PSYCHOL, V18, P105, DOI 10.1037/h0030644
   Dolgov I, 2014, COMPUT HUM BEHAV, V33, P49, DOI 10.1016/j.chb.2013.12.028
   Edwards AM, 2018, BMJ OPEN SPORT EXERC, V4, DOI 10.1136/bmjsem-2018-000368
   Feltz DL, 2011, J SPORT EXERCISE PSY, V33, P506, DOI 10.1123/jsep.33.4.506
   Fluet Gerard G, 2013, Curr Phys Med Rehabil Rep, V1, P9
   Gajadhar BJ., 2010, P 3 INT C FUN GAM LE, P74, DOI 10.1145/1823818.1823826
   Gajadhar Brian., 2008, Proceeding of the Twentysixth Annual CHI Conference Extended Abstracts on Human Factors in Computing Systems CHI 08, P3099, DOI [10.1145/1358628.1358814, DOI 10.1145/1358628.1358814]
   Gill SD, 2016, INT J REHABIL RES, V39, P84, DOI 10.1097/MRR.0000000000000139
   Gorsic M, 2019, INT C REHAB ROBOT, P648, DOI [10.1109/icorr.2019.8779514, 10.1109/ICORR.2019.8779514]
   Gorsic M, 2019, JMIR SERIOUS GAMES, V7, DOI 10.2196/12788
   Gorsic M, 2017, BIOSYST BIOROBOT, V15, P363, DOI 10.1007/978-3-319-46669-9_61
   Gorsic M, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0231-4
   Gorsic M, 2016, IEEE ENG MED BIO, P4690, DOI 10.1109/EMBC.2016.7591774
   Guerin B., 1993, Social Facilitation, P244, DOI [10.1017/CBO9780511628214, DOI 10.1017/CBO9780511628214]
   Nguyen H, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P3695
   Hamari J, 2015, COMPUT HUM BEHAV, V50, P333, DOI 10.1016/j.chb.2015.04.018
   Hoeg Emil Rosenlund, 2020, Interactivity, Game Creation, Design, Learning, and Innovation. 8th EAI International Conference, ArtsIT 2019, and 4th EAI International Conference, DLI 2019. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 328), P379, DOI 10.1007/978-3-030-53294-9_26
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Huang HC, 2019, GAMES HEALTH J, V8, P220, DOI 10.1089/g4h.2018.0057
   Hummersone C, 2016, IOSR MATLAB TOOLBOX
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kaos MD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300660
   Kappen DL, 2019, INT J HUM-COMPUT INT, V35, P140, DOI 10.1080/10447318.2018.1441253
   Katsigiannis S, 2019, IEEE T CONSUM ELECTR, V65, P119, DOI 10.1109/TCE.2018.2879065
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshner EA, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0552-6
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Larsen LH, 2013, GAMES HEALTH J, V2, P205, DOI 10.1089/g4h.2013.0036
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Levac D, 2012, RES DEV DISABIL, V33, P214, DOI 10.1016/j.ridd.2011.09.007
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Lohse KR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093318
   Mace M, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0319-x
   Maclean N, 2000, BMJ-BRIT MED J, V321, P1051, DOI 10.1136/bmj.321.7268.1051
   Marker AM, 2015, GAMES HEALTH J, V4, P25, DOI 10.1089/g4h.2014.0066
   Maslow A.H., 1981, MOTIVATION PERSONALI
   Mayr U, 2012, PSYCHOL AGING, V27, P278, DOI 10.1037/a0025655
   Meldrum D, 2012, DISABIL REHABIL-ASSI, V7, P205, DOI 10.3109/17483107.2011.616922
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Moreira MC, 2013, DISABIL REHABIL-ASSI, V8, P357, DOI 10.3109/17483107.2012.749428
   Murata A, 2004, INT J HUM-COMPUT INT, V17, P463, DOI 10.1207/s15327590ijhc1704_2
   Nap Henk Herman, 2009, Gerontechnology, V8, P247, DOI 10.4017/gt.2009.08.84.003.00
   Nguyen-Vo T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P415, DOI 10.1109/VR.2018.8446383
   Peiris CL, 2012, J PHYSIOTHER, V58, P261, DOI 10.1016/S1836-9553(12)70128-5
   Pereira F, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0578-9
   Peters D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00797
   Proffitt R, 2015, PHYS THER, V95, P441, DOI 10.2522/ptj.20130571
   Przybylski AK, 2014, J PERS SOC PSYCHOL, V106, P441, DOI 10.1037/a0034820
   Reeve J, 1996, PERS SOC PSYCHOL B, V22, P24, DOI 10.1177/0146167296221003
   Reis E, 2019, PHYS THER REV, V24, P84, DOI 10.1080/10833196.2019.1639012
   Resnick Barbara, 2002, Clin Nurs Res, V11, P52, DOI 10.1177/1054773802011001005
   Rizzo A., 2014, CLIN VIRTUAL REALITY, V2, P1159
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Ballester BR, 2012, PRESENCE-TELEOP VIRT, V21, P490, DOI 10.1162/PRES_a_00129
   Ryan RM, 2020, CONTEMP EDUC PSYCHOL, V61, DOI 10.1016/j.cedpsych.2020.101860
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Salinas GD, 2011, INT J CHRONIC OBSTR, V6, P171, DOI 10.2147/COPD.S16396
   Sanders T., 2010, BCS HCI 2010, p, P160
   Schatzschneider C, 2016, IEEE T VIS COMPUT GR, V22, P1387, DOI 10.1109/TVCG.2016.2518137
   Schroeder SA, 2007, NEW ENGL J MED, V357, P1221, DOI 10.1056/NEJMsa073350
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Skinner BurrhusFrederic., 1965, Science and human behavior. Number, P92904
   Skjæret N, 2016, INT J MED INFORM, V85, P1, DOI 10.1016/j.ijmedinf.2015.10.008
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smeddinck JD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4143, DOI 10.1145/2702123.2702598
   Song H, 2013, COMPUT HUM BEHAV, V29, P1702, DOI 10.1016/j.chb.2013.01.042
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Teixeira PJ, 2012, INT J BEHAV NUTR PHY, V9, DOI 10.1186/1479-5868-9-78
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Triplett N., 1898, American Journal of Psychology, V9, P507, DOI DOI 10.2307/1412188
   UnitedNations DoE SocialAffairs PD, 2019, WORLD POPULATION PRO
   Unity Asset Store, 2018, PUN 2 FREE
   Unity Asset Store, 2017, EASYROADS3D PRO V3
   Unity Asset Store, 2019, LOW POL TAND BIK 01
   Unity Asset Store, ARD BLUET PLLUG
   Unity Asset Store, 2018, BIC GEAR SFX PAC
   Unity Asset Store, 2018, 5 SPORT HELM PACK
   van der Ham IJM, 2019, COMPUT HUM BEHAV, V94, P77, DOI 10.1016/j.chb.2019.01.005
   van Santen J, 2018, J ALZHEIMERS DIS, V63, P741, DOI 10.3233/JAD-170667
   Weber B, 2007, J PERS SOC PSYCHOL, V93, P973, DOI 10.1037/0022-3514.93.6.973
   Whittinghill DavidMatthew., 2015, Games Developers Conference (GDC), page, P74
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
NR 106
TC 14
Z9 14
U1 8
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 245
EP 262
DI 10.1007/s10055-021-00544-z
EA JUL 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000677937500001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Fechter, M
   Schleich, B
   Wartzack, S
AF Fechter, Marius
   Schleich, Benjamin
   Wartzack, Sandro
TI Comparative evaluation of WIMP and immersive natural finger interaction:
   a user study on CAD assembly modeling
SO VIRTUAL REALITY
LA English
DT Article
DE Natural user interface; Computer-aided design; Assembly modeling;
   Virtual reality
ID INTERFACE; DESIGN
AB Virtual and augmented reality allows the utilization of natural user interfaces, such as realistic finger interaction, even for purposes that were previously dominated by the WIMP paradigm. This new form of interaction is particularly suitable for applications involving manipulation tasks in 3D space, such as CAD assembly modeling. The objective of this paper is to evaluate the suitability of natural interaction for CAD assembly modeling in virtual reality. An advantage of the natural interaction compared to the conventional operation by computer mouse would indicate development potential for user interfaces of current CAD applications. Our approach bases on two main elements. Firstly, a novel natural user interface for realistic finger interaction enables the user to interact with virtual objects similar to physical ones. Secondly, an algorithm automatically detects constraints between CAD components based solely on their geometry and spatial location. In order to prove the usability of the natural CAD assembly modeling approach in comparison with the assembly procedure in current WIMP operated CAD software, we present a comparative user study. Results show that the VR method including natural finger interaction significantly outperforms the desktop-based CAD application in terms of efficiency and ease of use.
C1 [Fechter, Marius; Schleich, Benjamin; Wartzack, Sandro] Friedrich Alexander Univ Erlangen Nuremberg, Tech Fac, Inst Engn Design, Martensstr 9, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Fechter, M (corresponding author), Friedrich Alexander Univ Erlangen Nuremberg, Tech Fac, Inst Engn Design, Martensstr 9, D-91058 Erlangen, Germany.
EM marius.fechter@fau.de; schleich@mfk.fau.de; wartzack@mfk.fau.de
OI Wartzack, Sandro/0000-0002-0244-5033; Fechter,
   Marius/0000-0002-8883-221X
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. This research
   did not receive any grant from funding agencies in the public,
   commercial or not-for-profit sectors.
CR Alkemade R, 2017, INT J HUM-COMPUT INT, V33, P882, DOI 10.1080/10447318.2017.1296074
   [Anonymous], 2006, Turkish Journal of Medical Sciences
   Bérard F, 2009, LECT NOTES COMPUT SC, V5727, P400, DOI 10.1007/978-3-642-03658-3_45
   Borst CW, 2006, PRESENCE-VIRTUAL AUG, V15, P47, DOI 10.1162/pres.2006.15.1.47
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cohen J., 1988, STAT POWER ANAL BEHA
   Dankert T, 2013, VIRT ENV REAL 10 WOR
   Fechter, 2017, ASME 2017 INT DES EN, V1
   Hix D., 1993, Developing User Interfaces: Ensuring Usability through Product Process
   Houde S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P135, DOI 10.1145/142750.142772
   Jacobs J., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P43, DOI 10.1109/3DUI.2012.6184183
   Jacobs J, 2011, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2011.5759430
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   Joshi A., 2015, BRIT J APPL SCI TECH, V7, P396, DOI [10.9734/BJAST/2015/14975, DOI 10.9734/BJAST/2015/14975]
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Liu O, 2017, IEEE ROMAN, P751, DOI 10.1109/ROMAN.2017.8172387
   Marcelino L, 2003, COMPUT GRAPH-UK, V27, P19, DOI 10.1016/S0097-8493(02)00228-5
   Mendes D, 2018, COMPUTER GRAPHICS FO
   Mingxian Fa, 1993, Computer Graphics Forum, V12, pC237, DOI 10.1111/1467-8659.1230237
   Moehring M., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments, P181
   Ortega M, 2007, IEEE T VIS COMPUT GR, V13, P458, DOI 10.1109/TVCG.2007.1028
   Pascarelli C, 2018, LECT NOTES COMPUT SC, V10851, P435, DOI 10.1007/978-3-319-95282-6_32
   Periverzov Frol, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P121, DOI 10.1109/3DUI.2015.7131736
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Schultheis U., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P117, DOI 10.1109/3DUI.2012.6184195
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Seth Abhishek., 2007, Combining physical constraints with geometric constraint-based modeling for virtual assembly
   Song J, 2014, COMPUT AIDED DESIGN, V46, P239, DOI 10.1016/j.cad.2013.08.039
   Talvas A, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2013.6550206
   Toma MI, 2012, INT J INTERACT DES M, V6, P179, DOI 10.1007/s12008-012-0144-1
   Ullmann T, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P373, DOI 10.1109/PCCGA.2000.883961
   Valentini PP, 2018, INT J INTERACT DES M, V12, P1157, DOI 10.1007/s12008-018-0461-0
   Valentini PP, 2009, INT J INTERACT DES M, V3, P109, DOI 10.1007/s12008-009-0064-x
   vanDam A, 1997, COMMUN ACM, V40, P63, DOI 10.1145/253671.253708
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Wang ZB, 2013, INT J ADV MANUF TECH, V69, P1311, DOI 10.1007/s00170-013-5091-x
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Yao YX, 2006, INT J ADV MANUF TECH, V30, P959, DOI 10.1007/s00170-005-0069-y
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 39
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 143
EP 158
DI 10.1007/s10055-021-00543-0
EA JUN 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000661757400001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Guzsvinecz, T
   Orbán-Mihálykó, E
   Sik-Lányi, C
   Perge, E
AF Guzsvinecz, Tibor
   Orban-Mihalyko, Eva
   Sik-Lanyi, Cecilia
   Perge, Erika
TI Investigation of spatial ability test completion times in virtual
   reality using a desktop display and the Gear VR
SO VIRTUAL REALITY
LA English
DT Article
DE Cognitive skills; Desktop display; Gear VR; Human-computer interaction;
   Interaction time; Mental rotation; Spatial ability; Virtual reality
ID STUDENTS; DESIGN
AB The interaction time of students who did spatial ability tests in a virtual reality environment is analyzed. The spatial ability test completion times of 240 and 61 students were measured. A desktop display as well as the Gear VR were used by the former group and by the latter one, respectively. Logistic regression analysis was used to investigate the relationship between the probability of correct answers and completion times, while linear regression was used to evaluate effects and interactions of following factors on test completion times: the users' gender and primary hand, test type and device used. The findings were that while the completion times are not significantly affected by the users' primary hand, other factors have significant effects on them: they are decreased by the male gender in itself, while they are increased by solving Mental Rotation Tests or by using the Gear VR. The largest significant increment in interaction time in virtual reality during spatial ability tests is when Mental Rotation Tests are accomplished by males with the Gear VR, while the largest significant decrease in interaction time is when Mental Cutting Tests are completed with a desktop display.
C1 [Guzsvinecz, Tibor; Sik-Lanyi, Cecilia] Univ Pannonia, Dept Elect Engn & Informat Syst, Veszprem, Hungary.
   [Orban-Mihalyko, Eva] Univ Pannonia, Dept Math, Veszprem, Hungary.
   [Perge, Erika] Univ Debrecen, Dept Basic Tech Studies, Debrecen, Hungary.
C3 University of Pannonia; University of Pannonia; University of Debrecen
RP Guzsvinecz, T (corresponding author), Univ Pannonia, Dept Elect Engn & Informat Syst, Veszprem, Hungary.
EM guzsvinecz@virt.uni-pannon.hu; orbane@almos.uni-pannon.hu;
   lanyi@almos.uni-pannon.hu; perge@eng.unideb.hu
RI Perge, Erika/HMD-3116-2023; Guzsvinecz, Tibor/AAK-5708-2021
OI Perge, Erika/0000-0003-1285-1374; Guzsvinecz, Tibor/0000-0003-3273-313X
FU University of Pannonia
FX Open access funding provided by University of Pannonia.
CR Ault Holly K., 2010, Engineering Design Graphics Journal, V74, P12
   Bosnyak A., 2008, ACTA DIDACTICA UNIVE, V8, P1
   Branoff, 1999, P ASEE ANN C EXP, P1
   Brigos M, 2016, WSCG 2016 24 INT C C, P69
   Burdea G. C., 2003, Virtual reality technology
   Chang JSK, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P68, DOI 10.1145/3131277.3132171
   Drettakis G, 2007, PRESENCE-VIRTUAL AUG, V16, P318, DOI 10.1162/pres.16.3.318
   Dunser A., 2006, P 7 ACM SIGCHI NZ CH, P125, DOI 10.1145/1152760.1152776
   Gardner H., 1983, Frames of mind
   GHISELLI EE, 1973, PERS PSYCHOL, V26, P461, DOI 10.1111/j.1744-6570.1973.tb01150.x
   Guzsvinecz T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020526
   Guzsvinecz T, 2019, INT CONF COGN INFO, P363, DOI [10.1109/coginfocom47531.2019.9089919, 10.1109/CogInfoCom47531.2019.9089919]
   Guzsvinecz T, 2020, ACTA POLYTECH HUNG, V17, P35, DOI 10.12700/APH.17.2.2020.2.3
   Hartman N.W., 2006, ACM SIGGRAPH 2006 ED, P46, DOI DOI 10.1145/1179295.1179342
   Heldal I., 2007, INT J VIRTUAL REALIT, V6, P45
   Horváth I, 2016, INT CONF COGN INFO, P359, DOI 10.1109/CogInfoCom.2016.7804576
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1
   Jiang E., 2019, Practicing in Virtual Reality Improves Mental Rotation Ability: Lower Scorers Benefit More
   Kortum P, 2008, MORG KAUF SER INTER, P1, DOI 10.1016/B978-0-12-374017-5.00001-8
   Kovari A, 2018, INT CONF COGN INFO, P233, DOI 10.1109/CogInfoCom.2018.8639879
   Macik M, 2018, ACTA POLYTECH HUNG, V15, P149
   Maier, 1996, Selected Papers from the Annual Conference of Didactics of Mathematics, P63
   McLellan H., 1998, J VISUAL LITERACY, V18, P175, DOI DOI 10.1080/23796529.1998.11674538
   Miller C.L., 1991, ENG DES GRAPHIC J, V55, P5
   Miller C.L., 1992, ENG DES GRAPHIC J, V56, P27
   Molina-Carmona R, 2019, EM ST HIGH EDUC INNO, P171, DOI 10.1108/978-1-78756-555-520181013
   Molina-Carmona R, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041074
   Oman Charles M, 2002, Spat Cogn Comput, V2, P355, DOI 10.1023/A:1015548105563
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rizzo, 1998, P 2 EUR C DIS VIRT R, P213
   Rizzo A.A., 1998, CyberPsychology and Behavior, V1, P113
   Schroeder R, 2006, PRESENCE-VIRTUAL AUG, V15, P655, DOI 10.1162/pres.15.6.655
   Sutcliffe AG, 2019, INT J HUM-COMPUT INT, V35, P168, DOI 10.1080/10447318.2018.1443898
   Takala T.M., 2014, Proceedings of the 2Nd ACM Symposium on Spatial User Interaction, P94, DOI DOI 10.1145/2659766.2659774
   Walpole RE., 2011, PROBABILITY STAT ENG, V9th
   Wilson A., 2019, SEL COMPUT RES PAP, V8, P61
NR 37
TC 10
Z9 11
U1 6
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 601
EP 614
DI 10.1007/s10055-021-00509-2
EA MAR 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000629853500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Remacle, A
   Bouchard, S
   Etienne, AM
   Rivard, MC
   Morsomme, D
AF Remacle, Angelique
   Bouchard, Stephane
   Etienne, Anne-Marie
   Rivard, Marie-Christine
   Morsomme, Dominique
TI A virtual classroom can elicit teachers' speech characteristics:
   evidence from acoustic measurements during in vivo and in virtuo
   lessons, compared to a free speech control situation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Vocal behavior; Lombard speech; Acoustic measurement;
   Speech and language therapy; Teacher training
ID VOICE TRAINING-PROGRAM; ENVIRONMENTS; CONSENSUS; DOSIMETRY; SPEAKING;
   IMPACT; NOISE
AB To achieve pedagogic goals and deal with environmental constraints such as noise when lecturing, teachers adapt their speech production in terms of frequency, intensity, and temporal aspects. The mastery of appropriate vocal skills is key to teachers' speech intelligibility, health, and educational effectiveness. This project tests the relevance of virtual reality (VR) for training teachers' vocal skills by simulating a lesson in a realistic VR environment characterized by adjustable constraints such as background noise and fidgety children. The VR environment depicts an elementary school classroom with 16 pupils aged 9 to 12 years old animated with typical childlike actions. To validate this virtual classroom in terms of speech characteristics, we conducted acoustic analyses on the speech productions of 30 female teachers in three conditions: (1) giving a free speech while facing the experimenter (control), (2) teaching in their usual classroom (in vivo), and (3) teaching the same lesson in a virtual classroom (in virtuo). The background noise in the VR setting was adjusted for each talker so it was similar to the level measured in vivo. Repeated measures ANOVAs showed that teachers significantly increased their voice frequency, intensity, and intonation and made longer pauses while speaking in vivo and in virtuo, compared to the control condition (p < .001). These voice and speech adaptations (partly related to background noise), the strong feeling of presence, and the lack of side effects suggest that the virtual classroom may facilitate voice training and rehabilitation for teachers.
C1 [Remacle, Angelique] Fund Sci Res FRS FNRS, Brussels, Belgium.
   [Remacle, Angelique; Etienne, Anne-Marie; Morsomme, Dominique] Univ Liege, Dept Logopedie, Fac Psychol Logopedie & Sci Educ, Rue Aunaie 30 B38, B-4000 Liege, Belgium.
   [Remacle, Angelique] Univ Libre Bruxelles, Fac Sci Psychol & Educ, Brussels, Belgium.
   [Bouchard, Stephane; Rivard, Marie-Christine] Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Gatineau, PQ, Canada.
   [Bouchard, Stephane] Ctr Sante & Serv Sociaux Outaouais, Gatineau, PQ, Canada.
C3 Fonds de la Recherche Scientifique - FNRS; University of Liege;
   Universite Libre de Bruxelles; University of Quebec; University Quebec
   Outaouais
RP Remacle, A (corresponding author), Fund Sci Res FRS FNRS, Brussels, Belgium.; Remacle, A (corresponding author), Univ Liege, Dept Logopedie, Fac Psychol Logopedie & Sci Educ, Rue Aunaie 30 B38, B-4000 Liege, Belgium.; Remacle, A (corresponding author), Univ Libre Bruxelles, Fac Sci Psychol & Educ, Brussels, Belgium.
EM angelique.remacle@uliege.be
OI Remacle, Angelique/0000-0001-9338-977X; Bouchard,
   Stephane/0000-0002-5995-340X
FU Fund for Scientific Research-FNRS (F.R.S.-FNRS, Brussels, Belgium);
   Canada Research Chairs grant; Commission Mixte Permanente
   Quebec/Wallonie-Bruxelles
FX Angelique Remacle was supported by the Fund for Scientific Research-FNRS
   (F.R.S.-FNRS, Brussels, Belgium). This work was supported by a Canada
   Research Chairs grant awarded to Stephane Bouchard and a grant from the
   Commission Mixte Permanente Quebec/Wallonie-Bruxelles awarded to
   Stephane Bouchard and Anne-Marie Etienne. We thank Amandine Regnier for
   her assistance with data collection; Sysmex Belgium N.V. for providing
   the NL-21 sound level meter used in the study; and Jean-Jacques
   Embrechts, of the Montefiore Institute at the University of Liege, for
   his assistance with the calibration of the noise level in the VR
   environment.
CR Astolfi A, 2015, J ACOUST SOC AM, V137, P565, DOI 10.1121/1.4906259
   Bechet Marion, 2013, MOTS LANGAGES POLITI, V103, P23, DOI DOI 10.4000/MOTS.21460
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Brundage SB, 2015, AM J SPEECH-LANG PAT, V24, P139, DOI 10.1044/2014_AJSLP-14-0087
   Bryant L, 2020, DISABIL REHABIL-ASSI, V15, P365, DOI 10.1080/17483107.2018.1549276
   Cohen D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061402
   El-Yamri M, 2019, IEEE INT CONF ADV LE, P349, DOI 10.1109/ICALT.2019.00108
   Faham M, 2016, J VOICE, V30, DOI 10.1016/j.jvoice.2015.09.009
   Halabi O, 2017, INT J EMERG TECHNOL, V12, P50, DOI 10.3991/ijet.v12i05.6766
   Hazlett DE, 2011, J VOICE, V25, P181, DOI 10.1016/j.jvoice.2009.08.005
   Hincks R., 2004, P FONETIK 2004, P132
   Hunter EJ, 2020, J SPEECH LANG HEAR R, V63, P509, DOI 10.1044/2019_JSLHR-19-00057
   Jacobson BH, 1997, AM J SPEECH-LANG PAT, V6, P66, DOI [DOI 10.1044/1058-0360.0603.66, 10.1044/1058-0360.0603.66]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Kreiman J., 2011, Foundations of Voice Studies, DOI [10.1002/9781444395068, DOI 10.1002/9781444395068]
   Lombard E., 1911, Ann. Maladies Oreille, Larynx, Nez, Pharynx, V37, P101, DOI DOI 10.1145/1168987.1169028
   Manfredi C, 2016, LOGOP PHONIATR VOCO, V41, P49, DOI 10.3109/14015439.2014.970228
   Marshall J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160381
   López JM, 2017, J VOICE, V31, P697, DOI 10.1016/j.jvoice.2017.01.017
   Nanjundeswaran C, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2012.04.008
   Phadke KV, 2019, J VOICE, V33, DOI 10.1016/j.jvoice.2018.03.003
   Pizolato RA, 2013, J VOICE, V27, P603, DOI 10.1016/j.jvoice.2013.04.013
   Rantala LM, 2015, J SPEECH LANG HEAR R, V58, P1397, DOI 10.1044/2015_JSLHR-S-14-0248
   Remacle A, 2014, J SPEECH LANG HEAR R, V57, P406, DOI 10.1044/2013_JSLHR-S-12-0351
   Richter B, 2016, J VOICE, V30, P452, DOI 10.1016/j.jvoice.2015.05.005
   Robillard G., 2002, 25E CONGRES ANNUEL S
   Schiller IS, 2020, J SPEECH LANG HEAR R, V63, P2115, DOI 10.1044/2020_JSLHR-19-00348
   Schiller IS, 2018, J VOICE, V32, P578, DOI 10.1016/j.jvoice.2017.06.020
   Schneider J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163457
   Smiljanic R, 2009, LANG LINGUIST COMPAS, V3, P236, DOI 10.1111/j.1749-818x.2008.00112.x
   Theodoros DG, 2008, J TELEMED TELECARE, V14, P221, DOI 10.1258/jtt.2007.007044
   Timmermans B, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2011.03.001
   Titze IR, 2015, J ACOUST SOC AM, V137, P3005, DOI 10.1121/1.4919349
   Van Houtte E, 2011, J VOICE, V25, P570, DOI 10.1016/j.jvoice.2010.04.008
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Woisard V, 2004, Rev Laryngol Otol Rhinol (Bord), V125, P307
NR 37
TC 15
Z9 15
U1 2
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 935
EP 944
DI 10.1007/s10055-020-00491-1
EA JAN 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000606737500001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lopez-Gordo, MA
   Kohlmorgen, N
   Morillas, C
   Pelayo, F
AF Lopez-Gordo, M. A.
   Kohlmorgen, Nico
   Morillas, C.
   Pelayo, Francisco
TI Performance prediction at single-action level to a first-person shooter
   video game
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Performance; Prediction; Video game; First-person
   shooter
AB Serious games, professional entertainment (e.g. e-sport), or the immersive simulation of critical scenarios by means of virtual reality belong to the scope of the video game industry. With implications in economic (gambling) and professional careers (e-sports), researchers have focused on the high-level analysis of the win/lose chances and on the player's profile (good/bad performers). At the low-level analysis, the prediction of player's performance at single-action level, such as in the case of hits in a first-person shooter (FPS) video game, to the best of our knowledge, has not been undertaken yet. In this study we hypothesize that VR video games, embed enough contextual information to predict performance in an FPS game at single-action level. For this purpose, we developed an FPS video game and a single-shoot level prediction model based on virtual world contextual information. Eighteen students of the University of Granada without previous experience in the game played for 45-50 min and generated 600-1200 events each. Every event, which was composed of twenty-contextual-player-centred components of the virtual scenario, were transmitted on-line to a remote server to perform predictions. Data from fifteen out of eighteen participants were used to train the model prediction model. After training, the model predicted "hit"/"miss" with a mean accuracy of 74.1%. In a broad vision, our results suggest that immersive virtual environments bear enough contextual information for accurate predictions even at single-action level. In a closed-loop design, this finding could be used (e.g. in defence, professional e-sports, etc.) to anticipate participant's actions/decisions before they are taken, and modify the virtual scenario (e.g. abort mission, change environmental conditions) or drive the player (e. g. suggest options, relieve of command, etc.) according to the purpose of the mission.
C1 [Lopez-Gordo, M. A.] Univ Granada, Brain Comp Interface Lab CITIC UGR, Dept Signal Theory Telemat & Commun, Granada, Spain.
   [Kohlmorgen, Nico] Univ Lubeck, Dept Neurol, Social & Affect Neurosci Res Grp, Lubeck, Germany.
   [Morillas, C.; Pelayo, Francisco] Univ Granada, Dept Comp Architecture & Technol, Brain Comp Interface Lab CITIC UGR, Granada, Spain.
C3 University of Granada; University of Lubeck; University of Granada
RP Lopez-Gordo, MA (corresponding author), Univ Granada, Brain Comp Interface Lab CITIC UGR, Dept Signal Theory Telemat & Commun, Granada, Spain.
EM malg@ugr.es; nico.kohlmorgen@neuro.uni-luebeck.de; cmg@ugr.es;
   fpelayo@ugr.es
RI Morillas, Christian/B-1108-2012; Lopez-Gordo, Miguel A./A-6629-2013
OI Morillas, Christian/0000-0002-4084-6241; Lopez-Gordo, Miguel
   A./0000-0002-5470-1764
FU Spanish "Ministerio de Ciencia, Innovacion y Universidades"
   [PGC2018-098813-B-C31]; European Regional Development Funds (ERDF);
   Nicolo Association for the R&D in Neurotechnologies for disability
FX This work was supported by project PGC2018-098813-B-C31 (Spanish
   "Ministerio de Ciencia, Innovacion y Universidades"'), by European
   Regional Development Funds (ERDF) and by the Nicolo Association for the
   R&D in Neurotechnologies for disability.
CR Amin H., 2000, Virtual Reality, V5, P47, DOI 10.1007/BF01418976
   [Anonymous], 2012, RAISING STAKES E SPO
   [Anonymous], 2019, BUSINESS MAGAZINE
   Aryanata GA, 2017, INT J ENG EMERG TECH, V2, P1, DOI DOI 10.24843/IJEET.2017.V02.I01.P05
   Buckley D, 2014, ARXIV14111316
   Buckley D., 2013, COMPUTATIONAL INTELL, P1, DOI [10.4324/9780203107386, DOI 10.1109/CIG.2013.6633655]
   Buckley D, 2016, THESIS
   Cai H, 2012, VIRTUAL REAL-LONDON, V16, P25, DOI 10.1007/s10055-010-0171-9
   Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.1093/biomet/26.4.404
   Demirdjian David., 2005, VIRTUAL REAL-LONDON, V8, P222
   Felbrich B, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P61, DOI 10.1109/AIVR.2018.00016
   Heath G., 2015, MANY NEURONS HIDDEN
   Henning J. L., 2006, SIGARCH COMPUT ARCHI, V34, P1, DOI [DOI 10.1145/1186736.1186737, 10.1145/1186736.1186737]
   Jiang Y, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/186941
   Katona A, 2019, IEEE CONF COMPU INTE
   Liarokapis F, 2018, VIRTUAL REAL-LONDON, V22, P89, DOI 10.1007/s10055-018-0340-9
   Lopez MA, 2007, USE KOHONEN MAPS FEA, P407
   Lopez-Gordo MA, 2015, SIGNAL PROCESS, V117, P165, DOI 10.1016/j.sigpro.2015.05.004
   Lopez-Gordo MA, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500160
   Lopez-Gordo MA, 2012, INT J NEURAL SYST, V22, DOI 10.1142/S0129065712500098
   Mandrekar JN, 2010, J THORAC ONCOL, V5, P1315, DOI 10.1097/JTO.0b013e3181ec173d
   Minguillon J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082504
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Pinheiro A, 2014, ENTERTAIN COMPUT, V5, P347, DOI 10.1016/j.entcom.2014.06.002
   Ron-Angevin R, 2009, TRAINING ISSUE BRAIN, P666
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Sarkar A., 2019, IEEE C GAM
   SATHIABHAMA P, 2017, VIRTUAL REAL
   Velasco-Alvarez F, 2013, BCI BASED NAVIGATION, P404
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yang Y., 2016, REAL TIME ESPORTS MA
   ZHAO JB, 2019, VIRTUAL REAL LO 1130
NR 32
TC 5
Z9 5
U1 0
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 681
EP 693
DI 10.1007/s10055-020-00482-2
EA OCT 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000585692900001
DA 2024-07-18
ER

PT J
AU Xu, PF
   Wu, ZK
   Wang, XC
   Fu, Y
   He, Y
AF Xu, Pengfei
   Wu, Zhongke
   Wang, Xingce
   Fu, Yan
   He, Ying
TI An electromyogram-based tapping gesture model with differentiated
   vibration feedback by low-fidelity actuators
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Haptic feedback; Vibration model;
   Electromyography; Low-fidelity actuators; Mechanical stimulation
ID HAPTIC FEEDBACK; EMG CONTROL; IMPLEMENTATION; PREDICTION; SUMMATION;
   SYSTEM
AB Among other aspects like attention and focus, the effectiveness of actions, such as training in percussion, also relies on the correct gesture and strength of the individual carrying out the activity repetitively to develop proper muscle memory and train motor skills. To make this process economical and efficient, we propose a system that models the feature of direction and strength of a tap and receives the corresponding active haptic feedback in an immersive virtual environment. We propose a novel tapping gesture model that takes electromyogram and vibration feedback into consideration. We also propose an approach of designing vibration modes that follow the mechanical stimulation principles and generate distinguishable vibration feedback with low-fidelity actuators. We developed a prototype using myoelectric and haptic apparatus (Myo armband and HTC VIVE controllers) and evaluated our system by conducting a user study with 50 participants. The evaluation shows that the users can distinguish three common materials (wood, rubber, and aluminum), and our system allows them to actively adjust their direction and strength to grasp the correct point while tapping. We demonstrate the efficacy of our tapping model on a virtual Chinese chimes application and observe positive feedback from both novices and expert users.
C1 [Xu, Pengfei; Wu, Zhongke; Wang, Xingce; Fu, Yan] Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Beijing Normal University; Nanyang Technological University
RP Wu, ZK (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
EM pengfeixuabc@gmail.com; zwu@bnu.edu.cn
FU National Key R&D Program of China [2017YFB1402105, 2017YFB1002604];
   National Key Cooperation between the BRICS Program of China
   [2017YFE0100500]; Beijing Natural Science Foundation of China [4172033]
FX This work was supported by National Key R&D Program of China
   (No.2017YFB1402105, 2017YFB1002604), National Key Cooperation between
   the BRICS Program of China(No.2017YFE0100500) and Beijing Natural
   Science Foundation of China (No. 4172033).
CR Akhtar A, 2012, IEEE ENG MED BIO, P4160, DOI 10.1109/EMBC.2012.6346883
   [Anonymous], 2015, CUTANEOUS HAPTIC FEE
   Asamura N, 1999, P IEEE VIRT REAL ANN, P274, DOI 10.1109/VR.1999.756962
   Avanzini F, 2006, COMPUT ANIMAT VIRT W, V17, P411, DOI 10.1002/cav.144
   Navarro JC, 2012, DYNA-COLOMBIA, V79, P41
   Chang GC, 1996, MED ENG PHYS, V18, P529, DOI 10.1016/1350-4533(96)00006-9
   Choi K, 2005, P ANN INT IEEE EMBS, P5820
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Cosman PH, 2002, ANZ J SURG, V72, P30, DOI 10.1046/j.1445-2197.2002.02293.x
   Gescheider GA, 2002, SOMATOSENS MOT RES, V19, P114, DOI 10.1080/08990220220131505
   Gescheider GA, 1999, SOMATOSENS MOT RES, V16, P229
   Gescheider GA, 1976, SENSORY PROCESSES
   Giordano B, 2010, 10 C FRANC AC
   Hachisu Taku, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P173, DOI 10.1007/978-3-642-31401-8_16
   HUDGINS B, 1993, IEEE T BIO-MED ENG, V40, P82, DOI 10.1109/10.204774
   Jones L. A., 2006, HUMAN HAND FUNCTION
   Kaliki RR, 2008, P IEEE, V96, P1217, DOI 10.1109/JPROC.2008.922591
   Kim D, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Kim KS, 2011, IFMBE PROC, V35, P801, DOI 10.1007/978-3-642-21729-6_196
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Kwon C, 2019, VIRTUAL REAL-LONDON, V23, P101, DOI 10.1007/s10055-018-0364-1
   Lamata P, 2006, SURG ENDOSC, V20, P1368, DOI 10.1007/s00464-004-9269-z
   Lenzi T, 2012, IEEE T BIO-MED ENG, V59, P2180, DOI 10.1109/TBME.2012.2198821
   Lyons GM, 2003, P ANN INT IEEE EMBS, V25, P1625, DOI 10.1109/IEMBS.2003.1279682
   Mukaibo Y, 2005, IEEE INT CONF ROBOT, P2565
   Nymoen K, 2015, INT C NEW INT MUS EX
   Okamura AM, 2001, IEEE-ASME T MECH, V6, P245, DOI 10.1109/3516.951362
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Papetti S, 2018, SPRINGER SER TOUCH, P257, DOI 10.1007/978-3-319-58316-7_13
   Phinyomark A., 2010, ECTI-CON2010: The 2010 ECTI International Confernce on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, P856
   Pons JL, 2005, ROBOTICA, V23, P311, DOI 10.1017/S026357470400133X
   Pulliam CL, 2011, J REHABIL RES DEV, V48, P739, DOI 10.1682/JRRD.2010.12.0237
   Reaz MBI, 2006, BIOL PROCED ONLINE, V8, P11, DOI [10.1251/bpo124, 10.1251/bpo115]
   Ryge A, 2017, P IEEE VIRT REAL ANN, P365, DOI 10.1109/VR.2017.7892328
   Saponas TS, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Saponas TS, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P851
   Shima K, 2009, IEEE SYS MAN CYBERN, P2433, DOI 10.1109/ICSMC.2009.5346384
   Ström P, 2006, SURG ENDOSC, V20, P1383, DOI 10.1007/s00464-005-0545-3
   van der Meijden OAJ, 2009, SURG ENDOSC, V23, P1180, DOI 10.1007/s00464-008-0298-x
   Wellman Parris., 1995, PROC ASME DYNAMIC SY, V57, P713
   WESTLING G, 1987, EXP BRAIN RES, V66, P128
   Wirth M, 2018, IEEE ENG MED BIO, P4953, DOI 10.1109/EMBC.2018.8513213
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu CM, 2017, VIRTUAL REAL-LONDON, V21, P19, DOI 10.1007/s10055-016-0296-6
   Yem V, 2017, P IEEE VIRT REAL ANN, P99, DOI 10.1109/VR.2017.7892236
NR 45
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 383
EP 397
DI 10.1007/s10055-020-00458-2
EA JUL 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000552941600001
DA 2024-07-18
ER

PT J
AU Martinez-Gonzalez, P
   Oprea, S
   Garcia-Garcia, A
   Jover-Alvarez, A
   Orts-Escolano, S
   Garcia-Rodriguez, J
AF Martinez-Gonzalez, Pablo
   Oprea, Sergiu
   Garcia-Garcia, Alberto
   Jover-Alvarez, Alvaro
   Orts-Escolano, Sergio
   Garcia-Rodriguez, Jose
TI UnrealROX: an extremely photorealistic virtual reality environment for
   robotics simulations and synthetic data generation
SO VIRTUAL REALITY
LA English
DT Article
DE Robotics; Synthetic data; Grasping
AB Data-driven algorithms have surpassed traditional techniques in almost every aspect in robotic vision problems. Such algorithms need vast amounts of quality data to be able to work properly after their training process. Gathering and annotating that sheer amount of data in the real world is a time-consuming and error-prone task. These problems limit scale and quality. Synthetic data generation has become increasingly popular since it is faster to generate and automatic to annotate. However, most of the current datasets and environments lack realism, interactions, and details from the real world. UnrealROX is an environment built over Unreal Engine 4 which aims to reduce that reality gap by leveraging hyperrealistic indoor scenes that are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline to generate raw data and ground truth annotations. This virtual reality environment enables robotic vision researchers to generate realistic and visually plausible data with full ground truth for a wide variety of problems such as class and instance semantic segmentation, object detection, depth estimation, visual grasping, and navigation.
C1 [Martinez-Gonzalez, Pablo; Oprea, Sergiu; Garcia-Garcia, Alberto; Jover-Alvarez, Alvaro; Orts-Escolano, Sergio; Garcia-Rodriguez, Jose] Univ Alicante, Alicante, Spain.
C3 Universitat d'Alacant
RP Garcia-Garcia, A (corresponding author), Univ Alicante, Alicante, Spain.
EM pmartinez@dtic.ua.es; agarcia@dtic.ua.es
RI García, Alberto/HDO-5321-2022
OI Jover-Alvarez, Alvaro/0000-0002-9394-0493; Garcia-Garcia,
   Alberto/0000-0002-9575-6403; Martinez Gonzalez,
   Pablo/0000-0001-6037-9815
FU Spanish Government [TIN2016-76515-R]; Feder funds; University of
   Alicante [GRE16-19]; Valencian Government [GV/2018/022]; Spanish
   national grants for Ph.D. studies [FPU15/04516, FPU17/00166,
   ACIF/2018/197]
FX This work has been funded by the Spanish Government TIN2016-76515-R
   Grant for the COMBAHO project, supported with Feder funds. This work has
   also been supported by three Spanish national grants for Ph.D. studies
   (FPU15/04516, FPU17/00166, and ACIF/2018/197), by the University of
   Alicante Project GRE16-19, and by the Valencian Government Project
   GV/2018/022. Experiments were made possible by a generous hardware
   donation from NVIDIA. We would also like to thank Zuria Bauer for her
   collaboration in the depth estimation experiments.
CR [Anonymous], ARXIV170907857
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], DIST GRAB SAMPL NOW
   [Anonymous], OC 1 CONT
   [Anonymous], VR TEMPLATE
   [Anonymous], ARXIV171006425
   Bhoi Amlaan, 2019, ARXIV190109402
   Brodeur Simon, 2017, Home: a household multimodal environment
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kolve E, 2017, AI2 THOR INTERACTIVE
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahler J, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII
   MCCORMAC J, 2016, ARXIV161205079
   Pashevich A, 2019, IEEE INT C INT ROBOT, P2651, DOI [10.1109/iros40897.2019.8967622, 10.1109/IROS40897.2019.8967622]
   Qiu WC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1221, DOI 10.1145/3123266.3129396
   Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Savva M., 2017, MINOS: Multimodal indoor simulator for navigation in complex environments
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   To T., 2018, CVPR 2018 WORKSH REA
   Tobin J, 2017, IEEE INT C INT ROBOT, P23
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Yan Claudia., 2018, CHALET: Cornell house agent learning environment
NR 36
TC 22
Z9 25
U1 2
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 271
EP 288
DI 10.1007/s10055-019-00399-5
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Swidrak, J
   Pochwatko, G
   Navarro, X
   Oseka, L
   Dolinski, D
AF Swidrak, Justyna
   Pochwatko, Grzegorz
   Navarro, Xavi
   Oseka, Laura
   Dolinski, Dariusz
TI The joint influence of social status and personal attitudes in a contact
   and open versus a noncontact and homophobic culture on the virtual Midas
   touch
SO VIRTUAL REALITY
LA English
DT Article
DE Midas touch; Ultimatum game; Immersive virtual reality; Social status;
   Homophobia; Culture
ID PHYSICAL ATTRACTIVENESS; INTERPERSONAL DISTANCE; HELPING-BEHAVIOR;
   TACTILE CONTACT; GAY MEN; GENDER; LESBIANS; REQUESTS
AB Alongside the highly rapid development of virtual reality technology, embodied agents will become soon a common element of human-computer interactions. Our study analyzed the interactional influence of social status, personal attitudes (homophobia and social status importance), and culture on the efficiency of the virtual Midas touch effect. From a human perspective, we focused on the cultural background related to the social norms of touch, homophobia, and social status importance. In Poland, a noncontact culture, men avoid same-gender touch and also score very high on male homophobia. Catalonia, on the other hand, has a contact culture, where same-gender male touch is rather common and natural. Catalonia is also one of the most inclusive and open societies in the world. From an embodied agent's perspective, we asked whether the agent's social status influences compliance with virtual touch. We used a modified paradigm of the ultimatum game to observe whether Polish and Catalan men are more compliant when touched by high- or low-status agents. Our results suggest that the virtual interpersonal touch and social status importance influence compliance with a moderating effect of culture. We found also a significant effect of the offer's value and a moderating effect of culture and homophobia on compliance.
C1 [Swidrak, Justyna; Pochwatko, Grzegorz; Oseka, Laura] Polish Acad Sci, Inst Psychol, Warsaw, Poland.
   [Swidrak, Justyna; Navarro, Xavi] Univ Barcelona, Fac Psychol, Expt Virtual Environm Neurosci & Technol, Barcelona, Spain.
   [Dolinski, Dariusz] SWPS Univ Social Sci & Humanities, Fac Psychol Wroclaw, Wroclaw, Poland.
C3 Polish Academy of Sciences; Institute of Psychology of the Polish
   Academy of Sciences; University of Barcelona; SWPS University of Social
   Sciences & Humanities
RP Swidrak, J (corresponding author), Polish Acad Sci, Inst Psychol, Warsaw, Poland.; Swidrak, J (corresponding author), Univ Barcelona, Fac Psychol, Expt Virtual Environm Neurosci & Technol, Barcelona, Spain.
EM justyna.swidrak@psych.pan.pl
RI Świdrak, Justyna/AAX-3397-2021; Swidrak, Justyna/HGU-9131-2022; Navarro,
   Xavi/KEE-5474-2024
OI Świdrak, Justyna/0000-0003-0141-2667; Swidrak,
   Justyna/0000-0003-0141-2667; Oseka, Laura/0000-0003-4076-1165;
   Pochwatko, Grzegorz/0000-0001-8548-6916
FU National Centre of Science in Poland [2014/15/N/HS6/04135,
   2016/20/T/HS6/00599]
FX The first author benefits from the Prelude and Etiude grants from the
   National Centre of Science in Poland (2014/15/N/HS6/04135 and
   2016/20/T/HS6/00599). We would like to thank prof. Mel Slater for his
   comments on the study design and Ramon Oliva, Jose Valenzuela, and
   Alejandro Beacco for their help on the development of the virtual
   environment.
CR Adams HE, 1996, J ABNORM PSYCHOL, V105, P440, DOI 10.1037/0021-843X.105.3.440
   Anderson C, 2001, J PERS SOC PSYCHOL, V81, P116, DOI 10.1037//0022-3514.81.1.116
   Aslani S, 2016, J ORGAN BEHAV, V37, P1178, DOI 10.1002/job.2095
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Blue PR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01667
   Bolzendahl C, 2017, EUROPENOW
   Bratanova B, 2016, SCAND J PSYCHOL, V57, P243, DOI 10.1111/sjop.12281
   Cárdenas M, 2008, J SEX RES, V45, P140, DOI 10.1080/00224490801987424
   Chen SXH, 2006, J SOC PSYCHOL, V146, P223, DOI 10.3200/SOCP.146.2.223-244
   Chen YR, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P62, DOI 10.1145/3308532.3329420
   Cheval B, 2016, J SEX MED, V13, P825, DOI 10.1016/j.jsxm.2016.02.165
   CRUSCO AH, 1984, PERS SOC PSYCHOL B, V10, P512, DOI 10.1177/0146167284104003
   DEBEVEC K, 1986, PSYCHOL REP, V58, P503, DOI 10.2466/pr0.1986.58.2.503
   Demiris G, 2018, INNOV AGING, V2, P53, DOI [10.1093/geroni/igy023.196, DOI 10.1093/GERONI/IGY023.196]
   DiBiase R, 2004, J SOC PSYCHOL, V144, P49, DOI 10.3200/SOCP.144.1.49-62
   Dolinski D., 2013, POL PSYCHOL BULL, V44, P457, DOI DOI 10.2478/PPB-2013-0051
   Dolinski D, 2010, J NONVERBAL BEHAV, V34, P179, DOI 10.1007/s10919-010-0090-1
   EAGLY AH, 1986, PSYCHOL BULL, V100, P283, DOI 10.1037/0033-2909.100.3.283
   Eastwick PW, 2009, SOC INFLUENCE, V4, P18, DOI 10.1080/15534510802254087
   Erceau D, 2007, J SOC PSYCHOL, V147, P441, DOI 10.3200/SOCP.147.4.441-444
   Fehr E, 2000, J ECON PERSPECT, V14, P159, DOI 10.1257/jep.14.3.159
   Floyd K, 2000, J SOC PSYCHOL, V140, P774, DOI 10.1080/00224540009600516
   Frevert TK, 2014, SOCIOL COMPASS, V8, P313, DOI 10.1111/soc4.12132
   Gallace A, 2010, NEUROSCI BIOBEHAV R, V34, P246, DOI 10.1016/j.neubiorev.2008.10.004
   GOODMAN MD, 1993, J SOC PSYCHOL, V133, P23, DOI 10.1080/00224545.1993.9712115
   Guéguen N, 2003, J SOC PSYCHOL, V143, P785, DOI 10.1080/00224540309600431
   Gueguen N., 2006, International Journal of Management, V23, P24
   Guéguen N, 2010, J BEHAV MED, V33, P466, DOI 10.1007/s10865-010-9277-5
   Güth W, 2014, J ECON BEHAV ORGAN, V108, P396, DOI 10.1016/j.jebo.2014.06.006
   GUTH W, 1982, J ECON BEHAV ORGAN, V3, P367, DOI 10.1016/0167-2681(82)90011-7
   Haans A, 2009, IEEE T HAPTICS, V2, P136, DOI 10.1109/ToH.2009.20
   Haans Antal, 2006, Virtual Reality, P149
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   Harjunen VJ, 2018, COMPUT HUM BEHAV, V87, P384, DOI 10.1016/j.chb.2018.06.012
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   HEREK GM, 1988, J SEX RES, V25, P451, DOI 10.1080/00224498809551476
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Huberman BA, 2004, SOC PSYCHOL QUART, V67, P103, DOI 10.1177/019027250406700109
   Joda T, 2019, COMPUT BIOL MED, V108, P93, DOI 10.1016/j.compbiomed.2019.03.012
   KLEINKE CL, 1977, J EXP SOC PSYCHOL, V13, P218, DOI 10.1016/0022-1031(77)90044-0
   KLEINKE CL, 1977, J SOC PSYCHOL, V101, P223, DOI 10.1080/00224545.1977.9924011
   Leung AKY, 2011, J PERS SOC PSYCHOL, V100, P507, DOI 10.1037/a0022151
   Lucas GM, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P22, DOI 10.1145/3308332.3329464
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Nasierowski W, 1998, ORGAN STUD, V19, P495, DOI 10.1177/017084069801900306
   Pais EE, 2007, GENERALITAT PROYECTA
   PATTERSON ML, 1986, J NONVERBAL BEHAV, V10, P41, DOI 10.1007/BF00987204
   Pochwatko G, 2019, NOWOCZESNE TECHNOLOG, P272
   REMLAND MS, 1995, J SOC PSYCHOL, V135, P281, DOI 10.1080/00224545.1995.9713958
   Salamanca Gastón, 2013, Universum, V28, P35
   Schuster S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05122-5
   Sorokowska A, 2017, J CROSS CULT PSYCHOL, V48, P577, DOI 10.1177/0022022117698039
   Spapé MM, 2015, PSYCHOPHYSIOLOGY, V52, P378, DOI 10.1111/psyp.12361
   STIER DS, 1984, J PERS SOC PSYCHOL, V47, P440, DOI 10.1037/0022-3514.47.2.440
   STORRS D, 1990, J NONVERBAL BEHAV, V14, P87, DOI 10.1007/BF01670436
   Szmajke A, 2003, POL PSYCHOL B, V34, P153
   Tinsley CH, 2001, J APPL PSYCHOL, V86, P583, DOI 10.1037//0021-9010.86.4.583
   Uppot RN, 2019, RADIOLOGY, V291, P570, DOI 10.1148/radiol.2019182210
   van Erp JBF., 2015, Front Digit Humanit, V2, DOI [10.3389/fdigh.2015.00002, DOI 10.3389/FDIGH.2015.00002]
   Weitz K, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P7, DOI 10.1145/3308532.3329441
NR 67
TC 4
Z9 4
U1 0
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 619
EP 633
DI 10.1007/s10055-019-00423-8
EA JAN 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000505420100001
DA 2024-07-18
ER

PT J
AU Saab, MM
   Landers, M
   Cooke, E
   Murphy, D
   Hegarty, J
AF Saab, Mohamad M.
   Landers, Margaret
   Cooke, Eoghan
   Murphy, David
   Hegarty, Josephine
TI Feasibility and usability of a virtual reality intervention to enhance
   men's awareness of testicular disorders (E-MAT)
SO VIRTUAL REALITY
LA English
DT Article
DE Feasibility; Health promotion; Testicular cancer; Testicular diseases;
   Usability; Virtual reality
ID SELF-EXAMINATION; CANCER AWARENESS; HEALTH; INFORMATION; ADULTS;
   SATISFACTION; KNOWLEDGE; ANXIETY; TORSION; BREAST
AB Testicular cancer is the most common cancer among men younger than 50, and benign testicular disorders such as torsion and epididymitis can be life-threatening if left untreated. Men's awareness of testicular disorders is lacking, and their intentions to see help for symptoms of testicular disease are low. This study aimed to describe the development, feasibility, and usability of a virtual reality (VR) intervention designed to enhance men's awareness of testicular disorders (E-MAT). We designed E-MAT as a three-level VR experience and tested its feasibility and usability with 15 men recruited from a university. Following exposure to the intervention, participants filled a 43-item questionnaire. Participants agreed that the technology was comfortable to use, testicular disorders were well represented, the use of light humor was appropriate, and the scientific facts were easy to understand. Participants also agreed that the intervention was suited for men from different sociodemographic backgrounds and felt confident using VR. Overall, participants perceived the intervention as user-friendly, enjoyable, and aesthetically appealing. To the best of our knowledge, VR has not been used to promote men's health in the past, let alone increasing their awareness and help seeking for testicular disorders. We recommend testing the effectiveness of E-MAT and making it available on public platforms that men can access at their own leisure. VR can be used in future interventions to educate men about various health topics.
C1 [Saab, Mohamad M.; Landers, Margaret; Hegarty, Josephine] Univ Coll Cork, Sch Nursing & Midwifery, Brookfield Hlth Sci Complex,Coll Rd, Cork T12 AK54, Ireland.
   [Cooke, Eoghan; Murphy, David] Univ Coll Cork, Dept Comp Sci, Cork, Ireland.
C3 University College Cork; University College Cork
RP Saab, MM (corresponding author), Univ Coll Cork, Sch Nursing & Midwifery, Brookfield Hlth Sci Complex,Coll Rd, Cork T12 AK54, Ireland.
EM msaab@ucc.ie
RI Murphy, David/A-4900-2019
OI Murphy, David/0000-0002-9685-8292; Hegarty,
   Josephine/0000-0002-1663-4820
FU School of Nursing and Midwifery, University College Cork
FX This study was supported by a PhD scholarship granted by the School of
   Nursing and Midwifery, University College Cork.
CR [Anonymous], 2016, SEER STAT FACT SHEET
   Baker P, 2014, B WORLD HEALTH ORGAN, V92, P618, DOI 10.2471/BLT.13.132795
   Bayne CE, 2017, J PEDIATR-US, V186, P200, DOI 10.1016/j.jpeds.2017.03.037
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Brown Carlton G, 2012, Medsurg Nurs, V21, P97
   Cardos RAI, 2017, COMPUT HUM BEHAV, V72, P371, DOI 10.1016/j.chb.2017.03.007
   Clark Karen, 2011, W V Med J, V107, P35
   Craig P, 2013, INT J NURS STUD, V50, P587, DOI 10.1016/j.ijnurstu.2012.09.010
   Dhiman A, 2016, IEEE XPLORE
   Elo S, 2008, J ADV NURS, V62, P107, DOI 10.1111/j.1365-2648.2007.04569.x
   Evans REC, 2012, J HEALTH PSYCHOL, V17, P579, DOI 10.1177/1359105311421046
   Fernandes AS, 2016, IEEE XPLORE
   Flesch R., 1981, How to write plain English: A book for lawyers
   Foreman M, 2017, AM J OCCUP THER
   Gomez-Rodriguez M, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036005
   Gordhan CG, 2015, KOREAN J UROL, V56, P3, DOI 10.4111/kju.2015.56.1.3
   Hashibe M, 2016, J CANCER SURVIV, V10, P1051, DOI 10.1007/s11764-016-0548-1
   He J., 2010, Journal of Information Systems Education, V21, P203
   Hinton PR., 2004, SPSS explained, DOI DOI 10.4324/9780203642597
   Jensen JD, 2010, J AGING HEALTH, V22, P804, DOI 10.1177/0898264310366161
   Kandalaft MR, 2013, J AUTISM DEV DISORD, V43, P34, DOI 10.1007/s10803-012-1544-6
   Kedzierewicz R, 2011, MIL MED, V176, P1188, DOI 10.7205/MILMED-D-11-00037
   Kennett A, 2014, INT J STD AIDS, V25, P844, DOI 10.1177/0956462414522774
   Lemole GM, 2007, NEUROSURGERY, V61, P142, DOI 10.1227/01.neu.0000279734.22931.21
   Lloréns R, 2015, ARCH PHYS MED REHAB, V96, P418, DOI 10.1016/j.apmr.2014.10.019
   McCullagh J, 2005, Nurs Stand, V19, P41
   Miloff A, 2016, BIOMED CENTRAL
   Mind Commerce, 2016, VIRT REAL MARK OUTL
   Nabi RL, 2016, HEALTH COMMUN, V31, P873, DOI 10.1080/10410236.2014.1000479
   Oliffe JL, 2009, PSYCHO-ONCOLOGY, V18, P916, DOI 10.1002/pon.1415
   Oliveira CR, 2016, SPAN J PSYCHOL, V19, DOI 10.1017/sjp.2016.96
   Oosterom-Calo R, 2016, LECT NOTES COMPUT SC, V9755, P342, DOI 10.1007/978-3-319-39949-2_33
   Orsmond GI, 2015, OTJR-OCCUP PART HEAL, V35, P169, DOI 10.1177/1539449215578649
   Powe BD, 2007, AM J MENS HEALTH, V1, P73, DOI 10.1177/1557988306295305
   Rioja J, 2011, BJU INT, V107, P1852, DOI 10.1111/j.1464-410X.2011.10353.x
   Robinson M, 2010, HEALTH PROMOT INT, V25, P363, DOI 10.1093/heapro/daq022
   Saab M.M., 2016, AM J MENS HLTH
   Saab MM, 2018, NURS RES, V67, P169, DOI 10.1097/NNR.0000000000000268
   Saab MM, 2018, PSYCHO-ONCOLOGY, V27, P410, DOI 10.1002/pon.4506
   Saab MM, 2017, INT J NURS STUD, V67, P41, DOI 10.1016/j.ijnurstu.2016.11.016
   Saab MM, 2017, EUR J ONCOL NURS, V26, P27, DOI 10.1016/j.ejon.2016.11.001
   Saab MM, 2016, CANCER NURS, V39, P473, DOI 10.1097/NCC.0000000000000333
   Saab MM, 2016, ONCOL NURS FORUM, V43, pE8, DOI 10.1188/16.ONF.E8-E23
   Saab M, 2014, NURS RES, V63, P203, DOI 10.1097/NNR.0000000000000033
   Shallwani K, 2010, ASIAN PAC J CANCER P, V11, P383
   Shanmugalingam Thurkaa, 2013, Clin Epidemiol, V5, P417, DOI 10.2147/CLEP.S34430
   Shteynshlyuger A, 2013, J PEDIATR UROL, V9, P683, DOI 10.1016/j.jpurol.2012.08.002
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Sprauten M, 2012, J CLIN ONCOL, V30, P300, DOI 10.1200/JCO.2011.37.4025
   Szymanski DM, 2001, J ACAD MARKET SCI, V29, P16
   Thornton CP, 2016, J PEDIATR HEALTH CAR, V30, P518, DOI 10.1016/j.pedhc.2015.11.009
   Trojian TH, 2009, AM FAM PHYSICIAN, V79, P583
   Umeh K, 2016, J BEHAV MED, V39, P151, DOI 10.1007/s10865-010-9262-z
   van der Meijden OAJ, 2009, SURG ENDOSC, V23, P1180, DOI 10.1007/s00464-008-0298-x
   Vankipuram A, 2014, IEEE J BIOMED HEALTH, V18, P1478, DOI 10.1109/JBHI.2013.2285102
   Verhagen T, 2011, INFORM MANAGE-AMSTER, V48, P201, DOI 10.1016/j.im.2011.02.004
   Wampler SM, 2010, PRIMARY CARE, V37, P613, DOI 10.1016/j.pop.2010.04.009
   Whitehead AL, 2014, CONTEMP CLIN TRIALS, V38, P130, DOI 10.1016/j.cct.2014.04.001
   Yoo BN, 2012, ASIAN PAC J CANCER P, V13, P123, DOI 10.7314/APJCP.2012.13.1.123
NR 60
TC 11
Z9 12
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 169
EP 178
DI 10.1007/s10055-018-0368-x
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kerous, B
   Skola, F
   Liarokapis, F
AF Kerous, Bojan
   Skola, Filip
   Liarokapis, Fotis
TI EEG-based BCI and video games: a progress report
SO VIRTUAL REALITY
LA English
DT Article
DE Brain-computer interface; Games; EEG
ID BRAIN-COMPUTER-INTERFACE; VISUAL-EVOKED-POTENTIALS; SLOW CORTICAL
   POTENTIALS; VIRTUAL-REALITY; LONG-TERM; ATTENTION; NEUROFEEDBACK; TIME;
   COMMUNICATION; MOTIVATION
AB This paper presents a systematic review of electroencephalography (EEG)-based brain-computer interfaces (BCIs) used in the video games, a vibrant field of research that touches upon all relevant questions concerning the future directions of BCI. The paper examines the progress of BCI research with regard to games and shows that gaming applications offer numerous advantages by orienting BCI to concerns and expectations of a gaming application. Different BCI paradigms are investigated, and future directions are discussed.
C1 [Kerous, Bojan; Skola, Filip; Liarokapis, Fotis] Masaryk Univ, HCI Lab, Bot 68a, Brno, Czech Republic.
C3 Masaryk University Brno
RP Kerous, B (corresponding author), Masaryk Univ, HCI Lab, Bot 68a, Brno, Czech Republic.
EM 454909@mail.muni.cz; xskola@mail.muni.cz; liarokap@fi.muni.cz
RI Kerous, Bojan/HSB-0548-2023; Liarokapis, Fotis/AAD-4444-2019; Škola,
   Filip/AAG-1888-2020; Liarokapis, Fotis/AAQ-9498-2021
OI Kerous, Bojan/0000-0002-5245-8457; Liarokapis,
   Fotis/0000-0003-3617-2261; Liarokapis, Fotis/0000-0003-3617-2261; Skola,
   Filip/0000-0003-4690-6687
CR Ahn M, 2015, J NEUROSCI METH, V243, P103, DOI 10.1016/j.jneumeth.2015.01.033
   Ahn M, 2014, SENSORS-BASEL, V14, P14601, DOI 10.3390/s140814601
   Ahn M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080886
   Ali A, 2015, IEEE ENG MED BIO, P67, DOI 10.1109/EMBC.2015.7318302
   Allison BZ, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026007
   Allison B, 2010, IEEE T NEUR SYS REH, V18, P107, DOI 10.1109/TNSRE.2009.2039495
   Amaral CP, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121970
   Ang KK, 2015, CLIN EEG NEUROSCI, V46, P310, DOI 10.1177/1550059414522229
   Angeloni C, 2012, NORTHEAST BIOENGIN C, P35, DOI 10.1109/NEBC.2012.6206949
   [Anonymous], 2016, P 7 AUGM HUM INT C 2
   [Anonymous], 1990, J CLIN NEUROPHYSIOL
   [Anonymous], P300 BCI STIMULI PRE
   [Anonymous], MIND GARDEN BRAIN CO
   [Anonymous], HDB DIGITAL GAMES EN
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2013, P 2013 INT C PHYS CO
   [Anonymous], COMPUTATIONAL INTELL
   [Anonymous], P 3 INT C PHYS COMP
   [Anonymous], WORKSH REP ENT WORKS
   [Anonymous], 1958, ELECTROEN CLIN NEURO
   [Anonymous], 2015, P 8 ACM SIGGRAPH C M
   [Anonymous], THESIS
   [Anonymous], 2013, P IEEE 2 INT C SER G
   [Anonymous], BRAINBASHER BCI GAME
   [Anonymous], AI HCI AI IA
   [Anonymous], P 3 AUGM HUM INT C
   [Anonymous], 2016, P 2016 8 INT C GAMES
   [Anonymous], BRAIN COMPUTER INT A
   [Anonymous], 2015, 8 INT C COMP GAM MUL
   [Anonymous], IJCAI
   [Anonymous], IET IR SIGN SYST C I
   [Anonymous], P DIGRA
   [Anonymous], P BRAINPLAY 2007 PLA
   [Anonymous], THEORY PRACTICE COMP
   [Anonymous], VIRT REH ICVR 2011 I
   Bai O, 2008, J NEURAL ENG, V5, P24, DOI 10.1088/1741-2560/5/1/003
   Banville H, 2016, BRAIN-COMPUT INTERFA, V3, P9, DOI 10.1080/2326263X.2015.1134958
   Bayliss JD, 2000, NEUROCOMPUTING, V32, P637, DOI 10.1016/S0925-2312(00)00226-5
   Bernays R, 2012, ADJUNCT PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P79
   Berta R, 2013, IEEE T COMP INTEL AI, V5, P164, DOI 10.1109/TCIAIG.2013.2260340
   Beveridge R, 2016, PROG BRAIN RES, V228, P329, DOI 10.1016/bs.pbr.2016.06.006
   Bianchi L, 2010, BRAIN TOPOGR, V23, P180, DOI 10.1007/s10548-010-0143-0
   Bin GY, 2009, IEEE COMPUT INTELL M, V4, P22, DOI 10.1109/MCI.2009.934562
   Blankertz B., 2009, BMC Neurosci., V10, pP84
   Blankertz B, 2010, NEUROIMAGE, V51, P1303, DOI 10.1016/j.neuroimage.2010.03.022
   Bonnet L, 2013, IEEE T COMP INTEL AI, V5, P185, DOI 10.1109/TCIAIG.2012.2237173
   Bordoloi S, 2012, 2012 4 INT C INTELLI, P1
   Bos DPO, 2010, HUM-COMPUT INT-SPRIN, P149, DOI 10.1007/978-1-84996-272-8_10
   Causse M, 2015, PROCEDIA MANUF, V3, P5230, DOI 10.1016/j.promfg.2015.07.594
   Chouhan T, 2015, IEEE SYS MAN CYBERN, P3104, DOI 10.1109/SMC.2015.539
   Chumerin N, 2013, IEEE T COMP INTEL AI, V5, P100, DOI 10.1109/TCIAIG.2012.2225623
   Cohen A, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00052
   Collinger JL, 2013, LANCET, V381, P557, DOI 10.1016/S0140-6736(12)61816-9
   Congedo M, 2011, P 5 INT BRAIN COMP I, P280
   Coulton Paul., 2011, Proceedings of the 15th International Academic Mindtrek Conference: Envisioning Future Media Environments, P37, DOI DOI 10.1145/2181037.2181045
   Coyle D., 2011, Proceedings of 2011 IEEE Symposium on Computational Intelligence,Cognitive Algorithms, Mind, and Brain, P1, DOI DOI 10.1109/CCMB.2011.5952128
   Daly JJ, 2008, LANCET NEUROL, V7, P1032, DOI 10.1016/S1474-4422(08)70223-0
   Daly JJ, 2009, J NEUROL PHYS THER, V33, P203, DOI 10.1097/NPT.0b013e3181c1fc0b
   de Lissa P, 2015, J NEUROSCI METH, V253, P47, DOI 10.1016/j.jneumeth.2015.05.025
   De Vos M, 2014, INT J PSYCHOPHYSIOL, V91, P46, DOI 10.1016/j.ijpsycho.2013.08.010
   Edlinger G, 2011, LECT NOTES COMPUT SC, V6766, P545, DOI 10.1007/978-3-642-21663-3_59
   Enriquez-Geppert S, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00051
   Ewing KC, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00223
   Falkenstein M, 2000, BIOL PSYCHOL, V51, P87, DOI 10.1016/S0301-0511(99)00031-9
   FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6
   Nicolas-Alonso LF, 2012, SENSORS-BASEL, V12, P1211, DOI 10.3390/s120201211
   Ferreira A.L.S., 2014, SBC J INTERACT SYST, V5, P3
   Finke A, 2009, NEURAL NETWORKS, V22, P1329, DOI 10.1016/j.neunet.2009.07.003
   Fouad MM, 2015, INTEL SYST REF LIBR, V74, P3, DOI 10.1007/978-3-319-10978-7_1
   Friedrich EV, 2014, FRONT NEUROENG, V7, P21
   Guger C, 2003, IEEE T NEUR SYS REH, V11, P145, DOI 10.1109/TNSRE.2003.814481
   Guger C., 2015, RECENT ADV BRAINCOMP, P127
   Guger C, 2009, NEUROSCI LETT, V462, P94, DOI 10.1016/j.neulet.2009.06.045
   Guo F, 2008, J NEURAL ENG, V5, P477, DOI 10.1088/1741-2560/5/4/011
   Gurkok Hayrettin, 2014, Universal Access in Human-Computer Interaction. Universal Access to Information and Knowledge. 8th International Conference, UAHCI 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8514, P549, DOI 10.1007/978-3-319-07440-5_50
   Gurkok Hayrettin, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P373, DOI 10.1007/978-3-642-33542-6_33
   Gürkök H, 2013, INT CONF AFFECT, P827, DOI 10.1109/ACII.2013.155
   Hakvoort G, 2011, LECT NOTES COMPUT SC, V6946, P115, DOI 10.1007/978-3-642-23774-4_12
   Hasan BAS, 2012, COMPUT BIOL MED, V42, P598, DOI 10.1016/j.compbiomed.2012.02.004
   Heidrich R, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P397, DOI 10.1145/2700648.2811388
   Huster RJ, 2014, INT J PSYCHOPHYSIOL, V91, P36, DOI 10.1016/j.ijpsycho.2013.08.011
   Hwang HJ, 2013, INT J HUM-COMPUT INT, V29, P814, DOI 10.1080/10447318.2013.780869
   Jackson MM, 2009, LECT NOTES COMPUT SC, V5611, P588, DOI 10.1007/978-3-642-02577-8_64
   Jarvela S., 2015, GAME RES METHODS, P193, DOI DOI 10.1184/R1/6686765
   Jeunet C, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/3/036024
   Jin J, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/036004
   Joselli M, 2014, BRAZIL SYMP GAME DIG, P123, DOI 10.1109/SBGAMES.2014.14
   Jurcak V, 2007, NEUROIMAGE, V34, P1600, DOI 10.1016/j.neuroimage.2006.09.024
   Kaplan AY, 2013, IEEE T COMP INTEL AI, V5, P141, DOI 10.1109/TCIAIG.2012.2237517
   Kaufmann T, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/5/056016
   Khong A, 2014, IEEE SYS MAN CYBERN, P1847, DOI 10.1109/SMC.2014.6974189
   Kleber B., 2005, COGN PROCESS, V6, P65
   Koo B, 2015, IEEE ENG MED BIO, P1103, DOI 10.1109/EMBC.2015.7318558
   Kos'myna N, 2013, IEEE T COMP INTEL AI, V5, P150, DOI 10.1109/TCIAIG.2012.2230003
   Kotsia I, 2013, IEEE COMPUT SOC CONF, P663, DOI 10.1109/CVPRW.2013.100
   Kreilinger A, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2011.00147
   Krepki R, 2007, MULTIMED TOOLS APPL, V33, P73, DOI 10.1007/s11042-006-0094-3
   KUBA M, 1992, DOC OPHTHALMOL, V80, P83, DOI 10.1007/BF00161234
   Kübler A, 2005, NEUROLOGY, V64, P1775, DOI 10.1212/01.WNL.0000158616.43002.6D
   Lécuyer A, 2008, COMPUTER, V41, P66, DOI 10.1109/MC.2008.410
   Lee Po-Lei, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P5, DOI 10.1109/ICCE-TW.2014.6904095
   Leeb R., 2012, Towards Practical Brain-Computer Interfaces: Bridging the Gap from Research to Real-World Applications, P197
   Leeb Robert, 2007, Comput Intell Neurosci, P79642, DOI 10.1155/2007/79642
   Leeb R, 2013, IEEE T COMP INTEL AI, V5, P117, DOI 10.1109/TCIAIG.2013.2242072
   Legény J, 2013, IEEE T COMP INTEL AI, V5, P111, DOI 10.1109/TCIAIG.2013.2252348
   Li JH, 2013, IEEE ENG MED BIO, P2200, DOI 10.1109/EMBC.2013.6609972
   Liao LD, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-5
   Liarokapis F, 2015, IEEE INT CONF INF VI, P488, DOI 10.1109/iV.2015.87
   Lim WL, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P169, DOI 10.1109/CW.2015.39
   Liu YS, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P161, DOI 10.1109/CW.2014.30
   Lopetegui E., 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P228, DOI 10.1109/CGAMES.2011.6000344
   Lotte F., 2011, Proceedings of the 6th International Conference on Foundations of Digital Games, FDG'11, P325, DOI DOI 10.1145/2159365.2159427
   Loup-Escande E., 2017, HDB DIGITAL GAMES EN, P225, DOI 10.1007/978-981-4560-52-8_3-1
   Luck S.J., 2004, EVENT RELATED POTENT
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Maby E, 2012, ADV HUM-COMPUT INTER, V2012, DOI 10.1155/2012/124728
   Marshall D, 2015, PROCEEDINGS OF CGAMES'2015 USA 20TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES - AI, ANIMATION, MOBILE, INTERACTIVE MULTIMEDIA, EDUCATIONAL AND SERIOUS GAMES, P18, DOI 10.1109/CGames.2015.7272957
   Marshall D, 2013, IEEE T COMP INTEL AI, V5, P82, DOI 10.1109/TCIAIG.2013.2263555
   Martinez P., 2007, COMPUT INTEL NEUROSC, V2007, P13, DOI DOI 10.1155/2007/94561
   Mayer K, 2013, J ATTEN DISORD, V17, P393, DOI 10.1177/1087054712468053
   McMahan T, 2015, PROCEDIA MANUF, V3, P2303, DOI 10.1016/j.promfg.2015.07.376
   Mercier-Ganady J, 2013, P ACM S VIRT REAL SO, P69
   Millán JD, 2008, INT J PATTERN RECOGN, V22, P959
   Mondéjar T, 2016, J BIOMED INFORM, V63, P131, DOI 10.1016/j.jbi.2016.08.006
   Mühl C, 2014, BRAIN-COMPUT INTERFA, V1, P66, DOI 10.1080/2326263X.2014.912881
   MULHOLLAND T, 1995, INT J PSYCHOPHYSIOL, V19, P263, DOI 10.1016/0167-8760(95)00019-O
   Munoz J, 2014, ACM INT C PROCEEDING, DOI [10.1145/2663806.2671211, DOI 10.1145/2663806.2671211]
   Munoz John E., 2015, 2015 10th Computing Colombian Conference (10CCC). Proceedings, P194, DOI 10.1109/ColumbianCC.2015.7333431
   Nacke LE, 2015, HUM-COMPUT INT-SPRIN, P63, DOI 10.1007/978-3-319-15985-0_4
   Nijboer F, 2013, NEUROETHICS-NETH, V6, P541, DOI 10.1007/s12152-011-9132-6
   Park K, 2016, 2016 IEEE/ACIS 14TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P125, DOI 10.1109/SERA.2016.7516137
   Pengfei Wei, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P1942, DOI 10.1109/ICMA.2010.5589104
   Pike M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5385, DOI 10.1145/2858036.2858276
   Pineda JA, 2003, IEEE T NEUR SYS REH, V11, P181, DOI 10.1109/TNSRE.2003.814445
   Pires Gabriel, 2011, 2011 IEEE 1 INT C SE, P1
   Qu XT, 2015, IEEE INT CONF COMP, P1
   Ramadan RA, 2015, INTEL SYST REF LIBR, V74, P31, DOI 10.1007/978-3-319-10978-7_2
   Riechmann H, 2016, IEEE T NEUR SYS REH, V24, P692, DOI 10.1109/TNSRE.2015.2490621
   Rohani DA, 2015, EPJ NONLINEAR BIOMED, V3, DOI 10.1140/epjnbp/s40366-015-0027-z
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Scherer R, 2011, LECT NOTES COMPUT SC, V6691, P362, DOI 10.1007/978-3-642-21501-8_45
   Sellers EW, 2010, AMYOTROPH LATERAL SC, V11, P449, DOI 10.3109/17482961003777470
   Shenjie S, 2014, IEEE SYS MAN CYBERN, P3150, DOI 10.1109/SMC.2014.6974412
   Shim BS, 2007, SERA 2007: 5TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT, AND APPLICATIONS, PROCEEDINGS, P751, DOI 10.1109/SERA.2007.94
   Sivanathan A, 2014, ENTERTAIN COMPUT, V5, P323, DOI 10.1016/j.entcom.2014.03.004
   Spüler M, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.7015.00155, 10.3389/fnhum.2015.00155]
   Stamatto AlessandroL., 2013, SBC J 3D INTERACTIVE, V4, P3
   Strehl U, 2006, PEDIATRICS, V118, pE1530, DOI 10.1542/peds.2005-2478
   Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291
   Teo G, 2015, PROCEDIA MANUF, V3, P1006, DOI 10.1016/j.promfg.2015.07.159
   Thomas KP, 2013, IEEE ENG MED BIO, P433, DOI 10.1109/EMBC.2013.6609529
   van de Laar B, 2013, IEEE T COMP INTEL AI, V5, P176, DOI 10.1109/TCIAIG.2013.2253778
   van Erp JBF, 2014, IEEE HAPTICS SYM, P397, DOI 10.1109/HAPTICS.2014.6775488
   van Vliet M., 2012, 2012 ISSNIP BIOSIGNA, P1, DOI DOI 10.1109/BRC.2012.6222186
   Velliste M, 2008, NATURE, V453, P1098, DOI 10.1038/nature06996
   VIDAL JJ, 1977, P IEEE, V65, P633, DOI 10.1109/PROC.1977.10542
   Vidaurre C, 2010, BRAIN TOPOGR, V23, P194, DOI 10.1007/s10548-009-0121-6
   Vourvopoulos A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0173-2
   Wang CC, 2007, P ANN INT IEEE EMBS, P4703, DOI 10.1109/IEMBS.2007.4353389
   Wang Q, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P270, DOI 10.1109/CW.2010.56
   Washburn DA, 2003, BEHAV RES METH INS C, V35, P185, DOI 10.3758/BF03202541
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Wu GB, 2014, INT CONF INFO SCI, P652, DOI 10.1109/ICIST.2014.6920562
   Yan S, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P306, DOI 10.1145/2856767.2856768
   Yoh M.-S., 2010, the Proceedings of the 12th ACM International Conference Adjunct Papers on Ubiquitous Computing, P389, DOI [DOI 10.1145/1864431.1864450, 10.1145/1864431.1864450]
   Yoon H, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P785
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
   Zander TO, 2010, HUM-COMPUT INT-SPRIN, P181, DOI 10.1007/978-1-84996-272-8_11
   Zhao QB, 2009, CHINESE SCI BULL, V54, P78, DOI 10.1007/s11434-008-0547-3
   Zhu Danhua, 2010, Comput Intell Neurosci, P702357, DOI 10.1155/2010/702357
NR 170
TC 109
Z9 118
U1 7
U2 123
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2018
VL 22
IS 2
SI SI
BP 119
EP 135
DI 10.1007/s10055-017-0328-x
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GC5KP
UT WOS:000429826700004
DA 2024-07-18
ER

PT J
AU Bhagat, KK
   Liou, WK
   Chang, CY
AF Bhagat, Kaushal Kumar
   Liou, Wei-Kai
   Chang, Chun-Yen
TI A cost-effective interactive 3D virtual reality system applied to
   military live firing training
SO VIRTUAL REALITY
LA English
DT Article
DE Serious games; Virtual reality (VR); Military training; Learning
   outcome; Learning motivation
ID STUDENTS LEARNING-PERFORMANCE; GAME; EDUCATION; SCIENCE; COLLABORATION;
   MATHEMATICS
AB The goal of the present study was to develop a cost-effective, man-machine digital interface, to improve students' real-world firing range training, results, and achievement scores. A serious game-based learning environment was developed, integrating invisible laser infrared technology, 1:1 real-scale rifle guns with recoil effects, as well as 3D interactive virtual reality (VR) military training digital information content, to train students in military live firing. To evaluate the effectiveness of the proposed design, students' performance, in terms of their learning achievement and learning motivation, was examined. One hundred and sixty high school students from Taiwan were divided into four individual groups of 40 students each, with one control group and three experimental groups (EG1, EG2, and EG3). The data were analyzed by one-way analysis of variance. The results of this cost-effective 3D VR showed significantly better learning motivation, learning outcomes, and positive impacts on users' actual live firing achievement scores.
C1 [Bhagat, Kaushal Kumar; Chang, Chun-Yen] Natl Taiwan Normal Univ, Grad Inst Sci Educ, Taipei 116, Taiwan.
   [Liou, Wei-Kai; Chang, Chun-Yen] Natl Taiwan Normal Univ, Sci Educ Ctr, 88 Sect 4,Ting Chou Rd, Taipei 116, Taiwan.
   [Chang, Chun-Yen] Natl Taiwan Normal Univ, Dept Earth Sci, Taipei 116, Taiwan.
C3 National Taiwan Normal University; National Taiwan Normal University;
   National Taiwan Normal University
RP Chang, CY (corresponding author), Natl Taiwan Normal Univ, Grad Inst Sci Educ, Taipei 116, Taiwan.; Chang, CY (corresponding author), Natl Taiwan Normal Univ, Sci Educ Ctr, 88 Sect 4,Ting Chou Rd, Taipei 116, Taiwan.; Chang, CY (corresponding author), Natl Taiwan Normal Univ, Dept Earth Sci, Taipei 116, Taiwan.
EM changcy@ntnu.edu.tw
RI Bhagat, Kaushal Kumar/I-6471-2019; Chang, Chun-Yen/B-1307-2008
OI Bhagat, Kaushal Kumar/0000-0002-6861-6819; Chang,
   Chun-Yen/0000-0003-2373-2004; Liou, Wei-Kai/0009-0006-0684-8573
FU "Aim for the Top University Project" of National Taiwan Normal
   University (NTNU); Ministry of Education, Taiwan, R.O.C.; "International
   Research-Intensive Center of Excellence Program" of NTNU; National
   Science Council, Taiwan, R.O.C. [NSC 103-2911-I-003-301]
FX This research is parti2ally supported by the "Aim for the Top University
   Project" of National Taiwan Normal University (NTNU), sponsored by the
   Ministry of Education, Taiwan, R.O.C. and the "International
   Research-Intensive Center of Excellence Program" of NTNU, and National
   Science Council, Taiwan, R.O.C. under Grant No. NSC 103-2911-I-003-301.
CR [Anonymous], 2013, National Post
   Cohen J., 1988, STAT POWER ANAL BEHA
   Defense USDO, 2013, US ARM RANG HDB
   Garris R., 2002, Simulation & Gaming, V33, P441, DOI 10.1177/1046878102238607
   Hagman JD, 2000, BASIC RIFLE MARKSMAN
   Hsu J, 2010, US MILITARY VIDEO GA
   Huizenga J, 2009, J COMPUT ASSIST LEAR, V25, P332, DOI [10.1111/J.1365-2729.2009.00316.x, 10.1111/j.1365-2729.2009.00316.x]
   Hummel HGK, 2011, BRIT J EDUC TECHNOL, V42, P1029, DOI 10.1111/j.1467-8535.2010.01122.x
   Hung CY, 2014, IEEE T LEARN TECHNOL, V7, P31, DOI 10.1109/TLT.2013.2294806
   Hwang GJ, 2012, BRIT J EDUC TECHNOL, V43, pE6, DOI 10.1111/j.1467-8535.2011.01242.x
   Kebritchi M, 2010, COMPUT EDUC, V55, P427, DOI 10.1016/j.compedu.2010.02.007
   Kennedy H., 1999, Simulation reshaping military training
   Ku O, 2014, EDUC TECHNOL SOC, V17, P65
   Lim C. W., 2013, ADV SCI TECHNOLOGY L, V39, P73
   Lim CP, 2008, COMPUT EDUC, V51, P1073, DOI 10.1016/j.compedu.2007.10.005
   Liou W-K, 2012, 2012 IEEE 4 INT C DI
   Marsh T, 2011, ENTERTAIN COMPUT, V2, P61, DOI 10.1016/j.entcom.2010.12.004
   Miller LM, 2011, COMPUT EDUC, V57, P1425, DOI 10.1016/j.compedu.2011.01.016
   Papastergiou M, 2009, COMPUT EDUC, V52, P1, DOI 10.1016/j.compedu.2008.06.004
   Sánchez J, 2011, COMPUT EDUC, V57, P1943, DOI 10.1016/j.compedu.2011.04.012
   Sung HY, 2015, COMPUT EDUC, V82, P179, DOI 10.1016/j.compedu.2014.11.012
   Sung HY, 2013, COMPUT EDUC, V63, P43, DOI 10.1016/j.compedu.2012.11.019
   Szondy D, 2014, US ARMY EXAMINING NE
   van der Spek ED, 2011, BRIT J EDUC TECHNOL, V42, P441, DOI 10.1111/j.1467-8535.2009.01021.x
   Vogel D., 2004, WORLD C ED MULT HYP
   Wang LC, 2010, INNOV EDUC TEACH INT, V47, P39, DOI 10.1080/14703290903525838
   Whitney SJ, 2014, J DEF MODEL SIMUL-AP, V11, P319, DOI 10.1177/1548512912472773
   Wijers M., 2008, P EUR C GAM BAS LEAR
NR 28
TC 107
Z9 120
U1 8
U2 161
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2016
VL 20
IS 2
BP 127
EP 140
DI 10.1007/s10055-016-0284-x
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1GA
UT WOS:000376092200003
DA 2024-07-18
ER

PT J
AU Ammi, M
   Katz, BFG
AF Ammi, Mehdi
   Katz, Brian F. G.
TI Intermodal audio-haptic intermodal display: improvement of communication
   and interpersonal awareness for collaborative search tasks
SO VIRTUAL REALITY
LA English
DT Article
DE Audio-haptic interaction; Collaborative virtual environment;
   Sonification; Search of targets
ID ENVIRONMENT; TOUCH
AB This paper studies a new sensorial approach to improving communication between partners during collaborative tasks taking place in abstract and non-visual virtual reality environments. The sensorial approach was investigated in the context of the search and identification of targets in a simplified 2D environment. It consists in finding a spatial configuration corresponding to a defined criterion such as a maximum, minimum, or defined score. During the collaborative search, users need to be aware of their results and also the results of their partners. In addition, they need to compare examined scores (e.g., docking score or physical value) with other results to make decisions. To support these features, an audio-haptic display was developed employing binaural audio with an inter-modal stimuli synthesis design to improve the collaborative search. This rendering tool allows for simultaneous use of the audio and haptic channels which enables an efficient individual search and comparison of results. In addition, it improves the communication and activity coordination between the partners. An experiment was carried out to evaluate the contribution of the tool to improve the collaborative search of targets in a 2D non-visual environment. The results clearly show a significant improvement in performance and working efficiency with the audio-haptic display as compared to a traditional haptic-only condition. Moreover, we observed a reduction in the need for verbal communication during some steps of the search process. However, this approach introduces some communication conflicts during the steps presenting high-level interactions between partners which reduce the working efficiency of some groups.
C1 [Ammi, Mehdi] Univ Paris 11, CNRS, LIMSI, F-91405 Orsay, France.
   [Katz, Brian F. G.] CNRS, LIMSI, F-91405 Orsay, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); Universite
   Paris Saclay
RP Ammi, M (corresponding author), Univ Paris 11, CNRS, LIMSI, F-91405 Orsay, France.
EM mehdi.ammi@limsi.fr; brian.katz@limsi.fr
RI Katz, Brian F.G./I-3191-2012
OI Katz, Brian F.G./0000-0001-5118-0943
CR Alhalabi MO, 2003, COMPUT GRAPH-UK, V27, P205, DOI 10.1016/S0097-8493(02)00277-7
   Ammi M., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P307, DOI 10.1109/HAPTIC.2012.6183807
   Ammi M., 2011, 2011 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2011), P74, DOI 10.1109/HAVE.2011.6088395
   Ammi M, 2007, IEEE INT CONF ROBOT, P454, DOI 10.1109/ROBOT.2007.363828
   Ammi M, 2014, INT J HUM-COMPUT INT, V30, P921, DOI 10.1080/10447318.2014.941277
   [Anonymous], 2000, SITUATION AWARENESS, DOI DOI 10.1201/B12461
   [Anonymous], 1986, SOCIAL FDN THOUGHT A
   [Anonymous], 1996, COGNITION WILD
   [Anonymous], 2008, P 14 M INT C AUD DIS
   Bailenson JN, 2008, MULTIMED TOOLS APPL, V37, P5, DOI 10.1007/s11042-007-0171-2
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Begault DurandR., 1994, 3-D sound for virtual reality and multimedia
   BLY SA, 1993, COMMUN ACM, V36, P28, DOI 10.1145/151233.151235
   Bruseberg A, 2001, TECHNICAL REPORT
   Carroll JM, 2003, INT J HUM-COMPUT ST, V58, P605, DOI 10.1016/S1071-5819(03)00024-7
   Catlin T., 1989, SIGCHI Bulletin, P365
   Chan A, 2008, INT J HUM-COMPUT ST, V66, P333, DOI 10.1016/j.ijhcs.2007.11.002
   Chastine J. W., 2008, P GRAPHICS INTERFACE, P275
   Cockburn A, 1999, INT J HUM-COMPUT INT, V11, P231, DOI 10.1207/S15327590IJHC1103_3
   Codella C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P329, DOI 10.1145/142750.142825
   Cornuet N, 2009, THESIS CNRS LIMI
   Cycling '74, 2010, MAX MSP
   Dix A., 1997, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V6, P135, DOI 10.1023/A:1008635907287
   Fassò A, 2009, ENVIRON MODELL SOFTW, V24, P1027, DOI 10.1016/j.envsoft.2009.02.009
   Fraser M., 1999, 99 UIST. Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, P27, DOI 10.1145/320719.322580
   Gibson J. J., 1966, The ecological approach to visual perception
   Glynn S.J., 2001, P HUMAN FACTORS ERGO, V45, P1911
   Gutwin C., 1999, ACM Transactions on Computer-Human Interaction, V6, P243, DOI 10.1145/329693.329696
   Gutwin C, 1996, Proceedings of Human Factors in Computing Systems (CHI), P208
   Hertenstein MJ, 2006, EMOTION, V6, P528, DOI 10.1037/1528-3542.6.3.528
   Hill J., 2003, P 2003 INT ACM SIGGR, P258, DOI DOI 10.1145/958160.958201
   Idrus Zainura, 2010, WSEAS Transactions on Computers, V9, P644
   Jensen N, 2007, BUILDING COLLABORATI
   Katz B.F.G., 2010, LIMSI SPATIALISATION
   Kiyokawa K, 1998, P SOC PHOTO-OPT INS, V3517, P2, DOI 10.1117/12.326923
   Lidal EM, 2007, IEEE COMPUT GRAPH, V27, P94, DOI 10.1109/MCG.2007.141
   McGookin David, 2006, P 12 INT C AUDITORY, P91
   Menelas BAJ, 2014, J MULTIMODAL USER IN, V8, P243, DOI 10.1007/s12193-014-0148-1
   Negron APP, 2009, WORKSH INT INN SUPP, P19
   Oliveira JC, 2000, COLLABORATIVE VIRTUA
   Parseihian G, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00269
   Parseihian G, 2012, J AUDIO ENG SOC, V60, P409
   Pellerin R, 2009, C INT NOUV TECHN REP
   Picinali L., 2012, 2012 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2012), P19, DOI 10.1109/HAVE.2012.6374432
   Picinali Lorenzo, 2012, Haptic and Audio Interaction Design. Proceedings 7th International Conference, HAID 2012, P131, DOI 10.1007/978-3-642-32796-4_14
   Sallnas E.-L., 2000, ACM Transactions on Computer-Human Interaction, V7, P461, DOI 10.1145/365058.365086
   Sanchez J., P CHI 03 HUM FACT CO, P798, DOI [10.1145/765891.765998, DOI 10.1145/765891.765998]
   Schonstein D, 2008, ACOUSTICS 08, V123, P1
   Simard J, 2010, P JOINT VIRT REAL C
   Simard J, 2010, EGVE EUROVR VEC, P43
   Swapp D, 2006, VIRTUAL REAL, V10, P24, DOI [DOI 10.1007/S10055-006-0027-5, DOI 10.1007/s10055-006-0027-5]
   Victor B, 2004, SOUND MOBILE UBIQUIT, P1
   Ying HY, 2007, INT J HUM-COMPUT ST
NR 53
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 235
EP 252
DI 10.1007/s10055-015-0273-5
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800008
DA 2024-07-18
ER

PT J
AU Liu, SG
   Yu, ZJ
AF Liu, Shiguang
   Yu, Zhuojun
TI Sounding fire for immersive virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Fire sound; Physically based simulation; GPU; Immersive virtual reality
ID INTERPOLATION; NOISE
AB Both visual information and sound are required in immersive virtual reality. This paper proposes a computational method for fast synthesis of plausible fire sound that is synchronized with physically based fire animations. We divide fire sound into two parts: low frequency and mid-to high frequency, and use two processes to separately synthesize these two parts. By simplifying calculations using a novel combustion sound model as well as leveraging GPU parallel computing in a marching-cube-like manner, our method speeds up the computation of low-frequency part by an order of magnitude. To run the time-stepping fire simulation at a relative low frequency rather than the audio rate, we add synchronized mid-and high-frequency wavelet details to low-frequency simulation contents with a post-process to generate complete fire sound. We validated our method with various experiments to build a solid physically based basis for real-time acoustic rendering that can be used for immersive virtual reality scenarios.
C1 [Liu, Shiguang; Yu, Zhuojun] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Liu, Shiguang] Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM shgliu@126.com
FU Natural Science Foundation of China [61170118, 60803047]; Application
   Foundation Research Plan Project of Tianjin [14JCQNJC00100]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments. This work was supported by the Natural Science
   Foundation of China under grant nos. 61170118 and 60803047, and the
   Application Foundation Research Plan Project of Tianjin under grant no.
   14JCQNJC00100.
CR ABUGOV DI, 1978, COMBUST EXPLO SHOCK+, V14, P606, DOI 10.1007/BF00789719
   [Anonymous], 1992, Modern Methods in Analytical Acoustics Lecture Notes
   Chadwick JN, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964979
   COENEN AJRM, 1992, ELECTRON LETT, V28, P1787, DOI 10.1049/el:19921139
   Cook RL, 2005, ACM T GRAPHIC, V24, P803, DOI 10.1145/1073204.1073264
   Dobashi Y, 2004, COMPUT GRAPH FORUM, V23, P539, DOI 10.1111/j.1467-8659.2004.00785.x
   Dobashi Y, 2003, ACM T GRAPHIC, V22, P732, DOI 10.1145/882262.882339
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Ihme M, 2009, P COMBUST INST, V32, P1545, DOI 10.1016/j.proci.2008.06.137
   Imura M, 2007, P SIGGRAPH
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Liu Shiguang., 2012, Transactions on Edutainment VII, volume 7145 of Lecture Notes in Computer Science, V7145, P110
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Marelli D, 2010, IEEE T AUDIO SPEECH, V18, P399
   Mitchell D. P., 1988, Computer Graphics, V22, P221, DOI 10.1145/378456.378514
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   O'Brien JF, 2001, COMP GRAPH, P529, DOI 10.1145/383259.383321
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Ren ZM, 2010, P IEEE VIRT REAL ANN, P139, DOI 10.1109/VR.2010.5444799
   Roads C., 2004, Microsound
   SERRA X, 1990, COMPUT MUSIC J, V14, P12, DOI 10.2307/3680788
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Stone R, 2009, VIRTUAL REAL-LONDON, V13, P3, DOI 10.1007/s10055-008-0110-1
   van den Doel K, 2001, COMP GRAPH, P537, DOI 10.1145/383259.383322
   Wang J, 2011, P ACM EUR S COMP AN
   Watt A., 2000, Virtual Reality, V5, P185, DOI 10.1007/BF01408517
   Zheng CX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531343
NR 29
TC 8
Z9 10
U1 2
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 291
EP 302
DI 10.1007/s10055-015-0271-7
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800012
DA 2024-07-18
ER

EF