FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Makarov, I
   Thors, SSS
   Ævarsson, EA
   Jörgensson, FKP
   Yeganeh, N
   Kristjánsson, A
   Unnthorsson, R
AF Makarov, Ivan
   Thors, Snorri Steinn Stefansson
   Aevarsson, Elvar Atli
   Jorgensson, Finnur Kari Pind
   Yeganeh, Nashmin
   Kristjansson, Arni
   Unnthorsson, Runar
TI The Haptic Intensity Order Illusion Is Caused by Amplitude Changes
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Intensity order illusion; tactile illusion; tactile attention
ID SENSORY-SUBSTITUTION; MECHANORECEPTIVE AFFERENTS; TACTILE
   DISCRIMINATION; CUTANEOUS RABBIT; MULLER-LYER; TOUCH; INFORMATION;
   MECHANISMS; ATTENTION; ROUGHNESS
AB When two brief vibrotactile stimulations are sequentially applied to observers' lower back, there is systematic mislocalization of the stimulation: if the second stimulation is of higher intensity than the first one, observers tend to respond that the second stimulation was above the first one, and vice versa when weak intensity stimulation follows a strong one. This haptic mislocalization effect has been called the intensity order illusion. In the original demonstration of the illusion, frequency and amplitude of the stimulation were inextricably linked so that changes in amplitude also resulted in changes in frequency. It is therefore unknown whether the illusion is caused by changes in frequency, amplitude or both. To test this, we performed a multifactorial experiment, where we used L5 actuators that allow independent manipulation of frequency and amplitude. This approach enabled us to investigate the effects of stimulus amplitude, frequency and location, and to assess any potential interactions among these factors. We report four main findings: (1) we were able to replicate the intensity order illusion with the L5 tactors; (2) the illusionmainly occurred in the upwards direction, or in other words, when strong stimulation following a weaker one occurred above or in the same location as the first stimulation; (3) the illusion did not occur when similar stimulation patterns were applied in the horizontal direction; and (4) the illusion was solely due to changes in amplitude, whereas changes in frequency (100 Hz vs 200 Hz) had no effect.
C1 [Makarov, Ivan; Thors, Snorri Steinn Stefansson; Aevarsson, Elvar Atli; Jorgensson, Finnur Kari Pind; Yeganeh, Nashmin; Unnthorsson, Runar] Univ Iceland, Fac Ind Engn Mech Engn & Comp Sci, Saemundargata 12, IS-102 Reykjavik, Iceland.
   [Makarov, Ivan; Kristjansson, Arni] Univ Iceland, Iceland Vis Lab, Fac Psychol, Sch Hlth Sci, Reykjavik, Iceland.
C3 University of Iceland; University of Iceland
RP Makarov, I (corresponding author), Univ Iceland, Fac Ind Engn Mech Engn & Comp Sci, Saemundargata 12, IS-102 Reykjavik, Iceland.; Makarov, I (corresponding author), Univ Iceland, Iceland Vis Lab, Fac Psychol, Sch Hlth Sci, Reykjavik, Iceland.
EM ivm3@hi.is; sss55@hi.is; elvaratli@hi.is; fp@treble.tech; nay2@hi.is;
   ak@hi.is; runson@hi.is
RI ; Unnthorsson, Runar/L-1884-2013
OI Kristjansson, Arni/0000-0003-4168-4886; Makarov,
   Ivan/0000-0002-1942-1759; Unnthorsson, Runar/0000-0002-1960-0263
CR Adams WJ, 2004, NAT NEUROSCI, V7, P1057, DOI 10.1038/nn1312
   AEarsson EA, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3529259
   Alvarez GA, 2004, PSYCHOL SCI, V15, P106, DOI 10.1111/j.0963-7214.2004.01502006.x
   Anema HA, 2008, COGN NEUROPSYCHOL, V25, P951, DOI 10.1080/02643290802041323
   APKARIANSTIELAU P, 1975, PERCEPT PSYCHOPHYS, V18, P362, DOI 10.3758/BF03211213
   ASH P, 1951, PSYCHOL BULL, V48, P289, DOI 10.1037/h0057773
   Bach-y-Rita P, 2003, TRENDS COGN SCI, V7, P541, DOI 10.1016/j.tics.2003.10.013
   Blankenburg F, 2006, PLOS BIOL, V4, P459, DOI 10.1371/journal.pbio.0040069
   BOLANOWSKI SJ, 1994, SOMATOSENS MOT RES, V11, P279, DOI 10.3109/08990229409051395
   BROADBENT DE, 1958, J ACOUST SOC AM, V30, P824, DOI 10.1121/1.1909779
   Brown DJ, 2014, MULTISENS RES, V27, P337, DOI 10.1163/22134808-00002462
   Brunyé TT, 2012, COGNITIVE SCI, V36, P1449, DOI 10.1111/j.1551-6709.2012.01268.x
   Carter O, 2008, CURR BIOL, V18, P1050, DOI 10.1016/j.cub.2008.06.027
   Cholewiak R. W., 2001, P 2001 EUROHAPTICS C
   Cholewiak RW, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P413
   Cholewiak RW, 1999, PERCEPTION, V28, P851, DOI 10.1068/p2873
   Cohen MA, 2016, TRENDS COGN SCI, V20, P324, DOI 10.1016/j.tics.2016.03.006
   CONNOR CE, 1992, J NEUROSCI, V12, P3414
   DAY RH, 1990, PERCEPT PSYCHOPHYS, V48, P375, DOI 10.3758/BF03206690
   Driver J, 2001, BRIT J PSYCHOL, V92, P53, DOI 10.1348/000712601162103
   Evans KK, 2010, J VISION, V10, DOI 10.1167/10.1.6
   Fitt ARB, 1917, J EXP PSYCHOL, V2, P264, DOI 10.1037/h0073891
   Flach R, 2006, J EXP PSYCHOL HUMAN, V32, P717, DOI 10.1037/0096-1523.32.3.717
   Frings C, 2008, PERCEPT PSYCHOPHYS, V70, P516, DOI 10.3758/PP.70.3.516
   Gallace A, 2006, PSYCHON B REV, V13, P300, DOI 10.3758/BF03193847
   Gardner E. P., 2013, Principles of Neural Science, V5th, P385
   GARDNER EP, 1972, J NEUROPHYSIOL, V35, P925, DOI 10.1152/jn.1972.35.6.925
   GELDARD FA, 1972, SCIENCE, V178, P178, DOI 10.1126/science.178.4057.178
   Gentaz E, 2004, PSYCHON B REV, V11, P31, DOI 10.3758/BF03206457
   Gibson GO, 2005, PERCEPT PSYCHOPHYS, V67, P1061, DOI 10.3758/BF03193632
   Goldreich D, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000333
   Goudge ME, 1918, AM J PSYCHOL, V29, P81, DOI 10.2307/1414107
   Gregory R. L., 1970, The Intelligent Eye
   Hayward V., 2015, Tactile illusions
   Hoffmann R, 2019, J NEUROPHYSIOL, V122, P1810, DOI 10.1152/jn.00125.2019
   Hoffmann R, 2018, EXP BRAIN RES, V236, P3405, DOI 10.1007/s00221-018-5387-z
   Hoffmann Rebekka, 2018, P 2 INT C COMP HUM I, P45, DOI [10.5220/0006899700450053, DOI 10.5220/0006899700450053]
   Howell J, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P673, DOI 10.1109/WHC.2013.6548489
   Jamal Y, 2017, MULTISENS RES, V30, P287, DOI 10.1163/22134808-00002553
   Jóhannesson OI, 2017, EXP BRAIN RES, V235, P3505, DOI 10.1007/s00221-017-5073-6
   Jóhannesson OI, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6030020
   Johnson KO, 2000, J CLIN NEUROPHYSIOL, V17, P539, DOI 10.1097/00004691-200011000-00002
   Jones LA, 2008, HUM FACTORS, V50, P90, DOI 10.1518/001872008X250638
   Kassambara A, 2021, rstatix: Pipe-friendly framework for basic statistical tests
   Knill D. C., 1996, Perception as Bayesian Inference
   KOKJER KJ, 1987, IEEE T SYST MAN CYB, V17, P100, DOI 10.1109/TSMC.1987.289337
   Kristjansson A, 2006, VIS COGN, V13, P324, DOI 10.1080/13506280544000039
   Kristjánsson A, 2023, PSYCHON B REV, V30, P22, DOI 10.3758/s13423-022-02125-w
   Kristjansson A, 2020, ATTEN PERCEPT PSYCHO, V82, P7, DOI 10.3758/s13414-019-01803-7
   Kristjánsson A, 2019, CURR OPIN PSYCHOL, V29, P71, DOI 10.1016/j.copsyc.2018.11.013
   Kristjánsson A, 2016, RESTOR NEUROL NEUROS, V34, P769, DOI 10.3233/RNN-160647
   Lawrence Michael A, 2016, CRAN
   LECHELT EC, 1977, B PSYCHONOMIC SOC, V10, P191
   LECHELT EC, 1988, PERCEPTION, V17, P579, DOI 10.1068/p170579
   Lederman SJ, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P97, DOI 10.1109/HAPTIC.2002.998946
   Lederman SJ, 2011, IEEE T HAPTICS, V4, P273, DOI 10.1109/ToH.2011.2
   Lofelt GmbH Datasheet, 2019, Revision 1.4 (2019) L5 Voice Coil Actuator
   LUCK SJ, 1989, NATURE, V342, P543, DOI 10.1038/342543a0
   Mahns DA, 2006, J NEUROPHYSIOL, V95, P1442, DOI 10.1152/jn.00483.2005
   Mancini F, 2014, PAIN, V155, P635, DOI 10.1016/j.pain.2013.12.024
   MARKS LE, 1974, AM J PSYCHOL, V87, P173, DOI 10.2307/1422011
   Medina S, 2018, EXP BRAIN RES, V236, P31, DOI 10.1007/s00221-017-5105-2
   Millar S, 2002, PERCEPT PSYCHOPHYS, V64, P353, DOI 10.3758/BF03194709
   Miller LE, 2016, CONSCIOUS COGN, V40, P17, DOI 10.1016/j.concog.2015.12.008
   Mortimer BJP, 2007, J ACOUST SOC AM, V121, P2970, DOI 10.1121/1.2715669
   NEISSER U, 1975, COGNITIVE PSYCHOL, V7, P480, DOI 10.1016/0010-0285(75)90019-5
   Nicula A, 2021, PERCEPTION, V50, P677, DOI 10.1177/03010066211025384
   Occelli V, 2009, NEUROREPORT, V20, P793, DOI 10.1097/WNR.0b013e32832b8069
   Pei YC, 2014, J NEUROPHYSIOL, V112, P3023, DOI 10.1152/jn.00391.2014
   Plaisier MA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74835-x
   Pratt CC, 1930, J EXP PSYCHOL, V13, P278, DOI 10.1037/h0072651
   Proulx MJ, 2016, RESTOR NEUROL NEUROS, V34, P29, DOI 10.3233/RNN-150541
   Rahal L, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P310, DOI 10.1109/VECIMS.2009.5068914
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   RStudio Team, 2023, RStudio: integrated development environment for R, DOI DOI 10.1145/3132847.3132886
   Sadibolova R, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00055
   SCHMIDT JM, 1981, PSYCHOL RES-PSYCH FO, V43, P293, DOI 10.1007/BF00308453
   SHERRICK CE, 1966, PERCEPT PSYCHOPHYS, V1, P175, DOI 10.3758/BF03210054
   Sofia KO, 2013, IEEE T HAPTICS, V6, P320, DOI 10.1109/TOH.2013.1
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Suto Y., 1952, Japanese Journal of Psychology, V22, P45
   SUZUKI K, 1992, PERCEPT PSYCHOPHYS, V52, P329, DOI 10.3758/BF03209149
   Tanriulu ÖD, 2021, COGNITION, V217, DOI 10.1016/j.cognition.2021.104903
   Taylor-Clarke M, 2004, NAT NEUROSCI, V7, P219, DOI 10.1038/nn1199
   Trojan Jorg, 2017, The Cutaneous Rabbit Effect: Phenomenology and Saltation
   Van Erp JBF, 2005, ERGONOMICS, V48, P302, DOI 10.1080/0014013042000327670
   Weber E.H., 1996, EH WEBER TACTILE SEN
   WEINSTEIN SIDNEY, 1968, P195
   Wheat HE, 2000, J NEUROPHYSIOL, V84, P1430, DOI 10.1152/jn.2000.84.3.1430
   Wickham H., 2019, J Open Source Softw, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/JOSS.01686]
   WONG TS, 1974, J EXP PSYCHOL, V103, P414, DOI 10.1037/h0037137
   Wurtz RH., 2000, Principles of Neural Science, V4th, P532
   Yoshioka T, 2001, J NEUROSCI, V21, P6905, DOI 10.1523/JNEUROSCI.21-17-06905.2001
   Ziat M, 2014, IEEE HAPTICS SYM, P581, DOI 10.1109/HAPTICS.2014.6775520
NR 95
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD JAN
PY 2024
VL 21
IS 1
AR 4
DI 10.1145/3626237
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS3W1
UT WOS:001168291400004
DA 2024-08-05
ER

PT J
AU Bartlett, KA
   Palacios-Ibáñez, A
   Camba, JD
AF Bartlett, Kristin A.
   Palacios-Ibanez, Almudena
   Camba, Jorge Dorribo
TI Design and Validation of a Virtual Reality Mental Rotation Test
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Spatial ability; mental rotation; virtual reality; visual perception;
   MRT; PSVT:R
ID SEX-DIFFERENCES; GENDER-DIFFERENCES; 3-DIMENSIONAL OBJECTS; SPATIAL
   SKILLS; ABILITY; METAANALYSIS; MAGNITUDE; STUDENTS
AB Mental rotation, a common measure of spatial ability, has traditionally been assessed through paper-based instruments like the Mental Rotation Test (MRT) or the Purdue Spatial Visualization Test: Rotations (PSVT:R). The fact that these instruments present 3D shapes in a 2D format devoid of natural cues like shading and perspective likely limits their ability to accurately assess the fundamental skill of mentally rotating 3D shapes. In this paper, we describe the Virtual Reality Mental Rotation Assessment (VRMRA), a virtual reality-based mental rotation assessment derived from the Revised PSVT:R and MRT. The VRMRA reimagines traditional mental rotation assessments in a room-scale virtual environment and uses hand-tracking and elements of gamification in attempts to create an intuitive, engaging experience for test-takers. To validate the instrument, we compared response patterns in the VRMRA with patterns observed on the MRT and Revised PSVT:R. For the PSVT:Rtype questions, items requiring a rotation around two axes were significantly harder than items requiring rotations around a single axis in the VRMRA, which is not the case in the Revised PSVT:R. For the MRT-type questions in the VRMRA, a moderate negative correlation was found between the degree of rotation in the X direction and item difficulty. While the problem of occlusion was reduced, features of the shapes and distractors accounted for 50.6% of the variance in item difficulty. Results suggest that the VRMRA is likely a more accurate tool to assess mental rotation ability in comparison to traditional instruments which present the stimuli through 2D media. Our findings also point to potential problems with the fundamental designs of the Revised PSVT:R and MRT question formats.
C1 [Bartlett, Kristin A.] Univ Kentucky, Pence Hall,175 Funkhouser Dr, Lexington, KY 40506 USA.
   [Palacios-Ibanez, Almudena] Univ Politecn Valencia, Camino Vera S-N, Valencia 46066, Spain.
   [Camba, Jorge Dorribo] Purdue Univ, Knoy Hall,401 Grant St, W Lafayette, IN 47907 USA.
C3 University of Kentucky; Universitat Politecnica de Valencia; Purdue
   University System; Purdue University
RP Bartlett, KA (corresponding author), Univ Kentucky, Pence Hall,175 Funkhouser Dr, Lexington, KY 40506 USA.
EM kristibartlett@uky.edu; alpaib@doctor.upv.es; jdorribo@purdue.edu
RI Palacios-Ibáñez, Almudena/AFX-0246-2022
OI Palacios-Ibáñez, Almudena/0000-0002-1115-0720; Bartlett,
   Kristin/0000-0003-3577-8034
FU Spanish Ministry of Education and Vocational Training under an FPU
   fellowship [FPU19/03878]; Universitat Politecnica de Valencia
FX Part of this research work has been supported by the Spanish Ministry of
   Education and Vocational Training under an FPU fellowship (FPU19/03878).
   Additionally, the stay of author Almudena Palacios-Ibanez at Purdue
   University was funded by the Universitat Politecnica de Valencia (grants
   for mobility of doctoral students from the Universitat Politecnica de
   Valencia for stays in 2022).
CR González NAA, 2018, INT J INTERACT DES M, V12, P133, DOI 10.1007/s12008-017-0388-x
   [Anonymous], 1998, Visual intelligence
   Ariali S., 2020, J TECH ED, V8, P46, DOI [10.48513/joted.v8i2.207, DOI 10.48513/JOTED.V8I2.207]
   Ariali S, 2021, INT J EMERG TECHNOL, V16, P20, DOI 10.3991/ijet.v16i09.18971
   Atit K, 2020, COGN RES, V5, DOI 10.1186/s41235-020-00210-z
   Bartlett KA, 2022, LECT NOTES COMPUT SC, V13328, P30, DOI 10.1007/978-3-031-05657-4_3
   Bartlett KA, 2023, SPAT COGN COMPUT, V23, P1, DOI 10.1080/13875868.2021.2019260
   Bartlett Kristin A., 2022, ASEE C EXPOSITION P
   Bors DA, 2011, LEARN INDIVID DIFFER, V21, P129, DOI 10.1016/j.lindif.2010.09.014
   Brandoff T.J., 2000, ENG DES GRAPHIC J, V64, P14
   Caissie A.F., 2009, The Open Psychology Journal, V2, P94, DOI [10.2174/1874350100902010094, DOI 10.2174/1874350100902010094]
   Chang CW, 2018, IEEE ACCESS, V6, P66590, DOI 10.1109/ACCESS.2018.2878270
   Chang JSK, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P681, DOI 10.1145/3024969.3025033
   Chang JSK, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P68, DOI 10.1145/3131277.3132171
   Chen Q, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P290, DOI 10.1109/VRW55335.2022.00067
   Doyle RA, 2013, Q J EXP PSYCHOL, V66, P801, DOI 10.1080/17470218.2012.719529
   Eliot J., 1983, INT DIRECTORY SPATIA
   Felix MC, 2011, PERCEPT MOTOR SKILL, V113, P38, DOI 10.2466/03.22.PMS.113.4.38-50
   Fisher ML, 2018, EVOL PSYCHOL SCI, V4, P124, DOI 10.1007/s40806-017-0120-x
   Gorska R., 2008, 2008 ASEE ANN C EXPO, V13, p1196.1, DOI [DOI 10.18260/1-2--4411, 10.18260/1-2-4411, DOI 10.18260/1-2-4411]
   Guay R.B., 1976, PURDUE SPATIAL VISUA
   Guzsvinecz T, 2022, VIRTUAL REAL-LONDON, V26, P601, DOI 10.1007/s10055-021-00509-2
   Guzsvinecz T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020526
   Guzsvinecz T, 2020, ACTA POLYTECH HUNG, V17, P35, DOI 10.12700/APH.17.2.2020.2.3
   Hartman N.W., 2006, ACM SIGGRAPH 2006 ED, P46, DOI DOI 10.1145/1179295.1179342
   Hegarty M., 2005, The Cambridge handbook of visuospatial thinking, V1st Ed., P121, DOI [10.1017/CBO9780511610448.005, DOI 10.1017/CBO9780511610448.005]
   Hegarty M, 2018, PSYCHON B REV, V25, P1212, DOI 10.3758/s13423-017-1347-z
   Hong JC, 2018, PR IEEE INT CONF TEA, P1204, DOI 10.1109/TALE.2018.8615333
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Jianping Yue, 2008, Engineering Design Graphics Journal, V72, P28
   Kaufmann H., 2008, P INT C GEOMETRY GRA
   Kim Jeffrey, 2021, International Journal of Construction Education and Research, P99, DOI 10.1080/15578771.2020.1717680
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Larson P, 1999, Cyberpsychol Behav, V2, P113, DOI 10.1089/cpb.1999.2.113
   Lin PH, 2019, INT J HUM-COMPUT INT, V35, P1736, DOI 10.1080/10447318.2019.1571784
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.2307/1130467
   Lou XL, 2021, VIRTUAL REAL-LONDON, V25, P367, DOI 10.1007/s10055-020-00461-7
   Maeda Y, 2013, INT J ENG EDUC, V29, P763
   Maeda Y, 2013, EDUC PSYCHOL REV, V25, P69, DOI 10.1007/s10648-012-9215-x
   Martín-Gutiérrez J, 2010, COMPUT GRAPH-UK, V34, P77, DOI 10.1016/j.cag.2009.11.003
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   McWilliams W, 1997, PERCEPT MOTOR SKILL, V85, P297, DOI 10.2466/pms.1997.85.1.297
   MESSICK S, 1995, AM PSYCHOL, V50, P741, DOI 10.1037/0003-066X.50.9.741
   Molina-Carmona R, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041074
   Mon-Williams M., 1995, Journal of the Society for Information Display, V3, P207, DOI 10.1889/1.1984970
   Neubauer AC, 2010, INTELLIGENCE, V38, P529, DOI 10.1016/j.intell.2010.06.001
   Nolte N, 2022, INTELLIGENCE, V91, DOI 10.1016/j.intell.2022.101626
   Palacios-Ibáñez A, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4055952
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   Pastel S, 2022, VIRTUAL REAL-LONDON, V26, P91, DOI 10.1007/s10055-021-00539-w
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Pizlo Z, 2008, 3D SHAPE: ITS UNIQUE PLACE IN VISUAL PERCEPTION, pIX
   Pizlo Z, 2008, SPATIAL VISION, V21, P495, DOI 10.1163/156856808786451453
   Pollard KA, 2020, VIRTUAL REAL-LONDON, V24, P783, DOI 10.1007/s10055-019-00411-y
   Rizzo Albert A., 1998, Cyberpsychol. Behav., V1, P8
   Robert M, 2003, MEM COGNITION, V31, P1136, DOI 10.3758/BF03196134
   Sanandaji A, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119888
   Sarilita Erli, 2022, Korean J Med Educ, V34, P309, DOI 10.3946/kjme.2022.239
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Sorby S, 2018, LEARN INDIVID DIFFER, V67, P209, DOI 10.1016/j.lindif.2018.09.001
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stieff M, 2018, J EDUC PSYCHOL, V110, P1160, DOI 10.1037/edu0000258
   Takahashi George, 2012, 67 EDGD MIDYEAR M P, P26
   Toth AJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56041-6
   Toth Robert, 2020, Gamified Mental Cutting Test for enhancing spatial skills
   Tsutsumi E, 2008, J GEOM GRAPH, V12, P109
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   VOYER D, 1995, PSYCHOL BULL, V117, P250, DOI 10.1037/0033-2909.117.2.250
   Voyer D, 2006, CAN J EXP PSYCHOL, V60, P91, DOI 10.1037/cjep2006010
   Yoon S. Y., 2011, Revised Purdue Spatial Visualization Test: Visualization of Rotations (Revised PSVT:R) Psychometric Instrument
   Yoon S. Y., 2011, Psychometric Properties of the Revised Purdue Spatial Visualization Tests: Visualization of Rotations (The Revised PSVT: R)
   Yue Jianping, 2006, P 2006 IJME
NR 72
TC 0
Z9 0
U1 5
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD APR
PY 2024
VL 21
IS 2
AR 5
DI 10.1145/3626238
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ3G6
UT WOS:001208695200001
OA Bronze
DA 2024-08-05
ER

PT J
AU Mallick, S
   Jeckeln, G
   Parde, CJ
   Castillo, CD
   O'toole, AJ
AF Mallick, Snipta
   Jeckeln, Geraldine
   Parde, Connor J.
   Castillo, Carlos D.
   O'toole, Alice J.
TI The Influence of the Other-Race Effect on Susceptibility to Face
   Morphing Attacks
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Face morphing; face identification; face matching; deep convolutional
   neural network; other-race effect
ID OWN-RACE; RECOGNITION; BIAS
AB Facial morphs created between two identities resemble both of the faces used to create the morph. Consequently, humans and machines are prone to mistake morphs made from two identities for either of the faces used to create the morph. This vulnerability has been exploited in "morph attacks" in security scenarios. Here, we asked whether the "other-race effect" (ORE)-the human advantage for identifying own- vs. other-race faces-exacerbates morph attack susceptibility for humans. We also asked whether face-identification performance in a deep convolutional neural network (DCNN) is affected by the race of morphed faces. Caucasian (CA) and East-Asian (EA) participants performed a face-identity matching task on pairs of CA and EA face images in two conditions. In the morph condition, different-identity pairs consisted of an image of identity "A" and a 50/50 morph between images of identity "A" and "B". In the baseline condition, morphs of different identities never appeared. As expected, morphs were identified mistakenly more often than original face images. Of primary interest, morph identification was substantially worse for cross-race faces than for own-race faces. Similar to humans, the DCNN performed more accurately for original face images than for morphed image pairs. Notably, the deep network proved substantially more accurate than humans in both cases. The results point to the possibility that DCNNs might be useful for improving face identification accuracy when morphed faces are presented. They also indicate the significance of the race of a face in morph attack susceptibility in applied settings.
C1 [Mallick, Snipta; Jeckeln, Geraldine; Parde, Connor J.; O'toole, Alice J.] Univ Texas Dallas, Sch Behav & Brain Sci, Richardson, TX 75083 USA.
   [Castillo, Carlos D.] Johns Hopkins Univ, Whiting Sch Engn, Baltimore, MD USA.
C3 University of Texas System; University of Texas Dallas; Johns Hopkins
   University
RP Mallick, S (corresponding author), Univ Texas Dallas, Sch Behav & Brain Sci, Richardson, TX 75083 USA.
EM mallicksnip@gmail.com; geraldinejeckeln@utdallas.edu;
   connor.parde@utdallas.edu; carlosdc@jhu.edu; otoole@utdallas.edu
OI O'Toole, Alice/0000-0001-7981-1508; Mallick, Snipta/0000-0001-8635-2354
FU National Eye Institute [R01EY029692-04]
FX Funding provided by National Eye Institute Grant R01EY029692-04 to AOT
   and CDC..
CR Bansal A, 2018, IEEE COMPUT SOC CONF, P10, DOI 10.1109/CVPRW.2018.00009
   Bansal A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P456
   Bansal A, 2017, IEEE INT CONF COMP V, P2545, DOI 10.1109/ICCVW.2017.299
   Cavazos Jacqueline G, 2021, IEEE Trans Biom Behav Identity Sci, V3, P101, DOI 10.1109/TBIOM.2020.3027269
   CHIRORO P, 1995, Q J EXP PSYCHOL-A, V48, P879, DOI 10.1080/14640749508401421
   Drozdowski Pawel, 2020, IEEE Transactions on Technology and Society, V1, P89, DOI 10.1109/TTS.2020.2992344
   Ferrara M., 2014, P IEEE INT JOINT C B, P1
   Frontex, 2015, Best practice technical guidelines for automated border control (ABC) systems
   github, Alyssa Quek and Face Morpher
   Grother Patrick, 2019, 8280 NISTIR
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Klare BF, 2012, IEEE T INF FOREN SEC, V7, P1789, DOI 10.1109/TIFS.2012.2214212
   Kramer RSS, 2019, PERCEPTION, V48, P175, DOI 10.1177/0301006619826495
   Lin WA, 2017, Arxiv, DOI arXiv:1703.04835
   Macmillan N. A., 2004, Detection theory: A user's guide, V2nd ed., DOI DOI 10.4324/9781410611147
   MALPASS RS, 1969, J PERS SOC PSYCHOL, V13, P330, DOI 10.1037/h0028434
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3
   Mousavi SM, 2020, VIS COGN, V28, P523, DOI 10.1080/13506285.2020.1836696
   Nightingale SJ, 2021, J VISION, V21, DOI 10.1167/jov.21.3.4
   Parkhi O. M., 2015, P BRIT MACH VIS C, p41.1
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Phillips P.J., 2018, P NATL ACAD SCI USA
   Phillips PJ, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870082
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Qualtrics, 2019, Qualtrics
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P1822, DOI 10.1109/CVPRW.2017.228
   Raghavendra R, 2016, IEEE CONF IMAGING SY, P201, DOI 10.1109/IST.2016.7738223
   Ranjan R, 2019, Arxiv, DOI arXiv:1804.01159
   Ritchie KL, 2020, BRIT J PSYCHOL, V111, P92, DOI 10.1111/bjop.12388
   Robertson DJ, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0113-8
   Robertson DJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173319
   Schrimpf M., 2020, Neuron
   Schrimpf Martin, 2018, BioRxiv, V2018
   Walker PM, 2003, PERCEPTION, V32, P1117, DOI 10.1068/p5098
   Westfall Jacob, PANGEA PANGEA: Power ANalysis for GEneral Anova designs
   Zhang Le-Bing, 2022, MSACNN: Face Morphing Detection via a Multiple Scales Attention Convolutional Neural Network, P17, DOI [10.1007/978-3-030-95398-0_2, DOI 10.1007/978-3-030-95398-0_2]
NR 38
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD JAN
PY 2024
VL 21
IS 1
AR 2
DI 10.1145/3618113
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS3W1
UT WOS:001168291400002
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, MQ
   Ding, J
   Levi, DM
   Cooper, EA
AF Wang, Minqi
   Ding, Jian
   Levi, Dennis M.
   Cooper, Emily A.
TI The Effect of Interocular Contrast Differences on the Appearance of
   Augmented Reality Imagery
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Stereoscopic displays; binocular vision
AB Augmented reality (AR) devices seek to create compelling visual experiences that merge virtual imagery with the natural world. These devices often rely on wearable near-eye display systems that can optically overlay digital images to the left and right eyes of the user separately. Ideally, the two eyes should be shown images with minimal radiometric differences (e.g., the same overall luminance, contrast, and color in both eyes), but achieving this binocular equality can be challenging in wearable systems with stringent demands on weight and size. Basic vision research has shown that a spectrum of potentially detrimental perceptual effects can be elicited by imagery with radiometric differences between the eyes, but it is not clear whether and how these findings apply to the experience of modern AR devices. In this work, we first develop a testing paradigm for assessing multiple aspects of visual appearance at once, and characterize five key perceptual factors when participants viewed stimuli with interocular contrast differences. In a second experiment, we simulate optical see-through AR imagery using conventional desktop LCD monitors and use the same paradigm to evaluate the multi-faceted perceptual implications when the AR display luminance differs between the two eyes. We also include simulations of monocular AR systems (i.e., systems in which only one eye sees the displayed image). Our results suggest that interocular contrast differences can drive several potentially detrimental perceptual effects in binocular AR systems, such as binocular luster, rivalry, and spurious depth differences. In addition, monocular AR displays tend to have more artifacts than binocular displays with a large contrast difference in the two eyes. A better understanding of the range and likelihood of these perceptual phenomena can help inform design choices that support high-quality user experiences in AR.
C1 [Wang, Minqi; Ding, Jian; Levi, Dennis M.; Cooper, Emily A.] Univ Calif Berkeley, Herbert Wertheim Sch Optometry & Vis Sci, Berkeley, CA 94720 USA.
C3 University of California System; University of California Berkeley
RP Wang, MQ (corresponding author), Univ Calif Berkeley, Herbert Wertheim Sch Optometry & Vis Sci, Berkeley, CA 94720 USA.
EM mwang67@berkeley.edu; jian.ding@berkeley.edu; dlevi@berkeley.edu;
   emilycooperp@berkeley.edu
RI Wang, Mina/AAA-7018-2021; qiufu, dai/N-9245-2015
OI Wang, Mina/0000-0002-4029-5806; Cooper, Emily/0000-0003-4889-7446; Liu,
   Lu/0000-0002-7496-5564; qiufu, dai/0000-0003-3438-8712; Zhao,
   Luopeng/0000-0002-9694-8669; Levi, Dennis/0000-0002-5350-8639; Ding,
   Jian/0000-0003-4258-1133
FU National Science Foundation [2041726]; NIH [T32EY007043]; Center for
   Innovation in Vision and Optics at University of California, Berkeley
FX This work was supported by a grant from the National Science Foundation
   (Award 2041726), an NIH training grant (T32EY007043), and a fellowship
   from the Center for Innovation in Vision and Optics at University of
   California, Berkeley.
CR Adams WJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep35805
   Baker DH, 2012, VISION RES, V56, P1, DOI 10.1016/j.visres.2012.01.008
   Blake R., 2001, Brain and Mind, V2, P5, DOI [DOI 10.1023/A:1017925416289, 10.1023/A:1017925416289]
   Cakmakci Ozan, 2019, SID Symposium Digest of Technical Papers, V50, P438, DOI 10.1002/sdtp.12950
   Campisi Patrizio, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2110
   Cao R, 2021, ELIFE, V10, DOI 10.7554/eLife.61581
   Chen ZB, 2020, IEEE J-STSP, V14, P103, DOI 10.1109/JSTSP.2020.2968182
   Cholewiak SA, 2020, OPT EXPRESS, V28, P38008, DOI 10.1364/OE.408404
   Ding J, 2006, P NATL ACAD SCI USA, V103, P1141, DOI 10.1073/pnas.0509629103
   Ding J, 2017, J VISION, V17, DOI 10.1167/17.13.4
   Ding J, 2013, J VISION, V13, DOI 10.1167/13.2.13
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Fan Y, 2017, INT CONF ACOUST SPEE, P2037, DOI 10.1109/ICASSP.2017.7952514
   Formankiewicz MA, 2009, VISION RES, V49, P1929, DOI 10.1016/j.visres.2009.05.001
   Freepik Company, 2019, Freepik Mobile App Icon Images
   MinqiWang Emily A., 2021, ACMTransactions on Graphics, V40
   Skerswetat J, 2023, CONSCIOUS COGN, V107, DOI 10.1016/j.concog.2022.103437
   Skerswetat J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32703-9
   Sprague WW, 2015, SCI ADV, V1, DOI 10.1126/sciadv.1400254
   Tong J, 2020, INT SYM MIX AUGMENT, P73, DOI [10.1109/1SMA1R50242.2020.00027, 10.1109/ISMAR50242.2020.00027]
   Wang MQ, 2022, J VISION, V22, DOI 10.1167/jov.22.12.7
   Wendt G, 2022, VISION RES, V194, DOI 10.1016/j.visres.2022.108008
   Wendt G, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519846133
   Yang X, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185589
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   Zhang LL, 2021, J OPT SOC AM A, V38, P701, DOI 10.1364/JOSAA.420395
   Zhang ZM, 2019, VISUAL COMPUT, V35, P997, DOI 10.1007/s00371-019-01669-8
   Zhang ZM, 2018, COMPUT GRAPH FORUM, V37, P433, DOI 10.1111/cgf.13580
   Zhong F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356552
NR 29
TC 2
Z9 2
U1 16
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD JAN
PY 2024
VL 21
IS 1
AR 1
DI 10.1145/3617684
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS3W1
UT WOS:001168291400001
PM 38351701
OA hybrid
DA 2024-08-05
ER

PT J
AU Ebelin, P
   Denes, G
   Akenine-Möller, T
   Aström, K
   Oskarsson, M
   Mcilhagga, WH
AF Ebelin, Pontus
   Denes, Gyorgy
   Akenine-Moller, Tomas
   Astrom, Kalle
   Oskarsson, Magnus
   Mcilhagga, William H.
TI Estimates of Temporal Edge Detection Filters in Human Vision
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Edge detection; temporal; human perception; user study
ID CONTRAST-SENSITIVITY; SPATIAL-FREQUENCY; MOTION; STATISTICS
AB Edge detection is an important process in human visual processing. However, as far as we know, few attempts have been made to map the temporal edge detection filters in human vision. To that end, we devised a user study and collected data from which we derived estimates of human temporal edge detection filters based on three different models, including the derivative of the infinite symmetric exponential function and temporal contrast sensitivity function. We analyze our findings using several different methods, including extending the filter to higher frequencies than were shown during the experiment. In addition, we show a proof of concept that our filter may be used in spatiotemporal image quality metrics by incorporating it into a flicker detection pipeline.
C1 [Ebelin, Pontus; Akenine-Moller, Tomas] NVIDIA, Scheelevagen 27, S-22363 Lund, Sweden.
   [Denes, Gyorgy] Perse Sch, Hills Rd, Cambridge CB2 8QF, England.
   [Denes, Gyorgy] Univ Cambridge, Hills Rd, Cambridge CB2 8QF, England.
   [Astrom, Kalle; Oskarsson, Magnus] Lund Univ, Ctr Math Sci, Solvegatan 18, S-22362 Lund, Sweden.
   [Mcilhagga, William H.] Univ Bradford, Optometry & Vis Sci, Richmond Rd, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Cambridge; Lund University; University of Bradford
RP Ebelin, P (corresponding author), NVIDIA, Scheelevagen 27, S-22363 Lund, Sweden.
EM pandersson@nvidia.com; gdenes@perse.co.uk; takenine@nvidia.com;
   karl.astrom@math.lth.se; magnus.oskarsson@math.lth.se;
   w.h.mcilhagga@bradford.ac.uk
RI Astrom, Kalle/C-2836-2009
OI Astrom, Kalle/0000-0002-8689-7810; Ebelin, Pontus/0000-0003-3497-2943
FU Wallenberg AI, Autonomous Systems and Software Program (WASP) - Knut and
   Alice Wallenberg Foundation; strategic research project ELLIIT
FX We thank the reviewers for their careful read-through of and
   constructive comments regarding our paper. We also thank My Andersson
   for her advice regarding the risk of epileptic seizures in an experiment
   such as ours. We are grateful to Joohwan Kim, Robert Toth, Anjul Patney,
   Rachel Brown, Andrew Russell, Bart Wronski, Jacob Munkberg, Jon
   Hasselgren, Anders Heyden, and Nikolai Hofmann for helpful discussions.
   We appreciate all the work by the participants of our user studies. This
   work was partially supported by the Wallenberg AI, Autonomous Systems
   and Software Program (WASP) funded by the Knut and Alice Wallenberg
   Foundation and the strategic research project ELLIIT.
CR ALLPORT DA, 1968, BRIT J PSYCHOL, V59, P395, DOI 10.1111/j.2044-8295.1968.tb01154.x
   Andersson P, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406183
   Åström K, 1999, ADV APPL PROBAB, V31, P855, DOI 10.1017/S0001867800009502
   Barten P. G. J., 1999, CONTRAST SENSITIVITY
   CORNSWEET TN, 1962, AM J PSYCHOL, V75, P485, DOI 10.2307/1419876
   DALY S, 1992, P SOC PHOTO-OPT INS, V1666, P2, DOI 10.1117/12.135952
   Davis J, 2015, SCI REP-UK, V5, DOI 10.1038/srep07861
   Denes Gyorgy, 2020, Ph. D. Dissertation, DOI [10.17863/CAM.54006, DOI 10.17863/CAM.54006]
   DILOLLO V, 1980, J EXP PSYCHOL GEN, V109, P75, DOI 10.1037/0096-3445.109.1.75
   DONG DW, 1995, NETWORK-COMP NEURAL, V6, P345, DOI 10.1088/0954-898X/6/3/003
   Dreyer John L. E., 1875, Proceedings of the Royal Irish Academy. Science, V2, P484
   Efron B., 1994, INTRO BOOTSTRAP, DOI 10.1201/9780429246593
   GREEN DM, 1964, PSYCHOL REV, V71, P392, DOI 10.1037/h0044520
   Huber P.J., 2009, Robust statistics, Vsecond
   Jäkel F, 2006, J VISION, V6, P1307, DOI 10.1167/6.11.13
   Jindal A, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480514
   Kanai R, 2004, VISION RES, V44, P2605, DOI 10.1016/j.visres.2003.10.028
   Kazmierczak R, 2022, Arxiv, DOI arXiv:2202.08692
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   Kingma D. P., 2014, arXiv
   Koutras P, 2015, SIGNAL PROCESS-IMAGE, V38, P15, DOI 10.1016/j.image.2015.08.004
   Krajancich B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459784
   KULIKOWSKI JJ, 1973, VISION RES, V13, P1455, DOI 10.1016/0042-6989(73)90006-0
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mantiuk RK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530115
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   McIlhagga W, 2018, VISION RES, V153, P30, DOI 10.1016/j.visres.2018.09.007
   McIlhagga W, 2018, J VISION, V18, DOI 10.1167/18.9.8
   McIlhagga W, 2011, INT J COMPUT VISION, V91, P251, DOI 10.1007/s11263-010-0392-0
   MUSTONEN J, 1993, VISION RES, V33, P2065, DOI 10.1016/0042-6989(93)90005-H
   Paszke A, 2019, ADV NEUR IN, V32
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Poynton C., 2003, Digital Video and HDTV Algorithms and Interfaces, V1st ed.
   Pu MY, 2022, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR52688.2022.00146
   ROBSON JG, 1966, J OPT SOC AM, V56, P1141, DOI 10.1364/JOSA.56.001141
   ROVAMO J, 1995, VISION RES, V35, P767, DOI 10.1016/0042-6989(94)00171-H
   ROVAMO J, 1992, VISION RES, V32, P631, DOI 10.1016/0042-6989(92)90179-M
   Schmittwilken L, 2022, J VISION, V22, DOI 10.1167/jov.22.8.5
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   SHALLICE T, 1964, BRIT J STATIST PSYCH, V17, P113, DOI 10.1111/j.2044-8317.1964.tb00254.x
   SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   STROUD JM, 1967, ANN NY ACAD SCI, V138, P623, DOI 10.1111/j.1749-6632.1967.tb55012.x
   Szeliski R., 2022, Computer Vision: Algorithms and Applications
   TOLHURST DJ, 1975, VISION RES, V15, P1367, DOI 10.1016/0042-6989(75)90192-3
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315, DOI 10.1098/rspb.1998.0577
   VanRullen R, 2003, TRENDS COGN SCI, V7, P207, DOI 10.1016/S1364-6613(03)00095-0
   Wandell B.A., 1995, Foundations of Vision
   Watson AB, 2016, Elect Imag, V2016, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.16.HVEI-102.
   Wolfe Alan, 2022, EUROGRAPHICS S RENDE, P117, DOI DOI 10.2312/SR.20221161
   Wutz A, 2012, VIS COGN, V20, P717, DOI 10.1080/13506285.2012.686460
   Ye NY, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954560
NR 52
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD APR
PY 2024
VL 21
IS 2
AR 7
DI 10.1145/3639052
PG 25
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ3G6
UT WOS:001208695200003
OA hybrid
DA 2024-08-05
ER

PT J
AU Kim, A
   Lee, JE
   Lee, KM
AF Kim, Aelee
   Lee, Jeong-Eun
   Lee, Kyoung-Min
TI Exploring the Relative Effects of Body Position and Locomotion Method on
   Presence and Cybersickness when Navigating a Virtual Environment
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Virtual reality; presence; cybersickness; body position; locomotion
   method
ID INFLUENCES POSTURAL ACTIVITY; MOTION SICKNESS; ATTENTIONAL DEMANDS;
   PATH-INTEGRATION; VISUAL FEEDBACK; REALITY; ORIENTATION; EXPERIENCE;
   SWAY; MOVEMENT
AB The primary goals of this research are to strengthen the understanding of the mechanisms underlying presence and cyber-sickness in relation to the body position and locomotion method when navigating a virtual environment (VE). In this regard, we compared two body positions (standing and sitting) and four locomotion methods (steering + embodied control [EC], steering + instrumental control [IC], teleportation + EC, and teleportation + IC) to examine the association between body position, locomotion method, presence, and cybersickness in VR. The results of a two-way ANOVA revealed a main effect of locomotion method on presence, with the sense of presence significantly lower for the steering + IC condition. However, there was no main effect of body position on presence, nor was there an interaction between body position and locomotion method. For cybersickness, nonparametric tests were used due to non-normality. The results of Mann-Whitney U tests indicated a statistically significant effect of body position on cybersickness. In particular, the level of cybersickness was significantly higher for a standing position than for a sitting position. In addition, the results of Kruskal-Wallis tests revealed that the locomotion method had a meaningful effect on cybersickness, with participants in the steering conditions feeling stronger symptoms of cybersickness than those in the teleportation conditions. Overall, this study confirmed the relationship between body position, locomotion method, presence, and cybersickness when navigating a VE.
C1 [Kim, Aelee] Seoul Natl Univ, Inst Cognit Sci, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Lee, Jeong-Eun; Lee, Kyoung-Min] Seoul Natl Univ, Interdisciplinary Program Cognit Sci, 1 Gwanak Ro, Seoul 08826, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Kim, A (corresponding author), Seoul Natl Univ, Inst Cognit Sci, 1 Gwanak Ro, Seoul 08826, South Korea.
EM kimaelee7@gmail.com; jeongeun12@snu.ac.kr; kminlee@snu.ac.kr
FU National Research Foundation of Korea Grant - Korean Government
   [NRF-2017M3C7A1047225]
FX This research was supported by the National Research Foundation of Korea
   Grant funded by the Korean Government (NRF-2017M3C7A1047225).
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Bakker NH, 1999, PRESENCE-TELEOP VIRT, V8, P36, DOI 10.1162/105474699566035
   Balcetis E, 2007, PSYCHOL SCI, V18, P917, DOI 10.1111/j.1467-9280.2007.02000.x
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Bardy BG, 1999, J EXP PSYCHOL HUMAN, V25, P1284, DOI 10.1037/0096-1523.25.5.1284
   Bhandari J., 2018, P 44 GRAPHICS INTERF, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018.223, DOI 10.20380/GI2018.223]
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bowman D, 2004, 3D User Interfaces: Theory and Practice
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Campos JL, 2009, PLOS ONE, V4, pA163, DOI 10.1371/journal.pone.0007793
   Carassa A., 2004, Proceedings of Presence 2004, P7
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chen YC, 2012, ECOL PSYCHOL, V24, P279, DOI 10.1080/10407413.2012.726181
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364722
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Conradi J, 2012, WORK, V41, P2201, DOI 10.3233/WOR-2012-0442-2201
   Curry C, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.581132
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis Simon., 2015, 11th Australasian Conference on Interactive Entertainment (IE 2015), P27, DOI DOI 10.17973/MMSJ.2015
   Dennison M, 2018, APPL ERGON, V71, P9, DOI 10.1016/j.apergo.2018.03.015
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Dimian AC, 2014, COMPUT-AIDED CHEM EN, V35, P127, DOI 10.1016/B978-0-444-62700-1.00004-8
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Dorado JL, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P47, DOI 10.1109/3DUI.2014.6798841
   Epstein RA, 2017, NAT NEUROSCI, V20, P1504, DOI 10.1038/nn.4656
   Farmani Y., 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI201 8.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Ferracani A, 2016, P 1 INT WORKSH MULT, P21, DOI DOI 10.1145/2983298.2983307
   Flach JM, 1998, PRESENCE-TELEOP VIRT, V7, P90, DOI 10.1162/105474698565550
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Harrington Jake, 2019, P COMP GRAPH VIS COM, P35, DOI [10.2312/cgvc.20191256, DOI 10.2312/CGVC.20191256]
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231, DOI DOI 10.1145/2670473.2670512
   Harris L. R., 2002, Virtual Reality, V6, P75, DOI 10.1007/s100550200008
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Horak F. B., 1996, HDB PHYSIOL 12, P255, DOI DOI 10.1002/CPHY.CP120107
   Horak FB, 2006, AGE AGEING, V35, P7, DOI 10.1093/ageing/afl077
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Irish M, 2019, ELIFE, V8, DOI 10.7554/eLife.50890
   Isip MIG, 2014, IND ENG MANAG SYST, V13, P185, DOI 10.7232/iems.2014.13.2.185
   Jacob Habgood M. P., 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P371, DOI 10.1109/VR.2018.8446130
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Johnson David M., 2005, Research Report
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   KERR B, 1985, J EXP PSYCHOL HUMAN, V11, P617, DOI 10.1037/0096-1523.11.5.617
   Kim A, 2020, INT J HUM-COMPUT INT, V36, P1683, DOI 10.1080/10447318.2020.1775373
   Kitson A., 2015, P 3 ACM S SPATIAL US, P123, DOI DOI 10.1145/2788940.2788956
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Kohn J, 2016, 13TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2016), DOI 10.1145/3001773.3001824
   Kolasinski EM, 1998, HUM FAC ERG SOC P, P1511, DOI 10.1177/154193129804202110
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   Koslucher F, 2016, EXP BRAIN RES, V234, P2709, DOI 10.1007/s00221-016-4675-8
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LAJOIE Y, 1993, EXP BRAIN RES, V97, P139
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Litleskare S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02436
   Marin L, 1999, HUM MOVEMENT SCI, V18, P31, DOI 10.1016/S0167-9457(98)00032-3
   Marsh AP, 2000, GAIT POSTURE, V12, P105, DOI 10.1016/S0966-6362(00)00074-6
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Money Kenneth E., 1990, P MOT SPAC SICKN, P1
   Morasso P, 2022, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.783501
   Mousavi M, 2013, ADV ENG FORUM, V10, P34, DOI 10.4028/www.scientific.net/AEF.10.34
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Nguyen-Vo T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P415, DOI 10.1109/VR.2018.8446383
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2014, EXP BRAIN RES, V232, P1185, DOI 10.1007/s00221-014-3835-y
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Park G.R., 2006, Proceedings of the Human Factors and Ergonomics Society 50 Annual Meeting, P2702, DOI DOI 10.1177/154193120605002607
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Powers William T., 2009, P PERC CONTR THEOR O, P20
   Powers William T., 2011, P PERC CONTR THEOR O, P30
   Reason J. T., 1975, Motion Sickness
   Reed-Jones RJ, 2008, NEUROSCI LETT, V435, P204, DOI 10.1016/j.neulet.2008.02.047
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2005, ACM Transactions on Applied Perception (TAP), V2, P183, DOI [10.1145/1077399.1077401, DOI 10.1145/1077399.1077401]
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI 10.1145/1166087.1166091
   Riecke BE, 2002, PRESENCE-VIRTUAL AUG, V11, P443, DOI 10.1162/105474602320935810
   Riecke BE, 2008, PRESENCE-TELEOP VIRT, V17, P143, DOI 10.1162/pres.17.2.143
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Riva G., 2014, Interacting with presence: HCI and the sense of presence in computer-mediated environments, P9, DOI DOI 10.2478/9783110409697
   Riva G, 2012, INTERACT COMPUT, V24, P203, DOI 10.1016/j.intcom.2012.04.007
   Rosenbaum D, 2017, PSYCHOL SCI, V28, P1864, DOI 10.1177/0956797617721270
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sadowski W, 2002, HUM FAC ER, P791
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Sheldon Robert, 2022, Degrees of freedom (mechanics)
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2002, PRESENCE-TELEOP VIRT, V11, P435, DOI 10.1162/105474602760204327
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI [10.1145/210079.210084, DOI 10.1145/210079.210084]
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith KC, 2019, ATTEN PERCEPT PSYCHO, V81, P2320, DOI 10.3758/s13414-019-01723-6
   Soler-Domínguez JL, 2020, J COMPUT DES ENG, V7, P577, DOI 10.1093/jcde/qwaa040
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Steinicke F., 2013, Human Walking in Virtual Environments: Perception, Technology, and Applications, V9781441984, DOI DOI 10.1007/978-1-4419-8432-6
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2000, HUM MOVEMENT SCI, V19, P203, DOI 10.1016/S0167-9457(00)00009-9
   Stoffregen TA, 2007, J MOTOR BEHAV, V39, P126, DOI 10.3200/JMBR.39.2.126-138
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Stoffregen TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066949
   Sunkara A, 2016, P NATL ACAD SCI USA, V113, P5077, DOI 10.1073/pnas.1604818113
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Whitton MC, 2005, P IEEE VIRT REAL ANN, P123
   Widdowson C, 2021, HUM FACTORS, V63, P296, DOI 10.1177/0018720819881254
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Woollacott M, 2002, GAIT POSTURE, V16, P1, DOI 10.1016/S0966-6362(01)00156-4
   Wraga M, 2004, MEM COGNITION, V32, P399, DOI 10.3758/BF03195834
   Zhou YY, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01546
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Zielasko D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P165, DOI 10.1109/VRW52623.2021.00038
NR 134
TC 1
Z9 1
U1 6
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD JAN
PY 2024
VL 21
IS 1
AR 3
DI 10.1145/3627706
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS3W1
UT WOS:001168291400003
DA 2024-08-05
ER

PT J
AU Chamnongthai, K
   Endo, T
   Matsuno, F
AF Chamnongthai, Komi
   Endo, Takahiro
   Matsuno, Fumitoshi
TI Two-finger Stiffness Discrimination with the Stochastic Resonance Effect
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Haptic perception; stochastic resonance; stiffness discrimination;
   two-finger task
ID TACTILE SENSATION; HAPTIC PERCEPTION; ELECTRICAL NOISE; PERFORMANCE;
   FINGERTIP; STIMULATION; SENSITIVITY; HAND; OLD
AB We investigated the ability of two fingers to discriminate stiffness with stochastic resonance. It is known that the haptic perception at the fingertip improves when vibrotactile noise propagates to the fingertip, which is a phenomenon called the stochastic resonance. The improvement in the haptic sensation of a fingertip depends on the intensity of the noise propagating to the fingertip. An improvement in the haptic sensation ofmultiple fingertips does not requiremultiple noise sources, such as vibrators, to be attached to multiple fingertips; i.e., even a single vibrator can propagate noise tomultiple fingers. In this study, we focus on stiffness discrimination as a task using multiple fingers, in which the thumb and index finger are used to touch an object and perceive its stiffness. Subsequently, we demonstrate that the stiffness perception is improved by propagating sufficiently intense noise to the thumb and index finger using only a single vibrator. The findings indicate the possibility of improving the haptic sensation at multiple fingertips using one vibrator.
C1 [Chamnongthai, Komi; Endo, Takahiro; Matsuno, Fumitoshi] Kyoto Univ, Kyoto 6158504, Japan.
C3 Kyoto University
RP Chamnongthai, K (corresponding author), Kyoto Univ, Kyoto 6158504, Japan.
EM chamnongthai.komi.46m@st.kyoto-u.ac.jp; endo.takahiro.7n@kyoto-u.ac.jp;
   matsuno@me.kyoto-u.ac.jp
RI Endo, Takahiro/IZE-8644-2023
OI Endo, Takahiro/0000-0002-2231-5359
FU KAKENHI [20H04227, 22K19794]
FX This work was supported in part by KAKENHI Grant Nos. 20H04227 and
   22K19794.
CR BOX GEP, 1958, ANN MATH STAT, V29, P610, DOI 10.1214/aoms/1177706645
   Chamnongthai Komi, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P497, DOI 10.1007/978-3-030-58147-3_55
   Chamnongthai K, 2020, IEEE T HUM-MACH SYST, V50, P593, DOI 10.1109/THMS.2020.3022859
   Collins JJ, 1996, NATURE, V383, P770, DOI 10.1038/383770a0
   Collins JJ, 1997, PHYS REV E, V56, P923, DOI 10.1103/PhysRevE.56.923
   CORNSWEET TN, 1962, AM J PSYCHOL, V75, P485, DOI 10.2307/1419876
   Dettmer M, 2015, SOMATOSENS MOT RES, V32, P128, DOI 10.3109/08990220.2015.1004045
   Dhruv NT, 2002, NEUROREPORT, V13, P597, DOI 10.1097/00001756-200204160-00012
   Dinse H.R., 2005, ACM Transactions on Applied Perception (TAP), V2, P71, DOI [DOI 10.1145/1060581.1060583, 10.1145/1060581.1060583]
   Enders LR, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-105
   Germer C. M., 2021, Res. Biomed. Eng, V37, P95, DOI [10.1007/s42600-020-00111-6, DOI 10.1007/S42600-020-00111-6]
   Han G, 2010, LECT NOTES COMPUT SC, V6191, P117
   Higashi K, 2018, IEEE T HAPTICS, V11, P646, DOI 10.1109/TOH.2018.2841820
   Ikemura S, 2021, IEEE ACCESS, V9, P17011, DOI 10.1109/ACCESS.2021.3053297
   JOHANSSON RS, 1982, BRAIN RES, V244, P17, DOI 10.1016/0006-8993(82)90899-X
   Kalisch T, 2008, CLIN INTERV AGING, V3, P673, DOI 10.2147/CIA.S3174
   Kossowsky H, 2022, IEEE T HAPTICS, V15, P351, DOI 10.1109/TOH.2022.3158386
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Kurita Y, 2013, IEEE T HUM-MACH SYST, V43, P333, DOI 10.1109/TSMC.2013.2242886
   Lakshminarayanan K, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12465
   Lawrence DA, 2000, IEEE T ROBOTIC AUTOM, V16, P357, DOI 10.1109/70.864228
   Lederman SJ, 2009, ATTEN PERCEPT PSYCHO, V71, P1439, DOI 10.3758/APP.71.7.1439
   Lederman S.J., 2009, Encyclopedia of Neuroscience, V5, P11
   Lederman SJ, 1999, PRESENCE-TELEOP VIRT, V8, P86, DOI 10.1162/105474699566062
   Okamura AM, 2001, IEEE-ASME T MECH, V6, P245, DOI 10.1109/3516.951362
   Park W, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3449065
   Pavlova EL, 2018, J MOTOR BEHAV, V50, P134, DOI 10.1080/00222895.2017.1306482
   Plater EB, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.789271
   Ray RK, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102056
   Richardson KA, 1998, CHAOS, V8, P599, DOI 10.1063/1.166341
   ROTHWELL JC, 1982, BRAIN, V105, P515, DOI 10.1093/brain/105.3.515
   Seo NJ, 2019, PHYS THER, V99, P319, DOI 10.1093/ptj/pzy143
   Seo NJ, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12624
   Tabachnick B. G., 2014, USING MULTIVARIATE S
   Tiest WMB, 2009, IEEE T HAPTICS, V2, P189, DOI 10.1109/ToH.2009.16
   Warren JP, 2008, IEEE T NEUR SYS REH, V16, P410, DOI 10.1109/TNSRE.2008.925072
   Wells C, 2005, PSYCHOL SCI, V16, P313, DOI 10.1111/j.0956-7976.2005.01533.x
   WESTLING G, 1984, EXP BRAIN RES, V53, P277
   Xu H, 2016, IEEE T NEUR SYS REH, V24, P827, DOI 10.1109/TNSRE.2015.2478153
   Zandiyeh P, 2019, J BIOMECH, V84, P52, DOI 10.1016/j.jbiomech.2018.12.018
   Zarkou A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0467-7
NR 41
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD APR
PY 2024
VL 21
IS 2
AR 6
DI 10.1145/3630254
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ3G6
UT WOS:001208695200002
OA Bronze
DA 2024-08-05
ER

PT J
AU Pouke, M
   Uotila, E
   Center, EG
   Timperi, KG
   Chambers, AP
   Ojala, T
   Lavalle, SM
AF Pouke, Matti
   Uotila, Elmeri
   Center, Evan G.
   Timperi, Kalle G.
   Chambers, Alexis P.
   Ojala, Timo
   Lavalle, Steven M.
TI Adaptation to Simulated Hypergravity in a Virtual Reality Throwing Task
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE virtual reality; gravity models; sensory adaptation
ID PRISM ADAPTATION; INTERNAL-MODELS; GRAVITY; PERCEPTION
AB According to previous research, humans are generally poor at adapting to earth-discrepant gravity, especially in Virtual Reality (VR), which cannot simulate the effects of gravity on the physical body. Most of the previous VR research on gravity adaptation has used perceptual or interception tasks, although adaptation to these tasks seems to be especially challenging compared to tasks with a more pronounced motor component. This article describes the results of two between-subjects studies (n = 60 and n = 42) that investigated adaptation to increased gravity simulated by an interactive VR experience. The experimental procedure was identical in both studies: In the adaptation phase, one group was trained to throw a ball at a target using Valve Index motion controllers in gravity that was simulated at five times of earth's gravity (hypergravity group), whereas another group threw at a longer-distance target under normal gravity (normal gravity group) so both groups had to exert the same amount of force when throwing (approximated manually in Study 1 and mathematically in Study 2). Then, in the measurement phase, both groups repeatedly threw a virtual ball at targets in normal gravity. In this phase, the trajectory of the ball was hidden at the moment of release so that the participants had to rely on their internal model of gravity to hit the targets rather than on visual feedback. Target distances were placed within the same range for both groups in the measurement phase. According to our preregistered hypotheses, we predicted that the hypergravity group would display worse overall throwing accuracy and would specifically overshoot the target more often than the normal gravity group. Our experimental data supported both hypotheses in both studies. The findings indicate that training an interactive task in higher simulated gravity led participants in both studies to update their internal gravity models, and therefore, some adaptation to higher gravity did indeed occur. However, our exploratory analysis also indicates that the participants in the hypergravity group began to gradually regain their throwing accuracy throughout the course of the measurement phase.
C1 [Pouke, Matti; Uotila, Elmeri; Center, Evan G.; Timperi, Kalle G.; Chambers, Alexis P.; Ojala, Timo; Lavalle, Steven M.] Univ Oulu, Ctr Ubiquitous Comp, Erkki Koiso Kanttilan Katu 3,Door E,POB 4500, FI-90014 Oulu, Finland.
C3 University of Oulu
RP Pouke, M (corresponding author), Univ Oulu, Ctr Ubiquitous Comp, Erkki Koiso Kanttilan Katu 3,Door E,POB 4500, FI-90014 Oulu, Finland.
EM matti.pouke@oulu.fi; roope.uotila@oulu.fi; evan.center@oulu.fi;
   kalle.timperi@oulu.fi; alexis.chambers@oulu.fi; timo.ojala@oulu.fi;
   steven.lavalle@oulu.fi
OI Center, Evan/0009-0008-4541-713X; Uotila, Elmeri/0009-0006-5710-032X;
   Pouke, Matti/0000-0002-0105-5164; Chambers, Alexis/0000-0002-2027-4960
FU Academy of Finland [PIXIE 331822, PERCEPT 322637]; SRC of Academy of
   Finland [COMBAT 293389]; Business Finland [HUMOR 3656/31/2019]; European
   Research Council [ILLUSIVE 101020977]
FX This work was supported by the Academy of Finland projects PIXIE 331822,
   PERCEPT 322637, SRC of Academy of Finland project COMBAT 293389,
   Business Finland project HUMOR 3656/31/2019, and the European Research
   Council project ILLUSIVE 101020977.
CR Adams H, 2018, IEEE T VIS COMPUT GR, V24, P1408, DOI 10.1109/TVCG.2018.2794072
   Aoki H, 2001, AIP CONF PROC, V552, P29, DOI 10.1063/1.1357901
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Brubach L, 2022, IEEE T VIS COMPUT GR, V28, P2267, DOI 10.1109/TVCG.2022.3150496
   Bruguera Miquel Bosch, 2019, 70 INT ASTR C
   Cano Porras D, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01308
   Creem-Regehr SH, 2023, PHILOS T R SOC B, V378, DOI 10.1098/rstb.2021.0456
   Crevecoeur F, 2009, J NEUROPHYSIOL, V102, P786, DOI 10.1152/jn.00113.2009
   Gaveau J, 2011, J NEUROPHYSIOL, V106, P620, DOI 10.1152/jn.00081.2011
   Gravano S, 2021, NPJ MICROGRAVITY, V7, DOI 10.1038/s41526-021-00179-z
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   Jiang A, 2023, BUILD ENVIRON, V227, DOI 10.1016/j.buildenv.2022.109789
   Jingjing Zhang, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382876
   Jörges B, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00203
   Jost PD, 2008, HIPPOKRATIA, V12, P37
   Kelly JW, 2023, IEEE T VIS COMPUT GR, V29, P4978, DOI 10.1109/TVCG.2022.3196606
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   Kozhevnikov M, 2001, PSYCHON B REV, V8, P439, DOI 10.3758/BF03196179
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   La Scaleia B, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00076
   LACQUANITI F, 1989, J NEUROSCI, V9, P149
   Langbehn E, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P211, DOI 10.1109/3DUI.2016.7460054
   Maltsev Andrey V., 2021, Scient. Visualiz., V13, P52
   McIntyre J, 2001, NAT NEUROSCI, V4, P693, DOI 10.1038/89477
   Merfeld DM, 1999, NATURE, V398, P615, DOI 10.1038/19303
   Millet G, 2008, LECT NOTES COMPUT SC, V5024, P847, DOI 10.1007/978-3-540-69057-3_107
   Montgomery K, 2001, IEEE VISUAL, P509, DOI 10.1109/VISUAL.2001.964564
   Oddsson LI, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-25
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Pouke M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.869603
   Pouke M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.655744
   Pouke M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P913, DOI [10.1109/VR46266.2020.00116, 10.1109/VR46266.2020.1580974317169]
   Redding GM, 2005, NEUROSCI BIOBEHAV R, V29, P431, DOI 10.1016/j.neubiorev.2004.12.004
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rönkkö J, 2006, INT J HUM-COMPUT ST, V64, P182, DOI 10.1016/j.hcs.2005.08.004
   Senot P, 2005, J NEUROPHYSIOL, V94, P4471, DOI 10.1152/jn.00527.2005
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Slater M, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00003
   Ullman TD, 2017, TRENDS COGN SCI, V21, P649, DOI 10.1016/j.tics.2017.05.012
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Ye T, 2017, IEEE T VIS COMPUT GR, V23, P1369, DOI 10.1109/TVCG.2017.2657235
   Zago M, 2005, J NEUROPHYSIOL, V94, P1346, DOI 10.1152/jn.00215.2005
   Zago M, 2004, J NEUROPHYSIOL, V91, P1620, DOI 10.1152/jn.00862.2003
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
NR 44
TC 0
Z9 0
U1 3
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD APR
PY 2024
VL 21
IS 2
AR 8
DI 10.1145/3643849
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ3G6
UT WOS:001208695200004
OA hybrid
DA 2024-08-05
ER

EF