FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Pan, H
   Huang, J
AF Pan, Hao
   Huang, Jun
TI Semantic-enhanced discriminative embedding learning for cross-modal
   retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cross-modal retrieval; Semantic enhanced; Erasing; Metric learning
AB Cross-modal retrieval requires the retrieval from image to text and vice versa. Most existing methods leverage attention mechanism to explore advanced encoding network and utilize the ranking losses to reduce modal gap. Although these methods have achieved remarkable performance, they still suffer from some drawbacks that hinder the model from learning discriminative semantic embeddings. For example, the attention mechanism may assign larger weights to irrelevant parts than relevant parts, which prevents the model from learning discriminative attention distribution. In addition, traditional ranking losses could disregard relatively discriminative information due to the lack of appropriate hardest negative sample mining and information weighting schemes. In this paper, in order to alleviate these issues, a novel semantic-enhanced discriminative embedding learning method is proposed to enhance the discriminative ability of the model, which mainly consists of three modules. The attention-guided erasing module enables the attention model pay more attention to the relevant parts and reduce the interferences of irrelevant parts by erasing non-attention parts. The large-scale negative sampling module leverages momentum-updated memory banks to expand the number of negative samples, which helps increase the probability of hardest negative being sampled. Moreover, the weighted InfoNCE loss module designs a weighted scheme to assign a larger weight to a harder pair. We evaluate the proposed modules by integrating them into three existing cross-modal retrieval models. Extensive experiments demonstrate that integrating each proposed module to the existing models can steadily improve the performance of all models.
C1 [Pan, Hao; Huang, Jun] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Pan, Hao; Huang, Jun] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Shanghai Advanced Research Institute,
   CAS
RP Huang, J (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.; Huang, J (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.
EM panhao2019@sari.ac.cn; huangj@sari.ac.cn
OI huang, jun/0000-0003-4939-3880
FU National Key R &D Program of China [2019YFC1521204]
FX This paper was supported by National Key R &D Program of China
   (2019YFC1521204).
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Chen T, 2020, EUROPEAN C COMPUTER
   Faghri F., 2018, BRIT MACHINE VISION
   Grauman K., 2018, P IEEE C COMPUTER VI
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoffer E, 2015, INT WORKSHOP SIMILAR
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li K, 2019, P IEEECVF INT C COMP
   Lin T-Y, 2014, EUROPEAN C COMPUTER, P40755
   Liu FY, 2020, AAAI CONF ARTIF INTE, V34, P11563
   Liu XH, 2019, PROC CVPR IEEE, P1950, DOI 10.1109/CVPR.2019.00205
   Mithun Niluthpol Chowdhury, 2018, P 2018 ACM INT C MUL, P19
   Nam H, 2017, P IEEE C COMPUTER VI
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song HO, 2016, P IEEE C COMPUTER VI
   vandenOord Aaron, 2018, ARXIV180703748
   Wang H., 2020, EUROPEAN C COMPUTER
   Wang L, 2018, IEEE T PATTERN ANAL, V41
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wei J, 2020, P IEEECVF C COMPUTER
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wen KY, 2021, IEEE T CIRC SYST VID, V31, P2866, DOI 10.1109/TCSVT.2020.3030656
   Young P., 2014, Trans. Assoc. Comput. Linguist, V2
   Yu R, 2018, P EUROPEAN C COMPUTE
NR 29
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 369
EP 382
DI 10.1007/s13735-022-00237-6
EA MAY 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000793616900001
DA 2024-07-18
ER

PT J
AU Yang, JY
   Jiang, J
   Guo, YM
AF Yang, Junyan
   Jiang, Jie
   Guo, Yanming
TI MHA-WoML: Multi-head attention and Wasserstein-OT for few-shot learning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few-shot learning; Hierarchical multi-head attention; Wasserstein
   distance; Optimal transport theory
AB Few-shot learning aims to classify novel classes with extreme few labeled samples. Existing metric-learning-based approaches tend to employ the off-the-shelf CNN models for feature extraction, and conventional clustering algorithms for feature matching. These methods neglect the importance of image regions and might trap in over-fitting problems during feature clustering. In this work, we propose a novel MHA-WoML framework for few-shot learning, which adaptively focuses on semantically dominant regions, and well relieves the over-fitting problem. Specifically, we first design a hierarchical multi-head attention (MHA) module, which consists of three functional heads (i.e., rare head, syntactic head and positional head) with masks, to extract comprehensive image features, and screen out invalid features. The MHA behaves better than current transformers in few-shot recognition. Then, we incorporate the optimal transport theory into Wasserstein distance and propose a Wasserstein-OT metric learning (WoML) module for category clustering. The WoML module focuses more on calculating the appropriately approximate barycenter to avoid the over accurate sub-stage fitting which may threaten the global fitting, thus alleviating the problem of over-fitting in the training process. Experimental results show that our approach achieves remarkably better performance compared to current state-of-the-art methods by scoring about 3% higher accuracy, across four benchmark datasets including MiniImageNet, TieredImageNet, CIFAR-FS and CUB200.
C1 [Yang, Junyan; Jiang, Jie; Guo, Yanming] Natl Univ Def Technol, Coll Syst Engn, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Guo, YM (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha, Hunan, Peoples R China.
EM junyanyang@nudt.edu.cn; jiejiang@nudt.edu.cn; guoyanming@nudt.edu.cn
OI Jiang, Jie/0000-0001-9666-815X
FU Ministry of Science and Technology of China [2020AAA0108800]
FX This research was supported in part by the Ministry of Science and
   Technology of China under grant No. 2020AAA0108800. The authors have no
   financial or proprietary interests in any material discussed in this
   article.
CR Barz B, 2019, IEEE T PATTERN ANAL, V41, P1088, DOI 10.1109/TPAMI.2018.2823766
   Bateni Peyman, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14481, DOI 10.1109/CVPR42600.2020.01450
   Bateni P, 2022, IEEE WINT CONF APPL, P1597, DOI 10.1109/WACV51458.2022.00166
   Bendou Y, 2021, EASY ENSEMBLE AUGMEN
   Bertinetto Luca, 2019, PROC INT C LEARN REP
   Boudiaf M., 2020, Advances in Neural Information Processing Systems (NeurIPS)
   Cariello D, 2019, LINEAR MULTILINEAR A, V67, P2345, DOI 10.1080/03081087.2018.1491524
   Chen D, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1745, DOI 10.1109/ICASSP39728.2021.9413783
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Di Nezza E, 2015, INT MATH RES NOTICES, V2015, P7287, DOI 10.1093/imrn/rnu166
   Esfandiarpoor R, 2020, ARXIV
   Finn C, 2017, PR MACH LEARN RES, V70
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A., 2014, ARXIV
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YQ, 2021, LECT NOTES COMPUT SC, V12892, P487, DOI 10.1007/978-3-030-86340-1_39
   Hu YQ, 2021, INT C PATT RECOG, P8164, DOI 10.1109/ICPR48806.2021.9412076
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8651, DOI 10.1109/ICCV48922.2021.00855
   Jian Y, 2022, AAAI
   Kasai H, 2020, INT CONF ACOUST SPEE, P6039, DOI [10.1109/ICASSP40776.2020.9054427, 10.1109/icassp40776.2020.9054427]
   Kye SM, 2020, ARXIV
   Le DH, 2021, ADV NEUR IN, V34
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li XZ, 2019, ADV NEUR IN, V32
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Muzellec B, 2020, ICML
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Rajasegaran J, 2020, ARXIV
   Ravichandran A, 2019, IEEE I CONF COMP VIS, P331, DOI 10.1109/ICCV.2019.00042
   Ren M, ARXIV
   Rizve MN, 2021, PROC CVPR IEEE, P10831, DOI 10.1109/CVPR46437.2021.01069
   Rodriguez Pau, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P121, DOI 10.1007/978-3-030-58574-7_8
   Shao S, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4193, DOI 10.1145/3474085.3475553
   Song Yang, 2021, INT C LEARN REPR
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang WG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7283, DOI 10.1109/ICCV48922.2021.00721
   Wang Yuqing, 2020, CVPR
   Wu J, 2021, ICCV
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang F, 2022, WACV
   Yang I, 2017, IEEE CONTR SYST LETT, V1, P164, DOI 10.1109/LCSYS.2017.2711553
   Yang L, 2020, PROC CVPR IEEE, P2366, DOI 10.1109/CVPR42600.2020.00244
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H., 2021, arXiv
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang R, 2020, IEEE T FUZZY SYST, V28, P2814, DOI 10.1109/TFUZZ.2019.2945232
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Ziko I., 2020, ICML, P11660
NR 58
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 681
EP 694
DI 10.1007/s13735-022-00254-5
EA SEP 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000855995400001
DA 2024-07-18
ER

PT J
AU Gulshad, S
   Smeulders, A
AF Gulshad, Sadaf
   Smeulders, Arnold
TI Counterfactual attribute-based visual explanations for classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Explainable AI; Counterfactual; Explanations; Attributes;
   Classification; Adversarial examples
AB In this paper, our aim is to provide human understandable intuitive factual and counterfactual explanations for the decisions of neural networks. Humans tend to reinforce their decisions by providing attributes and counterattributes. Hence, in this work, we utilize attributes as well as examples to provide explanations. In order to provide counterexplanations we make use of directed perturbations to arrive at the counterclass attribute values in doing so, we explain what is present and what is absent in the original image. We evaluate our method when images are misclassified into closer counterclasses as well as when misclassified into completely different counterclasses. We conducted experiments on both finegrained as well as coarsegrained datasets. We verified our attribute-based explanations method both quantitatively and qualitatively and showed that attributes provide discriminating and human understandable explanations for both standard as well as robust networks.
C1 [Gulshad, Sadaf; Smeulders, Arnold] Univ Amsterdam, UvA Bosch Delta Lab, Amsterdam, Netherlands.
C3 University of Amsterdam
RP Gulshad, S (corresponding author), Univ Amsterdam, UvA Bosch Delta Lab, Amsterdam, Netherlands.
EM s.gulshad@uva.nl; a.w.m.smeulders@uva.nl
OI Gulshad, Sadaf/0000-0003-3929-7174
CR Abbasnejad E., 2020, P IEEE CVF C COMP VI, P10044, DOI DOI 10.1109/CVPR42600.2020.01006
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Browne, 2020, ARXIV PREPRINT ARXIV
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009
   Dong YP, 2017, PROC CVPR IEEE, P975, DOI 10.1109/CVPR.2017.110
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   Edwards L., 2017, Duke Law & Technology Review, V16, P18
   Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371
   Goyal Y, 2019, PR MACH LEARN RES, V97
   Gulshad Sadaf, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P35, DOI 10.1145/3372278.3390672
   Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120
   Hendricks LA, 2018, LECT NOTES COMPUT SC, V11207, P793, DOI 10.1007/978-3-030-01219-9_47
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Hendricks Lisa Anne, 2018, ARXIV180609809, P95
   Hsieh C.-Y., 2020, EVALUATIONS METHODS, Vabs
   Ignatiev A, 2019, ADV NEUR IN, V32
   Jiang L, 2019, J VISUAL-JAPAN, V22, P401, DOI 10.1007/s12650-018-0531-1
   Kanehira A, 2019, PROC CVPR IEEE, P8586, DOI [10.1109/CVPR.2019.00880, 10.1109/CVPR.2019.00879]
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kurakin Alexey, 2017, INT C LEARN REPR
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Liu S., 2019, CVPR
   Loyola-González O, 2019, IEEE ACCESS, V7, P154096, DOI 10.1109/ACCESS.2019.2949286
   Madry A., 2018, ARXIV
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Ribeiro Marco Tulio, 2016, P 22 ACM SIGKDD INT, P1135, DOI [DOI 10.1145/2939672.2939778, 10.18653/v1/n16-3020, 10.1145/2939672.2939778. u r l, DOI 10.1145/2939672.2939778.URL]
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Simonyan K., 2013, arXiv preprint arXiv:1312.6034
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsipras D., 2019, ROBUSTNESS MAY BE OD
   Wachter S., 2018, Harv. JL & Tech., V31, P841, DOI DOI 10.2139/SSRN.3063289
   Zhang T., 2019, INT C MACHINE LEARNI, P7502
   Zhao B, 2019, PROC CVPR IEEE, P8576, DOI 10.1109/CVPR.2019.00878
   Zintgraf L. M., 2017, ARXIV170204595, P1
NR 41
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2021
VL 10
IS 2
SI SI
BP 127
EP 140
DI 10.1007/s13735-021-00208-3
EA APR 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SK0DY
UT WOS:000640949800001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Messina, N
   Amato, G
   Carrara, F
   Falchi, F
   Gennaro, C
AF Messina, Nicola
   Amato, Giuseppe
   Carrara, Fabio
   Falchi, Fabrizio
   Gennaro, Claudio
TI Learning visual features for relational CBIR
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE CLEVR; Content-based image retrieval; Deep learning; Relational
   reasoning; Relation networks; Deep features
AB Recent works in deep-learning research highlighted remarkable relational reasoning capabilities of some carefully designed architectures. In this work, we employ a relationship-aware deep learning model to extract compact visual features used relational image descriptors. In particular, we are interested in relational content-based image retrieval (R-CBIR), a task consisting in finding images containing similar inter-object relationships. Inspired by the relation networks (RN) employed in relational visual question answering (R-VQA), we present novel architectures to explicitly capture relational information from images in the form of network activations that can be subsequently extracted and used as visual features. We describe a two-stage relation network module (2S-RN), trained on the R-VQA task, able to collect non-aggregated visual features. Then, we propose the aggregated visual features relation network (AVF-RN) module that is able to produce better relationship-aware features by learning the aggregation directly inside the network. We employ an R-CBIR ground-truth built by exploiting scene-graphs similarities available in the CLEVR dataset in order to rank images in a relational fashion. Experiments show that features extracted from our 2S-RN model provide an improved retrieval performance with respect to standard non-relational methods. Moreover, we demonstrate that the features extracted from the novel AVF-RN can further improve the performance measured on the R-CBIR task, reaching the state-of-the-art on the proposed dataset.
C1 [Messina, Nicola; Amato, Giuseppe; Carrara, Fabio; Falchi, Fabrizio; Gennaro, Claudio] Via G Monizzi 1, I-56124 Pisa, Italy.
RP Messina, N (corresponding author), Via G Monizzi 1, I-56124 Pisa, Italy.
EM nicola.messina@isti.cnr.it; giuseppe.amato@isti.cnr.it;
   fabio.carrara@isti.cnr.it; fabrizio.falchi@isti.cnr.it;
   claudio.gennaro@isti.cnr.it
RI Gennaro, Claudio/AAH-5171-2019; Falchi, Fabrizio/J-2920-2012; Amato,
   Giuseppe/F-2227-2013; Carrara, Fabio/R-2275-2019; Messina,
   Nicola/AAB-3309-2022
OI Gennaro, Claudio/0000-0002-3715-149X; Falchi,
   Fabrizio/0000-0001-6258-5313; Amato, Giuseppe/0000-0003-0171-4315;
   Carrara, Fabio/0000-0001-5014-5089; Messina, Nicola/0000-0003-3011-2487
CR [Anonymous], 2016, VISUAL GENOME CONNEC
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], ARXIV171007300 CORR
   [Anonymous], 2017, Clevr: A diagnostic dataset for compositional language and elementary visual reasoning
   [Anonymous], ARXIV151102274 CORR
   [Anonymous], ARXIV151202167 CORR
   [Anonymous], ARXIV180907041 CORR
   [Anonymous], ICCV 2017 INT C COMP
   [Anonymous], ARXIV150500468 CORR
   [Anonymous], 2018, ARXIV180410660
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, ARXIV161007940
   [Anonymous], 2018, SIGKDD 2018
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], ARXIV180800191 CORR
   [Anonymous], ARXIV170205068 CORR
   [Anonymous], ARXIV170907604 CORR
   [Anonymous], ARXIV181110696 CORR
   [Anonymous], 2016, EUR C COMP VIS
   Belilovsky E., 2017, JOINT EMBEDDINGS SCE
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kuznetsova A, 2018, ARXIV181100982 CORR
   Malinowski M, 2014, ADV NEUR IN, V27
   Melucci M., 2007, SIGIR Forum, V41, P18, DOI 10.1145/1273221.1273223
   Messina N, 2019, LECT NOTES COMPUT SC, V11132, P486, DOI 10.1007/978-3-030-11018-5_40
   Ren M., 2015, NEURIPS, P2953
   Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004
   Santoro A., 2017, ADV NEURAL INFORM PR, V30, P4967
   Xie B, 2017, IEEE ICC
NR 31
TC 8
Z9 9
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2020
VL 9
IS 2
SI SI
BP 113
EP 124
DI 10.1007/s13735-019-00178-7
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ4GS
UT WOS:000534963100004
DA 2024-07-18
ER

PT J
AU Mithun, NC
   Li, JC
   Metze, F
   Roy-Chowdhury, AK
AF Mithun, Niluthpol C.
   Li, Juncheng
   Metze, Florian
   Roy-Chowdhury, Amit K.
TI Joint embeddings with multimodal cues for video-text retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video-text retrieval; Joint embedding; Multimodal cues
AB For multimedia applications, constructing a joint representation that could carry information for multiple modalities could be very conducive for downstream use cases. In this paper, we study how to effectively utilize available multimodal cues from videos in learning joint representations for the cross-modal video-text retrieval task. Existing hand-labeled video-text datasets are often very limited by their size considering the enormous amount of diversity the visual world contains. This makes it extremely difficult to develop a robust video-text retrieval system based on deep neural network models. In this regard, we propose a framework that simultaneously utilizes multimodal visual cues by a "mixture of experts" approach for retrieval. We conduct extensive experiments to verify that our system is able to boost the performance of the retrieval task compared to the state of the art. In addition, we propose a modified pairwise ranking loss function in training the embedding and study the effect of various loss functions. Experiments on two benchmark datasets show that our approach yields significant gain compared to the state of the art.
C1 [Mithun, Niluthpol C.; Roy-Chowdhury, Amit K.] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Li, Juncheng; Metze, Florian] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 University of California System; University of California Riverside;
   Carnegie Mellon University
RP Mithun, NC (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM nmithun@ece.ucr.edu; junchenl@cs.cmu.edu; fmetze@cs.cmu.edu;
   amitrc@ece.ucr.edu
RI Metze, Florian/N-4661-2014; ARSLAN, Okan/AAA-3232-2020; Mithun,
   Niluthpol/AAH-1795-2019
OI Mithun, Niluthpol/0000-0003-3611-4141; Roy-Chowdhury,
   Amit/0000-0001-6690-9725
FU NSF [33384, IIS-1746031, CNS-1544969, ACI-1548562, ACI-1445606]; Bosch
   Graduate Fellowship; NVIDIA Corporation
FX This work was partially supported by NSF grants 33384, IIS-1746031,
   CNS-1544969, ACI-1548562, and ACI-1445606. J. Li was supported by the
   Bosch Graduate Fellowship to CMU LTI. We gratefully acknowledge the
   support of NVIDIA Corporation with the donation of the Titan Xp GPU used
   for this research.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, P TRECVID
   [Anonymous], ARXIV151106238
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   [Anonymous], 2016, INT C LEARN REPR
   [Anonymous], 2018, ACM INT C MULT
   [Anonymous], 2016, ARXIV160908124
   [Anonymous], 2018, BRIT MACH VIS C BMVC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, P AAAI C ART INT AUS
   [Anonymous], 2018, ACM INT C MULT RETR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2016, P ADV NEUR INF PROC
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Aytar Yusuf, 2017, ARXIV170600932
   Bois R, 2017, LECT NOTES COMPUT SC, V10133, P185, DOI 10.1007/978-3-319-51814-5_16
   Budnik M, 2018, IEEE INT CON MULTI
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chi JZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P663
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Henning C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P14, DOI 10.1145/3078971.3078991
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang YF, 2017, IEEE INT CONF COMP V, P2313, DOI 10.1109/ICCVW.2017.273
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073
   Lee JH, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/258525.258587
   Ma Z, 2015, PR MACH LEARN RES, V37, P169
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mithun NC, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P230, DOI 10.1109/IPSN.2018.00051
   Mithun NiluthpolChowdhury., 2016, ACM International Conference on Multimedia (ACM MM), P566
   Otani Mayu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P651, DOI 10.1007/978-3-319-46604-0_46
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Polikar R, 2007, IEEE SIGNAL PROC MAG, V24, P59, DOI 10.1109/MSP.2007.4286565
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112
   Tran TQN, 2016, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2016.225
   Usunier N., 2009, P 26 ANN INT C MACH, P1057
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vukotic V, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P421, DOI 10.1145/3078971.3079038
   Vukotic V, 2018, IEEE MULTIMEDIA, V25, P11, DOI 10.1109/MMUL.2018.023121161
   Vukotic V, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P343, DOI 10.1145/2911996.2912064
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yan R., 2004, PROC ACM INT C MULTI, P548
   Zhang L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P907, DOI 10.1145/3123266.3123317
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 66
TC 14
Z9 14
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2019
VL 8
IS 1
SI SI
BP 3
EP 18
DI 10.1007/s13735-018-00166-3
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HT8ZD
UT WOS:000464853000002
DA 2024-07-18
ER

PT J
AU Taheri, F
   Rahbar, K
   Beheshtifard, Z
AF Taheri, Fatemeh
   Rahbar, Kambiz
   Beheshtifard, Ziaeddin
TI Content-based image retrieval using handcraft feature fusion in semantic
   pyramid
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Feature fusion; Semantic pyramid; Handcraft features; Deep features;
   Content-based image retrieval
ID NEURAL-NETWORKS
AB The main challenge of image retrieval systems is to retrieve similar samples in a way that can be interpreted in a semantic relationship with the user's query image. In recent years, deep neural networks, due to their remarkable role in extracting the content and semantic features of the image, have been at the center of attention for image retrieval. Processing occurs in deep neural networks, at multiple levels, and with a pyramid approach. This characteristic allows the extraction of semantic and high-level features from the image. On the other hand, the image content features can be extracted with high interpretability using handcraft features. Therefore, in the proposed approach, by fusing features and adding extra information sources, handcraft features are semantically enhanced. In this approach, handcraft features including color and texture are extracted from the semantic pyramid of the deep neural network. The semantic pyramid is the result of the fusion of feature maps in different levels of deep neural networks. Additionally, in this approach, feature vector interpretability is also considered. The t-SNE technique has been used to interpret the discriminability of the feature vector between the classes of the database. Also, the silhouette criterion has been introduced to study the degree of intra-class compatibility and inter-class dataset samples discriminability with feature vector.
C1 [Taheri, Fatemeh; Rahbar, Kambiz; Beheshtifard, Ziaeddin] Islamic Azad Univ, Dept Comp Engn, South Tehran Branch, Tehran, Iran.
C3 Islamic Azad University
RP Rahbar, K (corresponding author), Islamic Azad Univ, Dept Comp Engn, South Tehran Branch, Tehran, Iran.
EM k_rahbar@azad.ac.ir
RI Beheshtifard, Ziaeddin/AAR-7858-2021
OI Taheri, Fatemeh/0000-0002-4430-8416
CR Ahmed KT, 2021, IEEE ACCESS, V9, P41934, DOI 10.1109/ACCESS.2021.3063545
   Alemu LT, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103862
   Anitha K, 2022, BIOMEDICINES, V10, DOI 10.3390/biomedicines10102438
   Barbhuiya A, 2022, MULTIMEDIA SYST, V28, P1779, DOI 10.1007/s00530-022-00951-5
   Bedi AK, 2021, MULTIMED TOOLS APPL, V80, P20773, DOI 10.1007/s11042-021-10758-7
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Bengio Y, 2021, COMMUN ACM, V64, P58, DOI 10.1145/3448250
   Bu HH, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01466-0
   Chavda S, 2022, MULTIMED TOOLS APPL, V81, P4039, DOI 10.1007/s11042-021-11698-y
   Devulapalli Sudheer, 2023, Materials Today: Proceedings, P983, DOI 10.1016/j.matpr.2021.04.326
   Dong RS, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9794202
   Dubey SR, 2020, NEURAL COMPUT APPL, V32, P7539, DOI 10.1007/s00521-019-04279-6
   Feng yang, 2021, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2021.100096
   Gonzalez-Garcia A, 2018, INT J COMPUT VISION, V126, P476, DOI 10.1007/s11263-017-1048-0
   Hassanin M, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103448
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kalsekar A, 2022, MULTIMED TOOLS APPL, V81, P41199, DOI 10.1007/s11042-022-13124-3
   Kan SC, 2022, IEEE T IMAGE PROCESS, V31, P2988, DOI 10.1109/TIP.2022.3163571
   Kanaparthi SK, 2020, MULTIMED TOOLS APPL, V79, P34875, DOI 10.1007/s11042-019-08029-7
   Kenchappa YD, 2022, INT J SYST ASSUR ENG, V13, P2540, DOI 10.1007/s13198-022-01663-9
   Khan S., 2018, Synth. Lect. Comput. Vis., V8, P1, DOI [DOI 10.2200/S00822ED1V01Y201712COV015, 10.1007/978-3-031-01822-0]
   Khan UA, 2022, J KING SAUD UNIV-COM, V34, P7856, DOI 10.1016/j.jksuci.2022.07.005
   Li H, 2017, LECT NOTES COMPUT SC, V10666, P675, DOI 10.1007/978-3-319-71607-7_59
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Liu GH., 2022, INT J MACH LEARN CYB, DOI [10.1007/S13042-022-01645-0/METRICS, DOI 10.1007/S13042-022-01645-0/METRICS]
   Liu Y, 2019, WORLD WIDE WEB, V22, P1313, DOI 10.1007/s11280-018-0585-y
   Magesh PR, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104041
   Marcilio WE, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115020
   Mistry Yogita, 2018, Journal of Electrical Systems and Information Technology, V5, P874, DOI 10.1016/j.jesit.2016.12.009
   Mohite NB, 2022, MULTIMED TOOLS APPL, V81, P11379, DOI 10.1007/s11042-022-12085-x
   Phadikar BS, 2021, MULTIMED TOOLS APPL, V80, P15619, DOI 10.1007/s11042-021-10573-0
   Rodriguez-Martinez I, 2022, NEURAL NETWORKS, V152, P380, DOI 10.1016/j.neunet.2022.04.028
   Salih SF, 2023, J SUPERCOMPUT, V79, P2308, DOI 10.1007/s11227-022-04748-1
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sudha SK, 2022, APPL SOFT COMPUT, V125, DOI 10.1016/j.asoc.2022.109107
   Sunitha T, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103678
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taheri F, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13670-w
   Varish N, 2022, MULTIMED TOOLS APPL, V81, P20373, DOI 10.1007/s11042-022-12289-1
   Vasudevan Smrithi, 2020, Advances in Communication and Computational Technology. Select Proceedings of ICACCT 2019. Lecture Notes in Electrical Engineering (LNEE 668), P257, DOI 10.1007/978-981-15-5341-7_21
   wang.ist, CONTENT BASED IMAGE
   Wei WY, 2022, MULTIMED TOOLS APPL, V81, P659, DOI 10.1007/s11042-021-11198-z
   Xu LM, 2022, IEEE T IMAGE PROCESS, V31, P3371, DOI 10.1109/TIP.2022.3171081
   Zafar A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178643
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan ZQ, 2020, IEEE ACCESS, V8, P21524, DOI 10.1109/ACCESS.2020.2969287
   Zhang L, 2022, IEEE T PATTERN ANAL, V44, P456, DOI 10.1109/TPAMI.2020.3009758
   Zhou ZL, 2020, IEEE TETCI, V4, P593, DOI 10.1109/TETCI.2019.2909936
NR 49
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 21
DI 10.1007/s13735-023-00292-7
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O6LG9
UT WOS:001044894800003
DA 2024-07-18
ER

PT J
AU Negi, A
   Kumar, K
AF Negi, Alok
   Kumar, Krishan
TI End-to-end residual learning-based deep neural network model deployment
   for human activity recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Deep learning; Human activity recognition (HAR); Haryana residual
   learning; Transfer learning; UTKinect dataset
ID HUMAN-BEHAVIOR
AB Human activity recognition is a theme commonly explored in computer vision. Its applications in various domains include monitoring systems, video processing, robotics, and healthcare sector, etc. Activity recognition is a difficult task since there are structural changes among subjects, as well as inter-class and intra-class correlation between activities. As a result, a continuous intelligent control system for detecting human behavior with grouping of maximum information is necessary. Therefore, in this paper, a novel automatic system to identify human activity on the UTKinect dataset is implemented by using Residual learning-based Network "ResNet-50" and transfer learning to represent more complicated features and improved model robustness. The experimental results have shown an excellent generalization capability when tested on the validation set and obtained high accuracy of 98.60 per cent with a 0.02 loss score. The designed residual learning-based system indicates the efficiency of comparing with the other state-of-the-art models.
C1 [Negi, Alok] Natl Inst Technol, Comp Sci & Engn, Srinagar 246174, Uttaranchal, India.
   [Kumar, Krishan] Natl Inst Technol Kurukshetra, Comp Sci & Engn, Kurukshetra 136119, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; National Institute of Technology (NIT System);
   National Institute of Technology Kurukshetra
RP Negi, A (corresponding author), Natl Inst Technol, Comp Sci & Engn, Srinagar 246174, Uttaranchal, India.
EM aloknegi.phd2020@nituk.ac.in
RI KUMAR, KRISHAN/AAE-7003-2022
OI KUMAR, KRISHAN/0000-0003-4020-4051
FU DST
FX The authors would like to thank to the DST GoI for sponsoring the work
   under DST/ICPS/General/2018.
CR Ariz M, 2019, COMPUT VIS IMAGE UND, V180, P13, DOI 10.1016/j.cviu.2019.01.002
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Cai JX, 2020, NEUROCOMPUTING, V407, P428, DOI 10.1016/j.neucom.2020.03.111
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chaudhary S, 2019, NEUROCOMPUTING, V367, P207, DOI 10.1016/j.neucom.2019.08.031
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Cho H, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041055
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huo FF, 2012, COMPUT VIS IMAGE UND, V116, P634, DOI 10.1016/j.cviu.2011.12.006
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Liciotti D., 2019, Neurocomputing
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu JJ, 2020, NEUROCOMPUTING, V385, P22, DOI 10.1016/j.neucom.2019.11.048
   Lv MQ, 2019, NEUROCOMPUTING, V362, P33, DOI 10.1016/j.neucom.2019.06.051
   Masum Abdul Kadar Muhammad, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1332, DOI 10.1109/ICOEI.2019.8862610
   Mutegeki R, 2019, I C INF COMM TECH CO, P18, DOI 10.1109/ictc46691.2019.8939979
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Qin XL, 2020, NEUROCOMPUTING, V406, P127
   Roy A, 2019, TENCON IEEE REGION, P757, DOI [10.1109/TENCON.2019.8929519, 10.1109/tencon.2019.8929519]
   Saini R, 2018, NEUROCOMPUTING, V311, P99, DOI 10.1016/j.neucom.2018.05.042
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tüfek N, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806395
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Verma KK, 2021, INT J INTERACT MULTI, V7, P44, DOI 10.9781/ijimai.2021.08.008
   Verma KK, 2020, INT J INTERACT MULTI, V6, P125, DOI 10.9781/ijimai.2020.04.002
   Wang HR, 2018, NEUROCOMPUTING, V318, P109, DOI 10.1016/j.neucom.2018.08.037
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Zhao C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040716
   Zheng ZX, 2019, NEUROCOMPUTING, V358, P446, DOI 10.1016/j.neucom.2019.05.058
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 46
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 1
DI 10.1007/s13735-023-00269-6
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9C6RI
UT WOS:000935541800001
DA 2024-07-18
ER

PT J
AU Huang, ZJ
   Liu, ZG
   Chen, JH
   He, QM
   Wu, S
   Zhu, L
   Wang, M
AF Huang, Zhengjie
   Liu, Zhenguang
   Chen, Jianhai
   He, Qinming
   Wu, Shuang
   Zhu, Lei
   Wang, Meng
TI Who is gambling? Finding cryptocurrency gamblers using multi-modal
   retrieval methods
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Gambling detection; Multi-modal; Blockchain; Smart contract; Ethereum
ID BLOCKCHAIN; DAO
AB With the popularity of cryptocurrencies and the remarkable development of blockchain technology, decentralized applications emerged as a revolutionary force for the Internet. Meanwhile, decentralized applications have also attracted intense attention from the online gambling community, with more and more decentralized gambling platforms created through the help of smart contracts. Compared with conventional gambling platforms, decentralized gambling has transparent rules and a low participation threshold, attracting a substantial number of gamblers. In order to discover gambling behaviors and identify the contracts and addresses involved in gambling, we propose a tool termed ETHGamDet. The tool is able to automatically detect the smart contracts and addresses involved in gambling by scrutinizing the smart contract code and address transaction records. Interestingly, we present a novel LightGBM model with memory components, which possesses the ability to learn from its own misclassifications. As a side contribution, we construct and release a large-scale gambling dataset at https://github.corn/AwesomeHuang/Bitcoin-Gambling-Dataset to facilitate future research in this field. Empirically, ETHGamDet achieves a F1-score of 0.72 and 0.89 in address classification and contract classification respectively, and offers novel and interesting insights.
C1 [Huang, Zhengjie; Liu, Zhenguang; Chen, Jianhai; He, Qinming] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Wu, Shuang] Nanyang Technol Univ, Singapore, Singapore.
   [Zhu, Lei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Peoples R China.
C3 Zhejiang University; Nanyang Technological University; Shandong Normal
   University; Hefei University of Technology
RP Liu, ZG (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
EM zj.h@zju.edu.cn; liuzhenguang2008@gmail.com; chenjh919@zju.edu.cn;
   hqm@zju.edu.cn; wushuang@outlook.sg; leizhu0608@gmail.com;
   eric.mengwang@gmail.com
RI Zhu, Lei/GQQ-1130-2022; chen, Jianhai/AHC-1374-2022; Wang,
   Meng/ITR-8699-2023
OI Zhu, Lei/0000-0002-5348-7532; chen, Jianhai/0000-0002-7278-8090; 
FU National Key R &D Program of China [2021YFB2700500]; National Natural
   Science Foundation of China [61902348]; Key R &D Program of Zhejiang
   Province [2021C01104]
FX This work was supported in part by the National Key R &D Program of
   China (2021YFB2700500); in part by the National Natural Science
   Foundation of China (No. 61902348); and in part by the Key R &D Program
   of Zhejiang Province (No. 2021C01104).
CR Akcora CG, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4439
   Albert E, 2018, LECT NOTES COMPUT SC, V11138, P513, DOI 10.1007/978-3-030-01090-4_30
   [Anonymous], 2022, About Us
   [Anonymous], 2022, DEGENS ETHEREUM BETT
   Ante L, 2021, TECHNOL FORECAST SOC, V170, DOI 10.1016/j.techfore.2021.120851
   Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8
   Ayed AB., 2017, INT J NETWORK SECUR, V9, P01
   Bhargavan K, 2016, PROCEEDINGS OF THE 2016 ACM WORKSHOP ON PROGRAMMING LANGUAGES AND ANALYSIS FOR SECURITY (PLAS'16), P91, DOI 10.1145/2993600.2993611
   Brent L, 2018, Arxiv, DOI arXiv:1809.03981
   Broadhurst R., 2018, SSRN 3226758
   Campbell-Verduyn M, 2018, CRIME LAW SOCIAL CH, V69, P283, DOI 10.1007/s10611-017-9756-5
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chen T, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P442, DOI 10.1109/SANER.2017.7884650
   Chen WL, 2019, IEEE INFOCOM SER, P964, DOI [10.1109/infocom.2019.8737364, 10.1109/INFOCOM.2019.8737364]
   Chen WL, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1409, DOI 10.1145/3178876.3186046
   Chirtoaca D, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON DECENTRALIZED APPLICATIONS AND INFRASTRUCTURES (DAPPS 2020), P100, DOI 10.1109/DAPPS49028.2020.00012
   Er-Rajy L, 2017, J Internet Bank Commer, V22, P1, DOI DOI 10.1057/EJIS.2012.26
   Feng Q, 2019, J NETW COMPUT APPL, V126, P45, DOI 10.1016/j.jnca.2018.10.020
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fu Y, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P1110, DOI 10.1145/3338906.3341175
   Grech N, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276486
   Grech N, 2019, PROC INT CONF SOFTW, P1176, DOI 10.1109/ICSE.2019.00120
   Guo Y, 2016, FINANC INNOV, V2, DOI 10.1186/s40854-016-0034-9
   Hildenbrandt E, 2018, P IEEE COMPUT SECUR, P204, DOI 10.1109/CSF.2018.00022
   Huang Z, 2022, BITCOIN GAMBLING DAT
   Kalra S, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23082
   Ke GL, 2017, ADV NEUR IN, V30
   Lee C, 2020, COMM COM INF SC, V1156, P520, DOI 10.1007/978-981-15-2777-7_42
   Li PL, 2021, INFORM SCIENCES, V561, P130, DOI 10.1016/j.ins.2021.01.081
   Liu J, 2019, IEEE ACCESS, V7, P77894, DOI 10.1109/ACCESS.2019.2921624
   Liu ZG, 2023, IEEE T KNOWL DATA EN, V35, P1296, DOI 10.1109/TKDE.2021.3095196
   Liu ZG, 2021, Arxiv, DOI arXiv:2106.09282
   Luu L, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P254, DOI 10.1145/2976749.2978309
   Macrinici D, 2018, TELEMAT INFORM, V35, P2337, DOI 10.1016/j.tele.2018.10.004
   Mehar MI, 2019, J CASES INF TECHNOL, V21, P19, DOI 10.4018/JCIT.2019010102
   Miller J. J., 2013, P SO ASS INF SYST C
   Mohanta BK, 2018, INT CONF COMPUT
   Morishima S, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107087
   Norta A, 2017, COMM COM INF SC, V721, P595, DOI 10.1007/978-981-10-5427-3_61
   Qian P, 2019, INT CONF CLOUD COMPU, P62, DOI [10.1109/CCIS48116.2019.9073733, 10.1109/ccis48116.2019.9073733]
   Scholten OJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240693
   Suiche M., 2017, DEF con, V25
   Szabo N., 1994, SMART CONTRACTS
   Team E, 2017, ETHERSCAN ETHEREUM B
   Tsankov P, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P67, DOI 10.1145/3243734.3243780
   Victor F, 2019, LECT NOTES COMPUT SC, V11598, P113, DOI 10.1007/978-3-030-32101-7_8
   Warren W., 2017, 0x: An open protocol for decentralized exchange on the ethereum blockchain, P04
   Webber J., 2012, P 3 ANN C SYST PROGR, P217, DOI DOI 10.1145/2384716.2384777
   Wood G, 2018, ETHEREUM YELLOW PAPE, P30
   Wu JJ, 2022, IEEE T SYST MAN CY-S, V52, P1156, DOI 10.1109/TSMC.2020.3016821
   Yan CY, 2022, CYBERSECURITY, V5, DOI 10.1186/s42400-021-00107-4
   Zheng ZB, 2018, INT J WEB GRID SERV, V14, P352, DOI 10.1504/IJWGS.2018.095647
   Zhou Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1371
   Zhuang Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3283
   Zichichi M, 2019, IEEE CONF COMPUT, P313, DOI [10.1109/infcomw.2019.8845133, 10.1109/INFCOMW.2019.8845133]
NR 55
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 539
EP 551
DI 10.1007/s13735-022-00264-3
EA NOV 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000884204900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, ZG
   Wang, LW
   Qiao, J
AF Liu, Zhiguang
   Wang, Liangwei
   Qiao, Jian
TI Visual and semantic ensemble for scene text recognition with gated dual
   mutual attention
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Text recognition; Multimodal fusion; Convolutional neural network
ID NETWORK; REPRESENTATION
AB Scene text recognition is a challenging task in computer vision due to the significant differences in text appearance, such as image distortion and rotation. However, linguistic prior helps individuals reason text from images even if some characters are missing or blurry. This paper investigates the fusion of visual cues and linguistic dependencies to boost recognition performance. We introduce a relational attention module to leverage visual patterns and word representations. We embed linguistic dependencies from a language model into the optimization framework to ensure that the predicted sequence captures the contextual dependencies within a word. We propose a dual mutual attention transformer that promotes cross-modality interactions such that the inter- and intra-correlations between visual and linguistic can be fully explored. The introduced gate function enables the model to learn to determine the contribution of each modality and further boost the model performance. Extensive experiments demonstrate that our method enhances the recognition performance of low-quality images and achieves state-of-the-art performance on datasets of texts from regular and irregular scenes.
C1 [Liu, Zhiguang; Wang, Liangwei] Huawei Noahs Ark Lab, Shenzhen, Peoples R China.
   [Qiao, Jian] Huawei Technol, Shenzhen, Peoples R China.
C3 Huawei Technologies; Huawei Technologies
RP Liu, ZG (corresponding author), Huawei Noahs Ark Lab, Shenzhen, Peoples R China.
EM liuzhiguang1@huawei.com; wangliangwei@huawei.com;
   john.qiaojian@huawei.com
CR Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163
   Ben-Younes H, 2019, ARXIV
   Chelba C, 2013, ARXIV
   Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Dehghani Mostafa, 2018, ARXIV
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Elliott D., 2016, P 5 WORKSH VIS LANG, P70, DOI [10.18653/v1/w16-3210, DOI 10.18653/V1/W16-3210]
   Fang SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P248, DOI 10.1145/3240508.3240571
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   He P, 2016, AAAI CONF ARTIF INTE, P3501
   Jaderberg M., 2014, ARXIV
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jaume G, 2019, ARXIV
   Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245
   Li H, 2019, AAAI CONF ARTIF INTE, P8610
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Liao L, 2022, INFORMATION, V13, DOI 10.3390/info13020069
   Liao MH, 2019, AAAI CONF ARTIF INTE, P8714
   Liu W., 2018, 32 AAAI C ARTIFICIAL
   Liu ZG, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P210, DOI 10.1145/3460426.3463612
   Liu ZC, 2018, AAAI CONF ARTIF INTE, P7194
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Vaswani A, 2017, ADV NEUR IN, V30
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Wan ZY, 2020, AAAI CONF ARTIF INTE, V34, P12120
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang TW, 2020, AAAI CONF ARTIF INTE, V34, P12216
   Yang HJ, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P657, DOI 10.1145/2671188.2749352
   Yang L, 2020, NEUROCOMPUTING, V414, P67, DOI 10.1016/j.neucom.2020.07.010
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Yue X., 2020, ECCV, VVolume 12364, P135, DOI [DOI 10.1007/978-3-030-58529-7_9, 10.1007/978-3-030-58529-7_9]
   Zhao WQ, 2021, LECT NOTES COMPUT SC, V12822, P570, DOI 10.1007/978-3-030-86331-9_37
NR 40
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 669
EP 680
DI 10.1007/s13735-022-00253-6
EA OCT 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000864588700003
DA 2024-07-18
ER

PT J
AU Houhou, I
   Zitouni, A
   Ruichek, Y
   Bekhouche, SE
   Kas, M
   Taleb-Ahmed, A
AF Houhou, Ihssane
   Zitouni, Athmane
   Ruichek, Yassine
   Bekhouche, Salah Eddine
   Kas, Mohamed
   Taleb-Ahmed, Abdelmalik
TI RGBD deep multi-scale network for background subtraction
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Computer vision; Background subtraction; Deep learning; DMSN; RGBD;
   Unseen videos; Scene-independent evaluation
ID CONVOLUTIONAL NEURAL-NETWORKS
AB This paper proposes a novel deep learning model called deep multi-scale network (DMSN) for background subtraction. This convolutional neural network is built to use RGB color channels and Depth maps as inputs with which it can fuse semantic and spatial information. In comparison with previous deep learning background subtraction techniques that lack information due to its use of only RGB channels, our RGBD version is able to overcome most of the drawbacks, especially in some particular kinds of challenges. Further, this paper introduces a new protocol for the SBM-RGBD dataset, concerning scene-independent evaluation, dedicated to Deep Learning methods to set up a competitive platform that includes more challenging situations. The proposed method proved its efficiency in solving the background subtraction in complex situations at different levels. The experimental results verify that the proposed work outperforms the state of the art on SBM-RGBD and GSM datasets.
C1 [Houhou, Ihssane; Zitouni, Athmane] Univ Biskra, LESIA, Biskra 07000, Algeria.
   [Houhou, Ihssane; Ruichek, Yassine; Bekhouche, Salah Eddine; Kas, Mohamed] Bourgogne Franche Comte Univ, CIAD UMR 7533, UTBM, F-90010 Belfort, France.
   [Taleb-Ahmed, Abdelmalik] Polytech Univ Hauts de France, IEMN DOAE, F-59300 Valenciennes, France.
C3 Universite Mohamed Khider Biskra; Universite de Franche-Comte;
   Universite de Technologie de Belfort-Montbeliard (UTBM); Universite de
   Bourgogne; Centre National de la Recherche Scientifique (CNRS);
   Universite Polytechnique Hauts-de-France; Universite de Lille
RP Houhou, I (corresponding author), Univ Biskra, LESIA, Biskra 07000, Algeria.; Houhou, I (corresponding author), Bourgogne Franche Comte Univ, CIAD UMR 7533, UTBM, F-90010 Belfort, France.
EM ihssane.houhou@univ-biskra.dz
RI KAS, Mohamed/AAB-5618-2021; Bekhouche, Salah Eddine/AAK-6387-2021;
   Ruichek, Yassine/GRX-3627-2022
OI KAS, Mohamed/0000-0001-5123-4681; Bekhouche, Salah
   Eddine/0000-0001-5538-7407; HOUHOU, Ihssane/0000-0002-5149-6478;
   RUICHEK, Yassine/0000-0003-4795-8569
CR Afifi M, 2019, MULTIMED TOOLS APPL, V78, P20835, DOI 10.1007/s11042-019-7424-8
   Bakkay MC, 2018, 2018 25 IEEE INT C I
   Bilodeau G-A, 2013, 2013 INT C COMPUTER
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Braham M., 2016, 2016 INT C SYSTEMS S, P1
   Camplani M, 2017, LECT NOTES COMPUT SC, V10590, P219, DOI 10.1007/978-3-319-70742-6_21
   Dorudian N, 2019, IEEE SENS J, V19, P8191, DOI 10.1109/JSEN.2019.2920515
   Dou JF, 2019, MULTIMED TOOLS APPL, V78, P14549, DOI 10.1007/s11042-018-6854-z
   Elgammal A., 2000, European Conference on Computer Vision, P751767
   Giraldo JH, 2020, 2020 IEEE INT C IMAG
   Gracewell J, 2020, MULTIMED TOOLS APPL, V79, P4639, DOI 10.1007/s11042-019-7411-0
   Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Liu RR, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103267
   Long, 2015, P IEEE C COMP VIS PA
   Maddalena L, 2015, INT C IMAGE ANAL PRO
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2017, LECT NOTES COMPUT SC, V10590, P254, DOI 10.1007/978-3-319-70742-6_24
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mandal M., 2020, IEEE Transactions on Intelligent Transportation Systems, P1
   Minematsu T, 2017, LECT NOTES COMPUT SC, V10590, P266, DOI 10.1007/978-3-319-70742-6_25
   Moyà-Alcover G, 2017, PATTERN RECOGN LETT, V96, P76, DOI 10.1016/j.patrec.2016.09.004
   Murgia J, 2014, LECT NOTES ARTIF INT, V8856, P380, DOI 10.1007/978-3-319-13647-9_35
   Noh, 2012, AS C COMP VIS
   Patil PW, 2021, IEEE SIGNAL PROC LET, V28, P489, DOI 10.1109/LSP.2021.3059195
   Patil PW, 2021, P IEEECVF WINTER C A
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   St-Charles P.-L., 2015, 2015 IEEE WINTER C A
   St-Charles P-L, 2014, P IEEE C COMPUTER VI
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sultana M., 2018, ARXIV PREPRINT ARXIV
   Sultana M, 2019, MACH VISION APPL, V30, P375, DOI 10.1007/s00138-018-0993-0
   Tezcan MO, 2021, IEEE ACCESS, V9, P53849, DOI 10.1109/ACCESS.2021.3071163
   Tezcan O, 2020, IEEE WINTER C APPL C
   Wang Y, 2014, P IEEE C COMPUTER VI
   Yu, 2020, IEEE ACCESS, V8
   Zeng DD, 2018, IEEE ACCESS, V6, P16010, DOI 10.1109/ACCESS.2018.2817129
   Zhao C, 2019, IEEE T CIRCUITS SYST
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 49
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 395
EP 407
DI 10.1007/s13735-022-00232-x
EA MAY 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000792990200001
DA 2024-07-18
ER

PT J
AU Muller-Budack, E
   Theiner, J
   Diering, S
   Idahl, M
   Hakimov, S
   Ewerth, R
AF Muller-Budack, Eric
   Theiner, Jonas
   Diering, Sebastian
   Idahl, Maximilian
   Hakimov, Sherzod
   Ewerth, Ralph
TI Multimodal news analytics using measures of cross-modal entity and
   context consistency
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cross-modal consistency; News analytics; Image-text relations; Image
   repurposing detection
AB The World Wide Web has become a popular source to gather information and news. Multimodal information, e.g., supplement text with photographs, is typically used to convey the news more effectively or to attract attention. The photographs can be decorative, depict additional details, but might also contain misleading information. The quantification of the cross-modal consistency of entity representations can assist human assessors' evaluation of the overall multimodal message. In some cases such measures might give hints to detect fake news, which is an increasingly important topic in today's society. In this paper, we present a multimodal approach to quantify the entity coherence between image and text in real-world news. Named entity linking is applied to extract persons, locations, and events from news texts. Several measures are suggested to calculate the cross-modal similarity of the entities in text and photograph by exploiting state-of-the-art computer vision approaches. In contrast to previous work, our system automatically acquires example data from the Web and is applicable to real-world news. Moreover, an approach that quantifies contextual image-text relations is introduced. The feasibility is demonstrated on two datasets that cover different languages, topics, and domains.
C1 [Muller-Budack, Eric; Hakimov, Sherzod; Ewerth, Ralph] TIB Leibniz Informat Ctr Sci & Technol, Hannover, Germany.
   [Theiner, Jonas; Diering, Sebastian; Idahl, Maximilian; Ewerth, Ralph] Leibniz Univ Hannover, L3S Res Ctr, Hannover, Germany.
C3 Leibniz University Hannover
RP Muller-Budack, E; Ewerth, R (corresponding author), TIB Leibniz Informat Ctr Sci & Technol, Hannover, Germany.; Ewerth, R (corresponding author), Leibniz Univ Hannover, L3S Res Ctr, Hannover, Germany.
EM eric.mueller@tib.eu; ralph.ewerth@tib.eu
OI Hakimov, Sherzod/0000-0002-7421-6213; Ewerth, Ralph/0000-0003-0918-6297;
   Muller-Budack, Eric/0000-0002-6802-1241
FU European Union's Horizon research and innovation programme 2020 under
   the Marie Sklodowska-Curie Grant [812997]; German Research Foundation
   (DFG: Deutsche Forschungsgemeinschaft) [388420599]
FX This work has partially received funding from the European Union's
   Horizon research and innovation programme 2020 under the Marie
   Sklodowska-Curie Grant Agreement No 812997, and the German Research
   Foundation (DFG: Deutsche Forschungsgemeinschaft, project number:
   388420599). We are very grateful to Avishek Anand (L3S Research Center,
   Leibniz University Hannover) for his valuable comments that improved the
   quality of the paper.
CR Ahsan U, 2017, IEEE WINT CONF APPL, P669, DOI 10.1109/WACV.2017.80
   [Anonymous], 2005, VISUAL COMMUN-US, DOI [DOI 10.1177/1470357205055928, 10.1177/1470357205055928]
   [Anonymous], 2017, IN PRESS
   [Anonymous], 2016, Newspaper Research Journal, DOI DOI 10.1177/0739532916648961
   [Anonymous], 2018, 11 INT C LANG RES EV
   [Anonymous], 2016, P 7 INT C MULT SYST, DOI DOI 10.1145/2910017.2910624
   Barthes R, 1977, IMAGE MUSIC TEXT, P332
   Bateman JA, 2014, TEXT AND IMAGE: A CRITICAL INTRODUCTION TO THE VISUAL/VERBAL DIVIDE, P1
   Brank J, 2018, INFORM SLOVENIA, V42
   Broersma M, 2013, JOURNAL PRACT, V7, P446, DOI 10.1080/17512786.2013.802481
   Buko B., 2022, ABS151203385 CORR, V22, P8878
   Chen BC, 2019, IEEE WINT CONF APPL, P73, DOI 10.1109/WACVW.2019.00019
   Chen BC, 2017, IEEE COMPUT SOC CONF, P1872, DOI 10.1109/CVPRW.2017.234
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ewerth, 2021, P IEEE CVF WINT C AP, P2928
   Gottschalk S, 2019, SEMANT WEB, V10, P1039, DOI 10.3233/SW-190355
   Gottschalk S, 2018, LECT NOTES COMPUT SC, V10843, P272, DOI 10.1007/978-3-319-93417-4_18
   Halliday M.A.K., 2013, Halliday's Introduction to Functional Grammar, DOI 10.4324/9780203431269
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Henning C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P14, DOI 10.1145/3078971.3078991
   Henning C, 2018, INT J MULTIMED INF R, V7, P43, DOI 10.1007/s13735-017-0142-y
   Hoffart J., 2011, P 2011 C EMPIRICAL M, P782, DOI DOI 10.3115/V1/D11-1072
   Huang GB, 2007, TECHNICAL REPORT 07, P10
   Jaiswal A, 2019, PROC CVPR IEEE, P11322, DOI 10.1109/CVPR.2019.01159
   Jaiswal A, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1465, DOI 10.1145/3123266.3123385
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1029, DOI 10.1109/TIFS.2012.2188796
   Kolitsas N., 2018, P 22 C COMP NAT LANG
   Marsh EE, 2003, J DOC, V59, P647, DOI 10.1108/00220410310506303
   Müller-Budack E, 2018, LECT NOTES COMPUT SC, V11216, P575, DOI 10.1007/978-3-030-01258-8_35
   Muller-Budack Eric, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P16, DOI 10.1145/3372278.3390670
   Vo N, 2017, IEEE I CONF COMP VIS, P2640, DOI 10.1109/ICCV.2017.286
   Otto C, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P168, DOI 10.1145/3323873.3325049
   Ramisa A, 2018, IEEE T PATTERN ANAL, V40, P1072, DOI 10.1109/TPAMI.2017.2721945
   Rizzo G., 2012, P DEM 13 C EUR ASS C, P73
   Rogers R., 2013, P 5 ANN ACM WEB SCI, P356, DOI [DOI 10.1145/2464464.2464511, 10.1145/2464464.2464511]
   Sabir E, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1337, DOI 10.1145/3240508.3240707
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Unsworth L., 2006, 33rd International Systemic Functional Congress, P1165
   Wan, 2019, P 2019 C EMP METH NA, P4621, DOI [10.18653/v1/D19-1469, DOI 10.18653/V1/D19-1469]
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Xiaopeng Li, 2017, Applied Cryptography and Network Security. 15th International Conference, ACNS 2017. Proceedings: LNCS 10355, P103, DOI 10.1007/978-3-319-61204-1_6
   Xiong YJ, 2015, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2015.7298768
   Ye KR, 2021, IEEE T PATTERN ANAL, V43, P1308, DOI 10.1109/TPAMI.2019.2947440
   ZHANG MD, 2018, ARXIV180708205
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 47
TC 11
Z9 11
U1 2
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2021
VL 10
IS 2
SI SI
BP 111
EP 125
DI 10.1007/s13735-021-00207-4
EA APR 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SK0DY
UT WOS:000645187300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Xue, LX
   Zhang, A
   Wang, RG
   Yang, J
AF Xue, Lixia
   Zhang, Awen
   Wang, Ronggui
   Yang, Juan
TI PSNet: position-shift alignment network for image caption
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image caption; Grid features; Region features; Transformer
AB Recently, Transformer-based models have gained increasing popularity in the field of image captioning. The global attention mechanism of the Transformer facilitates the integration of region and grid features, leading to a significant improvement in accuracy. However, combining two features through direct fusion may lead to inevitable semantic noise, which is caused by non-synergistic issue of the region and grid features; meanwhile, the additional detector to extract region features also decrease the efficiency of the model. In this paper, we introduce a novel position-shift alignment network (PSNet) to exploit the advantages of the two features. Concretely, we embed a simple detector DETR into the model and extracted region features based on grid features to improve model efficiency. Moreover, we propose a P-shift alignment module to address semantic noise caused by non-synergistic issue of the region and grid features. To validate our model, we conduct extensive experiments and visualization on the MS-COCO dataset, and results show that PSNet is qualitatively competitive with existing models under comparable experimental conditions.
C1 [Xue, Lixia; Zhang, Awen; Wang, Ronggui; Yang, Juan] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Peoples R China.
EM yangjuan6985@163.com
RI lin, lin/KCZ-0185-2024; Li, Xintong/KHD-6915-2024; Lin,
   Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China; National Key R &D Program
   of China [2020YFC1512601];  [U20B2044]
FX We express our sincere thanks to the anonymous reviewers for their
   helpful comments and suggestions to raise the standard of this paper.
   This work was supported partially by the National Key R &D Program of
   China (Grant Number 2020YFC1512601), National Natural Science Foundation
   of China (Grant Number 62106064) and National Natural Science Foundation
   of China (Grant Number U20B2044).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Carion N, 2020, Arxiv, DOI [arXiv:2005.12872, DOI 10.48550/ARXIV.2005.12872]
   Chen LZ, 2023, DISPLAYS, V77, DOI 10.1016/j.displa.2023.102377
   Cheng Y, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P889, DOI 10.1145/3077136.3080671
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Fan Z, 2021, INT JOINT C ART INT
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gupta Ankush., 2012, P AAAI C ART INT
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He S, 2020, Arxiv, DOI arXiv:2004.14231
   Herdade S, 2019, Neural information processing systems
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jiang H., 2020, IEEE CVF C COMP VIS, DOI 10.1109/CVPR42600.2020.01028
   Jiang WT, 2022, IEEE T CIRC SYST VID, V32, P7706, DOI 10.1109/TCSVT.2022.3181490
   Jiang ZT, 2023, INT J MULTIMED INF R, V12, DOI 10.1007/s13735-023-00266-9
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo Y, 2021, AAAI C ARTIFICIAL IN
   Ma YW, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109420
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Najibi M, 2019, IEEE I CONF COMP VIS, P9744, DOI 10.1109/ICCV.2019.00984
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang CZ, 2022, APPL INTELL, V52, P6575, DOI 10.1007/s10489-021-02734-3
   Xian TT, 2022, IEEE T CIRC SYST VID, V32, P5762, DOI 10.1109/TCSVT.2022.3155795
   Xiao XY, 2019, IEEE T MULTIMEDIA, V21, P2942, DOI 10.1109/TMM.2019.2915033
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao ZY, 2021, Arxiv, DOI arXiv:2104.01318
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zeng P, 2022, INT JOINT C ART INT
   Zhang J, 2021, IEEE T MULTIMEDIA, V23, P92, DOI 10.1109/TMM.2020.2976552
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 58
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 42
DI 10.1007/s13735-023-00307-3
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z5EF5
UT WOS:001112299500001
DA 2024-07-18
ER

PT J
AU Tripathy, SK
   Srivastava, R
AF Tripathy, Santosh Kumar
   Srivastava, Rajeev
TI AMS-CNN: Attentive multi-stream CNN for video-based crowd counting
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Crowd count and density estimation; Crowd analysis; 3D CNN (C3D);
   Spatial-temporal features; Attentive density-map
ID CONVOLUTIONAL NEURAL-NETWORK
AB In recent years video-based crowd counting and density estimation (CCDE) have become essential for crowd analysis. Current approaches rarely exploit spatial-temporal features for CCDE, and they also usually do not consider measures to minimize the frame's background influence for obtaining crowd density maps, which has resulted in lower performance in terms of Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Again, attention to individual feature set's response toward crowd counting is also neglected. To this end, we are motivated to design an end-to-end trainable attentive multi-stream convolutional neural network (AMS-CNN) for crowd counting. At first, a multi-stream CNN (MS-CNN) is designed to obtain crowd density maps. The MS-CNN comprises three streams to fuse deep spatial, temporal, and spatial foreground features from different cues of the crowd video dataset, like frames, the volume of frames, and foregrounds of frames. To improve the accuracy, we designed three stream-wise attention modules to generate attentive crowd density maps, and their relative average is obtained using a relative averaged attentive density-map (RAAD) layer. The relative averaged density map is concatenated with the MS-CNN output, followed by two-stage CNN blocks to get the final density map. The experiments are demonstrated on three publicly available crowd density video datasets: Mall, UCSD, and Venice. We obtained promising and better results in terms of MAE and RMSE as compared with state-of-the-art approaches.
C1 [Tripathy, Santosh Kumar; Srivastava, Rajeev] Indian Inst Technol BHU, Comp & Vis Lab, Dept Comp Sci & Engn, Varanasi 221005, UP, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Tripathy, SK (corresponding author), Indian Inst Technol BHU, Comp & Vis Lab, Dept Comp Sci & Engn, Varanasi 221005, UP, India.
EM santoshktripathy.rs.cse18@iitbhu.ac.in; rajeev.cse@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556; Tripathy, Santosh
   Kumar/0000-0002-1995-2525
FU 'PARAM Shivay Facility' under the National SupercomputingMission,
   Government of India at the Indian Institute of Technology, Varanasi
FX The support and the resources provided by 'PARAM Shivay Facility' under
   the National SupercomputingMission, Government of India at the Indian
   Institute of Technology, Varanasi, are gratefully acknowledged.
CR An S, 2007, PROC CVPR IEEE, P1033
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   CHEN K, 2013, PROC CVPR IEEE, P2467, DOI [DOI 10.1109/CVPR.2013.319, 10.1109/CVPR.2013.319]
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Cho SH, 2014, PATTERN RECOGN LETT, V44, P64, DOI 10.1016/j.patrec.2013.11.017
   Han K, 2017, J ADV COMPUT INTELL, V21, P632, DOI 10.20965/jaciii.2017.p0632
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Kang Dongyeon Daniel, 2018, 2018 IEEE Photonics Conference (IPC), DOI 10.1109/IPCon.2018.8527218
   Kingma D. P., 2014, arXiv
   Lempitsky V., 2010, ADV NEURAL INF PROCE, V3, P1
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   Liu Z, 2019, IEEE ACCESS, V7, P88789, DOI 10.1109/ACCESS.2019.2926881
   Miao YQ, 2019, PATTERN RECOGN LETT, V125, P113, DOI 10.1016/j.patrec.2019.04.012
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Saqib M, 2019, IEEE ACCESS, V7, P35317, DOI 10.1109/ACCESS.2019.2904712
   Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551
   Shi X, 2020, REAL TIME DEEP NETWO
   statistical visual computing laboratory (SVCL) at UC SanDiego (UCSD), UCSD AN DET DAT
   Tripathy SK, 2020, MULTIMEDIA SYST, V26, P585, DOI 10.1007/s00530-020-00667-4
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wang YT, 2020, NEUROCOMPUTING, V382, P87, DOI 10.1016/j.neucom.2019.11.051
   Wei XL, 2019, PATTERN RECOGN LETT, V119, P12, DOI 10.1016/j.patrec.2017.12.002
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Yang DS, 2020, MULTIMED TOOLS APPL, V79, P19435, DOI 10.1007/s11042-020-08827-4
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang SH, 2017, IEEE I CONF COMP VIS, P3687, DOI 10.1109/ICCV.2017.396
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou Yuan, 2020, IEEE T CYBERN
NR 40
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2021
VL 10
IS 4
BP 239
EP 254
DI 10.1007/s13735-021-00220-7
EA OCT 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XC7OC
UT WOS:000713086900001
DA 2024-07-18
ER

PT J
AU Chahkandi, V
   Fadaeieslam, MJ
   Yaghmaee, F
AF Chahkandi, Vahid
   Fadaeieslam, Mohammad Javad
   Yaghmaee, Farzin
TI Improvement of image description using bidirectional LSTM
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image description; Bidirectional LSTM; Multimodal space; Region-based
   Convolutional Neural Networks (RCNN)
ID MODELS
AB As a high-level technique, automatic image description combines linguistic and visual information in order to extract an appropriate caption for an image. In this paper, we have proposed a method based on a recurrent neural network to synthesize descriptions in multimodal space. The innovation of this paper consists in generating sentences with variable length and novel structures. The Bi-LSTM network has been applied to achieve this purpose. This paper utilizes the inner product as common space, which reduces the computational cost and improves results. We have evaluated the performance of the proposed method on benchmark datasets: Flickr8K and Flickr30K. The results demonstrate that Bi-LSTM has better efficiency, as compared to the unidirectional model.
C1 [Chahkandi, Vahid; Fadaeieslam, Mohammad Javad; Yaghmaee, Farzin] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Fadaeieslam, MJ (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM fadaei@semnan.ac.ir
RI Yaghmaee, Farzin/AAZ-6590-2021; Fadaeieslam, Mohammad
   Javad/AAZ-2625-2021
OI Yaghmaee, Farzin/0000-0001-7430-542X; Fadaeieslam, Mohammad
   Javad/0000-0002-8560-6444
CR [Anonymous], P 13 C EUR ASS COMP
   [Anonymous], 2011, P 15 C COMP NAT LANG
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], P 2013 C EMP METH NA
   [Anonymous], 2015, ICML
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2012, P 50 ANN M ASS COMP
   [Anonymous], 2011, P C EMP METH NAT LAN
   [Anonymous], 2014, T ASSOC COMPUT LING
   [Anonymous], 2010, ECCV
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2013, CVPR
   [Anonymous], 2015, INT C LEARN REPR
   [Anonymous], AAAI
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Coyne B., 2001, SIGGRAPH '01
   Gupta Ankush., 2012, P AAAI C ART INT
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Karpathy A., 2015, P IEEE C COMP VIS PA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
NR 26
TC 5
Z9 6
U1 1
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2018
VL 7
IS 3
BP 147
EP 155
DI 10.1007/s13735-018-0158-y
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HI5SF
UT WOS:000456513600001
DA 2024-07-18
ER

PT J
AU Dorfer, M
   Schlüter, J
   Vall, A
   Korzeniowski, F
   Widmer, G
AF Dorfer, Matthias
   Schlueter, Jan
   Vall, Andreu
   Korzeniowski, Filip
   Widmer, Gerhard
TI End-to-end cross-modality retrieval with CCA projections and pairwise
   ranking loss
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cross-modality retrieval; Canonical correlation analysis; Ranking loss;
   Neural network; Joint embedding space
AB Cross-modality retrieval encompasses retrieval tasks where the fetched items are of a different type than the search query, e. g., retrieving pictures relevant to a given text query. The state-of-the-art approach to cross-modality retrieval relies on learning a joint embedding space of the two modalities, where items from either modality are retrieved using nearest-neighbor search. In this work, we introduce a neural network layer based on canonical correlation analysis (CCA) that learns better embedding spaces by analytically computing projections that maximize correlation. In contrast to previous approaches, the CCA layer allows us to combine existing objectives for embedding space learning, such as pairwise ranking losses, with the optimal projections of CCA. We show the effectiveness of our approach for cross-modality retrieval on three different scenarios (text-to-image, audio-sheet-music and zero-shot retrieval), surpassing both Deep CCA and a multi-view network using freely learned projections optimized by a pairwise ranking loss, especially when little training data is available (the code for all three methods is released at: https:// github. com/ CPJKU/ cca_layer).
C1 [Dorfer, Matthias; Vall, Andreu; Korzeniowski, Filip; Widmer, Gerhard] Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria.
   [Schlueter, Jan; Widmer, Gerhard] Austrian Res Inst Artificial Intelligence, A-1010 Vienna, Austria.
C3 Johannes Kepler University Linz
RP Dorfer, M (corresponding author), Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria.
EM matthias.dorfer@jku.at
RI Widmer, Gerhard/B-8218-2017
OI Widmer, Gerhard/0000-0003-3531-1282
FU Johannes Kepler University Linz
FX Open access funding provided by Johannes Kepler University Linz.
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   Andrew G., 2013, P ICML, P1247
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2010, CALTECH UCSD BIRDS
   [Anonymous], MATRIX COOKBOOKK NOV
   [Anonymous], P 17 INT SOC MUS INF
   [Anonymous], ARXIV E PRINTS
   [Anonymous], CORR
   [Anonymous], P 6 EUR C COMP VIS E
   [Anonymous], 2013, CoRR
   [Anonymous], 2008, P IND C COMP VIS GRA
   Boulanger-Lewandowski N., 2012, P 29 INT C MACH LEAR, P1881
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Chung Junyoung, 2014, ARXIV14123555
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Deng J., 2009, CVPR09
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hermann K. M., 2013, arXiv
   Ioffe S., 2015, INT C MACHINE LEARN, P448, DOI DOI 10.5555/3045118.3045167
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Magnus JR., 1985, ECON THEOR, V1, P179, DOI DOI 10.1017/S0266466600011129
   Mao Junhua., 2014, Explain images with multimodal recurrent neural networks
   Mardia K.V., 1979, Multivariate analysis. Probability and mathematical statistics
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Simonyan K., 2014, 14091556 ARXIV
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
NR 31
TC 25
Z9 26
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2018
VL 7
IS 2
BP 117
EP 128
DI 10.1007/s13735-018-0151-5
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GR5AE
UT WOS:000442633600003
OA Green Published, Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Kong, QY
   Jiang, J
   Yang, JY
   Wang, Q
AF Kong, Qiuyu
   Jiang, Jie
   Yang, Junyan
   Wang, Qi
TI Hierarchical bidirectional aggregation with prior guided transformer for
   few-shot segmentation
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few-shot semantic segmentation; Transformer; Information aggregation;
   Affinity map
AB Recent years have witnessed significant interest in few-shot segmentation methods, with the aim of predicting novel categories in a query image given the limited labeled support set. Despite demonstrated successes, some existing methods might suffer from the intra-class inconsistency between query and support samples for local unidirectional information guidance. We propose a hierarchical bidirectional aggregation with prior guided transformer for abundant intra-class common cues. Specifically, we adaptively aggregate support and query features by a non-local bidirectional information flow in a hierarchical manner to derive a closer and deeper correlation. We further introduce the prior affinity map to impart inductive bias and eliminate interfering semantics. Experimental results on three benchmark datasets demonstrate that the proposed method surpasses some previous state-of-the-art approaches well, especially performing favorably in handling challenging situations under 1-shot setting.
C1 [Kong, Qiuyu; Jiang, Jie; Yang, Junyan; Wang, Qi] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Jiang, J (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China.
EM kqymio@nudt.edu.cn; jiejiang@nudt.edu.cn; junyanyang@nudt.edu.cn;
   wq21e@nudt.edu.cn
OI Jiang, Jie/0000-0001-9666-815X
FU National Natural Science Foundation of China (NSFC) [61873274]
FX This work is supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant Number 61873274
CR Azad R, 2021, IEEE WINT CONF APPL, P2673, DOI 10.1109/WACV48630.2021.00272
   Boudiaf M, 2021, PROC CVPR IEEE, P13974, DOI 10.1109/CVPR46437.2021.01376
   Boyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P763, DOI 10.1007/978-3-030-58598-3_45
   Cao ZY, 2019, IEEE ACCESS, V7, P166109, DOI 10.1109/ACCESS.2019.2953465
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen X, 2022, EFFICIENT VISUAL TRA
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan Qi, 2022, Self-support few-shot semantic segmentation
   Graham B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12239, DOI 10.1109/ICCV48922.2021.01204
   Guo JY, 2022, PROC CVPR IEEE, P12165, DOI 10.1109/CVPR52688.2022.01186
   Han K., 2021, Adv. Neural Inf. Process. Syst., V34, P15908, DOI DOI 10.48550/ARXIV.2103.00112
   Haochen Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P730, DOI 10.1007/978-3-030-58601-0_43
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S., 2021, arXiv
   Kang D., 2022, CVPR, P9979
   Li G, 2021, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR46437.2021.00823
   Li X, 2020, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR42600.2020.00294
   Li Y., 2022, Adv. Neural Inf. Process. Syst., V35, P12934, DOI 10.48550/arXiv.2206.01191
   Liu WD, 2023, IEEE T MULTIMEDIA, V25, P5130, DOI 10.1109/TMM.2022.3187855
   Liu Y., 2020, P EUR C COMP VIS ECC, P142, DOI DOI 10.1007/978-3-030-58545-79
   Liu Y, 2022, P IEEECVF C COMPUTER, P11573
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu ZH, 2021, Arxiv, DOI arXiv:2108.03032
   Luo XL, 2023, Arxiv, DOI arXiv:2109.13788
   Min J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6921, DOI 10.1109/ICCV48922.2021.00686
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaban A., 2017, ONE SHOT LEARNING SE, DOI [10.5244/c.31.167, DOI 10.5244/C.31.167]
   Shi X, 2022, ECCV
   Tian Z., 2020, IEEE T PATTERN ANAL, DOI [10.1109/pami.2020.3013717, DOI 10.1109/PAMI.2020.3013717]
   Wang HC, 2021, IEEE WINT CONF APPL, P525, DOI 10.1109/WACV48630.2021.00057
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Xie EZ, 2021, ADV NEUR IN, V34
   Yang L., 2021, arXiv
   Yu Q., 2021, arXiv
   Yuan K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P559, DOI 10.1109/ICCV48922.2021.00062
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang GW, 2021, ADV NEUR IN, V34
   Zhang S, 2022, arXiv
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou DQ, 2021, Arxiv, DOI [arXiv:2103.11886, 10.48550/arXiv.2103.11886, DOI 10.48550/ARXIV.2103.11886]
NR 48
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 17
DI 10.1007/s13735-023-00282-9
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N7XB0
UT WOS:001039085600002
DA 2024-07-18
ER

PT J
AU Ilesanmi, AE
   Ilesanmi, T
   Idowu, OP
   Torigian, DA
   Udupa, JK
AF Ilesanmi, Ademola E.
   Ilesanmi, Taiwo
   Idowu, Oluwagbenga P.
   Torigian, Drew A.
   Udupa, Jayaram K.
TI Organ segmentation from computed tomography images using the 3D
   convolutional neural network: a systematic review
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE 3D convolutional neural network; Computed tomography images;
   Segmentation of organs; Image preprocessing
ID SPLIT BREGMAN METHOD; CT IMAGES; U-NET; MODEL
AB Computed tomography images are scans that combine a series of X-rays with computer processing techniques to display organs in the body. Recently, 3D CNN models have become effective in tasks relating to recognition, delineation, and classification. Therefore we propose a review to summarize different 3D CNN algorithms for segmenting organs in computed tomography images. This work systematically applies a two-stage procedure for review. A thorough screening of abstracts and titles to ascertain their relevance was done. Research papers published in the academic repositories were selected, analyzed, and reviewed. Insight relating to 3D organ segmentation is provided, with content such as database usage, disadvantages, and advantages. A comparison of two accuracies was carried out with a graph depicting database categories. Important insights, limitations, observations, and future directions were elucidated. After careful investigation, we observe that the encoder-decoder network is predominant for segmentation. The encoder-decoder framework provides a seamless procedure to segment CT images. A prediction of future trends with insightful recommendations for researchers is proposed. Finally, findings suggest that CNN algorithms produce good accuracies despite their limitations.
C1 [Ilesanmi, Ademola E.; Torigian, Drew A.; Udupa, Jayaram K.] Univ Penn, Dept Radiol, Med Image Proc Grp, Goddard Bldg,3710 Hamilton Walk,6th Floor, Philadelphia, PA 19104 USA.
   [Ilesanmi, Taiwo] Natl Populat Commiss, Abuja, Nigeria.
   [Idowu, Oluwagbenga P.] Sichuan Univ, West China Hosp, Chengdu, Peoples R China.
C3 University of Pennsylvania; Sichuan University
RP Ilesanmi, AE (corresponding author), Univ Penn, Dept Radiol, Med Image Proc Grp, Goddard Bldg,3710 Hamilton Walk,6th Floor, Philadelphia, PA 19104 USA.
EM Ademola.Ilesanmi@Pennmedicine.upenn.edu
CR Abramova V, 2021, COMPUT MED IMAG GRAP, V90, DOI 10.1016/j.compmedimag.2021.101908
   Altini N, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8020040
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bae HJ, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105119
   Diniz JOB, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105685
   Belal SL, 2019, EUR J RADIOL, V113, P89, DOI 10.1016/j.ejrad.2019.01.028
   Ben Salah M, 2010, IEEE T IMAGE PROCESS, V19, P220, DOI 10.1109/TIP.2009.2032940
   Boubnovski MM, 2022, CLIN RADIOL, V77, pE620, DOI 10.1016/j.crad.2022.04.012
   Cao Jianyun, 2020, COMPUT BIOL MED, V21
   Cao YD, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107813
   Cao Z, 2021, NEUROCOMPUTING, V453, P357, DOI 10.1016/j.neucom.2020.08.086
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen W, 2021, PROCEDIA COMPUT SCI, V192, P543, DOI 10.1016/j.procs.2021.08.056
   Chen X., 2019, ARXIV PREPRINT ARXIV
   Chen YL, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.01110
   Chi JN, 2021, NEUROCOMPUTING, V459, P81, DOI 10.1016/j.neucom.2021.06.021
   Chung M, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102023
   Dogan RO, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106141
   Dutande P, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102527
   Ecder T, 2013, KIDNEY INT SUPPL, V3, P335, DOI 10.1038/kisup.2013.70
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Gao YH, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101831
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu LY, 2021, ARTIF INTELL MED, V121, DOI 10.1016/j.artmed.2021.102189
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Heinrich Mattias P., 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P329, DOI 10.1007/978-3-319-66179-7_38
   Heinrich MP, 2019, MED IMAGE ANAL, V54, P1, DOI 10.1016/j.media.2019.02.006
   Heinrich MP, 2015, MICCAI CHALL WORKSH
   Hsieh J., 2013, Curr. Radiol. Rep., V1, P39, DOI 10.1007/s40134-012-0003-7
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang GL, 2017, IEEE ICC
   Huang ZC, 2020, INFORM SCIENCES, V522, P241, DOI 10.1016/j.ins.2020.02.067
   Hubbard LD, 1999, OPHTHALMOLOGY, V106, P2269, DOI 10.1016/S0161-6420(99)90525-0
   Ilesanmi AE, 2021, COMPLEX INTELL SYST, V7, P2179, DOI 10.1007/s40747-021-00428-4
   Ilesanmi AE, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102396
   Ilesanmi AE, 2021, BIOCYBERN BIOMED ENG, V41, P802, DOI 10.1016/j.bbe.2021.05.007
   Ilesanmi AE, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103879
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isensee F., 2018, nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation, DOI DOI 10.1007/978-3-658-25326-4_7
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kim H, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63285-0
   Koesten LM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1277, DOI 10.1145/3025453.3025838
   Kong B, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2019.101688
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lahoud P, 2021, J ENDODONT, V47, P827, DOI 10.1016/j.joen.2020.12.020
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li XG, 2020, NEURAL NETWORKS, V124, P75, DOI 10.1016/j.neunet.2020.01.005
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Z., 2021, COMPUT METH PROG BIO, V205, DOI [10.1016/j.cmpb.2021.106070, DOI 10.1016/J.CMPB.2021.106070]
   Lyu TL, 2021, COMPUT METH PROG BIO, V211, DOI 10.1016/j.cmpb.2021.106417
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mohassel Payman, 2020, Proceedings on Privacy Enhancing Technologies, V2020, P414, DOI 10.2478/popets-2020-0080
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Payer C, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P124, DOI 10.5220/0008975201240133
   Qayyum A, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104097
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Royal College of Radiologists, OLD RAD
   Ruiz-Cruz Jorge A., 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413067
   Sánchez JCG, 2020, PHYS MEDICA, V69, P241, DOI 10.1016/j.ejmp.2019.12.014
   Shi XJ, 2015, ADV NEUR IN, V28
   Shu X, 2021, NEUROCOMPUTING, V453, P438, DOI 10.1016/j.neucom.2021.01.081
   Su J, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107471
   Sun G, 2021, COMPUT METH PROG BIO, V211, DOI 10.1016/j.cmpb.2021.106422
   Tan JX, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101817
   Tong YB, 2019, MED IMAGE ANAL, V51, P169, DOI 10.1016/j.media.2018.11.002
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Udupa JK, 2014, MED IMAGE ANAL, V18, P752, DOI 10.1016/j.media.2014.04.003
   Ulyanov Dmitry, 2016, arXiv
   Wan H, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106609
   Wang JK, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106268
   Wei XQ, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/9956983
   Wenshuai Zhao, 2020, Informatics in Medicine Unlocked, V19, P386, DOI 10.1016/j.imu.2020.100357
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xie XW, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107024
   Xu JC, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104925
   Xu XN, 2018, INT J COMPUT ASS RAD, V13, P967, DOI 10.1007/s11548-018-1733-7
   Yang JZ, 2021, COMPUT MED IMAG GRAP, V92, DOI 10.1016/j.compmedimag.2021.101957
   Yang YY, 2012, J MATH ANAL APPL, V389, P351, DOI 10.1016/j.jmaa.2011.11.073
   You J, 2021, COMPUT MED IMAG GRAP, V90, DOI 10.1016/j.compmedimag.2021.101898
   Yuan WG, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101731
   Yuyin Zhou, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P693, DOI 10.1007/978-3-319-66182-7_79
   Zhang C, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104875
   Zhang C, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104424
   Zhang GY, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103172
   Zhang Y, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101884
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.3978/j.issn.2305-5839.2015.12.38
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou XR, 2020, ADV EXP MED BIOL, V1213, P135, DOI 10.1007/978-3-030-33128-3_9
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu ZT, 2018, INT CONF 3D VISION, P682, DOI 10.1109/3DV.2018.00083
NR 100
TC 5
Z9 5
U1 4
U2 34
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 315
EP 331
DI 10.1007/s13735-022-00242-9
EA JUL 2022
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000826135800001
DA 2024-07-18
ER

PT J
AU Naosekpam, V
   Sahu, N
AF Naosekpam, Veronica
   Sahu, Nilkanta
TI Text detection, recognition, and script identification in natural scene
   images: a Review
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Text Detection; Text recognition; Script identification; Scene
   understanding
ID ORIENTED TEXT; NEURAL-NETWORK; MEAN SHIFT; EXTRACTION; CLASSIFICATION;
   LOCALIZATION; ALGORITHM
AB Text in natural scene images plays a vital role in scene understanding. It contains a rich and abundant amount of valuable semantic information useful in many applications such as analysis of products' labels, autonomous driving, and blind navigation. Consequently, detection, recognition, and identification of scripts of texts present in scene images have recently received massive attention. This paper intends to walk through the advances on the mentioned topics, mainly focusing on the approaches proposed in the last 8-10 years. As per our knowledge, this paper is the first to provide a review on the scene text script identification. We also provide a clear and precise classification between conventional-, deep learning-, and hybrid-based methods, including their advantages and disadvantages. State-of-the-art evaluation metrics, benchmark datasets' characteristics, and performances of the existing methods are also analyzed and discussed. Lastly, we present an insight into potential research directions to complete the review. We hope this review will provide a brief insight for the researchers into scene text understanding.
C1 [Naosekpam, Veronica; Sahu, Nilkanta] Indian Inst Informat Technol Guwahati, Dept Comp Sci & Engn, Gauhati, Assam, India.
RP Naosekpam, V (corresponding author), Indian Inst Informat Technol Guwahati, Dept Comp Sci & Engn, Gauhati, Assam, India.
EM veronica.naosekpam@iiitg.ac.in; nilkanta@iiitg.ac.in
OI Naosekpam, Veronica/0000-0002-4850-4713
CR Ali M, 2016, IEEE IMAGE PROC, P2891, DOI 10.1109/ICIP.2016.7532888
   Ansari GJ, 2018, FUTURE GENER COMP SY, V87, P328, DOI 10.1016/j.future.2018.04.074
   Atienza R, 2021, LECT NOTES COMPUT SC, V12821, P319, DOI 10.1007/978-3-030-86549-8_21
   Baek J, 2019, IEEE I CONF COMP VIS, P4714, DOI 10.1109/ICCV.2019.00481
   Bai B, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P262, DOI 10.1109/DAS.2014.34
   Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg AC, 2005, PROC CVPR IEEE, P26
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Bochkovskiy A., 2020, PREPRINT
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Burie JC, 2015, PROC INT CONF DOC, P1161, DOI 10.1109/ICDAR.2015.7333943
   CAI Y, 2019, NEURAL COMPUT APPL
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Chakraborty N, 2021, J AMB INTEL HUM COMP, V12, P7997, DOI 10.1007/s12652-020-02528-4
   Chee Kheng Chng, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1571, DOI 10.1109/ICDAR.2019.00252
   Chen DT, 2001, PROC CVPR IEEE, P621
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chen J, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-019-2673-8
   Chen Xiangrong, 2004, Computer vision and pattern recognition, V2, pII
   Cho MS, 2011, PROC INT CONF DOC, P1034, DOI 10.1109/ICDAR.2011.209
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai PW, 2021, PROC CVPR IEEE, P7389, DOI 10.1109/CVPR46437.2021.00731
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dastidar S. G., 2021, P INT C COMP INT COM, P150
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Deng LJ, 2019, IEEE ACCESS, V7, P153400, DOI 10.1109/ACCESS.2019.2948405
   Deng LJ, 2019, NEUROCOMPUTING, V334, P134, DOI 10.1016/j.neucom.2019.01.013
   Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Feng YY, 2016, INT C PATT RECOG, P645, DOI 10.1109/ICPR.2016.7899707
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Fujii Y, 2017, PROC INT CONF DOC, P161, DOI 10.1109/ICDAR.2017.35
   Ghosh S, 2011, PROC INT CONF DOC, P294, DOI 10.1109/ICDAR.2011.67
   Gllavata J, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY (ISSPIT), VOLS 1 AND 2, P589
   Goel V, 2013, PROC INT CONF DOC, P398, DOI 10.1109/ICDAR.2013.87
   Gomez L, 2017, PATTERN RECOGN, V67, P85, DOI 10.1016/j.patcog.2017.01.032
   Gómez L, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P192, DOI 10.1109/DAS.2016.64
   Gómez L, 2015, PROC INT CONF DOC, P206, DOI 10.1109/ICDAR.2015.7333753
   Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Guan'an Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P275, DOI 10.1007/978-3-030-58598-3_17
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   Hanif Shehzad Muhammad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1, DOI 10.1109/ICDAR.2009.172
   Hanif S.M., 2008, Pattern Recognition, P1
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He P, 2016, AAAI CONF ARTIF INTE, P3501
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Hoiem D., 2009, World Literature Today
   Hu H, 2017, IEEE I CONF COMP VIS, P4950, DOI 10.1109/ICCV.2017.529
   Huang L., 2015, Comput. Sci.
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M., 2014, CORR
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jiang Y., 2017, ARXIV PREPRINT ARXIV, P1, DOI [10.1007/978-3-319-53316-2_1, DOI 10.1007/S10586-017-1449-4]
   Kang C, 2017, AAAI CONF ARTIF INTE, P4103
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kaur A, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P70, DOI 10.1109/ICIMIA.2017.7975565
   Kaur H, 2018, NATURAL SCENE TEXT L
   Keserwani Prateek, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P987, DOI 10.1109/ICDAR.2019.00162
   Keserwani P, 2021, IEEE ACCESS, V9, P36802, DOI 10.1109/ACCESS.2021.3063030
   Khatib T., 2015, SCI RES ESSAYS, V10, P105, DOI DOI 10.5897/SRE2014.6146
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kobchaisawat T, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010117
   Koo HI, 2012, IEEE T IMAGE PROCESS, V21, P1169, DOI 10.1109/TIP.2011.2166972
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification, P18
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar D, 2013, IEEE WORKSHOP COMPU, P1
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lee CY, 2019, PROC INT CONF DOC, P14, DOI 10.1109/ICDARW.2019.60125
   Lee CY, 2014, PROC CVPR IEEE, P4050, DOI 10.1109/CVPR.2014.516
   Li Y, 2012, INT C PATT RECOG, P681
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lienhart R, 1996, P SOC PHOTO-OPT INS, V2666, P180, DOI 10.1117/12.234741
   Lin CH, 2017, PROC CVPR IEEE, P2252, DOI 10.1109/CVPR.2017.242
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Litman Ron, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11959, DOI 10.1109/CVPR42600.2020.01198
   Liu J, 2019, CORR ABS190311800 AR
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2016, INT C PATT RECOG, P3999, DOI 10.1109/ICPR.2016.7900259
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Liu YL, 2019, PROC CVPR IEEE, P9604, DOI 10.1109/CVPR.2019.00984
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu LQ, 2021, J INTELL FUZZY SYST, V40, P551, DOI 10.3233/JIFS-200260
   Lu MH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135962
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Ma MK, 2021, NEUROCOMPUTING, V421, P222
   Mahajan S, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3506699
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mathew M, 2017, PROC INT CONF DOC, P42, DOI 10.1109/ICDAR.2017.364
   Mei JR, 2016, INT C PATT RECOG, P4053, DOI 10.1109/ICPR.2016.7900268
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127
   Mohanty S, 2018, IEEE IMAGE PROC, P2750, DOI 10.1109/ICIP.2018.8451058
   Nagaoka Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041232
   Naosekpam V, 2019, INT C MACHINE INTELL, P339
   Naosekpam V., 2021, COMMUN COMPUT PHYS, P243, DOI [DOI 10.1007/978-981-16-1092-9, DOI 10.1007/978-981-16-1092-921]
   Naosekpam V, 2022, LECT NOTE NETW SYST, V418, P368, DOI 10.1007/978-3-030-96308-8_34
   Naosekpam V, 2021, 2021 IEEE REGION 10 CONFERENCE (TENCON 2021), P664, DOI 10.1109/TENCON54134.2021.9707183
   Naosekpam V, 2019, LECT NOTES COMPUT SC, V11941, P614, DOI 10.1007/978-3-030-34869-4_67
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Nicolaou A, 2015, PROC INT CONF DOC, P716, DOI 10.1109/ICDAR.2015.7333855
   Novikova T, 2012, LECT NOTES COMPUT SC, V7577, P752, DOI 10.1007/978-3-642-33783-3_54
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Qiao Z., 2020, P IEEE CVF C COMP VI
   Qin HB, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061054
   Qin SY, 2017, PROC INT CONF DOC, P1275, DOI 10.1109/ICDAR.2017.210
   Raghunandan KS, 2019, IEEE T CIRC SYST VID, V29, P1145, DOI 10.1109/TCSVT.2018.2817642
   Rahul Y, 2019, CURR SCI INDIA, V116, P1993, DOI 10.18520/cs/v116/i12/1993-2000
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6
   Rusiñol M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P181, DOI 10.1109/DAS.2014.11
   Sang N etal, 2016, CORR ABS160609002 AR
   Sen P., 2021, INT C INTELLIGENT CO, P352
   SeongHun Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3983, DOI 10.1109/ICPR.2010.969
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shao H, 2021, IEEE PAC VIS SYMP, P1, DOI [10.1109/PacificVis52677.2021.00038, 10.1109/APEMC49932.2021.9596925]
   Sharma N, 2015, PROC INT CONF DOC, P1196, DOI 10.1109/ICDAR.2015.7333950
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi BG, 2017, PROC INT CONF DOC, P1429, DOI 10.1109/ICDAR.2017.233
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Shi BG, 2016, PATTERN RECOGN, V52, P448, DOI 10.1016/j.patcog.2015.11.005
   Shi BG, 2015, PROC INT CONF DOC, P531, DOI 10.1109/ICDAR.2015.7333818
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AK, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P428, DOI 10.1109/DAS.2016.57
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Phan TQ, 2011, PROC INT CONF DOC, P1240, DOI 10.1109/ICDAR.2011.250
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   VARMA M, 2003, PROC CVPR IEEE, P691, DOI DOI 10.1109/CVPR.2003.1211534
   Veit A, 2016, ADV NEUR IN, V29
   Verma M., 2017, P INT C COMPUTER VIS, P309, DOI DOI 10.1007/978-981-10-2107-7
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang QT, 2020, IEEE COMPUT SOC CONF, P2296, DOI 10.1109/CVPRW50498.2020.00278
   Wang T, 2012, INT C PATT RECOG, P3304
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wang XB, 2019, PROC CVPR IEEE, P6442, DOI 10.1109/CVPR.2019.00661
   Wang YN, 2015, PROC INT CONF DOC, P821, DOI 10.1109/ICDAR.2015.7333876
   Wu Y, 2017, IEEE I CONF COMP VIS, P5010, DOI 10.1109/ICCV.2017.535
   Xiang D., 2016, P EUR C COMP VIS AMS, V2020, P351, DOI 10.1007/978-3-319-46604-0_26
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589
   Yan RJ, 2021, PROC CVPR IEEE, P284, DOI 10.1109/CVPR46437.2021.00035
   Yang C, 2017, ARXIV PREPRINT ARXIV
   Yang QP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1071
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280
   Yao C, 2017, MSRA TEXT DETECTION
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yi-Feng Pan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P6, DOI 10.1109/ICDAR.2009.97
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yuan T.-L., 2018, ARXIV PREPRINT ARXIV
   Yuliang L., 2017, ARXIV171202170
   Yuliang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9806, DOI 10.1109/CVPR42600.2020.00983
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zdenek J, 2017, PROC INT CONF DOC, P369, DOI 10.1109/ICDAR.2017.68
   Zhan FN, 2019, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2019.00216
   Zhang CQ, 2019, PROC CVPR IEEE, P10544, DOI 10.1109/CVPR.2019.01080
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4
   Zhong Z., 2016, IEEE INT C AC
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhou Y., 2014, IEEE T IND ELECTRON, P1, DOI DOI 10.1109/BIGDATA.CONGRESS.2014.11
   Zhou Z., 2019, ARXIV190109657
   Zhu XY, 2017, PROC INT CONF DOC, P807, DOI 10.1109/ICDAR.2017.137
NR 192
TC 10
Z9 10
U1 13
U2 56
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 291
EP 314
DI 10.1007/s13735-022-00243-8
EA JUL 2022
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000822006000001
DA 2024-07-18
ER

PT J
AU Li, J
   Guo, YM
   Lao, SY
   Wu, YL
   Bai, L
   Wei, YM
AF Li, Jian
   Guo, Yanming
   Lao, Songyang
   Wu, Yulun
   Bai, Liang
   Wei, Yingmei
TI Towards a high robust neural network via feature matching
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Feature matching; Deep neural network; Adversarial attack and defense;
   Robustness
AB Image classification systems have been found vulnerable to adversarial attack, which is imperceptible to human but can easily fool deep neural networks. Recent researches indicate that regularizing the network by introducing randomness could greatly improve the model's robustness against adversarial attack, but the randomness module would normally involve complex calculations and numerous additional parameters and seriously affect the model performance on clean data. In this paper, we propose a feature matching module to regularize the network. Specifically, our model learns a feature vector for each category and imposes additional restrictions on image features. Then, the similarity between image features and category features is used as the basis for classification. Our method does not introduce any additional network parameters than undefended model and can be easily integrated into any neural network. Experiments on the CIFAR10 and SVHN datasets highlight that our proposed module can effectively improve both clean data and perturbed data accuracy in comparison with the stateof-the-art defense methods and outperform the L2P method by 6.3%, 24% on clean and perturbed data, respectively, using ResNet-V2(18) architecture.
C1 [Li, Jian; Guo, Yanming; Lao, Songyang; Wu, Yulun; Bai, Liang; Wei, Yingmei] Natl Univ Def Technol, Changsha, Peoples R China.
C3 National University of Defense Technology - China
RP Guo, YM (corresponding author), Natl Univ Def Technol, Changsha, Peoples R China.
EM guoyanming@nudt.edu.cn
CR ADDEPALLI S, 2020, CVPR, DOI DOI 10.1109/CVPR42600.2020.00110
   Araujo A, 2019, ARXIV PREPRINT ARXIV
   Athalye A, 2018, PR MACH LEARN RES, V80
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bhagoji Arjun Nitin, 2018, 2018 52nd Annual Conference on Information Sciences and Systems (CISS), DOI 10.1109/CISS.2018.8362326
   Bui A, 2021, ARXIV PREPRINT ARXIV
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Dziugaite G., 2016, ARXIV160800853
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZZ, 2019, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2019.00068
   Ilyas A, 2019, ADV NEUR IN, V32
   Jeddi A, 2020, PROC CVPR IEEE, P1238, DOI 10.1109/CVPR42600.2020.00132
   Jiang Z, 2020, NEURAL INFORM PROCES
   Kim M, 2021, NEUROINFORMATICS, V19, P233, DOI 10.1007/s12021-020-09482-8
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecuyer M, 2019, P IEEE S SECUR PRIV, P656, DOI 10.1109/SP.2019.00044
   Liu X., 2019, ICLR
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Liu Y, 2016, EMNLP
   Lyu CC, 2015, IEEE DATA MINING, P301, DOI 10.1109/ICDM.2015.84
   Madry A., 2018, ARXIV
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Papernot N, 2016, ARXIV161000768
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Ros AS, 2018, AAAI CONF ARTIF INTE, P1660
   Sankaranarayanan S, 2018, AAAI CONF ARTIF INTE, P4008
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
NR 32
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2021
VL 10
IS 4
BP 227
EP 237
DI 10.1007/s13735-021-00219-0
EA OCT 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XC7OC
UT WOS:000706934600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ceroni, A
   Ma, CY
   Ewerth, R
AF Ceroni, Andrea
   Ma, Chenyang
   Ewerth, Ralph
TI Mining exoticism from visual content with fusion-based deep neural
   networks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image retrieval; Visual concept classification; Exoticism
ID MULTILINGUAL WEB
AB Exoticism is the charm of the unfamiliar or something remote. It has received significant interest in different kinds of arts, but although visual concept classification in images and videos for semantic multimedia retrieval has been researched for years, the visual concept of exoticism has not been investigated yet from a computational perspective. In this paper, we present the first approach to automatically classify images as exotic or non-exotic. We have gathered two large datasets that cover exoticism in a general as well as a concept-specific way. The datasets have been annotated in a crowdsourcing approach. To circumvent cultural differences in the annotation, only North American crowdworkers are employed for this task. Two deep learning architectures to learn the concept of exoticism are evaluated. Besides deep learning features, we also investigate the usefulness of hand-crafted features, which are combined with deep features in our proposed fusion-based approach. Different machine learning models are compared with the fusion-based approach, which is the best performing one, reaching an accuracy over 83% and 91% on two different datasets. Comprehensive experimental results provide insights into which features contribute at most to recognizing exoticism. The estimation of image exoticism could be applied in fields like advertising and travel suggestions, as well as to increase serendipity and diversity of recommendations and search results.
C1 [Ceroni, Andrea; Ma, Chenyang; Ewerth, Ralph] Leibniz Univ Hannover, L3S Res Ctr, Hannover, Germany.
   [Ewerth, Ralph] Leibniz Informat Ctr Sci & Technol TIB, Visual Analyt Res Grp, Hannover, Germany.
C3 Leibniz University Hannover
RP Ewerth, R (corresponding author), Leibniz Univ Hannover, L3S Res Ctr, Hannover, Germany.; Ewerth, R (corresponding author), Leibniz Informat Ctr Sci & Technol TIB, Visual Analyt Res Grp, Hannover, Germany.
EM ceroni@l3s.de; chenyangma89@gmail.com; ewerth@13s.de
RI ma, chenyang/IZP-7615-2023
OI Ewerth, Ralph/0000-0003-0918-6297
CR Achanta  R., 2009, IEEE CVPR 09
   Adamopoulos P, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2559952
   [Anonymous], P TRECVID 2013
   [Anonymous], TRECVID 2015 WORKSH
   [Anonymous], 2018, The American Heritage Dictionary of the English Language
   [Anonymous], ECCV 14
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Bradski G, 2000, DR DOBBS J, V25, P120
   Donahue  J., 2014, ICML 14
   Eickhoff C, 2013, INFORM RETRIEVAL, V16, P121, DOI 10.1007/s10791-011-9181-9
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ewerth R, 2017, LECT NOTES COMPUT SC, V10193, P186, DOI 10.1007/978-3-319-56608-5_15
   Ge M, 2010, RECSYS 10
   Girshick R, 2014, CVPR 14
   Goldwater RobertJohn., 1986, Primitivism in Modern Art
   Gracia J, 2012, J WEB SEMANT, V11, P63, DOI 10.1016/j.websem.2011.09.001
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hare J, 2011, MM 11
   Howarth P, 2004, CIVR 04
   Hull DA, 1996, SIGIR 96
   Jacobs Michael., 1995, The Painted Voyage: Art, Travel, and Exploration
   Jenkins O. H., 1999, International Journal of Tourism Research, V1, P1
   Jia  Yangqing, 2014, ACM MM 14
   Jones A, 2007, THIS IS NOT A CRUISE
   Jou B, 2015, MM 15
   Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Locke RalphP., 2009, MUSICAL EXOTICISM IM
   Luo  Yiwen, 2008, ECCV 08
   Machajdik  Jana, 2010, ACM MM 10
   Mavridaki  E., 2015, IEEE ICIP 15
   Mavridaki E, 2014, ICIP 14
   Merriam-Webster Online, 2018, MERRIAM WEBSTERS DIC
   Mihalcea R, 2007, ACL 07
   Müller-Budack E, 2018, LECT NOTES COMPUT SC, V11216, P575, DOI 10.1007/978-3-030-01258-8_35
   Nguyen TT, 2014, WWW 14
   Pappas N, 2016, ICMR 16
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SanPedro J, 2009, WWW 09
   Segalen Victor., 2002, ESSAY EXOTICISM AEST
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Sheridan  Paraic, 1996, SIGIR 96
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Song K, 2006, ACM MM 06
   Szegedy  C., 2015, CVPR 15
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tapachai N., 2000, Journal of Travel Research, V39, P37, DOI 10.1177/004728750003900105
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tong H, 2004, PCM 04
   van Leuken RH, 2009, WWW 09
   vande Weijer J, 2007, IEEE CVPR 07
   Vargas  Saul, 2011, RECSYS 11
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Wu S, 2016, The Metallogenic Mechanism of Distal Contact Pb-Zn-ag Vines in Shizhuyuan Ore District, Hunan Province, China, V2016, P1
   Wu  Yaowen, 2010, ICPR 10
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yeh CH, 2010, ACM MM 10
   Zhang  Ning, 2014, ECCV 14
   Zhao  S., 2014, MM 14
   Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5534
NR 65
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2019
VL 8
IS 1
SI SI
BP 19
EP 33
DI 10.1007/s13735-018-00165-4
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HT8ZD
UT WOS:000464853000003
DA 2024-07-18
ER

PT J
AU Henning, C
   Ewerth, R
AF Henning, Christian
   Ewerth, Ralph
TI Estimating the information gap between textual and visual
   representations
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Text-image relations; Multimodal embeddings; Deep learning;
   Visual/verbal divide
AB To convey a complex matter, it is often beneficial to leverage two or more modalities. For example, slides are utilized to supplement an oral presentation, or photographs, drawings, figures, etc. are exploited in online news or scientific publications to complement textual information. However, the utilization of different modalities and their interrelations can be quite diverse. Sometimes, the transfer of information or knowledge may even be not eased, for instance, in case of contradictory information. The variety of possible interrelations of textual and graphical information and the question, how they can be described and automatically estimated have not been addressed yet by previous work. In this paper, we present several contributions to close this gap. First, we introduce two measures to describe two different dimensions of cross-modal interrelations: cross-modal mutual information (CMI) and semantic correlation (SC). Second, two novel deep learning systems are suggested to estimate CMI and SC of textual and visual information. The first deep neural network consists of an autoencoder that maps images and texts onto a multimodal embedding space. This representation is then exploited in order to train classifiers for SC and CMI. An advantage of this representation is that only a small set of labeled training examples is required for the supervised learning process. Third, three different and large datasets are combined for autoencoder training to increase the diversity of (unlabeled) image-text pairs such that they properly capture the broad range of possible interrelations. Fourth, experimental results are reported for a challenging dataset. Finally, we discuss several applications for the proposed system and outline areas for future work.
C1 [Henning, Christian; Ewerth, Ralph] Leibniz Univ Hannover, Inst Distributed Syst, Hannover, Germany.
   [Henning, Christian; Ewerth, Ralph] Leibniz Univ Hannover, Res Ctr L3S, Hannover, Germany.
   [Ewerth, Ralph] Leibniz Informat Ctr Sci & Technol TIB, Res Grp Visual Analyt, Dept Res & Dev, Hannover, Germany.
   [Henning, Christian] Swiss Fed Inst Technol, Inst Neuroinformat, Zurich, Switzerland.
C3 Leibniz University Hannover; Leibniz University Hannover; Swiss Federal
   Institutes of Technology Domain; ETH Zurich
RP Henning, C (corresponding author), Leibniz Univ Hannover, Inst Distributed Syst, Hannover, Germany.; Henning, C (corresponding author), Leibniz Univ Hannover, Res Ctr L3S, Hannover, Germany.; Henning, C (corresponding author), Swiss Fed Inst Technol, Inst Neuroinformat, Zurich, Switzerland.
EM henningc@ethz.ch; ralph.ewerth@tib.eu
RI Henning, Christian/KFS-6511-2024
CR Agosti M, 2014, DAGSTUHL REP, V3, P92
   [Anonymous], 2014, ARXIV14065679
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Barnard K, 2006, INF THEORY APPL, V2, P1
   Bateman JA, 2014, TEXT AND IMAGE: A CRITICAL INTRODUCTION TO THE VISUAL/VERBAL DIVIDE, P1
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Eickhoff C, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P223, DOI 10.1145/2556195.2556217
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Feng Yansong., 2008, P ACL 08 HLT, P272
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Izadinia H, 2015, IEEE I CONF COMP VIS, P10, DOI 10.1109/ICCV.2015.10
   Jiao Xue, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P427, DOI 10.1007/978-3-319-14442-9_48
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Mao Junhua., 2014, Explain images with multimodal recurrent neural networks
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Radford A., 2015, ARXIV
   Ramisa A, 2016, ARXIVARXIV160307141
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vakkari P, 2016, J INF SCI, V42, P7, DOI 10.1177/0165551515615833
   Vinyals O., 2014, ARXIV14114555
   Vinyals O., 2016, IEEE TPMAI, V39, P652, DOI DOI 10.1109/TPAMI.2016.2587640
   Wei Liu, 2005, 13th Annual ACM International Conference on Multimedia, P451, DOI 10.1145/1101149.1101249
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yanai K., 2005, 13th Annual ACM International Conference on Multimedia, P419, DOI 10.1145/1101149.1101241
   Zhang Yi., 2008, Annual Conference on Neural Information Processing Systems 20, P1945
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 31
TC 8
Z9 9
U1 1
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2018
VL 7
IS 1
SI SI
BP 43
EP 56
DI 10.1007/s13735-017-0142-y
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GB9SN
UT WOS:000429414200005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Blandfort, P
   Karayil, T
   Hees, J
   Dengel, A
AF Blandfort, Philipp
   Karayil, Tushar
   Hees, Joern
   Dengel, Andreas
TI The Focus-Aspect-Value model for predicting subjective visual attributes
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Visual interpretation; Subjectivity; Neural networks; Information
   fusion; Attribute prediction; Tensor fusion
AB Predicting subjective visual interpretation is important for several prominent tasks in computer vision, including multimedia retrieval. Many approaches reduce this problem to the prediction of adjective or attribute labels from images while neglecting attribute semantics and only processing the image in a holistic manner. Furthermore, there is a lack of relevant datasets with fine-grained subjective labels and sufficient scale for machine learning. In this paper, we explain the Focus-Aspect-Value (FAV) model to break down the process of subjective image interpretation into three steps and describe a dataset following this way of modeling. We train and evaluate several deep learning methods on this dataset, while we extend the experiments of the paper originally introducing FAV by adding a new evaluation metric, improving the concatenation approach and adding Multiplicative Fusion as another method. In our experiments, Tensor Fusion is among the best performing methods across all measures and outperforms the default way of information fusion (concatenation). In addition, we find that the way of combining information in neural networks not only affects prediction performance but can drastically change other properties of the model as well.
C1 [Blandfort, Philipp; Karayil, Tushar; Hees, Joern; Dengel, Andreas] DFKI, Kaiserslautern, Germany.
   [Blandfort, Philipp; Karayil, Tushar; Dengel, Andreas] TU Kaiserslautern, Kaiserslautern, Germany.
C3 German Research Center for Artificial Intelligence (DFKI); University of
   Kaiserslautern
RP Blandfort, P; Karayil, T (corresponding author), DFKI, Kaiserslautern, Germany.; Blandfort, P; Karayil, T (corresponding author), TU Kaiserslautern, Kaiserslautern, Germany.
EM philipp.blandfort@dfki.de; tushar.karayil@dfki.de; joern.hees@dfki.de;
   andreas.dengel@dfki.de
RI Dengel, Andreas/AAE-8190-2019
FU BMBF project DeFuseNN [01IW17002]; NVIDIA AI Lab (NVAIL) program
FX This work was supported by the BMBF project DeFuseNN (Grant 01IW17002)
   and the NVIDIA AI Lab (NVAIL) program.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], 2010, P 2010 WORKSH GEOM M
   [Anonymous], 2015, T ASSOC COMPUT LING
   [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   Bamman D, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P828
   Baroni Marco, 2010, P 2010 C EMP METH NA, P1183
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Blandfort P, 2019, IEEE IJCNN
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Carbon CC, 2011, I-PERCEPTION, V2, P708, DOI 10.1068/i0463aap
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Hamp B., 1997, AUTOMATIC INFORM EXT
   Hartung M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P54
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hesselmann G, 2008, J NEUROSCI, V28, P14481, DOI 10.1523/JNEUROSCI.4398-08.2008
   Jou B., 2016, Proceedings of the 24th ACM International Conference on Multimedia
   Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246
   Kalkowski S, 2015, MMCOMMONS'15: PROCEEDINGS OF THE 2015 WORKSHOP ON COMMUNITY-ORGANIZED MULTIMODAL MINING: OPPORTUNITIES FOR NOVEL SOLUTIONS, P25, DOI 10.1145/2814815.2814820
   Karayil T, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P16, DOI 10.1145/3323873.3325026
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Merriam-Webster, 2018, DEF SUBJ
   Moorthy AK, 2010, LECT NOTES COMPUT SC, V6315, P1, DOI 10.1007/978-3-642-15555-0_1
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Smith ML, 2012, CURR BIOL, V22, P191, DOI 10.1016/j.cub.2011.11.061
   Yuille A.L., 1996, Perception as Bayesian inference, P123
NR 32
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2020
VL 9
IS 1
SI SI
BP 47
EP 60
DI 10.1007/s13735-019-00188-5
EA JAN 2020
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KQ6ZX
UT WOS:000505328400001
DA 2024-07-18
ER

PT J
AU Saman, S
   Narayanan, SJ
AF Saman, Sangeetha
   Narayanan, Swathi Jamjala
TI Survey on brain tumor segmentation and feature extraction of MR images
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Human brain tumor; Medical imaging; Segmentation; Feature extraction;
   Magnetic resonance images; Convolutional neural networks
ID CONVOLUTIONAL NEURAL-NETWORKS; AUTOMATIC SEGMENTATION; TISSUE
   CLASSIFICATION; UNSUPERVISED SEGMENTATION; INTENSITY NONUNIFORMITY;
   MODEL; ALGORITHM; INHOMOGENEITY; TEXTURE; MACHINE
AB Brain tumor analysis plays an important role in medical imaging applications and in delivering a huge amount of anatomical and functional information, which increases and simplifies the diagnosis and disease therapy planning. However, the presence of image artifacts such as noise, intensity inhomogeneity and partial volume effect in magnetic resonance images can aggressively affect the quantitative brain tumor analysis. Also, the complex anatomy of the brain is another necessary factor to deal with. To avoid or reduce manual segmentation error, the automatic segmentation and detection of tumor have become the most challenging task for radiologists and clinicians. In this paper, most commonly used MR brain image segmentation algorithms and most popular brain MRI features are surveyed and summarized with an emphasis on their characteristics, merits, and demerits of these techniques. This paper presents a categorization of various segmentation algorithms ranging from simple threshold methods to high-level segmentation techniques such as deformable methods, graph-based, and deep learning approaches with a focus on gliomas which is most common of all malignant brain and central nervous system tumors. We also discuss the current trends with a focus on brain tumor segmentation, tissue segmentation and lesion detection using deep learning methods such as deep neural networks and convolutional neural networks. We also mentioned the future improvements to standardize the MRI-based brain tumor detection method for clinical use.
C1 [Saman, Sangeetha; Narayanan, Swathi Jamjala] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Saman, S (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM sangeethacse1990@gmail.com; swathi.jns@gmail.com
RI Narayanan S J, Jishnu/GQH-1507-2022
OI Narayanan S J, Jishnu/0000-0002-5950-5877
CR Akselrod-Ballin A, 2006, LECT NOTES COMPUT SC, V4191, P209
   Al-Dmour H, 2018, NEUROCOMPUTING, V275, P546, DOI 10.1016/j.neucom.2017.08.051
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anitha R, 2017, INT J IMAG SYST TECH, V27, P354, DOI 10.1002/ima.22238
   [Anonymous], BRAIN TUM STAT
   [Anonymous], 1996, CAMBRIDGE MONOGRAPHS
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2005, ICGST GVIP J
   [Anonymous], THESIS
   [Anonymous], MED PHYS
   [Anonymous], FUZZY SETS SYST
   [Anonymous], 2011, P ACM S RES APPL COM
   [Anonymous], P MED IM COMP COMP A
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], ARXIV13086056
   [Anonymous], 2014, P WIN CONTR C
   [Anonymous], 2000, HDB MED IMAGING
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 29 GEN ASSEMBLY INT
   [Anonymous], INT J COMPUT VIS
   [Anonymous], P 23 NAT RAD SCI C N
   [Anonymous], 1989, Decision Estimation and Classification
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Balafar MA, 2014, ARTIF INTELL REV, V41, P441, DOI 10.1007/s10462-012-9318-2
   Battaglini M, 2008, NEUROIMAGE, V40, P583, DOI 10.1016/j.neuroimage.2007.10.067
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822
   Bonte S, 2018, COMPUT BIOL MED, V98, P39, DOI 10.1016/j.compbiomed.2018.05.005
   Brown ES, 2012, INT J COMPUT VISION, V98, P103, DOI 10.1007/s11263-011-0499-y
   Capelle AS, 2000, IEEE IMAGE PROC, P613, DOI 10.1109/ICIP.2000.901033
   Chambolle A, 2012, SIAM J IMAGING SCI, V5, P1113, DOI 10.1137/110856733
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Cobzas D., 2007, PROC INT C COMPUTER, P1
   Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Cohen MS, 2000, HUM BRAIN MAPP, V10, P204, DOI 10.1002/1097-0193(200008)10:4<204::AID-HBM60>3.0.CO;2-2
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   Collins CM, 2005, J MAGN RESON IMAGING, V21, P192, DOI 10.1002/jmri.20245
   Cuadra MB., 2015, HDB BIOMEDICAL IMAGI, P221, DOI [DOI 10.1007/978-0-387-09749-7_12, 10.1007/978-0-387-09749-7_12]
   Dasgupta A, 2016, SOUTH ASIAN J CANCER, V5, P147, DOI 10.4103/2278-330X.187589
   DAVENPORT JW, 1988, COMPUT MATH APPL, V15, P819, DOI 10.1016/0898-1221(88)90119-8
   del Fresno M, 2009, COMPUT MED IMAG GRAP, V33, P369, DOI 10.1016/j.compmedimag.2009.03.002
   Despotovic I, 2010, IEEE ENG MED BIO, P5038, DOI 10.1109/IEMBS.2010.5627196
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Dvorak P., 2015, Proceeding of the Multimodal Brain Tumor Image Segmentation Challenge, P13, DOI DOI 10.1007/978-3-319-42016-5_6
   Fischl B, 2002, NEURON, V33, P341, DOI 10.1016/S0896-6273(02)00569-X
   Gering DT, 2002, LECT NOTES COMPUT SC, V2488, P388
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Gies V, 2004, IEEE IMAGE PROC, P1863
   Gonzalez RafaelC., 2004, Digital Image Using MATLAB Processing
   Gui L, 2012, MED IMAGE ANAL, V16, P1565, DOI 10.1016/j.media.2012.07.006
   Han JK, 1999, ELECTRON LETT, V35, P1305, DOI 10.1049/el:19990920
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Huang A, 2009, IEEE T BIO-MED ENG, V56, P1838, DOI 10.1109/TBME.2009.2017509
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Kabir Y, 2007, P ANN INT IEEE EMBS, P1595, DOI 10.1109/IEMBS.2007.4352610
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kang SH, 2013, NONLINEAR ANAL-THEOR, V76, P181, DOI 10.1016/j.na.2012.08.014
   Kapur T, 1996, Med Image Anal, V1, P109, DOI 10.1016/S1361-8415(96)80008-9
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4
   Krishnapuram R., 1999, FUZZ-IEEE'99. 1999 IEEE International Fuzzy Systems. Conference Proceedings (Cat. No.99CH36315), P1281, DOI 10.1109/FUZZY.1999.790086
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuklisova-Murgasova M, 2011, NEUROIMAGE, V54, P2750, DOI 10.1016/j.neuroimage.2010.10.019
   Kuo WF, 2008, COMPUT METH PROG BIO, V91, P191, DOI 10.1016/j.cmpb.2008.04.010
   LAUTERBUR PC, 1973, NATURE, V242, P190, DOI 10.1038/242190a0
   Lee JD, 2009, IEEE T MED IMAGING, V28, P894, DOI 10.1109/TMI.2009.2012896
   Lewis EB, 2004, NEUROIMAGE, V23, P75, DOI 10.1016/j.neuroimage.2004.04.030
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li N, 2007, INT CONF ACOUST SPEE, P613, DOI 10.1109/ICASSP.2007.365982
   Li QN, 2018, IEEE ACCESS, V6, P9543, DOI 10.1109/ACCESS.2018.2807698
   Liu L, 2015, IEEE IMAGE PROC, P2319, DOI 10.1109/ICIP.2015.7351216
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lötjönen JMP, 2010, NEUROIMAGE, V49, P2352, DOI 10.1016/j.neuroimage.2009.10.026
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mangin JF, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P162, DOI 10.1109/MMBIA.2000.852374
   MANSFIELD P, 1977, J PHYS C SOLID STATE, V10, pL55, DOI 10.1088/0022-3719/10/3/004
   Masutani Y, 1998, LECT NOTES COMPUT SC, V1496, P1242, DOI 10.1007/BFb0056314
   McInerney T, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P171, DOI 10.1109/MMBIA.1996.534069
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mesejo P, 2015, COMPUT MED IMAG GRAP, V43, P167, DOI 10.1016/j.compmedimag.2013.12.005
   Murugavalli S., 2007, Journal of Computer Sciences, V3, P841, DOI 10.3844/jcssp.2007.841.846
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Ortiz A, 2014, INFORM SCIENCES, V262, P117, DOI 10.1016/j.ins.2013.10.002
   Ortiz A, 2013, APPL SOFT COMPUT, V13, P2668, DOI 10.1016/j.asoc.2012.11.020
   OZKAN M, 1993, IEEE T MED IMAGING, V12, P534, DOI 10.1109/42.241881
   Passat N, 2005, J MAGN RESON IMAGING, V21, P715, DOI 10.1002/jmri.20307
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Pohl KA, 2006, NEUROIMAGE, V31, P228, DOI 10.1016/j.neuroimage.2005.11.044
   Prastawa M, 2005, MED IMAGE ANAL, V9, P457, DOI 10.1016/j.media.2005.05.007
   Prastawa M, 2003, ACAD RADIOL, V10, P1341, DOI 10.1016/S1076-6332(03)00506-3
   Ratan R., 2009, INDIAN J SCI TECHNOL, V2, P11
   Reddick WE, 1997, IEEE T MED IMAGING, V16, P911, DOI 10.1109/42.650887
   Rogowska J, 2000, BIOMED EN S, P69
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Shanthi KJ, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P422
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Shen HC, 2017, IEEE IMAGE PROC, P3864, DOI 10.1109/ICIP.2017.8297006
   Shi F, 2011, HUM BRAIN MAPP, V32, P382, DOI 10.1002/hbm.21023
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Sprawls P., 2000, Magnetic Resonance Imaging: Principles, Methods, and Techniques
   Stadlbauer A, 2004, NEUROIMAGE, V23, P454, DOI 10.1016/j.neuroimage.2004.06.022
   Sung YC, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P1000, DOI 10.1109/ICOSP.2000.891695
   TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X
   Tian GJ, 2011, IEEE T INF TECHNOL B, V15, P373, DOI 10.1109/TITB.2011.2106135
   Tran TN, 2005, CHEMOMETR INTELL LAB, V77, P3, DOI 10.1016/j.chemolab.2004.07.011
   Tu Z, 2008, IEEE T MED IMAGING, V27, P495, DOI 10.1109/TMI.2007.908121
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   Vijayakumar C, 2007, COMPUT MED IMAG GRAP, V31, P473, DOI 10.1016/j.compmedimag.2007.04.004
   Vijayakumar C, 2011, J MED PHYS, V36, P147, DOI 10.4103/0971-6203.83481
   Wang L, 2014, NEUROIMAGE, V84, P141, DOI 10.1016/j.neuroimage.2013.08.008
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7
   Weisenfeld NI, 2009, NEUROIMAGE, V47, P564, DOI 10.1016/j.neuroimage.2009.04.068
   Wells W. M.  III, 1995, Computer Vision, Virtual Reality and Robotics in Medicine. First International Conference, CVRMed '95. Proceedings, P59
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Xu XW, 1999, DATA MIN KNOWL DISC, V3, P263, DOI 10.1023/A:1009884809343
   Xue H, 2007, NEUROIMAGE, V38, P461, DOI 10.1016/j.neuroimage.2007.07.030
   Xue JH, 2003, PATTERN RECOGN LETT, V24, P2549, DOI 10.1016/S0167-8655(03)00100-4
   Yang XF, 2011, MED PHYS, V38, P2879, DOI 10.1118/1.3584199
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhou YX, 2007, IEEE T BIO-MED ENG, V54, P122, DOI 10.1109/TBME.2006.884645
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
NR 138
TC 32
Z9 34
U1 0
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2019
VL 8
IS 2
BP 79
EP 99
DI 10.1007/s13735-018-0162-2
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HX7JW
UT WOS:000467582100002
DA 2024-07-18
ER

PT J
AU Alfaro-Contreras, M
   Iñesta, JM
   Calvo-Zaragoza, J
AF Alfaro-Contreras, Maria
   Inesta, Jose M.
   Calvo-Zaragoza, Jorge
TI Optical music recognition for homophonic scores with neural networks and
   synthetic music generation
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Optical music recognition; Deep learning; End-to-end recognition; Music
   encoding
ID REMOVAL
AB The recognition of patterns that have a time dependency is common in areas like speech recognition or natural language processing. The equivalent situation in image analysis is present in tasks like text or video recognition. Recently, Convolutional Recurrent Neural Networks (CRNN) have been broadly applied to solve these tasks in an end-to-end fashion with successful performance. However, its application to Optical Music Recognition (OMR) is not so straightforward due to the presence of different elements sharing the same horizontal position, disrupting the linear flow of the timeline. In this paper, we study the ability of the state-of-the-art CRNN approach to learn codes that represent this disruption in homophonic scores. In our experiments, we study the lower bounds in the recognition task of real scores when the models are trained with synthetic data. Two relevant conclusions are drawn: (1) Our serialized ways of encoding the music content are appropriate for CRNN-based OMR; (2) the learning process is possible with synthetic data, but there exists a glass ceiling when recognizing real sheet music.
C1 [Alfaro-Contreras, Maria; Inesta, Jose M.; Calvo-Zaragoza, Jorge] Univ Alicante, Inst Univ Invest Informat, Ap 99, Alicante 03080, Spain.
C3 Universitat d'Alacant
RP Alfaro-Contreras, M (corresponding author), Univ Alicante, Inst Univ Invest Informat, Ap 99, Alicante 03080, Spain.
EM malfaro@dlsi.ua.es; inesta@dlsi.ua.es; jcalvo@dlsi.ua.es
OI Alfaro-Contreras, Maria/0000-0003-1676-3101
FU CRUE-CSIC; Springer Nature; MCIN/AEI [PID 2020-118447RA-I00]; Spanish
   Ministerio de Universidades [FPU19/049 57]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This paper is part of the I+D+i PID 2020-118447RA-I00
   (MultiScore) project, funded by MCIN/AEI/10. 13039/501100011033. The
   first author is supported by grant FPU19/049 57 from the Spanish
   Ministerio de Universidades.
CR Alfaro-Contreras M, 2021, P 22 INT SOC MUS INF, P35
   Alfaro-Contreras M, 2019, LECT NOTES COMPUT SC, V11868, P147, DOI 10.1007/978-3-030-31321-0_13
   AlfaroContreras M, 2018, CONSTRUCCION CORPUS
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   Bainbridge D, 2001, COMPUT HUMANITIES, V35, P95, DOI 10.1023/A:1002485918032
   Baró A, 2020, INT CONF FRONT HAND, P205, DOI 10.1109/ICFHR2020.2020.00046
   Baro Arnau, 2018, P 1 INT WORKSH READ, P5
   Burgoyne J.A., 2007, P C INT SOC MUSIC IN, P509
   Byrd D, 2015, J NEW MUSIC RES, V44, P169, DOI 10.1080/09298215.2015.1045424
   Calvo-Zaragoza J., 2018, P 19 INT SOC MUS INF, P248
   Calvo-Zaragoza J, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3397499
   Calvo-Zaragoza J, 2019, PATTERN RECOGN LETT, V128, P115, DOI 10.1016/j.patrec.2019.08.021
   Calvo-Zaragoza J, 2016, INT J DOC ANAL RECOG, V19, P211, DOI 10.1007/s10032-016-0266-2
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dutta Anjan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1965, DOI 10.1109/ICPR.2010.484
   Fornes A, 2014, HDB DOCUMENT IMAGE P, P749, DOI DOI 10.1007/978-0-85729-859-1_24
   Gallego AJ, 2017, EXPERT SYST APPL, V89, P138, DOI 10.1016/j.eswa.2017.07.002
   Good M etal, 2001, XML C EXP, P03
   Graves A, 2008, THESIS TU MUNICH
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Haji J., 2019, P 20 INT SOC MUSIC I, P75, DOI DOI 10.5281/ZENODO.3527744
   Hankinson A., 2011, Proceedings of the 12th International Society for Music Information Retrieval Conference, P293, DOI DOI 10.5281/ZENODO.1417609
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mengarelli L, 2020, MULTIMED TOOLS APPL, V79, P6383, DOI 10.1007/s11042-019-08200-0
   Miranda Eduardo, 2001, Composing music with computers, DOI DOI 10.4324/9780080502403
   Pacha A, 2017, PROC INT CONF DOC, P35, DOI 10.1109/ICDAR.2017.265
   Pedersoli F, 2016, INT J DOC ANAL RECOG, V19, P289, DOI 10.1007/s10032-016-0271-5
   Raphael C., 2011, 12 INT SOC MUSIC INF, P305, DOI DOI 10.5281/ZENODO.1414856
   Rebelo A, 2010, INT J DOC ANAL RECOG, V13, P19, DOI 10.1007/s10032-009-0100-1
   Rebelo A, 2012, INT J MULTIMED INF R, V1, P173, DOI 10.1007/s13735-012-0004-6
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Williams Ronald J., 1995, Backpropagation: Theory, architectures, and applications, V433
NR 33
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 12
DI 10.1007/s13735-023-00278-5
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4DD8
UT WOS:000995478300001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Gouizi, F
   Megherbi, AC
AF Gouizi, Fatma
   Megherbi, Ahmed Chaouki
TI Nested-Net: a deep nested network for background subtraction
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Background subtraction (BS); Foreground detection; Deep learning;
   Nested-Net; Micro-autoencoder; U-net
ID GAUSSIAN MIXTURE MODEL
AB Background subtraction is one of the most highly regarded steps in computer vision, especially in video surveillance applications. Although various approaches have been proposed to cope with the different difficulties of this field, many of these methods have not been able to fully tackle complicated situations in realistic scenes due to their sensitivity to many challenges. This paper presents a deep nested background subtraction algorithm based on residual micro-autoencoder blocks. Hence, our method is implemented as a U-net like architecture with more skip connections. The nested network uses residual connections between these micro-autoencoders that can extract significant multi-scale features of a complex scene. We also test and prove that the proposed method can work in various challenging situations. A small set of training samples is included to train this end-to-end network. The experimental results demonstrate that our model outperforms other state-of-the-art methods on two well-known benchmark datasets: CDNet 2014 and SBI 2015.
C1 [Gouizi, Fatma] Univ Biskra, Lab LESIA, Biskra, Algeria.
   [Megherbi, Ahmed Chaouki] Univ Biskra, Lab LI3C, Biskra, Algeria.
C3 Universite Mohamed Khider Biskra; Universite Mohamed Khider Biskra
RP Gouizi, F (corresponding author), Univ Biskra, Lab LESIA, Biskra, Algeria.
EM f.gouizi@univ-biskra.dz; ac.megherbi@univ-biskra.dz
OI Megherbi, Ahmed Chaouki/0000-0002-9262-6806
CR Akilan T, 2020, IEEE T INTELL TRANSP, V21, P4435, DOI 10.1109/TITS.2019.2940547
   Akilan T, 2020, IEEE T INTELL TRANSP, V21, P959, DOI 10.1109/TITS.2019.2900426
   Akilan T, 2018, INFORM SCIENCES, V430, P414, DOI 10.1016/j.ins.2017.11.062
   Babaee M, 2017, Arxiv, DOI [arXiv:1702.01731, 10.48550/ARXIV.1702.01731, DOI 10.48550/ARXIV.1702.01731]
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Bouwmans T, 2014, BACKGROUND MODELLING
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Brutzer S, 2011, PROC CVPR IEEE
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kalsotra R, 2022, VISUAL COMPUT, V38, P4151, DOI 10.1007/s00371-021-02286-0
   Karasulu B, 2013, PERFORMANCE EVALUATI, P7
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Liao J, 2018, LECT NOTES COMPUT SC, V11164, P524, DOI 10.1007/978-3-030-00776-8_48
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Maddalena L, 2015, LECT NOTES COMPUT SC, V9281, P469, DOI 10.1007/978-3-319-23222-5_57
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Mandal M, 2022, IEEE T INTELL TRANSP, V23, P6101, DOI [10.1109/TITS.2021.3077883, 10.3233/IP-200233]
   Panda MK, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103501
   Patil PW, 2021, IEEE SIGNAL PROC LET, V28, P489, DOI 10.1109/LSP.2021.3059195
   Qiu MK, 2019, IEEE ACCESS, V7, P85949, DOI 10.1109/ACCESS.2019.2925913
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rout DK, 2018, EXPERT SYST APPL, V97, P117, DOI 10.1016/j.eswa.2017.12.009
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P15, DOI 10.1007/978-3-319-07386-6_3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   St-Charles PL, 2014, IEEE COMPUT SOC CONF, P414, DOI 10.1109/CVPRW.2014.67
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI [10.1109/WACV45572.2020.9093464, 10.1109/wacv45572.2020.9093464]
   Nguyen TM, 2015, IEEE T NEUR NET LEAR, V26, P400, DOI 10.1109/TNNLS.2014.2314239
   Nguyen TP, 2019, IEEE T CIRC SYST VID, V29, P433, DOI 10.1109/TCSVT.2018.2795657
   Wang HZ, 2007, PATTERN RECOGN, V40, P1091, DOI 10.1016/j.patcog.2006.05.024
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wren C, 1995, REAL TIME TRACKING H, P2615
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Zeng DD, 2018, IEEE ACCESS, V6, P16010, DOI 10.1109/ACCESS.2018.2817129
   Zheng WB, 2020, NEUROCOMPUTING, V394, P178, DOI 10.1016/j.neucom.2019.04.088
   [郑文博 Zheng Wenbo], 2018, [自动化学报, Acta Automatica Sinica], V44, P878
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 55
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 5
DI 10.1007/s13735-023-00270-z
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9R0OR
UT WOS:000945355900001
DA 2024-07-18
ER

PT J
AU Kumar, P
   Chauhan, S
   Awasthi, LK
AF Kumar, Pranjal
   Chauhan, Siddhartha
   Awasthi, Lalit Kumar
TI Human pose estimation using deep learning: review, methodologies,
   progress and future research directions
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Human pose estimation; Action recognition; Deep learning
ID PICTORIAL STRUCTURES; 3D POSE; NETWORK; MODEL; REPRESENTATION;
   RECOGNITION; PEOPLE
AB Human pose estimation (HPE) has developed over the past decade into a vibrant field for research with a variety of real-world applications like 3D reconstruction, virtual testing and re-identification of the person. Information about human poses is also a critical component in many downstream tasks, such as activity recognition and movement tracking. This review focuses on the key aspects of deep learning in the development of both 2D & 3D HPE. It provides detailed information on the variety of databases, performance metrics and human body models incorporated for implementing HPE methodologies. This paper discusses variety of applications of HPE across domains like activity recognition, animation and gaming, virtual reality, video tracking, etc. The paper presents an analytical study of all the major works that use deep learning methods for various downstream tasks in each domain for both 2D & 3D HPE. Finally, it discusses issues and limitations in the current topic of HPE and recommend potential future research directions in order to make meaningful progress in this area.
C1 [Kumar, Pranjal; Chauhan, Siddhartha; Awasthi, Lalit Kumar] Natl Inst Technol Hamirpur, Hamirpur 177005, Himachal Prades, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Kumar, P (corresponding author), Natl Inst Technol Hamirpur, Hamirpur 177005, Himachal Prades, India.
EM pranjal@nith.ac.in
RI ; Awasthi, Lalit Kumar/V-3485-2019
OI KUMAR, PRANJAL/0000-0002-6167-9884; Awasthi, Lalit
   Kumar/0000-0001-8396-9025
CR Alcantara RS, 2022, PEERJ, V10, DOI 10.7717/peerj.12752
   Andrew A.M., 2001, Multiple view geometry in computer vision
   ANDRILUKA M, 2010, PROC CVPR IEEE, P623, DOI DOI 10.1109/CVPR.2010.5540156
   Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Arnab A, 2019, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2019.00351
   Artacho B., 2021, ARXIV
   Baradel Fabien, 2017, ARXIV
   BELAGIANNIS V, 2016, IEEE T PATTERN ANAL, V38, P1929, DOI DOI 10.1109/TPAMI.2015.2509986
   Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216
   Bouazizi A., 2022, ARXIV
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13
   Cai Y., 2020, COMPUTER VISION ECCV, P455
   Cao CQ, 2018, IEEE T CYBERNETICS, V48, P1095, DOI 10.1109/TCYB.2017.2756840
   Cao Z., 2020, ECCV, P387
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Charles J, 2016, PROC CVPR IEEE, P3063, DOI 10.1109/CVPR.2016.334
   Chen L, 2020, PROC CVPR IEEE, P3276, DOI 10.1109/CVPR42600.2020.00334
   Chen RJ, 2019, IEEE I CONF COMP VIS, P9186, DOI 10.1109/ICCV.2019.00928
   Chen X, 2014, ARXIV
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Chen ZH, 2020, LECT NOTES COMPUT SC, V12221, P276, DOI 10.1007/978-3-030-61864-3_24
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Cheng Y, 2021, PROC CVPR IEEE, P7645, DOI 10.1109/CVPR46437.2021.00756
   Ching-Hang Chen, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5759, DOI 10.1109/CVPR.2017.610
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Ciabattoni L, 2018, 2018 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P130, DOI 10.1109/ZINC.2018.8448970
   Cimen Gokcen, 2018, 12 INT C COMP GRAPH
   Congzhentao Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P477, DOI 10.1007/978-3-030-58604-1_29
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dabral R, 2018, LECT NOTES COMPUT SC, V11213, P679, DOI 10.1007/978-3-030-01240-3_41
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dang Q, 2019, TSINGHUA SCI TECHNOL, V24, P663, DOI 10.26599/TST.2018.9010100
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Dinghua Li, 2018, 2018 IEEE 8th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS), DOI 10.1109/ICCABS.2018.8541953
   Doering A., 2018, ARXIV
   Dong JT, 2019, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2019.00798
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan HD, 2019, IEEE I CONF COMP VIS, P9478, DOI 10.1109/ICCV.2019.00957
   Elhayek A, 2018, LECT NOTES COMPUT SC, V11162, P28, DOI 10.1007/978-3-030-01790-3_3
   Ershadi-Nasab S, 2018, MULTIMED TOOLS APPL, V77, P15573, DOI 10.1007/s11042-017-5133-8
   Escalona F, 2020, VIRTUAL REAL-LONDON, V24, P567, DOI 10.1007/s10055-019-00419-4
   Everingham M., 2010, BMVC, V2, P5
   Fabbri M, 2018, LECT NOTES COMPUT SC, V11208, P450, DOI 10.1007/978-3-030-01225-0_27
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fangyun Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P527, DOI 10.1007/978-3-030-58607-2_31
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Geertsema EE, 2019, J BIOMECH, V88, P25, DOI 10.1016/j.jbiomech.2019.03.007
   Geng ZG, 2021, PROC CVPR IEEE, P14671, DOI 10.1109/CVPR46437.2021.01444
   Girdhar R, 2018, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2018.00044
   Giryes R, 2014, ARXIV
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   Gong WJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16121966
   Graving JM, 2019, ELIFE, V8, DOI 10.7554/eLife.47994
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Güler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Habekost J, 2020, BMVC
   Haber E, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aa9a90
   Han Q, 2020, IEEE ACCESS, V8, P17556, DOI 10.1109/ACCESS.2019.2962778
   He Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P541, DOI 10.1007/978-3-030-58580-8_32
   Hendrycks D., 2019, arXiv
   Hogg D., 1983, Image Vision Computing, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   Hong F, 2022, ARXIV
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Huang JJ, 2020, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR42600.2020.00574
   Huang LJ, 2019, PATTERN RECOGN, V92, P165, DOI 10.1016/j.patcog.2019.03.010
   Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Iskakov K, 2019, IEEE I CONF COMP VIS, P7717, DOI 10.1109/ICCV.2019.00781
   Jiang T, 2021, IEEE COMPUT SOC CONF, P3389, DOI 10.1109/CVPRW53098.2021.00378
   Jiang W, 2020, PROC CVPR IEEE, P5578, DOI 10.1109/CVPR42600.2020.00562
   Jiao JB, 2018, LECT NOTES COMPUT SC, V11219, P55, DOI 10.1007/978-3-030-01267-0_4
   Jin S., 2020, ECCV, P718
   Jin S., 2020, COMPUTER VISION ECCV, P196
   Jin S, 2019, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2019.00581
   Jin Sheng, 2017, ICCV PoseTrack Workshop
   Jinsun Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P120, DOI 10.1007/978-3-030-58601-0_8
   Johnson WR, 2019, IEEE T BIO-MED ENG, V66, P689, DOI 10.1109/TBME.2018.2854632
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241
   Kadkhodamohammadi A, 2020, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01120-2
   Kamann Christoph, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8825, DOI 10.1109/CVPR42600.2020.00885
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Khan SS, 2017, MED ENG PHYS, V39, P12, DOI 10.1016/j.medengphy.2016.10.014
   Khirodkar R, 2022, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR52688.2022.00176
   Khurana T., 2021, IEEE INT C COMP VIS, P3174
   Kocabas M, 2018, LECT NOTES COMPUT SC, V11215, P437, DOI 10.1007/978-3-030-01252-6_26
   Kreiss S, 2022, IEEE T INTELL TRANSP, V23, P13498, DOI 10.1109/TITS.2021.3124981
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumarapu L, 2021, PATTERN RECOGN LETT, V147, P16, DOI 10.1016/j.patrec.2021.03.028
   Kundu Jogendra Nath, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P794, DOI 10.1007/978-3-030-58452-8_46
   Kundu JN, 2022, PROC CVPR IEEE, P20416, DOI 10.1109/CVPR52688.2022.01980
   Kundu JN, 2020, PROC CVPR IEEE, P6151, DOI 10.1109/CVPR42600.2020.00619
   Labuguen R, 2021, FRONT BEHAV NEUROSCI, V14, DOI 10.3389/fnbeh.2020.581154
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Leinen F, 2021, ARXIV
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P11354
   Li JF, 2021, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR46437.2021.00339
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li S, 2019, PROC CVPR IEEE, P10514, DOI 10.1109/CVPR.2019.01077
   Li SC, 2020, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR42600.2020.00621
   Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Li W., 2019, ARXIV
   Li Z, 2019, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2019.00228
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Lin Kevin, 2021, P IEEE CVF INT C COM, P12939
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J, 2022, IEEE T NEUR NET LEAR, V33, P1609, DOI 10.1109/TNNLS.2020.3043002
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WT, 2018, AAAI CONF ARTIF INTE, P7170
   Liu W, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3524497
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Liu ZG, 2021, PROC CVPR IEEE, P525, DOI 10.1109/CVPR46437.2021.00059
   Liu Zhenguang, 2022, P IEEE CVF C COMP VI, P11006
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12829, DOI 10.1109/ICCV48922.2021.01261
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Luo C, 2018, ARXIV
   Luo YM, 2019, IEEE T IMAGE PROCESS, V28, P142, DOI 10.1109/TIP.2018.2865666
   Luo ZX, 2021, PROC CVPR IEEE, P13259, DOI 10.1109/CVPR46437.2021.01306
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Mathis A, 2021, IEEE WINT CONF APPL, P1858, DOI 10.1109/WACV48630.2021.00190
   McGinley JL, 2009, GAIT POSTURE, V29, P360, DOI 10.1016/j.gaitpost.2008.09.003
   Mehta D, 2019, ARXIV
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mehta D, 2018, INT CONF 3D VISION, P120, DOI 10.1109/3DV.2018.00024
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Meinhardt T, 2022, PROC CVPR IEEE, P8834, DOI 10.1109/CVPR52688.2022.00864
   Michaelis C., 2019, ARXIV
   Mohamed A, 2021, ARXIV
   Moon G, 2019, IEEE I CONF COMP VIS, P10132, DOI 10.1109/ICCV.2019.01023
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170
   Morris M., 2021, P 39 INT SOC BIOM SP, P300
   Munea TL, 2020, IEEE ACCESS, V8, P133330, DOI 10.1109/ACCESS.2020.3010248
   Nasrabadi N.M, 2007, Pattern recognition and machine learning, V16
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nibali A, 2019, IEEE WINT CONF APPL, P1477, DOI 10.1109/WACV.2019.00162
   Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P705, DOI 10.1007/978-3-030-01228-1_42
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pereira TD, 2019, NAT METHODS, V16, P117, DOI 10.1038/s41592-018-0234-5
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Qiu HB, 2019, IEEE I CONF COMP VIS, P4341, DOI 10.1109/ICCV.2019.00444
   Qu C., 2021, P IEEECVF INT C COMP, P16147
   Raaj Y, 2019, PROC CVPR IEEE, P4615, DOI 10.1109/CVPR.2019.00475
   Ramachandran A, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/2167160
   Reddy ND, 2021, PROC CVPR IEEE, P15185, DOI 10.1109/CVPR46437.2021.01494
   Remelli E, 2020, PROC CVPR IEEE, P6039, DOI 10.1109/CVPR42600.2020.00608
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rhodin H, 2018, PROC CVPR IEEE, P8437, DOI 10.1109/CVPR.2018.00880
   Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985
   Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134
   Sajjan S, 2020, IEEE INT CONF ROBOT, P3634, DOI 10.1109/ICRA40945.2020.9197518
   Samet N, 2021, ARXIV
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Sarandi I., 2018, Arxiv
   Sárándi I, 2020, IEEE INT CONF AUTOMA, P407, DOI 10.1109/FG47880.2020.00108
   Sengupta A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11199, DOI 10.1109/ICCV48922.2021.01103
   Shahroudy Amir, 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shi D, 2021, INTERNET TECHNOL LET, V4, DOI 10.1002/itl2.261
   Sidenbladh H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P368, DOI 10.1109/AFGR.2000.840661
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Su K, 2019, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2019.00582
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Tang W, 2018, LECT NOTES COMPUT SC, V11207, P197, DOI 10.1007/978-3-030-01219-9_12
   Tang W, 2019, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2019.00120
   Tekin B., 2016, ARXIV
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Terven JR, 2021, SCI COMPUT PROGRAM, V211, DOI 10.1016/j.scico.2021.102702
   Tian Z., 2019, arXiv
   Tianshi Cheng, 2021, 2021 IEEE Power & Energy Society General Meeting (PESGM), DOI 10.1109/PESGM46819.2021.9638154
   Tölgyessy M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125756
   Tome D, 2018, INT CONF 3D VISION, P474, DOI 10.1109/3DV.2018.00061
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Tompson J, 2014, ADV NEUR IN, V27
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Trumble M, 2017, BRIT MACHINE VISION
   Tu Hanyue, 2020, EUROPEAN C COMPUTER, P197
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wandt B, 2019, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2019.00797
   Wang CY, 2019, IEEE I CONF COMP VIS, P743, DOI 10.1109/ICCV.2019.00083
   Wang C, 2021, ENG APPL ARTIF INTEL, V102, DOI 10.1016/j.engappai.2021.104260
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang JH, 2021, PROC CVPR IEEE, P11850, DOI 10.1109/CVPR46437.2021.01168
   Wang JB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P374, DOI 10.1145/3343031.3350910
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang XY, 2022, PATTERN ANAL APPL, V25, P731, DOI 10.1007/s10044-022-01071-6
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu Size, 2021, P IEEECVF INT C COMP, P11148
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xin Xiong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P682, DOI 10.1007/978-3-030-58589-1_41
   Xiu Y., 2018, ARXIV
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Xu L, 2022, IEEE T PATTERN ANAL
   Yajai A, 2017, J VIS COMMUN IMAGE R, V49, P257, DOI 10.1016/j.jvcir.2017.08.008
   Yan A, 2019, PROC CVPR IEEE, P7914, DOI 10.1109/CVPR.2019.00811
   Yang D, 2021, ARXIV
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Yang Y., 2011, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, page, V1385-1392, P2011, DOI DOI 10.1109/CVPR.2011.5995741
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Yi XY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459786
   Yu HX., 2021, ARXIV
   Yuan Y, 2022, PROC CVPR IEEE, P11028, DOI 10.1109/CVPR52688.2022.01076
   Zanfir A, 2018, PROC CVPR IEEE, P2148, DOI 10.1109/CVPR.2018.00229
   Zanfir Andrei, 2020, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 12351 LNCS, P465, DOI [DOI 10.48550/ARXIV.2003.10350, DOI 10.1007/978-3-030-58539]
   Zeng A., 2022, ARXIV
   Zeng W, 2020, PROC CVPR IEEE, P7052, DOI 10.1109/CVPR42600.2020.00708
   Zhang DJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182267
   Zhang HB, 2016, INTELL AUTOM SOFT CO, V22, P483, DOI 10.1080/10798587.2015.1095419
   Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280
   Zhang Y, 2021, IEEE T EM TOP COMP I, V5, P726, DOI 10.1109/TETCI.2021.3100641
   Zhang YX, 2020, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR42600.2020.00140
   Zhang Z, 2021, INT J COMPUT VISION, V129, P703, DOI 10.1007/s11263-020-01398-9
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zheng C., 2020, ARXIV
   Zheng S, 2016, PROC CVPR IEEE, P4480, DOI 10.1109/CVPR.2016.485
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou K, 2019, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2019.00243
   Zhou X., 2019, arXiv
   Zuffi S, 2012, PROC CVPR IEEE, P3546, DOI 10.1109/CVPR.2012.6248098
NR 259
TC 3
Z9 3
U1 23
U2 130
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 489
EP 521
DI 10.1007/s13735-022-00261-6
EA NOV 2022
PG 33
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000885402200001
DA 2024-07-18
ER

PT J
AU Varshney, D
   Vishwakarma, DK
AF Varshney, Deepika
   Vishwakarma, Dinesh Kumar
TI A unified approach of detecting misleading images via tracing its
   instances on web and analyzing its past context for the verification of
   multimedia content
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Fake news; Misleading information; Multimedia content; Web-platforms
AB The verification of multimedia content over social media is one of the challenging and crucial issues in the current scenario and gaining prominence in an age where user-generated content and online social web-platforms are the leading sources in shaping and propagating news stories. As these sources allow users to share their opinions without restriction, opportunistic users often post misleading/unreliable content on social media such as Twitter, Facebook, etc. At present, to lure users toward the news story, the text is often attached with some multimedia content (images/videos/audios). Verifying these contents to maintain the credibility and reliability of social media information is of paramount importance. Motivated by this, we proposed a generalized system that supports the automatic classification of images into credible or misleading. In this paper, we investigated machine learning-based as well as deep learning-based approaches utilized to verify misleading multimedia content, where the available image traces are used to identify the credibility of the content. The experiment is performed on the real-world dataset (Media-eval-2015 dataset) collected from Twitter. It also demonstrates the efficiency of our proposed approach and features using both Machine and Deep Learning Model (Bi-directional LSTM). The experiment result reveals that the Microsoft BING image search engine is quite effective in retrieving titles and performs better than our study's Google image search engine. It also shows that gathering clues from attached multimedia content (image) is more effective than detecting only posted content-based features.
C1 [Varshney, Deepika; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi 110042, India.
EM deepikavarshney06@gmail.com; dvishwakarma@mail.com
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047
CR [Anonymous], 2015, MCG ICT MEDIAEVAL 20
   Boididou C, 2018, INT J MULTIMED INF R, V7, P71, DOI 10.1007/s13735-017-0143-x
   Boididou Christina, 2015, CERTH UNITN PARTICIP
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kompatsiaris Yiannis, 2015, MediaEval, V3, P7
   Meel P, 2021, INFORM SCIENCES, V567, P23, DOI 10.1016/j.ins.2021.03.037
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Middleton Stuart, 2015, EXTRACTING ATTRIBUTE
   Oikawa MA, 2016, IEEE T INF FOREN SEC, V11, P5, DOI 10.1109/TIFS.2015.2442527
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Popat K, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2173, DOI 10.1145/2983323.2983661
   Shengyun Sun, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P120, DOI 10.1007/978-3-642-37401-2_14
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Silverman, 2015, MEDIAEVAL, V11, P1, DOI [10.1145/3070644, DOI 10.1145/3070644]
   Silverman C., 2016, DEFINITIVE GUIDE VER
   Varshney D, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114208
   Varshney D, 2021, APPL INTELL, V51, P4214, DOI 10.1007/s10489-020-02057-9
   Varshney D, 2021, J AMB INTEL HUM COMP, V12, P8961, DOI 10.1007/s12652-020-02698-1
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Zhu Y., 2012, P AAAI C ARTIFICIAL, V26
NR 24
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 445
EP 459
DI 10.1007/s13735-022-00235-8
EA JUL 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000825086600001
PM 35847991
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, XY
   Huang, J
AF Wang, Xiaoyi
   Huang, Jun
TI A local representation-enhanced recurrent convolutional network for
   image captioning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Recurrent convolutional network; Local representation; Image captioning;
   Attention mechanism
AB Image captioning is a challenging task that aims to generate a natural description for an image. The word prediction is dependent on local linguistic contexts and fine-grained visual information and is also guided by previous linguistic tokens. However, current captioning works do not fully utilize local visual and linguistic information, generating coarse or incorrect descriptions. Also, captioning decoders have less recently focused on convolutional neural network (CNN), which has the advantage in extracting features. To solve these problems, we propose a local representation-enhanced recurrent convolutional network (Lore-RCN). Specifically, we propose a visual convolutional network to obtain enhanced local linguistic context, which incorporates selected local visual information and models short-term neighboring. Furthermore, we propose a linguistic convolutional network to obtain enhanced linguistic representation, which models long- and short-term correlations explicitly to leverage guiding information from previous linguistic tokens. Experiments conducted on COCO and Flickr30k datasets have verified the superiority of our proposed recurrent CNN-based model.
C1 [Wang, Xiaoyi] Univ Chinese Acad Sci, Sch Microelect, Beijing, Peoples R China.
   [Wang, Xiaoyi; Huang, Jun] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Shanghai Advanced Research Institute,
   CAS
RP Huang, J (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
EM wangxiaoyi2019@sari.ac.cn; huangj@sari.ac.cn
OI huang, jun/0000-0003-4939-3880
FU National Key R&D Program of China [2019YFC1521204]
FX This work was supported by the National Key R&D Program of China
   (2019YFC1521204).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen R., 2019, INT WORKSH HUM BRAIN, P235
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dorfer M, 2018, INT J MULTIMED INF R, V7, P117, DOI 10.1007/s13735-018-0151-5
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gu JX, 2017, IEEE I CONF COMP VIS, P1231, DOI 10.1109/ICCV.2017.138
   Huang L., 2019, ARXIV190909060
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Ji JZ, 2020, IEEE T IMAGE PROCESS, V29, P7615, DOI 10.1109/TIP.2020.3004729
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Jin T, 2019, NEUROCOMPUTING, V370, P118, DOI 10.1016/j.neucom.2019.08.042
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan H, 2022, IEEE SIGNAL PROC LET, V29, P374, DOI 10.1109/LSP.2021.3135825
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   WANG C, 2021, APPL INTELL
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   WANG Q, 2018, ARXIV180509019
   Wang WX, 2019, AAAI CONF ARTIF INTE, P8957
   Wang Y, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107313
   Wei HY, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3439734
   Wu AM, 2020, IEEE T CIRC SYST VID, V30, P4299, DOI 10.1109/TCSVT.2019.2956593
   Wu J., 2018, ACM T MULTIM COMPUT, P1
   Xiao HH, 2020, PATTERN RECOGN LETT, V129, P173, DOI 10.1016/j.patrec.2019.11.003
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yang LY, 2021, IEEE T MULTIMEDIA, V23, P835, DOI 10.1109/TMM.2020.2990074
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
NR 44
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 149
EP 157
DI 10.1007/s13735-022-00231-y
EA APR 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000781686000002
DA 2024-07-18
ER

PT J
AU Benoughidene, A
   Titouna, F
AF Benoughidene, Abdelhalim
   Titouna, Faiza
TI A novel method for video shot boundary detection using CNN-LSTM approach
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cut transition (CT); Similarity learning; Video segmentation;
   Convolutional neural networks (CNN); Long short-term memory (LSTM)
ID CLASSIFICATION; ALGORITHM
AB Due to the rapid growth of digital videos and the massive increase in video content, there is an urgent need to develop efficient automatic video content analysis mechanisms for different tasks, namely summarization, retrieval, and classification. In all these applications, one needs to identify shot boundary detection. This paper proposes a novel dual-stage approach for cut transition detection that can withstand certain illumination and motion effects. Firstly, we present a deep neural network model using the pre-trained model combined with long short-term memory LSTM network and the euclidean distance metric. Two parallel pre-trained models sharing the same weights extract the spatial features. Then, these features are fed to the LSTM and the euclidean distance metric to classify the frames into specific categories (similar or not similar). To train the model, we generated a new database containing 5000 frame pairs with two labels (similar, dissimilar) for training and 1000 frame pairs for testing from online videos. Secondly, we adopt the segment selection process to predict the shot boundaries. This preprocessing method can help improve the accuracy and speed of the VSBD algorithm. Then, cut transition detection based on the similarity model is conducted to identify the shot boundaries in the candidate segments. Experimental results on standard databases TRECVid 2001, 2007, and RAI show that the proposed approach achieves better detection rates over the state-of-the-art SBD methods in terms of the F1 score criterion.
C1 [Benoughidene, Abdelhalim; Titouna, Faiza] Univ Batna 2, LaSTIC Lab, Dept Comp Sci, Batna, Algeria.
C3 University of Batna 2
RP Benoughidene, A (corresponding author), Univ Batna 2, LaSTIC Lab, Dept Comp Sci, Batna, Algeria.
EM benouhalim@gmail.com; ftitouna@yahoo.fr
OI AbdelHalim, Benoughidene/0000-0001-8969-2119
CR [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Baber J, 2011, IEEE
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9256, P801, DOI 10.1007/978-3-319-23192-1_67
   Bendraou Y, 2017, THESIS U LIT COTE OP
   Bhaumik H, 2019, APPL SOFT COMPUT, V75, P633, DOI 10.1016/j.asoc.2018.10.053
   Bruno E, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P289, DOI 10.1109/ICME.2002.1035775
   Cernekova Z, 2002, IEEE
   Chakraborty S, 2022, VISUAL COMPUT, V38, P445, DOI 10.1007/s00371-020-02027-9
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P4007, DOI 10.1007/s11042-020-09857-8
   Chakraborty S, 2019, APPL INTELL, V49, P3207, DOI 10.1007/s10489-019-01444-1
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Gygli M, 2018, INT WORK CONTENT MUL
   Halim B.A., 2019, P 1 INT C INN TRENDS, P34
   Hassanien A, 2017, ARXIV
   Jialei Bi, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P512, DOI 10.1109/CISP.2011.6099941
   Kar T, 2017, SIGNAL IMAGE VIDEO P, V11, P1237, DOI 10.1007/s11760-017-1080-0
   Kikukawa T., 1992, Transactions of the Institute of Electronics, Information and Communication Engineers A, VJ75-A, P204
   Kundu Amitava, 2013, Polibits, V0, P55
   Li ZJ, 2016, PROCEEDINGS 2016 FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2016), P15, DOI 10.1109/ICMIP.2016.24
   Liang R, 2017, IEEE INT SYM MULTIM, P489, DOI 10.1109/ISM.2017.97
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663
   Mishra R, 2021, MULTIMED TOOLS APPL, V80, P28109, DOI 10.1007/s11042-021-11052-2
   Mondal J, 2018, MULTIMED TOOLS APPL, V77, P8139, DOI 10.1007/s11042-017-4707-9
   Nishani E, 2017, MEDD C EMBED COMPUT, P242
   Pal G, 2015, ADV INTELL SYST, V338, P119, DOI 10.1007/978-3-319-13731-5_14
   Phil M, 2018, ILLUSTRATED GUIDE LS
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Shao H, 2015, AER ADV ENG RES, V38, P951
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Singh A, 2022, MULTIMED TOOLS APPL, V81, P17989, DOI 10.1007/s11042-022-12343-y
   Singh A, 2020, SIGNAL IMAGE VIDEO P, V14, P645, DOI 10.1007/s11760-019-01593-3
   Soucek T, 2019, ARXIV
   Sun J, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P45, DOI 10.1109/VCIP.2014.7051500
   SWANBERG D, 1993, P SOC PHOTO-OPT INS, V1908, P13
   Thounaojam DM, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/8469428
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Tippaya S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1025, DOI 10.1109/ICDSP.2015.7252033
   Wang LL, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102847
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Yadav RB, 2007, OPT LASER ENG, V45, P695, DOI 10.1016/j.optlaseng.2006.11.001
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zheng J, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P266, DOI 10.1109/ISIMP.2004.1434051
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 47
TC 6
Z9 6
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 653
EP 667
DI 10.1007/s13735-022-00251-8
EA OCT 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000865203200001
DA 2024-07-18
ER

PT J
AU Mohite, N
   Waghmare, L
   Gonde, A
   Vipparthi, S
AF Mohite, Nilima
   Waghmare, Laxman
   Gonde, Anil
   Vipparthi, Santoshkumar
TI 3D local circular difference patterns for biomedical image retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE 3D LCDP; 3D LCDWP; Gaussian filter bank; Image retrieval; Local mesh
   patterns
ID INVARIANT TEXTURE CLASSIFICATION; BINARY PATTERNS; TERNARY PATTERNS;
   EXTREMA PATTERNS; GABOR FILTER; WAVELET; DESCRIPTOR; FACE; FEATURES; MRI
AB In this paper, three-dimensional local circular difference patterns (3D LCDP) and three-dimensional local circular difference wavelet patterns (3D LCDWP) are proposed for retrieval of biomedical images. The standard patterns are used to correlate gray value of center pixel with neighboring pixels. In the proposed approach, 3D volume is generated for calculating local circular difference patterns with the help of three planes obtained from original image. In case of color image, RGB channels are used as three planes and Gaussian filter banks of different resolution for gray level image. From this 3D volume, LCDP values are obtained by calculating relationship between center pixel and neighboring pixels in five different directions. Finally, feature vector is generated using histogram. The performance is evaluated using different medical databases: (i) open access series of imaging studies MRI database, (ii) International early lung cancer action program and vision and image analysis research groups CT scans, (iii) MESSIDOR-Retinal image database. The results are compared with existing biomedical image retrieval techniques by considering average retrieval precision and average retrieval rate as evaluation parameters.
C1 [Mohite, Nilima; Waghmare, Laxman; Gonde, Anil] SGGSIET, Ctr Excellence Signal & Image Proc COESIP, Dept ECE, Nanded, India.
   [Vipparthi, Santoshkumar] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology; National
   Institute of Technology (NIT System); Malaviya National Institute of
   Technology Jaipur
RP Mohite, N (corresponding author), SGGSIET, Ctr Excellence Signal & Image Proc COESIP, Dept ECE, Nanded, India.
EM nilima.mohite7@gmail.com; lmwaghmare@sggs.ac.in; abgonde@gmail.com;
   santu155@gmail.com
RI VIPPARTHI, SANTOSH Kumar/D-3081-2017; Vipparthi, Santosh
   Kumar/AAV-8694-2020; WAGHMARE, LAXMAN/AAG-1602-2019
OI Vipparthi, Santosh Kumar/0000-0002-5672-3537; Waghmare,
   Laxman/0000-0002-4236-7359
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   Baby CG, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P195, DOI 10.1109/ICSIPR.2013.6497987
   Das P, 2017, INT J MULTIMED INF R, V6, P271, DOI 10.1007/s13735-017-0135-x
   Deep G, 2016, ENG SCI TECHNOL, V19, P1895, DOI 10.1016/j.jestch.2016.05.006
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Du SL, 2017, MULTIMED TOOLS APPL, V76, P13973, DOI 10.1007/s11042-016-3779-2
   Galshetwar GM, 2017, PROCEDIA COMPUT SCI, V115, P440, DOI 10.1016/j.procs.2017.09.103
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   Kumar T., 2018, 2018 IEEE 20 INT C E, P1
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Li M, 2008, PATTERN RECOGN LETT, V29, P664, DOI 10.1016/j.patrec.2007.12.001
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Nanni L, 2008, PATTERN RECOGN, V41, P3461, DOI 10.1016/j.patcog.2008.05.013
   Nanni L, 2011, EXPERT SYST APPL, V38, P5125, DOI 10.1016/j.eswa.2010.09.137
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Porter R, 1997, IEE P-VIS IMAGE SIGN, V144, P180, DOI 10.1049/ip-vis:19971182
   Rao LK, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0044-z
   Shinde AA, 2017, INT J MULTIMED INF R, V6, P281, DOI 10.1007/s13735-017-0132-0
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Sudhakar MS, 2014, APPL SOFT COMPUT, V22, P492, DOI 10.1016/j.asoc.2014.04.029
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Vipparthi SK, 2016, IET COMPUT VIS, V10, P182, DOI 10.1049/iet-cvi.2015.0035
   Wang XY, 2015, ENG APPL ARTIF INTEL, V37, P43, DOI 10.1016/j.engappai.2014.08.012
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou JX, 2018, INT J MACH LEARN CYB, V9, P677, DOI 10.1007/s13042-016-0597-9
NR 46
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2019
VL 8
IS 2
BP 115
EP 125
DI 10.1007/s13735-019-00170-1
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA HX7JW
UT WOS:000467582100004
DA 2024-07-18
ER

PT J
AU Boididou, C
   Papadopoulos, S
   Zampoglou, M
   Apostolidis, L
   Papadopoulou, O
   Kompatsiaris, Y
AF Boididou, Christina
   Papadopoulos, Symeon
   Zampoglou, Markos
   Apostolidis, Lazaros
   Papadopoulou, Olga
   Kompatsiaris, Yiannis
TI Detection and visualization of misleading content on Twitter
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Social media; Verification; Fake detection; Information credibility
ID AFFECTIVE NORMS
AB The problems of online misinformation and fake news have gained increasing prominence in an age where user-generated content and social media platforms are key forces in the shaping and diffusion of news stories. Unreliable information and misleading content are often posted and widely disseminated through popular social media platforms such as Twitter and Facebook. As a result, journalists and editors are in need of new tools that can help them speed up the verification process for content that is sourced from social media. Motivated by this need, in this paper, we present a system that supports the automatic classification of multimedia Twitter posts into credible or misleading. The system leverages credibility-oriented features extracted from the tweet and the user who published it, and trains a two-step classification model based on a novel semisupervised learning scheme. The latter uses the agreement between two independent pretrained models on new posts as guiding signals for retraining the classification model. We analyze a large labeled dataset of tweets that shared debunked fake and confirmed real images and videos, and show that integrating the newly proposed features, and making use of bagging in the initial classifiers and of the semisupervised learning scheme, significantly improves classification accuracy. Moreover, we present a Web-based application for visualizing and communicating the classification results to end users.
C1 [Boididou, Christina] Urban Big Data Ctr, Glasgow, Lanark, Scotland.
   [Boididou, Christina; Papadopoulos, Symeon; Zampoglou, Markos; Apostolidis, Lazaros; Papadopoulou, Olga; Kompatsiaris, Yiannis] CERTH ITI, Thessaloniki, Greece.
RP Papadopoulos, S (corresponding author), CERTH ITI, Thessaloniki, Greece.
EM christina.mpoid@gmail.com; papadop@iti.gr; markzampoglou@iti.gr;
   laaposto@iti.gr; olgapapa@iti.gr; ikom@iti.gr
RI Papadopoulos, Symeon/AET-0683-2022; Zampoglou, Markos/AAP-1579-2021;
   Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Papadopoulos,
   Symeon/0000-0002-5441-7341; Papadopoulou, Olga/0000-0002-0498-7506
FU REVEAL project - European Commission [610928]; InVID project - European
   Commission [687786]; H2020 - Industrial Leadership [687786] Funding
   Source: H2020 - Industrial Leadership
FX This work has been supported by the REVEAL and InVID projects, under
   Contract Nos. 610928 and 687786, respectively, funded by the European
   Commission.
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2015, MEDIAEVAL
   [Anonymous], SOCIAL MEDIA NEWSROO
   [Anonymous], P MEDIAEVAL 2016 WOR
   [Anonymous], 2016, P MEDIAEVAL 2016 WOR
   [Anonymous], P 1 WORKSH MULT VER
   [Anonymous], 2014, PROC COMPUT JOURNALI
   [Anonymous], EUROPEAN JOURNALISM
   [Anonymous], MEDIAEVAL 2015 WORKS
   [Anonymous], P MEDIAEVAL 2016 WOR
   [Anonymous], MEDIAEVAL 2015 WORKS
   [Anonymous], P MEDIAEVAL 2016 WOR
   [Anonymous], 2014, P 6 INT C SOC INF SO
   Boididou C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P283, DOI 10.1145/3078971.3078979
   Boididou C, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P743, DOI 10.1145/2567948.2579323
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Hassan N., 2015, Information security culture: Asystematic literature review, P1
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kanske P, 2010, BEHAV RES METHODS, V42, P987, DOI 10.3758/BRM.42.4.987
   Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150
   Kumar S, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P591, DOI 10.1145/2872427.2883085
   Martin N., 2014, SPEC LIB ASS ANN C V, P8
   Metaxas PanagiotisTakas., 2015, P 18 ACM C COMPANION, P69, DOI DOI 10.1145/2685553.2702691
   O'Donovan J, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P293, DOI 10.1109/SocialCom-PASSAT.2012.128
   Oikawa MA, 2016, IEEE T INF FOREN SEC, V11, P5, DOI 10.1109/TIFS.2015.2442527
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Ratkiewicz J, 2011, P 20 INT C COMP WORL
   Redondo J, 2007, BEHAV RES METHODS, V39, P600, DOI 10.3758/BF03193031
   Rubin VL, 2016, P 2 WORKSH COMP APPR, P7
   Shao CC, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P745, DOI 10.1145/2872518.2890098
   Shengyun Sun, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P120, DOI 10.1007/978-3-642-37401-2_14
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   Tsakalidis A, 2014, LECT NOTES COMPUT SC, V8787, P168, DOI 10.1007/978-3-319-11746-1_12
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zubiaga A., 2017, CoRR
NR 41
TC 76
Z9 84
U1 3
U2 56
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2018
VL 7
IS 1
SI SI
BP 71
EP 86
DI 10.1007/s13735-017-0143-x
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GB9SN
UT WOS:000429414200007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ansari, MA
   Singh, DK
   Singh, VP
AF Ansari, Mohd. Aquib
   Singh, Dushyant Kumar
   Singh, Vibhav Prakash
TI Detecting abnormal behavior in megastore for crime prevention using a
   deep neural architecture
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video surveillance; Human detection; Human activity recognition (HAR);
   Abnormal behavior; 3D convolutional neural network (CNN); Deep neural
   architecture
AB The popularity of employing neural networks in diverse academic, scientific endeavors, and industrial applications is on the rise. In addition to moving forward in neural networks, there has been a great interest in modeling human behavior and activity patterns to recognize particular events. Various methods have so far been proposed for building expert vision systems to understand the scene and draw true semantic inferences from the observed dynamics. However, classifying abnormal or unusual activities in real-time video sequences is still challenging, as the details in video sequences have a time continuity constraint. A cost-effective approach is still demanding, and so this work presents an advanced three-dimensional convolutional network (A3DConvNet) for detecting abnormal behavior of persons by analyzing their actions. The network proposed is 15 layers deep that uses 18 convolutional operations to effectively analyze the video contents and produces spatiotemporal features. The integrated dense layer uses these features for the efficient learning process, and the softmax layer is used as the output layer for labeling the sequences. Additionally, we have created a dataset that carries video clips to represent abnormal behaviors of humans in megastores/shops, which is a consequent contribution of this paper. The dataset includes five complicated activities in the shops/megastores: normal, shoplifting, drinking, eating, and damaging. By analyzing human actions, the proposed algorithm produces an alert if anything like abnormalities are found. Our method's effectiveness is demonstrated through extensive experiments conducted on the synthesized dataset, achieving an accuracy of up to similar to 91%.
C1 [Ansari, Mohd. Aquib; Singh, Dushyant Kumar; Singh, Vibhav Prakash] CSED, MNNIT Allahabad, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Ansari, MA (corresponding author), CSED, MNNIT Allahabad, Prayagraj, India.
EM mansari.aquib@gmail.com; dushyant@mnnit.ac.in; vibhav@mnnit.ac.in
RI Ansari, Aquib/AHC-0974-2022; Singh, Dushyant Kumar/AAD-8512-2021
CR Ansari MA, 2022, MULTIMED TOOLS APPL, V81, P22497, DOI 10.1007/s11042-021-11438-2
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   da Silva MV, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106513
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dwivedi N., 2019, 2019 IEEE Conference on Information and Communication Technology, P1, DOI DOI 10.1109/CICT48419.2019.9066227
   Gupta N, 2022, ARTIF INTELL REV, V55, P4755, DOI [10.1080/19475683.2022.2040587, 10.1007/s10462-021-10116-x]
   Jayaswal Ruchi, 2021, Revue d'Intelligence Artificielle, V35, P255, DOI 10.18280/ria.350309
   Kamel A, 2019, INT J HUM-COMPUT INT, V35, P427, DOI 10.1080/10447318.2018.1543081
   Kanagaraj K, 2021, SIGNAL IMAGE VIDEO P, V15, P779, DOI 10.1007/s11760-020-01796-z
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Martínez-Mascorro GA, 2021, COMPUTATION, V9, DOI 10.3390/computation9020024
   Riaz H, 2021, EUR W VIS INF PROCES, DOI 10.1109/EUVIP50544.2021.9484062
   Sargano AB, 2020, MULTIMED TOOLS APPL, V79, P30653, DOI 10.1007/s11042-020-09381-9
   Serpush Fatemeh, 2021, SN Comput Sci, V2, P94, DOI 10.1007/s42979-021-00484-0
   Singh Dushyant Kumar, 2020, Procedia Computer Science, V171, P350, DOI 10.1016/j.procs.2020.04.036
   Singh DK., 2016, International Journal of Control Theory and Applications, V9, P173
   Singh DK, 2018, INT C ADV INFORMATIC, P54
   Singh DK, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P487, DOI 10.1109/ICCCIS51004.2021.9397203
   Tam NN, 2017, PROC 8 INT S INF COM, P370
   Tsushita H., 2018, INT C BIG DAT AN DEE, V744, P284
NR 22
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 25
DI 10.1007/s13735-023-00289-2
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P1KJ1
UT WOS:001048295800001
DA 2024-07-18
ER

PT J
AU Iqbal, A
   Sharif, M
   Yasmin, M
   Raza, M
   Aftab, S
AF Iqbal, Ahmed
   Sharif, Muhammad
   Yasmin, Mussarat
   Raza, Mudassar
   Aftab, Shabib
TI Generative adversarial networks and its applications in the biomedical
   image segmentation: a comprehensive survey
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Generative adversarial network; GANs applications; GANs in medical image
   segmentation
ID SEMANTIC SEGMENTATION; GAN
AB Recent advancements with deep generative models have proven significant potential in the task of image synthesis, detection, segmentation, and classification. Segmenting the medical images is considered a primary challenge in the biomedical imaging field. There have been various GANs-based models proposed in the literature to resolve medical segmentation challenges. Our research outcome has identified 151 papers; after the twofold screening, 138 papers are selected for the final survey. A comprehensive survey is conducted on GANs network application to medical image segmentation, primarily focused on various GANs-based models, performance metrics, loss function, datasets, augmentation methods, paper implementation, and source codes. Secondly, this paper provides a detailed overview of GANs network application in different human diseases segmentation. We conclude our research with critical discussion, limitations of GANs, and suggestions for future directions. We hope this survey is beneficial and increases awareness of GANs network implementations for biomedical image segmentation tasks.
C1 [Iqbal, Ahmed; Sharif, Muhammad; Yasmin, Mussarat; Raza, Mudassar] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Rawalpindi, Pakistan.
   [Aftab, Shabib] Virtual Univ Pakistan, Dept Comp Sci, Lahore, Pakistan.
C3 COMSATS University Islamabad (CUI); Virtual University of Pakistan
RP Iqbal, A (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Rawalpindi, Pakistan.
EM ahmedeqbal@gmail.com; muhammadsharifmalik@yahoo.com;
   mussaratabdullah@gmail.com; mudassarkazmi@yahoo.com;
   shabib.aftab@gmail.com
RI Sharif, Muhammad/ACD-2598-2022; Aftab, Shabib/JDV-4960-2023; Yasmin,
   Mussarat/HPC-9476-2023; Sharif, Muhammad/AAB-8376-2022; iqbal,
   Ahmed/GWQ-5048-2022
OI Sharif, Muhammad/0000-0002-7258-8400; Aftab, Shabib/0000-0002-7662-1394;
   iqbal, Ahmed/0000-0003-4946-4167; Raza, Mudassar/0000-0001-9124-9298
CR Abdelhalim ISA, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113922
   Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006
   Alsinan Ahmed Z., 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P795, DOI 10.1007/978-3-030-59725-2_77
   Alsinan AZ, 2020, INT J COMPUT ASS RAD, V15, P1477, DOI 10.1007/s11548-020-02221-z
   Arbelle A, 2018, I S BIOMED IMAGING, P645, DOI 10.1109/ISBI.2018.8363657
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Baur C, 2019, LECT NOTES COMPUT SC, V11383, P161, DOI 10.1007/978-3-030-11723-8_16
   Bi L, 2019, I S BIOMED IMAGING, P1100, DOI [10.1109/isbi.2019.8759479, 10.1109/ISBI.2019.8759479]
   Bian XS, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105717
   Chang Q, 2020, SYNTHETIC LEARNING L, P1
   Chartsias A, 2018, LECT NOTES COMPUT SC, V11071, P490, DOI 10.1007/978-3-030-00934-2_55
   Chen H, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P301, DOI [10.1109/ICAIBD.2019.8836968, 10.1109/icaibd.2019.8836968]
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Cirillo MD, 2020, ARXIV, P1
   Dai W, 2018, LECT NOTES COMPUT SC, V11045, P263, DOI 10.1007/978-3-030-00889-5_30
   Delannoy Q, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103755
   Ding SS, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102224
   Dong SY, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101638
   Dong SY, 2018, LECT NOTES COMPUT SC, V11073, P622, DOI 10.1007/978-3-030-00937-3_71
   Dong X, 2019, RADIOTHER ONCOL, V141, P192, DOI 10.1016/j.radonc.2019.09.028
   Dong X, 2019, MED PHYS, V46, P2157, DOI 10.1002/mp.13458
   Dong Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P507, DOI 10.1007/978-3-319-66179-7_58
   Dou Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P691
   Elazab A, 2020, NEURAL NETWORKS, V132, P321, DOI 10.1016/j.neunet.2020.09.004
   Eslami M, 2020, IEEE T MED IMAGING, V39, P2553, DOI 10.1109/TMI.2020.2974159
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gaj S, 2020, MAGN RESON MED, V84, P437, DOI 10.1002/mrm.28111
   Garcia-Garcia A, 2017, MED IMAGE ANAL, V42, P60, DOI [10.1016/j.media.2017.07.005, DOI 10.1016/J.MEDIA.2017.07.005]
   Goel T, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09785-7
   Gong X, 2021, IEEE WINT CONF APPL, P3993, DOI 10.1109/WACV48630.2021.00404
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Y, 2019, LECT N BIOINFORMAT, V11466, P469, DOI 10.1007/978-3-030-17935-9_42
   Gupta L, 2019, LECT NOTES COMPUT SC, V11764, P631, DOI 10.1007/978-3-030-32239-7_70
   HAMGHALAM M, 2019, ARXIV190913640, DOI DOI 10.1007/978-3-030-46640-4_15
   Hamghalam M, 2020, NEURAL NETWORKS, V132, P43, DOI 10.1016/j.neunet.2020.08.014
   Hamghalam M, 2020, I S BIOMED IMAGING, P1499, DOI [10.1109/ISBI45749.2020.9098347, 10.1109/isbi45749.2020.9098347]
   Han LY, 2020, COMPUT METH PROG BIO, V189, DOI 10.1016/j.cmpb.2019.105275
   Han ZY, 2018, MED IMAGE ANAL, V50, P23, DOI 10.1016/j.media.2018.08.005
   Huang P, 2019, LECT NOTES COMPUT SC, V11766, P155, DOI 10.1007/978-3-030-32248-9_18
   Huang YW, 2020, IEEE T IMAGE PROCESS, V29, P8187, DOI 10.1109/TIP.2020.3011557
   Hui Qu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P175, DOI 10.1007/978-3-030-58583-9_11
   Iqbal A, 2010, J KING SAUD U COMPUT, DOI 10.1016/j.jksuci.2021.10.002
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Izadi S, 2018, I S BIOMED IMAGING, P881, DOI 10.1109/ISBI.2018.8363712
   Jiang Y, 2019, IEEE ACCESS, V7, P64483, DOI 10.1109/ACCESS.2019.2917508
   Kamnitsas K, 2017, LECT NOTES COMPUT SC, V10265, P597, DOI 10.1007/978-3-319-59050-9_47
   Kapil A, 2019, ARXIV190611118
   Kazeminia S, 2020, ARTIF INTELL MED, V109, DOI 10.1016/j.artmed.2020.101938
   Khalili N, 2019, LECT NOTES COMPUT SC, V11766, P320, DOI 10.1007/978-3-030-32248-9_36
   Khosravan N, 2019, LECT NOTES COMPUT SC, V11769, P68, DOI 10.1007/978-3-030-32226-7_8
   Ko S, 2020, ARXIV, P1
   Koyun O.C., 2019, 2019 IEEE INT S INNO, P1
   Kuang HL, 2019, LECT NOTES COMPUT SC, V11766, P856, DOI 10.1007/978-3-030-32248-9_95
   Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855
   Lahiri A, 2017, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2017.110
   Lan HR, 2019, LECT NOTES COMPUT SC, V11764, P273, DOI 10.1007/978-3-030-32239-7_31
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Li QY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154203
   Li YX, 2018, IEEE ACCESS, V6, P14048, DOI 10.1109/ACCESS.2018.2808938
   Li ZJ, 2019, LECT NOTES COMPUT SC, V11769, P275, DOI 10.1007/978-3-030-32226-7_31
   Li ZJ, 2018, LECT NOTES COMPUT SC, V10670, P123, DOI 10.1007/978-3-319-75238-9_11
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu P, 2019, LECT NOTES COMPUT SC, V11766, P110, DOI 10.1007/978-3-030-32248-9_13
   Liu XM, 2019, MED PHYS, V46, P3532, DOI 10.1002/mp.13584
   MAJURSKI M, 2019, IEEE COMPUT SOC C CO
   Martel AL, 1999, LECT NOTES COMPUT SC, V1679, P22
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Moeskops P, 2017, LECT NOTES COMPUT SC, V10553, P56, DOI 10.1007/978-3-319-67558-9_7
   Negi A, 2020, ARAB J SCI ENG, V45, P6399, DOI 10.1007/s13369-020-04480-z
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Nie D, 2019, AAAI CONF ARTIF INTE, P1085
   Nie D, 2020, INT J COMPUT VISION, V128, P2494, DOI 10.1007/s11263-020-01321-2
   Nie D, 2019, IEEE T NEUR NET LEAR, V30, P1552, DOI 10.1109/TNNLS.2018.2870182
   Oh KT, 2020, J DIGIT IMAGING, V33, P816, DOI 10.1007/s10278-020-00321-5
   Ossenberg-Engels J., 2019, INT WORKSHOP STAT AT, P109
   Pan YS, 2019, LECT NOTES COMPUT SC, V11766, P137, DOI 10.1007/978-3-030-32248-9_16
   Pandey S, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101782
   Pang SC, 2020, EUR J NUCL MED MOL I, V47, P2248, DOI 10.1007/s00259-020-04781-3
   Park KB, 2020, IEEE ACCESS, V8, P146308, DOI 10.1109/ACCESS.2020.3015108
   Kumar MRP, 2021, INT J MULTIMED INF R, V10, P1, DOI 10.1007/s13735-020-00196-w
   Peng YJ, 2019, MULTIMED TOOLS APPL, V78, P10965, DOI 10.1007/s11042-018-6523-2
   Pollastri F, 2020, MULTIMED TOOLS APPL, V79, P15575, DOI 10.1007/s11042-019-7717-y
   Rachmadi MF, 2019, LECT NOTES COMPUT SC, V11766, P146, DOI 10.1007/978-3-030-32248-9_17
   Radford A., 2016, ARXIV, DOI [10.48550/ARXIV.1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Rammy SA, 2019, 2019 22ND IEEE INTERNATIONAL MULTI TOPIC CONFERENCE (INMIC), P244, DOI 10.1109/inmic48123.2019.9022732
   Rezaei M., 2018, INFORM AKTUELL, DOI 10.1007/978-3-662-56537-7_89
   Rezaei M, 2020, MULTIMED TOOLS APPL, V79, P15329, DOI 10.1007/s11042-019-7305-1
   Rezaei M, 2019, IEEE WINT CONF APPL, P1836, DOI 10.1109/WACV.2019.00200
   Rezaei M, 2019, LECT NOTES COMPUT SC, V11384, P321, DOI 10.1007/978-3-030-11726-9_29
   Rezaei M, 2018, LECT NOTES COMPUT SC, V10670, P241, DOI 10.1007/978-3-319-75238-9_21
   Ruan YA, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101721
   Sadanandan SK, 2017, IEEE INT CONF COMP V, P36, DOI 10.1109/ICCVW.2017.11
   Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x
   Sarker M. Mostafa Kamal, 2019, ARXIV
   Sekuboyina A, 2018, LECT NOTES COMPUT SC, V11073, P649, DOI 10.1007/978-3-030-00937-3_74
   Shankaranarayana SM, 2017, LECT NOTES COMPUT SC, V10554, P168, DOI 10.1007/978-3-319-67561-9_19
   Shi HQ, 2020, CHIN CONT DECIS CONF, P2486, DOI [10.1109/ccdc49329.2020.9164303, 10.1109/CCDC49329.2020.9164303]
   Shi YG, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0623-8
   Sia D, 2017, GASTROENTEROLOGY, V152, P745, DOI 10.1053/j.gastro.2016.11.048
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   SINGHRAO K, 2020, MED PHYS
   Sivanesan U, 2019, ARXIV, P1
   Son J, 2019, J DIGIT IMAGING, V32, P499, DOI 10.1007/s10278-018-0126-3
   Sorin V, 2020, ACAD RADIOL, V27, P1175, DOI 10.1016/j.acra.2019.12.024
   Sun Y, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), P227, DOI 10.1109/ICBK50248.2020.00041
   Tan JX, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101817
   Teng L, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/1487035
   Tjio G, 2019, LECT NOTES COMPUT SC, V11855, P148, DOI 10.1007/978-3-030-32956-3_18
   Tokuoka Y, 2019, ICBBE 2019: 2019 6TH INTERNATIONAL CONFERENCE ON BIOMEDICAL AND BIOINFORMATICS ENGINEERING, P44, DOI 10.1145/3375923.3375948
   Tong N, 2019, MED PHYS, V46, P2669, DOI 10.1002/mp.13553
   Tsuda Hiroki, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P1065, DOI 10.1109/CVPRW.2019.00139
   Tu WL, 2019, C IND ELECT APPL, P228, DOI 10.1109/ICIEA.2019.8833908
   Tu WL, 2019, IEEE ACCESS, V7, P77037, DOI 10.1109/ACCESS.2019.2921815
   Bisneto TRV, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106165
   Wang D, 2017, INT CONF MACH LEARN, P385
   Wang GT, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101787
   Wang SJ, 2019, IEEE T MED IMAGING, V38, P2485, DOI 10.1109/TMI.2019.2899910
   Wang W, 2021, CLIN IMAG, V70, P1, DOI 10.1016/j.clinimag.2020.10.014
   Wegmayr V, 2019, LECT NOTES COMPUT SC, V11824, P247, DOI 10.1007/978-3-030-33676-9_17
   Wu C, 2019, INT CONF COMP SCI ED, P642, DOI [10.1109/iccse.2019.8845397, 10.1109/ICCSE.2019.8845397]
   Xia KJ, 2019, IEEE ACCESS, V7, P96349, DOI 10.1109/ACCESS.2019.2929270
   Xiao QQ, 2019, LECT NOTES COMPUT SC, V11663, P333, DOI 10.1007/978-3-030-27272-2_29
   Xiao XJ, 2019, LECT NOTES COMPUT SC, V11765, P237, DOI 10.1007/978-3-030-32245-8_27
   Xie H, 2020, NEURAL NETWORKS, V132, P477, DOI 10.1016/j.neunet.2020.09.005
   Xu CC, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101668
   Xu CC, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101568
   Xu CC, 2018, LECT NOTES COMPUT SC, V11071, P525, DOI 10.1007/978-3-030-00934-2_59
   Xu Z, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/5650463
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yan WJ, 2019, LECT NOTES COMPUT SC, V11765, P623, DOI 10.1007/978-3-030-32245-8_69
   Yanan Ruan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P439, DOI 10.1007/978-3-030-59719-1_43
   Yang JW, 2020, INTERDISCIP SCI, V12, P323, DOI 10.1007/s12539-020-00385-5
   Yang TJ, 2020, J DIGIT IMAGING, V33, P946, DOI 10.1007/s10278-020-00339-9
   Yang Y, 2019, ARXIV191202589, P1
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yin, 2019, COMMUN COMPUT INF SC, V1058, P608, DOI [10.1007/978-981-15-0118-0_47, DOI 10.1007/978-981-15-0118-0_47]
   Yizhe Zhang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P408, DOI 10.1007/978-3-319-66179-7_47
   Yu F, 2020, I S BIOMED IMAGING, P1503, DOI [10.1109/isbi45749.2020.9098535, 10.1109/ISBI45749.2020.9098535]
   Yuan WG, 2019, LECT NOTES COMPUT SC, V11766, P229, DOI 10.1007/978-3-030-32248-9_26
   Zama A, 2020, INT J COMPUT ASS RAD, V15, P931, DOI 10.1007/s11548-020-02192-1
   Zhang CY, 2018, 2018 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P84
   Zhang HR, 2019, THIRD INTERNATIONAL SYMPOSIUM ON IMAGE COMPUTING AND DIGITAL MEDICINE (ISICDM 2019), P118, DOI 10.1145/3364836.3364860
   Zhang Y, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101664
   Zhao MY, 2018, LECT NOTES COMPUT SC, V11073, P720, DOI 10.1007/978-3-030-00937-3_82
   Zheng H, 2019, LECT NOTES COMPUT SC, V11769, P148, DOI 10.1007/978-3-030-32226-7_17
   Zhou YJ, 2019, ADV DIFFER EQU-NY, DOI 10.1186/s13662-018-1939-6
   Zhou YK, 2021, NEUROCOMPUTING, V437, P118, DOI 10.1016/j.neucom.2020.06.143
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu WT, 2018, I S BIOMED IMAGING, P847, DOI 10.1109/ISBI.2018.8363704
NR 150
TC 24
Z9 24
U1 7
U2 57
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 333
EP 368
DI 10.1007/s13735-022-00240-x
EA JUL 2022
PG 36
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000824982000001
PM 35821891
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Li, J
   Guo, YM
   Lao, SY
   Zhao, X
   Bai, L
   Wang, HR
AF Li, Jian
   Guo, Yanming
   Lao, Songyang
   Zhao, Xiang
   Bai, Liang
   Wang, Haoran
TI Few2Decide: towards a robust model via using few neuron connections to
   decide
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few2Decide; Deep neural network; Adversarial attack and defense;
   Robustness
AB Researches have shown that image classification networks are vulnerable to adversarial examples, which seriously limits their application in safely critical scenarios. Existing defense methods usually employ adversarial training or adjust the network structure to resist adversarial attack. Although these defense methods can improve the model robustness to some extent, they often significantly decrease the accuracy on the clean data and bring additional computational cost. In this work, we analyze the impact of adversarial example on neuron connections and propose a Few2Decide method to train a robust model by dropping part of non-robust connections in the fully connected layer. Our model can get high perturbed data accuracy without increasing trainable parameters, meanwhile, get high clean data accuracy. Experimental results prove that our method can provide a robust model and achieve state-of-the-art performance on the CIFAR-10 dataset. Specifically, our Few2Decide method achieves 73.01% adversarial accuracy on the CIFAR-10 dataset under the challenging untargeted attack in white-box settings with an attack strength 8/255, using ResNet-20[4x] architecture.
C1 [Li, Jian; Guo, Yanming; Lao, Songyang; Zhao, Xiang; Bai, Liang; Wang, Haoran] Natl Univ Def Technol, Changsha, Peoples R China.
C3 National University of Defense Technology - China
RP Guo, YM (corresponding author), Natl Univ Def Technol, Changsha, Peoples R China.
EM guoyanming@nudt.edu.cn
RI Wang, Haoran/L-4320-2019; Yu, ZH/KBC-6889-2024
OI Wang, Haoran/0000-0001-7831-5238; 
CR Addepalli S, 2020, IEEE C COMP VIS PATT
   Athalye A, 2018, PR MACH LEARN RES, V80
   Bai Y., 2021, INT C LEARN REPR
   Bhagoji, 2018, ANN C INF SCI SYST C
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen PY, 2017, P 10 ACM WORKSH ART, P15, DOI [10.1145/3128572.3140448, DOI 10.1145/3128572.3140448]
   Cheng Minhao, 2020, INT C LEARN REPR
   Dziugaite G., 2016, ARXIV160800853
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He ZZ, 2019, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2019.00068
   Jeddi A, 2020, PROC CVPR IEEE, P1238, DOI 10.1109/CVPR42600.2020.00132
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lecuyer M, 2019, P IEEE S SECUR PRIV, P656, DOI 10.1109/SP.2019.00044
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Liu Y., 2017, INT C LEARNING REPRE
   Lyu CC, 2015, IEEE DATA MINING, P301, DOI 10.1109/ICDM.2015.84
   Madry A., 2018, ARXIV
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Rony J, 2019, PROC CVPR IEEE, P4317, DOI 10.1109/CVPR.2019.00445
   Ros AS, 2018, AAAI CONF ARTIF INTE, P1660
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Xiao J, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337895
NR 27
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 189
EP 198
DI 10.1007/s13735-021-00223-4
EA JAN 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000750795600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, QQ
   Su, F
   Wang, YY
AF Wang, Qianqian
   Su, Feng
   Wang, Yuyang
TI Hierarchical attentive deep neural networks for semantic music
   annotation through multiple music representations
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Music annotation; Convolutional network; Dual-state LSTM; Gated linear
   unit; Self-attention
ID FEATURES
AB Automatically assigning a group of appropriate semantic tags to one music piece provides an effective way for people to efficiently utilize the massive and ever increasing online and off-line music data. In this paper, we propose a novel end-to-end deep neural network model for automatic music annotation, which effectively integrates available multiple complementary music representations and jointly accomplishes music representation learning, structure modeling, and tag prediction. The model first hierarchically leverages attentive convolutional networks and recurrent networks to learn informative descriptions from Mel-spectrogram and raw waveform of the music and depict time-varying structures embedded in the description sequence. A dual-state LSTM network is then employed to capture the correlations between two representation channels as supplementary music descriptions. Finally, the model aggregates music description sequence into a holistic embedding with a self-attentive multi-weighting mechanism, which adaptively captures multi-aspect summarized information of the music for tag prediction. Experiments on the public MagnaTagATune benchmark music dataset show that the proposed model outperforms state-of-the-art methods for automatic music annotation.
C1 [Wang, Qianqian; Su, Feng; Wang, Yuyang] Nanjing Univ, State Key Lab Novel Software Technol, 163 Xianlin Rd, Nanjing, Peoples R China.
C3 Nanjing University
RP Su, F (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, 163 Xianlin Rd, Nanjing, Peoples R China.
EM suf@nju.edu.cn
CR [Anonymous], 2016, ICLR
   [Anonymous], 2012, P 13 INT SOC MUS INF
   [Anonymous], 2015, ARXIV150804999
   [Anonymous], 2017, STRUCTURED SELF ATTE
   [Anonymous], 2013, 14th International Society for Music Information Retrieval Conference (ISMIR-2013)
   [Anonymous], 2012, ARXIV12065241
   [Anonymous], P 17 C INT SOC MUS I
   [Anonymous], 2015, P 3 INT C LEARN REPR
   [Anonymous], 2012, THESIS
   Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7
   Bertin-Mahieux T, 2008, J NEW MUSIC RES, V37, P115, DOI 10.1080/09298210802479250
   Chang KaichunK., 2010, International Society for Music Information Retrieval, P387
   Chen ZS, 2009, IEEE T AUDIO SPEECH, V17, P1547, DOI 10.1109/TASL.2009.2022435
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Guclu U, 2016, Advances in Neural Information Processing Systems, V29, P2101
   Hamel P., 2011, Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR), P729
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kim T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P366, DOI 10.1109/ICASSP.2018.8462046
   Law E., 2009, Proc. Int. Conf. Music Inf. Retrieval, P387
   Lee J, 2017, IEEE SIGNAL PROC LET, V24, P1208, DOI 10.1109/LSP.2017.2713830
   Liu JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1048, DOI 10.1145/2964284.2964292
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   McKinney M.F., 2003, Proc. ISMIR, V3, P151
   Moore Brian C. J., 2004, An Introduction to the Psychology of Hearing, DOI DOI 10.1080/00224545.1957.9714298
   Ness S.R., 2009, Proceedings of the ACM International Conference on Multimedia, P705, DOI 10.1145/1631272.1631393
   Schluter J., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P118, DOI 10.1109/ICMLA.2011.102
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tingle D., 2010, P ISMIR, P55
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   van den Oord A., 2014, P 15 INT SOC MUSIC I, P29
   Xiong Y, 2017, IEEE INT CON MULTI, P961, DOI 10.1109/ICME.2017.8019341
   Yang ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P146, DOI 10.1145/3123266.3123327
NR 37
TC 12
Z9 12
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2020
VL 9
IS 1
SI SI
BP 3
EP 16
DI 10.1007/s13735-019-00186-7
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KQ6ZX
UT WOS:000517070300002
DA 2024-07-18
ER

PT J
AU Ameur, B
   Belahcene, M
   Masmoudi, S
   Ben Hamida, A
AF Ameur, Bilel
   Belahcene, Mebarka
   Masmoudi, Sabeur
   Ben Hamida, Ahmed
TI Hybrid descriptors and Weighted PCA-EFMNet for Face Verification in the
   Wild
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Descriptor; Deep learning; Classification; Fusion; Pooling
ID RECOGNITION; DISTANCE
AB Unconstrained face recognition is a complex task because of the numerous intra-class changes caused by lighting, occlusion, facial expressions and poses changes. Such variations affect considerably the performance of facial recognition systems, particularly those based on 2D information. In this research work, an efficient feature extraction method, called Gabor Local Binarized Statistical Image Features, is introduced. A new deep learning network is also developed to extract features relying on data processing components: (1) Cascaded Weighted Principal Component Analysis (WPCA) with Enhanced Fisher Model (WPCA-EFM); (2) binary hashing; and (3) Block-wise Histograms. The suggested architecture (Weighted PCA-EFM) is employed to learn multistage filter banks. Simple block histogram and binary hashing are applied for indexing and pooling, which facilitate the design and learning of our architecture for Face Verification in the Wild. Classification is finally performed using distance measure Cosine and support vector machine. Our experiments are carried out in real-world dataset: Labeled Faces in the Wild. Experimental findings demonstrate that the developed technique achieved high accuracy of 95%.
C1 [Ameur, Bilel; Masmoudi, Sabeur; Ben Hamida, Ahmed] Sfax Univ, ATMS, Natl Engn Sch Sfax ENIS, Soukra St,Km 3-5,BP 1173, Sfax 3038, Tunisia.
   [Ameur, Bilel] Gabes Univ, Natl Engn Sch Gabes ENIG, Ave Omar Ibn El Khattab Zrig, Gabes 6029, Tunisia.
   [Belahcene, Mebarka] Mohamed Khider Univ Biskra, Fac Sci & Technol, LI3C, BP 145 RP, Biskra 07000, Algeria.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Gabes; Universite Mohamed Khider Biskra
RP Ameur, B (corresponding author), Sfax Univ, ATMS, Natl Engn Sch Sfax ENIS, Soukra St,Km 3-5,BP 1173, Sfax 3038, Tunisia.; Ameur, B (corresponding author), Gabes Univ, Natl Engn Sch Gabes ENIG, Ave Omar Ibn El Khattab Zrig, Gabes 6029, Tunisia.
EM bilel.ameur@gmail.com
RI Sahnoun, Karim/HKW-3397-2023
OI ameur, bilel/0000-0002-9914-7605
CR Aliradi R, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC)
   Ameur B, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P453, DOI 10.1109/ATSIP.2016.7523134
   Anderson R, 2018, 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL CONFERENCE (INAPR), P34, DOI 10.1109/INAPR.2018.8627004
   [Anonymous], P C COMP SCI INF TEC
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], VIS COMPUT
   [Anonymous], 2008, LABELED FACES WILD D
   [Anonymous], INT C ADV TECHN SIGN
   [Anonymous], 2018, 2018 4 INT C ADV TEC
   [Anonymous], ARXIV181103214
   [Anonymous], SCI INF C
   [Anonymous], 2019, P IEEE INT C WIR COM
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   [Anonymous], BRIT MACH VIS C
   Arefin MMN, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P389, DOI 10.1109/ICREST.2019.8644317
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Bessaoudi M, 2019, NEUROCOMPUTING, V329, P267, DOI 10.1016/j.neucom.2018.09.051
   Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chauhan Nitin Kumar, 2018, 2018 International Conference on Computing, Power and Communication Technologies (GUCON), P347, DOI 10.1109/GUCON.2018.8675097
   Chong SC, 2018, J VIS COMMUN IMAGE R, V56, P207, DOI 10.1016/j.jvcir.2018.09.017
   Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Deng WH, 2019, IEEE T PATTERN ANAL, V41, P758, DOI 10.1109/TPAMI.2018.2800008
   Geng TY, 2018, NEURAL COMPUT APPL, V30, P3243, DOI 10.1007/s00521-017-2918-7
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Hu Junlin., 2014, COMPUTER VISION ACCV, P252
   Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968
   Juefei-Xu F, 2015, IEEE T IMAGE PROCESS, V24, P4780, DOI 10.1109/TIP.2015.2468173
   Lal M, 2018, INT J ADV COMPUT SC, V9, P42
   Li YK, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023016
   Lilei Zheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163085
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Mohammed NN, 2018, INT CONF INTEL INFOR, P267, DOI 10.1109/ICIIBMS.2018.8549971
   Ning C, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P204, DOI 10.1109/ICIVC.2018.8492872
   Ouamane A, 2015, IEEE INT CONF AUTOMA
   Ouamane A, 2014, IEEE IMAGE PROC, P313, DOI 10.1109/ICIP.2014.7025062
   Sun X., 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Sun Z, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618501219
   Wang Q, 2018, J COMPUT SCI TECH-CH, V33, P335, DOI 10.1007/s11390-018-1822-7
   Yadav SK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1878, DOI 10.1109/ICICCT.2018.8473220
   Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454
   Ying YM, 2012, J MACH LEARN RES, V13, P1
   Zafaruddin GM, 2019, ADV INTELL SYST, V810, P855, DOI 10.1007/978-981-13-1513-8_87
   Zeng H, 2016, INT J OPT, V2016, DOI 10.1155/2016/1584514
   Zhai YL, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P23, DOI 10.1145/3317640.3317655
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 49
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2019
VL 8
IS 3
BP 143
EP 154
DI 10.1007/s13735-019-00175-w
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS8RG
UT WOS:000482416600002
DA 2024-07-18
ER

PT J
AU Cui, LM
   Zhang, JW
   He, LF
   Yu, PS
AF Cui, Limeng
   Zhang, Jiawei
   He, Lifang
   Yu, Philip S.
TI Multi-view collective tensor decomposition for cross-modal hashing
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cross-modal hashing; Tensor factorization; Metric learning; Multi-view
   learning
ID QUANTIZATION; CODES
AB With the development of social media, data often come from a variety of sources in different modalities. These data contain complementary information that can be used to produce better learning algorithms. Such data exhibit dual heterogeneity: On the one hand, data obtained from multiple modalities are intrinsically different; on the other hand, features obtained from different disciplines are usually heterogeneous. Existing methods often consider the first facet while ignoring the second. Thus, in this paper, we propose a novel multi-view cross-modal hashing method named Multi-view Collective Tensor Decomposition (MCTD) to mitigate the dual heterogeneity at the same time, which can fully exploit the multimodal multi-view feature while simultaneously discovering multiple separated subspaces by leveraging the data categories as supervision information. We propose a novel cross-modal retrieval framework which consists of three components: (1) two tensors which model the multi-view features from different modalities in order to get better representation of the complementary features and a latent representation space; (2) a block-diagonal loss which is used to explicitly enforce a more discriminative latent space by leveraging supervision information; and (3) two feature projection matrices which characterize the data and generate the latent representation for incoming new queries. We use an iterative updating optimization algorithm to solve the objective function designed for MCTD. Extensive experiments prove the effectiveness of MCTD compared with state-of-the-art methods.
C1 [Cui, Limeng] Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16801 USA.
   [Zhang, Jiawei] Florida State Univ, Dept Comp Sci, IFM Lab, Tallahassee, FL 32306 USA.
   [He, Lifang] Cornell Univ, Weill Cornell Med, New York, NY 10021 USA.
   [Yu, Philip S.] Univ Illinois, Dept Comp Sci, Chicago, IL USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; State University System of Florida;
   Florida State University; Cornell University; Weill Cornell Medicine;
   University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
RP Cui, LM (corresponding author), Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16801 USA.
EM lzc334@psu.edu
RI Yu, Philip S/A-2815-2012; Cui, Limeng/AEI-0259-2022; He,
   Lifang/D-8175-2016; ARSLAN, Okan/AAA-3232-2020
OI He, Lifang/0000-0001-7810-9071; 
FU National Natural Science Foundation of China [61672313, 61503253];
   National Science Foundation [IIS-1526499, IIS-1763365, CNS-1626432];
   Natural Science Foundation of Guangdong Province [2017A030313339]
FX The work is supported by the National Natural Science Foundation of
   China under Grant No.: 61672313 and 61503253, the National Science
   Foundation under Grant Nos.: IIS-1526499, IIS-1763365 and CNS-1626432
   and Natural Science Foundation of Guangdong Province under Grant No.:
   2017A030313339.
CR [Anonymous], 2012, NEURIPS
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2012, Book A probabilistic model for multimodal hash function learning, DOI DOI 10.1145/2339530.2339678
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao BK, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P427, DOI 10.1145/2835776.2835777
   Cao Y, 2017, AAAI CONF ARTIF INTE, P3974
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Huang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1893
   Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Jin L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P311, DOI 10.1109/ISM.2014.56
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   LI K, 2017, TPAMI, V39, P1825, DOI DOI 10.1109/TPAMI.2016.2610969
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu Hong, 2016, IJCAI, P1767, DOI DOI 10.1109/TIP.2016.2564638
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Lu XY, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P433
   Moran S, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P907, DOI 10.1145/2766462.2767816
   Morup M, 2008, NEURAL COMPUT, V20, P2112, DOI 10.1162/neco.2008.11-06-407
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Qi JW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2630
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tang JH, 2015, IEEE T MULTIMEDIA, V17, P1899, DOI 10.1109/TMM.2015.2476660
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Wang J., 2014, CoRR
   Wang K., 2016, A comprehensive survey on cross-modal retrieval
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Yao T, 2016, NEUROCOMPUTING, V193, P250, DOI 10.1016/j.neucom.2016.02.016
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang J, 2018, UNSUPERVISED GENERAT
   Zhang J, 2017, IEEE T CIRCUITS SYST
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 47
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2019
VL 8
IS 1
SI SI
BP 47
EP 59
DI 10.1007/s13735-018-0164-0
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HT8ZD
UT WOS:000464853000005
DA 2024-07-18
ER

PT J
AU Muthureka, K
   Reddy, US
   Janet, B
AF Muthureka, K.
   Reddy, U. Srinivasulu
   Janet, B.
TI An improved customized CNN model for adaptive recognition of cerebral
   palsy people's handwritten digits in assessment
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cerebral palsy; Handwritten digit recognition; CNN; MNIST; Improving
   learning potential
ID CHARACTER-RECOGNITION; NEURAL-NETWORKS; CLASSIFICATION; CHILDREN
AB Cerebral palsy (CP) is used to describe a group of disorders, characterized by non-progressive, but permanent damage to the developing brain that results in motor deficits, functional difficulties, sensory impairments, and cognitive impairments. AI is rapidly developing with special importance to education and healthcare. Interdisciplinary research perspectives and applications have come up as a helping hand to meet out the needs in different paradigm of Assessment and Biomedicine. At this juncture, building assessment tools for people with motor coordinate impairment is a valuable yet novel research challenge. So, authors implement a handwritten digit recognition system using optical character recognition (OCR) on dataset of CP people's handwritten digits and based on study the problem statement is defined to detect variation in jerking hands on written to optical digits by proposing a custom convolutional neural network (CNN) architecture on the augmented dataset (CP handwritten data). The proposed research will look into a variety of design preferences for CNN-based handwritten digit recognition, including kernel size, layer count, stride size, and dilation. In addition, it evaluated the confusion matrix for maximum number prediction using various optimization algorithms. The extensive trials were conducted and obtained 85% accuracy for the CP dataset and 97% for the MNIST dataset.
C1 [Muthureka, K.; Reddy, U. Srinivasulu] Natl Inst Technol, Dept Comp Applicat, Machine Learning & Data Analyt Lab, Tiruchirappalli, India.
   [Muthureka, K.; Reddy, U. Srinivasulu] Natl Inst Technol, Ctr Excellence CoE Artificial Intelligence, Dept Comp Applicat, Tiruchirappalli, India.
   [Janet, B.] Natl Inst Technol, Dept Comp Applicat, Informat Proc Lab, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli; National
   Institute of Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Reddy, US (corresponding author), Natl Inst Technol, Dept Comp Applicat, Machine Learning & Data Analyt Lab, Tiruchirappalli, India.; Reddy, US (corresponding author), Natl Inst Technol, Ctr Excellence CoE Artificial Intelligence, Dept Comp Applicat, Tiruchirappalli, India.
EM usreddy@nitt.edu
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Ahmadi MN, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143976
   Alwadkar S., 2021, CHILDREN, V1, P3
   [Anonymous], 2016, 24 C COMP GRAPH VIS
   Arnould C, 2014, FRONT NEUROL, V5, DOI 10.3389/fneur.2014.00048
   Azzam A. M., 2018, IOSR Journal of Nursing and Health Science (IOSR-JNHS), V7, P84
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P3011, DOI 10.1007/s00521-020-05137-6
   Baldominos A, 2018, NEUROCOMPUTING, V283, P38, DOI 10.1016/j.neucom.2017.12.049
   Bonyani M, 2021, INT J DOC ANAL RECOG, V24, P133, DOI 10.1007/s10032-021-00368-2
   Bora MB, 2020, PROCEDIA COMPUT SCI, V167, P2403, DOI 10.1016/j.procs.2020.03.293
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Carbune V, 2020, INT J DOC ANAL RECOG, V23, P89, DOI 10.1007/s10032-020-00350-4
   Chen S, 2018, P INT C IND ENG OPER, P274
   Chen SW, 2021, PROCEDIA COMPUT SCI, V192, P4416, DOI 10.1016/j.procs.2021.09.218
   Chooi SL., 2011, PROGR ENG APPL TECHN, V2, P593
   Cui H, 2019, PATTERN RECOGN LETT, V125, P828, DOI 10.1016/j.patrec.2019.02.009
   Dong-yuan Ge, 2019, 2019 12th International Conference on Intelligent Computation Technology and Automation (ICICTA), P658, DOI 10.1109/ICICTA49267.2019.00145
   Donica DK, 2013, J OCC THER SCH EARLY, V6, P81, DOI 10.1080/19411243.2013.810938
   dos Santos MM, 2019, NEUROCOMPUTING, V329, P359, DOI 10.1016/j.neucom.2018.10.063
   Duran I, 2022, DEV MED CHILD NEUROL, V64, P228, DOI 10.1111/dmcn.15010
   Garg A, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P602, DOI [10.1109/spin.2019.8711703, 10.1109/SPIN.2019.8711703]
   Gunawan T.S., 2018, INDONES J ELECT ENG, V10, P562, DOI [10.11591/ijeecs.v10.i2.pp562-568, DOI 10.11591/IJEECS.V10.I2.PP562-568]
   Gupta S., 2018, INT J SCI RES IJSR, V7, P1402
   Hamdan Y.B., 2021, J. Inf. Technol. Digit. World, V3, P92, DOI [10.36548/jitdw.2021.2.003, DOI 10.36548/JITDW.2021.2.003]
   Husnain M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132758
   Joseph SE., 2019, INT J MED PHARM SCI, V9, P27
   Kandel I, 2020, ICT EXPRESS, V6, P312
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan H. A., 2017, J INTELL LEARN SYST, V09, P21, DOI [10.4236/jilsa.2017.92003, DOI 10.4236/JILSA.2017.92003]
   Kim HY, 2016, J PHYS THER SCI, V28, P347, DOI 10.1589/jpts.28.347
   Kulkarni SR, 2018, NEURAL NETWORKS, V103, P118, DOI 10.1016/j.neunet.2018.03.019
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Malek SA, 2022, EUR J PAEDIATR NEURO, V36, P19, DOI 10.1016/j.ejpn.2021.11.005
   Mor S.S., 2019, Int. J. Eng. Adv. Technol, V8, P172
   Mustapha Aatila, 2021, Journal of Physics: Conference Series, V1743, DOI 10.1088/1742-6596/1743/1/012002
   Proctor K., 2020, SPEECH THERAPY CEREB
   Rahman Mahbubar, 2015, International Journal of Image, Graphics and Signal Processing, V7, P42, DOI 10.5815/ijigsp.2015.08.05
   Ramadhan HH., 2022, J OPTOELECTRON LASER, V41, P724
   Sabour S, 2017, ADV NEUR IN, V30
   Saqib N, 2022, ALGORITHMS, V15, DOI 10.3390/a15040129
   Serpa-Andrade L., 2017, INT C APPL HUM FACT, DOI [10.1007/978-3-319-60483-1_58, DOI 10.1007/978-3-319-60483-1_58]
   Tiwari P, 2018, COGN SYST RES, V52, P1036, DOI 10.1016/j.cogsys.2018.08.022
   Trost SG, 2016, MED SCI SPORT EXER, V48, P958, DOI 10.1249/MSS.0000000000000842
   Valova Iren, 2020, Procedia Computer Science, V176, P660, DOI 10.1016/j.procs.2020.09.038
   van Hoorn JF, 2010, DEV MED CHILD NEUROL, V52, P941, DOI 10.1111/j.1469-8749.2010.03715.x
   Zhang J, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00715
   Zhang YX, 2019, COMPUT BIOL MED, V106, P33, DOI 10.1016/j.compbiomed.2019.01.009
NR 47
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 23
DI 10.1007/s13735-023-00291-8
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O6LG9
UT WOS:001044894800002
DA 2024-07-18
ER

PT J
AU Sahoo, C
   Wankhade, M
   Singh, BK
AF Sahoo, Chinmayee
   Wankhade, Mayur
   Singh, Binod Kumar
TI Sentiment analysis using deep learning techniques: a comprehensive
   review
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Sentiment analysis; Opinion analysis; Social media; Machine learning
ID NEURAL-NETWORK; CLASSIFICATION; MODEL; EXTRACTION; REPRESENTATION;
   CONTEXT; TRENDS; LSTM
AB With the exponential growth of social media platforms and online communication, the necessity of using automated sentiment analysis techniques has significantly increased. Deep learning techniques have emerged in extracting complex patterns and features from unstructured text data, which makes them a powerful tool for sentiment analysis. This research article presents a comprehensive review of sentiment analysis using deep learning techniques. We discuss various aspects of sentiment analysis, including data preprocessing, feature extraction, model architectures, and evaluation metrics. We explore the use of recurrent neural networks (RNNs), convolutional neural networks (CNNs), and transformer models in sentiment analysis tasks. We examine the utilization of RNNs, incorporating long short-term memory (LSTM) and gated recurrent unit (GRU), to model sequential dependencies in text data. Furthermore, we discuss the recent advancements in sentiment analysis achieved through a transformer. The findings from this review can facilitate the development of more accurate and efficient sentiment analysis models, enabling organizations to gain valuable insights from large volumes of textual data in several domains, such as social media, market analysis, and customer reviews.
C1 [Sahoo, Chinmayee; Singh, Binod Kumar] Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
   [Wankhade, Mayur] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Wankhade, M (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM 2021rscs001@nitjsr.ac.in; mayur.18dr0078@cse.iitism.ac.in;
   bksingh.cse@nitjsr.ac.in
RI Singh, Binod/AAB-8663-2019; Sahoo, Chinmayee/GYR-0682-2022; sahoo,
   chinmayee/IAN-4920-2023
OI Singh, Binod/0000-0002-2697-8918; Sahoo, Chinmayee/0000-0002-0557-3161; 
CR Abdi A, 2019, INFORM PROCESS MANAG, V56, P1245, DOI 10.1016/j.ipm.2019.02.018
   Acheampong FA, 2021, ARTIF INTELL REV, V54, P5789, DOI 10.1007/s10462-021-09958-2
   Agarwal Ayush, 2019, 2019 4th International Conference on Big Data, Cloud Computing, Data Science & Engineering (BCD), P19, DOI 10.1109/BCD.2019.8885108
   Ahanin Z, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151612539
   Ahmed AA, 2022, INT J SYST ASSUR ENG, V13, P699, DOI 10.1007/s13198-021-01594-x
   Ahmed K., 2023, J King Saud Univ Comput Inf Sci, V35
   Akhtyamova L, 2017, LECT NOTES COMPUT SC, V10260, P247, DOI 10.1007/978-3-319-59569-6_29
   Alatrash R., 2021, InProgress in Advanced Computing and Intelligent Engineeringpp, P123, DOI [10.1007/978-981-33-4299-6_10, DOI 10.1007/978-981-33-4299-6]
   AlBadani B, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031316
   Ameer I, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118534
   An H-w, 2022, J Ambient Intell Humaniz Comput, P1
   Ananthajothi K, 2022, DATA KNOWL ENG, V142, DOI 10.1016/j.datak.2022.102092
   [Anonymous], 2014, Yelp! Dataset
   [Anonymous], 2018, Advances in hybridization of intelligent methods: models, systems and applications
   [Anonymous], 2010, Proceedings of the NIPS-2010 Deep Learning and Unsupervised Feature Learning Workshop, DOI DOI 10.1007/978-3-540-87479-9
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Babu Nirmal Varghese, 2022, SN Comput Sci, V3, P74, DOI 10.1007/s42979-021-00958-1
   Baliyan Anupam, 2021, Proceedings of the 2021 8th International Conference on Computing for Sustainable Global Development (INDIACom), P710, DOI 10.1109/INDIACom51348.2021.00126
   Bartusiak R, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P53, DOI 10.1109/ENIC.2015.16
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Basiri ME, 2020, KNOWL-BASED SYST, V198, DOI 10.1016/j.knosys.2020.105949
   Batrinca B, 2015, AI SOC, V30, P89, DOI 10.1007/s00146-014-0549-4
   Behera RK, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102435
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Brasoveanu AMP, 2020, IEEE INT CONF INF VI, P270, DOI 10.1109/IV51561.2020.00051
   Brennan JR, 2020, NEUROPSYCHOLOGIA, V146, DOI 10.1016/j.neuropsychologia.2020.107479
   Brown J.S., 2000, Change, V32, P10, DOI [10.1080/00091380009601719, DOI 10.1080/00091380009601719]
   Cao Y, 2015, Int J Adv Comput Sci Appl, V6
   Chandra Y, 2020, 2020 7 INT C COMPUTI, P1
   Chandrasekaran G, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1415
   Chen FH, 2018, IEEE T MULTIMEDIA, V20, P997, DOI 10.1109/TMM.2017.2757769
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Chen XY, 2017, IEEE IMAGE PROC, P1557, DOI 10.1109/ICIP.2017.8296543
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Choudhary C, 2023, EXPERT SYST APPL, V216, DOI 10.1016/j.eswa.2022.119420
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Chunping O., 2014, Int J Multimed Ubiquitous Eng, V9, P385, DOI DOI 10.14257/IJMUE.2014.9.11.37
   Dashtipour K, 2021, NEUROCOMPUTING, V457, P377, DOI 10.1016/j.neucom.2021.02.020
   Day MY, 2017, 2017 IEEE 18TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI 2017), P382, DOI 10.1109/IRI.2017.79
   Desai Z, 2021, 2021 12 INT C COMP C, P1
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Dong X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2524
   Dragoni M, 2017, IEEE T AFFECT COMPUT, V8, P457, DOI 10.1109/TAFFC.2017.2717879
   Edara Deepak Chowdary, 2023, Journal of Ambient Intelligence and Humanized Computing, P5309, DOI 10.1007/s12652-019-01399-8
   Egger J, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106874
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Etaiwi W, 2021, INFORM-INT J COMPUT, V45, P89, DOI 10.31449/inf.v45i7.3674
   Ezaldeen H, 2022, J WEB SEMANT, V72, DOI 10.1016/j.websem.2021.100700
   Sánchez-Rada JF, 2019, INFORM FUSION, V52, P344, DOI 10.1016/j.inffus.2019.05.003
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Go Alec., 2009, CS224N project report 1.12
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Gou Z, 2023, Comput Intell Neurosci, V2023
   Goularas Dionysis, 2019, 2019 International Conference on Deep Learning and Machine Learning in Emerging Applications (Deep-ML). Proceedings, P12, DOI 10.1109/Deep-ML.2019.00011
   Gui L, 2017, KNOWL-BASED SYST, V124, P34, DOI 10.1016/j.knosys.2017.02.030
   Gunasekar M, 2023, INF TECHNOL CONTROL, V52, P100, DOI 10.5755/j01.itc.52.1.32119
   Habbat N, 2022, LECT NOTE DATA ENG, V110, P228, DOI 10.1007/978-3-030-94188-8_22
   Hao Wu, 2021, Intelligent Computing Theories and Application: 17th International Conference, ICIC 2021, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12836), P393, DOI 10.1007/978-3-030-84522-3_32
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Hatzivassiloglou Vasileios., 2000, COLING 2000
   Heerschop B., 2011, 11 DUTCH BELG INF RE, P38
   Huang B, 2022, KNOWL-BASED SYST, V243, DOI 10.1016/j.knosys.2022.108473
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huang Kaixin, 2023, 2023 International Conference on Networking, Informatics and Computing (ICNETIC), P194, DOI 10.1109/ICNETIC59568.2023.00047
   Huang QX, 2017, 2017 INTERNATIONAL CONFERENCE ON GREEN INFORMATICS (ICGI), P30, DOI 10.1109/ICGI.2017.45
   Huang YH, 2018, IFIP ADV INF COMM TE, V519, P143, DOI 10.1007/978-3-319-92007-8_13
   Irsoy O, 2014, ADV NEUR IN, V27
   Ramírez-Tinoco FJ, 2019, STUD COMPUT INTELL, V815, P189, DOI 10.1007/978-3-030-06149-4_8
   Jin ZG, 2020, NEURAL COMPUT APPL, V32, P9713, DOI 10.1007/s00521-019-04504-2
   Jing N, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115019
   Joseph J, 2022, MATER TODAY-PROC, V58, P456, DOI 10.1016/j.matpr.2022.02.483
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kalyan K.S., 2021, arXiv
   Kanan T, 2023, CLUSTER COMPUT, V26, P1285, DOI 10.1007/s10586-022-03626-y
   Kanmani S, 2023, Comput Syst Sci Eng, V45
   Karn AL, 2023, ELECTRON COMMER RES, V23, P279, DOI 10.1007/s10660-022-09630-z
   Kasmuri E., 2017, International Journal of Advances in SOft Computing Its Applications, V9, P132
   Kasri M., 2019, Proceedings of the 4th International Conference on Big Data and Internet of Things, P1, DOI DOI 10.1145/3372938.3372998
   Kaur G, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-022-00680-6
   Kaur R., 2022, Research Anthology on Implementing Sentiment Analysis Across Multiple Disciplines, V10, P1846, DOI DOI 10.4018/IJSSMET.2019040103
   Kim Y, 2014, Arxiv, DOI arXiv:1408.5882
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Kokab ST, 2022, ARRAY-NY, V14, DOI 10.1016/j.array.2022.100157
   Kyaw K.S., 2023, Asia Soc. Issues, V16, pe252965, DOI [10.48048/asi.2023.252965, DOI 10.48048/ASI.2023.252965]
   Lapponi E, 2012, INT CONF DAT MIN WOR, P687, DOI 10.1109/ICDMW.2012.23
   Lee G, 2018, KNOWL-BASED SYST, V152, P70, DOI 10.1016/j.knosys.2018.04.006
   Lee SI, 2018, LECT NOTES ELECTR EN, V461, P260, DOI 10.1007/978-981-10-6520-0_28
   Li KP, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116600
   Li XY, 2023, ENTERP INF SYST-UK, V17, DOI 10.1080/17517575.2022.2037160
   Li XL, 2020, IEEE ACCESS, V8, P46868, DOI 10.1109/ACCESS.2020.2978511
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Liu B., 2012, SYNTHESIS LECT HUMAN, V5, P1, DOI [DOI 10.1007/978-3-031-02145-9, 10.2200/S00416ED1V01Y201204HLT016, DOI 10.2200/S00416ED1V01Y201204HLT016]
   Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Long F, 2019, IEEE ACCESS, V7, P141960, DOI 10.1109/ACCESS.2019.2942614
   Luo YF, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102615
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Magdy Safaa, 2022, Computer Networks, V206, DOI 10.1016/j.comnet.2022.108826
   Majumder N, 2022, Neural Comput Appl, P1
   Mann S, 2023, LECT NOTES ELECTR EN, V959, P263, DOI 10.1007/978-981-19-6581-4_21
   Mao YY, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11121906
   Meng JN, 2019, INFORMATION, V10, DOI 10.3390/info10050162
   Micu A, 2017, PSYCHOL MARKET, V34, P1094, DOI 10.1002/mar.21049
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mishev K, 2020, IEEE ACCESS, V8, P131662, DOI 10.1109/ACCESS.2020.3009626
   Mohantya MD, 2022, Adv Data Min Tools Methods Soc Comput, V85
   Monika R, 2019, INT CONF ADV COMPU, P92, DOI [10.1109/IACC48062.2019.8971592, 10.1109/iacc48062.2019.8971592]
   Mukherjee P, 2021, PROCEDIA COMPUT SCI, V185, P370, DOI 10.1016/j.procs.2021.05.038
   Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6
   Neidhardt J, 2017, INF TECHNOL TOUR, V17, P101, DOI 10.1007/s40558-017-0079-2
   Oswald C, 2022, ACM T WEB, V16, DOI 10.1145/3538491
   Parvin S. Ashika, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P781, DOI 10.1109/ICOEI51242.2021.9453026
   Pavaloaia VD, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11164459
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Polignano M, 2019, ADJUNCT PUBLICATION OF THE 27TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (ACM UMAP '19 ADJUNCT), P63, DOI 10.1145/3314183.3324983
   Pontiki M., 2014, P 8 INT WORKSH SEM E, P27, DOI 10.3115/v1/S14-2004
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Prabakaran R., 2023, 2023 5th International Conference on Smart Systems and Inventive Technology (ICSSIT), P1445, DOI 10.1109/ICSSIT55814.2023.10060889
   Prabha MIO, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741438
   Qader W., 2019, An overview of bag of words;importance, implementation, applications, and challenges, P200, DOI [DOI 10.1109/IEC47844.2019.8950616.32, 10.1109/IEC47844.2019.8950616, DOI 10.1109/IEC47844.2019.8950616]
   Qaiser S., 2018, International Journal of Computer Applications, V181, P25, DOI [10.5120/ijca2018917395, DOI 10.5120/IJCA2018917395]
   Qian J, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P31, DOI 10.1145/3195106.3195111
   Qian Q, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1365
   Raffel C, 2020, J MACH LEARN RES, V21
   Rambocas M., 2018, Journal of Research in Interactive Marketing
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Rhanoui M, 2019, MACH LEARN KNOW EXTR, V1, P832, DOI 10.3390/make1030048
   Rodrigues AP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5211949
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rojas-Barahona LM, 2016, LANG LINGUIST COMPAS, V10, P701, DOI 10.1111/lnc3.12228
   Romero R, 2022, KNOWL-BASED SYST, V257, DOI 10.1016/j.knosys.2022.109914
   Sachin S., 2020, SN Comput. Sci, DOI [10.1007/s42979-020-0076-y, DOI 10.1007/S42979-020-0076-Y]
   Sadr H, 2019, NEURAL PROCESS LETT, V50, P2745, DOI 10.1007/s11063-019-10049-1
   Salim SS, 2020, 2020 INT C EM TECHN, P1
   Schuller B, 2015, WIRES DATA MIN KNOWL, V5, P255, DOI 10.1002/widm.1159
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Serrano-Guerrero J, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106768
   Shayaa S, 2018, IEEE ACCESS, V6, P37807, DOI 10.1109/ACCESS.2018.2851311
   Shi SM, 2017, INT CONF ASIAN LANG, P379, DOI 10.1109/IALP.2017.8300622
   Shilpa BL, 2023, KYBERNETES, V52, P748, DOI 10.1108/K-06-2021-0457
   Shuteng Niu, 2020, IEEE Transactions on Artificial Intelligence, V1, P151, DOI 10.1109/TAI.2021.3054609
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Socher R., 2011, P C EMP METH NAT LAN, P151
   Socher Richard, 2012, P 2012 JOINT C EMPIR, DOI [10.5555/2390948.2391084, DOI 10.1162/153244303322533223]
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Stalin Jacob W., 2022, Int. J. Intell. Netw., V3, P9
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Taj S, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673428
   Tan KL, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063915
   Tan KL, 2022, IEEE ACCESS, V10, P21517, DOI 10.1109/ACCESS.2022.3152828
   Tang DY, 2016, Arxiv, DOI arXiv:1605.08900
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Tao J, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-019-0278-0
   Tida S., 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.03480
   Tiwari D, 2022, NEW GENERAT COMPUT, V40, P1165, DOI 10.1007/s00354-022-00182-2
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   Umer M, 2023, MULTIMED TOOLS APPL, V82, P5569, DOI 10.1007/s11042-022-13459-x
   Uysal AK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P23, DOI 10.1109/CIT.2017.53
   Vaswani A, 2017, ADV NEUR IN, V30
   Venugopalan M, 2015, INT CONF CONTEMP, P241, DOI 10.1109/IC3.2015.7346686
   Vohra A, 2022, J Intell Inf Syst, P1
   Wallace B., 2015, ARXIV
   Wang J, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107663
   Wang XB, 2017, COMM COM INF SC, V774, P206, DOI 10.1007/978-981-10-6805-8_17
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wankhade Mayur, 2022, 2022 2nd Asian Conference on Innovation in Technology (ASIANCON), P1, DOI 10.1109/ASIANCON55314.2022.9908909
   Wankhade M, 2022, J Supercomput, P1
   Wankhade M, 2023, J SUPERCOMPUT, V79, P11452, DOI 10.1007/s11227-023-05112-7
   Wankhade M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21604-7
   Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1
   Wu D, 2017, IEEE INT CONF COMMUN, P1, DOI 10.1109/ACCESS.2016.2647384
   Wu HC, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361686
   Wu ST, 2022, CONNECT SCI, V34, P44, DOI 10.1080/09540091.2021.1940101
   Xiong SF, 2018, NEUROCOMPUTING, V275, P2459, DOI 10.1016/j.neucom.2017.11.023
   Xu H, 2019, Arxiv, DOI arXiv:1904.02232
   Xu YC, 2019, IEEE INT CONF BIG DA, P5573, DOI 10.1109/BigData47090.2019.9006342
   Xue Wei, 2017, P 8 INT JOINT C NATU, P151
   Yadav A, 2020, MULTIMEDIA SYST, V26, P431, DOI 10.1007/s00530-020-00656-7
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yasir M, 2023, J ENTERP INF MANAG, V36, P718, DOI 10.1108/JEIM-02-2020-0077
   Ye XX, 2021, IEEE ACCESS, V9, P94748, DOI 10.1109/ACCESS.2021.3094026
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu JF, 2019, IEEE-ACM T AUDIO SPE, V27, P168, DOI 10.1109/TASLP.2018.2875170
   Yun Liu, 2019, 2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media). Proceedings, P30, DOI 10.1109/Ubi-Media.2019.00015
   Zhang BW, 2018, IEEE ACCESS, V6, P58284, DOI 10.1109/ACCESS.2018.2874623
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang W, 2022, IEEE Trans. Knowl. Data Eng.
   Zhang YZ, 2021, NEURAL NETWORKS, V133, P40, DOI 10.1016/j.neunet.2020.10.001
   Zhao J, 2016, COMPUT LINGUIST, V42, P595, DOI 10.1162/COLI_r_00259
   Zhao W, 2018, IEEE T KNOWL DATA EN, V30, P185, DOI 10.1109/TKDE.2017.2756658
   Zhao YL, 2023, APPL SOFT COMPUT, V133, DOI 10.1016/j.asoc.2022.109921
   Zhou K, 2018, FUTURE GENER COMP SY, V86, P362, DOI 10.1016/j.future.2018.03.047
   Zhou YJ, 2022, KNOWL-BASED SYST, V257, DOI 10.1016/j.knosys.2022.109948
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 202
TC 3
Z9 4
U1 52
U2 68
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 41
DI 10.1007/s13735-023-00308-2
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y4PO5
UT WOS:001105099600001
DA 2024-07-18
ER

PT J
AU Melchiorre, AB
   Penz, D
   Ganhör, C
   Lesota, O
   Fragoso, V
   Fritzl, F
   Parada-Cabaleiro, E
   Schubert, F
   Schedl, M
AF Melchiorre, Alessandro B.
   Penz, David
   Ganhoer, Christian
   Lesota, Oleg
   Fragoso, Vasco
   Fritzl, Florian
   Parada-Cabaleiro, Emilia
   Schubert, Franz
   Schedl, Markus
TI Emotion-aware music tower blocks (EmoMTB ): an intelligent audiovisual
   interface for music discovery and recommendation
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Intelligent user interface; Music discovery and exploration; Affective
   computing; Emotion recognition; Clustering; Recommender system
AB Music listening has experienced a sharp increase during the last decade thanks to music streaming and recommendation services. While they offer text-based search functionality and provide recommendation lists of remarkable utility, their typical mode of interaction is unidimensional, i.e., they provide lists of consecutive tracks, which are commonly inspected in sequential order by the user. The user experience with such systems is heavily affected by cognition biases (e.g., position bias, human tendency to pay more attention to first positions of ordered lists) as well as algorithmic biases (e.g., popularity bias, the tendency of recommender systems to overrepresent popular items). This may cause dissatisfaction among the users by disabling them to find novel music to enjoy. In light of such systems and biases, we propose an intelligent audiovisual music exploration system named EmoMTB . It allows the user to browse the entirety of a given collection in a free nonlinear fashion. The navigation is assisted by a set of personalized emotion-aware recommendations, which serve as starting points for the exploration experience. EmoMTB adopts the metaphor of a city, in which each track (visualized as a colored cube) represents one floor of a building. Highly similar tracks are located in the same building; moderately similar ones form neighborhoods that mostly correspond to genres. Tracks situated between distinct neighborhoods create a gradual transition between genres. Users can navigate this music city using their smartphones as control devices. They can explore districts of well-known music or decide to leave their comfort zone. In addition, EmoMTB integrates an emotion-aware music recommendation system that re-ranks the list of suggested starting points for exploration according to the user's self-identified emotion or the collective emotion expressed in EmoMTB 's Twitter channel. Evaluation of EmoMTB has been carried out in a threefold way: by quantifying the homogeneity of the clustering underlying the construction of the city, by measuring the accuracy of the emotion predictor, and by carrying out a web-based survey composed of open questions to obtain qualitative feedback from users.
C1 [Melchiorre, Alessandro B.; Penz, David; Ganhoer, Christian; Lesota, Oleg; Fragoso, Vasco; Parada-Cabaleiro, Emilia; Schedl, Markus] Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.
   [Melchiorre, Alessandro B.; Lesota, Oleg; Parada-Cabaleiro, Emilia; Schedl, Markus] Linz Inst Technol, Human Ctr Artificial Intelligence, Linz, Austria.
   [Penz, David] TU Wien, Vienna, Austria.
   [Fritzl, Florian] Salzburg Univ Appl Sci, Salzburg, Austria.
   [Schubert, Franz] Univ Appl Arts Vienna, Vienna, Austria.
   [Schubert, Franz] St Polten UAS, St Polten, Austria.
C3 Johannes Kepler University Linz; Technische Universitat Wien
RP Schedl, M (corresponding author), Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.; Schedl, M (corresponding author), Linz Inst Technol, Human Ctr Artificial Intelligence, Linz, Austria.
EM markus.schedl@jku.at
RI Melchiorre, Alessandro B/JDW-7205-2023
OI Melchiorre, Alessandro Benedetto/0000-0003-1643-1166; Parada-Cabaleiro,
   Emilia/0000-0003-1843-3632; Lesota, Oleg/0000-0002-8321-6565; Schubert,
   Franz/0000-0001-8997-1652
FU State of Upper Austria; Federal Ministry of Education, Science, and
   Research [LIT-ARS-2020-015]; Austrian Science Fund (FWF) [P33526,
   P36413]; Austrian Science Fund (FWF) [P33526] Funding Source: Austrian
   Science Fund (FWF)
FX EmoMTB received financial support by the State of Upper Austria and the
   Federal Ministry of Education, Science, and Research, through grant
   LIT-ARS-2020-015, and by the Austrian Science Fund (FWF): P33526 and
   P36413. We further thank Peter Knees and Michael Mayr for their help
   with the first version of the interface. Open access funding provided by
   Austrian Science Fund (FWF).
CR Abdollahpouri H, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P529, DOI 10.1145/3306618.3314309
   Acheampong FA, 2020, ENG REP, V2, DOI 10.1002/eng2.12189
   Andjelkovic I, 2019, INT J HUM-COMPUT ST, V121, P142, DOI 10.1016/j.ijhcs.2018.04.004
   [Anonymous], 2017, Computer Science & Information Technology (CS & IT), DOI DOI 10.5121/CSIT.2017.70603
   Assuncao WG, 2022, MULTIMED TOOLS APPL, V81, P8367, DOI 10.1007/s11042-022-12110-z
   Ayata D, 2018, IEEE T CONSUM ELECTR, V64, P196, DOI 10.1109/TCE.2018.2844736
   Azzopardi L, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P27, DOI 10.1145/3406522.3446023
   Bradley M.M., 1999, C1 U FLOR CTR RES PS
   Deng SG, 2015, EXPERT SYST APPL, V42, P9284, DOI 10.1016/j.eswa.2015.08.029
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Ekman P., 2000, Handbook of cognition and emotion pp, P45, DOI 10.1002/0470013494.ch3
   Ghazi D, 2015, LECT NOTES COMPUT SC, V9042, P152, DOI 10.1007/978-3-319-18117-2_12
   Gómez-Cañón JS, 2021, IEEE SIGNAL PROC MAG, V38, P106, DOI 10.1109/MSP.2021.3106232
   Hamasaki M, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P523, DOI 10.1145/2567948.2576944
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Holm J, 2009, J NEW MUSIC RES, V38, P87, DOI 10.1080/09298210902940094
   Hu X., 2010, ISMIR, P619
   Hung H., 2021, PROC 22 INT SOC MUSI, P318
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Joachims T, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P781, DOI 10.1145/3018661.3018699
   Kaggle, 2022, EM DAT FOR NLP
   Kaminskas M, 2013, LOCATION AWARE MUSIC, DOI [10.1145/2507157.2507180, DOI 10.1145/2507157.2507180]
   Knees P, 2007, IEEE MULTIMEDIA, V14, P46, DOI 10.1109/MMUL.2007.48
   Knees Peter, 2019, ISMIR, P44
   Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4
   Lamere P, 2008, J NEW MUSIC RES, V37, P101, DOI 10.1080/09298210802479284
   Laurier C., 2009, ISMIR, P381
   Lesota O, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P601, DOI 10.1145/3460231.3478843
   Li, 2017, P 8 INT JOINT C NAT, V1, P986
   Liang Y, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P175, DOI 10.1145/3397481.3450700
   Liu GJ, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P2331, DOI [10.1109/ITNEC48623.2020.9084846, 10.1109/itnec48623.2020.9084846]
   Melchiorre AB, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102666
   Mohammad S.M., 2017, P 6 JOINT C LEXICAL
   Mohammad Saif., 2012, Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, SemEval'12, P246
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Panda R., 2018, ISMIR, P383
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Panda RES, 2013, 10 INT S COMP MUS MU, P570
   Pandey R, 2020, IEEE J PHOTOVOLT, V10, P1918, DOI 10.1109/JPHOTOV.2020.3017741
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schedl Markus, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P388, DOI 10.1145/3372278.3391928
   Schedl M, 2022, P 7 ACM SIGIR C HUM
   Schedl M, 2011, P 1 INT C MULTIMEDIA, P8
   Schmitt M, 2017, J MACH LEARN RES, V18
   Schuff J., 2017, P 8 WORKSHOP COMPUTA, P13
   Shen JY, 2020, VIS INFORM, V4, P99, DOI 10.1016/j.visinf.2020.04.003
   Shmueli B, 2019, Arxiv, DOI arXiv:1909.07734
   Shukla Stuti, 2017, 2017 International Conference on Infocom Technologies and Unmanned Systems (Trends and Future Directions) (ICTUS), P777, DOI 10.1109/ICTUS.2017.8286111
   Stober Sebastian, 2010, P 7 SOUND MUS COMP C
   Strapparava C., 2007, P 4 INT WORKSH SEM E, P70
   Vad Beatrix, 2015, Design and evaluation of a probabilistic music projection interface
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu B., 2013, P SIAM C DATA MINING, P279
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 56
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 13
DI 10.1007/s13735-023-00275-8
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I0PH8
UT WOS:000999876700001
PM 37274943
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Meng, LT
   Zhang, FF
   Zhang, X
   Xu, CS
AF Meng, Lingtao
   Zhang, Feifei
   Zhang, Xi
   Xu, Changsheng
TI Prototype local-global alignment network for image-text retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image-text retrieval; Local alignment; Global alignment; Prototype
AB Image-text retrieval is a challenging task due to the requirement of thorough multimodal understanding and precise inter-modality relationship discovery. However, most previous approaches resort to doing global image-text alignment and neglect fine-grained correspondence. Although some works explore local region-word alignment, they usually suffer from a heavy computing burden. In this paper, we propose a prototype local-global alignment (PLGA) network for image-text retrieval by jointly performing the fine-grained local alignment and high-level global alignment. Specifically, our PLGA contains two key components: a prototype-based local alignment module and a multi-scale global alignment module. The former enables efficient fine-grained local matching by combining region-prototype alignment and word-prototype alignment, and the latter helps perceive hierarchical global semantics by exploring multi-scale global correlations between the image and text. Overall, the local and global alignment modules can boost their performances for each other via the unified model. Quantitative and qualitative experimental results on Flickr30K and MS-COCO benchmarks demonstrate that our proposed approach performs favorably against state-of-the-art methods.
C1 [Meng, Lingtao; Zhang, Feifei] Tianjin Univ Technol, Sch Comp Sci & Engn, Binshui West St, Tianjin 300380, Tianjin, Peoples R China.
   [Zhang, Xi; Xu, Changsheng] Chinese Acad Sci, Inst Automat, East Zhongguancun Rd, Beijing 100080, Peoples R China.
C3 Tianjin University of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS
RP Zhang, FF (corresponding author), Tianjin Univ Technol, Sch Comp Sci & Engn, Binshui West St, Tianjin 300380, Tianjin, Peoples R China.
EM mlt18615213172@stud.tjut.edu.cn; feifeizhang1231@gmail.com;
   zhangxi2019@ia.ac.cn; csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023; Zhang, Feifei/A-3199-2015; Zhang, Xi
   Sheryl/AAI-1066-2019
FU National Key Research and Development Program of China [2018AAA0102200];
   National Natural Science Foundation of China [62036012, 61720106006,
   62002355, 61721004, 61832002, 62072455, 62102415, 62106262, U1836220];
   Beijing Natural Science Foundation [L201001]
FX This work was supported by National Key Research and Development Program
   of China (No. 2018AAA0102200), National Natural Science Foundation of
   China (Nos. 62036012, 61720106006, 62002355, 61721004, 61832002,
   62072455, 62102415, 62106262 and U1836220), Beijing Natural Science
   Foundation (L201001).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Chen JC, 2021, PROC CVPR IEEE, P15784, DOI 10.1109/CVPR46437.2021.01553
   Chen TL, 2020, AAAI CONF ARTIF INTE, V34, P10583
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diao HW, 2021, AAAI CONF ARTIF INTE, V35, P1218
   Faghri Fartash, 2017, arXiv
   Ge Y., 2020, P NIPS, V33, P11309
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P18, DOI 10.1007/978-3-030-58586-0_2
   He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652
   Hu P, 2021, PROC CVPR IEEE, P5399, DOI 10.1109/CVPR46437.2021.00536
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Huang Y, 2017, PROC CVPR IEEE, P7254, DOI 10.1109/CVPR.2017.767
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Ji Z, 2019, IEEE I CONF COMP VIS, P5753, DOI 10.1109/ICCV.2019.00585
   Jocher G., 2021, YOLOV5
   Karpathy A., 2014, ARXIV
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Klein Benjamin, 2014, ARXIV14117399
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li J, 2020, ARXIV
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C., 2020, P IEEE CVF C COMP VI, P10921, DOI DOI 10.1109/CVPR42600.2020.01093
   Liu Y, 2017, IEEE I CONF COMP VIS, P4127, DOI 10.1109/ICCV.2017.442
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Niu ZX, 2017, IEEE I CONF COMP VIS, P1899, DOI 10.1109/ICCV.2017.208
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salvador A, 2021, PROC CVPR IEEE, P15470, DOI 10.1109/CVPR46437.2021.01522
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Snell J, 2017, ARXIV
   Toyama J, 2016, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang SJ, 2020, IEEE WINT CONF APPL, P1497, DOI 10.1109/WACV45572.2020.9093614
   Wang XD, 2021, PROC CVPR IEEE, P12581, DOI 10.1109/CVPR46437.2021.01240
   Wehrmann P, 2020, AAAI CONF ARTIF INTE, V34, P12313
   Xi Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10938, DOI 10.1109/CVPR42600.2020.01095
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zhang X, 2021, PROC CVPR IEEE, P3435, DOI 10.1109/CVPR46437.2021.00344
   Zhe Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P402, DOI 10.1007/978-3-030-58610-2_24
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
NR 49
TC 2
Z9 2
U1 5
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 525
EP 538
DI 10.1007/s13735-022-00258-1
EA OCT 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000864588700002
DA 2024-07-18
ER

PT J
AU He, K
   Pu, N
   Lao, MR
   Lew, MS
AF He, Kai
   Pu, Nan
   Lao, Mingrui
   Lew, Michael S. S.
TI Few-shot and meta-learning methods for image understanding: a survey
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few-shot learning; Meta-learning; Image classification; Deep neural
   networks
AB State-of-the-art deep learning systems (e.g., ImageNet image classification) typically require very large training sets to achieve high accuracies. Therefore, one of the grand challenges is called few-shot learning where only a few training samples are required for good performance. In this survey, we illuminate one of the key paradigms in few-shot learning called meta-learning. These meta-learning methods, by simulating the tasks which will be presented at inference through episodic training, can effectively employ previous prior knowledge to guide the learning of new tasks. In this paper, we provide a comprehensive overview and key insights into the meta-learning approaches and categorize them into three branches according to their technical characteristics, namely metric-based, model-based and optimization-based meta-learning. Due to the major importance of the evaluation process, we also present an overview of current widely used benchmarks, as well as performances of recent meta-learning methods on these datasets. Based on over 200 papers in this survey, we conclude with the major challenges and future directions of few-shot learning and meta-learning.
C1 [He, Kai; Lao, Mingrui; Lew, Michael S. S.] Leiden Univ, LIACS Media Lab, Leiden, Netherlands.
   [Pu, Nan] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
C3 Leiden University - Excl LUMC; Leiden University; University of Trento
RP He, K (corresponding author), Leiden Univ, LIACS Media Lab, Leiden, Netherlands.
EM k.he@liacs.leidenuniv.nl; nan.pu@unitn.it; m.lao@liacs.leidenuniv.nl;
   m.s.lew@liacs.leidenuniv.nl
RI Pu, Nan/JMQ-1195-2023
FU LIACS MediaLab at Leiden University; China Scholarship Council (CSC)
   [201703170183]
FX This work was supported by LIACS MediaLab at Leiden University and China
   Scholarship Council (CSC No.201703170183).
CR Afrasiyabi Arman, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P18, DOI 10.1007/978-3-030-58558-7_2
   Afrasiyabi A, 2022, PROC CVPR IEEE, P9004, DOI 10.1109/CVPR52688.2022.00881
   Afrasiyabi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9021, DOI 10.1109/ICCV48922.2021.00891
   Akata Z, 2021, INT J COMPUT VISION, V129, P3169, DOI 10.1007/s11263-021-01522-3
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Antoniou A, 2019, Arxiv, DOI [arXiv:1902.09884, DOI 10.48550/ARXIV.1902.09884]
   Baghbaderani RK, 2019, WHISPERS, P1
   Baik S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9445, DOI 10.1109/ICCV48922.2021.00933
   BALDI P, 1993, NEURAL COMPUT, V5, P402, DOI 10.1162/neco.1993.5.3.402
   Bertinetto Luca, 2019, PROC INT C LEARN REP
   Bian WY, 2021, J IMAGING, V7, DOI 10.3390/jimaging7110231
   Bin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P438, DOI 10.1007/978-3-030-58548-8_26
   Brauwers G, 2023, IEEE T KNOWL DATA EN, V35, P3279, DOI 10.1109/TKDE.2021.3126456
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cai JH, 2020, Arxiv, DOI arXiv:2005.10544
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chao XW, 2023, MULTIMEDIA SYST, V29, P2843, DOI 10.1007/s00530-021-00827-0
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Chen YB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9042, DOI 10.1109/ICCV48922.2021.00893
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Cho H, 2021, ICCV
   Collier M, 2018, LECT NOTES COMPUT SC, V11141, P94, DOI 10.1007/978-3-030-01424-7_10
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng Shisheng, 2022, Cloud Computing - CLOUD 2022: 15th International Conference, Held as Part of the Services Conference Federation, SCF 2022, Proceedings. Lecture Notes in Computer Science (13731), P54, DOI 10.1007/978-3-031-23498-9_5
   Dhillon G. S., 2020, INT C LEARN REPR
   Ding G., 2022, CVPR, p11 194
   Ding L, 2022, Arxiv, DOI arXiv:2208.08135
   Do Jaejun, 2022, 2022 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia), P1, DOI 10.1109/ICCE-Asia57006.2022.9954846
   Dong JH, 2022, PROC CVPR IEEE, P9015, DOI 10.1109/CVPR52688.2022.00882
   dos Santos FP, 2021, SIBGRAPI, P207, DOI 10.1109/SIBGRAPI54419.2021.00036
   Dumoulin V, 2021, Arxiv, DOI arXiv:2104.02638
   Ebrahimi S, 2021, INT C LEARNING REPRE
   Eloff R, 2019, INT CONF ACOUST SPEE, P8623, DOI 10.1109/ICASSP.2019.8683587
   Elsken Thomas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12362, DOI 10.1109/CVPR42600.2020.01238
   Fallah A, 2021, Arxiv, DOI arXiv:2002.05135
   Fan M, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2353, DOI 10.1145/3357384.3358100
   Feurer M, 2015, AAAI CONF ARTIF INTE, P1128
   Finn C, 2018, ADV NEUR IN, V31
   Finn C, 2017, PR MACH LEARN RES, V70
   Gaikwad Madhava, 2022, 2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS), P1876, DOI 10.1109/ICICCS53718.2022.9788260
   Gao K, 2020, NEURIPS, P154
   Garnelo M., 2018, INT C MACH LEARN, V80, P1690, DOI DOI 10.48550/ARXIV.1807.01613
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Goldblum M, 2020, ADV NEUR IN, V33
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2014, Arxiv, DOI arXiv:1410.5401
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo N, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102065
   Gupta Aakriti, 2020, P 28 INT C COMP LING, P1061
   Gupta Abhishek, 2018, Advances in Neural Information Processing Systems, V31
   Han GX, 2023, Arxiv, DOI arXiv:2204.07841
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou I., 2022, Adv. Neural Inf. Process. Syst., P25767
   Hou RB, 2019, ADV NEUR IN, V32
   Hu TH, 2020, MEASUREMENT, V156, DOI 10.1016/j.measurement.2020.107539
   Huang HX, 2019, IEEE INT CON MULTI, P91, DOI 10.1109/ICME.2019.00024
   Huang W., 2021, MLICOM, V438, P243
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Kai Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13467, DOI 10.1109/CVPR42600.2020.01348
   Kang BY, 2019, IEEE I CONF COMP VIS, P8419, DOI 10.1109/ICCV.2019.00851
   Kang D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8802, DOI 10.1109/ICCV48922.2021.00870
   Karunaratne G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22364-0
   Khodadadeh S, 2019, ADV NEUR IN, V32
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Köksal A, 2023, Arxiv, DOI arXiv:2211.08358
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kulkarni TD, 2015, ADV NEUR IN, V28
   Lake BM, 2011, P 33TH ANN M COGNITI
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li AX, 2019, IEEE I CONF COMP VIS, P9714, DOI 10.1109/ICCV.2019.00981
   Li P, 2022, INFORM SCIENCES, V610, P592, DOI 10.1016/j.ins.2022.08.048
   Li WH, 2022, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR52688.2022.00702
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Li XM, 2020, NEUROCOMPUTING, V406, P49, DOI 10.1016/j.neucom.2020.04.040
   Li XX, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109381
   Li XX, 2021, NEUROCOMPUTING, V456, P463, DOI 10.1016/j.neucom.2020.05.114
   Li XX, 2021, IEEE T IMAGE PROCESS, V30, P1318, DOI 10.1109/TIP.2020.3043128
   Lin Y, 2021, ADV NEUR IN, V34
   Liu B, 2020, IEEE ACCESS, V8, P117096, DOI 10.1109/ACCESS.2020.3004968
   Liu H., 2019, INT C MACHINE LEARNI, P4061
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu WH, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3230709
   Liu Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111752
   Lu JS, 2016, ADV NEUR IN, V29
   Lungu IA, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P183, DOI [10.1109/AICAS48895.2020.9073996, 10.1109/aicas48895.2020.9073996]
   Luo S, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108586
   Ma J, 2021, ICCV, P562
   Mahesh B., 2019, Machine Learning Algorithms -A Review, DOI DOI 10.21275/ART20203995
   Mai SJ, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.001
   Malekmohamadi Faradonbe S., 2020, SN Comput. Sci., V1, P333, DOI [10.1007/s42979-020-00341-6, DOI 10.1007/S42979-020-00341-6]
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   McClelland JL, 1986, PARALLEL DISTRIBUTED, V2, P216, DOI [DOI 10.7551/MITPRESS/5237.001.0001, 10.7551/mitpress/5237.003.0008, DOI 10.7551/MITPRESS/5237.003.0008]
   Mehrotra A, 2017, Arxiv, DOI arXiv:1703.08033
   Miller A., 2016, P 2016 C EMP METH NA, P1400, DOI DOI 10.18653/V1/D16-1147
   Mishra N., 2018, INT C LEARN REPR
   Mishra N, 2018, Arxiv, DOI arXiv:1707.03141
   Moon J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217619
   Munkhdalai T, 2018, PR MACH LEARN RES, V80
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Najdenkoska I, 2023, arXiv
   Nichol A, 2018, Arxiv, DOI [arXiv:1803.02999, DOI 10.48550/ARXIV.1803.02999]
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Osahor U, 2022, IEEE WINT CONF APPL, P2040, DOI 10.1109/WACV51458.2022.00210
   Pahde F, 2021, IEEE WINT CONF APPL, P2643, DOI 10.1109/WACV48630.2021.00269
   Park S, 2019, IEEE I CONF COMP VIS, P9367, DOI 10.1109/ICCV.2019.00946
   Parnami A., 2022, arXiv
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Perez-Rua Juan-Manuel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13843, DOI 10.1109/CVPR42600.2020.01386
   Qiao LM, 2019, IEEE I CONF COMP VIS, P3602, DOI 10.1109/ICCV.2019.00370
   Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755
   Qin T., 2020, arXiv
   Ratner Alexander J, 2017, P NEURIPS, P3236
   Ravi S., 2016, INT C LEARNING REPRE
   Reif M, 2012, MACH LEARN, V87, P357, DOI 10.1007/s10994-012-5286-7
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Rohrbach M., 2013, Advances in neural information processing systems, P46
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Rostami M, 2019, IEEE COMPUT SOC CONF, P907, DOI 10.1109/CVPRW.2019.00120
   Rostami M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111374
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A. A., 2019, INT C LEARN REPR
   Santoro A., 2016, ICML, P1842
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Satrya WF, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020583
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sendera M, 2021, NEURIP
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shen ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9594
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Shu J, 2018, Arxiv, DOI arXiv:1808.04572
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108111
   Snell J, 2017, ADV NEUR IN, V30
   Song Yang, 2021, INT C LEARN REPR
   Song YS, 2022, Arxiv, DOI [arXiv:2205.06743, DOI 10.1145/3582688]
   Sun B, 2021, PROC CVPR IEEE, P7348, DOI 10.1109/CVPR46437.2021.00727
   Sun JM, 2021, INT C PATT RECOG, P7609, DOI 10.1109/ICPR48806.2021.9412941
   Sun N, 2023, KNOWL-BASED SYST, V264, DOI 10.1016/j.knosys.2023.110329
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sun X, 2021, IEEE T IND ELECTRON, V68, P3588, DOI 10.1109/TIE.2020.2977553
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tai Y, 2022, IEEE J-STARS, V15, P2240, DOI 10.1109/JSTARS.2022.3155406
   Tokmakov P, 2019, IEEE I CONF COMP VIS, P6381, DOI 10.1109/ICCV.2019.00647
   Tran K, 2019, INT J MACH LEARN COM, V9
   Triantafillou E., 2020, P 8 INT C LEARN REPR
   Tseng H. Y., 2020, ICLR
   Tsutsui S., 2019, NeurIPS, P3057
   Van Nhan Nguyen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P118, DOI 10.1007/978-3-030-58592-1_8
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang D, 2019, NEUROCOMPUTING, V349, P202, DOI 10.1016/j.neucom.2019.03.085
   Wang H, 2021, P 30 INT JOINT C ART, P1075
   Wang J., 2017, Convolutional Neural Networks vis. Recognit, V2017, P1
   Wang JH, 2020, IEEE INT CONF ELECTR, P178, DOI 10.1109/iceiec49280.2020.9152261
   Wang JH, 2018, INT CONF SOFTW ENG, P551, DOI 10.1109/ICSESS.2018.8663732
   Wang K, 2022, IEEE COMPUT SOC CONF, P3728, DOI 10.1109/CVPRW56347.2022.00417
   Wang RQ, 2023, NEUROCOMPUTING, V522, P142, DOI 10.1016/j.neucom.2022.12.011
   Wang SH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226437
   Wang X, 2019, PROC CVPR IEEE, P1831, DOI 10.1109/CVPR.2019.00193
   Wei J, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5493
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wen JF, 2018, Arxiv, DOI arXiv:1812.00543
   Wertheimer D, 2021, PROC CVPR IEEE, P8008, DOI 10.1109/CVPR46437.2021.00792
   Widhianingsih TDA, 2022, APPL INTELL, V52, P7037, DOI 10.1007/s10489-021-02744-1
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Xie JT, 2022, PROC CVPR IEEE, P7962, DOI 10.1109/CVPR52688.2022.00781
   Yang JC, 2022, PLANT METHODS, V18, DOI 10.1186/s13007-022-00866-2
   Yang P, 2022, IEEE WINT CONF APPL, P408, DOI 10.1109/WACV51458.2022.00048
   Yang SR, 2023, Arxiv, DOI [arXiv:2204.08610, 10.48550/arXiv.2204.08610]
   Yap PC, 2021, ICML, p11,909
   Yazdanpanah Moslem, 2022, CVPR
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Yu J, 2022, IEEE COMPUT SOC CONF, P304, DOI 10.1109/CVPRW56347.2022.00045
   Yu ZH, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P686
   Yue Z., 2020, P 34 C NEUR INF PROC, P2734
   Yunhui Guo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P124, DOI 10.1007/978-3-030-58583-9_8
   Zhang JG, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1906
   Zhang P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010108
   Zhang RX, 2018, ADV NEUR IN, V31
   Zhang S, 2015, P 29 PACIFIC ASIA C
   Zhang ZW, 2019, COMPUT BIOL MED, V108, P354, DOI 10.1016/j.compbiomed.2019.02.017
   Zhao C, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), P137, DOI 10.1109/ICBK50248.2020.00029
   Zheng WF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084059
   Zhongjie Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12853, DOI 10.1109/CVPR42600.2020.01287
   Zhu FY, 2019, NEUROCOMPUTING, V328, P182, DOI 10.1016/j.neucom.2018.02.099
   Zhu PF, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108820
   Zhu YH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1090
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Ziko I., 2020, ICML, P11660
   Zintgraf Luisa, 2019, PMLR, P7693
NR 203
TC 4
Z9 4
U1 12
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 14
DI 10.1007/s13735-023-00279-4
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L1KD0
UT WOS:001020905000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Pallawi, S
   Singh, DK
AF Pallawi, Shruti
   Singh, Dushyant Kumar
TI Study of Alzheimer's disease brain impairment and methods for its early
   diagnosis: a comprehensive survey
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Alzheimer's disease; Deep learning; Transfer learning; Magnetic
   resonance imaging; Brain anatomy
ID MILD COGNITIVE IMPAIRMENT; CONVOLUTION NEURAL-NETWORK; DEEP
   LEARNING-MODEL; CLASSIFICATION; IMAGES; CLASSIFIERS; ALGORITHMS;
   PREDICTION; ENSEMBLES; FMRI
AB Alzheimer's disease (AD) is one of the most severe kinds of dementia that affects the elderly population. Since this disease is incurable and the changes in brain sub-regions start decades before the symptoms are observed, early detection becomes more challenging. Discriminating similar brain patterns for AD classification is difficult as minute changes in biomarkers are detected in different neuroimaging modality, also in different image projections. Deep learning models have provided excellent performance in analyzing various neuroimaging and clinical data. In this survey, we performed a comparative analysis of 134 papers published between 2017 and 2022 to get 360 degrees knowledge of the AD kind of problem and everything done to examine and deeply analyze factors causing this. Different pre-processing tools and techniques, various datasets, and brain sub-regions affected mainly by AD have been reviewed. Further deep analysis of various biomarkers, feature extraction techniques, Deep learning and Machine learning architectures has been done for the survey. Summarization of the latest research articles with valuable findings has been represented in multiple tables. A novel approach has been used representing classification of biomarkers, pre-processing techniques and AD detection methods in form of figures and classification of AD on the basis of stages showing difference in accuracies between binary and multi-class in form of table. We finally concluded our paper by addressing some challenges faced during classification and provided recommendations that can be considered for future research in diagnosing various stages of AD.
C1 [Pallawi, Shruti; Singh, Dushyant Kumar] MNNIT Allahabad, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Pallawi, S (corresponding author), MNNIT Allahabad, Prayagraj, India.
EM shruti.2021rcs28@mnnit.ac.in; dushyant@mnnit.ac.in
RI Singh, Dushyant Kumar/AAD-8512-2021
CR Abuhmed T, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106688
   Afzal S, 2021, INT J INTERACT MULTI, V6, P26, DOI 10.9781/ijimai.2021.04.005
   Ahmed MR, 2019, IEEE REV BIOMED ENG, V12, P19, DOI 10.1109/RBME.2018.2886237
   Ahmed S, 2019, IEEE ACCESS, V7, P73373, DOI 10.1109/ACCESS.2019.2920011
   Al-Shoukry S, 2020, IEEE ACCESS, V8, P77131, DOI 10.1109/ACCESS.2020.2989396
   Alberdi A, 2016, ARTIF INTELL MED, V71, P1, DOI 10.1016/j.artmed.2016.06.003
   Altaf T, 2018, BIOMED SIGNAL PROCES, V43, P64, DOI 10.1016/j.bspc.2018.02.019
   An N, 2020, J BIOMED INFORM, V105, DOI 10.1016/j.jbi.2020.103411
   Ansari MA, 2022, CYBERN INF TECHNOL, V22, P190, DOI 10.2478/cait-2022-0012
   Ansari MA, 2022, MULTIMED TOOLS APPL, V81, P22497, DOI 10.1007/s11042-021-11438-2
   Basheera S, 2019, ALZH DEMENT-TRCI, V5, P974, DOI 10.1016/j.trci.2019.10.001
   Beyer K, INT C DAT THEOR
   Bi X, 2020, COGN COMPUT, V12, P513, DOI 10.1007/s12559-019-09688-2
   Bi XL, 2020, NEUROCOMPUTING, V392, P296, DOI 10.1016/j.neucom.2018.11.111
   Chen S., 2020, 2020 2nd International Conference on Big-Data Service and Intelligent Computation
   Chen YY, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107944
   Cheng B, 2019, BRAIN IMAGING BEHAV, V13, P138, DOI 10.1007/s11682-018-9846-8
   Cheng D, 2017, LECT NOTES COMPUT SC, V10541, P106, DOI 10.1007/978-3-319-67389-9_13
   Chitradevi D, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105857
   Choi H, 2020, EUR J NUCL MED MOL I, V47, P403, DOI 10.1007/s00259-019-04538-7
   Choi JY, 2020, IEEE SIGNAL PROC LET, V27, P206, DOI 10.1109/LSP.2020.2964161
   Cui RX, 2019, IEEE J BIOMED HEALTH, V23, P2099, DOI 10.1109/JBHI.2018.2882392
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Ebrahimighahnavieh MA, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105242
   Essemlali A, 2020, MED IMAGING DEEP LEA
   Farina FR, 2020, NEUROIMAGE, V215, DOI 10.1016/j.neuroimage.2020.116795
   Fulton LV, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9090212
   Ge CJ, 2019, NEUROCOMPUTING, V350, P60, DOI 10.1016/j.neucom.2019.04.023
   Gorji HT, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9090217
   Gosztolya G, 2019, COMPUT SPEECH LANG, V53, P181, DOI 10.1016/j.csl.2018.07.007
   Han KF, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac5ed5
   Hazarika RA, 2021, INT J MULTIMED INF R, V10, P199, DOI 10.1007/s13735-021-00210-9
   Hazarika RA, 2021, IEEE ACCESS, V9, P58503, DOI 10.1109/ACCESS.2021.3072559
   Helaly HA, 2022, COGN COMPUT, V14, P1711, DOI 10.1007/s12559-021-09946-2
   Hernandez-Dominguez Laura, 2018, Alzheimers Dement (Amst), V10, P260, DOI 10.1016/j.dadm.2018.02.004
   Hon M, 2017, IEEE INT C BIOINFORM, P1166, DOI 10.1109/BIBM.2017.8217822
   Houria L, 2022, PHYS ENG SCI MED, V45, P1043, DOI 10.1007/s13246-022-01165-9
   Hu CH, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510831
   Ieracitano C, 2020, NEURAL NETWORKS, V123, P176, DOI 10.1016/j.neunet.2019.12.006
   Islam Jyoti, 2020, Brain Inform, V7, P3, DOI 10.1186/s40708-020-00104-2
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Islam Jyoti, 2018, Brain Inform, V5, P2, DOI 10.1186/s40708-018-0080-3
   Jabason E, 2019, 2019 22 INT C INF FU, P3
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Janghel RR, 2021, IRBM, V42, P258, DOI 10.1016/j.irbm.2020.06.006
   Jha D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/9060124
   Jo T, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00220
   Ju RH, 2019, IEEE ACM T COMPUT BI, V16, P244, DOI 10.1109/TCBB.2017.2776910
   Kabir A, 2021, TENCON 2021
   Kapoor M., 2021, 2021 Thirteenth International Conference on Contemporary Computing (IC3-2021)
   Kar S, 2019, J ALZHEIMERS DIS REP, V3, P1, DOI 10.3233/ADR-180082
   Karwath A, 2017, C ART INT MED EUR
   Kathiravan S., 2013, SMARTCOMPUT REV, V3, P358, DOI [10.6029/smartcr.2013.05.006, DOI 10.6029/SMARTCR.2013.05.006]
   Kazemi Y, 2018, 2018 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P154
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan S, 2018, MECH SYST SIGNAL PR, V107, P241, DOI 10.1016/j.ymssp.2017.11.024
   Khojaste-Sarakhsi M, 2022, ARTIF INTELL MED, V130, DOI 10.1016/j.artmed.2022.102332
   Khvostikov A, 2018, Arxiv, DOI [arXiv:1801.05968, DOI 10.48550/ARXIV.1801.05968]
   Kim J, 2018, HUM BRAIN MAPP, V39, P3728, DOI 10.1002/hbm.24207
   Kumar SS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3383749
   Lei BY, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107247
   Li F, 2018, COMPUT MED IMAG GRAP, V70, P101, DOI 10.1016/j.compmedimag.2018.09.009
   Li F, 2014, LECT NOTES COMPUT SC, V8679, P240, DOI 10.1007/978-3-319-10581-9_30
   Li W, 2020, NEUROCOMPUTING, V388, P280, DOI 10.1016/j.neucom.2020.01.053
   Li XJ, 2017, LECT NOTES ARTIF INT, V10604, P519, DOI 10.1007/978-3-319-69179-4_36
   Lian CF, 2020, IEEE T PATTERN ANAL, V42, P880, DOI 10.1109/TPAMI.2018.2889096
   Liang S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010220
   Lin W, 2020, P 2020 INT S ART INT
   Liu J, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-3437-6
   Liu J, 2018, IEEE ACM T COMPUT BI, V15, P624, DOI 10.1109/TCBB.2016.2635144
   Liu J, 2017, IEEE T NANOBIOSCI, V16, P428, DOI 10.1109/TNB.2017.2707139
   Liu JX, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106032
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Liu MX, 2018, MED IMAGE ANAL, V43, P157, DOI 10.1016/j.media.2017.10.005
   Lu DH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22871-z
   Lu DH, 2018, MED IMAGE ANAL, V46, P26, DOI 10.1016/j.media.2018.02.002
   Luo S., 2017, Journal of Applied Mathematics and Physics, V5, P1892
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Malik F, 2018, ADV ELECTR COMPUT EN, V18, P61, DOI 10.4316/AECE.2018.01008
   Mehmood A, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020084
   Mendoza-León R, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103527
   Nagariya Akhil, 2020, arXiv
   Nawaz H, 2021, MULTIMED TOOLS APPL, V80, P35789, DOI 10.1007/s11042-020-09087-y
   Duc NT, 2020, NEUROINFORMATICS, V18, P71, DOI 10.1007/s12021-019-09419-w
   Noor Manan Binth Taj, 2020, Brain Inform, V7, P11, DOI 10.1186/s40708-020-00112-2
   Oh K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54548-6
   Ortiz A, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500258
   Pan J., 2021, arXiv
   Pan Q, 2021, 2021 IEEE INT C DAT
   Peng JL, 2019, PATTERN RECOGN, V88, P370, DOI 10.1016/j.patcog.2018.11.027
   Puente-Castro A, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103764
   Qiu S, 2022, Nat. Commun., V13, P1, DOI DOI 10.1038/S41467-022-31037-5
   Qiu SR, 2020, BRAIN, V143, P1920, DOI 10.1093/brain/awaa137
   Qiu Shangran, 2018, Alzheimers Dement (Amst), V10, P737, DOI 10.1016/j.dadm.2018.08.013
   Ramzan F, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1475-2
   Rathore S, 2017, NEUROIMAGE, V155, P530, DOI 10.1016/j.neuroimage.2017.03.057
   Raza M, 2019, EXPERT SYST APPL, V136, P353, DOI 10.1016/j.eswa.2019.06.038
   Sarraf S, 2016, DEEPAD ALZHEIMERS DI, DOI DOI 10.1101/070441
   Sarraf S, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P816, DOI 10.1109/FTC.2016.7821697
   Savas S, 2022, ARAB J SCI ENG, V47, P2201, DOI 10.1007/s13369-021-06131-3
   Sengupta S, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105596
   Shankar K, 2019, COMPUT ELECTR ENG, V77, P230, DOI 10.1016/j.compeleceng.2019.06.001
   Shanmugam JV, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103217
   Shen T, 2019, MOL IMAGING, V18, DOI 10.1177/1536012119877285
   Sheng JH, 2019, BEHAV BRAIN RES, V365, P210, DOI 10.1016/j.bbr.2019.03.004
   Shi BB, 2017, PATTERN RECOGN, V63, P487, DOI 10.1016/j.patcog.2016.09.032
   Singh A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060052
   Singh DK, 2022, 2022 IEEE REG 10 S T
   Singh DK, 2023, INT J SYST ASSUR ENG, V14, P79, DOI 10.1007/s13198-022-01822-y
   Singh DK, 2021, PROCEDIA COMPUT SCI, V189, P76, DOI 10.1016/j.procs.2021.05.071
   Song TA, 2019, I S BIOMED IMAGING, P414, DOI 10.1109/ISBI.2019.8759531
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Spasov SE, 2018, IEEE ENG MED BIO, P1271, DOI 10.1109/EMBC.2018.8512468
   Sun JW, 2020, INT J COMPUT ASS RAD, V15, P445, DOI 10.1007/s11548-019-02106-w
   Tangaro S, 2017, PHYS MEDICA, V38, P36, DOI 10.1016/j.ejmp.2017.04.027
   Tanveer M, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3344998
   Venugopalan J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-74399-w
   Vu TD, 2017, INT CONF BIG DATA, P309, DOI 10.1109/BIGCOMP.2017.7881683
   Wang H., 2021, Proceedings of the 2nd International Symposium on Artificial Intelligence for Medicine Sciences
   Wang HF, 2019, NEUROCOMPUTING, V333, P145, DOI 10.1016/j.neucom.2018.12.018
   Wang T, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19945-3
   Wang Y, 2018, IEEE ENG MED BIO, P754, DOI 10.1109/EMBC.2018.8512372
   Wen JH, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101694
   Yang ZG, 2020, SAUDI J BIOL SCI, V27, P659, DOI 10.1016/j.sjbs.2019.12.004
   Zhang F, 2019, NEUROCOMPUTING, V361, P185, DOI 10.1016/j.neucom.2019.04.093
   Zhang J, 2021, MAGN RESON IMAGING, V78, P119, DOI 10.1016/j.mri.2021.02.001
   Zhang L, 2022, NEUROCOMPUTING, V492, P353, DOI 10.1016/j.neucom.2022.04.012
   Zhang ZH, 2021, QUANT IMAG MED SURG, V11, P3338, DOI 10.21037/qims-21-91
   Zheng WH, 2018, BIOL PSYCHIAT-COGN N, V3, P887, DOI 10.1016/j.bpsc.2018.06.004
   Zheng X, 2017, I S BIOMED IMAGING, P456, DOI 10.1109/ISBI.2017.7950559
   Zhou K, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081372
   Zhu WY, 2021, IEEE T MED IMAGING, V40, P2354, DOI 10.1109/TMI.2021.3077079
   Zhu YY, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101825
   Zhu YH, 2022, INFORM FUSION, V77, P53, DOI 10.1016/j.inffus.2021.07.013
NR 134
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 7
DI 10.1007/s13735-023-00271-y
PG 29
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A0NQ8
UT WOS:000952187800001
DA 2024-07-18
ER

PT J
AU Yang, Y
   An, YZ
   Hu, JT
   Pan, LY
AF Yang, You
   An, Yongzhi
   Hu, Juntao
   Pan, Longyue
TI Tri-RAT: optimizing the attention scores for image captioning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image captioning; Attention mechanism; Transformer; Residual attention;
   Relative position information; Layer normalization
AB Attention mechanisms and grid features are widely used in current visual language tasks like image captioning. The attention scores are the key factor to the success of the attention mechanism. However, the connection between attention scores in different layers is not strong enough since Transformer is a hierarchical structure. Additionally, geometric information is inevitably lost when grid features are flattened to be fed into a transformer model. Therefore, bias scores about geometric position information should be added to the attention scores. Considering that there are three different kinds of attention modules in the transformer architecture, we build three independent paths (residual attention paths, RAPs) to propagate the attention scores from the previous layer as a prior for attention computation. This operation is like a residual connection between attention scores, which can enhance the connection and make each attention layer obtain a global comprehension. Then, we replace the traditional attention module with a novel residual attention with relative position module in the encoder to incorporate relative position scores with attention scores. Residual attention may increase the internal covariate shifts. To optimize the data distribution, we introduce residual attention with layer normalization on query vectors module in the decoder. Finally, we build our Residual Attention Transformer with three RAPs (Tri-RAT) for the image captioning task. The proposed model achieves competitive performance on the MSCOCO benchmark with all the state-of-the-art models. We gain 135.8% CIDEr on MS COCO "Karpathy" offline test split and 135.3% CIDEr on the online testing server.
C1 [Yang, You; An, Yongzhi; Hu, Juntao; Pan, Longyue] Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Yang, You] Natl Ctr Appl Math Chongqing, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP An, YZ (corresponding author), Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.
EM 20130958@cqnu.edu.cn; 2020110516064@stu.cqnu.edu.cn;
   hjt65190411@gmail.com; 2020110516011@stu.cqnu.edu.cn
OI An, Yongzhi/0000-0002-7619-672X
FU Chongqing Post-graduate Joint Training Base Project: Computer Technology
   Professional, Chongqing Normal University; Chongqing Century Keyi
   Technology Co., Ltd.; Chongqing Normal University [21XLB03]
FX This work is supported partially by the Chongqing Post-graduate Joint
   Training Base Project: Computer Technology Professional, Chongqing
   Normal University and Chongqing Century Keyi Technology Co., Ltd. It is
   also supported by PhD Start-up Fund/Talent Introduction Project of
   Chongqing Normal University, Grant No.21XLB03.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Gupta A., 2012, PROC AAAI C ARTIFICI, P606
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He R, 2020, ARXIV
   Herdade S, 2019, ADV NEUR IN, V32
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Ji JY, 2021, AAAI CONF ARTIF INTE, V35, P1655
   Jiang H, 2020, P IEEECVF C COMPUTER, P276
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Mao J, 2014, ARXIV
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Ushiku Y, 2015, IEEE I CONF COMP VIS, P2668, DOI 10.1109/ICCV.2015.306
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Ying C., 2021, ARXIV
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
NR 33
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 705
EP 715
DI 10.1007/s13735-022-00260-7
EA OCT 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000864588700001
DA 2024-07-18
ER

PT J
AU Elghoul, S
   Ghorbel, F
AF Elghoul, Sinda
   Ghorbel, Faouzi
TI A fast and robust affine-invariant method for shape registration under
   partial occlusion
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Affine invariant; Partial occlusion; Planar curve; Articulated
   deformations; Registration; Affine arc length; Pseudo-inverse matrix;
   Stability
ID FOURIER DESCRIPTORS; NONRIGID SHAPES; RECOGNITION; REPRESENTATION;
   DISTANCE; CURVES; RETRIEVAL; FRAMEWORK; MATRIX; SPACE
AB The acquisition of the planar images of the same object may be considerably different due to viewpoint dependencies, which influences the shape extraction, hence possibly making the curves partially visible and often accompanied by perspective distortions. In this paper, we propose a new contour alignment system relating to the special affine transformations that contain rotations and stretches, useful for describing planar contours which move in three-dimensional space and which are far enough away from the camera. The registration system that we suggest here includes a first optimization step relating to the dataset concerned. It consists in optimizing the number of correspondence points N between the curves to be registered. This is achieved by minimizing the conditioning of the correspondence matrix which is obtained by matching the re-sampling points by the equi-affine length of the two curves. This correspondence matrix is calculated for all the pairs of curves of the dataset by varying N. After extracting the optimal value of N, the estimation of the special affine transformation between a given couple of curves is realized by the pseudo-inverse of the correspondence matrix in the N-0 resolution. This approach allows both providing the best accuracy and stabilizing the results of registration. We evaluate and compare our algorithm with other existing methods under different shape variations including noise, missing parts, and articulated deformations. The experiments are conducted on several known datasets.
C1 [Elghoul, Sinda; Ghorbel, Faouzi] Manouba Univ, GRIFT Res Grp, CRISTAL Lab, Natl Sch Comp Sci ENSI, Manouba 2010, Tunisia.
C3 Universite de la Manouba
RP Elghoul, S (corresponding author), Manouba Univ, GRIFT Res Grp, CRISTAL Lab, Natl Sch Comp Sci ENSI, Manouba 2010, Tunisia.
EM sinda.elghoul@ensi-uma.tn
OI Ghorbel, Faouzi/0000-0002-6364-1089
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Bachelder IA, 1992, CONTOUR MATCHING USI
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   BenKhlifa A, 2019, SIGNAL PROCESS-IMAGE, V75, P32, DOI 10.1016/j.image.2019.03.009
   BRUCKSTEIN AM, 1992, INT J COMPUT VISION, V7, P271, DOI 10.1007/BF00126396
   Bryner D, 2014, IEEE T PATTERN ANAL, V36, P998, DOI 10.1109/TPAMI.2013.199
   Cao X., 2020, Handbook of Medical Image Computing and Computer Assisted Intervention, P319
   Cao Xiaohuan, 2017, Med Image Comput Comput Assist Interv, V10433, P300, DOI 10.1007/978-3-319-66182-7_35
   CHAKER F, 2007, IAPR C MACH VIS APPL, P291
   CRIMMINS TR, 1982, IEEE T SYST MAN CYB, V12, P848, DOI 10.1109/TSMC.1982.4308918
   Cui M, 2009, PATTERN RECOGN LETT, V30, P1, DOI 10.1016/j.patrec.2008.08.013
   Cyganski, 1987, 1 INT C COMP VIS
   Cyganski D., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V848, P33
   Cyganski D, 1995, PATTERN RECOGN, V28, P1845, DOI 10.1016/0031-3203(95)00060-7
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   de Vos BD, 2019, MED IMAGE ANAL, V52, P128, DOI 10.1016/j.media.2018.11.010
   de Vos BD, 2017, LECT NOTES COMPUT SC, V10553, P204, DOI 10.1007/978-3-319-67558-9_24
   Demirci M. F., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3057, DOI 10.1109/ICPR.2010.749
   Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P646
   Domokos C, 2010, PATTERN RECOGN, V43, P569, DOI 10.1016/j.patcog.2009.08.013
   Donoser Michael, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P281
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448
   El Rube I, 2006, IEEE T PATTERN ANAL, V28, P323, DOI 10.1109/TPAMI.2006.43
   El-ghazal A, 2012, J VIS COMMUN IMAGE R, V23, P622, DOI 10.1016/j.jvcir.2012.01.011
   El-Ghazal A, 2009, SIGNAL PROCESS-IMAGE, V24, P572, DOI 10.1016/j.image.2009.04.001
   Elghoul S, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P474, DOI 10.5220/0006719504740480
   Elghoul S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116058
   Eppenhof KAJ, 2018, PROC SPIE, V10574, DOI 10.1117/12.2292443
   Felzenszwalb PF, 2007, PROC CVPR IEEE, P367
   Ferrante E, 2019, IEEE J BIOMED HEALTH, V23, P1374, DOI 10.1109/JBHI.2018.2869700
   Ferrante E, 2017, MED IMAGE ANAL, V39, P101, DOI 10.1016/j.media.2017.04.010
   Fu HJ, 2013, IET COMPUT VIS, V7, P279, DOI 10.1049/iet-cvi.2012.0123
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Genovese A., 2014, Touchless Palmprint Recognit. Syst., P49
   Ghorbel F, 1998, ANN TELECOMMUN, V53, P242
   GHORBEL F, 1994, PATTERN RECOGN LETT, V15, P1043, DOI 10.1016/0167-8655(94)90037-X
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Gope C, 2005, PATTERN RECOGN, V38, P125, DOI 10.1016/j.patcog.2004.06.005
   Guimei Zhang, 2011, Journal of Computers, V6, P1740, DOI 10.4304/jcp.6.8.1740-1747
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu N, 2011, J GEOM, V102, P103, DOI 10.1007/s00022-012-0105-7
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   Hu YP, 2018, I S BIOMED IMAGING, P1070, DOI 10.1109/ISBI.2018.8363756
   Huang XM, 2005, PATTERN RECOGN LETT, V26, P1244, DOI 10.1016/j.patrec.2004.11.006
   HUTTENLOCHER DP, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P340, DOI 10.1145/98524.98599
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jia Q, 2016, PATTERN RECOGN, V52, P358, DOI 10.1016/j.patcog.2015.11.003
   JIN Q, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P742, DOI 10.1109/ICPR.1992.201667
   Joo H, 2009, IEEE INT CONF ROBOT, P2618
   Joshi K, 2020, INT J MULTIMED INF R, V9, P231, DOI 10.1007/s13735-020-00200-3
   Khalil MI, 2001, IEEE T PATTERN ANAL, V23, P1152, DOI 10.1109/34.954605
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Krebs Julian, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P344, DOI 10.1007/978-3-319-66182-7_40
   Krotosky SJ, 2007, COMPUT VIS IMAGE UND, V106, P270, DOI 10.1016/j.cviu.2006.10.008
   Laiche N, 2018, MULTIMED TOOLS APPL, V77, P13891, DOI 10.1007/s11042-017-4998-x
   LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047
   Latecki LJ, 2005, IMAGE VISION COMPUT, V23, P227, DOI 10.1016/j.imavis.2004.06.015
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Latecki LJ, 2007, PATTERN RECOGN, V40, P3069, DOI 10.1016/j.patcog.2007.03.004
   Liao R, 2017, AAAI CONF ARTIF INTE, P4168
   Lin WS, 2007, PATTERN RECOGN, V40, P1921, DOI 10.1016/j.patcog.2006.03.021
   Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu HL, 2014, RESULTS MATH, V65, P235, DOI 10.1007/s00025-013-0343-5
   Longbin Chen, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563078
   Mai F, 2010, IEEE IMAGE PROC, P4605, DOI 10.1109/ICIP.2010.5651645
   Mai F, 2011, PATTERN RECOGN, V44, P210, DOI 10.1016/j.patcog.2010.08.032
   Marvaniya S, 2018, MACH VISION APPL, V29, P553, DOI 10.1007/s00138-018-0912-4
   Merhy M, 2014, IEEE IMAGE PROC, P4742, DOI 10.1109/ICIP.2014.7025961
   Michel D, 2011, IMAGE VISION COMPUT, V29, P459, DOI 10.1016/j.imavis.2011.01.008
   Mokhtarian F, 2001, PATTERN ANAL APPL, V4, P1, DOI 10.1007/PL00010984
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Moyou M, 2020, IEEE T IMAGE PROCESS, V29, P3374, DOI 10.1109/TIP.2019.2959722
   Nomizu K, 1994, CAMBRIDGE TRACTS MAT
   Olver PJ, 2010, LOBACHEVSKII J MATH, V31, P77, DOI 10.1134/S1995080210020010
   Olver P. J., 2015, Impact150 Stories, P14
   Orrite C, 2004, COMPUT VIS IMAGE UND, V93, P34, DOI 10.1016/j.cviu.2003.09.005
   Osowski S, 2002, PATTERN RECOGN, V35, P1949, DOI 10.1016/S0031-3203(01)00153-4
   Raviv D, 2015, INT J COMPUT VISION, V111, P1, DOI 10.1007/s11263-014-0728-2
   REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675
   Rodríguez M, 2020, IEEE WINT CONF APPL, P1331, DOI 10.1109/WACV45572.2020.9093646
   Rui Y, 1998, SER SOFTW ENGN KNOWL, V8, P165
   Saber E, 2005, PATTERN RECOGN, V38, P1560, DOI 10.1016/j.patcog.2005.03.027
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shan Y, 2006, IEEE T PATTERN ANAL, V28, P568, DOI 10.1109/TPAMI.2006.83
   Sharma A, 2021, 3D SHAPE REGISTRATIO
   Shekar BH, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P46, DOI 10.1145/2708463.2709062
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Soderkvist O., 2001, COMPUTER VISION CLAS
   Sokic E, 2014, INT WORK CONTENT MUL
   Spivak M., 1975, COMPREHENSIVE INTRO
   Stergios C, 2018, LECT NOTES COMPUT SC, V11040, P13, DOI 10.1007/978-3-030-00946-5_2
   Temlyakov A, 2010, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2010.5539912
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Tieng QM, 1995, PATTERN RECOGN LETT, V16, P1287, DOI 10.1016/0167-8655(95)00079-1
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wang W, 2017, INT SYM COMPUT INTEL, P79, DOI 10.1109/ISCID.2017.157
   Wang ZB, 2018, MULTIMED TOOLS APPL, V77, P27405, DOI 10.1007/s11042-018-5929-1
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Yang CZ, 2019, SIGNAL PROCESS-IMAGE, V71, P110, DOI 10.1016/j.image.2018.11.004
   Yang CZ, 2018, NEUROCOMPUTING, V275, P1160, DOI 10.1016/j.neucom.2017.09.067
   Yang CZ, 2016, FRONT ARTIF INTEL AP, V285, P269, DOI 10.3233/978-1-61499-672-9-269
   Yang GQ, 2022, VISUAL COMPUT, V38, P603, DOI 10.1007/s00371-020-02037-7
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Yang Y, 2020, B MALAYS MATH SCI SO, V43, P3229, DOI 10.1007/s40840-019-00864-z
   Yang Y, 2018, FRACTALS, V26, DOI 10.1142/S0218348X18500573
   Ye YX, 2019, IEEE T GEOSCI REMOTE, V57, P9059, DOI 10.1109/TGRS.2019.2924684
   You X, 2007, IEEE T IMAGE PROCESS, V16, P1220, DOI 10.1109/TIP.2007.891800
   Yu Cao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2345, DOI 10.1109/CVPR.2011.5995588
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhang GM, 2015, INT CONF KNOWL SYS, P456, DOI 10.1109/ISKE.2015.52
   Zhang K, 2019, IEEE ACCESS, V7, P115637, DOI 10.1109/ACCESS.2019.2935879
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
   Zhang YN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155177
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
   Zuliani M, 2004, IEEE IMAGE PROC, P3041
NR 125
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2022
VL 11
IS 1
BP 39
EP 59
DI 10.1007/s13735-021-00224-3
EA NOV 2021
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI9SJ
UT WOS:000723990900001
DA 2024-07-18
ER

PT J
AU Pathak, D
   Raju, USN
AF Pathak, Debanjan
   Raju, U. S. N.
TI Content-based image retrieval using Group
   Normalized-Inception-Darknet-53
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE CBIR; Deep learning; Darknet-53; Inception layer; Group normalization;
   Transfer learning
ID NEURAL-NETWORKS; COLOR; FEATURES; CBIR
AB In recent days' research, deep learning methods have shown promising performance in various fields of computer vision, including content-based image retrieval (CBIR). In this paper, an improved version of Darknet-53, called GroupNormalized-Inception-Darknet-53 (GN-Inception-Darknet-53), is proposed to extract features for the CBIR model. To extract the more detailed features of an image, we augmented one inception layer which includes 1 x 1, 3 x 3, and 5 x 5 kernels in place of an existing 3 x 3 kernel. The output of this newly added inception layer is the concatenated results of these three kernels. To make the normalization process of the proposed model less dependent on batch size, group normalization (GN) layer is used instead of batch normalization. A total of five such inception layers are used in the proposed GN-Inception-Darknet-53, and the output of all these inception layers is depth concatenated to extract more detailed features of the image. To train the proposed model transfer learning mechanism is used. Five standard performance measures: average precision rate, average recall rate, F-measure, average normalized modified retrieval rank, and total minimum retrieval epoch, are calculated to evaluate the efficiency of our proposed method. To assess the performance of the proposed method, seven challenging image datasets: three natural datasets (Corel-1K, Corel-5K & Corel-10K), three subsets of ImageNet dataset, and UKbench dataset are used. For all these datasets, the proposed method shows better results than the nineteen methods used to compare that contain traditional and CNN methods for CBIR.
C1 [Pathak, Debanjan; Raju, U. S. N.] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Raju, USN (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
EM debanjan21pathak@gmail.com; usnraju@nitw.ac.in
RI Raju, U S N/AAN-7582-2020; pathak, debanjan/KQX-4840-2024
OI Raju, U S N/0000-0003-1049-7949; pathak, debanjan/0000-0002-5005-2525
CR Alluri L., 2020, INT J RECENT DEV SCI, V4, P160
   [Anonymous], 2018, YOLOV3 INCREMENTAL I
   Bhandi Vijayakumar, 2019, 2019 1st International Conference on Advanced Technologies in Intelligent Control, Environment, Computing & Communication Engineering (ICATIECE), P35, DOI 10.1109/ICATIECE45860.2019.9063814
   Bhowmick A, 2021, MULTIMED TOOLS APPL, V80, P35495, DOI 10.1007/s11042-020-10491-7
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Bouachir W., 2009, Proceedings of the 2009 Fifth International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2009), P215, DOI 10.1109/SITIS.2009.43
   Cai YH, 2019, IEEE ACCESS, V7, P51877, DOI 10.1109/ACCESS.2019.2911630
   Chen X, 2009, LECT NOTES ARTIF INT, V5476, P867, DOI 10.1007/978-3-642-01307-2_90
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elsayad I., 2010, P INT C CONT BAS MUL, P1
   Guo JM, 2015, IEEE T MULTIMEDIA, V17, P1576, DOI 10.1109/TMM.2015.2449234
   Guo JM, 2014, IEEE T IMAGE PROCESS, V23, P1269, DOI 10.1109/TIP.2013.2257812
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Hu RX, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2286330
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang J, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P325, DOI 10.1145/266180.266383
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kanaparthi SK, 2020, MULTIMED TOOLS APPL, V79, P34875, DOI 10.1007/s11042-019-08029-7
   Kokare M, 2002, IETE J RES, V48, P261, DOI 10.1080/03772063.2002.11416285
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li J, 2021, VISUAL COMPUT, V37, P619, DOI 10.1007/s00371-020-01828-2
   Liu Bo, 2019, Journal of Computer Applications, V39, P1663, DOI 10.11772/j.issn.1001-9081.2018102190
   Liu G.H., COREL 10K DATASET
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu SL, 2021, IEEE T NEUR NET LEAR, V32, P1389, DOI 10.1109/TNNLS.2020.2984676
   Maji Subhadip, 2020, CBIR USING FEATURES
   Mathew SP, 2015, ACTA POLYTECH HUNG, V12, P103
   Messina N, 2020, INT J MULTIMED INF R, V9, P113, DOI 10.1007/s13735-019-00178-7
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Mustafa F., 2019, INT C POW EL CONTR A, P1, DOI [10.1109/ICPECA47973.2019.89756318, DOI 10.1109/ICPECA47973.2019.89756318]
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Osowski S, 2002, PATTERN RECOGN, V35, P1949, DOI 10.1016/S0031-3203(01)00153-4
   Özaydin U, 2019, INT WORK CONTENT MUL
   Pradhan J, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2020.107063
   Ramanjaneyulu K, 2018, PROCEEDINGS OF THE 2018 3RD INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2018), P379, DOI 10.1109/ICICT43934.2018.9034389
   Rao YB, 2018, WORLD WIDE WEB, V21, P1505, DOI 10.1007/s11280-017-0523-4
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Shakarami A, 2020, OPTIK, V214, DOI 10.1016/j.ijleo.2020.164833
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song KK, 2018, IEEE ACCESS, V6, P44268, DOI 10.1109/ACCESS.2018.2862464
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tarawneh AS, 2020, INTELL DATA ANAL, V24, P47, DOI 10.3233/IDA-184411
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang, 2020, MODELINGOBJECTS CONC
   Wei SK, 2019, IEEE T IMAGE PROCESS, V28, P4580, DOI 10.1109/TIP.2019.2913513
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zhu L, 2014, IET IMAGE PROCESS, V8, P509, DOI 10.1049/iet-ipr.2013.0375
NR 67
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2021
VL 10
IS 3
BP 155
EP 170
DI 10.1007/s13735-021-00215-4
EA AUG 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UU7DE
UT WOS:000681177700001
DA 2024-07-18
ER

PT J
AU Chanu, OB
   Neelima, A
AF Chanu, Oinam Bidyapati
   Neelima, Arambam
TI A survey paper on secret image sharing schemes
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Secret image sharing; Steganography; Threshold scheme; Visual
   cryptography; Watermarking
ID STEGANOGRAPHY; AUTHENTICATION; LESS
AB With the speedy progress of network technology and internet applications, protection of digitized data against unauthorized access and modification has become a paramount issue. In order to face this challenge, numerous secret image sharing schemes have been introduced. Secret image sharing scheme is a method used for safeguarding the sensitive digitized image against illegal copying and tempering. The secret image is divided into many random shares in such a way that each share does not reveal any information to the intruders. In this paper, we present a comprehensive survey from over 100 papers which explains the new approaches and challenges. This paper also provides a comparative analysis of different methods based on different properties.
C1 [Chanu, Oinam Bidyapati; Neelima, Arambam] NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Chanu, OB (corresponding author), NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
EM obidyapatichanu@gmail.com; neelimaarambam@yahoo.co.in
OI Neelima, Arambam/0009-0003-2106-7757; CHANU, OINAM
   BIDYAPATI/0000-0002-3536-5435
CR Alharthi S, 2010, IEEE INT CON MULTI, P1661, DOI 10.1109/ICME.2010.5583180
   Anandhi, 2012, INT J COMPUT SCI NET, V12, P153
   Anbarasi J., 2015, INT ARAB J INF TECHN, V12, P708
   Anbarasi LJ, 2015, PROCEDIA COMPUT SCI, V46, P1794, DOI 10.1016/j.procs.2015.02.135
   [Anonymous], 2016, IJCSET, V6, P138
   [Anonymous], 2013, INT C INN ENG TECHN
   [Anonymous], 2012, INT J SCI ENG RES
   [Anonymous], 2014, J APPL MATH PHYS
   Bai L, 2006, DASC 2006: 2ND IEEE INTERNATIONAL SYMPOSIUM ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P31
   Bal RG, 2014, INT J INNOV RES COMP, V2, P3251
   Bhadran R, 2015, INT RES J ENG TECHNO, V2, P1391
   Bharanivendhan N., 2014, INT J COMPUTER APPL, V92, P11
   Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chan CS, 2014, KSII T INTERNET INF, V8, P1785, DOI 10.3837/tiis.2014.05.016
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Chang YJ, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2991410
   Chen C-C, 2015, J INF HIDING MULTIME, V7, P135
   Chen CC, 2008, J INF SCI ENG, V24, P1567
   Chen CC, 2017, J INF SECUR APPL, V33, P45, DOI 10.1016/j.jisa.2017.01.006
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen CC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013008
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chien-Chang Chen Y-CL, 2009, J ELECTRON IMAGING, V18
   Chin-Chen Chang, 2014, International Journal of Machine Learning and Computing, V4, P423, DOI 10.7763/IJMLC.2014.V4.448
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Ching-Nung Yang, 2014, International Journal of Machine Learning and Computing, V4, P522, DOI 10.7763/IJMLC.2014.V4.466
   Dastanian R, 2011, INT PROC COMPUT SCI, V6, P171
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Deshmukh M, 2016, INT CON ADV INFO NET, P690, DOI 10.1109/AINA.2016.56
   Dharwadkar N. V., 2010, Int. J. Signal Process., V6, P93
   Durgamba MNSS, 2015, INT J ADV RES COMPUT, V5, P134
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Fang WP, 2006, INT J COMPUT SCI NET, V6, P228
   Fang WP, 2011, INT J COMPUT SCI NET, V11, P20
   Fang WP, 2007, INT J EDUC INF TECH, V1, P43
   Feng B., 2015, IJ NETW SECUR, V17, P123
   Fereshte S., 2013, INT J COMPUT TECHNOL, V4, P494
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Harn L, 2017, WIRELESS PERS COMMUN, V95, P1495, DOI 10.1007/s11277-016-3862-z
   Hashim AT, 2013, INT C INF TECHN SIGN, P324
   Hodeish ME, 2016, PROCEDIA COMPUT SCI, V93, P760, DOI 10.1016/j.procs.2016.07.288
   Hu C, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691312500233
   Huang CP, 2006, INT C PATT RECOG, P802
   Isha M.P., 2014, INT J SCI RES IJSR, V3, P107
   Kandar S., 2011, INT J COMPUTER SCI I, V8, P543
   Karolin M, 2015, INT J ADV RES COMPUT, P2278
   Koga H, 2006, DESIGN CODE CRYPTOGR, V40, P81, DOI 10.1007/s10623-005-6700-y
   Koikara R, 2015, P INT C SEC MAN SAM, P178
   Koikara R., 2016, INT C SEC MAN SAM 16, P318
   Koikara R, 2015, LECT NOTES ELECTR EN, V315, P423, DOI 10.1007/978-3-319-07674-4_42
   Kong J, 2007, LECT NOTES COMPUT SC, V4688, P736
   Kuang-Shyr Wu, 2013, Applied Mechanics and Materials, V284-287, P3025, DOI 10.4028/www.scientific.net/AMM.284-287.3025
   Lee CW, 2012, IEEE T IMAGE PROCESS, V21, P207, DOI 10.1109/TIP.2011.2159984
   Lee CF, 2009, 2009 THIRD IEEE INTERNATIONAL CONFERENCE ON SECURE SOFTWARE INTEGRATION AND RELIABILITY IMPROVEMENT, PROCEEDINGS, P253, DOI 10.1109/SSIRI.2009.22
   Li H, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL & 13TH MEDITERRANEAN CONFERENCE ON CONTROL AND AUTOMATION, VOLS 1 AND 2, P429
   Li Liu, 2017, International Journal of Network Security, V19, P327, DOI 10.6633/IJNS.201703.19(3).01
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin SJ, 2009, OPT ENG, V48, DOI 10.1117/1.3168644
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Meghrajani YK, 2016, IEEE SIGNAL PROC LET, V23, P1429, DOI 10.1109/LSP.2016.2599076
   Merchant JL, 2006, PHYSIOLOGY OF THE GASTROINTESTINAL TRACT, VOLS 1 AND 2, 4TH EDITION, P1
   Metri P, 2014, J ENG COMPUT APPLSCI, V3, P51
   Mignotte M, WORKSH CRYPT, P371
   Mohamed Fathimal P., 2015, International Journal of Computer Network and Information Security, V7, P46, DOI 10.5815/ijcnis.2015.07.06
   Nag A, 2013, INT C HET NETW QUAL, P764
   Nag A, 2014, EGYPT INFORM J, V15, P201, DOI 10.1016/j.eij.2014.10.001
   Nag A, 2014, CYBERN INF TECHNOL, V14, P98, DOI 10.2478/cait-2014-0023
   Nair DG, ARXIV150207469
   Naor M., 1997, Security Protocols. International Workshop Proceedings, P197
   Naskar Prabir Kr, 2016, International Journal of Network Security, V18, P68
   Patel A, 2016, INT J SCI RES IJSR, V5, P1867
   Patil S, 2013, INT J COMPUT SCI ISS, V10, P290
   Rajput Aarti PK, 2012, INT J COMPUT APPL, V4, P24
   Rajput M, 2016, PROCEDIA COMPUT SCI, V89, P677, DOI 10.1016/j.procs.2016.06.034
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Sehgal N., 2014, INT J INFORM COMPUTA, V4, P1221
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sharma S, 2013, INT J COMPUTER SCI M, V2, P263
   Shetty S., 2015, INT J INNOVATIVE RES, V3, P3331
   Shyu S-J, 2008, P 25 WORKSH COMB MAT, P24
   Shyu SJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1332, DOI 10.1109/APSCC.2008.223
   Shyu SJ, 2009, J INTERNET TECHNOL, V10, P155
   Shyu SJ, 2009, LECT NOTES COMPUT SC, V5414, P988, DOI 10.1007/978-3-540-92957-4_86
   Singh P, 2017, SIGNAL PROCESS-IMAGE, V57, P46, DOI 10.1016/j.image.2017.04.012
   Surekha B., 2012, Int. J. Comput. Sci. Issues, V9, P312
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thorat SMK, 2016, INT J ADV RES COMPUT, V5, P37
   Tompa M., 1988, Journal of Cryptology, V1, P133
   Tsai M.H., 2013, 6 INT WORKSH IM MED, P135
   Tulasidasu M, 2015, INT CONF COMPUT INTE, P1173, DOI 10.1109/CICN.2015.227
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang K, 2009, P INT COMP SOFTW APP, P400, DOI 10.1109/COMPSAC.2009.60
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang ZH, 2014, JIH MSP, V5, P55
   Wu CC, 2009, IMAGING SCI J, V57, P140, DOI 10.1179/174313109X459887
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Yang CC, 2004, APPL MATH COMPUT, V151, P483, DOI 10.1016/S0096-3003(03)00355-2
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yu-Ting Lin, 2010, 2010 8th IEEE International Conference on Industrial Informatics (INDIN 2010), P437, DOI 10.1109/INDIN.2010.5549704
   Zhenfei Zhao, 2010, Information Technology Journal, V9, P298, DOI 10.3923/itj.2010.298.304
NR 111
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2019
VL 8
IS 4
BP 195
EP 215
DI 10.1007/s13735-018-0161-3
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KN5AU
UT WOS:000514850500002
DA 2024-07-18
ER

PT J
AU Yao, L
   Yang, Y
   Hu, JT
AF Yao, Lu
   Yang, You
   Hu, Juntao
TI Dual-feature collaborative relation-attention networks for visual
   question answering
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Visual question answering; Region feature; Grid feature; Relation
   attention; Positional encoding
AB Region and grid features extracted by object detection networks, which contain abundant image information, are widely used in visual question answering (VQA). The regions focus on object-level features, but the grids are better at representing contextual information and fine-grained attributes of images. However, most of the existing VQA models process visual information with one-way attention, failing to capture the internal relations between objects and analyze the feature details. In this work, we propose a novel multi-level collaborative decoder (MLCD) layer based on the encoder-decoder framework to address this issue, which incorporates visual location vectors into attention. Specifically, each MLCD is equipped with three different attention-MLP sub-modules to progressively and accurately mine the intrinsic interactions of features and enhance the influence of image content on prediction results. Additionally, to fully exploit the respective advantages of two features, we propose a novel relativity-augmented cross-attention (RACA) unit and add it to MLCD, in which the features after simple attention are complementarily augmented using global information and self-attributes. To validate the proposed methods, we stack the MLCD layer deeply to constitute our dual-feature collaborative relation-attention network (DFCRAN). We conduct extensive experiments and visualize the results on three benchmark datasets, including COCO-QA, VQA 1.0, and VQA 2.0, to prove the effectiveness of our model and achieve competitive performances compared to the state-of-the-art single models without pre-training.
C1 [Yao, Lu; Yang, You; Hu, Juntao] Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Yang, You] Natl Ctr Appl Math Chongqing, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP Yang, Y (corresponding author), Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.; Yang, Y (corresponding author), Natl Ctr Appl Math Chongqing, Chongqing 401331, Peoples R China.
EM 2020110516074@stu.cqnu.edu.cn; 20130958@cqnu.edu.cn;
   hjt65190411@gmail.com
FU Chongqing Postgraduate Joint Training Base Project [2019-45]; Start-up
   Fund/Talent Introduction Project of Chongqing Normal University
   [21XLB032]
FX This work was supported by two projects below: Chongqing Postgraduate
   Joint Training Base Project (Grant No. 2019-45), PhD Start-up
   Fund/Talent Introduction Project of Chongqing Normal University
   (21XLB032).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Gao H., 2015, INT C NEURAL INF PRO, P2296
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo B, 2021, INT C LEARNING REPRE
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jiang H, 2020, P IEEECVF C COMPUTER, P276
   Kim JH, 2018, ADV NEUR IN, V31
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lei Ba J., 2016, arXiv
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YC, 2023, IEEE T NEUR NET LEAR, V34, P1932, DOI 10.1109/TNNLS.2021.3105681
   Liu Y, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107956
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2016, ADV NEUR IN, V29
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Mao A., 2022, IEEE T MULTIMED, V2022, P1
   Nguyen DK, 2021, INT C LEARNING REPRE
   Nguyen V, 2022, Arxiv, DOI arXiv:2207.09666
   Peng L, 2022, IEEE T KNOWL DATA EN, V34, P1644, DOI 10.1109/TKDE.2020.2998805
   Peng L, 2022, IEEE T PATTERN ANAL, V44, P318, DOI 10.1109/TPAMI.2020.3004830
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rahman T, 2021, IEEE COMPUT SOC CONF, P1653, DOI 10.1109/CVPRW53098.2021.00181
   Ren MY, 2015, ADV NEUR IN, V28
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P519, DOI 10.1145/3240508.3240513
   Wu CF, 2018, ADV NEUR IN, V31
   Wu M, 2022, P IEEE CVF C COMP VI, p18,020
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang X., 2021, P IEEE INT C COMPUTE, P2197
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu Z, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3743, DOI 10.1145/3394171.3413977
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zeng Yan, 2022, ICML
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhou YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2054, DOI 10.1109/ICCV48922.2021.00208
   Zhou YY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1245, DOI 10.1145/3394171.3413998
NR 47
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 20
DI 10.1007/s13735-023-00283-8
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2XU0
UT WOS:001042508200001
DA 2024-07-18
ER

PT J
AU Kumar, P
   Rawat, P
   Chauhan, S
AF Kumar, Pranjal
   Rawat, Piyush
   Chauhan, Siddhartha
TI Contrastive self-supervised learning: review, progress, challenges and
   future research directions
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Contrastive learning; Self-supervised learning; Unsupervised learning;
   Data augmentation; Survey
ID EMBEDDINGS
AB In the last decade, deep supervised learning has had tremendous success. However, its flaws, such as its dependency on manual and costly annotations on large datasets and being exposed to attacks, have prompted researchers to look for alternative models. Incorporating contrastive learning (CL) for self-supervised learning (SSL) has turned out as an effective alternative. In this paper, a comprehensive review of CL methodology in terms of its approaches, encoding techniques and loss functions is provided. It discusses the applications of CL in various domains like Natural Language Processing (NLP), Computer Vision, speech and text recognition and prediction. The paper presents an overview and background about SSL for understanding the introductory ideas and concepts. A comparative study for all the works that use CL methods for various downstream tasks in each domain is performed. Finally, it discusses the limitations of current methods, as well as the need for additional techniques and future directions in order to make meaningful progress in this area.
C1 [Kumar, Pranjal; Chauhan, Siddhartha] NIT Hamirpur, Hamirpur 177005, Himachal Prades, India.
   [Rawat, Piyush] Univ Petr & Energy Studies, Sch Comp Sci, Dept Syst, Dehra Dun 248007, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; University of Petroleum & Energy Studies (UPES)
RP Kumar, P (corresponding author), NIT Hamirpur, Hamirpur 177005, Himachal Prades, India.
EM pranjal@nith.ac.in; psh.rawat@gmail.com; sid@nith.ac.in
OI KUMAR, PRANJAL/0000-0002-6167-9884
CR Afouras T., 2020, P EUR C COMP VIS, V12363, P208, DOI 10.1007/978-3-030- 58523-5-13
   Al-Tahan H., 2021, PMLR, P2530
   Alayrac J.-B., 2020, NeurIPS, V33, P25
   Albelwi S, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040551
   Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73
   Arandjelovic Relja, 2018, P EUR C COMP VIS ECC, P435
   Arivazhagan Naveen, 2019, ARXIV190705019
   Aroca-Ouellette S, 2020, ARXIV201001694
   Arora S, 2019, PR MACH LEARN RES, V97
   Asai A., 2019, INT C LEARN REPR
   Asano Y., 2020, ADV NEURAL INFORM PR, V33, P4660
   Bachman P, 2019, ADV NEUR IN, V32
   Baevski A., 2020, ADV NEURAL INFORM PR, V33, P12449
   Baevski A., 2019, ARXIV191005453
   Baevski A, 2021, ADV NEURAL INF PROCE, V34
   Baevski A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5360
   Baevski Alexei, 2019, ARXIV191103912
   Bai Y., 2020, ARXIV201113046
   Bao Hangbo, 2021, PROC INT C LEARN REP
   BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhattacharjee A, 2022, ARXIV220312000
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bui NDQ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P511, DOI 10.1145/3404835.3462840
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen L, 2021, FOOD SCI TECHNOL INT, V27, P22, DOI 10.1177/1082013220921597
   Chen M, 2020, PR MACH LEARN RES, V119
   Chen XC, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207010
   Chen X, 2021, IEEE DECIS CONTR P, P4064, DOI 10.1109/CDC45484.2021.9683242
   Cheng Joseph Y, 2020, ARXIV200704871
   Chi Zewen, 2020, ARXIV200707834
   Chiu C-C, 2022, ARXIV220201855
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chuang C.-Y., 2020, ARXIV200700224
   Chuang Gan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5589, DOI 10.1109/CVPR.2018.00586
   Chung Y-A, 2021, ARXIV210806209
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng Yuntian, 2020, 8 INT C LEARN REPR I
   Devlin J, 2019, P 2019 C N AM CHAPT, P4171
   Ding M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2694
   Dunbar E, 2020, ARXIV201005967
   Dunbar E, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P323, DOI 10.1109/ASRU.2017.8268953
   Ermolov A, 2021, PR MACH LEARN RES, V139
   Fang Hongchao, 2020, ARXIV200512766
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300
   Gan Chuang, 2020, P IEEECVF C COMPUTER, P10478, DOI DOI 10.1109/CVPR42600.2020.01049
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894
   Gao ZP, 2021, IEEE INT CONF TRUST, P1177, DOI 10.1109/TrustCom53373.2021.00159
   Ghojogh B, 2019, ARXIV190609436
   Giorgi John M, 2020, ARXIV200603659
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glass O, 2012, ASTERISQUE, P1
   Goldberger J., 2004, Advances in Neural Information Processing Systems, V17
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Gutmann Michael, 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300731
   Han Tengda, 2020, Adv. Neural Inf. Process. Syst., NIPS, V33, P5679
   Han T, 2021, MACROMOL RAPID COMM, V42, DOI 10.1002/marc.202000311
   Hassani K, 2020, PR MACH LEARN RES, V119
   He K., 2021, Masked autoencoders are scalable vision learners
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Heck M, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P740, DOI 10.1109/ASRU.2017.8269011
   Hinton GE, 1993, ADV NEURAL INFORM PR, P3, DOI [DOI 10.1021/JP906511Z, DOI 10.5555/2987189.2987190]
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hjelm R. D., 2020, ARXIV200713278
   Hjelm R Devon, 2018, ARXIV180806670
   Ho Chih-Hui, 2020, P INT C NEUR INF PRO, V33, P17081
   Holmberg OG, 2020, NAT MACH INTELL, V2, P719, DOI 10.1038/s42256-020-00247-1
   Hsu WN, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6533, DOI 10.1109/ICASSP39728.2021.9414460
   Hu D., 2020, Advances in Neural Information Processing Systems, P10077
   Hu D, 2019, PROC CVPR IEEE, P9240, DOI 10.1109/CVPR.2019.00947
   Hu Di, 2020, ARXIV200109414
   Hu QJ, 2021, PROC CVPR IEEE, P1074, DOI 10.1109/CVPR46437.2021.00113
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huynh Tri, 2022, P IEEECVF WINTER C A, P2785
   Ilharco G, 2020, PROBING CONTEXTUAL L, DOI [10.48550/arxiv.2005.00619, DOI 10.48550/ARXIV.2005.00619]
   Ili S, 2018, ARXIV180909795
   Jaegle A, 2021, PR MACH LEARN RES, V139
   Jain P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5954
   Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002
   Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691
   Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163
   Kalantidis Y., 2020, ADV NEURAL INFORM PR, V33, P21798
   Kalantidis Yannis, 2020, P INT C NEUR INF PRO, P21798
   Kawakami K, ARXIV200111128
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kim D, 2019, AAAI CONF ARTIF INTE, P8545
   Knights J, 2021, INT C PATT RECOG, P8914, DOI 10.1109/ICPR48806.2021.9412071
   Kong Quan, 2020, Advances in Neural Information Processing Systems, V33, P8089
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai C.-I, 2019, ARXIV190401575
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lample Guillaume, 2017, UNSUPERVISED MACHINE
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   Le-Khac PH, 2020, IEEE ACCESS, V8, P193907, DOI 10.1109/ACCESS.2020.3031549
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Li B., 2020, arXiv
   Li J., 2020, ICLR
   Li ZL, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1727, DOI 10.1145/3442381.3449859
   Liao D, 2021, ARXIV210604791
   Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Lin Yan-Bo, 2021, ARXIV210400315
   Liu B., 2012, SYNTHESIS LECT HUMAN, V5, P1, DOI [DOI 10.2200/S00416ED1V01Y201204HLT016, 10.2200/s00416ed1v01y201204hlt016]
   Liu X, 2021, IEEE Transactions on Knowledge & Data Engineering
   Liu Yinhan, 2019, ARXIV190711692
   Liu Yunze, 2020, ARXIV201213089
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lorre G, 2020, IEEE WINT CONF APPL, P651, DOI [10.1109/WACV45572.2020.9093278, 10.1109/wacv45572.2020.9093278]
   McCann B., 2017, Advances in neural information processing systems, P1
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Morgado P, 2021, PROC CVPR IEEE, P12470, DOI 10.1109/CVPR46437.2021.01229
   Nagrani A, 2020, INT CONF ACOUST SPEE, P6829, DOI [10.1109/ICASSP40776.2020.9054057, 10.1109/icassp40776.2020.9054057]
   Nandan A, 2020, LANGUAGE AGNOSTIC SP
   Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975
   Pan E, 2021, ADV NEURAL INF PROCE, V34
   Pan T, 2021, PROC CVPR IEEE, P11200, DOI 10.1109/CVPR46437.2021.01105
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Patrick M., 2020, ARXIV200304298
   Peng X, 2021, ARXIV210404676
   Purushwalkam S., 2020, ADV NEURAL INFORM PR, P3407, DOI 10.5555/3495724.3496011
   Qian R, 2021, PROC CVPR IEEE, P6960, DOI 10.1109/CVPR46437.2021.00689
   Radford A., 2019, LANGUAGE MODELS ARE
   Radford A, 2021, PR MACH LEARN RES, V139
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rajpurkar P., 2016, P 2016 C EMP METH NA, V2016, P2383
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Rifai S, 2011, ICML
   Robinson Joshua, 2020, INT C LEARN REPR
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Rui Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P292, DOI 10.1007/978-3-030-58565-5_18
   Saeed A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3875, DOI 10.1109/ICASSP39728.2021.9413528
   Schatz T, 2016, THESIS
   Schneider Steffen, 2019, P INTERSPEECH
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Senocak A, 2021, IEEE T PATTERN ANAL, V43, P1605, DOI 10.1109/TPAMI.2019.2952095
   Senocak A, 2018, PROC CVPR IEEE, P4358, DOI 10.1109/CVPR.2018.00458
   Shor J, 2021, ARXIV211004621
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simoulin A, 2021, EUR CHAPT ASS COMP L
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Stephane A-O, 2020, ARXIV201001694
   Sun Chen., 2019, arXiv
   Sun F.-Y., 2019, ARXIV190801000
   Sun M, 2021, ARXIV210604509
   Sun Siqi, 2020, ARXIV200914167
   Sun ZY, 2022, INT J COAL PREP UTIL, V42, P221, DOI [10.1080/19392699.2019.1590346, 10.1109/eurosime.2019.8724592]
   Tao L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2193, DOI 10.1145/3394171.3413694
   Tao Y, 2021, ARXIV210600131
   Tian Y., 2020, NeurIPS, V33, P6827
   Tokmakov Pavel, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P404, DOI 10.1007/978-3-030-66096-3_28
   Tran Chau, 2021, ARXIV210803265
   Trosten DJ, 2021, PROC CVPR IEEE, P1255, DOI 10.1109/CVPR46437.2021.00131
   Tsai TW, 2020, INT C LEARN REPR
   Tschannen M., 2019, ARXIV190713625
   Vahdat A., 2020, P 34 INT C NEUR INF, V33, P19667
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2016, PR MACH LEARN RES, V48
   vandenOord Aaron, 2018, ARXIV180703748
   Velickovic Petar, 2019, ICLR
   Vincent E, 2008, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.2008.4517558
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang F, 2021, PROC CVPR IEEE, P2495, DOI 10.1109/CVPR46437.2021.00252
   Wang J, 2021, AAAI, V1, P7
   Wang Jiangliu, 2020, ECCV, P504, DOI DOI 10.1007/978-3-030-58520-430
   Wang M, 2021, PROCEEDINGS OF 2021 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS '21), DOI 10.1145/3469213.3470707
   Wang T, 2020, INT C MACH LEARN, P9929, DOI DOI 10.1109/CVPR.2019.00516
   Wang WR, 2020, INT CONF ACOUST SPEE, P6889, DOI [10.1109/icassp40776.2020.9053541, 10.1109/ICASSP40776.2020.9053541]
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wei DL, 2018, PROC CVPR IEEE, P8052, DOI 10.1109/CVPR.2018.00840
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu C., 2021, arXiv
   Wu Lirong., 2021, IEEE Transactions on Knowledge and Data Engineering
   Wu Mike, 2020, ARXIV200513149
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Wu Zhuofeng, 2020, ARXIV201215466
   Xia J, 2022, ARXIV220203104
   Xia J, 2021, ARXIV211002027
   Xiao Fanyi, 2020, ARXIV200108740
   Xie Q., 2019, P ADV NEUR INF PROC
   Xue F, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115967
   Yan Yuanmeng, 2021, ARXIV210511741
   Yang Ceyuan, 2020, ARXIV200615489, P2
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yang K, 2020, IEEE COMPUT SOC CONF, P4069, DOI 10.1109/CVPRW50498.2020.00481
   Yang Z., 2019, NEURIPS, V5754, DOI [DOI 10.1109/ptc.2019.8810867, DOI 10.1080/10495398.2019.1653901]
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369
   Yao Ting, 2021, AAAI, V2, P7
   Yao Y, 2020, PROC CVPR IEEE, P6547, DOI 10.1109/CVPR42600.2020.00658
   You JX, 2018, PR MACH LEARN RES, V80
   You Y, 2020, ADV NEURAL INFORM PR, V33, P5812, DOI [10.48550/arXiv.2010.13902, DOI 10.48550/ARXIV.2010.13902]
   You YN, 2021, PR MACH LEARN RES, V139
   Zeng J, 2020, ARXIV200905923
   Zhan XH, 2020, PROC CVPR IEEE, P6687, DOI 10.1109/CVPR42600.2020.00672
   Zhang LW, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107805
   Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76
   Zhang S, 2020, SELF SUPERVISED REPR
   Zhang Y, 2021, ARXIV210913226
   Zhang Yu, 2020, ARXIV201010504
   Zhao C, 2020, ADV FUNCT MATER, V30, DOI 10.1002/adfm.202000776
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhu YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2069, DOI 10.1145/3442381.3449802
   Zhuang C., 2020, P IEEECVF C COMPUTER, P9563
   Zhuang CX, 2019, IEEE I CONF COMP VIS, P6001, DOI 10.1109/ICCV.2019.00610
   Zimmermann Roland S, 2021, INT C MACHINE LEARNI, P12979
NR 218
TC 10
Z9 11
U1 11
U2 52
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 461
EP 488
DI 10.1007/s13735-022-00245-6
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000900107300001
DA 2024-07-18
ER

PT J
AU Dagar, D
   Vishwakarma, DK
AF Dagar, Deepak
   Vishwakarma, Dinesh Kumar
TI A literature review and perspectives in deepfakes: generation,
   detection, and applications
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Deepfake; Face-swap; Face reenactment; Lip-sync; Body-puppetry; Speech
   synthesis; Deep learning
ID VOICE CONVERSION; FEATURE-EXTRACTION; UNIFIED FRAMEWORK; NEURAL-NETWORK;
   IMAGES; ATTENTION; PRESERVATION; MANIPULATION; MODEL; SPOOF
AB In the last few years, with the advancement of deep learning methods, especially Generative Adversarial Networks (GANs) and Variational Auto-encoders (VAEs), fabricated content has become more realistic and believable to the naked eye. Deepfake is one such emerging technology that allows the creation of highly realistic, believable synthetic content. On the one hand, Deepfake has paved the way for highly advanced applications in various fields like advertising, creative arts, and film productions. On the other hand, it poses a threat to various Multimedia Information Retrieval Systems (MIPR) such as face recognition and speech recognition systems and has more significant societal implications in spreading misleading information. This paper aims to assist an individual in understanding the deepfake technology (along with its application), current state-of-the-art methods and gives an idea about the future pathway of this technology. In this paper, we have presented a comprehensive literature survey on the application of deepfakes, followed by discussions on state-of-the-art methods for deepfake generation and detection for three media: Image, Video, and Audio. Next, we have extensively discussed the architectural components and dataset used for various methods of deepfakes. Furthermore, we discuss the various limitations and open challenges of deepfakes to identify the research gaps in this field. Finally, discuss the conclusion and future directions to explore the potential of this technology in the coming years.
C1 [Dagar, Deepak; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi 110042, India.
EM dvishwakarma@gmail.com
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047
CR Aberman K, 2019, EUROPEAN ASS COMPUTE
   Agarwal S, 2021, IEEE CVF C COMP VIS
   Agarwal S, 2020, IEEE COMPUT SOC CONF, P2814, DOI 10.1109/CVPRW50498.2020.00338
   AlBadawy EA, 2019, IEEE CVF C COMP VIS
   Amerini I, 2020, ACM WORKSHOP INFORM
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], 2019, CONTRIBUTING DATA DE
   [Anonymous], 2017, Advances in Neural Information Processing Systems
   [Anonymous], RESEMBLE AI
   [Anonymous], 2016, DEEPFAKES FACESWAP
   [Anonymous], RUDRABHA WAV2LIP
   [Anonymous], 2016, LECT NOTES COMPUTER
   Arik SO, 2017, PR MACH LEARN RES, V70
   Balamurli B, 2019, IEEE ACCESS
   Bing Han, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P320, DOI 10.1109/TBIOM.2021.3065735
   Bonomi M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103239
   Borrelli C, 2021, EURASIP J INF SECUR, V2021, DOI 10.1186/s13635-021-00116-3
   Brock A., 2019, INT C LEARN REPR
   Brown J, 2017, IEEE INT CON INF VIS, P29, DOI 10.1109/iV.2017.52
   Caldelli R, 2021, PATTERN RECOGN LETT, V146, P31, DOI 10.1016/j.patrec.2021.03.005
   Cao M, 2021, IEEE T IMAGE PROCESS, V30, P6107, DOI 10.1109/TIP.2021.3089909
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chen BJ, 2021, INFORM SCIENCES, V572, P16, DOI 10.1016/j.ins.2021.05.006
   Chen H.-S., 2021, IEEE INT C MULTIMEDI
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Chen MJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5949, DOI 10.1109/ICASSP39728.2021.9415042
   Chen P, 2021, IEEE INT C MULTIMEDI
   Chen T, 2020, OD 2020 SPEAK LANG R
   Chen Y., 2019, INT C LEARN REPR ICL, P1
   Chen Z, 2021, IEEE INT C AC SPEECH
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   Choi DH, 2020, IEEE IMAGE PROC, P823, DOI [10.1109/icip40778.2020.9190655, 10.1109/ICIP40778.2020.9190655]
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chugh K, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P439, DOI 10.1145/3394171.3413700
   Chung JS, 2018, INTERSPEECH, P1086
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   Cong J, 2020, INTERSPEECH, P811, DOI 10.21437/Interspeech.2020-2530
   Cozzolino D, 2019, ARXIV
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Damiani J., 2019, FORBES
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Das S., 2021, P IEEE CVF INT C COM, P3776, DOI 10.1109/ICCVW54120.2021.00421
   Deepfakes web, ONL DEEPF MAK
   Demir I., 2021, ACM S EYE TRACKING R
   DepFaceLab, GITHUB
   Ding Shaojin, 2020, INTERSPEECH
   Ding XY, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-00109-8
   Dolhansky B, 2019, ARXIV
   Dolhansky B., 2020, arXiv
   Dong X., 2020, arXiv
   Doublicat, HI ITS REF PLAC ENDL
   Doukas Michail Christos, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P31, DOI 10.1109/TBIOM.2021.3049576
   Du MN, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P325, DOI 10.1145/3340531.3411892
   Durall R., 2020, ARXIV
   FaceApp, MOST POPULARSELFIE E
   faceplusplus, Face++
   FakeApp, FAKEAPP IS PROGR LET
   Fernando T, 2019, ARXIV
   Frank Joel, 2020, INT C MACH LEARN, P3247
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Fu CY, 2021, IEEE T INF FOREN SEC, V16, P2218, DOI 10.1109/TIFS.2021.3050065
   Gafni Oran, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P882, DOI 10.1109/CVPR46437.2021.00094
   GMAIL, M AILABS SPEECH DAT
   Gomez-Alanis A, 2019, INTERSPEECH, P1068, DOI 10.21437/Interspeech.2019-2212
   Gomez-Alanis A, 2019, IEEE-ACM T AUDIO SPE, V27, P1985, DOI 10.1109/TASLP.2019.2937413
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu KX, 2020, AAAI CONF ARTIF INTE, V34, P10861
   Gu Z., 2021, P 29 ACM INT C MULTI, P3473
   Guarnera L, 2020, IEEE COMPUT SOC CONF, P2841, DOI 10.1109/CVPRW50498.2020.00341
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Gunendradasan T, 2019, INT CONF ACOUST SPEE, P6136, DOI 10.1109/ICASSP.2019.8682771
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   He PS, 2019, IEEE IMAGE PROC, P2299, DOI [10.1109/icip.2019.8803740, 10.1109/ICIP.2019.8803740]
   He Q, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5689, DOI 10.1109/ICASSP39728.2021.9414809
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hernandez-Ortega J., 2020, arXiv
   Hosier BC, 2020, IEEECVF C COMPUTER V
   Hosler B, 2021, IEEE COMPUT SOC CONF, P1013, DOI 10.1109/CVPRW53098.2021.00112
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Hu J, IEEE INT C IMAGE PRO
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Hu S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2500, DOI 10.1109/ICASSP39728.2021.9414582
   Huang J, 2021, IEEECVF INT C COMPUT
   Huang L, 2021, 2 INT C ARTIFICIAL I
   Huang L, 2020, IEEE-ACM T AUDIO SPE, V28, P1813, DOI 10.1109/TASLP.2020.2998870
   Huang L, 2019, INT CONF ACOUST SPEE, P2567, DOI [10.1109/icassp.2019.8682573, 10.1109/ICASSP.2019.8682573]
   Ito K., 2017, The LJ Speech Dataset
   Jaiman A, 2020, POSITIVE USES DEEPFA
   Jamaludin A, 2019, INT J COMPUT VISION, V127, P1767, DOI 10.1007/s11263-019-01150-y
   Jeon H, 2019, IEEE INT CONF COMP V, P1285, DOI 10.1109/ICCVW.2019.00163
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Juefei-Xu F, 2021, ARXIV
   Jung J.w., 2019, In INTERSPEECH
   Kameoka H, 2021, IEEE-ACM T AUDIO SPE, V29, P656, DOI 10.1109/TASLP.2020.3047262
   Kameoka H, 2020, IEEE-ACM T AUDIO SPE, V28, P1849, DOI 10.1109/TASLP.2020.3001456
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Katneoka H, 2019, IEEE-ACM T AUDIO SPE, V27, P1432, DOI 10.1109/TASLP.2019.2917232
   Kaur N, 2020, FORENSIC SCI MED PAT, V16, P481, DOI 10.1007/s12024-020-00230-7
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Khan SA, 2021, P 29 ACM INT C MULTI
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kim M, 2021, IEEE COMPUT SOC CONF, P1001, DOI 10.1109/CVPRW53098.2021.00111
   Kinnunen T, 2017, INTERSPEECH, P2, DOI 10.21437/Interspeech.2017-1111
   Kominek J., 2004, PROC 5 ISCA WORKSHOP, P223
   Koopman M, 2018, IRISH MACHINE VISION
   Korshunov P., 2018, arXiv
   Lahiri Avisek, 2021, IEEE CVF C COMP VIS
   Lai CI, 2019, INT CONF ACOUST SPEE, P6316, DOI 10.1109/ICASSP.2019.8682640
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Lee J, 2019, PR MACH LEARN RES, V97
   Lee S, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107256
   Lee S, 2020, INT CONF ACOUST SPEE, P6279, DOI [10.1109/ICASSP40776.2020.9053726, 10.1109/icassp40776.2020.9053726]
   Li G., 2021, IEEE INT C IMAGE PRO
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   Li LZ, 2020, PROC CVPR IEEE, P5073, DOI 10.1109/CVPR42600.2020.00512
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li X, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6354, DOI 10.1109/ICASSP39728.2021.9413828
   Li XR, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P88, DOI 10.1145/3366424.3382711
   Li Y, 2019, IEEECVF C COMPUTER V
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li ZH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7073, DOI 10.1109/ICASSP39728.2021.9414137
   Liang HB, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P79, DOI 10.1145/3474085.3475454
   Lima O.F., 2020, arXiv
   Liu LJ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3333002
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu R, 2019, INT S SIGN PROC SYST
   Liu R, 2021, IEEE-ACM T AUDIO SPE, V29, P1806, DOI 10.1109/TASLP.2021.3076369
   Liu RL, 2020, INT CONF ACOUST SPEE, P7759, DOI [10.1109/icassp40776.2020.9054523, 10.1109/ICASSP40776.2020.9054523]
   Trinh L, 2021, IEEE WINT CONF APPL, P1972, DOI 10.1109/WACV48630.2021.00202
   Lu C, IEEE INT C IMAGE PRO
   Lugstein F, 2021, PROCEEDINGS OF THE 2021 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, IH&MMSEC 2021, P7, DOI 10.1145/3437880.3460400
   Luo AW, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6359, DOI 10.1109/ICASSP39728.2021.9414670
   Luo Z, IEEE INT C IMAGE PRO
   MachineTube, US
   Maheshwari H, 2021, DATA SCI
   Maheshwari H, TEXT SPEECH SYSTEM M
   Malik H, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P512, DOI 10.1109/MIPR.2019.00104
   Martin K, WHAT IS VOICE CLONIN
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Masood M., 2021, ARXIV
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S., 2018, ARXIV
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Mittal T, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2823, DOI 10.1145/3394171.3413570
   Montserrat DM, 2020, IEEE COMPUT SOC CONF, P2851, DOI 10.1109/CVPRW50498.2020.00342
   Nagrani A, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101027
   Nguyen HH, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185974
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen T. T., 2019, arXiv
   Nguyen X., 2021, FORENSIC SCI INT DIG, DOI 10.1016/j.fsidi.2021.301108
   Nirkin Y, 2020, ARXIV
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Ouyang M, 2021, INT S CHINESE SPOKEN
   OWASP, 2020, DEEPFAKES HARMS THRE
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Patil HA, 2018, ASIAPAC SIGN INFO PR, P1047, DOI 10.23919/APSIPA.2018.8659666
   Peng B, 2022, IEEE T CIRC SYST VID, V32, P3673, DOI 10.1109/TCSVT.2021.3106047
   Ping Wei, 2018, INT C LEARNING REPRE
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Qi H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4318, DOI 10.1145/3394171.3413707
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Reimao R, 2019, 2019 10TH INTERNATIONAL CONFERENCE ON SPEECH TECHNOLOGY AND HUMAN-COMPUTER DIALOGUE (SPED), DOI 10.1109/sped.2019.8906599
   Ren Y, 2021, IEEE INT C IMAGE PRO
   Renwang Chen, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2003, DOI 10.1145/3394171.3413630
   Rizzotto L, 2019, DEEPFAKE ADS 4 DEC 2
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Rossler A., 2018, arXiv
   Sabir E, 2019, ARXIV
   Sabir Ekraam, 2019, CVPRW, V3
   Sanchez E, 2020, IEEE INT CONF AUTOMA, P53, DOI 10.1109/FG47880.2020.00015
   Saranya MS, 2018, INT CO SIG PROC COMM, P332, DOI 10.1109/SPCOM.2018.8724469
   Shang ZH, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107950
   Shen YT, 2020, PROC CVPR IEEE, P6367, DOI 10.1109/CVPR42600.2020.00640
   Shen YJ, 2022, IEEE T PATTERN ANAL, V44, P2004, DOI 10.1109/TPAMI.2020.3034267
   Shim HJ, 2018, CONF TECHNOL APPL, P172, DOI 10.1109/TAAI.2018.00046
   Singh J, 2018, TOWARDSDATASCIE 1107
   Sisman B, 2021, IEEE-ACM T AUDIO SPE, V29, P132, DOI 10.1109/TASLP.2020.3038524
   Sohrawardi SJ, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P2613, DOI 10.1145/3319535.3363269
   Strickland E, 2019, IEEE
   Sun X., 2020, ARXIV
   Sun ZK, 2021, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR46437.2021.00361
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tanaka K, 2019, INT CONF ACOUST SPEE, P6805, DOI [10.1109/icassp.2019.8683282, 10.1109/ICASSP.2019.8683282]
   Tariq Shahroz, 2019, SAC '19: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, P1296, DOI 10.1145/3297280.3297410
   Tariq S, P WEB C 2021
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201350
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tripathy S, 2021, IEEE WINT CONF APPL, P1328, DOI 10.1109/WACV48630.2021.00137
   Tripathy S, 2020, IEEE WINT CONF APPL, P3374, DOI [10.1109/wacv45572.2020.9093474, 10.1109/WACV45572.2020.9093474]
   Tu Y, INT C MACHINE LEARNI
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   Veaux C., 2016, CSTR VCTK corpus: English multi-speaker corpus for CSTR voice cloning toolkit
   Veaux C., 2013, SPEECH LANGUAGE PROC
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wang R, 2021, P 29 ACM INT C MULTI
   Wang R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3444
   Wang RB, 2020, INT CONF ACOUST SPEE, P7729, DOI [10.1109/ICASSP40776.2020.9053842, 10.1109/icassp40776.2020.9053842]
   Wang S.Y., 2020, IEEECVF C COMPUTER V
   Wang T.-C., 2019, Advances in Neural Information Processing Systems (NeurIPS)
   Wang X., 2020, P 28 ACM INT C MULT
   Wang X, 2020, COMPUT SPEECH LANG, V64, DOI [10.1016/j.csl.2020.101114, 10.1016/j.csi.2020.101114]
   Wang Z, 2020, ASIAPAC SIGN INFO PR, P1352
   Weiss RJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5679, DOI 10.1109/ICASSP39728.2021.9413851
   Wijethunga R. L. M. A. P., 2020, 2020 2nd International Conference on Advancements in Computing (ICAC), P192, DOI 10.1109/ICAC51239.2020.9357161
   Wu X, 2020, INT CONF ACOUST SPEE, P2952, DOI [10.1109/icassp40776.2020.9053969, 10.1109/ICASSP40776.2020.9053969]
   Wu ZZ, 2020, INTERSPEECH, P1101, DOI 10.21437/Interspeech.2020-1810
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2037
   Xiaodan Li, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P1864, DOI 10.1145/3394171.3414034
   Xu ZP, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103119
   Xuan XS, 2019, LECT NOTES COMPUT SC, V11818, P134, DOI 10.1007/978-3-030-31456-9_15
   Yang CZ, 2021, IEEE T INF FOREN SEC, V16, P1841, DOI 10.1109/TIFS.2020.3045937
   Yang JC, 2021, IEEE T INF FOREN SEC, V16, P4234, DOI 10.1109/TIFS.2021.3102487
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
   Yang JC, 2020, DIGIT SIGNAL PROCESS, V97, DOI 10.1016/j.dsp.2019.102622
   Yang J, 2023, INT J ENVIRON AN CH, V103, P2168, DOI 10.1080/03067319.2021.1890057
   Yang N, 2021, IEEE T IMAGE PROCESS, V30, P6198, DOI 10.1109/TIP.2021.3089905
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yasrab R, 2021, FORECASTING-BASEL, V3, P303, DOI 10.3390/forecast3020020
   Yasuda Y, 2019, INT CONF ACOUST SPEE, P6905, DOI [10.1109/icassp.2019.8682353, 10.1109/ICASSP.2019.8682353]
   You CH, 2020, IEEE-ACM T AUDIO SPE, V28, P2308, DOI 10.1109/TASLP.2020.3011320
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Yu PP, 2021, IET BIOMETRICS, V10, P607, DOI 10.1049/bme2.12031
   Zablotskaia Polina, 2019, BRIT MACH VIS C BMVC
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zao, DOWNL ZAOFREE ZAO AP
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang J., 2021, IEEE INT C MULTIMEDI
   Zhang J., 2019, arXiv
   Zhang JX, 2020, IEEE-ACM T AUDIO SPE, V28, P540, DOI 10.1109/TASLP.2019.2960721
   Zhang JX, 2019, IEEE-ACM T AUDIO SPE, V27, P631, DOI 10.1109/TASLP.2019.2892235
   Zhang LH, 2022, IEEE T CIRC SYST VID, V32, P2226, DOI 10.1109/TCSVT.2021.3089724
   Zhang MY, 2021, IEEE-ACM T AUDIO SPE, V29, P1290, DOI 10.1109/TASLP.2021.3066047
   Zhang MY, 2020, SPEECH COMMUN, V122, P31, DOI 10.1016/j.specom.2020.05.004
   Zhang Y., 2019, arXiv
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhao Y, 2019, INT C INFORM COMMUNI
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhou X, 2020, IEEE 3 INT C SAFE PR
   Zhou X, 2021, IEEE-ACM T AUDIO SPE, V29, P2643, DOI 10.1109/TASLP.2021.3093823
   Zhou YP, 2019, IEEE INT CONF COMP V, P1208, DOI 10.1109/ICCVW.2019.00153
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu YH, 2021, PROC CVPR IEEE, P4832, DOI 10.1109/CVPR46437.2021.00480
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
   Zhuang YX, 2019, IEEE IMAGE PROC, P3212, DOI [10.1109/icip.2019.8803464, 10.1109/ICIP.2019.8803464]
   Zi BJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2382, DOI 10.1145/3394171.3413769
NR 255
TC 10
Z9 10
U1 26
U2 87
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 219
EP 289
DI 10.1007/s13735-022-00241-w
EA JUL 2022
PG 71
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000830306800002
DA 2024-07-18
ER

PT J
AU Zumer, R
   Ratté, S
AF Zumer, Raphael
   Ratte, Sylvie
TI Color-independent classification of animation video
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Animation video; Medium-based classification; Color independence;
   Spatiotemporal features
AB This paper presents a method for the classification of animated video that does not rely on hue or saturation information, and aims to achieve a high level of performance in the context of automatic video categorization and encoder parameterization for low bit rate video processing. While existing animated and genre-based video classification approaches have achieved good results, they are highly dependent on color extraction and thus cannot be used to accurately analyze grayscale video content and realistic animation styles, such as pixilation, where the color palette is not sufficiently distinct from live action content. We first introduce a dataset specifically designed to test animation video classification with a high variety of visual content. We then present a set of hue-independent features based on spatial and temporal characteristics of animation video, which are used to perform the classification task. Most of these features have not previously been utilized in existing animation video classification approaches. Finally, an overview of test results, representing a success rate of over 80%, proves the viability of the proposed classification method.
C1 [Zumer, Raphael; Ratte, Sylvie] Ecole Technol Super, Dept Software & IT Engn, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada
RP Ratté, S (corresponding author), Ecole Technol Super, Dept Software & IT Engn, Montreal, PQ, Canada.
EM Raphael.Zumer.1@ens.etsmtl.ca; Sylvie.Ratte@etsmtl.ca
RI RattÃ©, Sylvie/ABU-0444-2022
OI Ratte, Sylvie/0000-0002-6021-4129
CR [Anonymous], 2002, P INT C IM PROC
   [Anonymous], 2001, PROC IEEE COMPUT SOC
   Dammak N, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P106, DOI 10.1109/ATSIP.2014.6834586
   Duarte LA, 2016, SIBGRAPI, P257, DOI [10.1109/SIBGRAPI.2016.043, 10.1109/SIBGRAPI.2016.40]
   Ekenel H.K., 2010, Proceedings of the 3rd international workshop on Automated information extraction in media production, P21, DOI DOI 10.1145/1877850.1877858
   Ionescu B, 2013, UNIV POLIT BUCHAR S, V75, P63
   Ionescu B, 2012, LECT NOTES COMPUT SC, V7131, P51
   Ionescu BE, 2014, MULTIMED TOOLS APPL, V70, P1007, DOI 10.1007/s11042-012-1097-x
   Jang WD, 2014, INT C PATT RECOG, P2655, DOI 10.1109/ICPR.2014.459
   Kim S, 2013, INT CONF ACOUST SPEE, P798, DOI 10.1109/ICASSP.2013.6637758
   Mironica I, 2016, MULTIMED TOOLS APPL, V75, P9045, DOI 10.1007/s11042-015-2819-7
   Rouvier M, 2015, IEEE-ACM T AUDIO SPE, V23, P1031, DOI 10.1109/TASLP.2014.2387411
   Safdarnejad Seyed Morteza, 2014, 2014 IEEE International Conference on Image Processing (ICIP), P1001, DOI 10.1109/ICIP.2014.7025201
   Saz O, 2014, IEEE W SP LANG TECH, P118, DOI 10.1109/SLT.2014.7078560
   Simoes GS, 2016, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2016.7727207
   Uijlings J, 2015, INT J MULTIMED INF R, V4, P33, DOI 10.1007/s13735-014-0069-5
   Wehrmann J., 2017, P S APPL COMP, P114
   Wehrmann J, 2016, PROCEEDINGS OF 2016 5TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS 2016), P1, DOI [10.1109/BRACIS.2016.012, 10.1109/BRACIS.2016.11]
   Yuan X, 2006, IEEE IMAGE PROC, P2905, DOI 10.1109/ICIP.2006.313037
NR 23
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2018
VL 7
IS 3
BP 187
EP 196
DI 10.1007/s13735-018-0146-2
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HI5SF
UT WOS:000456513600004
DA 2024-07-18
ER

PT J
AU Mourao, A
   Magalhaes, J
AF Mourao, Andre
   Magalhaes, Joao
TI Balancing search space partitions by sparse coding for distributed
   redundant media indexing and retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Search space partitioning; High-dimensional indexing; Dictionary design;
   Distributed search; Approximate nearest neighbor search
ID NEAREST-NEIGHBOR; QUANTIZATION; ALGORITHMS; SELECTION
AB Effective partitioning multimedia indexes is key for efficient kNN search. But existing algorithms are based on document similarity, without partition size or redundancy constraints. Our goal is to create an index partitioning algorithm that addresses the specific properties of a distributed system: load balancing across nodes, redundancy in node failure and efficient node usage under concurrent querying. We propose the representation of data with overcomplete codebooks. Each document is quantized into a small set of codewords and indexed on per-codeword partitions. Quantization algorithms are designed to fit data as best as possible, leading to a bias toward codewords that fit the principal directions of data in the original space. In this paper, we propose the balanced KSVD (B-KSVD) algorithm: It distributes data uniformly across codewords, according to the distribution in the original space. The comprehensive experiments focused on measuring the effectiveness of partition size balancing and retrieval quality. Results show that B-KSVD better balances partition sizes (i.e., lower SD in partition size distribution), compared to k-means and KSVD baselines. B-KSVD achieves 38% 1-recall by inspecting only 1% of the full index, distributed over 10 partitions. k-means creates partitions with higher size variation and requires either larger codebooks or the inspection of larger portions of the index to achieve similar retrieval performance.
C1 [Mourao, Andre; Magalhaes, Joao] Univ Nova Lisboa, Fac Ciencias & Tecnol, NOVA LINCS, Caparica, Portugal.
C3 Universidade Nova de Lisboa
RP Mourao, A (corresponding author), Univ Nova Lisboa, Fac Ciencias & Tecnol, NOVA LINCS, Caparica, Portugal.
EM a.mourao@campus.fct.unl.pt; jmag@fct.unl.pt
RI Magalhaes, Joao/A-2054-2010
OI Magalhaes, Joao/0000-0001-6290-5719; Mourao, Andre/0000-0002-9912-4235
FU CMU Portugal research project GoLocal [CMUP-ERI/TIC/0033/2014]; H ICT
   project COGNITUS [687605]; project NOVA LINCS [UID/CEC/04516/2013]; 
   [SFRH/BD/95064/2013]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/95064/2013] Funding Source: FCT
FX This work has been partially funded by the CMU Portugal research project
   GoLocal Ref. CMUP-ERI/TIC/0033/2014, by the H2020 ICT project COGNITUS
   with the Grant Agreement No. 687605, by the project NOVA LINCS Ref.
   UID/CEC/04516/2013 and by the Ph.D. scholarship Grant
   SFRH/BD/95064/2013.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 2015, ACM ICMR 15
   [Anonymous], 2011, NEURAL INFORM PROCES
   [Anonymous], ACM ICMR 15
   [Anonymous], 2010, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-009-0339-z
   [Anonymous], 1993, ORTHOGONAL MATCHING
   [Anonymous], 2011, INT WORKSH CONT BAS
   [Anonymous], RIDGE REGRESSION
   [Anonymous], ARXIV11023828
   [Anonymous], P OF BMVC
   [Anonymous], P OF BMVC
   [Anonymous], 1981, PATTERN RECOGNITIONW
   [Anonymous], 2009, NEURIPS
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Babenko Artem, 2016, P IEEE CVPR
   Buttcher S., 2010, Information Retrieval-Implementing and Evaluating Search Engines
   Cherian A, 2014, IEEE T IMAGE PROCESS, V23, P3646, DOI 10.1109/TIP.2014.2324280
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Grauman K., 2013, Machine Learning for Computer Vision, V411, P49, DOI 10.1007/978-3-642-28661-2_3
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Karger DavidR., 1997, P 29 ANN ACM S THEOR, P654, DOI DOI 10.1145/258533.258660
   Kulkarni Anagha., 2010, P 19 ACM INT C INFOR, P449, DOI DOI 10.1145/1871437.1871497
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Magalhaes Joao, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P815, DOI 10.1145/1277741.1277923
   Moise D., 2013, Proceedings of the 3rd ACM International conference on multimedia retrieval - ICMR'13, P17, DOI DOI 10.1145/2461466.2461470
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Thaler DG, 1998, IEEE ACM T NETWORK, V6, P1, DOI 10.1109/90.663936
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Weiss Y., 2008, NIPS, V9, P6
   Yang Z, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P556, DOI 10.1109/ICICISYS.2009.5358101
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 42
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2018
VL 7
IS 1
SI SI
BP 57
EP 70
DI 10.1007/s13735-017-0140-0
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GB9SN
UT WOS:000429414200006
DA 2024-07-18
ER

PT J
AU Khemakhem, F
   Ltifi, H
AF Khemakhem, Faten
   Ltifi, Hela
TI Neural style transfer generative adversarial network (NST-GAN) for
   facial expression recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Facial expression recognition; Identity-free expression; Neural style
   transfer generative adversarial network
ID FACE
AB With the increasing number of intelligent human-computer systems, more and more research is focusing on human emotion recognition. Facial expressions are an effective modality in emotional recognition, enhancing automatic emotional analysis. Although significant studies have investigated automatic facial expression recognition in the past decades, previous works were mainly produced for controlled environments. Unlike recent pure CNN-based works, we argue that it is practical and feasible to recognize an expression from a facial image. However, the extracted features may capture more identity-related information and are not purely associated with the specific task of expression recognition. To reduce the personal influence of identity-related features by removing identity information from facial images, we propose a neural style transfer generative adversarial network (NST-GAN) in this paper. The objective is to determine the expression information from the input image by removing identity information and transferring it to a synthetic identity. We employ experimental strategies to evaluate the proposed method on three public facial expression databases (CK+, FER-2013, and JAFFE). Extensive experiments prove that our NST-GAN outperforms other methods, setting a new state of the art.
C1 [Khemakhem, Faten; Ltifi, Hela] Univ Sfax, Natl Sch Engineers, Res Grp Intelligent Machines, Sfax, Tunisia.
   [Khemakhem, Faten] Univ Sfax, Fac Econ & Management, Dept Comp Sci, Sfax, Tunisia.
   [Ltifi, Hela] Univ Kairouan, Fac Sci & Tech Sidi Bouzid, Dept Comp Sci, Kairouan, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Faculty of Sciences Sfax; Universite de Monastir;
   Universite de Kairouan
RP Khemakhem, F; Ltifi, H (corresponding author), Univ Sfax, Natl Sch Engineers, Res Grp Intelligent Machines, Sfax, Tunisia.; Khemakhem, F (corresponding author), Univ Sfax, Fac Econ & Management, Dept Comp Sci, Sfax, Tunisia.; Ltifi, H (corresponding author), Univ Kairouan, Fac Sci & Tech Sidi Bouzid, Dept Comp Sci, Kairouan, Tunisia.
EM f.khemakhem@mac.gov.tn; hela.ltifi@ieee.org
RI LTIFI, Hela/K-5469-2012
FU Faten Khemakhem and Hela Ltifi declare that they have no affiliations
   with or involvement in any organization or entity with any financial
   interest, or non-financial interest in the subject matter or materials
   discussed in this manuscript.
FX Faten Khemakhem and Hela Ltifi declare that they have no affiliations
   with or involvement in any organization or entity with any financial
   interest, or non-financial interest in the subject matter or materials
   discussed in this manuscript.
CR [Anonymous], 2019, I C COMP SYST APPLIC, DOI DOI 10.1109/aiccsa47632.2019.9035249
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Chen J, 2014, FACIAL EXPRESSION RE
   Dhall A., 2014, PROC ICMI, P461, DOI DOI 10.1145/2663204.2666275
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Han DM, 2018, EXPERT SYST APPL, V95, P43, DOI 10.1016/j.eswa.2017.11.028
   Hertel L., 2015, 2015 INT JOINT C NEU, P1
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Khorrami P, 2016, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2016.7532431
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu ZT, 2017, IEEE-CAA J AUTOMATIC, V4, P668, DOI 10.1109/JAS.2017.7510622
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Martinez, 2016, ADV FACE DETECTION F, P63, DOI [DOI 10.1007/978-3-319-25958-1_4, 10.1007/978-3-319-25958-1_4]
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pramerdorfer C, 2016, Arxiv, DOI arXiv:1612.02903
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Souibgui MA, 2022, IEEE T PATTERN ANAL, V44, P1180, DOI 10.1109/TPAMI.2020.3022406
   Tao LL, 2016, IEEE INTELL SYST, V31, P19, DOI 10.1109/MIS.2016.25
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Xie WC, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106966
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
NR 35
TC 0
Z9 0
U1 6
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 26
DI 10.1007/s13735-023-00285-6
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P9KN6
UT WOS:001053793800003
DA 2024-07-18
ER

PT J
AU Zhou, LP
   Yang, J
AF Zhou, Liuping
   Yang, Jing
TI Video anomaly detection with memory-guided multilevel embedding
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video anomaly detection; Prototype; Memory; Multilevel embedding
AB Playing a vitally important role in the operation of intelligent video surveillance system and smart city, video anomaly detection (VAD) has been widely practiced and studied in both industrial circles and academia. In the present study, a new anomaly detection method is proposed for multi-level memory embedding. According to the novel method, the feature prototype of the sample is stored in the memory pool, which enhances the diversity of the sample feature prototype paradigm. Besides, the memory is embedded in the decoder in a hierarchical integrating manner, which makes the feature information of the object more complete and improves the quality of features. At the end of the model, modeling is performed for the channel relationship between the features of the object in the channel dimension, thus making the model capable of more efficient anomaly detection. This method is verified by conducting evaluation on three publicly available datasets: UCSD Ped2, CUHK Avenue, ShanghaiTech.
C1 [Zhou, Liuping; Yang, Jing] Guang Zhou Railway Ploytech, Sch Informat Engn, Guangzhou 510430, Peoples R China.
   [Yang, Jing] St Paul Univ Phillippines, Tuguegarao City 3500, Cagayan, Philippines.
RP Zhou, LP (corresponding author), Guang Zhou Railway Ploytech, Sch Informat Engn, Guangzhou 510430, Peoples R China.
EM zhouliuping73@126.com; yangjing@gtxy.edu.cn
CR Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Gong MG, 2020, NEURAL NETWORKS, V122, P364, DOI 10.1016/j.neunet.2019.11.002
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Suarez JJP, 2020, Arxiv, DOI arXiv:2009.14146
   Kanu-Asiegbu AM, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9660004
   Kim J, 2009, PROC CVPR IEEE, P2913
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latecki LJ, 2007, LECT NOTES ARTIF INT, V4571, P61
   Laxhammar R, 2009, FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P756
   Le VT, 2023, APPL INTELL, V53, P3240, DOI 10.1007/s10489-022-03613-1
   Li B, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103249
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu YW, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909850
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Ma JS, 2003, IEEE IJCNN, P1741
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Paffenroth R, 2013, IEEE J-STSP, V7, P38, DOI 10.1109/JSTSP.2012.2237381
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Peng JL, 2021, LASER OPTOELECTRON P, V58, DOI 10.3788/LOP202158.0600004
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ristea N.-C., 2022, P IEEECVF C COMPUTER, P13576, DOI 10.1109/CVPR52688.2022
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Medel JR, 2016, Arxiv, DOI arXiv:1612.00390
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024
   Tao X., 2022, IEEE Transactions on Instrumentation and Measurement, V71, P1
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Wang GD, 2022, LECT NOTES COMPUT SC, V13670, P494, DOI 10.1007/978-3-031-20080-9_29
   Wang HX, 2017, PATTERN RECOGN, V63, P268, DOI 10.1016/j.patcog.2016.10.014
   Xia GY, 2021, IEEE T NEUR NET LEAR, V32, P1612, DOI 10.1109/TNNLS.2020.2985817
   Xu D, 2015, Arxiv, DOI [arXiv:1510.01553, DOI 10.48550/ARXIV.1510.01553]
   Yang J, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108874
   Yu G, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P583, DOI 10.1145/3394171.3413973
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zaheer MZ, 2022, PROC CVPR IEEE, P14724, DOI 10.1109/CVPR52688.2022.01433
   Zaigham Zaheer Muhammad, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14171, DOI 10.1109/CVPR42600.2020.01419
   Zhang CX, 2019, AAAI CONF ARTIF INTE, P1409
   Zhang XX, 2018, IEEE T CIRC SYST VID, V28, P3066, DOI 10.1109/TCSVT.2017.2713480
   Zhang YX, 2023, IEEE T KNOWL DATA EN, V35, P12068, DOI 10.1109/TKDE.2021.3139916
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zong B., 2018, INT C LEARNING REPRE, P1
   Zou Y F., RECOGNITION RES ABNO
NR 56
TC 0
Z9 0
U1 5
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 6
DI 10.1007/s13735-023-00272-x
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9W8VW
UT WOS:000949357400001
DA 2024-07-18
ER

PT J
AU Papadopoulos, SI
   Koutlis, C
   Papadopoulos, S
   Kompatsiaris, I
AF Papadopoulos, Stefanos-Iordanis
   Koutlis, Christos
   Papadopoulos, Symeon
   Kompatsiaris, Ioannis
TI Multimodal Quasi-AutoRegression: forecasting the visual popularity of
   new fashion products
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Popularity forecasting; Trend detection; Quasi-AutoRegression;
   Multimodal learning; Computer vision; Fashion
ID NEURAL-NETWORKS
AB Estimating the preferences of consumers is of utmost importance for the fashion industry as appropriately leveraging this information can be beneficial in terms of profit. Trend detection in fashion is a challenging task due to the fast pace of change in the fashion industry. Moreover, forecasting the visual popularity of new garment designs is even more demanding due to lack of historical data. To this end, we propose MuQAR, a Multimodal Quasi-AutoRegressive deep learning architecture that combines two modules: (1) a multimodal multilayer perceptron processing categorical, visual and textual features of the product and (2) a Quasi-AutoRegressive neural network modelling the "target" time series of the product's attributes along with the "exogenous" time series of all other attributes. We utilize computer vision, image classification and image captioning, for automatically extracting visual features and textual descriptions from the images of new products. Product design in fashion is initially expressed visually and these features represent the products' unique characteristics without interfering with the creative process of its designers by requiring additional inputs (e.g. manually written texts). We employ the product's target attributes time series as a proxy of temporal popularity patterns, mitigating the lack of historical data, while exogenous time series help capture trends among interrelated attributes. We perform an extensive ablation analysis on two large-scale image fashion datasets, Mallzee-P and SHIFT15m to assess the adequacy of MuQAR and also use the Amazon Reviews: Home and Kitchen dataset to assess generalization to other domains. A comparative study on the VISUELLE dataset shows that MuQAR is capable of competing and surpassing the domain's current state of the art by 4.65% and 4.8% in terms of WAPE and MAE, respectively.
C1 [Papadopoulos, Stefanos-Iordanis; Koutlis, Christos; Papadopoulos, Symeon; Kompatsiaris, Ioannis] CERTH, Informat Technol Inst, Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas
RP Papadopoulos, SI (corresponding author), CERTH, Informat Technol Inst, Thessaloniki, Greece.
EM stefpapad@iti.gr; ckoutlis@iti.gr; papadop@iti.gr; ikom@iti.gr
RI Papadopoulos, Stefanos-Iordanis/JDH-5285-2023; Kompatsiaris,
   Ioannis/P-8594-2015; Papadopoulos, Symeon/AET-0683-2022; Koutlis,
   Christos/AAK-8028-2021
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Koutlis,
   Christos/0000-0003-3682-408X; Papadopoulos,
   Stefanos-Iordanis/0000-0002-1424-2647
FU Horizon 2020 European project [951908]; H2020 - Industrial Leadership
   [951908] Funding Source: H2020 - Industrial Leadership
FX This work is partially funded by the Horizon 2020 European project
   "eTryOn -virtual try-ons of garments enabling novel human fashion
   interactions" under grant agreement no. 951908.
CR Al-Halah Z, 2017, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2017.50
   Al-Halah Ziad, 2020, P IEEE CVF C COMP VI, P10136
   [Anonymous], 2017, PREPRINT
   [Anonymous], 2018, PREPRINT
   Billings SA, 2013, NONLINEAR SYSTEM IDENTIFICATION: NARMAX METHODS IN THE TIME, FREQUENCY, AND SPATIO-TEMPORAL DOMAINS, P1, DOI 10.1002/9781118535561
   Chang A.A., 2021, DATA SCI INTELLIGENT, V2, P34
   Cheng WH, 2021, ACM COMPUT SURV, V54, DOI [10.1145/3447239, 10.1145/3552468.3554360]
   Craparotta G, 2019, INT J COMPUT INT SYS, V12, P1537, DOI 10.2991/ijcis.d.191122.002
   Ekambaram V, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3110, DOI 10.1145/3394486.3403362
   Graves A., 2013, PREPRINT
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hwang CL, 1981, Multiple attribute decision making: Methods and applications a state-ofthe-art survey, DOI [DOI 10.1007/978-3-642-48318-93, 10.1007/978-3-642-48318-93, DOI 10.1007/978-3-642-48318-9]
   Kimura M, 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2108.12992
   Koutlis C, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106685
   Lai GK, 2018, ACM/SIGIR PROCEEDINGS 2018, P95, DOI 10.1145/3209978.3210006
   Lim B, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0209
   Lo L, 2019, IEEE IMAGE PROC, P3222, DOI [10.1109/icip.2019.8803461, 10.1109/ICIP.2019.8803461]
   Loureiro ALD, 2018, DECIS SUPPORT SYST, V114, P81, DOI 10.1016/j.dss.2018.08.010
   Mall U, 2019, IEEE I CONF COMP VIS, P411, DOI 10.1109/ICCV.2019.00050
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Niinimäki K, 2020, NAT REV EARTH ENV, V1, P189, DOI 10.1038/s43017-020-0039-9
   Papadopoulos Stefanos-Iordanis, 2022, Recommender Systems in Fashion and Retail: Proceedings of the Third Workshop at the Recommender Systems Conference (2021). Lecture Notes in Electrical Engineering (830), P95, DOI 10.1007/978-3-030-94016-4_7
   Shi XJ, 2015, ADV NEUR IN, V28
   Singh PK, 2019, PREPRINT
   Skenderi G, 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2109.09824
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang P, 2022, PREPRINT
   Yunshan Ma, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P82, DOI 10.1145/3372278.3390677
   Zhao BD, 2017, J SYST ENG ELECTRON, V28, P162, DOI 10.21629/JSEE.2017.01.18
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
NR 31
TC 10
Z9 10
U1 7
U2 16
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 717
EP 729
DI 10.1007/s13735-022-00262-5
EA OCT 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000865149900001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, MRP
   Jayagopal, P
AF Kumar, M. R. Pavan
   Jayagopal, Prabhu
TI Multi-class imbalanced image classification using conditioned GANs
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Imbalanced data; Convolutional neural network; Data augmentation;
   Generative model; Adversarial network
ID ADVERSARIAL; SMOTE
AB The problem of data skewness, class imbalance, data scarcity and noise limits the application of machine learning and deep learning models in applications like anomaly detection, fraud detection, intrusion detection, fault diagnosis, machine-to-machine communication, etc. Performance of supervised learning leans towards majority class and fails to generalize testing data in class imbalance and noisy data problems. Using neural-based data augmentation techniques for data generation and deep convolutional models for classification would enhance the performance of the applications mentioned above. Recently, GANs (generative adversarial networks) showed significant improvements in generating images. In this paper, a model that uses a conditioned deep convolutional GAN and an auxiliary classifier are proposed to tackle the aforementioned issues. The conditioned GAN is used for data generation of minority classes images and noisy images. Another auxiliary deep convolutional model is employed for the classification of images on data augmented dataset. Also, a multi-hinge loss is employed in both the data augmentation and classification tasks. The effectiveness of the proposed model is investigated on the quality of generated images and classification metrics using four publicly available popular datasets: MNIST, EMNIST, CIFAR10, and SVHN. The proposed model has shown significant improvements over the other often used models of data augmentation and multi-class imbalance image classification in terms of generated samples and classification accuracy.
C1 [Kumar, M. R. Pavan] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Jayagopal, Prabhu] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Jayagopal, P (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM marabattinasivapavan@gmail.com; jprabhuit@gmail.com
RI jayagopal, prabhu/AAF-8826-2019; jayagopal, prabhu/JCE-2168-2023; M,
   Dr.M Ranjith Kumar/U-4667-2019
OI jayagopal, prabhu/0000-0003-3335-6911; jayagopal,
   prabhu/0000-0003-3335-6911; M, Dr.M Ranjith Kumar/0000-0001-8411-7609; ,
   Pavan Kumar M R/0000-0002-6754-7372
CR Ali A., 2015, INT J ADV SOFT COMPU, V7, P176
   Ali-Gombe A, 2019, NEUROCOMPUTING, V361, P212, DOI 10.1016/j.neucom.2019.06.043
   Ali-Gombe Adamu., 2018, 2018 International Joint Conference on Neural Networks (IJCNN), P1, DOI DOI 10.1109/IJCNN.2018.8489387
   [Anonymous], 2016, GENERATING IMAGES PA
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Brock A., 2016, NEURAL PHOTOEDITING
   Bunkhumpornpat C, 2012, APPL INTELL, V36, P664, DOI 10.1007/s10489-011-0287-y
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Im D. J., 2016, ARXIV160205110
   Isola P., 2017, P IEEE C COMP VIS PA, P1125
   Karras T., 2018, INT CONFLEARN REPRES
   Kavalerov I, 2019, CGANS MULTIHINGE LOS
   Kim T, 2017, PR MACH LEARN RES, V70
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Liu Ming Yu, 2016, ADV NEURAL INF PROCE, P469
   Liu Y, 2017, IEEE-CAA J AUTOMATIC, V4, P27, DOI 10.1109/JAS.2017.7510349
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Mundra Kartik, 2020, AIMS '20: Proceedings of the 1st ACM Workshop on Autonomous and Intelligent Mobile Systems, DOI 10.1145/3377283.3377285
   Perarnau G., 2016, NIPS WORKSHOP ADVERS
   Radford A., 2015, ARXIV
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Taigman Y., 2016, INT C LEARN REPR
   Taylor L, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1542, DOI 10.1109/SSCI.2018.8628742
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wu JJ, 2016, ADV NEUR IN, V29
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 38
TC 2
Z9 3
U1 2
U2 37
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2021
VL 10
IS 3
BP 143
EP 153
DI 10.1007/s13735-021-00213-6
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UU7DE
UT WOS:000698955200002
DA 2024-07-18
ER

PT J
AU Jiménez, M
   Aguilar, J
   Monsalve-Pulido, J
   Montoya, E
AF Jimenez, Marvin
   Aguilar, Jose
   Monsalve-Pulido, Julin
   Montoya, Edwin
TI An automatic approach of audio feature engineering for the extraction,
   analysis and selection of descriptors
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Audio feature engineering; Data mining; Feature extraction; Feature
   selection
ID MUSICAL GENRE CLASSIFICATION
AB Currently, it is critical to find the correct features from the audio, in order to analyze the information contained in it. This paper analyzes several feature types in audio from different points of view: time series, sound engineering, etc. In particular, the description of audio as a set of time series is not very common in the literature, and it is one of the aspects studied in this paper. Particularly, this paper proposes an automated method for feature engineering in audios, to extract, analyze and select the best features in a given context. Specifically, this paper develops a hybrid scheme of extraction of audio descriptors based on different principles and defines an automatic approach for the analysis and selection of these descriptors in a given audio context. Finally, our approach was tested on grouping tasks and compared to previous works on audio classification problems, with encouraging results.
C1 [Jimenez, Marvin] Univ Sinu, Dept Ing Ind, Monteria, Colombia.
   [Aguilar, Jose] Univ Los Andes, CEMISID, Merida, Venezuela.
   [Aguilar, Jose; Monsalve-Pulido, Julin; Montoya, Edwin] Univ EAFIT, GIDITIC, Medellin, Colombia.
C3 University of Los Andes Venezuela; Universidad EAFIT
RP Aguilar, J (corresponding author), Univ Los Andes, CEMISID, Merida, Venezuela.; Aguilar, J (corresponding author), Univ EAFIT, GIDITIC, Medellin, Colombia.
EM aguilarjos@gmail.com
RI Monsalve-Pulido, Julian/AGQ-8057-2022; Aguilar, Jose/H-3017-2015
OI Monsalve-Pulido, Julian/0000-0002-0706-5881; Aguilar,
   Jose/0000-0003-4194-6882
FU Ministry of Science-Government of Antioquia-Republic of Colombia [64366]
FX This work has been supported by the project 64366: "Contenidos de
   aprendizaje inteligentes a travs del uso de herramientas de Big Data,
   Analtica Avanzada e IA"-Ministry of Science-Government of
   Antioquia-Republic of Colombia.
CR Aguilar J, 1998, NEURAL NETWORKS, V11, P731737
   Aguilar J., 2001, Rev. Colombiana Comput., V2, P7
   Aguilar J, 2020, COMPUTATION, V8, DOI 10.3390/computation8020030
   [Anonymous], 2017, Computational Analysis of Sound Scenes and Events, DOI [10.1007/978-3-319-63450-0_4, DOI 10.1007/978-3-319-63450-0_4]
   Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7
   Costa YMG, 2012, NEUR NETW IJCNN 2012, P1, DOI [10.1109/IJCNN.2012.6252626, DOI 10.1109/IJCNN.2012.6252626]
   Deldjoo Y, 2019, USER MODEL USER-ADAP, V29, P291, DOI 10.1007/s11257-019-09221-y
   Fulcher BD, 2014, IEEE T KNOWL DATA EN, V26, P3026, DOI 10.1109/TKDE.2014.2316504
   Holzapfel A, 2008, IEEE T AUDIO SPEECH, V16, P424, DOI 10.1109/TASL.2007.909434
   Hyndman RJ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1616, DOI 10.1109/ICDMW.2015.104
   Kobayashi T, 2018, IEEE INT SYM MULTIM, P180, DOI 10.1109/ISM.2018.00-15
   Li T, 2003, P 26 ANN INT ACM SIG, P282, DOI [DOI 10.1145/860435.860487, 10.1145/860484.860487, DOI 10.1145/860484.860487]
   Li T, 2006, IEEE T MULTIMEDIA, V8, P564, DOI 10.1109/TMM.2006.870730
   Lidy T, 2005, P 6 INT C MUS INF RE, P34
   Liu Q, 2016, ROBOTICS, V5, DOI 10.3390/robotics5010008
   Mandel M., 2005, ISMIR 2005, P594
   Moffat D, 2015, DAFX 2015 P 18 INT C
   Morales L, 2020, IEEE ACCESS, V8, P162917, DOI 10.1109/ACCESS.2020.3021675
   Morales L, 2019, SERV ORIENTED COMPUT, V13, P199, DOI 10.1007/s11761-019-00266-w
   Muaidi Hasan, 2014, RES J APPL SCI ENG T, V7, P5082
   Pampalk E, 2003, DAFX-03: 6TH INTERNATIONAL CONFERENCE ON DIGITAL AUDIO EFFECTS, PROCEEDINGS, P7
   Pampalk E., 2005, Proceedings of the International Conference on Music Information Retrieval, P628
   Pampalk E., 2002, P 10 ACM INT C MULT
   Panagakis I., 2008, ISMIR, P583
   Pearce A., 2017, Audio Engineering Society Conference: 2017 AES International Conference on Semantic Audio. Audio Engineering Society
   Seyerlehner K, 2010, P SOUND MUS COMP 201
   Seyerlehner K, 2009, ONL P 5 ANN MUS INF
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G., 2008, INTELLIGENT MUSIC IN, P31
   Wang XZ, 2006, DATA MIN KNOWL DISC, V13, P335, DOI 10.1007/s10618-005-0039-x
   Wulfing J., 2012, ISMIR, P139
NR 31
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2021
VL 10
IS 1
BP 33
EP 42
DI 10.1007/s13735-020-00202-1
EA JAN 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QV8OQ
UT WOS:000605843600001
DA 2024-07-18
ER

PT J
AU Alzu'bi, A
   Younis, LB
   Madain, A
AF Alzu'bi, Ahmad
   Younis, Lojin Bani
   Madain, Alia
TI An interactive attribute-preserving fashion recommendation with 3D
   image-based virtual try-on
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Fashion recommendation; Virtual try-on; Image retrieval; Deep learning;
   3D imaging
ID MODEL
AB Online shopping experiences should be simplified by incorporating essential features such as virtual try-on clothing and recommending new items based on the customer's preferences. This is necessary given the rapid growth of the fashion industry and the expansion of shopping technologies. In this paper, we propose a new approach integrating fashion image retrieval and recommendation with a 3D virtual try-on network. We aim to build an interactive attributes-preserving model that allows users to choose the favourite garments and virtually try them on after uploading a frontal image of the whole body. Several deep learning architectures are used to extract and learn the key attributes of garment image, by which each formulated image is subjected to effective human body segmentation and pose estimation procedures. Then, a 3D VTON network is used to generate a 3D image of the user wearing a specific garment, after which the fashion retrieval system recommends and ranks more relevant items. Extensive experiments on multi-domain fashion dataset demonstrate that the proposed framework outperforms the state-of-the-art methods in terms of fashion retrieval and attribute relevancy, achieving a top@30 accuracy of 80.02%, an NDCG@30 of 80.26%, and a top@30 mAP of 87.71%. Additionally, the generated generic image descriptors require very little memory space, enabling rapid online learning and retrieval of large-scale 3D images.
C1 [Alzu'bi, Ahmad; Younis, Lojin Bani; Madain, Alia] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Alzu'bi, A (corresponding author), Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
EM agalzubi@just.edu.jo; lhbaniyounis19@cit.just.edu.jo;
   asmadain@just.edu.jo
OI Alzu'bi, Ahmad/0000-0001-5466-0379
CR Abugabah A, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060873
   Ak KE, 2018, P EUROPEAN C COMPUTE
   Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   Ak KE, 2018, IEEE WINT CONF APPL, P1671, DOI 10.1109/WACV.2018.00186
   Alzu'bi A, 2020, ENG SCI TECHNOL, V23, P911, DOI 10.1016/j.jestch.2019.12.004
   Alzu'bi A, 2015, INT CONF SYST SIGNAL, P253, DOI 10.1109/IWSSIP.2015.7314224
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Baldrati A, 2022, PROC CVPR IEEE, P21434, DOI 10.1109/CVPR52688.2022.02080
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Bowen Wu FZ., 2021, 2D HUMAN PARSING
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Choutas Vasileios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P20, DOI 10.1007/978-3-030-58607-2_2
   De Divitiis L, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3531017
   Du C, 2023, ICASSP 2023 2023 IEE, P1
   Guo ZX, 2011, TEXT RES J, V81, P1871, DOI 10.1177/0040517511411968
   주신영, 2016, [Journal of the Korean Society of Clothing and Textiles, 한국의류학회지], V40, P506
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Han Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7847, DOI 10.1109/CVPR42600.2020.00787
   Hashmi MF, 2020, IEEE ACCESS, V8, P91603, DOI 10.1109/ACCESS.2020.2993574
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2018, ACM/SIGIR PROCEEDINGS 2018, P355, DOI 10.1145/3209978.3209981
   Hou YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12127, DOI 10.1109/ICCV48922.2021.01193
   Jo J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030508
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee HJ, 2019, IEEE INT CONF COMP V, P3129, DOI 10.1109/ICCVW.2019.00381
   Li WQ, 2020, IEEE ACCESS, V8, P141814, DOI 10.1109/ACCESS.2020.3013639
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mir A, 2020, PROC CVPR IEEE, P7021, DOI 10.1109/CVPR42600.2020.00705
   Morelli Davide, 2021, IT INF RETR WORKSH
   Park J, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P64, DOI 10.1145/2818048.2820065
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Quadrana M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P130, DOI 10.1145/3109859.3109896
   Sachdeva Himani, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P287, DOI 10.1007/978-981-13-7403-6_27
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santesteban I., 2022, Advances in Neural Information Processing Systems, V35, P12110
   Sarkar R, 2022, IEEE COMPUT SOC CONF, P2262, DOI 10.1109/CVPRW56347.2022.00249
   Shimizu R, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119167
   Smirnova E, 2017, P 2 WORKSH DEEP LEAR, P2
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   statista, FASH WORLDW STAT MAR
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang JB, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103225
   Wieczorek M, 2020, Neural Information Processing, P294
   Yang H, 2022, PROC CVPR IEEE, P3450, DOI 10.1109/CVPR52688.2022.00345
   Yu RY, 2019, IEEE I CONF COMP VIS, P10510, DOI 10.1109/ICCV.2019.01061
   Zanfir M, 2018, PROC CVPR IEEE, P5391, DOI 10.1109/CVPR.2018.00565
   Zhao B, 2017, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2017.652
   Zhao F., 2021, P IEEE CVF INT C COM, P13239
NR 56
TC 0
Z9 0
U1 10
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 24
DI 10.1007/s13735-023-00294-5
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O6LG9
UT WOS:001044894800004
DA 2024-07-18
ER

PT J
AU Koutlis, C
   Schinas, M
   Papadopoulos, S
AF Koutlis, Christos
   Schinas, Manos
   Papadopoulos, Symeon
TI MemeTector: enforcing deep focus for meme detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Meme detection; Visual part utilization; Trainable attention; Vision
   transformer
AB Image memes and specifically their widely known variation image macros are a special new media type that combines text with images and are used in social media to playfully or subtly express humor, irony, sarcasm and even hate. It is important to accurately retrieve image memes from social media to better capture the cultural and social aspects of online phenomena and detect potential issues (hate-speech, disinformation). Essentially, the background image of an image macro is a regular image easily recognized as such by humans but cumbersome for the machine to do so due to feature map similarity with the complete image macro. Hence, accumulating suitable feature maps in such cases can lead to deep understanding of the notion of image memes. To this end, we propose a methodology, called visual part utilization, that utilizes the visual part of image memes as instances of the regular image class and the initial image memes as instances of the image meme class to force the model to concentrate on the critical parts that characterize an image meme. Additionally, we employ a trainable attention mechanism on top of a standard ViT architecture to enhance the model's ability to focus on these critical parts and make the predictions interpretable. Several training and test scenarios involving web-scraped regular images of controlled text presence are considered for evaluating the model in terms of robustness and accuracy. The findings indicate that light visual part utilization combined with sufficient text presence during training provides the best and most robust model, surpassing state of the art. Source code and dataset are available at https://github.com/mever-team/memetector.
C1 [Koutlis, Christos; Schinas, Manos; Papadopoulos, Symeon] ITI, CERTH, 6th Km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Koutlis, C (corresponding author), ITI, CERTH, 6th Km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
EM ckoutlis@iti.gr; manosetro@iti.gr; papadop@iti.gr
RI Koutlis, Christos/AAK-8028-2021; Papadopoulos, Symeon/AET-0683-2022
FU HEAL-Link Greece; Horizon 2020 European project MediaVerse [957252];
   H2020 - Industrial Leadership [957252] Funding Source: H2020 -
   Industrial Leadership
FX Open access funding provided by HEAL-Link Greece. This work is partially
   funded by the Horizon 2020 European project MediaVerse under grant
   agreement no. 957252.
CR Afridi Tariq Habib, 2021, Innovations in Smart Cities Applications. Proceedings of the 5th International Conference on Smart City Applications. Lecture Notes in Networks and Systems (LNNS 183), P1451, DOI 10.1007/978-3-030-66840-2_109
   Aggarwal A, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5510253
   Amal A., 2018, P 6 INT C MULT COMP, P1
   Dancygier B, 2017, COGN LINGUIST, V28, P565, DOI 10.1515/cog-2017-0074
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Fiorucci S, 2020, P 7 EVALUATION CAMPA, DOI [10.4000/books.aaccademia.7352, DOI 10.4000/BOOKS.AACCADEMIA.7352]
   Gaurav D, 2020, COMM COM INF SC, V1232, P195, DOI 10.1007/978-3-030-65384-2_15
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SK, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P116, DOI [10.1109/ISI.2019.8823294, 10.1109/isi.2019.8823294]
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Jetley S, 2018, 6 INT C LEARNING REP
   Khedkar S, 2022, P INT C INN COMP COM, P609, DOI 10.1007/978-981-16-2597-8_52
   Kiela D., 2020, ADV NEURAL INFORM PR, V33, P2611
   Kiela D., 2021, P MACHINE LEARNING R, V133, P344
   Lei Ba J., 2016, arXiv
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Miliani M, 2020, CEUR WORKSHOP, DOI [10.4000/books.aaccademia.7330, DOI 10.4000/BOOKS.AACCADEMIA.7330]
   Olivieri A, 2022, WHAT IS MEME TECHNIC
   Segev E, 2015, J COMPUT-MEDIAT COMM, V20, P417, DOI 10.1111/jcc4.12120
   Setpal J, 2020, P 7 EV CAMP NAT LANG, DOI [10.4000/books.aaccademia.7405, DOI 10.4000/BOOKS.AACCADEMIA.7405]
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shrestha I, 2020, EVALUATION INTERPROC, P891, DOI [10.18653/v1/2020.semeval-1.113, DOI 10.18653/V1/2020.SEMEVAL-1.113]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha A, 2019, ACM INT CONF PR SER, P36, DOI 10.1145/3368567.3368582
   Smitha ES, 2018, L N COMPUT VIS BIOME, V28, P1015, DOI 10.1007/978-3-319-71767-8_87
   Suryawanshi S., 2020, P 2 WORKSH TROLL AGG, P32
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vaswani A, 2017, ANN C NEURAL INFORM
   Vlad GA, 2020, EVALITA, DOI 10.4000/books.aaccademia.7360
   Xie L, 2011, P 19 ACM INT C MULT, P53, DOI DOI 10.1145/2072298.2072307
   Ye J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P516
   Zannettou S, 2018, IMC'18: PROCEEDINGS OF THE INTERNET MEASUREMENT CONFERENCE, P188, DOI 10.1145/3278532.3278550
   Zhou Y, 2022, PREP BIOCHEM BIOTECH, V52, P681, DOI 10.1080/10826068.2021.1986720
NR 33
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 11
DI 10.1007/s13735-023-00277-6
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G3YY5
UT WOS:000988563100001
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Wu, ZF
   Ma, YH
   Cao, JZ
   Paul, A
   Li, X
AF Wu, Zhefu
   Ma, Yuhang
   Cao, Junzhuo
   Paul, Agyemang
   Li, Xiang
TI Multiple feedback based adversarial collaborative filtering with
   aesthetics
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Adversarial learning; Visually-aware; Personalized ranking; Adversarial
   perturbations; Recommendation systems
AB Visual-aware personalized recommendation systems can estimate the potential demand by evaluating consumer personalized preferences. In general, consumer feedback data is deduced from either explicit feedback or implicit feedback. However, explicit and implicit feedback raises the chance of malicious operation or misoperation, which can lead to deviations in recommended outcomes. Adversarial learning, a regularization approach that can resist disturbances, could be a promising choice for enhancing model resilience. We propose a novel adversarial collaborative filtering with aesthetics (ACFA) for the visual recommendation that utilizes adversarial learning to improve resilience and performance in the case of perturbation. The ACFA algorithm applies three types of input to the visual Bayesian personalized ranking: negative, unobserved, and positive feedback. Through feedbacks at various levels, it uses a probabilistic approach to obtain consumer personalized preferences. Since in visual recommendation, the aesthetic data in determining consumer preferences on product is critical, we construct the consumer personalized preferences model with aesthetic elements, and then use them to enhance the sampling quality when training the algorithm. To mitigate the negative effects of feedback noise, We use minimax adversarial learning to learn the ACFA objective function. Experiments using two datasets demonstrate that the ACFA model outperforms state-of-the-art algorithms on two metrics.
C1 [Wu, Zhefu; Ma, Yuhang; Cao, Junzhuo; Paul, Agyemang] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Peoples R China.
   [Li, Xiang] China Comserv HuiZhan Co, Hangzhou 311215, Peoples R China.
C3 Zhejiang University of Technology
RP Li, X (corresponding author), China Comserv HuiZhan Co, Hangzhou 311215, Peoples R China.
EM lixiang.zj@chinaccs.cn
FU Zhejiang Provincial Natural Science Foundation of China [LZ22F010005]
FX AcknowledgementsThis research was supported by Zhejiang Provincial
   Natural Science Foundation of China under Grant No. LZ22F010005.
CR Anelli VW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1094, DOI 10.1145/3404835.3462848
   Cao Z., 2007, P 24 INT C MACHINE L, P129, DOI DOI 10.1145/1273496.1273513
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Chen X, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P21, DOI 10.1145/2872518.2889349
   Cohen R, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P94, DOI 10.1145/3437963.3441757
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Di Noia T, 2020, 50TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOPS (DSN-W 2020), P1, DOI 10.1109/DSN-W50199.2020.00011
   He R., 2016, P 25 INT JOINT C ART, P3740
   He RN, 2016, AAAI CONF ARTIF INTE, P144
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hu Liang, 2013, P 22 INT C WORLD WID, P595, DOI DOI 10.1145/2488388.2488441
   Kang WC, 2017, IEEE DATA MINING, P207, DOI 10.1109/ICDM.2017.30
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Liu Q, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/3077136.3080658
   Liu ZR, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3590, DOI 10.1145/3442381.3449891
   Loftin R, 2016, AUTON AGENT MULTI-AG, V30, P30, DOI 10.1007/s10458-015-9283-7
   Loni B, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P361, DOI 10.1145/2959100.2959163
   Meng Lei, 2020, P MM, P3460, DOI 10.1145/3394171.3413598
   Niu W, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P423, DOI 10.1145/3159652.3159728
   Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16
   Paul A, 2022, APPL INTELL, V52, P3499, DOI 10.1007/s10489-021-02355-w
   Peugh JL, 2004, REV EDUC RES, V74, P525, DOI 10.3102/00346543074004525
   Rendle S., 2009, P 25 C UNCERTAINTY A, P452
   Tang JH, 2020, IEEE T KNOWL DATA EN, V32, P855, DOI 10.1109/TKDE.2019.2893638
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Wu ZF, 2017, 2017 14TH INTERNATIONAL WORKSHOP ON COMPLEX SYSTEMS AND NETWORKS (IWCSN), P205, DOI 10.1109/IWCSN.2017.8276528
   Yin RP, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3434, DOI 10.1145/3308558.3313739
   [俞东进 Yu Dongjin], 2018, [电子学报, Acta Electronica Sinica], V46, P2626
   Yu RL, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1727, DOI 10.1145/3269206.3269283
   Yu WH, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P649, DOI 10.1145/3178876.3186146
   Zhao T., 2014, P 23 ACM INT C C INF, P261, DOI DOI 10.1145/2661829.2661998
NR 32
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 9
DI 10.1007/s13735-023-00273-w
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5SU0
UT WOS:000976146500001
DA 2024-07-18
ER

PT J
AU Soleymani, M
   Riegler, M
   Halvorsen, P
AF Soleymani, Mohammad
   Riegler, Michael
   Halvorsen, Pal
TI Multimodal analysis of user behavior and browsed content under different
   image search intents
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Search intent; User behavior; Machine learning
ID FEATURES
AB The motivation or intent of a search for content may vary between users and use-cases. Knowledge and understanding of these underlying objectives may therefore be important in order to return appropriate search results, and studies of user search intent are emerging in information retrieval to understand why a user is searching for a particular type of content. In the context of image search, our work targets automatic recognition of users' intent in an early stage of a search session. We have designed seven different search scenarios under the intent conditions of finding items, re-finding items and entertainment. Moreover, we have collected facial expressions, physiological responses, eye gaze and implicit user interactions from 51 participants who performed seven different search tasks on a custom-built image retrieval platform, and we have analyzed the users' spontaneous and explicit reactions under different intent conditions. Finally, we trained different machine learning models to predict users' search intent from the visual content of the visited images, the user interactions and the spontaneous responses. Our experimental results show that after fusing the visual and user interaction features, our system achieved the F-1 score of 0.722 for classifying three classes in a user-independent cross-validation. Eye gaze and implicit user interactions, including mouse movements and keystrokes are the most informative features for intent recognition. In summary, the most promising results are obtained by modalities that can be captured unobtrusively and online, and the results therefore demonstrate the potential of including intent-based methods in multimedia retrieval platforms.
C1 [Soleymani, Mohammad] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
   [Riegler, Michael] Simula Metropolitan Ctr Digital Engn, Oslo, Norway.
   [Halvorsen, Pal] Simula Res Lab, Oslo, Norway.
C3 University of Geneva
RP Soleymani, M (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
EM mohammad.soleymani@unige.ch
RI Soleymani, Mohammad/AAS-2161-2020; Riegler, Michael A/E-5443-2015
OI Soleymani, Mohammad/0000-0003-2770-7236; Halvorsen,
   Pal/0000-0003-2073-7029
FU Swiss National Science Foundation Ambizione grant; Research Council of
   Norway [231687]
FX The work of Soleymani was supported by his Swiss National Science
   Foundation Ambizione grant. The work of Riegler and Halvorsen was
   supported by the Research Council of Norway as a part of the EONS
   project (grant 231687). We thank David Sander for his kind assistance
   for the ethical review of the experiment. We also thank "Fondation
   Campus Biotech Geneve" for providing access and support at their
   experimental facilities.
CR [Anonymous], MULT EXP ICME IEEE I
   [Anonymous], 2017, FRONTIERS ICT, DOI DOI 10.3389/FICT.2017.00001
   Arapakis I., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P461, DOI DOI 10.1145/1631272.1631336
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Blanchard N, 2014, LECT NOTES COMPUT SC, V8474, P55, DOI 10.1007/978-3-319-07221-0_7
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Chatzichristofis S., 2009, Proc. ofthe 6th IASTED International Conference, V134643, page, P064
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   D'Mello S, 2012, INT J HUM-COMPUT ST, V70, P377, DOI 10.1016/j.ijhcs.2012.01.004
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ekman P., 1978, Facial action coding system
   Elsweiler D, 2010, P 3 S INF INT CONT 2, P25, DOI [10.1145/1840784.1840790, DOI 10.1145/1840784.1840790]
   Fidel R., 1997, New Review of Hypermedia and Multimedia, V3, P181, DOI 10.1080/13614569708914689
   Gialampoukidis I, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P1, DOI 10.1109/SMAP.2016.7753375
   Gunatilaka AH, 2001, IEEE T PATTERN ANAL, V23, P577, DOI 10.1109/34.927459
   Hanjalic Alan., 2012, P 20 ACM INT C MULT, P1239
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   Jaques N, 2014, LECT NOTES COMPUT SC, V8474, P29, DOI 10.1007/978-3-319-07221-0_4
   Jou B, 2016, P 2016 ACM MULT C MM, P998
   Kofler C, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2954930
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Lagger C, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/3034706
   Lall S., 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI'16, P2529
   Lux M., 2012, P ACM MULT 2012 WORK, P17
   Lux M., 2010, CHI 10 HUM FACT COMP, P3913, DOI DOI 10.1145/1753846.1754078
   McDuff D., 2016, P CHI C HUM FACT COM, P3723
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moshfeghi Yashar, 2013, P 22 INT C WORLD WID, P931
   O'Hare N, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P559, DOI 10.1145/2911451.2911532
   Park JY, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P985, DOI 10.1145/2702123.2702527
   Poddar A., 2010, P 3 S INFORM INTERAC, P35, DOI DOI 10.1145/1840784.1840792
   Riegler M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P397, DOI 10.1145/2647868.2654894
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Soleymani M, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P256, DOI 10.1145/3078971.3078995
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Teevan Jaime, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P151, DOI 10.1145/1277741.1277770
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
NR 42
TC 10
Z9 10
U1 3
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2018
VL 7
IS 1
SI SI
BP 29
EP 41
DI 10.1007/s13735-018-0150-6
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GB9SN
UT WOS:000429414200004
DA 2024-07-18
ER

PT J
AU Mandia, S
   Singh, K
   Mitharwal, R
AF Mandia, Sandeep
   Singh, Kuldeep
   Mitharwal, Rajendra
TI Recognition of student engagement in classroom from affective states
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Learning-centered affective states; Visual cues; Classroom education;
   Engagement recognition
ID ACHIEVEMENT; DATABASE; FUSION; FACES
AB Student engagement is positively related to comprehension in teaching-learning process. Student engagement is widely studied in online learning environments, whereas this research focuses on student engagement recognition in classroom environments using visual cues. To incorporate learning-centered affective states, we curated a dataset with six learning-centered affective states from four public datasets. A graph convolution network (GCN)-based deep learning model with attention was designed and implemented to extract more contributing features from input video for student engagement recognition. The proposed architecture was evaluated on curated as well as four public datasets. An ablation study was conducted on a curated dataset, the best performing model with minority oversampling and focal cross-entropy loss achieved 65.35% accuracy. We also estimated the student engagement in authentic classroom data, and it showed a positive correlation between students' engagement levels and post-lesson test scores with a Pearson's coefficient value of 0.64. The proposed method outperformed the existing state-of-the-art methods on two of the public datasets with accuracy scores of 99.20% and 56.17%, and it achieved accuracy scores of 64.92% and 56.17% on other two public datasets which are better than many baseline results on them.
C1 [Mandia, Sandeep; Singh, Kuldeep; Mitharwal, Rajendra] Malaviya Natl Inst Technol, Dept Elect & Commun Engn, JLN Marg, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Mandia, S (corresponding author), Malaviya Natl Inst Technol, Dept Elect & Commun Engn, JLN Marg, Jaipur 302017, Rajasthan, India.
EM smandia20@gmail.com; kuldeep.ece@mnit.ac.in; rajendra.ece@mnit.ac.in
RI Mandia, Sandeep/KVX-9906-2024
OI Mandia, Sandeep/0000-0001-6362-4185
CR Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Ahuja Karan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351229
   Aluja-Banet T, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2017.03.007
   Alyuz N, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P100, DOI 10.1145/2993148.2993166
   [Anonymous], 2015, CAMERA BASED ESTIMAT
   Ashwin TS, 2020, FUTURE GENER COMP SY, V108, P334, DOI 10.1016/j.future.2020.02.075
   Aslan S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300534
   Bai J, 2022, IEEE T CYBERNETICS, V52, P13821, DOI 10.1109/TCYB.2021.3110813
   Baker R.S. J. D., 2014, The Oxford handbook of affective computing, P233
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Bevilacqua D, 2019, J COGNITIVE NEUROSCI, V31, P401, DOI 10.1162/jocn_a_01274
   Bhardwaj P, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107277
   Bidwell J., 2011, BEHAV RES METHODS
   Blanchard N, 2014, LECT NOTES COMPUT SC, V8474, P55, DOI 10.1007/978-3-319-07221-0_7
   Bosch N, 2021, IEEE T AFFECT COMPUT, V12, P974, DOI 10.1109/TAFFC.2019.2908837
   Bosch N, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2946837
   Anh BN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224729
   Cerezo R, 2016, COMPUT EDUC, V96, P42, DOI 10.1016/j.compedu.2016.02.006
   Chen X., 2020, Computers and Education: Artificial Intelligence, V1, P100002, DOI [10.1016/j.caeai.2020.100002, DOI 10.1016/J.CAEAI.2020.100002]
   Chi MTH, 2014, EDUC PSYCHOL-US, V49, P219, DOI 10.1080/00461520.2014.965823
   Christenson SL, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P813, DOI 10.1007/978-1-4614-2018-7
   Cocea M, 2011, IEEE T LEARN TECHNOL, V4, P114, DOI 10.1109/TLT.2010.14
   D'Mello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   D'Mello SK., 2010, International Journal of Artificial Intelligence in Education, V20, P361, DOI [DOI 10.3233/JAI-2010-012, 10.3233/JAI-2010-012]
   Darnell DK, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225709
   Deng WH, 2019, IEEE ACCESS, V7, P118727, DOI 10.1109/ACCESS.2019.2936663
   DMello S. K., 2018, DEEP COMPREHENSION, P52
   Eisele G, 2022, ASSESSMENT, V29, P136, DOI 10.1177/1073191120957102
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fairclough SH, 2006, BIOL PSYCHOL, V71, P100, DOI 10.1016/j.biopsycho.2005.03.007
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Fujii K, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174927
   Ghoddoosian R, 2019, IEEE COMPUT SOC CONF, P178, DOI 10.1109/CVPRW.2019.00027
   Goldberg P, 2021, EDUC PSYCHOL REV, V33, P27, DOI 10.1007/s10648-019-09514-z
   Gupta A, 2022, Arxiv, DOI arXiv:1609.01885
   Huang T, 2019, IEEE INT CONF ELECTR, P338, DOI [10.1109/ICEIEC.2019.8784559, 10.1109/iceiec.2019.8784559]
   Hutt S, 2019, USER MODEL USER-ADAP, V29, P821, DOI 10.1007/s11257-019-09228-5
   Janosz M, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P695, DOI 10.1007/978-1-4614-2018-7_33
   Ji YY, 2019, IEEE ACCESS, V7, P64136, DOI 10.1109/ACCESS.2019.2917382
   Khedher AB., 2019, J. Intell. Learn. Syst. Appl., V11, P1, DOI [10.4236/jilsa.2019.111001, DOI 10.4236/JILSA.2019.111001]
   Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002
   Lei H, 2018, SOC BEHAV PERSONAL, V46, P517, DOI 10.2224/sbp.7054
   Lewis D.D., 1994, MACH LEARN P 1994, P148
   Liao JC, 2021, APPL INTELL, V51, P6609, DOI 10.1007/s10489-020-02139-8
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu DZ, 2021, INT C PATT RECOG, P607, DOI 10.1109/ICPR48806.2021.9413094
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu R, 2017, IEEE WORK APPL SIG, P1, DOI 10.1109/WASPAA.2017.8169983
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003
   McNeal KS, 2020, CBE-LIFE SCI EDUC, V19, DOI 10.1187/cbe.19-08-0158
   Mehta NK, 2022, APPL INTELL, V52, P13803, DOI 10.1007/s10489-022-03200-4
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Ocumpaugh J., 2015, TEACHERS COLL COLUMB, V60
   ODonnell Angela M, 2006, ROLE PEERS GROUP LEA
   Okur E, 2017, LECT NOTES ARTIF INT, V10331, P250, DOI 10.1007/978-3-319-61425-0_21
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Ouyang F., 2021, COMPUTERS ED ARTIFIC, V2, P1, DOI [10.1016/j.caeai.2021.100020, DOI 10.1016/J.CAEAI.2021.100020]
   Pabba C, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12839
   Pan B, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03407-2
   Pekrun R., 2000, SOCIAL COGNITIVE CON
   Raca M, 2013, P 3 INT C LEARN AN K, P265
   Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471
   Sabourin JL, 2014, IEEE T AFFECT COMPUT, V5, P45, DOI 10.1109/T-AFFC.2013.27
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Schuller B, 2015, SMART INNOV SYST TEC, V37, P339, DOI 10.1007/978-3-319-18164-6_33
   SLAVIN RE, 1983, PSYCHOL BULL, V94, P429, DOI 10.1037/0033-2909.94.3.429
   Smallwood J, 2006, PSYCHOL BULL, V132, P946, DOI 10.1037/0033-2909.132.6.946
   Stewart A., 2017, GEN FACE BASED MIND
   Stewart A, 2017, LECT NOTES ARTIF INT, V10331, P359, DOI 10.1007/978-3-319-61425-0_30
   Sumer O, 2023, IEEE T AFFECT COMPUT, V14, P1012, DOI 10.1109/TAFFC.2021.3127692
   Thomas C, 2017, P 1 ACM SIGCHI INT W, P33, DOI DOI 10.1145/3139513.3139514
   Tölgyessy M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020413
   van de Grift WJCM, 2017, SCH EFF SCH IMPROV, V28, P337, DOI 10.1080/09243453.2016.1263215
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Xiang WB, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094689
   Yang JF, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P594, DOI 10.1145/3242969.3264981
   Ye M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199195
   Zaletelj J, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0228-8
   Zaletelj J, 2017, INT SYMP IMAGE SIG, P220, DOI 10.1109/ISPA.2017.8073599
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhang W, 2015, IEEE IJCNN
   Zhao S., 2019, ACM Trans.Multimedia Comput. Commun. Appl., V15, P1
NR 86
TC 0
Z9 0
U1 14
U2 29
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 18
DI 10.1007/s13735-023-00284-7
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N9TF9
UT WOS:001040344500001
DA 2024-07-18
ER

PT J
AU Li, RC
   Li, NN
   Wang, WM
AF Li, Ruochen
   Li, Nannan
   Wang, Wenmin
TI Maximizing mutual information inside intra- and inter-modality for
   audio-visual event retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Audio-visual retrieval; Variational autoencoder; Mutual information;
   InfoMax-VAE
AB The human brain can process sound and visual information in overlapping areas of the cerebral cortex, which means that audio and visual information are deeply correlated with each other when we explore the world. To simulate this function of the human brain, audio-visual event retrieval (AVER) has been proposed. AVER is about using data from one modality (e.g., audio data) to query data from another. In this work, we aim to improve the performance of audio-visual event retrieval. To achieve this goal, first, we propose a novel network, InfoIIM, which enhance the accuracy of intra-model feature representation and inter-model feature alignment. The backbone of this network is a parallel connection of two VAE models with two different encoders and a shared decoder. Secondly, to enable the VAE to learn better feature representations and to improve intra-modal retrieval performance, we have used InfoMax-VAE instead of the vanilla VAE model. Additionally, we study the influence of modality-shared features on the effectiveness of audio-visual event retrieval. To verify the effectiveness of our proposed method, we validate our model on the AVE dataset, and the results show that our model outperforms several existing algorithms in most of the metrics. Finally, we present our future research directions, hoping to inspire relevant researchers.
C1 [Li, Ruochen; Li, Nannan; Wang, Wenmin] Macau Univ Sci & Technol, Sch Engn & Comp Sci, Ave Wai Long, Taipa 999078, Macau, Peoples R China.
C3 Macau University of Science & Technology
RP Li, NN (corresponding author), Macau Univ Sci & Technol, Sch Engn & Comp Sci, Ave Wai Long, Taipa 999078, Macau, Peoples R China.
EM lircsszz@outlook.com; nnli@must.edu.mo; wmwang@must.edu.mo
RI Wang, Wenmin/W-3511-2019; Li, Ruochen/HHC-6630-2022
OI Wang, Wenmin/0000-0003-2664-4413; Li, Ruochen/0000-0002-4341-6474
FU Macau University of Science and Technology [FRG-22-102-FIE]
FX This project is supported by Funding for General Scientific Research of
   Macau University of Science and Technology (Grant No. FRG-22-102-FIE).
CR [Anonymous], 2021, ICASSP 2021 2021 IEE, DOI DOI 10.1109/ICASSP39728.2021.9414296
   Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73
   Arandjelovic Relja, 2018, P EUR C COMP VIS ECC, P435
   Aslaksen K, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01538
   Bowman S. R., 2015, GENERATING SENTENCES
   Chen Xi, 2016, ARXIV161102731
   Chung JS, 2020, INTERSPEECH, P2977, DOI 10.21437/Interspeech.2020-1064
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heller S, 2022, INT J MULTIMED INF R, V11, P1, DOI 10.1007/s13735-021-00225-2
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hong S, 2017, ARXIV170406761
   Kim Changil, 2018, P AS C COMP VIS ACCV, P276
   Li JJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1348, DOI 10.1145/3394171.3413503
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Nagrani A, 2018, LECT NOTES COMPUT SC, V11217, P73, DOI 10.1007/978-3-030-01261-8_5
   Nagrani A, 2018, PROC CVPR IEEE, P8427, DOI 10.1109/CVPR.2018.00879
   Ning HL, 2022, IEEE T MULTIMEDIA, V24, P1763, DOI 10.1109/TMM.2021.3071243
   Saeed MS, 2022, INT CONF ACOUST SPEE, P7057, DOI 10.1109/ICASSP43922.2022.9747704
   Smith HMJ, 2016, ATTEN PERCEPT PSYCHO, V78, P868, DOI 10.3758/s13414-015-1045-8
   Suresha M, 2020, INT J MULTIMED INF R, V9, P81, DOI 10.1007/s13735-019-00190-x
   Takida Y., 2021, ARXIV210208663
   Tian YP, 2018, LECT NOTES COMPUT SC, V11206, P252, DOI 10.1007/978-3-030-01216-8_16
   Wang H, 2020, COMPUT INTELL NEUROS, V2020
   Wang K., 2016, A comprehensive survey on cross-modal retrieval
   Wang LX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4610, DOI 10.1145/3394171.3416288
   Wen PS, 2021, PROC CVPR IEEE, P16342, DOI 10.1109/CVPR46437.2021.01608
   Wu F, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107335
   YanhuiWang Ning Xu, 2021, IEEE T CIRCUITS SYST
NR 29
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 10
DI 10.1007/s13735-023-00276-7
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F3SP7
UT WOS:000981579800001
DA 2024-07-18
ER

PT J
AU Sabahi, F
   Ahmad, MO
   Swamy, MNS
AF Sabahi, Farzad
   Omair Ahmad, M.
   Swamy, M. N. S.
TI A deep image retrieval network using Max-m-Min pooling and morphological
   feature generating residual blocks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image retrieval; Deep learning; Convolutional neural networks; Pooling;
   Morphological operation
AB The textural and structural information contained in the images is very important for generating highly discriminative features for the task of image retrieval. Morphological operations are nonlinear mathematical operations that can provide such textural and structural information. In this work, a new residual block based on a module using morphological operations coupled with an edge extraction module is proposed. A novel pooling operation focusing on the edges of the images is also proposed. A deep convolutional network is then designed using the proposed residual block and the new pooling operation that significantly improves its representational capacity. Extensive experiments are carried out to show the effectiveness of the ideas used in the design of the proposed deep image retrieval network. The proposed network is shown to significantly outperform existing state-of-the-art image retrieval networks on various benchmark datasets.
C1 [Sabahi, Farzad; Omair Ahmad, M.; Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ QC H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ QC H3G 1M8, Canada.
EM f_sabahi@encs.concordia.ca; omair@ece.concordia.ca;
   swamy@ece.concordia.ca
RI Sabahi, Farzad/JEF-1931-2023
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahmed KT, 2021, IEEE ACCESS, V9, P41934, DOI 10.1109/ACCESS.2021.3063545
   [Anonymous], 2009, CIFAR-100 (canadian institute for advanced research)
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bingyi Cao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P726, DOI 10.1007/978-3-030-58565-5_43
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Chen W, 2023, IEEE T PATTERN ANAL, V45, P7270, DOI 10.1109/TPAMI.2022.3218591
   Choi YR, 2021, IEEE T IMAGE PROCESS, V30, P1015, DOI 10.1109/TIP.2020.3040847
   Chollet F., KERAS
   Darlow L. N., 2018, arXiv
   Das P, 2017, INT J MULTIMED INF R, V6, P271, DOI 10.1007/s13735-017-0135-x
   Dubey SR, 2022, NEUROCOMPUTING, V503, P92, DOI 10.1016/j.neucom.2022.06.111
   Eghbali S, 2019, PROC CVPR IEEE, P11682, DOI 10.1109/CVPR.2019.01196
   Esmaeilzehi A, 2022, IEEE T BROADCAST, V68, P58, DOI 10.1109/TBC.2021.3126275
   Franchi G, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107246
   Gavali P, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P99, DOI 10.1016/B978-0-12-816718-2.00013-0
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Ghayoumi M, 2018, INT C MACH LEARN
   Gkelios S, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114940
   Jose A, 2018, IEEE IMAGE PROC, P480, DOI 10.1109/ICIP.2018.8451361
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050744
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rian Z, 2019, IEEE INT C SIGN SYST
   Rippel O., 2015, INT C NEUR INF PROC
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabahi F, 2022, IEEE INT MIDW S CIRC
   Satti P, 2020, IEEE SIGNAL PROC LET, V27, P1475, DOI 10.1109/LSP.2020.3016868
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Serra J., 1994, MATH MORPHOLOGY ITS
   Shen YM, 2020, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR42600.2020.00289
   Shi ZL, 2016, NEURAL NETWORKS, V83, P21, DOI 10.1016/j.neunet.2016.07.003
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Véstias MP, 2019, ALGORITHMS, V12, DOI 10.3390/a12080154
   Vharkate MN, 2022, MULTIMED TOOLS APPL, V81, P31787, DOI 10.1007/s11042-022-11997-y
   Wang B, 2013, IEEE INT C CONS EL
   Wang R, 2020, IEEE WINT CONF APPL
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Williams T, 2018, INT C LEARN REPR
   Wu M, 2019, IEEE INT GEOSC REM S
   Xu J, 2019, IEEE CVF INT C COMP
   Yu DJ, 2014, LECT NOTES ARTIF INT, V8818, P364, DOI 10.1007/978-3-319-11740-9_34
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zhi TC, 2016, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2016.7532802
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
   Zhu HP, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2019.102738
NR 52
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 8
DI 10.1007/s13735-023-00274-9
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5BR5
UT WOS:000975696700001
DA 2024-07-18
ER

PT J
AU Wundervald, B
AF Wundervald, Bruna
TI Cluster-based quotas for fairness improvements in music recommendation
   systems
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Fairness; Popularity bias; Cluster-based; Prediction quotas; Music
   recommendation systems
AB Increasingly, music recommendations are influencing user listening behavior, which naturally impacts the music industry, as well as the cultural and social aspects of our society. This has opened up a research area, namely the identification of biases introduced by recommender systems in the music context. Recent research, which focused on users of the Last.fm platform found that state-of-the-art music recommendation systems frequently tend to favor already popular items. To this end, we propose a new method for predicting music recommendations, which relies on a cluster-based quotas system. By assuming the distribution of the popularity of artists to have a latent variable that is estimated with a Gaussian Mixture, we find the underlying popularity clusters and use them to make the predictions by quotas that relate to each cluster mixing proportion, in a way that the resulting popularity distribution in the recommendations is closer to the popularity distribution seen in the data. In our experiments with the Last.fm data, our final predictions increased the recommendation frequencies of less popular artists, while preserving the specific characteristics of each algorithm. The GAP(g)(r) and mean average error (MAE) metrics are improved, showing that our recommendations are more accurate and approximate to the expected popularity of the artists in each user profile.
C1 [Wundervald, Bruna] Maynooth Univ, Maynooth, Kildare, Ireland.
C3 Maynooth University
RP Wundervald, B (corresponding author), Maynooth Univ, Maynooth, Kildare, Ireland.
EM bruna.wundervald@mu.ie
OI Wundervald, Bruna/0000-0001-8163-220X
CR Abdollahpouri H, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P42, DOI 10.1145/3109859.3109912
   [Anonymous], 2009, Music Recommendation and Discovery in the Long Tail
   Azpiazu I. M., 2018, C FAIRN ACC TRANSP P, P172
   Bauer C, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217389
   Cataltepe Z, 2009, COLLABORATIVE SOCIAL, P203
   Celma O., 2008, P 2 KDD WORKSH LARG, P1
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Chouldechova A., 2018, ARXIV PREPRINT ARXIV
   Karakayali N, 2018, THEOR CULT SOC, V35, P3, DOI 10.1177/0263276417722391
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Kowald Dominik, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P35, DOI 10.1007/978-3-030-45442-5_5
   Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433
   McLachlan G., 2007, EM ALGORITHM EXTENSI
   Mehrabi N., 2019, CORR
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Porcaro L, 2019, P 1 WORKSH DES HUM C
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Schedl M, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P103, DOI 10.1145/2911996.2912004
   Van den Oord A., 2013, P NIPS
   Verma S, 2018, 2018 IEEE/ACM INTERNATIONAL WORKSHOP ON SOFTWARE FAIRNESS (FAIRWARE 2018), P1, DOI [10.1145/3194770.3194776, 10.23919/FAIRWARE.2018.8452913]
   Wang SF, 2016, KNOWL-BASED SYST, V104, P145, DOI 10.1016/j.knosys.2016.04.018
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
NR 23
TC 7
Z9 7
U1 1
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2021
VL 10
IS 1
BP 25
EP 32
DI 10.1007/s13735-020-00203-0
EA JAN 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QV8OQ
UT WOS:000611080900001
DA 2024-07-18
ER

PT J
AU Ray, A
   Roy, S
AF Ray, Arkadip
   Roy, Somaditya
TI Recent trends in image watermarking techniques for copyright protection:
   a survey
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Watermarking; Copyright protection; Transform domain; Imperceptibility;
   Robustness
ID SINGULAR-VALUE DECOMPOSITION; DIGITAL IMAGES; WAVELET TRANSFORM;
   HOMOMORPHIC CRYPTOSYSTEM; ROBUST WATERMARKING; VISUAL CRYPTOGRAPHY;
   HIGHLY ROBUST; COLOR IMAGES; DWT-SVD; SCHEME
AB Digital copyright protection signifies the technology of rights protection, utilization control, and management of digital substances in the activity of production, propagation, retailing, and consumption. In the era of digital boom in information technology and multimedia, malicious exploitations and piracy have become a global phenomenon; thus, the need for digital content protection is inexorable. Image watermarking has been advocated universally to resolve innumerable dilemmas correlated with issues in the fields of digital rights management and multimedia security. According to anticipated applications, various suitable image watermarking procedures have been designed to safeguard the copyright of digital subjects. In this study, contemporary developments of digital image watermarking techniques are appraised so as to identify state-of-the-art practices and their limitations. This research contribution will be expedient for the academics in instigating efficient watermarking techniques for copyright authentication.
C1 [Ray, Arkadip] Govt Coll Engn & Ceram Technol, Dept Informat Technol, Kolkata 700010, W Bengal, India.
   [Roy, Somaditya] Techno Engn Coll Banipur, Dept Informat Technol, Habra 743233, W Bengal, India.
RP Ray, A (corresponding author), Govt Coll Engn & Ceram Technol, Dept Informat Technol, Kolkata 700010, W Bengal, India.
EM arka1dip2ray3@gmail.com; rsomaditya@gmail.com
OI Ray, Arkadip/0000-0002-3418-1888; Roy, Somaditya/0000-0002-4665-5219
CR Abbas NH, 2018, MULTIMED TOOLS APPL, V77, P24593, DOI 10.1007/s11042-017-5488-x
   Abbas SSA, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1, DOI 10.1109/WiSPNET.2016.7566077
   Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Al-Haj A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2017), P441, DOI 10.1109/INFOMAN.2017.7950424
   Al-Otum HM, 2019, MULTIMED TOOLS APPL, V78, P2199, DOI 10.1007/s11042-018-6328-3
   Al-Shayea TK, 2019, IEEE ICC
   Al-Shayea TK, 2019, IEEE INT WORKSH COMP, DOI 10.1109/camad.2019.8858489
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Amiri A, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-03452-0
   [Anonymous], 2016, P INT C REC COGN WIR
   Ansari IA, 2016, OPTIK, V127, P5711, DOI 10.1016/j.ijleo.2016.03.070
   Arrasyid Adli Azhar, 2018, 2018 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P522, DOI 10.1109/ISRITI.2018.8864461
   Assini I, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P574
   Bakhsh FY, 2018, J INF SECUR APPL, V41, P12, DOI 10.1016/j.jisa.2018.05.003
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Bharati S, 2018, 2018 INT C INN ENG T, P1, DOI [10.1109/CIET.2018.8660796, DOI 10.1109/ICAEEE.2018.8643004]
   Bhatnagar G, 2012, AEU-INT J ELECTRON C, V66, P275, DOI 10.1016/j.aeue.2011.08.005
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Borra S, 2019, INT J DIGIT CRIME FO, V11, P13, DOI 10.4018/IJDCF.2019040102
   Cetinel Gokcen, 2016, International Journal of Image, Graphics and Signal Processing, V8, P58, DOI 10.5815/ijigsp.2016.08.08
   Chauhan DS, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P626, DOI 10.1109/TSP.2017.8076062
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Dappuri B, 2020, MULTIMED TOOLS APPL, V79, P31103, DOI 10.1007/s11042-020-09433-0
   Darwish SM, 2020, MULTIMED TOOLS APPL, V79, P6503, DOI 10.1007/s11042-019-08290-w
   Das S., 2017, Journal of Bangladesh Agricultural University, V15, P7, DOI 10.3329/jbau.v15i1.33524
   De D, 2019, J COASTAL RES, P73, DOI 10.2112/SI86-011.1
   Degadwala SD, 2018, L N COMPUT VIS BIOME, V28, P902, DOI 10.1007/978-3-319-71767-8_77
   Devi BP, 2017, IETE J RES, V63, P870, DOI 10.1080/03772063.2017.1324328
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   El Houby EMF, 2020, MULTIMED TOOLS APPL, V79, P28453, DOI 10.1007/s11042-020-09333-3
   Ernawan F, 2019, IEEE ACCESS, V7, P151985, DOI 10.1109/ACCESS.2019.2948086
   Ernawan F, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P221, DOI 10.1109/CSPA.2018.8368716
   Ernawan F, 2017, INT CONF INTERNET, P92, DOI 10.23919/ICITST.2017.8356354
   Fatahbeygi A, 2019, J INF SECUR APPL, V45, P71, DOI 10.1016/j.jisa.2019.01.005
   Garg Palak, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P327, DOI 10.1007/978-981-13-2553-3_31
   Gonge SS, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P769, DOI 10.1109/IC3I.2016.7918064
   Gonge SS, 2015, COMM COM INF SC, V536, P290, DOI 10.1007/978-3-319-22915-7_28
   Gupta R, 2018, MULTIMED TOOLS APPL, V77, P19235, DOI 10.1007/s11042-017-5351-0
   Hamidi M, 2019, INFORMATION, V10, DOI 10.3390/info10020067
   Haribabu M, 2016, PROCEDIA COMPUT SCI, V93, P462, DOI 10.1016/j.procs.2016.07.234
   Harjito B, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P143, DOI 10.1109/ISESD.2016.7886708
   Harjito B, 2017, AIP CONF PROC, V1813, DOI 10.1063/1.4975968
   Heidari S, 2017, INT J THEOR PHYS, V56, P2562, DOI 10.1007/s10773-017-3412-9
   HEMDAN EE, 2020, MULTIMED TOOLS 0910
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Jagadeesh B, 2016, SOFT COMPUT, V20, P3679, DOI 10.1007/s00500-015-1729-y
   Jia SL, 2017, J APPL SCI ENG, V20, P193, DOI 10.6180/jase.2017.20.2.07
   Jiang XD, 2017, INT J INNOV COMPUT I, V13, P1709
   Juarez-Sandoval O, 2017, 2017 5 INT WORKSH BI, P1, DOI DOI 10.1109/IWBF.2017.7935084
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Kaur S, 2016, INT J EMERGING TECHN, V4, P59
   Kazemi MF, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0270-y
   Kazemi MF, 2020, COMPLEX INTELL SYST, V6, P213, DOI 10.1007/s40747-020-00129-4
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Khan MF, 2019, MEHRAN UNIV RES J EN, V38, P627, DOI 10.22581/muet1982.1903.09
   Khanam T, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010052
   Koley Subhadeep, 2019, Advances in Communication, Devices and Networking. ICCDN 2018. Proceedings: Lecture Notes in Electrical Engineering (LNEE 537), P201, DOI 10.1007/978-981-13-3450-4_23
   Kukreja S, 2020, MULTIMED TOOLS APPL, V79, P26155, DOI 10.1007/s11042-020-09130-y
   Kulkarni Pranesh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1443, DOI 10.1109/ICECA.2018.8474621
   Kumar KK, 2016, COMM COM INF SC, V628, P355, DOI 10.1007/978-981-10-3433-6_43
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lei BY, 2019, MULTIMED TOOLS APPL, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Maheswari S, 2015, RES J APPL SCI ENG T, V9, P507, DOI DOI 10.19026/RJASET.9.1433
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mallick AK, 2016, ADV INTELL SYST, V404, P589, DOI 10.1007/978-81-322-2695-6_50
   Manikandan VM, 2018, COMPUT ELECTR ENG, V72, P614, DOI 10.1016/j.compeleceng.2018.03.007
   Mardanpour M, 2016, ARXIV160309396
   Mascher A, 2006, P 13 INT C SYST SIGN, P53
   Mehta R, 2016, J SIGNAL PROCESS SYS, V84, P265, DOI 10.1007/s11265-015-1055-8
   Mishra A, 2019, MULTIMED TOOLS APPL, V78, P22127, DOI 10.1007/s11042-019-7452-4
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Murali P, 2018, OPTIK, V170, P242, DOI 10.1016/j.ijleo.2018.04.050
   Nagpal Sujata, 2016, International Journal of Modern Education and Computer Science, V8, P46, DOI 10.5815/ijmecs.2016.04.06
   Namachivayam A, 2017, ASIA PAC J RES, V1, P230
   Nguyen Chi Sy, 2020, International Journal of Machine Learning and Computing, V10, P675, DOI 10.18178/ijmlc.2020.10.5.990
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Noor R, 2019, SOFT COMPUT, V23, P9821, DOI 10.1007/s00500-019-03838-2
   Otto C, 2020, INT J MULTIMED INF R, V9, P31, DOI 10.1007/s13735-019-00187-6
   Pandey Mahendra Kumar, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P1269, DOI 10.1007/978-981-15-0751-9_116
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parekh M, 2018, ADV INTELL SYST, V710, P519, DOI 10.1007/978-981-10-7871-2_50
   Vo PH, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P331, DOI 10.1109/NAFOSTED.2017.8108087
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Prabha K, 2020, MULTIMED TOOLS APPL, V79, P6845, DOI 10.1007/s11042-019-08212-w
   Priya S, 2018, PERS UBIQUIT COMPUT, V22, P1141, DOI 10.1007/s00779-018-1131-8
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Rani A, 2016, MULTIMED TOOLS APPL, V75, P1027, DOI 10.1007/s11042-014-2344-0
   Rashid A., 2016, INT J COMPUTER APPL, V5, P147, DOI DOI 10.7753/IJCATR0503.1006
   Roy S, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170326
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Saxena P, 2019, AIR POLLUTION: SOURCES, IMPACTS AND CONTROLS, P1
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Sharmin S, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P215, DOI 10.1145/3300115.3309532
   Singh Astha, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P298, DOI 10.1109/IC3A48958.2020.233317
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED SYST APPL, P13, DOI 10.1007/978-3-319-57699-2_2
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh H, 2018, IET IMAGE PROCESS, V12, P1994, DOI 10.1049/iet-ipr.2018.5399
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh P, 2018, INFORM SCIENCES, V422, P77, DOI 10.1016/j.ins.2017.08.077
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Singh RP, 2016, NEUROCOMPUTING, V174, P238, DOI 10.1016/j.neucom.2015.03.115
   Singh R, 2018, METALS-BASEL, V8, DOI 10.3390/met8020127
   Singh SP, 2020, ADV INTELL SYST, V1024, P431, DOI 10.1007/978-981-32-9291-8_34
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Soppari K, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100287
   Su YG, 2019, J MOD OPTIC, V66, P377, DOI 10.1080/09500340.2018.1530387
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tagesse Takore Tamirat, 2018, 2nd International Conference on Micro-Electronics, Electromagnetics and Telecommunications, ICMEET 2016. Proceedings: LNEE 434, P51, DOI 10.1007/978-981-10-4280-5_6
   Takore Tamirat Tagesse, 2018, International Journal of Intelligent Systems and Applications, V10, P50, DOI 10.5815/ijisa.2018.11.06
   Tefas A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P597, DOI 10.1016/B978-0-12-374457-9.00022-6
   Thabit R., 2019, PERIOD POLYTECH ELEC, V63, P263, DOI [10.3311/PPee.14219, DOI 10.3311/PPEE.14219]
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2020, LECT NOTES ELECTR EN, V587, P897, DOI 10.1007/978-981-32-9775-3_80
   Thanki R., 2019, HDB MULTIMEDIA INFOR, P209
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Thanki RM, 2020, J AMB INTEL HUM COMP, V11, P1835, DOI 10.1007/s12652-019-01295-1
   Thanki RM, 2018, SIGNALS COMMUN TECHN, P137, DOI 10.1007/978-3-319-73183-4_7
   Vaidya SP, 2015, PROCEDIA COMPUT SCI, V58, P233, DOI 10.1016/j.procs.2015.08.063
   Venugopal T, 2018, INT J INTELL ENG SYS, V11, P271
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Xu W., 2019, IEEE 25 INT C MECH M
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
   Yu XY, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101227
   Yueh-Hong Chen, 2020, 2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech), P46, DOI 10.1109/LifeTech48969.2020.1570619213
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang YF, 2019, CIRC SYST SIGNAL PR, V38, P5135, DOI 10.1007/s00034-019-01112-2
   Zhang YP, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9020013
   Zhou Z, 2017, LECT NOTES COMPUT SC, V9317, P132, DOI 10.1007/978-3-319-53838-9_11
NR 138
TC 34
Z9 35
U1 6
U2 55
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2020
VL 9
IS 4
BP 249
EP 270
DI 10.1007/s13735-020-00197-9
EA OCT 2020
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OS6IE
UT WOS:000584860400001
DA 2024-07-18
ER

PT J
AU Sur, C
AF Sur, Chiranjib
TI MRECN: mixed representation enhanced (de)compositional network for
   caption generation from visual features, modeling as pseudo tensor
   product representation
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Language modeling; Representation learning; Mixed representation; Image
   description; Sequence generation; Image understanding; Automated textual
   feature extraction
ID ATTENTION
AB Semantic feature composition from image features has a drawback because it is unable to capture the content of the captions and failed to evolve as longer and meaningful captions. In this paper, we have proposed improvements on semantic features that can generate and evolve captions through the new approach called mixed fusion of representations and decomposition. Semantic works on the principle of using CNN visual features to generate context-word distribution and use that to generate captions using language decoder. Generated semantics are used for captioning, but have limitations. We have introduced a far better and newer approach with an enhanced representation-based network known as mixed representation enhanced (de)compositional network (MRECN), which can help produce better and different content for captions. As denoted from the results (0.351 BLUE_4), it has outperformed most of the state of the art. We defined a better feature decoding scheme using learned networks, which establishes an incoherence of related words into captions. From our research, we have come to some important conclusions regarding mixed representation strategies as it emerges as the most viable and promising way of representing the relationships of the sophisticated features for decision making and complex applications like the image to natural languages.
C1 [Sur, Chiranjib] Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL USA.
C3 State University System of Florida; University of Florida
RP Sur, C (corresponding author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL USA.
EM chiranjibsur@gmail.com
RI Sur, Chiranjib/Z-4268-2019
OI Sur, Chiranjib/0000-0002-1563-9304
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 2015, ARXIV150504467
   [Anonymous], 2018, ARXIV180500063
   [Anonymous], 2018, ARXIV180508389
   [Anonymous], 2017, ARXIV170406972
   Chen FH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P46, DOI 10.1145/3123266.3123275
   Chen FH, 2018, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2018.00146
   Chen H., 2017, ARXIV171202051
   Chen H, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P606, DOI 10.1109/ITME.2018.00139
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   Chen T., 2018, ARXIV180703871
   Cohn-Gordon Reuben, 2018, ARXIV180405417
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fu K, 2018, IEEE T NEUR NET LEAR, V29, P5910, DOI 10.1109/TNNLS.2018.2813306
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Gan Z, 2016, ARXIV161108002
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Harzig P, 2018, ARXIV180201958
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang W, 2018, ARXIV180400887
   JIN J, 2015, ARXIV150606272
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Levy A, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-017-0270-7
   Liu C, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4033
   Liu CX, 2017, AAAI CONF ARTIF INTE, P4176
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Liu X, 2018, ARXIV180308314
   Lu D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4013
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   MAO J, 2014, ARXIVPREPRINTARXIV14
   Mao J., 2015, ICCV
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Park CC, 2018, IEEE T PATTERN ANAL, V40, P945, DOI 10.1109/TPAMI.2017.2700381
   Park CC, 2017, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2017.681
   Pu YC, 2016, ADV NEUR IN, V29
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shang C, 2015, IEEE IC COMP COM NET
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Sur C, 2020, ARXIV200206701
   Sur C, 2020, ARXIV200206436
   Sur C, 2019, ARXIV191110115
   Sur C, 2020, ARXIV200614264
   Sur C, 2020, ARXIV200109545
   Sur C, 2018, ARXIV PREPRINT ARXIV
   Sur C, 2019, ARXIV PREPRINT ARXIV
   Sur C, 2020, ARXIV200614262
   Sur C, 2020, COMPUT SCI, V1, P229, DOI [10.1007/s42979-020-00238-4, DOI 10.1007/S42979-020-00238-4]
   Sur C, 2019, 5TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2019), P33, DOI 10.1109/BIGCOM.2019.00013
   Sur C, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1765-9
   Sur C, 2019, MULTIMED TOOLS APPL, V78, P32187, DOI 10.1007/s11042-019-08021-1
   Sur C, 2019, EVOL INTELL, V12, P689, DOI 10.1007/s12065-019-00278-7
   Sur C, 2019, MED BIOL ENG COMPUT, V57, P2483, DOI 10.1007/s11517-019-02038-2
   Sur C, 2019, J AMB INTEL HUM COMP, V10, P3573, DOI 10.1007/s12652-018-1084-9
   Sutskever I., 2011, P INT C MACHINE LEAR
   Sutskever I, 2014, ADV NEUR IN, V27
   Tran K, 2016, IEEE COMPUT SOC CONF, P434, DOI 10.1109/CVPRW.2016.61
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu CL, 2018, SIGNAL PROCESS-IMAGE, V67, P100, DOI 10.1016/j.image.2018.06.002
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu J, 2018, ARXIV180508661
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Yang Zhilin, 2016, Advances in Neural Information Processing Systems
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Ye SM, 2018, IEEE T IMAGE PROCESS, V27, P5514, DOI 10.1109/TIP.2018.2855406
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   You Quanzeng, 2018, ARXIV180110121
   Zhang L, 2017, ARXIV PREPRINT ARXIV
   Zhang Mingxing., 2018, IEEE Transactions on Image Processing
   Zhao W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1205
NR 83
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2020
VL 9
IS 4
BP 291
EP 316
DI 10.1007/s13735-020-00198-8
EA OCT 2020
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OS6IE
UT WOS:000583950900001
DA 2024-07-18
ER

PT J
AU Mirasadi, MS
   Foruzan, AH
AF Mirasadi, Mansoureh Sadat
   Foruzan, Amir Hossein
TI Content-based medical image retrieval of CT images of liver lesions
   using manifold learning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Focal liver lesions; Manifold learning; Image retrieval; Liver tumors;
   Multi-phase CT images
AB Accurate retrieval of liver CT images can help a specialist to decide on the type of lesion and treatment planning. However, the complex texture of the abnormality and its nonlinear characteristic reduces the recognition rate of a retrieval system. In this paper, we propose how to represent an abnormal region of a liver by individual attributes of a multi-phase CT image. The indexing of a medical image database is represented by a correlation graph distance, which considers nonlinear behavior of the feature space as well. The results showed that the average recall was improved by 7.5% using the proposed feature vector. Concerning a complex scheme for lesion representation and the manifold indexing technique, the recall of the system was increased by twice. The proposed indexing and feature representation prove the potential of our method in content-based medical image retrieval systems.
C1 [Mirasadi, Mansoureh Sadat; Foruzan, Amir Hossein] Shahed Univ, Dept Biomed Engn, Engn Fac, Persian Gulf Highway, Tehran 3319118651, Iran.
C3 Shahed University
RP Foruzan, AH (corresponding author), Shahed Univ, Dept Biomed Engn, Engn Fac, Persian Gulf Highway, Tehran 3319118651, Iran.
EM m.mirasadi@shahed.ac.ir; aforuzan@yahoo.com
RI Foruzan, Amir Hossein/ABE-3280-2021
OI Foruzan, Amir Hossein/0000-0003-0177-3227
CR Conjeti S, 2018, THESIS
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Ghodsi A., 2006, DIMENSIONALITY REDUC, V37, P38
   Golchin Elnaz., 2014, INT J BIOMED ENG TEC, V1, P23
   Pedronette DCG, 2018, PATTERN RECOGN, V75, P161, DOI 10.1016/j.patcog.2017.05.009
   Pedronette DCG, 2017, NEUROCOMPUTING, V260, P478, DOI 10.1016/j.neucom.2017.04.062
   Pedronette DCG, 2016, NEUROCOMPUTING, V208, P66, DOI 10.1016/j.neucom.2016.03.081
   Heidari Hadis, 2013, International Journal of Information Technology and Computer Science, V6, P33, DOI 10.5815/ijitcs.2014.01.04
   Li ZY, 2018, MED IMAGE ANAL, V43, P66, DOI 10.1016/j.media.2017.09.007
   Ma L, 2017, J BIOMED INFORM, V66, P148, DOI 10.1016/j.jbi.2017.01.002
   Malviya N., 2017, Advances in Computational Sciences and Technology, V10, P1577
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Roy S, 2014, IEEE T BIO-MED ENG, V61, P2768, DOI 10.1109/TBME.2014.2329057
   Satish B, 2017, 2017 INT C EL EL COM
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010
   Wang J, 2020, PATTERN RECOGN LETT, V130, P207, DOI 10.1016/j.patrec.2019.01.001
   Webber W, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852106
   Xu YY, 2018, INT J COMPUT ASS RAD, V13, P151, DOI 10.1007/s11548-017-1671-9
   Zin NAM, 2018, J PHYS CONF SER, V1019, DOI 10.1088/1742-6596/1019/1/012044
NR 21
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2019
VL 8
IS 4
BP 233
EP 240
DI 10.1007/s13735-019-00179-6
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KN5AU
UT WOS:000514850500004
DA 2024-07-18
ER

PT J
AU Kale, VV
   Hamde, ST
   Holambe, RS
AF Kale, Vandana V.
   Hamde, Satish T.
   Holambe, Raghunath S.
TI Brain disease diagnosis using local binary pattern and steerable pyramid
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Magnetic resonance imaging; Local binary pattern; Steerable pyramid;
   Feature extraction; Backpropagation neural network
ID COMPUTER-AIDED DIAGNOSIS; SUPPORT VECTOR MACHINE; WAVELET TRANSFORM;
   CLASSIFICATION; IMAGES; MRI; ADABOOST
AB Brain diseases can cause invisible disorders, cognitive and behavioral changes. Their symptoms vary widely. In some cases, treatment can improve the symptoms while in other cases injuries become permanent. Many disorders are progressive. Therefore, early and accurate diagnosis of disorder is essential for improving disorder condition and patient's quality of life. This paper presents the brain disease diagnosis system in which two feature extraction methods are compared. One of the feature extraction methods uses local binary pattern and steerable pyramid (SP) to decompose magnetic resonance (MR) brain images into subbands which are termed as LBPSP subbands. Another feature extraction method uses SP solely to decompose MR images into SP subbands. Energies over LBPSP and SP subbands are calculated. The features are subjected to backpropagation neural network classifier. To prove the effectiveness of the proposed system, multi-class disease classification is carried out on four MR image datasets. Also, 'one-vs-all' binary classification is performed on one of the datasets. Energy features of LBPSP subbands achieve multi-class classification accuracies of 97.67%, 97.27%, 94.67% and 85.01% on datasets DS-200, DS-310, DS-255 and DS-612, respectively. The performance measures of 'one-vs-all' binary class classification prove the competency and efficiency of LBPSP subband features over the existing methods.The comparative results of two feature extraction methods indicate that the energy features of LBPSP subbands have more discriminating potential than energy features of SP subbands. Experimental results reveal that energy features of LBPSP subbands lead to the existing classification methods.
C1 [Kale, Vandana V.] AISSMS Inst Informat Technol, Dept Instrumentat Engn, Pune 411001, Maharashtra, India.
   [Hamde, Satish T.; Holambe, Raghunath S.] SGGS Inst Engn & Technol, Dept Instrumentat Engn, Nanded 431606, Maharashtra, India.
C3 AISSMS Institute of information Technology; Shri Guru Gobind Singhji
   Institute of Engineering & Technology
RP Kale, VV (corresponding author), AISSMS Inst Informat Technol, Dept Instrumentat Engn, Pune 411001, Maharashtra, India.
EM vandanav_kale@yahoo.co.in; sthamde@sggs.ac.in; rsholambe@sggs.ac.in
RI Kale, Vandana/HMD-6387-2023; Holambe, Raghunath/AAH-9879-2019
OI Kale, Vandana/0000-0002-7724-9977
CR Bishop C. M., 1995, NEURAL NETWORKS PATT
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   El Aroussi M, 2009, INT J SIGNAL PROCESS, V5, P4
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Gudigar A, 2019, FUTURE GENER COMP SY, V90, P359, DOI 10.1016/j.future.2018.08.008
   Hagan M. T., 2014, NEURAL NETWORK DESIG
   Haykin S., 1994, NEURAL NETWORKS COMP
   Khalil M, 2018, PROCEDIA COMPUT SCI, V127, P218, DOI 10.1016/j.procs.2018.01.117
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Nanni L, 2011, EXPERT SYST APPL, V38, P6209, DOI 10.1016/j.eswa.2010.11.048
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Nayak DR, 2018, IEEE T SUSTAIN COMPU
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Perry Sprawls, 2000, MAGNETIC RESONANCE I
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2016, BIOMED ENG-BIOMED TE, V61, P431, DOI 10.1515/bmt-2015-0152
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 31
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2019
VL 8
IS 3
BP 155
EP 165
DI 10.1007/s13735-019-00174-x
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS8RG
UT WOS:000482416600003
DA 2024-07-18
ER

PT J
AU Ayuba, S
   Zainon, WMNW
AF Ayuba, Shehu
   Zainon, Wan Mohd Nazmee Wan
TI Medical image watermarking: a survey on applications, approach and
   performance requirement compliance
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Medical-Image; Watermarking-Requirement; MIW-Application;
   Authentication; Copyright-protection; Fingerprinting
ID REVERSIBLE WATERMARKING; SCHEME; ALGORITHM; DCT
AB Medical images are fundamentally utilized for rendering diagnostic and treatment to patients. Medical images are a patient body or part captured using medical imaging devices such as CT, X-Ray, PET, MRI, and US. Technological advancement introduces E-Healthcare systems, Telemedicine, and Electronic Health Information Systems (EHIS) enabling medical images to flow over the public network for remote healthcare services. The manipulation or replacement of medical images is fatal to the well-being of a patient, thereby requiring protection using watermarking. Watermarking is a data security approach toward protecting medical images against abuse by unauthorized personnel via providing confidentiality, authentication, and integrity verification. The dynamism and importance of medical image watermarking require constant literature update on trends, issues, and challenges which leading to the forgoing research survey. The survey proposes to highlight trending application areas in medical image watermarking research and evaluation of the recent approach adopted by researchers. Furthermore, the survey evaluates existing work in compliance with the standard benchmark requirement in design and performance and presents a discussion on the way forward to other possible research opportunities in the medical image watermarking domain.
C1 [Ayuba, Shehu; Zainon, Wan Mohd Nazmee Wan] Univ Sains Malaysia USM, Sch Comp Sci, Minden 11800, Penang, Malaysia.
   [Ayuba, Shehu] Aliko Dangote Univ Sci & Technol, Dept Comp Sci, Kano 713281, Nigeria.
C3 Universiti Sains Malaysia
RP Ayuba, S (corresponding author), Univ Sains Malaysia USM, Sch Comp Sci, Minden 11800, Penang, Malaysia.; Ayuba, S (corresponding author), Aliko Dangote Univ Sci & Technol, Dept Comp Sci, Kano 713281, Nigeria.
EM shehu_ayuba@student.usm.my
CR Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   Allaf AH, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON SMART CITY APPLICATIONS (SCA'18), DOI 10.1145/3286606.3286823
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Alshoura WH, 2021, IEEE ACCESS, V9, P32931, DOI 10.1109/ACCESS.2021.3060861
   Anand S, INT J ENG SCI RES TE
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Benyoussef M, 2014, INT CONF MULTIMED, P93, DOI 10.1109/ICMCS.2014.6911198
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   di Vimercati SD, 2003, SOFTWARE PRACT EXPER, V33, P397, DOI 10.1002/spe.513
   Ebrahimnejad J, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104831
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Giri KJ, 2019, INT J E-HEALTH MED C, V10, P30, DOI 10.4018/IJEHMC.2019100103
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hema M, 2022, IMPROVED HYBRID DCT
   Hisham SI., 2013, BIOMED ENG RES, V2, P79, DOI [10.5963/BER0202004, DOI 10.5963/BER0202004]
   Hu K, 2021, VISUAL COMPUT, V37, P2841, DOI 10.1007/s00371-021-02168-5
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Kelkar V, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3538979
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Krupinski EA, 2010, ATTEN PERCEPT PSYCHO, V72, P1205, DOI 10.3758/APP.72.5.1205
   Kumar Basant, 2015, 2015 38th International Conference on Telecommunications and Signal Processing (TSP), P1, DOI 10.1109/TSP.2015.7296412
   Kumar S, 2018, AIP CONF PROC, V1953, DOI [10.1109/CSITSS.2018.8768733, 10.1063/1.5032491]
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P9315, DOI 10.1007/s11042-020-09943-x
   Lakshmi C, 2018, COMPUT METH PROG BIO, V159, P11, DOI 10.1016/j.cmpb.2018.02.021
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Liew SC, 2013, J DIGIT IMAGING, V26, P316, DOI 10.1007/s10278-012-9484-4
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Mukhopadhyay SC., 2014, Inernet of Things: Challenges and Opportunities, DOI [10.1007/978-3-319-04223-7, DOI 10.1007/978-3-319-04223-7]
   Navas K, 2007, 2007 14 INT WORKSH S, P237
   Navas K., 2007, P INTERNATION C SCI, P25
   Novamizanti L., 2020, Int. J. Intell. Eng. Syst., V13, P266
   Nyeem H, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-135
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Ouazzane Hana, 2019, International Journal of Medical Engineering and Informatics, V11, P330
   Pan W, 2018, COMPUT METH PROG BIO, V160, P119, DOI 10.1016/j.cmpb.2018.03.011
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Pramanik P.K.D., 2019, Telemedicine Technologies, P201
   Priya S, 2017, 2017 INTERNATIONAL CONFERENCE ON ALGORITHMS, METHODOLOGY, MODELS AND APPLICATIONS IN EMERGING TECHNOLOGIES (ICAMMAET)
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Rahman AU, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8137436
   Rajani D, 2022, J APPL SEC RES, V17, P103, DOI 10.1080/19361610.2020.1838251
   Rajkumar S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i47/105556, DOI 10.17485/IJST/2016/V9I47/105556]
   Ramzan M, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100717
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Rao N.V., 2011, CVR Journal of Science and Technology, V1, P1
   Rathi SC, 2012, HLTH INFORMATICS AN, V1
   Rocek A, 2021, J DIGIT IMAGING, V34, P204, DOI 10.1007/s10278-020-00396-0
   Sajedi H, 2018, NETW MODEL ANAL HLTH, V7, DOI 10.1007/s13721-018-0169-x
   Satbirkaur M, INT J ENG SCI RES TE
   Seenivasagam V, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/516465
   Singh A, 2017, INT J E-HEALTH MED C, V8, P38, DOI 10.4018/IJEHMC.2017070103
   Singh AK, 2017, MULTIMED SYST APPL, P13, DOI 10.1007/978-3-319-57699-2_2
   Singh P, 2022, IEEE ACCESS, V10, P8974, DOI 10.1109/ACCESS.2022.3143801
   Sinhal R, 2022, MULTIMED TOOLS APPL, V81, P14045, DOI 10.1007/s11042-022-12082-0
   Soualmi Abdallah, 2021, International Journal of Computer Vision and Image Processing, V11, DOI 10.4018/IJCVIP.2021010101
   Soualmi A, 2022, INT J INF SECUR PRIV, V16, DOI 10.4018/IJISP.2022010102
   Soualmi A, 2021, MULTIMED TOOLS APPL, V80, P2279, DOI 10.1007/s11042-020-09614-x
   Swaraja K, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102688
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thabit R, 2021, MULTIMED TOOLS APPL, V80, P13439, DOI 10.1007/s11042-020-10421-7
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Thanki R, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0795-3
   Turuk M, 2018, J DIGIT IMAGING, V31, P167, DOI 10.1007/s10278-017-0024-0
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Venkatram N., 2014, IMAGE, V20, P23
   Verma U, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103694
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Xia ZQ, 2022, APPL INTELL, V52, P607, DOI 10.1007/s10489-021-02476-2
   Zaidan BB, 2017, SOFTWARE PRACT EXPER, V47, P1365, DOI 10.1002/spe.2465
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
NR 76
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 33
DI 10.1007/s13735-023-00290-9
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R6XM3
UT WOS:001065765400001
DA 2024-07-18
ER

PT J
AU Yan, J
   Xie, YX
   Luan, XD
   Guo, YM
   Gong, QZ
   Feng, SR
AF Yan, Jie
   Xie, Yuxiang
   Luan, Xidao
   Guo, Yanming
   Gong, Quanzhi
   Feng, Suru
TI Caption TLSTMs: combining transformer with LSTMs for image captioning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image captioning; Transformer; Abstract scene graph; Deep learning
ID LANGUAGE
AB Image to captions has attracted widespread attention over the years. Recurrent neural networks (RNN) and their corresponding variants have been the mainstream when it comes to dealing with image captioning task for a long time. However, transformer-based models have shown powerful and promising performance on visual tasks contrary to classic neural networks. In order to extract richer and more robust multimodal intersection feature representation, we improve the original abstract scene graph to caption model and propose the Caption TLSTMs which is made up of two LSTMs with Transformer blocks in the middle of them in this paper. Compared with the model before improvement, the architecture of our Caption TLSTMs enables the entire network to make the most of the long-term dependencies and feature representation ability of the LSTM, while encoding the multimodal textual, visual and graphic information with the transformer blocks as well. Finally, experiments on VisualGenome and MSCOCO datasets have shown good performance in improving the general image caption generation quality, demonstrating the effectiveness of the Caption TLSTMs model.
C1 [Yan, Jie; Xie, Yuxiang; Guo, Yanming; Gong, Quanzhi; Feng, Suru] Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Hunan, Peoples R China.
   [Luan, Xidao] Changsha Univ, Coll Comp Engn & Appl Math, Changsha 410000, Hunan, Peoples R China.
C3 National University of Defense Technology - China; Changsha University
RP Xie, YX (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Hunan, Peoples R China.
EM yjierrr@163.com; xyx89@163.com; xidaoluan@ccsu.cn;
   guoyanming@nudt.edu.cn; charles_g27@qq.com; fengsuru7636@163.com
RI yan, jie/HNJ-0097-2023; yan, jy/ISS-1790-2023
FU National Natural Science Foundation of China [61571453, 61806218]
FX This work has been supported by the National Natural Science Foundation
   of China under Contract Nos. 61571453 and 61806218.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2012, P AAAI C ART INT
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Deng J., 2009, IEEE C COMP VIS PATT
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Han K, 2020, ARXIV211106091
   Herdade S, 2019, ADV NEUR IN, V32
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Irie K, 2019, LANGUAGE MODELING DE
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khan S., 2021, Transformers in vision: A survey
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li RF, 2020, NEUROCOMPUTING, V396, P92, DOI 10.1016/j.neucom.2020.02.041
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu X, 2021, VIDEO IS WORTH 3 VIE
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schlichtkrull Michael, 2018, PROC EUR SEMANTIC WE, P593
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Soltau H, 2017, INTERSPEECH, P3707, DOI 10.21437/Interspeech.2017-1566
   Sun G, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7363, DOI 10.1109/ICASSP39728.2021.9414477
   Sutskever I, 2014, ADV NEUR IN, V27
   Ushiku Y, 2015, IEEE I CONF COMP VIS, P2668, DOI 10.1109/ICCV.2015.306
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2021, REFORMER RELATIONAL
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhu XX, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050739
NR 45
TC 5
Z9 5
U1 8
U2 55
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 111
EP 121
DI 10.1007/s13735-022-00228-7
EA MAR 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000772255300001
DA 2024-07-18
ER

PT J
AU Hafiz, AM
   Bhat, GM
AF Hafiz, Abdul Mueed
   Bhat, Ghulam Mohiuddin
TI A survey on instance segmentation: state of the art
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Instance segmentation; Object detection; Convolutional neural networks;
   Deep learning
ID DEEP; IMAGE; RECOGNITION; NETWORKS; MODELS
AB Object detection or localization is an incremental step in progression from coarse to fine digital image inference. It not only provides the classes of the image objects, but also provides the location of the image objects which have been classified. The location is given in the form of bounding boxes or centroids. Semantic segmentation gives fine inference by predicting labels for every pixel in the input image. Each pixel is labelled according to the object class within which it is enclosed. Furthering this evolution, instance segmentation gives different labels for separate instances of objects belonging to the same class. Hence, instance segmentation may be defined as the technique of simultaneously solving the problem of object detection as well as that of semantic segmentation. In this survey paper on instance segmentation, its background, issues, techniques, evolution, popular datasets, related work up to the state of the art and future scope have been discussed. The paper provides valuable information for those who want to do research in the field of instance segmentation.
C1 [Hafiz, Abdul Mueed; Bhat, Ghulam Mohiuddin] Univ Kashmir, Inst Technol, Dept Elect & Commun Engn, Srinagar 190006, J&k, India.
C3 University of Kashmir
RP Hafiz, AM (corresponding author), Univ Kashmir, Inst Technol, Dept Elect & Commun Engn, Srinagar 190006, J&k, India.
EM mueedhafiz@uok.edu.in; drgmbhat@uok.edu.in
RI Hafiz, Abdul Mueed/AAF-3806-2020
OI Hafiz, Abdul Mueed/0000-0002-2266-3708
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   AHMED P, 2000, J KING SAUD UNIV-COM, V12, P85
   [Anonymous], ARXIV161002579
   [Anonymous], ARXIV12111552
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], ARXIV170802551
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arnab A, 2017, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2017.100
   Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   BUNKE H, 1994, HDB CHARACTER RECOGN
   Burger H., 2012, CVPR
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao Y., 2019, CORR, P1, DOI [DOI 10.1109/ICCVW.2019.00246, 10.1109/ICCVW.2019.00246]
   Chandra S, 2017, IEEE I CONF COMP VIS, P5113, DOI 10.1109/ICCV.2017.546
   Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647
   Chellappa R, 2016, IMAGE VISION COMPUT, V55, P3, DOI 10.1016/j.imavis.2016.04.005
   Chen Hao, 2020, 2020 IEEE C COMP VIS, DOI [DOI 10.48550/ARXIV.2001.00309, DOI 10.1109/CVPR42600.2020.00860]
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   CHEN LC, 2017, ARXIV PREPRINT ARXIV, V1706, P5587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254
   Chen XL, 2019, IEEE I CONF COMP VIS, P2061, DOI 10.1109/ICCV.2019.00215
   Chen Y, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1467, DOI 10.1109/ICISCE.2017.306
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DICKINSON SJ, 2009, OBJECT CATEGORIZATIO
   EARNEST LD, 1963, INFORMATION PROCESSI, P462
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   Hariharan B, 2017, IEEE T PATTERN ANAL, V39, P627, DOI 10.1109/TPAMI.2016.2578328
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   Harley AW, 2017, IEEE I CONF COMP VIS, P5048, DOI 10.1109/ICCV.2017.539
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu Jie, 2018, P IEEE C COMP VIS PA
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kirillov A, 2017, PROC CVPR IEEE, P7322, DOI 10.1109/CVPR.2017.774
   Kirsch R.A., 1957, Papers and Discussions Presented at the December 9-13, 1957, Eastern Joint Computer Conference: Computers with Deadlines to Meet, P221
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee Y, 2019, ARXIV191106667, P13903
   Lee Y.J., 2019, arXiv:1904.02689
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   LENC K, 2015, PROC CVPR IEEE, P991
   LI J, 2017, ARXIV170507206
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu NP, 2016, DESIGN, MANUFACTURING AND MECHATRONICS (ICDMM 2015), P534
   Liu S., 2017, P ADV NEUR INF PROC, V30, P1519
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W., 2015, ARXIV150604579
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Moore GeorgeA., 1968, PICTORIAL PATTERN RE, P275
   Mordan T, 2019, INT J COMPUT VISION, V127, P1659, DOI 10.1007/s11263-018-1109-z
   MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468
   Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   NOUBOUD F, 1990, PATTERN RECOGN, V23, P1031, DOI 10.1016/0031-3203(90)90111-W
   OGORMAN L, 1995, DOCUMENT IMAGE ANAL
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pinheiro P.O., 2015, Learning to Segment Object Candidates
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   REN S, 2017, OBJECT DETECTION NET
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, P318
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schwing A., 2015, Fully Connected Deep Structured Networks
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang Y., 2013, DEEP LEARNING USING
   Tang YY, 1996, PATTERN RECOGN, V29, P1931, DOI 10.1016/S0031-3203(96)00044-1
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uhrig J, 2016, LECT NOTES COMPUT SC, V9796, P14, DOI 10.1007/978-3-319-45886-1_2
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X., 2020, Advances in Neural information processing systems
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Xie E., 2019, ARXIV190913226
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xinlong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P649, DOI 10.1007/978-3-030-58523-5_38
   Yu F., 2015, ARXIV
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   ZHAO J, 2018, ARXIV180403287V3
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou J, 2018, ARXIV181208434
   Zhu XX, 2016, INT J COMPUT VISION, V119, P76, DOI 10.1007/s11263-015-0812-2
NR 136
TC 196
Z9 219
U1 20
U2 75
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2020
VL 9
IS 3
BP 171
EP 189
DI 10.1007/s13735-020-00195-x
EA JUL 2020
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MQ6SK
UT WOS:000545199700001
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Zhang, R
   He, N
   Liu, SJ
   Wu, Y
   Yan, K
   He, YZ
   Lu, K
AF Zhang, Ren
   He, Ning
   Liu, Shengjie
   Wu, Ying
   Yan, Kang
   He, Yuzhe
   Lu, Ke
TI Your heart rate betrays you: multimodal learning with spatio-temporal
   fusion networks for micro-expression recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Micro-expression; Multimodal learning; Spatio-temporal feature fusion;
   Optical flow
AB Micro-expressions can convey feelings that people are trying to hide. At present, some studies on micro-expression, most of which only use the temporal or spatial information in the image to recognize micro-expressions, neglect the intrinsic features of the image. To solve this problem, we detect the subject's heart rate in the long micro-expression videos; we extract the image's spatio-temporal feature through a spatio-temporal network and then extract the heart rate feature using a heart rate network. A multimodal learning method that combines the heart rate and spatio-temporal features is used to recognize micro-expressions. The experimental results on CASMEII, SAMM, and SMIC show that the proposed methods' unweighted F1-score and unweighted average recall are 0.8867 and 0.8962, respectively. The spatio-temporal fusion network combined with heart rate information provides an essential reference for multimodal approaches to micro-expression recognition.
C1 [Zhang, Ren; He, Ning; Liu, Shengjie; Yan, Kang; He, Yuzhe] Beijing Union Univ, Beijing 100101, Peoples R China.
   [Wu, Ying] Beijing Informat Sci Technol Univ, Beijing 100101, Peoples R China.
   [Lu, Ke] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
C3 Beijing Union University; Beijing Information Science & Technology
   University; Chinese Academy of Sciences; University of Chinese Academy
   of Sciences, CAS
RP He, N (corresponding author), Beijing Union Univ, Beijing 100101, Peoples R China.
EM 851769359@qq.com; xxthening@buu.edu.cn; 1290542855@qq.com;
   wuying-2015s@outlook.com; 1399471158@qq.com; 849836043@qq.com;
   luk@ucas.ac.cn
RI Liu, Shengjie/AAP-8939-2020
OI Liu, Shengjie/0000-0003-0253-7410
FU National Natural Science Foundation of China [61872042, 61972375,
   62172045]; Key Project of Beijing Municipal Commission of Education
   [KZ201911417048]; Premium Funding Project for Academic Human Resources
   Development in Beijing Union University [BPHR2020AZ01, BPH2020EZ01];
   Science and Technology Project of Beijing Municipal Commission of
   Education [KM202111417009, KM201811417005]; Major Project of
   Technological Innovation 2030-"New Generation Artificial Intelligence"
   [2018AAA0100800]
FX This work is supported by the National Natural Science Foundation of
   China (61872042, 61972375, 62172045), the Key Project of Beijing
   Municipal Commission of Education (KZ201911417048), the Major Project of
   Technological Innovation 2030-"New Generation Artificial Intelligence"
   (2018AAA0100800), Premium Funding Project for Academic Human Resources
   Development in Beijing Union University (BPHR2020AZ01, BPH2020EZ01), and
   the Science and Technology Project of Beijing Municipal Commission of
   Education (KM202111417009, KM201811417005).
CR Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Gan YS, 2019, SIGNAL PROCESS-IMAGE, V74, P129, DOI 10.1016/j.image.2019.02.005
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krishnamurthy G., 2018, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Liong ST, 2019, IEEE INT CONF AUTOMA, P658, DOI 10.1109/fg.2019.8756567
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Liu YC, 2019, IEEE INT CONF AUTOMA, P631, DOI 10.1109/fg.2019.8756583
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   O'Sullivan M, 2009, LAW HUMAN BEHAV, V33, P530, DOI 10.1007/s10979-008-9166-4
   Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Rouast P. V., 2016, APPL INFORMATICS TEC, P1, DOI DOI 10.1007/978-3-319-41402-7_20
   Samadiani N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081863
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Van Quang N., 2019, IEEE INT CONF AUTOMA, DOI [10.1109/FG.2019.8756544, DOI 10.1109/fg.2019.8756544]
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Wang CY, 2020, NEUROCOMPUTING, V410, P354, DOI 10.1016/j.neucom.2020.06.005
   Weinberger S, 2010, NATURE, V465, P412, DOI 10.1038/465412a
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Zhang C, 2019, PROC CVPR IEEE, P12579, DOI 10.1109/CVPR.2019.01287
   Zhang R, 2022, MULTIMEDIA SYST, V28, P335, DOI 10.1007/s00530-021-00842-1
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
NR 32
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 553
EP 566
DI 10.1007/s13735-022-00250-9
EA OCT 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000865370700001
DA 2024-07-18
ER

PT J
AU Xie, YX
   Yan, J
   Kang, L
   Guo, YM
   Zhang, JH
   Luan, XD
AF Xie, Yuxiang
   Yan, Jie
   Kang, Lai
   Guo, Yanming
   Zhang, Jiahui
   Luan, Xidao
TI FCT: fusing CNN and transformer for scene classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Scene classification; Convolutional neural networks; Vision transformer;
   Deep learning
AB Scene classification based on convolutional neural networks (CNNs) has achieved great success in recent years. In CNNs, the convolution operation performs well in extracting local features, but its ability to capture global feature representations is limited. In vision transformer (ViT), the self-attention mechanism can capture long-term feature dependencies, but it breaks down the details of local features. In this work, we make full use of the advantages of the CNN and ViT and propose a Transformer-based framework that combines CNN to improve the discriminative ability of features for scene classification. Specifically, we take the deep convolutional feature as the input and establish the scene Transformer module to extract the global feature in the scene image. An end-to-end scene classification framework called the FCT is built by fusing the CNN and scene Transformer module. Experimental results show that our FCT achieves a new state-of-the-art performance on two standard benchmarks MIT Indoor 67 and SUN 397, with the accuracy of 90.75% and 77.50%, respectively.
C1 [Xie, Yuxiang; Yan, Jie; Kang, Lai; Guo, Yanming; Zhang, Jiahui] Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Hunan, Peoples R China.
   [Luan, Xidao] Changsha Univ, Coll Comp Engn & Appl Math, Changsha 410000, Hunan, Peoples R China.
C3 National University of Defense Technology - China; Changsha University
RP Guo, YM (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Hunan, Peoples R China.
EM xyx89@163.com; yjierrr@163.com; kanglai@nudt.edu.cn;
   guoyanming@nudt.edu.cn; 100634004@qq.com; xidaoluan@ccsu.cn
RI Zhang, Jiahui/ISU-9234-2023; yan, jy/ISS-1790-2023; yan,
   jie/HNJ-0097-2023
FU National Natural Science Foundation of China (NSFC) [61873274]
FX This research was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant No. 61873274.
CR Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen BH, 2018, PATTERN RECOGN, V76, P339, DOI 10.1016/j.patcog.2017.10.039
   Chen GW, 2020, IEEE T IMAGE PROCESS, V29, P5877, DOI 10.1109/TIP.2020.2986599
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen M, 2020, PR MACH LEARN RES, V119
   Chen Y., 2021, ARXIV
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dixit M, 2016, ADV NEUR IN, V29
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Hao SY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14061507
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Khan SH, 2017, IEEE I CONF COMP VIS, P5639, DOI 10.1109/ICCV.2017.601
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laranjeira C, 2019, SIBGRAPI, P249, DOI 10.1109/SIBGRAPI.2019.00041
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li YS, 2017, IEEE I CONF COMP VIS, P5757, DOI 10.1109/ICCV.2017.613
   Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2335, DOI 10.1109/TPAMI.2017.2651061
   Liu Y, 2018, AAAI CONF ARTIF INTE, P7178
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   López-Cifuentes A, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107256
   Lv PY, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3157671
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Qiu J., 2021, P IEEECVF C COMPUTER, P8322
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sicre R, 2017, PROC CVPR IEEE, P3116, DOI 10.1109/CVPR.2017.332
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2017, IEEE T IMAGE PROCESS, V26, P2028, DOI 10.1109/TIP.2017.2666739
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie L, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107205
   Zeng HT, 2022, IEEE T MULTIMEDIA, V24, P141, DOI 10.1109/TMM.2020.3046877
   Zeng HT, 2020, IEEE T MULTIMEDIA, V22, P1519, DOI 10.1109/TMM.2019.2944241
   Zhang JR, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13204143
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu X., 2020, arXiv
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 44
TC 5
Z9 5
U1 13
U2 50
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 611
EP 618
DI 10.1007/s13735-022-00252-7
EA SEP 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000854741900002
DA 2024-07-18
ER

PT J
AU Patrikar, DR
   Parate, MR
AF Patrikar, Devashree R.
   Parate, Mayur Rajaram
TI Anomaly detection using edge computing in video surveillance system:
   review
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Video surveillance; Anomaly detection; Edge computing; Machine learning
ID ABNORMAL EVENT DETECTION; DEEP NEURAL-NETWORKS; ADVERSARIAL NETWORK;
   ACTION RECOGNITION; CLOUD; LOCALIZATION; INTERNET; INTELLIGENCE;
   REPRESENTATION; FRAMEWORK
AB The current concept of smart cities influences urban planners and researchers to provide modern, secured and sustainable infrastructure and gives a decent quality of life to its residents. To fulfill this need, video surveillance cameras have been deployed to enhance the safety and well-being of the citizens. Despite technical developments in modern science, abnormal event detection in surveillance video systems is challenging and requires exhaustive human efforts. In this paper, we focus on evolution of anomaly detection followed by survey of various methodologies developed to detect anomalies in intelligent video surveillance. Further, we revisit the surveys on anomaly detection in the last decade. We then present a systematic categorization of methodologies for anomaly detection. As the notion of anomaly depends on context, we identify different objects-of-interest and publicly available datasets in anomaly detection. Since anomaly detection is a time-critical application of computer vision, we explore the anomaly detection using edge devices and approaches explicitly designed for them. The confluence of edge computing and anomaly detection for real-time and intelligent surveillance applications is also explored. Further, we discuss the challenges and opportunities involved in anomaly detection using the edge devices.
C1 [Patrikar, Devashree R.; Parate, Mayur Rajaram] Indian Inst Informat Technol, Nagpur, Maharashtra, India.
RP Patrikar, DR (corresponding author), Indian Inst Informat Technol, Nagpur, Maharashtra, India.
EM devashreepatrikar@gmail.com; mparate@iiitn.ac.in
CR Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Ajay BS, 2021, I CONF VLSI DESIGN, P175, DOI 10.1109/VLSID51830.2021.00035
   Angelini F, 2019, INT CONF ACOUST SPEE, P8444, DOI 10.1109/ICASSP.2019.8683026
   Asad M, 2021, VISUAL COMPUT, V37, P1415, DOI 10.1007/s00371-020-01878-6
   Ata-Ur-Rehman, 2021, IEEE ACCESS, V9, P19457, DOI 10.1109/ACCESS.2021.3054040
   Bansod SD, 2020, VISUAL COMPUT, V36, P609, DOI 10.1007/s00371-019-01647-0
   Bergman, 2020, ARXIV200210445
   Bock F, 2020, IEEE T INTELL TRANSP, V21, P496, DOI 10.1109/TITS.2019.2899149
   Bonetto M, 2015, IEEE IMAGE PROC, P2464, DOI 10.1109/ICIP.2015.7351245
   Bozcan, 2021, ARXIV PREPRINT ARXIV
   Chakravarthy AS, DRONESEGNET ROBUST A
   [陈珺娴 Chen Junxian], 2020, [高分子通报, Polymer Bulletin], P1
   Chen TH, 2015, DES AUT CON, DOI 10.1145/2744769.2744837
   Cheng H, 2022, IEEE T CLOUD COMPUT, V10, P1413, DOI 10.1109/TCC.2020.2990946
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Choi K, 2021, IEEE ACCESS, V9, P120043, DOI 10.1109/ACCESS.2021.3107975
   Chowdhury S., 2020, ARXIV PREPRINT ARXIV
   Chriki A, 2020, IEEE SYMP COMP COMMU, P152
   Chriki A, 2021, MULTIMED TOOLS APPL, V80, P2599, DOI 10.1007/s11042-020-09774-w
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Deng XH, 2021, COMPUT COMMUN, V166, P254, DOI 10.1016/j.comcom.2020.10.012
   Dinh TQ, 2018, IEEE T COMMUN, V66, P6353, DOI 10.1109/TCOMM.2018.2866572
   Dong F, 2020, IEEE ACCESS, V8, P88170, DOI 10.1109/ACCESS.2020.2993373
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Elgarrai Z, 2016, INT J MULTIMED INF R, V5, P229, DOI 10.1007/s13735-016-0113-8
   Ergen T, 2020, IEEE T NEUR NET LEAR, V31, P3127, DOI 10.1109/TNNLS.2019.2935975
   Farooq MU, 2017, INT J ADV COMPUT SC, V8, P270
   Ganokratanaa T, 2020, IEEE ACCESS, V8, P50312, DOI 10.1109/ACCESS.2020.2979869
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Ghosh AM, 2021, IEEE T IND INFORM, V17, P2191, DOI 10.1109/TII.2020.3008711
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo DS, 2018, IEEE T MULTIMEDIA, V20, P3428, DOI 10.1109/TMM.2018.2839534
   Guo F, 2019, IEEE T VEH TECHNOL, V68, P5618, DOI 10.1109/TVT.2019.2907692
   Hamdi S, 2021, J IMAGING, V7, DOI 10.3390/jimaging7050090
   Han X, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P745
   Hou JY, 2018, IEEE T MULTIMEDIA, V20, P1537, DOI 10.1109/TMM.2017.2771462
   Hu PF, 2017, IEEE T IND INFORM, V13, P1910, DOI 10.1109/TII.2016.2607178
   Hu WM, 2020, IEEE T KNOWL DATA EN, V32, P218, DOI 10.1109/TKDE.2018.2882404
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Isupova, 2016, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1606.08455, DOI 10.48550/ARXIV.1606.08455]
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang T, 2020, IEEE T GEOSCI REMOTE, V58, P4666, DOI 10.1109/TGRS.2020.2965961
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kang JW, 2018, IEEE T INTELL TRANSP, V19, P2627, DOI 10.1109/TITS.2017.2764095
   Ke RM, 2021, IEEE T INTELL TRANSP, V22, P4962, DOI 10.1109/TITS.2020.2984197
   Ke RM, 2019, IEEE T INTELL TRANSP, V20, P54, DOI 10.1109/TITS.2018.2797697
   Ke RM, 2017, IEEE T INTELL TRANSP, V18, P890, DOI 10.1109/TITS.2016.2595526
   Khan SD, 2021, VISUAL COMPUT, V37, P2127, DOI 10.1007/s00371-020-01974-7
   Kim JH, 2021, IEEE ACCESS, V9, P123348, DOI 10.1109/ACCESS.2021.3109904
   Kim WJ, 2020, IEEE ACCESS, V8, P116881, DOI 10.1109/ACCESS.2020.3004571
   Kong XJ, 2021, IEEE INTERNET THINGS, V8, P15929, DOI 10.1109/JIOT.2021.3051844
   Kumar D, 2017, VISUAL COMPUT, V33, P265, DOI 10.1007/s00371-015-1192-x
   Kumaran, 2019, ARXIV PREPRINT ARXIV
   Lai CF, 2019, IEEE T IND INFORM, V15, P2469, DOI 10.1109/TII.2019.2892818
   Lamba S., 2019, VISUAL COMPUT, P1
   Lao WL, 2009, IEEE T CONSUM ELECTR, V55, P591, DOI 10.1109/TCE.2009.5174427
   Lee SW, 2010, IEEE T KNOWL DATA EN, V22, P479, DOI 10.1109/TKDE.2009.123
   Lei J, 2020, IEEE T GEOSCI REMOTE, V58, P7406, DOI 10.1109/TGRS.2020.2982406
   Li LZ, 2018, IEEE T IND INFORM, V14, P4665, DOI 10.1109/TII.2018.2842821
   Li LH, 2021, IEEE T IND INFORM, V17, P4168, DOI 10.1109/TII.2020.3009111
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li XL, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P54, DOI 10.1109/CISP-BMEI.2016.7852681
   Li YS, 2018, IEEE ACCESS, V6, P40281, DOI 10.1109/ACCESS.2018.2851747
   Li ZY, 2020, IEEE ACCESS, V8, P25531, DOI 10.1109/ACCESS.2020.2970497
   Liu CS, 2019, IEEE T INTELL TRANSP, V20, P2122, DOI 10.1109/TITS.2018.2859348
   Liu JX, 2021, VISUAL COMPUT, V37, P359, DOI 10.1007/s00371-020-01804-w
   Liu PC, 2017, IEEE T CYBERNETICS, V47, P3719, DOI 10.1109/TCYB.2016.2578639
   Liu SW., 2018, ELECT IMAGING, V2018, P1, DOI DOI 10.2352/ISSN.2470-1173.2018.09.IRIACV-239
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Long CC, 2018, IEEE T MULTIMEDIA, V20, P1126, DOI 10.1109/TMM.2017.2764330
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Ma X, 2021, IEEE T CLOUD COMPUT, V9, P968, DOI 10.1109/TCC.2019.2903240
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Nieto RM, 2019, IEEE T INTELL TRANSP, V20, P1069, DOI 10.1109/TITS.2018.2838128
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Muhammad K, 2020, IEEE T IND INFORM, V16, P1067, DOI 10.1109/TII.2019.2915592
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Nguyen V., 2015, Annals of Data Science, V2, P21, DOI DOI 10.1007/S40745-015-0030-3
   Nikouei SY, 2021, IEEE T SERV COMPUT, V14, P1624, DOI 10.1109/TSC.2019.2916416
   Nikouei SY, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P256, DOI 10.1109/CIC.2018.00042
   Oza P, 2019, IEEE SIGNAL PROC LET, V26, P277, DOI 10.1109/LSP.2018.2889273
   Parate, 2021, ARXIV PREPRINT ARXIV
   Parate MR, 2018, APPL INTELL, V48, P300, DOI 10.1007/s10489-017-0974-4
   Parate MR, 2017, KSII T INTERNET INF, V11, P4909, DOI 10.3837/tiis.2017.10.013
   Kumar MRP, 2021, INT J MULTIMED INF R, V10, P1, DOI 10.1007/s13735-020-00196-w
   Perera P., 2021, ARXIV PREPRINT ARXIV
   Perveen N, 2018, IEEE T IMAGE PROCESS, V27, P5575, DOI 10.1109/TIP.2018.2856373
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Puvvadi ULN, 2015, IEEE T IND INFORM, V11, P1457, DOI 10.1109/TII.2015.2491259
   Qiang Y, 2021, IEEE ACCESS, V9, P68108, DOI 10.1109/ACCESS.2021.3077577
   Ramachandra B, 2022, IEEE T PATTERN ANAL, V44, P2293, DOI 10.1109/TPAMI.2020.3040591
   Ren WY, 2015, VISUAL COMPUT, V31, P245, DOI 10.1007/s00371-013-0915-0
   Rezaee Khosro, 2024, Personal and Ubiquitous Computing, V28, P135, DOI 10.1007/s00779-021-01586-5
   Ristea, 2021, ARXIV PREPRINT ARXIV
   Rodrigues TG, 2017, IEEE T COMPUT, V66, P810, DOI 10.1109/TC.2016.2620469
   Roy D, 2022, IEEE T INTELL TRANSP, V23, P3137, DOI 10.1109/TITS.2020.3031984
   Roy D, 2019, IEEE T MULTIMEDIA, V21, P1672, DOI 10.1109/TMM.2018.2887021
   Sabih M, 2022, VISUAL COMPUT, V38, P1719, DOI 10.1007/s00371-021-02100-x
   Sabokrou M, 2021, IEEE T NEUR NET LEAR, V32, P675, DOI 10.1109/TNNLS.2020.2979049
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Samuel D.J., 2021, Svd-gan for real-time unsupervised video anomaly detection
   Sarker MI, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21123993
   Saypadith S, 2021, IEEE ACCESS, V9, P150903, DOI 10.1109/ACCESS.2021.3126335
   Schneible J, 2017, IEEE MILIT COMMUN C, P678, DOI 10.1109/MILCOM.2017.8170817
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Shirahama K, 2015, INT J MULTIMED INF R, V4, P17, DOI 10.1007/s13735-014-0068-6
   Shobha B. S., 2018, 2018 3rd International Conference on Computational Systems and Information Technology for Sustainable Solutions (CSITSS), P183, DOI 10.1109/CSITSS.2018.8768743
   Shojaei G, 2019, INT J MULTIMED INF R, V8, P241, DOI 10.1007/s13735-019-00180-z
   Singh D, 2019, IEEE T INTELL TRANSP, V20, P879, DOI 10.1109/TITS.2018.2835308
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Song H, 2020, IEEE T MULTIMEDIA, V22, P2138, DOI 10.1109/TMM.2019.2950530
   Srivastava S, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P111, DOI 10.1109/CICT.2016.30
   Sun C, 2021, IEEE T MULTIMEDIA, V23, P3292, DOI 10.1109/TMM.2020.3023303
   Sun H, 2020, IEEE ACCESS, V8, P11615, DOI 10.1109/ACCESS.2019.2963159
   Suresha M, 2020, INT J MULTIMED INF R, V9, P81, DOI 10.1007/s13735-019-00190-x
   Suto K, 2015, IEEE TRANS COMPUT SO, V2, P127, DOI 10.1109/TCSS.2016.2518208
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tian B, 2015, IEEE T INTELL TRANSP, V16, P557, DOI 10.1109/TITS.2014.2340701
   Torres BS, 2018, VISUAL COMPUT, V34, P145, DOI 10.1007/s00371-016-1321-1
   Tripathi G, 2019, VISUAL COMPUT, V35, P753, DOI 10.1007/s00371-018-1499-5
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Ullah W, 2022, FUTURE GENER COMP SY, V129, P286, DOI 10.1016/j.future.2021.10.033
   Ullah W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082811
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Varghese B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P20, DOI 10.1109/SmartCloud.2016.18
   Vosta S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031021
   Wan SH, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108146
   Wang CJ, 2020, IEEE T IND INFORM, V16, P2667, DOI 10.1109/TII.2019.2945362
   Wang T, 2018, MULTIMED TOOLS APPL, V77, P17375, DOI 10.1007/s11042-017-5309-2
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang XJ, 2018, IEEE T IND INFORM, V14, P4568, DOI 10.1109/TII.2018.2816590
   Wang YX, 2019, IEEE T IND INFORM, V15, P976, DOI 10.1109/TII.2018.2883991
   Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554
   Xu K, 2018, IEEE T MULTIMEDIA, V20, P1062, DOI 10.1109/TMM.2018.2818942
   Xu RH, 2018, IEEE ICC
   Xu XL, 2020, IEEE INTERNET THINGS, V7, P7919, DOI [10.1109/TITS.2020.2995622, 10.1109/JIOT.2020.3000871]
   Xu YC, 2020, IEEE GEOSCI REMOTE S, V17, P1248, DOI 10.1109/LGRS.2019.2943861
   Xu Z, 2021, IEEE ACCESS, V9, P68482, DOI 10.1109/ACCESS.2021.3077499
   Yang L, 2016, IEEE T COMPUT, V65, P1440, DOI 10.1109/TC.2015.2435781
   Yang P, 2020, IEEE T IND INFORM, V16, P4855, DOI 10.1109/TII.2019.2949347
   Yang ZW, 2021, IEEE ACCESS, V9, P107842, DOI 10.1109/ACCESS.2021.3100678
   Yu BS, 2017, IEEE T SYST MAN CY-S, V47, P704, DOI 10.1109/TSMC.2016.2638048
   Yuan G, 2017, ARTIF INTELL REV, V47, P123, DOI 10.1007/s10462-016-9477-7
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zahra A, 2024, MULTIMED TOOLS APPL, V83, P15313, DOI 10.1007/s11042-021-11468-w
   Zhai, 2020, INT PETR TECHN C ONE
   Zhang JL, 2021, IEEE T IND INFORM, V17, P5012, DOI 10.1109/TII.2020.3007792
   Zhang QC, 2018, IEEE T IND INFORM, V14, P3170, DOI 10.1109/TII.2018.2808910
   Zhang WC, 2021, IEEE ACCESS, V9, P124847, DOI 10.1109/ACCESS.2021.3110798
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang Z, 2016, IEEE INTELL SYST, V31, P29, DOI 10.1109/MIS.2015.95
   Zhao Y, 2020, IEEE T COGN COMMUN, V6, P1146, DOI 10.1109/TCCN.2020.2999479
   Zheng XT, 2022, CAAI T INTELL TECHNO, V7, P419, DOI 10.1049/cit2.12068
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou Y, 2018, IEEE T INTELL TRANSP, V19, P1973, DOI 10.1109/TITS.2017.2740303
NR 168
TC 33
Z9 36
U1 19
U2 113
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 85
EP 110
DI 10.1007/s13735-022-00227-8
EA MAR 2022
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000776409700001
PM 35368446
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Heller, S
   Gsteiger, V
   Bailer, W
   Gurrin, C
   Jónsson, BT
   Lokoc, J
   Leibetseder, A
   Mejzlík, F
   Peska, L
   Rossetto, L
   Schall, K
   Schoeffmann, K
   Schuldt, H
   Spiess, F
   Tran, LD
   Vadicamo, L
   Vesely, P
   Vrochidis, S
   Wu, JX
AF Heller, Silvan
   Gsteiger, Viktor
   Bailer, Werner
   Gurrin, Cathal
   Jonsson, Bjorn Thor
   Lokoc, Jakub
   Leibetseder, Andreas
   Mejzlik, Frantisek
   Peska, Ladislav
   Rossetto, Luca
   Schall, Konstantin
   Schoeffmann, Klaus
   Schuldt, Heiko
   Spiess, Florian
   Tran, Ly-Duyen
   Vadicamo, Lucia
   Vesely, Patrik
   Vrochidis, Stefanos
   Wu, Jiaxin
TI Interactive video retrieval evaluation at a distance: comparing sixteen
   interactive video search systems in a remote setting at the 10th Video
   Browser Showdown
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Interactive video retrieval; Video browsing; Video content analysis;
   Content-based retrieval; Evaluations
AB The Video Browser Showdown addresses difficult video search challenges through an annual interactive evaluation campaign attracting research teams focusing on interactive video retrieval. The campaign aims to provide insights into the performance of participating interactive video retrieval systems, tested by selected search tasks on large video collections. For the first time in its ten year history, the Video Browser Showdown 2021 was organized in a fully remote setting and hosted a record number of sixteen scoring systems. In this paper, we describe the competition setting, tasks and results and give an overview of state-of-the-art methods used by the competing systems. By looking at query result logs provided by ten systems, we analyze differences in retrieval model performances and browsing times before a correct submission. Through advances in data gathering methodology and tools, we provide a comprehensive analysis of ad-hoc video search tasks, discuss results, task design and methodological challenges. We highlight that almost all top performing systems utilize some sort of joint embedding for text-image retrieval and enable specification of temporal context in queries for known-item search. Whereas a combination of these techniques drive the currently top performing systems, we identify several future challenges for interactive video search engines and the Video Browser Showdown competition itself.
C1 [Heller, Silvan; Gsteiger, Viktor; Schuldt, Heiko; Spiess, Florian] Univ Basel, Dept Math & Comp Sci, Basel, Switzerland.
   [Bailer, Werner] Joanneum Res, Graz, Austria.
   [Gurrin, Cathal; Tran, Ly-Duyen] Dublin City Univ, Dublin, Ireland.
   [Jonsson, Bjorn Thor] IT Univ Copenhagen, Copenhagen, Denmark.
   [Lokoc, Jakub; Mejzlik, Frantisek; Peska, Ladislav; Vesely, Patrik] Charles Univ Prague, Dept Software Engn, Prague, Czech Republic.
   [Leibetseder, Andreas; Schoeffmann, Klaus] Klagenfurt Univ, Klagenfurt, Austria.
   [Rossetto, Luca] Univ Zurich, Dept Informat, Zurich, Switzerland.
   [Schall, Konstantin] HTW Berlin, Visual Comp Grp, Berlin, Germany.
   [Vadicamo, Lucia] CNR, Inst Informat Sci & Technol ISTI, Pisa, Italy.
   [Vrochidis, Stefanos] Ctr Res & Technol Hellas CERTH, Informat Technol Inst ITI, Thessaloniki, Greece.
   [Wu, Jiaxin] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 University of Basel; Dublin City University; IT University Copenhagen;
   Charles University Prague; University of Klagenfurt; University of
   Zurich; Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); Centre for
   Research & Technology Hellas; City University of Hong Kong
RP Heller, S (corresponding author), Univ Basel, Dept Math & Comp Sci, Basel, Switzerland.
EM silvan.heller@unibas.ch; v.gsteiger@gmail.com; wemer.bailer@joanneum.at;
   cathal.gurrin@dcu.ie; bjth@itu.dk; jakub.lokoc@matfyz.cuni.cz;
   aleibets@itec.aau.at; frankinejzlik@gmail.com;
   ladislav.peska@matfyz.cuni.cz; rossetto@ifi.uzh.ch;
   konstantin.schall@htw-berlin.de; ks@itec.aau.at;
   heiko.schuldt@unibas.ch; florian.spiess@unibas.ch; ly.tran2@mail.dcu.ie;
   lucia.vadicamo@isti.cnr.it; prtrikvesely@gmail.com; stefanos@iti.gr;
   jiaxin.wu@my.cityu.edu.hk
RI Wu, Jiaxin/GVT-3486-2022; Gurrin, Cathal/Q-4442-2019; Vadicamo,
   Lucia/P-5138-2018; Peška, Ladislav/HTQ-1107-2023; Leibetseder,
   Andreas/AAI-2725-2020; Lokoč, Jakub/P-1216-2017; Rossetto,
   Luca/AAI-8684-2020
OI Gurrin, Cathal/0000-0003-2903-3968; Vadicamo, Lucia/0000-0001-7182-7038;
   Peška, Ladislav/0000-0001-8082-4509; Leibetseder,
   Andreas/0000-0002-9535-966X; Rossetto, Luca/0000-0002-5389-9465; Bailer,
   Werner/0000-0003-2442-4900; wu, jiaxin/0000-0003-4074-3442; Tran,
   Allie/0000-0002-9597-1832; Jonsson, Bjorn THor/0000-0003-0889-3491;
   Gsteiger, Viktor/0000-0002-6750-5500; Mejzlik,
   Frantisek/0000-0002-2636-0915; Schuldt, Heiko/0000-0001-9865-6371
FU Czech Science Foundation (GACR) [19-22071Y]; EU [825079, 951911]; FWF
   Austrian Science Fund [P 32010-N38]; Swiss National Science Foundation
   [CRSII5_193788]; Science Foundation Ireland [18/CRT/6223, 18/CRT/6224,
   SFI/12/RC/2289_2, SFI/13/RC/2106]; Science Foundation Ireland (SFI)
   [18/CRT/6224] Funding Source: Science Foundation Ireland (SFI); Swiss
   National Science Foundation (SNF) [CRSII5_193788] Funding Source: Swiss
   National Science Foundation (SNF)
FX This work was partially funded by the Czech Science Foundation (GACR)
   under project 19-22071Y, by the EU's Horizon 2020 research and
   innovation programme under the grant agreements no 825079, MindSpaces,
   and no 951911, AI4Media A European Excellence Centre for Media, Society
   and Democracy, by the FWF Austrian Science Fund under grant P 32010-N38,
   by the Swiss National Science Foundation (project "Participatory
   Knowledge Practices in Analog and Digital Image Archives", contract no.
   CRSII5_193788) and by Science Foundation Ireland under grant numbers
   18/CRT/6223, 18/CRT/6224, SFI/12/RC/2289_2 and SFI/13/RC/2106.
CR Amato G., 2021, INT C MULT MOD SPRIN, V2573, P473
   Amato G, 2021, J IMAGING, V7, DOI 10.3390/jimaging7050076
   Amato G, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095740
   Andreadis S., 2021, INT C MULT MOD, V2573, P398, DOI [10.1007/978-3-030-67835-7_35, DOI 10.1007/978-3-030-67835-7_35]
   Benavente R, 2008, J OPT SOC AM A, V25, P2582, DOI 10.1364/JOSAA.25.002582
   Berns F, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P334, DOI 10.1145/3323873.3325051
   Bochkovskiy A., 2020, PREPRINT
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P361, DOI 10.1109/ICPR.1996.546971
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Galanopoulos Damianos, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P336, DOI 10.1145/3372278.3390737
   Gasser R, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4465, DOI 10.1145/3394171.3414538
   Gurrin C, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P690, DOI 10.1145/3460426.3470945
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Heller Silvan, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P435, DOI 10.1007/978-3-030-67835-7_41
   Heller S, 2020, IEEE INT CONF MULTI
   Hezel N, 2021, INT C MULT MOD, P484, DOI DOI 10.1007/978-3-030-67835-7_49
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jiaxin Wu, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P391, DOI 10.1007/978-3-030-67835-7_34
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karisch Christof, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P405, DOI 10.1007/978-3-030-67835-7_36
   Kay W., 2017, ARXIV170506950
   Khan Omar Shahbaz, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P495, DOI 10.1007/978-3-030-45439-5_33
   Khan O.S., 2021, INT C MULT MOD, P410, DOI DOI 10.1007/978-3-030-67835-7_37
   Kratochvíl M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lee Y, INT C MULT MOD, P423, DOI [10.1007/978-3-030-67835-7_39, DOI 10.1007/978-3-030-67835-7_39]
   Leibetseder Andreas, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P455, DOI 10.1007/978-3-030-67835-7_44
   Leibetseder A, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P23, DOI 10.1145/3463948.3469060
   Li XR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1786, DOI 10.1145/3343031.3350906
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lokoc Jakub, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P429, DOI 10.1007/978-3-030-67835-7_40
   Lokoc J, 2022, LECT NOTES COMPUT SC, V13141, P193, DOI 10.1007/978-3-030-98358-1_16
   Lokoc J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2553, DOI 10.1145/3394171.3414002
   Lokoc J, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3445031
   Lokoc J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1777, DOI 10.1145/3343031.3351046
   Ly-Duyen Tran, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P490, DOI 10.1007/978-3-030-67835-7_50
   Markatopoulou F., 2017, P TRECVID 2017 WORKS
   Messina N, 2021, INT C PATT RECOG, P5222, DOI 10.1109/ICPR48806.2021.9413172
   Mettes P, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377875
   Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464
   Peska L, INT C MULT MOD, P467, DOI [10.1007/978-3-030-67835-7_46, DOI 10.1007/978-3-030-67835-7_46]
   Nguyen PA, 2020, LECT NOTES COMPUT SC, V11962, P772, DOI 10.1007/978-3-030-37734-2_68
   Nguyen PA, 2018, LECT NOTES COMPUT SC, V10705, P407, DOI 10.1007/978-3-319-73600-6_42
   Pittaras N, 2017, LECT NOTES COMPUT SC, V10132, P102, DOI 10.1007/978-3-319-51811-4_9
   Radford A, 2021, PR MACH LEARN RES, V139
   Redmon J., 2018, YOLOV3 OPEN IMAGES D
   Ressmann Anja, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P479, DOI 10.1007/978-3-030-67835-7_48
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Rossetto Luca, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P417, DOI 10.1007/978-3-030-67835-7_38
   Rossetto L., 2019, ARXIV190912526 CORR
   Rossetto L, 2021, ARXIV210501475 CORR
   Rossetto L., 2018, THESIS U BASEL, DOI [10.5451/unibas-006859522, DOI 10.5451/UNIBAS-006859522]
   Rossetto L, 2021, IEEE MULTIMEDIA, V28, P18, DOI 10.1109/MMUL.2021.3066779
   Rossetto L, 2021, IEEE T MULTIMEDIA, V23, P243, DOI 10.1109/TMM.2020.2980944
   Rossetto L, 2019, LECT NOTES COMPUT SC, V11295, P349, DOI 10.1007/978-3-030-05710-7_29
   Rossetto L, 2019, LECT NOTES COMPUT SC, V11296, P616, DOI 10.1007/978-3-030-05716-9_55
   Rossetto L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P18, DOI 10.1109/ISM.2014.38
   Rossetto Luca, 2021, INT CONFMULTIMEDIA M, P385
   Schall K, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901787
   Schoeffmann K, 2021, VBS 2021 OVERVIEW
   Schoeffmann K, 2019, INT WORK CONTENT MUL
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Souek T., 2020, ARXIV200804838 CORR
   Spiess Florian, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P441, DOI 10.1007/978-3-030-67835-7_42
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vesely P., 2021, INT C MULT MOD, P461, DOI [10.1007/978-3-030-67835-7_45, DOI 10.1007/978-3-030-67835-7_45]
   Wu JX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3357, DOI 10.1145/3394171.3413916
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Zhang HY, 2021, PROC CVPR IEEE, P8510, DOI 10.1109/CVPR46437.2021.00841
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 79
TC 25
Z9 25
U1 2
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2022
VL 11
IS 1
BP 1
EP 18
DI 10.1007/s13735-021-00225-2
EA JAN 2022
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI9SJ
UT WOS:000749297100001
PM 35096506
OA Bronze, Green Published, Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Kavoosifar, MR
   Apiletti, D
   Baralis, E
   Garza, P
   Huet, B
AF Kavoosifar, Mohammad Reza
   Apiletti, Daniele
   Baralis, Elena
   Garza, Paolo
   Huet, Benoit
TI Effective video hyperlinking by means of enriched feature sets and
   monomodal query combinations
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video retrieval; TRECVID; Multimedia indexing; Feature selection
ID SEARCH
AB Video content has been increasing at an unprecedented rate in recent years, bringing the need for improved tools providing efficient access to specific contents of interest. Within the management of video content, hyperlinking aims at determining related video segments from a collection with respect to an input video anchor. This paper describes the system we designed to address feature selection for the video hyperlinking challenge, as defined by TRECVID, one of the top worldwide venues for multimedia benchmarking. The proposed solution is based on different combinations of textual and visual features, enriched to capture the various facets of the videos: automatically generated transcripts, visual concepts, video metadata, named-entity recognition, and concept-mapping techniques. The different combinations of monomodal queries are experimentally evaluated, and the impact of both parameters and single features are discussed to identify their contributions. The best performing approach at the TRECVID 2017 video hyperlinking challenge was the ensemble feature selection, which includes three different monomodal queries based on enriched feature sets.
C1 [Kavoosifar, Mohammad Reza; Apiletti, Daniele; Baralis, Elena; Garza, Paolo] Politecn Torino, Dipartimento Automat & Informat, Turin, Italy.
   [Huet, Benoit] EURECOM, Sophia Antipolis, France.
C3 Polytechnic University of Turin; IMT - Institut Mines-Telecom; EURECOM
RP Apiletti, D (corresponding author), Politecn Torino, Dipartimento Automat & Informat, Turin, Italy.
EM mohammadreza.kavoosifar@polito.it; daniele.apiletti@polito.it;
   elena.baralis@polito.it; paolo.garza@polito.it; benoit.huet@eurecom.fr
CR Aly R, 2013, ARXIV13121913
   [Anonymous], 2013, MMSYS
   [Anonymous], 2005, P 43 ANN M ASS COMP, DOI DOI 10.3115/1219840.1219885
   [Anonymous], 2017, TREC VIDEO RETRIEVAL
   [Anonymous], 2016, 21 INT C INT US INT
   [Anonymous], 2016, MULTIMEDIA MODELING
   [Anonymous], 2015, Apache Solr enterprise search server
   Banerjee S., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P136
   Beecks C, 2015, IEEE INT SYM MULTIM, P33, DOI 10.1109/ISM.2015.21
   Blazek Adam, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P243, DOI 10.1007/978-3-319-14442-9_22
   Bois R, 2017, LECT NOTES COMPUT SC, V10133, P185, DOI 10.1007/978-3-319-51814-5_16
   Bradford RB, 2016, IEEE SYS MAN CYBERN, P509, DOI 10.1109/SMC.2016.7844290
   Cheng ZQ, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P292, DOI 10.1145/3078971.3079025
   Demirdelen M, 2017, TRECVID 2017 WORKSH
   Eskevich M, 2014, SEARCH HYPERLINKING
   Eskevich M, 2015, P 3 ED WORKSH SPEECH, P35
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Galuscakova Petra, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P853, DOI 10.1007/978-3-319-30671-1_80
   Gauvain JL, 2010, INT WORKSH SPOK LANG
   Hoogs A, 2015, ADV VID SIGN BAS SUR, P1
   Huet B, 2017, TRECVID 2017 WORKSH
   Huet B, 2016, TRECVID 2016 WORKSH
   Kumar J., 2015, APACHE SOLR SEARCH P
   Lamel L, 2012, FRONT ARTIF INTEL AP, V247, P1, DOI 10.3233/978-1-61499-133-5-1
   Larson, 2013, P 3 ACM C INT C MULT, P287
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Lin D, 1998, P 15 INT C MACH LEAR, V98, P296
   Liu XL, 2011, IEEE INT CON MULTI
   McCandless Michael., 2010, Lucene in Action: Covers Apache Lucene 3.0
   Moumtzidou A, 2016, LNCS, P394, DOI DOI 10.1007/978-3-319-27674-8_39
   Nakagawa A, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P354, DOI 10.1109/ICIAP.2003.1234075
   Okuoka T, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P501, DOI 10.1109/ISM.2009.67
   Quattoni A, 2007, PROC CVPR IEEE, P1553
   Racca DN, 2015, MEDIAEVAL
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Rossetto L, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P457, DOI 10.1145/3078971.3079012
   Safadi Bahjat, 2014, ICMR 2014 P ACM INT, P265
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soleymani M, 2018, INT J MULTIMED INF R, V7, P29, DOI 10.1007/s13735-018-0150-6
   Sun KM, 2011, 2011 INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND NEURAL COMPUTING (FSNC 2011), VOL II, P243
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tani MYK, 2017, INT J MULTIMED INF R, V6, P295, DOI 10.1007/s13735-017-0133-z
   Tay Y, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P695, DOI 10.1145/3077136.3080790
   Verma Y, 2018, INT J MULTIMED INF R, V7, P139, DOI 10.1007/s13735-017-0138-7
   Vukotic V, 2018, IEEE MULTIMEDIA, V25, P11, DOI 10.1109/MMUL.2018.023121161
   Vukotic V, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P343, DOI 10.1145/2911996.2912064
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
NR 47
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2020
VL 9
IS 3
BP 215
EP 227
DI 10.1007/s13735-019-00173-y
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MQ6SK
UT WOS:000553022800005
DA 2024-07-18
ER

PT J
AU He, N
   Ferguson, S
AF He, Na
   Ferguson, Sam
TI Music emotion recognition based on segment-level two-stage learning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Segment-level representation; Unsupervised learning; Music emotion
   recognition; Autoencoder
ID SPEECH; DURATION
AB In most Music Emotion Recognition (MER) tasks, researchers tend to use supervised learning models based on music features and corresponding annotation. However, few researchers have considered applying unsupervised learning approaches to labeled data except for feature representation. In this paper, we propose a segment-based two-stage model combining unsupervised learning and supervised learning. In the first stage, we split each music excerpt into contiguous segments and then utilize an autoencoder to generate segment-level feature representation. In the second stage, we feed these time-series music segments to a bidirectional long short-term memory deep learning model to achieve the final music emotion classification. Compared with the whole music excerpts, segments as model inputs could be the proper granularity for model training and augment the scale of training samples to reduce the risk of overfitting during deep learning. Apart from that, we also apply frequency and time masking to segment-level inputs in the unsupervised learning part to enhance training performance. We evaluate our model on two datasets. The results show that our model outperforms state-of-the-art models, some of which even use multimodal architectures. And the performance comparison also evidences the effectiveness of audio segmentation and the autoencoder with masking in an unsupervised way.
C1 [He, Na; Ferguson, Sam] Univ Technol Sydney, Fac Engn & IT, Sch Comp Sci, Ultimo, NSW 2007, Australia.
C3 University of Technology Sydney
RP He, N (corresponding author), Univ Technol Sydney, Fac Engn & IT, Sch Comp Sci, Ultimo, NSW 2007, Australia.
EM winterhn@gmail.com; samuel.ferguson@uts.edu.au
OI HE, NA/0000-0003-1801-9669
CR Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   [Anonymous], 2015, PROC 16 C INT SOC MU
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Corona H, 2015, P 12 INT C SOUND MUS, P363
   de Berardinis Jacopo, 2020, INT SOC MUSIC INFORM, P310
   Defossez A., 2019, Music source separation in the waveform domain
   Delbouys Remi., 2018, P 19 INT SOC MUS INF, P370
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fan JY, 2020, INT CONF ACOUST SPEE, P521, DOI [10.1109/ICASSP40776.2020.9052994, 10.1109/icassp40776.2020.9052994]
   Fu CZ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174894
   Gabrielsson A., 2001, Music And Emotion, P223, DOI DOI 10.1525/MP.2004.21.4.561
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Grekow J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P40, DOI 10.1109/INISTA.2017.8001129
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   He N, 2020, IEEE INT SYM MULTIM, P168, DOI 10.1109/ISM.2020.00037
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hu X, 2017, J ASSOC INF SCI TECH, V68, P273, DOI 10.1002/asi.23649
   Jeon B, 2017, CEUR WORKSHOP PROC
   Kadambari KV, 2018, MULTIMODAL APPROACH
   Kingma D. P., 2014, arXiv
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   Li JC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1241, DOI 10.1109/ICDMW.2015.136
   Li Y, 2018, INVESTIGATION MULTIM
   Liu AT, 2020, INT CONF ACOUST SPEE, P6419, DOI [10.1109/icassp40776.2020.9054458, 10.1109/ICASSP40776.2020.9054458]
   Madiraju N. S, 2018, Deep Temporal Clustering: Fully Unsupervised Learning of Time-Domain Features
   Nordström H, 2019, J ACOUST SOC AM, V145, P3058, DOI 10.1121/1.5108601
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sarkar R, 2020, MULTIMED TOOLS APPL, V79, P765, DOI 10.1007/s11042-019-08192-x
   Senac C, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095733
   Sharma Hardik, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P156, DOI 10.1109/ICSC48311.2020.9182745
   Tripathi S, 2017, AAAI CONF ARTIF INTE, P4746
   Wang QQ, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P150, DOI 10.1145/3323873.3325031
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Wu B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P117, DOI 10.1145/2647868.2654904
   Xianyu HS, 2016, IEEE INT CON MULTI
   Xiao ZZ, 2008, INT WORK CONTENT MUL, P1
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
   Yeh CH, 2014, MULTIMED TOOLS APPL, V73, P2103, DOI 10.1007/s11042-013-1687-2
   Yin G, 2020, EFFICIENT MULTIMODAL
   Yin GH, 2019, IEEE IMAGE PROC, P3277, DOI [10.1109/ICIP.2019.8803627, 10.1109/icip.2019.8803627]
   Yin Z, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00019
   Zhang KJ, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P135, DOI 10.1145/3206025.3206037
   Zhao Y, 2020, MUSICODER UNIVERSAL, DOI 10.1007/978-3-030-67832-6_34
   Zhou J, 2019, LECT NOTES ELECT ENG, DOI 10.1007/978-981-13-8707-4_3
NR 48
TC 6
Z9 6
U1 3
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 383
EP 394
DI 10.1007/s13735-022-00230-z
EA APR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000787109700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Nafea, O
   Abdul, W
   Muhammad, G
AF Nafea, Ohoud
   Abdul, Wadood
   Muhammad, Ghulam
TI Multi-sensor human activity recognition using CNN and GRU
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Human activity recognition; Convolutional neural networks (CNN); Gated
   recurrent uni (GRU)
ID SERIES
AB In the current era of rapid technological innovation, human activity recognition (HAR) has emerged as a principal research area in the field of multimedia information retrieval. The capacity to monitor people remotely is a main determinant of HAR's central role. Multiple gyroscope and accelerometer sensors can be used to aggregate data which can be used to recognise human activities-one of the key research objectives of this study. Optimal results are attained through the use of deep learning models to carry out HAR in the collected data. We propose the use of a hierarchical multi-resolution convolutional neural networks in combination with gated recurrent uni. We conducted an experiment on the mHealth and UCI data sets, the results of which demonstrate the efficiency of the proposed model, as it achieved acceptable accuracies: 99.35% in the mHealth data set and 94.50% in the UCI data set.
C1 [Nafea, Ohoud; Abdul, Wadood; Muhammad, Ghulam] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh 11543, Saudi Arabia.
C3 King Saud University
RP Nafea, O (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh 11543, Saudi Arabia.
EM 437204554@student.ksu.edu.sa; aabdulwaheed@ksu.edu.sa; ghulam@ksu.edu.sa
RI Abdul, Wadood/GZA-4884-2022; Muhammad, Ghulam/H-5884-2011
OI , Ohoud/0000-0002-6666-2491
FU King Saud University, Riyadh, Saudi Arabia [RSP-2021/34]
FX The authors extend their appreciation to Researchers Supporting Project
   Number (RSP-2021/34), King Saud University, Riyadh, Saudi Arabia.
CR Ahmad Z, 2021, IEEE SENS J, V21, P10978, DOI 10.1109/JSEN.2021.3062261
   Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   Banos Oresti, 2014, Ambient Assisted Living and Daily Activities. 6th International Work-Conference, IWAAL 2014. Proceedings: LNCS 8868, P91, DOI 10.1007/978-3-319-13105-4_14
   Bouchabou D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186037
   Brophy E., 2018, ARXIV PREPRINT ARXIV
   Canizo M, 2019, NEUROCOMPUTING, V363, P246, DOI 10.1016/j.neucom.2019.07.034
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Cosma G, 2019, IEEE ACCESS, V7, P107400, DOI 10.1109/ACCESS.2019.2932868
   Das DB, 2021, TURK J ELECTR ENG CO, V29, P2416, DOI 10.3906/elk-2010-75
   Deotale D, 2022, CMC-COMPUT MATER CON, V70, P3919, DOI 10.32604/cmc.2022.020655
   Dong M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051656
   Dua N, 2021, COMPUTING, V103, P1461, DOI 10.1007/s00607-021-00928-8
   Hanif MA, 2022, CMC-COMPUT MATER CON, V70, P3221, DOI 10.32604/cmc.2022.019815
   Kankanhalli MS, 2008, P IEEE, V96, P712, DOI 10.1109/JPROC.2008.916383
   Khowaja SA, 2017, EXPERT SYST APPL, V88, P165, DOI 10.1016/j.eswa.2017.06.040
   Lu W, 2020, THESIS AUCKLAND U TE
   Mutegeki Ronald, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P362, DOI 10.1109/ICAIIC48513.2020.9065078
   Nafea O, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062141
   O'Halloran J., 2019, IRISH C ARTIFICIAL I, P212
   Okai J, 2019, IEEE ENG MED BIO, P2486, DOI [10.1109/EMBC.2019.8857288, 10.1109/embc.2019.8857288]
   Onyekpe U, 2021, INFORMATION, V12, DOI 10.3390/info12030117
   Qin Z, 2020, INFORM FUSION, V53, P80, DOI 10.1016/j.inffus.2019.06.014
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Sun B, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3434746
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
NR 25
TC 10
Z9 10
U1 0
U2 16
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 135
EP 147
DI 10.1007/s13735-022-00234-9
EA APR 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000783740700001
DA 2024-07-18
ER

PT J
AU Junayed, MS
   Islam, MB
   Imani, H
   Aydin, T
AF Junayed, Masum Shah
   Islam, Md Baharul
   Imani, Hassan
   Aydin, Tarkan
TI PDS-Net: A novel point and depth-wise separable convolution for
   real-time object detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article; Early Access
DE Object detection; Classification; DWS Convolution; PWS convolution;
   Transformer encoder-decoder; Computer vision
ID RECOGNITION; NETWORK
AB Numerous recent object detectors and classifiers have shown acceptable performance in recent years by using convolutional neural networks and other efficient architectures. However, most of them continue to encounter difficulties like overfitting, increased computational costs, and low efficiency and performance in real-time scenarios. This paper proposes a new lightweight model for detecting and classifying objects in images. This model presents a backbone for extracting in-depth features and a spatial feature pyramid network (SFPN) for accurately detecting and categorizing objects. The proposed backbone uses point-wise separable (PWS) and depth-wise separable convolutions, which are more efficient than standard convolution. The PWS convolution utilizes a residual shortcut link to reduce computation time. We also propose a SFPN that comprises concatenation, transformer encoder-decoder, and feature fusion modules, which enables the simultaneous processing of multi-scale features, the extraction of low-level characteristics, and the creation of a pyramid of features to increase the effectiveness of the proposed model. The proposed model outperforms all of the existing backbones for object detection and classification in three publicly accessible datasets: PASCAL VOC 2007, PASCAL VOC 2012, and MS-COCO. Our extensive experiments show that the proposed model outperforms state-of-the-art detectors, with mAP improvements of 2.4% and 2.5% on VOC 2007, 3.0% and 2.6% on VOC 2012, and 2.5% and 3.6% on MS-COCO in the small and large sizes of the images, respectively. In the MS-COCO dataset, our model achieves FPS of 39.4 and 33.1 in a single GPU for the small (320 x 320) and large (512 x 512) sizes of the images, respectively, which shows that our method can run in real-time.
C1 [Junayed, Masum Shah; Islam, Md Baharul; Imani, Hassan; Aydin, Tarkan] Bahcesehir Univ, Dept Comp Engn, Yildiz Ciragan Cd, TR-34349 Istanbul, Turkey.
C3 Bahcesehir University
RP Junayed, MS; Islam, MB (corresponding author), Bahcesehir Univ, Dept Comp Engn, Yildiz Ciragan Cd, TR-34349 Istanbul, Turkey.
EM masumshahjunayed@gmail.com; bislam.eng@gmail.com;
   hassan.imani1987@gmail.com; tarkan.aydin@eng.bau.edu.tr
RI Islam, Md Baharul/R-3751-2019; Imani, Hassan/KSL-4309-2024; Junayed,
   Masum Shah/P-7375-2019
OI Islam, Md Baharul/0000-0002-9928-5776; Imani,
   Hassan/0000-0003-1566-3897; Junayed, Masum Shah/0000-0003-3592-4601
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [118C301]
FX This work was supported in part by the Scientific and Technological
   Research Council of Turkey (TUBITAK) through the 2232 Outstanding
   International Researchers Program under Project No. 118C301.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Bastian BT, 2019, INT J MULTIMED INF R, V8, P127, DOI 10.1007/s13735-019-00171-0
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bochkovskiy A., 2020, PREPRINT
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen X, IEEE T MULTIMED
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai J, ARXIV160506409
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J., 2009, IEEE C COMP VIS PATT
   Dosovitskiy A., ARXIV201011929
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farhadi A, COMPUT VIS PATTERN R
   FC MSBHS, 2021, IMAGE VISI COMPUT, V115
   Fu C.Y., ARXIV170106659
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   De Oliveira BAG, 2018, IEEE ACCESS, V6, P8714, DOI 10.1109/ACCESS.2018.2801813
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He W, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012042
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li BQ, 2018, IEEE ACCESS, V6, P18967, DOI 10.1109/ACCESS.2018.2814605
   Li JC, 2021, IEEE COMPUT SOC CONF, P2378, DOI 10.1109/CVPRW53098.2021.00270
   Li S, 2019, IEEE I CONF COMP VIS, P6608, DOI 10.1109/ICCV.2019.00671
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li YZ, 2021, IEEE T IMAGE PROCESS, V30, P2708, DOI 10.1109/TIP.2020.3048630
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2017, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2017.69
   Mahmood A, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.09.002
   Mani MR, 2016, INT J MULTIMED INF R, V5, P219, DOI 10.1007/s13735-016-0107-6
   Najibi M, 2019, IEEE I CONF COMP VIS, P9744, DOI 10.1109/ICCV.2019.00984
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S., 2015, IEEE T PATTERN ANAL, DOI [DOI 10.1109/TPAMI.2016.2577031, 10.1109/TPAMI.2016.2577031]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi CJ, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104099
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Solovyev R, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104117
   Soviany P, 2019, INT SYMP SYMB NUMERI, P209, DOI 10.1109/SYNASC.2018.00041
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang DC, 2019, IEEE ACCESS, V7, P144134, DOI 10.1109/ACCESS.2019.2945834
   Wang GY, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI [10.1145/3173574.3174143, 10.1145/3173574.3173624]
   Wu SK, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103911
   Xu H, 2019, IEEE I CONF COMP VIS, P6648, DOI 10.1109/ICCV.2019.00675
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 68
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD 2022 MAR 24
PY 2022
DI 10.1007/s11715-077-00779-6
EA MAR 2022
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY6MZ
UT WOS:000772700800001
DA 2024-07-18
ER

PT J
AU Suganyadevi, S
   Seethalakshmi, 
   Balasamy, K
AF Suganyadevi, S.
   Seethalakshmi, V
   Balasamy, K.
TI A review on deep learning in medical image analysis
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Deep learning; Survey; Image classes; Medical image analysis; Accuracy
ID CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; SEGMENTATION;
   REPRESENTATION; CORONAVIRUS; MASS
AB Ongoing improvements in AI, particularly concerning deep learning techniques, are assisting to identify, classify, and quantify patterns in clinical images. Deep learning is the quickest developing field in artificial intelligence and is effectively utilized lately in numerous areas, including medication. A brief outline is given on studies carried out on the region of application: neuro, brain, retinal, pneumonic, computerized pathology, bosom, heart, breast, bone, stomach, and musculoskeletal. For information exploration, knowledge deployment, and knowledge-based prediction, deep learning networks can be successfully applied to big data. In the field of medical image processing methods and analysis, fundamental information and state-of-the-art approaches with deep learning are presented in this paper. The primary goals of this paper are to present research on medical image processing as well as to define and implement the key guidelines that are identified and addressed.
C1 [Suganyadevi, S.; Seethalakshmi, V] KPR Inst Engn & Technol, Dept ECE, Coimbatore, Tamil Nadu, India.
   [Balasamy, K.] Dr Mahalingam Coll Engn & Technol, Dept IT, Coimbatore, Tamil Nadu, India.
RP Suganyadevi, S (corresponding author), KPR Inst Engn & Technol, Dept ECE, Coimbatore, Tamil Nadu, India.
EM suganya3223@gmail.com; seethav@kpriet.ac.in; balasamyk@gmail.com
RI Seethalakshmi, V/G-7972-2016; s, suganyadevi/AAB-9143-2022; Krishnasamy,
   Balasamy/ABE-1237-2021
OI Seethalakshmi, V/0000-0001-6518-6350; s,
   suganyadevi/0000-0001-6096-7510; Krishnasamy,
   Balasamy/0000-0003-0973-5698
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Akram SU, 2016, LECT NOTES COMPUT SC, V10008, P21, DOI 10.1007/978-3-319-46976-8_3
   Akselrod-Ballin A, 2016, LECT NOTES COMPUT SC, V10008, P197, DOI 10.1007/978-3-319-46976-8_21
   Alansary Amir, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P589, DOI 10.1007/978-3-319-46723-8_68
   Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Anavi Y, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217587
   Anavi Y, 2015, IEEE ENG MED BIO, P2940, DOI 10.1109/EMBC.2015.7319008
   Andermatt S, 2016, LECT NOTES COMPUT SC, V10008, P142, DOI 10.1007/978-3-319-46976-8_15
   [Anonymous], 2016, MEDICAL IMAGE COMPUT
   [Anonymous], 2016, H&E-stained whole slide image deep learning predicts SPOP mutation state in prostate cancer, DOI DOI 10.1101/064279
   [Anonymous], 2016, ARXIV160602382
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Antony J, 2016, INT C PATT RECOG, P1195, DOI 10.1109/ICPR.2016.7899799
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Apou G, 2016, COMPUT BIOL MED, V74, P91, DOI 10.1016/j.compbiomed.2016.05.004
   Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Avants B., 2009, Insight Journal
   Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Baumgartner Christian F., 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P203, DOI 10.1007/978-3-319-46723-8_24
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Benou A, 2016, LECT NOTES COMPUT SC, V10008, P95, DOI 10.1007/978-3-319-46976-8_11
   BenTaieb Aicha, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P460, DOI 10.1007/978-3-319-46723-8_53
   BenTaieb A, 2016, I S BIOMED IMAGING, P642, DOI 10.1109/ISBI.2016.7493349
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Birenbaum A, 2016, LECT NOTES COMPUT SC, V10008, P58, DOI 10.1007/978-3-319-46976-8_7
   Cheng X, 2018, COMP M BIO BIO E-IV, V6, P248, DOI 10.1080/21681163.2015.1135299
   Chollet F, 2015, KERAS
   Cicero M, 2017, INVEST RADIOL, V52, P281, DOI 10.1097/RLI.0000000000000341
   Civit-Masot J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134640
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   de Vos BD, 2017, IEEE T MED IMAGING, V36, P1470, DOI 10.1109/TMI.2017.2673121
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   Fu YB, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab843e
   Guo Y., 2019, Neutrosophic Set in Medical Image Analysis, V1st ed., P229
   Guo YR, 2016, IEEE T MED IMAGING, V35, P1077, DOI 10.1109/TMI.2015.2508280
   Guo YR, 2014, LECT NOTES COMPUT SC, V8674, P308, DOI 10.1007/978-3-319-10470-6_39
   Han XH, 2016, LECT NOTES COMPUT SC, V10008, P3, DOI 10.1007/978-3-319-46976-8_1
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   Hassan M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69813-2
   Haugeland J., 1989, Artificial Intelligence: The Very Idea
   Havaei Mohammad, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P469, DOI 10.1007/978-3-319-46723-8_54
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heran Yang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P521, DOI 10.1007/978-3-319-46723-8_60
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ismail A., 2019, Malaysian Journal of Computing, V4, P225, DOI 10.24191/mjoc.v4i1.6095
   Jain G, 2020, BIOCYBERN BIOMED ENG, V40, P1391, DOI 10.1016/j.bbe.2020.08.008
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Källén H, 2016, I S BIOMED IMAGING, P1163, DOI 10.1109/ISBI.2016.7493473
   Kowsari K, 2020, INFORMATION, V11, DOI 10.3390/info11060318
   Krishnasamy B, 2021, INTELLIGENT DATA ENG, V1177, DOI [10.1007/978-981-15-679-1_27, DOI 10.1007/978-981-15-679-1_27]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lekadir K, 2017, IEEE J BIOMED HEALTH, V21, P48, DOI 10.1109/JBHI.2016.2631401
   Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39
   Li WQ, 2016, I S BIOMED IMAGING, P1405, DOI 10.1109/ISBI.2016.7493530
   Lowekamp BC, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00045
   Merjulah R., 2019, Intelligent Data Analysis for Biomedical Applications, V1st ed., P209
   Miao S, 2016, IEEE T MED IMAGING, V35, P1352, DOI 10.1109/TMI.2016.2521800
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Oliveira FPM, 2014, COMPUT METHOD BIOMEC, V17, P73, DOI 10.1080/10255842.2012.670855
   Ouchicha C, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110245
   Pang S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3049632
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Pinaya WHL, 2016, SCI REP-UK, V6, DOI 10.1038/srep38897
   Plis SM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00229
   Poudel RPK, 2017, LECT NOTES COMPUT SC, V10129, P83, DOI 10.1007/978-3-319-52280-7_8
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Punn N.S., 2020, COVID 19 EPIDEMIC AN, DOI [10.1101/2020.04.08.20057679, DOI 10.1101/2020.04.08.20057679]
   Rajkomar A, 2017, J DIGIT IMAGING, V30, P95, DOI 10.1007/s10278-016-9914-9
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Ravishankar H, 2016, I S BIOMED IMAGING, P779, DOI 10.1109/ISBI.2016.7493382
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937
   Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345
   Samala RK, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217092
   Sarraf S.Tofighi., 2016, Classification of alzheimer's disease using fmri data and deep learning convolutional neural networks
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Sharma H, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P227, DOI [10.1109/Confluence47617.2020.9057809, 10.1109/confluence47617.2020.9057809]
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Sheng Wang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P640, DOI 10.1007/978-3-319-46723-8_74
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Singh SP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185097
   Song Y, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-173
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   Stern Darko, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P194, DOI 10.1007/978-3-319-46723-8_23
   Suganyadevi S., 2022, SMART HEALTHCARE SYS, P167, DOI [DOI 10.1002/9781119792253.CH8, 10.1002/9781119792253.ch8]
   Suk HI, 2013, LECT NOTES COMPUT SC, V8150, P583, DOI 10.1007/978-3-642-40763-5_72
   Sun W., 2016, SPIE Medical Imaging, p97850Z, DOI DOI 10.1117/12.2216307
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tao Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P115, DOI 10.1007/978-3-319-46723-8_14
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vu Tran P., 2016, ARXIV160400494
   Wang J, 2020, PROC CVPR IEEE, P4443, DOI 10.1109/CVPR42600.2020.00450
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Xie Yuanpu, 2016, Med Image Comput Comput Assist Interv, V9901, P185, DOI 10.1007/978-3-319-46723-8_22
   Xie YP, 2015, LECT NOTES COMPUT SC, V9351, P358, DOI 10.1007/978-3-319-24574-4_43
   Yan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1626, DOI 10.1109/ICASSP.2014.6853873
   Yang D, 2015, I S BIOMED IMAGING, P17, DOI 10.1109/ISBI.2015.7163806
   Yang X, 2016, LECT NOTES COMPUT SC, V10008, P48, DOI 10.1007/978-3-319-46976-8_6
   Yu LQ, 2017, AAAI CONF ARTIF INTE, P66
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H., 2016, ARXIV160708707
   Zhang Q, 2016, ULTRASONICS, V72, P150, DOI 10.1016/j.ultras.2016.08.004
   Zhang Y, 2016, ABS160502688 ARXIV
   Zhao JW, 2017, MED BIOL ENG COMPUT, V55, P1287, DOI 10.1007/s11517-016-1590-x
   Zheng Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P676, DOI 10.1007/978-3-319-46723-8_78
NR 119
TC 133
Z9 138
U1 33
U2 171
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2022
VL 11
IS 1
BP 19
EP 38
DI 10.1007/s13735-021-00218-1
EA SEP 2021
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI9SJ
UT WOS:000692438200001
PM 34513553
OA Green Published, Bronze
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Saremi, M
   Yaghmaee, F
AF Saremi, Mehrin
   Yaghmaee, Farzin
TI Early-stopped learning for action prediction in videos
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Early action recognition; Action prediction; Deep learning; Two-stream
   networks
ID ACTION RECOGNITION
AB Action prediction, also called early action recognition, is about recognizing an action in a video with partial observation. Various methods have been developed to tackle either offline or early action recognition, including deep learning approaches. In a family of deep learning methods, video frames or optical flow images are processed sequentially by the network. In this paper, we present a learning framework that can be applied to such methods to make them more appropriate for early recognition. We propose encouraging the learner to learn from earlier parts of the video and stop learning from some point on. By focusing on the earlier parts, we can expect the model to take full advantage of the information lying in these early parts. To this end, it is necessary to find a stopping point up to which enough information has been observed. We measure the amount of information with the help of the loss function. We applied our framework to Temporal Segment Networks and experimented on UCF11 and HMDB51 datasets. The results show that our method improves on Temporal Segment Networks and outperforms other baseline methods.
C1 [Saremi, Mehrin; Yaghmaee, Farzin] Semnan Univ, Elect & Comp Engn Dept, Semnan, Semnan Province, Iran.
C3 Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan, Semnan Province, Iran.
EM m.saremi@semnan.ac.ir; f_yaghmaee@semnan.ac.ir
RI Saremi, Mehrin/HTM-6225-2023; Yaghmaee, Farzin/AAZ-6590-2021
OI Yaghmaee, Farzin/0000-0001-7430-542X; Saremi, Mehrin/0000-0001-6557-9656
CR [Anonymous], 2018, 2018 International Joint Conference on Neural Networks (IJCNN), DOI 10.1145/2851141.2851145
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.214
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Cui R, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102923
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Furnari A, 2021, IEEE T PATTERN ANAL, V43, P4021, DOI 10.1109/TPAMI.2020.2992889
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hu JF, 2019, IEEE T PATTERN ANAL, V41, P2568, DOI 10.1109/TPAMI.2018.2863279
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Kong Y, 2020, IEEE T PATTERN ANAL, V42, P539, DOI 10.1109/TPAMI.2018.2882805
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lai SF, 2018, IEEE T IMAGE PROCESS, V27, P2272, DOI 10.1109/TIP.2017.2751145
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu J, 2018, PROC CVPR IEEE, P8349, DOI 10.1109/CVPR.2018.00871
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Ramezani M, 2016, ARTIF INTELL REV, V46, P485, DOI 10.1007/s10462-016-9473-y
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang HR, 2018, NEUROCOMPUTING, V318, P109, DOI 10.1016/j.neucom.2018.08.037
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Weng JW, 2020, IEEE T CIRC SYST VID, V30, P4626, DOI 10.1109/TCSVT.2020.2976789
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
NR 38
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2021
VL 10
IS 4
BP 219
EP 226
DI 10.1007/s13735-021-00216-3
EA AUG 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XC7OC
UT WOS:000684475400001
DA 2024-07-18
ER

PT J
AU Georgiou, T
   Liu, Y
   Chen, W
   Lew, M
AF Georgiou, Theodoros
   Liu, Yu
   Chen, Wei
   Lew, Michael
TI A survey of traditional and deep learning-based feature descriptors for
   high dimensional data in computer vision
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE High dimensional; Computer vision; Feature descriptors; Deep learning
ID 3D OBJECT RECOGNITION; PERFORMANCE EVALUATION; ACTIONLET ENSEMBLE; SHAPE
   DESCRIPTORS; SURFACE-FEATURE; SCALE; SPACE; EFFICIENT; MOTION; ROBUST
AB Higher dimensional data such as video and 3D are the leading edge of multimedia retrieval and computer vision research. In this survey, we give a comprehensive overview and key insights into the state of the art of higher dimensional features from deep learning and also traditional approaches. Current approaches are frequently using 3D information from the sensor or are using 3D in modeling and understanding the 3D world. With the growth of prevalent application areas such as 3D games, self-driving automobiles, health monitoring and sports activity training, a wide variety of new sensors have allowed researchers to develop feature description models beyond 2D. Although higher dimensional data enhance the performance of methods on numerous tasks, they can also introduce new challenges and problems. The higher dimensionality of the data often leads to more complicated structures which present additional problems in both extracting meaningful content and in adapting it for current machine learning algorithms. Due to the major importance of the evaluation process, we also present an overview of the current datasets and benchmarks. Moreover, based on more than 330 papers from this study, we present the major challenges and future directions.
C1 [Georgiou, Theodoros; Liu, Yu; Chen, Wei; Lew, Michael] Leiden Univ, Leiden Inst Adv Comp Sci, Niels Bohrweg 1, Leiden, Netherlands.
C3 Leiden University - Excl LUMC; Leiden University
RP Georgiou, T (corresponding author), Leiden Univ, Leiden Inst Adv Comp Sci, Niels Bohrweg 1, Leiden, Netherlands.
EM t.k.georgiou@liacs.leidenuniv.nl
FU Netherlands Organization for Scientific Research (NWO) [628.006.002]
FX This work is part of the research program DAMIOSO with project number
   628.006.002, which is partly financed by the Netherlands Organization
   for Scientific Research (NWO) and partly by Honda Research
   Institute-Europe (GmbH).
CR Abu-El-Haija Sami, 2016, arXiv
   Agostinelli F., 2014, arXiv preprint arXiv:1412.6830
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alexandre LA, 2016, ADV INTELL SYST COMP, V302, P888, DOI 10.1007/978-3-319-08338-4_64
   Allaire Stephane, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563023
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   [Anonymous], 2014, WORKSHOP INT C LEARN
   [Anonymous], 2015, CORR
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2017, Frustum pointnets for 3d object detection from rgb-d data
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.442
   [Anonymous], 2011, P ADV NEURAL INFORM
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barekatain M, 2017, IEEE COMPUT SOC CONF, P2153, DOI 10.1109/CVPRW.2017.267
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579
   Behley J, 2013, IEEE INT C INT ROBOT, P4195, DOI 10.1109/IROS.2013.6696957
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bo L., 2013, Experimental Robotics, volume 88 of Springer Tracts in Advanced Robotics, P387
   Bo L., 2010, ADV NEURAL INFORM PR, V23, P244
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Bo LF, 2011, PROC CVPR IEEE, P1729, DOI 10.1109/CVPR.2011.5995719
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Bro R, 2008, J CHEMOMETR, V22, P135, DOI 10.1002/cem.1122
   BRONSTEIN A, 2010, IMAGING ANAL APPL D, V3, P1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Chang Angel X., 2015, arXiv
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Cheng G, 2016, PROC CVPR IEEE, P2884, DOI 10.1109/CVPR.2016.315
   Cheung W, 2007, I S BIOMED IMAGING, P720, DOI 10.1109/ISBI.2007.356953
   Cho K., 2014, ARXIV14061078
   Choi Sungjoon., 2016, CoRR
   Clevert D., 2016, ARXIV151107289
   Cocosco C.A., 1997, NeuroImage
   Cooijmans T., 2016, CoRR
   Couprie C., 2013, ARXIV13013572, P1
   Couprie C, 2012, EUR SIGNAL PR CONF, P2233
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142
   Deng Liuyuan, 2019, RFBNET DEEP MULTIMOD
   Deng Z, 2015, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2015.202
   do Nascimento ER, 2013, NEUROCOMPUTING, V120, P141, DOI 10.1016/j.neucom.2012.08.064
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   ElNaghy Hanan, 2013, International Journal of Research and Reviews in Applied Sciences, V14, P412
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Fan Y, 2014, P INTERSPEECH, P1964
   Farabet C, 2012, P 29 INT C MACH LEAR, P1857
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   FLINT A, 2007, DICTA 07, P182
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Gao JY, 2017, IEEE I CONF COMP VIS, P5277, DOI 10.1109/ICCV.2017.563
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Garcia N, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P489, DOI 10.1145/3206025.3206083
   Garcia N, 2017, IEEE INT CONF COMP V, P2293, DOI 10.1109/ICCVW.2017.270
   Geiger A., 2012, CVPR
   GEORGIOU T, 2018, 2018 INT JOINT C NEU, P1
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   GOODFELLOW IJ, 2013, P INT C MACH LEARN
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139
   Guo WL, 2019, MACH VISION APPL, V30, P763, DOI 10.1007/s00138-019-01027-7
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Guo YL, 2015, INFORM SCIENCES, V293, P196, DOI 10.1016/j.ins.2014.09.015
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Guo Yulan., 2013, Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications, V1, P86, DOI [10.5220/0004277600860093, DOI 10.5220/0004277600860093]
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hadfield S, 2017, INT J COMPUT VISION, V121, P95, DOI 10.1007/s11263-016-0917-2
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassner T, 2013, IEEE COMPUT SOC CONF, P245, DOI 10.1109/CVPRW.2013.43
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde V, 2016, CoRR
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hermans A, 2014, IEEE INT CONF ROBOT, P2631, DOI 10.1109/ICRA.2014.6907236
   Hinterstoisser S, 2016, LECT NOTES COMPUT SC, V9907, P834, DOI 10.1007/978-3-319-46487-9_51
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 1986, Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations, V1, P2
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoft Nico, 2014, KI 2014: Advances in Artificial Intelligence. 37th Annual German Conference on AI. Proceedings: LNCS 8736, P80, DOI 10.1007/978-3-319-11206-0_9
   HOLMES DR, 2005, MICCAI WORKSH
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Hua Binh-Son, 2016, 3DV
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang L, 2018, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2018.00089
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Ioannidou A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3042064
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kadir T., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P25, DOI 10.1049/cp:20030478
   Kang S., 2016, CoRR
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Khan SH, 2014, LECT NOTES COMPUT SC, V8689, P679, DOI 10.1007/978-3-319-10590-1_44
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lai K., 2013, Consumer Depth Cameras for Computer Vision: Research Topics and Applications, P167
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   López GL, 2017, MULTIMED TOOLS APPL, V76, P6993, DOI 10.1007/s11042-016-3330-5
   Laurent C, 2016, INT CONF ACOUST SPEE, P2657, DOI 10.1109/ICASSP.2016.7472159
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li B, 2014, EUR WORKSH 3D OBJ RE, P121
   Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li YS, 2018, SIGNAL IMAGE VIDEO P, V12, P403, DOI 10.1007/s11760-017-1172-x
   Li YS, 2017, IEEE ACCESS, V5, P10323, DOI 10.1109/ACCESS.2017.2712789
   LI Z, 2016, ARXIV160405000
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lim T., 2016, Proc. ICLR
   LIN G, 2017, P CVPR IEEE
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YG, 2018, MULTIMED TOOLS APPL, V77, P22159, DOI 10.1007/s11042-018-5704-3
   Lo TWR, 2009, COMPUT VIS IMAGE UND, V113, P1235, DOI 10.1016/j.cviu.2009.06.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Luong M.-T., 2014, ARXIV14108206
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   MAES C, 2010, BIOM THEOR APPL SYST, P1
   Marcos D, 2016, INT C PATT RECOG, P2012, DOI 10.1109/ICPR.2016.7899932
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Matsuda T, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P100, DOI 10.1109/BigMM.2015.66
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   MCCORMAC J, 2016, ARXIV161205079
   Memisevic R., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Mian A. S., 2004, Sensor Review, V24, P206, DOI 10.1108/02602280410525995
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mokhtarian F, 2001, IMAGE VISION COMPUT, V19, P271, DOI 10.1016/S0262-8856(00)00076-7
   Monfort M, 2019, T PATTERN ANAL MACH, V1-1
   Müller AC, 2014, IEEE INT CONF ROBOT, P6232, DOI 10.1109/ICRA.2014.6907778
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ngiam J., 2011, P 28 INT C MACHINE L, P1105, DOI 10.5555/3104482.3104621
   Ni D, 2009, COMPUT MED IMAG GRAP, V33, P559, DOI 10.1016/j.compmedimag.2009.05.006
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   QI CR, 2017, P CVPR IEEE
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   QUADROS A, 2013, SYDNEY URBAN OBJECTS
   Quan SW, 2018, SIGNAL PROCESS-IMAGE, V65, P67, DOI 10.1016/j.image.2018.03.015
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207
   Ren Mengye, 2016, ARXIV161104520
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rennie C, 2016, IEEE ROBOT AUTOM LET, V1, P1179, DOI 10.1109/LRA.2016.2532924
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Rios-Cabrera R, 2013, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2013.256
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Rohr K, 1997, IMAGE VISION COMPUT, V15, P219, DOI 10.1016/S0262-8856(96)01127-4
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Rosten E., 2006, P 2006 9 EUR C COMP, P430, DOI DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   SALAKHUTDINOV R, 2008, TECHNICAL REPORT
   Salakhutdinov R., 2010, JMLR WORKSHOP C P, P693
   Salimans T, 2016, ADV NEUR IN, V29
   SAPUTRA MRU, 2018, VISUAL SLAM STRUCTUR, P37
   Savarese S, 2007, IEEE I CONF COMP VIS, P1245
   Savva Manolis, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P24, DOI 10.1109/CVPRW.2015.7301289
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sebe N, 2004, LECT NOTES COMPUT SC, V3058, P1
   Sedaghat Nima., 2016, CoRR
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2014, IEEE INT CONF ROBOT, P509, DOI 10.1109/ICRA.2014.6906903
   Singh T, 2019, ARTIF INTELL REV, V52, P1107, DOI 10.1007/s10462-018-9651-1
   Socher R., 2012, NIPS, V3, P8
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Srivastava RK, 2015, ARXIV150500387
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517
   Stückler J, 2015, J REAL-TIME IMAGE PR, V10, P599, DOI 10.1007/s11554-013-0379-5
   Stückler J, 2012, IEEE INT C INT ROBOT, P3005, DOI 10.1109/IROS.2012.6385983
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tangade SS, 2012, ANNU IEEE IND CONF, P525
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Teichman Alex, 2011, 2011 IEEE International Conference on Robotics and Automation, P4034
   Teichman A, 2012, INT J ROBOT RES, V31, P804, DOI 10.1177/0278364912442751
   Tejani A, 2018, IEEE T PATTERN ANAL, V40, P119, DOI 10.1109/TPAMI.2017.2665623
   Thomee B., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P59
   Thomee Bart, 2015, ARXIV150301817
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Trottier L, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P207, DOI 10.1109/ICMLA.2017.00038
   Ulyanov Dmitry, 2016, arXiv
   VALADA A, 2019, INT J COMPUT VIS
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang AR, 2014, LECT NOTES COMPUT SC, V8693, P453, DOI 10.1007/978-3-319-10602-1_30
   Wang C., 2019, ARXIV190601592
   Wang DZ, 2012, IEEE INT CONF ROBOT, P4038, DOI 10.1109/ICRA.2012.6224734
   Wang G., 2018, Advances in neural information processing systems, P21
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Willems RM, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.039.2009
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   XU H, 2018, ARXIV180405113
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yang JQ, 2017, PATTERN RECOGN, V65, P175, DOI 10.1016/j.patcog.2016.11.019
   Yang JQ, 2016, INFORM SCIENCES, V346, P163, DOI 10.1016/j.ins.2016.01.095
   Yang X., 2012, P IEEE C COMP VIS PA, P14
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Yu HS, 2018, NEUROCOMPUTING, V304, P82, DOI 10.1016/j.neucom.2018.03.037
   Yu Tsz-Ho., 2010, Proceedings of the British Machine Vision Conference, V2, P6
   Yu W., 2014, Visualizing and comparing convolutional neural networks
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Yumer ME, 2016, LECT NOTES COMPUT SC, V9910, P294, DOI 10.1007/978-3-319-46466-4_18
   Yumer ME, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766908
   Yun Jiang, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3304, DOI 10.1109/ICRA.2011.5980145
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zou Y, 2018, PATTERN RECOGN, V76, P522, DOI 10.1016/j.patcog.2017.11.029
NR 335
TC 84
Z9 88
U1 7
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2020
VL 9
IS 3
BP 135
EP 170
DI 10.1007/s13735-019-00183-w
EA NOV 2019
PG 36
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MQ6SK
UT WOS:000498025200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Vall, A
   Quadrana, M
   Schedl, M
   Widmer, G
AF Vall, Andreu
   Quadrana, Massimo
   Schedl, Markus
   Widmer, Gerhard
TI Order, context and popularity bias in next-song recommendations
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Music recommender systems; Music playlist continuation; Sequential
   recommendation; Collaborative filtering; Recurrent neural networks
AB The availability of increasingly larger multimedia collections has fostered extensive research in recommender systems. Instead of capturing general user preferences, the task of next-item recommendation focuses on revealing specific session preferences encoded in the most recent user interactions. This study focuses on the music domain, particularly on the task of music playlist continuation, a paradigmatic case of next-item recommendation. While the accuracy achieved in next-song recommendations is important, in this work we shift our focus toward a deeper understanding of fundamental playlist characteristics, namely the song order, the song context and the song popularity, and their relation to the recommendation of playlist continuations. We also propose an approach to assess the quality of the recommendations that mitigates known problems of off-line experiments for music recommender systems. Our results indicate that knowing a longer song context has a positive impact on next-song recommendations. We find that the long-tailed nature of the playlist datasets makes simple and highly expressive playlist models appear to perform comparably, but further analysis reveals the advantage of using highly expressive models. Finally, our experiments suggest that the song order is not crucial to accurately predict next-song recommendations.
C1 [Vall, Andreu; Schedl, Markus; Widmer, Gerhard] Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.
   [Widmer, Gerhard] Austrian Res Inst Artificial Intelligence, Vienna, Austria.
   [Quadrana, Massimo] Pandora Media Inc, Oakland, CA USA.
C3 Johannes Kepler University Linz
RP Vall, A (corresponding author), Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.
EM andreu.vall@jku.at; mquadrana@pandora.com; markus.schedl@jku.at;
   gerhard.widmer@jku.at
RI Widmer, Gerhard/B-8218-2017
OI Widmer, Gerhard/0000-0003-3531-1282
CR Aizenberg N., 2012, P 21 INT C WORLD WID, P1, DOI DOI 10.1145/2187836.2187838
   [Anonymous], 2015, RECOMMENDER SYSTEMS
   [Anonymous], ARXIV150600019
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bonnin G, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2652481
   Celma O, 2010, MUSIC RECOMMENDATION AND DISCOVERY, P1, DOI 10.1007/978-3-642-13287-2
   Chen S., 2012, P 18 ACM SIGKDD INT, P714, DOI [DOI 10.1145/2339530.2339643, 10.1145/2339530.2339643]
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cunningham SJ, 2006, P ISMIR
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Flexer Arthur., 2008, ISMIR, P173, DOI DOI 10.5281/ZENODO.1418272
   Hariri N., 2012, P 6 ACM C RECOMMENDE, P131, DOI DOI 10.1145/2365952.2365979
   Hidasi B, 2016, P ICLR
   Hidasi B, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P241, DOI 10.1145/2959100.2959167
   Jannach D., 2015, P RECSYS, P187
   Jannach D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P306, DOI 10.1145/3109859.3109872
   Jansson A, 2015, P ISMIR
   Kamehkhosh I, 2018, JOINT P IUI WORKSH T
   Knees P., 2006, P MIR, P147
   Lee Jin Ha, 2011, ISMIR, V11, P109
   Logan B, 2002, P ISMIR
   McFee B., 2011, Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR, P537
   McFee B., 2012, The International Society for Music Information Retrieval (ISMIR), P343
   Platt JC, 2002, ADV NEUR IN, V14, P1425
   Pohle T., 2005, P DAFX, P220
   Rendle S., 2009, P 25 C UNCERTAINTY A, P452
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Vall A., 2017, RECSYS 2017 POST P C
   Vall A., 2018, P ICMPC ESCOM GRAZ A
NR 33
TC 10
Z9 10
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2019
VL 8
IS 2
BP 101
EP 113
DI 10.1007/s13735-019-00169-8
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HX7JW
UT WOS:000467582100003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Wary, A
   Neelima, A
AF Wary, Alongbar
   Neelima, Arambam
TI A review on robust video copy detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Robust visual hashing; Video copy detection; Cryptographic hash;
   Watermarking
ID STATISTICAL IMAGE FEATURES; HASHING ALGORITHM; SCHEME; EFFICIENT;
   LOCALIZATION; FINGERPRINTS; FRAMEWORK; ROTATION
AB The unprecedented escalation and proliferation of digital multimedia and Internet technology have triggered the enormous copyright infringement issues and tampering of digital content. Detection or localization of copy-paste forgery of digital content and distinguishing between original and manipulated video have become a weighty challenge at the present era of multimedia technology. Several distortions such as rotation, scaling and gamma correction are applied into an original video by an adversary to manipulate the original video for copyright infringement. Due to the emergence of ubiquitous digital videos on the Internet and to surpass the challenges, various copy detection schemes have been introduced by several researchers. Many real-time applications such as detection of duplicate Web videos and monitoring of real-time TV commercial media content over multi-broadcast channels require the robust copy detection approach for high security purpose. The other applications include the rapid advancement of video navigation and editing technology such as finding the opening sequence of a TV show and combining or editing similar versions of the same video for copyright infringement. This paper depicts a comprehensive overview of robust visual hashing to identify similar video contents for digital piracy detection, which overcomes the demerits of conventional cryptographic hash functions and watermarking. The paramount goal of this scheme is to generate the perceptual hash code of fixed size of length from video segments which are robust against distinct distortions or attacks such as scaling, rotation, compression, frame rate change, frame dropping, contrast enhancement, etc., made by an adversary. Besides, in this paper, distinct state-of-the-art schemes used for copy detection have been studied thoroughly and classified based on the methodology they have implemented.
C1 [Wary, Alongbar; Neelima, Arambam] NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Wary, A (corresponding author), NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
EM alongwar56@gmail.com; neelimaarambam@yahoo.co.in
OI Neelima, Arambam/0009-0003-2106-7757
CR [Anonymous], ELECT J DIFFERENTIAL
   [Anonymous], IEEE10 INT C IM SIGN
   [Anonymous], 2013, 2013 4 NAT C COMP VI
   [Anonymous], 2016, J. Signal Inf. Process, DOI [10.4236/jsip.2016.72010, DOI 10.4236/JSIP.2016.72010]
   [Anonymous], ELSEVIER PROCEDIA CO
   [Anonymous], 2014, 10 INT S TELECOMMUNI
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Boukhari A, 2016, J VIS COMMUN IMAGE R, V34, P50, DOI 10.1016/j.jvcir.2015.10.015
   Chen DY, 2013, J VIS COMMUN IMAGE R, V24, P544, DOI 10.1016/j.jvcir.2013.04.005
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Chen ZX, 2018, IEEE T CIRC SYST VID, V28, P1421, DOI 10.1109/TCSVT.2017.2669095
   Cheng Deng, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P350, DOI 10.1109/ICCNC.2012.6167442
   Chiu CY, 2008, IEEE T CIRC SYST VID, V18, P412, DOI 10.1109/TCSVT.2008.918447
   Chiu CY, 2013, NEUROCOMPUTING, V105, P70, DOI 10.1016/j.neucom.2012.04.036
   Cho HJ, 2009, IEEE INT CON MULTI, P1732
   Chongtham C, 2018, IJST-T ELECTR ENG, V42, P107, DOI 10.1007/s40998-018-0052-x
   Cirakman O, 2010, IEEE IMAGE PROC, P2373, DOI 10.1109/ICIP.2010.5652649
   Coskun Baris, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P2295
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   DEROOVER C, 1970, TSP, V53, P4020, DOI DOI 10.1109/TSP.2005.855414
   Devi S, 2012, INT J COMPUT APPL, V51, P29
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Esmaeili Mani Malek, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P179, DOI 10.1109/ICCE.2010.5418777
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Garboan A., 2011, 2011 3rd European Workshop on Visual Information Processing, P216, DOI 10.1109/EuVIP.2011.6045522
   Gu XG, 2013, INT CONF ACOUST SPEE, P1508, DOI 10.1109/ICASSP.2013.6637903
   Guiguang Ding, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P347, DOI 10.1109/ISM.2010.59
   Guzman-Zavaleta ZJ, 2016, 2016 IEEE 18 INT WOR, P1
   HAO Y, 2017, TMM, V19, P1, DOI DOI 10.1109/TMM.2016.2610324
   HAO Y, 1944, TIP, V26, P5531, DOI DOI 10.1109/TIP.2017.2737329
   Harris C, 1998, ALVEY VIS C, V15, P10, DOI DOI 10.5244
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P17309, DOI 10.1007/s11042-017-5307-4
   Himeur Y, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P40
   Himeur Y, 2015, IEEE INT SYMP SIGNAL, P495, DOI 10.1109/ISSPIT.2015.7394386
   Hu YC, 2018, J VIS COMMUN IMAGE R, V55, P21, DOI 10.1016/j.jvcir.2018.05.013
   Hua XS, 2004, IEEE IMAGE PROC, P685
   Hyun-seok Min, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P562, DOI 10.1109/ICME.2012.58
   Juan Chen, 2010, 2010 International Conference on Apperceiving Computing and Intelligence Analysis (ICACIA 2010), P303, DOI 10.1109/ICACIA.2010.5709906
   Katz Jonathan, 1996, HDB APPL CRYPTOGRAPH
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Kim J, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P1667
   Kim S, 2014, SIGNAL PROCESS-IMAGE, V29, P788, DOI 10.1016/j.image.2014.05.002
   Kim S, 2014, J VIS COMMUN IMAGE R, V25, P373, DOI 10.1016/j.jvcir.2013.12.003
   Kitanovski V., 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P140, DOI 10.1109/EUVIP.2010.5699100
   Koz A, 2010, INT CONF ACOUST SPEE, P1842, DOI 10.1109/ICASSP.2010.5495380
   Kunhu Alavi, 2016, 2016 ONL INT C GREEN, P1
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Lee JH., 2014, J NANOMATER, V2014, P1, DOI [10.1186/1029-242X-2014-1, DOI 10.1155/2014/612608]
   Lee SJ, 2015, MICROSC MICROANAL, V21, P936, DOI 10.1017/S1431927615013719
   Lee SH, 2013, DIGIT SIGNAL PROCESS, V23, P1505, DOI 10.1016/j.dsp.2013.04.012
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lee S, 2009, IEEE T CIRC SYST VID, V19, P1379, DOI 10.1109/TCSVT.2009.2022801
   Li J, 2018, MULTIMED TOOLS APPL, P1
   Li JN, 2014, INT SYMP WIREL, P97, DOI 10.1109/WPMC.2014.7014798
   LI M, 1973, TIP, V21, P4397, DOI DOI 10.1109/TIP.2012.2206036
   Li YN, 2017, INT CONF ACOUST SPEE, P2162, DOI 10.1109/ICASSP.2017.7952539
   Li YN, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 2, PROCEEDINGS, P79, DOI 10.1109/IAS.2009.291
   Lian SG, 2010, STUD COMPUT INTELL, V282, P253
   Ligang Zheng, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2537, DOI 10.1109/ICIP.2011.6116179
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1209, DOI 10.1109/TMM.2016.2645404
   Liu XC, 2013, IEEE INT WORKS INFOR, P109, DOI 10.1109/WIFS.2013.6707803
   Liu XC, 2013, IEEE SIGNAL PROC LET, V20, P1253, DOI 10.1109/LSP.2013.2287006
   Maani E, 2008, IEEE IMAGE PROC, P1716, DOI 10.1109/ICIP.2008.4712105
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   Mao JF, 2016, NEUROCOMPUTING, V173, P2022, DOI 10.1016/j.neucom.2015.09.001
   Massoudi A, 2006, IEEE IMAGE PROC, P2297, DOI 10.1109/ICIP.2006.312834
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Min HS, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P65, DOI 10.1109/ISM.2009.93
   Mishra M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND SYSTEMS (ICCCS'14), P63, DOI 10.1109/ICCCS.2014.7068169
   Mohan R, 1998, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.1998.679686
   Mucedero A, 2004, IEEE IMAGE PROC, P2239
   Neelima A, 2017, IMAGING SCI J, V65, P62, DOI 10.1080/13682199.2016.1260216
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Nie XS, 2015, J VIS COMMUN IMAGE R, V32, P120, DOI 10.1016/j.jvcir.2015.08.001
   Nie XS, 2010, INT CONF SIGN PROCES, P1837, DOI 10.1109/ICOSP.2010.5656914
   Nikolaidis N, 2006, I S INTELL SIG PROC, P391
   Özbulak G, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P124, DOI 10.1109/ICDSP.2016.7868529
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Peng HY, 2013, IEEE IMAGE PROC, P4482, DOI 10.1109/ICIP.2013.6738923
   Radhakrishnan R, 2008, INT CONF ACOUST SPEE, P2245, DOI 10.1109/ICASSP.2008.4518092
   Roopalakshmi R, 2015, PROCEDIA COMPUT SCI, V57, P385, DOI 10.1016/j.procs.2015.07.353
   Roopalakshmi R, 2013, SIGNAL PROCESS, V93, P2339, DOI 10.1016/j.sigpro.2012.06.004
   Roopalakshmi R., 2010, IEEE INT C COMP INT, P1
   Rouhi AH, 2015, 2015 INT C DIG IM CO, P1
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saikia N., 2011, P NAT C COMM NCC BAN, P1
   Saikia N, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P694, DOI 10.1109/ICGCIoT.2015.7380552
   Sandoval-Soto R., 2017, P INT C SIGNAL PROCE, P1, DOI 10.1109/SCCC.2017.8405140
   Saracoglu A, 2009, INT WORK CONTENT MUL, P213, DOI 10.1109/CBMI.2009.12
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   Setyawan I, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY SYSTEMS AND INNOVATION (ICITSI), P111, DOI 10.1109/ICITSI.2014.7048247
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shinde S, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P15, DOI 10.1145/2818567.2818570
   Singh RD, 2017, FORENSIC SCI INT, V281, P75, DOI 10.1016/j.forsciint.2017.10.028
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Su X, 2009, INT CONF ACOUST SPEE, P1525, DOI 10.1109/ICASSP.2009.4959886
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   Sun JD, 2012, IEEE SIGNAL PROC LET, V19, P328, DOI 10.1109/LSP.2012.2192271
   Sun R, 2017, OPTIK, V128, P139, DOI 10.1016/j.ijleo.2016.09.105
   Tang ZJ, 2016, AEU-INT J ELECTRON C, V70, P833, DOI 10.1016/j.aeue.2016.03.010
   Tasdemir Kasim, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3134, DOI 10.1109/ICPR.2010.767
   Thomas RM, 2015, PROCEDIA COMPUT SCI, V46, P1668, DOI 10.1016/j.procs.2015.02.106
   Uchida Y, 2010, IEEE IMAGE PROC, P1021, DOI 10.1109/ICIP.2010.5650242
   Wang J, 2012, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2012.6466942
   Wang L, 2017, LECT NOTES COMPUT SC, V10132, P576, DOI 10.1007/978-3-319-51811-4_47
   Wang RB, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P223, DOI 10.1109/BigMM.2016.12
   Wang W, 2015, 2015 IEEE 16TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P309, DOI 10.1109/ICCT.2015.7399849
   Wu PH, 2009, INT CONF ACOUST SPEE, P3465, DOI 10.1109/ICASSP.2009.4960371
   WU X, 2008, 2008 19TH INTERNATIO, V19, P1
   Wu ZP, 2009, IEEE INT CON MULTI, P554, DOI 10.1109/ICME.2009.5202556
   Xiushan Nie, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P555, DOI 10.1109/ICMEW.2017.8026322
   Xu ZH, 2009, IEEE INT CON MULTI, P434, DOI 10.1109/ICME.2009.5202527
   Yang GB, 2012, COMPUT SECUR, V31, P33, DOI 10.1016/j.cose.2011.11.004
   Yang L, 2010, 2010 INT C COMP APPL, V12, pV12
   Ye GN, 2013, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2013.282
   Yu-Gang Jiang, 2016, IEEE Transactions on Big Data, V2, P32, DOI 10.1109/TBDATA.2016.2530714
   Zhao YX, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P305, DOI 10.1109/CIS.2008.175
   Zhijie Zhang, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P13, DOI 10.1109/ICAL.2010.5585375
   Zhuang NF, 2016, INT C PATT RECOG, P3222, DOI 10.1109/ICPR.2016.7900131
NR 123
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2019
VL 8
IS 2
BP 61
EP 78
DI 10.1007/s13735-018-0159-x
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA HX7JW
UT WOS:000467582100001
DA 2024-07-18
ER

PT J
AU Wen, ZH
   Su, J
   Zhang, YX
   Li, MY
   Gan, GX
   Zhang, SM
   Fan, DY
AF Wen, Zonghui
   Su, Jia
   Zhang, Yongxiang
   Li, Mingyu
   Gan, Guoxi
   Zhang, Shenmeng
   Fan, Deyu
TI A lightweight small object detection algorithm based on improved YOLOv5
   for driving scenarios
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Small object detection; Autonomous driving; LSD-YOLO; YOLOv5
ID CONVOLUTIONAL NEURAL-NETWORK
AB Small object detection has been a longstanding challenge in the field of object detection, and achieving high detection accuracy is crucial for autonomous driving, especially for small objects. This article focuses on researching small object detection algorithms in driving scenarios. To address the need for higher accuracy and fewer parameters in object detection for autonomous driving, we propose LSD-YOLO, a small object detection algorithm with higher average precision and fewer parameters. Building upon YOLOv5, we fully leverage small-scale feature maps to enhance the network's detection ability for small objects. Additionally, we introduce a new structure called FasterC3 to reduce the network's latency and parameter volume. To locate attention regions in complex driving scenarios, we integrate Coordinate Attention and explore multiple solutions to determine the optimal approach. Furthermore, we use a spatial pyramid pooling method called LeakySPPF (Wen and Zhang, in: Jin Z, Jiang Y, Buchmann RA, Bi Y, Ghiran A-M, Ma W (eds.) Knowledge Science, Engineering and Management, pp. 39-46. Springer, Cham, 2023) to further improve network speed, achieving up to 15% faster computation. Finally, to better match driving scenarios, we propose a medium-sized dataset called Cone4k to supplement insufficient categories in the VisDrone dataset. Extensive experiments show that our proposed LSD-YOLO(s) achieves an mAP and F1 score of 24.9 and 48.6, respectively, on the VisDrone2021 dataset, resulting in a 4.6% and 3.6% improvement over YOLOv5(s) while reducing parameter volume by 7.5%.
C1 [Wen, Zonghui; Su, Jia; Zhang, Yongxiang; Gan, Guoxi; Zhang, Shenmeng] Capital Normal Univ, Informat Engn Coll, Beijing, Peoples R China.
   [Li, Mingyu] Nanyang Technol Univ, Singapore, Singapore.
   [Fan, Deyu] Qingdao Univ Sci & Technol, Qingdao, Peoples R China.
C3 Capital Normal University; Nanyang Technological University; Qingdao
   University of Science & Technology
RP Su, J (corresponding author), Capital Normal Univ, Informat Engn Coll, Beijing, Peoples R China.
EM wenzonghui@gmail.com; sujia@cnu.edu.cn; zhangyongxiang@cnu.edu.cn;
   consigliere@qq.com; 2211002037@cnu.edu.cn; 2211002002@cnu.edu.cn;
   1303390238@qq.com
FU We would like to thank the laboratory of Capital Normal University for
   its equipment, teachers' guidance, and students' help.; laboratory of
   Capital Normal University
FX We would like to thank the laboratory of Capital Normal University for
   its equipment, teachers' guidance, and students' help.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen D, 2023, Hyneter: hybrid network transformer for object detection
   Chen JR, 2023, PROC CVPR IEEE, P12021, DOI 10.1109/CVPR52729.2023.01157
   Cui L, 2020, MDSSD: multi-scale deconvolutional single shot detector for small objects
   Ding JG, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2023.119560
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Han W, 2020, INTERSPEECH, P3610, DOI 10.21437/Interspeech.2020-2059
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2020, IEEE T PATTERN ANAL, V42, P2011, DOI 10.1109/TPAMI.2019.2913372
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Li C., 2022, ARXIV, DOI [DOI 10.48550/ARXIV.2209.02976, 10.48550/arXiv.2209.02976]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ZG, 2019, IEEE ACCESS, V7, P57120, DOI 10.1109/ACCESS.2019.2913882
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Prajapati K, 2020, IEEE COMPUT SOC CONF, P1904, DOI 10.1109/CVPRW50498.2020.00240
   Razghandi M, 2022, IEEE ICC, P4781, DOI 10.1109/ICC45855.2022.9839249
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun K, 2021, IEEE T IMAGE PROCESS, V30, P868, DOI 10.1109/TIP.2020.3039378
   Sunkara R, 2023, LECT NOTES ARTIF INT, V13715, P443, DOI 10.1007/978-3-031-26409-2_27
   Tan Mingxing, 2019, CoRR abs/1911.09070 1911.09070
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wen Z., 2023, Knowledge science, engineering and management, P39, DOI [10.1007/978-3-031-40286-9_4, DOI 10.1007/978-3-031-40286-9_4]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu S, 2022, Lai B PP-YOLOE: an evolved version of YOLO
   Yang CHY, 2022, PROC CVPR IEEE, P13658, DOI 10.1109/CVPR52688.2022.01330
   Yang H, 2023, IEEE T CIRC SYST VID, V33, P3872, DOI 10.1109/TCSVT.2023.3234311
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4771, DOI 10.1109/ICCV48922.2021.00475
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y.-F., 2022, FOCAL EFFICIENT IOU
   Zheng ZH, 2022, IEEE T CYBERNETICS, V52, P8574, DOI 10.1109/TCYB.2021.3095305
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
NR 49
TC 1
Z9 1
U1 32
U2 48
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 38
DI 10.1007/s13735-023-00305-5
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X7AU4
UT WOS:001099943000002
DA 2024-07-18
ER

PT J
AU Kas, M
   El-merabet, Y
   Ruichek, Y
   Messoussi, R
AF Kas, M.
   El-merabet, Y.
   Ruichek, Y.
   Messoussi, R.
TI Generative adversarial networks for 2D-based CNN pose-invariant face
   recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Face recognition challenges; Pose invariant face recognition; GAN image
   translation; CNN face classification framework; Deep residual networks
ID IDENTIFICATION
AB The computer vision community considers the pose-invariant face recognition (PIFR) as one of the most challenging applications. Many works were devoted to enhancing face recognition performance when facing profile samples. They mainly focused on 2D- and 3D-based frontalization techniques trying to synthesize frontal views from profile ones. In the same context, we propose in this paper a new 2D PIFR technique based on Generative Adversarial Network image translation. The used GAN is Pix2Pix paired architecture covering many generator and discriminator models that will be comprehensively evaluated on a new benchmark proposed in this paper referred to as Combined-PIFR database, which is composed of four datasets that provide profiles images and their corresponding frontal ones. The paired architecture we are using is based on computing the L1 distance between the generated image and the ground truth one (pairs). Therefore, both generator and discriminator architectures are paired ones. The Combined-PIFR database is partitioned respecting person-independent constraints to evaluate our proposed framework's frontalization and classification sub-systems fairly. Thanks to the GAN-based frontalization, the recorded results demonstrate an important improvement of 33.57% compared to the baseline.
C1 [Kas, M.; El-merabet, Y.; Messoussi, R.] Univ Ibn Tofail, Fac Sci, Dept Phys, Lab LASTID, BP 133, Kenitra 14000, Morocco.
   [Kas, M.; Ruichek, Y.] Univ Bourgogne Franche Comte, UTBM, CIAD UMR 7533, F-25200 Montbeliard, France.
C3 Ibn Tofail University of Kenitra; Universite de Technologie de
   Belfort-Montbeliard (UTBM)
RP Kas, M (corresponding author), Univ Ibn Tofail, Fac Sci, Dept Phys, Lab LASTID, BP 133, Kenitra 14000, Morocco.; Kas, M (corresponding author), Univ Bourgogne Franche Comte, UTBM, CIAD UMR 7533, F-25200 Montbeliard, France.
EM mohamed.kas@uitac.ma; y.el-merabet@univ-ibntofaiLac.ma;
   yassine.ruichek@utbm.fr; messoussi@uit.ac.ma
RI KAS, Mohamed/AAB-5618-2021; El merabet, Youssef/P-1034-2015
OI KAS, Mohamed/0000-0001-5123-4681; El merabet,
   Youssef/0000-0001-6938-9374; RUICHEK, Yassine/0000-0003-4795-8569
FU CNSRT-Maroc (Centre National de la Recherche Scientifique et Technique);
   French government
FX The authors gratefully acknowledge the funding received from CNSRT-Maroc
   (Centre National de la Recherche Scientifique et Technique) and the
   French government (Eiffel scholarship).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Fischer M., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P331, DOI 10.1109/BTAS.2012.6374597
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim TK, 2006, IEEE T CIRC SYST VID, V16, P1096, DOI 10.1109/TCSVT.2006.881197
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957
   Li D, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2412374
   Li PP, 2019, IEEE I CONF COMP VIS, P10042, DOI 10.1109/ICCV.2019.01014
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sato M., 2018, P 11 INT JOINT C BIO, P216
   su-myung，Gang, 2019, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V22, P547, DOI 10.9717/kmms.2019.22.5.547
   Tang H, 2019, IEEE INT CONF AUTOMA, P192, DOI 10.1109/fg.2019.8756586
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xu R, 2017, ARXIV
   Yin Y, 2020, ARXIV
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
   Zhu Z., 2014, ARXIV
   Zou H, 2018, INT C PATT RECOG, P3561, DOI 10.1109/ICPR.2018.8546154
NR 34
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 639
EP 651
DI 10.1007/s13735-022-00249-2
EA SEP 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000854741900001
DA 2024-07-18
ER

PT J
AU Zhou, XP
   Han, XY
   Li, HR
   Wang, J
   Liang, X
AF Zhou, Xiaoping
   Han, Xiangyu
   Li, Haoran
   Wang, Jia
   Liang, Xun
TI Cross-domain image retrieval: methods and applications
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image retrieval; Cross-domain; Deep learning; Feature space migration;
   Image domain migration
ID CLOTHING RETRIEVAL; FACE; NETWORK; FEATURES; REPRESENTATION; ALGORITHMS;
   FUSION; CODES
AB Cross-domain images have been witnessed in an increasing number of applications. This new trend triggers demands for cross-domain image retrieval (CDIR), which finds images in one visual domain according to a query image from another visual domain. Although image retrieval has been studied extensively, exploration of the CDIR remains at its initial stage. This study systematically surveys the methods and applications of the CDIR. Since images from different visual domains exhibit different features, learning discriminative feature representations while preserving domain-invariant features of images from different visual domains is the main challenge of the CDIR. According to the feature transformation stage of images from different visual domains, existing CDIR methods are categorized and analyzed. One is based on feature space migration and the other is based on image domain migration. Then, applications of CDIR in clothing, infrared, remote sensing, sketch, and other scenarios are summarized. Finally, the existing CDIR schemes are concluded, and new directions for future research are proposed.
C1 [Zhou, Xiaoping; Han, Xiangyu; Li, Haoran; Wang, Jia] Beijing Univ Civil Engn & Architecture, Beijing Key Lab Intelligent Proc Bldg Big Data, Beijing 100044, Peoples R China.
   [Liang, Xun] Renmin Univ China, Sch Informat, Beijing, Peoples R China.
C3 Beijing University of Civil Engineering & Architecture; Renmin
   University of China
RP Wang, J (corresponding author), Beijing Univ Civil Engn & Architecture, Beijing Key Lab Intelligent Proc Bldg Big Data, Beijing 100044, Peoples R China.
EM lukefchou@gmail.com; wangjia@bucea.edu.cn
RI Han, Xiangyu/GPW-5375-2022; Zhou, Xiaoping/L-2980-2019
OI Zhou, Xiaoping/0000-0001-5278-6576
FU Beijing Natural Science Foundation [4202017]; Key Research and
   Development Program of Anhui Province of China [202104a07020017]; Youth
   Talent Support Program of Beijing Municipal Education Commission
   [CITTCD201904050]
FX The funding were provided by the Beijing Natural Science Foundation
   (Grant No. 4202017), the Key Research and Development Program of Anhui
   Province of China (Grant No. 202104a07020017) and the the Youth Talent
   Support Program of Beijing Municipal Education Commission (Grant No.
   CIT&TCD201904050).
CR Ali N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157428
   Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   Amato G, 2013, LECT NOTES COMPUT SC, V8199, P245, DOI 10.1007/978-3-642-41062-8_25
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2017, BRIT MACH VIS C BMVC
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2013, ICMR
   [Anonymous], 2017, 2017 7 INT C IMAGE P, DOI DOI 10.1109/IPTA.2017.8310131
   Anwar H, 2014, IEEE IMAGE PROC, P5257, DOI 10.1109/ICIP.2014.7026064
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bae HB, 2020, IEEE ACCESS, V8, P50452, DOI 10.1109/ACCESS.2020.2980047
   Bai C, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102835
   Beal Matthew James, 2003, Variational algorithms for approximate Bayesian inference
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bui T, 2017, COMPUT VIS IMAGE UND, V164, P27, DOI 10.1016/j.cviu.2017.06.007
   Bui T, 2016, ARXIV
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaudhuri U, 2020, PATTERN RECOGN LETT, V131, P456, DOI 10.1016/j.patrec.2020.02.006
   Chen W., 2021, ARXIV
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Denton E., 2015, ARXIV
   Donahue J, 2017, ARXIV
   Du H, 2021, IEEE SIGNAL PROC LET, V28, P768, DOI 10.1109/LSP.2021.3071663
   Duanmu X., 2010, 7 INT C INF TECHN, P200, DOI DOI 10.1109/ITNG.2010.231
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   [范林龙 Fan Linlong], 2021, [图学学报, Journal of Graphics], V42, P44
   Ferreira RS, 2020, IEEE GEOSCI REMOTE S, V17, P1460, DOI 10.1109/LGRS.2019.2945680
   Fuentes A, 2021, IEEE COMPUT SOC CONF, P2134, DOI 10.1109/CVPRW53098.2021.00242
   Gajic B, 2018, IEEE COMPUT SOC CONF, P1950, DOI 10.1109/CVPRW.2018.00243
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Ghosh Neha, 2018, Proceedings of International Conference on Recent Advancement on Computer and Communication. ICRAC 2017. Lecture Notes in Networks and Systems (LNNS 34), P305, DOI 10.1007/978-981-10-8198-9_32
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo LT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1267, DOI 10.1145/3123266.3127939
   Ha I, 2018, BUILD ENVIRON, V140, P23, DOI 10.1016/j.buildenv.2018.05.026
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hameed IM, 2021, COGENT ENG, V8, DOI 10.1080/23311916.2021.1927469
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hermans Alexander, 2017, ARXIV170307737
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ibrahimi S, 2019, IEEE INT CONF COMP V, P3165, DOI 10.1109/ICCVW.2019.00390
   Irtaza A, 2015, SIGNAL IMAGE VIDEO P, V9, P1503, DOI 10.1007/s11760-013-0601-8
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Ji X, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1654, DOI 10.1145/3123266.3123429
   Jian Wang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2612, DOI 10.1109/ICCV.2017.283
   Jian-jian JI., 2019, J GRAPH, DOI [10.11996/JG.j.2095-302X.2019061008, DOI 10.11996/JG.J.2095-302X.2019061008]
   Kampelmuhler Moritz, 2020, P IEEECVF WINTER C A, P3203
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kateb B, 2009, NEUROIMAGE, V47, pT154, DOI 10.1016/j.neuroimage.2009.03.043
   Khan R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.89
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kingma D. P., 2014, arXiv
   Kodituwakku S.R., 2004, INDIAN J COMPUTER SC, V1, P207
   Kong B., 2017, British Machine Vision Conference (BMVC), P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kucer M, 2019, IEEE COMPUT SOC CONF, P344, DOI 10.1109/CVPRW.2019.00047
   Kumar VA, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P591, DOI 10.1109/ICIIP47207.2019.8985733
   Laubrock J, 2020, TOP COGN SCI, V12, P274, DOI 10.1111/tops.12476
   Lee T, 2018, INT CONF 3D VISION, P258, DOI 10.1109/3DV.2018.00038
   Lei HP, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5577735
   Lei JJ, 2017, IEEE IMAGE PROC, P3685, DOI 10.1109/ICIP.2017.8296970
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P6521, DOI 10.1109/TGRS.2018.2839705
   Lin HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1676, DOI 10.1145/3343031.3350900
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Liu C, 2020, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR42600.2020.00692
   Liu FC, 2021, IEEE T CIRC SYST VID, V31, P4485, DOI 10.1109/TCSVT.2020.3048945
   Liu J, 2013, ARXIV
   Liu J, 2019, AAAI CONF ARTIF INTE, P8754
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu L, 2017, PROC CVPR IEEE, P2298, DOI 10.1109/CVPR.2017.247
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Liu Wei., 2011, P 28 INT C MACHINE L, P1
   Liu XM, 2016, AER ADV ENG RES, V116, P1, DOI 10.1145/2875194.2875248
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XY, 2021, ISPRS J PHOTOGRAMM, V180, P296, DOI 10.1016/j.isprsjprs.2021.08.018
   [罗琪彬 Luo Qibin], 2019, [图学学报, Journal of Graphics], V40, P1056
   Luo Y., 2019, ARXIV
   Miao YW, 2020, IEEE ACCESS, V8, P142669, DOI 10.1109/ACCESS.2020.3013631
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pang K., 2017, BMVC, P1
   Park S, 2019, IEEE COMPUT SOC CONF, P316, DOI 10.1109/CVPRW.2019.00042
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russell B., 2011, International Conference on Computer Vision Workshops, P545
   Sain A, 2021, PROC CVPR IEEE, P8500, DOI 10.1109/CVPR46437.2021.00840
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shao H, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P753
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Shi XS, 2018, PATTERN RECOGN, V81, P14, DOI 10.1016/j.patcog.2018.03.015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Song L, 2017, ARXIV
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Syam B, 2013, INT ARAB J INF TECHN, V10, P143
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   [王欢欢 Wang Huanhuan], 2021, [图学学报, Journal of Graphics], V42, P688
   Wang R, 2009, LECT NOTES COMPUT SC, V5558, P319, DOI 10.1007/978-3-642-01793-3_33
   Wang W, 2016, SIGMOD REC, V45, P17, DOI 10.1145/3003665.3003669
   Wang X, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P7, DOI 10.1145/2911996.2912002
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wang XG, 2016, NEUROCOMPUTING, V207, P387, DOI 10.1016/j.neucom.2016.04.046
   Wei X, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107012
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu BW, 2020, INT CONF ACOUST SPEE, P2133, DOI [10.1109/ICASSP40776.2020.9053675, 10.1109/icassp40776.2020.9053675]
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xiang XZ, 2019, IEEE SENS J, V19, P11706, DOI 10.1109/JSEN.2019.2936916
   Xiong W, 2020, IEEE J-STARS, V13, P5284, DOI 10.1109/JSTARS.2020.3021390
   Xiong W, 2020, IEEE T GEOSCI REMOTE, V58, P4860, DOI 10.1109/TGRS.2020.2968096
   Xiong W, 2020, IEEE J-STARS, V13, P1234, DOI 10.1109/JSTARS.2020.2980870
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yu D, 2018, NEUROCOMPUTING, V296, P23, DOI 10.1016/j.neucom.2018.03.031
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   [张鹏飞 Zhang Pengfei], 2021, [图学学报, Journal of Graphics], V42, P572
   Zhang YF, 2018, LECT NOTES COMPUT SC, V11164, P392, DOI 10.1007/978-3-030-00776-8_36
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou D, 2016, IEEE IMAGE PROC, P2445, DOI 10.1109/ICIP.2016.7532798
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 152
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 199
EP 218
DI 10.1007/s13735-022-00244-7
EA JUL 2022
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000830306800001
DA 2024-07-18
ER

PT J
AU Panigrahi, S
   Raju, USN
AF Panigrahi, Sweta
   Raju, U. S. N.
TI InceptionDepth-wiseYOLOv2: improved implementation of YOLO framework for
   pedestrian detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE YOLO; Fire module; CNN; Detection; Feature map
ID CLASSIFICATION
AB Pedestrian detection is one of the most challenging research areas in computer vision, as it involves classifying the image and localizing the pedestrian. Its applications, especially in automated surveillance and robotics, are exceedingly sought-after. Compared to traditional hand-crafted methods, convolutional neural networks (CNNs) have superior detection results. The single-stage detection networks, particularly the You Only Look Once (YOLO) network, have attained a satisfactory performance in object detection without compromising the computation speed and are among the state-of-the-art CNN-based methods. The YOLO framework can be leveraged to use in pedestrian detection as well. In this work, we propose an improved YOLOv2, called InceptionDepth-wiseYOLOv2. The proposed model uses a modified DarkNet53 engineered for a robust feature formation. Three inception depth-wise convolution modules are integrated at varying levels in DarkNet53, leading to a comprehensive feature of an object in the image. The proposed method is compared with state-of-the-art detection methods, i.e., FasterRCNN, YOLOv2 with various base networks, YOLOv3, and Single Shot Multibox Detector. Detection Error Trade-off Curve, Precision-Recall Curve, Log Average Miss Rate, and Average Precision performance metrics are used to compare the methods. The analysis for the count of pedestrians detected concerning their height is also carried out. The experimental study used three benchmark pedestrian datasets: the INRIA Pedestrian, PASCAL VOC 2012, and Caltech Pedestrian.
C1 [Panigrahi, Sweta; Raju, U. S. N.] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Raju, USN (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
EM sweta.panigrahi6@gmail.com; usnraju@nitw.ac.in
RI Raju, U S N/AAN-7582-2020
OI Raju, U S N/0000-0003-1049-7949; Panigrahi, Sweta/0000-0002-2245-2046
CR [Anonymous], 2015, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2015.7299034
   Cai ZW, 2020, IEEE T PATTERN ANAL, V42, P2195, DOI 10.1109/TPAMI.2019.2910514
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao JL, 2017, IEEE T IMAGE PROCESS, V26, P3210, DOI 10.1109/TIP.2017.2694224
   Cao JL, 2016, IEEE T IMAGE PROCESS, V25, P5538, DOI 10.1109/TIP.2016.2609807
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hsu WY, 2021, IEEE T IMAGE PROCESS, V30, P934, DOI 10.1109/TIP.2020.3039574
   Hurney P, 2015, IET INTELL TRANSP SY, V9, P75, DOI 10.1049/iet-its.2013.0163
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2020, MULTIMED TOOLS APPL, V79, P21389, DOI 10.1007/s11042-020-08864-z
   Li HL, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P796, DOI 10.1109/CISP-BMEI.2016.7852818
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZM, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3518959
   Martin A., 1997, The DET Curve in Assessment of Detection Task Performance
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wenbo Lan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1547, DOI 10.1109/ICMA.2018.8484698
   Wu S, 2018, IEEE T IMAGE PROCESS, V27, P1418, DOI 10.1109/TIP.2017.2779271
   Yang X, 2020, ADV VISUAL COMPUTING, V12510, P1526, DOI [10.1007/978-3-030-64559-5_2, DOI 10.1007/978-3-030-64559-5_2]
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zhao Y, 2020, IEEE T IMAGE PROCESS, V29, P1591, DOI 10.1109/TIP.2019.2942686
   Zhu C, 2015, IEEE T IMAGE PROCESS, V24, P5619, DOI 10.1109/TIP.2015.2483376
NR 46
TC 4
Z9 5
U1 4
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 409
EP 430
DI 10.1007/s13735-022-00239-4
EA MAY 2022
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000793616900002
DA 2024-07-18
ER

PT J
AU Shojaei, G
   Razzazi, F
AF Shojaei, Ghazaleh
   Razzazi, Farbod
TI Semi-supervised domain adaptation for pedestrian detection in video
   surveillance based on maximum independence assumption
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Domain adaptation; Pedestrian detection; Transfer learning;
   Semi-supervised learning; Transfer component analysis; Maximum
   independence domain adaptation
ID FEATURES
AB In this paper, two domain adaptation approaches are utilized in a pedestrian detection application that is one of the most interesting and widely used fields in machine vision. In cases where the distributions of training and test data are different, the performance of pedestrian detection algorithms drops significantly. In this paper, employing two methods, namely transfer component analysis (TCA) and maximum independence domain adaptation (MIDA), the source and target domain data are represented in a new space where the distributions of two domains are more similar to each other, while the local geometry of data is preserved. Thereby, the classifier trained in the original space can be applied to the target data after the transformation. The experimental results of the proposed approach obtained on INRIA train dataset and CUHK test dataset show 82% about relative reduction in the classification error in the case of using TCA and about 84% in the case of using MIDA, compared to the baseline method where no domain adaptation method has been applied.
C1 [Shojaei, Ghazaleh; Razzazi, Farbod] Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University
RP Razzazi, F (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
EM razzazi@srbiau.ac.ir
RI Razzazi, Farbod/AAO-8522-2021
OI Razzazi, Farbod/0000-0003-4970-8117
CR Ali K, 2011, PROC CVPR IEEE, P1433, DOI 10.1109/CVPR.2011.5995403
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., 2010, BMVC 2010, DOI DOI 10.5244/C.24.68
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317
   Javed O, 2005, PROC CVPR IEEE, P696
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P626
   Maâmatou H, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0143-4
   Mao YX, 2015, IEEE WINT CONF APPL, P170, DOI 10.1109/WACV.2015.30
   Pan S.J., 2008, P 23 AAAI C ART INT, V8, P677, DOI DOI 10.5555/1620163.1620177
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pang JB, 2011, IEEE T IMAGE PROCESS, V20, P1388, DOI 10.1109/TIP.2010.2103951
   Qi G., 2011, Proc. ACM International Conference on World Wide Web, P297
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Roth P., 2009, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), P2727
   Roth P. M., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P223
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Song L, 2012, J MACH LEARN RES, V13, P1393
   Sun DQ, 2015, I S INTELL SIG PR, P52
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Yan K, 2018, IEEE T CYBERNETICS, V48, P288, DOI 10.1109/TCYB.2016.2633306
   Yu Guangbin, 2007, Shengwu Duoyangxing, V15, P188, DOI 10.1360/biodiv.060292
   Yuan Shi, 2012, P INT C MACH LEARN I, P1275
NR 33
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2019
VL 8
IS 4
BP 241
EP 252
DI 10.1007/s13735-019-00180-z
EA NOV 2019
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KN5AU
UT WOS:000493687700001
DA 2024-07-18
ER

PT J
AU Yuan, TH
   Liu, WF
   Yan, F
   Liu, BD
AF Yuan, Tianhao
   Liu, Weifeng
   Yan, Fei
   Liu, Baodi
TI Decision fusion for few-shot image classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few-shot learning; Decision fusion; Logistic regression; ProCRC
AB Recent few-shot learning methods mostly only use a single classifier to complete image classification. In general, a single classifier is likely to be overfitting because of its inherent drawbacks. However, the recognition rate of categorization will be significantly increased if we can utilize the complementary information of different classifiers. For the few-shot problem, the test samples come from new classes, which makes it difficult for a single classifier to distinguish, and it can be improved via decision fusion. In this paper, we propose decision fusion for few-shot learning (DF-FSL) to overcome the drawbacks of single classifier. To be specific, we assign the task to two classifiers, which are the logical regression classifier and probabilistic collaborative representation-based classifier (ProCRC), then allow the two classifiers to learn together through several iterations. Finally, we evaluate our approach on four benchmark image datasets, which include CIFAR-FS, CUB, miniImageNet and tieredImageNet datasets, and two remote sensing image datasets which are RSD46-WHU and NWPU-RESIS45. The experimental results illustrate the complementarity between different classifiers and show that the performance of our proposed DF-FSL method provides an obvious improvement. And DF-FSL can make great progress in few-shot remote sensing image classification.
C1 [Yuan, Tianhao; Liu, Weifeng; Liu, Baodi] China Univ Petr East China, Coll Control Sci & Engn, Qingdao 266580, Shandong, Peoples R China.
   [Yan, Fei] Lijin Cty Party Comm Off, Dongying 257499, Shandong, Peoples R China.
C3 China University of Petroleum
RP Liu, BD (corresponding author), China Univ Petr East China, Coll Control Sci & Engn, Qingdao 266580, Shandong, Peoples R China.
EM yuantianhao2002@163.com; liuwf@upc.edu.cn; 13854653889@163.com;
   thu.liubaodi@gmail.com
RI liu, weifeng/B-7909-2008
FU The paper was supported by the Natural Science Foundation of Shandong
   Province, China (Grant No. ZR2019MF073), the Fundamental Research Funds
   for the Central Universities, China University of Petroleum (East China)
   (Grant No. 20CX05001A), the Major Scienti [20CX05001A]; Natural Science
   Foundation of Shandong Province, China [ZD2019-183-008]; Fundamental
   Research Funds for the Central Universities, China University of
   Petroleum (East China); Major Scientific and Technological Projects of
   CNPC;  [ZR2019MF073]
FX The paper was supported by the Natural Science Foundation of Shandong
   Province, China (Grant No. ZR2019MF073), the Fundamental Research Funds
   for the Central Universities, China University of Petroleum (East China)
   (Grant No. 20CX05001A), the Major Scientific and Technological Projects
   of CNPC (No. ZD2019-183-008).
CR Afrasiyabi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9021, DOI 10.1109/ICCV48922.2021.00891
   Andrychowicz M, 2016, ADV NEUR IN, V29
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2012, P ICML WORKSHOP UNSU
   Bertinetto L, 2019, Arxiv, DOI arXiv:1805.08136
   Cai SJ, 2016, PROC CVPR IEEE, P2950, DOI 10.1109/CVPR.2016.322
   Chen WY, 2020, Arxiv, DOI arXiv:1904.04232
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Chikontwe P, 2022, PROC CVPR IEEE, P14534, DOI 10.1109/CVPR52688.2022.01415
   Cruz RMO, 2018, INFORM FUSION, V41, P195, DOI 10.1016/j.inffus.2017.09.010
   Fei N., 2020, MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning (ICLR)
   Finn C, 2017, PR MACH LEARN RES, V70
   Gong Y, 2021, DATA INTELLIGENCE, V3, P568, DOI 10.1162/dint_a_00102
   Graves A, 2014, Arxiv, DOI arXiv:1410.5401
   Hao FS, 2022, IEEE T CIRC SYST VID, V32, P4351, DOI 10.1109/TCSVT.2021.3132912
   Hao FS, 2019, IEEE I CONF COMP VIS, P8459, DOI 10.1109/ICCV.2019.00855
   Hao FS, 2019, IEEE ACCESS, V7, P100501, DOI 10.1109/ACCESS.2019.2906665
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kim J., 2020, EUR C COMP VIS, P599, DOI DOI 10.1007/978-3-030-58452-8_35
   KING G, 2001, POLIT ANAL, V0009
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X
   Lake B. M., 2013, Adv. Neural Inf. Proces. Syst., P2526, DOI DOI 10.5555/2999792.2999894
   Lan RS, 2017, IEEE INT CON MULTI, P1392, DOI 10.1109/ICME.2017.8019308
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li Y, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00770-1
   Li Y, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106055
   Li Y, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105240
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Luo, 2020, TRANSMATCH TRANSFER
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Mishra A, 2019, INT J MULTIMED INF R, V8, P135, DOI 10.1007/s13735-018-0160-4
   Oh J, 2021, Arxiv, DOI arXiv:2008.08882
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Qiao LM, 2019, IEEE I CONF COMP VIS, P3602, DOI 10.1109/ICCV.2019.00370
   Ravi S, 2016, OPTIMIZATION MODEL F
   Ren MY, 2018, Arxiv, DOI arXiv:1803.00676
   Revaud J, 2019, Arxiv, DOI [arXiv:1906.06195, DOI 10.48550/ARXIV.1906.06195]
   Rezende DJ, 2016, PR MACH LEARN RES, V48
   Rodriguez Pau, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P121, DOI 10.1007/978-3-030-58574-7_8
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Dhillon GS, 2020, Arxiv, DOI arXiv:1909.02729
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Xing C., 2019, Advances in Neural Information Processing Systems, P4847
   Xing L, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3180791
   Xing L, 2022, NEUROCOMPUTING, V488, P1, DOI 10.1016/j.neucom.2022.02.073
   Xu CM, 2021, PROC CVPR IEEE, P5178, DOI 10.1109/CVPR46437.2021.00514
   Xu R, 2022, NEURAL PROCESS LETT, V54, P3339, DOI 10.1007/s11063-022-10770-4
   Yang JY, 2022, INT J MULTIMED INF R, V11, P681, DOI 10.1007/s13735-022-00254-5
   Yikai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12833, DOI 10.1109/CVPR42600.2020.01285
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Zhang P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010108
NR 63
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 31
DI 10.1007/s13735-023-00281-w
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q4DO4
UT WOS:001057042200002
DA 2024-07-18
ER

PT J
AU Togo, R
   Honma, Y
   Abe, M
   Ogawa, T
   Haseyama, M
AF Togo, Ren
   Honma, Yuki
   Abe, Maiku
   Ogawa, Takahiro
   Haseyama, Miki
TI Similar interior coordination image retrieval with multi-view features
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Interior coordination; Deep learning; Similar image retrieval;
   Multi-view features
AB This paper presents a novel similar image retrieval method for interior coordination. Interior coordination is very familiar; however, it is still an abstract and difficult concept. Even if we are involved in coordination every day, it does not mean we can become professional coordinators. By realizing the retrieval that can provide similar interior coordination images from a query room image, inspiring users' ideas for interior coordination becomes feasible. In the proposed method, we extract image features specialized for interior coordination and realize similar interior coordination image retrieval. We employ multi-view features: object-based, color-based, and semantic-based features, in the feature extraction phase. The extracted features are used to calculate similarity between the query image and the database images for the retrieval. We conducted experiments using a sophisticated real-world interior coordination image dataset. Furthermore, we qualitatively and quantitatively evaluated the effectiveness of the proposed method.
C1 [Togo, Ren; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Fac Informat Sci & Technol, Sapporo, Hokkaido, Japan.
   [Honma, Yuki] Nitori Holdings Co Ltd, Informat Syst Innovat Off, Sapporo, Hokkaido, Japan.
   [Honma, Yuki; Abe, Maiku] Hokkaido Univ, Educ & Res Ctr Math & Data Sci, Sapporo, Hokkaido, Japan.
C3 Hokkaido University; Hokkaido University
RP Togo, R (corresponding author), Hokkaido Univ, Fac Informat Sci & Technol, Sapporo, Hokkaido, Japan.
EM togo@lmd.ist.hokudai.ac.jp
OI Togo, Ren/0000-0002-4474-3995
FU JSPS KAKENHI [JP20K19857]; NITORI Future Design Course at Education and
   Research Center for Mathematical and Data Science, Hokkaido Univ;
   Grants-in-Aid for Scientific Research [21H03456, 20K19857] Funding
   Source: KAKEN
FX This research was partly supported by JSPS KAKENHI Grant Number
   JP20K19857 and the NITORI Future Design Course at Education andResearch
   Center forMathematical andData Science, Hokkaido Univ.
CR Al-Emran M., 2020, SOCIAL INTERNET THIN, P197, DOI [https://doi.org/10.1007/978-3-030-24513-912, DOI 10.1007/978-3-030-24513-9_12, 10.1007/978-3-030-24513-9_12, DOI 10.1007/978-3-030-24513-912]
   [Anonymous], 2015, INT J SIGNAL PROCESS
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Brooker G., 2010, What is Interior Design? Roto Vision: Miles
   Cho JY, 2019, J INTERIOR DES, V44, P141, DOI 10.1111/joid.12143
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Daniels I, 2015, EMOT SPACE SOC, V15, P47, DOI 10.1016/j.emospa.2014.11.003
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dustdar S., 2005, International Journal of Web and Grid Services, V1, P1, DOI 10.1504/IJWGS.2005.007545
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   Gibbs J., 2005, Interior Design
   Greco L, 2020, PATTERN RECOGN LETT, V135, P346, DOI 10.1016/j.patrec.2020.05.016
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jocher G. J., 2021, Ultralytics/Yolov5: V6. 0-YOLOv5nNanomodels, Roboflow Integration, TensorFlow Export, OpenCV DNN Support
   Kaothanthong N, 2016, PATTERN RECOGN LETT, V78, P14, DOI 10.1016/j.patrec.2016.03.029
   Khanam S, 2011, COMM COM INF SC, V265, P120
   Kishi R, 2020, CURR TOP ENV HEAL PR, P3, DOI 10.1007/978-981-32-9182-9_1
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Leng JW, 2020, RENEW SUST ENERG REV, V132, DOI 10.1016/j.rser.2020.110112
   Li Y, 2018, MACH VISION APPL, V29, P1083, DOI 10.1007/s00138-018-0953-8
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MW, 2017, INFORM RETRIEVAL J, V20, P575, DOI 10.1007/s10791-017-9311-0
   Liu MM, 2020, IEEE T VIS COMPUT GR, V26, P1702, DOI 10.1109/TVCG.2018.2880737
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lohr Virginia I., 1996, Journal of Environmental Horticulture, V14, P97
   Lu Y, 2019, J MANAG ANAL, V6, P1, DOI 10.1080/23270012.2019.1570365
   Marjani M, 2017, IEEE ACCESS, V5, P5247, DOI 10.1109/ACCESS.2017.2689040
   Moares R., 2019, P 5 INT C CYB SEC PR
   Nhamo G, 2020, ENVIRON ECON POLICY, V22, P315, DOI 10.1007/s10018-019-00259-1
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Raanaas RK, 2011, J ENVIRON PSYCHOL, V31, P99, DOI 10.1016/j.jenvp.2010.11.005
   Rehman MHU, 2019, FUTURE GENER COMP SY, V99, P247, DOI 10.1016/j.future.2019.04.020
   Ruff CL, 2009, INT J TECHNOL DES ED, V19, P67, DOI 10.1007/s10798-007-9038-0
   SAVOLAINEN R, 1995, LIBR INFORM SCI RES, V17, P259, DOI 10.1016/0740-8188(95)90048-9
   Shih JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI 10.1007/s11042-008-0256-6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun PW, 2020, J CLEAN PROD, V260, DOI 10.1016/j.jclepro.2020.121077
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Togo R, 2021, PROC SPIE, V11766, DOI 10.1117/12.2590675
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Yanagi R, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3816, DOI 10.1145/3474085.3475681
   Yanagi R, 2020, IEEE ACCESS, V8, P96777, DOI 10.1109/ACCESS.2020.2995815
   Yasmin M, 2014, J APPL RES TECHNOL, V12, P87, DOI 10.1016/S1665-6423(14)71609-8
   Zhang Jin, 2007, VISUALIZATION INFORM, V23
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
NR 48
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 731
EP 740
DI 10.1007/s13735-022-00247-4
EA AUG 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000844923900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU de la Fuente, C
   Valero-Mas, JJ
   Castellanos, FJ
   Calvo-Zaragoza, J
AF de la Fuente, Carlos
   Valero-Mas, Jose J.
   Castellanos, Francisco J.
   Calvo-Zaragoza, Jorge
TI Multimodal image and audio music transcription
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Multimodal recognition; Automatic music transcription; Optical music
   recognition and deep learning
AB Optical Music Recognition (OMR) and Automatic Music Transcription (AMT) stand for the research fields that aim at obtaining a structured digital representation from sheet music images and acoustic recordings, respectively. While these fields have traditionally evolved independently, the fact that both tasks may share the same output representation poses the question of whether they could be combined in a synergistic manner to exploit the individual transcription advantages depicted by each modality. To evaluate this hypothesis, this paper presents a multimodal framework that combines the predictions from two neural end-to-end OMR and AMT systems by considering a local alignment approach. We assess several experimental scenarios with monophonic music pieces to evaluate our approach under different conditions of the individual transcription systems. In general, the multimodal framework clearly outperforms the single recognition modalities, attaining a relative improvement close to 40% in the best case. Our initial premise is, therefore, validated, thus opening avenues for further research in multimodal OMR-AMT transcription.
C1 [de la Fuente, Carlos; Valero-Mas, Jose J.; Castellanos, Francisco J.; Calvo-Zaragoza, Jorge] Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
C3 Universitat d'Alacant
RP de la Fuente, C (corresponding author), Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
EM cdlf4@alu.ua.es; jjvalero@dlsi.ua.es; fcastellanos@dlsi.ua.es;
   jcalvo@dlsi.ua.es
RI Valero-Mas, Jose J./HSB-4673-2023; Castellanos Regalado, Francisco
   Jose/S-3302-2018
OI Valero-Mas, Jose J./0000-0001-8667-4070; Calvo-Zaragoza,
   Jorge/0000-0003-3183-2232; Castellanos Regalado, Francisco
   Jose/0000-0001-9949-5522
FU Spanish "Ministerio de Ciencia e Innovacion" [PID2020-118447RA-I00];
   Spanish "Ministerio de Educacion y Formacion Profesional"
   [20CO1/000966]; "Programa I+D+i de la Generalitat Valenciana"
   [ACIF/2019/042, APOSTD/2020/256]; CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research was partially funded by the Spanish
   "Ministerio de Ciencia e Innovacion" through project MultiScore
   (PID2020-118447RA-I00). The first author acknowledges the support from
   the Spanish "Ministerio de Educacion y Formacion Profesional" through
   grant 20CO1/000966. The second and third authors acknowledge support
   from the "Programa I+D+i de la Generalitat Valenciana" through grants
   ACIF/2019/042 and APOSTD/2020/256, respectively.
CR [Anonymous], 2014, FOUND TRENDS INF RET, V8, P128, DOI 10.1561/1500000042
   Benetos E, 2019, IEEE SIGNAL PROC MAG, V36, P20, DOI 10.1109/MSP.2018.2869928
   Benetos E, 2013, J INTELL INF SYST, V41, P407, DOI 10.1007/s10844-013-0258-3
   Calvo-Zaragoza J., 2018, P 19 INT SOC MUS INF, P248
   Calvo-Zaragoza J, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3397499
   Calvo-Zaragoza J, 2017, PROC INT CONF DOC, P1081, DOI 10.1109/ICDAR.2017.179
   Calvo-Zaragoza Jorge., 2017, Proceedings of the 18th International Society for Music Information Retrieval Conference, P472, DOI [DOI 10.5281/ZENODO.1418333, 10.5281/zenodo.1418333]
   Dumas Bruno., 2012, Proceedings of the 4th ACM SIGCHI symposium on Engineering interactive computing systems - EICS'12, P15
   Granell E., 2018, P IBERSPEECH, P92
   Granell E, 2015, LECT NOTES COMPUT SC, V9256, P246, DOI 10.1007/978-3-319-23192-1_21
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Toselli AH, 2011, MULTIMODAL INTERACTIVE PATTERN RECOGNITON AND APPLICATIONS, P1, DOI 10.1007/978-0-85729-479-1_1
   Inesta JoseM., 2018, Proceedings of the 1st International Workshop on Reading Music Systems, P17
   Kingma D. P., 2014, arXiv
   Kristensson PO, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P588
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Miki M, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-2
   Pitsikalis V, 2017, SPRING SER CHALLENGE, P467, DOI 10.1007/978-3-319-57021-1_16
   Rebelo A, 2012, INT J MULTIMED INF R, V1, P173, DOI 10.1007/s13735-012-0004-6
   Román MA, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113769
   Roman Miguel A, 2019, P 20 INT SOC MUSIC I, P731
   Serra X., 2013, Roadmap for Music Information ReSearch
   Simonetta F, 2019, 2019 INTERNATIONAL WORKSHOP ON MULTILAYER MUSIC REPRESENTATION AND PROCESSING (MMRP 2019), P10, DOI [10.1109/MMRP.2019.00012, 10.1109/MMRP.2019.8665366]
   Singh A., 2012, 2012 IEEE International Conference on Emerging Signal Processing Applications, P52, DOI 10.1109/ESPA.2012.6152444
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
NR 25
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2022
VL 11
IS 1
BP 77
EP 84
DI 10.1007/s13735-021-00221-6
EA NOV 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI9SJ
UT WOS:000717439300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Jalali, V
   Kaur, D
AF Jalali, Vatika
   Kaur, Dapinder
TI A study of classification and feature extraction techniques for brain
   tumor detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Tumor; MRI; Feature extraction; Classifier
ID SEGMENTATION; MRI; FUSION
AB Medical imaging aids in the analysis of interior parts of the human body such as the functioning of the organs or tissues for early treatment of diseases. Many different types of medical imaging technologies exist, for example, X-ray radiography, magnetic resonance imaging, endoscopy, positron emission tomography, CT scan (computed tomography), and many more. A tumor is an abnormal tissue in the brain which causes damage to the functioning of the cell. Therefore, brain tumor detection is an incredibly tricky task. Manual detection of a tumor is quite risky as it involves the insertion of a needle in the brain. Thus, there is a need for automated brain tumor detection systems. The well-timed detection of the tumor can add to accurate treatment and can increase the survival rate of patients. From machine learning techniques, namely K-nearest neighbor, support vector machine, and more to soft computing techniques, namely artificial neural network, self-organizing map, and others hold a significant stand in detection and categorization of brain tumor. Various methods including deep learning-based classifiers such as convolutional neural network, recurrent neural network, deep belief network (DBN), and others are used to make it easier to detect the tumor. Hybrid classifiers were also used for classification systems such as combining the machine learning approach with soft computing. This study is to summarize and compare the work of various authors on automatic brain tumor detection using medical imaging. Based on the accuracy, specificity, and sensitivity parameters, the results of different techniques are analyzed and compared graphically.
C1 [Jalali, Vatika; Kaur, Dapinder] Chandigarh Engn Coll, Comp Sci, Landran, Punjab, India.
RP Jalali, V (corresponding author), Chandigarh Engn Coll, Comp Sci, Landran, Punjab, India.
EM vatikajalali23@gmail.com; dapinder.coecse@cgc.edu.in
RI Kaur, Dapinder/AAD-8888-2021
OI Kaur, Dapinder/0000-0003-4594-020X
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Abd-Ellah MK, 2019, MAGN RESON IMAGING, V61, P300, DOI 10.1016/j.mri.2019.05.028
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Alentorn A, 2016, PRESENTING SIGNS SYM, P19
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anjali R, 2017, EFFICIENT CLASSIFIER
   Arasi PRE, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1266-9
   Arora A, 2019, FUNDAMENTAL STEPS DI
   Ata ES, 2016, EUR J RADIOL, V85, P1545, DOI 10.1016/j.ejrad.2016.05.015
   Babu AE, 2018, 2018 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P213, DOI 10.1109/ICEDSS.2018.8544353
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Banan R, 2017, NEW WHO 2016 CLASSIF
   Begum SS, 2020, MULTIMED TOOLS APPL, V79, P14009, DOI 10.1007/s11042-020-08643-w
   Burduk R, 2013, LECT NOTES COMPUT SC, V8104, P401, DOI 10.1007/978-3-642-40925-7_37
   Chander PS, 2019, LECT NOTES MECH ENG, P49
   Chandra SK, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2019.101841
   Chaudhary Atish, 2020, International Journal of Information Technology, V12, P141, DOI 10.1007/s41870-018-0255-4
   Cheng YM, 2019, LECT NOTES COMPUT SC, V11953, P524, DOI 10.1007/978-3-030-36708-4_43
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   da Silva EAB, 2005, ELECTRICAL ENGINEERING HANDBOOK, P891, DOI 10.1016/B978-012170960-0/50064-5
   Das S., 2019, 2019 1 INT C ADV SCI, P1
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Deserno TM, 2011, BIOL MED PHYS BIOMED, P1, DOI 10.1007/978-3-642-15816-2_1
   Devi Nilakshi, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P125, DOI 10.1007/978-981-10-6890-4_11
   Devkota B, 2018, PROCEDIA COMPUT SCI, V125, P115, DOI 10.1016/j.procs.2017.12.017
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Du EY, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/432972
   Eckenstein M, 2020, HDB CLIN NEUROLOGY P, P241
   Eluri Venkateswara Reddy, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P319, DOI 10.1007/978-981-13-3393-4_33
   Gan WS, 2020, SIGNAL PROCESS IMAGE, DOI 10.1007/978-981-10-5550-8_10
   Kurka PRG, 2019, MECH SYST SIGNAL PR, V124, P142, DOI 10.1016/j.ymssp.2019.01.015
   Garg Vibhu, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1230), P161, DOI 10.1007/978-3-030-52243-8_13
   Ghahfarrokhi SS, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102025
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Hamid MAA, 2020, J MED BIOL ENG, V40, P307, DOI 10.1007/s40846-020-00510-1
   Hardan H, 2016, IMAGE PROCESSING
   Hargrave M, 2020, DEEP LEARNING CAN HE
   Harif M, 2017, PEDIAT CANC AFR, DOI 10.1007/978-3-319-17936-0_2
   Hashemzehi R, 2020, BIOCYBERN BIOMED ENG, V40, P1225, DOI 10.1016/j.bbe.2020.06.001
   Iftekharuddin KM, 2009, APPL MATH COMPUT, V207, P23, DOI 10.1016/j.amc.2007.10.063
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Kissane J, 2020, MRI RADIOLOGY FUNDAM, P33
   Kumar A.., 2018, PROC ICACCCN, P179
   Kumar P, 2019, BRAIN TUMOR MRI SEGM
   Kumar S, 2020, BIOCYBERN BIOMED ENG, V40, P1190, DOI 10.1016/j.bbe.2020.05.009
   Lahmiri S, 2017, BIOMED SIGNAL PROCES, V31, P148, DOI 10.1016/j.bspc.2016.07.008
   Leece R, 2017, NEURO-ONCOLOGY, V19, P1553, DOI 10.1093/neuonc/nox091
   Maharjan S, 2020, J NEUROSCI METH, V330, DOI 10.1016/j.jneumeth.2019.108520
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Marghalani Bashayer Fouad, 2019, Procedia Computer Science, V163, P78, DOI 10.1016/j.procs.2019.12.089
   Mehekare V, 2017, INT J ADV RES ELECT, DOI 10.15662/IJAREEIE.2017.0605082
   Minz A, 2017, IEEE INT ADV COMPUT, P701, DOI [10.1109/IACC.2017.0146, 10.1109/IACC.2017.137]
   Narasimhamurthy A, 2017, MED IMAGING, DOI 10.4018/978-1-5225-0571-6.ch002
   Naser MA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103758
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Parveen Singh A, 2016, P INT C REC COGN WIR, P123, DOI [10.1007/978-81-322-2638-3_14, DOI 10.1007/978-81-322-2638-3_14]
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Rajan PG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1368-4
   Raju AR, 2018, BIOCYBERN BIOMED ENG, V38, P646, DOI 10.1016/j.bbe.2018.05.001
   Rashid M.H.O., 2018, INTRO CHAPTER ADSORP, DOI [10.1109/IC4ME2.2018.8465613, DOI 10.5772/INTECHOPEN.77190]
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Seeram E, 2020, DIGIT RADIOGR, DOI 10.1007/978-981-15-6522-9_2
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Sert E, 2019, MED HYPOTHESES, V133, DOI 10.1016/j.mehy.2019.109413
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Sharma M, 2018, LECT NOTE DATA ENG, V4, P145, DOI 10.1007/978-981-10-4600-1_14
   Song GL, 2019, IEEE ACCESS, V7, P13842, DOI 10.1109/ACCESS.2019.2894435
   Spine M, 2018, BRAIN BIOPSY
   Sriramakrishnan P, 2019, BIOCYBERN BIOMED ENG, V39, P470, DOI 10.1016/j.bbe.2019.02.002
   Sun Z, 2011, BIOMEDICAL IMAGING R
   Tyagi V., 2018, UNDERSTANDING DIGITA
   Vallabhaneni RB, 2018, ALEX ENG J, V57, P2387, DOI 10.1016/j.aej.2017.09.011
   Venkat E, 2016, DIGITAL IMAGE PROCES
   Vijay V, 2016, PROCEDIA COMPUT SCI, V92, P475, DOI 10.1016/j.procs.2016.07.370
   Vimal Kurup R., 2019, ICICCT 2019 SYSTEM R, P110
   Zhang DW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107562
   Zimmerman RA, 2000, NEUROIMAGING, DOI 10.1007/978-1-4612-1152-5_27
NR 79
TC 7
Z9 7
U1 0
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2020
VL 9
IS 4
BP 271
EP 290
DI 10.1007/s13735-020-00199-7
EA NOV 2020
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OS6IE
UT WOS:000588843300001
DA 2024-07-18
ER

PT J
AU Mishra, A
AF Mishra, Anand
TI DHFML: deep heterogeneous feature metric learning for matching
   photograph and cartoon pairs
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Deep metric learning; Cross-modality; Heterogeneous face verification;
   Cross-modal retrieval
AB We study the problem of retrieving cartoon faces of celebrities given their real face as a query. We refer to this problem as Photo2Cartoon. The Photo2Cartoon problem is challenging since (i) cartoons vary excessively in style and (ii) modality gap between real and cartoon faces is large. To address these challenges, we present a discriminative deep metric learning approach designed for matching cross-modal faces and showcase Photo2Cartoon. The proposed approach learns a nonlinear transformation to project real and cartoon face pairs into a common subspace where distance between positive pairs becomes smaller as compared to distance between negative pairs. We evaluate our method on two public benchmarks, namely IIIT-CFW and Viewed Sketch, and show superior retrieval results as compared to related methods.
C1 [Mishra, Anand] IISc, Dept Computat & Data Sci, Bangalore, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Mishra, A (corresponding author), IISc, Dept Computat & Data Sci, Bangalore, Karnataka, India.
EM anandmishra@iisc.ac.in
RI Mishra, Anand/ABA-3300-2021
OI Mishra, Anand/0000-0002-7806-2557
CR [Anonymous], 2013, BMVC
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2 INT C AUD VID BAS
   [Anonymous], 2015, BMVC
   [Anonymous], 2009, ICCV
   [Anonymous], CIKM
   [Anonymous], 2015, BMVC
   [Anonymous], 2014, ACCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2005, NIPS
   [Anonymous], 2013, In ICCV
   Bellet A, 2013, ARXIV13066709 CORR
   Cao Q., 2018, FG
   Fan H, 2014, ARXIV14032802 CORR
   Hardle W.K., 2015, Applied Multivariate Statistical Analysis, P443, DOI DOI 10.1007/978-3-662-45171-7_16
   Hu P., 2017, CVPR
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Huang X, 2017, ARXIV170307026
   Huo J, 2016, ACM MM
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Koch G., 2015, P ICML DEEP LEARN WO, V2
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Martinez A. M., 1998, THE AR FACE DATABASE
   MAURO R, 1992, MEM COGNITION, V20, P433, DOI 10.3758/BF03210927
   Mignon Alexis, 2012, ACCV
   Mishra A, 2016, VASE ECCVW
   Simonyan K., 2014, 14091556 ARXIV
   SUGIYAMA M, 2006, ICML
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 32
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2019
VL 8
IS 3
BP 135
EP 142
DI 10.1007/s13735-018-0160-4
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS8RG
UT WOS:000482416600001
DA 2024-07-18
ER

PT J
AU Bhorge, SB
   Manthalkar, RR
AF Bhorge, Sidharth B.
   Manthalkar, Ramachandra R.
TI Three-dimensional spatio-temporal trajectory descriptor for human action
   recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Spatio-temporal descriptor; Directional derivative; Human action
   recognition; Shape of trajectories
AB This paper presents a method for action recognition based on trajectory representation. The motion information for action recognition is obtained by tracking the key points through the video sequence using a standard KLT tracker. We propose a new 3D spatio-temporal descriptor based on histogram of directional derivative (3D-HODD) to describe the volume extracted around the trajectories. Our descriptor describes the local object appearance within the volume effectively and distinctively. The final descriptor constructed by combining the shape of trajectories (motion information) with 3D-HODD (appearance information). A multiclass support vector machine has been used to classify the human activities. The proposed framework for recognition of human action has been extensively validated on the benchmark datasets, with a focus that this methodology is robust and attains more precise human action recognition rate as compared to current methodologies available.
C1 [Bhorge, Sidharth B.] Vishwakarma Inst Technol, Dept E&TC, Pune, Maharashtra, India.
   [Manthalkar, Ramachandra R.] Shri Guru Gobind Singhji Inst Engn & Technol, Dept E&TC, Nanded, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology
RP Bhorge, SB (corresponding author), Vishwakarma Inst Technol, Dept E&TC, Pune, Maharashtra, India.
EM Siddharth.bhorge@vit.edu; rrmanthalkar@sggs.ac.in
RI Manthalkar, Ramchandra/ABH-2074-2020
OI Manthalkar, Ramchandra/0000-0003-0262-5971; Bhorge,
   sidharth/0000-0003-1052-5516
CR Abdul-Azim HA, 2015, EGYPT INFORM J, V16, P187, DOI 10.1016/j.eij.2015.05.002
   Alghyaline S, 2016, IEEE SYS MAN CYBERN, P2163, DOI 10.1109/SMC.2016.7844559
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], P BRIT MACH VIS C, DOI DOI 10.5244/C.24.8
   Avgerinakis K, 2015, J AMB INTEL SMART EN, V7, P817, DOI 10.3233/AIS-150347
   Banerjee P, 2011, IEEE INT C ADV VID S
   Barger TS, 2005, IEEE T SYST MAN CY A, V35, P22, DOI 10.1109/TSMCA.2004.838474
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bhorge S, 2017, IEEE INT C DAT MAN A
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dollar P, 2005, IEEE INT WORKSH VS P
   Falco P, 2017, IEEE ROBOT AUTOM LET, V2, P811, DOI 10.1109/LRA.2017.2652494
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Kl A, 2008, BRIT MACH VIS C
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li NJ, 2014, MACH VISION APPL, V25, P1793, DOI 10.1007/s00138-014-0639-9
   Lin WY, 2008, IEEE T CIRC SYST VID, V18, P1128, DOI 10.1109/TCSVT.2008.927111
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Murthy OVR, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P412, DOI 10.1109/ICCVW.2013.61
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seo JJ, 2017, IMAGE VISION COMPUT, V58, P76, DOI 10.1016/j.imavis.2016.06.002
   Shao L, 2011, NEUROCOMPUTING, V74, P962, DOI 10.1016/j.neucom.2010.11.013
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Somasundaram G, 2014, COMPUT VIS IMAGE UND, V123, P1, DOI 10.1016/j.cviu.2014.01.002
   Song Y, 2015, IEEE SIGNAL PROC LET, V22, P426, DOI 10.1109/LSP.2014.2361901
   Sun J, 2010, IEEE INT C MULT EXP
   Turaga P, 2011, IEEE SENS J, V11, P593, DOI 10.1109/JSEN.2010.2050309
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Vishwakarma DK, 2017, IEEE T COGN DEV SYST, V9, P316, DOI 10.1109/TCDS.2016.2577044
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang XF, 2017, SIGNAL PROCESS-IMAGE, V57, P91, DOI 10.1016/j.image.2017.05.007
   Wang XF, 2016, MACH VISION APPL, V27, P861, DOI 10.1007/s00138-016-0746-x
   Wang YX, 2017, NEUROCOMPUTING, V228, P19, DOI 10.1016/j.neucom.2016.07.058
   Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51
   Zhou ZN, 2008, IEEE T CIRC SYST VID, V18, P1489, DOI 10.1109/TCSVT.2008.2005612
NR 43
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2018
VL 7
IS 3
BP 197
EP 205
DI 10.1007/s13735-018-0152-4
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HI5SF
UT WOS:000456513600005
DA 2024-07-18
ER

PT J
AU Fang, YC
   Wang, LJ
   Lin, SQ
   Ni, L
AF Fang, Yuchun
   Wang, Liangjun
   Lin, Shiquan
   Ni, Lan
TI Visual feature segmentation with reinforcement learning for continuous
   sign language recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video recognition; Sign language recognition; Reinforcement learning;
   Deep learning
AB Continuous sign language recognition (CSLR) involves inputting a video that contains unbroken signs and outputting a prediction of the sign gloss sequence. Our research found that the visual features extracted from different signs in a sign language video show a noticeable disparity. As a result, we employed reinforcement learning (RL) to segment the visual features of the video into multiple groups to aid in model training. Compared to previous CSLR methods, our approach results in a more fine-tuned and supervised training process, leading to greater effective gradient backpropagation and improved model performance. We introduce a novel method named "Visual Feature Segmentation with Reinforcement Learning (VFS-RL)" for CSLR. Firstly, we constructed an end-to-end continuous sign language recognition network. Subsequently, we designed an auxiliary task of multi-class recognition to improve the model's capability for extracting semantic information from sign video, which uses RL to group the video's visual features. Finally, we conducted experiments on two public CSLR datasets, and the results of our ablation studies demonstrate the effectiveness of our proposed method. Our approach has competitive results compared to other methods in comparison tests.
C1 [Fang, Yuchun; Wang, Liangjun; Lin, Shiquan] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Ni, Lan] Shanghai Univ, Coll Liberal Arts, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University
RP Ni, L (corresponding author), Shanghai Univ, Coll Liberal Arts, Shanghai, Peoples R China.
EM ycfang@shu.edu.cn; shuwlj@shu.edu.cn; funterlin@shu.edu.cn;
   yclannimail@shu.edu.cn
RI Zhou, Xinyi/KGM-6689-2024; fang, yu/KCK-2014-2024; Liu,
   yuqing/KEI-3260-2024; guo, ppdop/KAL-9865-2024; chen,
   huan/KEC-2019-2024; LI, LIXIN/KFS-0074-2024; qin, cheng/KHC-3344-2024;
   Ni, Lan/KFR-4762-2024; yang, yunfeng/KHT-9566-2024
FU We appreciate the High Performance Computing Center of Shanghai
   University and Shanghai Engineering Research Center of Intelligent
   Computing System No.: 19DZ2252600 for providing the computing resources.
   [19DZ2252600]
FX We appreciate the High Performance Computing Center of Shanghai
   University and Shanghai Engineering Research Center of Intelligent
   Computing System No.: 19DZ2252600 for providing the computing resources.
CR Adaloglou N, 2022, IEEE T MULTIMEDIA, V24, P1750, DOI 10.1109/TMM.2021.3070438
   Al-Ayyoub M, 2018, J COMPUT SCI-NETH, V26, P522, DOI 10.1016/j.jocs.2017.11.011
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   Das S, 2023, NEURAL COMPUT APPL, V35, P1469, DOI 10.1007/s00521-022-07840-y
   Deng XM, 2017, Arxiv, DOI arXiv:1704.02224
   Dittmar T, 2015, J COMPUT SCI-NETH, V10, P66, DOI 10.1016/j.jocs.2015.03.002
   Farajzadeh N, 2021, J COMPUT SCI-NETH, V56, DOI 10.1016/j.jocs.2021.101486
   Freeman W. T., 1995, P INT WORKSH AUT FAC, V12, P296
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P744
   Guo J., 2022, LNCS, V13536, P408, DOI [10.1007/978-3-031-18913-532, DOI 10.1007/978-3-031-18913-532]
   Gupta B, 2016, INT CONF COMP COMMUN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosseini A, 2022, J COMPUT SCI-NETH, V61, DOI 10.1016/j.jocs.2022.101638
   Huang J., 2018, P AAAI C ARTIFICIAL, VVolume 32
   Huang SL, 2021, IEEE ACCESS, V9, P70948, DOI 10.1109/ACCESS.2021.3078638
   Ibrahim NB, 2018, J KING SAUD UNIV-COM, V30, P470, DOI 10.1016/j.jksuci.2017.09.007
   Ka Leong Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P697, DOI 10.1007/978-3-030-58586-0_41
   KingaD A, 2015, AN INTERNATIONALCONF
   Koller O, 2020, IEEE T PATTERN ANAL, V42, P2306, DOI 10.1109/TPAMI.2019.2911077
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Koller Oscar., 2016, P BMVC, P1, DOI 10.5244/C.30.136
   Li HZ, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107392
   Li RH, 2022, APPL INTELL, V52, P14624, DOI 10.1007/s10489-022-03407-5
   Liu H, 2018, Advances in neural information processing systems, V31
   Pu JF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P885
   Pu JF, 2019, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2019.00429
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Shi BW, 2018, IEEE W SP LANG TECH, P145, DOI 10.1109/SLT.2018.8639639
   Wahid MF, 2018, J COMPUT SCI-NETH, V27, P69, DOI 10.1016/j.jocs.2018.04.019
   Wang F, 2022, NEURAL COMPUT APPL, V34, P17921, DOI 10.1007/s00521-022-07415-x
   Wang F, 2022, NEURAL COMPUT APPL, V34, P2413, DOI 10.1007/s00521-021-06467-9
   Wei CC, 2021, IEEE T CIRC SYST VID, V31, P1138, DOI 10.1109/TCSVT.2020.2999384
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xie P, 2022, IEEE T MULTIMEDIA, V24, P3908, DOI 10.1109/TMM.2021.3109665
   Yang ZY, 2019, Arxiv, DOI arXiv:1908.01341
   Zhang Jingyun, 2016, 2016 IEEE International Conference on Multimedia & Expo: Workshops (ICMEW), DOI 10.1109/ICMEW.2016.7574749
   Zhang ZH, 2019, IEEE IMAGE PROC, P285, DOI [10.1109/ICIP.2019.8802972, 10.1109/icip.2019.8802972]
   Zhe Niu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P172, DOI 10.1007/978-3-030-58517-4_11
   Zhou H, 2020, AAAI CONF ARTIF INTE, V34, P13009
   Zhou H, 2019, IEEE INT CON MULTI, P1282, DOI 10.1109/ICME.2019.00223
NR 42
TC 0
Z9 0
U1 8
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 39
DI 10.1007/s13735-023-00302-8
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y0LC6
UT WOS:001102260800001
DA 2024-07-18
ER

PT J
AU Mahajan, S
   Rani, R
   Trehan, K
AF Mahajan, Shilpa
   Rani, Rajneesh
   Trehan, Karan
TI DELIGHT-Net: DEep and LIGHTweight network to segment Indian text at word
   level from wild scenic images
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Natural scene image; Text extraction; Text segmentation; Text analysis
   system; Deep learning
ID CHARACTER SEGMENTATION; FRAMEWORK; EXTRACTION
AB The recognition and detection of multioriented text from textual natural scene images are still challenging in the computer vision community. The segmentation on either word level or character level is a vital step in the entire end-to-end performance of the scene text recognition system. Many academicians and researchers have done work in the prominent field of segmenting the words or characters from complex document images as well as handwritten images for various non-Indian scripts. In this paper, we extensively presented a deep learning-based architecture named DELIGHT-Net which is derived from the general UNet architecture to segment the text at the word level from natural scene images. The method is mainly proposed to segment the Devanagari, Gurumukhi, and English scenic words from complete images collected from day-to-day life. To achieve this, we have introduced a new dataset, i.e., National Institute of Technology Jalandhar-Word Segmentation (NITJ-WS) which has around 2200 text blocks extracted from 1500 natural images containing unilingual, bilingual, and trilingual text. The benchmark comparative assessment of our dataset is performed with the proposed model and two state-of-the-art models, i.e., UNet and ResUNet. Statistical and visual results are evaluated using different evaluation parameters, which depict the efficiency of the proposed model. Some possible future directions are also recommended in the manuscript. We hope that our work is a stepping stone for academicians in the field of natural scene text recognition.
C1 [Mahajan, Shilpa; Rani, Rajneesh; Trehan, Karan] Dr BR Ambedkar Natl Inst Technol, Jalandhar 144011, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Mahajan, S (corresponding author), Dr BR Ambedkar Natl Inst Technol, Jalandhar 144011, Punjab, India.
EM shilpam.cs.17@nitj.ac.in
CR Alghamdi A, 2021, 2021 IEEE NATIONAL COMPUTING COLLEGES CONFERENCE (NCCC 2021), P1012, DOI 10.1109/NCCC49330.2021.9428836
   Amara M, 2016, ADV INTELL SYST, V420, P167, DOI 10.1007/978-3-319-27221-4_14
   Ansari GJ, 2018, FUTURE GENER COMP SY, V87, P328, DOI 10.1016/j.future.2018.04.074
   Bansal V, 2002, PATTERN RECOGN, V35, P875, DOI 10.1016/S0031-3203(01)00081-4
   Basavaraju HT, 2021, EVOL INTELL, V14, P881, DOI 10.1007/s12065-020-00472-y
   Bhattacharya Ujjwal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P171, DOI 10.1109/ICDAR.2009.178
   Chaitra Y, 2022, 2022 IEEE INT C DAT, P1
   Chaitra Y. L., 2022, ICT with Intelligent Applications: Proceedings of ICTIS 2021. Smart Innovation, Systems and Technologies (248), P563, DOI 10.1007/978-981-16-4177-0_55
   Chaitra YL, 2022, ARAB J SCI ENG, V47, P9629, DOI 10.1007/s13369-021-06309-9
   Chongsheng Zhang, 2022, IEEE Transactions on Artificial Intelligence, V3, P297, DOI 10.1109/TAI.2021.3116216
   Dai YC, 2018, INT C PATT RECOG, P3604, DOI 10.1109/ICPR.2018.8546066
   Dezhi Peng, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P25, DOI 10.1109/ICDAR.2019.00014
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Firdaus FI, 2017, 2017 INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET), P392, DOI 10.1109/SIET.2017.8304170
   Jamali Mahabadi S.E., 2019, IEEE International Topical Meeting on Microwave Photonics, P1, DOI 10.1109/icict46931.2019.8977630
   Karaoglu S, 2017, IEEE T MULTIMEDIA, V19, P1063, DOI 10.1109/TMM.2016.2638622
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Khare V, 2019, EXPERT SYST APPL, V131, P219, DOI 10.1016/j.eswa.2019.04.030
   Kumar S, 2007, IEEE T IMAGE PROCESS, V16, P2117, DOI 10.1109/TIP.2007.900098
   Liu XQ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1721, DOI 10.1109/ICME.2006.262882
   Liu XQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATIONS, VOLS 1-4, CONFERENCE PROCEEDINGS, P701
   Lu T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107591
   Madi B, 2022, INT J DOC ANAL RECOG, V25, P415, DOI 10.1007/s10032-022-00408-5
   Mahajan S, 2021, ARTIF INTELL REV, V54, P4317, DOI 10.1007/s10462-021-10000-8
   Mahajan S, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P584, DOI 10.1109/ICSCCC.2018.8703369
   Mancas-Thillou C, 2005, PROC INT CONF DOC, P312, DOI 10.1109/ICDAR.2005.76
   Mechi Olfa, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P369, DOI 10.1109/ICDAR.2019.00066
   Milosevic N, 2019, INT J DOC ANAL RECOG, V22, P55, DOI 10.1007/s10032-019-00317-0
   Minghui Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P706, DOI 10.1007/978-3-030-58621-8_41
   Nguyen DD, 2022, INT J DOC ANAL RECOG, V25, P1, DOI 10.1007/s10032-021-00390-4
   Papavassiliou V, 2010, PATTERN RECOGN, V43, P369, DOI 10.1016/j.patcog.2009.05.007
   Qomariyah F., 2017, J Telecommun Electron Comput Eng, V9, P19
   Raj H, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P513, DOI 10.1109/ICACCI.2014.6968472
   Rajan V, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P1136, DOI 10.1109/ICCMC.2017.8282651
   Rajyagor B., 2021, INDIAN J SCI TECHNOL, V14, P618, DOI [10.17485/IJST/v14i7.2146, DOI 10.17485/IJST/v14i7.2146]
   Rong XJ, 2020, IEEE T IMAGE PROCESS, V29, P591, DOI 10.1109/TIP.2019.2930176
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahare P, 2018, IEEE ACCESS, V6, P10603, DOI 10.1109/ACCESS.2018.2795104
   Saleem SI, 2021, CMC-COMPUT MATER CON, V68, P2727, DOI 10.32604/cmc.2021.016447
   Wang C, 2021, IEEE T IMAGE PROCESS, V30, P8212, DOI 10.1109/TIP.2021.3113157
   Xu X., 2022, CVPR, P19152
   Xu XQ, 2021, PROC CVPR IEEE, P12040, DOI 10.1109/CVPR46437.2021.01187
   Yang H, 2015, IEEE T CYBERNETICS, V45, P533, DOI 10.1109/TCYB.2014.2330657
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
NR 44
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 29
DI 10.1007/s13735-023-00293-6
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q9UJ8
UT WOS:001060892300001
DA 2024-07-18
ER

PT J
AU Junayed, MS
   Islam, MB
   Imani, H
   Aydin, T
AF Junayed, Masum Shah
   Islam, Md Baharul
   Imani, Hassan
   Aydin, Tarkan
TI PDS-Net: A novel point and depth-wise separable convolution for
   real-time object detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Object detection; Classification; DWS Convolution; PWS convolution;
   Transformer encoder-decoder; Computer vision
ID FEATURE PYRAMID NETWORK; RECOGNITION
AB Numerous recent object detectors and classifiers have shown acceptable performance in recent years by using convolutional neural networks and other efficient architectures. However, most of them continue to encounter difficulties like overfitting, increased computational costs, and low efficiency and performance in real-time scenarios. This paper proposes a new lightweight model for detecting and classifying objects in images. This model presents a backbone for extracting in-depth features and a spatial feature pyramid network (SFPN) for accurately detecting and categorizing objects. The proposed backbone uses point-wise separable (PWS) and depth-wise separable convolutions, which are more efficient than standard convolution. The PWS convolution utilizes a residual shortcut link to reduce computation time. We also propose a SFPN that comprises concatenation, transformer encoder-decoder, and feature fusion modules, which enables the simultaneous processing of multi-scale features, the extraction of low-level characteristics, and the creation of a pyramid of features to increase the effectiveness of the proposed model. The proposed model outperforms all of the existing backbones for object detection and classification in three publicly accessible datasets: PASCAL VOC 2007, PASCAL VOC 2012, and MS-COCO. Our extensive experiments show that the proposed model outperforms state-of-the-art detectors, with mAP improvements of 2.4% and 2.5% on VOC 2007, 3.0% and 2.6% on VOC 2012, and 2.5% and 3.6% on MS-COCO in the small and large sizes of the images, respectively. In the MS-COCO dataset, our model achieves FPS of 39.4 and 33.1 in a single GPU for the small (320 x 320) and large (512 x 512) sizes of the images, respectively, which shows that our method can run in real-time.
C1 [Junayed, Masum Shah; Islam, Md Baharul; Imani, Hassan; Aydin, Tarkan] Bahcesehir Univ, Dept Comp Engn, TR-34349 Istanbul, Turkey.
C3 Bahcesehir University
RP Junayed, MS; Islam, MB (corresponding author), Bahcesehir Univ, Dept Comp Engn, TR-34349 Istanbul, Turkey.
EM masumshahjunayed@gmail.com; bislam.eng@gmail.com;
   hassan.imani1987@gmail.com; tarkan.aydin@eng.bau.edu.tr
RI Imani, Hassan/KSL-4309-2024; Islam, Md Baharul/R-3751-2019; Junayed,
   Masum Shah/P-7375-2019
OI Imani, Hassan/0000-0003-1566-3897; Islam, Md
   Baharul/0000-0002-9928-5776; Junayed, Masum Shah/0000-0003-3592-4601;
   Aydin, Tarkan/0000-0002-2018-405X
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   through the 2232 Outstanding International Researchers Program [118C301]
FX This work was supported in part by the Scientific and Technological
   Research Council of Turkey (TUBITAK) through the 2232 Outstanding
   International Researchers Program under Project No. 118C301.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   [Anonymous], 2018, IEEE INT CON MULTI
   [Anonymous], 2015, P ADV NEUR INF PROC
   Aziz L, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104287
   Bastian BT, 2019, INT J MULTIMED INF R, V8, P127, DOI 10.1007/s13735-019-00171-0
   Bell S, 2016, P IEEE C COMPUTER VI
   Bochkovskiy A., 2020, PREPRINT
   Cai Z, 2016, EUROPEAN C COMPUTER
   Carion N, 2020, EUR C COMP VIS
   Chen X, IEEE T MULTIMED
   Chollet F., 2017, P IEEE C COMPUTER VI
   Dai J, 2016, P IEEE C COMPUTER VI
   Dai J, ARXIV160506409
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A., ARXIV201011929
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farhadi A, COMPUT VIS PATTERN R
   Fu C.Y., ARXIV170106659
   Geiger A, 2012, 2012 IEEE C COMPUTER
   Ghiasi G, 2019, P IEEE C COMPUTER VI
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   De Oliveira BAG, 2018, IEEE ACCESS, V6, P8714, DOI 10.1109/ACCESS.2018.2801813
   He K, 2017, P IEEE INT C COMP VI
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He W, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012042
   Huang Z, 2019, P IEEECVF C COMPUTER
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2016, P IEEE C COMPUTER VI
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li BQ, 2018, IEEE ACCESS, V6, P18967, DOI 10.1109/ACCESS.2018.2814605
   Li J, 2021, P IEEE CVF C COMP VI
   Li S, 2019, P IEEECVF INT C COMP
   Li Y, 2019, P IEEECVF INT C COMP
   Li YZ, 2021, IEEE T IMAGE PROCESS, V30, P2708, DOI 10.1109/TIP.2020.3048630
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2017, P IEEE INT C COMPUTE
   Mahmood A, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.09.002
   Mani MR, 2016, INT J MULTIMED INF R, V5, P219, DOI 10.1007/s13735-016-0107-6
   Najibi M, 2019, P IEEECVF INT C COMP
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi CJ, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104099
   Shrivastava A., 2016, P IEEE C COMPUTER VI
   Singh B, 2018, P IEEE C COMPUTER VI
   Solovyev R, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104117
   Soviany P, 2018, 20 INT S SYMBOLIC NU
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tan M., 2020, P IEEE CVF C COMP VI
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang DC, 2019, IEEE ACCESS, V7, P144134, DOI 10.1109/ACCESS.2019.2945834
   Wu SK, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103911
   Xu H, 2019, P IEEECVF INT C COMP
   Zhang Z, 2018, P IEEE C COMPUTER VI
   Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3
   Zhao Q, 2019, P AAAI C ARTIFICIAL
   Zhou P, 2018, P IEEE C COMPUTER VI
   Zhu Y, 2017, P IEEE INT C COMPUTE
NR 69
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 171
EP 188
DI 10.1007/s13735-022-00229-6
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000791798400007
DA 2024-07-18
ER

PT J
AU Ellouze, M
AF Ellouze, Mehdi
TI How can users' comments posted on social media videos be a source of
   effective tags?
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video tagging; Social media comments; Self-organizing map; YouTube
AB This paper proposed a new approach for the extraction of tags from users' comments made about videos. In fact, videos on the social media, like Facebook and YouTube, are usually accompanied by comments where users may give opinions about things evoked in the video. The main challenge is how to extract relevant tags from them. To the best of the authors' knowledge, this is the first research work to present an approach to extract tags from comments posted about videos on the social media. We do not pretend that comments can be a perfect solution for tagging videos since we rather tried to investigate the reliability of comments to tag videos and we studied how they can serve as a source of tags. The proposed approach is based on filtering the comments to retain only the words that could be possible tags. We relied on the self-organizing map clustering considering that tags of a given video are semantically and contextually close. We tested our approach on the Google YouTube 8M dataset, and the achieved results show that we can rely on comments to extract tags. They could be also used to enrich and refine the existing uploaders' tags as a second area of application. This can mitigate the bias effect of the uploader's tags which are generally subjective.
C1 [Ellouze, Mehdi] Sfax Univ, FSEG Sfax, Dept Comp Engn, Airport Rd Km 4, Sfax 3018, Tunisia.
C3 Universite de Sfax
RP Ellouze, M (corresponding author), Sfax Univ, FSEG Sfax, Dept Comp Engn, Airport Rd Km 4, Sfax 3018, Tunisia.
EM mehdi.ellouze@ieee.org
FU GeneralDirection of Scientific Research and Technological Renovation
   (DGRSRT), Tunisia, under the PEJC program
FX This work was done due to the financial support from the
   GeneralDirection of Scientific Research and Technological Renovation
   (DGRSRT), Tunisia, under the PEJC program.
CR Abu-El-Haija Sami, 2016, arXiv
   [Anonymous], 2020, YOUTUBE ACADEMYLAST
   [Anonymous], GOOGLE IO 2013SEMANT
   Anthony L., 2014, AntConc Version 3.4.3
   Ayadi T, 2013, NEURAL COMPUT APPL, V22, P1387, DOI 10.1007/s00521-012-0930-5
   Ballan L, 2015, COMPUT VIS IMAGE UND, V140, P58, DOI 10.1016/j.cviu.2015.05.009
   Ballan L, 2015, MULTIMED TOOLS APPL, V74, P1443, DOI 10.1007/s11042-014-1976-4
   Baraldi L, 2017, COMM COM INF SC, V733, P56, DOI 10.1007/978-3-319-68130-6_5
   Bird S., 2009, NATURAL LANGUAGE PRO
   Bollegala D, 2007, P 16 INT WORLD WID W
   Campos R, 2020, INFORM SCIENCES, V509, P257, DOI 10.1016/j.ins.2019.09.013
   Chen PI, 2010, EXPERT SYST APPL, V37, P1928, DOI 10.1016/j.eswa.2009.07.016
   Chiraratanasopha B., 2021, SCI TECHNOL HUM VAL, V11, P66
   Chou CL, 2014, LECT NOTES ARTIF INT, V8643, P700, DOI 10.1007/978-3-319-13186-3_62
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Ellouze M, 2007, ACT C GEOTUNIS 2007, P271
   Ellouze M, 2010, MULTIMED TOOLS APPL, V47, P325, DOI 10.1007/s11042-009-0325-5
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Klami M, 2006, LECT NOTES COMPUT SC, V4224, P912
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Marujo L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P637
   Mazloom M, 2016, IEEE T MULTIMEDIA, V18, P1378, DOI 10.1109/TMM.2016.2559947
   Oorschot G, 2012, WORKSHOP DETECTION R
   Pacella M, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/5139574
   Park J, 2014, J INF SCI, V40, P38, DOI 10.1177/0165551513508877
   Siersdorfer S, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/1571941.1572010
   Talabis M.R.M., 2015, INFORM SECURITY ANAL, P123, DOI [10.1016/B978-0-12-800207-0.00006-x, DOI 10.1016/B978-0-12-800207-0.00006-X]
   Tang Anthony., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '12, P1569
   Ultsch A., 1990, PROC INT NEURAL NETW, P305
   Vesanto J., 2005, SOM TOOLBOX MATLAB 5
   Viana P, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0094-5
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Xiang Z, 2008, J TRAVEL RES, V47, P137, DOI 10.1177/0047287508321193
   Wei Y, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1553, DOI 10.1109/FSKD.2016.7603407
   Youtube, APIYOUTUBE DATA API
   YouTube, 8MLARGE SCALE LABELE
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
   Zhu XF, 2013, IEEE T MULTIMEDIA, V15, P633, DOI 10.1109/TMM.2012.2233723
NR 39
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2022
VL 11
IS 3
BP 431
EP 443
DI 10.1007/s13735-022-00238-5
EA MAY 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S5XP
UT WOS:000800968300001
PM 35646509
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hafiz, AM
   Parah, SA
   Bhat, RA
AF Hafiz, A. M.
   Parah, S. A.
   Bhat, R. A.
TI Reinforcement learning applied to machine vision: state of the art
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Reinforcement learning; Machine vision; Applications
ID POLICY; SEGMENTATION; NETWORKS; TRACKING; STRATEGY; MODEL
AB Reinforcement learning (RL) is gaining a foothold in artificial intelligence-based research academia. More and more applications are coming to fore where RL is being applied in a novel and successful manner. As the areas of application are diverse, one important area of industrial and research significance having a high scope is machine vision. In this survey paper, the basics of RL are discussed first in order to give the reader an overview of the technology. Subsequently, the important, novel and upcoming state-of-the-art applications are discussed in the field of RL. The research areas discussed include image segmentation, object detection, object tracking, robotic vision, autonomous driving and image classification/retrieval. Various state-of-the-art works are discussed and an impression of the potential and impact of RL in the field of machine vision is built.
C1 [Hafiz, A. M.; Bhat, R. A.] Univ Kashmir, Inst Technol, Srinagar 190006, J&k, India.
   [Parah, S. A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, J&k, India.
C3 University of Kashmir; University of Kashmir
RP Hafiz, AM (corresponding author), Univ Kashmir, Inst Technol, Srinagar 190006, J&k, India.
EM mueedhafiz@uok.edu.in
RI Hafiz, Abdul Mueed/AAF-3806-2020
OI Hafiz, Abdul Mueed/0000-0002-2266-3708
CR Akhloufi MA, 2019, DRONES-BASEL, V3, DOI 10.3390/drones3030058
   [Anonymous], 2017, ELECT IMAG, DOI [DOI 10.2352/ISSN.2470-1173.2017.19.AVM-023, 10.2352/ISSN.2470-1173.2017.19.AVM-023]
   [Anonymous], 2012, PROC INT C MACH LEAR
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Bhat, 2020, ARXIV PREPRINT ARXIV
   Bohg J, 2014, IEEE T ROBOT, V30, P289, DOI 10.1109/TRO.2013.2289018
   Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286
   Carta S, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113820
   Casanova Arantxa, 2020, ARXIV201204027
   Chavan-Dafle N, 2018, IEEE INT CONF ROBOT, P254
   Chen JY, 2019, IEEE INT C INTELL TR, P2765, DOI 10.1109/ITSC.2019.8917306
   Chen L, 2020, NEUROCOMPUTING, V383, P324, DOI 10.1016/j.neucom.2019.11.017
   Chen TS, 2018, AAAI CONF ARTIF INTE, P6730
   Christiano P., 2016, ARXIV161003518
   Czech J., 2021, REINFORCEMENT LEARNI, P151, DOI DOI 10.1007/978-3-030-41188-6_13
   Dan Zhang, 2018, Advances in Polymer Technology, V37, P1878, DOI 10.1002/adv.21846
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Ejaz MM, 2021, IEEE SENS J, V21, P2230, DOI 10.1109/JSEN.2020.3016299
   Fan J., 2020, LEARNING DYNAMICS CO, P486, DOI DOI 10.48550/ARXIV.1901.00137
   Gao MF, 2018, PROC CVPR IEEE, P6926, DOI 10.1109/CVPR.2018.00724
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Ghadirzadeh A, 2017, IEEE INT C INT ROBOT, P2351, DOI 10.1109/IROS.2017.8206046
   Gonzalez-Garcia A, 2015, PROC CVPR IEEE, P3022, DOI 10.1109/CVPR.2015.7298921
   Gözen D, 2021, INT C PATT RECOG, P10082, DOI 10.1109/ICPR48806.2021.9413316
   Guionneau, 2015, SIMULATION SOFTWARE
   GUPTA AK, 2017, ARXIV170503865
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hsu RC, 2015, INT J PHOTOENERGY, V2015, DOI 10.1155/2015/496401
   Hundt A, 2020, IEEE ROBOT AUTOM LET, V5, P6724, DOI 10.1109/LRA.2020.3015448
   Isele D, 2018, IEEE INT CONF ROBOT, P2034
   Jain SD, 2016, PROC CVPR IEEE, P2864, DOI 10.1109/CVPR.2016.313
   Jie ZQ, 2016, ADV NEUR IN, V29
   Kalakrishnan M, 2011, IEEE INT C INT ROBOT, P4639, DOI 10.1109/IROS.2011.6048825
   Kalashnikov D., 2018, CORL
   Karayev S, 2014, PROC CVPR IEEE, P572, DOI 10.1109/CVPR.2014.80
   Kelleher JD, 2019, MIT PRESS ESSENT, P1
   Keselman A., 2018, ARXIV PREPRINT ARXIV
   Kiran BR, 2022, IEEE T INTELL TRANSP, V23, P4909, DOI 10.1109/TITS.2021.3054625
   Konda VR, 2000, ADV NEUR IN, V12, P1008
   Konyushkova K, 2015, IEEE I CONF COMP VIS, P2974, DOI 10.1109/ICCV.2015.340
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuosku M, 2017, THESIS
   Li CJ, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P359
   Lin Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P399, DOI 10.1007/978-3-319-66179-7_46
   Liu W, 2021, IEEE ACCESS
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo WH, 2020, IEEE T PATTERN ANAL, V42, P1317, DOI 10.1109/TPAMI.2019.2899570
   Mackowiak R., 2018, BMVC
   Mahler J, 2018, IEEE INT CONF ROBOT, P5620
   Martens J, 2015, PR MACH LEARN RES, V37, P2408
   Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Morrison D, 2018, IEEE INT CONF ROBOT, P7757
   Mousavi H. K., 2019, ARXIV PREPRINT ARXIV
   Mousavi HK, 2019, IEEE INT C INT ROBOT, P5020, DOI [10.1109/iros40897.2019.8968129, 10.1109/IROS40897.2019.8968129]
   Ngai DCK, 2011, IEEE T INTELL TRANSP, V12, P509, DOI 10.1109/TITS.2011.2106158
   Nguyen TT, 2020, IEEE T CYBERNETICS, V50, P3826, DOI 10.1109/TCYB.2020.2977374
   Pan X., 2017, ARXIV PREPRINT ARXIV
   Park YJ, 2020, IEEE ACCESS, V8, P125389, DOI 10.1109/ACCESS.2020.3007219
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Pei Yang, 2019, 2019 IEEE 1st International Conference on Civil Aviation Safety and Information Technology (ICCASIT), P277, DOI 10.1109/ICCASIT48058.2019.8973189
   Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003
   Pirinen A, 2018, PROC CVPR IEEE, P6945, DOI 10.1109/CVPR.2018.00726
   Ranzato, 2004, CALTECH 101
   Rao Kanishka, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11154, DOI 10.1109/CVPR42600.2020.01117
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Rusu A. A., 2017, C ROBOT LEARNING, P262
   Ryu H, 2020, AAAI CONF ARTIF INTE, V34, P7236
   Sadeghi F, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII
   Sallab A.E., 2016, arXiv preprint arXiv:1612. 04340, V2, P1
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Settles B., 2008, P NIPS WORKSHOP COST, VVolume 1
   Singla A, 2021, IEEE T INTELL TRANSP, V22, P107, DOI 10.1109/TITS.2019.2954952
   Smith RL, 2019, IEEE NUCL SCI CONF R, DOI 10.1109/nss/mic42101.2019.9060031
   Sun CY, 2021, IEEE T NEUR NET LEAR, V32, P2054, DOI 10.1109/TNNLS.2020.2996209
   Sun SY, 2020, ADV ROBOTICS, V34, P888, DOI 10.1080/01691864.2020.1753569
   Supancic J, 2017, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2017.43
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tallamraju R, 2020, IEEE ROBOT AUTOM LET, V5, P6678, DOI 10.1109/LRA.2020.3013906
   ten Pas A, 2017, INT J ROBOT RES, V36, P1455, DOI 10.1177/0278364917735594
   Tobin Josh, 2017, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P23, DOI 10.1109/IROS.2017.8202133
   Tzeng E., 2020, Adapting Deep Visuomotor Representations with Weak Pairwise Constraints, VXII, P688, DOI DOI 10.1007/978-3-030-43089-4_44
   Uzkent B, 2020, IEEE WINT CONF APPL, P1813, DOI 10.1109/WACV45572.2020.9093447
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Vezhnevets A, 2012, PROC CVPR IEEE, P3162, DOI 10.1109/CVPR.2012.6248050
   Vijayanarasimhan S, 2009, PROC CVPR IEEE, P2262, DOI 10.1109/CVPRW.2009.5206705
   Wang P., 2017, 2017 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2017.8007930
   Wang P, 2018, IEEE INT VEH SYM, P1379, DOI 10.1109/IVS.2018.8500556
   Wang XZ, 2020, INT J MACH LEARN CYB, V11, P747, DOI 10.1007/s13042-020-01096-5
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P71, DOI 10.1007/978-3-540-69321-5_8
   Wu YH, 2017, ADV NEUR IN, V30
   Yahya A, 2017, IEEE INT C INT ROBOT, P79, DOI 10.1109/IROS.2017.8202141
   Yang D, 2019, LECT NOTES COMPUT SC, V11765, P3, DOI 10.1007/978-3-030-32245-8_1
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zeng A, 2018, IEEE INT C INT ROBOT, P4238, DOI 10.1109/IROS.2018.8593986
   Zhang HF, 2020, AAAI CONF ARTIF INTE, V34, P7325
   Zhang W, 2019, IEEE T AUTOM SCI ENG, V16, P1522, DOI 10.1109/TASE.2018.2877499
   Zhang Z, 2021, IEEE T NEUR NET LEAR, V32, P4639, DOI 10.1109/TNNLS.2020.3025711
   Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675
   Zhong Z, 2019, IEEE ACCESS, V7, P28069, DOI 10.1109/ACCESS.2019.2900476
NR 106
TC 6
Z9 6
U1 5
U2 44
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2021
VL 10
IS 2
SI SI
BP 71
EP 82
DI 10.1007/s13735-021-00209-2
EA MAY 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SK0DY
UT WOS:000646467400001
DA 2024-07-18
ER

PT J
AU Nguyen, V
   Ngo, TD
AF Vy Nguyen
   Thanh Duc Ngo
TI Single-image crowd counting: a comparative survey on deep learning-based
   approaches
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Crowd counting; Computer vision; Deep learning; Literature review
ID DENSITY
AB Crowd counting is an attracting computer vision problem. Solutions to crowd counting hold high adaptability to other counting problems such as traffic counting and cell counting. Numerous methods have been proposed for the problem. Deep learning-based methods play a significant role in recent advancement. However, no existing literature reviews capture their sophisticated development by challenges. In this paper, we discuss and categorize recent deep learning works in crowd counting by considering how they address the challenges.
C1 [Vy Nguyen; Thanh Duc Ngo] Univ Informat Technol, VNU HCM, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Ngo, TD (corresponding author), Univ Informat Technol, VNU HCM, Ho Chi Minh City, Vietnam.
EM vynt@uit.edu.vn; thanhnd@uit.edu.vn
FU Vietnam National University Ho Chi Minh City (VNU-HCM) [C2018-26-01]
FX This research is funded by Vietnam National University Ho Chi Minh City
   (VNU-HCM) under Grant No. C2018-26-01.
CR [Anonymous], 1997, Image Processing for Security Applications, DOI DOI 10.1049/IC:19970387
   [Anonymous], 2017, CVPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, ARXIV180700601
   [Anonymous], 2018, ARXIV180106642
   [Anonymous], 2019, 33 AAAI C ART INT
   [Anonymous], 2018, ARXIV180801050
   [Anonymous], 2009, Robust background model for pixel based people counting using a single uncalibrated camera, DOI DOI 10.1109/PETS-WINTER.2009.5399531
   [Anonymous], 2018, ARXIV180709959
   [Anonymous], 2005, P BRIT MACH VIS C
   [Anonymous], ARXIV170603686
   [Anonymous], ARXIV180303095
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], P AS C COMP VIS
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Cho SY, 1999, IEEE T SYST MAN CY B, V29, P535, DOI 10.1109/3477.775269
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Dong L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1011
   Ferryman J, 2014, PATTERN RECOGN LETT, V44, P3, DOI 10.1016/j.patrec.2014.01.005
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Hussain N, 2011, SAFETY SCI, V49, P824, DOI 10.1016/j.ssci.2011.01.005
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jia Hong Yin, 1996, Recent Developments in Computer Vision. Second Asian Conference on Computer Vision, ACCV '95. Invited Session Papers, P489
   Kong D, 2006, INT C PATT RECOG, P1187
   Kumagai S., 2017, arXiv preprint arXiv:1703.09393
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li M., 2008, 2008 19 INT C PATTER, P1, DOI DOI 10.1109/ICPR.2008.4761705
   Li XH, 2006, T I MEAS CONTROL, V28, P299, DOI 10.1191/0142331206tim178oa
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Ma RH, 2004, 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2, P170
   Ma WH, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL I, PROCEEDINGS, P142, DOI 10.1109/IITA.2008.303
   Marana AN, 1999, INT CONF ACOUST SPEE, P3521, DOI 10.1109/ICASSP.1999.757602
   Marana AN, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P354, DOI 10.1109/SIBGRA.1998.722773
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Rahmalan H., 2006, Institution of Engineering and Technology Conference on Crime and Security, P540
   REGAZZONI CS, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1860, DOI 10.1109/IECON.1993.339357
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sam DB, 2018, AAAI CONF ARTIF INTE, P7323
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Simonyan K., 2014, 14091556 ARXIV
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Watson Ray., 2011, SIGNIFICANCE, V8, P104, DOI DOI 10.1111/J.1740-9713.2011.00502.X
   Wenhua Ma, 2010, Proceedings of the 5th International Conference on Computer Sciences and Convergence Information Technology (ICCIT 2010), P170, DOI 10.1109/ICCIT.2010.5711051
   Wenhua Ma, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P958, DOI 10.1109/PACIIA.2008.258
   Wu XY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P214, DOI 10.1109/ROBIO.2006.340379
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
   Zitouni MS, 2016, NEUROCOMPUTING, V186, P139, DOI 10.1016/j.neucom.2015.12.070
NR 68
TC 14
Z9 16
U1 1
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2020
VL 9
IS 2
SI SI
BP 63
EP 80
DI 10.1007/s13735-019-00181-y
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ML2MC
UT WOS:000549305600001
DA 2024-07-18
ER

PT J
AU Li, HZ
   Ellis, JG
   Zhang, L
   Chang, SF
AF Li, Hongzhi
   Ellis, Joseph G.
   Zhang, Lei
   Chang, Shih-Fu
TI Automatic visual pattern mining from categorical image dataset
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
AB We study in this paper the problem of visual pattern mining, which is to identify visually distinctive and semantically meaningful regions in images for solving various visual recognition tasks. Toward this goal, we propose a novel deep neural network architecture called PatternNet for discovering visual patterns that are both discriminative and representative. The proposed PatternNet leverages the filters in the last convolution layer of a convolutional neural network to find locally consistent visual patches, and by combining these filters we can effectively discover unique visual patterns. In addition, PatternNet can discover visual patterns efficiently without performing expensive image patch sampling, and this advantage provides an order of magnitude speedup compared to most other approaches. We evaluate the proposed PatternNet subjectively by showing randomly selected visual patterns which are discovered by our method and quantitatively by performing image classification with the identified visual patterns and comparing our performance with the current state-of-the-art. We also directly evaluate the quality of the discovered visual patterns by leveraging the identified patterns as proposed objects in an image and compare with other relevant methods.
C1 [Li, Hongzhi; Zhang, Lei] Microsoft Res, Redmond, WA 98052 USA.
   [Ellis, Joseph G.; Chang, Shih-Fu] Columbia Univ, New York, NY 10027 USA.
C3 Microsoft; Columbia University
RP Li, HZ (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM hongzhi.li@microsoft.com; jge2105@columbia.edu; leizhang@microsoft.com;
   sfchang@ee.columbia.edu
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2014, ATTENTION FINE GRAIN
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2010, P NIPS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, ARXIV14126598
   [Anonymous], 2013, NIPS
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Chen G, 2015, IEEE WINT CONF APPL, P860, DOI 10.1109/WACV.2015.119
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215
   Gavves E, 2015, INT J COMPUT VISION, V111, P191, DOI 10.1007/s11263-014-0741-5
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115
   Li Y, 2015, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2015.7298699
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Pu J, 2014, LECT NOTES COMPUT SC, V8691, P425, DOI 10.1007/978-3-319-10578-9_28
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Simonyan K., 2014, 14091556 ARXIV
   Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6
   Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang W, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P297, DOI 10.1145/2647868.2654942
   Zheng Shou, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11220), P162, DOI 10.1007/978-3-030-01270-0_10
NR 36
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2019
VL 8
IS 1
SI SI
BP 35
EP 45
DI 10.1007/s13735-018-0163-1
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HT8ZD
UT WOS:000464853000004
DA 2024-07-18
ER

PT J
AU Tufchi, S
   Yadav, A
   Ahmed, T
AF Tufchi, Shivani
   Yadav, Ashima
   Ahmed, Tanveer
TI A comprehensive survey of multimodal fake news detection techniques:
   advances, challenges, and opportunities
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Fake news; Fact-checking; Deep learning; Handmade features; Adversarial
   networks; Attention mechanism
ID NETWORK
AB The escalating prevalence of disinformation, or "fake news," on social media platforms represents a growing societal concern with far-reaching implications. Its ubiquitous presence across platforms such as Facebook, Twitter, and Instagram exacerbates the criticality of this issue. Consequently, the development of efficacious counter strategies-such as fact-checking mechanisms and media literacy initiatives-is paramount. This domain of crafting robust defensive strategies against disinformation has burgeoned into an expansive field of investigation, with primary emphasis on the identification and categorization of fake news within the digital media landscape. This study offers a comprehensive survey of the contemporary research landscape on disinformation, or "fake news," detection, and mitigation strategies. We meticulously analyze the life cycle of disinformation-from inception and propagation to detection-shedding light on both supervised and unsupervised learning techniques such as generative adversarial networks (GANs). The paper provides a comparative analysis of different classification models across a variety of text- and image-based datasets related to fake news. Furthermore, it provides an in-depth discussion of the key evaluation metrics used in assessing the accuracy of news authenticity. Challenges have been put forth concerning the sophisticated task of precisely detecting fake news, an undertaking obscured by its subtle and often deceptive aspects. By offering in-depth insights into the phenomenon of fake news and potential counterstrategies, this survey is anticipated to enrich scholarly understanding, thereby catalyzing the development of innovative solutions to tackle this persistent global issue.
C1 [Tufchi, Shivani; Yadav, Ashima; Ahmed, Tanveer] Bennett Univ, Comp Sci, Greater Noida 201310, UP, India.
RP Tufchi, S (corresponding author), Bennett Univ, Comp Sci, Greater Noida 201310, UP, India.
EM e21soep0017@bennett.edu.in; ashima.yadav@bennett.edu.in;
   tanveer.ahmed@bennett.edu.in
CR Agarwal A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1178, DOI [10.1109/ICICCS48265.2020.9121030, 10.1109/iciccs48265.2020.9121030]
   Agarwala V, 2019, PROCEDIA COMPUT SCI, V165, P377, DOI 10.1016/j.procs.2020.01.035
   Ahmadi K., 2021, J COMMUN ENG, V11, P55
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Ahmed S., 2022, arXiv
   Ahmed SR, 2022, 2022 INT C HUMAN COM, P1
   Al-Asadi MA., 2022, Combating Fake News with Computational Intelligence Techniques, P39, DOI [10.1007/978-3-030-90087-8_2, DOI 10.1007/978-3-030-90087-8_2]
   Alghamdi J, 2022, INFORMATION, V13, DOI 10.3390/info13120576
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Althabiti S, 2022, WORKING NOTES CLEF
   Alzaidi MS, 2022, WIREL COMMUN MOBILE
   Atri D, 2019, Arxiv, DOI arXiv:1910.09871
   Bagade A, 2020, ACM INT CONF PR SER, P302, DOI 10.1145/3371158.3371402
   Bang YO, 2021, arXiv
   Botnevik B, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2117, DOI 10.1145/3397271.3401396
   Brasoveanu AMP, 2021, NEURAL PROCESS LETT, V53, P3055, DOI 10.1007/s11063-020-10365-x
   Brookes S, 2023, JOURNALISM, V24, P1938, DOI 10.1177/14648849221078465
   Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40
   Buonomo B, 2020, RIC MAT, V69, P483, DOI 10.1007/s11587-020-00506-8
   Campan A, 2017, IEEE INT CONF BIG DA, P4453, DOI 10.1109/BigData.2017.8258484
   Chaffey BD, 2022, SMARTINSIGHTS
   Chatterjee M, 2019, RISE DIGITAL HUMAN, V14, P2022
   Chaudhary L, 2022, COMP ANAL SUPERVISED
   Chen M.-Y., 2022, ACM T INTERNET TECHN
   Chen YX, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2897, DOI 10.1145/3485447.3511968
   Choi H, 2022, PATTERN RECOGN LETT, V154, P44, DOI 10.1016/j.patrec.2022.01.007
   Choudhary A, 2021, 2021 7 INT C SIGN PR, P182
   Das M., 2022, CAUSES SYMPTOMS SOCI, P73
   Davoudi M, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116635
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhawan A, 2022, COMPUT COMMUN, V185, P130, DOI 10.1016/j.comcom.2022.01.003
   Draws Tim, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2114, DOI 10.1145/3531146.3534629
   Duc Tuan N. M., 2021, 2021 RIVF INT C COMP
   Felber T, 2021, Arxiv, DOI arXiv:2101.03717
   Garg Sonal, 2020, Proceedings of the 2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), P17, DOI 10.1109/SMART50582.2020.9337152
   Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray J, 2020, NEW MEDIA SOC, V22, P317, DOI 10.1177/1461444819856912
   Guo ZJ, 2022, T ASSOC COMPUT LING, V10, P178, DOI 10.1162/tacl_a_00454
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Han Y, 2020, Arxiv, DOI arXiv:2007.03316
   Harrag FZ, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3501401
   He N., 2021, arXiv, DOI DOI 10.48550/ARXIV.2105.14376
   Horne BD, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3363818
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Ibrishimova MD, 2020, ADV INTELL SYST, V1035, P223, DOI 10.1007/978-3-030-29035-1_22
   Islam MR, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00696-x
   Jain DK, 2022, NEURAL COMPUT APPL, V34, P15129, DOI 10.1007/s00521-021-06743-8
   Jain V, 2022, NEURAL COMPUT APPL, V34, P771, DOI 10.1007/s00521-021-06450-4
   Jaiswal A.K., 2019, P 2 INT C ADV COMPUT
   Jeon H, 2020, IFIP INT C ICT SYST, V580, P416, DOI 10.1007/978-3-030-58201-2_28
   Jiang T, 2021, IEEE ACCESS, V9, P22626, DOI 10.1109/ACCESS.2021.3056079
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jindal S., 2020, CEUR WORKSH P, V2560, P138
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), P439, DOI 10.1145/3430984.3431070
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kaliyar RK, 2019, INT CONF ADV COMPU, P103, DOI [10.1109/IACC48062.2019.8971579, 10.1109/iacc48062.2019.8971579]
   Kalsnes Bente., 2018, OXFORD RES ENCY COMM
   Kazemi A., 2021, arXiv
   Khan T, 2021, J NETW COMPUT APPL, V190, DOI 10.1016/j.jnca.2021.103112
   Khanam Z., 2021, IOP Conference Series: Materials Science and Engineering, V1099, DOI 10.1088/1757-899X/1099/1/012040
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kim S, 2022, arXiv
   Koloski B, 2022, NEUROCOMPUTING, V496, P208, DOI 10.1016/j.neucom.2022.01.096
   Kumar A, 2022, SOFT COMPUT, P1
   Kumar N, 2021, 2021 INT C COMP COMM, P1
   Kumari R, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115412
   Lahby M., 2022, Combating Fake News with Computational Intelligence Techniques, P3
   Lampridis O, 2022, COMPUTING, V104, P717, DOI 10.1007/s00607-021-01013-w
   Li PG, 2021, IEEE T MULTIMEDIA, V24, P3455, DOI 10.1109/TMM.2021.3098988
   Liu LS, 2021, Arxiv, DOI arXiv:2109.04559
   Ma K, 2022, Appl. Intell., P1
   Mahfoudi G, 2019, EUR SIGNAL PR CONF
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mengoni P, 2022, LECT NOTES COMPUT SC, V13377, P138, DOI 10.1007/978-3-031-10536-4_10
   Mishra S, 2022, P 1 WORKSHOP MULTIMO
   Mishra S, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1575365
   Monti F, 2019, Arxiv, DOI arXiv:1902.06673
   Mridha MF, 2021, IEEE ACCESS, V9, P156151, DOI 10.1109/ACCESS.2021.3129329
   Nakamura K, 2020, Arxiv, DOI arXiv:1911.03854
   Nakov P, 2022, LECT NOTES COMPUT SC, V13390, P495, DOI 10.1007/978-3-031-13643-6_29
   Nakov P, 2022, LECT NOTES COMPUT SC, V13186, P416, DOI 10.1007/978-3-030-99739-7_52
   Nezami OM, 2019, LECT NOTES ARTIF INT, V11051, P226, DOI 10.1007/978-3-030-10925-7_14
   Nielsen DS, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3141, DOI 10.1145/3477495.3531744
   Nithya SH, 2022, J INF KNOWL MANAG, V21, DOI 10.1142/S0219649222500368
   Oshikawa R, 2020, Arxiv, DOI arXiv:1811.00770
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Pankovska E, 2022, P WORKSHOP REDUCING
   Parekh Z, 2021, Arxiv, DOI arXiv:2004.15020
   Pathak A, 2022, INTEGRATED APPROACH
   Pavleska T., 2018, Social Media Convergence, V29, P1
   Pennycook G, 2021, TRENDS COGN SCI, V25, P388, DOI 10.1016/j.tics.2021.02.007
   Piazza James A., 2022, DYNAMICS ASYMMETRIC, V15, P55, DOI [DOI 10.1080/17467586.2021.1895263, 10.1080/17467586.2021.1895263]
   Pritzkau A, 2022, WORKING NOTES CLEF
   Probierz B, 2021, INT C COMP COLL INT, P387
   Qazi M, 2020, 2020 3 INT C COMPUTI, P1, DOI [10.1109/iCoMET48670.2020.9074071, DOI 10.1109/ICOMET48670.2020.9074071]
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Qian SS, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P153, DOI 10.1145/3404835.3462871
   Qian SS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451215
   Raj C, 2021, APPL INTELL, V51, P8132, DOI 10.1007/s10489-021-02345-y
   Ramya S, 2022, P INT C COMP INT, P113
   Ramya S. P., 2021, International Journal of Cognitive Informatics and Natural Intelligence, P1, DOI 10.4018/IJCINI.295809
   Rana MS, 2022, IEEE ACCESS, V10, P25494, DOI 10.1109/ACCESS.2022.3154404
   Rashkin Hannah, 2017, P C EMP METH NAT LAN, P2931
   Rastogi S, 2023, INT J INF SECUR, V22, P177, DOI 10.1007/s10207-022-00625-3
   Raza S, 2022, INT J DATA SCI ANAL, V13, P335, DOI 10.1007/s41060-021-00302-z
   Riedel B, 2018, Arxiv, DOI arXiv:1707.03264
   Rohera D, 2022, IEEE ACCESS, V10, P30367, DOI 10.1109/ACCESS.2022.3159651
   Sá N, 2021, Arxiv, DOI arXiv:2004.14420
   Sagnika S, 2021, NEURAL COMPUT APPL, V33, P17425, DOI 10.1007/s00521-021-06328-5
   Saji R, 2021, 2021 12 INT C COMP C, P1
   Santia G.C., 2018, P 12 INT AAAI C WEB, P531
   Schoenmueller V, 2023, Arxiv, DOI arXiv:2203.10560
   Segura-Bedmar I, 2022, INFORMATION, V13, DOI 10.3390/info13060284
   Seow JW, 2022, NEUROCOMPUTING, V513, P351, DOI 10.1016/j.neucom.2022.09.135
   Shahid W, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3177359
   Shao Y, 2022, 1ST ACM INTERNATIONAL WORKSHOP ON MULTIMEDIA AI AGAINST DISINFORMATION, MAD 2022, P78, DOI 10.1145/3512732.3533583
   Sharma DK, 2023, COMPLEX INTELL SYST, V9, P2843, DOI 10.1007/s40747-021-00552-1
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Sharma U, 2020, International Journal of Creative Research Thoughts (IJCRT), V8, P509
   Shrivastava G, 2020, IEEE T COMPUT SOC SY, V7, P1159, DOI 10.1109/TCSS.2020.3014135
   Shrivastava S, 2022, SMART SYSTEMS INNOVA, P273
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Silva A, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102618
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2022, NEURAL COMPUT APPL, V34, P21503, DOI 10.1007/s00521-021-06086-4
   Singh P, 2022, Arxiv, DOI arXiv:2205.08159
   Singh VK, 2021, J ASSOC INF SCI TECH, V72, P3, DOI 10.1002/asi.24359
   Singhal S, 2022, P INT AAAI C WEB SOC, V16, P1322
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Skinnell R, 2021, COLL COMPOS COMMUN, V72, P546
   Soni B, 2019, J INF SECUR APPL, V45, P44, DOI 10.1016/j.jisa.2019.01.007
   Sorour S.E., 2022, J. Theor. Appl. Inf. Technol., V100, P5072
   Sudhakar M, 2023, INFORM COMMUNICATION, P1
   Tariq S, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P1296, DOI 10.1145/3297280.3297410
   Tian L, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P79, DOI 10.1145/3366424.3382706
   Tiwary T, 2023, MULTIMED TOOLS APPL, V82, P3801, DOI 10.1007/s11042-022-13443-5
   Tyagi S, 2023, EVOL SYST-GER, V14, P545, DOI 10.1007/s12530-022-09446-0
   Vargo CJ, 2018, NEW MEDIA SOC, V20, P2028, DOI 10.1177/1461444817712086
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma Pawan Kumar, 2022, Applications of Artificial Intelligence and Machine Learning: Select Proceedings of ICAAAIML 2021. Lecture Notes in Electrical Engineering (925), P557, DOI 10.1007/978-981-19-4831-2_45
   Vijjali R, 2020, Arxiv, DOI arXiv:2011.13253
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Wagener A., 2020, Postdigital Science and Education, V2, P147, DOI DOI 10.1007/S42438-019-00066-7
   Wang JZ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031093
   Wang JW, 2022, MULTIMED TOOLS APPL, V81, P42527, DOI 10.1007/s11042-021-11592-7
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wei PF, 2022, IEEE SIGNAL PROC LET, V29, P1382, DOI 10.1109/LSP.2022.3181893
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
   Wright D., 2022, arXiv
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Xiao S, 2022, DIGIT COMMUN NETW, V8, P877, DOI 10.1016/j.dcan.2022.07.010
   Xu P, 2022, MULTIMED TOOLS APPL, V81, P13799, DOI 10.1007/s11042-022-12290-8
   Xue JX, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102610
   Yang CR, 2022, EUR CON SFTWR MTNCE, P385, DOI 10.1109/SANER53432.2022.00054
   Wang WY, 2017, Arxiv, DOI arXiv:1705.00648
   Yang Z., 2022, arXiv
   Ying L, 2021, IEEE ACCESS, V9, P132818, DOI 10.1109/ACCESS.2021.3113981
   Ying L, 2021, IEEE ACCESS, V9, P132363, DOI 10.1109/ACCESS.2021.3114093
   Yu C, 2022, PATTERN RECOGN LETT, V153, P92, DOI 10.1016/j.patrec.2021.11.026
   Zhang HW, 2022, IEEE T MULTIMEDIA, V24, P1449, DOI 10.1109/TMM.2021.3065498
   Zhang T, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206973
   Zhou KM, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1614
   Zhou XY, 2020, Arxiv, DOI arXiv:2003.04981
   Zhou XY, 2020, Arxiv, DOI [arXiv:1812.00315, DOI 10.1145/3395046, DOI 10.48550/ARXIV.1812.00315]
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 172
TC 1
Z9 1
U1 12
U2 32
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 28
DI 10.1007/s13735-023-00296-3
PG 27
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P9KN6
UT WOS:001053793800001
DA 2024-07-18
ER

PT J
AU Wang, YD
   Hu, ZF
   Ji, Z
AF Wang, Yaodong
   Hu, Zhenfei
   Ji, Zhong
TI Attribute-wise reasoning reinforcement learning for pedestrian attribute
   retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Pedestrian attribute retrieval; Reinforcement learning; Intelligent
   surveillance
ID ATTENTION NETWORK; FOCAL LOSS; RECOGNITION; MODEL
AB Pedestrian attribute retrieval (PAR) aims at retrieving soft-biometric attributes of pedestrian images from video surveillance. Despite advancements, PAR grapples with challenges, notably the concern of attribute imbalanced distribution. Within this context, we highlight a critical observation: this challenge encompasses both inter-attribute and overlooked intra-attribute imbalanced data distribution. To address the overlooked intra-attribute imbalance problem, we introduce an attribute-wise reasoning reinforcement learning framework (AwRL). AwRL formulates PAR as a Markov decision process (MDP), orchestrating attribute retrieval individually within reinforcement learning episodes. By traversing the entire PAR dataset, each attribute retrieval is calibrated with distinct reward scales, thereby ameliorating the intra-attribute imbalance. Additionally, we develop a novel supervised reinforcement loss function (SR-Loss) to enhance the robustness of the retrieval model. SR-Loss mitigates reinforcement learning's inherent training instability in the trial-and-error interactions with the environment. The experimental results on three benchmark datasets of PETA, RAP and PA100K demonstrate the effectiveness of our approach, underscoring its capacity to surmount the intra-attribute imbalanced problem.
C1 [Wang, Yaodong; Hu, Zhenfei; Ji, Zhong] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Ji, Z (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM wangyaodong@tju.edu.cn; hzf0226@tju.edu.cn; jizhong@tju.edu.cn
FU This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grant 62176178 and the Natural Science Foundation of
   Tianjin under Grant 19JCYBJC16000. [62176178]; National Natural Science
   Foundation of China (NSFC) [19JCYBJC16000]; Natural Science Foundation
   of Tianjin
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grant 62176178 and the Natural Science Foundation of
   Tianjin under Grant 19JCYBJC16000.
CR An HR, 2021, IEEE T MULTIMEDIA, V23, P268, DOI 10.1109/TMM.2020.2975417
   [Anonymous], 2018, ARXIV180809102
   Chen WC, 2022, MACH INTELL RES, V19, P153, DOI 10.1007/s11633-022-1321-8
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Duong CN, 2019, PROC CVPR IEEE, P10005, DOI 10.1109/CVPR.2019.01025
   Guo H, 2022, INT J COMPUT VISION, V130, P1088, DOI 10.1007/s11263-022-01591-y
   Hafiz AM, 2021, INT J MULTIMED INF R, V10, P71, DOI 10.1007/s13735-021-00209-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ji Z, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104585
   Ji Z, 2020, PATTERN RECOGN LETT, V138, P170, DOI 10.1016/j.patrec.2020.07.018
   Ji Z, 2019, PATTERN RECOGN LETT, V120, P89, DOI 10.1016/j.patrec.2019.01.010
   Ji Z, 2017, IEEE IMAGE PROC, P151, DOI 10.1109/ICIP.2017.8296261
   Joulin A, 2016, Arxiv, DOI [arXiv:1607.01759, DOI 10.48550/ARXIV.1607.01759]
   Le N, 2022, ARTIF INTELL REV, V55, P2733, DOI 10.1007/s10462-021-10061-9
   Li D, 2018, IEEE INT C MULT EXP, P1
   Li DW, 2016, Arxiv, DOI arXiv:1603.07054
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Li Y, 2020, IEEE ACCESS, V8, P164570, DOI 10.1109/ACCESS.2020.3010435
   Liu F, 2017, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2017.443
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu ZY, 2022, PATTERN RECOGN LETT, V163, P112, DOI 10.1016/j.patrec.2022.10.003
   Lv Jiping, 2022, BIC 2022: 2022 2nd International Conference on Bioinformatics and Intelligent Computing, P421, DOI 10.1145/3523286.3524581
   Miaomiao Lou, 2019, Artificial Intelligence and Security. 5th International Conference, ICAIS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11632), P217, DOI 10.1007/978-3-030-24274-9_19
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Murthy CB, 2021, INT J MULTIMED INF R, V10, P171, DOI 10.1007/s13735-021-00212-7
   Nafea O, 2022, INT J MULTIMED INF R, V11, P135, DOI 10.1007/s13735-022-00234-9
   Panigrahi S, 2022, INT J MULTIMED INF R, V11, P409, DOI 10.1007/s13735-022-00239-4
   Patrikar DR, 2022, INT J MULTIMED INF R, V11, P85, DOI 10.1007/s13735-022-00227-8
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saremi M, 2021, INT J MULTIMED INF R, V10, P219, DOI 10.1007/s13735-021-00216-3
   Sarfraz M., 2017, BRIT MACH VIS C
   Sathish PK, 2018, INT J MULTIMED INF R, V7, P221, DOI 10.1007/s13735-018-0153-3
   Siadari TS, 2019, IEEE INT CONF COMP V, P1098, DOI 10.1109/ICCVW.2019.00140
   Sudowe P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P329, DOI 10.1109/ICCVW.2015.51
   Tan ZC, 2019, IEEE T IMAGE PROCESS, V28, P6126, DOI 10.1109/TIP.2019.2919199
   Tang CF, 2019, IEEE I CONF COMP VIS, P4996, DOI 10.1109/ICCV.2019.00510
   Teng Z, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107188
   Tianrui Liu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P483, DOI 10.1007/978-3-030-59716-0_46
   Wang CH, 2021, INT C PATT RECOG, P4276, DOI 10.1109/ICPR48806.2021.9412947
   Wang JY, 2017, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2017.65
   Wu JY, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108865
   Wu MD, 2020, AAAI CONF ARTIF INTE, V34, P12394
   Yang Y, 2021, INT J COMPUT VISION, V129, P2731, DOI 10.1007/s11263-021-01499-z
   Zeng HT, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102757
   Zhang JJ, 2020, Arxiv, DOI arXiv:2011.06798
   Zhao RJ, 2022, MULTIMEDIA SYST, V28, P1069, DOI 10.1007/s00530-022-00893-y
   Zhao Y, 2022, Signal Image Video Process, P1
   Zheng XQ, 2021, INT C PATT RECOG, P7349, DOI 10.1109/ICPR48806.2021.9411959
   Zhou M, 2021, NEUROCOMPUTING, V443, P369, DOI 10.1016/j.neucom.2021.02.073
   Zhou Y, 2017, BRIT MACH VIS C, P1
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
NR 53
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 35
DI 10.1007/s13735-023-00300-w
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA W0RZ3
UT WOS:001088802200001
DA 2024-07-18
ER

PT J
AU Yan, J
   Xie, YX
   Guo, YM
   Wei, YM
   Zhang, XP
   Luan, XD
AF Yan, Jie
   Xie, Yuxiang
   Guo, Yanming
   Wei, Yingmei
   Zhang, Xiaoping
   Luan, Xidao
TI CoCoOpter: Pre-train, prompt, and fine-tune the vision-language model
   for few-shot image classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Few-shot image classification; Contrastive vision-language pre-training;
   Prompt tuning; Multi-modal
ID NETWORK
AB Few-shot image classification aims at learning to generalize to unseen new categories from a few training samples. Transfer learning is one prominent approach to the task, which first learns a backbone from the base classes and then trains a classifier on new classes with the prior learned knowledge. Typically, the convolutional neural network (CNN) is the preferred backbone. However, when the samples are limited, the representation ability of the feature extracted by CNN will decrease, thus leading to the performance degradation of few-shot image classification. Recently, the pre-trained large-scale vision-language model like CLIP has shown non-trivial potential, which can be used as a backbone for zero or few-shot transfer on a series of downstream tasks with the prompt. To fully explore the few-shot image classification performance of vision-language models, we propose CoCoOpter, a novel "pre-training + prompt tuning + fine-tuning" paradigm based on CLIP. CoCoOpter alleviates the overfitting and ensures generalizability in unseen new categories. Specifically, it learns an input-specific neural network to relieve overfitting by drawing attention away from a specific category to each specific input sample. Then, to establish connection between the visual and textual signals, it introduces the previously learned visual representations to perform automatic prompt tuning in the middle of the pre-trained CLIP, enabling learning input-specified prompt vectors. Moreover, two learnable lightweight neural networks are added at the end of CLIP to guide information propagation between different classes by fine-tuning both the visual and textual features. We perform extensive experiments on 11 image classification datasets. The results show that CoCoOpter is more generalizable in unseen classes and achieves superior few-shot classification performance with a straightforward design.
C1 [Yan, Jie; Xie, Yuxiang; Guo, Yanming; Wei, Yingmei] Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Peoples R China.
   [Zhang, Xiaoping] Toronto Metropolitan Univ, Ryerson Univ, Finance Dept, Dept Elect Comp & Biomed Engn,Ted Rogers Sch Manag, Toronto, ON, Canada.
   [Luan, Xidao] Changsha Univ, Coll Comp Engn & Appl Math, Changsha 410000, Peoples R China.
C3 National University of Defense Technology - China; Toronto Metropolitan
   University; Changsha University
RP Wei, YM (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410000, Peoples R China.
EM yjierrr@163.com; xyx89@163.com; guoyanming@nudt.edu.cn;
   weiyingmei@nudt.edu.cn; xzhang@ee.ryerson.ca; xidaoluan@ccsu.cn
RI Jia, Li/JVN-3095-2024; Zhang, Xiaoping/AAX-7947-2021; Zhang,
   Xiaoping/AFW-5367-2022; yuan, lin/JDW-7387-2023; Zhang, Xiao-Ping
   (Steven)/B-1436-2016
OI Zhang, Xiaoping/0000-0002-8891-0978; Zhang,
   Xiaoping/0000-0002-8891-0978; Zhang, Xiao-Ping
   (Steven)/0000-0001-5241-0069
FU This work was partially supported by the National Natural Science
   Foundation of China No. 61806218, the National Key Research and
   Development Program of China No. 2021YFB3100800, and the Ministry of
   Science and Technology of China No. 2020AAA0108800. [2021YFB3100800];
   National Natural Science Foundation of China [2020AAA0108800]; National
   Key Research and Development Program of China; Ministry of Science and
   Technology of China;  [61806218]
FX This work was partially supported by the National Natural Science
   Foundation of China No. 61806218, the National Key Research and
   Development Program of China No. 2021YFB3100800, and the Ministry of
   Science and Technology of China No. 2020AAA0108800.
CR Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3458, DOI 10.1109/ICCV48922.2021.00346
   Bertinetto L., 2016, Advances in neural information processing systems, P523
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen MT, 2020, AAAI CONF ARTIF INTE, V34, P10559
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen W.-Y., 2019, P INT C LEARNING REP
   Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2778, DOI 10.1145/3485447.3511998
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A., INT C LEARN REPRESEN, P1
   Finn C, 2017, PR MACH LEARN RES, V70
   Gao P., 2021, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Jia C, 2021, PR MACH LEARN RES, V139
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lee Y, 2018, PR MACH LEARN RES, V80
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li M, 2022, CVPR, P19880
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li XX, 2021, IEEE T IMAGE PROCESS, V30, P1318, DOI 10.1109/TIP.2020.3043128
   Lifchitz Y, 2019, PROC CVPR IEEE, P9250, DOI 10.1109/CVPR.2019.00948
   Lin CC, 2021, IEEE T IMAGE PROCESS, V30, P9245, DOI 10.1109/TIP.2021.3124322
   Lin CC, 2019, IEEE IMAGE PROC, P3302, DOI [10.1109/icip.2019.8803420, 10.1109/ICIP.2019.8803420]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Pei YT, 2021, IEEE T CIRC SYST VID, V31, P2231, DOI 10.1109/TCSVT.2020.3016863
   Qi H, 2018, PROC CVPR IEEE, P5822, DOI 10.1109/CVPR.2018.00610
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford A, 2021, PR MACH LEARN RES, V139
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rao YM, 2022, PROC CVPR IEEE, P18061, DOI 10.1109/CVPR52688.2022.01755
   Ravi S., 2016, INT C LEARNING REPRE
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WH, 2022, Arxiv, DOI arXiv:2208.10442
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3500, DOI 10.1109/ICCV48922.2021.00350
   Yaoyao Liu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P404, DOI 10.1007/978-3-030-58517-4_24
   Yin CX, 2022, IEEE T MULTIMEDIA, V24, P4183, DOI 10.1109/TMM.2021.3114541
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Zeng YW, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2003, DOI 10.1145/3477495.3531795
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zhao TZ, 2021, PR MACH LEARN RES, V139
   Zhou K, 2022, P IEEECVF C COMPUTER, P16816
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
   Zhou L, 2021, IEEE T MULTIMEDIA, V23, P1035, DOI 10.1109/TMM.2020.2991592
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu YH, 2021, IEEE T MULTIMEDIA, V23, P1200, DOI 10.1109/TMM.2020.2993952
NR 60
TC 0
Z9 0
U1 15
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 27
DI 10.1007/s13735-023-00286-5
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P9KN6
UT WOS:001053793800002
DA 2024-07-18
ER

PT J
AU Fathollahi, MS
   Razzazi, F
AF Sheikh Fathollahi, Mohamadreza
   Razzazi, Farbod
TI Music similarity measurement and recommendation system using
   convolutional neural networks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Music similarity system; Music recommendation system; Music genre
   classification; Convolutional neural network
AB Due to the massive and growing volume of music on the internet, and the lack of proper management on this massive volume, similarity and music recommendation systems have been designed. The music similarity system, which is the basis of the recommendation system, can automatically generate a user's playlist according to the similar features of each piece of music. In this paper, we designed a desirable music genre classification using convolutional neural network for extracting high-level features from intermediate networks layers. For similarity measurement, we considered cosine similarity and Euclidean distances between feature vectors. We applied this automatic recommendation system on three databases with different genres and showed that the recommender achieves significant accuracy in 10-Best results.
C1 [Sheikh Fathollahi, Mohamadreza; Razzazi, Farbod] Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University
RP Razzazi, F (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
EM Razzazi@srbiau.ac.ir
RI Razzazi, Farbod/AAO-8522-2021
OI Razzazi, Farbod/0000-0003-4970-8117
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2014, ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing-Proceedings
   [Anonymous], 2013, INT J DATA MIN KNOWL, DOI DOI 10.5121/IJDKP.2013.3107
   [Anonymous], 2012, COMPUTING RES REPOSI
   Bello J. P., 2005, P 6 INT C MUSIC INFO, P304, DOI 10.5281/zenodo.1417431
   Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7
   Bian WH, 2019, LECT NOTES ARTIF INT, V11672, P56, DOI 10.1007/978-3-030-29894-4_5
   Bogdanov Dmitry., 2011, 12th International Society for Music Information Retrieval Conference, number ISMIR 2011, P97
   Choi K, 2017, 18 INT SOC MUS INF R, P120
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Fessahaye F., 2019, P 2019 IEEE INT C CO, P1
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Homburg Helge., 2005, ISMIR, P528
   Huang A, 2008, P NZ COMP SCI NZCSRS, P135
   Humphrey EJ, 2013, J INTELL INF SYST, V41, P461, DOI 10.1007/s10844-013-0248-5
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Kingma D, 2015, INT C LEARN REPR ICL, P232
   Li TLH, 2010, LECT NOTES ENG COMP, P546
   Liu CJ, 2014, PATTERN RECOGN, V47, P359, DOI 10.1016/j.patcog.2013.06.023
   Oramas S., 2018, T INT SOC MUSIC INFO, V1, P4, DOI DOI 10.5334/TISMIR.10
   Qian G, 2004, P ACM S APPL COMP, P340
   Senac C, 2017, P 15 INT WORKSH CONT, P119
   Song Y, 2012, 9 INT S COMP MUS MOD, P112
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Sturm BL, 2014, J NEW MUSIC RES, V43, P147, DOI 10.1080/09298215.2014.894533
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G, 2008, P INT MOB INF SYST, P101
   Uitdenbogerd A, 2002, ISMIR 2002, P204
   Van den Oord A., 2013, P NIPS
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940
   Yang H, 2019, P ANN C INT SPEECH C, P450
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhang PJ, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P379, DOI 10.1145/2671188.2749367
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
NR 36
TC 27
Z9 28
U1 3
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2021
VL 10
IS 1
BP 43
EP 53
DI 10.1007/s13735-021-00206-5
EA MAR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QV8OQ
UT WOS:000625468800001
DA 2024-07-18
ER

PT J
AU Otto, C
   Springstein, M
   Anand, A
   Ewerth, R
AF Otto, Christian
   Springstein, Matthias
   Anand, Avishek
   Ewerth, Ralph
TI Characterization and classification of semantic image-text relations
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image-text class; Multimodality; Data augmentation; Semantic gap
AB The beneficial, complementary nature of visual and textual information to convey information is widely known, for example, in entertainment, news, advertisements, science, or education. While the complex interplay of image and text to form semantic meaning has been thoroughly studied in linguistics and communication sciences for several decades, computer vision and multimedia research remained on the surface of the problem more or less. An exception is previous work that introduced the two metrics Cross-Modal Mutual Information and Semantic Correlation in order to model complex image-text relations. In this paper, we motivate the necessity of an additional metric called Status in order to cover complex image-text relations more completely. This set of metrics enables us to derive a novel categorization of eight semantic image-text classes based on three dimensions. In addition, we demonstrate how to automatically gather and augment a dataset for these classes from the Web. Further, we present a deep learning system to automatically predict either of the three metrics, as well as a system to directly predict the eight image-text classes. Experimental results show the feasibility of the approach, whereby the predict-all approach outperforms the cascaded approach of the metric classifiers.
C1 [Otto, Christian; Springstein, Matthias; Ewerth, Ralph] TIB Leibniz Informat Ctr Sci & Technol, Hannover, Germany.
   [Anand, Avishek; Ewerth, Ralph] Leibniz Univ Hannover, L3S Res Ctr, Hannover, Germany.
C3 Leibniz University Hannover
RP Otto, C (corresponding author), TIB Leibniz Informat Ctr Sci & Technol, Hannover, Germany.
EM christian.otto@tib.eu; ralph.ewerth@tib.eu
OI Ewerth, Ralph/0000-0003-0918-6297; Otto, Christian/0000-0003-0226-3608
FU Projekt DEAL; Leibniz Association, Germany (Leibniz Competition 2018,
   funding line "Collaborative Excellence", Project SALIENT) [K68/2017]
FX Open Access funding provided by Projekt DEAL. Part of this work is
   financially supported by the Leibniz Association, Germany (Leibniz
   Competition 2018, funding line "Collaborative Excellence", Project
   SALIENT [K68/2017]).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Balaneshin-kordan S, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P28, DOI 10.1145/3159652.3159735
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Barthes Roland, 1977, Image-Music-Text, P142
   Bateman JA, 2014, TEXT AND IMAGE: A CRITICAL INTRODUCTION TO THE VISUAL/VERBAL DIVIDE, P1
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Fan MD, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1698, DOI 10.1145/3123266.3123369
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Halliday M.A.K., 2013, Halliday's Introduction to Functional Grammar, DOI 10.4324/9780203431269
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henning C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P14, DOI 10.1145/3078971.3078991
   Henning C, 2018, INT J MULTIMED INF R, V7, P43, DOI 10.1007/s13735-017-0142-y
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang T.-H., 2016, NAACL HLT, P1233
   Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123
   Jaques Natasha., 2015, Multimodal Machine Learning Workshop in conjunction with NIPS, P1
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Karpathy A, 2014, ADV NEUR IN, V27
   KLOEPFER R, 1977, KOMPLEMENTARITAT SPR
   KRIPPEND.K, 1970, EDUC PSYCHOL MEAS, V30, P61, DOI 10.1177/001316447003000105
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KRUK J, 2019, ABS190409073 CORR
   Lan WY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1549, DOI 10.1145/3123266.3123366
   Liang J, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P569, DOI 10.1145/2911451.2911527
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FY, 2014, IEEE J BIOMED HEALTH, V18, P984, DOI 10.1109/JBHI.2013.2285378
   Liu P, 2016, 2016 17TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1480, DOI 10.1109/ICEPT.2016.7583403
   Marsh EE, 2003, J DOC, V59, P647, DOI 10.1108/00220410310506303
   Martinec R., 2005, VISUAL COMMUNICATION, V4, P337, DOI DOI 10.1177/1470357205055928
   Mazloom M., 2016, P ACM MULT, P197, DOI [10.1145/2964284.2967210, 10]
   McCloud S., 1993, Understanding Comics: The Invisible Art
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mithun NC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1856, DOI 10.1145/3240508.3240712
   Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064
   Noth Winifried., 1995, HDB SEMIOTICS
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Qi JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P528, DOI 10.1145/3240508.3240558
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schifanella R., 2016, P 24 ACM INT C MULT, P1136
   Shutova E., 2016, PROC C N AM CHAPTER, P160, DOI [10.18653/V1/N16-1020, DOI 10.18653/V1/N16-1020]
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Unsworth L., 2006, 33rd International Systemic Functional Congress, P1165
   van Leeuwen T., 2005, Introducing social semiotics
   Xu N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2399, DOI 10.1145/3132847.3133142
   Xu X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P46, DOI 10.1145/3206025.3206033
   Yeh YR, 2012, IEEE T MULTIMEDIA, V14, P563, DOI 10.1109/TMM.2012.2188783
   ZHANG MD, 2018, ARXIV180708205
   2017, PAGES ME LIST ANTONY
NR 53
TC 9
Z9 10
U1 3
U2 24
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2020
VL 9
IS 1
SI SI
BP 31
EP 45
DI 10.1007/s13735-019-00187-6
EA JAN 2020
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KQ6ZX
UT WOS:000508709000002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Moghaddam, HA
   Zare, A
AF Moghaddam, Hamid Abrishami
   Zare, Amin
TI Spatiotemporal wavelet correlogram for human action recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Spatiotemporal wavelet correlogram; Autocorrelogram subvector; Quantized
   coefficients; Wavelet subbands; Human action recognition; 3D discrete
   wavelet transform
ID DENSE; TRAJECTORIES; DESCRIPTORS; HISTOGRAMS; FEATURES; SYSTEMS
AB In this paper, we present a spatiotemporal wavelet correlogram (STWC) as a new feature for human action recognition (HAR) in videos. The proposed feature benefits from a different approach with respect to bag of visual words, interest point detection and descriptor representation method. The new approach requires neither motion estimation (tracking) nor background/foreground subtraction. STWC is generated more efficiently compared to the state-of-the-art HAR methods and achieves comparable results. STWC utilizes the multi-scale, multi-resolution property of wavelet transform and considers the correlation of wavelet coefficients. It is generated by computing spatiotemporal correlogram of quantized wavelet coefficients. These coefficients are computed using 3D wavelet decomposition and a simple quantization method. Based on the present findings, recommendations are made for the selection of the richest wavelet subbands to compute STWC.
C1 [Moghaddam, Hamid Abrishami] KN Toosi Univ Technol, Fac Elect & Comp Engn, Tehran, Iran.
   [Zare, Amin] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 K. N. Toosi University of Technology; Islamic Azad University
RP Moghaddam, HA (corresponding author), KN Toosi Univ Technol, Fac Elect & Comp Engn, Tehran, Iran.
EM moghaddam@kntu.ac.ir
RI Abrishami Moghaddam, Hamid/AAW-9288-2021; Zare, Amin/AAE-3309-2020;
   Zare, Amin/JAX-7370-2023; zare, amin/AAD-3044-2019
OI Zare, Amin/0000-0001-5308-6969; 
CR Ahad MAR, 2016, J MULTIMODAL USER IN, V10, P335, DOI 10.1007/s12193-016-0229-4
   [Anonymous], COMPUT ELECT ENG
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], INT J DIGIT LIB
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arunnehru J, 2018, PROCEDIA COMPUT SCI, V133, P471, DOI 10.1016/j.procs.2018.07.059
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Castro-Muñoz G, 2015, SIGNAL PROCESS-IMAGE, V30, P190, DOI 10.1016/j.image.2014.10.002
   Charalampous K, 2016, PATTERN ANAL APPL, V19, P337, DOI 10.1007/s10044-014-0404-8
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng MQ, 2017, PATTERN RECOGN, V67, P186, DOI 10.1016/j.patcog.2017.02.014
   Dilmen E, 2018, SOFT COMPUT, V22, P4457, DOI 10.1007/s00500-017-2713-5
   Dou JF, 2014, OPTIK, V125, P1891, DOI 10.1016/j.ijleo.2013.10.022
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fathi A, 2008, P IEEE C COMPUTER VI, P1
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Harris C., 1988, ALVEY VISION C, P147151
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Klaser A., 2008, BRIT MACHINE VISION
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li NN, 2018, NEUROCOMPUTING, V311, P65, DOI 10.1016/j.neucom.2018.05.033
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu GL, 2014, NEUROCOMPUTING, V123, P328, DOI 10.1016/j.neucom.2013.06.042
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Carmona JM, 2018, PATTERN RECOGN, V81, P443, DOI 10.1016/j.patcog.2018.04.015
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Moghaddam HA, 2005, PATTERN RECOGN, V38, P2506, DOI 10.1016/j.patcog.2005.05.010
   Nasiri JA, 2014, SIGNAL PROCESS, V104, P248, DOI [10.1016/j.sigpro.2014.04.010, 10.1016/j.sigpro.2014.04,010]
   Natarajan P, 2010, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR.2010.5539876
   Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P77, DOI 10.1109/TCSVT.2014.2333151
   Qiang Zhou, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P291, DOI 10.1007/978-3-642-33863-2_29
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sheng BY, 2015, NEUROCOMPUTING, V158, P73, DOI 10.1016/j.neucom.2015.01.064
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Ullah MM, 2012, IEEE IMAGE PROC, P777, DOI 10.1109/ICIP.2012.6466975
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LL, 2016, J VIS COMMUN IMAGE R, V40, P159, DOI 10.1016/j.jvcir.2016.06.023
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yu J, 2014, NEUROCOMPUTING, V131, P200, DOI 10.1016/j.neucom.2013.10.024
   Zhou W, 2014, SIGNAL PROCESS-IMAGE, V29, P546, DOI 10.1016/j.image.2014.01.012
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
NR 57
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2019
VL 8
IS 3
BP 167
EP 180
DI 10.1007/s13735-018-00167-2
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS8RG
UT WOS:000482416600004
DA 2024-07-18
ER

PT J
AU Chen, K
   Kovvuri, R
   Gao, JY
   Nevatia, R
AF Chen, Kan
   Kovvuri, Rama
   Gao, Jiyang
   Nevatia, Ram
TI MSRC: multimodal spatial regression with semantic context for phrase
   grounding
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Phrase grounding; Spatial regression; Multimodal; context
AB Given a textual description of an image, phrase grounding localizes objects in the image referred by query phrases in the description. State-of-the-art methods treat phrase grounding as a ranking problem and address it by retrieving a set of proposals according to the query's semantics, which are limited by the performance of independent proposal generation systems and ignore useful cues from context in the description. In this paper, we propose a novel multimodal spatial regression with semantic context (MSRC) system which not only predicts the location of ground truth based on proposal bounding boxes, but also refines prediction results by penalizing similarities of different queries coming from same sentences. There are two advantages of MSRC: First, it sidesteps the performance upper bound from independent proposal generation systems by adopting regression mechanism. Second, MSRC not only encodes the semantics of a query phrase, but also considers its relation with context (i.e., other queries from the same sentence) via a context refinement network. Experiments show MSRC system achieves a significant improvement in accuracy on two popular datasets: Flickr30K Entities and Refer-it Game, with 6.64 and 5.28% increase over the state of the arts, respectively.
C1 [Chen, Kan; Kovvuri, Rama; Gao, Jiyang; Nevatia, Ram] Univ Southern Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Chen, K (corresponding author), Univ Southern Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
EM kanchen@usc.edu; nkovvuri@usc.edu; jiyangga@usc.edu; nevatia@usc.edu
RI Chen, Kan/AAX-1609-2020; Kovvuri, Rama/JZE-2587-2024
FU Air Force Research Laboratory; Defense Advanced Research Projects Agency
   [FA8750-16-2-0204]
FX This paper is based, in part, on research sponsored by the Air Force
   Research Laboratory and the Defense Advanced Research Projects Agency
   under Agreement No. FA8750-16-2-0204. The U.S. Government is authorized
   to reproduce and distribute reprints for Governmental purposes
   notwithstanding any copyright notation thereon. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of the Air Force Research
   Laboratory and the Defense Advanced Research Projects Agency or the U.S.
   Government.
CR [Anonymous], 2015, CVPR
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Chen K, 2016, CVPR WORKSH
   Chen K, 2017, IEEE I CONF COMP VIS, P824, DOI 10.1109/ICCV.2017.95
   Chen Kan., 2017, CVPR
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Justin J, 2016, CVPR
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Karpathy Andrej, 2014, Advances in neural information processing systems, P1889
   Kazemzadeh S., 2014, EMNLP, P787, DOI DOI 10.3115/V1/D14-1086
   Kingma D. P., 2014, arXiv
   Krishnamurthy Jayant., 2013, Transactions of the Association for Computational Linguistics, V1, P193, DOI DOI 10.1162/TACLA00220
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Matuszek C., 2012, ICML, P1435
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Plummer B. A, 2016, IJCV
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Uijlings JRR, 2013, IJCV, DOI DOI 10.1007/S11263-013-0620-5
   Wang MZ, 2016, LECT NOTES COMPUT SC, V9912, P696, DOI 10.1007/978-3-319-46484-8_42
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 34
TC 6
Z9 7
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2018
VL 7
IS 1
SI SI
BP 17
EP 28
DI 10.1007/s13735-017-0139-6
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GB9SN
UT WOS:000429414200003
DA 2024-07-18
ER

PT J
AU Islam, SM
   Joardar, S
   Sekh, AA
AF Islam, Sk Maidul
   Joardar, Subhankar
   Sekh, Arif Ahmed
TI Ornament image retrieval using few-shot learning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Fashion retrieval; OrnamentFIR dataset; One-shot learning; Matching
   network; OrnamentFIR dataset
ID FASHION
AB In this paper, we introduce OrnamentFIR, a novel ornament dataset related to the fashion industry. In recent years, the retrieval of clothing and footwear articles has received significant interest from researchers. However, because of the design intricacy and lack of a suitable dataset, intricate fashion products, like jewelry, have not gotten much attention. We have assembled the OrnamentFIR dataset to address this issue. By revisiting the publically accessible datasets, namely RingFIR and NecklaceFIR, we create a novel dataset called OrnamentFIR. The dataset includes over similar to 4.4 K high-quality images of bangles, over similar to 4.8 K high-definition images of necklaces, and more than similar to 2.6 K high-quality images of earrings. The dataset is divided into three named classes: ring, necklace, and bangle, with each class having 46, 49, and 56 labeled categories, respectively. Due to the limited amount of data, we employed matching networks, a neural network that uses recent advances in attention and memory to enable rapid learning, to extract the desired image from the dataset. Using the matching networks for one-shot learning technique, we achieve 68% accuracy for RGB photographs, 62% accuracy for segmented images, and 50% accuracy for RGB+Segmented images. For the benefit of researchers, the ornament dataset has been made public. Public access to the dataset and code is provided at https://github.com/iammaidul/OrnamentFIR.
C1 [Islam, Sk Maidul] Global Inst Sci & Technol, Purba Medinipur, India.
   [Joardar, Subhankar] Haldia Inst Technol, Purba Medinipur, India.
   [Sekh, Arif Ahmed] XIM Univ, Bhubaneswar, India.
C3 Haldia Institute of Technology
RP Islam, SM (corresponding author), Global Inst Sci & Technol, Purba Medinipur, India.
EM iammaidul@gmail.com; subhankarranchi@yahoo.co.in; skarifahmed@gmail.com
OI Islam, Sk Maidul/0000-0003-2470-1269
CR Ak KE, 2019, IEEE INT CONF COMP V, P3121, DOI 10.1109/ICCVW.2019.00379
   Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   Ak KE, 2018, PATTERN RECOGN LETT, V112, P212, DOI 10.1016/j.patrec.2018.07.019
   Alayrac JB, 2022, Arxiv, DOI [arXiv:2204.14198, DOI 10.48550/ARXIV.2204.14198]
   [Anonymous], 2015, P 8 INT C MOB MULT C
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Cheng ZQ, 2017, PROC CVPR IEEE, P4169, DOI 10.1109/CVPR.2017.444
   Corbière C, 2017, IEEE INT CONF COMP V, P2268, DOI 10.1109/ICCVW.2017.266
   D'Innocente A, 2021, IEEE COMPUT SOC CONF, P3905, DOI 10.1109/CVPRW53098.2021.00435
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong H., 2020, CVPR, P8120
   Finn C, 2017, PR MACH LEARN RES, V70
   Gajic B, 2018, IEEE COMPUT SOC CONF, P1950, DOI 10.1109/CVPRW.2018.00243
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hidayati SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P438, DOI 10.1145/3240508.3240546
   Huang JS, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P731, DOI 10.1145/2647868.2654885
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Islam SM., 2021, SN COMPUT SCI, V2, P1, DOI [10.1007/s42979-021-00734-1, DOI 10.1007/S42979-021-00734-1]
   Jaradat S, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P407, DOI 10.1145/3109859.3109861
   Jiang SH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P52, DOI 10.1145/2964284.2967182
   Kang WC, 2017, IEEE DATA MINING, P207, DOI 10.1109/ICDM.2017.30
   Khurana T, 2018, IEEE IMAGE PROC, P2102, DOI 10.1109/ICIP.2018.8451281
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kinli F, 2019, IEEE INT CONF COMP V, P3109, DOI 10.1109/ICCVW.2019.00376
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang ZH, 2019, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2019.00316
   Kucer M, 2019, IEEE COMPUT SOC CONF, P344, DOI 10.1109/CVPRW.2019.00047
   Lake B., 2011, P ANN M COGNITIVE SC, P1
   Lang YN, 2020, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR42600.2020.00267
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Lin K, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P499, DOI 10.1145/2671188.2749318
   Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340
   Liu KH, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P313, DOI 10.1145/2911996.2912058
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Loni B, 2014, P 5 ACM MULT SYST C, P41
   Loni Babak., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, P72
   Ma Z, 2020, AAAI CONF ARTIF INTE, V34, P11741
   Maidul Islam SK, 2022, Multimedia Tools Appl, P1
   Maidul Islam Sk, 2021, Revised Selected Papers, P100
   Maidul Islam SK, 2023, Revised Selected Papers, P180
   Miao YW, 2020, IEEE ACCESS, V8, P142669, DOI 10.1109/ACCESS.2020.3013631
   Pandey N, 2020, NEUROCOMPUTING, V414, P356, DOI 10.1016/j.neucom.2020.07.092
   Perez E, 2021, ADV NEUR IN
   Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755
   Rostamzadeh N, 2018, Arxiv, DOI arXiv:1806.08317
   Shi Mengyun, 2020, arXiv
   Snell J, 2017, ADV NEUR IN, V30
   Song Y, 2017, IEEE INT CONF COMP V, P2243, DOI 10.1109/ICCVW.2017.262
   Su HB, 2021, IEEE T CIRC SYST VID, V31, P3254, DOI 10.1109/TCSVT.2020.3034981
   Sun X, 2021, IEEE J-STARS, V14, P2387, DOI 10.1109/JSTARS.2021.3052869
   Verma S, 2018, IEEE IMAGE PROC, P500, DOI 10.1109/ICIP.2018.8451164
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wang Z, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Wu H, 2021, PROC CVPR IEEE, P11302, DOI 10.1109/CVPR46437.2021.01115
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Xiaoling G., 2020, Inf Process Manag, V57
   Yin RP, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3434, DOI 10.1145/3308558.3313739
   Zhang HJ, 2020, NEURAL COMPUT APPL, V32, P4519, DOI [10.1007/s00521-018-3579-x, 10.1007/s00521-018-3691-y]
   Zhang YH, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P993, DOI 10.1145/3219819.3219820
   Zhao L, 2019, CLOTH TEXT RES J, V37, P87, DOI 10.1177/0887302X18821187
   Zhou W, 2019, J VIS COMMUN IMAGE R, V61, P112, DOI 10.1016/j.jvcir.2019.03.003
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
   Zou XX, 2019, IEEE COMPUT SOC CONF, P296, DOI 10.1109/CVPRW.2019.00039
NR 68
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 30
DI 10.1007/s13735-023-00299-0
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FG7M9
UT WOS:001144675900001
DA 2024-07-18
ER

PT J
AU Liu, MY
   Zhao, HG
   Ma, LF
   Li, MY
AF Liu, Mingyue
   Zhao, Honggang
   Ma, Longfei
   Li, Mingyong
TI Modal interaction-enhanced prompt learning by transformer decoder for
   vision-language models
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Modal interaction; CLIP; Prompt learning; Self-attention
AB In the current multimodal retrieval field, CoOp is the preferred approach among many models due to its simplicity and powerful adaptive capability. However, CoOp focuses primarily on optimizing prompts to perform contrast learning, without considering image-text interactions and the impact on the model when visual information is incorporated into the prompts. In this work, we propose a prompt tuning method for simulating image-text interaction based on CoOp: Decoding context optimization (DeCoOp). Through extensive experiments on 11 image classification datasets, seven datasets under the few-shot setting and all 11 datasets under the zero-shot setting are ahead of CoOp in our method. Experiments on four target datasets of ImageNet show a model performance improvement of more than 10%, demonstrating that our approach substantially outperforms the baseline model CoOp in terms of point domain generalization and robustness. In addition, ablation experiments performed on three representative datasets confirmed the effectiveness and further improvement of the accuracy of DeCoOp. Finally, experiments are performed on 11 datasets using different visual backbones, and it is not difficult to find that the gap between our approach and handcrafted prompts is large in all architectures and shows better performance than CoOp.
C1 [Liu, Mingyue; Zhao, Honggang; Ma, Longfei; Li, Mingyong] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Li, Mingyong] Chongqing Natl Ctr Appl Math, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP Li, MY (corresponding author), Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.; Li, MY (corresponding author), Chongqing Natl Ctr Appl Math, Chongqing 401331, Peoples R China.
EM 2021210516057@stu.cqnu.edu.cn; 2021210516098@stu.cqnu.edu.cn;
   2021210516063@stu.cqnu.edu.cn; limingyong@cqnu.edu.cn
RI Liu, Mingyue/JPL-7029-2023
FU Chongqing Natural Science Foundation of China [CSTB2022NSCQ-MSX1417];
   Science and Technology Research Program of Chongqing Municipal Education
   Commission [KJZD-K202200513]; Chongqing Normal University Fund
   [22XLB003]
FX AcknowledgementsThis work was partially supported by Chongqing Natural
   Science Foundation of China(Grant No. CSTB2022NSCQ-MSX1417), the Science
   and Technology Research Program of Chongqing Municipal Education
   Commission (Grant No. KJZD-K202200513) and Chongqing Normal University
   Fund (Grant No. 22XLB003).
CR [Anonymous], 2004, 2004 C COMP VIS PATT
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Gao P., 2021, P IEEE CVF C COMP VI, P3621
   Gao P., 2021, arXiv
   Ge C., 2022, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Hendrycks D., The many faces of robustness: A critical analysis of out-of-distribution generalization
   Hendrycks D, 2021, PROC CVPR IEEE, P15257, DOI 10.1109/CVPR46437.2021.01501
   Jia ML, 2022, Arxiv, DOI arXiv:2203.12119
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Manling, 2022, P IEEE CVF C COMP VI, P16420
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Radford A, 2021, PR MACH LEARN RES, V139
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rao YM, 2022, PROC CVPR IEEE, P18061, DOI 10.1109/CVPR52688.2022.01755
   Recht B, 2019, PR MACH LEARN RES, V97
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Haohan, 2019, ADV NEURAL INFORM PR
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Zhang RR, 2021, Arxiv, DOI arXiv:2111.03930
   Zhou K, 2022, P IEEECVF C COMPUTER, P16816
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
NR 33
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 19
DI 10.1007/s13735-023-00287-4
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N9NQ7
UT WOS:001040199300001
DA 2024-07-18
ER

PT J
AU Zhang, XW
   Fang, Q
   Hu, J
   Qian, SS
   Xu, CS
AF Zhang, Xiaowei
   Fang, Quan
   Hu, Jun
   Qian, Shengsheng
   Xu, Changsheng
TI TCKGE: Transformers with contrastive learning for knowledge graph
   embedding
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Augmentation; Contrastive learning; Knowledge graph; Transformer
AB Representation learning of knowledge graphs has emerged as a powerful technique for various downstream tasks. In recent years, numerous research efforts have been made for knowledge graphs embedding. However, previous approaches usually have difficulty dealing with complex multi-relational knowledge graphs due to their shallow network architecture. In this paper, we propose a novel framework named Transformers with Contrastive learning for Knowledge Graph Embedding (TCKGE), which aims to learn complex semantics in multi-relational knowledge graphs with deep architectures. To effectively capture the rich semantics of knowledge graphs, our framework leverages the powerful Transformers to build a deep hierarchical architecture to dynamically learn the embeddings of entities and relations. To obtain more robust knowledge embeddings with our deep architecture, we design a contrastive learning scheme to facilitate optimization by exploring the effectiveness of several different data augmentation strategies. The experimental results on two benchmark datasets show the superior of TCKGE over state-of-the-art models.
C1 [Zhang, Xiaowei] Zhengzhou Univ, Henan Inst Adv Technol, Zhengzhou 450001, Peoples R China.
   [Fang, Quan; Hu, Jun; Qian, Shengsheng; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Zhengzhou University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Fang, Q (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM xiaowei.zhan9@gmail.com; qfang@nlpr.ia.ac.cn; hujunxianligong@gmail.com;
   shengsheng.qian@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn
RI zhang, xiaowei/GQH-5387-2022; xu, cj/HJZ-3488-2023
FU National Natural Science Foundation of China [62036012, 62072456,
   62106262]; Open Research Projects of Zhejiang Lab [2021KE0AB05]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62036012, 62072456, 62106262. This work
   is supported by Open Research Projects of Zhejiang Lab (NO. 2021KE0AB05)
CR Balazevic I., 2019, Tensor Factorization for Knowledge Graph Completion, P5184
   Bollacker K., 2008, P 2008 ACM SIGMOD IN, P1247, DOI 10.1145/1376616.1376746
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Bordes Antoine, 2014, P C EMP METH NAT LAN, P615
   Broscheit S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P165
   Chami, 2020, LOW DIMENSIONAL HYPE, P6901
   Chaudhary C, 2020, IEEE T MULTIMEDIA, V22, P897, DOI 10.1109/TMM.2019.2937181
   Chen S, 2021, HITTER HIERARCHICAL, P10395
   Chen T, 2020, PR MACH LEARN RES, V119
   Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Guo QY, 2022, IEEE T KNOWL DATA EN, V34, P3549, DOI 10.1109/TKDE.2020.3028705
   Hassani K, 2020, CONTRASTIVE MULTIVIE, V119, P4116
   Hayashi H, 2020, AAAI CONF ARTIF INTE, V34, P7911
   Ji GL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P687
   Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843
   Jia YT, 2016, AAAI CONF ARTIF INTE, P992
   Kazemi SM, 2018, ADV NEUR IN, V31
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Liu H, 2017, ANALOGICAL INFERENCE, V70, P2168
   Logan RL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5962
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nickel M., 2011, P 28 INT C MACH LEAR, V11, P3104482, DOI 10.5555/3104482.3104584
   Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592
   Reinanda R, 2020, FOUND TRENDS INF RET, V14, P289, DOI 10.1561/1500000063
   Riedel S., 2013, P HUM LANG TECHN C N, P74
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   SUCHANEK Fabian M., 2007, 16 INT WORLD WID WEB, V16, P697, DOI DOI 10.1145/1242572.1242667
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895
   Sun ZY, 2022, INT J COAL PREP UTIL, V42, P221, DOI [10.1080/19392699.2019.1590346, 10.1109/eurosime.2019.8724592]
   Toutanova K., 2015, P 3 WORKSH CONT VECT, P57, DOI [10.18653/v1/W15-4007, DOI 10.18653/V1/W15-4007]
   Trouillon T, 2016, PR MACH LEARN RES, V48
   vandenOord Aaron, 2018, ARXIV180703748
   Vashishth S., 2020, Composition-based MultiRelational Graph Convolutional Networks
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P., 2018, ARXIV
   Verga P, 2020, ARXIV
   Wan S, 2021, AAAI CONF ARTIF INTE, V35, P10049
   Wang QY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM)
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang Z, 2014, AAAI CONF ARTIF INTE, P1112
   Weston J., 2013, P EMNLP, P1366
   Xiao Han, 2015, ARXIV
   Xiong W, 2017, DEEPPATH REINFORCEME, P564
   Xue F, 2020, IEEE T MULTIMEDIA, V22, P2098, DOI 10.1109/TMM.2019.2951194
   Yan YM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5065
   Yang B, 2014, P INT C LEARNING REP
   You Yuning, 2020, Graph contrastive learning with augmentations
   Zhang R, 2021, ARXIV
   Zhang XS, 2015, IEEE T MULTIMEDIA, V17, P1562, DOI 10.1109/TMM.2015.2449660
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhu YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2069, DOI 10.1145/3442381.3449802
NR 55
TC 2
Z9 2
U1 6
U2 37
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 589
EP 597
DI 10.1007/s13735-022-00256-3
EA NOV 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000889032300001
DA 2024-07-18
ER

PT J
AU El Asnaoui, K
AF El Asnaoui, Khalid
TI Design ensemble deep learning model for pneumonia disease classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Pneumonia disease; Pneumonia multiclass classification; Covid-19; X-ray
   images; Computer-aided diagnosis; Deep learning; Ensemble deep learning
AB With the recent spread of the SARS-CoV-2 virus, computer-aided diagnosis (CAD) has received more attention. The most important CAD application is to detect and classify pneumonia diseases using X-ray images, especially, in a critical period as pandemic of covid-19 that is kind of pneumonia. In this work, we aim to evaluate the performance of single and ensemble learning models for the pneumonia disease classification. The ensembles used are mainly based on fined-tuned versions of (InceptionResNet_V2, ResNet50 and MobileNet_V2). We collected a new dataset containing 6087 chest X-ray images in which we conduct comprehensive experiments. As a result, for a single model, we found out that InceptionResNet_V2 gives 93.52% of F1 score. In addition, ensemble of 3 models (ResNet50 with MobileNet_V2 with InceptionResNet_V2) shows more accurate than other ensembles constructed (94.84% of F1 score).
C1 [El Asnaoui, Khalid] Mohammed First Univ, Natl Sch Appl Sci ENSA, Dept Comp Sci, BP 669, Oujda 60000, Morocco.
C3 Mohammed First University of Oujda
RP El Asnaoui, K (corresponding author), Mohammed First Univ, Natl Sch Appl Sci ENSA, Dept Comp Sci, BP 669, Oujda 60000, Morocco.
EM khalid.elasnaoui@gmail.com
OI EL ASNAOUI, KHALID/0000-0003-4260-6898
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ahmad W. S. H. M. W., 2016, P INT C DIGITAL IMAG, P1
   [Anonymous], 2018, INT J DYN SYST DIFFE, DOI https://doi.org/10.1504/IJDSDE.2018.10009168
   [Anonymous], 2015, J DIGIT INF MANAG
   [Anonymous], 2018, PROC INT C ADV INF T, DOI [DOI 10.1007/978-3-319-69137-4_17, https://doi.org/10.1007/978-3-319-69137-4_17, 10.1007/978-3-319-69137-4_17]
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Apostolopoulos ID, 2020, J MED BIOL ENG, V40, P462, DOI 10.1007/s40846-020-00529-4
   Ashraf K, 2017, ARXIV PREPRINT ARXIV
   Ausawalaithong W, 2018, BIOMED ENG INT CONF
   Ayan E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741582
   Azzeh M, 2015, J SYST SOFTWARE, V103, P36, DOI 10.1016/j.jss.2015.01.028
   Barrientos R., 2016, 2016 IEEE 36 CENTR A, P1, DOI [10.1109/CONCAPAN.2016.7942375, DOI 10.1109/CONCAPAN.2016.7942375]
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Braga PL, 2007, IEEE IJCNN, P1595, DOI 10.1109/IJCNN.2007.4371196
   Butt C, 2023, APPL INTELL, V53, P4874, DOI 10.1007/s10489-020-01714-3
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Cicero M, 2017, INVEST RADIOL, V52, P281, DOI 10.1097/RLI.0000000000000341
   Correa M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206410
   Dong YX, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P51, DOI 10.1109/CHASE.2017.59
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   El Asnaoui K, 2016, INT J APPL MATH STAT, V54, P54
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Ghaderzadeh M, 2020, ARXIV PREPRINT ARXIV
   Ghassemi, 2020, ARXIV200611988
   Gu XH, 2018, PROCEEDINGS OF 2018 THE 3RD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2018), P88, DOI 10.1145/3195588.3195597
   Gundel Sebastian, 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P757, DOI 10.1007/978-3-030-13469-3_88
   Habib Nahida, 2020, SN Comput Sci, V1, P359, DOI 10.1007/s42979-020-00373-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Idri A, 2020, ARXIV PREPRINT ARXIV
   Janghel RR, 2014, LECT NOTES COMPUT SC, V8795, P8, DOI 10.1007/978-3-319-11897-0_2
   Ke Q, 2019, EXPERT SYST APPL, V126, P218, DOI 10.1016/j.eswa.2019.01.060
   Kermany Daniel, 2018, Mendeley Data, V2
   Khan W, 2020, INTELLIGENT PNEUMONI
   Khobragade S, 2016, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, INTELLIGENT CONTROL AND ENERGY SYSTEMS (ICPEICES 2016)
   Kwon H, 2019, HEALTHC INFORM RES, V25, P283, DOI 10.4258/hir.2019.25.4.283
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Madani A, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293971
   Maghdid HS, 2021, PROC SPIE, V11734, DOI 10.1117/12.2588672
   Mohamed Ouhda, 2019, Lecture Notes in Real-Time Intelligent Systems. Advances in Intelligent Systems and Computing (AISC 756), P463, DOI 10.1007/978-3-319-91337-7_41
   Narin A., 2020, ARXIV200310849
   Orbann C, 2017, EPIDEMICS-NETH, V19, P24, DOI 10.1016/j.epidem.2016.12.001
   Rajaraman S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101715
   Rajpurkar Pranav, 2017, ARXIV170701836
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Saraiva AA, 2019, BIOIMAGING: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2, P112, DOI 10.5220/0007404301120119
   Sethy PK, 2020, Detection of coronavirus disease (covid-19) based on deep features
   Siddiqi R, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P64, DOI 10.1145/3342999.3343001
   Sirazitdinov I, 2019, COMPUT ELECTR ENG, V78, P388, DOI 10.1016/j.compeleceng.2019.08.004
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taghanaki Saeid Asgari, 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P87, DOI 10.1007/978-3-030-02628-8_10
   Turukalo TL, 2020, PNEUMONIA DETECTION
   Varshni D., 2019 IEEE INT C EL C, DOI DOI 10.1109/ICECCT.2019.8869364
   Yoon, 2020, ARXIV PREPRINT ARXIV
   Zerouaoui Hasnae, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (1161), P44, DOI 10.1007/978-3-030-45697-9_5
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 57
TC 21
Z9 21
U1 1
U2 32
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2021
VL 10
IS 1
BP 55
EP 68
DI 10.1007/s13735-021-00204-7
EA FEB 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QV8OQ
UT WOS:000619901700001
PM 33643764
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Joshi, K
   Patel, MI
AF Joshi, Khushbu
   Patel, Manish I.
TI Recent advances in local feature detector and descriptor: a literature
   survey
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Computer vision system; Local feature detector; Local feature
   descriptor; Multispectral image
ID INVARIANT FEATURE TRANSFORM; INTEREST POINT DETECTORS; OBJECT DETECTION;
   PERFORMANCE EVALUATION; IMAGE FEATURES; SCALE; SIFT; ALGORITHM;
   TRACKING; STEREO
AB The computer vision system is the technology that deals with identifying and detecting the objects of a particular class in digital images and videos. Local feature detection and description play an essential role in many computer vision applications like object detection, object classification, etc. The accuracy of these applications depends on the performance of local feature detectors and descriptors used in the methods. Over the past decades, new algorithms and techniques have been introduced with the development of machine learning and deep learning techniques. The machine learning techniques can lead the work to the next level when sufficient data is provided. Deep learning algorithms can handle a large amount of data efficiently. However, this may raise questions in a researcher's mind about selecting the best algorithm and best method for a particular application to increase the performance. The selection of the algorithms highly depends on the type of application and amount of data to be handled. This encouraged us to write a comprehensive survey of local image feature detectors and descriptors from state-of-the-art to the recent ones. This paper presents feature detection and description methods in the visible band with their advantages and disadvantages. We also gave an overview of current performance evaluations and benchmark datasets. Besides, the methods and algorithms are described to find the features beyond the visible band. Finally, we concluded the survey with future directions. This survey may help researchers and serve as a reference in the field of the computer vision system.
C1 [Joshi, Khushbu] Sankalchand Patel Univ, Visanagar, India.
   [Joshi, Khushbu] LDRP Inst Technol & Res, Gandhinagar, India.
   [Patel, Manish I.] Nirma Univ, Ahmadabad, Gujarat, India.
C3 Nirma University
RP Joshi, K (corresponding author), Sankalchand Patel Univ, Visanagar, India.; Joshi, K (corresponding author), LDRP Inst Technol & Res, Gandhinagar, India.
EM skhushi86@gmail.com; manish.i.patel@nirmauni.ac.in
RI Patel, Manish/AGC-1491-2022; Patel, Manish/T-1887-2019
OI Patel, Manish/0000-0003-2948-9770
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2012, P NEUR INF PROC SYST
   ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747
   Baeza-Yates R., 1999, Modern information retrieval
   Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820816
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bianco S, 2015, DIGIT SIGNAL PROCESS, V44, P1, DOI 10.1016/j.dsp.2015.06.001
   Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Canclini A, 2013, INT CONF DIGIT SIG
   Chao JS, 2013, IEEE INT WORKSH MULT, P29, DOI 10.1109/MMSP.2013.6659259
   Chen JA, 2010, IEEE T BIO-MED ENG, V57, P1707, DOI 10.1109/TBME.2010.2042169
   Chen J, 2020, IEEE GEOSCI REMOTE S, V17, P681, DOI 10.1109/LGRS.2019.2930462
   Cheung W, 2007, I S BIOMED IMAGING, P720, DOI 10.1109/ISBI.2007.356953
   Dahl A. L., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P318, DOI 10.1109/3DIMPVT.2011.47
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Dickscheid T, 2011, INT J COMPUT VISION, V94, P154, DOI 10.1007/s11263-010-0340-z
   Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145
   Filipe S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P476
   Fu Xiping., 2014, Asian Conference on Computer Vision, P162
   Fu ZT, 2019, IEEE GEOSCI REMOTE S, V16, P100, DOI 10.1109/LGRS.2018.2867635
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   GHOSAL S, 1994, IEEE IMAGE PROC, P934, DOI 10.1109/ICIP.1994.413246
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Haja A, 2008, LECT NOTES COMPUT SC, V5096, P112, DOI 10.1007/978-3-540-69321-5_12
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartmann W, 2014, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2014.9
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Helber Helber P. P., IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, V12 12, P2217, DOI [DOI 10.1109/JSTARS.2019.2918242, 10.1109/IGARSS.2018.8519248]
   Ishii T, 2016, INT C PATT RECOG, P3344, DOI 10.1109/ICPR.2016.7900150
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang JH, 2019, IEEE ACCESS, V7, P20607, DOI 10.1109/ACCESS.2019.2896128
   Kaneva B, 2011, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2011.6126508
   Kangas V, 2011, COMP LOCAL FEATURE D
   Ke Y, 2004, PROC CVPR IEEE, P506
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Krawiec K, 2005, IEEE T SYST MAN CY B, V35, P409, DOI 10.1109/TSMCB.2005.846644
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lazebnik S., 2006, P IEEE INT C COMP VI, V2, P2169
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee MH, 2017, J VIS COMMUN IMAGE R, V47, P62, DOI 10.1016/j.jvcir.2017.05.008
   Leng CC, 2019, IEEE ACCESS, V7, P6424, DOI 10.1109/ACCESS.2018.2888856
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Li YS, 2014, INFORM SCIENCES, V281, P559, DOI 10.1016/j.ins.2013.12.022
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Lowe D, 1999, P 7 INT C COMP VIS K, P1150
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo ZX, 2020, PROC CVPR IEEE, P6588, DOI 10.1109/CVPR42600.2020.00662
   Ma J, 2021, INT J PAVEMENT ENG, V22, P1399, DOI 10.1080/10298436.2019.1694677
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Miksik O, 2012, INT C PATT RECOG, P2681
   Moravec H.P., 1977, P 5 INT JOINT C ARTI
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Morel J, 2016, AFFINE SIFT ASIFT
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ono Y, 2018, ADV NEUR IN, V31
   Patel MI, 2016, PROCEDIA COMPUT SCI, V93, P382, DOI 10.1016/j.procs.2016.07.224
   Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Restrepo MI, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.46
   Rosenfeld A, 1978, COMP CORNER DETECTIO
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Shen F, 2002, PATTERN RECOGN LETT, V23, P1039, DOI 10.1016/S0167-8655(02)00035-1
   Shen S, IMAGE CLASSIFICATION
   Shen WY, 2011, MODELLING SIMULATION, P277, DOI 10.1109/CIT.2011.51
   Shen XL, 2019, PROC CVPR IEEE, P8124, DOI 10.1109/CVPR.2019.00832
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Srisuk S, 2019, INT ELECT ENG CONGR, DOI 10.1109/ieecon45304.2019.8938687
   Strecha C, 2008, PROC CVPR IEEE, P2838
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Strecha C, 2009, LECT NOTES COMPUT SC, V5748, P151, DOI 10.1007/978-3-642-03798-6_16
   Su XQ, 2013, IEEE INT SYMP CIRC S, P2892, DOI 10.1109/ISCAS.2013.6572483
   Sun ZH, 2004, PATTERN RECOGN, V37, P2165, DOI 10.1016/j.patcog.2004.03.013
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan SY, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207191
   Torr PHS, 1995, THESIS
   Trujillo L, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P887
   Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Uchida Y, 2016, ARXIV160708368
   Uehara K, 2020, INT J REMOTE SENS, V41, P752, DOI 10.1080/01431161.2019.1648904
   Uehara K, 2017, IEEE SYS MAN CYBERN, P1339, DOI 10.1109/SMC.2017.8122799
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165
   Vollmer M., 2018, Infrared Thermal Imaging. Fundamentals, Research and Applications, VSecond
   Wang R, 2019, IEEE ACCESS, V7, P71235, DOI 10.1109/ACCESS.2019.2918813
   Yao QL, 2019, INT GEOSCI REMOTE SE, P1450, DOI [10.1109/IGARSS.2019.8897851, 10.1109/igarss.2019.8897851]
   Yi KM, 2016, PROC CVPR IEEE, P107, DOI 10.1109/CVPR.2016.19
   Ying X, 2019, IEEE ACCESS, V7, P94508, DOI 10.1109/ACCESS.2019.2928522
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang X, 2017, PROC CVPR IEEE, P4923, DOI 10.1109/CVPR.2017.523
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zuniga OA, 1983, P IEEE C COMP VIS PA
NR 124
TC 19
Z9 20
U1 1
U2 26
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2020
VL 9
IS 4
BP 231
EP 247
DI 10.1007/s13735-020-00200-3
EA OCT 2020
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OS6IE
UT WOS:000583108900001
DA 2024-07-18
ER

PT J
AU Bouhlel, N
   Feki, G
   Ben Ammar, A
   Ben Amar, C
AF Bouhlel, Noura
   Feki, Ghada
   Ben Ammar, Anis
   Ben Amar, Chokri
TI Hypergraph learning with collaborative representation for image search
   reranking
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image search; Hypergraph; Reranking; Regression; Collaborative
   representation
ID RETRIEVAL; RANKING; DIVERSIFICATION; TREE
AB Image search reranking has received considerable attention in recent years. It aims at refining the text-based image search results by boosting the rank of relevant images. Hypergraph has been widely used for relevance estimation, where textual results are taken as vertices and the hypergraph ranking is performed to learn their relevance scores. Rather than using the K-nearest neighbor method, recent works have adopted the sparse representation to effectively construct an informative hypergraph. The sparse representation is insensitive to noise and can capture the real neighborhood structure. However, it suffers from a heavy computational cost. Motivated by this observation, in this paper, we leveraged the ridge regression for hypergraph construction. By imposing an l(2)-regularizer on the size of their regression coefficients, the ridge regression enforces the training samples to collaborate to represent one query. The so-called collaborative representation exhibits more discriminative power and robustness while being computationally efficient. Thereafter, based on the obtained collaborative representation vectors, we measured the pairwise similarities among samples and generated hyperedges. Extensive experiments on the public MediaEval benchmarks demonstrated the effectiveness and superiority of our method over the state-of-the-art reranking methods.
C1 [Bouhlel, Noura; Feki, Ghada; Ben Ammar, Anis; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Bouhlel, N (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM noura.bouhlel.tn@ieee.org; ghada.feki@ieee.org;
   ben.ammar.regim@gmail.com; chokri.benamar@ieee.org
RI Bouhlel, Noura/AAF-4072-2021; Chokri, BEN AMAR/K-5237-2012
OI Bouhlel, Noura/0000-0002-5602-8892
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX The research leading to these results has received funding from the
   Ministry of Higher Education and Scientific Research of Tunisia under
   the Grant Agreement Number LR11ES48.
CR BOTEANU B, 2016, MEDIAEVAL 2016 WORKS
   Boteanu B, 2017, MULTIMED TOOLS APPL, V76, P11889, DOI 10.1007/s11042-016-3678-6
   BOUHLEL N, 2016, INT C INT SYST DES A, V2016, P479
   Bouhlel N, 2017, LECT NOTES COMPUT SC, V10424, P279, DOI 10.1007/978-3-319-64689-3_23
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cai JJ, 2015, IEEE T IMAGE PROCESS, V24, P261, DOI 10.1109/TIP.2014.2372616
   Chebaro MR, 2010, PROCEEDINGS OF THE ASME INTERNATIONAL PIPELINE CONFERENCE 2010, VOL 1, P511
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Cheng XQ, 2013, IEEE T KNOWL DATA EN, V25, P177, DOI 10.1109/TKDE.2011.190
   Dang-Pham D., 2015, Investigating the formation of information security climate perceptions with social network analysis: A research proposal, P1
   Feki Ghada, 2014, 6th International Conference on Knowledge Discovery and Information Retrieval (KDIR 2014). Proceedings, P444
   FEKI G, 2016, P MEDIAEVAL 2016 WOR
   Feki G, 2015, INT CONF INTELL SYST, P499, DOI 10.1109/ISDA.2015.7489166
   Feki G, 2016, J INF ASSUR SECUR, V11, P144
   Feki G, 2013, INT WORK CONTENT MUL, P148
   FERREIRA C, 2016, MEDIAEVAL 2016 WORKS
   Guedri Boulbaba, 2011, 2011 International Conference on High Performance Computing & Simulation, P369
   Hong CQ, 2013, NEUROCOMPUTING, V101, P94, DOI 10.1016/j.neucom.2012.09.001
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   IONESCU B, 2015, P 6 ACM MULT SYST C, P207
   Ionescu B, 2016, MULTIMED TOOLS APPL, V75, P1301, DOI 10.1007/s11042-014-2369-4
   Jing PG, 2018, NEUROCOMPUTING, V274, P50, DOI 10.1016/j.neucom.2016.05.085
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Ksibi Amel, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P571, DOI 10.1007/978-3-642-40246-3_71
   Liu Y, 2013, NEUROCOMPUTING, V119, P49, DOI 10.1016/j.neucom.2012.02.051
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mejdoub M, 2008, INT WORK CONTENT MUL, P349
   Mejdoub M, 2009, J VIS COMMUN IMAGE R, V20, P145, DOI 10.1016/j.jvcir.2008.12.003
   PALOTTI JRM, 2014, P MEDIAEVAL 2014 WOR
   SPAMPINATO C, 2014, MEDIAEVAL
   Spyromitros-Xioufis E, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P323, DOI 10.1145/2671188.2749334
   SPYROMITROSXIOU.E, 2014, MEDIAEVAL 2014 MULT
   Tian XM, 2011, IEEE T MULTIMEDIA, V13, P639, DOI 10.1109/TMM.2011.2111363
   TOLLARI S, 2016, CEUR WORKSHOP P, V1739
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P810, DOI 10.1109/TPAMI.2013.214
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Yan R, 2003, LECT NOTES COMPUT SC, V2728, P238
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou D., 2006, NIPS, V19
   Zhou WG, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422960
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu Xiaojin., 2007, HLT NAACL
NR 44
TC 7
Z9 7
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2020
VL 9
IS 3
BP 205
EP 214
DI 10.1007/s13735-019-00191-w
EA JAN 2020
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MQ6SK
UT WOS:000508709000001
DA 2024-07-18
ER

PT J
AU Cheng, KY
   Zhu, XS
   Zhan, YZ
   Pei, YS
AF Cheng, Keyang
   Zhu, Xuesen
   Zhan, Yongzhao
   Pei, Yunshen
TI Video deblurring and flow-guided feature aggregation for obstacle
   detection in agricultural videos
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Agriculture; Feature aggregation; Obstacle detection; Video deblurring
AB Autonomous agricultural vehicles are increasingly common on farms, where they can replace humans in tasks such as irrigation, harvesting, and weeding, reducing labor costs. Real-time obstacle avoidance is a prerequisite for their work. At present, vehicles equipped with vision sensors cannot perform end-to-end video object detection, and their accuracy is also affected by motion blur. We propose a novel agricultural obstacle detection method based on RNN and flow-guided feature aggregation, combining video deblurring and object detection tasks for joint optimization. In addition, to make full use of the region proposals, a region shared strategy is proposed to improve the efficiency of video deblurring. The proposed method can solve the common motion blur problem in agricultural video and is expected to be suitable for all kinds of obstacle detection tasks in agricultural scenes. We experimented with this method on the FieldSAFE and GOPRO datasets. Our method provides better detection performance and is computationally less costly than other methods according to experimental results.
C1 [Cheng, Keyang; Zhu, Xuesen; Zhan, Yongzhao; Pei, Yunshen] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Cheng, KY (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
EM kycheng@ujs.edu.cn; 973126498@qq.com; yzzhan@ujs.edu.cn;
   2948977624@qq.com
RI Zhang, Zhentao/JQV-7389-2023; jin, li/IWU-4648-2023
FU National Natural Science Foundation of China [61972183]; Science and
   Technology Project of Jiangsu Province [BE2022781]
FX Our research work is supported by the National Natural Science
   Foundation of China (No 61972183) and the Science and Technology Project
   of Jiangsu Province (No BE2022781).
CR Bastian BT, 2019, INT J MULTIMED INF R, V8, P127, DOI 10.1007/s13735-019-00171-0
   Bertasius G, 2018, LECT NOTES COMPUT SC, V11216, P342, DOI 10.1007/978-3-030-01258-8_21
   Campos Y, 2016, APPL SOFT COMPUT, V45, P86, DOI 10.1016/j.asoc.2016.03.016
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen Y., 2020, CVPR, P10337
   Christiansen P, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111904
   Dai JF, 2016, ADV NEUR IN, V29
   Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Gao Z., 2022, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isobe, 2022, ARXIV
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kim TH, 2017, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2017.435
   Kragh MF, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112579
   Lee B, 2016, LECT NOTES COMPUT SC, V9914, P68, DOI 10.1007/978-3-319-48881-3_6
   Murthy CB, 2021, INT J MULTIMED INF R, V10, P171, DOI 10.1007/s13735-021-00212-7
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2020, PROC CVPR IEEE, P3040, DOI 10.1109/CVPR42600.2020.00311
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross P, 2014, IEEE INT CONF ROBOT, P1699, DOI 10.1109/ICRA.2014.6907080
   Ruan L, 2022, ARXIV
   Sayed M, 2021, PROC CVPR IEEE, P1706, DOI 10.1109/CVPR46437.2021.00175
   Song Han W. J. D., 2016, arXiv
   Suresha M, 2020, INT J MULTIMED INF R, V9, P81, DOI 10.1007/s13735-019-00190-x
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33
   Wang ZW, 2020, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR42600.2020.00212
   Wieschollek P, 2017, IEEE I CONF COMP VIS, P231, DOI 10.1109/ICCV.2017.34
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang KH, 2019, IEEE T IMAGE PROCESS, V28, P291, DOI 10.1109/TIP.2018.2867733
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhengkai Jiang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P18, DOI 10.1007/978-3-030-58517-4_2
   Zhou, 2022, ARXIV
   Zhou Jun Zhou Jun, 2011, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V42, P154
   Zhu X., 2020, arXiv
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
   Zhujun Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P220, DOI 10.1007/978-3-030-58595-2_14
NR 40
TC 0
Z9 0
U1 5
U2 22
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 577
EP 588
DI 10.1007/s13735-022-00263-4
EA OCT 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000869623400001
DA 2024-07-18
ER

PT J
AU Fisichella, M
AF Fisichella, Marco
TI Siamese coding network and pair similarity prediction for near-duplicate
   image detection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Indexing methods; Deep features extraction; Near-duplicate image
   detection; Locality sensitive hashing; High-dimensional datasets
ID NEIGHBOR
AB Near-duplicate detection in a dataset involves finding the elements that are closest to a new query element according to a given similarity function and proximity threshold. The brute force approach is very computationally intensive as it evaluates the similarity between the queried item and all items in the dataset. The potential application domain is an image sharing website that checks for plagiarism or piracy every time a new image is uploaded. Among the various approaches, near-duplicate detection was effectively addressed by SimPair LSH (Fisichella et al., in Decker, Lhotska, Link, Spies, Wagner (eds) Database and expert systems applications, Springer, 2014). As the name suggests, SimPair LSH uses locality sensitive hashing (LSH) and computes and stores in advance a small set of near-duplicate pairs present in the dataset and uses them to reduce the candidate set returned for a given query using the Triangle inequality. We develop an algorithm that predicts how the candidate set will be reduced. We also develop a new efficient method for near-duplicate image detection using a deep Siamese coding neural network that is able to extract effective features from images useful for building LSH indices. Extensive experiments on two benchmark datasets confirm the effectiveness of our deep Siamese coding network and prediction algorithm.
C1 [Fisichella, Marco] Leibniz Univ Hannover, Res Ctr L3S, Appelstr 9A, D-30167 Hannover, Germany.
C3 Leibniz University Hannover
RP Fisichella, M (corresponding author), Leibniz Univ Hannover, Res Ctr L3S, Appelstr 9A, D-30167 Hannover, Germany.
EM mfisichella@L3S.de
OI FISICHELLA, Marco/0000-0002-6894-1101
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Andoni A, 2021, IMPLEMENTATIONS LS E
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   Andoni Alexandr, 2014, P 25 ANN ACM SIAM S, P1018
   [Anonymous], 1961, Adaptive control processes: a guided tour, DOI DOI 10.1515/9781400874668
   [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Ceroni A., 2015, P 24 ACM INT C INF K, P1815, DOI [10.1145/2806416.2806624, DOI 10.1145/2806416.2806624]
   Ceroni A, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1157, DOI 10.1145/2911451.2911452
   Chum Ondrej., 2007, CIVR 07, P549, DOI DOI 10.1145/1282280.1282359
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fisichella Marco, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings: LNCS 8645, P59, DOI 10.1007/978-3-319-10085-2_5
   Fisichella M, 2021, INT J DIGIT LIBRARIE, V22, P339, DOI 10.1007/s00799-021-00308-9
   Fisichella M, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5030034
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Huang Q, 2015, PROC VLDB ENDOW, V9, P1
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jafari O, 2021, ARXIVABS210208942
   Krizhevsky A., 2009, The CIFAR-10 Dataset
   Liu WQ, 2019, PROC INT CONF DATA, P1670, DOI 10.1109/ICDE.2019.00169
   Lu KJ, 2020, PROC INT CONF DATA, P1045, DOI 10.1109/ICDE48307.2020.00095
   Lv Q., 2007, P 33 INT C VER LARG
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Teixeira T, 2013, ARXIVABS13104136
   Wang Q, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P358, DOI 10.1109/ISCSLP.2012.6423463
   Zheng BL, 2020, PROC VLDB ENDOW, V13, P643, DOI 10.14778/3377369.3377374
NR 26
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 159
EP 170
DI 10.1007/s13735-022-00233-w
EA APR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000781686000001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Murthy, CB
   Hashmi, MF
   Keskar, AG
AF Murthy, Chintakindi Balaram
   Hashmi, Mohammad Farukh
   Keskar, Avinash G.
TI Optimized MobileNet plus SSD: a real-time pedestrian detection on a
   low-end edge device
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Pedestrian detection; Computer vision (CV); Optimized MobileNet plus SSD
   Network; Caltech pedestrian dataset; Jetson Nano board
AB One of the most fundamental challenges in computer vision is pedestrian detection since it involves both the classification and localization of pedestrians at a location. To achieve real-time pedestrian detection without having any loss in detection accuracy, an Optimized MobileNet + SSD network is proposed. There are four important components in pedestrian detection: feature extraction, deformation, occlusion handling and classification. The existing methods design these components either independently or in a sequential format, and the interaction among these components has not been explored yet. The proposed network lets the components work in coordination in such a manner that their strengths are improved and the number of parameters is decreased compared to recent detection architectures. We propose a concatenation feature fusion module for adding contextual information in the Optimized MobileNet + SSD network to improve the detection accuracy of pedestrians. The proposed model achieved 80.4% average precision with a detection speed of 34.01 frames per second (fps) when tested on the Jetson Nano board, which is much faster compared to standard video speed (30 fps). Experimental results have shown that the proposed network has a better detection effect during low light conditions and for darker pictures. Therefore, the proposed network is well suited for low-end edge devices.
C1 [Murthy, Chintakindi Balaram; Hashmi, Mohammad Farukh] Natl Inst Technol, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
   [Keskar, Avinash G.] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur, Maharashtra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal; National Institute of Technology (NIT System);
   Visvesvaraya National Institute of Technology, Nagpur
RP Hashmi, MF (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
EM mdfarukh@nitw.ac.in
RI HASHMI, MOHAMMAD FARUKH/W-1428-2019
OI HASHMI, MOHAMMAD FARUKH/0000-0002-3808-9122; Keskar,
   Avinash/0000-0002-9660-1139
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Afifi M., 2019, ARXIV PREPRINT ARXIV
   Cao GM, 2018, PROC SPIE, V10615, DOI 10.1117/12.2304811
   Chen YC, 2019, IEEE VTS VEH TECHNOL, DOI [10.1109/vtcspring.2019.8746552, 10.4324/9780429425882]
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fukui H, 2015, IEEE INT VEH SYM, P223, DOI 10.1109/IVS.2015.7225690
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang P, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418560141
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Murthy C. B., 2020, 2020 IEEE 17 INDIA C, P1, DOI DOI 10.1109/INDICON49873.2020.9342082
   Murthy CB, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093280
   Ouyang WL, 2018, IEEE T PATTERN ANAL, V40, P1874, DOI 10.1109/TPAMI.2017.2738645
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghi MA, 2014, LECT NOTES COMPUT SC, V8689, P65, DOI 10.1007/978-3-319-10590-1_5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szarvas M, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P224
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Yang F, 2019, IEEE ACCESS, V7, P15478, DOI 10.1109/ACCESS.2019.2895376
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 32
TC 12
Z9 12
U1 4
U2 25
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2021
VL 10
IS 3
BP 171
EP 184
DI 10.1007/s13735-021-00212-7
EA JUL 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UU7DE
UT WOS:000674069200001
DA 2024-07-18
ER

PT J
AU Saremi, M
   Yaghmaee, F
AF Saremi, Mehrin
   Yaghmaee, Farzin
TI Probabilistic selection of frames for early action recognition in videos
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Early action recognition; Convolutional neural network; Deep learning;
   Frame selection
ID PREDICTION
AB Early action recognition seeks to recognize human actions in a video, while the video has been only partially observed. In this paper, we introduce an approach to this kind of recognition task. In some offline (non-early) recognition works, it has been proposed to sample frames of the video uniformly and use them in training of the model. However, there is no reason that uniform sampling should be optimal, so we propose a non-uniform sampling to make it more tailored to early recognition. The proposed method samples the frames in such a way that earlier frames are more likely to be chosen. These frames are then used in training a deep network architecture. We compare our sampling approach with a uniform sampling process, using HMDB51 dataset as a benchmark. We further compare our method with other state-of-the-art early recognition works. The experimental results suggest that our sampling process leads to better recognition accuracy than uniform sampling, at the early stages of the video, and that our proposed algorithm outperforms the state-of-the-art.
C1 [Saremi, Mehrin] Semnan Univ, Elect & Comp Engn, Semnan 1911135131, Iran.
   [Yaghmaee, Farzin] Semnan Univ, Fac Elect & Comp Engn, Semnan 1911135131, Iran.
C3 Semnan University; Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan 1911135131, Iran.
EM m.saremi@semnan.ac.ir; f_yaghmaee@semnan.ac.ir
RI Saremi, Mehrin/HTM-6225-2023; Yaghmaee, Farzin/AAZ-6590-2021
OI Yaghmaee, Farzin/0000-0001-7430-542X; Saremi, Mehrin/0000-0001-6557-9656
CR Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu JF, 2019, IEEE T PATTERN ANAL, V41, P2568, DOI 10.1109/TPAMI.2018.2863279
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lai SF, 2018, IEEE T IMAGE PROCESS, V27, P2272, DOI 10.1109/TIP.2017.2751145
   Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18
   Wang HR, 2018, NEUROCOMPUTING, V318, P109, DOI 10.1016/j.neucom.2018.08.037
   Wang HR, 2017, NEUROCOMPUTING, V225, P139, DOI 10.1016/j.neucom.2016.11.004
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Xu Z, 2015, IEEE I CONF COMP VIS, P3191, DOI 10.1109/ICCV.2015.365
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
NR 19
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2019
VL 8
IS 4
BP 253
EP 257
DI 10.1007/s13735-019-00182-x
EA OCT 2019
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KN5AU
UT WOS:000492932500001
DA 2024-07-18
ER

PT J
AU Galshetwar, GM
   Waghmare, LM
   Gonde, AB
   Murala, S
AF Galshetwar, G. M.
   Waghmare, L. M.
   Gonde, A. B.
   Murala, S.
TI Multi-dimensional multi-directional mask maximum edge pattern for
   bio-medical image retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Local binary pattern (LBP); Local mesh pattern (LMeP); Multi-dimensional
   multi-directional mask maximum edge patterns [(MD)(2)MaMEP]
ID FEATURE DESCRIPTOR; WAVELET CORRELOGRAM; XOR PATTERNS; TEXTURE;
   CLASSIFICATION; MRI
AB Authors have proposed novel multi-dimensional multi-directional mask maximum edge patterns for the bio-medical image retrieval. Standard local binary patterns encode relationship of neighbor pixels with center pixel. Local mesh patterns encode the relationship between adjacent pixels surrounding the center pixel. Proposed approach encodes relationship of neighbour pixels in adjacent planes of a multi-dimensional image, in three stages. In the first stage, five sub images are formed by traversing in five different directions on three planes of a multi-dimensional image. In the second stage, directional masks are applied on each sub image to find directional edges. In stage three, maximum edge patterns are found based on the directions of the directional edges. To examine performance analysis of the proposed algorithm, we tested proposed algorithm on three benchmark databases, which gives retrieval accuracy for top 10 images on MESSIDOR (Retinal images), VIA/I-ELCAP (CT images) and OASIS-MRI databases respectively in terms of average retrieval precision. The comparison reflects, there is considerable improvement in the performance.
C1 [Galshetwar, G. M.; Gonde, A. B.] SGGSIET, Ctr Excellence Signal & Image Proc, Nanded, Maharashtra, India.
   [Waghmare, L. M.] SGGSIET, Dept Instrumentat Engn, Nanded, Maharashtra, India.
   [Murala, S.] IIT Ropar, Comp Vis & Pattern Recognit Lab, Rupnagar, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology; Shri
   Guru Gobind Singhji Institute of Engineering & Technology; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Ropar
RP Galshetwar, GM (corresponding author), SGGSIET, Ctr Excellence Signal & Image Proc, Nanded, Maharashtra, India.
EM gmgalshetwar@gmail.com
RI Murala, Subrahmanyam/D-1397-2017; WAGHMARE, LAXMAN/AAG-1602-2019
OI Waghmare, Laxman/0000-0002-4236-7359
CR Aman JM, 2010, I S BIOMED IMAGING, P1357, DOI 10.1109/ISBI.2010.5490249
   Baby CG, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P195, DOI 10.1109/ICSIPR.2013.6497987
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Chi YL, 2013, MED PHYS, V40, DOI 10.1118/1.4820539
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Deep G, 2016, PROCEDIA COMPUT SCI, V85, P954, DOI 10.1016/j.procs.2016.05.287
   Dharani T, 2013, 2013 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, INFORMATICS AND MEDICAL ENGINEERING (PRIME)
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dudhane A, 2017, ADV INTEL SYS RES, V137, P515
   Dudhane Akshay A., 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P345, DOI 10.1007/978-981-10-7895-8_27
   Gonde AB, 2017, 2017 4 INT C IMAGE I, P1
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jai-Andaloussi S, 2010, IEEE ENG MED BIO, P3069, DOI 10.1109/IEMBS.2010.5626134
   Larnard M, 2007, P ANN INT IEEE EMBS, P4532
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Marcus DS, 2010, J COGNITIVE NEUROSCI, V22, P2677, DOI 10.1162/jocn.2009.21407
   Moghaddam HA, 2013, PATTERN ANAL APPL, V16, P163, DOI 10.1007/s10044-011-0230-1
   Moghaddam HA, 2005, PATTERN RECOGN, V38, P2506, DOI 10.1016/j.patcog.2005.05.010
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Naguib AM, 2013, COMP MED SY, P560, DOI 10.1109/CBMS.2013.6627877
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Rosas-Romero R, 2015, COMPUT MED IMAG GRAP, V44, P41, DOI 10.1016/j.compmedimag.2015.07.001
   Sastry CS, 2007, PATTERN RECOGN LETT, V28, P293, DOI 10.1016/j.patrec.2006.07.015
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Tobin KW, 2008, IEEE ENG MED BIO, P5441, DOI 10.1109/IEMBS.2008.4650445
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Vipparthi SK, 2016, IET COMPUT VIS, V10, P182, DOI 10.1049/iet-cvi.2015.0035
   Vipparthi SK, 2015, NEUROCOMPUTING, V167, P336, DOI 10.1016/j.neucom.2015.04.062
   Vipparthi SK, 2015, OPTIK, V126, P1467, DOI 10.1016/j.ijleo.2015.04.018
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Vipparthi SK, 2014, COMPUT ELECTR ENG, V40, P163, DOI 10.1016/j.compeleceng.2014.04.018
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Xavier L., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P79, DOI 10.1109/ICECTECH.2011.5941861
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
NR 43
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD NOV
PY 2018
VL 7
IS 4
BP 231
EP 239
DI 10.1007/s13735-018-0156-0
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GX5SL
UT WOS:000447810500003
DA 2024-07-18
ER

PT J
AU Nagai, Y
   Uchida, Y
   Sakazawa, S
   Satoh, S
AF Nagai, Yuki
   Uchida, Yusuke
   Sakazawa, Shigeyuki
   Satoh, Shin'ichi
TI Digital watermarking for deep neural networks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
AB Although deep neural networks have made tremendous progress in the area of multimedia representation, training neural models requires a large amount of data and time. It is well known that utilizing trained models as initial weights often achieves lower training error than neural networks that are not pre-trained. A fine-tuning step helps to both reduce the computational cost and improve the performance. Therefore, sharing trained models has been very important for the rapid progress of research and development. In addition, trained models could be important assets for the owner(s) who trained them; hence, we regard trained models as intellectual property. In this paper, we propose a digital watermarking technology for ownership authorization of deep neural networks. First, we formulate a new problem: embedding watermarks into deep neural networks. We also define requirements, embedding situations, and attack types on watermarking in deep neural networks. Second, we propose a general framework for embedding a watermark in model parameters, using a parameter regularizer. Our approach does not impair the performance of networks into which a watermark is placed because the watermark is embedded while training the host network. Finally, we perform comprehensive experiments to reveal the potential of watermarking deep neural networks as the basis of this new research effort. We show that our framework can embed a watermark during the training of a deep neural network from scratch, and during fine-tuning and distilling, without impairing its performance. The embedded watermark does not disappear even after fine-tuning or parameter pruning; the watermark remains complete even after 65% of parameters are pruned.
C1 [Nagai, Yuki] KDDI Res Inc, 2-1-15 Ohara, Fujimino, Saitama 3568502, Japan.
   [Uchida, Yusuke] DeNA Co Ltd, Shibuya Ku, 21-1 Shibuya, Tokyo 1508510, Japan.
   [Sakazawa, Shigeyuki] Osaka Inst Technol, 1-79-1 Kitayama, Hirakata, Osaka 5730196, Japan.
   [Satoh, Shin'ichi] Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
C3 KDDI Corporation; KDDI Research, Inc.; Osaka Institute of Technology;
   Research Organization of Information & Systems (ROIS); National
   Institute of Informatics (NII) - Japan
RP Nagai, Y (corresponding author), KDDI Res Inc, 2-1-15 Ohara, Fujimino, Saitama 3568502, Japan.
EM yk-nagai@kddi-research.jp; yusuke.a.uchida@dena.com;
   shigeyuki.sakazawa@oit.ac.jp; satoh@nii.ac.jp
OI Uchida, Yusuke/0000-0002-6932-1465
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   AMARI S, 1967, IEEE TRANS ELECTRON, VEC16, P299, DOI 10.1109/PGEC.1967.264666
   [Anonymous], P INTERSPEECH
   [Anonymous], P OF CVPR
   [Anonymous], P OF ECCV
   [Anonymous], 2010, P PYTHON SCI COMPUTI
   [Anonymous], P OF NIPS
   [Anonymous], 2015, PROC LEARNINGSYS
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], P OF ECCV
   [Anonymous], P OF MM
   [Anonymous], 2011, P NIPS WORKSH BIGLEA
   [Anonymous], 2015, P AISTATS
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2004, P CVPR WORKSH GEN MO
   [Anonymous], P OF ICLR
   [Anonymous], P OF CVPR
   [Anonymous], P OF ICLR
   [Anonymous], P OF ICML
   [Anonymous], P OF NIPS
   [Anonymous], P OF NIPS
   [Anonymous], P OF ICMR
   [Anonymous], 2014, P NIPS WORKSH DEEP L
   [Anonymous], P OF ICME
   [Anonymous], P OF ICMR
   [Anonymous], P OF ICLR
   [Anonymous], P OF NIPS
   [Anonymous], P OF ICIP
   [Anonymous], P OF NIPS
   [Anonymous], 1983, SOV MATH DOKL
   [Anonymous], P OF ISCA
   [Anonymous], P OF ICME
   [Anonymous], 2017, ARXIV171101894
   Ba LJ, 2014, ADV NEUR IN, V27
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Barr J, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P69
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chollet F., 2015, KERAS
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Haitsma J., 2002, P ISMIR 2002 3 INT C, P107
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Johnson N., 2000, Information Hiding: Steganography and Watermarking - Attacks and Countermeasures, V1
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Van den Oord A., 2013, P NIPS
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
NR 53
TC 51
Z9 59
U1 2
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2018
VL 7
IS 1
SI SI
BP 3
EP 16
DI 10.1007/s13735-018-0147-1
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GB9SN
UT WOS:000429414200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, JC
   Hua, Y
   Yang, YY
   Kou, HW
AF Wang, Jiachen
   Hua, Yan
   Yang, Yingyun
   Kou, Hongwei
TI SPSD: Similarity-preserving self-distillation for video-text retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video-text alignment; Cross-modality; Knowledge distillation;
   Transformer; Contrastive learning
AB Most of existing methods solve cross-modal video and text retrieval via coarse-grained similarity computation based on global representations or fine-grained cross-modal interaction. The former misses sufficient information, while the latter suffers from inferior efficiency in inference. Furthermore, hierarchical features of transformer have not been fully utilized in cross-modal contrastive learning. In this paper, we propose similarity-preserving self-distillation method (SPSD) to achieve video and text alignment by cross-granularity and cross-layer ways. For cross-granularity self-distillation, fine-grained cross-modal similarity based on video and text token-wise interaction is transferred to coarse-grained similarity based on global video and text representations. To utilize hierarchical features of deep video and text transformer encoders, we propose cross-layer self-distillation by regarding cross-modal similarity based on semantic features as teacher to provide soft label for the similarity learning based on low-level features. Besides, we construct hierarchical contrastive loss and cross-granularity self-distillation loss at both feature and semantic levels for training transformer-based video and text encoders. SPSD sufficiently utilizes the fine-grained cross-modal interaction and hierarchical transformer features by generating distillation signals through network itself in training stage. In retrieval inference, cross-modal similarity computation between video and text is based on semantic-level global embeddings. Our SPSD achieves outstanding performance for video-text retrieval on MSRVTT, ActivityNet and LSMDC datasets. Our code is available at https://github.com/Macro-1998/SPSD/.
C1 [Wang, Jiachen] Zhihu, A5 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Hua, Yan; Yang, Yingyun; Kou, Hongwei] Commun Univ China, Sch Informat & Commun Engn, 1 Dingfuzhuang East St, Beijing 100024, Peoples R China.
C3 Communication University of China
RP Hua, Y (corresponding author), Commun Univ China, Sch Informat & Commun Engn, 1 Dingfuzhuang East St, Beijing 100024, Peoples R China.
EM huayan@cuc.edu.cn
FU National Key Research and Development Program of China [2020YFB1406800]
FX This work was funded by National Key Research and Development Program of
   China (Grant No.2020YFB1406800).
CR [Anonymous], 2023, INT C LEARN REPR
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Peters ME, 2018, Arxiv, DOI arXiv:1808.08949
   Gabeur Valentin, 2020, P EUR C COMP VIS, V12349, P214, DOI [10.48550/arXiv.2007.10639, DOI 10.48550/ARXIV.2007.10639]
   Gao YZ, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2023, P76, DOI 10.1145/3591106.3592238
   Ging S, 2020, 34 C NEURAL INFORM P
   Gorti Satya Krishna, 2022, P IEEE CVF C COMP VI, P5006
   Hao YR, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4143
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   Hinton G., 2015, COMPUT SCI, V2
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Huang HY, 2019, Arxiv, DOI arXiv:1909.00964
   Huang PY, 2021, INT C LEARNING REPRE
   Huang Siteng, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P6565, DOI 10.1109/CVPR52729.2023.00635
   Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849
   Ji KX, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P949, DOI 10.1145/3477495.3531960
   Ji M, 2021, PROC CVPR IEEE, P10659, DOI 10.1109/CVPR46437.2021.01052
   Ji Z., 2021, INT JOINT C ART INT, P765, DOI DOI 10.24963/IJCAI.2021/106
   Jiang H., 2022, arXiv
   Jiang J, 2022, IEEE Access
   Jin M, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108354
   Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Lample G, 2019, Arxiv, DOI arXiv:1901.07291
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li J., 2022, P INT JOINT C ARTIFI, P3215, DOI DOI 10.24963/IJCAI.2022/446
   Liu S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11895, DOI 10.1109/ICCV48922.2021.01170
   Liu Y, 2020, Arxiv, DOI arXiv:1907.13487
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu JS, 2019, ADV NEUR IN, V32
   Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Qiao YF, 2019, Arxiv, DOI arXiv:1904.07531
   Radford A, 2021, PR MACH LEARN RES, V139
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Su Weijie, 2020, ICLR
   Tan H, 2019, C EMP METH NAT LANG, DOI [10.18653/v1/D19-1514, DOI 10.18653/V1/D19-1514]
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Tian Y., 2020, Contrastive representation distillation
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang HR, 2022, LECT NOTES COMPUT SC, V13696, P700, DOI 10.1007/978-3-031-20059-5_40
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Wang XH, 2021, PROC CVPR IEEE, P5075, DOI 10.1109/CVPR46437.2021.00504
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yang JW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11542, DOI 10.1109/ICCV48922.2021.01136
   Yao LW, 2021, Arxiv, DOI arXiv:2111.07783
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhu JG, 2021, PROC CVPR IEEE, P9256, DOI 10.1109/CVPR46437.2021.00914
   Zhu L., 2020, P IEEE CVF C COMP VI, DOI 10.1109/CVPR42600.2020.00877
   Zolfaghari M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1430, DOI 10.1109/ICCV48922.2021.00148
NR 56
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 32
DI 10.1007/s13735-023-00298-1
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q4DO4
UT WOS:001057042200001
DA 2024-07-18
ER

PT J
AU Nejad, EM
   Affendey, LS
   Latip, RB
   Bin Ishak, I
   Banaeeyan, R
AF Nejad, Elaheh Mahraban
   Affendey, Lilly Suriani
   Latip, Rohaya Binti
   Bin Ishak, Iskandar
   Banaeeyan, Rasoul
TI Transferred Semantic Scores for Scalable Retrieval of Histopathological
   Breast Cancer Images
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Breast cancer retrieval; Transferred semantic score; Deep convolutional
   neural network; Histopathological image
ID FEATURES; SCALE
AB Content-based medical image retrieval (CBMIR) is an active field of research and a complementary decision support tool for the diagnosis of breast cancer. Current CBMIR systems employ hand-engineered image descriptors which are not effective enough at retrieval phase. Besides this drawback, the so-called semantic gap in the CBMIR is not still addressed leaving the room for further improvements. To fill in the two mentioned existing gaps, we proposed a new retrieval method which exploited a deep pre-trained convolutional neural network model to extract class-specific and patient-specific tumorous descriptor to firstly train a binary breast cancer classifier and then a multi-patient classifier aiming for reducing dimensions of the raw deeply transferred features and obtaining semantic scores which significantly enhanced the performance in terms of mean average precision. We evaluated the method on scalable BreakHis dataset of histopathological breast cancer images. After conducting five sets of experiments, results demonstrated the superior effectiveness of the proposed semantic-driven retrieval methods by means of increased mean average precision and decreased dimensionality and retrieval time. In overall, an improvement of 29.03% was obtained by the proposed class-driven semantic retrieval method.
C1 [Nejad, Elaheh Mahraban; Affendey, Lilly Suriani; Latip, Rohaya Binti; Bin Ishak, Iskandar] Univ Putra Malaysia, Fac Comp Sci & Informat Technol, Serdang, Malaysia.
   [Banaeeyan, Rasoul] Multimedia Univ, Fac Engn, Cyberjaya, Malaysia.
C3 Universiti Putra Malaysia; Multimedia University
RP Nejad, EM (corresponding author), Univ Putra Malaysia, Fac Comp Sci & Informat Technol, Serdang, Malaysia.
EM mahrabannejad@gmail.com; lilly@upm.edu.my; rohayalt@upm.edu.my;
   iskandar_i@upm.edu.my; banaeeyan@gmail.com
RI Latip, Rohaya/ABB-9475-2021
CR Ahmad J, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0875-4
   Ahmad J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0836-y
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P20271, DOI 10.1007/s11042-017-5453-8
   Boomilingam T, 2017, MULTIMED TOOLS APPL, V76, P21729, DOI 10.1007/s11042-016-3969-y
   Conjeti  S., 2017, ARXIV170305724
   Das P, 2017, INT J MULTIMED INF R, V6, P271, DOI 10.1007/s13735-017-0135-x
   Escalera S, 2009, PATTERN RECOGN LETT, V30, P285, DOI 10.1016/j.patrec.2008.10.002
   Jenitta A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0799-z
   Jiang ML, 2015, I S BIOMED IMAGING, P276, DOI 10.1109/ISBI.2015.7163867
   Kieffer B, 2017, ARXIV171005726
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li WB, 2017, SIGNAL PROCESS-IMAGE, V59, P131, DOI 10.1016/j.image.2017.06.013
   Liu JJ, 2017, IEEE T CIRC SYST VID, V27, P2450, DOI 10.1109/TCSVT.2016.2592329
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Shah A, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217162
   Shi XS, 2017, MED IMAGE ANAL, V42, P117, DOI 10.1016/j.media.2017.07.009
   Siegel R, 2012, CA-CANCER J CLIN, V62, P10, DOI 10.3322/caac.20138
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Srikar E, 2016, CBIR SIFT BASED COMP
   Tang QL, 2018, J DIGIT IMAGING, V31, P107, DOI 10.1007/s10278-017-0017-z
   Varga D, 2016, IEEE SYS MAN CYBERN, P2636, DOI 10.1109/SMC.2016.7844637
   Wu G, 2015, PATCH BASED TECHNIQU
   Yadav P, 2019, CLUSTER COMPUT, V22, P1345, DOI 10.1007/s10586-017-1625-6
   Zare MR, 2016, PACIS 13, P13
   Zhang F, 2016, NEUROCOMPUTING, V177, P75, DOI 10.1016/j.neucom.2015.11.008
   Zhang XF, 2015, I S BIOMED IMAGING, P1288, DOI 10.1109/ISBI.2015.7164110
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zhao JJ, 2017, J COMPUT SCI TECH-CH, V32, P457, DOI 10.1007/s11390-017-1736-9
NR 31
TC 12
Z9 12
U1 1
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD NOV
PY 2018
VL 7
IS 4
BP 241
EP 249
DI 10.1007/s13735-018-0157-z
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GX5SL
UT WOS:000447810500004
DA 2024-07-18
ER

PT J
AU Guo, YM
   Liu, Y
   Georgiou, T
   Lew, MS
AF Guo, Yanming
   Liu, Yu
   Georgiou, Theodoros
   Lew, Michael S.
TI A review of semantic segmentation using deep neural networks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Image segmentation; Computer vision; Deep learning; Convolutional neural
   networks; Machine learning
ID IMAGE
AB During the long history of computer vision, one of the grand challenges has been semantic segmentation which is the ability to segment an unknown image into different parts and objects (e. g., beach, ocean, sun, dog, swimmer). Furthermore, segmentation is even deeper than object recognition because recognition is not necessary for segmentation. Specifically, humans can perform image segmentation without even knowing what the objects are (for example, in satellite imagery or medical X-ray scans, there may be several objects which are unknown, but they can still be segmented within the image typically for further investigation). Performing segmentation without knowing the exact identity of all objects in the scene is an important part of our visual understanding process which can give us a powerful model to understand the world and also be used to improve or augment existing computer vision techniques. Herein this work, we review the field of semantic segmentation as pertaining to deep convolutional neural networks. We provide comprehensive coverage of the top approaches and summarize the strengths, weaknesses and major challenges.
C1 [Guo, Yanming; Liu, Yu; Georgiou, Theodoros; Lew, Michael S.] Leiden Univ, LIACS, Niels Bohrweg 1, NL-2333 CA Leiden, Netherlands.
C3 Leiden University - Excl LUMC; Leiden University
RP Lew, MS (corresponding author), Leiden Univ, LIACS, Niels Bohrweg 1, NL-2333 CA Leiden, Netherlands.
EM y.guo@liacs.leidenuniv.nl; y.liu@liacs.leidenuniv.nl;
   t.georgiou@liacs.leidenuniv.nl; m.s.k.lew@liacs.leidenuniv.nl
CR Aly Ashraf A., 2011, International Journal of Computer Science & Information Technology, V3, P99, DOI 10.5121/ijcsit.2011.3509
   [Anonymous], MMM
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2016, ECCV
   [Anonymous], 2016, ECCV
   [Anonymous], MIR
   [Anonymous], 2007, HUM-COMPUT INTERACT
   [Anonymous], 2015, ICLR
   [Anonymous], 2015, ICCV
   [Anonymous], 2014, ECCV
   [Anonymous], 2015, ICCV
   [Anonymous], 2014, CVPR
   [Anonymous], ICLR WORKSHOP
   [Anonymous], 2015, P 2015 IEEE C COMPUT
   [Anonymous], HCI WORKSHOP
   [Anonymous], 2015, ICCV
   [Anonymous], 2017, IEEE T PATTERN ANAL
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2016, NIPS
   [Anonymous], 2015, ICLR WORKSHOP
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, ECCV
   [Anonymous], 2015, ICCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, ECCV
   [Anonymous], CVPR
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Atmosukarto I, 2013, INT J MULTIMED INF R, V2, P103, DOI 10.1007/s13735-012-0015-3
   Boyle, 2014, CENGAGE LEARNING
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chatfield K, 2015, INT J MULTIMED INF R, V4, P75, DOI 10.1007/s13735-015-0077-0
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Girshick R., 2013, IEEE Comput. Soc., P580
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Ilea DE, 2011, PATTERN RECOGN, V44, P2479, DOI 10.1016/j.patcog.2011.03.005
   Khan Muhammad Waseem, 2014, International Journal of Future Computer and Communication, V3, P89, DOI 10.7763/IJFCC.2014.V3.274
   Krahenbuhl P., 2011, NIPS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin G., 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Liu Siqi, 2016, P IEEE C COMP VIS PA
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallik A, 2012, INT J MULTIMED INF R, V1, P249, DOI 10.1007/s13735-012-0021-5
   Muthukrishnan R., 2011, International Journal of Computer Science & Information Technology, V3, P259, DOI 10.5121/ijcsit.2011.3620
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Patil DD., 2013, IJCSMC, V2, P22
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Shimoda Wataru, 2016, ECCV
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vantaram SR, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.040901
   Wei YC, 2016, PATTERN RECOGN, V59, P234, DOI 10.1016/j.patcog.2016.01.015
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yu P, 2012, IEEE T GEOSCI REMOTE, V50, P1302, DOI 10.1109/TGRS.2011.2164085
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zuva T, 2011, CANADIAN J IMAGE PRO, V2, P20
NR 63
TC 402
Z9 430
U1 27
U2 265
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2018
VL 7
IS 2
BP 87
EP 93
DI 10.1007/s13735-017-0141-z
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GR5AE
UT WOS:000442633600001
OA hybrid, Green Published
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Ravat, RS
   Verma, Y
AF Ravat, Rajvardhan Singh
   Verma, Yashaswi
TI A retrieval-based approach for diverse and image-specific adversary
   selection
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Adversarial attack; Deep CNN; Diversity; Determinantal point process
AB While deep neural network-based models have demonstrated compelling performance on various tasks in computer vision and other fields, they have been found to be vulnerable to adversarial attacks. Particularly, deep convolutional neural network (CNN)-based models can be easily fooled by adding a small quasi-imperceptible perturbation to the input, thus resulting in significant drop in prediction accuracies. While most of the previous works have focused on generating one adversary/perturbation per model, it was recently shown that it is possible to learn a continuous distribution over adversarial perturbations for a model. Building upon this work, in this paper, we propose a new technique for image-specific adversary selection and treat it as a retrieval task. The proposed technique utilizes a learned model that ranks the perturbations in a given set of perturbations based on their ability to fool with respect to a given sample. This model is a conditional determinantal point process model that also explicitly induces diversity among the retrieved perturbations. We conduct experiments on the ImageNet dataset using four popular deep CNN image classification models, and demonstrate that the proposed method consistently achieves state-of-the-art fooling rates.
C1 [Ravat, Rajvardhan Singh] Circle Life Healthcare Pvt Ltd, New Delhi, India.
   [Verma, Yashaswi] Indian Inst Technol Jodhpur, Dept Comp Sci & Engn, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Verma, Y (corresponding author), Indian Inst Technol Jodhpur, Dept Comp Sci & Engn, Jodhpur, Rajasthan, India.
EM yashaswi@iitj.ac.in
RI Verma, Yashaswi/GXF-3950-2022
OI Verma, Yashaswi/0000-0003-2317-2641
CR [Anonymous], ARXIV170309202 CORR
   [Anonymous], LEARNING ATTACK ADVE
   [Anonymous], INT C MACH LEARN
   [Anonymous], 2014, ARXIV14125068 CORR
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], ARXIV161101236 CORR
   [Anonymous], ADV INFORM SYSTEMS E
   Biggio B, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600027
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kulesza A., 2011, UAI, P419
   Kulesza A, 2012, FOUND TRENDS MACH LE, V5, P123, DOI 10.1561/2200000044
   MACCHI O, 1975, ADV APPL PROBAB, V7, P83, DOI 10.2307/1425855
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Mopuri K.R., 2017, BRIT MACH VIS C
   Mopuri KR, 2018, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2018.00084
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Szegedy Christian, 2014, INT C LEARN REPR INT
   Tramer F., 2018, ICLR 18
   Tsipras Dimitris, 2018, 6 INT C LEARN REPR I
   Wu B., 2017, IEEE C COMP VIS PATT
NR 25
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2020
VL 9
IS 2
SI SI
BP 125
EP 133
DI 10.1007/s13735-019-00177-8
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ4GS
UT WOS:000534963100005
DA 2024-07-18
ER

PT J
AU Nguyen, VT
   Le, DD
   Tran, MT
   Nguyen, TV
   Ngo, TD
   Satoh, S
   Duong, DA
AF Vinh-Tiep Nguyen
   Duy Dinh Le
   Minh-Triet Tran
   Nguyen, Tam V.
   Thanh Duc Ngo
   Satoh, Shin'ichi
   Duc Anh Duong
TI Video instance search via spatial fusion of visual words and object
   proposals
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video instance search; Bag-of-visual-word model; Object proposal;
   Spatial fusion
ID SCALE; GEOMETRY
AB Most popular systems for object instance search are based on the bag-of-visual-word model. The inherent weaknesses of this standard model such as quantization error, unstructured representation, burstiness phenomenon are to some extent solved. However, it has a serious problem of searching small objects on a database with cluttered background. In many situations, even the irrelevant objects which share the same texture or shape with a query object get higher score than relevant ones. To overcome this problem, we propose a novel fusion method to significantly boost the accuracy of instance search systems. Firstly, we use the state-of-the-art object detector with denser feature for finding object bounding box and similarity score. Secondly, to exploit the spatial relationship of each visual word with an object proposal, a detected area that might contain a query object, we define three categories of visual word pairs, i.e., discriminative, weak relevant, and context inferred ones. Finally, we propose a new re-ranking scheme with three weighting functions corresponding to the three categories of visual word pairs to compute the final similarity score between a query topic and a video shot. To illustrate the efficiency of the proposed method, we conduct experiments on datasets which have a wide variety of types of query objects. Experimental results on TRECVID Instance Search datasets (INS2013 and INS2014) show the superiority of our proposed method over the state-of-the-art approaches.
C1 [Vinh-Tiep Nguyen; Duy Dinh Le; Thanh Duc Ngo; Duc Anh Duong] Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Minh-Triet Tran] Univ Sci, Ho Chi Minh City, Vietnam.
   [Nguyen, Tam V.] Univ Dayton, Dayton, OH 45469 USA.
   [Satoh, Shin'ichi] NII, Tokyo, Japan.
C3 University System of Ohio; University of Dayton; Research Organization
   of Information & Systems (ROIS); National Institute of Informatics (NII)
   - Japan
RP Nguyen, VT (corresponding author), Univ Informat Technol, Ho Chi Minh City, Vietnam.
EM tiepnv@uit.edu.vn; duyld@uit.edu.vn; tmtriet@fit.hcmus.edu.vn;
   tamnguyen@udayton.edu; thanhnd@uit.edu.vn; satoh@nii.ac.jp;
   ducda@uit.edu.vn
RI Nguyen, Tam/HSG-3007-2023; Nguyen, Tam/AAU-6504-2020; Tran,
   Minh-Triet/HTO-6586-2023
OI Nguyen, Tam/0000-0003-0236-7992; Nguyen, Vinh-Tiep/0000-0003-4260-7874;
   Tran, Minh-Triet/0000-0003-3046-3041
FU Vietnam National University Ho Chi Minh City (VNU-HCM) [B2017-26-01];
   University of Dayton under STEM Catalyst Grant
FX This research is funded by Vietnam National University Ho Chi Minh City
   (VNU-HCM) under grant number B2017-26-01 and University of Dayton under
   STEM Catalyst Grant.
CR [Anonymous], 2014, BRIT MACH VIS C
   [Anonymous], 2015, MOL SIMUL
   [Anonymous], TRECVID
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P TRECVID 2013
   [Anonymous], 2007, CVPR
   [Anonymous], P ACM C INT C MULT R
   [Anonymous], 2015, NEURAL INFORM PROCES
   [Anonymous], 2008, CVPR
   Araujo A, 2017, IEEE T CIRCUITS SYST
   Awad G, 2017, INT J MULTIMED INF R, V6, P1, DOI 10.1007/s13735-017-0121-3
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Li HL, 2017, IEEE ACCESS, V5, P13665, DOI 10.1109/ACCESS.2017.2729943
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Mohedano E, 2017, DEEP LEARN IMAGE PRO, V31, P137
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Over P., 2014, Proceedings of TRECVID 2014
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Pratikakis I., 2016, P 3DOR, P79
   Radenovi F, 2018, ARXIV180311285
   Radenovi F, 2018, IEEE T PATTERN ANAL
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Salvador A., 2016, P IEEE C COMP VIS PA
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007
   Tolias G, 2011, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2011.6126427
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Zhou WG, 2015, IEEE T IMAGE PROCESS, V24, P967, DOI 10.1109/TIP.2015.2389624
   Zhou X, 2014, IEEE IMAGE PROC, P3008, DOI 10.1109/ICIP.2014.7025608
   Zhu C-Z, 2014, NAGOYA U TRECVID 201
   Zhu CZ, 2013, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2013.214
NR 38
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2019
VL 8
IS 3
BP 181
EP 192
DI 10.1007/s13735-019-00172-z
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS8RG
UT WOS:000482416600005
OA Bronze
DA 2024-07-18
ER

PT J
AU Hazarika, A
   Dutta, L
   Boro, M
   Barthakur, M
   Bhuyan, M
AF Hazarika, Anil
   Dutta, Lachit
   Boro, Meenakshi
   Barthakur, Mausumi
   Bhuyan, Manabendra
TI An automatic feature extraction and fusionmodel: application to
   electromyogram (EMG) signal classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Multiple view; Fusion; Canonical correlation analysis (CCA); Motor unit
   action potential (MUAP) Electromyography (EMG)
ID CANONICAL CORRELATION-ANALYSIS; DECISION-SUPPORT-SYSTEM; MUAP
   CLASSIFICATION; DIAGNOSIS; RECOGNITION; EXTENSIONS; SCHEME; DWT
AB In this paper, we present a real-time feature extraction and fusion model for an automated staging of electromyogram signals-generalizing canonical correlation analysis (CCA). The proposed method is capable of capturing multiple view information (i.e., feature matrices) generated from signals. Our algorithm employs an optimization technique to derive sets of statistical features among the paired views based on which possible variations of signals have been demonstrated. Next, discrete wavelet transformation is performed on multiple views to create domain independent views which are then subjected to CCA optimization. The estimated two sets of statistically independent features from two independent analysis are concentrated through two recently proposed fusion models, and then, we evaluate global feature matrices. Further it is validated statistically for p < 0.05. The proposed algorithm is then analyzed and compared with state-of-the-art methods. Results indicate that the proposed approach outperforms many other methods in terms of accuracy, specificity and sensitivity, which are 98.80, 99.0 and 98.0%, respectively. Thus, the proposed algorithm is suitable for large-scale applications and expedite diagnosis research.
C1 [Hazarika, Anil; Dutta, Lachit; Boro, Meenakshi; Bhuyan, Manabendra] Tezpur Univ, Dept Elect & Commun Engn, Sonitpur, Assam, India.
   [Barthakur, Mausumi] Guwahati Neurol Res Ctr, Dept Neurophysiol, Gauhati, Assam, India.
C3 Tezpur University
RP Hazarika, A (corresponding author), Tezpur Univ, Dept Elect & Commun Engn, Sonitpur, Assam, India.
EM anilhazarika8@gmail.com; lachit@tezu.ernet.in;
   meenakshi.boro013@gmail.com; mausumi@tezu.ernet.in; manab@tezu.ernet.in
RI Dutta, Lachit/J-9677-2019
OI Dutta, Lachit/0000-0002-1806-2061
CR Abel EW, 2006, IEEE T BIO-MED ENG, V53, P219, DOI 10.1109/TBME.2005.862548
   Barthakur M., 2013, P ACEEE INT C ADV SI P ACEEE INT C ADV SI, P706
   Barthakur M, 2015, THESIS
   Bartos M., 2014, P IEEE INT C P REC A, P1
   Bentaleb Y., 2010, INT J CONT ENG SCI, V3, P285
   Brüser C, 2013, IEEE J BIOMED HEALTH, V17, P162, DOI 10.1109/TITB.2012.2225067
   Chu JU, 2007, IEEE-ASME T MECH, V12, P282, DOI 10.1109/TMECH.2007.897262
   Correa NM, 2010, IEEE J-STSP, V2, P39
   De Clercq W, 2006, IEEE T BIO-MED ENG, V53, P2583, DOI 10.1109/TBME.2006.879459
   Dobrowolski AP, 2012, COMPUT METH PROG BIO, V107, P393, DOI 10.1016/j.cmpb.2010.12.006
   Doulah ABMSU, 2014, IEEE T BIOMED CIRC S, V8, P155, DOI 10.1109/TBCAS.2014.2309252
   Dutta L., 2016, SENS TRANSDUCERS, V202, P38
   Englehart K, 2001, IEEE T BIO-MED ENG, V48, P302, DOI 10.1109/10.914793
   Fu Y, 2009, P ACM INT C CONT BAS, P127
   Gokgoz E, 2015, BIOMED SIGNAL PROCES, V18, P138, DOI 10.1016/j.bspc.2014.12.005
   Gokgoz E, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0031-3
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hassan AR, 2016, BIOCYBERN BIOMED ENG, V36, P256, DOI 10.1016/j.bbe.2015.11.003
   Hassan M, 2011, IEEE T BIO-MED ENG, V58, P2441, DOI 10.1109/TBME.2011.2151861
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Johnson R.A., 2007, Applied multivariate statistial analysis, Vsixth
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Kamali T, 2014, IEEE T NEUR SYS REH, V22, P191, DOI 10.1109/TNSRE.2013.2291322
   Katsis CD, 2007, COMPUT BIOL MED, V37, P1232, DOI 10.1016/j.compbiomed.2006.11.010
   Kaur Gurmanik, 2009, WSEAS Transactions on Signal Processing, V5, P379
   Khushaba RN, 2014, IEEE T NEUR SYS REH, V22, P745, DOI 10.1109/TNSRE.2014.2304470
   Lin ZL, 2006, IEEE T BIO-MED ENG, V53, P2610, DOI 10.1109/TBME.2006.886577
   Liu MX, 2016, IEEE T BIO-MED ENG, V63, P1473, DOI 10.1109/TBME.2015.2496233
   Naik GR, 2016, IEEE T NEUR SYS REH, V24, P734, DOI 10.1109/TNSRE.2015.2454503
   Nikolic M., 2001, Detailed analysis of clinical electromyography signals EMG decomposition, findings and firing pattern analysis in controls and patients with myopathy and amytrophic lateral sclerosis
   Peng Y, 2010, NEURAL PROCESS LETT, V31, P1, DOI 10.1007/s11063-009-9123-3
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Shen XB, 2015, NEURAL PROCESS LETT, V42, P301, DOI 10.1007/s11063-014-9358-5
   Shen XB, 2014, J VIS COMMUN IMAGE R, V25, P1894, DOI 10.1016/j.jvcir.2014.09.004
   Subasi A, 2015, SIGNAL IMAGE VIDEO P, V9, P399, DOI 10.1007/s11760-013-0480-z
   Subasi A, 2013, COMPUT BIOL MED, V43, P576, DOI 10.1016/j.compbiomed.2013.01.020
   Subasi A, 2012, COMPUT BIOL MED, V42, P806, DOI 10.1016/j.compbiomed.2012.06.004
   Subasi A, 2012, APPL SOFT COMPUT, V12, P2188, DOI 10.1016/j.asoc.2012.03.035
   Sun BY, 2010, IEEE T NEURAL NETWOR, V21, P163, DOI 10.1109/TNN.2009.2036363
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Yousefi J, 2014, COMPUT BIOL MED, V51, P1, DOI 10.1016/j.compbiomed.2014.04.018
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Zhang C, 2014, IEEE T INTELL TRANSP, V15, P168, DOI 10.1109/TITS.2013.2275192
NR 51
TC 13
Z9 15
U1 0
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2018
VL 7
IS 3
BP 173
EP 186
DI 10.1007/s13735-018-0149-z
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HI5SF
UT WOS:000456513600003
DA 2024-07-18
ER

PT J
AU Verma, Y
   Jha, A
   Jawahar, CV
AF Verma, Yashaswi
   Jha, Abhishek
   Jawahar, C., V
TI Cross-specificity: modelling data semantics for cross-modal matching and
   retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cross-media analysis; Semantic matching; Cross-modal retrieval
ID IMAGES
AB While dealing with multi-modal data such as pairs of images and text, though individual samples may demonstrate inherent heterogeneity in their content, they are usually coupled with each other based on some higher-level concepts such as their categories. This shared information can be useful in measuring semantics of samples across modalities in a relative manner. In this paper, we investigate the problem of analysing the degree of specificity in the semantic content of a sample in one modality with respect to semantically similar samples in another modality. Samples that have high similarity with semantically similar samples from another modality are considered to be specific, while others are considered to be relatively ambiguous. To model this property, we propose a novel notion of "cross-specificity". We present two mechanisms to measure cross-specificity: one based on human judgement and other based on an automated approach. We analyse different aspects of cross-specificity and demonstrate its utility in cross-modal retrieval task. Experiments show that though conceptually simple, it can benefit several existing cross-modal retrieval techniques and provide significant boost in their performance.
C1 [Verma, Yashaswi] Indian Inst Sci, Bengaluru, India.
   [Jha, Abhishek; Jawahar, C., V] IIIT Hyderabad, Hyderabad, India.
C3 Indian Institute of Science (IISC) - Bangalore; International Institute
   of Information Technology Hyderabad
RP Verma, Y (corresponding author), Indian Inst Sci, Bengaluru, India.
EM yashaswiv@iisc.ac.in
RI Verma, Yashaswi/GXF-3950-2022; Jawahar, C.V./ACR-3102-2022
OI Verma, Yashaswi/0000-0003-2317-2641; Jawahar, C.V./0000-0001-6767-7057;
   Jha, Abhishek/0000-0002-0350-2474; Jha, Abhishek/0000-0001-9161-0450
FU Department of Science and Technology (India)
FX YV would like to thank the Department of Science and Technology (India)
   for the INSPIRE Faculty Award.
CR [Anonymous], 2009, ICCV
   [Anonymous], 2012, ECCV
   [Anonymous], JMLR
   [Anonymous], TACL
   [Anonymous], CVPR
   [Anonymous], 2012, CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], NIPS
   [Anonymous], 2013, ICML
   [Anonymous], CVPR
   [Anonymous], 2014, AISTATS
   [Anonymous], 2010, P 18 INT C MULT 2010
   Chen X, 2012, IEEE T MULTIMEDIA, V14, P3, DOI 10.1109/TMM.2011.2167223
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Spain M, 2011, INT J COMPUT VISION, V91, P59, DOI 10.1007/s11263-010-0376-0
   Verma Y, 2017, COMPUT VIS IMAGE UND, V154, P48, DOI 10.1016/j.cviu.2016.10.001
NR 23
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2018
VL 7
IS 2
BP 139
EP 146
DI 10.1007/s13735-017-0138-7
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GR5AE
UT WOS:000442633600005
DA 2024-07-18
ER

PT J
AU Kim, JH
   Hao, F
   Leung, CKS
   Nasridinov, A
AF Kim, Jeong-Hun
   Hao, Fei
   Leung, Carson Kai-Sang
   Nasridinov, Aziz
TI Cluster-guided temporal modeling for action recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Keyframe selection; Temporal modeling; Temporal redundancy; Data
   clustering; Action recognition
AB Action recognition is a video understanding task that is carried out to recognize an action of an object in a video. In order to recognize the action, it is necessary to extract motion information through temporal modeling. However, videos typically contain high temporal redundancy, such as iterative events and adjacent frames. This high temporal redundancy weakens information related to actual action, making it difficult for the final classifier to recognize the action. In this article, we focus on preserving helpful information for action recognition by reducing the high temporal redundancy in videos. To achieve this goal, we propose a novel frame selection method called cluster-guided frame selection (CluFrame). Specifically, CluFrame compresses an input video into keyframes of clusters discovered by applying k-means clustering to frame-wise features extracted from pre-trained 2D-CNNs in the temporal compression (TC) module. In addition, CluFrame selects keyframes related to the action of the input video by optimizing the TC module based on the action recognition results. Experimental results on five benchmark datasets demonstrate that CluFrame addresses the high temporal redundancy in the video and achieves action recognition accuracy improvement over existing action recognition methods by up to 6.6% and by about 0.7% compared to state-of-the-art frame selection methods.
C1 [Kim, Jeong-Hun; Nasridinov, Aziz] Chungbuk Natl Univ, Dept Comp Sci, Cheongju 28644, South Korea.
   [Hao, Fei] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
   [Leung, Carson Kai-Sang] Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
C3 Chungbuk National University; Shaanxi Normal University; University of
   Manitoba
RP Nasridinov, A (corresponding author), Chungbuk Natl Univ, Dept Comp Sci, Cheongju 28644, South Korea.; Leung, CKS (corresponding author), Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
EM Carson.leung@umanitoba.ca; aziz@chungbuk.ac.kr
RI Leung, Carson/M-8682-2013
OI Leung, Carson/0000-0002-7541-9127
FU Basic Science Research Program through the National Research Foundation
   of Korea [2021R1I1A3042145]; MSIT (Ministry of Science and ICT), Korea,
   under the Grand Information Technology Research Center support program
   [IITP-2023-2020-0-01462]
FX This article is funded by the Basic Science Research Program through the
   National Research Foundation of Korea (Grant No: 2021R1I1A3042145). This
   research was supported by the MSIT (Ministry of Science and ICT), Korea,
   under the Grand Information Technology Research Center support program
   (IITP-2023-2020-0-01462) supervised by the IITP (Institute for
   Information & communications Technology Planning & Evaluation).
CR Nguyen A, 2018, IEEE INT CONF ROBOT, P3782
   Bastianelli E, 2016, APPL INTELL, V44, P43, DOI 10.1007/s10489-015-0695-5
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Choi S, 2021, AAAI CONF ARTIF INTE, V35, P1166, DOI 10.5626/KTCP.2021.27.1.7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong WK, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108797
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Fan HH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P705
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gao RH, 2020, PROC CVPR IEEE, P10454, DOI 10.1109/CVPR42600.2020.01047
   Girdhar R., 2017, PROC CVPR IEEE, P971, DOI DOI 10.1109/CVPR.2017.337
   Gowda SN, 2021, AAAI CONF ARTIF INTE, V35, P1451
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LJ, 2021, APPL INTELL, V51, P2128, DOI 10.1007/s10489-020-01933-8
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Korbar B, 2019, IEEE I CONF COMP VIS, P6241, DOI 10.1109/ICCV.2019.00633
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CM, 2023, APPL INTELL, V53, P4784, DOI 10.1007/s10489-022-03813-9
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu C, 2021, APPL INTELL, V51, P7903, DOI 10.1007/s10489-021-02280-y
   Mahdisoltani F, 2018, Arxiv, DOI arXiv:1804.09235
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pers J, 2010, PATTERN RECOGN LETT, V31, P1369, DOI 10.1016/j.patrec.2010.03.024
   Segal S, 2020, P C ROB LEARN C ROB, P973, DOI [10.48550/arXiv.2011.06165, DOI 10.48550/ARXIV.2011.06165]
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun L, 2017, IEEE I CONF COMP VIS, P2166, DOI 10.1109/ICCV.2017.236
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang P, 2019, PATTERN RECOGN, V91, P357, DOI 10.1016/j.patcog.2019.03.002
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wilson Justin, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10045, DOI 10.1109/ICRA40945.2020.9197528
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Wu S., 2010, Advances in Neural Information Processing Systems, P2478
   Wu ZX, 2019, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2019.00137
   Xiao JB, 2021, PROC CVPR IEEE, P9772, DOI 10.1109/CVPR46437.2021.00965
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Zhang JB, 2017, AAAI CONF ARTIF INTE, P1655
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu C, 2018, LECT NOTES COMPUT SC, V11209, P139, DOI 10.1007/978-3-030-01228-1_9
NR 61
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 15
DI 10.1007/s13735-023-00280-x
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M9QN6
UT WOS:001033488400001
DA 2024-07-18
ER

PT J
AU Mingyong, L
   Yewen, L
   Mingyuan, G
   Longfei, M
AF Mingyong, Li
   Yewen, Li
   Mingyuan, Ge
   Longfei, Ma
TI CLIP-based fusion-modal reconstructing hashing for large-scale
   unsupervised cross-modal retrieval
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Unsupervised cross-modal retrieval; Deep hashing; Autoencoder;
   Contrastive language-image pre-training
ID NETWORK
AB As multi-modal data proliferates, people are no longer content with a single mode of data retrieval for access to information. Deep hashing retrieval algorithms have attracted much attention for their advantages of efficient storage and fast query speed. Currently, the existing unsupervised hashing methods generally have two limitations: (1) Existing methods fail to adequately capture the latent semantic relevance and coexistent information from the different modality data, resulting in the lack of effective feature and hash encoding representation to bridge the heterogeneous and semantic gaps in multi-modal data. (2) Existing unsupervised methods typically construct a similarity matrix to guide the hash code learning, which suffers from inaccurate similarity problems, resulting in sub-optimal retrieval performance. To address these issues, we propose a novel CLIP-based fusion-modal reconstructing hashing for Large-scale Unsupervised Cross-modal Retrieval. First, we use CLIP to encode cross-modal features of visual modalities, and learn the common representation space of the hash code using modality-specific autoencoders. Second, we propose an efficient fusion approach to construct a semantically complementary affinity matrix that can maximize the potential semantic relevance of different modal instances. Furthermore, to retain the intrinsic semantic similarity of all similar pairs in the learned hash codes, an objective function for similarity reconstruction based on semantic complementation is designed to learn high-quality hash code representations. Sufficient experiments were carried out on four multi-modal benchmark datasets (WIKI, MIRFLICKR, NUS-WIDE, and MS COCO), and the proposed method achieves state-of-the-art image-text retrieval performance compared to several representative unsupervised cross-modal hashing methods.
C1 [Mingyong, Li; Yewen, Li; Mingyuan, Ge; Longfei, Ma] Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP Mingyong, L (corresponding author), Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.
EM limingyong@cqnu.edu.cn; 2021210516048@stu.cqnu.edu.cn;
   2021210516034@stu.cqnu.edu.cn; 2021210516063@stu.cqnu.edu.cn
OI Ge, Mingyuan/0000-0002-4094-0078; Ma, Longfei/0000-0002-5224-9196; Li,
   Yewen/0000-0001-8406-0606
FU National Natural Science foundation of China [62003065]; Science and
   Technology Project of Chongqing Education Commission of China
   [KJQN201900520]; Chongqing Normal University Fund [22XLB003]
FX AcknowledgementsThis work was partially supported by National Natural
   Science foundation of China (No: 62003065), Science and Technology
   Project of Chongqing Education Commission of China (KJQN201900520) and
   Chongqing Normal University Fund (NO. 22XLB003).
CR Bai S., 2017, P AAAI C ARTIFICIAL, P31
   Bai S, 2019, IEEE T PATTERN ANAL, V41, P1213, DOI 10.1109/TPAMI.2018.2828815
   Cao J., 2020, SPRINGER, P565
   Cheng QM, 2021, IEEE J-STARS, V14, P4284, DOI 10.1109/JSTARS.2021.3070872
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cong Bai, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P525, DOI 10.1145/3372278.3390711
   Dejie Yang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P44, DOI 10.1145/3372278.3390673
   Dubey SR, 2022, Arxiv, DOI arXiv:2109.12564
   Fan LX, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P825
   Gong QK, 2022, Arxiv, DOI arXiv:2201.05541
   Gu W, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/3323873.3325045
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kumar Shaishav, 2011, 22 INT JOINT C ART I
   Li C, 2019, AAAI CONF ARTIF INTE, P176
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1589, DOI 10.1145/3240508.3240684
   Liu S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1379, DOI 10.1145/3397271.3401086
   Lu JS, 2019, ADV NEUR IN, V32
   Lu X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1129, DOI 10.1145/3343031.3350999
   Mikriukov G., 2022, arXiv
   Radford A, 2021, PR MACH LEARN RES, V139
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen X, 2021, 2021 IEEE INT C MULT, P1
   Shi YF, 2022, IEEE T CIRC SYST VID, V32, P7255, DOI 10.1109/TCSVT.2022.3172716
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Su SP, 2019, IEEE I CONF COMP VIS, P3027, DOI 10.1109/ICCV.2019.00312
   Su WJ, 2020, Arxiv, DOI arXiv:1908.08530
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang XZ, 2020, NEUROCOMPUTING, V400, P255, DOI 10.1016/j.neucom.2020.03.019
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu J, 2021, AAAI CONF ARTIF INTE, V35, P4626
   Zeng Z., 2022, arXiv
   Zhang DL, 2023, IEEE T KNOWL DATA EN, V35, P6461, DOI 10.1109/TKDE.2022.3159131
   Zhang DL, 2021, LECT NOTES COMPUT SC, V13020, P524, DOI 10.1007/978-3-030-88007-1_43
   Zhang DL, 2023, IEEE T KNOWL DATA EN, V35, P1365, DOI 10.1109/TKDE.2021.3099125
   Zhang DL, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108343
   Zhang DL, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3446774
   Zhang DL, 2022, IEEE T CYBERNETICS, V52, P5947, DOI 10.1109/TCYB.2020.3032017
   Zhang J, 2018, AAAI CONF ARTIF INTE, P539
   Zhang PF, 2022, IEEE T MULTIMEDIA, V24, P466, DOI 10.1109/TMM.2021.3053766
   Zhang PF, 2021, WORLD WIDE WEB, V24, P563, DOI 10.1007/s11280-020-00859-y
   Zhang X, 2018, LECT NOTES COMPUT SC, V11219, P614, DOI 10.1007/978-3-030-01267-0_36
   Zhuo YX, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2022, P158, DOI 10.1145/3512527.3531381
NR 52
TC 1
Z9 1
U1 8
U2 31
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 2
DI 10.1007/s13735-023-00268-7
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9C2QR
UT WOS:000935268700001
DA 2024-07-18
ER

PT J
AU Cai, SL
   Wang, CP
   Ding, JJ
   Yu, J
   Fan, JP
AF Cai, Silin
   Wang, Changping
   Ding, Jiajun
   Yu, Jun
   Fan, Jianping
TI FDAM: full-dimension attention module for deep convolutional neural
   networks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Attention mechanism; Convolutional neural network; Image classification;
   Object recognition; Elo rating mechanism
AB The attention mechanism is an important component of cross-modal research. It can improve the performance of convolutional neural networks by distinguishing the informative parts of the feature map from the useless ones. Various kinds of attention are proposed by recent studies. Different attentions use distinct division method to weight each part of the feature map. In this paper, we propose a full-dimension attention module, which is a lightweight, fully interactive 3-D attention mechanism. FDAM generates 3-D attention maps for both spatial and channel dimensions in parallel and then multiplies them to the feature map. It is difficult to obtain discriminative attention map cell under channel interaction at a low computational cost. Therefore, we adapt a generalized Elo rating mechanism to generate cell-level attention maps. We store historical information with a slight amount of non-training parameters to spread the computation over each training iteration. The proposed module can be seamlessly integrated into the end-to-end training of the CNN framework. Experiments demonstrate that it outperforms many existing attention mechanisms on different network structures and datasets for computer vision tasks, such as image classification and object detection.
C1 [Cai, Silin; Wang, Changping] Hangzhou Dianzi Univ, Zhuoyue Honor Coll, 2 Main St, Hangzhou 310018, Zhejiang, Peoples R China.
   [Ding, Jiajun; Yu, Jun; Fan, Jianping] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, 2 Main St, Hangzhou 310018, Zhejiang, Peoples R China.
   [Ding, Jiajun] Hangzhou Dianzi Univ, Shangyu Inst Sci & Engn, Shangyu 312300, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; Hangzhou Dianzi
   University
RP Fan, JP (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, 2 Main St, Hangzhou 310018, Zhejiang, Peoples R China.
EM fanjianping@hdu.edu.cn
RI cai, silin/GZL-4344-2022
FU Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK219909299001-015]; Natural Science Foundation of China [62206082];
   National Undergraduate Training Program for Innovation and
   Entrepreneurship [202110336042, 2022R407A002]
FX The authors acknowledge the financial supported by the Fundamental
   Research Funds for the Provincial Universities of Zhejiang (Grant No.
   GK219909299001-015), the Natural Science Foundation of China (Grant No.
   62206082), National Undergraduate Training Program for Innovation and
   Entrepreneurship (Grant No. 202110336042) and Planted talent plan (Grant
   No. 2022R407A002).
CR Berg A., 2020, CHANCE, V33, P31, DOI [10.1080/09332480.2020.1820249, DOI 10.1080/09332480.2020.1820249]
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Elo A. E., 1978, The Rating of Chessplayers, Past and Present
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huddar MG, 2020, INT J MULTIMED INF R, V9, P103, DOI 10.1007/s13735-019-00185-8
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li J, 2022, INT J MULTIMED INF R, V11, P189, DOI 10.1007/s13735-021-00223-4
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Park J., 2018, ARXIV
   Pelánek R, 2016, COMPUT EDUC, V98, P169, DOI 10.1016/j.compedu.2016.03.017
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shojaei G, 2019, INT J MULTIMED INF R, V8, P241, DOI 10.1007/s13735-019-00180-z
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szczecinski L, 2020, J QUANT ANAL SPORTS, V16, P211, DOI 10.1515/jqas-2019-0102
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie JY, 2022, IEEE T PATTERN ANAL, V44, P8230, DOI 10.1109/TPAMI.2021.3102955
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang LX, 2021, PR MACH LEARN RES, V139
   Yang Z., 2020, P IEEECVF C COMPUTER, P11794
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zagoruyko S., 2016, ARXIV
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 46
TC 2
Z9 2
U1 6
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 599
EP 610
DI 10.1007/s13735-022-00248-3
EA NOV 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000880233600001
DA 2024-07-18
ER

PT J
AU Kumar, P
   Rawat, P
   Chauhan, S
AF Kumar, Pranjal
   Rawat, Piyush
   Chauhan, Siddhartha
TI Contrastive self-supervised learning: review, progress, challenges and
   future research directions
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review; Early Access
DE Contrastive learning; Self-supervised learning; Unsupervised learning;
   Data augmentation; Survey
ID REPRESENTATION; EMBEDDINGS
AB In the last decade, deep supervised learning has had tremendous success. However, its flaws, such as its dependency on manual and costly annotations on large datasets and being exposed to attacks, have prompted researchers to look for alternative models. Incorporating contrastive learning (CL) for self-supervised learning (SSL) has turned out as an effective alternative. In this paper, a comprehensive review of CL methodology in terms of its approaches, encoding techniques and loss functions is provided. It discusses the applications of CL in various domains like Natural Language Processing (NLP), Computer Vision, speech and text recognition and prediction. The paper presents an overview and background about SSL for understanding the introductory ideas and concepts. A comparative study for all the works that use CL methods for various downstream tasks in each domain is performed. Finally, it discusses the limitations of current methods, as well as the need for additional techniques and future directions in order to make meaningful progress in this area.
C1 [Kumar, Pranjal; Chauhan, Siddhartha] NIT Hamirpur, Hamirpur 177005, Himachal Prades, India.
   [Rawat, Piyush] Univ Petr & Energy Studies, Sch Comp Sci, Dept Syst, Dehra Dun 248007, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; University of Petroleum & Energy Studies (UPES)
RP Kumar, P (corresponding author), NIT Hamirpur, Hamirpur 177005, Himachal Prades, India.
EM pranjal@nith.ac.in; psh.rawat@gmail.com; sid@nith.ac.in
CR Afouras T, 2020, P EUR C COMP VIS, P208
   Al-Tahan H., 2021, PMLR, P2530
   Alayrac J.-B., 2020, NeurIPS, V33, P25
   Albelwi S, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040551
   [Anonymous], 2018, OPENAL BLOG
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73
   Arandjelovic Relja, 2018, P EUR C COMP VIS ECC, P435
   Arivazhagan N, 2019, Arxiv, DOI arXiv:1907.05019
   Aroca-Ouellette S, 2020, Arxiv, DOI arXiv:2010.01694
   Arora S., 2019, arXiv
   Asai A, 2020, Arxiv, DOI arXiv:1911.10470
   Asano Y., 2020, ADV NEURAL INFORM PR, V33, P4660
   Bachman P, 2019, ADV NEUR IN, V32
   Baevski A, 2020, Arxiv, DOI arXiv:1911.03912
   Baevski A, 2019, Arxiv, DOI arXiv:1903.07785
   Baevski A, 2020, Arxiv, DOI arXiv:1910.05453
   Baevski Alexei, 2020, Advances in neural information processing systems
   Bai YT, 2020, Arxiv, DOI arXiv:2011.13046
   Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhattacharjee Amrita, 2022, arXiv
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Bui ND, 2021, P 44 INT ACM SIGIR C, P511
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen M, 2020, PR MACH LEARN RES, V119
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen XL, 2020, Arxiv, DOI arXiv:2003.04297
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Chi ZW, 2021, Arxiv, DOI arXiv:2007.07834
   Chiu CC, 2022, Arxiv, DOI arXiv:2202.01855
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chuang Ching-Yao, 2020, ADV NEURAL INFORM PR, V33, P8765, DOI DOI 10.48550/ARXIV.2007.00224
   Chuang Gan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5589, DOI 10.1109/CVPR.2018.00586
   Chung YA, 2021, Arxiv, DOI [arXiv:2108.06209, DOI 10.48550/ARXIV.2108.06209]
   Deng J., 2009, IEEE C COMP VIS PATT
   Deng YT, 2020, Arxiv, DOI arXiv:2004.11714
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Hjelm RD, 2020, Arxiv, DOI arXiv:2007.13278
   Hjelm RD, 2019, Arxiv, DOI arXiv:1808.06670
   Ding M, 2019, Arxiv, DOI arXiv:1905.05460
   Dunbar E, 2020, Arxiv, DOI arXiv:2010.05967
   Dunbar E, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P323, DOI 10.1109/ASRU.2017.8268953
   Ermolov A, 2021, PR MACH LEARN RES, V139
   Fang HC, 2020, Arxiv, DOI arXiv:2005.12766
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300
   Gan Chuang, 2020, P IEEECVF C COMPUTER, P10478, DOI DOI 10.1109/CVPR42600.2020.01049
   Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Ghojogh B, 2022, Arxiv, DOI arXiv:1906.09436
   Giorgi J, 2021, Arxiv, DOI arXiv:2006.03659
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glass J., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P1, DOI 10.1109/ISSPA.2012.6310546
   Goldberger J., 2004, Neighbourhood Components Analysis
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Gutmann Michael, 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Han TD, 2019, IEEE INT CONF COMP V, P1483, DOI 10.1109/ICCVW.2019.00186
   Han Tengda, 2020, Adv. Neural Inf. Process. Syst., NIPS, V33, P5679
   Hassani K, 2020, PR MACH LEARN RES, V119
   He K., 2016, P IEEE C COMP VIS PA
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   Heck M, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P740, DOI 10.1109/ASRU.2017.8269011
   Hinton GE, 1993, ADV NEURAL INFORM PR, P3, DOI [DOI 10.1021/JP906511Z, DOI 10.5555/2987189.2987190]
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Ho Chih-Hui, 2020, P INT C NEUR INF PRO, V33, P17081
   Holmberg OG, 2020, NAT MACH INTELL, V2, P719, DOI 10.1038/s42256-020-00247-1
   Hsu W.-N., 2021, ADV NEUR IN, p27 826
   Hsu WN, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6533, DOI 10.1109/ICASSP39728.2021.9414460
   Hu D., 2020, Advances in Neural Information Processing Systems, P10077
   Hu D, 2020, Arxiv, DOI arXiv:2001.09414
   Hu D, 2019, PROC CVPR IEEE, P9240, DOI 10.1109/CVPR.2019.00947
   Hu QJ, 2021, PROC CVPR IEEE, P1074, DOI 10.1109/CVPR46437.2021.00113
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huynh Tri, 2022, P IEEECVF WINTER C A, P2785
   Ilharco G, 2021, Arxiv, DOI [arXiv:2005.00619, 10.48550/arxiv.2005.00619]
   Ilic S, 2018, Arxiv, DOI arXiv:1809.09795
   Jaegle Andrew, 2021, PERCEIVER GEN PERCEP
   Jain P, 2022, Arxiv, DOI arXiv:2007.04973
   Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002
   Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691
   JasonWei Kai, 2019, arXiv, DOI DOI 10.48550/ARXIV.1901.11196
   Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kalantidis Yannis, 2020, P INT C NEUR INF PRO, P21798
   Kawakami K, 2020, Arxiv, DOI arXiv:2001.11128
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kim D, 2019, AAAI CONF ARTIF INTE, P8545
   Knights J, 2021, INT C PATT RECOG, P8914, DOI 10.1109/ICPR48806.2021.9412071
   Kong Quan, 2020, Advances in Neural Information Processing Systems, V33, P8089
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai CI, 2019, Arxiv, DOI arXiv:1904.01575
   Lample G, 2019, Arxiv, DOI arXiv:1901.07291
   Lample G, 2018, Arxiv, DOI arXiv:1711.00043
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Le-Khac PH, 2020, IEEE ACCESS, V8, P193907, DOI 10.1109/ACCESS.2020.3031549
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Li BH, 2020, Arxiv, DOI [arXiv:2011.05864, DOI 10.48550/ARXIV.2011.05864]
   Li JN, 2021, Arxiv, DOI [arXiv:2005.04966, DOI 10.48550/ARXIV.2005.04966]
   Li YF, 2021, AAAI CONF ARTIF INTE, V35, P8547
   Li ZL, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1727, DOI 10.1145/3442381.3449859
   Liao D., 2021, ARXIV
   Lin Y., P IEEE CVPR, V2021, P11174
   Lin Y-B, 2021, arXiv
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu X, 2021, IEEE Transactions on Knowledge & Data Engineering
   Liu Y., 2020, arXiv
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lorre G, 2020, IEEE WINT CONF APPL, P651, DOI [10.1109/WACV45572.2020.9093278, 10.1109/wacv45572.2020.9093278]
   McCann B., 2017, Advances in neural information processing systems, P1
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Morgado P, 2021, PROC CVPR IEEE, P12470, DOI 10.1109/CVPR46437.2021.01229
   Nagrani A, 2020, INT CONF ACOUST SPEE, P6829, DOI [10.1109/ICASSP40776.2020.9054057, 10.1109/icassp40776.2020.9054057]
   Nandan A, 2020, LANGUAGE AGNOSTIC SP
   Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975
   Pan EL, 2021, ADV NEUR IN, V34
   Pan T, 2021, PROC CVPR IEEE, P11200, DOI 10.1109/CVPR46437.2021.01105
   Patrick M, 2021, Arxiv, DOI arXiv:2003.04298
   Peng XT, 2021, Arxiv, DOI arXiv:2104.04676
   Prakash Senthil Purushwalkam Shiva, 2020, Adv. Neural Inform. Process. Syst., V33
   Qian R, 2021, PROC CVPR IEEE, P6960, DOI 10.1109/CVPR46437.2021.00689
   Radford A., 2019, LANGUAGE MODELS ARE
   Radford A, 2021, PR MACH LEARN RES, V139
   Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250
   Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Robinson J., 2020, arXiv
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Rui Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P292, DOI 10.1007/978-3-030-58565-5_18
   Park DS, 2019, Arxiv, DOI [arXiv:1904.08779, DOI 10.48550/ARXIV.1904.08779]
   Saeed A, 2021, ICASSP 2021 2021 IEE, P3875, DOI DOI 10.1109/ICASSP39728.2021.9413528
   Schatz T, 2016, THESIS
   Schneider S, 2019, INTERSPEECH, P3465, DOI 10.21437/Interspeech.2019-1873
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Senocak A, 2021, IEEE T PATTERN ANAL, V43, P1605, DOI 10.1109/TPAMI.2019.2952095
   Senocak A, 2018, PROC CVPR IEEE, P4358, DOI 10.1109/CVPR.2018.00458
   Shor J, 2022, Arxiv, DOI arXiv:2110.04621
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simoulin A, 2021, EUROPEAN CHAPTER ASS
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun C, 2019, Arxiv, DOI arXiv:1906.05743
   Sun F.-Y., 2019, arXiv
   Sun M, ARXIV PREPRINT ARXIV
   Sun SQ, 2020, Arxiv, DOI arXiv:2009.14167
   Sun ZQ, 2019, Arxiv, DOI arXiv:1902.10197
   Tao L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2193, DOI 10.1145/3394171.3413694
   Tao Yaling, 2021, arXiv
   Tengda Han, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P312, DOI 10.1007/978-3-030-58580-8_19
   Tian Y., 2020, NeurIPS, V33, P6827
   Tokmakov Pavel, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P404, DOI 10.1007/978-3-030-66096-3_28
   Tran C, 2021, Arxiv, DOI arXiv:2108.03265
   Trosten DJ, 2021, PROC CVPR IEEE, P1255, DOI 10.1109/CVPR46437.2021.00131
   Tsai TW, 2020, INT C LEARNING REPRE
   Tschannen M, 2020, Arxiv, DOI [arXiv:1907.13625, DOI 10.48550/ARXIV.1907.13625]
   Vahdat A., 2020, P 34 INT C NEUR INF, V33, P19667
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Velickovic Petar, 2019, ICLR
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang F, 2021, PROC CVPR IEEE, P2495, DOI 10.1109/CVPR46437.2021.00252
   Wang Jiangliu, 2020, ECCV, P504, DOI DOI 10.1007/978-3-030-58520-430
   Wang Jinpeng, 2021, AAAI
   Wang T, 2020, INT C MACH LEARN, P9929, DOI DOI 10.1109/CVPR.2019.00516
   Wang WR, 2020, INT CONF ACOUST SPEE, P6889, DOI [10.1109/icassp40776.2020.9053541, 10.1109/ICASSP40776.2020.9053541]
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wei DL, 2018, PROC CVPR IEEE, P8052, DOI 10.1109/CVPR.2018.00840
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu F., 2021, arXiv
   Wu Lirong., 2021, IEEE Transactions on Knowledge and Data Engineering
   Wu MK, 2020, Arxiv, DOI arXiv:2005.13149
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Wu ZF, 2020, Arxiv, DOI arXiv:2012.15466
   Xia J, 2022, Arxiv, DOI arXiv:2110.02027
   Xia J, 2022, Arxiv, DOI arXiv:2202.03104
   Xiao FY, 2020, Arxiv, DOI arXiv:2001.08740
   Xie Q., 2020, Unsupervised data augmentation for consistency training, P6256
   Xue F, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115967
   Cheng JY, 2020, Arxiv, DOI arXiv:2007.04871
   Yan YM, 2021, Arxiv, DOI arXiv:2105.11741
   Yang CY, 2020, Arxiv, DOI arXiv:2006.15489
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yang K, 2020, IEEE COMPUT SOC CONF, P4069, DOI 10.1109/CVPRW50498.2020.00481
   Yang ZL, 2018, Arxiv, DOI arXiv:1809.09600
   Yang ZL, 2019, ADV NEUR IN, V32
   Yao T, 2021, AAAI CONF ARTIF INTE, V35, P10656
   Yao Y, 2020, PROC CVPR IEEE, P6547, DOI 10.1109/CVPR42600.2020.00658
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   You JX, 2018, PR MACH LEARN RES, V80
   You Y, 2020, ADV NEURAL INFORM PR, V33, P5812, DOI [10.48550/arXiv.2010.13902, DOI 10.48550/ARXIV.2010.13902]
   You YN, 2021, PR MACH LEARN RES, V139
   Zeng JQ, 2020, Arxiv, DOI arXiv:2009.05923
   Zhan XH, 2020, PROC CVPR IEEE, P6687, DOI 10.1109/CVPR42600.2020.00672
   Zhang LW, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107805
   Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76
   Zhang S, 2020, SELF SUPERVISED REPR
   Zhang Y.-F., 2021, arXiv
   Zhang Y, 2022, Arxiv, DOI [arXiv:2010.10504, DOI 10.48550/ARXIV.2010.10504]
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhu YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2069, DOI 10.1145/3442381.3449802
   Zhuang C., 2020, P IEEECVF C COMPUTER, P9563
   Zhuang CX, 2019, IEEE I CONF COMP VIS, P6001, DOI 10.1109/ICCV.2019.00610
   Zimmermann Roland S, 2021, INT C MACHINE LEARNI, P12979
NR 216
TC 0
Z9 0
U1 10
U2 39
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD 2022 AUG 5
PY 2022
DI 10.1007/s11715-077-00245-6
EA AUG 2022
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3O0OQ
UT WOS:000836541800001
DA 2024-07-18
ER

PT J
AU Meraz, M
   Ansari, MA
   Javed, M
   Chakraborty, P
AF Meraz, Md
   Ansari, Md Afzal
   Javed, Mohammed
   Chakraborty, Pavan
TI DC-GNN: drop channel graph neural network for object classification and
   part segmentation in the point cloud
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Graph neural network; Object classification; Part segmentation; Drop
   channel layer; LiDAR, point cloud
AB In the recent years, the problem of 3D shape analysis in the point cloud is considered as one of the challenging research topics in the field of computer vision. The major issues here are effective representation of the 3D information, meaningful feature extraction and subsequent task of classification. In this research paper, a deep learning-based network called Drop Channel Graph Neural Network (DC-GNN) is proposed for object classification and part segmentation. The DC-GNN model employs the idea of k-NN-based drop channel with hierarchical feature selection approach at each layer for dynamic graph construction, and further, with the help of Multi-Layer Perceptron Networks accomplishes the task of object classification. The same DC-GNN model is extended to carry out part segmentation in the point cloud data using the ShapeNet-Part benchmark dataset. The proposed network reports the state-of-the-art classification accuracy of 93.64% with ModelNet-40 dataset (Source-Code-https://github.com/merazlab/DC-GNN).
C1 [Meraz, Md; Ansari, Md Afzal; Javed, Mohammed; Chakraborty, Pavan] Indian Inst Informat Technol Allahabad, Ctr Intelligent Robot CIR Lab, Dept IT, Prayagraj 211012, UP, India.
C3 Indian Institute of Information Technology Allahabad
RP Meraz, M (corresponding author), Indian Inst Informat Technol Allahabad, Ctr Intelligent Robot CIR Lab, Dept IT, Prayagraj 211012, UP, India.
EM merazlab@gmail.com; mit2019072@iiita.ac.in; javed@iiita.ac.in;
   pavan@iiita.ac.in
RI Javed, Mohammed/HKE-5354-2023
OI Javed, Mohammed/0000-0002-3019-7401
FU Central Computing Facility (CCF) of Indian Institute of Information
   Technology Allahabad; Ministry of Education, Government of India
FX The author gratefully acknowledges the support of Central Computing
   Facility (CCF) of Indian Institute of Information Technology Allahabad,
   and the resources provided by PARAM Shivay Facility under the National
   Supercomputer Mission, at the IIT-BHU Varanasi. This research work is
   carried out with the support received from the Ministry of Education,
   Government of India.
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Atzmon M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201301
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Guo Meng-Hao, 2020, ARXIV201209688
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Jaderberg M, 2015, ADV NEUR IN, V28
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760
   Kutila M, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P265, DOI 10.1109/ITSC.2016.7795565
   Lan SY, 2019, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2019.00109
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li YY, 2018, ADV NEUR IN, V31
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Mao JG, 2019, IEEE I CONF COMP VIS, P1578, DOI 10.1109/ICCV.2019.00166
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Qi CR, 2017, ADV NEUR IN, V30
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xu QG, 2020, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR42600.2020.00570
   Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
NR 31
TC 1
Z9 1
U1 4
U2 26
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2022
VL 11
IS 2
BP 123
EP 133
DI 10.1007/s13735-022-00236-7
EA APR 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1A5LQ
UT WOS:000784742900001
DA 2024-07-18
ER

PT J
AU Hazarika, RA
   Abraham, A
   Sur, SN
   Maji, AK
   Kandar, D
AF Hazarika, Ruhul Amin
   Abraham, Ajith
   Sur, Samarendra Nath
   Maji, Arnab Kumar
   Kandar, Debdatta
TI Different techniques for Alzheimer's disease classification using brain
   images: a study
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Alzheimer&#8217; s disease (AD); Artificial neural network (ANN);
   Support vector machine (SVM); Random forest (RF); K-nearest neighbor
   (KNN); Magnetic resonance imaging (MRI)
ID TRANSCRANIAL MAGNETIC STIMULATION; FEATURE-SELECTION; NEURAL-NETWORKS;
   GRAY-MATTER; DIAGNOSIS; PREDICTION
AB Alzheimer's disease (AD) is a kind of dementia that is mostly experienced by people who are in the age of early 60s. In AD, brain cells that are responsible for forming memories and cognitive decisions, get affected which causes overall gray matter shrinkage in the human brain. Since AD patients are growing exponentially in the world, researchers are trying to develop an accurate mechanism for diagnosing the disease using brain images. In this paper, several research articles on AD classification are analyzed along with detailed observations. We have summarized as well as compared the research articles based on their classification performance. Although all the reviewed articles have the potential to classify AD, still there lies major future challenges. Among all the reviewed papers, it is found that the recent deep neural network-based classification techniques can produce the most promising results with an average performance rate of 93%.
C1 [Hazarika, Ruhul Amin; Maji, Arnab Kumar; Kandar, Debdatta] North Eastern Hill Univ, Dept Informat Technol, Shillong 793022, Meghalaya, India.
   [Abraham, Ajith] Sci Network Innovat & Res Excellence Auburn, Machine Intelligence Res Labs MIR Labs, Auburn, WA 98071 USA.
   [Sur, Samarendra Nath] Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Elect & Commun Engn, Majitar 737136, Sikkim, India.
C3 North Eastern Hill University; Sikkim Manipal Institute of Technology;
   Sikkim Manipal University
RP Hazarika, RA; Kandar, D (corresponding author), North Eastern Hill Univ, Dept Informat Technol, Shillong 793022, Meghalaya, India.
EM rahazarika@gmail.com; abraham.ajith@gmail.com; samar.sur@gmail.com;
   arnab.maji@gmail.com; kdebdatta@gmail.com
RI Abraham, Ajith/A-1416-2008; Sur, Samarendra Nath/I-9050-2019; Maji,
   Arnab Kumar/IUP-3517-2023; Hazarika, Ruhul Amin/IAM-4331-2023
OI Abraham, Ajith/0000-0002-0169-6738; Sur, Samarendra
   Nath/0000-0001-8184-0623; Maji, Arnab Kumar/0000-0002-3320-9965; 
CR A. Association, ALZH DIS FACT SHEET
   Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9
   ADNI, Alzheimer's Disease Neuroimaging Initiative
   Ahad NA, 2014, AIP CONF PROC, V1605, P888, DOI 10.1063/1.4887707
   Alam S, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8750506
   Ali J., 2012, International Journal of Computer Science Issues (IJCSI), V9, P272
   [Anonymous], 2013, OVIDIUS U ANN SERIES
   [Anonymous], 2010, Int. J. Comput. Appl.
   [Anonymous], 2000, TIME BRAIN
   Ardekani BA, 2017, J ALZHEIMERS DIS, V55, P269, DOI 10.3233/JAD-160594
   Banzi R, 2016, ALZHEIMERS RES THER, V8, DOI 10.1186/s13195-016-0201-2
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Basheera S, 2019, ALZH DEMENT-TRCI, V5, P974, DOI 10.1016/j.trci.2019.10.001
   Beason-Held LL, 2013, J NEUROSCI, V33, P18008, DOI 10.1523/JNEUROSCI.1402-13.2013
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Cassani R, 2018, DIS MARKERS, V2018, DOI 10.1155/2018/5174815
   Cousins KAQ, 2020, BRAIN, V143, P2295, DOI 10.1093/brain/awaa165
   Cusano C, 2004, PROC SPIE, V5304, P330
   Dastgheib ZA, 2012, MED BIOL ENG COMPUT, V50, P483, DOI 10.1007/s11517-012-0890-z
   Elshatoury H, 2019, J ALZHEIMERS DIS, V72, P515, DOI 10.3233/JAD-190704
   Fischmeister FPS, 2013, NEUROIMAGE-CLIN, V3, P369, DOI 10.1016/j.nicl.2013.09.007
   Gadkari Dhanashree., 2004, Image Quality Analysis Using GLCM
   Gooblar J, 2015, JAMA NEUROL, V72, P1484, DOI 10.1001/jamaneurol.2015.2875
   Gray KR, 2013, NEUROIMAGE, V65, P167, DOI 10.1016/j.neuroimage.2012.09.065
   Guyon I, 2006, STUD FUZZ SOFT COMP, V207, P1
   Hallett M, 2017, CLIN NEUROPHYSIOL, V128, P2125, DOI 10.1016/j.clinph.2017.08.007
   Hemanth DJ, 2012, COMM COM INF SC, V350, P349
   Humpel C, 2011, TRENDS BIOTECHNOL, V29, P26, DOI 10.1016/j.tibtech.2010.09.007
   Imandoust S. B., 2013, INT J ENG RES APPL, V3, P605
   Islam Jyoti, 2018, Brain Inform, V5, P2, DOI 10.1186/s40708-018-0080-3
   Jack CR, 2016, NEUROLOGY, V87, P539, DOI 10.1212/WNL.0000000000002923
   Jain, 2017, INT J NEW TECHNOL RE, V3, P5, DOI [10.5121/sipij.2013.4502, DOI 10.5121/SIPIJ.2013.4502]
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Janicak PG, 2015, NEUROPSYCH DIS TREAT, V11, P1549, DOI 10.2147/NDT.S67477
   Jongkreangkrai C, 2016, J PHYS CONF SER, V694, DOI 10.1088/1742-6596/694/1/012036
   Kamathe Rupali S., 2018, ICTACT Journal on Image and Video Processing, V8, P1665, DOI 10.21917/ijivp.2017.0234
   Karamizadeh S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS, AND CONTROL TECHNOLOGY (I4CT), P63, DOI 10.1109/I4CT.2014.6914146
   Kaye JA, 1998, NEUROLOGY, V51, pS45, DOI 10.1212/WNL.51.1_Suppl_1.S45
   Kim, 2010, INT J SOFTW ENG ITS, V4, P66
   Kim J, 2021, PSYCHIAT INVEST, V18, P69, DOI 10.30773/pi.2020.0304
   Korolev IO., 2014, MSRJ, V4, P24, DOI DOI 10.3402/MSRJ.V3I0.201333
   Kraetzer C, 2007, LECT NOTES COMPUT SC, V4567, P359
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P34, DOI 10.1016/j.imu.2018.12.003
   Lebedev AV, 2014, NEUROIMAGE-CLIN, V6, P115, DOI 10.1016/j.nicl.2014.08.023
   Ledig C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29295-9
   Li M., 2014, MATH PROBL ENG, V2014, P1, DOI [DOI 10.1155/2014/434972, 10.1155/2014/434972]
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   LIN N, 2015, INT J ADV COMPUT SC, V10
   Liu MH, 2018, NEUROINFORMATICS, V16, P295, DOI 10.1007/s12021-018-9370-4
   Liu MH, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00035
   Lu DC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22000-w
   Maggipinto T, 2017, PHYS MED BIOL, V62, P2361, DOI 10.1088/1361-6560/aa5dbe
   Mahesh G., 2014, AM J PHYTOMED CLIN T, V2, P463
   Mahmon NA, 2014, 2014 IEEE 5TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P153, DOI 10.1109/ICSGRC.2014.6908713
   Maldonado S, 2017, EUR J OPER RES, V261, P656, DOI 10.1016/j.ejor.2017.02.037
   Mareeswari S., 2015, INT J COMPUT SCI APP, V5, P27, DOI [10.5121/ijcsa.2015.5103, DOI 10.5121/IJCSA.2015.5103]
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   2007, DEMENTIA NICE SCIE G
   Naghibi SA, 2017, WATER RESOUR MANAG, V31, P2761, DOI 10.1007/s11269-017-1660-3
   Nandhini, 2016, IJCET
   Nanni L, 2019, ARTIF INTELL MED, V97, P19, DOI 10.1016/j.artmed.2019.05.003
   NIH, 2020, ALZH DIS CLIN BAS SC
   O'Bryant SE, 2017, ALZHEIMERS DEMENT, V13, P45, DOI 10.1016/j.jalz.2016.09.014
   OASIS Brains, OPEN ACCESS SERIES I
   Oppedal K, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/572567
   Patange, 2018, INT J ENG RES TECHNO, V7, P22780181
   Pham T A., 2010, Optimization of Texture Feature Extration Algorithm
   Rajeswari, 2018, INT J ADV RES COMPUT, DOI 10.26483/ijarcs.v9i2.5353
   Richhariya B, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101903
   Rohr K., 2001, LANDMARK BASED IMAGE, V21
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Schmidt MF, 2018, HUM BRAIN MAPP, V39, P2500, DOI 10.1002/hbm.24017
   Segovia F, 2012, NEUROCOMPUTING, V75, P64, DOI 10.1016/j.neucom.2011.03.050
   Sharma K., 2014, IOSR J. Eng., V4, P06
   Sheehan B, 2012, THER ADV NEUROL DISO, V5, P349, DOI 10.1177/1756285612455733
   Smith AD, 2002, P NATL ACAD SCI USA, V99, P4135, DOI 10.1073/pnas.082107399
   Sonka M., 2014, Image processing, analysis, and machine vision
   Statnikov A, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-319
   Swiebocka-Wiek J, 2016, LECT NOTES COMPUT SC, V9842, P172, DOI 10.1007/978-3-319-45378-1_16
   Symms M, 2004, J NEUROL NEUROSUR PS, V75, P1235, DOI 10.1136/jnnp.2003.032714
   Taqi AM, 2017, INT J ADV COMPUT SC, V8, P10
   Thompson PM, 2003, J NEUROSCI, V23, P994
   Tufail A.B., 2012, Age, V2012, P1731, DOI DOI 10.5281/zenodo.1084608
   Turner RS, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00496
   Wani N., 2018, Soft Computing Based Medical Image Analysis, P31, DOI DOI 10.1016/B978-0-12-813087-2.00002-6
   Xiao Z, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/1952373
   Yamanakkanavar N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113243
   Zhang J, 2017, IEEE J BIOMED HEALTH, V21, P1607, DOI 10.1109/JBHI.2017.2704614
   Zheng Chuanchuan, 2016, Brain Inform, V3, P17, DOI 10.1007/s40708-015-0027-x
   Zhou H, 2008, INFORM SCIENCES, V178, P4314, DOI 10.1016/j.ins.2008.07.015
NR 90
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2021
VL 10
IS 4
BP 199
EP 218
DI 10.1007/s13735-021-00210-9
EA MAY 2021
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XC7OC
UT WOS:000652087000001
DA 2024-07-18
ER

PT J
AU Kumar, MRP
   Jayagopal, P
AF Pavan Kumar, M. R.
   Jayagopal, Prabhu
TI Generative adversarial networks: a survey on applications and challenges
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Generative model; Convolutional neural network; segmentation; Object
   detection; Generative adversarial network
ID IMAGE SYNTHESIS; TEXT; SIMILARITY
AB Deep neural networks have attained great success in handling high dimensional data, especially images. However, generating naturalistic images containing ginormous subjects for different tasks like image classification, segmentation, object detection, reconstruction, etc., is continued to be a difficult task. Generative modelling has the potential to learn any kind of data distribution in an unsupervised manner. Variational autoencoder (VAE), autoregressive models, and generative adversarial network (GAN) are the popular generative modelling approaches that generate data distributions. Among these, GANs have gained much attention from the research community in recent years in terms of generating quality images and data augmentation. In this context, we collected research articles that employed GANs for solving various tasks from popular databases and summarized them based on their application. The main objective of this article is to present the nuts and bolts of GANs, state-of-the-art related work and its applications, evaluation metrics, challenges involved in training GANs, and benchmark datasets that would benefit naive and enthusiastic researchers who are interested in working on GANs.
C1 [Pavan Kumar, M. R.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Jayagopal, Prabhu] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Jayagopal, P (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM marabattinasivapavan@gmail.com; jprabhuit@gmail.com
RI M, Dr.M Ranjith Kumar/U-4667-2019; jayagopal, prabhu/JCE-2168-2023;
   jayagopal, prabhu/AAF-8826-2019
OI M, Dr.M Ranjith Kumar/0000-0001-8411-7609; jayagopal,
   prabhu/0000-0003-3335-6911; jayagopal, prabhu/0000-0003-3335-6911; ,
   Pavan Kumar M R/0000-0002-6754-7372
CR Ak KE, 2020, PATTERN RECOGN LETT, V135, P22, DOI 10.1016/j.patrec.2020.02.030
   [Anonymous], 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, P IEEE WINTER C APPL
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Arjovsky, 2017, ARXIV170104862
   Arjovsky M., 2017, ARXIV170107875
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Che Tong, 2016, CoRR
   Chen JY, 2020, NEUROCOMPUTING, V416, P125, DOI 10.1016/j.neucom.2018.12.092
   Chen Q, 2020, IEEE T IMAGE PROCESS, V29, P7454, DOI 10.1109/TIP.2020.3003227
   Chen WC, 2020, BIOCHEM ENG J, V154, DOI 10.1016/j.bej.2019.107440
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chonwiharnphan P, 2020, IEEE ACCESS, V8, P41384, DOI 10.1109/ACCESS.2020.2976491
   Delannoy Q, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103755
   Dolhansky B., 2020, arXiv preprint arXiv:200607397
   Dong JY, 2019, IEEE GEOSCI REMOTE S, V16, P173, DOI 10.1109/LGRS.2018.2870880
   Feng J, 2019, IEEE T GEOSCI REMOTE, V57, P5329, DOI 10.1109/TGRS.2019.2899057
   Gao Y, 2019, IEEE T MED IMAGING, V38, P2059, DOI 10.1109/TMI.2019.2894692
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grover Aditya, 2017, ARXIV170508868
   Guo CK, 2020, INFORM SCIENCES, V534, P117, DOI 10.1016/j.ins.2020.05.046
   Hamada K., 2018, P EUR C COMP VIS ECC, P0
   Han LY, 2020, COMPUT METH PROG BIO, V189, DOI 10.1016/j.cmpb.2019.105275
   Han ZY, 2019, NEUROCOMPUTING, V368, P188, DOI 10.1016/j.neucom.2019.08.049
   Harada S, 2019, IEEE ACCESS, V7, P144292, DOI 10.1109/ACCESS.2019.2934928
   Hayashi H, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104927
   He JJ, 2020, NEUROCOMPUTING, V402, P359, DOI 10.1016/j.neucom.2020.03.107
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113244
   He XX, 2020, NEUROCOMPUTING, V405, P37, DOI 10.1016/j.neucom.2020.04.044
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hsu CC, 2019, IEEE T IMAGE PROCESS, V28, P6225, DOI 10.1109/TIP.2019.2924554
   Hu ZH, 2020, IEEE ACCESS, V8, P63336, DOI 10.1109/ACCESS.2020.2982750
   Huang SK, 2020, AD HOC NETW, V105, DOI 10.1016/j.adhoc.2020.102177
   Im D. J., 2016, ARXIV160205110
   Iranmanesh SM, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103861
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jin X, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107143
   Jin Yanghua, 2017, ARXIV170805509
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kasem HM, 2019, IEEE ACCESS, V7, P182993, DOI 10.1109/ACCESS.2019.2959940
   Kim HJ, 2020, PHYS RES A, V954, DOI [10.1016/j.nima.2019.02.041, DOI 10.1016/J.NIMA.2019.02.041]
   Kim K, 2018, IEEE ACCESS, V6, P54207, DOI 10.1109/ACCESS.2018.2872025
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Kuang Y, 2020, IEEE ACCESS, V8, P77725, DOI 10.1109/ACCESS.2020.2987961
   Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Kwak Hanock, 2016, ARXIV160705387
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee M, 2019, IEEE ACCESS, V7, P28158, DOI 10.1109/ACCESS.2019.2899108
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Lei M, 2019, IEEE ACCESS, V7, P168236, DOI 10.1109/ACCESS.2019.2954475
   Li H, 2020, IEEE ACCESS, V8, P62448, DOI 10.1109/ACCESS.2020.2981496
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Li XQ, 2019, IEEE ACCESS, V7, P147928, DOI 10.1109/ACCESS.2018.2872695
   Li Y, 2018, INFORM SCIENCES, V450, P301, DOI 10.1016/j.ins.2018.03.050
   Lim Theodore, 2016, P INT C LEARN REPR
   Lin S, 2019, IEEE ACCESS, V7, P148413, DOI 10.1109/ACCESS.2019.2946062
   Liu CL, 2019, IEEE ACCESS, V7, P108866, DOI 10.1109/ACCESS.2019.2933531
   Liu L, 2019, IEEE ACCESS, V7, P77027, DOI 10.1109/ACCESS.2019.2921859
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mandal B, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2886427
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Metz Luke, 2016, ARXIV161102163
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Odena Augustus., 2016, Semi-supervised learning with generative adversarial networks
   Oluwasanmi A, 2020, IEEE ACCESS, V8, P31733, DOI 10.1109/ACCESS.2020.2973296
   Pan TY, 2020, ISA T, V101, P379, DOI 10.1016/j.isatra.2020.01.014
   Pang YW, 2019, IEEE T CIRC SYST VID, V29, P3211, DOI 10.1109/TCSVT.2018.2880223
   Park J, 2020, IEEE T IMAGE PROCESS, V29, P4721, DOI 10.1109/TIP.2020.2975986
   Perarnau G., 2016, NIPS WORKSH ADV TRAI
   Qi L, 2019, IEEE ACCESS, V7, P172305, DOI 10.1109/ACCESS.2019.2956210
   Qian YM, 2019, SPEECH COMMUN, V114, P1, DOI 10.1016/j.specom.2019.08.006
   Radford A., 2015, ARXIV
   Rizzo G, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102217
   Rong CL, 2020, IEEE ACCESS, V8, P68842, DOI 10.1109/ACCESS.2020.2986079
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth K, 2017, ADV NEUR IN, V30
   Ruan YA, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101721
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salimans T, 2016, ADV NEUR IN, V29
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Shaker AM, 2020, IEEE ACCESS, V8, P35592, DOI 10.1109/ACCESS.2020.2974712
   Shao SY, 2019, COMPUT IND, V106, P85, DOI 10.1016/j.compind.2019.01.001
   Shi YL, 2019, IEEE GEOSCI REMOTE S, V16, P603, DOI 10.1109/LGRS.2018.2878486
   Sun YL, 2020, IEEE T INF FOREN SEC, V15, P2679, DOI 10.1109/TIFS.2020.2975921
   Taigman Y., 2016, INT C LEARN REPR
   Tseng BW, 2020, IEEE T INF FOREN SEC, V15, P2499, DOI 10.1109/TIFS.2020.2968188
   Bisneto TRV, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106165
   Wang CY, 2019, IEEE T EVOLUT COMPUT, V23, P921, DOI 10.1109/TEVC.2019.2895748
   Wang H, 2019, INT GEOSCI REMOTE SE, P9792, DOI [10.1109/IGARSS.2019.8900073, 10.1109/igarss.2019.8900073]
   Wang JL, 2019, IEEE T SEMICONDUCT M, V32, P310, DOI 10.1109/TSM.2019.2925361
   Wang K, 2019, ARTIF INTELL-AMST, V275, P540, DOI 10.1016/j.artint.2019.07.003
   Wang P, 2019, IEEE ACCESS, V7, P100910, DOI 10.1109/ACCESS.2019.2930882
   Wang Q, 2019, IEEE SIGNAL PROC LET, V26, P400, DOI 10.1109/LSP.2018.2890205
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang YR, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106333
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen SP, 2019, IEEE T CIRC SYST VID, V29, P2337, DOI 10.1109/TCSVT.2018.2867934
   Wu JJ, 2016, ADV NEUR IN, V29
   Xiang P, 2019, IEEE SIGNAL PROC LET, V26, P650, DOI 10.1109/LSP.2019.2903874
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yan K, 2020, BUILD ENVIRON, V172, DOI 10.1016/j.buildenv.2020.106698
   Yanagi R, 2019, IEEE ACCESS, V7, P153183, DOI 10.1109/ACCESS.2019.2947409
   Yang S, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P685, DOI 10.1109/ASRU.2017.8269003
   Yang WM, 2019, IEEE T INF FOREN SEC, V14, P2512, DOI 10.1109/TIFS.2019.2902819
   Yang Y, 2020, IEEE ACCESS, V8, P105217, DOI 10.1109/ACCESS.2020.2993928
   Yang ZG, 2019, IEEE ACCESS, V7, P175947, DOI 10.1109/ACCESS.2019.2955382
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   You S., 2019, ARXIV PREPRINT ARXIV
   Yu C, 2020, IEEE ACCESS, V8, P128140, DOI 10.1109/ACCESS.2020.3008523
   Yu H, 2020, IEEE T VEH TECHNOL, V69, P3680, DOI 10.1109/TVT.2020.2978450
   Yu L., 2016, CoRR
   Yu W, 2020, IEEE ACCESS, V8, P55170, DOI 10.1109/ACCESS.2020.2980898
   Yuan JH, 2020, IEEE ACCESS, V8, P22617, DOI 10.1109/ACCESS.2020.2969288
   Zhang CY, 2019, NEUROCOMPUTING, V340, P259, DOI 10.1016/j.neucom.2019.01.093
   Zhang H., 2019, INT C MACHINE LEARNI, P12744, DOI DOI 10.48550/ARXIV.1805.08318
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   ZHANG JY, 2019, IEEE ACCESS, V7
   Zhang W, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107377
   Zhang XQ, 2020, IEEE ACCESS, V8, P10989, DOI 10.1109/ACCESS.2020.2965184
   Zhang Y, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101664
   Zhao BX, 2019, IEEE ACCESS, V7, P185893, DOI 10.1109/ACCESS.2019.2956947
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   Zhao JM, 2019, ENG APPL ARTIF INTEL, V82, P263, DOI 10.1016/j.engappai.2019.04.003
   Zheng JY, 2019, IEEE ACCESS, V7, P154971, DOI 10.1109/ACCESS.2019.2949070
   Zhou ZX, 2020, IEEE T BIO-MED ENG, V67, P298, DOI 10.1109/TBME.2019.2912986
   Zhu DJ, 2020, NEUROCOMPUTING, V381, P40, DOI 10.1016/j.neucom.2019.10.065
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
   Zhuang HJ, 2019, IEEE ACCESS, V7, P169426, DOI 10.1109/ACCESS.2019.2955087
NR 141
TC 32
Z9 32
U1 4
U2 54
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2021
VL 10
IS 1
BP 1
EP 24
DI 10.1007/s13735-020-00196-w
EA OCT 2020
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QV8OQ
UT WOS:000582316500001
DA 2024-07-18
ER

PT J
AU Huddar, MG
   Sannakki, SS
   Rajpurohit, VS
AF Huddar, Mahesh G.
   Sannakki, Sanjeev S.
   Rajpurohit, Vijay S.
TI Multi-level context extraction and attention-based contextual
   inter-modal fusion for multimodal sentiment analysis and emotion
   classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Attention model; Inter-modal fusion; Multi-level contextual information;
   Bidirectional recurrent neural network
AB The recent advancements in the Internet technology and its associated services, led the users to post a large amount of multimodal data into social media Web sites, online shopping portals, video repositories, etc. The availability of the huge amount of multimodal content, multimodal sentiment classification, and affective computing has become the most researched topic. The extraction of context among the neighboring utterances and considering the importance of inter-modal utterances before multimodal fusion are the most important research issues in this field. This article presents a novel approach to extract the context at multiple levels and to understand the importance of inter-modal utterances in sentiment and emotion classification. Experiments are conducted on two publically accepted datasets such as CMU-MOSI for sentiment analysis and IEMOCAP for emotion classification. By incorporating the utterance-level contextual information and importance of inter-modal utterances, the proposed model outperforms the standard baselines by over 3% in classification accuracy.
C1 [Huddar, Mahesh G.] Hirasugar Inst Technol, Dept Comp Sci & Engn, Nidasoshi, Belagavi, India.
   [Sannakki, Sanjeev S.; Rajpurohit, Vijay S.] Gogte Inst Technol, Dept Comp Sci & Engn, Belagavi, India.
RP Huddar, MG (corresponding author), Hirasugar Inst Technol, Dept Comp Sci & Engn, Nidasoshi, Belagavi, India.
EM mailtomgh1@gmail.com; sannakkisanjeev@gmail.com; vijaysr2k@yahoo.com
RI Sannakki, Sanjeev/AAX-4145-2021; Rajpurohit/AGF-9902-2022; RAJPUROHIT,
   VIJAY/ADR-6899-2022; Huddar, Mahesh G./S-4686-2019
OI RAJPUROHIT, VIJAY/0000-0003-0659-296X; Huddar, Mahesh
   G./0000-0002-4344-6024
CR [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   [Anonymous], 2019, INT J ENG ADV TECHNO
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen LS, 1998, P 3 INT C FAC GEST R
   de Kok S, 2018, PROG ARTIF INTELL, V7, P295, DOI 10.1007/s13748-018-0163-7
   Ellis JA, 2014, EXPERT REV MOL MED, V16, DOI 10.1017/erm.2014.5
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Eyben F, 2010, J MULTIMODAL USER IN, V3, P7, DOI 10.1007/s12193-009-0032-6
   Gohil S, 2018, JMIR PUBLIC HLTH SUR, V4, P72, DOI 10.2196/publichealth.5789
   Gupta P, 2016, INT CONF COMP COMMUN
   Huddar Mahesh G., 2019, International Journal of Computer Sciences and Engineering, V7, P876
   Huddar MG, 2018, 2018 INT C COMP TECH
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy Andrej, 2014, P INT COMP VIS PATT
   Kirilenko AP, 2018, J TRAVEL RES, V57, P1012, DOI 10.1177/0047287517729757
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Korayem M, 2012, COMM COM INF SC, V322, P128
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   Lyu K, 2016, WIRELESS PERS COMMUN, V89, P941, DOI 10.1007/s11277-016-3346-1
   Mariéthoz J, 2005, IEEE SIGNAL PROC LET, V12, P532, DOI 10.1109/LSP.2005.847860
   Mars A, 2017, PROCEDIA COMPUT SCI, V112, P906, DOI 10.1016/j.procs.2017.08.114
   Mohammad SM, 2013, 2 JOINT C LEX COMP S
   Nagamma P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P933, DOI 10.1109/CCAA.2015.7148530
   Nalisnick ET, 2013, PROC INT CONF DOC, P758, DOI 10.1109/ICDAR.2013.155
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Peng B, 2015, INT C INT TEXT PROC
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Ramteke J, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 1, P107
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Rozgi V, 2013, P 2012 AS PAC SIGN I
   Teh YW, 2000, P 13 INT C NEUR INF
   Thakor P, 2015, PROCEDIA COMPUT SCI, V53, P199, DOI 10.1016/j.procs.2015.07.295
   Wöllmer M, 2013, IEEE INTELL SYST, V28, P46, DOI 10.1109/MIS.2013.34
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
NR 43
TC 21
Z9 21
U1 1
U2 19
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2020
VL 9
IS 2
SI SI
BP 103
EP 112
DI 10.1007/s13735-019-00185-8
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ4GS
UT WOS:000534963100003
DA 2024-07-18
ER

PT J
AU Garcia, N
   Renoust, B
   Nakashima, Y
AF Garcia, Noa
   Renoust, Benjamin
   Nakashima, Yuta
TI ContextNet: representation and exploration for painting classification
   and retrieval in context
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Art classification; Multi-modal retrieval; Knowledge graphs;
   Visualisation; Multitask learning
AB In automatic art analysis, models that besides the visual elements of an artwork represent the relationships between the different artistic attributes could be very informative. Those kinds of relationships, however, usually appear in a very subtle way, being extremely difficult to detect with standard convolutional neural networks. In this work, we propose to capture contextual artistic information from fine-art paintings with a specific ContextNet network. As context can be obtained from multiple sources, we explore two modalities of ContextNets: one based on multitask learning and another one based on knowledge graphs. Once the contextual information is obtained, we use it to enhance visual representations computed with a neural network. In this way, we are able to (1) capture information about the content and the style with the visual representations and (2) encode relationships between different artistic attributes with the ContextNet. We evaluate our models on both painting classification and retrieval, and by visualising the resulting embeddings on a knowledge graph, we can confirm that our models represent specific stylistic aspects present in the data.
C1 [Garcia, Noa; Renoust, Benjamin; Nakashima, Yuta] Osaka Univ, Inst Databil Sci, Osaka, Japan.
C3 Osaka University
RP Garcia, N (corresponding author), Osaka Univ, Inst Databil Sci, Osaka, Japan.
EM noagarcia@ids.osaka-u.ac.jp
OI Garcia, Noa/0000-0002-9200-6359
CR [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   [Anonymous], 2015, Large-scale classification of fine-art paintings: Learning the right metric on the right feature, DOI 10
   Auber D, 2018, ENCY SOCIAL NETWORK, V1, P28
   Bar Y, 2014, CHAM SPRINGER, V71, P84
   Bilen H., 2016, ADV NEURAL INFORM PR, P235
   Carlson Andrew, 2010, AAAI
   Carneiro G, 2012, LECT NOTES COMPUT SC, V7575, P143, DOI 10.1007/978-3-642-33765-9_11
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Chu WT, 2018, IEEE T MULTIMEDIA, V20, P2491, DOI 10.1109/TMM.2018.2801718
   Collomosse J, 2017, IEEE I CONF COMP VIS, P2679, DOI 10.1109/ICCV.2017.290
   Crowley E., 2014, P BRIT MACH VIS C BM
   Crowley Elliot J., 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P721, DOI 10.1007/978-3-319-46604-0_50
   Crowley E. J., 2015, BMVC, P1
   Cui P, 2018, IEEE T MULTIMEDIA, V20, P198, DOI 10.1109/TMM.2017.2724843
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Deng J., 2014, EUR C COMP VIS, P48
   Dwyer T, 2006, LECT NOTES COMPUT SC, V3843, P153
   Fergus R, 2010, LECT NOTES COMPUT SC, V6311, P762, DOI 10.1007/978-3-642-15549-9_55
   Garcia N, 2018, P EUROPEAN C COMPUTE
   Garcia N, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P25, DOI 10.1145/3323873.3325028
   Garcia Nuno C, 2019, ARXIV191210982
   Goyal P, 2018, BASED SYST, V151, P94, DOI [10.1016/j.knosys.2018.03.022, DOI 10.1016/J.KNOSYS.2018.03.022]
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Johnson CR, 2008, IEEE SIGNAL PROC MAG, V25, P37, DOI 10.1109/MSP.2008.923513
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Karayev Sergey., 2014, P BRIT MACHINE VISIO
   Khan FS, 2014, MACH VISION APPL
   Krishna R., 2016, CoRR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lambert A, 2010, COMPUT GRAPH FORUM, V29, P853, DOI 10.1111/j.1467-8659.2009.01700.x
   Long M, 2015, ARXIVABS150602117, V3
   Ma D, 2017, P 2017 ACM MULTIMEDI
   Mao H, 2017, ACM MULTIMEDIA C
   Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10
   Mensink T, 2014, P INT C MULTIMEDIA R
   Miller GA, 1995, APPL COMPUTATIONAL M, V38, P41, DOI [10.1145/219717.219748, DOI 10.1145/219717.219748]
   Renoust Benjamin, 2019, P 2019 ACM MULTIMEDI, P1
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Ruder S., 2016, ARXIV
   Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720
   Sanakoyeu A, 2018, P EUROPEAN C COMPUTE, V2
   Schubert E, 2017, ACM T DATABASE SYST, V42, DOI 10.1145/3068335
   Seguin B, 2016, CHAM SPRINGER, V753, P767
   Sener O, 2018, 32 C NEURAL INFORM P, V31
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   Strezoski G, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P78, DOI 10.1145/3323873.3325009
   Strezoski G, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3273022
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Wattenberg M., 2016, Distill, V1, DOI DOI 10.23915/DISTILL.00002
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2016, ADV NEUR IN, V29
   Zhang H, 2016, ACM T MULTIM COMPUT, V1
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 60
TC 16
Z9 17
U1 4
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2020
VL 9
IS 1
SI SI
BP 17
EP 30
DI 10.1007/s13735-019-00189-4
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KQ6ZX
UT WOS:000517070300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Biswas, R
   Roy, S
   Purkayastha, D
AF Biswas, Ranjit
   Roy, Sudipta
   Purkayastha, Debraj
TI An efficient content-basedmedical image indexing and retrieval using
   local texture feature descriptors
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Local binary pattern (LBP); Threshold local binary AND pattern (TLBAP);
   Local adjacent neighborhood average difference pattern (LANADP); Feature
   extraction; Medical image retrieval
ID BINARY PATTERNS; COOCCURRENCE PATTERN; EXTREMA; CLASSIFICATION; COLOR;
   FACE; MRI; RECOGNITION
AB This paper presents an efficient medical image indexing and retrieval method using two new proposed feature descriptors named as threshold local binary AND pattern (TLBAP) and local adjacent neighborhood average difference pattern (LANADP). In basic local binary pattern (LBP), every center pixel is considered as a threshold to generate the binary pattern, whereas in the proposed method a threshold value is calculated using the highest pixel intensity of the neighboring pixels to construct the threshold local binary pattern (TLBP). Thereafter, logical AND operation is performed between LBP and TLBP pattern to produce TLBAP pattern. The objective of the other feature descriptor named here as LANADP is to explore the relationship of neighboring pixels with its adjacent neighbors in vertical, horizontal and diagonal directions. In the proposed work, both TLBAP and LANADP features are concatenated in the form of the histograms to generate the final features vector and the performance of the system is evaluated. To test the effectiveness of the proposed method, three publicly available medical image databases, namely OASIS-MRI brain images, NEMA-CT images and VIA/ELCAP-CT images, are used. Two measures, viz. average retrieval precision and average retrieval rate, have been used to evaluate the performance of the method proposed which is further compared with some existing local pattern-based methods. The experimental results show that the proposed methods give better results as compared to the other existing methods considered in this study.
C1 [Biswas, Ranjit] Ramkrishna Mahavidyalaya, Dept Informat Technol, Kailashahar 799277, Tripura, India.
   [Roy, Sudipta; Purkayastha, Debraj] Assam Univ, Dept Comp Sci & Engn, Silchar 788011, India.
C3 Assam University
RP Biswas, R (corresponding author), Ramkrishna Mahavidyalaya, Dept Informat Technol, Kailashahar 799277, Tripura, India.
EM ranjitit1984@gmail.com; sudipta.it@gmail.com; cyberdebraj@gmail.com
RI Roy, Sudipta/V-7932-2018
OI Roy, Sudipta/0000-0003-0244-6455
CR [Anonymous], 2002, P 5 NORD SIGN PROC S
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Hamouchene I, 2014, AASRI PROC, V9, P2, DOI 10.1016/j.aasri.2014.09.002
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He YG, 2013, PATTERN ANAL APPL, V16, P595, DOI 10.1007/s10044-011-0264-4
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Jiri T, 2010, P COMP VIS WINT WORK
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Ryu J, 2015, IEEE T IMAGE PROCESS, V24, P2254, DOI 10.1109/TIP.2015.2419081
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P649, DOI 10.1109/ICACCE.2015.81
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P782, DOI 10.1109/HPCC.2008.55
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 36
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2019
VL 8
IS 4
BP 217
EP 231
DI 10.1007/s13735-019-00176-9
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA KN5AU
UT WOS:000514850500003
DA 2024-07-18
ER

PT J
AU Bastian, BT
   Jiji, CV
AF Bastian, Blossom Treesa
   Jiji, C., V
TI Pedestrian detection using first- and second-order aggregate channel
   features
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Aggregate channel features; Pedestrian detection; Second-order features;
   AdaBoost classifier
AB The content-based analysis of visual multimedia like images and videos are urgently needed to empower human society for the automation of difficult tasks. Pedestrian detection serves as a backbone for a multitude of image processing and machine learning algorithms and secures quite a lot of real-world applications. Keeping this fact in mind, here, we deal with the fabrication of suitable features to identify human/pedestrian instances from images with near accuracy. Accordingly, we introduce second-order aggregate channel features (SOACF) to enhance the performance of much-celebrated pedestrian detection algorithm which was mainly based on the first-order information in an image-aggregate channel features detector (ACF detector). We experimentally proved the complementary nature of ACF and SOACF. Designed to garner both these features together, instead of simple concatenation, or direct merging of the two detectors, we employed a weighted non-maximum suppression merging algorithm. The prospective detector not only performed well on INRIA, Caltech and KITTI pedestrian data set but also, mitigate the miss rate by similar to 4% in Caltech data set and similar to 2% in KITTI data set in comparison with ACF detector. Despite the fact that our in-house generated detector uses only a few channels, it surpasses many state-of-the-art methods based on baseline ACF detector. Moreover, the detection speed is 100 times faster than the topmost pedestrian detector based on ACF.
C1 [Bastian, Blossom Treesa; Jiji, C., V] Coll Engn Trivandrum, Trivandrum, Kerala, India.
C3 College of Engineering, Trivandrum
RP Bastian, BT (corresponding author), Coll Engn Trivandrum, Trivandrum, Kerala, India.
EM blossombastian@cet.ac.in; jijicv@cet.ac.in
RI V, Jiji C/O-8644-2019
OI V, Jiji C/0000-0002-6667-226X; Bastian, Blossom
   Treesa/0000-0001-5642-4812
CR [Anonymous], 2012, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2012, PROC IEEE C COMPUTER
   [Anonymous], 2013, CVPR
   Cao H, 2010, LECT NOTES COMPUT SC, V5995, P628
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   HUANG D, 1974, TIP, V23, P4680, DOI DOI 10.1109/TIP.2014.2353814
   Jiang YS, 2015, PROC CVPR IEEE, P240, DOI 10.1109/CVPR.2015.7298620
   Kaur A, 2017, INT J MULTIMED INF R, V6, P115, DOI 10.1007/s13735-016-0116-5
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Sathish PK, 2018, INT J MULTIMED INF R, V7, P221, DOI 10.1007/s13735-018-0153-3
   Shirahama K, 2015, INT J MULTIMED INF R, V4, P17, DOI 10.1007/s13735-014-0068-6
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126
NR 22
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2019
VL 8
IS 2
BP 127
EP 133
DI 10.1007/s13735-019-00171-0
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA HX7JW
UT WOS:000467582100005
DA 2024-07-18
ER

PT J
AU Shen, WZ
   Chen, JP
   Shao, J
AF Shen, Wenzhong
   Chen, Jinpeng
   Shao, Jie
TI FOF: a fine-grained object detection and feature extraction end-to-end
   network
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE End-to-end network; Fine-grained object detection; Feature extraction;
   Metric learning; YOLO
AB Currently, widely used object detection can predict targets present in the training set. However, in fine-grained object detection tasks, such as commodity detection, the introduction of a new target class requires retraining the model, which significantly reduces the flexibility of the algorithm in applications. In response to this problem, we propose an end-to-end fine-grained object detection and feature extraction network (FOF). To detect and identify objects beyond the target category of the training set, the category output in the network head is removed and replaced with a 128-dimensional feature vector. We used the ArcFace loss function to improve feature classification during training. Since there is no category output, an improved non-maximum suppression algorithm, non-maximum suppression-feature similarity, is proposed to distinguish same class and dissimilar class prediction boxes by feature similarity. During the inference, FOF outputs prediction boxes and feature vectors, and matches them with the feature vectors in the feature gallery to determine the detected object category and complete object detection and recognition. Experimental results indicate that FOF achieved high accuracy in both the MS COCO, PASCAL VOC2012, SmartUVM, and a large-scale and fine-grained Retail Product Checkout datasets. In addition, the method exhibits a low equal error rate when identifying new categories, achieving the objective of detecting and identifying new categories without the need to retrain the model.
C1 [Shen, Wenzhong; Chen, Jinpeng; Shao, Jie] Shanghai Univ Elect Power, Dept Elect & Informat Engn, Shanghai 200120, Peoples R China.
C3 Shanghai University of Electric Power
RP Chen, JP (corresponding author), Shanghai Univ Elect Power, Dept Elect & Informat Engn, Shanghai 200120, Peoples R China.
EM shenwenzhong@shiep.edu.cn; cjpnice@163.com; shaojie@shiep.edu.cn
RI shen, wenzhong/X-4461-2019; CHEN, Jinpeng/ABH-7707-2022
OI CHEN, Jinpeng/0000-0002-0469-4463
FU National Natural Science Foundation of China [61802250]
FX This study was funded by National Natural Science Foundation of China,
   No. 61802250.
CR Cui C, 2021, A lightweight cpu convolutional neural network, Pp-lcnet
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Jocher Glenn, 2021, Zenodo
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2017, Arxiv, DOI arXiv:1612.02295
   Lv ZQ, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107891
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Sun XX, 2019, AAAI CONF ARTIF INTE, P273
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang QS, 2019, LECT NOTES COMPUT SC, V11845, P332, DOI 10.1007/978-3-030-33723-0_27
   Wei SY, 2022, Arxiv, DOI arXiv:2111.00775
   Wei XS, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-022-3513-y
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yu Guanghua, 2021, A better real-time object detector on mobile devices
   Zhang HJ, 2020, IEEE T IND INFORM, V16, P7722, DOI 10.1109/TII.2019.2954956
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang XP, 2016, IEEE T IMAGE PROCESS, V25, P878, DOI 10.1109/TIP.2015.2509425
   Zhao YF, 2021, PROC CVPR IEEE, P15074, DOI 10.1109/CVPR46437.2021.01483
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng ZH, 2022, IEEE T CYBERNETICS, V52, P8574, DOI 10.1109/TCYB.2021.3095305
NR 31
TC 1
Z9 1
U1 4
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 40
DI 10.1007/s13735-023-00306-4
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y3JP6
UT WOS:001104268300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, ZF
   Zhang, S
   Paul, A
   Fang, LP
AF Wu, Zhefu
   Zhang, Song
   Paul, Agyemang
   Fang, Luping
TI Style-aware adversarial pairwise ranking for image recommendation
   systems
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image recommendation; Style features; Content features; Iterative
   perturbation; Adversarial training
AB The vulnerability of Machine Learning (ML) models to adversarial attack and their prominence pose security issues, notably in image recommendation systems. The adversarial training method is an excellent strategy for improving the generalization capacity of ML models by creating attacks in the embedding space during training. While there has been a plethora of testing on image recommendation system vulnerabilities and defenses, iterative adversarial training methodologies have received little attention. Furthermore, when browsing visual images, consumers are more interested in the content and how well the image style matches the content. However, when compared to image content, the impact of image styles on the adversarial recommendation community has rarely been examined. In this work, we propose a robust Adversarial Content and Style Bayesian Personalized Ranking (ACSBPR) approach that leverages content and style features for image recommendation. The ACSBPR technique makes three significant contributions: (1) Incorporate content and style features jointly for image recommendation. (2) Present a multi-objective pairwise ranking with Dynamic Negative Sampling to optimize the system and anticipate consumer preferences. (3) To reduce the influence of the attack, we train the ACSBPR objective function using minimax iterative adversarial training. Extensive investigations on the Flickr dataset demonstrate that our strategy achieves better performance when compared to state-of-the-art image recommendation models.
C1 [Wu, Zhefu; Zhang, Song; Paul, Agyemang; Fang, Luping] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Peoples R China.
C3 Zhejiang University of Technology
RP Fang, LP (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Peoples R China.
EM flp@zjut.edu.cn
FU Zhejiang Provincial Natural Science Foundation of China [LZ22F010005]
FX AcknowledgementsThis research was supported by Zhejiang Provincial
   Natural Science Foundation of China under Grant No. LZ22F010005.
CR Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Al-Halah Z, 2017, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2017.50
   Anelli VW, 2020, LECT NOTES COMPUT SC, V12123, P307, DOI 10.1007/978-3-030-49461-2_18
   Anelli Vito Walter, 2021, INT FLAIRS C P FLAIR, V34, DOI [10.32473/ flairs.v34i1.128443 Proceedings ( FLAIRS, DOI 10.32473/FLAIRS.V34I1.128443]
   Chen HY, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P363, DOI 10.1145/3298689.3346987
   Deldjoo Y, 2019, Arxiv, DOI arXiv:1908.07968
   Deldjoo Y, 2022, LECT NOTES COMPUT SC, V13186, P84, DOI 10.1007/978-3-030-99739-7_10
   Deldjoo Y, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P869, DOI 10.1145/3336191.3371877
   Di Noia T, 2020, 50TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOPS (DSN-W 2020), P1, DOI 10.1109/DSN-W50199.2020.00011
   Ding JT, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P13, DOI 10.1145/3184558.3186905
   Du YL, 2019, IEEE T MULTIMEDIA, V21, P555, DOI 10.1109/TMM.2018.2887018
   Fang MH, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P3019, DOI 10.1145/3366423.3380072
   Fang MH, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P381, DOI 10.1145/3274694.3274706
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   He M, 2019, IEEE ACCESS, V7, P14198, DOI 10.1109/ACCESS.2019.2892984
   He R., 2016, P 25 INT JOINT C ART, P3740
   He RN, 2016, AAAI CONF ARTIF INTE, P144
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   He XN, 2018, ACM/SIGIR PROCEEDINGS 2018, P355, DOI 10.1145/3209978.3209981
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Huang L., 2011, P 4 ACM WORKSH SEC A, P43
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Kabbur S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P659
   Kang WC, 2017, IEEE DATA MINING, P207, DOI 10.1109/ICDM.2017.30
   Kiapour MH, 2014, LECT NOTES COMPUT SC, V8689, P472, DOI 10.1007/978-3-319-10590-1_31
   Kurakin A, 2017, Arxiv, DOI arXiv:1607.02533
   Lam S. K., 2004, P 13 INT C WORLD WID, P393, DOI DOI 10.1145/988672.988726
   Li YC, 2017, IEEE T MULTIMEDIA, V19, P1946, DOI 10.1109/TMM.2017.2690144
   Liu Q, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/3077136.3080658
   Luo SC, 2019, CCF T PERVAS COMPUT, V1, P275, DOI 10.1007/s42486-019-00017-y
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   O'Mahony M., 2004, ACM Trans. Internet Technol, V4, DOI DOI 10.1145/1031114.1031116
   Paul A, 2022, MULTIMED TOOLS APPL, V81, P14573, DOI 10.1007/s11042-022-12259-7
   Paul A, 2022, NEURAL PROCESS LETT, V54, P637, DOI 10.1007/s11063-021-10647-y
   Paul A, 2022, APPL INTELL, V52, P3499, DOI 10.1007/s10489-021-02355-w
   Rafailidis D, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1057, DOI 10.1145/3331184.3331313
   Rendle S., 2009, P 25 C UNCERTAINTY A, P452
   Rendle S, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P273, DOI 10.1145/2556195.2556248
   Simo-Serra E, 2016, PROC CVPR IEEE, P298, DOI 10.1109/CVPR.2016.39
   Tang JH, 2020, IEEE T KNOWL DATA EN, V32, P855, DOI 10.1109/TKDE.2019.2893638
   Veit A, 2015, IEEE I CONF COMP VIS, P4642, DOI 10.1109/ICCV.2015.527
   Wang X, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P185, DOI 10.1145/3077136.3080771
   Xue F, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3314578
   Yu WH, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P649, DOI 10.1145/3178876.3186146
   Yuan F, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1065, DOI 10.1145/3331184.3331321
   Zhang WE, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3374217
   Zhang WN, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P785
NR 49
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 22
DI 10.1007/s13735-023-00295-4
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O6LG9
UT WOS:001044894800001
DA 2024-07-18
ER

PT J
AU Yang, XH
   Wang, Z
   Liu, WH
   Chang, XY
   Wu, NN
AF Yang, Xiaohan
   Wang, Zhen
   Liu, Wenhao
   Chang, Xinyi
   Wu, Nannan
TI Deep adversarial multi-label cross-modal hashing algorithm
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Cross-modal retrieval; Image-text retrieval; Cross-modal similarity
   preserving; Hashing algorithm
ID VGG-16
AB In recent years, more and more researchers employ the hashing algorithm to improve the large-scale cross-modal retrieval efficiency by mapping the floating-point feature into the compact binary code. However, the cross-modal hashing algorithm usually computes the similarity relationship based on single class labels, while ignoring the multi-label information. To solve the above problem, we propose the deep adversarial multi-label cross-modal hashing algorithm (DAMCH) which takes both multi-label and deep feature into consideration during establishing the cross-modal neighbor matrix. Firstly, we propose the inter- and intra-modal neighbor relationship preserving function to make the Hamming neighbor relationship be consistent with the original neighbor relationship. Secondly, we design linear classification functions to learn binary features' semantic labels and establish the hash semantic preserving loss function to guarantee the binary features have the same semantic information as the original label. Furthermore, we establish the intra-modal adversarial loss function to minimize the information loss during mapping the floating-point feature into the compact binary code, and propose the inter-modal adversarial loss function to ensure different modal features own the same distribution. Finally, we conduct the cross-modal retrieval comparative experiments and the ablation studies on two public datasets MIRFickr and NUS-WIDE. The experimental results show that DAMCH outperforms the current state-of-the-art methods.
C1 [Yang, Xiaohan; Wang, Zhen; Liu, Wenhao; Chang, Xinyi; Wu, Nannan] Shandong Univ Technol, Sch Comp Sci & Technol, Zibo 255000, Peoples R China.
   [Wang, Zhen] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Qianjin St, Changchun 130012, Jilin, Peoples R China.
C3 Shandong University of Technology; Jilin University
RP Wang, Z (corresponding author), Shandong Univ Technol, Sch Comp Sci & Technol, Zibo 255000, Peoples R China.; Wang, Z (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Qianjin St, Changchun 130012, Jilin, Peoples R China.
EM 21505020639@stumail.sdut.cn.com; wzh@sdut.edu.cn;
   22505030010@stumail.sdut.cn.com; 22505030007@stumail.sdut.cn.com;
   21505020635@stumail.sdut.cn.com
FU National Natural Science Foundation of China [61841602]; Natural Science
   Foundation of Shandong Province of China [ZR2021MF017, ZR2020MF147,
   ZR2018PF005]; Youth Innovation Science and Technology Team Foundation of
   Shandong Higher School [2021KJ031]; Fundamental Research Funds for the
   Central Universities, JLU [93K172021K12]
FX This research was funded by the National Natural Science Foundation of
   China, Grant Number 61841602, the Natural Science Foundation of Shandong
   Province of China, Grant Number ZR2021MF017, ZR2020MF147 and
   ZR2018PF005, the Youth Innovation Science and Technology Team Foundation
   of Shandong Higher School, Grant Number 2021KJ031 and the Fundamental
   Research Funds for the Central Universities, JLU, Grant Number
   93K172021K12.
CR [Anonymous], 2009, ICIVR
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cai LW, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14020043
   Cao Y, 2017, P BRIT MACH VIS C
   Chen SB, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107262
   Chen ZD, 2018, AAAI CONF ARTIF INTE, P274
   Cong Bai, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P525, DOI 10.1145/3372278.3390711
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Gouk H., 2016, 8 AS C MACH LEARN, V63, P318
   Gu W, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/3323873.3325045
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Jin L, 2023, IEEE T NEUR NET LEAR, V34, P1838, DOI 10.1109/TNNLS.2020.2997020
   Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Li Z., 2021, CSSE, V2, P36
   Li ZY, 2022, NEUROCOMPUTING, V483, P148, DOI 10.1016/j.neucom.2022.02.007
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Nie XS, 2021, IEEE T CIRC SYST VID, V31, P401, DOI 10.1109/TCSVT.2020.2974877
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Siddan G, 2022, MULTIMED TOOLS APPL, V81, P2393, DOI 10.1007/s11042-021-11543-2
   Simonyan K., 2014, CORR
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tu RC, 2022, IEEE T KNOWL DATA EN, V34, P560, DOI 10.1109/TKDE.2020.2987312
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Ye M, 2021, IEEE J-STARS, V14, P6916, DOI 10.1109/JSTARS.2021.3090085
   Zhan YW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3386, DOI 10.1145/3394171.3413962
   Zhang CF, 2020, J ADV COMPUT INTELL, V24, P568
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang J, 2020, IEEE T CYBERNETICS, V50, P489, DOI 10.1109/TCYB.2018.2868826
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
   Zou XT, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2020.116131
NR 36
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 16
DI 10.1007/s13735-023-00288-3
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N7XB0
UT WOS:001039085600001
DA 2024-07-18
ER

PT J
AU Jiang, ZT
   Wang, XX
   Zhai, ZY
   Cheng, B
AF Jiang, Zetao
   Wang, Xiuxian
   Zhai, Zhongyi
   Cheng, Bo
TI LG-MLFormer: local and global MLP for image captioning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image captioning; Reinforcement learning; Artificial intelligence;
   Transformer; Multi-layer perceptrons
AB Self-attention-based image captioning model exists visual features' spatial information loss problem, introducing relative position encoding can solve the problem to some extent. However, it will bring additional parameters and greater computational complexity. To solve the above problem, we propose a novel local-global MLFormer (LG-MLFormer) with specifically designed encoder module Local-global multi-layer perceptron (LG-MLP). The LG-MLP can capture the latent correlations between different images and its linear stacking calculation mode can reduce computational complexity. It consists of two independent local MLP (LM) modules and a cross-domain global MLP (CDGM) module. The LM specially designs the mapping dimension between linear layers to realize the self-compensation of visual features' spatial information without introducing relative position encoding. The CDGM module aggregates cross-domain potential correlations between grid-based features and region-based features to realize the complementary advantages of these global and local semantic associations. Experiments on the Karpathy test split and the online test server reveal that our approach provides superior or comparable performance to the state-of-the-art (SOTA).
C1 [Jiang, Zetao; Wang, Xiuxian; Zhai, Zhongyi] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin 541004, Peoples R China.
   [Cheng, Bo] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
C3 Guilin University of Electronic Technology; Beijing University of Posts
   & Telecommunications
RP Zhai, ZY (corresponding author), Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin 541004, Peoples R China.
EM zhaizhongyi@guet.edu.cn
RI Cheng, Bo/K-8817-2012
FU National Natural Science Foundation of China [62172118, 61876049];
   Nature Science key Foundation of Guangxi [GIIP2006]; Guangxi Key
   Laboratory of Image and Graphic Intelligent Processing [GIIP2007,
   GIIP2008, YCB2021070]; Innovation Project of Guangxi Graduate Education
   [YCBZ2018052, YCSW2022269, 62262009];  [2021GXNSFDA196002]
FX This work was supported by the National Natural Science Foundation of
   China under Grants (62172118, 61876049, 62262009) and Nature Science key
   Foundation of Guangxi (2021GXNSFDA196002); in part by the Guangxi Key
   Laboratory of Image and Graphic Intelligent Processing under Grants
   (GIIP2006, GIIP2007, GIIP2008); and in part by the Innovation Project of
   Guangxi Graduate Education under Grants (YCB2021070, YCBZ2018052,
   YCSW2022269).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2005, M ASS COMP LING
   Barraco M, 2022, ICPR
   Brock A, 2021, Arxiv, DOI [arXiv:2102.06171, DOI 10.48550/ARXIV.2102.06171]
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen XP, 2018, PROC CVPR IEEE, P7995, DOI 10.1109/CVPR.2018.00834
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Cornia M, 2019, PROC CVPR IEEE, P8299, DOI 10.1109/CVPR.2019.00850
   Ding X., 2021, arXiv
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Guo MH, 2021, Arxiv, DOI arXiv:2105.02358
   Herdade S, 2019, ADV NEUR IN, V32
   Hu X., 2022, IEEE C COMP VIS PATT, P17980
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Ji J, 2021, P AAAI C ARTIFICIAL
   Jiang H., 2020, IEEE C COMP VIS PATT, P10267
   Jiang WT, 2022, IEEE T CIRC SYST VID, V32, P7706, DOI 10.1109/TCSVT.2022.3181490
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kolesnikov A, 2020, Arxiv, DOI [arXiv:1912.11370, DOI 10.48550/ARXIV.1912.11370]
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuo CW, 2022, PROC CVPR IEEE, P17948, DOI 10.1109/CVPR52688.2022.01744
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li JN, 2022, Arxiv, DOI [arXiv:2201.12086, 10.48550/arXiv.2201.12086]
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H., 2021, arXiv
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, Arxiv, DOI arXiv:2101.06462
   Mao JH, 2014, Arxiv, DOI arXiv:1410.1090
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Pan Y., 2020, P IEEE C COMPUTER VI
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Radford A, 2021, PR MACH LEARN RES, V139
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Ushiku Y, 2015, IEEE I CONF COMP VIS, P2668, DOI 10.1109/ICCV.2015.306
   Vaswani A, 2021, Arxiv, DOI [arXiv:2103.12731, 10.48550/ARXIV.2103.12731]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang J, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3523-6
   Wu LX, 2021, IEEE T CIRC SYST VID, V31, P3118, DOI 10.1109/TCSVT.2020.3036860
   Xian TT, 2022, NEURAL NETWORKS, V148, P129, DOI 10.1016/j.neunet.2022.01.011
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
NR 50
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 4
DI 10.1007/s13735-023-00266-9
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9G3IK
UT WOS:000938050200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhu, CJ
   Jia, Q
   Chen, W
   Guo, YM
   Liu, Y
AF Zhu, Cunjuan
   Jia, Qi
   Chen, Wei
   Guo, Yanming
   Liu, Yu
TI Deep learning for video-text retrieval: a review
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Deep learning; Video-text retrieval; Cross-modal representation; Feature
   matching; Metric learning
AB Video-Text Retrieval (VTR) aims to search for the most relevant video related to the semantics in a given sentence, and vice versa. In general, this retrieval task is composed of four successive steps: video and textual feature representation extraction, feature embedding and matching, and objective functions. In the last, a list of samples retrieved from the dataset is ranked based on their matching similarities to the query. In recent years, significant and flourishing progress has been achieved by deep learning techniques, however, VTR is still a challenging task due to the problems like how to learn an efficient spatial-temporal video feature and how to narrow the cross-modal gap. In this survey, we review and summarize over 100 research papers related to VTR, demonstrate state-of-the-art performance on several commonly benchmarked datasets, and discuss potential challenges and directions, with the expectation to provide some insights for researchers in the field of video-text retrieval.
C1 [Zhu, Cunjuan; Jia, Qi; Liu, Yu] Dalian Univ Technol, Dalian, Peoples R China.
   [Chen, Wei; Guo, Yanming] Natl Univ Def Technol, Changsha, Peoples R China.
C3 Dalian University of Technology; National University of Defense
   Technology - China
RP Liu, Y (corresponding author), Dalian Univ Technol, Dalian, Peoples R China.
EM Zhucunjuan@163.com; jiaqi@dlut.edu.cn; weichen@nudt.edu.cn;
   guoyanming@nudt.edu.cn; liuyu8824@dlut.edu.cn
RI yu, hui/KDO-3946-2024; Zhang, Yusi/JNS-2335-2023; Ma,
   Xiaodong/JAN-7473-2023; Wang, yl/JNR-4963-2023; chen, si/JPK-4258-2023;
   zhang, yue/JAC-3705-2023; Huang, Jingyi/KCY-2239-2024; lu,
   Li/KBA-2603-2024; Lu, Wang/JVO-0416-2024; LI, Yueyi/JUF-7422-2023
FU National Natural Science Foundation of China [62102061, 62272083]
FX Funding was provided by National Natural Science Foundation of China
   (Grant Nos. 62102061, 62272083).
CR Ali A, 2022, P IEEE CVF WINT C AP, P1565
   Amrani E, 2021, AAAI CONF ARTIF INTE, V35, P6644
   [Anonymous], 2016, P 24 ACM INT C MULT
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Bain M., 2021, P IEEE CVF INT C COM, P1728
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen S., 2020, P IEEE CVF C COMP VI, P10638
   Chen Y., 2015, THESIS
   Cheng X., 2021, arXiv
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Croitoru I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11563, DOI 10.1109/ICCV48922.2021.01138
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dong J, 2022, IEEE Transactions on Circuits and Systems for Video Technology
   Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957
   Dong JF, 2018, IEEE T MULTIMEDIA, V20, P3377, DOI 10.1109/TMM.2018.2832602
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Dzabraev M, 2021, IEEE COMPUT SOC CONF, P3349, DOI 10.1109/CVPRW53098.2021.00374
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   Fan HH, 2020, AAAI CONF ARTIF INTE, V34, P10754
   Fang H., 2021, arXiv
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gabeur Valentin, 2020, P EUR C COMP VIS, V12349, P214, DOI [10.48550/arXiv.2007.10639, DOI 10.48550/ARXIV.2007.10639]
   Gao ZJ, 2022, Arxiv, DOI arXiv:2111.05610
   Ge Y., 2022, arXiv
   Ge Y, 2022, arXiv
   Ging S., 2020, PROCANNU C NEURAL IN, V33, P22605
   Gorti Satya Krishna, 2022, P IEEE CVF C COMP VI, P5006
   Guo XD, 2021, PROC CVPR IEEE, P12613, DOI 10.1109/CVPR46437.2021.01243
   Han N, 2022, Arxiv, DOI arXiv:2110.15609
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang J, 2022, Arxiv, DOI arXiv:2204.03382
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Korbar B, 2020, Arxiv, DOI arXiv:2006.07203
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Krizhevsky A, 2012, ADV NEURAL INF PROCE, V25
   Kunitsyn Alexander, 2022, arXiv
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Lei J, 2021, PROC CVPR IEEE, P7327, DOI 10.1109/CVPR46437.2021.00725
   Li LJ, 2020, Arxiv, DOI arXiv:2005.00200
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11895, DOI 10.1109/ICCV48922.2021.01170
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2020, Arxiv, DOI arXiv:1907.13487
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lu YJ, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P127, DOI 10.1145/2911996.2912015
   Luo HS, 2021, Arxiv, DOI arXiv:2104.08860
   Luo HS, 2020, Arxiv, DOI arXiv:2002.06353
   Ma YW, 2022, Arxiv, DOI arXiv:2207.07285
   Miech A, 2020, Arxiv, DOI arXiv:1804.02516
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064
   Otani Mayu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P651, DOI 10.1007/978-3-319-46604-0_46
   Patrick M, 2021, Arxiv, DOI arXiv:2010.02824
   Qiu ZF, 2019, PROC CVPR IEEE, P12048, DOI 10.1109/CVPR.2019.01233
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Radford A, 2021, PR MACH LEARN RES, V139
   Rao YM, 2021, 35 C NEURAL INFORM P, V34
   Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Tai KS, 2015, Arxiv, DOI arXiv:1503.00075
   Shvetsova N, 2021, Arxiv, DOI arXiv:2112.04446
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Y, 2019, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2019.00208
   Su WJ, 2020, Arxiv, DOI arXiv:1908.08530
   Sun C, 2019, Arxiv, DOI arXiv:1906.05743
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]
   Torabi A, 2016, Arxiv, DOI arXiv:1609.08124
   Tran D, 2017, Arxiv, DOI [arXiv:1708.05038, DOI 10.48550/ARXIV.1708.05038]
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Vaswani A, 2017, ADV NEUR IN, V30
   Wallace B., 2015, ARXIV
   Wang JP, 2022, Arxiv, DOI arXiv:2202.03384
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang Q., 2022, arXiv
   Wang XH, 2021, PROC CVPR IEEE, P5075, DOI 10.1109/CVPR46437.2021.00504
   Wang X, 2019, IEEE I CONF COMP VIS, P4580, DOI 10.1109/ICCV.2019.00468
   Wang YB, 2022, Arxiv, DOI arXiv:2208.12526
   Wray M, 2019, IEEE I CONF COMP VIS, P450, DOI 10.1109/ICCV.2019.00054
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Wu P, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3518, DOI 10.1145/3474085.3475515
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yang X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1339, DOI 10.1145/3397271.3401151
   Yao T, 2018, Arxiv, DOI arXiv:1807.00686
   Yu Y., 2016, ARXIV PREPRINT ARXIV
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Zhai AD, 2019, Arxiv, DOI arXiv:1811.12649
   Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23
   Zhang YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13557, DOI [10.1109/iccv48922.2021.01332, 10.1109/ICCV48922.2021.01332]
   Zhao S, 2022, arXiv
   Zhong YJ, 2019, LECT NOTES COMPUT SC, V11362, P35, DOI 10.1007/978-3-030-20890-5_3
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu L., 2020, P IEEE CVF C COMP VI, DOI 10.1109/CVPR42600.2020.00877
   Zhuo YX, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2022, P158, DOI 10.1145/3512527.3531381
NR 115
TC 3
Z9 3
U1 11
U2 37
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2023
VL 12
IS 1
AR 3
DI 10.1007/s13735-023-00267-8
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9G3IK
UT WOS:000938050200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, ZF
   Jiang, TL
   Liu, CP
   Ji, Y
AF Zhang, Zefan
   Jiang, Tianling
   Liu, Chunping
   Ji, Yi
TI Multi-aware coreference relation network for visual dialog
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Visual dialog; Multimedia; Coreference resolution; Cross-modal
   relationships
AB As a challenging cross-media task, visual dialog assesses whether an AI agent can converse in human language based on its understanding of visual content. So the critical issue is to pay attention not only to the problem of coreference in vision, but also to the problem of coreference in and between vision and language. In this paper, we propose the multi-aware coreference relation network (MACR-Net) to solve it from both textual and visual perspectives and to do fusion in complementary awareness. Specifically, its textual coreference relation module identifies textual coreference relations based on multi-aware textual representation from textual view. Furthermore, the visual coreference relation module adaptively adjusts visual coreference relations based on contextual-aware relations representation from visual view. Finally, the multi-modals fusion module fuses multi-aware relations to get an aligned representation. Extensive experiments on the VisDial v1.0 benchmarks show that MACR-Net achieves state-of-the-art performance.
C1 [Zhang, Zefan; Jiang, Tianling; Liu, Chunping; Ji, Yi] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215000, Jiangsu, Peoples R China.
C3 Soochow University - China
RP Liu, CP; Ji, Y (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215000, Jiangsu, Peoples R China.
EM zfzhang1997@stu.suda.edu.cn; tljiang@stu.suda.edu.cn; cpliu@suda.edu.cn;
   jiyi@suda.edu.cn
OI zhang, zefan/0000-0001-5627-050X; Liu, Chunping/0009-0008-1495-5138
FU National Natural Science Foundation of China [61972059, 61773272,
   61602332]; Natural Science Foundation of the Jiangsu Higher Education
   Institutions of China [19KJA230001]; Key Laboratory of Symbolic
   Computation and Knowledge Engineering of Ministry of Education, Jilin
   University [No93K172016K08]; Priority Academic Program Development of
   Jiangsu Higher Education Institutions (PAPD)
FX This work was supported by National Natural Science Foundation of China
   Nos 61972059, 61773272, 61602332; Natural Science Foundation of the
   Jiangsu Higher Education Institutions of China No 19KJA230001, Key
   Laboratory of Symbolic Computation and Knowledge Engineering of Ministry
   of Education, Jilin University No93K172016K08; the Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD).
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen F., 2021, ARXIV
   Clark K., 2016, P 2016 C EMPIRICAL M, P2256, DOI DOI 10.18653/V1/D16-1245
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Durrett G, 2013, P 2013 C EMP METH NA, P1971
   Gan Z, 2019, ARXIV
   Guo DL, 2019, PROC CVPR IEEE, P10426, DOI 10.1109/CVPR.2019.01068
   Hoang MH, 2021, IEEE ACCESS, V9, P90465, DOI 10.1109/ACCESS.2021.3091169
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jiang TL, 2021, INT C PATT RECOG, P2041, DOI 10.1109/ICPR48806.2021.9412629
   Jiang X., 2020, ARXIV
   Jiang XZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1265, DOI 10.1145/3394171.3413826
   Kottur S, 2018, LECT NOTES COMPUT SC, V11219, P160, DOI 10.1007/978-3-030-01267-0_10
   Lee Kenton., 2018, NAACL
   Lin J. Y., 2020, ARXIV
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2017, ADV NEUR IN, V30
   Lu JS, 2016, ADV NEUR IN, V29
   Lv J., 2020, ARXIV
   Nguyen Van-Quang, 2020, ECCV
   Niu YL, 2019, PROC CVPR IEEE, P6672, DOI 10.1109/CVPR.2019.00684
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Qiao Y, 2020, 2020 IEEE INT C MULT, P1
   Quan J., 2019, arXiv
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tu T, 2021, PROC CVPR IEEE, P5618, DOI 10.1109/CVPR46437.2021.00557
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Yang TH, 2019, IEEE I CONF COMP VIS, P2561, DOI 10.1109/ICCV.2019.00265
   Yu J, 2021, IEEE T IMAGE PROCESS, V30, P220, DOI 10.1109/TIP.2020.3034494
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
NR 32
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 567
EP 576
DI 10.1007/s13735-022-00257-2
EA NOV 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000889384400001
DA 2024-07-18
ER

PT J
AU Parseh, MJ
   Rahmanimanesh, M
   Keshavarzi, P
   Azimifar, Z
AF Parseh, Mohammad Javad
   Rahmanimanesh, Mohammad
   Keshavarzi, Parviz
   Azimifar, Zohreh
TI Semantic-aware visual scene representation
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Scene representation; Scene-specific object; Semantic feature; Deep
   visual feature
ID FEATURE FUSION; CLASSIFICATION; NETWORK; FEATURES; CNN
AB Scene classification is a mature and active computer vision task, due to the inherent ambiguity. The scene classification task aims to classify the visual scene images in predefined categories based on the ambient content, objects and the layout of the images. Inspired by human visual scene understanding, the visual scenes can be divided into two categories: (1) Object-based scenes that consist of the scene-specific objects and can be understood with those objects. (2) Layout-based scenes that are understandable based on the layout and the ambient content of the scene images. Scene-specific objects semantically help to understand object-based scenes, whereas the layout and the ambient content are effective in understanding layout-based scenes by representing the visual appearance of the scene images. Hence, one of the main challenges in scene classification is to create a discriminative representation that can provide a high-level perception of visual scenes. Accordingly, we have presented a discriminative hybrid representation of visual scenes, in which semantic features extracted from scene-specific objects are fused with visual features extracted from a deep CNN. The proposed scene representation method is used for the scene classification task and is applied to three benchmark scene datasets including: MIT67, SUN397, and UIUC Sports. Moreover, a new scene dataset, called "Scene40," has been introduced, and also, the results of our proposed method have been presented on it. Experimental results show that our proposed method has achieved remarkable performance in the scene classification task and has outperformed the state-of-the-art methods.
C1 [Parseh, Mohammad Javad; Rahmanimanesh, Mohammad; Keshavarzi, Parviz] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
   [Azimifar, Zohreh] Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.
C3 Semnan University; Shiraz University
RP Rahmanimanesh, M (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM rahmanimanesh@semnan.ac.ir
RI Keshavarzi, Parviz/M-2641-2017; Parseh, Mohammad Javad/KHD-5651-2024;
   Parseh, Mohammad Javad/AAX-6284-2021
OI Parseh, Mohammad Javad/0000-0003-0109-3133; 
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Bai S, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417550138
   Bai S, 2017, EXPERT SYST APPL, V71, P279, DOI 10.1016/j.eswa.2016.10.038
   Chen BH, 2018, PATTERN RECOGN, V76, P339, DOI 10.1016/j.patcog.2017.10.039
   Chen GW, 2020, IEEE T IMAGE PROCESS, V29, P5877, DOI 10.1109/TIP.2020.2986599
   Cheng XJ, 2018, PATTERN RECOGN, V74, P474, DOI 10.1016/j.patcog.2017.09.025
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dixit M, 2016, ADV NEUR IN, V29
   Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916
   Donggeun Yoo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P71, DOI 10.1109/CVPRW.2015.7301274
   Durand T, 2016, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2016.513
   Gamage, 2021, ARXIV
   Gao BB, 2015, ARXIV
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Guo S, 2017, IEEE T IMAGE PROCESS, V26, P808, DOI 10.1109/TIP.2016.2629443
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   Hayat M, 2016, IEEE T IMAGE PROCESS, V25, P4829, DOI 10.1109/TIP.2016.2599292
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henderson JM, 1999, ANNU REV PSYCHOL, V50, P243, DOI 10.1146/annurev.psych.50.1.243
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khan SH, 2017, IEEE I CONF COMP VIS, P5639, DOI 10.1109/ICCV.2017.601
   Khan SH, 2016, IEEE T IMAGE PROCESS, V25, P3372, DOI 10.1109/TIP.2016.2567076
   Kim HJ, 2018, LECT NOTES COMPUT SC, V11215, P471, DOI 10.1007/978-3-030-01252-6_28
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091366
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li XP, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108455
   Li YB, 2019, PATTERN RECOGN, V90, P436, DOI 10.1016/j.patcog.2019.02.005
   Li YS, 2017, IEEE I CONF COMP VIS, P5757, DOI 10.1109/ICCV.2017.613
   Limin Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P30, DOI 10.1109/CVPRW.2015.7301333
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu BY, 2015, LECT NOTES COMPUT SC, V9003, P643, DOI 10.1007/978-3-319-16865-4_42
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2335, DOI 10.1109/TPAMI.2017.2651061
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, AAAI CONF ARTIF INTE, P7178
   Liu Y, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.06.012
   López-Cifuentes A, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107256
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Messina N, 2020, INT J MULTIMED INF R, V9, P113, DOI 10.1007/s13735-019-00178-7
   Muller-Budack E, 2021, INT J MULTIMED INF R, V10, P111, DOI 10.1007/s13735-021-00207-4
   Qiu J., 2021, P IEEECVF C COMPUTER, P8322
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezanejad M, 2019, PROC CVPR IEEE, P4111, DOI 10.1109/CVPR.2019.00424
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Savchenko AV, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108248
   Seong H, 2020, IEEE ACCESS, V8, P82066, DOI 10.1109/ACCESS.2020.2989863
   Shi J, 2019, IEEE ACCESS, V7, P45230, DOI 10.1109/ACCESS.2019.2908448
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6
   Sinha N, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102066
   Song XH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4523
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Song XH, 2016, PATTERN RECOGN, V59, P98, DOI 10.1016/j.patcog.2016.01.019
   Sorkhi AG, 2020, MULTIMED TOOLS APPL, V79, P18033, DOI 10.1007/s11042-019-08264-y
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Sun N, 2019, IEEE T CIRC SYST VID, V29, P1715, DOI 10.1109/TCSVT.2018.2848543
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang PJ, 2017, NEUROCOMPUTING, V225, P188, DOI 10.1016/j.neucom.2016.11.023
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang LM, 2017, IEEE T IMAGE PROCESS, V26, P2055, DOI 10.1109/TIP.2017.2675339
   Wang Z, 2017, IEEE T IMAGE PROCESS, V26, P2028, DOI 10.1109/TIP.2017.2666739
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Xia SF, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101072
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie GS, 2017, IEEE T CIRC SYST VID, V27, P1263, DOI 10.1109/TCSVT.2015.2511543
   Xie L, 2018, PATTERN RECOGN, V82, P118, DOI 10.1016/j.patcog.2018.04.025
   Xie LX, 2017, INT J COMPUT VISION, V123, P226, DOI 10.1007/s11263-016-0970-x
   Xie LX, 2016, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2016.36
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Yang Y, 2011, PROCEDIA ENGINEER, V24, P177, DOI 10.1016/j.proeng.2011.11.2622
   Yin WB, 2019, J VIS COMMUN IMAGE R, V60, P59, DOI 10.1016/j.jvcir.2019.01.002
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng D., 2021, ARXIV
   Zhang CJ, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103084
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 101
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 619
EP 638
DI 10.1007/s13735-022-00246-5
EA AUG 2022
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000847604300001
DA 2024-07-18
ER

PT J
AU Bulbul, MF
   Islam, S
   Azme, Z
   Pareek, P
   Kabir, MH
   Ali, H
AF Bulbul, Mohammad Farhad
   Islam, Saiful
   Azme, Zannatul
   Pareek, Preksha
   Kabir, Md Humaun
   Ali, Hazrat
TI Enhancing the performance of 3D auto-correlation gradient features in
   depth action classification
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Depth action recognition; Depth motion maps; Auto-correlation features;
   Collaborative representation; Dictionary learning
ID HUMAN ACTION RECOGNITION; MOTION RECOGNITION; DESCRIPTOR; FUSION; IMAGE;
   POSE; 2D
AB The 3D auto-correlation gradient features have demonstrated only limited success on depth action data, whereas the 2D auto-correlation gradient features have been successful in the domain. In this paper, we propose to calculate three depth motion map sequences from each depth action video by accumulating only the motion information of the action. We then obtain the three vectors of 3D auto-correlation gradient features by applying the space-time auto-correlation of gradients (STACOG) descriptor on the depth motion map sequences. The three vectors are then concatenated and passed to an unsupervised classifier to recognize the action. The experimental evaluation on four public datasets (MSR-Action3D, DHA, UTD-MHAD, and MSR-Gesture3D dataset) demonstrates the superiority of our proposed method over state-of-the-art methods.
C1 [Bulbul, Mohammad Farhad; Azme, Zannatul] Jashore Univ Sci & Technol, Dept Math, Jashore, Bangladesh.
   [Islam, Saiful] Stamford Univ Bangladesh, Dept Comp Sci & Engn, Dhaka, Bangladesh.
   [Pareek, Preksha] Nirma Univ, Inst Technol, Ahmadabad, Gujarat, India.
   [Kabir, Md Humaun] Jashore Univ Sci & Technol, Dept Phys, Jashore, Bangladesh.
   [Ali, Hazrat] Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar.
C3 Stamford University Bangladesh; Nirma University; Qatar Foundation (QF);
   Hamad Bin Khalifa University-Qatar
RP Ali, H (corresponding author), Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar.
EM farhad@just.edu.bd; haali2@hbku.edu.qa
RI Ali, Hazrat/J-2920-2019; ISLAM, SAIFUL/HMD-6072-2023; Pareek,
   Preksha/HNI-1351-2023
OI Ali, Hazrat/0000-0003-3058-5794; ISLAM, SAIFUL/0000-0001-6693-0559;
   Pareek, Preksha/0000-0002-5653-1500
CR Ahmad Z, 2021, IEEE SENS J, V21, P3623, DOI 10.1109/JSEN.2020.3028561
   Al-Obaidi S., 2019, P 3 IET INT C TECHN
   Ali Heba Hamdy, 2018, Future Computing and Informatics Journal, V3, P51, DOI 10.1016/j.fcij.2017.11.002
   Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bulbul MF, 2019, 2019 UK CHINA EMERGI, P1
   Bulbul MF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113642
   Bulbul MF, 2021, COMPUT J, V64, P1633, DOI 10.1093/comjnl/bxz123
   Bulbul MF, 2019, J INTELL FUZZY SYST, V36, P3385, DOI 10.3233/JIFS-181136
   Bulbul MF, 2015, INT J MULTIMED DATA, V6, P23, DOI 10.4018/IJMDEM.2015100102
   Chen C, 2017, IEEE ACCESS, V5, P22590, DOI 10.1109/ACCESS.2017.2759058
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   De Smedt Q., 2018, P INT WORKSH UND HUM, V10188, P86, DOI 10.1007/978-3-319-91863-1-7
   Gao Z, 2014, KSII T INTERNET INF, V8, P483, DOI 10.3837/tiis.2014.02.009
   Gao Z, 2014, J ELECTR ENG TECHNOL, V9, P739, DOI 10.5370/JEET.2014.9.2.739
   Gul MA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9121993
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Ji XP, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P208, DOI 10.1109/ICACI.2016.7449827
   Ke Jina, 2017, The Journal of Engineering, DOI 10.1049/joe.2016.0330
   Khan S, 2018, 2018 12TH INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P71, DOI 10.1109/ICOSST.2018.8632192
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Kong J, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033027
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Kwon D, 2016, IEEE ACCESS, V4, P3659, DOI 10.1109/ACCESS.2016.2587754
   Lemieux N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174946
   Li C, 2017, IEEE INT CONF MULTI
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu H, 2015, IEEE IMAGE PROC, P4674, DOI 10.1109/ICIP.2015.7351693
   Liu MY, 2019, AAAI CONF ARTIF INTE, P8762
   Liu MY, 2016, INT CONF 3D VISION, P47, DOI 10.1109/3DV.2016.14
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Martin M, 2019, IEEE I CONF COMP VIS, P2801, DOI 10.1109/ICCV.2019.00289
   Nghia Liu Kim, 2018, INT J IMAGE GRAPHICS, V10, P9
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Ou HS, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6670087
   Park S, 2018, INT CONF UBIQ FUTUR, P868, DOI 10.1109/ICUFN.2018.8436644
   Rahmani H, 2016, PATTERN RECOGN LETT, V72, P62, DOI 10.1016/j.patrec.2015.07.015
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Rani SS, 2021, MATER TODAY-PROC, V37, P3164, DOI 10.1016/j.matpr.2020.09.052
   Rodomagoulakis I, 2016, INT CONF ACOUST SPEE, P2702, DOI 10.1109/ICASSP.2016.7472168
   Shojaei-Hashemi A, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351648
   Sidor K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102940
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tang Nick C., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4608, DOI 10.1109/ICASSP.2014.6854475
   Tasnim N, 2020, INVENTIONS-BASEL, V5, DOI 10.3390/inventions5030049
   Tikhonov A. N., 1979, SOLUTIONS ILL POSED, V21, P266, DOI [10.1137/1021044, DOI 10.1137/1021044]
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang Q, 2020, NEURAL NETWORKS, V122, P1, DOI 10.1016/j.neunet.2019.09.029
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang R, 2014, ASIAN C COMPUTER VIS, P37
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
NR 68
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD MAR
PY 2022
VL 11
IS 1
BP 61
EP 76
DI 10.1007/s13735-021-00226-1
EA JAN 2022
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI9SJ
UT WOS:000743005300001
DA 2024-07-18
ER

PT J
AU Suresha, M
   Kuppa, S
   Raghukumar, DS
AF Suresha, M.
   Kuppa, S.
   Raghukumar, D. S.
TI A study on deep learning spatiotemporal models and feature extraction
   techniques for video understanding
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Spatiotemporal; Deep learning; Video understanding; Computer vision;
   Survey
ID ACTION RECOGNITION; REPRESENTATION; SURVEILLANCE; CHALLENGES; FRAMEWORK;
   CUES
AB Video understanding requires abundant semantic information. Substantial progress has been made on deep learning models in the image, text, and audio domains, and notable efforts have been recently dedicated to the design of deep networks in the video domain. We discuss the state-of-the-art convolutional neural network (CNN) and its pipelines for the exploration of video features, various fusion strategies, and their performances; we also discuss the limitations of CNN for long-term motion cues and the use of sequential learning models such as long short-term memory to overcome these limitations. In addition, we address various multi-model approaches for extracting important cues and score fusion techniques from hybrid deep learning frameworks. Then, we highlight future plans in this domain, recent trends, and substantial challenges for video understanding. This survey's objectives are to study the plethora of approaches that have been developed for solving video understanding problems, to comprehensively study spatiotemporal cues, to explore the various models that are available for solving these problems and to identify the most promising approaches.
C1 [Suresha, M.; Kuppa, S.; Raghukumar, D. S.] Kuvempu Univ, Dept Comp Sci, Shimoga 577451, Karnataka, India.
C3 Kuvempu University
RP Suresha, M (corresponding author), Kuvempu Univ, Dept Comp Sci, Shimoga 577451, Karnataka, India.
EM sureshm@kuvempu.ac.in; kuppa1993@gmail.com; rg12.clk@gmail.com
RI s, kuppa/AAM-1714-2021; M, Suresha/IYJ-0254-2023
OI s, kuppa/0000-0002-7897-6789; M, Suresha/0000-0003-0668-926X
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   [Anonymous], 2016, ARXIV160906782
   Atluri G, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161602
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   BARRETT B, 2018, WIRED
   Bhorge SB, 2018, INT J MULTIMED INF R, V7, P197, DOI 10.1007/s13735-018-0152-4
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Burghouts GJ, 2013, PATTERN RECOGN LETT, V34, P1861, DOI 10.1016/j.patrec.2013.01.024
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen D, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0122-0
   Chen K, 2018, INT J MULTIMED INF R, V7, P17, DOI 10.1007/s13735-017-0139-6
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Cocchia A, 2014, PROGR IS, P13, DOI 10.1007/978-3-319-06160-3_2
   Deldjoo Y, 2018, INT J MULTIMED INF R, V7, P207, DOI 10.1007/s13735-018-0155-1
   Du GM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P708, DOI 10.1109/SIPROCESS.2016.7888355
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2018, LECT NOTES COMPUT SC, V11220, P388, DOI 10.1007/978-3-030-01270-0_23
   Evensen D, 2019, NAT CLIM CHANGE, V9, P428, DOI 10.1038/s41558-019-0481-1
   Fan J., 2019, A Selective Overview of Deep Learning
   *FED HIGHW ADM, 2015, VID AN RES PROJ RES
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Gonzalez Teofilo F, 2007, Handbook of approximation algorithms and metaheuristics
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Hatcher WG, 2018, IEEE ACCESS, V6, P24411, DOI 10.1109/ACCESS.2018.2830661
   He D., 2018, ARXIV PREPRINT ARXIV
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Huang H., 2018, ARXIV180304469
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Kahn Jeremy., 2018, Bloomberg
   KANGWEI L, 2018, SIGNAL IMAGE VIDEO P, V12, P255
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2
   Kong Y., 2018, ARXIV180611230
   Krüger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Kumaran S. Kelathodi, 2019, arXiv, arXiv-1901.
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lenz I, 2012, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2012.6386146
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Li F, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P579, DOI 10.1109/ICACI.2012.6463231
   Li Q, 2017, INT J MULTIMED INF R, V6, P85, DOI 10.1007/s13735-016-0117-4
   LI XG, 2017, INT J CIV ENG
   Liu J, 2019, APPL INTELL, V49, P3436, DOI 10.1007/s10489-019-01459-8
   Livni R, 2014, ADV NEUR IN, V27
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mamoshina P, 2016, MOL PHARMACEUT, V13, P1445, DOI 10.1021/acs.molpharmaceut.5b00982
   Marcus G., 2018, ARXIV180100631
   Melfi R, 2013, PATTERN RECOGN LETT, V34, P1990, DOI 10.1016/j.patrec.2013.04.025
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Mithun NC, 2019, INT J MULTIMED INF R, V8, P3, DOI 10.1007/s13735-018-00166-3
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Naseer S, 2018, IEEE ACCESS, V6, P48231, DOI 10.1109/ACCESS.2018.2863036
   Palma-Behnke R., 2012, 2012 IEEE PES Innovative Smart Grid Technologies (ISGT), DOI 10.1109/ISGT.2012.6175756
   Papadopoulos K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163503
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Peng KJ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P960, DOI 10.1109/ROBIO.2009.5420735
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Qiu ZF, 2018, IEEE T MULTIMEDIA, V20, P939, DOI 10.1109/TMM.2017.2759504
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rolnick D., 2019, ARXIV190605433
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sekma M, 2015, PATTERN RECOGN LETT, V65, P37, DOI 10.1016/j.patrec.2015.06.029
   SELIGMAN L, 2016, DEF NEWS
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Shou Z, 2019, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2019.00136
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Sivarajah U, 2017, J BUS RES, V70, P263, DOI 10.1016/j.jbusres.2016.08.001
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Sun C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P371, DOI 10.1145/2733373.2806226
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thakkar K. C., 2018, PRAC BRIZ MACH VIS C, P270
   Tian YC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P303, DOI 10.1145/3180155.3180220
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Van-Dung Hoang, 2018, IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society. Proceedings, P3225, DOI 10.1109/IECON.2018.8591338
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang T, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P13, DOI 10.1109/AVSS.2012.39
   Wang Y, 2017, IEEE INT CONF COMP V, P2129, DOI 10.1109/ICCVW.2017.249
   Wang Z, 2018, NEUROCOMPUTING, V287, P68, DOI 10.1016/j.neucom.2018.01.076
   WENG X, 2019, ARXIV190309616
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Wu ZX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P167, DOI 10.1145/2647868.2654931
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yao L, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/1760172
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Yuan Y, 2016, PATTERN RECOGN, V59, P88, DOI 10.1016/j.patcog.2016.02.022
   Zablocki M., 2014, Journal of Theoretical and Applied Computer Science, V8, P13
   Ouadiay FZ, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Zhan FN, 2019, PROC CVPR IEEE, P3648, DOI 10.1109/CVPR.2019.00377
   Zhang C., 2018, A study on overfitting in deep reinforcement learning
   ZHANG H, 2019, ARXIV190305577
   Zhang JF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173735
   Zhang WC, 2019, ALGORITHMS, V12, DOI 10.3390/a12010008
   Zhang XY, 2019, AAAI CONF ARTIF INTE, P9227
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
   Zhu Alex Zihao, 2018, ARXIV180206898, DOI [10.15607/RSS.2018.XIV.062, DOI 10.15607/RSS.2018.XIV.062]
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   2018, HONDA NEWS
NR 120
TC 14
Z9 15
U1 4
U2 22
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2020
VL 9
IS 2
SI SI
BP 81
EP 101
DI 10.1007/s13735-019-00190-x
EA JAN 2020
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ4GS
UT WOS:000509166000001
DA 2024-07-18
ER

PT J
AU Schedl, M
   Zamani, H
   Chen, CW
   Deldjoo, Y
   Elahi, M
AF Schedl, Markus
   Zamani, Hamed
   Chen, Ching-Wei
   Deldjoo, Yashar
   Elahi, Mehdi
TI Current challenges and visions in music recommender systems research
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Music recommender systems; Challenges; Automatic playlist continuation;
   User-centric computing
ID OF-THE-ART; INFORMATION-RETRIEVAL; USER; PERSONALITY; PREFERENCES;
   CONTEXT; EXPRESSION; DIVERSITY; EMOTIONS; FEEDBACK
AB Music recommender systems (MRSs) have experienced a boom in recent years, thanks to the emergence and success of online streaming services, which nowadays make available almost all music in the world at the user's fingertip. While today's MRSs considerably help users to find interesting music in these huge catalogs, MRS research is still facing substantial challenges. In particular when it comes to build, incorporate, and evaluate recommendation strategies that integrate information beyond simple user-item interactions or content-based descriptors, but dig deep into the very essence of listener needs, preferences, and intentions, MRS research becomes a big endeavor and related publications quite sparse. The purpose of this trends and survey article is twofold. We first identify and shed light on what we believe are the most pressing challenges MRS research is facing, from both academic and industry perspectives. We review the state of the art toward solving these challenges and discuss its limitations. Second, we detail possible future directions and visions we contemplate for the further evolution of the field. The article should therefore serve two purposes: giving the interested reader an overview of current challenges in MRS research and providing guidance for young researchers by identifying interesting, yet under-researched, directions in the field.
C1 [Schedl, Markus] Johannes Kepler Univ Linz, Dept Computat Percept, Linz, Austria.
   [Zamani, Hamed] Univ Massachusetts, Ctr Intelligent Informat Retrieval, Amherst, MA 01003 USA.
   [Chen, Ching-Wei] Spotify USA Inc, New York, NY USA.
   [Deldjoo, Yashar] Politecn Milan, Dept Comp Sci, Milan, Italy.
   [Elahi, Mehdi] Free Univ Bozen Bolzano, Bolzano, Italy.
C3 Johannes Kepler University Linz; University of Massachusetts System;
   University of Massachusetts Amherst; Spotify; Polytechnic University of
   Milan; Free University of Bozen-Bolzano
RP Schedl, M (corresponding author), Johannes Kepler Univ Linz, Dept Computat Percept, Linz, Austria.
EM markus.schedl@jku.at; zamani@cs.umass.edu; cw@spotify.com;
   yashar.deldjoo@polimi.it; meelahi@unibi.it
RI Deldjoo, Yashar/O-5453-2015; Deldjoo, Yashar/ABB-5753-2020; Elahi,
   Mehdi/S-2348-2019
OI Deldjoo, Yashar/0000-0002-6767-358X; Elahi, Mehdi/0000-0003-2203-9195;
   Schedl, Markus/0000-0003-1706-3406
FU Johannes Kepler University Linz
FX Open access funding provided by Johannes Kepler University Linz. We
   would like to thank all researchers in the fields of recommender
   systems, information retrieval, music research, and multimedia, with
   whom we had the pleasure to discuss and collaborate in recent years, and
   whom in turn influenced and helped shaping this article. Special thanks
   go to Peter Knees and Fabien Gouyon for the fruitful discussions while
   preparing the ACM Recommender Systems 2017 tutorial on music recommender
   systems. In addition, we would like to thank the reviewers of our
   manuscript, who provided useful and constructive comments to improve the
   original draft and turn it into what it is now. We would also like to
   thank Eelco Wiechert for providing additional pointers to relevant
   literature. Furthermore, the many personal discussions with actual users
   of MRS unveiled important shortcomings of current approaches and in turn
   were considered in this article.
CR Adamopoulos P, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2559952
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Agarwal D, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P19
   Aggarwal C C., 2016, Recommender Systems, P139
   Aggarwal C. C., 2016, RECOMMENDER SYSTEMS, P199
   Aggarwal C. C., 2016, RECOMMENDER SYSTEMS, P225, DOI [DOI 10.1007/S10489-021-03121-8, DOI 10.1007/978-3-319-29659-3_7]
   Aiolli Fabio, 2013, P RECSYS, P273, DOI DOI 10.1145/2507157.2507189
   Alghoniemy M., 2000, Proceedings ACM Multimedia 2000, P356, DOI 10.1145/354384.375451
   Alghoniemy M., 2001, P IEEE INT C MULT EX
   [Anonymous], 2010, P 7 SOUND MUS COMP C
   [Anonymous], 2011, P ISMIR
   [Anonymous], 2010, 11 INT SOC MUS INF R
   [Anonymous], 2009, P 3 ACM C REC SYST A, DOI DOI 10.1145/1639714.1639720
   [Anonymous], 2014, P 4 ACM INT C MULT R
   [Anonymous], 2006, P INT SOC MUS INF RE
   [Anonymous], 2012, ACM T INTEL SYST TEC, DOI DOI 10.1145/2168752.2168754
   [Anonymous], 2012, P INT S COMP MUS MOD
   Baeza-Yates R A, 2011, MODERN INFORM RETRIE
   Baltrunas L, 2011, LECT NOTES BUS INF P, V85, P89
   Barrington L., 2009, Proceedings of the International Conference on Music Information Retrieval, P357
   Bauer C, 2017, J AMB INTEL SMART EN, V9, P377, DOI 10.3233/AIS-170445
   Bennett PN, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P135
   Bodner E, 2007, ART PSYCHOTHER, V34, P142, DOI 10.1016/j.aip.2006.12.002
   Boer D, 2012, PSYCHOL MUSIC, V40, P179, DOI 10.1177/0305735610381885
   Bogdanov D, 2013, INFORM PROCESS MANAG, V49, P13, DOI 10.1016/j.ipm.2012.06.004
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Bonnin G, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2652481
   Braunhofer M., 2014, Information and Communication Technologies in Tourism, P537, DOI [DOI 10.1007/978-3-319-14343-9_39, 10.1007/978-3-319-14343-939, DOI 10.1007/978-3-319-14343-939]
   Braunhofer M, 2014, INTELL ARTIF, V8, P129, DOI 10.3233/IA-140069
   Breese J., 1998, P 14 C UNC ART INT, P43
   Burger J.M., 2010, Personality
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Cantador I., 2015, CROSS DOMAIN RECOMME, P919
   Cantador I, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P401, DOI 10.1145/2645710.2645777
   Carenini G., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P12, DOI 10.1145/604045.604052
   Caulder S., 2008, P 3 INT AUD MOSTL C
   Cebrian T., 2010, Proceedings of 4th ACM Conference on Recommender Systems, P349
   Chen S., 2012, P 18 ACM SIGKDD INT, P714, DOI [DOI 10.1145/2339530.2339643, 10.1145/2339530.2339643]
   Chen S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P865
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Cornelis O, 2013, J NEW MUSIC RES, V42, P131, DOI 10.1080/09298215.2013.812123
   Cremonesi P., 2011, 2011 IEEE International Conference on Data Mining Workshops, P496, DOI 10.1109/ICDMW.2011.57
   Cremonesi P, 2017, MULTIMED TOOLS APPL, V76, P5275, DOI 10.1007/s11042-016-3946-5
   Cremonesi P, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P297, DOI 10.1145/2645710.2645769
   Cunningham S. J., 2009, P 10 INT SOC MUS INF
   Cunningham S.J., 2005, P 6 INT C MUS INF RE, P474
   Cunningham S.J., 2007, Proceedings of the 8th International Society for Music Information Retrieval Conference (ISMIR'07), P83
   CUNNINGHAM SJ, 2006, P 7 INT C MUS INF RE
   Deldjoo Y, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095734
   Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Dey L, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV)
   Donaldson J, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P187
   Dror Gideon, 2011, P 2011 INT C KDD CUP, P3
   Dunn G, 2009, LECT NOTES COMPUT SC, V5535, P259, DOI 10.1007/978-3-642-02247-0_25
   Dutta S., 2014, INT SOC MUSIC INFORM, P397
   Dzhambazov Georgi Bogomilov, 2016, P 17 INT SOC MUSIC I, P716
   Eghbal-Zadeh H., 2015, P 16 INT SOC MUSIC I, P554
   Elahi Mehdi, 2013, AI*IA 2013: Advances in Artificial Intelligence. XIIIth International Conference of the Italian Association for Artificial Intelligence. Proceedings: LNCS 8249, P360, DOI 10.1007/978-3-319-03524-6_31
   Elahi M., 2012, P 20 INT C FDN INT S, P254, DOI DOI 10.1007/978-3-642-34624-8_30
   Elahi M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P326, DOI 10.1145/3109859.3109908
   Elahi M, 2016, COMPUT SCI REV, V20, P29, DOI 10.1016/j.cosrev.2016.05.002
   Elahi M, 2014, LECT NOTES BUS INF P, V188, P113
   Elahi M, 2013, ACM T INTEL SYST TEC, V5, DOI 10.1145/2542182.2542195
   Elahi M, 2011, LECT NOTES BUS INF P, V85, P160
   Elahi M, 2011, LECT NOTES COMPUT SC, V6787, P414, DOI 10.1007/978-3-642-22362-4_40
   Elbadrawy A, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2700495
   Erdal M, 2016, LECT NOTES ARTIF INT, P298, DOI 10.1007/978-3-319-46182-3_25
   Fang-Fei Kuo, 2005, 13th Annual ACM International Conference on Multimedia, P507
   Fern~andez-Tob ias I, 2012, Proceedings of Spanish Conference on Information Retrieval, P1
   Fernández-Tobías I, 2016, USER MODEL USER-ADAP, V26, P221, DOI 10.1007/s11257-016-9172-z
   Ferwerda B., 2015, POSTERS DEMOS LATE B, V1388
   Ferwerda B., 2016, 24 C US MOD AD PERS
   Ferwerda B, 2016, P 4 WORKSH EM PERS P
   Ferwerda B., 2016, P 2016 C US MOD AD P, P287
   Ferwerda B., 2015, P 33 ANN ACM C EXT A, P2241, DOI [10.1145/2702613.2732754, DOI 10.1145/2702613.2732754]
   FLEXER A, 2008, P 9 INT C MUS INF RE
   Gillhofer M, 2015, P 21 INT C MULT MOD
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Gross J.J., 2007, HDB EMOTION REGULATI, P1
   Gunawardana Asela, 2015, Recommender Systems Handbook, P265, DOI [DOI 10.1007/978-1-0716-2197-415, 10.1007/978-1-0716-2197-4_15, DOI 10.1007/978-1-0716-2197-4_15]
   Hart J., 2012, CHI C HUM FACT COMP
   Hassenzahl M., 2005, The thing and I: understanding the relationship between user and product, P31, DOI [10.1007/1-4020-2967-5_4ID:Hassenzahl2005, DOI 10.1007/AND1-4020-2967-54]
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herrera P, 2010, 1 WORKHS MUS REC DIS, P7
   Hevner K, 1935, PSYCHOL REV, V42, P186, DOI 10.1037/h0054832
   Hu R., 2011, RECSYS 11 P 5 ACM C, P197, DOI [10.1145/2043932.2043969, DOI 10.1145/2043932.2043969]
   Hu R, 2010, LECT NOTES COMPUT SC, V6075, P291
   Hu Rong., 2009, Proceedings of the 14th international conference on Intelligent user interfaces, P367
   Hu X, 2012, P ISMIR
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Huq A, 2010, J NEW MUSIC RES, V39, P227, DOI 10.1080/09298215.2010.513733
   Iman Kamehkhosh Dietmar Jannach GB, 2018, JOINT P 23 ACM C INT
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   John O.P., 1999, HDB PERSONALITY THEO, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260
   Juslin P. N, 2011, HDB MUSIC EMOTION TH
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kaminskas M., 2013, P 7 ACM C REC SYST N, P17
   Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720
   Kaminskas M, 2012, COMPUT SCI REV, V6, P89, DOI 10.1016/j.cosrev.2012.04.002
   Kelly JP, 2006, ARTIF INTELL REV, V25, P79, DOI 10.1007/s10462-007-9023-8
   Khan MM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3073565
   Kluver D, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P121, DOI 10.1145/2645710.2645742
   Knees P, 2016, INFORM RETRIEVAL SER
   Knees P., 2006, P 8 ACM SIGMM INT WO
   Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4
   Knijnenburg Bart P., 2015, Evaluating Recommender Systems with User Experiments, P309, DOI [DOI 10.1007/978-1-4899-7637-69, 10.1007/978-0-387-85820-3, DOI 10.1007/978-1-4899-7637-6_9]
   Konecni V.J., 1982, The psychology of music, P497
   Koole S, 2009, COGNITION EMOTION, V23, P4, DOI 10.1080/02699930802619031
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Laplante A, 2014, 15 INT SOC MUS INF R
   Laplante A., 2006, P 7 INT C MUSIC INFO, P381
   Lee JH, 2011, P 12 INT SOC MUS INF
   Lee JH, 2017, J ASSOC INF SCI TECH, V68, P1186, DOI 10.1002/asi.23754
   Lee JH, 2016, J ASSOC INF SCI TECH, V67, P1301, DOI 10.1002/asi.23471
   Lehmann J., 2012, P INT C US MOD AD PE, P164
   Li Q, 2005, LECT NOTES COMPUT SC, V3689, P72
   Liu NathanN., 2008, P 31 ANN INT ACM SIG, P83
   Logan B., 2002, ISMIR, V2, P295
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   Maillet F., 2009, P INT SOC MUSIC INFO, P345
   McFee B, 2012, P 21 INT C WORLD WID, P909, DOI [DOI 10.1145/2187980, 10.1145/2187980.2188222]
   McFee B., 2012, The International Society for Music Information Retrieval (ISMIR), P343
   McFee Brian, 2011, P 12 INT SOC MUS INF
   McNee SM, 2003, LECT NOTES ARTIF INT, V2702, P178
   Mei T, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1961209.1961213
   North A., 1996, Psychomusicology, V15, P30, DOI [DOI 10.1037/H0094081, 10.1037/h0094081]
   North A. C., 2008, The social and applied psychology of music
   Novello A, 2006, P 7 INT C MUS INF RE
   O'Brien HL, 2010, J AM SOC INF SCI TEC, V61, P50, DOI 10.1002/asi.21229
   O'Hara K., 2006, Consuming music together: social and collaborative aspects of music consumption technologies, V35
   Pachet F, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P457, DOI 10.1109/MMCS.1999.779245
   Pagano R, 2017, ARXIV170102021 CORR
   Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16
   Panteli M., 2016, P 17 INT SOC MUS INF, P538
   Pettijohn TF, 2010, CURR PSYCHOL, V29, P328, DOI 10.1007/s12144-010-9092-8
   Pichl M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1360, DOI 10.1109/ICDMW.2015.145
   Pohle T, 2007, IEEE T MULTIMEDIA, V9, P567, DOI 10.1109/TMM.2006.887991
   Pu P, 2012, USER MODEL USER-ADAP, V22, P317, DOI 10.1007/s11257-011-9115-7
   Punkanen M, 2011, J AFFECT DISORDERS, V130, P118, DOI 10.1016/j.jad.2010.10.034
   Quadrana M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190616
   Rashid A. M., 2008, SIGKDD Explorations, V10, P90
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   Repetto RC, 2014, P INT SOC MUS INF RE, P313
   Reynolds G., 2007, Proceedings of Audio Mostly Conference: Interaction with Sound, P84
   Rubens N, 2011, RECOMMENDER SYSTEMS HANDBOOK, P735, DOI 10.1007/978-0-387-85820-3_23
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schäfer T, 2017, PERS INDIV DIFFER, V116, P265, DOI 10.1016/j.paid.2017.04.061
   Schäfer T, 2016, MUSIC SCI, V20, P263, DOI 10.1177/1029864915622054
   Schäfer T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00511
   Schedl M, 2012, P 2 WORKSH CONT AW R
   Schedl M., 2015, Recommender Systems Handbook, V2nd, P453, DOI DOI 10.1007/978-1-4899-7637-6_13
   Schedl M, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P157, DOI 10.1145/2910017.2910604
   Schedl M, 2018, IEEE T AFFECT COMPUT, V9, P507, DOI 10.1109/TAFFC.2017.2663421
   Schedl M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P392, DOI 10.1145/3109859.3109934
   Schedl M, 2017, INT J MULTIMED INF R, V6, P71, DOI 10.1007/s13735-017-0118-y
   Schedl M, 2013, J INTELL INF SYST, V41, P523, DOI 10.1007/s10844-013-0247-6
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Serra X, 2014, AUD ENG SOC C 53 INT
   Serra X, 2014, J NEW MUSIC RES, V43, P1, DOI 10.1080/09298215.2014.894083
   Seyerlehner K., 2010, AUDIO TRAIN TEST TAS
   Shao B, 2009, IEEE T AUDIO SPEECH, V17, P1602, DOI 10.1109/TASL.2009.2020893
   Skowron M, 2017, LECT NOTES COMPUT SC, V10193, P561, DOI 10.1007/978-3-319-56608-5_49
   Skowron M, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P107, DOI 10.1145/2872518.2889368
   Slaney Malcolm, 2006, Proceedings of the 1st ACM Workshop on Audio and Music Computing Multimedia, P77, DOI 10.1145/1178723.1178735
   Smyth B, 2001, LECT NOTES ARTIF INT, V2080, P347
   Sordo Mohamad., 2014, P 1 INT C DIGITAL LI, P1, DOI DOI 10.1145/2660168.2660182
   Swearingen K., 2001, P ACM SIGIR WORKSH R, V13, P1
   Tamir M, 2011, EMOT REV, V3, P3, DOI 10.1177/1754073910388685
   Tintarev N, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P391, DOI 10.1145/3079628.3079633
   Tkalcic M, 2016, USER MODEL USER-ADAP, V26, P103, DOI 10.1007/s11257-016-9175-9
   Tkalcic M, 2013, J MULTIMODAL USER IN, V7, P143, DOI 10.1007/s12193-012-0107-7
   Uitdenbogerd A, 2002, ISMIR 2002, P204
   Vall Andreu, 2017, RECSYS POSTERS
   Vargas S., 2011, P 5 ACM C RECOMMENDE, P109, DOI DOI 10.1145/2043932.2043955
   Vargas S, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P209, DOI 10.1145/2645710.2645743
   Wang Xinxi., 2012, Proceedings of the 20th ACM international conference on Multimedia, P99, DOI [DOI 10.1145/2393347.2393368, 10.1145/2393347.2393368]
   Weimer M, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P275
   Yang YH, 2011, MULTIMEDIA COMPUT CO, P1
   Yang YH, 2013, ACM T INTEL SYST TEC, V3
   Zamani N, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1531, DOI 10.1145/3038912.3052648
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhang Yuan Cao, 2012, P 5 ACM INT C WEB SE
   Zhang ZH, 2016, AAAI CONF ARTIF INTE, P2358
   Zheleva Elena., 2010, Proceedings of the 19th international conference on World wide web, WWW '10, P1019
   Zhou T, 2010, P NATL ACAD SCI USA, V107, P4511, DOI 10.1073/pnas.1000488107
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
   Ziviani N, 2012, P 6 ACM C REC SYST, P19, DOI [DOI 10.1145/2365952.2365962, 10.1145/2365952.2365962]
NR 191
TC 145
Z9 154
U1 5
U2 44
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2018
VL 7
IS 2
BP 95
EP 116
DI 10.1007/s13735-018-0154-2
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GR5AE
UT WOS:000442633600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Sharma, A
   Singh, R
AF Sharma, Abhilasha
   Singh, Roshni
TI ConvST-LSTM-Net: convolutional spatiotemporal LSTM networks for
   skeleton-based human action recognition
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Activity recognition; LSTM; Spatiotemporal; Skeleton sequence; ConvLSTM
ID MOTION ANALYSIS; FUSION
AB Human action recognition (HAR) emphases on perceiving and identifying the action behavior done by humans within an image/video. The HAR activities include motion patterns and normal or abnormal activities like standing, walking, sitting, running, playing, falling, fighting, etc. Recently, it sparks the attention of researchers especially in 3D skeleton sequence. The actions of human can be represented via sequence of motions of skeletal keyjoints, although not all the skeleton keyjoints are informative in nature. Various approaches for HAR are used like LSTM, ConvLSTM, Conv-GRU, ST-LSTM, etc. Thus far, ST-LSTM approaches have shown tremendous performance in 3D skeleton sequence tasks but the detection of irrelevant keyjoints produce noise that deteriorates the performance of the model. So, the intent is to bring attention toward improving the efficacy of the model by focusing on informative keyjoint coordinates only. Therefore, the research paper introduces a new class of spatiotemporal LSTM approaches named as ConvST-LSTM-Net (convolutional spatiotemporal long short-term memory network) for skeleton-based action recognition. The prime focus of proposed model is to identify the informative keyjoints in each frame. The result of extensive experimental analysis exhibits that ConvST-LSTM-Net outperforms the state-of-the-art models on various benchmarks dataset, viz. NTU RGB + D 60, UT-Kinetics, UP-Fall Detection, UCF101, and HDMB51 for skeleton sequence data.
C1 [Sharma, Abhilasha; Singh, Roshni] Delhi Technol Univ, Dept Software Engn, Shahbad Daulatpur 110042, Delhi, India.
C3 Delhi Technological University
RP Singh, R (corresponding author), Delhi Technol Univ, Dept Software Engn, Shahbad Daulatpur 110042, Delhi, India.
EM abhi16.sharma@gmail.com; roshnisingh1815@gmail.com
FU Not applicable.
FX Not applicable.
CR Abdulhussein AA, 2022, Int J Electrical Comput Eng, V12, P2088
   Andrade-Ambriz YA, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116287
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Cai W, 2020, INT CONF AWARE SCI, DOI 10.1109/ICAST51195.2020.9319493
   Cao CQ, 2019, IEEE T CIRC SYST VID, V29, P3247, DOI 10.1109/TCSVT.2018.2879913
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Dallel M, 2022, PROCEEDINGS OF 2022 7TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING TECHNOLOGIES, ICMLT 2022, P155, DOI 10.1145/3529399.3529425
   Ding CY, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104675
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan HD, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P7351, DOI 10.1145/3503161.3548546
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Duan J., 2022, arXiv
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Gao BK, 2022, APPL INTELL, V52, P5608, DOI 10.1007/s10489-021-02723-6
   Hou R, 2022, Comput Gr
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Huang XH, 2023, Arxiv, DOI arXiv:2301.10900
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Kalimuthu Sivakumar, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P815, DOI 10.1109/ICACITE51222.2021.9404753
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Khaire P, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103531
   Khowaja SA, 2022, Journal of Ambient Intelligence and Humanized Computing, P1
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li B, 2017, IEEE INT C COMPUT, P187, DOI 10.1109/CSE-EUC.2017.217
   Li C, 2017, IEEE INT CONF MULTI
   Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26
   Lin WY, 2008, IEEE INT SYMP CIRC S, P2737, DOI 10.1109/ISCAS.2008.4542023
   Liu J, 2017, IEEE T PATTERN ANAL, V2017
   Liu JF, 2024, IEEE T MULTIMEDIA, V26, P811, DOI 10.1109/TMM.2023.3271811
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu SH, 2022, APPL INTELL, V52, P1544, DOI 10.1007/s10489-021-02517-w
   Mahdikhanlou K, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109217
   Martínez-Villaseñor L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091988
   Niu W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P719, DOI 10.1109/ICME.2004.1394293
   Patrona F, 2018, PATTERN RECOGN, V76, P612, DOI 10.1016/j.patcog.2017.12.007
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qiu S, 2022, INFORM FUSION, V80, P241, DOI 10.1016/j.inffus.2021.11.006
   Sanchez-Caballero A, 2022, Multimedia Tools Appl, P1
   Setiawan F, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116566
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Song YF, 2023, IEEE T PATTERN ANAL, V45, P1474, DOI 10.1109/TPAMI.2022.3157033
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vishwakarma DK, 2015, PROCEDIA COMPUT SCI, V57, P438, DOI 10.1016/j.procs.2015.07.515
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Wu LY, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109231
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xie J, 2021, NEUROCOMPUTING, V440, P230, DOI 10.1016/j.neucom.2021.02.001
   Xu HJ, 2023, Arxiv, DOI arXiv:2305.12398
   Xu WY, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107236
   Yadav S. K., 2022, Soft Computing, P1
   Yadav SK, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107948
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang Y, 2022, IEEE T CIRC SYST VID, V32, P8623, DOI 10.1109/TCSVT.2022.3194350
   Yao Huiling, 2023, Cyber Physical Systems, P1, DOI 10.1080/23335777.2021.1940303
   Ye Lei, 2021, Journal of Physics: Conference Series, V1883, DOI 10.1088/1742-6596/1883/1/012174
   Yue R, 2022, Action recognition based on RGB and skeleton data sets: A survey
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zhang DJ, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107312
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648
   Zhang XK, 2020, IEEE T NEUR NET LEAR, V31, P3047, DOI 10.1109/TNNLS.2019.2935173
   Zhao R, 2019, IEEE I CONF COMP VIS, P6881, DOI 10.1109/ICCV.2019.00698
   Zhu KJ, 2020, IEEE T MULTIMEDIA, V22, P2977, DOI 10.1109/TMM.2019.2962304
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 76
TC 0
Z9 0
U1 21
U2 30
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 34
DI 10.1007/s13735-023-00301-9
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA W5AZ3
UT WOS:001091764000001
DA 2024-07-18
ER

PT J
AU Zhai, ZY
   Chen, XF
   Huang, YS
   Zhao, LZ
   Cheng, B
   He, Q
AF Zhai, Zhongyi
   Chen, Xiaofeng
   Huang, Yishuang
   Zhao, Lingzhong
   Cheng, Bo
   He, Qian
TI Joint multi-scale information and long-range dependence for video
   captioning
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Video captioning; Multi-scale; Non-local; Long-range dependence
AB Since deep learning methods have achieved great success in both computer vision and natural language processing, video captioning tasks based on these two fields have also attracted extensive attention. Video captioning is a challenging task, which aims to present video information in the form of natural language to enhance video intelligibility. Most of the current researches in video captioning focus on the behavioral description of the main objects of the video, especially on the holistic understanding of the content. This trend makes most video captioning efforts ignoring the characteristics of smaller objects in the video, resulting in ambiguous, imprecise, or even fundamentally wrong descriptions. In this paper, a novel video captioning method MSLR is proposed, which improves the accuracy of video description by extracting features of video objects with different granularity and preserving long-range temporal dependencies. Specifically, the proposed method performs convolution operations at different scales to obtain different granular spatial features of videos and then fuses them to generate a unified spatial representation. On this basis, a temporal extraction network is further constructed using non-local blocks to preserve the long-range dependencies of videos. Evaluated on two popular benchmark datasets, the experimental results demonstrate the superiority of MSLR over the previous state-of-the-art methods, and the effectiveness of MSLR components is verified through ablation experiments and text evaluation.
C1 [Zhai, Zhongyi; Chen, Xiaofeng; Huang, Yishuang; Zhao, Lingzhong; He, Qian] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
   [Cheng, Bo] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
C3 Guilin University of Electronic Technology; Beijing University of Posts
   & Telecommunications
RP Zhao, LZ (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
EM zhaolingzhong@126.com
FU This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 62262009, 61902086, Major R amp;D
   Project of Guangxi (AA22068071-3) Guangxi Key Laboratory of Trusted
   Software (kx202054), Open Foundation of State key Lab [62262009,
   61902086]; National Natural Science Foundation of China [AA22068071-3];
   Major R amp;D Project of Guangxi [kx202054]; Guangxi Key Laboratory of
   Trusted Software [SKLNST-2022-1-04]; Open Foundation of State key
   Laboratory of Networking and Switching Technology in China
   [2022YCXS064]; Innovation Project of GUET Graduate Education
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 62262009, 61902086, Major R &D
   Project of Guangxi (AA22068071-3) Guangxi Key Laboratory of Trusted
   Software (kx202054), Open Foundation of State key Laboratory of
   Networking and Switching Technology in China (SKLNST-2022-1-04),
   Innovation Project of GUET Graduate Education (2022YCXS064).
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390
   [Anonymous], 2013, 27 AAAI C ART INT
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Barbu A, 2012, Arxiv, DOI arXiv:1204.2742
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen JW, 2019, AAAI CONF ARTIF INTE, P8167
   Chen M, 2018, AS C MACH LEARN, P847
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Deng JC, 2022, IEEE T CIRC SYST VID, V32, P880, DOI 10.1109/TCSVT.2021.3063423
   Gao LL, 2022, IEEE T IMAGE PROCESS, V31, P202, DOI 10.1109/TIP.2021.3120867
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Hou JY, 2019, IEEE I CONF COMP VIS, P8917, DOI 10.1109/ICCV.2019.00901
   Hu M, 2021, PROC CVPR IEEE, P15338, DOI 10.1109/CVPR46437.2021.01509
   Ji WT, 2022, APPL SOFT COMPUT, V117, DOI 10.1016/j.asoc.2021.108332
   Jin T, 2020, Arxiv, DOI arXiv:2007.11888
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Khan M. U. G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1480, DOI 10.1109/ICCVW.2011.6130425
   Kingma D. P., 2014, arXiv
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Lee J., 2019, Int J Comput Vis Robot, V9, P502
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu FL, 2022, IEEE T PATTERN ANAL, V44, P9255, DOI 10.1109/TPAMI.2021.3132229
   Madake J, 2022, 3 INT C EM TECHN INC, P1
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rafiq G, 2023, ARTIF INTELL REV, V56, P13293, DOI 10.1007/s10462-023-10414-6
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santoro A, 2017, ADV NEUR IN, V30
   Seo PH, 2022, PROC CVPR IEEE, P17938, DOI 10.1109/CVPR52688.2022.01743
   Shetty R., 2016, P 24 ACM INT C MULTI, P1073
   Thomason J., 2014, INTEGRATING LANGUAGE
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, Arxiv, DOI arXiv:1412.4729
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2019, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2019.00273
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu Hui, 2022, Artificial Intelligence and Robotics: 7th International Symposium, ISAIR 2022, Proceedings. Communications in Computer and Information Science (1700), P21, DOI 10.1007/978-981-19-7946-0_3
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhang XS, 2017, PROC CVPR IEEE, P6250, DOI 10.1109/CVPR.2017.662
   Zhao H, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.916
   Zheng Q., 2020, 2020 CVPR, P13093, DOI 10.1109/CVPR42600.2020.01311
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
NR 60
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2023
VL 12
IS 2
AR 37
DI 10.1007/s13735-023-00303-7
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X7AU4
UT WOS:001099943000001
DA 2024-07-18
ER

PT J
AU Fathollahi, MS
   Heidari, R
AF Fathollahi, Mohammadreza Sheikh
   Heidari, Rezvan
TI Gender classification from face images using central difference
   convolutional networks
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Gender classification; Central difference convolution; Face recognition;
   Convolutional neural networks
ID LOCAL BINARY PATTERNS
AB Nowadays gender classification which plays a vital role in face recognition systems is one of the main matters in computer vision. It is difficult to classify the gender from facial images when dealing with unconstrained images in a cross-dataset protocol. In this work, we propose two convolutional neural networks where one of the networks used the central difference convolution layer and another network used the vanilla convolution layer. The system was trained with the Casia WebFace dataset and tested on two cross-datasets, labeled faces in the wild (LFW) and FEI dataset. It is worth mentioning that the experimental results show the power and effectiveness of the proposed method. This method obtains a classification rate of 97.79% for the LFW dataset and 99.10% for the FEI dataset.
C1 [Fathollahi, Mohammadreza Sheikh; Heidari, Rezvan] Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University
RP Fathollahi, MS (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
EM mr.fathollahi73@gmail.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdalali O. E, 2021, 7 INT C ENG MIS
   Almabdy S., 2021, INT J COMPUT DIGIT S, V10, P465
   Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105
   Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Ben Jabra M, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P294, DOI 10.5220/0008928002940301
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Curtidor A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111358
   Dago-Casas P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2152, DOI 10.1109/ICCVW.2011.6130514
   Golomb B., 1990, P NIPS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, 12070580 ARXIV
   Hsu CY, 2021, MULTIMED TOOLS APPL, V80, P11631, DOI 10.1007/s11042-020-10141-y
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Islam MM, 2020, INVENTIONS-BASEL, V5, DOI 10.3390/inventions5020016
   Jain A. K., 2014, MSU Tech. Rep.(MSU-CSE-14-5
   Kasinski A, 2010, PATTERN ANAL APPL, V13, P197, DOI 10.1007/s10044-009-0150-5
   Kaur KD, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P595, DOI 10.1109/CONFLUENCE.2017.7943221
   Kaya Y, 2017, SIGNAL IMAGE VIDEO P, V11, P769, DOI 10.1007/s11760-016-1021-3
   Kingma D, 2015, INT C LEARN REPR ICL, P232
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Lian HC, 2006, LECT NOTES COMPUT SC, V3972, P202
   Liao MM, 2020, NEUROCOMPUTING, V373, P35, DOI 10.1016/j.neucom.2019.09.025
   Masud M, 2020, COMPUT COMMUN, V152, P215, DOI 10.1016/j.comcom.2020.01.050
   Ng C., 2012, PRICAI 2012: Trends in Arti cial Intelligence, V7458, P335
   Rouhsedaghat M, 2020, ARXIV
   Saha D., 2020, IRJET, V7, P1223
   Sajid A. K, 2011, INT MULTITOPIC C INM
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Fathollahi MS, 2021, INT J MULTIMED INF R, V10, P43, DOI 10.1007/s13735-021-00206-5
   Sun N, 2006, LECT NOTES COMPUT SC, V3972, P194
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thomaz C. E., 2012, FEI face database
   Wadhera A, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168925
   Yi Dong, 2014, ARXIV14117923
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang XX, 2021, IEEE ACCESS, V9, P166303, DOI 10.1109/ACCESS.2021.3135428
NR 41
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD DEC
PY 2022
VL 11
IS 4
SI SI
BP 695
EP 703
DI 10.1007/s13735-022-00259-0
EA SEP 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7C9EN
UT WOS:000856596500001
DA 2024-07-18
ER

PT J
AU Yürekli, A
   Kaleli, C
   Bilge, A
AF Yurekli, Ali
   Kaleli, Cihan
   Bilge, Alper
TI Alleviating the cold-start playlist continuation in music recommendation
   using latent semantic indexing
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Music recommender systems; Automatic playlist continuation; Cold-start
   problem; Latent semantic indexing; Ad hoc retrieval
ID SYSTEMS
AB The cold-start problem is a grand challenge in music recommender systems aiming to provide users with a better and continuous music listening experience. When a new user creates a playlist, the recommender system remains in a cold-start state until enough information is collected to identify the user's musical taste. In such cases, playlist metadata, such as title or description, have been successfully employed to create intent recommendation models. In this paper, we propose a multi-stage retrieval system utilizing user-generated titles to alleviate the cold-start problem in automatic playlist continuation. Initially, playlists are clustered to form a music documents collection. Then, the system applies latent semantic indexing to the collection to discover hidden patterns between tracks and playlist titles. For similarity calculation, singular value decomposition is performed on a track-cluster matrix. When the system is given a new playlist as a cold-start instance, it first retrieves neighboring clusters and then produces a ranked list of recommendations by weighting candidate tracks in these clusters. We scrutinize the performance of the proposed system on a large, real-world music playlists dataset supplied by the Spotify platform. Our empirical results show that the proposed system outperforms the state-of-the-art approaches and improves recommendation accuracy significantly in three primary evaluation metrics.
C1 [Yurekli, Ali; Kaleli, Cihan] Eskisehir Tech Univ, Dept Comp Engn, TR-26555 Eskisehir, Turkey.
   [Bilge, Alper] Akdeniz Univ, Dept Comp Engn, TR-07058 Antalya, Turkey.
C3 Eskisehir Technical University; Akdeniz University
RP Yürekli, A (corresponding author), Eskisehir Tech Univ, Dept Comp Engn, TR-26555 Eskisehir, Turkey.
EM aliyurekli@eskisehir.edu.tr; ckaleli@eskisehir.edu.tr;
   abilge@akdeniz.edu.tr
RI Yürekli, Ali/ABF-5917-2021; BILGE, ALPER/G-3583-2013
OI Yürekli, Ali/0000-0001-8690-7559; BILGE, ALPER/0000-0003-3467-9915;
   Kaleli, Cihan/0000-0001-6769-4594
FU Eskiehir Technical University [20ADP172]
FX This work was supported by the Grant 20ADP172 from Eskiehir Technical
   University.
CR Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   [Anonymous], 2007, HDB LATENT SEMANTIC, DOI DOI 10.4324/9780203936399
   Antenucci S, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267475
   Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Bonnin G, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2652481
   Chen CW, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P527, DOI 10.1145/3240323.3240342
   Cremonesi Paolo., 2011, Proceedings of the Second International Workshop on Information Heterogeneity and Fusion in Recommender Systems, HetRec'11, P33, DOI DOI 10.1145/2039320.2039325
   de Gemmis M., 2015, RECOMMENDER SYSTEMS, P119, DOI [DOI 10.1007/978-1-4899-7637-6_4, 10.1007/978-1-4899-7637-6_4]
   Faggioli G, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267486
   Ferraro A, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P586, DOI 10.1145/3298689.3347052
   Ferraro A, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267473
   Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jin YH, 2020, MILITARY MED RES, V7, DOI 10.1186/s40779-020-0233-6
   Kaleli, 2020, J AMB INTEL HUM COMP, P1
   Kallumadi S, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267478
   Kamehkhosh I, 2020, USER MODEL USER-ADAP, V30, P285, DOI 10.1007/s11257-019-09237-4
   Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720
   Kaya M, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267472
   Kelen DM, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267477
   Kim J, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267485
   Kuhn A, 2005, WCRE: 12TH WORKING CONFERENCE ON REVERSE ENGINEERING 2005, PROCEEDINGS, P133
   Lam X. N., 2008, P 2 INT C UBIQUITOUS, P208, DOI [DOI 10.1145/1352793.1352837, 10.1145/1352793.1352837]
   Lika B, 2014, EXPERT SYST APPL, V41, P2065, DOI 10.1016/j.eswa.2013.09.005
   Liu NathanNan., 2011, RecSys, P37
   Logan B., 2002, ISMIR, V2, P295
   Ludewig M, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267474
   Mimno D, 2011, EMNLP, P262, DOI DOI 10.5555/2145432.2145462
   Musto Cataldo, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P729, DOI 10.1007/978-3-319-30671-1_60
   Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P159, DOI 10.1145/275487.275505
   Park YJ, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P11
   Pichl M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1360, DOI 10.1109/ICDMW.2015.145
   Polignano M, 2019, ADJUNCT PUBLICATION OF THE 27TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (ACM UMAP '19 ADJUNCT), P235, DOI 10.1145/3314183.3323455
   Rashid A. M., 2008, SIGKDD Explorations, V10, P90
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Rubtsov V, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267488
   Saveski M, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P89, DOI 10.1145/2645710.2645751
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Stevens K, 2012, P JOINT C EMPIRICAL, P952, DOI DOI 10.5555/2390948.2391052
   Symeonidis P, 2008, STUD CLASS DATA ANAL, P619, DOI 10.1007/978-3-540-78246-9_73
   Tran T, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P245, DOI 10.1145/3331184.3331234
   Vall A, 2019, USER MODEL USER-ADAP, V29, P527, DOI 10.1007/s11257-018-9215-8
   van Niedek T, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267483
   Volkovs M, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267480
   Voorhees E. M., 2005, TREC: Experiment and Evaluation in Information Retrieval
   Weston J, 2011, IJCAI
   Yang H, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267482
   Zamani H, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3344257
   Zhao X, 2018, RECSYS CHALLENGE'18: PROCEEDINGS OF THE ACM RECOMMENDER SYSTEMS CHALLENGE 2018, DOI 10.1145/3267471.3267479
   Zhu L, 2018, ROUTL CONTEMP CHINA, P10
NR 51
TC 1
Z9 2
U1 2
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2021
VL 10
IS 3
BP 185
EP 198
DI 10.1007/s13735-021-00214-5
EA SEP 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UU7DE
UT WOS:000692454300001
DA 2024-07-18
ER

PT J
AU Hazra, A
AF Hazra, Abhishek
TI A comprehensive survey on chest diseases analysis: technique, challenges
   and future research directions
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Review
DE Chest diseases; Convolutional neural network; Deep learning; Medical
   images
ID CONVOLUTIONAL NEURAL-NETWORKS; LUNG NODULE; X-RAY; IMAGE DATABASE; DEEP;
   CLASSIFICATION; RADIOGRAPHS; ENSEMBLE; CANCER
AB Learning with chest diseases and their classification, segmentation, localization, annotation, and abnormality detection are challenging and exciting research objectives. Over the past few years, different researchers have come with various learning techniques for improving performance in chest image analysis. However, the scarcity of labeled datasets and less computational processing power was a reason for the negligible performance improvement. Nevertheless, with the advancement in Deep Learning (DL) techniques, researchers succeeded in achieving state-of-the-art results and created a new research paradigm. Among the different DL techniques, Convolutional Neural Network comes with a revolution for identifying abnormality in chest images. This survey aims to highlight the importance of deep learning techniques in chest disease diagnosis. In this paper, our primary objective is to broadly analyze different DL techniques and recognize some of the important research challenges that mostly affect deep neural networks for investigating various chest diseases. Specifically, we focus on several chest diseases, symptoms, preliminary treatments, and state-of-the-art detection techniques. We also introduce several chest image analysis tools, techniques, and datasets for analyzing chest diseases. Further, we have presented several open research challenges and future research directions in the field of chest image analysis.
C1 [Hazra, Abhishek] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Hazra, A (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM abhishekhazra.18DR0018@cse.iitism.ac.in
RI HAZRA, ABHISHEK/AAC-1451-2019
OI HAZRA, ABHISHEK/0000-0003-0796-6265
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Altaf F, 2019, IEEE ACCESS, V7, P99540, DOI 10.1109/ACCESS.2019.2929365
   Anavi Y, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217587
   Anavi Y, 2015, IEEE ENG MED BIO, P2940, DOI 10.1109/EMBC.2015.7319008
   [Anonymous], 1999, Stochastics and Stochastic Reports, DOI DOI 10.1080/17442509908834179
   [Anonymous], 2017, Learning to diagnose from scratch by exploiting dependencies among labels
   [Anonymous], 2016, Neon
   [Anonymous], 2016, SKYMIND
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Baltruschat IM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42294-8
   Bank D., 2020, AUTOENCODERS
   Bar Y, 2018, COMP M BIO BIO E-IV, V6, P259, DOI 10.1080/21681163.2016.1138324
   Bar Y, 2015, PROC SPIE, V9414, DOI 10.1117/12.2083124
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bhat, 2020, ARXIV PREPRINT ARXIV
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   CenterBerkeley, 2016, CAFFE
   Charbonnier JP, 2017, MED IMAGE ANAL, V36, P52, DOI 10.1016/j.media.2016.11.001
   Chaudhry Arslan, 2019, ARXIV190210486
   Chen SH, 2017, IEEE T MED IMAGING, V36, P802, DOI 10.1109/TMI.2016.2629462
   Chollet F., KERAS
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Choudhary P, 2021, EVOL SYST-GER, V12, P567, DOI 10.1007/s12530-019-09316-2
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Cicero M, 2017, INVEST RADIOL, V52, P281, DOI 10.1097/RLI.0000000000000341
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   Collobert R, 2016, TORCH
   Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080
   Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Farhat H, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01101-5
   Ramirez-Gutierrez CF, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-51200-1
   Ferguson Max, 2017, 2017 IEEE International Conference on Big Data (Big Data), P1726
   Gang P, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P878, DOI 10.1109/ICACI.2018.8377579
   Gao MC, 2018, COMP M BIO BIO E-IV, V6, P1, DOI 10.1080/21681163.2015.1124249
   Gao MC, 2016, I S BIOMED IMAGING, P1265, DOI 10.1109/ISBI.2016.7493497
   Ge YS, 2021, IEEE T BIO-MED ENG, V68, P1751, DOI 10.1109/TBME.2020.3011119
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Ghassemi, 2020, ARXIV200611988
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Google, 2016, TENS
   Gordienko Y, 2018, P INT C COMP SCI ENG, P638
   Gozes O., 2020, RAPID AI DEV CYCLE C
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guan Q., 2018, ARXIV PREPRINT ARXIV
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   Hazra Abhishek, 2021, Advances in Biomedical Engineering and Technology. Select Proceedings of ICBEST 2018. Lecture Notes in Bioengineering (LNBE), P103, DOI 10.1007/978-981-15-6329-4_10
   Hazra A, 2021, APPL INTELL, V51, P2291, DOI 10.1007/s10489-020-01901-2
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Heo SJ, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16020250
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Xin, 2020, ARXIV201206678
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Hwang EJ, 2019, RADIOLOGY, V293, P573, DOI 10.1148/radiol.2019191225
   Hwang EJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.1095
   Hwang S, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216198
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kim, 2016, ARXIV PREPRINT ARXIV
   Kingma D. P., 2013, ARXIV13126114
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lee SM, 2019, J THORAC IMAG, V34, P75, DOI 10.1097/RTI.0000000000000387
   Li X, 2019, EUR J RADIOL, V120, DOI 10.1016/j.ejrad.2019.108692
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lo SCB, 1995, IEEE T MED IMAGING, V14, P711, DOI 10.1109/42.476112
   Luchies Adam C, 2018, IEEE Trans Med Imaging, V37, P2010, DOI [10.1109/ULTSYM.2017.8091878, 10.1109/TMI.2018.2809641]
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Luo LY, 2020, IEEE T MED IMAGING, V39, P3583, DOI 10.1109/TMI.2020.3000949
   Ma JC, 2020, FRONT MED-PRC, V14, P450, DOI 10.1007/s11684-019-0726-4
   Mao, 2020, ARXIV PREPRINT ARXIV
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Mduma N., 2019, DATA SCI J, V18, P14, DOI DOI 10.5334/DSJ-2019-014
   Mehdipoor G, 2017, BMC MED IMAGING, V17, DOI 10.1186/s12880-017-0222-8
   Microsoft, 2016, CNTK
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mittal A, 2017, IET IMAGE PROCESS, V11, P937, DOI 10.1049/iet-ipr.2016.0526
   Narayanan Uma, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P2118, DOI 10.1109/ICECDS.2017.8389824
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Novikov AA, 2018, IEEE T MED IMAGING, V37, P1865, DOI 10.1109/TMI.2018.2806086
   Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464
   Peng CT, 2020, IEEE T MED IMAGING, V39, P3831, DOI 10.1109/TMI.2020.3005432
   Pérez SR, 2020, PHYS MEDICA, V76, P62, DOI 10.1016/j.ejmp.2020.06.014
   Pise NN, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P593
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qin ZC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48148-7
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P9603, DOI 10.1109/JIOT.2020.3013710
   Rajkomar A, 2017, J DIGIT IMAGING, V30, P95, DOI 10.1007/s10278-016-9914-9
   Rajpurkar Pranav, 2017, ARXIV170701836
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Schaff F, 2020, IEEE T MED IMAGING, V39, P3891, DOI 10.1109/TMI.2020.3006815
   Schwab E, 2020, I S BIOMED IMAGING, P1879, DOI [10.1109/isbi45749.2020.9098551, 10.1109/ISBI45749.2020.9098551]
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shan F., 2020, ARXIV200304655
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindhu Meena K., 2020, P INT C ART INT SMAR, P627
   Singh, 2020, ARXIV PREPRINT ARXIV
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Srivastava RK, 2015, ADV NEUR IN, V28
   Sun W., 2016, SPIE Medical Imaging, p97850Z, DOI DOI 10.1117/12.2216307
   Syben C, 2020, IEEE T MED IMAGING, V39, P3488, DOI 10.1109/TMI.2020.2998179
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Teramoto A, 2016, MED PHYS, V43, P2821, DOI 10.1118/1.4948498
   Tian J, 2016, INT C MED IM COMP CO, P124, DOI DOI 10.1007/978-3-319-46723-8
   Tolkachev A, 2021, IEEE J BIOMED HEALTH, V25, P1660, DOI 10.1109/JBHI.2020.3023476
   Universite de Montreal, 2016, THEAN
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   van Ginneken B, 2001, IEEE T MED IMAGING, V20, P1228, DOI 10.1109/42.974918
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang CM, 2017, COMPUT MED IMAG GRAP, V57, P10, DOI 10.1016/j.compmedimag.2016.11.004
   Wang SQ, 2022, IEEE T SYST MAN CY-S, V52, P426, DOI 10.1109/TSMC.2020.2997852
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wei R, 2019, IEEE ACCESS, V7, P37026, DOI 10.1109/ACCESS.2019.2899385
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wolfram Research, 2016, WOLFRAM MATH
   Wong KKL, 2020, FUTURE GENER COMP SY, V110, P802, DOI 10.1016/j.future.2019.09.047
   Yang W, 2017, MED IMAGE ANAL, V35, P421, DOI 10.1016/j.media.2016.08.004
   Yu H, 2020, P 2020 5 INT C MACH, P68
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
NR 141
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD JUN
PY 2021
VL 10
IS 2
SI SI
BP 83
EP 110
DI 10.1007/s13735-021-00205-6
EA FEB 2021
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SK0DY
UT WOS:000619717100001
DA 2024-07-18
ER

PT J
AU Theodosiou, Z
   Tsapatsoulis, N
AF Theodosiou, Zenonas
   Tsapatsoulis, Nicolas
TI Image annotation: the effects of content, lexicon and annotation method
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Image annotation; Crowdsourcing; Manual annotation; Annotation quality
ID AGREEMENT; DATASETS; MODEL
AB Image annotation is the process of assigning metadata to images, allowing effective retrieval by text-based search techniques. Despite the lots of efforts in automatic multimedia analysis, automatic semantic annotation of multimedia is still inefficient due to the problems in modeling high-level semantic terms. In this paper, we examine the factors affecting the quality of annotations collected through crowdsourcing platforms. An image dataset was manually annotated utilizing: (1) a vocabulary consists of preselected set of keywords, (2) an hierarchical vocabulary and (3) free keywords. The results show that the annotation quality is affected by the image content itself and the used lexicon. As we expected while annotation using the hierarchical vocabulary is more representative, the use of free keywords leads to increased invalid annotation. Finally, it is shown that images requiring annotations that are not directly related to their content (i.e., annotation using abstract concepts) lead to accrue annotator inconsistency revealing in that way the difficulty in annotating such kind of images is not limited to automatic annotation, but it is a generic problem of annotation.
C1 [Theodosiou, Zenonas] Res Ctr Interact Media Smart Syst & Emerging Tech, Nicosia, Cyprus.
   [Tsapatsoulis, Nicolas] Cyprus Univ Technol, Dept Commun & Internet Studies, Limassol, Cyprus.
C3 Cyprus University of Technology
RP Theodosiou, Z (corresponding author), Res Ctr Interact Media Smart Syst & Emerging Tech, Nicosia, Cyprus.
EM z.theodosiou@rise.org.cy; nicolas.tsapatsoulis@cut.ac.cy
RI TSAPATSOULIS, NICOLAS/E-4146-2016
OI TSAPATSOULIS, NICOLAS/0000-0002-6739-8602; Theodosiou,
   Zenonas/0000-0003-3168-2350
FU European Union [739578]; Government of the Republic of Cyprus through
   the Directorate General for European Programmes, Coordination and
   Development
FX This work has been partly supported by the project that has received
   funding from the European Union's Horizon 2020 research and innovation
   programme under Grant Agreement No. 739578 (RISE-Call:
   H2020-WIDE-SPREAD-01-2016-2017-TeamingPhase2) and the Government of the
   Republic of Cyprus through the Directorate General for European
   Programmes, Coordination and Development.
CR Allahbakhsh M, 2013, IEEE INTERNET COMPUT, V17, P76, DOI 10.1109/MIC.2013.20
   [Anonymous], 2010, 2010 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2010.5543189
   [Anonymous], CIVR 09
   Aroyo L, 2015, AI MAG, V36, P15, DOI 10.1609/aimag.v36i1.2564
   Artstein R, 2017, Handbook of Linguistic Annotation, P297, DOI DOI 10.1007/978-94-024-0881-211
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Brabham D. C, 2008, Convergence, V14, P75, DOI DOI 10.1177/1354856507084420
   Brants Thorsten, 2000, P 2 INT C LANG RES E
   Brawley AM, 2016, COMPUT HUM BEHAV, V54, P531, DOI 10.1016/j.chb.2015.08.031
   Callison-Burch C., 2009, EMNLP '09: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, P286
   Chen KT, 2009, MATH COMPUT SCI ENG, P491, DOI 10.1145/1631272.1631339
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng QM, 2018, PATTERN RECOGN, V79, P242, DOI 10.1016/j.patcog.2018.02.017
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   COWLES M, 1982, AM PSYCHOL, V37, P553, DOI 10.1037/0003-066X.37.5.553
   Cruz AJ, 2017, TRANSCULT 1400-1700, P1
   Nguyen DT, 2018, IEEE T VIS COMPUT GR, V24, P3005, DOI 10.1109/TVCG.2017.2772238
   Dutta Abhishek, 2019, MM '19: Proceedings of the 27th ACM International Conference on Multimedia, P2276, DOI 10.1145/3343031.3350535
   Dutta A, 2018, MULTIMED TOOLS APPL, V77, P31991, DOI 10.1007/s11042-018-6247-3
   Fowler F.J., 2014, APPL SOCIAL RES METH, V1
   Fujisawa S, 2007, B IEEE TECHNICAL COM
   Ghezzi A, 2018, INT J MANAG REV, V20, P343, DOI 10.1111/ijmr.12135
   Glowacz A, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110299
   Glowacz A, 2019, MECH SYST SIGNAL PR, V117, P65, DOI 10.1016/j.ymssp.2018.07.044
   Gulati P, 2019, ADV INTELL SYST, V731, P173, DOI 10.1007/978-981-10-8848-3_17
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Hare JS, 2006, PROC SPIE, V6073, DOI 10.1117/12.647755
   Heidorn PB, 1999, LIBR TRENDS, V48, P303
   Hong S, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487982
   Howe J, 2006, WIRED, V14, P1, DOI DOI 10.1086/599595
   Howe J., 2008, Crowdsourcing: Why the Power of the Crowd Is Driving the Future of Business
   Huang YP, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192407
   Jin C, 2019, MULTIMED TOOLS APPL, V78, P11815, DOI 10.1007/s11042-018-6742-6
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Kilgarriff A, 1998, COMPUT SPEECH LANG, V12, P453, DOI 10.1006/csla.1998.0108
   Kittur A, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P37
   Kovashka A, 2014, FOUND TRENDS COMPUT, V10, pI, DOI 10.1561/0600000071
   Kwasnicka H, 2010, STUD COMPUT INTELL, V263, P387
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Leksir YLD, 2018, INFRARED PHYS TECHN, V89, P120, DOI 10.1016/j.infrared.2017.12.015
   Li A, 2017, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2017.210
   Lovett M, 2018, APPL PSYCHOL-INT REV, V67, P339, DOI 10.1111/apps.12124
   Ma YC, 2019, MULTIMED TOOLS APPL, V78, P3767, DOI 10.1007/s11042-018-6038-x
   Macdonald Craig., 2009, WSCD'09: Proceedings of the 2009 workshop on Web Search Click Data, P75, DOI DOI 10.1145/1507509.1507521
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Matusiak K. K., 2006, OCLC Systems & Services, V22, P283, DOI 10.1108/10650750610706998
   McCredie MN, 2019, ASSESSMENT, V26, P759, DOI 10.1177/1073191118760709
   Nowak S., 2010, P INT C MULT INF RET, P557, DOI [10.1145/1743384.1743478, DOI 10.1145/1743384.1743478]
   Papadopoulos K, 2008, P 14 INT C VIRT SYST
   Perina A, 2017, IEEE I CONF COMP VIS, P4336, DOI 10.1109/ICCV.2017.464
   Piramanayagam S, 2016, PROC SPIE, V10004, DOI 10.1117/12.2243169
   Randolph J., 2008, ONLINE KAPPA CALCULA
   Randolph J. J., 2005, Free-Marginal Multirater Kappa (multirater K free): An Alternative to Fleiss' Fixed-Marginal Multirater Kappa
   Raykar VC, 2009, P 26 ANN INT C MACH, P889, DOI [10.1145/1553374.1553488, DOI 10.1145/1553374.1553488]
   Ristin M, 2016, IEEE T PATTERN ANAL, V38, P490, DOI 10.1109/TPAMI.2015.2459678
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sheng V. S., 2008, P 14 ACM SIGKDD INT, P614, DOI DOI 10.1145/1401890.1401965
   Smyth P., 1995, Advances in Neural Information Processing Systems 7, P1085
   Snow R, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751
   Theodosiou Z, 2011, P 5 INT C INT MULT S
   Theodosiou Z, 2012, 2012 SEVENTH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2012), P73, DOI 10.1109/SMAP.2012.23
   TYAGI V, 2017, CONTENT BASED IMAGE, P29, DOI DOI 10.1007/978-981-10-6759-4_2
   Vijayanarasimhan S, 2009, PROC CVPR IEEE, P2262, DOI 10.1109/CVPRW.2009.5206705
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Whitehill J., 2009, Advances in Neural Information Processing Systems, P2035
   Wigness M, 2018, INT J COMPUT VISION, V126, P59, DOI 10.1007/s11263-017-1039-1
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Yadav P, 2017, STUD HEALTH TECHNOL, V245, P644, DOI 10.3233/978-1-61499-830-3-644
   Yang CM, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P821, DOI 10.1109/ICOIN.2018.8343233
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang RF, 2006, MULTIMEDIA SYST, V12, P27, DOI 10.1007/s00530-006-0025-1
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 75
TC 5
Z9 5
U1 7
U2 34
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2020
VL 9
IS 3
BP 191
EP 203
DI 10.1007/s13735-020-00193-z
EA MAR 2020
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MQ6SK
UT WOS:000517687800001
DA 2024-07-18
ER

PT J
AU Sathish, PK
   Balaji, S
AF Sathish, P. K.
   Balaji, S.
TI A complete person re-identification model using Kernel-PCA-based
   Gabor-filtered hybrid descriptors
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Pedestrian detection; Deep learning; Person re-identification; Video
   surveillance; Kernel PCA; Spatial descriptor; Distance metric learning
ID NETWORKS; FEATURES
AB Person re-identification is a challenging problem in computer vision. Lots of research interest is observed in this area over the past few years. A model for complete person re-identification can prove useful in this direction. Use of convolutional neural networks for pedestrian detection can improve the accuracy of detection to a larger extent. Deriving a descriptor which is invariant to the changes in the illumination, background and the pose can make the difference in the re-identification process. The predominant part of our work focuses on building a robust descriptor which can tackle such challenges. We have concentrated on building a descriptor by employing appearance-based features extracted both at local and global levels. Further, the dimensionality of the descriptor is reduced using kernel PCA. Distance metric learning algorithms are used to evaluate the descriptor on three major benchmark datasets. We propose a complete person re-identification system which involves both pedestrian detection and person re-identification. Major contributions of this work are to detect pedestrians from surveillance videos using CNN-based learning and to generate a kernel-PCA-based spatial descriptor and evaluate the descriptor using known distance metric learning methods on benchmark datasets.
C1 [Sathish, P. K.] Christ Univ, Dept Comp Sci & Engn, Bengaluru 560074, India.
   [Balaji, S.] Jyothi Inst Technol, Ctr Incubat Innovat Res & Consultancy, Bengaluru, India.
C3 Christ University
RP Sathish, PK (corresponding author), Christ Univ, Dept Comp Sci & Engn, Bengaluru 560074, India.
EM sathish.pk20@gmail.com
RI K, Sathish P/AAE-2997-2020
OI K, Sathish P/0000-0002-6049-9443
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2006, 2006 IEEE COMPUTER S
   [Anonymous], 2009, BRIT MACH VIS C
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], P 7 IEEE INT C ADV V
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P IEEE INT C ADV VID
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C
   [Anonymous], ACM SIGGRAPH INT C C
   [Anonymous], 20 INT C PATT REC IC
   [Anonymous], P INT C MACH LEARN
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], P INT C MACH LEARN
   [Anonymous], 2001, P 2 EUR WORKSH ADV V
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2011, P 2011 JOINT ACM WOR
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PedroF., 2008, IEEE C COMPUTER VISI
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hirzer M., 2011, P SCAND C IM AN SCIA
   Ijiri Yoshihisa, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P603
   Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabzmeydani P., 2007, IEEE C COMPUTER VISI, P1
   Sathish PK, 2017, INT J MULTIMED INF R, V6, P289, DOI 10.1007/s13735-017-0136-9
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Struc V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/847680
   Struc V, 2009, INFORMATICA-LITHUAN, V20, P115
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Weber M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P361, DOI 10.1109/AVSS.2011.6027351
   Xiang ZJ, 2014, MULTIMED TOOLS APPL, V73, P91, DOI 10.1007/s11042-012-1286-7
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhou BL, 2014, ADV NEUR IN, V27
NR 61
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD NOV
PY 2018
VL 7
IS 4
BP 221
EP 229
DI 10.1007/s13735-018-0153-3
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GX5SL
UT WOS:000447810500002
DA 2024-07-18
ER

PT J
AU Sabetghadam, S
   Lupu, M
   Bierig, R
   Rauber, A
AF Sabetghadam, Serwah
   Lupu, Mihai
   Bierig, Ralf
   Rauber, Andreas
TI A faceted approach to reachability analysis of graph modelled
   collections
SO INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL
LA English
DT Article
DE Information Retrieval; Multimodal; Facet; Graph; Recall; Reachability
ID IMAGE RETRIEVAL; SEARCH; PAGERANK; FUSION
AB Nowadays, there is a proliferation of available information sources from different modalities-text, images, audio, video and more. Information objects are not isolated anymore. They are frequently connected via metadata, semantic links, etc. This leads to various challenges in graph-based information retrieval. This paper is concerned with the reachability analysis of multimodal graph modelled collections. We use our framework to leverage the combination of features of different modalities through our formulation of faceted search. This study highlights the effect of different facets and link types in improving reachability of relevant information objects. The experiments are performed on the Image CLEF 2011 Wikipedia collection with about 400,000 documents and images. The results demonstrate that the combination of different facets is conductive to obtain higher reachability. We obtain 373% recall gain for very hard topics by using our graph model of the collection. Further, by adding semantic links to the collection, we gain a 10% increase in the overall recall.
C1 [Sabetghadam, Serwah; Lupu, Mihai; Rauber, Andreas] Vienna Univ Technol, Inst Software Technol & Interact Syst, Vienna, Austria.
   [Bierig, Ralf] Maynooth Univ, Dept Comp Sci, Maynooth, Kildare, Ireland.
C3 Technische Universitat Wien; Maynooth University
RP Sabetghadam, S (corresponding author), Vienna Univ Technol, Inst Software Technol & Interact Syst, Vienna, Austria.
EM sabetghadam@ifs.tuwien.ac.at; lupu@ifs.tuwien.ac.at;
   rauber@ifs.tuwien.ac.at
RI Bierig, Ralf/IQX-1311-2023
OI Bierig, Ralf/0000-0002-2939-140X
FU Austrian Science Fund (FWF); FWF [I1094-N23, P25905-N23]
FX Open access funding provided by Austrian Science Fund (FWF). The
   computational results presented have been achieved using the Vienna
   Scientific Cluster (VSC) (http://vsc.ac.at/). The authors were partially
   supported by FWF projects I1094-N23(MU-CKE) and P25905-N23(ADmiRE).
CR [Anonymous], 2014, P CLEF SHEFF UK
   [Anonymous], P INF RETR FAC C IRF
   [Anonymous], P INT IR TECHN PROF
   [Anonymous], 2001, P NEUR INF PROC SYST
   [Anonymous], P C LABS EV FOR CLEF
   [Anonymous], P INT C MULT RETR IC
   [Anonymous], 2011, CIKM
   [Anonymous], P WORKSH MULT INF RE
   [Anonymous], 2010, P ACM INT C IMAGE VI
   [Anonymous], C LABS EV FOR CLEF
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Berkhin P, 2005, INTERNET MATH, V2, P73, DOI 10.1080/15427951.2005.10129098
   Bredin H, 2014, INT J MULTIMED INF R, V3, P161, DOI 10.1007/s13735-014-0055-y
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang SF, 2007, INT CONF ACOUST SPEE, P1205
   Clements M, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852107
   Collins-Thompson Kevyn., 2005, PROC 14 INT C INFORM, P704
   Crestani F, 1997, ARTIF INTELL REV, V11, P453, DOI 10.1023/A:1006569829653
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duan LX, 2011, IEEE T IMAGE PROCESS, V20, P3280, DOI 10.1109/TIP.2011.2159227
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242
   Hauptmann AG, 2008, P IEEE, V96, P602, DOI 10.1109/JPROC.2008.916355
   Hsu WinstonH., 2007, ACM MM
   Hwang Sj., 2010, P BRIT MACHINE VISIO, P1
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Larsen Birger., 2006, Information Interaction in Context, P88
   Lazaridis M, 2013, SIGNAL PROCESS-IMAGE, V28, P351, DOI 10.1016/j.image.2012.04.001
   Li Xirong., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '10, P10
   Liu Jingjing., 2007, MULTIMEDIA 07, P208
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Minack E, 2010, J WEB SEMANT, V8, P37, DOI 10.1016/j.websem.2009.12.001
   Nottelmann H, 2003, INFORM RETRIEVAL, V6, P363, DOI 10.1023/A:1026080230789
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Pei-Cheng Cheng, 2004, Multilingual Information Access for Text, Speech and Images. 5th Workshop of the Cross-Language Evaluation Forum, CLEF 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3491), P793
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Rocha C., 2004, P 13 INT C WORLD WID, P374, DOI DOI 10.1145/988672.988723
   Sabetghadam Serwah, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P370, DOI 10.1007/978-3-319-16354-3_41
   Sabetghadam S., 2014, INFORM ACCESS EVALUA, P86, DOI DOI 10.1007/978-3-319-11382-1_9
   Schinas M, 2016, INT J MULTIMED INF R, V5, P51, DOI 10.1007/s13735-015-0089-9
   Skov M, 2008, INFORM PROCESS MANAG, V44, P1673, DOI 10.1016/j.ipm.2008.05.006
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Tonon Alberto, 2012, Proceedings of the 35th Annual International ACM SIGIR Conference on Research & Development in Information Retrieval (SIGIR 2012), P125, DOI 10.1145/2348283.2348304
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
NR 49
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2192-6611
EI 2192-662X
J9 INT J MULTIMED INF R
JI Int. J. Multimed. Inf. Retr.
PD SEP
PY 2018
VL 7
IS 3
BP 157
EP 171
DI 10.1007/s13735-017-0145-8
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HI5SF
UT WOS:000456513600002
PM 30956928
OA hybrid, Green Published
DA 2024-07-18
ER

EF