FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Hilasaca, GM
   Marcilio-Jr, WE
   Eler, DM
   Martins, RM
   Paulovich, FV
AF Hilasaca, Gladys M.
   Marcilio-Jr, Wilson E.
   Eler, Danilo M.
   Martins, Rafael M.
   Paulovich, Fernando V.
TI A Grid-Based Method for Removing Overlaps of Dimensionality Reduction
   Scatterplot Layouts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dimensionality reduction; multidimensional projection; scatterplots;
   overlap removal
ID NEIGHBORHOOD PRESERVATION; VISUAL ANALYSIS; ADJUSTMENT
AB Dimensionality Reduction (DR) scatterplot layouts have become a ubiquitous visualization tool for analyzing multidimensional datasets. Despite their popularity, such scatterplots suffer from occlusion, especially when informative glyphs are used to represent data instances, potentially obfuscating critical information for the analysis under execution. Different strategies have been devised to address this issue, either producing overlap-free layouts that lack the powerful capabilities of contemporary DR techniques in uncovering interesting data patterns or eliminating overlaps as a post-processing strategy. Despite the good results of post-processing techniques, most of the best methods typically expand or distort the scatterplot area, thus reducing glyphs' size (sometimes) to unreadable dimensions, defeating the purpose of removing overlaps. This article presents Distance Grid (DGrid), a novel post-processing strategy to remove overlaps from DR layouts that faithfully preserves the original layout's characteristics and bounds the minimum glyph sizes. We show that DGrid surpasses the state-of-the-art in overlap removal (through an extensive comparative evaluation considering multiple different metrics) while also being one of the fastest techniques, especially for large datasets. A user study with 51 participants also shows that DGrid is consistently ranked among the top techniques for preserving the original scatterplots' visual characteristics and the aesthetics of the final results.
C1 [Hilasaca, Gladys M.] Fed Univ So Paulo UNIFESP, BR-05508220 Sao Paulo, Brazil.
   [Marcilio-Jr, Wilson E.] Sao Paulo State Univ, BR-05508070 Sao Paulo, Brazil.
   [Eler, Danilo M.] Sao Paulo State Univ, S-35252 Sao Paulo, Brazil.
   [Martins, Rafael M.; Paulovich, Fernando V.] Linnaeus Univ, NL-5612 AZ Vaxjo, Sweden.
C3 Universidade Estadual Paulista; Universidade Estadual Paulista; Linnaeus
   University
RP Paulovich, FV (corresponding author), Linnaeus Univ, NL-5612 AZ Vaxjo, Sweden.
EM gladysmarleny@gmail.com; wilson_jr@outlook.com; danilo.eler@unesp.br;
   rafael.martins@lnu.se; f.paulovich@tue.nl
RI Paulovich, Fernando/G-1329-2010
OI Paulovich, Fernando/0000-0002-2316-760X; Eler,
   Danilo/0000-0002-9493-145X
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   Emerging Leaders in the Americas Program (ELAP); Government of Canada;
   CAPES-Brazil
FX The authors would like to thank all reviewers who dedicated time to this
   article. Your comments and feedback were beneficial and indeed led to
   substantial improvement in the quality and clarity of this manuscript.
   We acknowledge the support of the Natural Sciences and Engineering
   Research Council of Canada(NSERC), CAPES-Brazil, and the Emerging
   Leaders in the Americas Program (ELAP) with the support of the
   Government of Canada.
CR Anderson J.A., 1988, Neurocomputing: Foundations ofResearch
   Ramos-Guajardo AB, 2020, INT J APPROX REASON, V119, P1, DOI 10.1016/j.ijar.2019.12.012
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bertini E., 2006, Information Visualization, V5, P95, DOI 10.1057/palgrave.ivs.9500122
   Brath R, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P25, DOI 10.1109/3DVis.2014.7160096
   Breitling R, 2004, FEBS LETT, V573, P83, DOI 10.1016/j.febslet.2004.07.055
   Brown R. A., 2015, J. Comput. Graph. Techn., V4, P50
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chen F., 2020, J. Graph Algorithms Appl., V24, P683, DOI [10.7155/jgaa.00532, DOI 10.7155/JGAA.00532]
   Chen X, 2020, IEEE T VIS COMPUT GR, V26, P729, DOI 10.1109/TVCG.2019.2934541
   Cutura R, 2022, J VISUAL-JAPAN, V25, P1291, DOI 10.1007/s12650-022-00854-7
   Dua D., 2017, UCI Machine Learning Repository
   Duarte FSLG, 2014, IEEE T VIS COMPUT GR, V20, P2063, DOI 10.1109/TVCG.2014.2346276
   Dwyer T, 2006, LECT NOTES COMPUT SC, V3843, P153
   Eler DM, 2009, VISUAL COMPUT, V25, P923, DOI 10.1007/s00371-009-0368-7
   Elmqvist N., 2005, P ACM S VIRT REAL SO, P134, DOI DOI 10.1145/1101616.1101643
   Eppstein D, 2013, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2013.6596124
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fried O, 2015, COMPUT GRAPH FORUM, V34, P155, DOI 10.1111/cgf.12549
   Fuchs J, 2014, IEEE T VIS COMPUT GR, V20, P2251, DOI 10.1109/TVCG.2014.2346426
   Gansner E., 2010, J. Graph Algorithms Appl., V14, P53
   Gomez-Nieto Erick, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P115, DOI 10.1109/SIBGRAPI.2013.25
   Gomez-Nieto E, 2014, IEEE T VIS COMPUT GR, V20, P457, DOI 10.1109/TVCG.2013.242
   Hayashi K, 1998, LECT NOTES COMPUT SC, V1547, P183
   Helliwell J., 2019, World Happiness Report 2019
   Jenks G.F., 1967, International Yearbook of Cartography, V7, P186
   Kammer D, 2020, IEEE T VIS COMPUT GR, V26, P1661, DOI 10.1109/TVCG.2020.2969060
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2553
   Li J, 2009, IEEE PAC VIS SYMP, P97, DOI 10.1109/PACIFICVIS.2009.4906843
   Lundberg SM, 2017, ADV NEUR IN, V30
   Marcilio WE, 2019, INFORM VISUAL, V18, P426, DOI 10.1177/1473871619845093
   Martins RM, 2014, COMPUT GRAPH-UK, V41, P26, DOI 10.1016/j.cag.2014.01.006
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   McNeill G, 2017, COMPUT GRAPH FORUM, V36, P435, DOI 10.1111/cgf.13200
   Meulemans W, 2019, COMPUT GRAPH FORUM, V38, P713, DOI 10.1111/cgf.13722
   Meulemans W, 2017, IEEE T VIS COMPUT GR, V23, P381, DOI 10.1109/TVCG.2016.2598542
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Nachmanson L, 2016, LECT NOTES COMPUT SC, V9801, P33, DOI 10.1007/978-3-319-50106-2_3
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pinho R., 2009, P ACM S APPL COMP NE, P1757, DOI DOI 10.1145/1529282.1529679
   Pinho R, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P32, DOI 10.1109/IV.2009.12
   Quadrianto N, 2010, IEEE T PATTERN ANAL, V32, P1809, DOI 10.1109/TPAMI.2009.184
   Raisz E, 1934, GEOGR REV, V24, P292, DOI 10.2307/208794
   Rauber PE, 2018, INFORM VISUAL, V17, P282, DOI 10.1177/1473871617713337
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Strobelt H, 2012, COMPUT GRAPH FORUM, V31, P1135, DOI 10.1111/j.1467-8659.2012.03106.x
   Strong G., 2011, P GRAPH INT, P206
   Tory M, 2007, IEEE T VIS COMPUT GR, V13, P1262, DOI 10.1109/TVCG.2007.70596
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Garderen M, 2017, COMPUT GRAPH FORUM, V36, P423, DOI 10.1111/cgf.13199
   van Kreveld M, 2004, LECT NOTES COMPUT SC, V3221, P724
   Venna J, 2001, LECT NOTES COMPUT SC, V2130, P485
   Wood J, 2008, IEEE T VIS COMPUT GR, V14, P1348, DOI 10.1109/TVCG.2008.165
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
NR 61
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5733
EP 5749
DI 10.1109/TVCG.2023.3309941
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400072
PM 37647195
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Panavas, L
   Crnovrsanin, T
   Adams, JL
   Ullman, J
   Sargavad, A
   Tory, M
   Dunne, C
AF Panavas, Liudas
   Crnovrsanin, Tarik
   Adams, Jane Lydia
   Ullman, Jonathan
   Sargavad, Ali
   Tory, Melanie
   Dunne, Cody
TI Investigating the Visual Utility of Differentially Private Scatterplots
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Differential privacy; data study; scatterplots; visual utility
ID FRAMEWORK; HISTOGRAM
AB Increasingly, visualization practitioners are working with, using, and studying private and sensitive data. There can be many stakeholders interested in the resulting analyses-but widespread sharing of the data can cause harm to individuals, companies, and organizations. Practitioners are increasingly turning to differential privacy to enable public data sharing with a guaranteed amount of privacy. Differential privacy algorithms do this by aggregating data statistics with noise, and this now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. To address this gap, we had experts examine 1,200 differentially private scatterplots created with a variety of parameter choices and tested their ability to see aggregate patterns in the private output (i.e. the visual utility of the chart). We synthesized these results to provide easy-to-use guidance for visualization practitioners releasing private data through scatterplots. Our findings also provide a ground truth for visual utility, which we use to benchmark automated utility metrics from various fields. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection.
C1 [Panavas, Liudas; Crnovrsanin, Tarik; Adams, Jane Lydia; Ullman, Jonathan; Tory, Melanie; Dunne, Cody] Northeastern Univ, Boston, MA 02115 USA.
   [Sargavad, Ali] Univ Massachusetts, Amherst, MA 01003 USA.
C3 Northeastern University; University of Massachusetts System; University
   of Massachusetts Amherst
RP Panavas, L (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM panavas.l@northeastern.edu; t.crnovrsanin@northeastern.edu;
   adams.jan@northeastern.edu; j.ullman@northeastern.edu;
   asarv@cs.umass.edu; m.tory@northeastern.edu; c.dunne@northeastern.edu
OI Panavas, Liudas/0000-0003-0428-5579; Dunne, Cody/0000-0002-1609-9776;
   Crnovrsanin, Tarik/0000-0002-4397-5532; Adams, Jane/0000-0002-7826-3500;
   Tory, Melanie/0000-0002-6806-9253; Sarvghad, Ali/0000-0003-3718-7043
FU NIEHS Superfund Research Program [P42ES017198]
FX This work was supported by NIEHS Superfund Research Program under Grant
   P42ES017198 (PROTECT). Recommended for acceptance by Peer-Timo Bremer.
CR Abowd JM, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2867, DOI 10.1145/3219819.3226070
   ANSCOMBE FJ, 1973, AM STAT, V27, P17, DOI 10.2307/2682899
   Arnold C, 2020, arXiv
   Bhattacharjee K, 2020, COMPUT GRAPH FORUM, V39, P675, DOI 10.1111/cgf.14032
   Borkin MA, 2011, IEEE T VIS COMPUT GR, V17, P2479, DOI 10.1109/TVCG.2011.192
   Conover W. J., 1979, Tech. Rep. L.A-7677-MS, DOI [10.1161/CIRCULATIONAHA.107.700971, DOI 10.1161/CIRCULATIONAHA.107.700971]
   Dasgupta A, 2019, IEEE SYM VIS CYB SEC, DOI 10.1109/vizsec48167.2019.9161608
   Dasgupta A, 2013, COMPUT GRAPH FORUM, V32, P35, DOI 10.1111/cgf.12142
   Dhotre PS, 2017, RIVER PUBL SER COMM, P39
   Dobrota B., 2021, Master's thesis
   Dragicevic P., 2015, PhD thesis
   Dwork C., 2019, J. Priv. Confidentiality, V9, DOI DOI 10.29012/JPC.689
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Dwork C, 2006, LECT NOTES COMPUT SC, V4004, P486
   Dwork C, 2017, ANNU REV STAT APPL, V4, P61, DOI 10.1146/annurev-statistics-060116-054123
   Dwork C, 2010, ANN IEEE SYMP FOUND, P51, DOI 10.1109/FOCS.2010.12
   Elmqvist N, 2015, INFORM VISUAL, V14, P250, DOI 10.1177/1473871613513228
   Erlingsson U, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1054, DOI 10.1145/2660267.2660348
   FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Frigerio L, 2019, IFIP ADV INF COMM TE, V562, P151, DOI 10.1007/978-3-030-22312-0_11
   Gaboardi M, 2018, Arxiv, DOI arXiv:1609.04340
   Garrido G. M., 2021, arXiv
   Ghosh A, 2012, SIAM J COMPUT, V41, P1673, DOI 10.1137/09076828X
   Hallgren Kevin A, 2012, Tutor Quant Methods Psychol, V8, P23
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Hay M, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2101, DOI 10.1145/2882903.2899387
   Hay M, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P139, DOI 10.1145/2882903.2882931
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Holohan N, 2019, Arxiv, DOI arXiv:1907.02444
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Khamis H, 2008, J DIAGN MED SONOG, V24, P155, DOI 10.1177/8756479308317006
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Kotsogiannis L, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1323, DOI 10.1145/3035918.3035945
   Kung SY, 2017, MULTIMED TOOLS APPL, V76, P3999, DOI 10.1007/s11042-015-2959-9
   Lee H. B., 2017, Master's thesis
   Li C, 2014, Arxiv, DOI arXiv:1410.0265
   Matejka J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1290, DOI 10.1145/3025453.3025912
   Matute J, 2018, IEEE T VIS COMPUT GR, V24, P542, DOI 10.1109/TVCG.2017.2744339
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Nanayakkara P., 2022, arXiv
   Nida N, 2016, IIOAB J, V7, P202
   Panavas L., 2022, PREPRINT
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Qardaji W, 2013, PROC INT CONF DATA, P757, DOI 10.1109/ICDE.2013.6544872
   Sdv-Dev, 2022, SDV-Dev/SDGym: Benchmarking synthetic data generation methods
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Soria-Comas J, 2017, IEEE T INF FOREN SEC, V12, P1418, DOI 10.1109/TIFS.2017.2663337
   South L, 2022, COMPUT GRAPH FORUM, V41, P43, DOI 10.1111/cgf.14521
   St John MF, 2021, IEEE SYM VIS CYB SEC, P26, DOI 10.1109/VizSec53666.2021.00008
   Sturges HA, 1926, J AM STAT ASSOC, V21, P65, DOI 10.1080/01621459.1926.10502161
   Thaker P, 2020, Arxiv, DOI arXiv:2006.12018
   Torfi A, 2022, INFORM SCIENCES, V586, P485, DOI 10.1016/j.ins.2021.12.018
   Trivedi P.K., 2007, Foundations and Trends in Econometrics, V1, P1, DOI DOI 10.1561/0800000005
   Wang XM, 2019, IEEE T VIS COMPUT GR, V25, P193, DOI 10.1109/TVCG.2018.2865021
   Wang XM, 2018, IEEE T VIS COMPUT GR, V24, P351, DOI 10.1109/TVCG.2017.2745139
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Winograd-Cort D, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3110254
   Wood Alexandra, 2018, Vanderbilt journal of entertainment and technology law, V21, P209, DOI [10.2139/ssrn.3338027, DOI 10.2139/SSRN.3338027]
   Xiao YH, 2010, LECT NOTES COMPUT SC, V6358, P150, DOI 10.1007/978-3-642-15546-8_11
   Xu J, 2013, VLDB J, V22, P797, DOI 10.1007/s00778-013-0309-y
   Zhang D., 2016, Theory Pract. Differe. Privacy, V2016, P1
   Zhang D, 2021, IEEE T VIS COMPUT GR, V27, P1786, DOI 10.1109/TVCG.2020.3030369
   Zhang D, 2018, INT CONF MANAGE DATA, P115, DOI 10.1145/3183713.3196921
   Zhang SL, 2022, Arxiv, DOI arXiv:2202.09587
   Zhang X., 2014, P INT C DAT MIN SDM, P587
   Zhou JH, 2023, IEEE T VIS COMPUT GR, V29, P809, DOI 10.1109/TVCG.2022.3209391
   Zhu TQ, 2017, IEEE T KNOWL DATA EN, V29, P1619, DOI 10.1109/TKDE.2017.2697856
NR 71
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5370
EP 5385
DI 10.1109/TVCG.2023.3292391
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400005
PM 37405888
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhao, ZM
   Xie, W
   Zuo, BH
   Wang, YG
AF Zhao, Zimeng
   Xie, Wei
   Zuo, Binghui
   Wang, Yangang
TI Skeleton Extraction for Articulated Objects With the Spherical
   Unwrapping Profiles
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Skeleton; Three-dimensional displays; Feature extraction; Heating
   systems; Topology; Point cloud compression; Task analysis; Skeleton
   embedding; spherical unwrapping; surface-to-image representation
ID HUMAN POSE ESTIMATION; ALGORITHM
AB Embedding unified skeletons into unregistered scans is fundamental to finding correspondences, depicting motions, and capturing underlying structures among the articulated objects in the same category. Some existing approaches rely on laborious registration to adapt a predefined LBS model to each input, while others require the input to be set to a canonical pose, e.g., T-pose or A-pose. However, their effectiveness is always influenced by the water-tightness, face topology, and vertex density of the input mesh. At the core of our approach lies a novel unwrapping method, named SUPPLE (Spherical UnwraPping ProfiLEs), which maps a surface into image planes independent of mesh topologies. Based on this lower-dimensional representation, a learning-based framework is further designed to localize and connect skeletal joints with fully convolutional architectures. Experiments demonstrate that our framework yields reliable skeleton extractions across a broad range of articulated categories, from raw scans to online CADs.
C1 [Zhao, Zimeng; Xie, Wei; Zuo, Binghui; Wang, Yangang] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Wang, YG (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM zzmpassion@gmail.com; xiewei.xw@outlook.com; z_binghui@163.com;
   yangangwang@seu.edu.cn
OI Xie, Wei/0000-0001-7632-2987; Zhao, Zimeng/0000-0001-6570-0620; Wang,
   Yangang/0000-0002-1325-9252
FU National Natural Science Foundation of China [62076061]; Natural Science
   Foundation of Jiangsu Province [BK20220127]; Young Elite Scientists
   Sponsorship Program by CAST [YES20200025]; Program of Southeast
   University [2242021R41083]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62076061, in part by the Natural Science
   Foundation of Jiangsu Province under Grant BK20220127, by the "Young
   Elite Scientists Sponsorship Program by CAST" under Grant YES20200025
   and by the "Zhishan Young Scholar" Program of Southeast University under
   Grant 2242021R41083.
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Akenine-Mo T., 2018, Real-time rendering
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], UTAH 3D ANIMATION RE
   [Anonymous], TURBOSQUID
   [Anonymous], THINGIVERSE
   Antotsiou D, 2019, LECT NOTES COMPUT SC, V11134, P287, DOI 10.1007/978-3-030-11024-6_19
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789
   Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Biggs Benjamin, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P195, DOI 10.1007/978-3-030-58621-8_12
   Le BH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925959
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boukhayma A, 2019, PROC CVPR IEEE, P10835, DOI 10.1109/CVPR.2019.01110
   Bridson Robert., 2007, SIGGRAPH sketches, V10, DOI DOI 10.1145/1278780.1278807
   Cao ZJ, 2017, INT CONF 3D VISION, P566, DOI 10.1109/3DV.2017.00070
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chao YW, 2021, PROC CVPR IEEE, P9040, DOI 10.1109/CVPR46437.2021.00893
   Chen Cailing, 2018, Wuhan University Journal of Natural Sciences, V23, P201, DOI 10.1007/s11859-018-1311-4
   Chen P, 2021, P IEEE CVF INT C COM, P12929
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Chen Xin, 2021, P IEEE CVF C COMP VI
   Choi Hongsuk, 2020, COMPUTER VISION ECCV
   Choutas Vasileios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P20, DOI 10.1007/978-3-030-58607-2_2
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   Deng B., 2020, LNCS, P612, DOI DOI 10.1007/978-3-030-58571-636
   Ding YK, 2022, PROC CVPR IEEE, P8575, DOI 10.1109/CVPR52688.2022.00839
   Dong ZJ, 2022, PROC CVPR IEEE, P20438, DOI 10.1109/CVPR52688.2022.01982
   Garau N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11657, DOI 10.1109/ICCV48922.2021.01147
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Ge LH, 2018, LECT NOTES COMPUT SC, V11217, P489, DOI 10.1007/978-3-030-01261-8_29
   Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109
   Ge LH, 2018, PROC CVPR IEEE, P8417, DOI 10.1109/CVPR.2018.00878
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Georgakis Georgios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P768, DOI 10.1007/978-3-030-58520-4_45
   GOLDSMITH J, 1987, IEEE COMPUT GRAPH, V7, P14, DOI 10.1109/MCG.1987.276983
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hanocka R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392415
   Hasler N., 2010, P 2010 ACM SIGGRAPH, P23, DOI [DOI 10.1145/1730804.1730809, 10.1145/1730804.1730809]
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang BZ, 2022, IEEE T IMAGE PROCESS, V31, P4679, DOI 10.1109/TIP.2022.3187294
   Huang BZ, 2021, INT CONF 3D VISION, P710, DOI 10.1109/3DV53792.2021.00080
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Jiang B., 2022, P IEEECVF C COMPUTER, P5605
   Junjie Cao, 2010, Proceedings of the Shape Modeling International (SMI 2010), P187, DOI 10.1109/SMI.2010.25
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Karunratanakul K, 2021, INT CONF 3D VISION, P11, DOI 10.1109/3DV53792.2021.00012
   Karunratanakul K, 2020, INT CONF 3D VISION, P333, DOI 10.1109/3DV50981.2020.00043
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P39
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kingma D. P., 2014, arXiv
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kulon D., 2019, P BRIT MACH VIS C, V30, P1
   Kulon D, 2020, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR42600.2020.00504
   Le BH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601161
   Lewiner T., 2003, Journal of Graphics Tools, V8, P1, DOI 10.1080/10867651.2003.10487582
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Lin C, 2021, PROC CVPR IEEE, P4275, DOI 10.1109/CVPR46437.2021.00426
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma QL, 2021, PROC CVPR IEEE, P16077, DOI 10.1109/CVPR46437.2021.01582
   Ma QL, 2020, PROC CVPR IEEE, P6468, DOI 10.1109/CVPR42600.2020.00650
   Maas A.L., 2013, ICML WORK DEEP LEARN, V28
   Magnenat-Thalmann Nadia., 1988, P GRAPH INT 88, P26, DOI 10.20380/GI1988.04
   Malik J, 2020, PROC CVPR IEEE, P7111, DOI 10.1109/CVPR42600.2020.00714
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mihajlovic M, 2021, PROC CVPR IEEE, P10456, DOI 10.1109/CVPR46437.2021.01032
   Mildenhall B, 2020, P ECCV, DOI DOI 10.1007/978-3-030-58452-8
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Moon G., 2020, P EUR C COMP VIS ECC, P440
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Morreale L, 2022, PROC CVPR IEEE, P19311, DOI 10.1109/CVPR52688.2022.01873
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Ni S., 2020, P ACM SIGGRAPH 2020
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Nt H, 2019, Arxiv, DOI arXiv:1905.09550
   Oono K., 2019, arXiv, DOI DOI 10.48550/ARXIV.1905.10947
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Palmer D, 2022, PROC CVPR IEEE, P18644, DOI 10.1109/CVPR52688.2022.01811
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Patel P, 2021, PROC CVPR IEEE, P13463, DOI 10.1109/CVPR46437.2021.01326
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Peng C, 2016, COMPUT GRAPH-UK, V59, P107, DOI 10.1016/j.cag.2016.06.001
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Pishchulin L, 2017, PATTERN RECOGN, V67, P276, DOI 10.1016/j.patcog.2017.02.018
   Poranne R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130845
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qin HX, 2020, COMPUT GRAPH FORUM, V39, P363, DOI 10.1111/cgf.14151
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Rao YM, 2019, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2019.00054
   Reynolds D.A., 2009, Encyclopedia of biometrics, V741, P659, DOI [DOI 10.1007/978-0-387-73003-5_196, DOI 10.1007/978-1-4899-7488-4_196]
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito S, 2021, PROC CVPR IEEE, P2885, DOI 10.1109/CVPR46437.2021.00291
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Sawhney R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132705
   Schaefer Scott, 2007, P 5 EUR S GEOM PROC, P153, DOI [10.5555/1281991.1282013, DOI 10.2312/SGP/SGP07/153-162]
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Shi RX, 2021, PROC CVPR IEEE, P43, DOI 10.1109/CVPR46437.2021.00011
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tiwari Garvita, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P1, DOI 10.1007/978-3-030-58580-8_1
   Vaswani A., 2017, Advances in neural information processing systems, P5998
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang SF, 2021, PROC CVPR IEEE, P7635, DOI 10.1109/CVPR46437.2021.00755
   Wang YG, 2020, IEEE T IMAGE PROCESS, V29, P2977, DOI 10.1109/TIP.2019.2955280
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiong F, 2019, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2019.00088
   Xiu YL, 2022, PROC CVPR IEEE, P13286, DOI 10.1109/CVPR52688.2022.01294
   Xu Z, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392379
   Xu Z, 2019, INT CONF 3D VISION, P298, DOI 10.1109/3DV.2019.00041
   Yang YP, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON 3D VISION, VOL. 2, P41, DOI 10.1109/3DV.2014.47
   Yang ZQ, 2020, PROC CVPR IEEE, P5305, DOI 10.1109/CVPR42600.2020.00535
   Yao PF, 2019, Arxiv, DOI arXiv:1903.10153
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   You Y., 2020, P IEEE CVF C COMP VI, p13 647
   You Y, 2022, PROC CVPR IEEE, P17021, DOI 10.1109/CVPR52688.2022.01653
   Yu ZX, 2020, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR42600.2020.00306
   Yuan SX, 2017, PROC CVPR IEEE, P2605, DOI 10.1109/CVPR.2017.279
   Zhang BW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11334, DOI 10.1109/ICCV48922.2021.01116
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
   Zhang JK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459756
   ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082
   Zhang T., 2020, P IEEE CVF C COMP VI, P7376
   Zhang ZH, 2020, IEEE T VIS COMPUT GR, V26, P1851, DOI 10.1109/TVCG.2020.2973076
   Zhao W, 2007, VISUAL COMPUT, V23, P987, DOI 10.1007/s00371-007-0167-y
   Zhao ZY, 2020, INT CONF ACOUST SPEE, P2478, DOI [10.1109/icassp40776.2020.9053321, 10.1109/ICASSP40776.2020.9053321]
   Zhao ZM, 2022, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR52688.2022.00169
   Zhao ZM, 2021, INT CONF 3D VISION, P899, DOI 10.1109/3DV53792.2021.00098
   Zhao ZM, 2020, PROC SPIE, V11550, DOI 10.1117/12.2572825
   Zhong CL, 2022, Arxiv, DOI arXiv:2206.01724
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
   Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
   Zuffi S, 2019, IEEE I CONF COMP VIS, P5358, DOI 10.1109/ICCV.2019.00546
   Zuffi S, 2018, PROC CVPR IEEE, P3955, DOI 10.1109/CVPR.2018.00416
   Zuffi S, 2017, PROC CVPR IEEE, P5524, DOI 10.1109/CVPR.2017.586
NR 151
TC 0
Z9 0
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3731
EP 3748
DI 10.1109/TVCG.2023.3239370
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700011
PM 37022000
DA 2024-08-05
ER

PT J
AU Combe, T
   Fribourg, R
   Detto, L
   Norm, JM
AF Combe, Theo
   Fribourg, Rebecca
   Detto, Lucas
   Norm, Jean-Marie
TI Exploring the Influence of Virtual Avatar Heads in Mixed Reality on
   Social Presence, Performance and User Experience in Collaborative Tasks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Collaboration; Task analysis; Faces; Resists; Mixed reality;
   Cameras; Mixed Reality; Avatar Representation
ID COMMUNICATION; ENVIRONMENTS
AB In Mixed Reality (MR), users' heads are largely (if not completely) occluded by the MR Head-Mounted Display (HMD) they are wearing. As a consequence, one cannot see their facial expressions and other communication cues when interacting locally. In this paper, we investigate how displaying virtual avatars' heads on-top of the (HMD-occluded) heads of participants in a Video See-Through (VST) Mixed Reality local collaborative task could improve their collaboration as well as social presence. We hypothesized that virtual heads would convey more communicative cues (such as eye direction or facial expressions) hidden by the MR HMDs and lead to better collaboration and social presence. To do so, we conducted a between-subject study ($\mathrm{n}=88$) with two independent variables: the type of avatar (CartoonAvatar/RealisticAvatar/NoAvatar) and the level of facial expressions provided (HighExpr/LowExpr). The experiment involved two dyadic communication tasks: (i) the "20-question" game where one participant asks questions to guess a hidden word known by the other participant and (ii) a urban planning problem where participants have to solve a puzzle by collaborating. Each pair of participants performed both tasks using a specific type of avatar and facial animation. Our results indicate that while adding an avatar's head does not necessarily improve social presence, the amount of facial expressions provided through the social interaction does have an impact. Moreover, participants rated their performance higher when observing a realistic avatar but rated the cartoon avatars as less uncanny. Taken together, our results contribute to a better understanding of the role of partial avatars in local MR collaboration and pave the way for further research exploring collaboration in different scenarios, with different avatar types or MR setups.
C1 [Combe, Theo; Fribourg, Rebecca; Norm, Jean-Marie] Nantes Univ, Ecole Cent Nantes, LS2N PACCE, UMR 6004, Nantes, France.
   [Detto, Lucas] Nantes Univ, ENSA Nantes, Ecole Cent Nantes, CNRS,AAU CRENAU,UMR 1563, Nantes, France.
C3 Nantes Universite; Ecole Centrale de Nantes; Centre National de la
   Recherche Scientifique (CNRS); CNRS - Institute for Humanities & Social
   Sciences (INSHS); Nantes Universite; Ecole Centrale de Nantes
RP Combe, T (corresponding author), Nantes Univ, Ecole Cent Nantes, LS2N PACCE, UMR 6004, Nantes, France.
EM theo.combe@ec-nantes.fr; rebecca.fribourg@ec-nantes.fr;
   lucas.detto@eleves.ec-nantes.fr; jean-marie.normand@ec-nantes.fr
OI Combe, Theo/0000-0003-1209-5580
CR Aburumman N, 2022, INT J HUM-COMPUT ST, V164, DOI 10.1016/j.ijhcs.2022.102819
   Anjyo K., 2018, Handbook of Human Motion, P2145, DOI [10.1007/978-3-319-14418-425, DOI 10.1007/978-3-319-14418-425]
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bente G., 2007, PRES 2007 P 10 ANN I
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Billinghurst M, 2003, INT J HUM-COMPUT INT, V16, P395, DOI 10.1207/S15327590IJHC1603_2
   Biocca E., 2002, P 5 ANN INT WORKSH P, P2
   Biocca F., 2001, 4 ANN INT WORKSH PRE
   Cho S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P26, DOI [10.1109/VR46266.2020.00-84, 10.1109/VR46266.2020.1581170537418]
   Choudhary Z, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P425, DOI [10.1109/VR46266.2020.00-41, 10.1109/VR46266.2020.1581089101511]
   Dubosc C, 2021, COMPUT GRAPH-UK, V101, P82, DOI 10.1016/j.cag.2021.08.011
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Harms C., 2004, P 7 ANN INT WORKSH P, P246
   HART S G, 1988, P139
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Hepperle D, 2022, VISUAL COMPUT, V38, P1227, DOI 10.1007/s00371-021-02151-0
   Herrera F, 2018, PRESENCE-VIRTUAL AUG, V27, P163, DOI 10.1162/PRES_a_00324
   Higgins D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.668499
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Joiner R., 2002, P C COMP SUPP COLL L, P371
   Jongerius C, 2020, J NONVERBAL BEHAV, V44, P363, DOI 10.1007/s10919-020-00333-3
   Kaliisa R, 2022, COMPUT EDUC OPEN, V3, DOI 10.1016/j.caeo.2022.100073
   KENDON A, 1969, BRIT J PSYCHOL, V60, P481, DOI 10.1111/j.2044-8295.1969.tb01222.x
   Kreijns K, 2003, COMPUT HUM BEHAV, V19, P335, DOI 10.1016/S0747-5632(02)00057-2
   Kruzic CO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76672-4
   Kullmann P., 2023, 2023 CHI C HUM FACT, DOI [10.1145/3544549.3585617, DOI 10.1145/3544549.3585617]
   Lankes M., 2018, P 13 INT C FDN DIG G, DOI [10.1145/3235765.3235766, DOI 10.1145/3235765.3235766]
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Mai C, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P515, DOI 10.1145/3152832.3157813
   Manor BR, 2003, J NEUROSCI METH, V128, P85, DOI 10.1016/S0165-0270(03)00151-1
   Matsuda N, 2021, SIGGRAPH '21: ACM SIGGRAPH 2021 EMERGING TECHNOLOGIES, DOI 10.1145/3450550.3465338
   McDonnell R., 2012, Motion in Games, P8
   Meier A, 2007, INT J COMP-SUPP COLL, V2, P63, DOI 10.1007/s11412-006-9005-x
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Morin DG, 2023, VIRTUAL REAL-LONDON, V27, P2129, DOI 10.1007/s10055-023-00785-0
   Mottelson A, 2023, ACM T COMPUT-HUM INT, V30, DOI 10.1145/3590767
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   O'Brien H., 2016, Why engagement matters: Cross-disciplinary perspectives of user engagement in digital media, P27
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Oyama E, 2021, ADV ROBOTICS, V35, P1223, DOI 10.1080/01691864.2021.1976670
   Pan Y, 2023, IEEE T VIS COMPUT GR, V29, P2527, DOI 10.1109/TVCG.2023.3247101
   Park S, 2019, ROUTL ADV KOREAN STU, P3
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186495
   Prytz E., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P119, DOI 10.1109/ISMAR.2010.5643559
   Rebol M, 2022, INT SYM MIX AUGMENT, P346, DOI 10.1109/ISMAR55827.2022.00050
   Rogers SL, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.750729
   Seymour M, 2021, J ASSOC INF SYST, V22, P591, DOI 10.17705/1jais.00674
   Shin M, 2019, COMPUT HUM BEHAV, V94, P100, DOI 10.1016/j.chb.2019.01.016
   Stefanova M. P., 2020, PhD thesis, P3
   Sterna R, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.705448
   Swinth K., 2002, P 5 ANN INT WORKSH P, V392, P3
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Torre E., 2019, P MOT INT GAM, P1, DOI 10.1145/3359566.33600653
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   Visconti A, 2023, COMPUT ANIMAT VIRT W, V34, DOI 10.1002/cav.2188
   Waldow K, 2019, LECT NOTES COMPUT SC, V11883, P246, DOI 10.1007/978-3-030-31908-3_15
   Wang P, 2023, VIRTUAL REAL-LONDON, V27, P1409, DOI 10.1007/s10055-023-00748-5
   Wiltshire TravisJ., 2013, P HUMAN FACTORS ERGO, V57, P1273, DOI DOI 10.1177/15419312135712826
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yu K, 2022, IEEE T VIS COMPUT GR, V28, P2190, DOI 10.1109/TVCG.2022.3150520
   Zhao YJ, 2018, Arxiv, DOI arXiv:1807.08772
   Zhao YJ, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI [10.1109/VR.2019.8797925, 10.1109/vr.2019.8797925]
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 68
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2206
EP 2216
DI 10.1109/TVCG.2024.3372051
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400060
PM 38437082
DA 2024-08-05
ER

PT J
AU Wen, EL
   Gupta, C
   Sasikumar, P
   Billinghurst, M
   Wilmott, J
   Skow, E
   Dey, A
   Nanayakkara, S
AF Wen, Elliott
   Gupta, Chitralekha
   Sasikumar, Prasanth
   Billinghurst, Mark
   Wilmott, James
   Skow, Emily
   Dey, Arindam
   Nanayakkara, Suranga
TI VR.net: A Real-world Dataset for Virtual Reality Motion Sickness
   Research
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Motion Sickness; Virtual Reality; Machine Learning
ID VISUALLY-INDUCED MOTION; FIELD-OF-VIEW; SIMULATOR SICKNESS; HEART-RATE;
   CYBERSICKNESS; VECTION; DEPTH; ANGLE; PITCH; GAZE
AB Researchers have used machine learning approaches to identify motion sickness in VR experience. These approaches would certainly benefit from an accurately labeled, real-world, diverse dataset that enables the development of generalizable ML models. We introduce 'VR.net', a dataset comprising 165-hour gameplay videos from 100 real-world games spanning ten diverse genres, evaluated by 500 participants. VR.net accurately assigns 24 motion sickness-related labels for each video frame, such as camera/object movement, depth of field, and motion flow. Building such a dataset is challenging since manual labeling would require an infeasible amount of time. Instead, we implement a tool to automatically and precisely extract ground truth data from 3D engines' rendering pipelines without accessing VR games' source code. We illustrate the utility of VR.net through several applications, such as risk factor detection and sickness level prediction. We believe that the scale, accuracy, and diversity of VR.net can offer unparalleled opportunities for VR motion sickness research and beyond.We also provide access to our data collection tool, enabling researchers to contribute to the expansion of VR.net.
C1 [Wen, Elliott; Billinghurst, Mark] Univ Auckland, Auckland, New Zealand.
   [Gupta, Chitralekha; Sasikumar, Prasanth; Nanayakkara, Suranga] Natl Univ Singapore, Singapore, Singapore.
   [Wilmott, James; Skow, Emily; Dey, Arindam] Meta Real Labs, Burlingame, CA USA.
C3 University of Auckland; National University of Singapore
RP Wen, EL (corresponding author), Univ Auckland, Auckland, New Zealand.
EM jq.elliott.wen@gmail.com; Chitralekha@ahlab.org; Prasanth@ahlab.org;
   mark.billinghurst@auckland.ac.nz; jwilmott@meta.com; emilyskow@meta.com;
   aridey@meta.com; suranga@ahlab.org
OI NANAYAKKARA, SURANGA/0000-0001-7441-5493
CR Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Alloghani M., 2020, Supervised and Unsupervised Learning for Data Science, P3, DOI [10.1007/978-3-030-22475-2, DOI 10.1007/978-3-030-22475-21, DOI 10.1007/978-3-030-22475-2_1, 10.1007/978-3-030-22475-2_1]
   [Anonymous], 2023, Int. J. Comput. Digit. Syst, V5
   [Anonymous], Meta captures 90% of vr headset market share
   Arima M, 2004, OCEANS '04 MTS/IEEE TECHNO-OCEAN '04, VOLS 1- 2, CONFERENCE PROCEEDINGS, VOLS. 1-4, P1129
   Beggiato M, 2020, ADV INTELL SYST COMP, V1131, P932, DOI 10.1007/978-3-030-39512-4_142
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chardonnet M. A., 2015, International conference on artificial reality and telexistence eurographics symposium on virtual environments, P9
   Cheng-Li Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P334, DOI 10.1109/FSKD.2012.6234149
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Duh HBL, 2001, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2001.913791
   Ekman W. V., 1978, EnvironmentalPsychology & Nonverbal Behavior, V3
   Emoto M, 2008, DISPLAYS, V29, P90, DOI 10.1016/j.displa.2007.09.010
   Fan HQ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3783, DOI 10.1145/3474085.3478329
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fifty C, 2021, ADV NEUR IN, V34
   Foxman M, 2022, IEEE T GAMES, V14, P466, DOI 10.1109/TG.2021.3119521
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Hell S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P153, DOI 10.1109/AIVR.2018.00032
   Holmes SR, 2001, J PSYCHOPHYSIOL, V15, P35, DOI 10.1027//0269-8803.15.1.35
   Johnson D. M., 2005, Introduction to and review of simulator sickness research, V1
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim H., 2020, IEEE Trans-actions on Neural Networks and Learning Systems, V3
   Kim HG, 2021, AAAI CONF ARTIF INTE, V35, P836
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim W., 2018, 2018 10 INT C QUAL M, P1
   Kuiper OX, 2020, APPL ERGON, V85, DOI 10.1016/j.apergo.2020.103068
   LaCount LT, 2009, COMPUT CARDIOL, V36, P49
   Lee JY, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145697
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Li JY, 2021, AUTOMOTIVEUI '21: 13TH INTERNATIONAL ACM CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P28, DOI [10.1145/34091183475137, 10.1145/3409118.3475137]
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Naeem A., An unsupervised machinelearning algorithms: Comprehensive review
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Park SH, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1145/3491102.3501847, 10.1016/j.cap.2022.08.010]
   Proffitt DR, 1995, PSYCHON B REV, V2, P409, DOI 10.3758/BF03210980
   Sangmin Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P170, DOI 10.1007/978-3-030-58592-1_11
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Smyth J, 2021, APPL ERGON, V92, DOI 10.1016/j.apergo.2020.103315
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   Solorio-Fernández S, 2020, ARTIF INTELL REV, V53, P907, DOI 10.1007/s10462-019-09682-y
   Tan RC, 2022, IEEE INTELL SYST, V37, P86, DOI 10.1109/MIS.2022.3208485
   Terenzi P., 2020, AIAA SCIT 2020 FOR, P0171
   Tong Z, 2022, Arxiv, DOI arXiv:2203.12602
   Totosis N, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P552, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00104
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   Wen E, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545656
   Wibirama S, 2018, ENTERTAIN COMPUT, V26, P117, DOI 10.1016/j.entcom.2018.02.003
   Wibirama S, 2014, IEEE ENG MED BIO, P4803, DOI 10.1109/EMBC.2014.6944698
   Xue A. El Ali, 2021, IEEE Transactions on Multimedia, V2
   Zuzewicz K, 2011, INT J OCCUP SAF ERGO, V17, P403
NR 64
TC 1
Z9 1
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2330
EP 2336
DI 10.1109/TVCG.2024.3372044
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400053
PM 38437109
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhang, WH
   Yue, YT
   Pan, H
   Chen, ZG
   Wang, C
   Pfister, H
   Wang, WP
AF Zhang, Wenhua
   Yue, Yating
   Pan, Hao
   Chen, Zhonggui
   Wang, Chuan
   Pfister, Hanspeter
   Wang, Wenping
TI Marching Windows: Scalable Mesh Generation for Volumetric Data With
   Multiple Materials
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topology; Mesh generation; Three-dimensional displays; Imaging; Data
   visualization; Memory management; Measurement; Large volumetric data;
   multiple material; marching windows; mesh simplification; topology
   guarantee
ID TETRAHEDRAL MESHES; SIMPLIFICATION; ALGORITHM; SURFACES
AB Volumetric data abounds in medical imaging and other fields. With the improved imaging quality and the increased resolution, volumetric datasets are getting so large that the existing tools have become inadequate for processing and analyzing the data. Here we consider the problem of computing tetrahedral meshes to represent large volumetric datasets with labeled multiple materials, which are often encountered in medical imaging or microscopy optical slice tomography. Such tetrahedral meshes are a more compact and expressive geometric representation so are in demand for efficient visualization and simulation of the data, which are impossible if the original large volumetric data are used directly due to the large memory requirement. Existing methods for meshing volumetric data are not scalable for handling large datasets due to their sheer demand on excessively large run-time memory or failure to produce a tet-mesh that preserves the multi-material structure of the original volumetric data. In this article we propose a novel approach, called Marching Windows, that uses a moving window and a disk-swap strategy to reduce the run-time memory footprint, devise a new scheme that guarantees to preserve the topological structure of the original dataset, and adopt an error-guided optimization technique to improve both geometric approximation error and mesh quality. Extensive experiments show that our method is capable of processing very large volumetric datasets beyond the capability of the existing methods and producing tetrahedral meshes of high quality.
C1 [Zhang, Wenhua; Yue, Yating; Wang, Chuan] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Pan, Hao] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Chen, Zhonggui] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
   [Pfister, Hanspeter] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Wang, Wenping] Texas A&M Univ, Dept Visualizat, College Stn, TX 77843 USA.
C3 University of Hong Kong; Microsoft Research Asia; Microsoft; Xiamen
   University; Harvard University; Texas A&M University System; Texas A&M
   University College Station
RP Zhang, WH (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM winniezhangcoding@gmail.com; ytyue@cs.hku.hk; haopan@microsoft.com;
   chenzhonggui@xmu.edu.cn; cwang.hku@gmail.com; pfister@g.harvard.edu;
   wenping@tamu.edu
RI Zhang, Wenhua/HOC-9630-2023
OI Zhang, Wenhua/0000-0001-5411-0684; PAN, Hao/0000-0003-3628-9777; Chen,
   Zhonggui/0000-0002-9960-4896; Pfister, Hanspeter/0000-0002-3620-2582
FU National Natural Science Foundation of China
FX No Statement Available
CR Alliez C., 2015, inCGAL User Reference Manual
   Alliez P, 2005, ACM T GRAPHIC, V24, P617, DOI 10.1145/1073204.1073238
   Amenta N., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P39, DOI 10.1145/276884.276889
   [Anonymous], 2008, Discrete Differential Geometry. Ed. by
   [Anonymous], 2020, The CGAL Project CGAL User and Reference Manual 5.1.0
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Boltcheva D, 2009, LECT NOTES COMPUT SC, V5762, P283, DOI 10.1007/978-3-642-04271-3_35
   Bronson J, 2014, IEEE T VIS COMPUT GR, V20, P223, DOI 10.1109/TVCG.2013.115
   Cabiddu D, 2015, COMPUT GRAPH-UK, V51, P81, DOI 10.1016/j.cag.2015.05.015
   Chen L, 2004, J COMPUT MATH, V22, P299
   Chen ZG, 2014, SIAM J SCI COMPUT, V36, pA930, DOI 10.1137/120875132
   Cheng SW, 2010, DISCRETE COMPUT GEOM, V43, P121, DOI 10.1007/s00454-008-9109-3
   Choi HK, 2010, INT J ADV MANUF TECH, V50, P235, DOI 10.1007/s00170-009-2484-y
   Chopra P, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P133, DOI 10.1109/VISUAL.2002.1183767
   Cignoni P, 2000, IEEE VISUAL, P85, DOI 10.1109/VISUAL.2000.885680
   Cohen-Steiner David., 2002, P 18 ANN S COMPUTATI, P199, DOI [10.1145/513400.513425, DOI 10.1145/513400.513425]
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   CUTLER B., 2004, SGP 04, P93
   Date H, 2009, IEEE T MAGN, V45, P1352, DOI 10.1109/TMAG.2009.2012623
   Dey Tamal., 1999, Publications de lInstitut Mathmatique, V66, P23
   Dey TK, 2009, ALGORITHMS, V2, P1327, DOI 10.3390/a2041327
   DOI A, 1991, IEICE TRANS COMMUN, V74, P214
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Eppstein D, 2001, TUTORIAL 10 INT MESH, V10
   Faraj N, 2016, COMPUT GRAPH-UK, V58, P150, DOI 10.1016/j.cag.2016.05.019
   Frey P.J, 2007, Mesh generation: application to finite elements
   Fu XM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661235
   Garland M, 2005, ACM T GRAPHIC, V24, P209, DOI 10.1145/1061347.1061350
   Garland Michael, 1997, SIGGRAPH, DOI DOI 10.1145/258734.258849
   Guanlong Li, 2012, 2012 IEEE/ACIS 11th International Conference on Computer and Information Science (ICIS), P356, DOI 10.1109/ICIS.2012.107
   Harer H Edelsbrunner J., 2010, COMPUTATIONAL TOPOLO
   Heckbert PS, 1999, COMP GEOM-THEOR APPL, V14, P49, DOI 10.1016/S0925-7721(99)00030-9
   Heller N, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101821
   Ito Y, 2007, MATH COMPUT SIMULAT, V75, P200, DOI 10.1016/j.matcom.2006.12.008
   Lévy B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778856
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Loseille A, 2015, PROCEDIA ENGINEER, V124, P57, DOI 10.1016/j.proeng.2015.10.122
   Ma WY, 2004, COMPUT AIDED DESIGN, V36, P525, DOI 10.1016/S0010-4485(03)00160-X
   Meyer M, 2008, IEEE T VIS COMPUT GR, V14, P1539, DOI 10.1109/TVCG.2008.154
   Moore RH, 2009, ENG COMPUT-GERMANY, V25, P221, DOI 10.1007/s00366-008-0114-1
   Murphy M, 2001, INT J COMPUT GEOM AP, V11, P669, DOI 10.1142/S0218195901000699
   Pons JP, 2007, LECT NOTES COMPUT SC, V4584, P198
   Renze KJ, 1996, IEEE COMPUT GRAPH, V16, P24, DOI 10.1109/38.544069
   Rossignac P., 1993, Multi-Resolution 3D Approximations forRendering Complex Scenes
   RUPPERT J, 1995, J ALGORITHM, V18, P548, DOI 10.1006/jagm.1995.1021
   Said R, 1999, COMPUT METHOD APPL M, V177, P109, DOI 10.1016/S0045-7825(98)00374-0
   Shewchuk H., 2014, S COMPUT GEOMETRY, P290
   Shewchuk J. R., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P86, DOI 10.1145/276884.276894
   Shewchuk JonathanRichard., 2002, 11 INT MESHING ROUND, P193
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Si H, 2010, FINITE ELEM ANAL DES, V46, P33, DOI 10.1016/j.finel.2009.06.017
   Soler L., 2010, TECH REP, P1
   Soucy M, 1996, COMPUT VIS IMAGE UND, V63, P1, DOI 10.1006/cviu.1996.0001
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P1007, DOI 10.1109/TVCG.2010.90
   Trotts IJ, 1999, IEEE T VIS COMPUT GR, V5, P224, DOI 10.1109/2945.795214
   Vivodtzev F, 2011, MATH VIS, P55
   Wei Donglai, 2020, Med Image Comput Comput Assist Interv, V12265, P66, DOI 10.1007/978-3-030-59722-1_7
   Wu Y., 2004, Proceedings of the 2Nd International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, P50
   Yao JH, 2016, COMPUT MED IMAG GRAP, V49, P16, DOI 10.1016/j.compmedimag.2015.12.006
NR 59
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1728
EP 1742
DI 10.1109/TVCG.2022.3225526
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500006
PM 36455093
DA 2024-08-05
ER

PT J
AU Floricel, C
   Wentzel, A
   Mohamed, A
   Fuller, CD
   Canahuate, G
   Marai, GE
AF Floricel, Carla
   Wentzel, Andrew
   Mohamed, Abdallah
   Fuller, C. David
   Canahuate, Guadalupe
   Marai, G. Elisabeta
TI Roses Have Thorns: Understanding the Downside of Oncological Care
   Delivery Through Visual Analytics and Sequential Rule Mining
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Cancer; Computational modeling; Data visualization; Data
   mining; Analytical models; Data models; Temporal Data; Life Sciences;
   Mixed Initiative Human-Machine Analysis; Data Clustering and Aggregation
ID SYMPTOM CLUSTERS; EVENT SEQUENCES; CANCER-PATIENTS; NECK-CANCER;
   ASSOCIATION; VALIDATION; PREDICTION; COHORT; HEAD
AB Personalized head and neck cancer therapeutics have greatly improved survival rates for patients, but are often leading to understudied long-lasting symptoms which affect quality of life. Sequential rule mining (SRM) is a promising unsupervised machine learning method for predicting longitudinal patterns in temporal data which, however, can output many repetitive patterns that are difficult to interpret without the assistance of visual analytics. We present a data-driven, human-machine analysis visual system developed in collaboration with SRM model builders in cancer symptom research, which facilitates mechanistic knowledge discovery in large scale, multivariate cohort symptom data. Our system supports multivariate predictive modeling of post-treatment symptoms based on during-treatment symptoms. It supports this goal through an SRM, clustering, and aggregation back end, and a custom front end to help develop and tune the predictive models. The system also explains the resulting predictions in the context of therapeutic decisions typical in personalized care delivery. We evaluate the resulting models and system with an interdisciplinary group of modelers and head and neck oncology researchers. The results demonstrate that our system effectively supports clinical and symptom research.
C1 [Floricel, Carla; Wentzel, Andrew; Marai, G. Elisabeta] Univ Illinois, Chicago, IL 60607 USA.
   [Canahuate, Guadalupe] Univ Iowa, Iowa City, IA USA.
   [Mohamed, Abdallah; Fuller, C. David] Univ Texas MD Anderson Canc Ctr, Austin, TX USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; University of Iowa; University
   of Texas System; UTMD Anderson Cancer Center
RP Floricel, C (corresponding author), Univ Illinois, Chicago, IL 60607 USA.
EM cflori3@uic.edu; awentze2@uic.edu; asmohamed@mdanderson.org;
   cdfuller@mdanderson.org; guadalupe-canahuate@uiowa.edu; gmarai@uic.edu
OI Fuller, Clifton/0000-0002-5264-3994
FU NIH
FX No Statement Available
CR Agarwal R., 1994, P 20 INT C VER LARG, V1215, P487, DOI DOI 10.5555/645920.672836
   Aktas A, 2010, PALLIATIVE MED, V24, P373, DOI 10.1177/0269216310367842
   Antweiler D, 2022, IEEE VIS CONF, P55, DOI 10.1109/VIS54862.2022.00020
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Bernard J., 2014, PROC IEEE VIS WORKSH, DOI DOI 10.1109/MCG.2015.492
   Biggs M., 2021, 19 INT C ARTIF INTEL, DOI DOI 10.1007/978-3-030-77211-6_582,3
   Brasseur L, 2005, TECH COMMUN Q, V14, P161, DOI 10.1207/s15427625tcq1402_3
   Bruzzese D, 2008, LECT NOTES COMPUT SC, V4404, P103, DOI 10.1007/978-3-540-71080-6_8
   Caballero HSG, 2017, 2017 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC), P39, DOI 10.1109/VAHC.2017.8387499
   Canahuate G, 2023, ORAL ONCOL, V144, DOI 10.1016/j.oraloncology.2023.106460
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Christopherson KM, 2019, CLIN TRANSL RAD ONCO, V18, P16, DOI 10.1016/j.ctro.2019.06.005
   Chui KKH, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014683
   Cleeland CS, 2000, CANCER-AM CANCER SOC, V89, P1634, DOI 10.1002/1097-0142(20001001)89:7<1634::AID-CNCR29>3.0.CO;2-V
   Nguyen D, 2018, KNOWL-BASED SYST, V161, P313, DOI 10.1016/j.knosys.2018.07.031
   DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364
   Deogun J, 2005, LECT NOTES ARTIF INT, V3642, P98, DOI 10.1007/11548706_11
   Dong ST, 2016, J PAIN SYMPTOM MANAG, V51, P88, DOI 10.1016/j.jpainsymman.2015.07.013
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Elshehaly M, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P11, DOI 10.1109/BELIV57783.2022.00006
   Eraj S. A., 2017, Rad. Onco., V12, P2
   Fan G, 2007, Curr Oncol, V14, P173, DOI 10.3747/co.2007.145
   Floricel C, 2022, Arxiv, DOI arXiv:2210.01618
   Floricel C, 2022, IEEE T VIS COMPUT GR, V28, P151, DOI 10.1109/TVCG.2021.3114810
   Fournier-Viger P, 2014, J MACH LEARN RES, V15, P3389
   Fournier-Viger P, 2012, KNOWL-BASED SYST, V25, P63, DOI 10.1016/j.knosys.2011.07.005
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Guo S., 2019, PROC CHI C HUMAN FAC, P1, DOI DOI 10.1145/3290605.33008032
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Gwede CK, 2008, SUPPORT CARE CANCER, V16, P925, DOI 10.1007/s00520-007-0364-2
   Huang CW, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0218-7
   Huat Ong K., 2002, INT WORKSHOP ACT MIN
   Illi J, 2012, CYTOKINE, V58, P437, DOI 10.1016/j.cyto.2012.02.015
   Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI [DOI 10.1111/J.1469-8137.1912.TB05611.X, 10.1111/J.1469-8137.1912.TB05611.X]
   Jentner W, 2019, STUD BIG DATA, V51, P303, DOI 10.1007/978-3-030-04921-8_12
   Kim HJ, 2013, CURR OPIN SUPPORT PA, V7, P45, DOI 10.1097/SPC.0b013e32835bf28b
   Klemm P, 2014, IEEE T VIS COMPUT GR, V20, P1673, DOI 10.1109/TVCG.2014.2346591
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Letham B, 2015, ANN APPL STAT, V9, P1350, DOI 10.1214/15-AOAS848
   Luciani T, 2020, J Biomed Inform, V112S, P100067, DOI 10.1016/j.yjbinx.2020.100067
   Luciani T., 2018, IEEE Trans. Vis. Comp. Graph., V25, P6
   Malik S., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10. 1145/2678025.2701407, 10.1145/2678025.2701407]
   Marai G. E., 2015, EUROVIS WORKSHOP VIS, P9
   Marai G. E., 2019, Ten simple rules to create biological network figures for communication, P5
   Marai GE, 2019, IEEE T VIS COMPUT GR, V25, P1732, DOI 10.1109/TVCG.2018.2817557
   Marai GE, 2018, IEEE T VIS COMPUT GR, V24, P913, DOI 10.1109/TVCG.2017.2744459
   Maries A, 2013, IEEE T VIS COMPUT GR, V19, P2916, DOI 10.1109/TVCG.2013.161
   Martens D, 2009, IEEE T KNOWL DATA EN, V21, P178, DOI 10.1109/TKDE.2008.131
   Metsalu T, 2015, NUCLEIC ACIDS RES, V43, pW566, DOI 10.1093/nar/gkv468
   Meuschke M., 2021, IEEE Trans. Vis. Comp. Graph., DOI DOI 10.1109/TVCG.2021.31340832
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Multidisciplinary Larynx Cancer Working Group, 2017, Sci. Reports, V7, P6
   O'Sullivan B, 2016, LANCET ONCOL, V17, P440, DOI 10.1016/S1470-2045(15)00560-4
   Peake G, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2060, DOI 10.1145/3219819.3220072
   Plaisant C, 1996, P SIGCHI C HUM FACT, V1996, P221, DOI [DOI 10.1145/238386.238493.2, 10.1145/257089.2573912, DOI 10.1145/257089.2573912, DOI 10.1145/238386.238493]
   Raidou RG, 2015, COMPUT GRAPH FORUM, V34, P11, DOI 10.1111/cgf.12613
   Rosenthal DI, 2007, HEAD NECK-J SCI SPEC, V29, P923, DOI 10.1002/hed.20602
   Skerman HM, 2009, RES NURS HEALTH, V32, P345, DOI 10.1002/nur.20323
   Tandan M, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104249
   Tardini E, 2022, J MED INTERNET RES, V24, DOI 10.2196/29455
   Tosado J., 2020, Scientific reports, V10, P2
   van Dijk L. V., 2021, Cancer, V127, P2
   van Dijk LV, 2023, EUR J CANCER, V178, P150, DOI 10.1016/j.ejca.2022.10.011
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P238, DOI 10.1109/TVCG.2021.3114840
   Wang TD, 2009, IEEE T VIS COMPUT GR, V15, P1049, DOI 10.1109/TVCG.2009.187
   Wang Y., 2021, IDEAS '21. Assoc. for Comp. Mach., DOI DOI 10.1145/3472163.34721772
   Wenskovitch JE, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-316
   Wentzel A, 2020, IEEE T VIS COMPUT GR, V26, P949, DOI 10.1109/TVCG.2019.2934546
   Wentzel A., 2023, Comp. Graph. Forum, DOI DOI 10.1111/CGF.148302
   Wentzel A, 2021, RADIOTHER ONCOL, V161, P152, DOI 10.1016/j.radonc.2021.06.016
   Wentzel A, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P281, DOI 10.1109/VIS47514.2020.00063
   Wentzel A, 2020, RADIOTHER ONCOL, V148, P245, DOI 10.1016/j.radonc.2020.05.023
   Wongsuphasawat K., 2011, IEEE VISWEEK WORKSHO, P6
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Yang H, 2017, INT C MACH LEARN
   Yuan J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P6, DOI 10.1109/VIS49827.2021.9623303
   Zdilar L, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.18.00052
   Zhang ZY, 2015, INFORM VISUAL, V14, P289, DOI 10.1177/1473871614526077
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zhuochen Jin, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3344258
NR 82
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1227
EP 1237
DI 10.1109/TVCG.2023.3326939
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500037
PM 38015695
OA Green Submitted, Green Accepted
DA 2024-08-05
ER

PT J
AU Morrical, N
   Zellmann, S
   Sahistan, A
   Shriwise, P
   Pascucci, V
AF Morrical, Nate
   Zellmann, Stefan
   Sahistan, Alper
   Shriwise, Patrick
   Pascucci, Valerio
TI Attribute-Aware RBFs: Interactive Visualization of Time Series Particle
   Volumes Using RT Core Range Queries
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ray Tracing; Volume Rendering; Particle Volumes; Radial Basis Functions;
   Scientific Visualization
ID MODELS
AB Smoothed-particle hydrodynamics (SPH) is a mesh-free method used to simulate volumetric media in fluids, astrophysics, and solid mechanics. Visualizing these simulations is problematic because these datasets often contain millions, if not billions of particles carrying physical attributes and moving over time. Radial basis functions (RBFs) are used to model particles, and overlapping particles are interpolated to reconstruct a high-quality volumetric field; however, this interpolation process is expensive and makes interactive visualization difficult. Existing RBF interpolation schemes do not account for color-mapped attributes and are instead constrained to visualizing just the density field. To address these challenges, we exploit ray tracing cores in modern GPU architectures to accelerate scalar field reconstruction. We use a novel RBF interpolation scheme to integrate per-particle colors and densities, and leverage GPU-parallel tree construction and refitting to quickly update the tree as the simulation animates over time or when the user manipulates particle radii. We also propose a Hilbert reordering scheme to cluster particles together at the leaves of the tree to reduce tree memory consumption. Finally, we reduce the noise of volumetric shadows by adopting a spatially temporal blue noise sampling scheme. Our method can provide a more detailed and interactive view of these large, volumetric, time-series particle datasets than traditional methods, leading to new insights into these physics simulations.
C1 [Morrical, Nate; Sahistan, Alper; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
   [Zellmann, Stefan] Univ Cologne, Cologne, Germany.
   [Shriwise, Patrick] Argonne Natl Lab, Argonne, IL USA.
C3 Utah System of Higher Education; University of Utah; University of
   Cologne; United States Department of Energy (DOE); Argonne National
   Laboratory
RP Morrical, N (corresponding author), Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
EM natemorrical@gmail.com
RI pascucci, Valerio/GXF-0616-2022
OI pascucci, Valerio/0000-0002-8877-2042; Zellmann,
   Stefan/0000-0003-2880-9090; Sahistan, Alper/0000-0002-3480-7713;
   Morrical, Nathan/0000-0002-2262-6974; Shriwise,
   Patrick/0000-0002-3979-7665
FU UChicago Argonne, LLC
FX No Statement Available
CR Berzins M, 2016, SIAM J SCI COMPUT, V38, pS101, DOI 10.1137/15M1023270
   Cha D, 2009, COMPUT GRAPH FORUM, V28, P1247, DOI 10.1111/j.1467-8659.2009.01502.x
   Evangelou I., 2021, Journal of Computer Graphics Techniques (JCGT), V10, P25
   Fraedrich R, 2010, IEEE T VIS COMPUT GR, V16, P1533, DOI 10.1109/TVCG.2010.148
   Fraedrich R, 2009, IEEE T VIS COMPUT GR, V15, P1251, DOI 10.1109/TVCG.2009.142
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Gralka P, 2020, SYMP LARG DATA ANAL, P42, DOI 10.1109/LDAV51489.2020.00012
   Green S., 2008, Volumetric particle shadows
   Gumhold S, 2003, VISION, MODELING, AND VISUALIZATION 2003, P245
   Habib S, 2016, NEW ASTRON, V42, P49, DOI 10.1016/j.newast.2015.06.003
   Heinen M, 2019, J CHEM PHYS, V151, DOI 10.1063/1.5111759
   Jang Y., 2010, IEEE EG S VOLUME GRA, DOI [10.2312/VG/VG10/045-052, DOI 10.2312/VG/VG10/045-052]
   Karras Tero, 2012, P 4 ACM SIGGRAPH EUR, P33, DOI [10.2312/EGGH/HPG12/033-037, DOI 10.2312/EGGH/HPG12/033-037]
   Knoll A., 2021, Ray Tracing Gems II, Chapter 44: Path Tracing RBF Particle Volumes, P713, DOI [10.1007/978-1-4842-7185-8_44, DOI 10.1007/978-1-4842-7185-8_44]
   Knoll A., 2019, Ray Tracing Gems, Chapter 29: Efficient Particle Volume Splatting in a Ray Tracer, P533, DOI [10.1007/978-1-4842-4427-2_29, DOI 10.1007/978-1-4842-4427-2_29]
   Knoll A, 2014, COMPUT GRAPH FORUM, V33, P71, DOI 10.1111/cgf.12363
   Kuhnert J, 2014, Advances in PDE modeling and computation, P119
   Kutz P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073665
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Lindemann F, 2011, IEEE T VIS COMPUT GR, V17, P1922, DOI 10.1109/TVCG.2011.161
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Morrical N, 2023, IEEE T VIS COMPUT GR, V29, P537, DOI 10.1109/TVCG.2022.3209418
   Morrical N, 2022, IEEE T VIS COMPUT GR, V28, P2852, DOI 10.1109/TVCG.2020.3042930
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Morrical Nathan V, 2023, Zenodo, DOI 10.5281/ZENODO.8173156
   Morrical Nathan V, 2023, Zenodo, DOI 10.5281/ZENODO.8019116
   Navrátil PA, 2007, IEEE T VIS COMPUT GR, V13, P1712, DOI 10.1109/TVCG.2007.70526
   Novak J., 2018, ACM SIGGRAPH COURSES, DOI 10/c5fj
   NVIDIA Corp, 2021, Technical report
   Orthmann J., 2010, Vision, Modeling, and Visualization, P147, DOI [10.2312/PE/VMV/VMV10, DOI 10.2312/PE/VMV/VMV10]
   Piochowiak M, 2021, COMPUT GRAPH FORUM, V40, P97, DOI 10.1111/cgf.14121
   Preston A, 2016, IEEE PAC VIS SYMP, P48, DOI 10.1109/PACIFICVIS.2016.7465250
   Qingyu Meng, 2012, 2012 SC Companion: High-Performance Computing, Networking, Storage and Analysis (SCC), P2441, DOI 10.1109/SCC.2012.6674233
   Simon G., 2020, Particle simulation using CUDA
   Slattery S., 2022, Cabana: A Performance Portable Library for Particle-Based Simulations, DOI [10.5281/zenodo, DOI 10.5281/ZENODO]
   Wald I, 2022, IEEE T VIS COMPUT GR, V28, P583, DOI 10.1109/TVCG.2021.3114869
   Wald I, 2021, IEEE T VIS COMPUT GR, V27, P625, DOI 10.1109/TVCG.2020.3030470
   Wald Ingo, 2019, HighPerformance Graphics-Short Papers, DOI [DOI 10.2312/HPG.20191189, 10.2312/hpg.20191189]
   Winchenbach R, 2020, COMPUT GRAPH FORUM, V39, P527, DOI 10.1111/cgf.14090
   Wolfe Alan, 2022, EUROGRAPHICS S RENDE, P117, DOI DOI 10.2312/SR.20221161
   Woodcock E., 1965, P C APPL COMP METH R, P557
   Yu IS, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609971
   Zellmann S., 2022, P 22 EUR S PAR GRAPH, P61
   Zellmann S, 2023, Arxiv, DOI arXiv:2211.09997
   Zellmann S, 2022, COMPUT SCI ENG, V24, P40, DOI 10.1109/MCSE.2022.3153677
   Zellmann S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P96, DOI 10.1109/VIS47514.2020.00026
   Zhao SW, 2023, INT J NUMER METH ENG, V124, P696, DOI 10.1002/nme.7139
NR 48
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1150
EP 1160
DI 10.1109/TVCG.2023.3327366
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500028
PM 37878450
DA 2024-08-05
ER

PT J
AU Scimone, A
   Eckelt, K
   Streit, M
   Hinterreiter, A
AF Scimone, Anna
   Eckelt, Klaus
   Streit, Marc
   Hinterreiter, Andreas
TI Marjorie: Visualizing Type 1 Diabetes Data to Support Pattern
   Exploration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Design study; task analysis; diabetes; time series data; visual
   analytics; clustering
ID TIME-SERIES DATA
AB In this work we propose Marjorie, a visual analytics approach to address the challenge of analyzing patients' diabetes data during brief regular appointments with their diabetologists. Designed in consultation with diabetologists, Marjorie uses a combination of visual and algorithmic methods to support the exploration of patterns in the data. Patterns of interest include seasonal variations of the glucose profiles, and non-periodic patterns such as fluctuations around mealtimes or periods of hypoglycemia (i.e., glucose levels below the normal range). We introduce a unique representation of glucose data based on modified horizon graphs and hierarchical clustering of adjacent carbohydrate or insulin entries. Semantic zooming allows the exploration of patterns on different levels of temporal detail. We evaluated our solution in a case study, which demonstrated Marjorie's potential to provide valuable insights into therapy parameters and unfavorable eating habits, among others. The study results and informal feedback collected from target users suggest that Marjorie effectively supports patients and diabetologists in the joint exploration of patterns in diabetes data, potentially enabling more informed treatment decisions. A free copy of this paper and all supplemental materials are available at https://osf.io/34t8c/.
C1 [Scimone, Anna; Eckelt, Klaus; Streit, Marc; Hinterreiter, Andreas] Johannes Kepler Univ Linz, Linz, Austria.
C3 Johannes Kepler University Linz
RP Scimone, A (corresponding author), Johannes Kepler Univ Linz, Linz, Austria.
EM anna_scimone@live.de; klaus.eckelt@jku.at; marc.streit@jku.at;
   andreas.hinterreiter@jku.at
FU Austrian Research Promotion Agency
FX No Statement Available
CR Abbott Diabetes Care Inc, 2023, LibreView Portal
   Aigner Wolfgang, 2011, Foundations and Trends in Human-Computer Interaction, V5, P207, DOI 10.1561/1100000039
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bade R, 2004, P SIGCHI C HUM FACT, DOI [DOI 10.1145/985692.985706, 10.1145/985692.985706]
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Bazaev N.A., 2013, Biomed. Eng, V47, P100, DOI [10.1007/s10527-013-9320-2, DOI 10.1007/S10527-013-9344-7, 10.1007/s10527-013-9344-7]
   Best CH, 1923, J BIOL CHEM, V57, P709
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Danne T, 2017, DIABETES CARE, V40, P1631, DOI 10.2337/dc17-1600
   Dexcom Inc, 2023, Dexcom Clarity Reports
   Eckelt K, 2023, IEEE T VIS COMPUT GR, V29, P3312, DOI 10.1109/TVCG.2022.3156760
   Federico P, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P273, DOI 10.1145/2598153.2598172
   Ferreira L, 2009, COMMUN STAT-SIMUL C, V38, P1925, DOI 10.1080/03610910903168603
   Fluck D., 2021, Coblis: Color Blindness Simulator
   Fujiwara T, 2021, IEEE T VIS COMPUT GR, V27, P1601, DOI 10.1109/TVCG.2020.3028889
   Glooko Inc, 2023, Glooko
   Green A, 2021, DIABETOLOGIA, V64, P2741, DOI 10.1007/s00125-021-05571-8
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Hall H, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2005143
   Hinterreiter A, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387165
   Holt R. I., A Consensus Report by the American Diabetes Association (ADA) and the European Association for the
   Hyndman R. J., 2018, FORECASTING PRINCIPL
   Johnson ML, 2019, DIABETES TECHNOL THE, V21, pS17, DOI 10.1089/dia.2019.0034
   Karen H., 2017, Participatory design, P177
   Kovatchev BP, 2017, NAT REV ENDOCRINOL, V13, P425, DOI 10.1038/nrendo.2017.3
   Lobo B., 2021, IEEE Transactions on Biomedical Engineering, DOI [10.1109/TBME.2021.31031273, DOI 10.1109/TBME.2021.31031273]
   Medtronic Inc, 2023, Medtronic CareLink Software
   Medtronic Inc, 2018, Medtronic IPRO 2 System for CGM
   Müller W, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P737, DOI 10.1109/WSC.2003.1261490
   Munzner T., 2014, Visualization Analysis and Design, DOI [10.1201/b175115, DOI 10.1201/B175115]
   Munzner T, 2008, LECT NOTES COMPUT SC, V4950, P134, DOI 10.1007/978-3-540-70956-5_6
   NATHAN DM, 1993, NEW ENGL J MED, V328, P1676, DOI 10.1056/NEJM199306103282306
   Plotly Technologies Inc, 2023, Plotly Dash User Guide & Documentation
   Reijner H., 2008, PROC IEEE VIS WORKSH
   Rind Alexander, 2011, Information Quality in e-Health. Proceedings 7th Conference of the Workgroup Human-Computer Interaction and Usability Engineering of the Austrian Computer Society, USAB 2011, P301, DOI 10.1007/978-3-642-25364-5_22
   Rostène W, 2021, ENDOCR REV, V42, P503, DOI 10.1210/endrev/bnab020
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Stitz H, 2016, IEEE T VIS COMPUT GR, V22, P2594, DOI 10.1109/TVCG.2015.2513389
   The Nightscout Foundation, 2023, The Nightscout Project
   The OpenAPS Community, 2017, Understanding Insulin on Board (IOB) Calculations
   Tidepool Project, Tidepool
   Tominski C., 2023, The TimeViz Browser-A Visual Survey of Visualization Techniques for Time-Oriented Data
   van den Elzen S, 2023, IEEE COMPUT GRAPH, V43, P78, DOI 10.1109/MCG.2023.3237286
   Wang Q, 2022, COMPUT GRAPH FORUM, V41, P69, DOI 10.1111/cgf.14424
   Woldaregay AZ, 2019, J MED INTERNET RES, V21, DOI 10.2196/11030
   Wong Jenise C, 2017, J Diabetes Sci Technol, V11, P800, DOI 10.1177/1932296817691305
   Yu Yuncong, 2023, IEEE Trans Vis Comput Graph, V29, P33, DOI 10.1109/TVCG.2022.3209431
   Zhang Y., 2021, PROC PERVASIVEHEALTH, P427, DOI [10.1145/3421937.34219572,3,5,9, DOI 10.1145/3421937.34219572,3,5,9]
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
NR 50
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1216
EP 1226
DI 10.1109/TVCG.2023.3326936
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500053
PM 37874710
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Wu, YF
   Guo, ZY
   Mamakos, M
   Hartline, J
   Hullman, J
AF Wu, Yifan
   Guo, Ziyang
   Mamakos, Michalis
   Hartline, Jason
   Hullman, Jessica
TI The Rational Agent Benchmark for Data Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Behavioral sciences; Visualization;
   Benchmark testing; Bayes methods; Uncertainty; Evaluation;
   decision-making; rational agent; scoring rule
ID UNCERTAINTY
AB Understanding how helpful a visualization is from experimental results is difficult because the observed performance is confounded with aspects of the study design, such as how useful the information that is visualized is for the task. We develop a rational agent framework for designing and interpreting visualization experiments. Our framework conceives two experiments with the same setup: one with behavioral agents (human subjects), and the other one with a hypothetical rational agent. A visualization is evaluated by comparing the expected performance of behavioral agents to that of a rational agent under different assumptions. Using recent visualization decision studies from the literature, we demonstrate how the framework can be used to pre-experimentally evaluate the experiment design by bounding the expected improvement in performance from having access to visualizations, and post-experimentally to deconfound errors of information extraction from errors of optimization, among other analyses.
C1 [Wu, Yifan; Guo, Ziyang; Mamakos, Michalis; Hartline, Jason; Hullman, Jessica] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Wu, YF (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM yifan.wu@u.northwestern.edu; ziyangguo2027@u.northwestern.edu;
   michailmamakos2022@u.northwestern.edu; hartline@northwestern.edu;
   jhullman@northwestern.edu
OI Guo, Ziyang/0009-0004-4200-6774; Hullman, Jessica/0000-0001-6826-3550;
   Hartline, Jason/0000-0001-5505-6819; Wu, Yifan/0000-0002-4299-8169
CR Agrawal M, 2020, P NATL ACAD SCI USA, V117, P8825, DOI 10.1073/pnas.1915841117
   [Anonymous], 2006, Proceedings of the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization, DOI [10.1145/1168149.1168158, DOI 10.1145/1168149.1168158]
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Coe R., 2002, British Educ. Res. Assoc. Ann. Conf, V12, P14
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fudenberg D, 2022, J POLIT ECON, DOI 10.1086/718371
   Gonzalez C, 2011, PSYCHOL REV, V118, P523, DOI 10.1037/a0024558
   Heine C, 2021, IEEE T VIS COMPUT GR, V27, P1000, DOI 10.1109/TVCG.2020.3030395
   Hofman JM, 2021, NATURE, V595, P181, DOI 10.1038/s41586-021-03659-0
   Hullman J., 2021, Harvard Data Science Review, DOI [10.1162/99608f92.3ab8a5872,9, DOI 10.1162/99608F92.3AB8A5872,9]
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Isenberg P., 2008, Proceedings of the 2008 Workshop on BEyond time and errors: novel evaLuation methods for Information Visualization, P1, DOI [10.1145/1377966.1377974, DOI 10.1145/1377966.1377974]
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Kale A., 2023, IEEE Transactions on Visualization and Computer Graphics
   Kale A, 2022, IEEE T VIS COMPUT GR, V28, P1150, DOI 10.1109/TVCG.2021.3114824
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Knill D., 1996, Perception as Bayesian Inference, P2
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Li Yingkai, 2022, EC '22: Proceedings of the 23rd ACM Conference on Economics and Computation, P988, DOI 10.1145/3490486.3538338
   Mason W., 2009, P ACM SIGKDD WORKSH, P77, DOI DOI 10.1145/1600150.1600175
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Savelli S, 2013, APPL COGNITIVE PSYCH, V27, P527, DOI 10.1002/acp.2932
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Yarkoni T, 2022, BEHAV BRAIN SCI, V45, DOI 10.1017/S0140525X20001685
   Zuk T, 2006, PROC SPIE, V6060, DOI 10.1117/12.643631
NR 33
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 338
EP 347
DI 10.1109/TVCG.2023.3326513
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500063
PM 37871058
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Miura, S
   Fukumoto, R
   Okamura, N
   Fujie, MG
   Sugano, S
AF Miura, Satoshi
   Fukumoto, Ryota
   Okamura, Naomi
   Fujie, Masakatsu G.
   Sugano, Shigeki
TI Visual Illusion Created by a Striped Pattern Through Augmented Reality
   for the Prevention of Tumbling on Stairs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Stairs; Foot; Visualization; Augmented reality; Trajectory; Resists;
   Training; Human-computer interaction; user interfaces; virtual and
   augmented reality; virtual device interfaces
ID MINIMUM FOOT CLEARANCE; BLURRING VISION; FALLS; RISK; AGE; WALKING;
   MODEL; GAIT; CLASSIFICATION; PREDICTION
AB A fall on stairs can be a dangerous accident. An important indicator of falling risk is the foot clearance, which is the height of the foot when ascending stairs or the distance of the foot from the step when descending. We developed an augmented reality system with a holographic lens using a visual illusion to improve the foot clearance on stairs. The system draws a vertical striped pattern on the stair riser as the participant ascends the stairs to create the illusion that the steps are higher than the actual steps, and draws a horizontal striped pattern on the stair tread as the participant descends the stairs to create the illusion of narrower stairs. We experimentally evaluated the accuracy of the system and fitted a model to determine the appropriate stripe thickness. Finally, participants ascended and descended stairs before, during, and after using the augmented reality system. The foot clearance significantly improved, not only while the participants used the system but also after they used the system compared with before.
C1 [Miura, Satoshi] Tokyo Inst Technol, Dept Mech Engn, Meguro Ku, Tokyo 1528550, Japan.
   [Fukumoto, Ryota] Waseda Univ, Dept Modern Mech Engn, Tokyo 1698050, Japan.
C3 Tokyo Institute of Technology; Waseda University
RP Miura, S (corresponding author), Tokyo Inst Technol, Dept Mech Engn, Meguro Ku, Tokyo 1528550, Japan.
EM miura.s.aj@m.titech.ac.jp; fukuryo@toki.waseda.jp;
   n-okamura@toki.waseda.jp; mgfujie@waseda.jp; sugano@waseda.jp
OI Miura, Satoshi/0000-0001-5402-8074
FU JSPS KAKENHI [21K18075]; Murata Foundation; Hattori Foundation; Takano
   Foundation; Suzuki Foundation; Nakajima Foundation
FX This work was supported in part by JSPS KAKENHI under Grant 21K18075, in
   part by the Murata Foundation, in part by the Hattori Foundation, in
   part by the Takano Foundation, in part by the Suzuki Foundation; and in
   part by the Nakajima Foundation.
CR [Anonymous], 2023, "Japanese building standards law enforcement ordinance
   Arora P, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P791, DOI 10.1109/SPIN.2015.7095388
   Begg R, 2007, GAIT POSTURE, V25, P191, DOI 10.1016/j.gaitpost.2006.03.008
   Berkebile JA, 2022, IEEE T BIO-MED ENG, V69, P1909, DOI 10.1109/TBME.2021.3130540
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Camargo J, 2021, IEEE T BIO-MED ENG, V68, P1569, DOI 10.1109/TBME.2021.3065809
   Choi I, 2021, IEEE T VIS COMPUT GR, V27, P4387, DOI 10.1109/TVCG.2020.3002245
   Dingwell JB, 2017, GAIT POSTURE, V55, P131, DOI 10.1016/j.gaitpost.2017.03.018
   Elliott D.B., 2015, PUBLIC HLTH RES, V3, P1, DOI [DOI 10.3310/PHR03080, 10.3310/phr03080.30, DOI 10.3310/PHR03080.30]
   Elliott DB, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004577
   Fang Y, 2022, IEEE T BIO-MED ENG, V69, P2143, DOI 10.1109/TBME.2021.3137447
   Foster RJ, 2016, ERGONOMICS, V59, P884, DOI 10.1080/00140139.2015.1105304
   Foster RJ, 2015, INVEST OPHTH VIS SCI, V56, P2950, DOI 10.1167/iovs.14-16018
   GOMI H, 1990, PROCEEDINGS OF THE 29TH IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, P3289, DOI 10.1109/CDC.1990.203403
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Hamel KA, 2005, GAIT POSTURE, V21, P135, DOI 10.1016/j.gaitpost.2004.01.006
   Hamel KA, 2004, J AM GERIATR SOC, V52, P563, DOI 10.1111/j.1532-5415.2004.52162.x
   Heasley K, 2005, INVEST OPHTH VIS SCI, V46, P3584, DOI 10.1167/iovs.05-0059
   Heasley K, 2004, INVEST OPHTH VIS SCI, V45, P2122, DOI 10.1167/iovs.03-1199
   HINDMARSH JJ, 1989, ARCH INTERN MED, V149, P2217, DOI 10.1001/archinte.149.10.2217
   Jazayeri M, 2007, NATURE, V446, P912, DOI 10.1038/nature05739
   JOFFE M, 1988, PEDIATRICS, V82, P457
   KAWATO M, 1992, BIOL CYBERN, V68, P95, DOI 10.1007/BF00201431
   Khademi G, 2021, IEEE T BIO-MED ENG, V68, P967, DOI 10.1109/TBME.2020.3016129
   L. andW. Ministry of Health, 2017, "Number of mortality /composition ratio by age by type of main accident in the family by type
   Lai DTH, 2012, HUM MOVEMENT SCI, V31, P271, DOI 10.1016/j.humov.2010.07.009
   Li S, 2022, IEEE T VIS COMPUT GR, V28, P3035, DOI 10.1109/TVCG.2020.3044563
   LORD SR, 1993, AUST J PUBLIC HEALTH, V17, P240, DOI 10.1111/j.1753-6405.1993.tb00143.x
   Marshall SW, 2005, AM J PREV MED, V28, P95, DOI 10.1016/j.amepre.2004.09.015
   Miura S., 2019, J. Biomech. Sci. Eng., V14, P1, DOI [10.1299/jbse.18-00216, DOI 10.1299/JBSE.18-00216]
   Mori M., 2011, J. Soc.Biomech., V35, P201
   MULLEN KT, 1985, J PHYSIOL-LONDON, V359, P381, DOI 10.1113/jphysiol.1985.sp015591
   Norman D.A., 1988, PSYCHOL EVERYDAY THI
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Rabe KG, 2021, IEEE T BIO-MED ENG, V68, P1379, DOI 10.1109/TBME.2020.3032077
   Resquín F, 2016, EUR J TRANSL MYOL, V26, P255, DOI 10.4081/ejtm.2016.6164
   Riess TJ, 1998, ST HEAL T, V58, P200
   Roos PE, 2013, HUM MOVEMENT SCI, V32, P984, DOI 10.1016/j.humov.2013.07.001
   Schulz BW, 2017, J BIOMECH, V55, P107, DOI 10.1016/j.jbiomech.2017.02.024
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Stacoff A, 2005, GAIT POSTURE, V21, P24, DOI 10.1016/j.gaitpost.2003.11.003
   Stolyarov R, 2021, IEEE T BIO-MED ENG, V68, P384, DOI 10.1109/TBME.2020.2994152
   Sugimoto K, 2008, IEEE DECIS CONTR P, P714, DOI 10.1109/CDC.2008.4738996
   Valois H., 1974, Vis. Res., V14, P75
   van der Zijden AM, 2017, J BIOMECH, V54, P19, DOI 10.1016/j.jbiomech.2017.01.033
   Weerdesteyn V, 2005, HUM MOVEMENT SCI, V24, P865, DOI 10.1016/j.humov.2005.10.013
   Woodward RB, 2022, IEEE T BIO-MED ENG, V69, P1202, DOI 10.1109/TBME.2021.3120616
   Yoshida A, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P83
   Yun Y, 2014, J BIOMECH, V47, P186, DOI 10.1016/j.jbiomech.2013.09.032
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zietz D, 2011, GAIT POSTURE, V34, P279, DOI 10.1016/j.gaitpost.2011.05.017
NR 51
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5466
EP 5477
DI 10.1109/TVCG.2023.3295425
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400007
PM 37450363
DA 2024-08-05
ER

PT J
AU Wu, HS
   Ma, ZH
   Wu, WL
   Liu, XT
   Li, CZ
   Wen, ZK
AF Wu, Huisi
   Ma, Ziheng
   Wu, Wenliang
   Liu, Xueting
   Li, Chengze
   Wen, Zhenkun
TI Shading-Guided Manga Screening From Reference
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Line drawing shading; manga screening; screentone generation
ID IMAGE; QUALITY
AB Manga screening is a critical process in manga production, which still requires intensive labor and cost. Existing manga screening methods either generate simple dotted screentones only or rely on color information and manual hints during screentone selection. Due to the large domain gap between line drawings and screened manga, and the difficulties in generating high-quality, properly selected and shaded screentones, even state-of-the-art deep learning methods cannot convert line drawings to screened manga well. Besides, ambiguity exists in the screening process since different artists may screen differently for the same line drawing. In this article, we propose to introduce shaded line drawing as the intermediate counterpart of the screened manga so that the manga screening task can be decomposed into two sub-tasks, generating shading from a line drawing and replacing shading with proper screentones. The reference image is adopted to resolve the ambiguity issue and provides options and controls on the generated screened manga. We proposed a reference-based shading generation network and a reference-based screentone generation module to achieve the two sub-tasks individually. We conduct extensive visual and quantitative experiments to verify the effectiveness of our system. Results and statistics show that our method outperforms existing methods on the manga screening task.
C1 [Wu, Huisi; Ma, Ziheng; Wu, Wenliang; Liu, Xueting; Wen, Zhenkun] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Guangdong, Peoples R China.
   [Li, Chengze] Caritas Inst Higher Educ, Sch Comp & Informat Sci, Hong Kong 999077, Peoples R China.
C3 Shenzhen University; Saint Francis University Hong Kong
RP Wu, HS (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Guangdong, Peoples R China.
EM hswu@szu.edu.cn; 2070276193@email.szu.edu.cn;
   wenliangwu2019@email.szu.edu.cn; xtliu@szu.edu.cn; czli@cihe.edu.hk;
   wenzk@szu.edu.cn
RI ; Li, Chengze/AAU-7168-2021
OI Wu, Huisi/0000-0002-0399-9089; Li, Chengze/0000-0002-1519-750X; Ma,
   Ziheng/0000-0002-2628-553X
FU National Natural Science Foundation of China [61973221, 62002232,
   62273241]; Natural Science Foundation of Guangdong Province, China
   [2019A1515011165]; Major Project of the New Generation of Artificial
   Intelligence [2018AAA0102900]
FX No Statement Available
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   [Anonymous], 1987, P 14 ANN C COMP GRAP, DOI [10.1145/37401.37410, DOI 10.1145/37401.37410, DOI 10.1145/37402.37410]
   Aramaki Y, 2016, IEEE IMAGE PROC, P2901, DOI 10.1109/ICIP.2016.7532890
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Baqai FA, 2003, IEEE T IMAGE PROCESS, V12, P1, DOI 10.1109/TIP.2002.806244
   Bayer B. E., 1973, P IEEE INT C COMM, P69
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Cheng JX, 2021, PROC CVPR IEEE, P134, DOI 10.1109/CVPR46437.2021.00020
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   ESCHBACH R, 1991, J OPT SOC AM A, V8, P1844, DOI 10.1364/JOSAA.8.001844
   Fujimoto A, 2016, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON COMICS ANALYSIS, PROCESSING AND UNDERSTANDING (MANPU 2016), DOI 10.1145/3011549.3011551
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456
   Graphics Gems V, 1995, P 14 ANN C COMP GRAP, P65
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Hwang BW, 2004, LECT NOTES COMPUT SC, V3029, P473
   Isola P., 2017, P IEEE C COMP VIS PA, P1125, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Ito Kota., 2015, P 36 ANN C EUR ASS C
   Jayaraman PK, 2018, IEEE T VIS COMPUT GR, V24, P2103, DOI 10.1109/TVCG.2017.2705182
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kalischek N, 2021, PROC CVPR IEEE, P9377, DOI 10.1109/CVPR46437.2021.00926
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D. P., 2014, arXiv
   KNUTH DE, 1987, ACM T GRAPHIC, V6, P245, DOI 10.1145/35039.35040
   Kotovenko D, 2019, PROC CVPR IEEE, P10024, DOI 10.1109/CVPR.2019.01027
   Kwak NJ, 2006, 2006 International Conference on Hybrid Information Technology, Vol 1, Proceedings, P499
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Li CL, 2017, ACM T INFORM SYST, V36, DOI 10.1145/3091108
   Li XT, 2019, PROC CVPR IEEE, P3804, DOI 10.1109/CVPR.2019.00393
   Lin T., 2021, P IEEE CVF C COMP VI, P5141
   Liu C. Li, Comput. Vis. Media, V3, P61
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Pang Y., 2008, P ACM SIGGRAPH C, P1
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Qu YG, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409108
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Sanakoyeu A, 2018, LECT NOTES COMPUT SC, V11212, P715, DOI 10.1007/978-3-030-01237-3_43
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Shi M, 2023, IEEE T VIS COMPUT GR, V29, P2965, DOI 10.1109/TVCG.2022.3146000
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Svoboda J., 2020, P IEEE CVF C COMP VI, P13816
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie MS, 2021, Arxiv, DOI arXiv:2105.06830
   Xie MS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459822
   Xie MS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417873
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang LM, 2021, PROC CVPR IEEE, P5638, DOI 10.1109/CVPR46437.2021.00559
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
   Zhou BF, 2003, ACM T GRAPHIC, V22, P437, DOI 10.1145/882262.882289
   Zhou XR, 2021, PROC CVPR IEEE, P11460, DOI 10.1109/CVPR46437.2021.01130
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 62
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4941
EP 4954
DI 10.1109/TVCG.2023.3282223
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400012
PM 37267131
DA 2024-08-05
ER

PT J
AU Qiu, JX
   Yin, ZX
   Cheng, MM
   Ren, B
AF Qiu, Jiaxiong
   Yin, Ze-Xin
   Cheng, Ming-Ming
   Ren, Bo
TI NeRC: Rendering Planar Caustics by Learning Implicit Neural
   Representations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Caustics; centering calibration; photon mapping; sine activation; volume
   rendering
ID GLOBAL ILLUMINATION
AB Caustics are challenging light transport effects for photo-realistic rendering. Photon mapping techniques play a fundamental role in rendering caustics. However, photon mapping methods render single caustics under the stationary light source in a fixed scene view. They require significant storage and computing resources to produce high-quality results. In this paper, we propose efficiently rendering more diverse caustics of a scene with the camera and the light source moving. We present a novel learning-based volume rendering approach with implicit representations for our proposed task. Considering the variety of materials and textures of planar caustic receivers, we decompose the output appearance into two components: the diffuse and specular parts with a probabilistic module. Unlike NeRF, we construct weights for rendering each component from the implicit signed distance function (SDF). Moreover, we introduce the centering calibration and the sine activation function to improve the performance of the color prediction network. Extensive experiments on the synthetic and real-world datasets illustrate that our method achieves much better performance than baselines in the quantitative and qualitative comparison, for rendering caustics in novel views with the dynamic light source. Especially, our method outperforms the baseline on the temporal consistency across frames.
C1 [Qiu, Jiaxiong; Yin, Ze-Xin; Cheng, Ming-Ming; Ren, Bo] Nankai Univ, Coll Comp Sci, VCIP, Tianjin 300000, Peoples R China.
C3 Nankai University
RP Ren, B (corresponding author), Nankai Univ, Coll Comp Sci, VCIP, Tianjin 300000, Peoples R China.
EM qiujiaxiong727@gmail.com; Zexin.Yin.cn@gmail.com; cmm@nankai.edu.cn;
   rb@nankai.edu.cn
RI Cheng, Ming-Ming/A-2527-2009; Qiu, Jiaxiong/KDM-8471-2024
OI Cheng, Ming-Ming/0000-0001-5550-8758; Qiu, Jiaxiong/0000-0002-6065-7296
FU National Key Research and Development Program of China [2018AAA0100400];
   NSFC [61922046, 62132012]
FX This work was supported by the National Key Research and Development
   Program of China under Grant 2018AAA0100400, in part by the NSFC under
   Grant 61922046, and in part by the NSFC under Grant 62132012.
CR [Anonymous], 2001, Realistic Image Synthesis Using Photon Mapping
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Bemana M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417827
   Bojanowski P, 2019, Arxiv, DOI arXiv:1707.05776
   Durand F, 2005, ACM T GRAPHIC, V24, P1115, DOI 10.1145/1073204.1073320
   Gao SH, 2021, PROC CVPR IEEE, P8665, DOI 10.1109/CVPR46437.2021.00856
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315, DOI DOI 10.1002/ECS2.1832
   Gropp A, 2020, Arxiv, DOI arXiv:2002.10099
   Hachisuka S., 2008, P ACM SIGGRAPH C AS, P1
   Hachisuka T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618487
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kaza S., 2019, "Differentiable volume rendering using signed distancefunctions
   Lombardi S, 2019, Arxiv, DOI [arXiv:1906.07751, 10.1145/3306346.3323020, DOI 10.1145/3306346.3323020]
   Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Nair V., 2010, ICML, P807
   Pauly M, 2000, SPRING COMP SCI, P11
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shi XH, 2021, IEEE T VIS COMPUT GR, V27, P4183, DOI 10.1109/TVCG.2021.3106488
   Shirley P, 1995, SPRING COMP SCI, P219
   Sitzmann V, 2020, Adv. Neural. Inf. Process. Syst, V33, P7462
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Trevithick A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15162, DOI 10.1109/ICCV48922.2021.01490
   Tse H, 2012, Gopro Hero 2 Dive Housing-Swimming Pool Test 1080p HD30fps
   Veach E., 1998, ROBUST MONTE CARLO M, pAAI9837162
   Verbin D, 2022, PROC CVPR IEEE, P5481, DOI 10.1109/CVPR52688.2022.00541
   Walter B, 1997, ACM T GRAPHIC, V16, P217, DOI 10.1145/256157.256158
   Wang P., 2021, PROC NEURIPS, V34, P27171
   Xu B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356547
   Zhang K, 2020, Arxiv, DOI arXiv:2010.07492
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhu SL, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3476828
   Zhu SL, 2020, COMPUT GRAPH FORUM, V39, P35, DOI 10.1111/cgf.14052
NR 36
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4339
EP 4348
DI 10.1109/TVCG.2023.3259382
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700072
PM 37030762
DA 2024-08-05
ER

PT J
AU Rogha, M
   Sah, S
   Karduni, A
   Markant, D
   Dou, WW
AF Rogha, Milad
   Sah, Subham
   Karduni, Alireza
   Markant, Douglas
   Dou, Wenwen
TI The Impact of Elicitation and Contrasting Narratives on Engagement,
   Recall and Attitude Change With News Articles Containing Data
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Market research; Visualization; Uncertainty; Data
   models; Correlation; Attitude control; Belief elicitation; visual
   elicitation; data visualization; contrasting narratives
ID COGNITION; BIASES; POWER
AB News articles containing data visualizations play an important role in informing the public on issues ranging from public health to politics. Recent research on the persuasive appeal of data visualizations suggests that prior attitudes can be notoriously difficult to change. Inspired by an NYT article, we designed two experiments to evaluate the impact of elicitation and contrasting narratives on attitude change, recall, and engagement. We hypothesized that eliciting prior beliefs leads to more elaborative thinking that ultimately results in higher attitude change, better recall, and engagement. Our findings revealed that visual elicitation leads to higher engagement in terms of feelings of surprise. While there is an overall attitude change across all experiment conditions, we did not observe a significant effect of belief elicitation on attitude change. With regard to recall error, while participants in the draw trend elicitation exhibited significantly lower recall error than participants in the categorize trend condition, we found no significant difference in recall error when comparing elicitation conditions to no elicitation. In a follow-up study, we added contrasting narratives with the purpose of making the main visualization (communicating data on the focal issue) appear strikingly different. Compared to the results of Study 1, we found that contrasting narratives improved engagement in terms of surprise and interest but interestingly resulted in higher recall error and no significant change in attitude. We discuss the effects of elicitation and contrasting narratives in the context of topic involvement and the strengths of temporal trends encoded in the data visualization.
C1 [Rogha, Milad; Sah, Subham; Dou, Wenwen] Univ North Carolina Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Markant, Douglas] Univ North Carolina Charlotte, Dept Psychol Sci, Charlotte, NC 28223 USA.
   [Karduni, Alireza] Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
C3 University of North Carolina; University of North Carolina Charlotte;
   University of North Carolina; University of North Carolina Charlotte;
   Simon Fraser University
RP Rogha, M (corresponding author), Univ North Carolina Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
EM mrogha@charlotte.edu; ssah1@uncc.edu; alireza116@gmail.com;
   dmarkant@charlotte.edu; wdou1@uncc.edu
OI Markant, Douglas/0000-0003-0568-2648; Rogha, Milad/0000-0002-1464-2157;
   Sah, Subham/0009-0007-9446-6731; Dou, Wenwen/0000-0003-0319-9484;
   Karduni, Alireza/0000-0001-9719-7513
FU NSF [CNS-1747785, CNS-2323795]
FX This work was supported in part by the NSF under Grant CNS-1747785 and
   by the NFS under Grant CNS-2323795.
CR Brinol R. E., 2005, Individual differences in attitude change, P575
   Brod G, 2018, LEARN INSTR, V55, P22, DOI 10.1016/j.learninstruc.2018.01.013
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Bycoffe E., 2008, Howunpopular is Joe Biden?
   Ceja CR, 2021, IEEE T VIS COMPUT GR, V27, P1054, DOI 10.1109/TVCG.2020.3030422
   Christie D., 2022, Comprehensive Renewable Energy, V8, P149, DOI DOI 10.1016/B978-0-12-819727-1.00083-2
   Curran PJ, 2009, PSYCHOL METHODS, V14, P81, DOI 10.1037/a0015914
   Fazio LK, 2009, PSYCHON B REV, V16, P88, DOI 10.3758/PBR.16.1.88
   FiveThirtyEight, about us
   Gupta A., 2021, Comput. Graph. Forum, V40, P207
   Haddock G, 2019, ADV EXP SOC PSYCHOL, V59, P53, DOI 10.1016/bs.aesp.2018.10.002
   Heyer J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376887
   Josh K., 2017, You draw it: Just how bad is the drug overdose epidemic?
   Karduni A, 2021, IEEE T VIS COMPUT GR, V27, P978, DOI 10.1109/TVCG.2020.3029412
   Kim L. A., 2019, P CHI C HUM FACT COM, P1
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Kirsh D, 2010, AI SOC, V25, P441, DOI 10.1007/s00146-010-0272-8
   Koonchanok G. Y., 2023, arXiv
   Koonchanok P., 2021, P CHI C HUM FACT COM, P1
   Kruschke JK, 2018, PSYCHON B REV, V25, P178, DOI 10.3758/s13423-016-1221-4
   Liao W.-T., 2013, P SIGCHI C HUM FACT, P2359, DOI [10.1145/2470654.2481326, DOI 10.1145/2470654.2481326]
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Mahajan S, 2022, COMPUT GRAPH FORUM, V41, P477, DOI 10.1111/cgf.14556
   Makowski D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02767
   Mantri Prateek, 2023, IEEE Trans Vis Comput Graph, V29, P1005, DOI 10.1109/TVCG.2022.3209467
   Markant D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581330
   McColeman CM, 2021, IEEE T VIS COMPUT GR, V27, P1063, DOI 10.1109/TVCG.2020.3030345
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   OBrien H., 2016, WHY ENGAGEMENT MATTE
   Pandey AV, 2014, IEEE T VIS COMPUT GR, V20, P2211, DOI 10.1109/TVCG.2014.2346419
   Petty J., 2002, Mass Media Attitude Change: Impli-cations on the Elaboration Likelihood Model of Persuasion, P155
   Petty RE, 1999, DUAL-PROCESS THEORIES IN SOCIAL PSYCHOLOGY, P41
   Petty RE, 2001, SOC COGNITION, V19, P418, DOI 10.1521/soco.19.4.418.20758
   Ritchie H, 1999, Drug use
   Sanborn AN, 2010, COGNITIVE PSYCHOL, V60, P63, DOI 10.1016/j.cogpsych.2009.07.001
   Sanborn T., ADV NEURAL INF PROCE
   Upshot, 2014, "The New York TimesApr. 22,
   Vehtari A, 2017, STAT COMPUT, V27, P1413, DOI 10.1007/s11222-016-9696-4
   Wagner R. E., 2011, TheoriesSoc. Psychol., V1, P96
   Wallace-Wells B, 2021, Is there a case for legalizing heroin?
   Xiong Cindy, 2023, IEEE Trans Vis Comput Graph, V29, P493, DOI 10.1109/TVCG.2022.3209405
NR 42
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4375
EP 4389
DI 10.1109/TVCG.2024.3355884
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700015
PM 38241101
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lu, M
   Zeng, XF
   Lanir, J
   Sun, XQ
   Li, GZ
   Cohen-Or, D
   Huang, H
AF Lu, Min
   Zeng, Xiangfang
   Lanir, Joel
   Sun, Xiaoqin
   Li, Guozheng
   Cohen-Or, Daniel
   Huang, Hui
TI Sticky Links: Encoding Quantitative Data of Graph Edges
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Encoding; Layout; Shape; Clutter; Graph drawing;
   Uncertainty; Graph visualization; edge drawing; quantitative encoding
ID OF-THE-ART; VISUALIZATION; LAYOUT
AB Visually encoding quantitative information associated with graph links is an important problem in graph visualization. A conventional approach is to vary the thickness of lines to encode the strength of connections in node-link diagrams. In this paper, we present Sticky Links, a novel visual encoding method that draws graph links with stickiness. Taking the metaphor of links with glues, sticky links represent connection strength using spiky shapes, ranging from two broken spikes for weak connections to connected lines for strong connections. We conducted a controlled user study to compare the efficiency and aesthetic appeal of stickiness with conventional thickness encoding. Our results show that stickiness enables more effective and expressive quantitative encoding while maintaining the perception of node connectivity. Participants also found sticky links to be more aesthetic and less visually cluttering than conventional thickness encoding. Overall, our findings suggest that sticky links offer a promising alternative to conventional methods for encoding quantitative information in graphs.
C1 [Lu, Min; Zeng, Xiangfang; Sun, Xiaoqin; Huang, Hui] Shenzhen Univ, Shenzhen 518060, Peoples R China.
   [Lanir, Joel] Univ Haifa, IL-3498838 H_efa, Israel.
   [Li, Guozheng] Beijing Inst Technol, Beijing 100811, Peoples R China.
   [Cohen-Or, Daniel] Tel Aviv Univeristy, IL-6997801 Tel Aviv, Israel.
C3 Shenzhen University; University of Haifa; Beijing Institute of
   Technology
RP Huang, H (corresponding author), Shenzhen Univ, Shenzhen 518060, Peoples R China.
EM lumin.vis@gmail.com; xiangfangzeng15@gmail.com; ylanir@is.haifa.il;
   ssharonqin@gmail.com; guozheng.li@bit.edu.cn; cohenor@gmail.com;
   hhzhiyan@gmail.com
RI Huang, Hui/JGB-1049-2023
OI Huang, Hui/0000-0003-3212-0544; Li, Guozheng/0000-0001-6663-6712
FU NSFC
FX No Statement Available
CR Abello J, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P183, DOI 10.1109/INFVIS.2004.46
   Battista G. D., 1998, Graph drawing: algorithms for the visualization of graphs
   Baur M, 2004, LECT NOTES COMPUT SC, V3353, P332
   BECKER RA, 1995, IEEE T VIS COMPUT GR, V1, P16, DOI 10.1109/2945.468391
   Bennett Chris, 2007, PROC CAE, DOI [10.2312/COMPAESTH/COMPAESTH07/057-064, 10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   Binucci C., 2016, 2016 P 7 INT C INF I, P1
   Bludau Mark-Jan, 2021, EuroVis 2021-Posters, P3, DOI [10.2312/evp.20211070, DOI 10.2312/EVP.20211070]
   Bruckdorfer Till, 2012, Fun with Algorithms. Proceedings 6th International Conference (FUN 2012), P40, DOI 10.1007/978-3-642-30347-0_7
   Bruckdorfer T., 2012, P INT S GRAPH DRAW, P67
   Burch M, 2014, IEEE INT CONF INF VI, P53, DOI 10.1109/IV.2014.45
   Burch M, 2017, IEEE INT CON INF VIS, P199, DOI 10.1109/iV.2017.43
   Burch M, 2012, LECT NOTES COMPUT SC, V7034, P226
   Buschel W., 2018, P CHI WORKSH DAT VIS
   Buschmann S, 2016, VISUAL COMPUT, V32, P371, DOI 10.1007/s00371-015-1185-9
   Cheong SH, 2020, INFORM VISUAL, V19, P65, DOI 10.1177/1473871618821740
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Didimo W, 2019, INFORM SCIENCES, V505, P406, DOI 10.1016/j.ins.2019.07.097
   Dong WH, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7070281
   Dunne C., 2013, P SIGCHI C HUM FACT, P3247, DOI DOI 10.1145/2470654.2466444
   Eades Peter, 1984, Congressus Numerantium, V42, P149
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Hansen DL, 2011, ANALYZING SOCIAL MEDIA NETWORKS WITH NODEXL: INSIGHTS FROM A CONNECTED WORLD, P11, DOI 10.1016/B978-0-12-382229-1.00002-3
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Henry N, 2006, IEEE T VIS COMPUT GR, V12, P677, DOI 10.1109/TVCG.2006.160
   Herman I., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P13
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Holten D, 2011, IEEE PAC VIS SYMP, P195, DOI 10.1109/PACIFICVIS.2011.5742390
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Holten D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2299
   Hummel M, 2019, LECT NOTES COMPUT SC, V11904, P323, DOI 10.1007/978-3-030-35802-0_25
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Jankun-Kelly TJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P59, DOI 10.1109/INFVIS.2003.1249009
   Kale B, 2023, COMPUT GRAPH FORUM, V42, P471, DOI 10.1111/cgf.14856
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Landauer T.K., 1997, Handbood of Human-Computer Interaction, V2nd, P203, DOI DOI 10.1016/B978-044481862-1.50075-3
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Liu YK, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186727
   Liu Y, 2023, Arxiv, DOI arXiv:2211.12875
   Matuszewski C, 1999, LECT NOTES COMPUT SC, V1731, P217
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Misue K, 2019, LECT NOTES COMPUT SC, V11904, P337, DOI 10.1007/978-3-030-35802-0_26
   Navlakha S., 2008, P ACM SIGMOD INT C M, P419, DOI DOI 10.1145/1376616.1376661
   Pan JC, 2021, IEEE T VIS COMPUT GR, V27, P1655, DOI 10.1109/TVCG.2020.3030393
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   REINGOLD EM, 1981, IEEE T SOFTWARE ENG, V7, P223, DOI 10.1109/TSE.1981.234519
   Riche NH, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P506, DOI 10.1145/2254556.2254652
   Romat H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173761
   Rusu A, 2011, IEEE INT CONF INF VI, P488, DOI 10.1109/IV.2011.63
   Sathiyanarayanan M, 2017, INT CONF COMMUN SYST, P570, DOI 10.1109/COMSNETS.2017.7945455
   Schmauder Hansjorg, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P123
   Schoffel S., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P2292
   Schwank J, 2016, IEEE INT CONF INF VI, P45, DOI 10.1109/IV.2016.19
   Streit M, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S6-S4
   Tufte E. R., 1985, TLS-TIMES LIT SUPPL, V7, P15
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   van Ham F, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P199, DOI 10.1109/INFVIS.2004.43
   van Ham F, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P227, DOI 10.1109/INFVIS.2003.1249030
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Wilkinson L.., 1999, The Grammar of Graphics
   Wong K, 2006, SOFTWARE QUAL J, V14, P233, DOI 10.1007/s11219-006-9218-2
   Yang WK, 2023, Arxiv, DOI arXiv:2310.05771
   Yuan XR, 2012, IEEE T VIS COMPUT GR, V18, P2699, DOI 10.1109/TVCG.2012.236
NR 70
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2968
EP 2980
DI 10.1109/TVCG.2024.3388562
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500013
PM 38648150
DA 2024-08-05
ER

PT J
AU Wang, JC
   Ma, J
   Zhou, Z
   Xie, X
   Zhang, H
   Wu, YC
   Qu, HM
AF Wang, Jiachen
   Ma, Ji
   Zhou, Zheng
   Xie, Xiao
   Zhang, Hui
   Wu, Yingcai
   Qu, Huamin
TI TacPrint: Visualizing the Biomechanical Fingerprint in Table Tennis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Biomechanics; Sports; Fingerprint recognition; Biological system
   modeling; Data visualization; Machine learning; Feature extraction; Data
   transformation; biomechanical data; machine learning
ID INTERACTIVE VISUALIZATION; RACKET SPORTS; PRESSURE; VIDEO
AB Table tennis is a sport that demands high levels of technical proficiency and body coordination from players. Biomechanical fingerprints can provide valuable insights into players' habitual movement patterns and characteristics, allowing them to identify and improve technical weaknesses. Despite the potential, few studies have developed effective methods for generating such fingerprints. To address this gap, we propose TacPrint, a framework for generating a biomechanical fingerprint for each player. TacPrint leverages machine learning techniques to extract comprehensive features from biomechanics data collected by inertial measurement units (IMU) and employs the attention mechanism to enhance model interpretability. After generating fingerprints, TacPrint provides a visualization system to facilitate the exploration and investigation of these fingerprints. In order to validate the effectiveness of the framework, we designed an experiment to evaluate the model's performance and conducted a case study with the system. The results of our experiment demonstrated the high accuracy and effectiveness of the model. Additionally, we discussed the potential of TacPrint to be extended to other sports.
C1 [Wang, Jiachen; Ma, Ji; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Zhou, Zheng; Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sports Sci, Hangzhou 310027, Peoples R China.
   [Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
C3 Zhejiang University; Zhejiang University; Hong Kong University of
   Science & Technology
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou 310027, Peoples R China.
EM wangjiachen@zju.edu.cn; zjumaji@zju.edu.cn; zheng.zhou@zju.edu.cn;
   xxie@zju.edu.cn; zhang_hui@zju.edu.cn; ycwu@zju.edu.cn;
   huamin@cse.ust.hk
OI , Hui/0000-0003-0601-3905; Wang, Jiachen/0000-0001-9630-9958; Ma,
   Ji/0000-0002-9018-4047
FU NSFC
FX No Statement Available
CR Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   Bernard J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P217, DOI 10.5220/0006127502170224
   Blank P, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P2, DOI 10.1145/3123021.3123040
   Blank P, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P93, DOI 10.1145/2802083.2802087
   Borgo R., 2013, P EUR, P39, DOI [DOI 10.2312/CONF/EG2013/STARS/039-063, 10.2312/CONF/EG2013/STARS/039-063]
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Chen Zhutian, 2023, IEEE Trans Vis Comput Graph, V29, P918, DOI 10.1109/TVCG.2022.3209497
   Chung DHS, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.25
   Chung DHS, 2015, INFORM VISUAL, V14, P76, DOI 10.1177/1473871613511959
   Deng Dazhen, 2023, IEEE Trans Vis Comput Graph, V29, P690, DOI 10.1109/TVCG.2022.3209468
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Deng ZK, 2024, IEEE T VIS COMPUT GR, V30, P1194, DOI 10.1109/TVCG.2023.3327162
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Fu FQ, 2016, INT J SPORTS SCI COA, V11, P559, DOI 10.1177/1747954116654778
   Goldsberry Kirk., 2012, 2012 MIT Sloan Sports Analytics Conference, V9, P12
   Gravenhorst F., 2015, Int. J. Comput. Sci. Sport, V14, P4
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He YQ, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9080336
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Ibrahim N, 2022, SPORT BIOMECH, V21, P1065, DOI 10.1080/14763141.2020.1726995
   Iino Y, 2017, HUM MOVEMENT SCI, V56, P98, DOI 10.1016/j.humov.2017.10.021
   Iino Y, 2016, J SPORT SCI, V34, P721, DOI 10.1080/02640414.2015.1069377
   Iino Y, 2011, SPORT BIOMECH, V10, P361, DOI 10.1080/14763141.2011.629304
   Iino Y, 2009, J SPORT SCI, V27, P1311, DOI 10.1080/02640410903264458
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Jino Y., 2018, ISBS Proc. Arch., V36
   Ke GL, 2017, ADV NEUR IN, V30
   Lam WK, 2019, EUR J SPORT SCI, V19, P471, DOI 10.1080/17461391.2018.1534993
   Lees A, 2003, J SPORT SCI, V21, P707, DOI 10.1080/0264041031000140275
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Legg PA, 2013, IEEE T VIS COMPUT GR, V19, P2109, DOI 10.1109/TVCG.2013.207
   Letarte G., 2018, P 2018 EMNLP WORKSH, P267, DOI DOI 10.18653/V1/W18-5429
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Lu SS, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9958256
   Ma RJ, 2018, 2018 IEEE 1ST INTERNATIONAL CONFERENCE ON MICRO/NANO SENSORS FOR AI, HEALTHCARE, AND ROBOTICS (NSENS), P73, DOI 10.1109/NSENS.2018.8713634
   Mitsui T, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORKING (ICMU), P100, DOI 10.1109/ICMU.2015.7061049
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Rusu A, 2010, IEEE INT CONF INF VI, P207, DOI 10.1109/IV.2010.39
   Sisneros R., 2013, P 1 WORKSH SPORTS DA
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2015, ISPRS INT J GEO-INF, V4, P2159, DOI 10.3390/ijgi4042159
   Wang Jiachen, 2023, IEEE Trans Vis Comput Graph, V29, P951, DOI 10.1109/TVCG.2022.3209352
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang JC, 2020, IEEE T VIS COMPUT GR, V26, P407, DOI 10.1109/TVCG.2019.2934630
   Wang YF, 2018, IEEE INTERNET THINGS, V5, P4558, DOI 10.1109/JIOT.2018.2837347
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11
   Wong DWC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155203
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu Yihong, 2023, IEEE Trans Vis Comput Graph, V29, P929, DOI 10.1109/TVCG.2022.3209373
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Xia K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061638
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Yang WK, 2024, COMPUT VIS MEDIA, V10, P399, DOI 10.1007/s41095-023-0393-x
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Yu CX, 2018, PEERJ, V6, DOI 10.7717/peerj.4760
   Zhou ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3553
NR 66
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2955
EP 2967
DI 10.1109/TVCG.2024.3388555
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500010
PM 38619948
DA 2024-08-05
ER

PT J
AU Garzotto, F
   Gianotti, M
   Patti, A
   Pentimalli, F
   Vona, F
AF Garzotto, Franca
   Gianotti, Mattia
   Patti, Alberto
   Pentimalli, Francesca
   Vona, Francesco
TI Empowering Persons with Autism Through Cross-Reality and Conversational
   Agents
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human computer interaction; Accessibility technologies; Interactive
   learning environments; Virtual reality; Augmented reality;
   Conversational agents
ID AUGMENTED REALITY; ADOLESCENTS; STUDENTS; ADULTS
AB Autism Spectrum Disorder is a neurodevelopmental condition that can affect autonomy and independence. Our research explores the integration of Cross-Reality and Conversational Agents for Autistic persons to improve ability and confidence in everyday life situations. We combine two technologies of the Virtual-Real continuum. User experiences unfold from the simulation of tasks in VR to the execution of similar tasks supported by AR in the real world. A speech-based Conversational Agent is integrated with both VR and AR. It provides contextualized help, promotes generalization, and stimulates users to apply what they learned in the virtual space. The paper presents the approach and describes an empirical study involving 17 young Autistic persons.
C1 [Garzotto, Franca; Gianotti, Mattia; Patti, Alberto; Pentimalli, Francesca; Vona, Francesco] Politecn Milan, Dept Elect Informat & Bioengn, Milan, Italy.
C3 Polytechnic University of Milan
RP Garzotto, F (corresponding author), Politecn Milan, Dept Elect Informat & Bioengn, Milan, Italy.
EM franca.garzotto@polimi.it; mattia.gianotti@polimi.it;
   alberto.patti@polimi.it; francesca.pentimalli@polimi.it;
   francesco.vona@polimi.it
OI Gianotti, Mattia/0000-0001-6035-3367; Vona,
   Francesco/0000-0003-4558-4989; Patti, Alberto/0000-0002-6871-7417;
   Pentimalli, Francesca/0000-0002-5052-0560
FU TIM Foundation Program "Liberi di comunicare"
FX No Statement Available
CR Adjorlu A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P294, DOI 10.1109/ISMAR-Adjunct.2017.93
   Ali MR, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423900
   Allouch M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248448
   Berenguer C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176143
   Bernardes M, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P127, DOI 10.1109/ICVR.2015.7358609
   Bradley R, 2018, J ENABLING TECHNOL, V12, P101, DOI 10.1108/JET-01-2018-0004
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Cha I, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445116
   Cihak DF, 2016, J SPEC EDUC TECHNOL, V31, P99, DOI 10.1177/0162643416651724
   Cowan RJ, 2007, PSYCHOL SCHOOLS, V44, P701, DOI 10.1002/pits.20259
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   Glaser N, 2022, VIRTUAL REAL-LONDON, V26, P1705, DOI 10.1007/s10055-022-00661-3
   Gonzalez L., 2018, Clarifai featured hack: Spectrum navigator is a gps app that helps people navigate by landmark
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Hartholt A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P205, DOI 10.1145/3349537.3352766
   Howlin P, 1998, J CHILD PSYCHOL PSYC, V39, P307, DOI 10.1111/1469-7610.00327
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Ladner R. E., 2015, Interactions, V22, P24, DOI DOI 10.1145/2723869
   LOVAAS OI, 1987, J CONSULT CLIN PSYCH, V55, P3, DOI 10.1037/0022-006X.55.1.3
   McCleery JP, 2020, AUTISM RES, V13, P1418, DOI 10.1002/aur.2352
   McCready M, 2022, IEEE INT SYMP M AU R, P183, DOI 10.1109/ISMAR-Adjunct57072.2022.00041
   McMahon D, 2015, J RES TECHNOL EDUC, V47, P157, DOI 10.1080/15391523.2015.1047698
   Miller IT, 2020, AUTISM ADULTHOOD, V2, P325, DOI 10.1089/aut.2019.0076
   Mirenda P. L., 1987, Handbook of autism and pervasive developmental disorders
   Nadel J., 2022, Autism and Socially Interactive Agents, V1, P437
   Parris J., 2019, Boise airport virtual reality experience will help children with autism
   Rao PA, 2008, J AUTISM DEV DISORD, V38, P353, DOI 10.1007/s10803-007-0402-4
   Razavi SZ, 2016, LECT NOTES ARTIF INT, V10011, P460, DOI 10.1007/978-3-319-47665-0_55
   Smith MJ, 2014, J AUTISM DEV DISORD, V44, P2450, DOI 10.1007/s10803-014-2113-y
   Soccini Agata Marta, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P234, DOI 10.1007/978-3-030-62655-6_16
   Soriano LD, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-24478-x
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Thomsen LA, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P50, DOI 10.1109/VRW52623.2021.00015
   Wang M, 2013, SCI WORLD J, DOI 10.1155/2013/716890
   Wang NJ, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3531116
   Williams DL, 2015, AUTISM, V19, P859, DOI 10.1177/1362361315586171
   Williams DL, 2014, J AUTISM DEV DISORD, V44, P2908, DOI 10.1007/s10803-014-2190-y
NR 38
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2591
EP 2601
DI 10.1109/TVCG.2024.3372110
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400047
PM 38437092
DA 2024-08-05
ER

PT J
AU Ceneda, D
   Collins, C
   El-Assady, M
   Miksch, S
   Tominski, C
   Arleo, A
AF Ceneda, Davide
   Collins, Christopher
   El-Assady, Mennatallah
   Miksch, Silvia
   Tominski, Christian
   Arleo, Alessio
TI A Heuristic Approach for Dual Expert/End-User Evaluation of Guidance in
   Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Guidance; heuristics; evaluation; visual analytics
ID VISUALIZATION; DESIGN; TASKS
AB Guidance can support users during the exploration and analysis of complex data. Previous research focused on characterizing the theoretical aspects of guidance in visual analytics and implementing guidance in different scenarios. However, the evaluation of guidance-enhanced visual analytics solutions remains an open research question. We tackle this question by introducing and validating a practical evaluation methodology for guidance in visual analytics. We identify eight quality criteria to be fulfilled and collect expert feedback on their validity. To facilitate actual evaluation studies, we derive two sets of heuristics. The first set targets heuristic evaluations conducted by expert evaluators. The second set facilitates end-user studies where participants actually use a guidance-enhanced system. By following such a dual approach, the different quality criteria of guidance can be examined from two different perspectives, enhancing the overall value of evaluation studies. To test the practical utility of our methodology, we employ it in two studies to gain insight into the quality of two guidance-enhanced visual analytics solutions, one being a work-in-progress research prototype, and the other being a publicly available visualization recommender system. Based on these two evaluations, we derive good practices for conducting evaluations of guidance in visual analytics and identify pitfalls to be avoided during such studies.
C1 [Ceneda, Davide; Miksch, Silvia; Arleo, Alessio] TU Wien, Vienna, Austria.
   [Collins, Christopher] Ontario Tech Univ, Oshawa, ON, Canada.
   [El-Assady, Mennatallah] Swiss Fed Inst Technol, AI Ctr, Zurich, Switzerland.
   [Tominski, Christian] Univ Rostock, VAC Inst, Rostock, Germany.
C3 Technische Universitat Wien; Swiss Federal Institutes of Technology
   Domain; ETH Zurich; University of Rostock
RP Ceneda, D (corresponding author), TU Wien, Vienna, Austria.
EM davide.ceneda@tuwien.ac.at; christopher.collins@ontariotechu.ca;
   melassady@ai.ethz.ch; miksch@ifs.tuwien.ac.at;
   christian.tominski@uni-rostock.de; alessio.arleo@tuwien.ac.at
RI Tominski, Christian/H-6388-2019; Arleo, Alessio/IRZ-8036-2023
OI Tominski, Christian/0000-0001-7704-355X; Arleo,
   Alessio/0000-0003-2008-3651; Ceneda, Davide/0000-0003-1198-567X; Miksch,
   Silvia/0000-0003-4427-5703; El-Assady, Mennatallah/0000-0001-8526-2613
FU Vienna Science and Technology Fund (WWTF)
FX No Statement Available
CR Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   [Anonymous], 2006, Proceedings of the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization, DOI [10.1145/1168149.1168158, DOI 10.1145/1168149.1168158]
   [Anonymous], Templates and Protocol
   Baldonado MQW, 2000, P WORK C ADV VIS INT, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Bergeron R., 1972, Advances in Computers, V12, P175, DOI DOI 10.1016/S0065-2458(08)60510-04
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Ceneda D., 2018, P 9 INT EUROVIS WORK, P19, DOI [10.2312/eurova.20181107, DOI 10.2312/EUROVA.20181107]
   Ceneda D., 2018, Visualization in Data Science (VDS), V2, P3
   Ceneda D, 2022, IEEE T VIS COMPUT GR, V28, P4570, DOI 10.1109/TVCG.2021.3094870
   Ceneda D, 2020, COMPUT GRAPH FORUM, V39, P269, DOI 10.1111/cgf.14017
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen CM, 2000, INT J HUM-COMPUT ST, V53, P631, DOI 10.1006/ijhc.2000.0421
   Chen CM, 2000, INT J HUM-COMPUT ST, V53, P851, DOI 10.1006/ijhc.2000.0422
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Cook K. A., 2005, Technical report, P1
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Forsell C., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P136, DOI 10.1109/IV.2012.33
   Forsell C., 2010, P INT C ADV VISUAL I, P199, DOI [DOI 10.1145/1842993.18430292, 10.1145/1842993.18430292]
   Gladisch S, 2013, LECT NOTES COMPUT SC, V8034, P36, DOI 10.1007/978-3-642-41939-3_4
   Gotz D., 2010, P INT WORKSH INT VIS, P1, DOI [DOI 10.1145/2002353.2002355, 10.1145/2002353.2002355]
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI DOI 10.1145/1502650.1502695
   Han WK, 2023, INFORM VISUAL, V22, P140, DOI 10.1177/14738716221147289
   He T., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P363, DOI DOI 10.1109/TVCG.2022.32093902,3
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hinkins T.R., 1997, Journal of Hospitality Tourism Research, V21, P100, DOI [DOI 10.1177/109634809702100108, 10.1177/1096348097021001089, DOI 10.1177/1096348097021001089]
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krishnamoorthy G., 2006, P E LEARN WORLD C E, P2122
   Luboschik M., 2012, 2012 IEEE Symposium on Biological Data Visualization (BioVis 2012), P33, DOI 10.1109/BioVis.2012.6378590
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Manka JS, 2003, PROCEEDINGS OF THE TWENTY-NINTH ANNUAL CONFERENCE ON EXPLOSIVES AND BLASTING TECHNIQUE, VOL 1, P169
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   MOLICH R, 1990, COMMUN ACM, V33, P338, DOI 10.1145/77481.77486
   Nielsen J, 1994, Usability Inspection Methods, P25, DOI [10.5555/189200.189209, DOI 10.5555/189200.189209, DOI 10.1089/TMJ.2010.0114]
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Perez-Messina I, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14555
   Plaisant Catherine, 2004, Proceedings of the working conference on Advanced visual interfaces, P109, DOI DOI 10.1145/989863.989880
   Saket B, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P133, DOI 10.1145/2993901.2993903
   Scapin DL, 1997, BEHAV INFORM TECHNOL, V16, P220, DOI 10.1080/014492997119806
   Sperotto F, 2021, EUR J PEDIATR, V180, P307, DOI 10.1007/s00431-020-03766-6
   Sperrle Fabian, 2023, IEEE Trans Vis Comput Graph, V29, P1124, DOI 10.1109/TVCG.2022.3209393
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Stasko J., 2014, P 5 WORKSH TIM ERR N, P46, DOI [DOI 10.1145/2669557.26695792,9, 10.1145/2669557.2669579, DOI 10.1145/2669557.2669579]
   Stoiber C, 2022, VIS INFORM, V6, P68, DOI 10.1016/j.visinf.2022.02.005
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Zuk T, 2006, PROC SPIE, V6060, DOI 10.1117/12.643631
   Zuk Torre, 2006, P WORKSH TIM ERR NOV, P1, DOI DOI 10.1145/1168149.1168162
NR 55
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 997
EP 1007
DI 10.1109/TVCG.2023.3327152
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500077
PM 37903044
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Hao, JN
   Shi, Q
   Ye, YL
   Zeng, W
AF Hao, Jianing
   Shi, Qing
   Ye, Yilin
   Zeng, Wei
TI <i>TimeTuner:</i> Diagnosing Time Representations for Time-Series
   Forecasting with Counterfactual Explanations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time-series forecasting; counterfactual explanation; visual analytics
ID STATE
AB Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely TimeTuner, designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual explanations to connect the relationships among time-series representations, multivariate features and model predictions. Next, we design multiple coordinated views including a partition-based correlation matrix and juxtaposed bivariate stripes, and provide a set of interactions that allow users to step into the transformation selection process, navigate through the feature space, and reason the model performance. We instantiate TimeTuner with two transformation methods of smoothing and sampling, and demonstrate its applicability on real-world time-series forecasting of univariate sunspots and multivariate air pollutants. Feedback from domain experts indicates that our system can help characterize time-series representations and guide the feature engineering processes.
C1 [Hao, Jianing; Shi, Qing; Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
   [Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
EM jhao768@connect.hkust-gz.edu.cn; brantqshi@hkust-gz.edu.cn;
   yyebd@connect.hkust-gz.edu.cn; weizeng@hkust-gz.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Aigner W, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P457, DOI 10.1109/IV.2005.97
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Asuero AG, 2006, CRIT REV ANAL CHEM, V36, P41, DOI 10.1080/10408340500526766
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Benjamin L., 2021, Proc. CIRP, V99, P650, DOI DOI 10.1016/J.PROCIR.2021.03.088
   Binns R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173951
   Box GEP, 1970, Journal of American Statistical Association, V65, P1509
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Burch M, 2019, PROCEEDINGS OF THE 12TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION, VINCI 2019, DOI 10.1145/3356422.3356423
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   Cascarino G., 2022, Bank of Italy Occasional Paper, DOI [10.32057/0.QEF.2022.0674, DOI 10.32057/0.QEF.2022.0674]
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   CHEUNG YW, 1995, J BUS ECON STAT, V13, P277, DOI 10.2307/1392187
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174216
   d3js, The javascript library for bespoke data visualization
   Dachselt Raimund., 2006, P ANN SIGCHI C HUMAN, P682, DOI DOI 10.1145/1125451.11255902
   Elsayed S, 2021, Arxiv, DOI arXiv:2101.02118
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   GARDNER ES, 1985, J FORECASTING, V4, P1, DOI 10.1002/for.3980040103
   Hao M.C., 2007, Proceedings of Eurographics/IEEEVGTC Symposium on Visualization 2007, P27, DOI [10.2312/VisSym/EuroVis07/027-034, DOI 10.2312/VISSYM/EUROVIS07/027-034]
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Karimi AH, 2020, PR MACH LEARN RES, V108, P895
   keras, About us
   Kincaid R, 2010, IEEE T VIS COMPUT GR, V16, P900, DOI 10.1109/TVCG.2010.193
   Kincaid Robert, 2006, P WORK C ADV VIS INT, P404
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lammarsch T, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P44, DOI 10.1109/IV.2009.52
   Lewis D., 1973, Counterfactuals, DOI [10.2307/22737382, DOI 10.2307/22737382]
   Liang X, 2015, P ROY SOC A-MATH PHY, V471, DOI 10.1098/rspa.2015.0257
   Lim B, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206906
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Mishra P., 2022, Counterfactual Explanations for XAI Models, P265, DOI [10.1145/3514094.3534144, DOI 10.1145/3514094.3534144]
   Molnar C., 2019, INTERPRETABLE MACHIN, DOI DOI 10.3389/FNB0T.2013.00021
   Mothilal RK, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P607, DOI 10.1145/3351095.3372850
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Nocke T, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P763, DOI 10.1109/WSC.2003.1261493
   Oppermann M, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P41, DOI 10.1109/VIS49827.2021.9623320
   palletsprojects, Flask documentation
   Rangapuram SS, 2018, ADV NEUR IN, V31
   readthedocs, Welcome to the shap documentation
   Sagheer A, 2019, NEUROCOMPUTING, V323, P203, DOI 10.1016/j.neucom.2018.09.082
   Saito T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P173, DOI 10.1109/INFVIS.2005.1532144
   Sarkar S., 2016, PROC CEUR, V1773, P2
   Schrijver CJ, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL046658
   scipy, scipy.stats.pearsonr.
   Shen QM, 2020, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis48177.2020.2785
   Shi Y., 2023, IEEE Trans. Vis. Comput. Graphics, P1
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Siami-Namini S, 2018, Arxiv, DOI arXiv:1803.06386
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Verma S, 2020, Arxiv, DOI arXiv:2010.10596
   Vue.js, About us
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Xu K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445083
   Xu K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174237
   Yajnik M, 1999, IEEE INFOCOM SER, P345, DOI 10.1109/INFCOM.1999.749301
   Zeng W, 2021, IEEE T VIS COMPUT GR, V27, P839, DOI 10.1109/TVCG.2020.3030410
   Zhao J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1737
NR 67
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1183
EP 1193
DI 10.1109/TVCG.2023.3327389
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500034
PM 37883273
DA 2024-08-05
ER

PT J
AU Hung, SH
   Zhang, Y
   Zhang, E
AF Hung, Shih-Hsuan
   Zhang, Yue
   Zhang, Eugene
TI Global Topology of 3D Symmetric Tensor Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tensors; Structural rings; Three-dimensional displays; Topology; Stress;
   Feature extraction; Data visualization; Tensor field visualization; 3D
   symmetric tensor fields; global tensor field topology; topological
   graphs; degenerate curves; neutral surfaces; wedges and trisectors
ID SURFACES; VISUALIZATION; EXTRACTION; LINES
AB There have been recent advances in the analysis and visualization of 3D symmetric tensor fields, with a focus on the robust extraction of tensor field topology. However, topological features such as degenerate curves and neutral surfaces do not live in isolation. Instead, they intriguingly interact with each other. In this paper, we introduce the notion of topological graph for 3D symmetric tensor fields to facilitate global topological analysis of such fields. The nodes of the graph include degenerate curves and regions bounded by neutral surfaces in the domain. The edges in the graph denote the adjacency information between the regions and degenerate curves. In addition, we observe that a degenerate curve can be a loop and even a knot and that two degenerate curves (whether in the same region or not) can form a link. We provide a definition and theoretical analysis of individual degenerate curves in order to help understand why knots and links may occur. Moreover, we differentiate between wedges and trisectors, thus making the analysis more detailed about degenerate curves. We incorporate this information into the topological graph. Such a graph can not only reveal the global structure in a 3D symmetric tensor field but also allow two symmetric tensor fields to be compared. We demonstrate our approach by applying it to solid mechanics and material science data sets.
C1 [Hung, Shih-Hsuan; Zhang, Yue; Zhang, Eugene] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
C3 Oregon State University
RP Hung, SH (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
EM hungsh@oregonstate.edu; zhangyue@oregonstate.edu;
   zhange@eecs.oregonstate.edu
OI Zhang, Yue/0000-0002-8467-2781; Zhang, Eugene/0000-0003-4752-3119
FU NSF
FX No Statement Available
CR BANCHOFF T, 1976, INDIANA U MATH J, V25, P1171, DOI 10.1512/iumj.1976.25.25093
   Calcaterra C, 2008, J MATH ANAL APPL, V338, P1108, DOI 10.1016/j.jmaa.2007.06.001
   Cammoun L., 2009, Advances in Pattern Recognition
   Chaimahawan P, 2021, LAT AM J SOLIDS STRU, V18
   Chen GN, 2007, IEEE T VIS COMPUT GR, V13, P769, DOI 10.1109/TVCG.2007.1021
   Crane K., 2018, Discrete differential geometry: An applied introduction, P1153
   Criscione JC, 2000, J MECH PHYS SOLIDS, V48, P2445, DOI 10.1016/S0022-5096(00)00023-5
   De Leeuw W., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P349, DOI 10.1109/VISUAL.1999.809907
   DELMARCELLE T, 1993, IEEE COMPUT GRAPH, V13, P25, DOI 10.1109/38.219447
   Dieck TT, 2008, EMS TEXTB MATH, P1
   Dudzinski N., 1952, RAE/Met-69
   Hannifin P., 2007, Parker o-ring handbook
   Hesselink L, 1997, IEEE T VIS COMPUT GR, V3, P1, DOI 10.1109/2945.582332
   Hung SH, 2022, IEEE T VIS COMPUT GR, V28, P33, DOI 10.1109/TVCG.2021.3114808
   Jankowai J, 2019, COMPUT GRAPH FORUM, V38, P337, DOI 10.1111/cgf.13693
   Kaczynski T., 2004, Applied mathematical sciences, V157
   Khan F, 2020, IEEE T VIS COMPUT GR, V26, P270, DOI 10.1109/TVCG.2019.2934314
   Kratz A, 2013, COMPUT GRAPH FORUM, V32, P49, DOI 10.1111/j.1467-8659.2012.03231.x
   Lin Z., 2012, 2D Asymmetric Tensor Field Topology, P191, DOI DOI 10.1007/978-3-642-23175-913
   Livingston C., 1993, Carus Math. Monogr., V24
   MARKUS L, 1955, ANN MATH, V62, P411, DOI 10.2307/1970071
   Palacios J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130844
   Palacios J, 2016, IEEE T VIS COMPUT GR, V22, P1248, DOI 10.1109/TVCG.2015.2484343
   Panagiotou E, 2020, P ROY SOC A-MATH PHY, V476, DOI 10.1098/rspa.2020.0124
   Qu BT, 2021, IEEE T VIS COMPUT GR, V27, P583, DOI 10.1109/TVCG.2020.3030431
   Rotman J. J., 2013, An Introduction to Algebraic Topology, V119
   Roy L, 2019, IEEE T VIS COMPUT GR, V25, P1102, DOI 10.1109/TVCG.2018.2864768
   Rudin W., 1990, International Series in Pure & Applied Mathematics, V2nd
   Smith M, 2009, ABAQUSSTANDARD USERS
   Tao J, 2018, IEEE T VIS COMPUT GR, V24, P3200, DOI 10.1109/TVCG.2017.2773071
   Tricoche X, 2008, IEEE T VIS COMPUT GR, V14, P1627, DOI 10.1109/TVCG.2008.148
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
   Zhang Y., 2020, Topological Methods in Data Analysis and Visualization V, P237, DOI DOI 10.1007/978-3-030-43036-8
   Zhang Y., 2017, Topological Methods in Data Analysis and Visualization IV, P221, DOI DOI 10.1007/978-3-319-44684-413
   [Чжан Юн-Цзюнь Zhang Yongjun], 2017, [Металловедение и термическая обработка металлов, Metallovedenie i termicheskaya obrabotka metallov], P29
   Zheng XQ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P551
   Zheng XQ, 2005, IEEE T VIS COMPUT GR, V11, P395, DOI 10.1109/TVCG.2005.67
   Zheng XQ, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P313, DOI 10.1109/VISUAL.2004.105
NR 38
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1282
EP 1291
DI 10.1109/TVCG.2023.3326933
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500058
PM 37874708
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Setlur, V
   Correll, M
   Satyanarayan, A
   Tory, M
AF Setlur, Vidya
   Correll, Michael
   Satyanarayan, Arvind
   Tory, Melanie
TI Heuristics for Supporting Cooperative Dashboard Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Oral communication; Data visualization; Guidelines; Visualization;
   Maintenance engineering; Surveys; Grounding; Gricean maxims; interactive
   visualization; conversation initiation; grounding; turn-taking; repair
   and refinement
ID ORGANIZATION
AB Dashboards are no longer mere static displays of metrics; through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines, however, are often unable to account for this expanded scope as they largely focus on best practices for visual design. In contrast, we frame dashboard design as facilitating an analytical conversation: a cooperative, interactive experience where a user may interact with, reason about, or freely query the underlying data. By drawing on established principles of conversational flow and communication, we define the concept of a cooperative dashboard as one that enables a fruitful and productive analytical conversation, and derive a set of 39 dashboard design heuristics to support effective analytical conversations. To assess the utility of this framing, we asked 52 computer science and engineering graduate students to apply our heuristics to critique and design dashboards as part of an ungraded, opt-in homework assignment. Feedback from participants demonstrates that our heuristics surface new reasons dashboards may fail, and encourage a more fluid, supportive, and responsive style of dashboard design. Our approach suggests several compelling directions for future work, including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement and extending cooperative principles to other analytical workflows.
C1 [Setlur, Vidya; Correll, Michael] Tableau Res, Palo Alto, CA 94306 USA.
   [Satyanarayan, Arvind] MIT CSAIL, Cambridge, MA 02139 USA.
   [Tory, Melanie] Northeastern Univ, Boston, MA USA.
C3 Massachusetts Institute of Technology (MIT); Northeastern University
RP Setlur, V (corresponding author), Tableau Res, Palo Alto, CA 94306 USA.
EM vsetlur@tableau.com; m.correll@northeastern.edu; arvindsatya@mit.edu;
   m.tory@northeastern.edu
OI Satyanarayan, Arvind/0000-0001-5564-635X; Setlur,
   Vidya/0000-0003-3722-406X
FU NSF
FX No Statement Available
CR Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006
   Agarwal S, 2022, LIBR HI TECH, V40, P1013, DOI 10.1108/LHT-09-2021-0330
   Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   [Anonymous], 2005, INT C INT AN MCLEAN
   [Anonymous], 2021, Microsoft Q&A
   [Anonymous], 2021, IBM Watson Analytics
   Bach B., 2022, IEEE TVCG, P2
   Bartram M., 2021, arXiv
   Beebe S., 2004, Interpersonal Communication: Relating to Others, P2
   Bertini E., 2006, Advanced Visual Interfaces, P2
   Brehmer M., 2022, IEEE TVCG, V28, P4
   Cassell J, 2001, AI MAG, V22, P67
   Chaves AP, 2021, INT J HUM-COMPUT INT, V37, P729, DOI 10.1080/10447318.2020.1841438
   Chen X., 2020, IEEE TVCG, V27, P2
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   Coppock L., 2005, Politeness Strategies in Conversation Closings, V01, P4
   Cuttone A., 2014, INT C UN ACC HUM COM, P2
   Davis W., 2019, The Stanford Encyclopedia of Philosophy, P5
   Deng DZ, 2022, Arxiv, DOI [arXiv:2203.10476, 10.48550/arXiv.2203.10476, DOI 10.48550/ARXIV.2203.10476]
   Dhanoa V, 2022, COMPUT GRAPH FORUM, V41, P501, DOI 10.1111/cgf.14558
   Diakopoulos N., 2016, Pearson, P2
   Dimara E., 2021, IEEE TVCG, P2
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dowding D, 2018, APPL CLIN INFORM, V9, P511, DOI 10.1055/s-0038-1666842
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   En L. Q., 2011, 2011 6 ACM IEEE INT, P4
   Endsley T. C., 2017, P HUMAN FACTORS ERGO, V61, P2
   Epley S., 2022, Best States to Retire in the United States
   Feng M., 2017, IEEE TVCG, V23, P4
   Few S., 2006, Information Dashboard Design: The Effective Visual Communication of Data, P2
   Fiore-Gartland B., 2015, International Journal of Communication, V9, P2
   Forsell C., 2010, P INT C ADV VISUAL I, P199, DOI [DOI 10.1145/1842993.18430292, 10.1145/1842993.18430292]
   Fulfagar Lokesh, 2021, Design for TomorrowVolume 1. Proceedings of ICoRD 2021. Smart Innovation, Systems and Technologies (SIST 221), P375, DOI 10.1007/978-981-16-0041-8_32
   Furmanski C, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P215, DOI 10.1109/ISMAR.2002.1115091
   Gaggiano J. D., 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence, P2
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
   Grice P., 1975, Syntax and Semantics, V3, P41
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hohn Sviatlana, 2021, Chatbot Research and Design. 4th International Workshop, CONVERSATIONS 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12604), P131, DOI 10.1007/978-3-030-68288-0_9
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Hullman Jessica, 2021, Harvard Data Science Review, V3
   kaggle, 2023, About us
   Key Alicia, 2012, P 2012 ACM SIGMOD IN, P681, DOI [10.1145/2213836.2213931, DOI 10.1145/2213836.2213931]
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kristiansen Y. S., 2021, IEEE TVCG, V28, P2
   Lam H., 2017, IEEE TVCG, V24, P2
   Langevin R., 2021, CHI, P1
   Lee D. J.-L., 2022, IEEE TVCG, V28, P3
   Lee-Robbins E., 2022, IEEE TVCG, P2
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Lin Y., 2023, IEEE TVCG, P1
   Luo B, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1434
   Maguire M., 2019, Design, User Experience, and Usability. Practice and Case Studies: 8th International Conference, DUXU 2019, Held as Part of the 21st HCI International Conference, HCII 2019, Orlando, FL, USA, 2631 July 2019, Proceedings, P212
   Merriam-Webster, 2022, Heuristic, V5
   Muller M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300356
   NIELSEN J, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P152, DOI 10.1145/191666.191729
   Nielsen Jakob, 2005, 10 Usability Heuristics for User Interface Design
   Nowacki Caroline, 2020, Design, User Experience, and Usability. Design for Contemporary Interactive Environments. 9th International Conference, DUXU 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12201), P117, DOI 10.1007/978-3-030-49760-6_8
   Pandey A, 2022, Arxiv, DOI arXiv:2208.03175
   Panfili L., 2021, Proceedings of the Linguistic Society of America, V6, P288
   Qu Z., 2017, IEEE TVCG, V24, P2
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Saygin AP, 2002, J PRAGMATICS, V34, P227, DOI 10.1016/S0378-2166(02)80001-7
   SCHEGLOFF EA, 1977, LANGUAGE, V53, P361, DOI 10.2307/413107
   Setlur Vidya, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P966, DOI 10.1145/3379337.3415813
   Setlur V., 2016, UIST, P4
   Setlur V., 2022, Functional Aesthetics for Data Visualization, P4
   Setlur V, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501972
   Setlur V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P216, DOI 10.1109/VIS47514.2020.00050
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shi Y., 2022, IEEE TVCG, P1
   Singh P., World Indicators Dashboard
   Srinivasan A., 2023, EuroVis 2023-Short Papers, DOI DOI 10.2312/EVS.202310352
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Sugisaki Kyoko, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P309, DOI 10.1145/3404983.3405505
   Tarrell A., 2014, Proceedings of the Fifth Workshop on Beyond Time And Errors: Novel Evaluation Methods for Visualization, P110
   ThoughtSpot, 2021, ABOUT US
   Tominski C., 2015, Synthesis Lectures on Visualization, P1
   Tory M, 2005, IEEE COMPUT GRAPH, V25, P8, DOI 10.1109/MCG.2005.102
   Tory M., 2021, IEEE Computer Graphics and Applications, V2
   Tory M, 2019, IEEE CONF VIS ANAL, P93, DOI [10.1109/VAST47406.2019.8986918, 10.1109/vast47406.2019.8986918]
   Väätajä H, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P36, DOI 10.1145/2993901.2993918
   wa, Washington State COVID-19 Summary Dashboard
   Wall E., 2022, IEEE TVCG, V28, P4
   Wall E, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P111, DOI [10.1109/VISUAL.2019.8933611, 10.1109/visual.2019.8933611]
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Ware C, 2008, MORG KAUF SER INTER, P1
   Wei ZXN, 2018, IEEE PERVAS COMPUT, V17, P84, DOI 10.1109/MPRV.2018.022511249
   Wexler S., 2017, The Big Book of Dashboards: Visualizing your Data using Real-world Business Scenarios, V1, P2
   Whitworth B, 2005, BEHAV INFORM TECHNOL, V24, P353, DOI 10.1080/01449290512331333700
   Wu A., 2021, IEEE TVCG, V28, P2
   Yigitbasioglu O. M., 2012, International Journal of Accounting Information Systems, V13, P2
   Zuk T., 2006, P 2006 AVI WORKSH TI, P1
NR 100
TC 2
Z9 2
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 370
EP 380
DI 10.1109/TVCG.2023.3327158
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500019
PM 37883257
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Kim, H
   Kim, J
   Han, Y
   Hong, H
   Kwon, OS
   Park, YW
   Elmqvist, N
   Ko, S
   Kwon, BC
AF Kim, Hwiyeon
   Kim, Joohee
   Han, Yunha
   Hong, Hwajung
   Kwon, Oh-Sang
   Park, Young-Woo
   Elmqvist, Niklas
   Ko, Sungahn
   Kwon, Bum Chul
TI Towards Visualization Thumbnail Designs That Entice Reading Data-Driven
   Articles
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data journalism; data-driven storytelling; online news; visualization;
   thumbnail images; data stories
ID VISUAL EMBELLISHMENTS; PICTURE; RECOGNITION; MEMORY
AB As online news increasingly include data journalism, there is a corresponding increase in the incorporation of visualization in article thumbnail images. However, little research exists on the design rationale for visualization thumbnails, such as resizing, cropping, simplifying, and embellishing charts that appear within the body of the associated article. Therefore, in this paper we aim to understand these design choices and determine what makes a visualization thumbnail inviting and interpretable. To this end, we first survey visualization thumbnails collected online and discuss visualization thumbnail practices with data journalists and news graphics designers. Based on the survey and discussion results, we then define a design space for visualization thumbnails and conduct a user study with four types of visualization thumbnails derived from the design space. The study results indicate that different chart components play different roles in attracting reader attention and enhancing reader understandability of the visualization thumbnails. We also find various thumbnail design strategies for effectively combining the charts' components, such as a data summary with highlights and data labels, and a visual legend with text labels and Human Recognizable Objects (HROs), into thumbnails. Ultimately, we distill our findings into design implications that allow effective visualization thumbnail designs for data-rich news articles. Our work can thus be seen as a first step toward providing structured guidance on how to design compelling thumbnails for data stories.
C1 [Kim, Hwiyeon; Kim, Joohee; Han, Yunha; Kwon, Oh-Sang; Park, Young-Woo; Ko, Sungahn] UNIST, Ulsan 44919, South Korea.
   [Hong, Hwajung] Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea.
   [Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Kwon, Bum Chul] IBM Res, Cambridge, MA 10598 USA.
C3 Ulsan National Institute of Science & Technology (UNIST); Korea Advanced
   Institute of Science & Technology (KAIST); University System of
   Maryland; University of Maryland College Park; International Business
   Machines (IBM)
RP Ko, S (corresponding author), UNIST, Ulsan 44919, South Korea.
EM hwiyeon.d@gmail.com; jkim17@unist.ac.kr; diana438@unist.ac.kr;
   hwajung@kaist.ac.kr; oskwon@unist.ac.kr; ywpark@unist.ac.kr;
   elm@umd.edu; sako@unist.ac.kr; bumchul.kwon@us.ibm.com
OI Kwon, Bum Chul/0000-0002-9391-6274; Park, Young-Woo/0000-0003-2257-9394;
   Elmqvist, Niklas/0000-0001-5805-5301; Ko, Sungahn/0000-0002-7410-5652
FU Korean National Research Foundation (NRF) [2021R1A2C1004542]; Korea
   Health Industry Development Institute(KHIDI) - Ministry of Health &
   Welfare, Republic of Korea [HI22C0646]; Institute of Information &
   Communications Technology Planning & Evaluation (IITP) [2020-0-01336];
   UNIST - Korea government (MSIT)
FX This work was supported in part by the Korean National Research
   Foundation (NRF) under Grant 2021R1A2C1004542, in part by a grant of the
   Korea Health Technology R&D Project through the Korea Health Industry
   Development Institute(KHIDI), funded by the Ministry of Health &
   Welfare, Republic of Korea under Grant HI22C0646, and in part by the
   Institute of Information & Communications Technology Planning &
   Evaluation (IITP) under Grant 2020-0-01336-Artificial Intelligence
   Graduate School Program, UNIST, funded by the Korea government(MSIT).
   Recommended for acceptance by R. Chang.
CR Agrawala M, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1924421.1924439
   Ally B, 2009, NEUROPSYCHOLOGIA, V47, P595, DOI 10.1016/j.neuropsychologia.2008.10.010
   Amini F., 2018, Data-Driven Storytelling
   Andry T., 2021, P ACM C HUM FACT COM, P1
   Aula A., 2010, Proceedings of the 19th international conference on World Wide Web, WWW '10, P51
   Barrett AW, 2005, POLIT RES QUART, V58, P609, DOI 10.1177/106591290505800408
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI 10.1191/1478088706qp063oa
   Bycoffe A., 2018, The New York Times
   Bycoffe A., 2018, Five ThirtyEight
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Byrne L, 2016, IEEE T VIS COMPUT GR, V22, P509, DOI 10.1109/TVCG.2015.2467321
   Caple H, 2012, VISUAL COMMUN-US, V11, P207, DOI 10.1177/1470357211434032
   Cawthon N, 2007, IEEE INT CONF INF VI, P637
   CHILDERS TL, 1984, J CONSUM RES, V11, P643, DOI 10.1086/209001
   Cockburn A., 2006, Proceedings of the ACM CHI Conference on Human Factors in Computing Systems, P1
   Correll M., 2020, P ACM C HUM FACT COM, P1
   Curran T, 2011, J COGNITIVE NEUROSCI, V23, P1247, DOI 10.1162/jocn.2010.21464
   Dziadosz S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P365
   Eastwood J., 2017, The Wall Street J.
   Grocer S., 2019, Five Thirty Eight
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hill S., 2017, P C INF SYST APPL RE
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Inbar Ohad, 2007, P 14 EUR C COGN ERG, P185, DOI DOI 10.1145/1362550.1362587
   Kaasten S, 2002, BCS CONF SERIES, P247
   Kelly J. D, 1988, P ANN M ASS ED JOURN, P1
   Kennedy H., 2020, Data Vis. Soc., V11, P169, DOI [10.2307/j.ctvzgb8c7.17, DOI 10.1515/9789048543137-015]
   Kim H, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P116, DOI [10.1109/visual.2019.8933773, 10.1109/VISUAL.2019.8933773]
   Knox J.S., 2009, SOC SEMIOT, V19, P165
   Knox JS, 2009, DISCOURSE COMMUN, V3, P145, DOI 10.1177/1750481309102450
   Koerth M., 2018, Five Thirty Eight
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Kosara R, 2016, IEEE COMPUT GRAPH, V36, P80, DOI 10.1109/MCG.2016.2
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kruschke J., 2014, Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, V2nd
   Lam Heidi., 2005, P SIGCHI C HUMAN FAC, P681
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Li Z., 2008, Proceeding of the 17th international conference on World Wide Web, WWW '08, P21, DOI DOI 10.1145/1367497.1367501
   Matejka J., 2013, P SIGCHI C HUM FACT, P1159
   McBride DM, 2002, CONSCIOUS COGN, V11, P423, DOI 10.1016/S1053-8100(02)00007-7
   Moere AV, 2011, INFORM VISUAL, V10, P356, DOI 10.1177/1473871611415996
   Nguyen PH, 2016, IEEE CONF VIS ANAL, P91, DOI 10.1109/VAST.2016.7883515
   Norman D. A., 2007, Interactions, V14, P40
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Phillips O., 2018, Five Thirty Eight
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Ritchie J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300423
   Robertson G., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P153, DOI 10.1145/288392.288596
   Roeder O., 2018, Five ThirtyEight
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   SHEPARD RN, 1967, J VERB LEARN VERB BE, V6, P156, DOI 10.1016/S0022-5371(67)80067-7
   SIMKIN D, 1987, J AM STAT ASSOC, V82, P454, DOI 10.2307/2289447
   Skau D, 2015, COMPUT GRAPH FORUM, V34, P221, DOI 10.1111/cgf.12634
   Smith A, 2019, Majorities of Americans find it unacceptable to use algorithms to make decisions with real-world consequences for humans
   Song YL, 2016, Arxiv, DOI arXiv:1609.01388
   Stolper C.D., 2018, Data-Driven Storytelling
   Suh B., 2003, P ANN ACM S US INT S, P95
   T. E. Team, 2018, The Economist
   Teevan J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2023
   The New York Times, 2018, The New York Times
   The New York Times' Upshot, 2018, The New York Times
   Topkara M., 2012, P ACM C HUM FACT COM, P565
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Whitehouse AJO, 2006, BRIT J DEV PSYCHOL, V24, P767, DOI 10.1348/026151005X74153
   Woodruff A., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P198, DOI 10.1145/365024.365098
   Yangandul C, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204571
   Yao G, 1999, BRIT J MATH STAT PSY, V52, P79, DOI 10.1348/000711099158973
   Yoghourdjian V, 2018, IEEE T VIS COMPUT GR, V24, P3081, DOI 10.1109/TVCG.2018.2790961
NR 78
TC 0
Z9 0
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4825
EP 4840
DI 10.1109/TVCG.2023.3278304
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400043
PM 37216254
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Liu, Z
   Zhao, YW
   Zhan, SJ
   Liu, YY
   Chen, RJ
   He, Y
AF Liu, Zheng
   Zhao, Yaowu
   Zhan, Sijing
   Liu, Yuanyuan
   Chen, Renjie
   He, Ying
TI PCDNF: Revisiting Learning-Based Point Cloud Denoising via Joint Normal
   Filtering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Noise reduction; Point cloud compression; Task analysis; Noise
   measurement; Feature extraction; Three-dimensional displays; Computer
   architecture; Point cloud denoising; normal filtering; 3D deep learning;
   point cloud processing
AB Point cloud denoising is a fundamental and challenging problem in geometry processing. Existing methods typically involve direct denoising of noisy input or filtering raw normals followed by point position updates. Recognizing the crucial relationship between point cloud denoising and normal filtering, we re-examine this problem from a multitask perspective and propose an end-to-end network called PCDNF for joint normal filtering-based point cloud denoising. We introduce an auxiliary normal filtering task to enhance the network's ability to remove noise while preserving geometric features more accurately. Our network incorporates two novel modules. First, we design a shape-aware selector to improve noise removal performance by constructing latent tangent space representations for specific points, taking into account learned point and normal features as well as geometric priors. Second, we develop a feature refinement module to fuse point and normal features, capitalizing on the strengths of point features in describing geometric details and normal features in representing geometric structures, such as sharp edges and corners. This combination overcomes the limitations of each feature type and better recovers geometric information. Extensive evaluations, comparisons, and ablation studies demonstrate that the proposed method outperforms state-of-the-art approaches in both point cloud denoising and normal filtering.
C1 [Liu, Zheng; Zhao, Yaowu; Liu, Yuanyuan] China Univ Geosci Wuhan, Sch Comp Sci, Wuhan 430079, Peoples R China.
   [Zhan, Sijing] China Univ Geosci Wuhan, Natl Engn Res Ctr Geog Informat Syst, Wuhan 430079, Peoples R China.
   [Liu, Yuanyuan] China Univ Geosci Wuhan, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430079, Peoples R China.
   [Chen, Renjie] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
C3 China University of Geosciences; China University of Geosciences; China
   University of Geosciences; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; Nanyang Technological University
RP Chen, RJ (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.
EM liu.zheng.jojo@gmail.com; 912626756@qq.com; 1585730049@qq.com;
   liuyy@cug.edu.cn; renjiec@ustc.edu.cn; yhe@ntu.edu.sg
RI chen, renjie/I-5995-2016
OI chen, renjie/0000-0001-8395-4392; Liu, Zheng/0000-0001-6713-6680
FU National Key R#x0026;D Program of China [2022YFB3904100]; NSF of China
   [62072422, 62076227]; NSF of Anhui Province [2008085MF195];
   Collaborative Innovation Center for Natural Resources Planning and
   Marine Technology of Guangzhou [2023B04J0301]; Key-Area Research and
   Development Program of Guangdong Province [2020B0101130009]; Ministry of
   Education, Singapore [MOE-T2EP20220-000, RT19/22]
FX No Statement Available
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Amenta N, 2004, ACM T GRAPHIC, V23, P264, DOI 10.1145/1015706.1015713
   [Anonymous], 2022, Int. J. Comput.Vis., V130, P615
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Ben-Shabat Yizhak, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P20, DOI 10.1007/978-3-030-58452-8_2
   Ben-Shabat Y, 2019, PROC CVPR IEEE, P10104, DOI 10.1109/CVPR.2019.01035
   Cao JJ, 2022, IEEE T IND ELECTRON, V69, P921, DOI 10.1109/TIE.2021.3053904
   Cazals F, 2005, COMPUT AIDED GEOM D, V22, P121, DOI 10.1016/j.cagd.2004.09.004
   Chen HL, 2023, IEEE T PATTERN ANAL, V45, P2913, DOI 10.1109/TPAMI.2022.3175183
   Chen HH, 2019, COMPUT AIDED DESIGN, V115, P122, DOI 10.1016/j.cad.2019.05.036
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Digne J, 2018, IEEE T VIS COMPUT GR, V24, P2238, DOI 10.1109/TVCG.2017.2719024
   Edirimuni DD, 2023, PROC CVPR IEEE, P13530, DOI 10.1109/CVPR52729.2023.01300
   Edirimuni de Silva, IEEE Trans.Vis. Comput. Graph., DOI [10.1109/TVCG.2023.3263866.41M., DOI 10.1109/TVCG.2023.3263866.41M]
   Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   He K., 2015, ICCV, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   Hou F, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530096
   Hu W, 2020, IEEE T SIGNAL PROCES, V68, P2841, DOI 10.1109/TSP.2020.2978617
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276405, 10.1145/1239451.1239473]
   Liu SL, 2021, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR46437.2021.00183
   Liu Z, 2022, IEEE T VIS COMPUT GR, V28, P4418, DOI 10.1109/TVCG.2021.3088118
   Liu Z, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102857
   Lu DN, 2020, COMPUT AIDED DESIGN, V125, DOI 10.1016/j.cad.2020.102860
   Lu XQ, 2022, IEEE T VIS COMPUT GR, V28, P1835, DOI 10.1109/TVCG.2020.3026785
   Lu XQ, 2018, IEEE T VIS COMPUT GR, V24, P2315, DOI 10.1109/TVCG.2017.2725948
   Luo ST, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1330, DOI 10.1145/3394171.3413727
   Luo Shitong, 2021, P IEEECVF INT C COMP, P4583
   Mattei E, 2017, COMPUT GRAPH FORUM, V36, P123, DOI 10.1111/cgf.13068
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pistilli Francesca, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P103, DOI 10.1007/978-3-030-58565-5_7
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Qi CR, 2017, ADV NEUR IN, V30
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Roveri R, 2018, COMPUT GRAPH FORUM, V37, P87, DOI 10.1111/cgf.13344
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Sharma R, 2021, Arxiv, DOI arXiv:2102.13391
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sun C., 2022, Comput-AidedDes., V149, P28
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Wang JX, 2022, COMPUT AIDED DESIGN, V144, DOI 10.1016/j.cad.2021.103162
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wei MQ, 2023, IEEE T VIS COMPUT GR, V29, P1357, DOI 10.1109/TVCG.2021.3113463
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhang J, 2022, COMPUT AIDED DESIGN, V142, DOI 10.1016/j.cad.2021.103119
   Zhang JY, 2022, IEEE T PATTERN ANAL, V44, P3450, DOI 10.1109/TPAMI.2021.3054619
   Zhou HR, 2023, IEEE T PATTERN ANAL, V45, P946, DOI 10.1109/TPAMI.2022.3145877
   Zhou J, 2022, COMPUT AIDED DESIGN, V142, DOI 10.1016/j.cad.2021.103121
   Zhou J, 2020, COMPUT AIDED DESIGN, V129, DOI 10.1016/j.cad.2020.102916
   Zhou L, 2022, GRAPH MODELS, V121, DOI 10.1016/j.gmod.2022.101140
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zhu Runsong, 2021, P IEEE CVF INT C COM, P6118
NR 59
TC 5
Z9 5
U1 2
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5419
EP 5436
DI 10.1109/TVCG.2023.3292464
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400013
PM 37405886
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhang, PZ
   Yang, LX
   Xie, XH
   Lai, JH
AF Zhang, Pengze
   Yang, Lingxiao
   Xie, Xiaohua
   Lai, Jianhuang
TI Pose Guided Person Image Generation Via Dual-Task Correlation and
   Affinity Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Correlation; Semantics; Image synthesis; Transformers;
   Three-dimensional displays; Training; Generative adversarial networks;
   neural rendering; person image generation; pose transfer; view synthesis
AB Pose Guided Person Image Generation (PGPIG) is the task of transforming a person's image from the source pose to a target pose. Existing PGPIG methods often tend to learn an end-to-end transformation between the source image and the target image, but do not seriously consider two issues: 1) the PGPIG is an ill-posed problem, and 2) the texture mapping requires effective supervision. In order to alleviate these two challenges, we propose a novel method by incorporating Dual-task Pose Transformer Network and Texture Affinity learning mechanism (DPTN-TA). To assist the ill-posed source-to-target task learning, DPTN-TA introduces an auxiliary task, i.e., source-to-source task, by a Siamese structure and further explores the dual-task correlation. Specifically, the correlation is built by the proposed Pose Transformer Module (PTM), which can adaptively capture the fine-grained mapping between sources and targets and can promote the source texture transmission to enhance the details of the generated images. Moreover, we propose a novel texture affinity loss to better supervise the learning of texture mapping. In this way, the network is able to learn complex spatial transformations effectively. Extensive experiments show that our DPTN-TA can produce perceptually realistic person images under significant pose changes. Furthermore, our DPTN-TA is not limited to processing human bodies but can be flexibly extended to view synthesis of other objects, i.e., faces and chairs, outperforming the state-of-the-arts in terms of both LPIPS and FID. Our code is available at: https://github.com/PangzeCheung/Dual-task-Pose-Transformer-Network.
C1 [Zhang, Pengze; Xie, Xiaohua] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Zhang, Pengze; Yang, Lingxiao; Xie, Xiaohua; Lai, Jianhuang] Sun Yat Sen Univ, Guangzhou 510006, Peoples R China.
   [Zhang, Pengze; Yang, Lingxiao; Xie, Xiaohua; Lai, Jianhuang] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen University
RP Xie, XH (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.; Xie, XH (corresponding author), Sun Yat Sen Univ, Guangzhou 510006, Peoples R China.
EM zhangpz3@mail2.sysu.edu.cn; yanglx9@mail.sysu.edu.cn;
   xiexiaoh6@mail.sysu.edu.cn; stsljh@mail.sysu.edu.cn
OI Xie, Xiaohua/0000-0002-0310-4679
FU National Natural Science Foundation of China [U22A2095, 62072482]
FX No Statement Available
CR Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231
   Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Albahar B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480559
   Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487
   Avidan S, 1998, IEEE T VIS COMPUT GR, V4, P293, DOI 10.1109/2945.765324
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen Y, 2016, IEEE T VIS COMPUT GR, V22, P2000, DOI 10.1109/TVCG.2015.2478779
   Clegg A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766986
   Deng QX, 2022, IEEE T VIS COMPUT GR, V28, P3113, DOI 10.1109/TVCG.2021.3051251
   Dosovitskiy A., 2020, PROC INT C LEARN RE, P1, DOI DOI 10.48550/ARXIV
   Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923
   Ge CJ, 2021, PROC CVPR IEEE, P16923, DOI 10.1109/CVPR46437.2021.01665
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Grigorev A, 2019, PROC CVPR IEEE, P12127, DOI 10.1109/CVPR.2019.01241
   Gross I., 2008, P IEEE INT C AUT FAC, P1
   Hao Tang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P717, DOI 10.1007/978-3-030-58595-2_43
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   He D., 2016, P ADV NEUR INF PROC, P820, DOI DOI 10.5555/3157096.3157188
   He LX, 2020, Arxiv, DOI arXiv:2006.02631
   Hensel M, 2017, ADV NEUR IN, V30
   Hudson Drew A, 2021, INT C ON MACH LEARN, P4487
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Jiang Y., 2021, arXiv, DOI DOI 10.48550/ARXIV.2102.07074
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, INT C LEARN REPR
   Lee M, 2021, IEEE T VIS COMPUT GR, V27, P3534, DOI 10.1109/TVCG.2019.2959575
   Li BY, 2019, ADV NEUR IN, V32
   Li WH, 2023, IEEE T MULTIMEDIA, V25, P1282, DOI 10.1109/TMM.2022.3141231
   Li YN, 2019, PROC CVPR IEEE, P3688, DOI 10.1109/CVPR.2019.00381
   Lin K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12919, DOI 10.1109/ICCV48922.2021.01270
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Ling Z. Wang, IEEE Trans. Visual. Comput. Graph., DOI [10.1109/TVCG.2022.3166666.12Q, DOI 10.1109/TVCG.2022.3166666.12Q]
   Liu LJ, 2021, IEEE T VIS COMPUT GR, V27, P4009, DOI 10.1109/TVCG.2020.2996594
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lv ZY, 2021, PROC CVPR IEEE, P10801, DOI 10.1109/CVPR46437.2021.01066
   Ma LQ, 2017, ADV NEUR IN, V30
   Men YF, 2020, PROC CVPR IEEE, P5083, DOI 10.1109/CVPR42600.2020.00513
   Mingyu Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P87, DOI 10.1007/978-3-030-58604-1_6
   Miyato Takeru, 2018, ICLR
   Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8
   Rematas K, 2017, IEEE T PATTERN ANAL, V39, P1576, DOI 10.1109/TPAMI.2016.2601093
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, DOI 10.48550/ARXIV.1706.05098]
   Sarkar Kripasindhu., 2021, arXiv
   Shi DH, 2022, PROC CVPR IEEE, P11059, DOI 10.1109/CVPR52688.2022.01079
   Shu YZ, 2022, IEEE T VIS COMPUT GR, V28, P3376, DOI 10.1109/TVCG.2021.3067201
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun SH, 2018, LECT NOTES COMPUT SC, V11207, P162, DOI 10.1007/978-3-030-01219-9_10
   Tabejamaat F., 2021, BRIT MACH VIS C, P1
   Tian Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P942
   Touvron H, 2021, Arxiv, DOI [arXiv:2012.12877, 10.48550/arXiv.2012.12877]
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y., 2019, INT C LEARN REPR
   Wang YJ, 2018, AAAI CONF ARTIF INTE, P5553
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu XG, 2019, IEEE I CONF COMP VIS, P7790, DOI 10.1109/ICCV.2019.00788
   Xu Y., 2022, P ADV NEUR INF PROC, P1
   Yin M., 2021, P IEEE CVF C COMP VI, P7220
   Yurui Ren, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7687, DOI 10.1109/CVPR42600.2020.00771
   Zeng YH, 2023, IEEE T VIS COMPUT GR, V29, P3266, DOI 10.1109/TVCG.2022.3156949
   Zhang JS, 2021, PROC CVPR IEEE, P7978, DOI 10.1109/CVPR46437.2021.00789
   Zhang PZ, 2022, PROC CVPR IEEE, P7703, DOI 10.1109/CVPR52688.2022.00756
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhou YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2054, DOI 10.1109/ICCV48922.2021.00208
   Zhu X., 2021, ICLR, P1, DOI DOI 10.48550/ARXIV.2010.04159
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
NR 74
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5111
EP 5128
DI 10.1109/TVCG.2023.3286394
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400097
PM 37318966
DA 2024-08-05
ER

PT J
AU Zhou, WY
   Yuan, L
   Chen, SY
   Gao, L
   Hu, SM
AF Zhou, Wen-Yang
   Yuan, Lu
   Chen, Shu-Yu
   Gao, Lin
   Hu, Shi-Min
TI LC-NeRF: Local Controllable Face Generation in Neural Radiance Field
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geometry; Faces; Three-dimensional displays; Generators; Semantics;
   Codes; Controllability; 3D face generation; neural radiance fields;
   semantic manipulation
AB 3D face generation has achieved high visual quality and 3D consistency thanks to the development of neural radiance fields (NeRF). However, these methods model the whole face as a neural radiance field, which limits the controllability of the local regions. In other words, previous methods struggle to independently control local regions, such as the mouth, nose, and hair. To improve local controllability in NeRF-based face generation, we propose LC-NeRF, which is composed of a Local Region Generators Module (LRGM) and a Spatial-Aware Fusion Module (SAFM), allowing for geometry and texture control of local facial regions. The LRGM models different facial regions as independent neural radiance fields and the SAFM is responsible for merging multiple independent neural radiance fields into a complete representation. Finally, LC-NeRF enables the modification of the latent code associated with each individual generator, thereby allowing precise control over the corresponding local region. Qualitative and quantitative evaluations show that our method provides better local controllability than state-of-the-art 3D-aware face generation methods. A perception study reveals that our method outperforms existing state-of-the-art methods in terms of image quality, face consistency, and editing effects. Furthermore, our method exhibits favorable performance in downstream tasks, including real image editing and text-driven facial image editing.
C1 [Zhou, Wen-Yang; Hu, Shi-Min] Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
   [Yuan, Lu] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   [Chen, Shu-Yu; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing 100045, Peoples R China.
C3 Tsinghua University; Stanford University; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Hu, SM (corresponding author), Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
EM zhouwy19@mails.tsinghua.edu.cn; luyuan@stanford.edu;
   chenshuyu@ict.ac.cn; gaolin@ict.ac.cn; shimin@tsinghua.edu.cn
OI Hu, Shi-Min/0000-0001-7507-6542
FU National Key R&D Program of China [2021ZD0112902]; Natural Science
   Foundation of China [62220106003]; Research Grant of Beijing Higher
   Institution Engineering Research Center; Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2021ZD0112902, in part by the Natural Science Foundation of
   China under Grant 62220106003, in part by the Research Grant of Beijing
   Higher Institution Engineering Research Center and Tsinghua-Tencent
   Joint Laboratory for Internet Innovation Technology.
CR Chan Eric R, 2021, arXiv
   Chen AP, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3470848
   Chen SY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459760
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Deng Y, 2022, PROC CVPR IEEE, P10663, DOI 10.1109/CVPR52688.2022.01041
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gropp A, 2020, Arxiv, DOI arXiv:2002.10099
   Gu JT, 2021, Arxiv, DOI arXiv:2110.08985
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   Jiang K, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555377
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2021, ADV NEUR IN, V34
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D. P., 2014, arXiv
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   OrEl R, 2022, PROC CVPR IEEE, P13493, DOI 10.1109/CVPR52688.2022.01314
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Portenier T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201393
   Chan ER, 2021, Arxiv, DOI arXiv:2012.00926
   Roich D, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3544777
   Shi YC, 2022, PROC CVPR IEEE, P11244, DOI 10.1109/CVPR52688.2022.01097
   Shuyang Gu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3431, DOI 10.1109/CVPR.2019.00355
   Sitzmann V, 2020, Adv. Neural. Inf. Process. Syst, V33, P7462
   Sun JX, 2022, PROC CVPR IEEE, P7662, DOI 10.1109/CVPR52688.2022.00752
   Sun Jingxiang, 2022, arXiv
   Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2
   ZHOu S., 2022, ADV NEURAL INF PROCE, P30599
   Zhu PH, 2021, Arxiv, DOI arXiv:2012.09036
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
NR 31
TC 1
Z9 1
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5437
EP 5448
DI 10.1109/TVCG.2023.3293653
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400031
PM 37459257
DA 2024-08-05
ER

PT J
AU Zhuang, JF
   Zeng, P
   Zhuang, W
   Guo, XY
   Liu, PZ
AF Zhuang, Jiafu
   Zeng, Pan
   Zhuang, Wei
   Guo, Xiaoyu
   Liu, Peizhong
TI Supervertex Sampling Network: A Geodesic Differential SLIC Approach for
   3D Mesh
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Clustering algorithms; Shape; Task analysis;
   Manifolds; Deep learning; Training; 3D mesh segmentation; 3D shape
   learning; deep clustering; graph neural network
ID SEGMENTATION
AB The analysis of 3D meshes with deep learning has become prevalent in computer graphics. As an essential structure, hierarchical representation is critical for mesh pooling in multiscale analysis. Existing clustering-based mesh hierarchy construction methods involve nonlinear discretization optimization operations, making them nondifferential and challenging to embed in other trainable networks for learning. Inspired by deep superpixel learning methods in image processing, we extend them from 2D images to 3D meshes by proposing a novel differentiable chart-based segmentation method named geodesic differential supervertex (GDSV). The key to the GDSV method is to ensure that the geodesic position updates are differentiable while satisfying the constraint that the renewed supervertices lie on the manifold surface. To this end, in addition to using the differential SLIC clustering algorithm to update the nonpositional features of the supervertices, a reparameterization trick, the Gumbel-Softmax trick, is employed to renew the geodesic positions of the supervertices. Therefore, the geodesic position update problem is converted into a linear matrix multiplication issue. The GDSV method can be an independent module for chart-based segmentation tasks. Meanwhile, it can be combined with the front-end feature learning network and the back-end task-specific network as a plug-in-plug-out module for training; and be applied to tasks such as shape classification, part segmentation, and 3D scene understanding. Experimental results show the excellent performance of our proposed algorithm on a range of datasets.
C1 [Zhuang, Jiafu] Quanzhou Normal Univ, Sch Phys & Informat Engn, Quanzhou 362000, Fujian, Peoples R China.
   [Zeng, Pan] Huaqiao Univ, Sch Med, Quanzhou 362021, Fujian, Peoples R China.
   [Zhuang, Wei] Univ Manchester, Dept Social Stat, Manchester M13 9PL, England.
   [Guo, Xiaoyu] Quanzhou Normal Univ, Coll Oceanol & Food Sci, Quanzhou 362000, Fujian, Peoples R China.
   [Liu, Peizhong] Huaqiao Univ, Coll Engn, Quanzhou 362021, Fujian, Peoples R China.
   [Liu, Peizhong] Quanzhou Med Coll, Sch Med, Quanzhou 362021, Fujian, Peoples R China.
C3 Quanzhou Normal University; Huaqiao University; University of
   Manchester; Quanzhou Normal University; Huaqiao University
RP Liu, PZ (corresponding author), Huaqiao Univ, Coll Engn, Quanzhou 362021, Fujian, Peoples R China.; Liu, PZ (corresponding author), Quanzhou Med Coll, Sch Med, Quanzhou 362021, Fujian, Peoples R China.
EM jfzhuang001@qq.com; 954181775@qq.com;
   wei.zhuang-2@postgrad.manchester.ac.uk; guoxiaoyu@qztc.edu.cn;
   pzliu@hqu.edu.cn
OI zhuang, jiafu/0000-0001-6072-2679; Liu, Peizhong/0000-0001-8785-0195
FU Education and Scientific Research Project for Middle-Aged and Young
   Teachers of Fujian Province [JAT210302, JAT210314]; Innovation and
   Entrepreneurship Project for College Students [202110399024]; Fujian
   Provincial Science and Technology Major Project [2020HZ02014]; Fujian
   Province Science and Technology Program of China [2021H0053]; Quanzhou
   Science and Technology Major Project [2021GZ1]; Quanzhou City Science
   and Technology Program of China [2020C019R, 2021C031R]
FX No Statement Available
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Ben Izhak R, 2022, IEEE WINT CONF APPL, P2937, DOI 10.1109/WACV51458.2022.00299
   Boscaini D, 2016, ADV NEUR IN, V29
   Cangea C, 2018, Arxiv, DOI arXiv:1811.01287
   Chang AE, 2017, Arxiv, DOI arXiv:1709.06158
   Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28
   Defferrard M, 2016, ADV NEUR IN, V29
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398
   Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, DOI 10.48550/ARXIV.1903.02428]
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Guo K, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2835487
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Hoppe H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P189, DOI 10.1145/258734.258843
   Hu RZ, 2012, COMPUT GRAPH FORUM, V31, P1703, DOI 10.1111/j.1467-8659.2012.03175.x
   Hu SM, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3506694
   HU ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15468, DOI 10.1109/ICCV48922.2021.01520
   Huang JW, 2018, Arxiv, DOI arXiv:1802.01698
   Huang JW, 2019, PROC CVPR IEEE, P4435, DOI 10.1109/CVPR.2019.00457
   Maddison CJ, 2017, Arxiv, DOI arXiv:1611.00712
   Jampani V, 2018, LECT NOTES COMPUT SC, V11211, P363, DOI 10.1007/978-3-030-01234-2_22
   Jiao X, 2023, COMPUT AIDED DESIGN, V160, DOI 10.1016/j.cad.2023.103512
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kim J, 2007, INT CONF ACOUST SPEE, P429
   Lahav A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417806
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li XJ, 2022, LECT NOTES COMPUT SC, V13689, P541, DOI 10.1007/978-3-031-19818-2_31
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Meny J, 2021, COMPUT AIDED GEOM D, V89, DOI 10.1016/j.cagd.2021.102025
   Milano F., 2020, Advances in Neural Information Processing Systems, P952
   Potamias RA, 2022, PROC CVPR IEEE, P18562, DOI 10.1109/CVPR52688.2022.01803
   Poulenard A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275102
   Purkait P, 2017, Arxiv, DOI [arXiv:1712.03452, DOI arXiv:1712.03452.null]
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qiao YL, 2022, IEEE T VIS COMPUT GR, V28, P1317, DOI 10.1109/TVCG.2020.3014449
   Rakotosaona MJ, 2021, PROC CVPR IEEE, P22, DOI 10.1109/CVPR46437.2021.00009
   Rakotosaona MJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480554
   Ranjan E, 2020, AAAI CONF ARTIF INTE, V34, P5470
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Schult Jonas, 2020, P IEEE CVF C COMP VI, P8612, DOI DOI 10.1109/CVPR42600.2020.00864
   Sethian JA, 2000, P NATL ACAD SCI USA, V97, P5699, DOI 10.1073/pnas.090060097
   Shapira L, 2010, INT J COMPUT VISION, V89, P309, DOI 10.1007/s11263-009-0279-0
   Smirnov D., 2022, Ph.D. dissertation
   Smirnov D, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459797
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Su JC, 2019, LECT NOTES COMPUT SC, V11131, P645, DOI 10.1007/978-3-030-11015-4_49
   Sun CY, 2023, COMPUT VIS MEDIA, V9, P229, DOI 10.1007/s41095-022-0281-9
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   Toth C.D., 2017, Handbook of Discrete and Computational Geometry
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wiersma R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530166
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   Ying R, 2018, ADV NEUR IN, V31
   Zhu L, 2021, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR46437.2021.00128
NR 70
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5553
EP 5565
DI 10.1109/TVCG.2023.3294845
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400067
PM 37440384
DA 2024-08-05
ER

PT J
AU Fukuoka, M
   Nakamura, F
   Verhulst, A
   Inami, M
   Kitazaki, M
   Sugimoto, M
AF Fukuoka, Masaaki
   Nakamura, Fumihiko
   Verhulst, Adrien
   Inami, Masahiko
   Kitazaki, Michiteru
   Sugimoto, Maki
TI Sensory Attenuation With a Virtual Robotic Arm Controlled Using Facial
   Movements
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Manipulators; Robot sensing systems; Rubber; Cognition; Virtual
   environments; Task analysis; Standards; Sensory attenuation; human
   augmentation; robotic arm; virtual reality
ID SELF-INITIATED SOUNDS; BODY OWNERSHIP; INTERNAL-MODEL; AUDITORY ERPS;
   AGENCY; INTEGRATION; PERCEPTION; AWARENESS; HEARING; SPEECH
AB When humans generate stimuli voluntarily, they perceive the stimuli more weakly than those produced by others, which is called sensory attenuation (SA). SA has been investigated in various body parts, but it is unclear whether an extended body induces SA. This study investigated the SA of audio stimuli generated by an extended body. SA was assessed using a sound comparison task in a virtual environment. We prepared robotic arms as extended bodies, and the robotic arms were controlled by facial movements. To evaluate the SA of robotic arms, we conducted two experiments. Experiment 1 investigated the SA of the robotic arms under four conditions. The results showed that robotic arms manipulated by voluntary actions attenuated audio stimuli. Experiment 2 investigated the SA of the robotic arm and innate body under five conditions. The results indicated that the innate body and robotic arm induced SA, while there were differences in the sense of agency between the innate body and robotic arm. Analysis of the results indicated three findings regarding the SA of the extended body. First, controlling the robotic arm with voluntary actions in a virtual environment attenuates the audio stimuli. Second, there were differences in the sense of agency related to SA between extended and innate bodies. Third, the SA of the robotic arm was correlated with the sense of body ownership.
C1 [Fukuoka, Masaaki; Nakamura, Fumihiko; Sugimoto, Maki] Keio Univ, Fac Sci & Technol, Tokyo 1088345, Japan.
   [Verhulst, Adrien] Keio Univ, Sony Comp Sci Labs, Tokyo 1088345, Japan.
   [Inami, Masahiko] Univ Tokyo, Dept Adv Interdisciplinary Studies, Tokyo 1138654, Japan.
   [Kitazaki, Michiteru] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi 4418580, Japan.
C3 Keio University; Keio University; University of Tokyo; Toyohashi
   University of Technology
RP Fukuoka, M (corresponding author), Keio Univ, Fac Sci & Technol, Tokyo 1088345, Japan.
EM mskifukuoka@imlab.ics.keio.ac.jp; f.nakamura@imlab.ics.keio.ac.jp;
   adrien.verhulst@imlab.ics.keio.ac.jp; inami@star.rcast.u-tokyo.ac.jp;
   mich@tut.jp; sugimoto@imlab.ics.keio.ac.jp
OI Nakamura, Fumihiko/0000-0001-6285-3963; INAMI,
   MASAHIKO/0000-0002-8652-0730; Fukuoka, Masaaki/0000-0001-7892-4623;
   Kitazaki, Michiteru/0000-0003-0966-4842
FU JST ERATO [JP-MJER1701]
FX This project was supported by JST ERATO under Grant JP-MJER1701.
CR Abdi E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134501
   Baess P, 2011, PSYCHOPHYSIOLOGY, V48, P1276, DOI 10.1111/j.1469-8986.2011.01196.x
   Bashford L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156591
   Bien Z, 2004, AUTON ROBOT, V16, P165, DOI 10.1023/B:AURO.0000016864.12513.77
   Blakemore SJ, 2000, NEUROREPORT, V11, pR11, DOI 10.1097/00001756-200008030-00002
   Blakemore SJ, 1999, J COGNITIVE NEUROSCI, V11, P551, DOI 10.1162/089892999563607
   Bock R.D., 1968, The measurement and prediction of judgment and choice
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Burin D, 2017, J ADV RES, V8, P649, DOI 10.1016/j.jare.2017.08.001
   Burin D, 2017, COGNITION, V166, P164, DOI 10.1016/j.cognition.2017.05.035
   Cardoso-Leite P, 2010, PSYCHOL SCI, V21, P1740, DOI 10.1177/0956797610389187
   Desantis A, 2014, COGNITION, V132, P243, DOI 10.1016/j.cognition.2014.04.010
   Dewey JA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110118
   Divenyi PL, 1997, EAR HEARING, V18, P42, DOI 10.1097/00003446-199702000-00005
   Dogge M, 2019, TRENDS COGN SCI, V23, P743, DOI 10.1016/j.tics.2019.06.008
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fitts P., 1964, CATEGORIES HUM LEARN, P243, DOI DOI 10.1016/B978-1-48323145-7.50016-9
   FRANCIS BA, 1976, AUTOMATICA, V12, P457, DOI 10.1016/0005-1098(76)90006-6
   Frith CD, 2000, PHILOS T R SOC B, V355, P1771, DOI 10.1098/rstb.2000.0734
   Fritsch A, 2021, CONSCIOUS COGN, V88, DOI 10.1016/j.concog.2020.103073
   Fukuoka M., 2020, Trans. Virtual Reality Soc. Jpn., V25, P451
   Fukuoka M, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P9, DOI 10.1145/3355355.3361888
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Guterstam A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017208
   Hesse MD, 2010, CEREB CORTEX, V20, P425, DOI 10.1093/cercor/bhp110
   Horváth J, 2013, BIOL PSYCHOL, V93, P81, DOI 10.1016/j.biopsycho.2012.12.008
   Horváth J, 2013, PSYCHOPHYSIOLOGY, V50, P266, DOI 10.1111/psyp.12009
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Humes LE, 2009, ATTEN PERCEPT PSYCHO, V71, P860, DOI 10.3758/APP.71.4.860
   Hussain I, 2017, INT C REHAB ROBOT, P1177, DOI 10.1109/ICORR.2017.8009409
   Imamizu H, 2012, CEREBELLUM, V11, P325, DOI 10.1007/s12311-010-0241-2
   Inamura T, 2017, ADV ROBOTICS, V31, P97, DOI 10.1080/01691864.2016.1264885
   International Organization for Standardization, 2023, ISO 226:2003
   Jazbec M, 2017, IEEE SYS MAN CYBERN, P1471, DOI 10.1109/SMC.2017.8122821
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   KAWATO M, 1987, BIOL CYBERN, V57, P169, DOI 10.1007/BF00364149
   Kilteni K, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.100843
   Kilteni K, 2019, ELIFE, V8, DOI 10.7554/eLife.42888
   Kilteni K, 2017, P NATL ACAD SCI USA, V114, P8426, DOI 10.1073/pnas.1703347114
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Klaffehn AL, 2019, NEUROPSYCHOLOGIA, V132, DOI 10.1016/j.neuropsychologia.2019.107145
   Laak KJ, 2017, NEUROSCI CONSCIOUS, V3, DOI 10.1093/nc/niw025
   Lindquist K, 2008, ADV PSYCHOL, V139, P167
   Ma K, 2015, CONSCIOUS COGN, V36, P277, DOI 10.1016/j.concog.2015.07.008
   Maindonald J., 2003, DATA ANAL GRAPHICS U, V2nd
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4
   Mifsud NG, 2017, NEUROPSYCHOLOGIA, V103, P38, DOI 10.1016/j.neuropsychologia.2017.07.019
   Nakamura T., 2021, Determine the subjective point of equivalence (PSE) using R
   Newport R, 2010, EXP BRAIN RES, V204, P385, DOI 10.1007/s00221-009-2104-y
   Oppenheimer DM, 2009, J EXP SOC PSYCHOL, V45, P867, DOI 10.1016/j.jesp.2009.03.009
   OUCHI T, 1994, ACTA OTO-LARYNGOL, P89
   Paillard J., 1993, The use of tools by human and non-human primates, P36
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pyasik M, 2021, NEUROIMAGE, V229, DOI 10.1016/j.neuroimage.2021.117727
   Reznik D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127651
   Rosa N, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3341225
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Sasaki T., 2017, P ACM SIGGRAPH EM TE, DOI DOI 10.1145/3084822.3084837
   Sato A, 2008, CONSCIOUS COGN, V17, P1219, DOI 10.1016/j.concog.2008.01.003
   Sato Y, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.172170
   Schwarz KA, 2018, J EXP PSYCHOL GEN, V147, P418, DOI 10.1037/xge0000353
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   United States Department of Labor, 2023, Calculations and application of age corrections to audiograms
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Watt R.J., 1981, CURRENT PSYCHOL REV, V1, P205
   Wei Wang, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1733, DOI 10.1109/ROBIO.2012.6491218
   Weiss C, 2011, COGNITION, V121, P207, DOI 10.1016/j.cognition.2011.06.011
   Weller L, 2017, BIOL PSYCHOL, V123, P241, DOI 10.1016/j.biopsycho.2016.12.015
   Wolpe N, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13034
   Wolpert DM, 2000, NAT NEUROSCI, V3, P1212, DOI 10.1038/81497
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
   Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 75
TC 0
Z9 0
U1 7
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4023
EP 4038
DI 10.1109/TVCG.2023.3246092
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700042
PM 37027567
DA 2024-08-05
ER

PT J
AU Hoang, D
   Bhatia, H
   Lindstrom, P
   Pascucci, V
AF Hoang, Duong
   Bhatia, Harsh
   Lindstrom, Peter
   Pascucci, Valerio
TI Progressive Tree-Based Compression of Large-Scale Particle Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Encoding; Decoding; Image reconstruction; Data models; Computational
   modeling; Compressors; Task analysis; Coarse approximation; compression
   (coding); data compaction and compression; hierarchical;
   multiresolution; particle datasets; progressive decompression; tree
   traversal; visualization
ID POINT CLOUDS; MOLECULAR-DYNAMICS; SELF-SIMILARITY; FRAMEWORK; EFFICIENT;
   SURFACES; SCHEME; SYSTEM
AB Scientific simulations and observations using particles have been creating large datasets that require effective and efficient data reduction to store, transfer, and analyze. However, current approaches either compress only small data well while being inefficient for large data, or handle large data but with insufficient compression. Toward effective and scalable compression/decompression of particle positions, we introduce new kinds of particle hierarchies and corresponding traversal orders that quickly reduce reconstruction error while being fast and low in memory footprint. Our solution to compression of large-scale particle data is a flexible block-based hierarchy that supports progressive, random-access, and error-driven decoding, where error estimation heuristics can be supplied by the user. For low-level node encoding, we introduce new schemes that effectively compress both uniform and densely structured particle distributions. Our proposed methods thus target all three phases of a tree-based particle compression pipeline, namely tree construction, tree traversal, and node encoding. The improved efficacy and flexibility of these methods over existing compressors are demonstrated through extensive experimentation, using a wide range of scientific particle datasets.
C1 [Hoang, Duong; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
   [Bhatia, Harsh; Lindstrom, Peter] Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94550 USA.
C3 Utah System of Higher Education; University of Utah; United States
   Department of Energy (DOE); Lawrence Livermore National Laboratory
RP Hoang, D (corresponding author), Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
EM duong@sci.utah.edu; hbhatia@llnl.gov; pl@llnl.gov; pascucci@sci.utah.edu
RI pascucci, Valerio/GXF-0616-2022
OI pascucci, Valerio/0000-0002-8877-2042; Lindstrom,
   Peter/0000-0003-3817-4199; Hoang, Duong/0000-0003-4707-7198
FU U.S. Department of Energy (DOE) [DE-FE0031880]; Exascale Computing
   Project [17-SC-20-SC]; National Nuclear Security Administration; NSF OAC
   award [1842042, 1941085]; NSF CMMI award [1629660]; DOE
   [DE-AC52-07NA27344]; LLNL-LDRD Program [17-SI-004]
FX This work was supported in part by the U.S. Department of Energy
   (DOE)under Grant DE-FE0031880 and in part by the Exascale Computing
   Project under Grant 17-SC-20-SC, a collaborative effort of the DOE
   Office of Science and the National Nuclear Security Administration. This
   work was supported in part by the NSF OAC award under Grant 1842042, in
   part by the NSF OAC award under Grant 1941085, and in part by the NSF
   CMMI award under Grant 1629660. This work was also performed under the
   auspices of the DOE by Lawrence Livermore National Laboratory under
   Grant DE-AC52-07NA27344 and supported in part by the LLNL-LDRD Program
   under Project under Grant 17-SI-004.
CR Alexiou E, 2017, PROC SPIE, V10396, DOI 10.1117/12.2275142
   [Anonymous], 2016, Scientific visualization contest
   Berzins M, 2016, SIAM J SCI COMPUT, V38, pS101, DOI 10.1137/15M1023270
   Botsch M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P53
   Byna S., 2013, P CRAY US GROUP C
   Cai K., 2006, PROC ACM VIRTUAL REA, P83
   Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730
   Cirio G, 2010, GRAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P5
   Devillers O, 2000, IEEE VISUAL, P319, DOI 10.1109/VISUAL.2000.885711
   Digne J, 2014, COMPUT GRAPH FORUM, V33, P155, DOI 10.1111/cgf.12305
   Dodge Y., 2008, The concise encyclopedia of statistics
   Dovrat O, 2019, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2019.00287
   Draco, Geometric coding for dynamic voxelized point clouds
   Fan YX, 2013, ASIAPAC SIGN INFO PR
   Fleishman S, 2003, ACM T GRAPHIC, V22, P997, DOI 10.1145/944020.944023
   Fraedrich R, 2009, IEEE T VIS COMPUT GR, V15, P1251, DOI 10.1109/TVCG.2009.142
   Garcia DC, 2020, IEEE T IMAGE PROCESS, V29, P313, DOI 10.1109/TIP.2019.2931466
   github, MPEG-PCC-TMC13: Geometrybased point cloud compression
   Gobbetti E, 2004, COMPUT GRAPH-UK, V28, P815, DOI 10.1016/j.cag.2004.08.010
   Golla T, 2015, IEEE INT C INT ROBOT, P5087, DOI 10.1109/IROS.2015.7354093
   Goswami P, 2013, VISUAL COMPUT, V29, P69, DOI 10.1007/s00371-012-0675-2
   Grottel S, 2012, IEEE T VIS COMPUT GR, V18, P2061, DOI 10.1109/TVCG.2012.282
   Guarda AFR, 2021, IEEE J-STSP, V15, P415, DOI 10.1109/JSTSP.2020.3047520
   Gumhold S., 2005, ACM SIGGRAPH 2005 Sketches
   Habib S, 2016, NEW ASTRON, V42, P49, DOI 10.1016/j.newast.2015.06.003
   Hoang D., 2022, Progressive particle compression
   Hoang D, 2021, SYMP LARG DATA ANAL, P32, DOI 10.1109/LDAV53230.2021.00011
   Hoang D, 2021, IEEE T VIS COMPUT GR, V27, P603, DOI 10.1109/TVCG.2020.3030381
   Hopf M, 2004, IEEE COMPUT GRAPH, V24, P64, DOI 10.1109/MCG.2004.7
   Hosseini M, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P25, DOI 10.1145/3210424.3210429
   Huang LL, 2020, PROC CVPR IEEE, P1310, DOI 10.1109/CVPR42600.2020.00139
   Huang Y, 2008, IEEE T VIS COMPUT GR, V14, P440, DOI 10.1109/TVCG.2007.70441
   Hubo E, 2008, COMPUT GRAPH-UK, V32, P221, DOI 10.1016/j.cag.2008.01.012
   Hubo E, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P105
   Isenburg M, 2013, PHOTOGRAMM ENG REM S, V79, P209, DOI 10.14358/PERS.79.2.209
   Jin SA, 2020, INT PARALL DISTRIB P, P105, DOI 10.1109/IPDPS47924.2020.00021
   Khalil JE, 2017, COMPUT GRAPH FORUM, V36, P275, DOI 10.1111/cgf.12938
   Kim TJ, 2010, IEEE T VIS COMPUT GR, V16, P273, DOI 10.1109/TVCG.2009.71
   King D, 1999, COMP GEOM-THEOR APPL, V14, P91, DOI 10.1016/S0925-7721(99)00025-5
   Krivokuca M., 2018, ISO/IEC JTC1/SC29 WG11 (MPEG) input document m42914
   Krivokuca M, 2020, IEEE T IMAGE PROCESS, V29, P2217, DOI 10.1109/TIP.2019.2957853
   Krüger J, 2006, VISUAL COMPUT, V22, P517, DOI 10.1007/s00371-006-0026-2
   Lasserre S, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P145, DOI 10.1145/3304109.3306224
   Le Muzic Mathieu, 2015, Eurographics Workshop Vis Comput Biomed, V2015, P61, DOI 10.2312/vcbm.20151209
   Lee H, 2003, ACM T GRAPHIC, V22, P471, DOI 10.1145/882262.882294
   Lee H, 2012, VISUAL COMPUT, V28, P137, DOI 10.1007/s00371-011-0602-y
   Lindstrom P., 2003, PROC SYMPOS INTERACT, P93
   Liu H, 2020, IEEE T BROADCAST, V66, P701, DOI 10.1109/TBC.2019.2957652
   Maglo A, 2012, COMPUT GRAPH-UK, V36, P349, DOI 10.1016/j.cag.2012.03.023
   Martinez Rubi O., 2015, Capturing Reality Forum, DOI [10.13140/RG.2.1.1731.4326/1, DOI 10.13140/RG.2.1.1731.4326/1]
   McGuire M., 2017, COMPUTER GRAPHICS AR
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Merry B, 2006, COMPUT GRAPH FORUM, V25, P709, DOI 10.1111/j.1467-8659.2006.00993.x
   Metere A, 2015, SOFT MATTER, V11, P4606, DOI 10.1039/c5sm00570a
   Milani S, 2020, IEEE T IMAGE PROCESS, V29, P8213, DOI 10.1109/TIP.2020.3011811
   Moffat A, 1998, ACM T INFORM SYST, V16, P256, DOI 10.1145/290159.290162
   Moffat A, 2000, INFORM RETRIEVAL, V3, P25, DOI 10.1023/A:1013002601898
   Nguyen DT, 2021, IEEE T CIRC SYST VID, V31, P4617, DOI 10.1109/TCSVT.2021.3100279
   Ochotta T, 2008, COMPUT GRAPH FORUM, V27, P1647, DOI 10.1111/j.1467-8659.2008.01178.x
   Omeltchenko A, 2000, COMPUT PHYS COMMUN, V131, P78, DOI 10.1016/S0010-4655(00)00083-7
   OpenTopography, About us
   Park SB, 2009, IEEE T MULTIMEDIA, V11, P177, DOI 10.1109/TMM.2008.2008868
   Pascucci V., 2001, P INT C HIGH PERF CO, P45
   Patwary MMA, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807616
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Peng JL, 2010, COMPUT GRAPH FORUM, V29, P2029, DOI 10.1111/j.1467-8659.2010.01789.x
   Peng JL, 2005, ACM T GRAPHIC, V24, P609, DOI 10.1145/1073204.1073237
   Peng JL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1
   Peng JL, 2003, PROC SPIE, V5242, P301, DOI 10.1117/12.510857
   Qingyu Meng, 2012, 2012 SC Companion: High-Performance Computing, Networking, Storage and Analysis (SCC), P2441, DOI 10.1109/SCC.2012.6674233
   Rente PD, 2019, IEEE T MULTIMEDIA, V21, P284, DOI 10.1109/TMM.2018.2859591
   Rizzi S., 2015, P EUR S PAR GRAPH VI, P1
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Schatz K, 2016, SYMP LARG DATA ANAL, P56, DOI 10.1109/LDAV.2016.7874310
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Schnabel R., 2006, P S POINT BAS GRAPH, P111
   Schütz M, 2020, COMPUT GRAPH FORUM, V39, P155, DOI 10.1111/cgf.14134
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Singh JM, 2006, LECT NOTES COMPUT SC, V4338, P364
   Slattery Stuart, 2019, Zenodo, DOI 10.5281/ZENODO.2591488
   Smith J, 2012, COMPUT GRAPH-UK, V36, P341, DOI 10.1016/j.cag.2012.03.032
   Sweldens W, 1996, Z ANGEW MATH MECH, V76, P41
   Tao DW, 2017, IEEE INT CONF BIG DA, P486, DOI 10.1109/BigData.2017.8257962
   Teuhola J, 2009, COMPUT J, V52, P368, DOI 10.1093/comjnl/bxn030
   Thanou D, 2016, IEEE T IMAGE PROCESS, V25, P1765, DOI 10.1109/TIP.2016.2529506
   Usher W, 2021, INT PARALL DISTRIB P, P547, DOI 10.1109/IPDPS49936.2021.00063
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P123, DOI 10.1109/TVCG.2004.1260764
   Valette S, 2009, COMPUT GRAPH FORUM, V28, P1301, DOI 10.1111/j.1467-8659.2009.01507.x
   Wald I., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P9, DOI 10.1109/PBG.2005.194058
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Wald I, 2015, 2015 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P57, DOI 10.1109/SciVis.2015.7429492
   Wang JQ, 2021, IEEE T CIRC SYST VID, V31, P4909, DOI 10.1109/TCSVT.2021.3051377
   WASCHBUSCH M., 2004, Proceedings of Eurographics Symposium on Point-Based Graphics 2004, P95
   Woodring J, 2011, COMPUT GRAPH FORUM, V30, P1151, DOI 10.1111/j.1467-8659.2011.01964.x
   Zhang DZ, 2008, J COMPUT PHYS, V227, P3159, DOI 10.1016/j.jcp.2007.11.021
   Zhiyan Du, 2009, 2009 Data Compression Conference. DCC 2009, P420, DOI 10.1109/DCC.2009.73
NR 96
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4321
EP 4338
DI 10.1109/TVCG.2023.3260628
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700094
PM 37027261
DA 2024-08-05
ER

PT J
AU Hu, JB
   Wang, SF
   He, Y
   Luo, ZX
   Lei, N
   Liu, LG
AF Hu, Jiangbei
   Wang, Shengfa
   He, Ying
   Luo, Zhongxuan
   Lei, Na
   Liu, Ligang
TI A Parametric Design Method for Engraving Patterns on Thin Shells
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optimization; Shape; Topology; Design methodology; Computational
   modeling; Solid modeling; Three-dimensional displays; Parametric design;
   pattern engraving; structural optimization; thin shells
ID FINITE-ELEMENT-ANALYSIS; TOPOLOGY OPTIMIZATION; SURFACES
AB Designing thin-shell structures that are diverse, lightweight, and physically viable is a challenging task for traditional heuristic methods. To address this challenge, we present a novel parametric design framework for engraving regular, irregular, and customized patterns on thin-shell structures. Our method optimizes pattern parameters such as size and orientation, to ensure structural stiffness while minimizing material consumption. Our method is unique in that it works directly with shapes and patterns represented by functions, and can engrave patterns through simple function operations. By eliminating the need for remeshing in traditional FEM methods, our method is more computationally efficient in optimizing mechanical properties and can significantly increase the diversity of shell structure design. Quantitative evaluation confirms the convergence of the proposed method. We conduct experiments on regular, irregular, and customized patterns and present 3D printed results to demonstrate the effectiveness of our approach.
C1 [Hu, Jiangbei; Wang, Shengfa; Lei, Na] Dalian Univ Technol, DUT RU Int Sch Informat & Software Engn, Dalian 116024, Peoples R China.
   [Hu, Jiangbei; Lei, Na] Dalian Univ Technol, Key Lab Ubiquitous Network & Serv Software Liaonin, Dalian 116024, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Luo, Zhongxuan] Dalian Univ Technol, Sch Software Technol, Dalian 116024, Peoples R China.
   [Luo, Zhongxuan] Guilin Univ Elect Technol, Inst Artificial Intelligence, Guilin 541004, Guangxi, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei, Anhui, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology;
   Nanyang Technological University; Dalian University of Technology;
   Guilin University of Electronic Technology; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Wang, SF (corresponding author), Dalian Univ Technol, DUT RU Int Sch Informat & Software Engn, Dalian 116024, Peoples R China.; He, Y (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
EM jiangbei.hu@ntu.edu.sg; sfwang@dlut.edu.cn; yhe@ntu.edu.sg;
   zxluo@dlut.edu.cn; nalei@dlut.edu.cn; lgliu@ustc.edu.cn
OI Lei, Na/0000-0003-3361-0756; Hu, Jiangbei/0000-0002-6774-6267
FU National Key R&D Program of China [2020YFB1709402, 2021YFA1003003];
   Academic Research Fund of the Ministry of Education of Singapore
   [MOE-T2EP20220-0005, RG20/20]
FX This work was supported by the National Key R&D Program of China under
   Grants 2020YFB1709402 and 2021YFA1003003 and in part by the Academic
   Research Fund under Grant MOE-T2EP20220-0005 & RG20/20 of the Ministry
   of Education of Singapore.
CR Adriaenssens S., 2014, Shell Struc-tures for Architecture: Form Finding and Optimization
   Ahsan AMMN, 2018, PROCEDIA MANUF, V26, P900, DOI 10.1016/j.promfg.2018.07.117
   Allaire G, 1997, NUMER MATH, V76, P27, DOI 10.1007/s002110050253
   Bächer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601157
   Bendse M.P., 1989, STRUCTURAL OPTIMIZAT, V1, P193, DOI [DOI 10.1007/BF01650949, 10.1007/BF016509492,4]
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P509, DOI 10.1111/cgf.13146
   Bickel B, 2018, COMPUT GRAPH FORUM, V37, P325, DOI 10.1111/cgf.13327
   Bucalem ML, 1997, ARCH COMPUT METHOD E, V4, P3, DOI 10.1007/BF02818930
   Chai SM, 2018, GRAPH MODELS, V97, P80, DOI 10.1016/j.gmod.2018.04.002
   Chen WK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925911
   Cheng L, 2019, COMPUT METHOD APPL M, V344, P334, DOI 10.1016/j.cma.2018.10.010
   Cirak F, 2002, COMPUT AIDED DESIGN, V34, P137, DOI 10.1016/S0010-4485(01)00061-6
   Cohen E., 2001, Geometric Modeling WithSplines: An Introduction
   Dumas J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766984
   Farshad M., 2013, Design and Analysis of Shell Structures, V16
   Hollister SJ, 2005, NAT MATER, V4, P518, DOI 10.1038/nmat1421
   Hu JB, 2022, IEEE T VIS COMPUT GR, V28, P2615, DOI 10.1109/TVCG.2020.3037697
   Jawad Maan., 2012, Theory and design of plate and shell structures
   Jiang CG, 2014, COMPUT GRAPH FORUM, V33, P185, DOI 10.1111/cgf.12444
   Kuipers T, 2019, COMPUT AIDED DESIGN, V114, P37, DOI 10.1016/j.cad.2019.05.003
   Le T. N. H., 2021, P SIGGRAPH AS POST, P1
   Leung Y.-S., 2015, Comput. Vis. Media, V1, P239
   Lévy B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778856
   Liu C, 2018, STRUCT MULTIDISCIP O, V58, P2455, DOI 10.1007/s00158-018-2114-0
   Liu JK, 2018, STRUCT MULTIDISCIP O, V57, P2457, DOI 10.1007/s00158-018-1994-3
   Liu X., 2020, Comput.-Aided Des., V127, P1
   Lu L, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601168
   Martínez J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322989
   Martínez J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818101
   Melaragno M., 2012, An introduction to shell structures: the art and science of vaulting
   Nguyen TH, 2010, STRUCT MULTIDISCIP O, V41, P525, DOI 10.1007/s00158-009-0443-8
   Panetta J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323040
   Peng CH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201306
   Pietroni N, 2015, COMPUT GRAPH FORUM, V34, P627, DOI 10.1111/cgf.12590
   Préost R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461957
   Rao C, 2019, COMPUT AIDED GEOM D, V71, P130, DOI 10.1016/j.cagd.2019.04.018
   Schroeder C, 2005, COMPUT AIDED DESIGN, V37, P339, DOI 10.1016/j.cad.2004.03.008
   Schumacher C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275085
   Schumacher C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201278
   Schumacher C, 2016, COMPUT GRAPH FORUM, V35, P101, DOI 10.1111/cgf.12967
   Skouras M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461979
   SKYUM S, 1991, INFORM PROCESS LETT, V37, P121, DOI 10.1016/0020-0190(91)90030-L
   Stadlbauer P, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13929
   Svanberg K, 2001, SIAM J OPTIMIZ, V12, P555
   Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297
   Vaxman Amir, 2022, Zenodo, DOI 10.5281/ZENODO.3338174
   Wang MY, 2003, COMPUT METHOD APPL M, V192, P227, DOI 10.1016/S0045-7825(02)00559-5
   Wang WM, 2018, IEEE T VIS COMPUT GR, V24, P2787, DOI 10.1109/TVCG.2017.2764462
   Wang WM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508382
   Wu J, 2018, IEEE T VIS COMPUT GR, V24, P1127, DOI 10.1109/TVCG.2017.2655523
   Wu ZY, 2005, J GLOBAL OPTIM, V31, P45, DOI 10.1007/s10898-004-0569-6
   XIE YM, 1993, COMPUT STRUCT, V49, P885, DOI 10.1016/0045-7949(93)90035-C
   Yang JR, 2019, COMPUT AIDED DESIGN, V114, P191, DOI 10.1016/j.cad.2019.05.028
   Zehnder J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925888
   Zhang JY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661255
   Zhang WS, 2016, STRUCT MULTIDISCIP O, V53, P1243, DOI 10.1007/s00158-015-1372-3
   Zhang XL, 2015, COMPUT AIDED GEOM D, V35-36, P149, DOI 10.1016/j.cagd.2015.03.012
   Zhang XT, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P243, DOI 10.1145/3126594.3126600
NR 58
TC 1
Z9 1
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3719
EP 3730
DI 10.1109/TVCG.2023.3240503
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700058
PM 37022859
DA 2024-08-05
ER

PT J
AU Lin, YN
   Li, HT
   Wu, AY
   Wang, Y
   Qu, HM
AF Lin, Yanna
   Li, Haotian
   Wu, Aoyu
   Wang, Yong
   Qu, Huamin
TI DMiner: Dashboard Design Mining and Recommendation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Layout; Encoding; Feature extraction; Data mining;
   Visualization; Software development management; Dashboards; design
   mining; multiple-view visualization; visualization recommendation
ID MULTIPLE VIEWS
AB Dashboards, which comprise multiple views on a single display, help analyze and communicate multiple perspectives of data simultaneously. However, creating effective and elegant dashboards is challenging since it requires careful and logical arrangement and coordination of multiple visualizations. To solve the problem, we propose a data-driven approach for mining design rules from dashboards and automating dashboard organization. Specifically, we focus on two prominent aspects of the organization: arrangement, which describes the position, size, and layout of each view in the display space; and coordination, which indicates the interaction between pairwise views. We build a new dataset containing 854 dashboards crawled online, and develop feature engineering methods for describing the single views and view-wise relationships in terms of data, encoding, layout, and interactions. Further, we identify design rules among those features and develop a recommender for dashboard design. We demonstrate the usefulness of DMiner through an expert study and a user study. The expert study shows that our extracted design rules are reasonable and conform to the design practice of experts. Moreover, a comparative user study shows that our recommender could help automate dashboard organization and reach human-level performance. In summary, our work offers a promising starting point for design mining visualizations to build recommenders.
C1 [Lin, Yanna; Li, Haotian; Wu, Aoyu; Qu, Huamin] Hong Kong Univ Sci & Technol, Kowloon, Hong Kong, Peoples R China.
   [Wang, Yong] Singapore Management Univ, Singapore 178902, Singapore.
C3 Hong Kong University of Science & Technology; Singapore Management
   University
RP Lin, YN (corresponding author), Hong Kong Univ Sci & Technol, Kowloon, Hong Kong, Peoples R China.
EM ylindg@connect.ust.hk; haotian.li@connect.ust.hk; awuac@connect.ust.hk;
   yongwang@smu.edu.sg; huamin@cse.ust.hk
OI Wu, Aoyu/0000-0001-9187-9265; Lin, Yanna/0000-0003-3730-0827
FU HK RGC GRF [16210722]; Singapore Ministry of Education (MOE) Academic
   Research Fund (AcRF) Tier 2 [T2EP20222-0049]
FX This work was partially supported by HK RGC GRF under Grant 16210722,
   and in part by the Singapore Ministry of Education (MOE) Academic
   Research Fund (AcRF) Tier 2 under Grant T2EP20222-0049.
CR Al-maneea HM, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P121, DOI [10.1109/VISUAL.2019.8933655, 10.1109/visual.2019.8933655]
   [Anonymous], Binary vector-wikipedia
   [Anonymous], Data Visualization | Microsoft Power BI
   Bach B., 2022, arXiv
   Baldonado M. Q. W., 2000, Proceedings of the Conference on Advanced Visual Interfaces, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Bartram L., 2002, Information Visualization, V1, P66, DOI 10.1057/palgrave/ivs/9500005
   Cao YR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517648
   Chen R, 2022, IEEE T VIS COMPUT GR, V28, P4127, DOI 10.1109/TVCG.2021.3076222
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Deng DZ, 2022, Arxiv, DOI arXiv:2208.01232
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Dowding D, 2018, APPL CLIN INFORM, V9, P511, DOI 10.1055/s-0038-1666842
   Forsell C., 2010, P INT C ADV VISUAL I, P199, DOI [DOI 10.1145/1842993.18430292, 10.1145/1842993.18430292]
   Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148
   github, About Us
   Greco S., 2016, Multiple Criteria Decision Analysis, P497
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Key Alicia, 2012, P 2012 ACM SIGMOD IN, P681, DOI [10.1145/2213836.2213931, DOI 10.1145/2213836.2213931]
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Langner R, 2019, IEEE T VIS COMPUT GR, V25, P608, DOI 10.1109/TVCG.2018.2865235
   Lee S, 2018, KOREAN J ANESTHESIOL, V71, P353, DOI 10.4097/kja.d.18.00242
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI [10.1145/345513.345282, DOI 10.1145/345513.345282]
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Roberts JC, 1998, IEEE INFOR VIS, P8, DOI 10.1109/IV.1998.694193
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sadana R, 2016, COMPUT GRAPH FORUM, V35, P261, DOI 10.1111/cgf.12902
   Saket B., 2018, arXiv
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Shao LD, 2021, J VISUAL-JAPAN, V24, P1237, DOI 10.1007/s12650-021-00781-z
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Singh C., 2021, imodels: A Python package for fitting interpretable models, V6
   Smith V. S., 2013, New Directions Eval., P21, DOI [10.1002/ev.20072, DOI 10.1002/EV.20072]
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Sun MY, 2022, IEEE T VIS COMPUT GR, V28, P4741, DOI 10.1109/TVCG.2021.3102966
   Sun MY, 2022, IEEE T VIS COMPUT GR, V28, P54, DOI 10.1109/TVCG.2021.3114801
   Tableau, About us
   Tufte E. R., 1985, TLS-TIMES LIT SUPPL, V7, P15
   Tundo Alessandro, 2020, 2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW), P215, DOI 10.1109/ISSREW51248.2020.00075
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517618
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
NR 55
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4108
EP 4121
DI 10.1109/TVCG.2023.3251344
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700016
PM 37028006
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Shao, ZK
   Sun, SR
   Zhao, YH
   Wang, SY
   Wei, ZY
   Gui, T
   Turkay, C
   Chen, SM
AF Shao, Zekai
   Sun, Shuran
   Zhao, Yuheng
   Wang, Siyuan
   Wei, Zhongyu
   Gui, Tao
   Turkay, Cagatay
   Chen, Siming
TI Visual Explanation for Open-Domain Question Answering With BERT
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Analytical models; Transformers; Task analysis; Data models; Visual
   analytics; Bit error rate; Semantics; Explainable machine learning;
   open-domain question answering; visual analytics
ID ANALYTICS
AB Open-domain question answering (OpenQA) is an essential but challenging task in natural language processing that aims to answer questions in natural language formats on the basis of large-scale unstructured passages. Recent research has taken the performance of benchmark datasets to new heights, especially when these datasets are combined with techniques for machine reading comprehension based on Transformer models. However, as identified through our ongoing collaboration with domain experts and our review of literature, three key challenges limit their further improvement: (i) complex data with multiple long texts, (ii) complex model architecture with multiple modules, and (iii) semantically complex decision process. In this paper, we present VEQA, a visual analytics system that helps experts understand the decision reasons of OpenQA and provides insights into model improvement. The system summarizes the data flow within and between modules in the OpenQA model as the decision process takes place at the summary, instance and candidate levels. Specifically, it guides users through a summary visualization of dataset and module response to explore individual instances with a ranking visualization that incorporates context. Furthermore, VEQA supports fine-grained exploration of the decision flow within a single module through a comparative tree visualization. We demonstrate the effectiveness of VEQA in promoting interpretability and providing insights into model enhancement through a case study and expert evaluation.
C1 [Shao, Zekai; Sun, Shuran; Zhao, Yuheng; Wang, Siyuan; Wei, Zhongyu; Gui, Tao; Chen, Siming] Fudan Univ, Shanghai 200437, Peoples R China.
   [Turkay, Cagatay] Univ Warwick, Coventry CV4 7AL, England.
C3 Fudan University; University of Warwick
RP Chen, SM (corresponding author), Fudan Univ, Shanghai 200437, Peoples R China.
EM zkshao19@fudan.edu.cn; srsun20@fudan.edu.cn; yuhengzhao@fudan.edu.cn;
   wangsy18@fudan.edu.cn; zywei@fudan.edu.cn; tgui@fudan.edu.cn;
   cagatay.turkay@warwick.ac.uk; simingchen3@gmail.com
OI Wang, Siyuan/0000-0001-7357-2913; Wei, Zhongyu/0000-0003-3789-8507;
   Turkay, Cagatay/0000-0001-6788-251X; Sun, Shuran/0000-0003-2297-5602;
   Zhao, Yuheng/0000-0003-1573-8772; Shao, Zekai/0000-0003-2014-5293
FU National Natural Science Foundation of China [62202105]; Shanghai
   Municipal Science and Technology Major [2018SHZDZX01, 2021SHZDZX0103];
   General Program [21ZR1403300]; Sailing Program [21YF1402900]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 62202105, in part by Shanghai Municipal Science and
   Technology Major Project under Grants 2018SHZDZX01, and 2021SHZDZX0103,
   in part by General Program under Grant 21ZR1403300,in part by Sailing
   Program under Grant 21YF1402900, and in part by ZJLab.
CR Abadi M., 2016, arXiv
   Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4190
   Agrawal A, 2017, INT J COMPUT VISION, V123, P4, DOI 10.1007/s11263-016-0966-6
   Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002
   Asai A, 2020, Arxiv, DOI arXiv:1911.10470
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Caballero M., 2021, Int. J. Artif. Intell. Appl., V12, P1
   Cheng FR, 2022, IEEE T VIS COMPUT GR, V28, P378, DOI 10.1109/TVCG.2021.3114836
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Chung JY, 2017, Arxiv, DOI arXiv:1609.01704
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Denil M., 2014, arXiv
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhamdhere K, 2018, Arxiv, DOI arXiv:1805.12233
   Drozdov A, 2019, Arxiv, DOI arXiv:1904.02142
   Falconer J., 2011, "Google: Our new search strategy is to compute answers," not links
   Fujiwara T., 2022, J. Data Sci. Statist. Visualisation, V2, P1
   Fujiwara T, 2022, IEEE T VIS COMPUT GR, V28, P758, DOI 10.1109/TVCG.2021.3114807
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Gutmann A., 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Hao YR, 2021, Arxiv, DOI arXiv:2004.11207
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888
   Hou YJ, 2022, IEEE T VIS COMPUT GR, V28, P1030, DOI 10.1109/TVCG.2021.3114777
   Jain S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3543
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769
   Khattab O, 2021, T ASSOC COMPUT LING, V9, P929, DOI 10.1162/tacl_a_00405
   Kitaev N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3499
   Kobayashi G, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7057
   Kovaleva Olga, 2019, arXiv
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lal V, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P135
   Lee G, 2019, AAAI CONF ARTIF INTE, P9861
   Lee J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3661
   Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086
   Lewis M, 2019, Arxiv, DOI arXiv:1910.13461
   Li J., 2016, Proceedings of the 2016 NAACL, P681, DOI [DOI 10.18653/V1/N16-1082, 10.18653/v1/N16-1082]
   Li R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P220
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SS, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P36, DOI 10.13697/j.cnki.32-1449/tu.2018.01.013
   Liu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P188
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mao YN, 2021, Arxiv, DOI arXiv:2009.08553
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Nie YX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2553
   Ono JP, 2021, IEEE T VIS COMPUT GR, V27, P390, DOI 10.1109/TVCG.2020.3030361
   OpenAI, 2022, Chatgpt: Optimizing language models for dialogue
   Pascual D, 2021, Arxiv, DOI arXiv:2004.05916
   Qu YQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5835
   Ramnath S, 2020, Arxiv, DOI arXiv:2010.08983
   Ren RY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2825
   Ren RY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2173
   Robinson Joshua, 2020, arXiv
   Rücklé A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P19, DOI 10.18653/v1/P17-4004
   Sachan D. S., 2021, P 59 ANN M ASS COMPU, P6648
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Shen YK, 2019, Arxiv, DOI arXiv:1810.09536
   Shrikumar A, 2018, Arxiv, DOI arXiv:1807.09946
   Silva S, 2011, COMPUT GRAPH-UK, V35, P320, DOI 10.1016/j.cag.2010.11.015
   Skrlj B, 2020, Arxiv, DOI arXiv:2005.05716
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Sun HT, 2019, Arxiv, DOI arXiv:1904.09537
   Sun HT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4231
   Sun K, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4126
   Sundararajan M, 2017, Arxiv, DOI [arXiv:1703.01365, DOI 10.48550/ARXIV.1703.01365]
   Tenney I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P107
   van Aken B, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1823, DOI 10.1145/3357384.3358028
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang JH, 2023, IEEE T VIS COMPUT GR, V29, P5033, DOI 10.1109/TVCG.2022.3201101
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang SH, 2018, AAAI CONF ARTIF INTE, P5981
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang ZJ, 2021, Arxiv, DOI arXiv:2103.14625
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72
   Yasunaga M, 2021, Arxiv, DOI arXiv:2104.06378
   Ye X, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5496
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang D, 2021, AAAI CONF ARTIF INTE, V35, P14328
   Zhu FB, 2021, Arxiv, DOI [arXiv:2101.00774, DOI 10.48550/ARXIV.2101.00774]
NR 94
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3779
EP 3797
DI 10.1109/TVCG.2023.3243676
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700093
PM 37027746
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Chen, CJ
   Chen, JS
   Yang, WK
   Wang, HZ
   Knittel, J
   Zhao, XB
   Koch, S
   Ertl, T
   Liu, SX
AF Chen, Changjian
   Chen, Jiashu
   Yang, Weikai
   Wang, Haoze
   Knittel, Johannes
   Zhao, Xibin
   Koch, Steffen
   Ertl, Thomas
   Liu, Shixia
TI Enhancing Single-Frame Supervision for Better Temporal Action
   Localization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Location awareness; Annotations; Videos; Visualization; Noise
   measurement; Data visualization; Uncertainty; Single-frame supervision;
   storyline visualization; temporal action localization
ID BODY-MASS INDEX; VIDEO; ALGORITHM; PATTERNS
AB Temporal action localization aims to identify the boundaries and categories of actions in videos, such as scoring a goal in a football match. Single-frame supervision has emerged as a labor-efficient way to train action localizers as it requires only one annotated frame per action. However, it often suffers from poor performance due to the lack of precise boundary annotations. To address this issue, we propose a visual analysis method that aligns similar actions and then propagates a few user-provided annotations (e.g., boundaries, category labels) to similar actions via the generated alignments. Our method models the alignment between actions as a heaviest path problem and the annotation propagation as a quadratic optimization problem. As the automatically generated alignments may not accurately match the associated actions and could produce inaccurate localization results, we develop a storyline visualization to explain the localization results of actions and their alignments. This visualization facilitates users in correcting wrong localization results and misalignments. The corrections are then used to improve the localization results of other actions. The effectiveness of our method in improving localization performance is demonstrated through quantitative evaluation and a case study.
C1 [Chen, Changjian] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410012, Hunan, Peoples R China.
   [Chen, Jiashu; Yang, Weikai; Wang, Haoze; Zhao, Xibin; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100190, Peoples R China.
   [Knittel, Johannes; Koch, Steffen; Ertl, Thomas] Univ Stuttgart, D-70174 Stuttgart, Germany.
C3 Hunan University; Tsinghua University; University of Stuttgart
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100190, Peoples R China.
EM changjianchen@hnu.edu.cn; johannes.knittel@vis.uni-stuttgart.de;
   zxb@tsinghua.edu.cn; steffen.koch@vis.uni-stuttgart.de;
   Thomas.Ertl@vis.uni-stuttgart.de; shixia@tsinghua.edu.cn
OI Ertl, Thomas/0000-0003-4019-2505
FU National Natural Science Foundation of China
FX No Statement Available
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   [Anonymous], 2012, P SIGCHI C HUMAN FAC, DOI [DOI 10.1145/2207676.22077672, DOI 10.1145/2207676.2207767]
   Arias-Hernandez R., 2011, P IEEE HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.2011.339
   Arora P, 2016, PROCEDIA COMPUT SCI, V78, P507, DOI 10.1016/j.procs.2016.02.095
   Botchen RP, 2008, IEEE T VIS COMPUT GR, V14, P885, DOI 10.1109/TVCG.2008.40
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen CJ, 2024, IEEE T VIS COMPUT GR, V30, P76, DOI 10.1109/TVCG.2023.3326588
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen M, 2006, IEEE T VIS COMPUT GR, V12, P1093, DOI 10.1109/TVCG.2006.194
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Daniel G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P409, DOI 10.1109/VISUAL.2003.1250401
   Duffy B, 2015, IEEE T VIS COMPUT GR, V21, P980, DOI 10.1109/TVCG.2013.265
   Elhamifar E, 2016, IEEE T PATTERN ANAL, V38, P2182, DOI 10.1109/TPAMI.2015.2511748
   Fan Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P420, DOI 10.1007/978-3-030-58548-8_25
   FENG DF, 1987, J MOL EVOL, V25, P351, DOI 10.1007/BF02603120
   Haines O., 2014, P BRIT MACH VIS C, V2, P3
   Han Z, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4165, DOI 10.1145/3474085.3475549
   He JB, 2024, IEEE T VIS COMPUT GR, V30, P87, DOI 10.1109/TVCG.2023.3326586
   HELD M, 1962, J SOC IND APPL MATH, V10, P196, DOI 10.1137/0110015
   Höferlin M, 2013, IEEE T MULTIMEDIA, V15, P908, DOI 10.1109/TMM.2013.2238521
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521
   Ji JW, 2019, IEEE I CONF COMP VIS, P7072, DOI 10.1109/ICCV.2019.00717
   Kaidi Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10615, DOI 10.1109/CVPR42600.2020.01063
   Kang H.-W., 2006, P IEEE COMP SOC C CO, V2, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842]
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Lewis D. D., 1995, SIGIR Forum, V29, P13, DOI 10.1145/219587.219592
   Li Z, 2021, PROC CVPR IEEE, P8361, DOI 10.1109/CVPR46437.2021.00826
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2023, COMPUTER, V56, P4, DOI 10.1109/MC.2023.3304568
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu XL, 2022, IEEE T IMAGE PROCESS, V31, P5427, DOI 10.1109/TIP.2022.3195321
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Ma B, 2018, IEEE T VIS COMPUT GR, V24, P3253, DOI 10.1109/TVCG.2017.2776935
   Ma CX, 2020, J COMPUT SCI TECH-CH, V35, P576, DOI 10.1007/s11390-020-0271-2
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Muller M., 2007, Information Retrieval for Music and Motion, DOI [10.1007/978-3-540-74048-3, DOI 10.1007/978-3-540-74048-3_4]
   Newby P, 2003, AM J CLIN NUTR, V77, P1417, DOI 10.1093/ajcn/77.6.1417
   Ono JP, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300293
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Reddy CK, 2014, CH CRC DATA MIN KNOW, P87
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Swift ME, 2023, IEEE T VIS COMPUT GR, V29, P171, DOI 10.1109/TVCG.2022.3209454
   Tan H.-K., 2008, P ACM INT C MULT, P861, DOI DOI 10.1145/1459359.1459506
   Tan Hung-Khoon, 2009, P ACM INT C MULT, P145, DOI DOI 10.1145/1631272.1631295
   Tan L, 2012, IEEE COMPUT GRAPH, V32, P46, DOI 10.1109/MCG.2011.89
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Togo P, 2001, INT J OBESITY, V25, P1741, DOI 10.1038/sj.ijo.0801819
   Wang X, 2021, PROC CVPR IEEE, P1905, DOI 10.1109/CVPR46437.2021.00194
   Wang Y., 2012, P ACM INT C MULT, P941, DOI [10.1145/2393347.23963525, DOI 10.1145/2393347.23963525, 10.1145/2393347.2396352, DOI 10.1145/2393347.2396352]
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Xia HF, 2020, IEEE ACCESS, V8, P70477, DOI 10.1109/ACCESS.2020.2986861
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang L, 2022, IEEE T PATTERN ANAL, V44, P9814, DOI 10.1109/TPAMI.2021.3132058
   Yang WK, 2024, COMPUT VIS MEDIA, V10, P399, DOI 10.1007/s41095-023-0393-x
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yu Yuncong, 2023, IEEE Trans Vis Comput Graph, V29, P33, DOI 10.1109/TVCG.2022.3209431
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang CL, 2022, LECT NOTES COMPUT SC, V13664, P492, DOI 10.1007/978-3-031-19772-7_29
   Zhao PN, 2021, AAAI CONF ARTIF INTE, V35, P11007
   Zhao T, 2023, IEEE T PATTERN ANAL, V45, P3019, DOI 10.1109/TPAMI.2022.3178957
   Zhu Xiaojin, 2005, Ph.D. thesis,
NR 69
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2903
EP 2915
DI 10.1109/TVCG.2024.3388521
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500008
PM 38619947
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ye, SQ
   Chen, DD
   Han, SF
   Liao, J
AF Ye, Shuquan
   Chen, Dongdong
   Han, Songfang
   Liao, Jing
TI 3D Question Answering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud; scene understanding
ID LANGUAGE; VISION
AB Visual question answering (VQA) has experienced tremendous progress in recent years. However, most efforts have only focused on 2D image question-answering tasks. In this article, we extend VQA to its 3D counterpart, 3D question answering (3DQA), which can facilitate a machine's perception of 3D real-world scenarios. Unlike 2D image VQA, 3DQA takes the color point cloud as input and requires both appearance and 3D geometrical comprehension to answer the 3D-related questions. To this end, we propose a novel transformer-based 3DQA framework "3DQA-TR", which consists of two encoders to exploit the appearance and geometry information, respectively. Finally, the multi-modal information about the appearance, geometry, and linguistic question can attend to each other via a 3D-linguistic Bert to predict the target answers. To verify the effectiveness of our proposed 3DQA framework, we further develop the first 3DQA dataset "ScanQA", which builds on the ScanNet dataset and contains over 10 K question-answer pairs for 806 scenes. To the best of our knowledge, ScanQA is the first large-scale dataset with natural-language questions and free-form answers in 3D environments that is fully human-annotated. We also use several visualizations and experiments to investigate the astonishing diversity of the collected questions and the significant differences between this task from 2D VQA and 3D captioning. Extensive experiments on this dataset demonstrate the obvious superiority of our proposed 3DQA framework over state-of-the-art VQA frameworks and the effectiveness of our major designs. Our code and dataset will be made publicly available to facilitate research in this direction. The code and data are available at http://shuquanye.com/3DQA_website/.
C1 [Ye, Shuquan; Liao, Jing] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
   [Chen, Dongdong] Microsoft Cloud AI, Redmond, WA 98052 USA.
   [Han, Songfang] Univ Calif San Diego, La Jolla, CA 92093 USA.
C3 City University of Hong Kong; University of California System;
   University of California San Diego
RP Liao, J (corresponding author), City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
EM shuquanye2-c@my.cityu.edu.hk; cddlyf@gmail.com; hansongfang@gmail.com;
   jingliao@cityu.edu.hk
RI Chen, Dongdong/AAR-4481-2020
OI Chen, Dongdong/0000-0002-7016-9288; Chen, Dongdong/0000-0002-4642-4373;
   LIAO, Jing/0000-0001-7014-5377; Han, Songfang/0000-0002-6432-8764
FU Hong Kong Research Grants Council
FX No Statement Available
CR Achlioptas Panos, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P422, DOI 10.1007/978-3-030-58452-8_25
   Agrawal A, 2016, Arxiv, DOI arXiv:1606.07356
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Amizadeh S., 2020, INT C MACHINE LEARNI, P279
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Banerjee P., 2021, P IEEE CVF INT C COM, P1908
   Bansal Ankan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P51, DOI 10.1007/978-3-030-58589-1_4
   Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439
   Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269
   Chen D. Z., 2020, EUR C COMP VIS, P202, DOI DOI 10.1007/978-3-030-58565-513
   Chen DZ, 2021, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR46437.2021.00321
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Chen WH, 2021, IEEE WINT CONF APPL, P655, DOI 10.1109/WACV48630.2021.00070
   Chen XL, 2015, Arxiv, DOI arXiv:1504.00325
   Chou SH, 2020, IEEE WINT CONF APPL, P1596, DOI 10.1109/WACV45572.2020.9093452
   Chou W.-L., 2020, P IEEE CVF WINT C AP, P1607
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   David HA, 1997, AM STAT, V51, P9, DOI 10.2307/2684684
   Denkowski M., 2014, P WMT ACL, P376
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Feng M., 2021, arXiv
   Gao HY, 2015, ADV NEUR IN, V28
   Garcia M., 2020, AAAI C ARTIF INTELL, p10 826
   Goyal A., 2020, Advances in Neural Information Processing Systems, V33, P10514
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Hu SM, 2020, IEEE T VIS COMPUT GR, V26, P2485, DOI 10.1109/TVCG.2018.2889944
   Huang PH, 2021, AAAI CONF ARTIF INTE, V35, P1610
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kahou Samira Ebrahimi, 2018, arXiv, DOI DOI 10.48550/ARXIV.1710.07300
   Kervadec C, 2021, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR46437.2021.00280
   Kim J.-H., 2017, P INT C LEARN REPR, P1
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lan Z., 2020, INT C LEARN REPR
   Lei J, 2020, Arxiv, DOI arXiv:1904.11574
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1369
   Li L, 2023, IEEE T VIS COMPUT GR, V29, P3368, DOI 10.1109/TVCG.2022.3160005
   Li Xianzhi, 2021, IEEE T VISUALIZATION
   Liu Z, 2021, Arxiv, DOI arXiv:2104.00678
   Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782
   Loshchilov I., 2018, INT C LEARN REPR
   Lu JS, 2019, ADV NEUR IN, V32
   Lu JS, 2016, ADV NEUR IN, V29
   Malinowski M, 2014, ADV NEUR IN, V27
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qiu Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082281
   Qiu Y, 2019, INT CONF 3D VISION, P756, DOI 10.1109/3DV.2019.00088
   Ren MY, 2015, ADV NEUR IN, V28
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Singh A., 2018, SYSML WORKSH NEURIPS, V2018
   STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009
   Su Weijie, 2020, 8 INT C LEARN REPR I
   Su Y.-C., 2021, arXiv
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tang KH, 2019, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2019.00678
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wijmans E, 2019, PROC CVPR IEEE, P6652, DOI 10.1109/CVPR.2019.00682
   Yang JW, 2020, Arxiv, DOI arXiv:2012.11587
   Yang ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1836, DOI 10.1109/ICCV48922.2021.00187
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Ye SQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6423, DOI 10.1109/ICCV48922.2021.00638
   Ye SQ, 2022, IEEE T VIS COMPUT GR, V28, P3206, DOI 10.1109/TVCG.2021.3058311
   Yu LC, 2015, Arxiv, DOI arXiv:1506.00278
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yuan Z., 2021, ICCV, P1791
   Yun H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2011, DOI 10.1109/ICCV48922.2021.00204
   Zadeh A, 2019, PROC CVPR IEEE, P8799, DOI 10.1109/CVPR.2019.00901
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 84
TC 1
Z9 1
U1 6
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1772
EP 1786
DI 10.1109/TVCG.2022.3225327
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500008
PM 36446015
DA 2024-08-05
ER

PT J
AU Gaba, A
   Kaufman, Z
   Cheung, J
   Shvakel, M
   Hall, KW
   Brun, Y
   Bearfield, CX
AF Gaba, Aimen
   Kaufman, Zhanna
   Cheung, Jason
   Shvakel, Marie
   Hall, Kyle Wm.
   Brun, Yuriy
   Bearfield, Cindy Xiong
TI My Model is Unfair, Do People Even Care? Visual Design Affects Trust and
   Perceived Bias in Machine Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Computational modeling; Analytical models; Data models;
   Bars; Investment; Games; machine learning; fairness; bias; trust; visual
   design; gender; human-subjects studies
ID PERCEPTION
AB Machine learning technology has become ubiquitous, but, unfortunately, often exhibits bias. As a consequence, disparate stakeholders need to interact with and make informed decisions about using machine learning models in everyday systems. Visualization technology can support stakeholders in understanding and evaluating trade-offs between, for example, accuracy and fairness of models. This paper aims to empirically answer "Can visualization design choices affect a stakeholder's perception of model bias, trust in a model, and willingness to adopt a model?" Through a series of controlled, crowd-sourced experiments with more than 1,500 participants, we identify a set of strategies people follow in deciding which models to trust. Our results show that men and women prioritize fairness and performance differently and that visual design choices significantly affect that prioritization. For example, women trust fairer models more often than men do, participants value fairness more when it is explained using text than as a bar chart, and being explicitly told a model is biased has a bigger impact than showing past biased performance. We test the generalizability of our results by comparing the effect of multiple textual and visual design choices and offer potential explanations of the cognitive mechanisms behind the difference in fairness perception and trust. Our research guides design considerations to support future work developing visualization systems for machine learning.
C1 [Gaba, Aimen; Kaufman, Zhanna; Cheung, Jason; Shvakel, Marie; Brun, Yuriy; Bearfield, Cindy Xiong] Univ Massachusetts, Amherst, MA 01003 USA.
   [Hall, Kyle Wm.] TD Bank, Global Compliance, Cherry Hill, NJ USA.
C3 University of Massachusetts System; University of Massachusetts Amherst
RP Gaba, A (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.
EM agaba@umass.edu; zhannakaufma@umass.edu; jasoncheung@umass.edu;
   mshvakel@umass.edu; kyle.hall@td.com; brun@umass.edu; yaxiong@umass.edu
OI Xiong Bearfield, Cindy/0000-0002-1451-4083; Brun,
   Yuriy/0000-0003-3027-7986
FU National Science Foundation
FX No Statement Available
CR Ahmad J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P56, DOI 10.1109/VIS49827.2021.9623314
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Angwin J., 2016, MACHINE BIAS
   Bell A., 2023, The possibility of fairness: Revisiting the impossibility theorem in practice, P1
   BERG J, 1995, GAME ECON BEHAV, V10, P122, DOI 10.1006/game.1995.1027
   Bird S., 2020, Tech. Rep. MSR-TR-2020-32
   Black W. C., 2019, Cengage Learning EMEA, V4
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI 10.1191/1478088706qp063oa
   Braun V., 2012, Thematic analysis, P5
   Brülhart M, 2012, ECON LETT, V115, P20, DOI 10.1016/j.econlet.2011.11.039
   Buolamwini J., 2018, C FAIRN ACC TRANSP, V81, P77, DOI DOI 10.2147/OTT.S126905
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   CARVER CS, 1994, J PERS SOC PSYCHOL, V67, P319, DOI 10.1037/0022-3514.67.2.319
   Chatzimparmpas A, 2020, INFORM VISUAL, V19, P207, DOI 10.1177/1473871620904671
   Coleman J., 1990, Foundations of Social Theory. ACLS Humanities E-Book, P2
   Dang JH, 2020, TRENDS COGN SCI, V24, P267, DOI 10.1016/j.tics.2020.01.007
   Deng ZL, 2022, IEEE T COMPUT SOC SY, V9, P1768, DOI 10.1109/TCSS.2022.3162345
   Dwork C, 2012, P 3 INN THEOR COMP S, P214, DOI DOI 10.1145/2090236.2090255
   Elhamdadi H., 2022, WORKSHOP TRUST EXPER, DOI [10.48550/arXiv.2209.143401,2, DOI 10.48550/ARXIV.2209.143401,2]
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732
   Friedler S. A., 2016, CoRR, abs/1609.07236, P2
   Gaba A., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1
   Galhotra S, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P498, DOI 10.1145/3106237.3106277
   Ghai B., 2023, IEEE Transactions on Visualization and Computer Graphics, V29, DOI DOI 10.1109/TVCG.2022.32094842
   Giguere Stephen, 2022, ICLR
   Glaeser EL, 2000, Q J ECON, V115, P811, DOI 10.1162/003355300554926
   Goldstein D. G., 2022, The Behavioral Economics Guide, pVI
   GOODLAND R, 1987, ECOL MODEL, V38, P19, DOI 10.1016/0304-3800(87)90043-3
   Hall KW, 2022, IEEE T VIS COMPUT GR, V28, P654, DOI 10.1109/TVCG.2021.3114805
   Harrison G, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P392, DOI 10.1145/3351095.3372831
   Hoffrage U, 2000, SCIENCE, V290, P2261, DOI 10.1126/science.290.5500.2261
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Holder Eli, 2023, IEEE Trans Vis Comput Graph, V29, P624, DOI 10.1109/TVCG.2022.3209377
   Johnson B, 2023, EURO J DECIS PROCESS, V11, DOI 10.1016/j.ejdp.2023.100031
   Jun Zheng, 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P141, DOI 10.1145/503376.503402
   Bellamy RKE, 2018, Arxiv, DOI arXiv:1810.01943
   Khan F. A., 2023, CORR
   Kim D. H., 2021, CHI
   Komorita S. S., 2019, Social dilemmas, V2, P9
   Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kreps D., 1990, Perspectives on Positive Political Economy, V2, P9
   Lai V., 2021, CoRR, abs/2112.11471, P1
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Mayr E., 2019, EUROVIS WORKSHOP TRU, P1
   Metevier B, 2019, ADV NEURAL INFORM PR, P14922
   Munechika D, 2022, IEEE VIS CONF, P45, DOI 10.1109/VIS54862.2022.00018
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Ooge J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P93, DOI 10.1145/3490099.3511140
   Otto S., 2009, Jahrestagung der Deutschen Gesellschaft fur Akustik, P3
   Padilla L., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P12
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Papenmeier A, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3495013
   Paulhus D.L., 2007, Handbook of research methods in personality psychology, P224, DOI DOI 10.1002/0470013435.CH6
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Pielot Martin, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130956
   Poursabzi-Sangdeh F, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445315
   Q.ai, 2022, Forbes, P1
   Qualtrics I., 2013, Qualtrics, P3
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Ross C., 2018, STAT+, P1
   ROTTER JB, 1980, AM PSYCHOL, V35, P1, DOI 10.1037/0003-066X.35.1.1
   Roy PK, 2020, PROCEDIA COMPUT SCI, V167, P2318, DOI 10.1016/j.procs.2020.03.284
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Schloss KB, 2021, IEEE T VIS COMPUT GR, V27, P1022, DOI 10.1109/TVCG.2020.3030434
   Sears DO, 2005, ADV EXP SOC PSYCHOL, V37, P95, DOI 10.1016/S0065-2601(05)37002-X
   Sheard N., 2022, The movement to ban government use of face recognition, P1
   Singer N., 2019, New York Times, P1
   Stark TH, 2019, SOCIOL METHOD RES, P75959
   Stokes C., 2022, IEEE Transactions on Visualization and Computer Graphics, P8
   Supplementary materials for My Model is Unfair, 2023, Do People Even Care? Visual Design Affects Trust and Perceived Bias in Machine Learning
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Thomas PS, 2019, SCIENCE, V366, P999, DOI 10.1126/science.aag3311
   van Berkel N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445365
   Vereschak O., 2021, Proceedings of the ACM Human-Computer Interactions, V5, DOI DOI 10.1145/34760682
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1470, DOI 10.1109/TVCG.2020.3030471
   Wang R., 2020, CHI, P1, DOI [10.1145/3313831.33768131,2, DOI 10.1145/3313831.33768131,2]
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Xie TK, 2022, IEEE T VIS COMPUT GR, V28, P368, DOI 10.1109/TVCG.2021.3114850
   Xiong C., 2019, EUROVIS WORKSHOP REP
   Xiong C., 2022, CHI
   Xiong C., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2023.32892926
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Yin MY, 2019, IEEE CONF WIREL MOB, DOI [10.1109/wimob.2019.8923576, 10.1145/3290605.3300509]
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zürn M, 2017, J ECON PSYCHOL, V61, P74, DOI 10.1016/j.joep.2017.02.016
NR 92
TC 1
Z9 1
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 327
EP 337
DI 10.1109/TVCG.2023.3327192
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500057
PM 37878441
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Kale, A
   Guo, ZY
   Qiao, XL
   Heer, J
   Hullman, J
AF Kale, Alex
   Guo, Ziyang
   Qiao, Xiao Li
   Heer, Jeffrey
   Hullman, Jessica
TI EVM: Incorporating Model Checking into Exploratory Visual Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; model checks; exploratory analysis
ID INFERENCE; SELECTION; VISUALIZATION; PLOTS
AB Visual analytics (VA) tools support data exploration by helping analysts quickly and iteratively generate views of data which reveal interesting patterns. However, these tools seldom enable explicit checks of the resulting interpretations of data-e.g., whether patterns can be accounted for by a model that implies a particular structure in the relationships between variables. We present EVM, a data exploration tool that enables users to express and check provisional interpretations of data in the form of statistical models. EVM integrates support for visualization-based model checks by rendering distributions of model predictions alongside user-generated views of data. In a user study with data scientists practicing in the private and public sector, we evaluate how model checks influence analysts' thinking during data exploration. Our analysis characterizes how participants use model checks to scrutinize expectations about data generating process and surfaces further opportunities to scaffold model exploration in VA tools.
C1 [Kale, Alex] Univ Chicago, Chicago, IL 60637 USA.
   [Guo, Ziyang; Qiao, Xiao Li; Hullman, Jessica] Northwestern Univ, Evanston, IL USA.
   [Heer, Jeffrey] Univ Washington, Seattle, WA USA.
C3 University of Chicago; Northwestern University; University of
   Washington; University of Washington Seattle
RP Kale, A (corresponding author), Univ Chicago, Chicago, IL 60637 USA.
EM kalea@uchicago.edu; ziyangguo2027@u.northwestern.edu; emqiao@gmail.com;
   jheer@uw.edu; jhullman@northwestern.edu
OI Hullman, Jessica/0000-0001-6826-3550; Guo, Ziyang/0009-0004-4200-6774;
   Heer, Jeffrey/0000-0002-6175-1655
FU NSF
FX No Statement Available
CR Alvarez GA, 2011, TRENDS COGN SCI, V15, P122, DOI 10.1016/j.tics.2011.01.003
   [Anonymous], 1996, Journal of Computational and Graphical Statistics, DOI [10.1080/10618600.1996.10474701, DOI 10.1080/10618600.1996.10474701]
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Becker R. A., 1987, Statistical Science, V4, P355, DOI DOI 10.1214/SS/1177013104
   Berk R, 2013, ANN STAT, V41, P802, DOI 10.1214/12-AOS1077
   Buja A., 1987, P 18 S INT, P171
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Choi IK, 2019, IEEE INT CONF INF VI, P116, DOI 10.1109/IV-2.2019.00032
   Choi IK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300298
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Cortez P., 2007, A Data Mining Approach to Predict Forest Fires using Meteorological Data
   Cortez P, 2008, 15TH EUROPEAN CONCURRENT ENGINEERING CONFERENCE/5TH FUTURE BUSINESS TECHNOLOGY CONFERENCE, P5
   Devezer B, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.200805
   Dua D., 2017, UCI Machine Learning Repository
   Gabry J, 2019, J ROY STAT SOC A, V182, P389, DOI 10.1111/rssa.12378
   Gelman A, 2004, J COMPUT GRAPH STAT, V13, P755, DOI 10.1198/106186004X11435
   Gelman A, 2003, INT STAT REV, V71, P369
   Gelman A., 2013, The garden of forking paths: Why multiple comparisons can be a problem, even when there is no "fishing expedition"or "p-hacking"and the research hypothesis was posited ahead of time, V348, P3
   Gelman Andrew., 2020, arXiv, DOI DOI 10.48550/ARXIV.2011.01808
   Green T. R. G., 1990, P 5 C BRIT COMP SOC, P9
   Guo G, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581236
   Harrell FE., 2001, Regression modeling strategies: with applications to linear models, logistic regression, and survival analysis, P53, DOI DOI 10.1007/978-1-4757-3462-1
   Hullman J., 2021, Harvard Data Science Review, DOI DOI 10.1162/99608F92.3AB8A5871,2,3,9
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Jun E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501888
   Kale A., 2022, IEEE Trans. on Visualization and Computer Graphics, V28, DOI DOI 10.1109/TVCG.2021.31148242
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kibler D., 1989, Computational Intelligence, V5, P5
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kim YS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300912
   Koonchanok R., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.34457982,6,8,9
   Kraska T, 2018, PROC VLDB ENDOW, V11, P2150, DOI 10.14778/3229863.3240493
   Loy A, 2016, AM STAT, V70, P202, DOI 10.1080/00031305.2015.1077728
   Majumder M, 2013, J AM STAT ASSOC, V108, P942, DOI 10.1080/01621459.2013.808157
   McNutt A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445356
   McNutt Andrew M, 2023, IEEE Trans Vis Comput Graph, V29, P160, DOI 10.1109/TVCG.2022.3209460
   MILLER AJ, 1984, J ROY STAT SOC A STA, V147, P389, DOI 10.2307/2981576
   Nguyen F, 2020, COMPUT GRAPH FORUM, V39, P33, DOI 10.1111/cgf.13902
   Oberauer K, 2019, PSYCHON B REV, V26, P1596, DOI 10.3758/s13423-019-01645-2
   Ooms J, 2014, Arxiv, DOI arXiv:1406.4806
   Pinheiro J., 2020, Linear and Nonlinear Mixed Effects Models, V3, P5
   Pu XY, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P37
   Rigby RA, 2005, J ROY STAT SOC C, V54, P507, DOI 10.1111/j.1467-9876.2005.00510.x
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Talbot J., personal communication, P3
   Tibshirani RJ, 2016, J AM STAT ASSOC, V111, P600, DOI 10.1080/01621459.2015.1108848
   Tukey J. W., 1966, AFIPS '66 Proceedings of ACM, P695, DOI [10.1145/1464291.14643662, DOI 10.1145/1464291.14643662]
   Tukey J.W., 1977, Exploratory data analysis, V2
   Tukey J. W., 1972, P 18 C DES EXP ARM R, V1010, P2
   TUKEY JW, 1972, Q APPL MATH, V30, P51, DOI 10.1090/qam/99740
   Vanderplas S., 2021, Harvard Data Science Review, P1, DOI DOI 10.1162/99608F92.7D099FD02
   VanderPlas S, 2017, J COMPUT GRAPH STAT, V26, P231, DOI 10.1080/10618600.2016.1209116
   Velleman PF, 2012, WIRES COMPUT STAT, V4, P407, DOI 10.1002/wics.1208
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wickham H., 2019, J Open Source Softw, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]
   Wickham H, 2015, STAT ANAL DATA MIN, V8, P203, DOI 10.1002/sam.11271
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Wilkinson L., 2005, The Grammar of Graphics, DOI DOI 10.1007/0-387-28695-03,4,8
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu Y., 2017, IEEE VIS WORKSH DEAL, P2
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yarkoni T, 2017, PERSPECT PSYCHOL SCI, V12, P1100, DOI 10.1177/1745691617693393
   Zgraggen E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174053
   Zhang DP, 2022, IEEE T VIS COMPUT GR, V28, P443, DOI 10.1109/TVCG.2021.3114679
   Zhao ZG, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P527, DOI 10.1145/3035918.3064019
NR 70
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 208
EP 218
DI 10.1109/TVCG.2023.3326516
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500107
PM 37871070
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Klenert, N
   Lepper, V
   Baum, D
AF Klenert, Nicolas
   Lepper, Verena
   Baum, Daniel
TI A Local Iterative Approach for the Extraction of 2D Manifolds from
   Strongly Curved and Folded Thin-Layer Structures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ridge surface; crease surface; 2D manifold extraction; fast marching;
   virtual unfolding; historical documents
ID VISUALIZATION; CREASES
AB Ridge surfaces represent important features for the analysis of 3-dimensional (3D) datasets in diverse applications and are often derived from varying underlying data including flow fields, geological fault data, and point data, but they can also be present in the original scalar images acquired using a plethora of imaging techniques. Our work is motivated by the analysis of image data acquired using micro-computed tomography (mu CT) of ancient, rolled and folded thin-layer structures such as papyrus, parchment, and paper as well as silver and lead sheets. From these documents we know that they are 2-dimensional (2D) in nature. Hence, we are particularly interested in reconstructing 2D manifolds that approximate the document's structure. The image data from which we want to reconstruct the 2D manifolds are often very noisy and represent folded, densely-layered structures with many artifacts, such as ruptures or layer splitting and merging. Previous ridge-surface extraction methods fail to extract the desired 2D manifold for such challenging data. We have therefore developed a novel method to extract 2D manifolds. The proposed method uses a local fast marching scheme in combination with a separation of the region covered by fast marching into two sub-regions. The 2D manifold of interest is then extracted as the surface separating the two sub-regions. The local scheme can be applied for both automatic propagation as well as interactive analysis. We demonstrate the applicability and robustness of our method on both artificial data as well as real-world data including folded silver and papyrus sheets.
C1 [Klenert, Nicolas; Baum, Daniel] Zuse Inst Berlin, Berlin, Germany.
   [Lepper, Verena] Agypt Museum & Papyrussammlung, Berlin, Germany.
C3 Zuse Institute Berlin
RP Klenert, N (corresponding author), Zuse Inst Berlin, Berlin, Germany.
EM klenert@zib.de; v.lepper@smb.spk-berlin.de; baum@zib.de
OI Klenert, Nicolas/0009-0006-4443-8620; Baum, Daniel/0000-0003-1550-7245
FU German Research Foundation (DFG)
FX No Statement Available
CR Algarni M, 2019, IEEE T PATTERN ANAL, V41, P726, DOI 10.1109/TPAMI.2018.2811810
   Ambellan F, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102178
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   Arnold V. I., 2006, Ordinary Differential Equations, V1
   Axler S., 2019, Measure, integration and real analysis, V1, DOI DOI 10.1007/978-3-030-33143-6
   Barakat S, 2011, COMPUT GRAPH FORUM, V30, P961, DOI 10.1111/j.1467-8659.2011.01945.x
   Barakat S, 2010, PROCEDIA COMPUT SCI, V1, P1703, DOI 10.1016/j.procs.2010.04.192
   Barfod GH, 2015, SCI REP-UK, V5, DOI 10.1038/srep17765
   Baum D, 2017, APPL PHYS A-MATER, V123, DOI 10.1007/s00339-017-0808-6
   Dambrogio J, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21326-w
   Deschamps T, 2001, MED IMAGE ANAL, V5, P281, DOI 10.1016/S1361-8415(01)00046-9
   Eberly D., 1994, Journal of Mathematical Imaging and Vision, V4, P353, DOI 10.1007/BF01262402
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Hale D., 2012, SEG (Society of Exploration Geophysicists) Technical Program Expanded Abstracts, P1, DOI [10.1190/segam2012-0734.1, DOI 10.1190/SEGAM2012-0734.1]
   HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P28, DOI 10.1016/0734-189X(83)90094-4
   Hege H.-C., 1997, Technical report
   Herter F, 2021, COMPUT GRAPH FORUM, V40, P147, DOI 10.1111/cgf.14296
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kindlmann G, 2018, COMPUT GRAPH FORUM, V37, P525, DOI 10.1111/cgf.13439
   Kindlmann G, 2006, LECT NOTES COMPUT SC, V4190, P126
   Kindlmann GL, 2009, IEEE T VIS COMPUT GR, V15, P1415, DOI 10.1109/TVCG.2009.177
   KOENDERINK JJ, 1993, P SOC PHOTO-OPT INS, V2031, P2, DOI 10.1117/12.146617
   Lee J, 2013, INT ADV SELF RES, P205
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Mahnke HE, 2020, J CULT HERIT, V41, P264, DOI 10.1016/j.culher.2019.07.007
   Mirebeau JM, 2014, SIAM J NUMER ANAL, V52, P1573, DOI 10.1137/120861667
   Mocella V., personal communication
   Mocella V, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms6895
   Neuber D., 2012, ZfP-Zeitung, V132, P39
   Peikert R, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P119
   Sadlo F, 2007, IEEE T VIS COMPUT GR, V13, P1456, DOI 10.1109/TVCG.2007.70554
   Sahner J, 2007, IEEE T VIS COMPUT GR, V13, P980, DOI 10.1109/TVCG.2007.1053
   Samko O, 2014, PATTERN RECOGN, V47, P248, DOI 10.1016/j.patcog.2013.06.015
   Schultz T, 2010, IEEE T VIS COMPUT GR, V16, P109, DOI 10.1109/TVCG.2009.44
   Seales WB, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1601247
   Sethian JA, 1999, GEOPHYSICS, V64, P516, DOI 10.1190/1.1444558
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Stanford University Computer Graphics Laboratory, 2014, The Stanford 3D Scanning Repository
   Vavrík D, 2020, ARCHAEOL ANTHROP SCI, V12, DOI 10.1007/s12520-019-00976-4
   Wilster-Hansen B, 2022, ARCHAEOMETRY, V64, P969, DOI 10.1111/arcm.12734
NR 42
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1260
EP 1270
DI 10.1109/TVCG.2023.3327403
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500103
PM 37930919
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Oliver, P
   Zhang, E
   Zhang, Y
AF Oliver, Peter
   Zhang, Eugene
   Zhang, Yue
TI Scalable Hypergraph Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Hypergraph visualization; scalable visualization; polygon layout;
   hypergraph embedding; primal-dual visualization
ID SPARSIFICATION; ALGORITHM; SET; LAYOUT
AB Hypergraph visualization has many applications in network data analysis. Recently, a polygon-based representation for hypergraphs has been proposed with demonstrated benefits. However, the polygon-based layout often suffers from excessive self-intersections when the input dataset is relatively large. In this paper, we propose a framework in which the hypergraph is iteratively simplified through a set of atomic operations. Then, the layout of the simplest hypergraph is optimized and used as the foundation for a reverse process that brings the simplest hypergraph back to the original one, but with an improved layout. At the core of our approach is the set of atomic simplification operations and an operation priority measure to guide the simplification process. In addition, we introduce necessary definitions and conditions for hypergraph planarity within the polygon representation. We extend our approach to handle simultaneous simplification and layout optimization for both the hypergraph and its dual. We demonstrate the utility of our approach with datasets from a number of real-world applications.
C1 [Oliver, Peter; Zhang, Eugene; Zhang, Yue] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
C3 Oregon State University
RP Zhang, E (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
EM oliverpe@oregonstate.edu; zhange@eecs.oregonstate.edu;
   zhangyue@oregonstate.edu
OI Zhang, Eugene/0000-0003-4752-3119; Zhang, Yue/0000-0002-8467-2781
CR Alpert CJ, 1996, APCCAS '96 - IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS '96, P298, DOI 10.1109/APCAS.1996.569275
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   [Anonymous], 2022, World trade organization regional trade agreements database
   Arafat NA, 2017, LECT NOTES COMPUT SC, V10439, P387, DOI 10.1007/978-3-319-64471-4_31
   Benczur A. A., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P47, DOI 10.1145/237814.237827
   Berge C., 1976, North-Holland mathematical library, V6
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Bravo-Hermsdorff G, 2020, Arxiv, DOI arXiv:1902.09702
   Bretto A., 2013, HYPERGRAPH THEORY IN, DOI DOI 10.1007/978-3-319-00080-0
   BUI TN, 1993, PROCEEDINGS OF THE SIXTH SIAM CONFERENCE ON PARALLEL PROCESSING FOR SCIENTIFIC COMPUTING, VOLS 1 AND 2, P445
   Chekuri C, 2018, SIAM J COMPUT, V47, P2118, DOI 10.1137/18M1163865
   Chen Y., Leibniz International Proceedings in Informatics (LIPIcs), V198
   CHENG CK, 1991, IEEE T COMPUT AID D, V10, P1502, DOI 10.1109/43.103500
   CONG J, 1993, ACM IEEE D, P755
   Devine K. D., 2006, P IEEE INT PAR DISTR, P1, DOI DOI 10.1109/IPDPS.2006.1639359
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Frank F., SOFSEM 2021: Theory and Practice of Computer Science, P361
   Garbers J., 1990, 1990 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.90CH2924-9), P520, DOI 10.1109/ICCAD.1990.129970
   Gazepoint, 2021, GP3 EYE TRACK
   Hagen L., 1992, 1992 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.92CH03183-1), P422, DOI 10.1109/ICCAD.1992.279334
   Hagen L., 1991, 1991 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (91CH3026-2), P10, DOI 10.1109/ICCAD.1991.185177
   Hauck S, 1997, IEEE T COMPUT AID D, V16, P849, DOI 10.1109/43.644609
   Hendrickson B, 1995, SUPERCOMP PROC, P626
   Imre M, 2020, COMPUT GRAPH-UK, V87, P89, DOI 10.1016/j.cag.2020.02.004
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jacobsen B, 2021, IEEE T VIS COMPUT GR, V27, P1257, DOI 10.1109/TVCG.2020.3030475
   Kabiljo I, 2017, PROC VLDB ENDOW, V10, P1418, DOI 10.14778/3137628.3137650
   Kapralov M, 2022, ANN IEEE SYMP FOUND, P1159, DOI 10.1109/FOCS52979.2021.00114
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Karypis G, 1999, IEEE T VLSI SYST, V7, P69, DOI 10.1109/92.748202
   Kim B, 2007, INTERACT COMPUT, V19, P630, DOI 10.1016/j.intcom.2007.05.004
   Kogan D, 2015, PROCEEDINGS OF THE 6TH INNOVATIONS IN THEORETICAL COMPUTER SCIENCE (ITCS'15), P366, DOI 10.1145/2688073.2688093
   Kuratowski K., 1930, Fundamenta mathematicae, V15, P271, DOI DOI 10.1007/S10623-014-9982-0
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Ley M., 2005, DBLP Computer Science Bibliography
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Louis A, 2015, ACM S THEORY COMPUT, P713, DOI 10.1145/2746539.2746555
   Micallef L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101717
   Qu BT, 2022, IEEE T VIS COMPUT GR, V28, P633, DOI 10.1109/TVCG.2021.3114759
   Qu BT, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139314
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Rodgers P, 2008, LECT NOTES ARTIF INT, V5223, P13, DOI 10.1007/978-3-540-87730-1_6
   Ron D, 2011, MULTISCALE MODEL SIM, V9, P407, DOI 10.1137/100791142
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Santamaría R, 2010, IEICE T INF SYST, VE93D, P1957, DOI 10.1587/transinf.E93.D.1957
   Simonetto P, 2016, IEEE T VIS COMPUT GR, V22, P678, DOI 10.1109/TVCG.2015.2467992
   Simonetto P, 2009, COMPUT GRAPH FORUM, V28, P967, DOI 10.1111/j.1467-8659.2009.01452.x
   Soma T., 2019, P 30 ANN ACM SIAM S, P2570, DOI DOI 10.1137/1.9781611975482.159
   Spielman DA, 2011, SIAM J COMPUT, V40, P981, DOI 10.1137/08074489X
   Stapleton G, 2012, J VISUAL LANG COMPUT, V23, P163, DOI 10.1016/j.jvlc.2012.02.001
   Stasko J, 2007, IEEE CONF VIS ANAL, P131, DOI 10.1109/VAST.2007.4389006
   Thomassen C., 1984, Progress in graph theory
   Trifunovic A, 2008, J PARALLEL DISTR COM, V68, P563, DOI 10.1016/j.jpdc.2007.11.002
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Zykov A. A., 1974, Russ. Math. Surv., V29, P89, DOI [10.1070/RM1974v029n06ABEH001303, DOI 10.1070/RM1974V029N06ABEH001303]
NR 57
TC 2
Z9 2
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 595
EP 605
DI 10.1109/TVCG.2023.3326599
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500047
PM 37871049
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Dennig, FL
   Miller, M
   Keim, DA
   El-Assady, M
AF Dennig, Frederik L.
   Miller, Matthias
   Keim, Daniel A.
   El-Assady, Mennatallah
TI FS/DS: A Theoretical Framework for the Dual Analysis of Feature Space
   and Data Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Analytical models; Data models; Visual analytics;
   Task analysis; Adaptation models; Taxonomy; dual analysis; feature
   space; data space; feature exploration; mixed data; high-dimensional
   data
ID VISUAL ANALYTICS; QUALITY METRICS; EXPLORATION; VISUALIZATION;
   GENERATION; TYPOLOGY; GUIDANCE; MODEL
AB With the surge of data-driven analysis techniques, there is a rising demand for enhancing the exploration of large high-dimensional data by enabling interactions for the joint analysis of features (i.e., dimensions). Such a dual analysis of the feature space and data space is characterized by three components, 1) a view visualizing feature summaries, 2) a view that visualizes the data records, and 3) a bidirectional linking of both plots triggered by human interaction in one of both visualizations, e.g., Linking & Brushing. Dual analysis approaches span many domains, e.g., medicine, crime analysis, and biology. The proposed solutions encapsulate various techniques, such as feature selection or statistical analysis. However, each approach establishes a new definition of dual analysis. To address this gap, we systematically reviewed published dual analysis methods to investigate and formalize the key elements, such as the techniques used to visualize the feature space and data space, as well as the interaction between both spaces. From the information elicited during our review, we propose a unified theoretical framework for dual analysis, encompassing all existing approaches extending the field. We apply our proposed formalization describing the interactions between each component and relate them to the addressed tasks. Additionally, we categorize the existing approaches using our framework and derive future research directions to advance dual analysis by including state-of-the-art visual analysis techniques to improve data exploration.
C1 [Dennig, Frederik L.] Univ Konstanz, Data Anal & Visualizat Res Grp, D-78457 Constance, Germany.
   [Miller, Matthias] Univ Konstanz, AI Ctr, D-78457 Constance, Germany.
C3 University of Konstanz; University of Konstanz
RP Dennig, FL (corresponding author), Univ Konstanz, Data Anal & Visualizat Res Grp, D-78457 Constance, Germany.
EM frederik.dennig@uni-konstanz.de; matthias.miller@uni-konstanz.de;
   keim@uni-konstanz.de; melassady@ai.ethz.ch
OI El-Assady, Mennatallah/0000-0001-8526-2613; Dennig, Frederik
   L./0000-0003-1116-8450
FU Deutsche Forschungsgemeinschaft(DFG, German Research Foundation)
   [251654672 - TRR 161]; Federal Ministry of Education and the Research of
   Germany (BMBF) through PEGASUS under the Program "Forschung fur
   diezivile Sicherheit"; ETH AI Center
FX This work was supported in part by the Deutsche
   Forschungsgemeinschaft(DFG, German Research Foundation) under Grant
   251654672 - TRR 161 (Project A03), in part by the Federal Ministry of
   Education and the Research of Germany (BMBF) through PEGASUS under the
   Program "Forschung fur diezivile Sicherheit 20182023" and its
   announcement "Zivile Sicherheit - Schutzvor organisierter Kriminalitat
   II," and in part by ETH AI Center.
CR Abuthawabeh M., P 21 EUR C VIS
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Artur E, 2019, COMPUT GRAPH-UK, V84, P160, DOI 10.1016/j.cag.2019.08.015
   Baumgartner C, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P11, DOI 10.1109/ICDM.2004.10112
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Bertin Jacques, 1983, Semiology of graphics
   Bertini E., 2009, Proceedings of the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery: Integrating Automated Analysis with Interactive Exploration, P12
   Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229
   Bibal A, 2021, ARRAY-NY, V11, DOI 10.1016/j.array.2021.100080
   Borg P. J. F., 2005, Modern Multidimensional Scaling: Theoryand Applications
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brownlee J., 2017, "Why one-hot encode data in machine learning?
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   Chen W, 2009, IEEE T VIS COMPUT GR, V15, P1433, DOI 10.1109/TVCG.2009.112
   Dennig FL, 2021, COMPUT GRAPH FORUM, V40, P375, DOI 10.1111/cgf.14314
   Dennig FL, 2019, IEEE CONF VIS ANAL, P69, DOI [10.1109/vast47406.2019.8986940, 10.1109/VAST47406.2019.8986940]
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Doleisch H, 2006, SIMUL-T SOC MOD SIM, V82, P851, DOI 10.1177/0037549707078278
   Dowling M, 2019, IEEE T VIS COMPUT GR, V25, P172, DOI 10.1109/TVCG.2018.2865047
   Endert A, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.73
   Ester H., P 2 C KNOWL DISC
   Evans DW, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038966
   Fernstad SJ, 2013, INFORM VISUAL, V12, P44, DOI 10.1177/1473871612460526
   Fisher M. D., 2018, Making Data Visual-A Practical Guide toUsing Visualization for Insight
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Garrison L, 2021, IEEE T VIS COMPUT GR, V27, P2908, DOI 10.1109/TVCG.2021.3057519
   Görtler J, 2020, IEEE T VIS COMPUT GR, V26, P822, DOI 10.1109/TVCG.2019.2934812
   Green TM, 2008, IEEE CONF VIS ANAL, P91, DOI 10.1109/VAST.2008.4677361
   Hagele David, 2023, IEEE Trans Vis Comput Graph, V29, P23, DOI 10.1109/TVCG.2022.3209420
   Han M., 2000, Data Mining: Concepts and Techniques
   Hinterreiter A, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387165
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Itoh T, 2017, J VISUAL LANG COMPUT, V43, P1, DOI 10.1016/j.jvlc.2017.03.001
   Jentner W, 2018, VISUAL COMPUT, V34, P1225, DOI 10.1007/s00371-018-1483-0
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT, DOI 10.1016/0169-7439(87)80084-92
   Kailing K, 2004, SIAM PROC S, P246
   Kailing K, 2003, LECT NOTES ARTIF INT, V2838, P241
   Kandogan E., 2000, P IEEE INF VIS S, P12
   Keim D. A., 1996, SIGMOD Record, V25, P35, DOI 10.1145/245882.245896
   Keim J., 2010, Mastering theInformation Age-Solving Problems With Visual Analytics, P32
   Koprinska Irena, 2009, New Frontiers in Applied Data Mining. PAKDD 2009. International Workshops. Revised Selected Papers, P106
   Krause J, 2016, SYMP LARG DATA ANAL, P11, DOI 10.1109/LDAV.2016.7874305
   Kriegel HP, 2012, WIRES DATA MIN KNOWL, V2, P351, DOI 10.1002/widm.1057
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Landesberger S., 2014, of Human Centric Visualization, P653, DOI [10.1007/978-1-4614-7485-2_26, DOI 10.1007/978-1-4614-7485-2_26]
   Lekschas F, 2021, IEEE T VIS COMPUT GR, V27, P358, DOI 10.1109/TVCG.2020.3028948
   Mehri M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4080097
   Miller M, 2022, COMPUT GRAPH FORUM, V41, P283, DOI 10.1111/cgf.14540
   Minghim R, 2006, PROC SPIE, V6060, DOI 10.1117/12.650880
   Muller J, 2021, IEEE T VIS COMPUT GR, V27, P2953, DOI 10.1109/TVCG.2021.3056424
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Nováková L, 2009, LECT NOTES COMPUT SC, V5722, P56, DOI 10.1007/978-3-642-04125-9_9
   Pages J., 2014, MULTIPLE FACTOR ANAL, DOI DOI 10.1201/B17700
   Perez-Messina I, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14555
   Rauber PE, 2018, INFORM VISUAL, V17, P282, DOI 10.1177/1473871617713337
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Self R. K., 2016, P WORKSH HUM IN THE
   Simoudis E., 1996, Data Mining, p65 H
   Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039
   Soriano-Vargas A, 2020, INFORM VISUAL, V19, P3, DOI 10.1177/1473871619858937
   Sperrle Fabian, 2023, IEEE Trans Vis Comput Graph, V29, P1124, DOI 10.1109/TVCG.2022.3209393
   Steinparz A. P., 2019, P 10 INT EUROVIS WOR, P19
   Turkay C, 2017, NEUROCOMPUTING, V268, P153, DOI 10.1016/j.neucom.2016.11.087
   Turkay C, 2017, IEEE T VIS COMPUT GR, V23, P131, DOI 10.1109/TVCG.2016.2598470
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   Turkay C, 2014, IEEE COMPUT GRAPH, V34, P38, DOI 10.1109/MCG.2014.1
   Turkay C, 2012, IEEE T VIS COMPUT GR, V18, P2621, DOI 10.1109/TVCG.2012.256
   Turkay C, 2011, IEEE T VIS COMPUT GR, V17, P2591, DOI 10.1109/TVCG.2011.178
   Tzeng E. B., P IEEE 14 VIS C
   van der Corput P, 2016, COMPUT GRAPH FORUM, V35, P31, DOI 10.1111/cgf.12879
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Wang L, 2012, IEEE T VIS COMPUT GR, V18, P121, DOI 10.1109/TVCG.2011.23
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Ward M. O., 2009, Encyclopedia of Database Systems, P1626
   Weaver C, 2010, IEEE T VIS COMPUT GR, V16, P192, DOI 10.1109/TVCG.2009.94
   Wei H., P IEEE PAC VIS S
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yuan XR, 2013, IEEE T VIS COMPUT GR, V19, P2625, DOI 10.1109/TVCG.2013.150
   Zanabria GG, 2016, COMPUT GRAPH-UK, V60, P107, DOI 10.1016/j.cag.2016.08.007
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
   Zhao JQ, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P161, DOI [10.1109/VISUAL.2019.8933619, 10.1109/visual.2019.8933619]
NR 84
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5165
EP 5182
DI 10.1109/TVCG.2023.3288356
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400025
PM 37342951
DA 2024-08-05
ER

PT J
AU Wu, MG
   Sun, YJ
   Jiang, SJ
AF Wu, Mingguang
   Sun, Yanjie
   Jiang, Shangjing
TI Adaptive Color Transfer From Images to Terrain Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Elevation colors; color transfer; terrain visualization
ID SEMANTIC DISCRIMINABILITY; DEPTH; MODEL
AB Terrain mapping is not only dedicated to communicating how high or steep a landscape is but can also help to indicate how we feel about a place. However, crafting effective and expressive elevation colors is challenging for both nonexperts and experts. In this article, we present a two-step image-to-terrain color transfer method that can transfer color from arbitrary images to diverse terrain models. First, we present a new image color organization method that organizes discrete, irregular image colors into a continuous, regular color grid that facilitates a series of color operations, such as local and global searching, categorical color selection and sequential color interpolation. Second, we quantify a series of cartographic concerns about elevation color crafting, such as the "lower, higher" principle, color conventions, and aerial perspectives. We also define color similarity between images and terrain visualizations with aesthetic quality. We then mathematically formulate image-to-terrain color transfer as a dual-objective optimization problem and offer a heuristic searching method to solve the problem. Finally, we compare elevation colors from our method with a standard color scheme and a representative color scale generation tool based on four test terrains. The evaluations show that the elevation colors from the proposed method are most effective and that our results are visually favorable. We also showcase that our method can transfer emotion from images to terrain visualizations.
C1 [Wu, Mingguang; Sun, Yanjie; Jiang, Shangjing] Nanjing Normal Univ, Coll Geog Sci, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing Normal University
RP Sun, YJ (corresponding author), Nanjing Normal Univ, Coll Geog Sci, Nanjing 210023, Jiangsu, Peoples R China.
EM wmg@njnu.edu.cn; yanjiesun@njnu.edu.cn; 211301018@njnu.edu.cn
OI Sun, Yanjie/0000-0002-7099-5133; Jiang, Shangjing/0000-0002-6920-3901
FU National Natural Science Foundation of China [41971417, 41930104];
   Postgraduate Research &Practice Innovation Program of Jiangsu Province
   [KYCX22_1575, KYCX22_1559]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 41971417 and 41930104 and in part by
   the Postgraduate Research &Practice Innovation Program of Jiangsu
   Province under Grants KYCX22_1575 and KYCX22_1559
CR Anderson C. L., 2018, M.S. thesis,
   Anderson CL, 2022, IEEE T VIS COMPUT GR, V28, P2867, DOI 10.1109/TVCG.2021.3050118
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Brassel K., 1974, The American Cartographer, V1, P15
   Bratkova M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559759
   Brewer C.A., 2003, Cartography and Geographic Information Science, V30, P5
   Brewer C.A., 1993, Proceedings, Eleventh International Symposium on Computer-Assisted Cartography (Auto- Carto-11), Minneapolis, October/November, P328
   Bujack R, 2018, IEEE T VIS COMPUT GR, V24, P923, DOI 10.1109/TVCG.2017.2743978
   Casey EdwardS., 2005, Earth-Mapping: Artists Reshaping Landscape
   Clelandt M., 1937, A Practical Description of the Munsell Color System: WithSuggestions For Its Use
   Deb K, 2014, Search methodologies, DOI DOI 10.1007/978-1-4614-6940-7_15
   EGUSA H, 1983, PERCEPTION, V12, P167, DOI 10.1068/p120167
   Eyton J.Ronald., 1990, Cartographica: The International Journal for Geographic Information and Geovisualization, V27, P20
   Frigo O, 2015, LECT NOTES COMPUT SC, V9005, P655, DOI 10.1007/978-3-319-16811-1_43
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Greenfield Gary., 2005, COMPUTATIONAL AESTHE
   Guibal CRC, 2004, PSYCHOL RES-PSYCH FO, V69, P30, DOI 10.1007/s00426-003-0167-0
   Häberling C, 2002, ISPRS J PHOTOGRAMM, V57, P134, DOI 10.1016/S0924-2716(02)00113-2
   Imhof E., 1982, CARTOGRAPHIC RELIEF
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jenny B., 2001, Car- tographica: Int. J. Geographic Inf. Geovisualization, V38, P67
   Jenny B, 2021, CARTOGR GEOGR INF SC, V48, P21, DOI 10.1080/15230406.2020.1813052
   Jenny B, 2021, IEEE T VIS COMPUT GR, V27, P1225, DOI 10.1109/TVCG.2020.3030456
   Jenny H, 2013, CARTOGR GEOGR INF SC, V40, P297, DOI 10.1080/15230406.2013.795001
   Jolivet J., 2009, P C GISCIENCE RES PO, P1
   Kennelly P. J., 2009, P INT CART C
   Kita N, 2016, COMPUT GRAPH FORUM, V35, P127, DOI 10.1111/cgf.13010
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Li YJ, 2018, LECT NOTES COMPUT SC, V11207, P468, DOI 10.1007/978-3-030-01219-9_28
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Montello DR, 2018, HANDBOOK OF BEHAVIORAL AND COGNITIVE GEOGRAPHY, P177
   Moon P, 1944, J OPT SOC AM, V34, P46, DOI 10.1364/JOSA.34.000046
   Mukherjee K, 2022, IEEE T VIS COMPUT GR, V28, P697, DOI 10.1109/TVCG.2021.3114780
   Nardini P, 2021, IEEE T VIS COMPUT GR, V27, P3048, DOI 10.1109/TVCG.2019.2961674
   Neumann A., 2005, P 1 EUR C COMP AESTH, P111
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Omkar SN, 2011, APPL SOFT COMPUT, V11, P489, DOI 10.1016/j.asoc.2009.12.008
   Ou LC, 2006, COLOR RES APPL, V31, P191, DOI 10.1002/col.20208
   Patterson T., 2001, Creating swiss-style shaded relief in photoshop
   Patterson Tom., 2011, Cartographic Perspectives, V69, P31
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Samsel F, 2021, 2021 IEEE VIS ARTS PROGRAM (VISAP 2021), P20, DOI 10.1109/VISAP52981.2021.00009
   Schloss KB, 2021, IEEE T VIS COMPUT GR, V27, P1022, DOI 10.1109/TVCG.2020.3030434
   Schloss KB, 2020, J OPT SOC AM A, V37, P813, DOI 10.1364/JOSAA.383588
   Schloss KB, 2011, ATTEN PERCEPT PSYCHO, V73, P551, DOI 10.3758/s13414-010-0027-0
   Schoenlein Melissa A, 2023, IEEE Trans Vis Comput Graph, V29, P385, DOI 10.1109/TVCG.2022.3209443
   Senanayake C. R., 2007, P BRIT MACH VIS C, P1
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Susanto Y, 2020, IEEE INTELL SYST, V35, P96, DOI 10.1109/MIS.2020.2992799
   Tsai YH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925942
   Wilms L, 2018, PSYCHOL RES-PSYCH FO, V82, P896, DOI 10.1007/s00426-017-0880-8
   Wu FZ, 2013, COMPUT GRAPH FORUM, V32, P190, DOI 10.1111/cgf.12008
   Wu MG, 2022, CARTOGR GEOGR INF SC, V49, P289, DOI 10.1080/15230406.2021.1982009
   Wu MG, 2019, CARTOGR J, V56, P161, DOI 10.1080/00087041.2018.1507182
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 58
TC 2
Z9 2
U1 3
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5538
EP 5552
DI 10.1109/TVCG.2023.3295122
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400035
PM 37440387
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Xu, WP
   Zhang, P
   Yu, ML
   Yang, L
   Wang, WM
   Liu, LG
AF Xu, Wenpeng
   Zhang, Peng
   Yu, Menglin
   Yang, Li
   Wang, Weiming
   Liu, Ligang
TI Topology Optimization Via Spatially-Varying TPMS
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Microstructure; Optimization; Topology; Lattices; Three-dimensional
   printing; Shape; Three-dimensional displays; Additive manufacturing;
   microstructure; topology optimization; triply periodic minimal surface
ID POROUS SCAFFOLD DESIGN; LEVEL SET METHOD; LATTICE STRUCTURES; FEATURE
   EVOLUTION; CODE WRITTEN; HOMOGENIZATION; MICROSTRUCTURES; SPLINES;
   MODELS; INFILL
AB Structural design with multi-family triply periodic minimal surfaces (TPMS) is a meaningful work that can combine the advantages of different types of TPMS. However, very few methods consider the influence of the blending of different TPMS on structural performance, and the manufacturability of final structure. Therefore, this work proposes a method to design manufacturable microstructures with topology optimization (TO) based on spatially-varying TPMS. In our method, different types of TPMS are simultaneously considered in the optimization to maximize the performance of designed microstructure. The geometric and mechanical properties of the unit cells generated with TPMS, that is minimal surface lattice cell (MSLC), are analyzed to obtain the performance of different types of TPMS. In the designed microstructure, MSLCs of different types are smoothly blended with an interpolation method. To analyze the influence of deformed MSLCs on the performance of the final structure, the blending blocks are introduced to describe the connection cases between different types of MSLCs. The mechanical properties of deformed MSLCs are analyzed and applied in TO process to reduce the influence of deformed MSLCs on the performance of final structure. The infill resolution of MSLC within a given design domain is determined according to the minimal printable wall thickness of MSLC and structural stiffness. Both numerical and physical experimental results demonstrate the effectiveness of the proposed method.
C1 [Xu, Wenpeng; Zhang, Peng] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454099, Henan, Peoples R China.
   [Yu, Menglin] Henan Polytech Univ, Sch Mech & Power Engn, Jiaozuo 454099, Henan, Peoples R China.
   [Yang, Li] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China.
   [Wang, Weiming] Dalian Univ Technol, Sch Math Sci, Key Lab Computat Math & Data Intelligence Liaoning, Dalian 116024, Peoples R China.
   [Wang, Weiming] Univ Manchester, Dept Mech Aerosp & Civil Engn, Manchester M13 9PL, England.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.
C3 Henan Polytechnic University; Henan Polytechnic University; Dalian
   University of Technology; Dalian University of Technology; University of
   Manchester; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Wang, WM (corresponding author), Dalian Univ Technol, Sch Math Sci, Key Lab Computat Math & Data Intelligence Liaoning, Dalian 116024, Peoples R China.; Wang, WM (corresponding author), Univ Manchester, Dept Mech Aerosp & Civil Engn, Manchester M13 9PL, England.
EM wpxu08@gmail.com; hpuzp98@qq.com; 2510392773@qq.com; 690660794@qq.com;
   wwmdlut@gmail.com; lgliu@ustc.edu.cn
RI Wang, Weiming/H-4944-2017; Xu, Wenpeng/JQW-3191-2023
OI Wang, Weiming/0000-0001-6289-0094; Zhang, Peng/0009-0005-1468-7346; Xu,
   Wenpeng/0000-0002-0852-4904
FU National Natural Science Foundation of China [62172073, 62025207];
   Natural Science Foundation of Liaoning Province [2021-MS-110]; Key
   Scientific Research Projects of Colleges and Universities of Henan
   Province [21A520017]; National key research and development program
   [2022YFB3303000]; Fundamental Research Fund [DUT22QN212]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 62172073, and 62025207, in part by the Natural
   Science Foundation of Liaoning Province under Grant 2021-MS-110, in part
   by the Key Scientific Research Projects of Colleges and Universities of
   Henan Province under Grant 21A520017, in part by the National key
   research and development program under Grant 2022YFB3303000, and in part
   by Fundamental Research Fund under Grant DUT22QN212.
CR 3ds, 2021, Abaqus
   Abueidda DW, 2016, MECH MATER, V95, P102, DOI 10.1016/j.mechmat.2016.01.004
   Al-Ketan O, 2020, J MECH BEHAV BIOMED, V102, DOI 10.1016/j.jmbbm.2019.103520
   Andreassen E, 2014, MECH MATER, V69, P1, DOI 10.1016/j.mechmat.2013.09.018
   [Anonymous], 2011, P INT SOL FREEF FABR, DOI DOI 10.1017/CBO9781107415324.004
   Aremu AO, 2016, C PROC SOC EXP MECH, P83, DOI 10.1007/978-3-319-22443-5_10
   Bendsoe M.P., 2003, TOPOLOGY OPTIMIZATIO, DOI DOI 10.1063/1.3278595
   BENDSOE MP, 1988, COMPUT METHOD APPL M, V71, P197, DOI 10.1016/0045-7825(88)90086-2
   Challis VJ, 2008, INT J SOLIDS STRUCT, V45, P4130, DOI 10.1016/j.ijsolstr.2008.02.025
   Cheng L, 2018, STRUCT MULTIDISCIP O, V58, P511, DOI 10.1007/s00158-018-1905-7
   Cheng L, 2018, COMPUT METHOD APPL M, V332, P408, DOI 10.1016/j.cma.2017.12.024
   Feng JW, 2018, COMPUT METHOD APPL M, V336, P333, DOI 10.1016/j.cma.2018.03.007
   Feng YX, 2022, MATER DESIGN, V222, DOI 10.1016/j.matdes.2022.111078
   Gao W, 2015, COMPUT AIDED DESIGN, V69, P65, DOI 10.1016/j.cad.2015.04.001
   Garner E, 2019, ADDIT MANUF, V26, P65, DOI 10.1016/j.addma.2018.12.007
   Grigorovitch M, 2017, COMPUT STRUCT, V179, P95, DOI 10.1016/j.compstruc.2016.11.001
   Grigorovitch M, 2021, COMPUT MECH, V68, P1437, DOI 10.1007/s00466-021-02077-3
   Hu JB, 2022, IEEE T VIS COMPUT GR, V28, P2615, DOI 10.1109/TVCG.2020.3037697
   Hu JB, 2019, VISUAL COMPUT, V35, P949, DOI 10.1007/s00371-019-01672-z
   Huang XD, 2010, STRUCT MULTIDISCIP O, V41, P671, DOI 10.1007/s00158-010-0487-9
   Lee M, 2018, COMPUT AIDED DESIGN, V101, P23, DOI 10.1016/j.cad.2018.03.007
   Li DW, 2019, MATERIALS, V12, DOI 10.3390/ma12132183
   Li DW, 2019, J MECH DESIGN, V141, DOI 10.1115/1.4042617
   Li DW, 2018, COMPUT AIDED DESIGN, V104, P87, DOI 10.1016/j.cad.2018.06.003
   Li DW, 2016, INT J ADV MANUF TECH, V83, P1627, DOI 10.1007/s00170-015-7704-z
   Liu K, 2014, STRUCT MULTIDISCIP O, V50, P1175, DOI 10.1007/s00158-014-1107-x
   Liu L., 2014, P SIGGRAPH ASIA COUR, P1
   Liu PQ, 2021, COMPUT GRAPH-UK, V100, P106, DOI 10.1016/j.cag.2021.07.021
   Liu XL, 2022, COMPUT METHOD APPL M, V390, DOI 10.1016/j.cma.2021.114466
   Liu XP, 2018, GRAPH MODELS, V98, P14, DOI 10.1016/j.gmod.2018.05.001
   Livesu M, 2017, COMPUT GRAPH FORUM, V36, P537, DOI 10.1111/cgf.13147
   Loh GH, 2018, ADDIT MANUF, V23, P34, DOI 10.1016/j.addma.2018.06.023
   Lu L, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601168
   Osanov M, 2016, ANNU REV MATER RES, V46, P211, DOI 10.1146/annurev-matsci-070115-031826
   Plocher J, 2019, MATER DESIGN, V183, DOI 10.1016/j.matdes.2019.108164
   Rajon DA, 2003, COMPUT MED IMAG GRAP, V27, P411, DOI 10.1016/S0895-6111(03)00032-6
   SIGMUND O, 1994, INT J SOLIDS STRUCT, V31, P2313, DOI 10.1016/0020-7683(94)90154-6
   Sigmund O, 1997, J MECH PHYS SOLIDS, V45, P1037, DOI 10.1016/S0022-5096(96)00114-7
   Sigmund O, 2001, STRUCT MULTIDISCIP O, V21, P120, DOI 10.1007/s001580050176
   Sigmund O, 2013, STRUCT MULTIDISCIP O, V48, P1031, DOI 10.1007/s00158-013-0978-6
   SVANBERG K, 1987, INT J NUMER METH ENG, V24, P359, DOI 10.1002/nme.1620240207
   Vijayavenkataraman S, 2018, ACS APPL BIO MATER, V1, P259, DOI 10.1021/acsabm.8b00052
   Wang MY, 2019, COMPUT METHOD APPL M, V349, P378, DOI 10.1016/j.cma.2019.02.026
   Wang MY, 2003, COMPUT METHOD APPL M, V192, P227, DOI 10.1016/S0045-7825(02)00559-5
   Wang SF, 2022, COMPUT AIDED DESIGN, V142, DOI 10.1016/j.cad.2021.103123
   Wang WM, 2023, ADDIT MANUF, V67, DOI 10.1016/j.addma.2023.103507
   Wang WM, 2022, ADDIT MANUF, V54, DOI 10.1016/j.addma.2022.102717
   Wang WM, 2018, IEEE T VIS COMPUT GR, V24, P2787, DOI 10.1109/TVCG.2017.2764462
   Wang WM, 2017, COMPUT GRAPH-UK, V66, P154, DOI 10.1016/j.cag.2017.05.022
   Wang WM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508382
   Wang X, 2018, ADDIT MANUF, V20, P189, DOI 10.1016/j.addma.2017.10.001
   Wu J, 2021, STRUCT MULTIDISCIP O, V63, P1455, DOI 10.1007/s00158-021-02881-8
   Wu J, 2021, IEEE T VIS COMPUT GR, V27, P43, DOI 10.1109/TVCG.2019.2938946
   Wu J, 2018, IEEE T VIS COMPUT GR, V24, P1127, DOI 10.1109/TVCG.2017.2655523
   Wu J, 2016, COMPUT AIDED DESIGN, V80, P32, DOI 10.1016/j.cad.2016.07.006
   Xie Y, 2017, VIS INFORM, V1, P9, DOI 10.1016/j.visinf.2017.01.002
   Xu SQ, 2016, MATER DESIGN, V93, P443, DOI 10.1016/j.matdes.2016.01.007
   Xu WP, 2022, IEEE T VIS COMPUT GR, V28, P4462, DOI 10.1109/TVCG.2021.3091509
   Yan CZ, 2014, MATER DESIGN, V55, P533, DOI 10.1016/j.matdes.2013.10.027
   Yan X, 2020, IEEE T VIS COMPUT GR, V26, P3037, DOI 10.1109/TVCG.2019.2914044
   Yang N, 2014, COMPUT AIDED DESIGN, V56, P11, DOI 10.1016/j.cad.2014.06.006
   Yang Y, 2018, COMPUT GRAPH-UK, V70, P148, DOI 10.1016/j.cag.2017.07.005
   Yoo DJ, 2015, INT J PRECIS ENG MAN, V16, P2021, DOI 10.1007/s12541-015-0263-2
   Yoo DJ, 2011, INT J PRECIS ENG MAN, V12, P61, DOI 10.1007/s12541-011-0008-9
   Yu SX, 2019, MATER DESIGN, V182, DOI 10.1016/j.matdes.2019.108021
   Zadpoor AA, 2016, MATER HORIZ, V3, P371, DOI 10.1039/c6mh00065g
   Zhang SN, 2022, INT J MECH SCI, V235, DOI 10.1016/j.ijmecsci.2022.107713
   Zhang XL, 2015, COMPUT AIDED GEOM D, V35-36, P149, DOI 10.1016/j.cagd.2015.03.012
   Zheng XY, 2014, SCIENCE, V344, P1373, DOI 10.1126/science.1252291
   Zhou H, 2021, J MECH PHYS SOLIDS, V148, DOI 10.1016/j.jmps.2021.104298
   Zong HM, 2019, COMPUT METHOD APPL M, V354, P487, DOI 10.1016/j.cma.2019.05.029
NR 71
TC 2
Z9 2
U1 12
U2 33
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4570
EP 4587
DI 10.1109/TVCG.2023.3268068
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400036
PM 37074903
DA 2024-08-05
ER

PT J
AU Zhang, J
   Zhou, KN
   Luximon, Y
   Lee, TY
   Li, P
AF Zhang, Jie
   Zhou, Kangneng
   Luximon, Yan
   Lee, Tong-Yee
   Li, Ping
TI MeshWGAN: Mesh-to-Mesh Wasserstein GAN With Multi-Task Gradient Penalty
   for 3D Facial Geometric Age Transformation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Age transformation; 3D face geometry; MeshWGAN; mesh generative
   adversarial networks; multi-task gradient penalty
ID FACE; IMAGE
AB As the metaverse develops rapidly, 3D facial age transformation is attracting increasing attention, which may bring many potential benefits to a wide variety of users, e.g., 3D aging figures creation, 3D facial data augmentation and editing. Compared with 2D methods, 3D face aging is an underexplored problem. To fill this gap, we propose a new mesh-to-mesh Wasserstein generative adversarial network (MeshWGAN) with a multi-task gradient penalty to model a continuous bi-directional 3D facial geometric aging process. To the best of our knowledge, this is the first architecture to achieve 3D facial geometric age transformation via real 3D scans. As previous image-to-image translation methods cannot be directly applied to the 3D facial mesh, which is totally different from 2D images, we built a mesh encoder, decoder, and multi-task discriminator to facilitate mesh-to-mesh transformations. To mitigate the lack of 3D datasets containing children's faces, we collected scans from 765 subjects aged 5-17 in combination with existing 3D face databases, which provided a large training dataset. Experiments have shown that our architecture can predict 3D facial aging geometries with better identity preservation and age closeness compared to 3D trivial baselines. We also demonstrated the advantages of our approach via various 3D face-related graphics applications.
C1 [Zhang, Jie; Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Zhang, Jie; Luximon, Yan; Li, Ping] Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
   [Zhou, Kangneng] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
   [Luximon, Yan] Lab Artificial Intelligence Design, Hong Kong, Peoples R China.
   [Lee, Tong-Yee] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
C3 Hong Kong Polytechnic University; Hong Kong Polytechnic University;
   University of Science & Technology Beijing; National Cheng Kung
   University
RP Li, P (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.; Luximon, Y; Li, P (corresponding author), Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
EM peterzhang1130@163.com; elliszkn@163.com; yan.luximon@polyu.edu.hk;
   tonylee@ncku.edu.tw; p.li@polyu.edu.hk
RI Zhang, Jie/I-1032-2019; Luximon, Yan/A-7946-2010
OI Zhang, Jie/0000-0001-8219-5590; Luximon, Yan/0000-0003-2843-847X; Li,
   Ping/0000-0002-1503-0240; Zhou, Kangneng/0000-0001-9102-9527
FU Research Grants Council of Hong Kong [PolyU 15603419]; National Science
   and Technology Council, Taiwan [110-2221-E-006-135-MY3]; Hong Kong
   Polytechnic University [P0042740, P0030419, P0043906, P0044520]
FX This work was supported in part by the Research Grants Council of Hong
   Kong under Grant PolyU 15603419, in part by the National Science and
   Technology Council under Grant 110-2221-E-006-135-MY3, Taiwan, and in
   part by The Hong Kong Polytechnic University under Grants P0042740,
   P0030419, P0043906, and P0044520.
CR Alaluf Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459805
   Albert AM, 2007, FORENSIC SCI INT, V172, P1, DOI 10.1016/j.forsciint.2007.03.015
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bagdanov Andrew D, 2011, P JOINT ACM WORKSH H, P79
   Bao LC, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3472954
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Bouritsas G, 2019, IEEE I CONF COMP VIS, P7212, DOI 10.1109/ICCV.2019.00731
   Bruna J., 2014, C TRACK P
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dai H, 2020, INT J COMPUT VISION, V128, P547, DOI 10.1007/s11263-019-01260-7
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Duong C. N., 2018, ARXIV
   Egger B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3395208
   Fang H, 2020, IEEE COMPUT SOC CONF, P3500, DOI 10.1109/CVPRW50498.2020.00410
   Fey M., 2019, ICLR WORKSHOP REPRES
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gecer Baris, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P415, DOI 10.1007/978-3-030-58526-6_25
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Georgopoulos M, 2020, IEEE COMPUT SOC CONF, P66, DOI 10.1109/CVPRW50498.2020.00015
   Gong SW, 2019, IEEE INT CONF COMP V, P4141, DOI 10.1109/ICCVW.2019.00509
   He S., 2021, P IEEE INT C COMP VI, P3877
   He ZL, 2019, IEEE I CONF COMP VIS, P9439, DOI 10.1109/ICCV.2019.00953
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang ZH, 2019, PROC CVPR IEEE, P11949, DOI 10.1109/CVPR.2019.01223
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kingma D.P., 2015, PROC INT C LEARN RE
   Li P, 2022, IEEE T NEUR NET LEAR, V33, P5346, DOI 10.1109/TNNLS.2021.3070463
   Lim I, 2019, LECT NOTES COMPUT SC, V11131, P349, DOI 10.1007/978-3-030-11015-4_26
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Matthews HS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91465-z
   Moschoglou S, 2020, INT J COMPUT VISION, V128, P2534, DOI 10.1007/s11263-020-01329-8
   Olivier N, 2023, COMPUT GRAPH-UK, V110, P69, DOI 10.1016/j.cag.2022.12.004
   Or-El Roy, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P739, DOI 10.1007/978-3-030-58539-6_44
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Paszke A, 2019, ADV NEUR IN, V32
   Peipei Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P86, DOI 10.1007/978-3-030-58580-8_6
   Ploumpis S, 2021, IEEE T PATTERN ANAL, V43, P4142, DOI 10.1109/TPAMI.2020.2991150
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Reddi S. J., 2018, P INT C LEARN REPR, P23
   Sheng B, 2019, IEEE T VIS COMPUT GR, V25, P3216, DOI 10.1109/TVCG.2018.2866090
   Smith WAP, 2020, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR42600.2020.00506
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wu YQ, 2022, IEEE T CIRC SYST VID, V32, P4338, DOI 10.1109/TCSVT.2021.3133313
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Yao X, 2021, INT C PATT RECOG, P8624, DOI 10.1109/ICPR48806.2021.9412383
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang J, 2022, INT J IND ERGONOM, V90, DOI 10.1016/j.ergon.2022.103321
   Zhang J, 2022, COMPUT AIDED DESIGN, V150, DOI 10.1016/j.cad.2022.103271
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 56
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4927
EP 4940
DI 10.1109/TVCG.2023.3284500
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400023
PM 37307186
DA 2024-08-05
ER

PT J
AU Goudé, I
   Bruckert, A
   Olivier, AH
   Pettré, J
   Cozot, R
   Bouatouch, K
   Christie, M
   Hoyet, L
AF Goude, Ific
   Bruckert, Alexandre
   Olivier, Anne-Helene
   Pettre, Julien
   Cozot, Remi
   Bouatouch, Kadi
   Christie, Marc
   Hoyet, Ludovic
TI Real-Time Multi-Map Saliency-Driven Gaze Behavior for Non-Conversational
   Characters
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Animation; Visualization; Solid modeling; Real-time
   systems; Biological system modeling; Head; dataset; eye-tracking data;
   gaze behavior; neural networks; simulation
ID EYE-MOVEMENTS; ATTENTION; MODEL
AB Gaze behavior of virtual characters in video games and virtual reality experiences is a key factor of realism and immersion. Indeed, gaze plays many roles when interacting with the environment; not only does it indicate what characters are looking at, but it also plays an important role in verbal and non-verbal behaviors and in making virtual characters alive. Automated computing of gaze behaviors is however a challenging problem, and to date none of the existing methods are capable of producing close-to-real results in an interactive context. We therefore propose a novel method that leverages recent advances in several distinct areas related to visual saliency, attention mechanisms, saccadic behavior modelling, and head-gaze animation techniques. Our approach articulates these advances to converge on a multi-map saliency-driven model which offers real-time realistic gaze behaviors for non-conversational characters, together with additional user-control over customizable features to compose a wide variety of results. We first evaluate the benefits of our approach through an objective evaluation that confronts our gaze simulation with ground truth data using an eye-tracking dataset specifically acquired for this purpose. We then rely on subjective evaluation to measure the level of realism of gaze animations generated by our method, in comparison with gaze animations captured from real actors. Our results show that our method generates gaze behaviors that cannot be distinguished from captured gaze animations. Overall, we believe that these results will open the way for more natural and intuitive design of realistic and coherent gaze animations for real-time applications.
C1 [Goude, Ific; Olivier, Anne-Helene; Pettre, Julien; Bouatouch, Kadi; Christie, Marc; Hoyet, Ludovic] Univ Rennes, Inria, CNRS, IRISA, F-35000 Rennes, France.
   [Bruckert, Alexandre] Nantes Univ, CNRS, IRCCyN, UMR 6004,Eecole Cent Nantes,LS2N, F-44000 Nantes, France.
   [Cozot, Remi] Littoral Opal Coast Univ, F-59140 Dunkerque, France.
C3 Inria; Universite de Rennes; Centre National de la Recherche
   Scientifique (CNRS); Nantes Universite; Ecole Centrale de Nantes; Centre
   National de la Recherche Scientifique (CNRS)
RP Bruckert, A (corresponding author), Nantes Univ, CNRS, IRCCyN, UMR 6004,Eecole Cent Nantes,LS2N, F-44000 Nantes, France.
EM ific.goude@irisa.fr; alexandre.bruckert@univ-nantes.fr;
   anne-helene.olivier@univ-rennes2.fr; julien.pettre@inria.fr;
   remi.cozot@univ-littoral.fr; kadi.bouatouch@irisa.fr;
   marc.christie@irisa.fr; ludovic.hoyet@inria.fr
RI Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049; Pettre, Julien/0000-0003-1812-1436;
   Bruckert, Alexandre/0000-0003-2623-4975
CR Abid M, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901782
   Agil U, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1806
   Andrist S., 2012, Proceedings of the International Conference on Human Factors in Computing, CHI '12, P705
   Arpa Sami, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P168, DOI 10.1007/978-3-642-25090-3_15
   Bannier K, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204560
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715
   BOTZEL K, 1993, BRAIN, V116, P337, DOI 10.1093/brain/116.2.337
   Brockmole JR, 2005, PSYCHON B REV, V12, P1061, DOI 10.3758/BF03206444
   Bruckert A, 2021, NEUROCOMPUTING, V453, P693, DOI 10.1016/j.neucom.2020.06.131
   Bulbul A., 2010, P 7 S APPL PERC GRAP, P81
   Courty N., 2003, Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429), pIII
   David EJ, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P432, DOI 10.1145/3204949.3208139
   Djilali YAD, 2021, IEEE INT CONF COMP V, P3743, DOI 10.1109/ICCVW54120.2021.00418
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Gillies M., 2001, Tech. Rep. TR522
   Gillies MFP, 2002, J VISUAL COMP ANIMAT, V13, P287, DOI 10.1002/vis.296
   Gu E, 2007, LECT NOTES ARTIF INT, V4840, P277
   Imaoka Y, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.572938
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Jarodzka K., 2010, P 2010 S EYE TRACKIN, P211, DOI DOI 10.1145/1743666.1743718
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T., 2012, Tech. Rep. TR-2012-001
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   Klein A., 2019, P 12 ACM SIGGRAPH C, P1
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Kümmerer M, 2018, LECT NOTES COMPUT SC, V11220, P798, DOI 10.1007/978-3-030-01270-0_47
   Le Meur O, 2017, EUR SIGNAL PR CONF, P1892, DOI 10.23919/EUSIPCO.2017.8081538
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Loth S, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P263, DOI 10.1145/3267851.3267852
   Manor BR, 2003, J NEUROSCI METH, V128, P85, DOI 10.1016/S0165-0270(03)00151-1
   Mills M, 2011, J VISION, V11, DOI 10.1167/11.8.17
   Normoyle Aline., 2013, Proceedings of motion on games, P141
   Oyekoya Oyewole., 2009, Proceedings of the 16th acm symposium on virtual reality software and technology, P199
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2792, P93
   Peters C, 2003, COMP ANIM CONF PROC, P111, DOI 10.1109/CASA.2003.1199311
   Peters C., 2003, P ACM SIGGRAPH C 200, P1
   Peters C, 2011, COGN TECHNOL, P293, DOI 10.1007/978-3-642-15184-2_16
   Peters C, 2010, COMPUT GRAPH-UK, V34, P677, DOI 10.1016/j.cag.2010.09.007
   Picot A, 2007, LECT NOTES ARTIF INT, V4722, P272
   Ruhland Kerstin., 2014, Eurographics state-of-the-art report, P69
   Salvucci D.D., 2000, P 2000 S EYE TRACKIN, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Samuel AG, 2003, PSYCHON B REV, V10, P897, DOI 10.3758/BF03196550
   Satogata R, 2020, ACMIEEE INT CONF HUM, P433, DOI 10.1145/3371382.3378248
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Stellmach S., 2010, ACM S EYE TRACK RES, P109, DOI [DOI 10.1145/1743666, DOI 10.1145/1743666.1743693]
   Steptoe W, 2010, COMPUT ANIMAT VIRT W, V21, P161, DOI 10.1002/cav.354
   Takashima K., 2008, Proceedings of Graphics Interface 2008, P169, DOI DOI 10.1145/1375714.1375744
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
NR 56
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3871
EP 3883
DI 10.1109/TVCG.2023.3244679
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700044
PM 37022858
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Meidiana, A
   Hong, SH
   Eades, P
   Keim, D
AF Meidiana, Amyra
   Hong, Seok-Hee
   Eades, Peter
   Keim, Daniel
TI Automorphism Faithfulness Metrics for Symmetric Graph Drawings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Graph drawing; Orbits; Vehicle dynamics; Time measurement;
   Stress measurement; Stress; Automorphism; faithfulness metrics; graph
   drawing; symmetry
ID PLANAR GRAPHS
AB In this article, we present new quality metrics for symmetric graph drawing based on group theory. Roughly speaking, the new metrics are faithfulness metrics, i.e., they measure how faithfully a drawing of a graph displays the ground truth (i.e., geometric automorphisms) of the graph as symmetries. More specifically, we introduce two types of automorphism faithfulness metrics for displaying: (1) a single geometric automorphism as a symmetry (axial or rotational), and (2) a group of geometric automorphisms (cyclic or dihedral). We present algorithms to compute the automorphism faithfulness metrics in O(n log n) time. Moreover, we also present efficient algorithms to detect exact symmetries in a graph drawing. We then validate our automorphism faithfulness metrics using deformation experiments. Finally, we use the metrics to evaluate existing graph drawing algorithms to compare how faithfully they display geometric automorphisms of a graph as symmetries.
C1 [Meidiana, Amyra; Hong, Seok-Hee; Eades, Peter] Univ Sydney, Camperdown, NSW 2006, Australia.
   [Keim, Daniel] Univ Konstanz, D-78464 Constance, Germany.
C3 University of Sydney; University of Konstanz
RP Meidiana, A (corresponding author), Univ Sydney, Camperdown, NSW 2006, Australia.
EM amyra.meidiana@sydney.edu.au; seokhee.hong@sydney.edu.au;
   peter.eades@sydney.edu.au; keim@uni-konstanz.de
FU ARC (Australian Research Council) DP (Discovery Project) [DP190103301]
FX This work was supported by an ARC (Australian Research Council) DP
   (Discovery Project) under grant (# DP190103301).
CR Abelson D, 2007, DISCRETE APPL MATH, V155, P2211, DOI 10.1016/j.dam.2007.04.027
   ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910
   Battista G. D., 1998, Graph drawing: algorithms for the visualization of graphs
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Buchheim C, 2003, MATH PROGRAM, V98, P369, DOI 10.1007/s10107-003-0409-3
   Chen H.-L., 2000, P 8 INT S GRAPH DRAW, P372
   Chin KW, 2001, INFORM PROCESS LETT, V79, P73, DOI 10.1016/S0020-0190(00)00174-5
   De Luca F, 2019, LECT NOTES COMPUT SC, V11904, P499, DOI 10.1007/978-3-030-35802-0_38
   Eades P, 2000, THEOR COMPUT SCI, V240, P379, DOI 10.1016/S0304-3975(99)00239-X
   Eades P., 2013, Handbook of Graph Drawing and Visualisation
   Eades P, 2015, LECT NOTES COMPUT SC, V9411, P502, DOI 10.1007/978-3-319-27261-0_41
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Hong SH, 2006, DISCRETE COMPUT GEOM, V36, P283, DOI 10.1007/s00454-006-1231-5
   Hong SH, 2010, ALGORITHMICA, V58, P433, DOI 10.1007/s00453-008-9275-y
   Hong SH, 2006, ALGORITHMICA, V44, P67, DOI 10.1007/s00453-005-1149-y
   Hong SH, 2005, ALGORITHMICA, V42, P159, DOI 10.1007/s00453-004-1132-z
   Hong SH, 2003, LECT NOTES COMPUT SC, V2906, P405
   Hong SH, 2000, COMP GEOM-THEOR APPL, V17, P165, DOI 10.1016/S0925-7721(00)00020-1
   Klapaukh R, 2018, LECT NOTES ARTIF INT, V10871, P739, DOI 10.1007/978-3-319-91376-6_71
   Knuth D. E., 1977, SIAM Journal on Computing, V6, P323, DOI 10.1137/0206024
   Koren Y, 2005, COMPUT MATH APPL, V49, P1867, DOI 10.1016/j.camwa.2004.08.015
   LUBIW A, 1981, SIAM J COMPUT, V10, P11, DOI 10.1137/0210002
   MANNING J, 1992, DISCRETE APPL MATH, V39, P13, DOI 10.1016/0166-218X(92)90112-N
   Manning J., 1988, CONGR NUMER CONF J N, V64, P159
   Manning J. B., 1991, Ph.D. dissertation
   Meidiana Amyra, 2020, Graph Drawing and Network Visualization. 28th International Symposium, GD 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12590), P450, DOI 10.1007/978-3-030-68766-3_35
   Meidiana A, 2020, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis48177.2020.1022
   Meidiana A, 2019, LECT NOTES COMPUT SC, V11904, P125, DOI 10.1007/978-3-030-35802-0_10
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Nguyen Q, 2013, IEEE PAC VIS SYMP, P209, DOI 10.1109/PacificVis.2013.6596147
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Welch E, 2017, COMPUT GRAPH FORUM, V36, P341, DOI 10.1111/cgf.13192
   Wolter J., 1985, The Visual Computer, V1, P37, DOI DOI 10.1007/BF01901268
   ZABRODSKY H, 1995, J AM CHEM SOC, V117, P462, DOI 10.1021/ja00106a053
   ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508
NR 37
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3241
EP 3255
DI 10.1109/TVCG.2022.3229354
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700079
PM 37015686
DA 2024-08-05
ER

PT J
AU Xiong, CY
   Lee-Robbins, E
   Zhang, ICY
   Gaba, A
   Franconeri, S
AF Xiong, Cindy
   Lee-Robbins, Elsie
   Zhang, Icy
   Gaba, Aimen
   Franconeri, Steven
TI Reasoning Affordances With Tables and Bar Charts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Cognition; Urban areas; Bars; Skin; Affordances;
   Weapons; tabular displays; empirical evaluation; reasoning
ID CONFIRMATION BIAS; INFORMATION; SCIENCE; VISUALIZATIONS; PERCEPTION;
   FREQUENCY; KNOWLEDGE; PEOPLE; FORMAT; IMPACT
AB A viewer's existing beliefs can prevent accurate reasoning with data visualizations. In particular, confirmation bias can cause people to overweigh information that confirms their beliefs, and dismiss information that disconfirms them. We tested whether confirmation bias exists when people reason with visualized data and whether certain visualization designs can elicit less biased reasoning strategies. We asked crowdworkers to solve reasoning problems that had the potential to evoke both poor reasoning strategies and confirmation bias. We created two scenarios, one in which we primed people with a belief before asking them to make a decision, and another in which people held pre-existing beliefs. The data was presented as either a table, a bar table, or a bar chart. To correctly solve the problem, participants should use a complex reasoning strategy to compare two ratios, each between two pairs of values. But participants could also be tempted to use simpler, superficial heuristics, shortcuts, or biased strategies to reason about the problem. Presenting the data in a table format helped participants reason with the correct ratio strategy while showing the data as a bar table or a bar chart led participants towards incorrect heuristics. Confirmation bias was not significantly present when beliefs were primed, but it was present when beliefs were pre-existing. Additionally, the table presentation format was more likely to afford the ratio reasoning strategy, and the use of ratio strategy was more likely to lead to the correct answer. These findings suggest that data presentation formats can affect affordances for reasoning.
C1 [Xiong, Cindy] UMass Amherst, Coll Informat & Comp Sci, Amherst, MA 01002 USA.
   [Lee-Robbins, Elsie] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Zhang, Icy] UCLA, Los Angeles, CA 90095 USA.
   [Gaba, Aimen] UMass Amherst, Amherst, MA 01003 USA.
   [Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   University of Michigan System; University of Michigan; University of
   California System; University of California Los Angeles; University of
   Massachusetts System; University of Massachusetts Amherst; Northwestern
   University
RP Xiong, CY (corresponding author), UMass Amherst, Coll Informat & Comp Sci, Amherst, MA 01002 USA.
EM cindy.xiong@cs.umass.edu; elsielee@umich.edu; yunyi9847@g.ucla.edu;
   agaba@umass.edu; franconeri@northwestern.edu
OI Xiong Bearfield, Cindy/0000-0002-1451-4083
FU NSF [CHS-1901485]
FX This work was supported by NSF under Grant CHS-1901485.
CR Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Andrade EB, 2011, ORGAN BEHAV HUM DEC, V116, P252, DOI 10.1016/j.obhdp.2011.07.002
   BADDELEY AD, 1978, ERGONOMICS, V21, P627, DOI 10.1080/00140137808931764
   Bartram M., 2021, arXiv
   Binder K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01186
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   CHAIKEN S, 1980, J PERS SOC PSYCHOL, V39, P752, DOI 10.1037/0022-3514.39.5.752
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cook MB, 2008, HUM FACTORS, V50, P745, DOI 10.1518/001872008X354183
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dimara E, 2017, IEEE T VIS COMPUT GR, V23, P471, DOI 10.1109/TVCG.2016.2598594
   Dragicevic P, 2018, IEEE T VIS COMPUT GR, V24, P781, DOI 10.1109/TVCG.2017.2744298
   Ellis A., 2015, P IEEE WORKSH VIS DE, P1
   Ellis Geoffrey., 2018, COGNITIVE BIASES VIS
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Feldman-Stewart D, 2000, MED DECIS MAKING, V20, P228, DOI 10.1177/0272989X0002000208
   Franconeri S. L., 2013, "The nature and status of visual resources
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Franconeri SL, 2021, CURR DIR PSYCHOL SCI, V30, P367, DOI 10.1177/09637214211009512
   Franconeri SL, 2012, COGNITION, V122, P210, DOI 10.1016/j.cognition.2011.11.002
   Gaba Aimen, 2023, IEEE Trans Vis Comput Graph, V29, P1211, DOI 10.1109/TVCG.2022.3209456
   Garcia-Retamero R, 2009, AM J PUBLIC HEALTH, V99, P2196, DOI 10.2105/AJPH.2009.160234
   GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037/0033-295X.102.4.684
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hawley ST, 2008, PATIENT EDUC COUNS, V73, P448, DOI 10.1016/j.pec.2008.07.023
   Hegarty M, 2010, J EXP PSYCHOL LEARN, V36, P37, DOI 10.1037/a0017683
   Heiser J, 2006, COGNITIVE SCI, V30, P581, DOI 10.1207/s15516709cog0000_70
   HIGGINS ET, 1985, J EXP PSYCHOL LEARN, V11, P59, DOI 10.1037/0278-7393.11.1.59
   Hink JK, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P1155, DOI 10.1177/154193129604002302
   Kahan D.M., 2017, BEHAV PUBLIC POLICY, V1, P54, DOI DOI 10.1017/BPP.2016.2
   Kahneman D., 2011, THINKING FAST SLOW
   Kappes A, 2020, NAT NEUROSCI, V23, P130, DOI 10.1038/s41593-019-0549-2
   Karduni A, 2021, IEEE T VIS COMPUT GR, V27, P978, DOI 10.1109/TVCG.2020.3029412
   Khan A, 2015, INT J HUM-COMPUT ST, V83, P94, DOI 10.1016/j.ijhcs.2015.07.001
   Killen CP, 2020, INT J PROJ MANAG, V38, P267, DOI 10.1016/j.ijproman.2020.04.002
   Kim Y.-S., 2019, P CHI C HUM FACT COM, P14
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Klayman J., 1995, Psychology of Learning and Motivation, V32, P385, DOI DOI 10.1016/S0079-7421(08)60315-1
   LARKIN JH, 1987, COGNITIVE SCI, V11, P65, DOI 10.1016/S0364-0213(87)80026-5
   LI GH, 1994, AVIAT SPACE ENVIR MD, V65, P944
   Lovett A., 2022, "What does the chart say? Grouping cues guide viewer comparisons and conclusions in visualizations
   Mahajan S, 2022, COMPUT GRAPH FORUM, V41, P477, DOI 10.1111/cgf.14556
   Mantri Prateek, 2023, IEEE Trans Vis Comput Graph, V29, P1005, DOI 10.1109/TVCG.2022.3209467
   Mendel R, 2011, PSYCHOL MED, V41, P2651, DOI 10.1017/S0033291711000808
   Meyer J, 1999, HUM FACTORS, V41, P570, DOI 10.1518/001872099779656707
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Michal AL, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0059-2
   Norman D., 2013, The design of everyday things: Revised and expanded edition
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Nothelfer S., 2018, J. Vis., V18, P321
   O'Sullivan ED, 2018, J ROY COLL PHYS EDIN, V48, P225, DOI 10.4997/JRCPE.2018.306
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Pandey AV, 2014, IEEE T VIS COMPUT GR, V20, P2211, DOI 10.1109/TVCG.2014.2346419
   Pariser E., 2011, The Filter Bubble: How the New Personalized Web Is Changing What We Read and How We Think, DOI DOI 10.5860/CHOICE.50-0926
   Patterson RE, 2014, COMPUT GRAPH-UK, V42, P42, DOI 10.1016/j.cag.2014.03.002
   Picon E., 2017, J VISION, V17, P1284
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Schaubroeck J., 1991, HUM PERFORM, V4, P127
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   SNYDER M, 1979, J EXP SOC PSYCHOL, V15, P330, DOI 10.1016/0022-1031(79)90042-8
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Sukumar R., 2018, Biases Visualizations, P161
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tal A, 2016, PUBLIC UNDERST SCI, V25, P117, DOI 10.1177/0963662514549688
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Tingley D, 2014, J STAT SOFTW, V59
   Tsai S., 2011, P HUM FACT ERG SOC A, P385, DOI [10.1177/1071181311551079, DOI 10.1177/1071181311551079]
   TVERSKY A, 1991, Q J ECON, V106, P1039, DOI 10.2307/2937956
   Tversky B., 2014, Handbook of Human Centric Visualization, P3
   Valdez AC, 2018, IEEE T VIS COMPUT GR, V24, P584, DOI 10.1109/TVCG.2017.2744138
   Vallée-Tourangeau F, 2008, EUR J COGN PSYCHOL, V20, P177, DOI 10.1080/09541440601056588
   Wall E, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P111, DOI [10.1109/VISUAL.2019.8933611, 10.1109/visual.2019.8933611]
   WASON PC, 1968, Q J EXP PSYCHOL, V20, P273, DOI 10.1080/14640746808400161
   WASSERMAN EA, 1990, J EXP PSYCHOL LEARN, V16, P509, DOI 10.1037/0278-7393.16.3.509
   Winter L.-C., 2017, Doctoral Diss
   WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774
   Wolfe JM, 1998, PSYCHOL SCI, V9, P33, DOI 10.1111/1467-9280.00006
   Wright W., 2006, Conference on Human Factors in Computing Systems. CHI2006, P801
   Xiong A., 2022, P CHI C HUM FACT COM, P1
   Xiong C., 2021, J. Vis., V21, P2095
   Xiong Cindy, 2023, IEEE Trans Vis Comput Graph, V29, P493, DOI 10.1109/TVCG.2022.3209405
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   YI YJ, 1990, J ADVERTISING, V19, P40, DOI 10.1080/00913367.1990.10673186
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Zacks JM, 2020, POL INS BEH BRAIN SC, V7, P52, DOI 10.1177/2372732219893712
NR 91
TC 2
Z9 2
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3487
EP 3502
DI 10.1109/TVCG.2022.3232959
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700025
PM 37015636
DA 2024-08-05
ER

PT J
AU Nam, JW
   Isenberg, T
   Keefe, DF
AF Nam, Jung Who
   Isenberg, Tobias
   Keefe, Daniel F.
TI V-Mail: 3D-Enabled Correspondence About Spatial Data on (Almost) All
   Your Devices
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Three-dimensional displays; Annotations; Spatial
   databases; Collaboration; Software; Task analysis; Communication;
   human-computer interaction; immersive analytics; storytelling;
   visualization of scientific 3D data
ID VISUALIZATION; STORIES
AB We present V-Mail, a framework of cross-platform applications, interactive techniques, and communication protocols for improved multi-person correspondence about spatial 3D datasets. Inspired by the daily use of e-mail, V-Mail seeks to enable a similar style of rapid, multi-person communication accessible on any device; however, it aims to do this in the new context of spatial 3D communication, where limited access to 3D graphics hardware typically prevents such communication. The approach integrates visual data storytelling with data exploration, spatial annotations, and animated transitions. V-Mail "data stories" are exported in a standard video file format to establish a common baseline level of access on (almost) any device. The V-Mail framework also includes a series of complementary client applications and plugins that enable different degrees of story co-authoring and data exploration, adjusted automatically to match the capabilities of various devices. A lightweight, phone-based V-Mail app makes it possible to annotate data by adding captions to the video. These spatial annotations are then immediately accessible to team members running high-end 3D graphics visualization systems that also include a V-Mail client, implemented as a plugin. Results and evaluation from applying V-Mail to assist communication within an interdisciplinary science team studying Antarctic ice sheets confirm the utility of the asynchronous, cross-platform collaborative framework while also highlighting some current limitations and opportunities for future work.
C1 [Nam, Jung Who; Keefe, Daniel F.] Univ Minnesota, Minneapolis, MN 55455 USA.
   [Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, LISN, F-91190 Gif Sur Yvette, France.
C3 University of Minnesota System; University of Minnesota Twin Cities;
   Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   Paris Cite; Universite Paris Saclay
RP Nam, JW (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
EM namxx054@umn.edu; tobias.isenberg@inria.fr; dfk@umn.edu
RI ; Isenberg, Tobias/A-7575-2008
OI Nam, Jung Who/0000-0003-0295-6906; Isenberg, Tobias/0000-0001-7953-8644;
   Keefe, Daniel/0000-0002-7039-2340
FU National Science Foundation
FX No Statement Available
CR Acevedo D, 2001, IEEE VISUAL, P493, DOI 10.1109/VISUAL.2001.964560
   Ahrens B., inThe Visualization Handbook
   Akiba H, 2010, IEEE COMPUT GRAPH, V30, P61, DOI 10.1109/MCG.2009.107
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bladin K, 2018, IEEE T VIS COMPUT GR, V24, P802, DOI 10.1109/TVCG.2017.2743958
   de Lange P, 2018, LECT NOTES COMPUT SC, V11007, P88, DOI 10.1007/978-3-319-96565-9_9
   Dong Hyun Jeong, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P231, DOI 10.1109/VAST.2010.5652958
   Duarte N., 2019, Data Story: Explain Data and Inspire Action Through Story
   Eccles R, 2008, INFORM VISUAL, V7, P3, DOI 10.1057/palgrave.ivs.9500173
   Farooq H, 2016, SCI REP-UK, V6, DOI 10.1038/srep38927
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Heer J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1029
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Heer J, 2008, INFORM VISUAL, V7, P49, DOI 10.1057/palgrave.ivs.9500167
   Iserhardt-Bauer S, 2001, IEEE VISUAL, P425, DOI 10.1109/VISUAL.2001.964542
   Jeong DH, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0023-4
   Johnson S, 2020, IEEE T VIS COMPUT GR, V26, P492, DOI 10.1109/TVCG.2019.2934260
   Klein T, 2018, IEEE T VIS COMPUT GR, V24, P862, DOI 10.1109/TVCG.2017.2744258
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kouril D, 2023, IEEE T VIS COMPUT GR, V29, P1733, DOI 10.1109/TVCG.2021.3130670
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Liao Isaac, 2014, Smart Graphics. 12th International Symposium (SG 2014). Proceedings: LNCS 8698, P1, DOI 10.1007/978-3-319-11650-1_1
   Lidal EM, 2013, COMPUT GRAPH-UK, V37, P445, DOI 10.1016/j.cag.2013.01.010
   Luke EJ, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P61, DOI 10.1109/VISUAL.2002.1183758
   Lundblad Patrik, 2013, 2013 17th International Conference on Information Visualisation, P263, DOI 10.1109/IV.2013.35
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Meuschke M, 2021, Arxiv, DOI arXiv:2108.05462
   Riche C., 2018, Data-Driven Storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stolper B., 2016, Microsoft Research, Washing-ton, Tech. Rep. MSR-TR-2016-14
   Stolper CD, 2016, Tech. rep. MSR-TR-2016-14
   Thöny M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030123
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Tsang Michael, 2002, P 15 ANN ACM S US IN, P111
   Usher W, 2020, SYMP LARG DATA ANAL, P27, DOI 10.1109/LDAV51489.2020.00010
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Wohlfart H., 2007, P JOINT EUR IEEE VGT, P91, DOI [10.2312/VisSym/EuroVis07/091-098, DOI 10.2312/VISSYM/EUROVIS07/091-098]
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Ynnerman A, 2018, IEEE COMPUT GRAPH, V38, P13, DOI 10.1109/MCG.2018.032421649
NR 43
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1853
EP 1867
DI 10.1109/TVCG.2022.3229017
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500010
PM 37015540
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Leon, GM
   Isenberg, P
   Breiter, A
AF Leon, Gabriela Molina
   Isenberg, Petra
   Breiter, Andreas
TI Eliciting Multimodal and Collaborative Interactions for Data Exploration
   on Large Vertical Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Collaborative work; elicitation study; large vertical
   displays; multimodal interaction; spatio-temporal data
ID INFORMATION VISUALIZATION; AUGMENTED REALITY; TOUCH; WALL; MANIPULATION;
   SPEECH; MOBILE; PEN
AB We examined user preferences to combine multiple interaction modalities for collaborative interaction with data shown on large vertical displays. Large vertical displays facilitate visual data exploration and allow the use of diverse interaction modalities by multiple users at different distances from the screen. Yet, how to offer multiple interaction modalities is a non-trivial problem. We conducted an elicitation study with 20 participants that generated 1015 interaction proposals combining touch, speech, pen, and mid-air gestures. Given the opportunity to interact using these four modalities, participants preferred speech interaction in 10 of 15 low-level tasks and direct manipulation for straightforward tasks such as showing a tooltip or selecting. In contrast to previous work, participants most favored unimodal and personal interactions. We identified what we call collaborative synonyms among their interaction proposals and found that pairs of users collaborated either unimodally and simultaneously or multimodally and sequentially. We provide insights into how end-users associate visual exploration tasks with certain modalities and how they collaborate at different interaction distances using specific interaction modalities.(1)
C1 [Leon, Gabriela Molina; Breiter, Andreas] Univ Bremen, D-28359 Bremen, Germany.
   [Isenberg, Petra] Univ Paris Saclay, CNRS, Inria, LISN, F-91405 Orsay, France.
C3 University of Bremen; Microsoft; Centre National de la Recherche
   Scientifique (CNRS); Universite Paris Cite; Inria; Universite Paris
   Saclay
RP Leon, GM (corresponding author), Univ Bremen, D-28359 Bremen, Germany.
EM molina@uni-bremen.de; petra.isenberg@inria.fr; abreiter@uni-bremen.de
RI Breiter, Andreas/P-4859-2016
OI Molina Leon, Gabriela C./0000-0002-9223-2022; Isenberg,
   Petra/0000-0002-2948-6417
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Abras D., 2004, Encyclope-dia of Human-Computer Interaction, V37, P445
   ALI A. X., 2021, P 2021 CHI C HUMAN F, DOI 10.1145/3411764.3445758
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   Andrienko N, 2006, Exploratory analysis of spatial and temporal data
   Badam S. K., 2017, P 2 WORKSH IMM AN
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Ball R, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P191
   Baudisch P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P31, DOI 10.1145/502348.502354
   Bezerianos A, 2012, IEEE T VIS COMPUT GR, V18, P2516, DOI 10.1109/TVCG.2012.251
   Bongshin Lee, 2021, Foundations and Trends in Human-Computer Interaction, V14, P1, DOI 10.1561/1100000081
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brudy F., 2014, P INT S PERVASIVE DI, P1, DOI [DOI 10.1145/2611009.2611028, 10.1145/2611009.2611028]
   Buxton W., 1995, Readings in Human-Computer Interaction, P494, DOI [10.1016/B978-0-08-051574-8.50051-0, DOI 10.1016/B978-0-08-051574-8.50051-0]
   Dostal Jakub., 2014, P 19 INT C INTELLIGE, P143, DOI DOI 10.1145/2557500.2557541
   Drucker S.M., 2013, P OF THE SIGCHI C ON, P2301
   G. Foundation, 2022, Free data via gapminder.org, cc -by license
   Guimbretiere F., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P21, DOI 10.1145/502348.502353
   Herholz L. L., 2008, 13 INT FALL WORKSH V, P101
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hinckley K., 2010, Proceedings of the 23nd annual ACM symposium on User interface software and technology, P27, DOI [10.1145/1866029.1866036, DOI 10.1145/1866029.1866036]
   Hinrichs U, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3023
   Horak T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173593
   Isenberg P., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P179, DOI 10.1109/VAST.2010.5652880
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Isenberg P, 2009, IEEE COMPUT GRAPH, V29, P44, DOI 10.1109/MCG.2009.78
   Isenberg P, 2009, COMPUT GRAPH FORUM, V28, P1031, DOI 10.1111/j.1467-8659.2009.01444.x
   Jakobsen MR, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2576099
   Jakobsen MR, 2013, IEEE T VIS COMPUT GR, V19, P2386, DOI 10.1109/TVCG.2013.166
   Kister U, 2017, COMPUT GRAPH FORUM, V36, P503, DOI 10.1111/cgf.13206
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Langner R, 2019, IEEE T VIS COMPUT GR, V25, P608, DOI 10.1109/TVCG.2018.2865235
   Lee B, 2015, IEEE PAC VIS SYMP, P199, DOI 10.1109/PACIFICVIS.2015.7156378
   León GM, 2022, COMPUT GRAPH FORUM, V41, P417, DOI 10.1111/cgf.14551
   Liu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6730, DOI 10.1145/3025453.3025594
   Mignot Christophe., 1993, INTERACT 93 CHI 93 C, P67
   Morris M. R., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1201
   Morris M.R., 2012, P 2012 ACM INT C INT, DOI [DOI 10.1145/2396636.2396651, 10.1145/2396636.2396651]
   Morris M. R., 2014, Interactions, V21, P40, DOI DOI 10.1145/2591689
   Nacenta Miguel A., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, New York, NY, USA, P1099, DOI [10.1145/2470654.2466142, DOI 10.1145/2470654.2466142]
   Nancel M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P177
   Nebeling Michael, 2014, P 9 ACM INT C INT TA, P15, DOI DOI 10.1145/2669485.2669497
   Oviatt A., 1997, Referring Phenomena Multimedia Context Their Comput. Treat., P1
   Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398
   Perera M, 2021, IEEE SYS MAN CYBERN, P2576, DOI 10.1109/SMC52423.2021.9658673
   Plotly, 2022, Plotly express in python
   Prouzeau A, 2017, IEEE T VIS COMPUT GR, V23, P1936, DOI 10.1109/TVCG.2016.2592906
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Riehmann P, 2020, COMPUT GRAPH FORUM, V39, P265, DOI 10.1111/cgf.13979
   Rogers Y, 2004, INTERACT COMPUT, V16, P1133, DOI 10.1016/j.intcom.2004.07.008
   Sadana R, 2016, COMPUT GRAPH FORUM, V35, P261, DOI 10.1111/cgf.12902
   Sadana R, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P265, DOI 10.1145/2598153.2598163
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Sassenberg K, 2005, J EXP SOC PSYCHOL, V41, P506, DOI 10.1016/j.jesp.2004.10.002
   Srinivasan A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376782
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   T. Y. Channel, 2018, Tableau
   Tsandilas T., 2016, Research Report 1584
   Tsandilas T, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3182168
   Vatavu RD, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3476101
   Vatavu RD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300454
   Vatavu RD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1325, DOI 10.1145/2702123.2702223
   Villarreal-Narvaez S, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P855, DOI 10.1145/3357236.3395511
   Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275
   Willett Q., 2014, P EUR C VIS, DOI [10.2312/eurovisshort.20141161, DOI 10.2312/EUROVISSHORT.20141161]
   Williams AS, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040088
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Williams Adam S., CONCISE GUIDE ELICIT
   Wobbrock J.O., 2005, CHi '05 extended abstracts on Human factors in computing systems-CHi '05. new york, new york, DOI DOI 10.1145/1056808.1057043
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
NR 71
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1624
EP 1637
DI 10.1109/TVCG.2023.3323150
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300002
PM 37930918
OA hybrid
DA 2024-08-05
ER

PT J
AU Xu, X
   Wang, L
   Pérard-Gayot, A
   Membarth, R
   Li, CY
   Yang, CL
   Slusallek, P
AF Xu, Xiang
   Wang, Lu
   Perard-Gayot, Arsene
   Membarth, Richard
   Li, Cuiyu
   Yang, Chenglei
   Slusallek, Philipp
TI Temporal Coherence-Based Distributed Ray Tracing of Massive Scenes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Ray tracing; Portals; Heuristic
   algorithms; Dynamic scheduling; Task analysis; Distributed databases;
   Computer graphics; distributed graphics; ray tracing
ID CACHE
AB Distributed ray tracing algorithms are widely used when rendering massive scenes, where data utilization and load balancing are the keys to improving performance. One essential observation is that rays are temporally coherent, which indicates that temporal information can be used to improve computational efficiency. In this paper, we use temporal coherence to optimize the performance of distributed ray tracing. First, we propose a temporal coherence-based scheduling algorithm to guide the task/data assignment and scheduling. Then, we propose a virtual portal structure to predict the radiance of rays based on the previous frame, and send the rays with low radiance to a precomputed simplified model for further tracing, which can dramatically reduce the traversal complexity and the overhead of network data transmission. The approach was validated on scenes of sizes up to 355 GB. Our algorithm can achieve a speedup of up to 81% compared to previous algorithms, with a very small mean squared error.
C1 [Xu, Xiang] Shandong Univ Finance & Econ, Shandong Key Lab Blockchain Finance, Jinan 250101, Shandong, Peoples R China.
   [Wang, Lu; Yang, Chenglei] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
   [Perard-Gayot, Arsene] Weta Digital, Wellington 6243, New Zealand.
   [Membarth, Richard] TH Ingolstadt THI, Res Inst AImot Bavaria, D-85049 Ingolstadt, Germany.
   [Membarth, Richard; Slusallek, Philipp] Saarland Informat Campus, German Res Ctr Artificial Intelligence DFKI, D-66123 Saarbrucken, Saarland, Germany.
   [Li, Cuiyu] Adv Comp East China Subctr, Suzhou 215300, Jiangsu, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University; German
   Research Center for Artificial Intelligence (DFKI)
RP Wang, L (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
EM xuxiang8420@outlook.com; luwang_hcivr@sdu.edu.cn;
   aperardgayot@wetafx.co.nz; Richard.Membarth@thi.de; lxyystn@126.com;
   chl_yang@sdu.edu.cn; philipp.slusallek@dfki.de
RI 徐, 翔/KOC-9548-2024
OI Slusallek, Philipp/0000-0002-2189-2429; xu, xiang/0000-0002-9570-0784
FU National Key R#x0026;D Program of China
FX No Statement Available
CR Abram G, 2018, SYMP LARG DATA ANAL, P72, DOI 10.1109/LDAV.2018.8739241
   [Anonymous], 2017, ACM SIGGRAPH 2017 TA
   BADOUEL D, 1994, IEEE COMPUT GRAPH, V14, P69, DOI 10.1109/38.291533
   Budge B, 2009, COMPUT GRAPH FORUM, V28, P385, DOI 10.1111/j.1467-8659.2009.01378.x
   DeMarle DavidE., 2004, EGPGV, P93
   DeMarle DE, 2005, PARALLEL COMPUT, V31, P221, DOI 10.1016/j.parco.2005.02.007
   DeMarle DE, 2003, PVG 2003 PROCEEDINGS, P87, DOI 10.1109/PVGS.2003.1249046
   Djeu P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019634
   Eisenacher C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12158
   Fussell C., 2012, EUR S PAR GRAPH VIS, P61
   Gassenbauer V, 2009, COMPUT GRAPH FORUM, V28, P1189, DOI 10.1111/j.1467-8659.2009.01496.x
   Green S. A., 1990, Visual Computer, V6, P62, DOI 10.1007/BF01901067
   Gropp W., 1994, Using MPI: Portable Parallel Programming with the Message-Passing Interface
   Howison M., 2010, P EUR S PAR GRAPH VI, P1
   Howison M, 2012, IEEE T VIS COMPUT GR, V18, P17, DOI 10.1109/TVCG.2011.24
   Kato T., 2002, Fourth Eurographics Workshop on Parallel Graphics and Visualization, P7
   Kobayashi H., 1988, Visual Computer, V4, P197, DOI 10.1007/BF01887592
   Larsen M, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P276, DOI 10.1109/SC.2016.23
   Matt J., 2016, Physically Based Rendering, V3rd
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Moon B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805972
   Müller T, 2017, COMPUT GRAPH FORUM, V36, P91, DOI 10.1111/cgf.13227
   Navrátil PA, 2014, IEEE T VIS COMPUT GR, V20, P893, DOI 10.1109/TVCG.2013.261
   Park H, 2018, SYMP LARG DATA ANAL, P77, DOI 10.1109/LDAV.2018.8739224
   Pérard-Gayot A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322955
   Pharr M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P101, DOI 10.1145/258734.258791
   Plachetka T, 2003, Event -driven message passing and parallel simulation of global illumination
   Plachetka T, 2004, P 5 EUR C PAR GRAPH, P101
   Reinhard E., 1999, Proceedings 1999 IEEE Parallel Visualization and Graphics Symposium (Cat. No.99EX381), P21, DOI 10.1109/PVGS.1999.810135
   Son M, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105784
   Studio B, 2020, Agent 327-blender cloud
   Wald I, 2001, SPRING EUROGRAP, P277
   Wald I, 2022, Arxiv, DOI arXiv:2204.10170
   Ward G, 1999, ACM T GRAPHIC, V18, P361, DOI 10.1145/337680.337722
   Yoon SE, 2006, VISUAL COMPUT, V22, P772, DOI 10.1007/s00371-006-0062-y
   Zellmann S., 2020, P EUR S PAR GRAPH VI, P1
   Zhu JQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459798
NR 37
TC 0
Z9 0
U1 3
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1489
EP 1501
DI 10.1109/TVCG.2022.3219982
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300010
PM 36342995
DA 2024-08-05
ER

PT J
AU Li, RZ
   Cui, WW
   Song, TQ
   Xie, X
   Ding, R
   Wang, Y
   Zhang, HD
   Zhou, H
   Wu, YC
AF Li, Renzhong
   Cui, Weiwei
   Song, Tianqi
   Xie, Xiao
   Ding, Rui
   Wang, Yun
   Zhang, Haidong
   Zhou, Hong
   Wu, Yingcai
TI Causality-Based Visual Analysis of Questionnaire Responses
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Causal analysis; Questionnaire; Design study
ID ASSOCIATION RULES; EXPLORATION
AB As the final stage of questionnaire analysis, causal reasoning is the key to turning responses into valuable insights and actionable items for decision-makers. During the questionnaire analysis, classical statistical methods (e.g., Differences-in-Differences) have been widely exploited to evaluate causality between questions. However, due to the huge search space and complex causal structure in data, causal reasoning is still extremely challenging and time-consuming, and often conducted in a trial-and-error manner. On the other hand, existing visual methods of causal reasoning face the challenge of bringing scalability and expert knowledge together and can hardly be used in the questionnaire scenario. In this work, we present a systematic solution to help analysts effectively and efficiently explore questionnaire data and derive causality. Based on the association mining algorithm, we dig question combinations with potential inner causality and help analysts interactively explore the causal sub-graph of each question combination. Furthermore, leveraging the requirements collected from the experts, we built a visualization tool and conducted a comparative study with the state-of-the-art system to show the usability and efficiency of our system.
C1 [Li, Renzhong; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Zhejiang, Peoples R China.
   [Cui, Weiwei; Ding, Rui; Wang, Yun; Zhang, Haidong] Microsoft Res Asia, Beijing, Peoples R China.
   [Song, Tianqi; Xie, Xiao] Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
   [Zhou, Hong] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Zhejiang University; Microsoft Research Asia; Microsoft; Zhejiang
   University; Shenzhen University
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
EM renzhongli@zju.edu.cn; weiweicu@microsoft.com; holly1027@zju.edu.cn;
   xxie@zju.edu.cn; juding@microsoft.com; wangyun@microsoft.com;
   haizhang@microsoft.com; hzhou@szu.edu.cn; ycwu@zju.edu.cn
OI Li, Renzhong/0000-0002-6577-036X
FU National Key R&D Program of China
FX No Statement Available
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   [Anonymous], 2020, Microsoft Forms
   [Anonymous], 2020, About us
   Antonakis J, 2010, LEADERSHIP QUART, V21, P1086, DOI 10.1016/j.leaqua.2010.10.010
   Bae J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P64, DOI 10.5220/0006102300640074
   Bae J, 2017, COMPUT GRAPH FORUM, V36, P411, DOI 10.1111/cgf.13198
   Bertrand M, 2004, Q J ECON, V119, P249, DOI 10.1162/003355304772839588
   Borgelt C, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P395
   Burton SH, 2014, INTELL DATA ANAL, V18, P479, DOI 10.3233/IDA-140652
   Cao AQ, 2021, VIS INFORM, V5, P102, DOI 10.1016/j.visinf.2021.09.002
   Chen YL, 2009, KNOWL-BASED SYST, V22, P46, DOI 10.1016/j.knosys.2008.06.003
   Craft B, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P110, DOI 10.1109/IV.2005.28
   Craney T. A., 2002, Quality Engineering, V14, P391, DOI 10.1081/QEN-120001878
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P2486, DOI 10.1109/TVCG.2021.3071387
   Eick SG, 2002, J COMPUT GRAPH STAT, V11, P22, DOI 10.1198/106186002317375604
   FARRAR DE, 1967, REV ECON STAT, V49, P92, DOI 10.2307/1937887
   GAREY MR, 1977, SIAM J APPL MATH, V32, P826, DOI 10.1137/0132071
   Ghai Bhavya, 2023, IEEE Trans Vis Comput Graph, V29, P473, DOI 10.1109/TVCG.2022.3209484
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Hahn JY, 2001, ECONOMETRICA, V69, P201, DOI 10.1111/1468-0262.00183
   Hoque MN, 2022, IEEE T VIS COMPUT GR, V28, P4728, DOI 10.1109/TVCG.2021.3102051
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Kaggle, 2022, US
   Kale A, 2022, IEEE T VIS COMPUT GR, V28, P1150, DOI 10.1109/TVCG.2021.3114824
   Klaus J, 2023, VIS INFORM, V7, P72, DOI 10.1016/j.visinf.2023.05.001
   Krosnick Jon A., 2018, The Palgrave handbook of survey research, P439, DOI DOI 10.1007/978-3-319-54395-6_53
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lonsdale C, 2011, PSYCHOL SPORT EXERC, V12, P284, DOI 10.1016/j.psychsport.2010.11.003
   Mendez J., 2023, Computer Graphics Forum, DOI [10.1111/cgf.147302, DOI 10.1111/CGF.147302]
   Müller-Sielaff J, 2023, IEEE T VIS COMPUT GR, V29, P3602, DOI 10.1109/TVCG.2022.3166071
   Pearl J., 2000, Causality: Models, Reasoning, and Inference, P5
   Pister A, 2021, IEEE T VIS COMPUT GR, V27, P1775, DOI 10.1109/TVCG.2020.3030347
   Ramsey Joseph, 2017, Int J Data Sci Anal, V3, P121, DOI 10.1007/s41060-016-0032-z
   Spirtes P., 1991, Social Science Computer Review, V9, P62, DOI 10.1177/089443939100900106
   Tianchi, 2021, About Us
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   VIRZI RA, 1992, HUM FACTORS, V34, P457, DOI 10.1177/001872089203400407
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wei Xiaofeng, 2016, Computer Engineering, V42, P71, DOI 10.3969/j.issn.1000-3428.2016.01.014
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
   Yeon H, 2021, J VISUAL-JAPAN, V24, P583, DOI 10.1007/s12650-020-00716-0
   Yi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P752, DOI 10.1007/978-3-030-58595-2_45
   Zhu ZH, 2023, J VISUAL-JAPAN, V26, P611, DOI 10.1007/s12650-022-00896-x
NR 48
TC 0
Z9 0
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 638
EP 648
DI 10.1109/TVCG.2023.3327376
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500018
PM 37903040
DA 2024-08-05
ER

PT J
AU Newburger, E
   Elmqvist, N
AF Newburger, Eric
   Elmqvist, Niklas
TI Visualization According to Statisticians: An Interview Study on the Role
   of Visualization for Inferential Statistics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Interviews; Visualization; Industries; Encoding;
   Cognitive science; Codes; Inferential statistics; qualitative interview
   study; thematic coding; statistical visualization
ID INFORMATION VISUALIZATION; VISUAL REPRESENTATIONS
AB Statisticians are not only one of the earliest professional adopters of data visualization, but also some of its most prolific users. Understanding how these professionals utilize visual representations in their analytic process may shed light on best practices for visual sensemaking. We present results from an interview study involving 18 professional statisticians (19.7 years average in the profession) on three aspects: (1) their use of visualization in their daily analytic work; (2) their mental models of inferential statistical processes; and (3) their design recommendations for how to best represent statistical inferences. Interview sessions consisted of discussing inferential statistics, eliciting participant sketches of suitable visual designs, and finally, a design intervention with our proposed visual designs. We analyzed interview transcripts using thematic analysis and open coding, deriving thematic codes on statistical mindset, analytic process, and analytic toolkit. The key findings for each aspect are as follows: (1) statisticians make extensive use of visualization during all phases of their work (and not just when reporting results); (2) their mental models of inferential methods tend to be mostly visually based; and (3) many statisticians abhor dichotomous thinking. The latter suggests that a multi-faceted visual display of inferential statistics that includes a visual indicator of analytically important effect sizes may help to balance the attributed epistemic power of traditional statistical testing with an awareness of the uncertainty of sensemaking.
C1 [Newburger, Eric] US Naval Acad, Annapolis, MD 21402 USA.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
C3 United States Department of Defense; United States Navy; United States
   Naval Academy; Aarhus University
RP Newburger, E (corresponding author), US Naval Acad, Annapolis, MD 21402 USA.
EM enewburg@terpmail.umd.edu; elm@cs.au.dk
OI Newburger, Eric/0000-0001-8777-0363; Elmqvist,
   Niklas/0000-0001-5805-5301
CR Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], 1993, Visualizing Data
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Calin-Jageman RJ, 2019, AM STAT, V73, P271, DOI 10.1080/00031305.2018.1518266
   Casella G., 2001, Statistical Inference, V2nd, P2
   Correll M, 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, DOI [DOI 10.1145/2207676.22085562, 10.1145/2207676.2208556, DOI 10.1145/2207676.2208556]
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Fisher R. A., 1922, Philos Trans R Soc Lond, V222, P309, DOI [10.1098/rsta.1922.0009, DOI 10.1098/RSTA.1922.0009]
   Gaver B., 1999, ACM Interactions, V6, P21, DOI DOI 10.1145/291224.291235
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Hald A., 1998, Probability and Statistics, P2
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Lazar J., 2017, Research Methods in HumanComputer Interaction, V2, P3
   Lehmann E. L., 2005, Testing Statistical Hypotheses, V3rd, P2
   Mustafa R.Y., 1996, J STAT ED, V4, DOI [DOI 10.1080/10691898.1996.11910504, 10.1080/10691898.1996.11910504]
   Newburger E., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.32107635, DOI 10.1109/TVCG.2022.32107635]
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Scaife M, 1996, INT J HUM-COMPUT ST, V45, P185, DOI 10.1006/ijhc.1996.0048
   Schervish MJ., 1995, Theory of statistics, DOI DOI 10.1007/978-1-4612-4250-5
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Tukey J.W., 1977, Exploratory data analysis, V2
   Wallace Jayne, 2013, P SIGCHI C HUM FACT, P3441, DOI DOI 10.1145/2470654.2466473
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
NR 32
TC 0
Z9 0
U1 6
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 230
EP 239
DI 10.1109/TVCG.2023.3326521
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500098
PM 37871077
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhao, LX
   Isenberg, T
   Xie, FQ
   Liang, HN
   Yu, LY
AF Zhao, Lixiang
   Isenberg, Tobias
   Xie, Fuqi
   Liang, Hai-Ning
   Yu, Lingyun
TI MeTACAST: Target- and Context-Aware Spatial Selection in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial selection; immersive analytics; virtual reality (VR);
   target-aware and context-aware interaction for visualization
ID GALAXIES; OBJECTS
AB We propose three novel spatial data selection techniques for particle data in VR visualization environments. They are designed to be target- and context-aware and be suitable for a wide range of data features and complex scenarios. Each technique is designed to be adjusted to particular selection intents: the selection of consecutive dense regions, the selection of filament-like structures, and the selection of clusters-with all of them facilitating post-selection threshold adjustment. These techniques allow users to precisely select those regions of space for further exploration-with simple and approximate 3D pointing, brushing, or drawing input-using flexible point- or path-based input and without being limited by 3D occlusions, non-homogeneous feature density, or complex data shapes. These new techniques are evaluated in a controlled experiment and compared with the Baseline method, a region-based 3D painting selection. Our results indicate that our techniques are effective in handling a wide range of scenarios and allow users to select data based on their comprehension of crucial features. Furthermore, we analyze the attributes, requirements, and strategies of our spatial selection methods and compare them with existing state-of-the-art selection methods to handle diverse data features and situations. Based on this analysis we provide guidelines for choosing the most suitable 3D spatial selection techniques based on the interaction environment, the given data characteristics, or the need for interactive post-selection threshold adjustment.
C1 [Zhao, Lixiang; Xie, Fuqi; Liang, Hai-Ning; Yu, Lingyun] Xian Jiaotong Liverpool Univ, Xian, Peoples R China.
   [Isenberg, Tobias] Univ Paris Saclay, INRIA, LISN, CNRS, Paris, France.
C3 Xi'an Jiaotong-Liverpool University; Universite Paris Saclay; Universite
   Paris Cite; Centre National de la Recherche Scientifique (CNRS); Inria
RP Yu, LY (corresponding author), Xian Jiaotong Liverpool Univ, Xian, Peoples R China.
EM lixiang.zhao17@student.xjtlu.edu.cn; tobias.isenberg@inria.fr;
   fuqi.xie18@student.xjtlu.edu.cn; haining.liang@xjtlu.edu.cn;
   lingyun.yu@xjtlu.edu.cn
RI ; Isenberg, Tobias/A-7575-2008
OI Zhao, Lixiang/0000-0001-6181-1673; Liang, Hai-Ning/0000-0003-3600-8955;
   Isenberg, Tobias/0000-0001-7953-8644; Xie, Fuqi/0009-0008-4728-9346
FU NSFC
FX No Statement Available
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Baguley T, 2009, BRIT J PSYCHOL, V100, P603, DOI 10.1348/000712608X377117
   Baloup M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300331, 10.1109/africon46755.2019.9133906]
   BECHTOLD J, 1994, ASTROPHYS J SUPPL S, V91, P1, DOI 10.1086/191937
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Besancon L, 2019, COMPUT GRAPH FORUM, V38, P553, DOI 10.1111/cgf.13710
   Bond JR, 1996, NATURE, V380, P603, DOI 10.1038/380603a0
   Brown R., Valve index
   Brunhart-Lupo N, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P19, DOI 10.1109/IMMERSIVE.2016.7932377
   Chen W, 2009, IEEE T VIS COMPUT GR, V15, P1433, DOI 10.1109/TVCG.2009.112
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2017, IEEE PAC VIS SYMP, P46, DOI 10.1109/PACIFICVIS.2017.8031578
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966
   Danyluk K, 2022, IEEE T VIS COMPUT GR, V28, P1930, DOI 10.1109/TVCG.2020.3023336
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI DOI 10.2312/EGVE/IPT_EGVE2005/201-209
   Dragicevic P., 2014, CHI EXTENDED ABSTRAC, P607, DOI DOI 10.1145/2559206.2578881
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Ferdosi BJ, 2011, ASTRON ASTROPHYS, V531, DOI 10.1051/0004-6361/201116878
   Franzluebbers A., 2022, PROC, DOI [10.1145/3565970.3567696, DOI 10.1145/3565970.3567696]
   Gomez SR, 2010, LECT NOTES COMPUT SC, V6454, P373, DOI 10.1007/978-3-642-17274-8_37
   Grossman T., 2006, P 19 ACM S US INT SO, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Guest M, 2001, Arxiv, DOI arXiv:math/0104155
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hentschel B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P253, DOI 10.1109/VR.2009.4811041
   Hong J., 2021, P GRAPH INT MISS ON, P213, DOI [10.20380/G12021.33, DOI 10.20380/G12021.33, 10.20380/GI2021.33, DOI 10.20380/GI2021.33]
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Keefe DF, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P51
   König WA, 2009, LECT NOTES COMPUT SC, V5726, P658, DOI 10.1007/978-3-642-03655-2_73
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Lee SY, 2003, PROC SPIE, V4756, P38, DOI 10.1117/12.497665
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P191
   Lucas J. F., 2005, Design and evaluation of 3D multiple object selection techniques
   Lucas JohnF., 2005, Design and evaluation of 3D multiple object selection techniques
   Maletic JI, 2001, PROG COMPREHEN, P26, DOI 10.1109/WPC.2001.921711
   Malmberg F, 2006, LECT NOTES COMPUT SC, V4245, P663
   Maslych M, 2023, Symposium Virtual Re, P460, DOI 10.1109/VR55154.2023.00061
   McDonald T, 2021, IEEE T VIS COMPUT GR, V27, P744, DOI 10.1109/TVCG.2020.3030363
   Montano-Murillo RA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P53, DOI [10.1109/VR46266.2020.1581198507712, 10.1109/VR46266.2020.00-81]
   Owada S, 2005, P 2005 S INT 3D GRAP, P111, DOI DOI 10.1145/1053427.1053445
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Pivovar J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P907, DOI 10.1109/VRW55335.2022.00307
   Poupyrev I, 1999, J VISUAL LANG COMPUT, V10, P19, DOI 10.1006/jvlc.1998.0112
   Sereno M, 2022, COMPUT GRAPH FORUM, V41, P403, DOI 10.1111/cgf.14550
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Springel V, 2005, NATURE, V435, P629, DOI 10.1038/nature03597
   Springel V, 2008, MON NOT R ASTRON SOC, V391, P1685, DOI 10.1111/j.1365-2966.2008.14066.x
   Stenholt R., 2012, Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology - VRST'12, P105, DOI [DOI 10.1145/2407336.2407357, 10.1145/2407336, DOI 10.1145/2407336]
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Tietjen C., 2008, Bildverarbeitung fur die Medizin (BVM), P407, DOI [10.1007/978-3-540-78640-5_82, DOI 10.1007/978-3-540-78640-5_82]
   VandenBos G.R., 2009, PUBL MAN AM PSYCH AS
   vanTeylingen R, 1997, IEEE T VIS COMPUT GR, V3, P65, DOI 10.1109/2945.582350
   Wei YS, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581042
   Wiebel A, 2012, IEEE T VIS COMPUT GR, V18, P2236, DOI 10.1109/TVCG.2012.292
   Wills GJ, 1996, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION '96, PROCEEDINGS, P54, DOI 10.1109/INFVIS.1996.559216
   Wingrave CA, 2005, P IEEE VIRT REAL ANN, P163
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   Xu PF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366161
   Yu LY, 2016, IEEE T VIS COMPUT GR, V22, P886, DOI 10.1109/TVCG.2015.2467202
   Yu LY, 2012, IEEE T VIS COMPUT GR, V18, P2245, DOI 10.1109/TVCG.2012.217
   Zhao LX, 2022, IEEE INT SYMP M AU R, P118, DOI 10.1109/ISMAR-Adjunct57072.2022.00031
NR 65
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 480
EP 494
DI 10.1109/TVCG.2023.3326517
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500026
PM 37871080
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Cong, MT
   Lan, LA
   Fedkiw, R
AF Cong, Matthew
   Lan, Lana
   Fedkiw, Ronald
TI Local Geometric Indexing of High Resolution Data for Facial
   Reconstruction From Sparse Markers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Faces; Geometry; Surface reconstruction; Cameras; Point cloud
   compression; Deformation; Computer graphics; image processing and
   computer vision; interpolation
AB When considering sparse motion capture marker data, one typically struggles to balance its overfitting via a high dimensional blendshape system versus underfitting caused by smoothness constraints. With the current trend towards using more and more data, our aim is not to fit the motion capture markers with a parameterized (blendshape) model or to smoothly interpolate a surface through the marker positions, but rather to find an instance in the high resolution dataset that contains local geometry to fit each marker. Just as is true for typical machine learning applications, this approach benefits from a plethora of data, and thus we also consider augmenting the dataset via specially designed physical simulations that target the high resolution dataset such that the simulation output lies on the same so-called manifold as the data targeted.
C1 [Cong, Matthew; Lan, Lana; Fedkiw, Ronald] Ind Light & Mag, San Francisco, CA 94129 USA.
   [Fedkiw, Ronald] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
C3 Stanford University
RP Cong, MT (corresponding author), Ind Light & Mag, San Francisco, CA 94129 USA.
EM matthew.d.cong@gmail.com; lanalan@gmail.com; fedkiw@cs.stanford.edu
FU ONR [N00014-19-1-2285, N00014-21-1-2771]
FX No Statement Available
CR Beeler T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601182
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970
   Bermano AH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2546276
   Bhat R., 2013, P 12 ACM SIGGRAPH EU, P7, DOI 10.1145/2485895.24859153J.P.
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   Bickel M., P ACM EUR SIGGRAPH S
   Ribera RBI, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073674
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Chuang C., 2002, Comput. Sci. Tech. Rep., V2, P25
   Cong K. S., 2016, P ACM SIGGRAPH EUR S, P119
   Cong M, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085040
   Cong Matthew, 2015, P 14 ACM SIGGRAPH EU, P175
   de Berg Mark, 2008, Computational Geometry, V3rd, DOI DOI 10.1007/978-3-540-77974-2
   Dinev D, 2018, COMPUT GRAPH FORUM, V37, P93, DOI 10.1111/cgf.13515
   FUJIMOTO A, 1986, IEEE COMPUT GRAPH, V6, P16, DOI 10.1109/MCG.1986.276715
   Fyffe A., 2015, ACM Trans.Graph., V34, DOI [10.1145/26385498A., DOI 10.1145/26385498A]
   Ghosh A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024163
   Huynh L, 2018, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2018.00877
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Lan M., 2017, P ACM SIGGRAPH DIG P, DOI [10.1145/3105692.310569318C, DOI 10.1145/3105692.310569318C]
   Lefebvre M., 1974, A parametric model for human faces, P199
   Li H., 2009, P ACM SIGGRAPH AS PA, P10, DOI [10.1145/1661412.1618521, DOI 10.1145/1661412.1618521]
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Lüders S, 2022, J COMPUT PHYS, V467, DOI 10.1016/j.jcp.2022.111476
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Moser L, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085086
   Orvalho Veronica., 2012, P 33 ANN C EUR ASS C, P183, DOI DOI 10.2312/CONF/EG2012/STARS/183-204
   Park SW, 2006, IEEE T VIS COMPUT GR, V12, P243, DOI 10.1109/TVCG.2006.27
   Pharr JR, 2010, Physically Based Rendering: From Theory toImplementation
   Piper B., 1993, Computing (Supplementum), P227, DOI 10.1007/978-3-7091-6916-2_15
   Rhee M., P 35 ANN C EUR ASS C
   Seo J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024198
   Seol Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159519
   Shewchuk JonathanRichard., 2002, 11 INT MESHING ROUND, P193
   SIBSON R, 1980, MATH PROC CAMBRIDGE, V87, P151, DOI 10.1017/S0305004100056589
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Wu CL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925882
   Zell E, 2022, COMPUT GRAPH FORUM, V41, P121, DOI 10.1111/cgf.14463
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zoss G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201382
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5289
EP 5298
DI 10.1109/TVCG.2023.3289495
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400048
PM 37363850
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Fung, KLT
   Perrault, ST
   Gastner, MT
AF Fung, Kelvin L. T.
   Perrault, Simon T.
   Gastner, Michael T.
TI Effectiveness of Area-to-Value Legends and Grid Lines in Contiguous Area
   Cartograms
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cartogram; geovisualization; interactive data exploration; quantitative
   evaluation
ID ALGORITHM
AB A contiguous area cartogram is a geographic map in which the area of each region is proportional to numerical data (e.g., population size) while keeping neighboring regions connected. In this study, we investigated whether value-to-area legends (square symbols next to the values represented by the squares' areas) and grid lines aid map readers in making better area judgments. We conducted an experiment to determine the accuracy, speed, and confidence with which readers infer numerical data values for the mapped regions. We found that, when only informed about the total numerical value represented by the whole cartogram without any legend, the distribution of estimates for individual regions was centered near the true value with substantial spread. Legends with grid lines significantly reduced the spread but led to a tendency to underestimate the values. Comparing differences between regions or between cartograms revealed that legends and grid lines slowed the estimation without improving accuracy. However, participants were more likely to complete the tasks when legends and grid lines were present, particularly when the area units represented by these features could be interactively selected. We recommend considering the cartogram's use case and purpose before deciding whether to include grid lines or an interactive legend.
C1 [Fung, Kelvin L. T.] Yale NUS Coll, Singapore 138527, Singapore.
   [Fung, Kelvin L. T.] UCL, London WC1E 6BT, England.
   [Gastner, Michael T.] Singapore Inst Technol, Singapore 138683, Singapore.
   [Perrault, Simon T.] Singapore Univ Technol & Design, Singapore 487372, Singapore.
C3 Yale NUS College; University of London; University College London;
   Singapore Institute of Technology; Singapore University of Technology &
   Design
RP Gastner, MT (corresponding author), Singapore Inst Technol, Singapore 138683, Singapore.
EM fltkelvin@u.yale-nus.edu.sg; simon_perrault@sutd.edu.sg;
   michael.gastner@singaporetech.edu.sg
OI Fung, Kelvin/0009-0009-1694-3234; Gastner, Michael/0000-0002-1097-8833;
   Perrault, Simon/0000-0002-3105-9350
FU Ministry of Education - Singapore [MOE-T2EP20221-0007]; Academic
   Research Fund Tier 1 programme [IG18-PRB104, R-607-000-401-114];
   Yale-NUSunder its Summer Research Programme
FX No Statement Available
CR Abdi H., 2010, Encycl. Res. Des., V1, P1, DOI DOI 10.4135/9781412961288.N178
   Allen Mike., 2017, SAGE ENCY COMMUNICAT, DOI [DOI 10.4135/9781483381411, 10.4135/9781483381411.n601]
   Aschwanden C., 1998, Kartographische Nachrichten, V48, P221
   Bartram L, 2011, IEEE T VIS COMPUT GR, V17, P1444, DOI 10.1109/TVCG.2010.237
   Bestgen A.-K., 2013, P COGN SCI SOC, P193
   Boers M, 2018, ANN RHEUM DIS, V77, P833, DOI 10.1136/annrheumdis-2018-213396
   Brewer C.A., 2013, ColorBrewer: Color Advice for Maps
   Cano RG, 2015, COMPUT GRAPH FORUM, V34, P361, DOI 10.1111/cgf.12648
   Clark R., 2012, The carbon map
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cox C.W., 1976, The American Cartographer, V3, P65
   Cruz P, 2017, PROCEEDINGS OF THE 2017 IEEE VIS ARTS PROGRAM (VISAP)
   Cumming G., 2012, UNDERSTANDING NEW ST
   Dent B. D., 1975, Amer.Cartographer, V2, P154
   Dorling D., 1996, Concepts and Techniques in Modern Geography, V59
   Dukaczewski D, 2020, INT CONF CARTOGR GIS, P15
   Duncan IK, 2021, IEEE T VIS COMPUT GR, V27, P2136, DOI 10.1109/TVCG.2020.3041745
   Fay MP, 2010, R J, V2, P53
   Few S., 2005, DM Review
   Flannery J. J., 1971, Cartographica: Int. J. Geographic Inf. Geovisualization, V8, P96, DOI [DOI 10.3138/J647-1776-745H-3667, 10.3138/J647-1776-745H-3667]
   Gastner M. T., 2022, Encyclopedia of Mathematical Geosciences, P1
   Gastner M. T, 2021, "Creating cartograms online
   Gastner MT, 2018, P NATL ACAD SCI USA, V115, pE2156, DOI 10.1073/pnas.1712674115
   GOODCHILD MF, 1988, AM CARTOGRAPHER, V15, P311, DOI 10.1559/152304088783886973
   Gotthard B., 2022, Worldmapper rediscover the world as you'venever seen it before
   GRANT DA, 1948, PSYCHOL BULL, V45, P427, DOI 10.1037/h0053912
   GRIFFIN TLC, 1983, AM CARTOGRAPHER, V10, P17, DOI 10.1559/152304083783948258
   Han R, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6060180
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hennig J., 2010, ArcUser, P66
   Kaspar S., 2011, P 25 INT CART C, P112
   Lachenbruch P., 2005, Encyclopedia of Biostatistics, P1
   McCrum-Gardner E, 2008, BRIT J ORAL MAX SURG, V46, P38, DOI 10.1016/j.bjoms.2007.09.002
   McKinlay J, 2010, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630243
   McKnight P. E., 2010, The Corsini Encyclopedia of Psychology, P1
   Nusrat S., 2015, P EUR C VIS SHORT PA, P61
   Nusrat S, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399873
   Nusrat S, 2018, IEEE T VIS COMPUT GR, V24, P1100, DOI 10.1109/TVCG.2016.2642109
   OLSON JM, 1976, PROF GEOGR, V28, P371, DOI 10.1111/j.0033-0124.1976.00371.x
   Ordnance Survey, 2016, "Using the national grid
   Peterson MP, 1999, INT J GEOGR INF SCI, V13, P375, DOI 10.1080/136588199241256
   Riedmann M., 2021, Die Erde in karten: So haben Sie die Welt nochnicht gesehen
   Rittschof KA, 1996, J GEOGR, V95, P50, DOI 10.1080/00221349608978925
   Schwabish JA, 2014, J ECON PERSPECT, V28, P209, DOI 10.1257/jep.28.1.209
   Shimizu E, 2009, INT J GEOGR INF SCI, V23, P1453, DOI 10.1080/13658810802186882
   Sischka PE, 2022, SOC SCI COMPUT REV, V40, P405, DOI 10.1177/0894439320907067
   Snyder J. P, 1987, Map Projections-A Working Manual
   Stone M., 2008, P 16 IST SID COL IM, P355
   Sun H, 2010, CARTOGR J, V47, P12, DOI 10.1179/000870409X12525737905169
   Tingsheng I. K., P 8 INT C CART
   Tingsheng S., 2019, Abstr. Int. Cartographic Assoc., V1
   Tobler W R, 1973, Ann N Y Acad Sci, V219, P215, DOI 10.1111/j.1749-6632.1973.tb41401.x
   van Kreveld M, 2004, LECT NOTES COMPUT SC, V3221, P724
   Veaux De, 2015, Stats: Data and Models, V4th
   Wickham H., 2021, "ggplot2: Elegant graphics for data analysis
   Wilkinson L., 2012, Handbook of Computational Statistics: Concepts and Methods, P375, DOI [DOI 10.1007/978-3-642-21551-313, 10.1007/978-3-642-21551-3_13d, DOI 10.1007/978-3-642-21551-3_13D]
   Woytinsky WladimirS., 1953, World Population and Production: Trends and Outlook
   Yau YC, 2021, ENVIRON PLANN A, V53, P1249, DOI 10.1177/0308518X21998356
NR 59
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4631
EP 4647
DI 10.1109/TVCG.2023.3275925
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400091
PM 37186538
OA Green Accepted, hybrid
DA 2024-08-05
ER

PT J
AU Kumar, A
   Zhang, XY
   Xin, HL
   Yan, HF
   Huang, XJ
   Xu, W
   Müller, K
AF Kumar, Ayush
   Zhang, Xinyu
   Xin, Huolin L.
   Yan, Hanfei
   Huang, Xiaojing
   Xu, Wei
   Mueller, Klaus
TI RadVolViz: An Information Display-Inspired Transfer Function Editor for
   Multivariate Volume Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Battery; color mapping; multi channel data; multivariate data; transfer
   function; volume rendering; volume visualization
ID MULTIDIMENSIONAL TRANSFER-FUNCTIONS; COLOR
AB In volume visualization transfer functions are widely used for mapping voxel properties to color and opacity. Typically, volume density data are scalars which require simple 1D transfer functions to achieve this mapping. If the volume densities are vectors of three channels, one can straightforwardly map each channel to either red, green or blue, which requires a trivial extension of the 1D transfer function editor. We devise a new method that applies to volume data with more than three channels. These types of data often arise in scientific scanning applications, where the data are separated into spectral bands or chemical elements. Our method expands on prior work in which a multivariate information display, RadViz, was fused with a radial color map, in order to visualize multi-band 2D images. In this work, we extend this joint interface to blended volume rendering. The information display allows users to recognize the presence and value distribution of the multivariate voxels and the joint volume rendering display visualizes their spatial distribution. We design a set of operators and lenses that allow users to interactively control the mapping of the multivariate voxels to opacity and color. This enables users to isolate or emphasize volumetric structures with desired multivariate properties. Furthermore, it turns out that our method also enables more insightful displays even for RGB data. We demonstrate our method with three datasets obtained from spectral electron microscopy, high energy X-ray scanning, and atmospheric science.
C1 [Kumar, Ayush; Zhang, Xinyu; Mueller, Klaus] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Yan, Hanfei; Huang, Xiaojing; Xu, Wei] Brookhaven Natl Lab, Upton, NY 11973 USA.
   [Xin, Huolin L.] Univ Calif Irvine, Dept Phys & Astron, Irvine, CA 92697 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; United States Department of Energy (DOE); Brookhaven
   National Laboratory; University of California System; University of
   California Irvine
RP Kumar, A (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM aykumar@cs.stonybrook.edu; zhang146@cs.stonybrook.edu; huolinx@uci.edu;
   hyan@bnl.gov; xjhuang@bnl.gov; xuw@bnl.gov; mueller@cs.stonybrook.edu
RI Huang, Xiaojing/K-3075-2012
OI Zhang, Xinyu/0000-0002-7475-8979; Xu, Wei/0000-0002-4525-4819; Mueller,
   Klaus/0000-0002-0996-8590; Kumar, Ayush/0000-0001-5867-5623
FU NSF [IIS 1527200, 1941613, CHE-1900401]; Brookhaven National Laboratory
   LDRD [16-041]; DOE Office of Science by Brookhaven National Laboratory
   [DE-SC0012704]
FX No Statement Available
CR Abbasloo A, 2016, IEEE T VIS COMPUT GR, V22, P975, DOI 10.1109/TVCG.2015.2467031
   Ayachit U., 2015, PARAVIEW GUIDE PARAL
   Bertini E, 2005, THIRD INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P22
   Bramon R, 2013, IEEE J BIOMED HEALTH, V17, P870, DOI 10.1109/JBHI.2013.2263227
   Cheng SH, 2019, IEEE T VIS COMPUT GR, V25, P1361, DOI 10.1109/TVCG.2018.2808489
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   CIBC, 2016, Sci. Comput. Imag. Inst.
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Ferreira GC, 2020, RADIAT PHYS CHEM, V167, DOI 10.1016/j.radphyschem.2019.02.049
   Giesen J, 2007, IEEE T VIS COMPUT GR, V13, P1664, DOI 10.1109/TVCG.2007.70542
   Guo HQ, 2011, IEEE PAC VIS SYMP, P19, DOI 10.1109/PACIFICVIS.2011.5742368
   Haidacher Martin., 2008, P EUROGRAPHICS WORKS, P101, DOI DOI 10.2312/VCBM/VCBM08/101-108
   Hanwell MarcusD., 2019, MICROSC MICROANAL, V25, P408, DOI [10.1017/S1431927619002770, DOI 10.1017/S1431927619002770]
   Harris WM, 2014, NANOSCALE, V6, P4480, DOI 10.1039/c3nr06684c
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hovden R, 2020, MRS BULL, V45, P298, DOI 10.1557/mrs.2020.87
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Kaufman A., 2005, VISUALIZATION HDB, V1st, P127, DOI [10.1016/B978-012387582-2/50009-5, DOI 10.1016/B978-012387582-2/50009-5]
   Kim HS, 2010, INFORM VISUAL, V9, P167, DOI 10.1057/ivs.2010.6
   Kindlmann G., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P183, DOI 10.1109/VISUAL.1999.809886
   Kindlmann G, 2000, IEEE T VIS COMPUT GR, V6, P124, DOI 10.1109/2945.856994
   Kniss J, 2001, IEEE VISUAL, P255, DOI 10.1109/VISUAL.2001.964519
   Kniss JM, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P287
   Kühne L, 2012, IEEE T VIS COMPUT GR, V18, P2122, DOI 10.1109/TVCG.2012.186
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Li WD, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14589
   Liu SS, 2014, SYMP LARG DATA ANAL, P35, DOI 10.1109/LDAV.2014.7013202
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Lu AD, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P655
   Lundstrom C., 2006, P EG IEEE VGTC WORKS, P1
   Maciejewski R, 2009, IEEE T VIS COMPUT GR, V15, P1473, DOI 10.1109/TVCG.2009.185
   Markus IM, 2014, J PHYS CHEM LETT, V5, P3649, DOI 10.1021/jz5017526
   Mörth E, 2020, LECT NOTES COMPUT SC, V12221, P351, DOI 10.1007/978-3-030-61864-3_29
   Muraki S, 2001, IEEE T VIS COMPUT GR, V7, P265, DOI 10.1109/2945.942694
   Pfaffelmoser T, 2011, COMPUT GRAPH FORUM, V30, P951, DOI 10.1111/j.1467-8659.2011.01944.x
   Pinto Franciscode Moura., 2007, Eurographics IEEE-VGTC Symposium on Visualization, P131
   Sereda P., 2006, P 8 JOINT EUR IEEE V
   Shao YY, 2013, ADV FUNCT MATER, V23, P987, DOI 10.1002/adfm.201200688
   Steiner JD, 2019, ACS APPL MATER INTER, V11, P37885, DOI 10.1021/acsami.9b14729
   Tzeng F.-Y., 2004, S DATA VISUALISATION, P17, DOI DOI 10.2312/VISSYM/VISSYM04/017-024
   Tzeng FY, 2005, IEEE T VIS COMPUT GR, V11, P273, DOI 10.1109/TVCG.2005.38
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wang L, 2012, COMPUT GRAPH FORUM, V31, P1305, DOI 10.1111/j.1467-8659.2012.03123.x
   Wang L, 2012, IEEE T VIS COMPUT GR, V18, P121, DOI 10.1109/TVCG.2011.23
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yan HF, 2020, MRS BULL, V45, P264, DOI 10.1557/mrs.2020.90
   Yan HF, 2018, NANO FUTURES, V2, DOI 10.1088/2399-1984/aab25d
   Zhang JN, 2019, NAT ENERGY, V4, P594, DOI 10.1038/s41560-019-0409-z
NR 49
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4464
EP 4479
DI 10.1109/TVCG.2023.3263856
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400070
PM 37030815
OA Green Submitted
DA 2024-08-05
ER

PT J
AU van den Brandt, A
   Jonkheer, EM
   van Workum, DJM
   van de Wetering, H
   Smit, S
   Vilanova, A
AF van den Brandt, Astrid
   Jonkheer, Eef M.
   van Workum, Dirk-Jan M.
   van de Wetering, Huub
   Smit, Sandra
   Vilanova, Anna
TI PanVA: Pangenomic Variant Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; design study; pangenomics; comparative genomics;
   variant analysis
ID SEQUENCE; ALIGNMENT; DESIGN
AB Genomics researchers increasingly use multiple reference genomes to comprehensively explore genetic variants underlying differences in detectable characteristics between organisms. Pangenomes allow for an efficient data representation of multiple related genomes and their associated metadata. However, current visual analysis approaches for exploring these complex genotype-phenotype relationships are often based on single reference approaches or lack adequate support for interpreting the variants in the genomic context with heterogeneous (meta)data. This design study introduces PanVA, a visual analytics design for pangenomic variant analysis developed with the active participation of genomics researchers. The design uniquely combines tailored visual representations with interactions such as sorting, grouping, and aggregation, allowing users to navigate and explore different perspectives on complex genotype-phenotype relations. Through evaluation in the context of plants and pathogen research, we show that PanVA helps researchers explore variants in genes and generate hypotheses about their role in phenotypic variation.
C1 [van den Brandt, Astrid; van de Wetering, Huub; Vilanova, Anna] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
   [Jonkheer, Eef M.; van Workum, Dirk-Jan M.; Smit, Sandra] Wageningen Univ & Res, Bioinformat Grp, NL-6708 PB Wageningen, Netherlands.
C3 Eindhoven University of Technology; Wageningen University & Research
RP van den Brandt, A (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
EM a.v.d.brandt@tue.nl; eef.jonkheer@wur.nl; dirk-jan.vanworkum@wur.nl;
   h.v.d.wetering@tue.nl; sandra.smit@wur.nl; a.vilanova@tue.nl
RI Smit, Sandra/E-6787-2010
OI Smit, Sandra/0000-0001-5239-5321; van den Brandt,
   Astrid/0000-0002-3676-1341; van Workum, Dirk-Jan/0000-0001-6247-5499;
   Jonkheer, Eef/0000-0002-2608-6311; Vilanova, Anna/0000-0002-1034-737X;
   van de Wetering, Huub/0000-0002-0517-1322
FU Dutch Top Consortium for Knowledge and Innovation (TKI) Agri Food
   [TU18034]
FX This work was supported in part by the Dutch Top Consortium for
   Knowledge and Innovation (TKI) Agri & Food under Grant TU18034.
CR Alonso-Blanco C, 2016, CELL, V166, P481, DOI 10.1016/j.cell.2016.05.063
   Bandeira V, 2020, IEEE INT NEW CIRC, P74, DOI [10.1109/NEWCAS49341.2020.9159791, 10.1109/newcas49341.2020.9159791]
   Bayer PE, 2020, NAT PLANTS, V6, P914, DOI 10.1038/s41477-020-0733-0
   Bederson B. B., 1999, INFOVIS 99
   Carriço JA, 2018, ALGORITHM MOL BIOL, V13, DOI 10.1186/s13015-017-0119-7
   Chen YA, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-293
   Cigna J, 2017, PLANT DIS, V101, P1278, DOI 10.1094/PDIS-12-16-1810-RE
   Computomics, 2022, "Computomics GmbH
   Diesh C, 2023, GENOME BIOL, V24, DOI 10.1186/s13059-023-02914-z
   Ding W, 2018, NUCLEIC ACIDS RES, V46, DOI 10.1093/nar/gkx977
   Donlin M. J., 2009, Curr. Protoc. Bioinf., V28, P1
   Duda RO, 2001, Pattern classification, V2nd
   Eades P., 1991, Tech. Rep. IIAS-RR-91-16E
   Fernandez NF, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.151
   Ferstay JA, 2013, IEEE T VIS COMPUT GR, V19, P2546, DOI 10.1109/TVCG.2013.214
   Gautreau G, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007732
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Glueck M, 2017, IEEE T VIS COMPUT GR, V23, P191, DOI 10.1109/TVCG.2016.2598469
   Golicz AA, 2020, TRENDS GENET, V36, P132, DOI 10.1016/j.tig.2019.11.006
   Guarracino A, 2022, BIOINFORMATICS, V38, P3319, DOI 10.1093/bioinformatics/btac308
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Heinrich J, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-S8-S2
   Hurgobin B, 2017, BIOLOGY-BASEL, V6, DOI 10.3390/biology6010021
   Huson D., 2010, Phylogenetic Networks: Concepts, Algorithms and Applications
   Jiao WB, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14779-y
   Jonkheer EM, 2022, BIOINFORMATICS, V38, P4403, DOI 10.1093/bioinformatics/btac506
   Jonkheer EM, 2021, BMC GENOMICS, V22, DOI 10.1186/s12864-021-07583-5
   Kearse M, 2012, BIOINFORMATICS, V28, P1647, DOI 10.1093/bioinformatics/bts199
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Kultys M., 2014, BMC Proc., V8, P1
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   Lam HM, 2010, NAT GENET, V42, P1053, DOI 10.1038/ng.715
   Letunic I, 2021, NUCLEIC ACIDS RES, V49, pW293, DOI 10.1093/nar/gkab301
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Malik S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2890478
   Marschall T, 2018, BRIEF BIOINFORM, V19, P118, DOI 10.1093/bib/bbw089
   Mayor C, 2000, BIOINFORMATICS, V16, P1046, DOI 10.1093/bioinformatics/16.11.1046
   Meyer M, 2010, COMPUT GRAPH FORUM, V29, P1043, DOI 10.1111/j.1467-8659.2009.01710.x
   Meyer M, 2009, IEEE T VIS COMPUT GR, V15, P897, DOI 10.1109/TVCG.2009.167
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P1543, DOI 10.1109/TVCG.2018.2811488
   Nusrat S, 2019, COMPUT GRAPH FORUM, V38, P781, DOI 10.1111/cgf.13727
   Paten B, 2017, GENOME RES, V27, P665, DOI 10.1101/gr.214155.116
   Pendergrass SA, 2012, BIODATA MIN, V5, DOI 10.1186/1756-0381-5-5
   Roberts JC, 2016, IEEE T VIS COMPUT GR, V22, P419, DOI 10.1109/TVCG.2015.2467271
   Rogers J, 2021, IEEE T VIS COMPUT GR, V27, P1106, DOI 10.1109/TVCG.2020.3030405
   Ruddle RA, 2022, IEEE T VIS COMPUT GR, V28, P3070, DOI 10.1109/TVCG.2021.3050497
   SCHNEIDER TD, 1990, NUCLEIC ACIDS RES, V18, P6097, DOI 10.1093/nar/18.20.6097
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Seo J, 2002, COMPUTER, V35, P80
   Sheikhizadeh S, 2016, BIOINFORMATICS, V32, P487, DOI 10.1093/bioinformatics/btw455
   Sievers F, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.75
   Slack J., 2004, German Conference on Bioinformatics, P37
   Smit S., 2022, "Visual analytics for plant pangenomes
   Sun C, 2017, NUCLEIC ACIDS RES, V45, P597, DOI 10.1093/nar/gkw958
   Thorvaldsdóttir H, 2013, BRIEF BIOINFORM, V14, P178, DOI 10.1093/bib/bbs017
   Treangen TJ, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0524-x
   Venkatachalam B, 2010, IEEE ACM T COMPUT BI, V7, P588, DOI 10.1109/TCBB.2010.57
   Walkowiak S, 2020, NATURE, V588, DOI 10.1038/s41586-020-2961-x
   Waterhouse AM, 2009, BIOINFORMATICS, V25, P1189, DOI 10.1093/bioinformatics/btp033
   Wilkinson L, 2009, AM STAT, V63, P179, DOI 10.1198/tas.2009.0033
   Paz MW, 2022, BIOINFORM ADV, V2, DOI 10.1093/bioadv/vbac075
NR 64
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4895
EP 4909
DI 10.1109/TVCG.2023.3282364
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400084
PM 37267130
OA Green Published
DA 2024-08-05
ER

PT J
AU Wang, M
   Li, YJ
   Shi, JC
   Steinicke, F
AF Wang, Miao
   Li, Yi-Jun
   Shi, Jinchuan
   Steinicke, Frank
TI SceneFusion: Room-Scale Environmental Fusion for Efficient Traveling
   Between Separate Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teleportation; Visualization; Collaboration; Task analysis; Portals;
   Legged locomotion; Three-dimensional displays; Virtual reality;
   collaborative virtual environments; scene transition
ID GROUP NAVIGATION; VISUAL COMFORT; REALITY; TRANSITION
AB Traveling between scenes has become a major requirement for navigation in numerous virtual reality (VR) social platforms and game applications, allowing users to efficiently explore multiple virtual environments (VEs). To facilitate scene transition, prevalent techniques such as instant teleportation and virtual portals have been extensively adopted. However, these techniques exhibit limitations when there is a need for frequent travel between separate VEs, particularly within indoor environments, resulting in low efficiency. In this article, we first analyze the design rationale for a novel navigation method supporting efficient travel between virtual indoor scenes. Based on the analysis, we introduce the SceneFusion technique that fuses separate virtual rooms into an integrated environment. SceneFusion enables users to perceive rich visual information from both rooms simultaneously, achieving high visual continuity and spatial awareness. While existing teleportation techniques passively transport users, SceneFusion allows users to actively access the fused environment using short-range locomotion techniques. User experiments confirmed that SceneFusion outperforms instant teleportation and virtual portal techniques in terms of efficiency, workload, and preference for both single-user exploration and multi-user collaboration tasks in separate VEs. Thus, SceneFusion presents an effective solution for seamless traveling between virtual indoor scenes.
C1 [Wang, Miao; Li, Yi-Jun; Shi, Jinchuan] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Wang, Miao] Zhongguancun Lab, Beijing 100094, Peoples R China.
   [Steinicke, Frank] Univ Hamburg, Dept Informat, D-22605 Hamburg, Germany.
C3 Beihang University; Zhongguancun Laboratory; University of Hamburg
RP Wang, M (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM miaowang.me@gmail.com; yaoling@buaa.edu.cn; buaashijinchuan@gmail.com;
   frank.steinicke@uni-hamburg.de
RI Steinicke, Frank/AAC-2976-2020
OI Steinicke, Frank/0000-0001-9879-7414; Li, Yi-Jun/0000-0003-2733-2913;
   Shi, Jin-Chuan/0009-0003-4899-2205
FU National Natural Science Foundation of China [61932003]; Fundamental
   Research Funds for the Central Universities; BMBF; BMWi; DFG; EU
FX No Statement Available
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Agrawala M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P327, DOI 10.1145/258734.258875
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Benford S, 2001, COMMUN ACM, V44, P79, DOI 10.1145/379300.379322
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bolte B., 2011, P VIRT REAL INT C, P1
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bruder G, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P75, DOI 10.1109/3DUI.2009.4811208
   Burdea G.C., 1999, VIRTUAL REALITY PROT, V2, P17, DOI 10.1.1.135.6358
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Chow Kevin, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359142
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Fitter HN, 2014, PROCEDIA ENGINEER, V97, P1155, DOI 10.1016/j.proeng.2014.12.394
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Games V., 2023, Pavlov VR
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Guo JJ, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/2996296
   Han P-H., 2017, P ACM SIGGRAPH EM TE, P1
   Hanson S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P367, DOI [10.1109/vr.2019.8797751, 10.1109/VR.2019.8797751]
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   He ZY, 2020, INT SYM MIX AUGMENT, P542, DOI 10.1109/ISMAR50242.2020.00082
   Hsu TW, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P363, DOI [10.1109/VR46266.2020.1581231362069, 10.1109/VR46266.2020.00-48]
   Husung M., 2019, P MENSCH COMPUTER 20, P245, DOI [10.1145/3340764.3340779, DOI 10.1145/3340764.3340779]
   Insko B. E, 2001, Passive Haptics Significantly Enhances Virtual Environ- ments
   Irlitti A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P31, DOI [10.1109/ISMAR-Adjunct.2016.25, 10.1109/ISMAR-Adjunct.2016.0032]
   Jung YJ, 2014, IEEE T CONSUM ELECTR, V60, P1, DOI 10.1109/TCE.2014.6780918
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Keshavarzi M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P353, DOI [10.1109/VR46266.2020.00-49, 10.1109/VR46266.2020.1581131119600]
   Kim D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P379, DOI 10.1109/VR51125.2022.00057
   Kiyokawa K., 2005, P INT C HUM COMP INT
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Kunert A, 2020, IEEE T VIS COMPUT GR, V26, P3271, DOI 10.1109/TVCG.2019.2914677
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lee GA, 2020, INT SYM MIX AUGMENT, P498, DOI 10.1109/ISMAR50242.2020.00078
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Li CY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480478
   Li JB, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P585, DOI 10.1145/3130859.3130860
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Liao MY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P163, DOI [10.1109/vr.2019.8797708, 10.1109/VR.2019.8797708]
   Lili Wang, 2022, 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P628, DOI 10.1109/VRW55335.2022.00165
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Lokki T, 2005, IEEE MULTIMEDIA, V12, P80, DOI 10.1109/MMUL.2005.33
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   MacQuarrie A, 2018, IEEE T VIS COMPUT GR, V24, P1564, DOI 10.1109/TVCG.2018.2793561
   Malinov YD, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P501, DOI 10.1109/VR50410.2021.00074
   Men L, 2017, P IEEE VIRT REAL ANN, P285, DOI 10.1109/VR.2017.7892288
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Moghadam KR, 2017, P IEEE VIRT REAL ANN, P375, DOI 10.1109/VR.2017.7892333
   Nehmé Y, 2021, IEEE T VIS COMPUT GR, V27, P2202, DOI 10.1109/TVCG.2020.3036153
   Nguyen T.T. H., 2013, P GRAPP INT C COMP G, P327
   Nguyen T.T. H., 2014, P INT WORKSH COLL VI, P1
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132822
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Razzaque S., 2005, Redirected walking
   Rhee T, 2020, IEEE T VIS COMPUT GR, V26, P1923, DOI 10.1109/TVCG.2020.2973065
   Sayyad E, 2020, INT SYM MIX AUGMENT, P608, DOI 10.1109/ISMAR50242.2020.00088
   Schott D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P296, DOI 10.1109/VR50410.2021.00052
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Soret R, 2021, APPL ERGON, V97, DOI 10.1016/j.apergo.2021.103535
   Sra M, 2018, IEEE T VIS COMPUT GR, V24, P3174, DOI 10.1109/TVCG.2017.2762691
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Stotko P, 2019, IEEE T VIS COMPUT GR, V25, P2102, DOI 10.1109/TVCG.2019.2899231
   Summers C, 2017, 2017 IEEE 3RD VR WORKSHOP ON SONIC INTERACTIONS FOR VIRTUAL ENVIRONMENTS (SIVE)
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Teo T, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364238
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Thanyadit Santawat, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274441
   Thanyadit S., 2020, P S SPAT US INT, P1
   V. Inc, 2023, VRChat
   Vasylevska K., 2014, P 15 INT C PRES, P205
   Walton DJ, 1999, COMPUT AIDED DESIGN, V31, P857, DOI 10.1016/S0010-4485(99)00073-1
   Wang LL, 2021, INT SYM MIX AUGMENT, P60, DOI 10.1109/ISMAR52148.2021.00020
   Wang M, 2020, COMPUT VIS MEDIA, V6, P3, DOI 10.1007/s41095-020-0162-z
   Weissker Tim, 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2524, DOI 10.1109/TVCG.2021.3067756
   Weissker T, 2020, IEEE T VIS COMPUT GR, V26, P1860, DOI 10.1109/TVCG.2020.2973474
   Weissker T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI [10.1109/VR.2019.8797807, 10.1109/vr.2019.8797807]
   Wells T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376541
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Xu SZ, 2024, IEEE T VIS COMPUT GR, V30, P1916, DOI 10.1109/TVCG.2023.3251648
   Yanxiang Zhang, 2018, Augmented Reality, Virtual Reality, and Computer Graphics. 5th International Conference, AVR 2018. Proceedings: LNCS 10850, P190, DOI 10.1007/978-3-319-95270-3_14
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/vr.2019.8797719, 10.1109/VR.2019.8797719]
   Yoshida N, 2006, VISUAL COMPUT, V22, P896, DOI 10.1007/s00371-006-0076-5
   Young J, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3397331
   Young J, 2019, IEEE T VIS COMPUT GR, V25, P1908, DOI 10.1109/TVCG.2019.2898737
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Zeltzer D., 1992, Presence: Teleop. Virt. Environ., V1, P127, DOI [DOI 10.1162/PRES.1992.1.1.127, 10.1162/pres.1992.1.1.127]
   Zhang YZ, 2022, IEEE T VIS COMPUT GR, V28, P2146, DOI 10.1109/TVCG.2022.3150512
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 102
TC 1
Z9 1
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4615
EP 4630
DI 10.1109/TVCG.2023.3271709
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400021
PM 37126613
DA 2024-08-05
ER

PT J
AU Deng, ZK
   Chen, SF
   Xie, X
   Sun, GD
   Xu, ML
   Weng, D
   Wu, YC
AF Deng, Zikun
   Chen, Shifu
   Xie, Xiao
   Sun, Guodao
   Xu, Mingliang
   Weng, Di
   Wu, Yingcai
TI Multilevel Visual Analysis of Aggregate Geo-Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geospatial network; multilevel analysis; information visualization;
   graph drawing
ID OF-THE-ART; MASS MOBILITY; MAP LAYOUT; VISUALIZATION; ABSTRACTION;
   EVOLUTION; DYNAMICS; PATTERNS; AWARE
AB Numerous patterns found in urban phenomena, such as air pollution and human mobility, can be characterized as many directed geospatial networks (geo-networks) that represent spreading processes in urban space. These geo-networks can be analyzed from multiple levels, ranging from the macro-level of summarizing all geo-networks, meso-level of comparing or summarizing parts of geo-networks, and micro-level of inspecting individual geo-networks. Most of the existing visualizations cannot support multilevel analysis well. These techniques work by: 1) showing geo-networks separately with multiple maps leads to heavy context switching costs between different maps; 2) summarizing all geo-networks into a single network can lead to the loss of individual information; 3) drawing all geo-networks onto one map might suffer from the visual scalability issue in distinguishing individual geo-networks. In this study, we propose GeoNetverse, a novel visualization technique for analyzing aggregate geo-networks from multiple levels. Inspired by metro maps, GeoNetverse balances the overview and details of the geo-networks by placing the edges shared between geo-networks in a stacked manner. To enhance the visual scalability, GeoNetverse incorporates a level-of-detail rendering, a progressive crossing minimization, and a coloring technique. A set of evaluations was conducted to evaluate GeoNetverse from multiple perspectives.
C1 [Deng, Zikun; Chen, Shifu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Xie, Xiao] Zhejiang Univ, Dept Sport Sci, Hangzhou 310058, Zhejiang, Peoples R China.
   [Sun, Guodao] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310014, Zhejiang, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450052, Peoples R China.
   [Xu, Mingliang] MOE China Natl Supercomp Ctr Zhengzhou, Engn Res Ctr Intelligent Swarm Syst, Zhengzhou 450052, Peoples R China.
   [Weng, Di] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University of
   Technology; Zhengzhou University; Microsoft; Microsoft Research Asia
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.; Weng, D (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM zikun_rain@zju.edu.cn; sfchen@zju.edu.cn; xxie@zju.edu.cn;
   guodao@zjut.edu.cn; iexumingliang@zzu.edu.cn; mystery.wd@gmail.com;
   ycwu@zju.edu.cn
RI Deng, Zikun/IQT-3106-2023
OI Weng, Di/0000-0003-2712-7274; Sun, Guodao/0000-0002-8383-8153
FU NSFC [62072400, 61972356, 62036010]; Collaborative Innovation Center of
   Artificial Intelligence by MOE; Zhejiang Provincial Government (ZJU)
FX This work was supported in part by NSFC under Grants 62072400, 61972356,
   and 62036010 and in part by the Collaborative Innovation Center of
   Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU).
   Yingcai Wu and Di Weng are the co-corresponding authors.
CR Andrienko G, 2017, IEEE T VIS COMPUT GR, V23, P2120, DOI 10.1109/TVCG.2016.2616404
   Andrienko N, 2016, INFORM SYST, V57, P172, DOI 10.1016/j.is.2015.08.007
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   Arendt D, 2017, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2017.8585487
   Bach B., 2011, P INT C WORLD WID WE, P177
   Baldonado M. Q. W., 2000, Proceedings of the Conference on Advanced Visual Interfaces, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Bast H, 2019, ACM TRANS SPAT ALGOR, V5, DOI 10.1145/3337790
   BENDER EA, 1985, J ALGORITHM, V6, P275, DOI 10.1016/0196-6774(85)90044-6
   Bourqui R, 2016, IEEE PAC VIS SYMP, P184, DOI 10.1109/PACIFICVIS.2016.7465267
   Cakmak E, 2020, COMPUT GRAPH FORUM, V39, P63, DOI 10.1111/cgf.13963
   Chen W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200766
   Deng Z., 2022, J. Vis., P1
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P2486, DOI 10.1109/TVCG.2021.3071387
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Dong Y., 2022, J. Vis.
   Ducruet C, 2017, J TRANSP GEOGR, V60, P47, DOI 10.1016/j.jtrangeo.2017.02.007
   Dübel S, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P11, DOI 10.1109/3DVis.2014.7160094
   Feng ZZ, 2021, IEEE T VIS COMPUT GR, V27, P828, DOI 10.1109/TVCG.2020.3030469
   Fink Martin, 2013, Graph Drawing. 21st International Symposium, GD 2013. Revised Selected Papers: LNCS 8242, P328, DOI 10.1007/978-3-319-03841-4_29
   Gansner ER, 2011, IEEE PAC VIS SYMP, P187, DOI 10.1109/PACIFICVIS.2011.5742389
   Garcia G, 2021, IEEE T VIS COMPUT GR, V27, P2313, DOI 10.1109/TVCG.2019.2947515
   Guo DS, 2012, T GIS, V16, P411, DOI 10.1111/j.1467-9671.2012.01344.x
   Hong L, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820811
   Hou YJ, 2022, IEEE T VIS COMPUT GR, V28, P1030, DOI 10.1109/TVCG.2021.3114777
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   HUFF DL, 1963, LAND ECON, V39, P81, DOI 10.2307/3144521
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Jamonnak S, 2022, IEEE T VIS COMPUT GR, V28, P1019, DOI 10.1109/TVCG.2021.3114853
   Jensen Tommy R, 2011, GRAPH COLORING PROBL, V39
   Ko S, 2014, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2014.7042484
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Li XC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1863, DOI 10.1145/3097983.3098090
   Liang YX, 2017, 25TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2017), DOI 10.1145/3139958.3139960
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu HY, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.10.002
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Shuhan, 2023, IEEE Trans Vis Comput Graph, V29, P1091, DOI 10.1109/TVCG.2022.3209430
   Lu M, 2017, IEEE T BIG DATA, V3, P234, DOI 10.1109/TBDATA.2017.2667700
   Malaguti E, 2010, INT T OPER RES, V17, P1, DOI 10.1111/j.1475-3995.2009.00696.x
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Mutzel P, 2001, SIAM J OPTIMIZ, V11, P1065, DOI 10.1137/S1052623498334013
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Nollenburg M., 2014, P SCHEM MAPP WORKSH
   Pérez-Messina I, 2020, ALGORITHMS, V13, DOI 10.3390/a13110298
   Peysakhovich V, 2015, IEEE PAC VIS SYMP, P39, DOI 10.1109/PACIFICVIS.2015.7156354
   Roth RE, 2013, IEEE T VIS COMPUT GR, V19, P2356, DOI 10.1109/TVCG.2013.130
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Tao Y., 2012, J. Vis., P1
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   Vehlow C, 2015, COMPUT GRAPH FORUM, V34, P277, DOI 10.1111/cgf.12512
   Verbeek K, 2011, IEEE T VIS COMPUT GR, V17, P2536, DOI 10.1109/TVCG.2011.202
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Wang HX, 2021, VIS INFORM, V5, P82, DOI 10.1016/j.visinf.2021.09.001
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Weng D, 2021, IEEE T INTELL TRANSP, V22, P1185, DOI 10.1109/TITS.2020.2964012
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Wu WC, 2016, IEEE T VIS COMPUT GR, V22, P935, DOI 10.1109/TVCG.2015.2467194
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Yang C, 2023, IEEE T VIS COMPUT GR, V29, P3586, DOI 10.1109/TVCG.2022.3165385
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2017, IEEE T VIS COMPUT GR, V23, P411, DOI 10.1109/TVCG.2016.2598885
   Zarate DC, 2018, IEEE PAC VIS SYMP, P135, DOI 10.1109/PacificVis.2018.00025
   Zhao WX, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2022.06.002
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zheng JX, 2021, IEEE T VIS COMPUT GR, V27, P2244, DOI 10.1109/TVCG.2019.2944619
NR 79
TC 1
Z9 1
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3135
EP 3150
DI 10.1109/TVCG.2022.3229953
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700049
PM 37015452
DA 2024-08-05
ER

PT J
AU Engel, D
   Hartwig, S
   Ropinski, T
AF Engel, Dominik
   Hartwig, Sebastian
   Ropinski, Timo
TI Monocular Depth Decomposition of Semi-Transparent Volume Renderings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Volume rendering; depth compositing; monocular depth estimation
AB Neural networks have shown great success in extracting geometric information from color images. Especially, monocular depth estimation networks are increasingly reliable in real-world scenes. In this work we investigate the applicability of such monocular depth estimation networks to semi-transparent volume rendered images. As depth is notoriously difficult to define in a volumetric scene without clearly defined surfaces, we consider different depth computations that have emerged in practice, and compare state-of-the-art monocular depth estimation approaches for these different interpretations during an evaluation considering different degrees of opacity in the renderings. Additionally, we investigate how these networks can be extended to further obtain color and opacity information, in order to create a layered representation of the scene based on a single color image. This layered representation consists of spatially separated semi-transparent intervals that composite to the original input rendering. In our experiments we show that existing approaches to monocular depth estimation can be adapted to perform well on semi-transparent volume renderings, which has several applications in the area of scientific visualization, like re-composition with additional objects and labels or additional shading.
C1 [Engel, Dominik; Hartwig, Sebastian; Ropinski, Timo] Ulm Univ, Visual Comp Grp, D-89081 Ulm, Germany.
C3 Ulm University
RP Engel, D (corresponding author), Ulm Univ, Visual Comp Grp, D-89081 Ulm, Germany.
EM dominik.engel@uni-ulm.de; sebastian.hartwig@uni-ulm.de;
   timo.ropinski@uni-ulm.de
OI Engel, Dominik/0000-0002-5766-7215; Hartwig,
   Sebastian/0000-0001-8642-2789; Ropinski, Timo/0000-0002-7857-5512
FU Deutsche Forschungsgemeinschaft (DFG) [391107954]
FX This work was partially supported in part by the Deutsche
   Forschungsgemeinschaft (DFG) under Grant 391107954 (Inviwo).
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Bailey D., 1998, J. Graph. Tools, P1
   Behrendt P., 2017, P EUR WORKSH VIS COM, P159
   Bruckner S, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P671
   Bruckner S, 2009, COMPUT GRAPH FORUM, V28, P775, DOI 10.1111/j.1467-8659.2009.01474.x
   Caban JJ, 2008, IEEE T VIS COMPUT GR, V14, P1364, DOI 10.1109/TVCG.2008.169
   Chilamkurthy S, 2018, Arxiv, DOI [arXiv:1803.05854, DOI 10.48550/ARXIV.1803.05854]
   Choi J, 2021, IEEE INT CONF ROBOT, P467, DOI 10.1109/ICRA48506.2021.9560831
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Eigen D., 2014, In: Neural Information Processing Systems, P2366, DOI DOI 10.5555/2969033.2969091
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Elmqvist N., 2014, EuroVis -Short Papers, DOI [10.2312/eurovisshort.20141164, DOI 10.2312/EUROVISSHORT.20141164]
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Frey Steffen, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P123, DOI 10.1109/SIBGRAPI.2013.26
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   GEIGER A, 2013, IJRR, V32, P1231, DOI DOI 10.1177/0278364913491297
   KAUFMAN A, 1990, NATO ADV SCI I F-COM, V60, P217
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee J.H., 2019, arXiv
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Lindholm S, 2015, COMPUT GRAPH FORUM, V34, P74, DOI 10.1111/cgf.12460
   Lindholm S, 2014, IEEE T VIS COMPUT GR, V20, P2447, DOI 10.1109/TVCG.2014.2346351
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Maximov M, 2020, PROC CVPR IEEE, P1068, DOI 10.1109/CVPR42600.2020.00115
   Newman TS, 2006, COMPUT GRAPH-UK, V30, P854, DOI 10.1016/j.cag.2006.07.021
   Pajarola R., 2008, P EUR IEEE COMP SOC
   Prassni JS, 2010, IEEE PAC VIS SYMP, P9, DOI 10.1109/PACIFICVIS.2010.5429624
   Ramamonjisoa Y., 2020, P IEEE CVF C COMP VI, P14648
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Ropinski T., 2007, Internal labels as shape cues for medical illustration, P203
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shengjie Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13113, DOI 10.1109/CVPR42600.2020.01313
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Steenblik R. A., 1987, True Three-Dimensional Imaging Techniques &Display Technologies, P34
   Stoppel S, 2018, IEEE PAC VIS SYMP, P36, DOI 10.1109/PacificVis.2018.00014
   Tikhonova A, 2010, IEEE PAC VIS SYMP, P177, DOI 10.1109/PACIFICVIS.2010.5429595
   Wang J., IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3167896.41L, DOI 10.1109/TVCG.2022.3167896.41L]
   Wang LJ, 2020, PROC CVPR IEEE, P538, DOI 10.1109/CVPR42600.2020.00062
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss J., 2021, Deep direct volume rendering: Learning visual feature mappings from exemplary images, DOI DOI 10.48550/ARXIV.2106.05429
   Weiss S, 2022, Arxiv, DOI arXiv:2112.01579
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P562, DOI 10.1109/TVCG.2021.3114769
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Wiebel A., 2011, ZIB-Report
   Wiebel A, 2012, IEEE T VIS COMPUT GR, V18, P2236, DOI 10.1109/TVCG.2012.292
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Zellmann S, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2012, VOL 2, PTS A AND B, P1385
   Zhao YH, 2020, PROC CVPR IEEE, P3327, DOI 10.1109/CVPR42600.2020.00339
NR 53
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3981
EP 3994
DI 10.1109/TVCG.2023.3245305
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700021
PM 37027532
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Gong, MJ
   Chen, XJ
AF Gong, Mingjun
   Chen, Xiaojun
TI 3D Surface-Closed Mesh Clipping Based on Polygonal Partitioning for
   Surgical Planning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surgery; Planning; Partitioning algorithms; Computational modeling;
   Three-dimensional displays; Software algorithms; Software; Model
   clipping; surgical planning; triangular mesh; partitioning
ID MAXILLOFACIAL SURGERY; TIME; SEGMENTATION; NAVIGATION; SIMULATION
AB How to create an efficient and accurate interactive tool for triangular mesh clipping is one of the key problems to be solved in computer-assisted surgical planning. Although the existing algorithms can realize three-dimensional model clipping, problems still remain unsolved regarding the flexibility of clipping paths and the capping of clipped cross-sections. In this study, we propose a mesh clipping algorithm for surgical planning based on polygonal convex partitioning. First, two-dimensional polygonal regions are extended to three-dimensional clipping paths generated from selected reference points. Second, the convex regions are partitioned with a recursive algorithm to obtain the clipped and residual models with closed surfaces. Finally, surgical planning software with the function of mesh clipping has been developed, which is capable to create complex clipping paths by normal vector adjustment and thickness control. The robustness and efficiency of our algorithm have been demonstrated by surgical planning of craniomaxillofacial osteotomy, pelvis tumor resection and cranial vault remodeling.
C1 [Gong, Mingjun] Shanghai Jiao Tong Univ, Sch Mech Engn, Inst Biomed Mfg & Life Qual Engn, Shanghai 200240, Peoples R China.
   [Chen, Xiaojun] Shanghai Jiao Tong Univ, Sch Mech Engn, Inst Med Robot, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Chen, XJ (corresponding author), Shanghai Jiao Tong Univ, Sch Mech Engn, Inst Med Robot, Shanghai 200240, Peoples R China.
EM 897774009@sjtu.edu.cn; xiaojunchen@sjtu.edu.cn
FU National Key R&D Program of China [2022YFE0197900]; National Natural
   Science Foundation of China [81971709, M-0019, 82011530141]; Foundation
   of Science and Technology Commission of Shanghai Municipality
   [20490740700]; Shanghai Jiao Tong University Foundation on Medical and
   Technological Joint Science Research [YG2019ZDA06, YG2021ZD21,
   YG2021QN72, YG2022QN056]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2022YFE0197900, in part by the National Natural Science
   Foundation of China under Grants 81971709, M-0019, and 82011530141, in
   part by the Foundation of Science and Technology Commission of Shanghai
   Municipality under Grant 20490740700, and in part by Shanghai Jiao Tong
   University Foundation on Medical and Technological Joint Science
   Research under Grants YG2019ZDA06, YG2021ZD21, YG2021QN72, and
   YG2022QN056.
CR Chahhou M, 2014, IEEE T PATTERN ANAL, V36, P1687, DOI 10.1109/TPAMI.2013.2297314
   CHAZELLE B, 1991, DISCRETE COMPUT GEOM, V6, P485, DOI 10.1007/BF02574703
   Chen XJ, 2016, EXPERT REV MED DEVIC, V13, P1043, DOI 10.1080/17434440.2016.1243054
   Chen ZX, 2021, J ORAL MAXIL SURG, V79, DOI 10.1016/j.joms.2020.09.005
   Eberly D., 2022, Triangulation by ear clipping
   Franz L, 2017, J ORAL MAXIL SURG, V75, P1971, DOI 10.1016/j.joms.2017.04.043
   García-Mato D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54148-4
   Greene D. H., 1983, Comput. Geometry, V1, P235
   Greiner G, 1998, ACM T GRAPHIC, V17, P71, DOI 10.1145/274363.274364
   Hammoudeh JA, 2015, PRS-GLOB OPEN, V3, DOI 10.1097/GOX.0000000000000184
   HERTEL S, 1983, LECT NOTES COMPUT SC, V158, P207
   Hu YX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323011
   Jiao X, 2018, J COMPUT APPL MATH, V329, P134, DOI 10.1016/j.cam.2017.05.007
   Le T, 2017, COMPUT GRAPH-UK, V66, P103, DOI 10.1016/j.cag.2017.05.011
   Li Z., 2020, Int. J. Adv. Robotic Syst., V17
   Mardini S, 2014, J PLAST RECONSTR AES, V67, P336, DOI 10.1016/j.bjps.2013.11.004
   Mehta VA, 2010, NEUROSURG FOCUS, V29, DOI 10.3171/2010.9.FOCUS10204
   Nilsson J, 2020, J CRANIO MAXILL SURG, V48, P132, DOI 10.1016/j.jcms.2019.11.024
   Pan JJ, 2015, COMPUT ANIMAT VIRT W, V26, P321, DOI 10.1002/cav.1655
   Paulus CJ, 2015, VISUAL COMPUT, V31, P831, DOI 10.1007/s00371-015-1123-x
   Phillips Bradley J, 2017, Bull Emerg Trauma, V5, P221, DOI 10.18869/acadpub.beat.5.4.499.
   Qin YG, 2019, ENERGY SCI ENG, V7, P1154, DOI 10.1002/ese3.335
   Shewchuk J.R., 1996, APPL COMPUTATIONAL G, P203, DOI DOI 10.1007/BFB0014497
   Simonson LJ, 2010, COMPUT AIDED DESIGN, V42, P1189, DOI 10.1016/j.cad.2010.06.008
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   SUTHERLAND IE, 1974, COMMUN ACM, V17, P32, DOI 10.1145/360767.360802
   Theologou P, 2015, COMPUT VIS IMAGE UND, V135, P49, DOI 10.1016/j.cviu.2014.12.008
   Tierny J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P215, DOI 10.1109/SMI.2007.38
   VATTI BR, 1992, COMMUN ACM, V35, P56, DOI 10.1145/129902.129906
   Vercruysse H, 2021, J CRANIO MAXILL SURG, V49, P341, DOI 10.1016/j.jcms.2021.01.011
   Wang CCL, 2011, IEEE T VIS COMPUT GR, V17, P836, DOI 10.1109/TVCG.2010.106
   Wang MN, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1923
   Weiler K., 1977, ACM SIGGRAPH COMPUTE, V11, P214, DOI DOI 10.1145/965141.563896
   Wong KC, 2015, COMPUT AIDED SURG, V20, P14, DOI 10.3109/10929088.2015.1076039
   Wong KC, 2016, INT J COMPUT ASS RAD, V11, P307, DOI 10.1007/s11548-015-1250-x
   Wu J, 2015, COMPUT GRAPH FORUM, V34, P161, DOI 10.1111/cgf.12528
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
   Zhan QQ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145987
   Zhang Y, 2020, IEEE T MED IMAGING, V39, P1511, DOI 10.1109/TMI.2019.2951838
   Zheng YY, 2012, IEEE T VIS COMPUT GR, V18, P1304, DOI 10.1109/TVCG.2011.140
NR 40
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3374
EP 3385
DI 10.1109/TVCG.2022.3230739
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700090
PM 37015426
DA 2024-08-05
ER

PT J
AU Zhang, W
   Kam-Kwai, W
   Chen, YT
   Jia, AL
   Wang, LW
   Zhang, JW
   Cheng, LC
   Qu, HM
   Chen, W
AF Zhang, Wei
   Kam-Kwai, Wong
   Chen, Yitian
   Jia, Ailing
   Wang, Luwei
   Zhang, Jian-Wei
   Cheng, Lechao
   Qu, Huamin
   Chen, Wei
TI ScrollTimes: Tracing the Provenance of Paintings as a Window Into
   History
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; digital humanities; painting analysis; traditional
   chinese painting
AB The study of cultural artifact provenance, tracing ownership and preservation, holds significant importance in archaeology and art history. Modern technology has advanced this field, yet challenges persist, including recognizing evidence from diverse sources, integrating sociocultural context, and enhancing interactive automation for comprehensive provenance analysis. In collaboration with art historians, we examined the handscroll, a traditional Chinese painting form that provides a rich source of historical data and a unique opportunity to explore history through cultural artifacts. We present a three-tiered methodology encompassing artifact, contextual, and provenance levels, designed to create a "Biography" for handscroll. Our approach incorporates the application of image processing techniques and language models to extract, validate, and augment elements within handscroll using various cultural heritage databases. To facilitate efficient analysis of non-contiguous extracted elements, we have developed a distinctive layout. Additionally, we introduce ScrollTimes, a visual analysis system tailored to support the three-tiered analysis of handscroll, allowing art historians to interactively create biographies tailored to their interests. Validated through case studies and expert interviews, our approach offers a window into history, fostering a holistic understanding of handscroll provenance and historical significance.
C1 [Zhang, Wei; Chen, Yitian; Jia, Ailing; Wang, Luwei; Zhang, Jian-Wei; Cheng, Lechao; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Kam-Kwai, Wong; Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong 999077, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Hong Kong University of Science & Technology;
   Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM zw_yixian@zju.edu.cn; kkwongar@connect.ust.hk; oscarchen@zju.edu.cn;
   jiaailing@zju.edu.cn; ppwlwpp@zju.edu.cn; zjw.cs@zju.edu.cn;
   liygcheng@zju.edu.cn; huamin@cse.ust.hk; chenvis@zju.edu.cn
OI Zhang, Jianwei/0000-0001-8358-6278; Chen, Wei/0000-0002-8365-4741; chen,
   yi tian/0009-0000-0590-594X; WONG, Kam Kwai/0000-0002-2813-1972; Cheng,
   Lechao/0000-0002-7546-9052
FU Fundamental Research Funds for the Central Universities
FX No Statement Available
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Beijing Erudition Digital Technology Research Center,, About us
   Benard Elisabeth., 2000, GODDESSES WHO RULE
   Boutsi AM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212508
   Burke Peter., 2001, Eyewitnessing: The Uses of Images as Historical Evidence
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Cheng F., 1994, Empty and Full: The Language of Chinese Painting
   Cheng M., 2018, Essential Terms of Chinese Painting, Kowloon Tong
   Chung Hae-Kyung, 2016, Journal of Ethnic Foods, V3, P42
   Damova M, 2011, ADV INTEL SOFT COMPU, V101, P17
   David L, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9659547
   Davis E, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3429458
   Davis K., 2019, Art Libraries J., V44, P162, DOI DOI 10.1017/ALJ.2019.24
   dila, Place Authority Database (PlaAD)
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Dragoni M, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3012289
   Dragoni M, 2016, LECT NOTES COMPUT SC, V9678, P724, DOI 10.1007/978-3-319-34129-3_44
   Fan ZB, 2019, LEONARDO, V52, P111, DOI [10.1162/leon_a_01409, 10.1162/LEON_a_01409]
   Feigenbaum Gail., 2012, PROVENANCE ALTERNATE
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P295, DOI 10.1109/TVCG.2023.3327168
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P3813, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Feng YCJ, 2022, J VISUAL-JAPAN, V25, P671, DOI 10.1007/s12650-021-00780-0
   Fong WC, 2003, ART BULL, V85, P258, DOI 10.2307/3177344
   García-Zarza P, 2022, LECT NOTES COMPUT SC, V13450, P441, DOI 10.1007/978-3-031-16290-9_34
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Grill J.B., 2020, P 34 INT C NEUR INF, V33, P21271, DOI [10.48550/arXiv.2006.07733, DOI 10.48550/ARXIV.2006.07733]
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Haskell F., 1993, Hist. and its Images: Art and the Interpretation of the Past, DOI [10.5860/choice.31-1330, DOI 10.5860/CHOICE.31-1330]
   He H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091015
   He JB, 2024, IEEE T VIS COMPUT GR, V30, P87, DOI 10.1109/TVCG.2023.3326586
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh CK, 2013, IEEE COMPUT GRAPH, V33, P16, DOI 10.1109/MCG.2013.50
   Hung CC, 2018, ELECTRON LIBR, V36, P172, DOI 10.1108/EL-10-2016-0219
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jiang W, 2021, COGN COMPUT, V13, P1287, DOI 10.1007/s12559-021-09896-9
   Jiang W, 2019, NEUROCOMPUTING, V330, P280, DOI 10.1016/j.neucom.2018.11.003
   Jin S, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382934
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Krystalakos O, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3201011
   Kusnick J., 2021, Report on Narrative Visualization Techniques for OPDB Data. Deliverable within the H2020 Project InTaVia
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Lengyel A., 2000, China Rev. Int., V7, P260, DOI [DOI 10.1353/CRI.2000.0035, 10.1353/cri.2000.0035]
   Li JC, 2024, IEEE T VIS COMPUT GR, V30, P3022, DOI 10.1109/TVCG.2024.3388525
   Li M, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2021.12.006
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Liong ST, 2020, COMPUT INTELL-US, V36, P1183, DOI 10.1111/coin.12328
   Liu C, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P641, DOI 10.1109/ICSPCC.2014.6986272
   mappingpublichousing, ABOUT US
   Mayr E, 2022, 2022 IEEE 7TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH), P13, DOI 10.1109/VIS4DH57440.2022.00008
   Mohammad SM, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1225
   N. P. Museum, National palace museum open data
   Newman GE, 2011, J CONSUM RES, V38, P215, DOI 10.1086/658999
   Nishanbaev I, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10100684
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Person Authority Database (PerAD), About us
   Rodriguez-Gonzálvez P, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8020061
   Rodriguez-Gonzálvez P, 2017, INT ARCH PHOTOGRAMM, V42-2, P609, DOI 10.5194/isprs-archives-XLII-2-W3-609-2017
   Roth Kathe., 2002, Japan Encyclopedia
   Rowland D., 1997, The Intellectual Background of the Sch. of Athens: Tracking Divine Wisdom in the Rome of Julius II
   Ruiz-Calleja A, 2023, SEMANT WEB, V14, P181, DOI 10.3233/SW-212907
   sammlung, About us
   Shirato G, 2023, VIS INFORM, V7, P77, DOI 10.1016/j.visinf.2023.01.001
   Siren Osvald., 1963, CHINESE ART PAINTING, VSB57
   Tadalafil, ABOUT US
   Tang F, 2018, IEEE T VIS COMPUT GR, V24, P3019, DOI 10.1109/TVCG.2017.2774292
   Tang T., P 36 ANN ACM S US IN
   Tong W, 2023, Symposium Virtual Re, P387, DOI 10.1109/VR55154.2023.00054
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   Wang R, 2021, INT C PATT RECOG, P3077, DOI 10.1109/ICPR48806.2021.9413063
   Wang XY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1800
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Wong KK, 2024, IEEE T VIS COMPUT GR, V30, P4008, DOI 10.1109/TVCG.2023.3245609
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Ye Shuainan, 2023, IEEE Trans Vis Comput Graph, V29, P429, DOI 10.1109/TVCG.2022.3209388
   Zhang FQ, 2020, IEEE ACCESS, V8, P132002, DOI 10.1109/ACCESS.2020.3009470
   Zhang KJ, 2022, FRONT INFORM TECH EL, V23, P1479, DOI 10.1631/FITEE.2100094
   Zhang W, 2023, Arxiv, DOI arXiv:2307.14227
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhang W, 2023, IEEE T VIS COMPUT GR, V29, P3009, DOI 10.1109/TVCG.2022.3146508
   Zhenhao Dong, 2020, 2020 International Conference on Culture-oriented Science & Technology (ICCST), P383, DOI 10.1109/ICCST50977.2020.00080
   zjlib, Chinese Historical Figures Seal Data (CHFSD)
NR 82
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2981
EP 2994
DI 10.1109/TVCG.2024.3388523
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500015
PM 38625782
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Pan, Y
   Tan, S
   Cheng, SR
   Lin, QF
   Zeng, ZJ
   Mitchell, K
AF Pan, Ye
   Tan, Shuai
   Cheng, Shengran
   Lin, Qunfen
   Zeng, Zijiao
   Mitchell, Kenny
TI Expressive Talking Avatars
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human computer interaction (HCI); HCI design and evaluation methods;
   User studies; Computer graphics; Graphics systems and interfaces;
   Virtual reality; Human-centered computing
AB Stylized avatars are common virtual representations used in VR to support interaction and communication between remote collaborators. However, explicit expressions are notoriously difficult to create, mainly because most current methods rely on geometric markers and features modeled for human faces, not stylized avatar faces. To cope with the challenge of emotional and expressive generating talking avatars, we build the Emotional Talking Avatar Dataset which is a talking-face video corpus featuring 6 different stylized characters talking with 7 different emotions. Together with the dataset, we also release an emotional talking avatar generation method which enables the manipulation of emotion. We validated the effectiveness of our dataset and our method in generating audio based puppetry examples, including comparisons to state-of-the-art techniques and a user study. Finally, various applications of this method are discussed in the context of animating avatars in VR.
C1 [Pan, Ye; Tan, Shuai; Cheng, Shengran] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Lin, Qunfen; Zeng, Zijiao] Tencent Games, Shenzhen, Peoples R China.
   [Mitchell, Kenny] Edinburgh Napier Univ, Edinburgh, Scotland.
C3 Shanghai Jiao Tong University; Edinburgh Napier University
RP Pan, Y (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM whitneypanye@sjtu.edu.cn; tanshuai0219@sjtu.edu.cn;
   SR-Cheng@sjtu.edu.cn; volleylin@tencent.com; zijiaozeng@tencent.com;
   k.mitchell2@napier.ac.uk
RI Mitchell, Kenny/AAZ-3421-2020
OI Mitchell, Kenny/0000-0003-2420-7447; Cheng,
   Shengran/0000-0003-4044-0185; Tan, Shuai/0000-0003-3322-5161
FU National Natural Science Foundation of China
FX No Statement Available
CR Aneja D, 2018, IEEE WINT CONF APPL, P160, DOI 10.1109/WACV.2018.00024
   Aneja D, 2017, LECT NOTES COMPUT SC, V10112, P136, DOI 10.1007/978-3-319-54184-6_9
   Bao L., 2023, arXiv
   Berndt D.J., 1994, P 3 INT C KNOWL DISC
   Brito C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P864, DOI [10.1109/VR.2019.8798303, 10.1109/vr.2019.8798303]
   Chen Q, 2023, Arxiv, DOI arXiv:2303.05322
   Cuturi M, 2017, PR MACH LEARN RES, V70
   Danieau F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P784, DOI [10.1109/VR.2019.8798208, 10.1109/vr.2019.8798208]
   Du CP, 2021, INTERSPEECH, P3136, DOI 10.21437/Interspeech.2021-802
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Faigin G., 2012, The artist's complete guide to facial expression
   Gururani S., 2023, P IEEE CVF INT C COM, P20914
   Hsu WN, 2021, IEEE-ACM T AUDIO SPE, V29, P3451, DOI 10.1109/TASLP.2021.3122291
   Ji X., 2022, ACM SIGGRAPH 2022 C, P1
   Ji XY, 2021, PROC CVPR IEEE, P14075, DOI 10.1109/CVPR46437.2021.01386
   Kaisiyuan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P700, DOI 10.1007/978-3-030-58589-1_42
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Lewis JP, 2014, Eurographics (State of the Art Reports), V1, P2, DOI [DOI 10.2312/EGST.20141042, 10.2312/egst.20141042]
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462019
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Logan B., 2000, ISMIR
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Malleson C, 2017, P IEEE VIRT REAL ANN, P447, DOI 10.1109/VR.2017.7892372
   Pan Y., 2023, P 31 ACM INT C MULT
   Pan Y, 2023, IEEE T VIS COMPUT GR, V29, P2527, DOI 10.1109/TVCG.2023.3247101
   Pan YF, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555408
   Ren Y., 2020, INT C LEARN REPR
   Richard A, 2021, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV48630.2021.00009
   Richard A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1153, DOI 10.1109/ICCV48922.2021.00121
   Sakoe H., 1971, 1971 P INT C AC BUD
   Tan S., 2023, P IEEECVF INT C COMP, P22146
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Taylor Sarah L, 2012, P ACM SIGGRAPHEUROGR, P275, DOI DOI 10.2312/SCA/SCA12/275-284
   Wu HZ, 2023, Arxiv, DOI arXiv:2308.05428
   Ye Z., 2023, arXiv
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/vr.2019.8797719, 10.1109/VR.2019.8797719]
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
NR 41
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2538
EP 2548
DI 10.1109/TVCG.2024.3372047
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400063
PM 38437076
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Tian, F
   Ni, ST
   Zhang, XY
   Chen, F
   Zhu, QL
   Xu, CY
   Li, YZ
AF Tian, Feng
   Ni, Shuting
   Zhang, Xiaoyue
   Chen, Fei
   Zhu, Qiaolian
   Xu, Chunyi
   Li, Yuzhi
TI Enhancing Tai Chi Training System: Towards Group-Based and
   Hyper-Realistic Training Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; social experience; action guidance trajectories; hand
   movement trajectories analysis; hyper-realistic
AB In this article, we propose a lightweight and flexible enhanced Tai Chi training system composed of multiple standalone virtual reality (VR) devices. The system aims to enable a hyper-realistic multi-user action training platform at low cost by displaying real-time action guidance trajectories, providing real-world impossible visual effects and functions, and rapidly enhancing movement precision and communication interest for learners. We objectively evaluate participants' action quality at different levels of immersion, including traditional coach guidance (TCG), VR, and mixed reality (MR), along with subjective measures like motion sickness, quality of interaction, social meaning, presence/immersion to comprehensively explore the system's feasibility. The results indicate VR performs the best in training accuracy, but MR provides superior social experience and relatively high accuracy. Unlike TCG, MR offers hyper-realistic hand movement trajectories and Tai Chi social references. Compared with VR, MR provides more realistic avatar companions and a safer environment. In summary, MR balances accuracy and social experience.
C1 [Tian, Feng; Ni, Shuting; Zhang, Xiaoyue; Chen, Fei; Zhu, Qiaolian; Xu, Chunyi; Li, Yuzhi] Shanghai Univ, Shanghai, Peoples R China.
C3 Shanghai University
RP Tian, F (corresponding author), Shanghai Univ, Shanghai, Peoples R China.
EM ouman@shu.edu.cn; shangkenst@shu.edu.cn; zxy0716@shu.edu.cn;
   buer2001@shu.edu.cn; gjky@shu.edu.cn; xcy2008@shu.edu.cn;
   shadowmcv@shu.edu.cn
OI Li, Yuzhi/0009-0009-7050-7775
FU Shanghai University Interdisciplinary Joint Project
FX No Statement Available
CR [Anonymous], 2020, IN2020 IEEE C VIRTUA, P858, DOI [10.1109/VRW50115.2020.002821,2,3[39]W.-L, DOI 10.1109/VRW50115.2020.002821,2,3[39]W.-L]
   Tsai WL, 2022, IEEE T VIS COMPUT GR, V28, P2970, DOI 10.1109/TVCG.2020.3046326
   Wang MJ, 2022, IEEE T LEARN TECHNOL, V15, P685, DOI 10.1109/TLT.2022.3210828
   Weidner F, 2023, IEEE T VIS COMPUT GR, V29, P2596, DOI 10.1109/TVCG.2023.3247072
   Weissker T, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P719, DOI 10.1109/VRW55335.2022.00215
   Winkler A, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555411
   Zeng YQ, 2021, 2021 IEEE 7TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2021), P240, DOI 10.1109/ICVR51878.2021.9483700
   Zhao CJ, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2446413
NR 8
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2713
EP 2723
DI 10.1109/TVCG.2024.3372099
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400068
PM 38457324
DA 2024-08-05
ER

PT J
AU Sisouk, K
   Delon, J
   Tierny, J
AF Sisouk, Keanu
   Delon, Julie
   Tierny, Julien
TI Wasserstein Dictionaries of Persistence Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ensemble data; persistence diagrams; topological data analysis
ID NONPARAMETRIC MODELS; MORSE COMPLEXES; VISUAL ANALYSIS; CRITICAL-POINTS;
   REEB GRAPHS; UNCERTAINTY; VISUALIZATION; TOPOLOGY; VARIABILITY;
   INTERPOLATION
AB This article presents a computational framework for the concise encoding of an ensemble of persistence diagrams, in the form of weighted Wasserstein barycenters Turner et al. (2014), Vidal et al. (2020) of a dictionary of atom diagrams. We introduce a multi-scale gradient descent approach for the efficient resolution of the corresponding minimization problem, which interleaves the optimization of the barycenter weights with the optimization of the atom diagrams. Our approach leverages the analytic expressions for the gradient of both sub-problems to ensure fast iterations and it additionally exploits shared-memory parallelism. Extensive experiments on public ensembles demonstrate the efficiency of our approach, with Wasserstein dictionary computations in the orders of minutes for the largest examples. We show the utility of our contributions in two applications. First, we apply Wassserstein dictionaries to data reduction and reliably compress persistence diagrams by concisely representing them with their weights in the dictionary. Second, we present a dimensionality reduction framework based on a Wasserstein dictionary defined with a small number of atoms (typically three) and encode the dictionary as a low dimensional simplex embedded in a visual space (typically in 2D). In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used to reproduce our results.
C1 [Sisouk, Keanu; Tierny, Julien] Sorbonne Univ, F-75005 Paris, France.
   [Delon, Julie] Univ Paris Cite, F-75006 Paris, France.
C3 Sorbonne Universite; Universite Paris Cite
RP Sisouk, K (corresponding author), Sorbonne Univ, F-75005 Paris, France.
EM Keanu.Sisouk@lip6.fr; julie.delon@u-paris.fr;
   julien.tierny@sorbonneuniversite.fr
RI Delon, Julie/U-5964-2017
OI Delon, Julie/0000-0002-7182-7537
FU European Commission
FX No Statement Available
CR Acharya A, 2015, IEEE PAC VIS SYMP, P271, DOI 10.1109/PACIFICVIS.2015.7156387
   Anderson KL, 2018, LECT NOTES COMPUT SC, V11083, P67, DOI 10.1007/978-3-030-00755-3_8
   Athawale T. M., 2019, arXiv
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Ayachit U., 2015, P 1 WORKSHOP IN SITU, DOI [DOI 10.1145/2828612.2828624, 10.1145/2828612.2828624]
   BERTSEKAS DP, 1981, MATH PROGRAM, V21, P152, DOI 10.1007/BF01584237
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Bhatia H, 2012, IEEE T VIS COMPUT GR, V18, P1383, DOI 10.1109/TVCG.2011.265
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bin Masood T., 2019, P TOP METH DAT AN VI, P327
   Bock A, 2018, IEEE T VIS COMPUT GR, V24, P812, DOI 10.1109/TVCG.2017.2743980
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P139, DOI 10.1109/VISUAL.2003.1250365
   Brown N, 2021, PROCEEDINGS OF URGENTHPC 2021: THE THIRD INTERNATIONAL WORKSHOP ON HPC FOR URGENT DECISION MAKING, P36, DOI 10.1109/UrgentHPC54802.2021.00010
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P918
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cohen-Steiner D, 2010, FOUND COMPUT MATH, V10, P127, DOI 10.1007/s10208-010-9060-6
   Cuturi M., 2013, Ad-vances in Neural Information Processing Systems, V26, P1
   Cuturi M, 2014, PR MACH LEARN RES, V32, P685
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Diggle PJ, 2002, Analysis of Longitudinal Data, V2nd
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P249, DOI 10.1109/TVCG.2012.115
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Edelsbrunner H., 2009, Computational Topology: An Introduction
   Edelsbrunner H., 2003, P 19 ANN S COMP GEOM, P361, DOI [10.1145/777792.777846, DOI 10.1145/777792.777846]
   Favelier G., 2016, P IEEE SCIVIS CONT
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Forman R., 1998, AM
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Gueunet C., 2019, P EUR S PAR GRAPH VI
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Guillou P., 2023, IEEE Trans. Vis. Comput. Graph.
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2016, IEEE T VIS COMPUT GR, V22, P916, DOI 10.1109/TVCG.2015.2467432
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   ISO/IEC, 2008, 983200 ISOIEC
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Kantorovitch L, 1942, CR ACAD SCI URSS, V37, P199
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Kerber M., 2017, ACM J. Exp. Algorithmics, V22
   Kraus M, 2010, IMAGAPP & IVAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS, P132
   Kruskal J. B., 1978, SUPS
   Lacombe T., 2018, Advances in Neural Information Processing Systems
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Liebmann T, 2016, COMPUT GRAPH FORUM, V35, P361, DOI 10.1111/cgf.12912
   Maadasamy S, 2012, INT C HIGH PERFORM
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI DOI 10.1559/1523040054738936
   Maljovec D, 2016, IEEE PAC VIS SYMP, P64, DOI 10.1109/PACIFICVIS.2016.7465252
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Monge G., 1781, Academie Royale des Sci. de Paris
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nauleau F., 2022, P IEEE S LARG DAT AN, P1
   Olejniczak M, 2023, PHYS CHEM CHEM PHYS, V25, P5942, DOI 10.1039/d2cp05893f
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Organizers, 2004, The IEEE SciVis Contest
   Otto M., 2010, CGF, V31, P1045
   Otto M, 2011, IEEE PAC VIS SYMP, P67, DOI 10.1109/PACIFICVIS.2011.5742374
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Parsa S, 2012, P 28 ANN S COMP GEOM, P269
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239509, 10.1145/1276377.1276449]
   Petz C, 2012, COMPUT GRAPH FORUM, V31, P1045, DOI 10.1111/j.1467-8659.2012.03097.x
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Pfaffelmoser T, 2012, COMPUT GRAPH FORUM, V31, P1025, DOI 10.1111/j.1467-8659.2012.03095.x
   Pfaffelmoser T, 2011, COMPUT GRAPH FORUM, V30, P951, DOI 10.1111/j.1467-8659.2011.01944.x
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Pöthkow K, 2011, IEEE T VIS COMPUT GR, V17, P1393, DOI 10.1109/TVCG.2010.247
   Pont M, 2023, IEEE T VIS COMPUT GR, V29, P1573, DOI 10.1109/TVCG.2022.3215001
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Potter K, 2013, IEEE COMPUT GRAPH, V33, P75, DOI 10.1109/MCG.2013.14
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Schlegel S, 2012, IEEE T VIS COMPUT GR, V18, P2305, DOI 10.1109/TVCG.2012.249
   Schmitz MA, 2018, SIAM J IMAGING SCI, V11, P643, DOI 10.1137/17M1140431
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   SINKHORN R, 1967, AM MATH MON, V74, P402, DOI 10.2307/2314570
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Szymczak A, 2013, IEEE T VIS COMPUT GR, V19, P799, DOI 10.1109/TVCG.2012.147
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Turner Y., 2014, DCG
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Wang B, 2023, IEEE TOPOINVIS
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Woodruff DP, 2014, FOUND TRENDS THEOR C, V10, P1, DOI 10.1561/0400000060
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
NR 105
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1638
EP 1651
DI 10.1109/TVCG.2023.3330262
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300013
PM 37930922
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, CL
   Thompson, J
   Lee, B
AF Wang, Chenglong
   Thompson, John
   Lee, Bongshin
TI Data Formulator: AI-Powered Concept-Driven Visualization Authoring
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Temperature distribution; Urban areas;
   Visualization; Transforms; Histograms; Libraries; AI; visualization
   authoring; data transformation; programming by example; natural
   language; large language model
ID DESIGN; LYRA
AB With most modern visualization tools, authors need to transform their data into tidy formats to create visualizations they want. Because this requires experience with programming or separate data processing tools, data transformation remains a barrier in visualization authoring. To address this challenge, we present a new visualization paradigm, concept binding, that separates high-level visualization intents and low-level data transformation steps, leveraging an AI agent. We realize this paradigm in Data Formulator, an interactive visualization authoring tool. With Data Formulator, authors first define data concepts they plan to visualize using natural languages or examples, and then bind them to visual channels. Data Formulator then dispatches its AI-agent to automatically transform the input data to surface these concepts and generate desired visualizations. When presenting the results (transformed table and output visualizations) from the AI agent, Data Formulator provides feedback to help authors inspect and understand them. A user study with 10 participants shows that participants could learn and use Data Formulator to create visualizations that involve challenging data transformations, and presents interesting future research directions.
C1 [Wang, Chenglong; Thompson, John; Lee, Bongshin] Microsoft Res, Redmond, WA 98052 USA.
C3 Microsoft
RP Wang, CL (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM chenglong.wang@microsoft.com; johnthompson@microsoft.com;
   bongshin@microsoft.com
CR Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030
   Barman S, 2016, ACM SIGPLAN NOTICES, V51, P748, DOI 10.1145/3022671.2984020
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Chaudhuri S, 2021, FOUND TRENDS PROGRAM, V7, P158, DOI 10.1561/2500000049
   Chen M., CoRR
   Chen QC, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3563307
   Chowdhery A, 2022, Arxiv, DOI arXiv:2204.02311
   Fried D, 2023, Arxiv, DOI [arXiv:2204.05999, 10.48550/ARXIV.2204.05999]
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010
   Hendrycks D., 2021, P NEURAL INFORM PROC
   Ji RY, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P1143, DOI 10.1145/3385412.3386025
   Jin ZJ, 2020, PROC VLDB ENDOW, V13, P2368, DOI 10.14778/3407790.3407831
   Jin ZJ, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P683, DOI 10.1145/3035918.3064034
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kery Mary Beth, 2020, UIST, P140
   Kim D. H., CHI 20
   Lai Yuhang, 2022, arXiv
   Lee DJL, 2022, IEEE T VIS COMPUT GR, V28, P4225, DOI 10.1109/TVCG.2021.3085751
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Li TJJ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P577, DOI 10.1145/3332165.3347899
   Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Ouyang Long, 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI 10.1177/01454455830072006
   Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470
   Poesia G., 2022, 10 INT C LEARNING RE
   Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2814270.2814310, 10.1145/2858965.2814310]
   Pu K, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545691
   Raman V., 2001, VLDB 2001 P 27 INT C, P9
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159
   Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400
   Stolte C., 2002, P 8 ACM SIGKDD INT C, P112, DOI [DOI 10.1145/775047.775064, 10.1145/775047.7750648, DOI 10.1145/775047.7750648]
   T. pandas development team, 2023, pandas-dev/pandas: Pandas, DOI [10.5281/zenodo.77415801,9, DOI 10.5281/ZENODO.77415801,9]
   Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476
   VanderPlas J., 2018, J OPEN SOURCE SOFTW, V3, P1057, DOI [DOI 10.21105/JOSS.01057, 10.21105/joss.01057]
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wang CL, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3371117
   Wang CL, 2017, ACM SIGPLAN NOTICES, V52, P452, DOI [10.1145/3140587.3062365, 10.1145/3062341.3062365]
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wickham Hadley, 2024, CRAN
   Wilkinson L., 2005, The Grammar of Graphics, Second Edition. Statistics and computing, VSecond, P8
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xiong Kai, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209470
   Yan C, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1539, DOI 10.1145/3318464.3389738
   Zhang T., 2021, CHI 21 CHI C HUMAN F, P1
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 63
TC 0
Z9 0
U1 6
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1128
EP 1138
DI 10.1109/TVCG.2023.3326585
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500081
PM 37871079
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Filipov, V
   Arleo, A
   Bogl, M
   Miksch, S
AF Filipov, Velitchko
   Arleo, Alessio
   Bogl, Markus
   Miksch, Silvia
TI On Network Structural and Temporal Encodings: A Space and Time Odyssey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Encoding; Animation; Layout; Visualization; Time factors;
   Topology; Human-centered computing-visualization-graph drawings;
   empirical studies in visualization
ID NODE-LINK; GRAPH; VISUALIZATION; VIOLATIONS
AB The dynamic network visualization design space consists of two major dimensions: network structural and temporal representation. As more techniques are developed and published, a clear need for evaluation and experimental comparisons between them emerges. Most studies explore the temporal dimension and diverse interaction techniques supporting the participants, focusing on a single structural representation. Empirical evidence about performance and preference for different visualization approaches is scattered over different studies, experimental settings, and tasks. This paper aims to comprehensively investigate the dynamic network visualization design space in two evaluations. First, a controlled study assessing participants' response times, accuracy, and preferences for different combinations of network structural and temporal representations on typical dynamic network exploration tasks, with and without the support of standard interaction methods. Second, the best-performing combinations from the first study are enhanced based on participants' feedback and evaluated in a heuristic-based qualitative study with visualization experts on a real-world network. Our results highlight node-link with animation and playback controls as the best-performing combination and the most preferred based on ratings. Matrices achieve similar performance to node-link in the first study but have considerably lower scores in our second evaluation. Similarly, juxtaposition exhibits evident scalability issues in more realistic analysis contexts.
C1 [Filipov, Velitchko] TU Wien, Ctr Visual Analyt Sci & Technol CVAST, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Filipov, V (corresponding author), TU Wien, Ctr Visual Analyt Sci & Technol CVAST, A-1040 Vienna, Austria.
EM velitchko.filipov@tuwien.ac.at; alessio.arleo@tuwien.ac.at;
   markus.boegl@tuwien.ac.at; silvia.miksch@tuwien.ac.at
RI Arleo, Alessio/IRZ-8036-2023
OI Arleo, Alessio/0000-0003-2008-3651; Filipov,
   Velitchko/0000-0001-9592-2179; Bogl, Markus/0000-0002-8337-4774; Miksch,
   Silvia/0000-0003-4427-5703
FU ArtVis [P35767]
FX No Statement Available
CR Abdelaal Moataz, 2023, IEEE Trans Vis Comput Graph, V29, P896, DOI 10.1109/TVCG.2022.3209427
   Ahn JW, 2014, IEEE T VIS COMPUT GR, V20, P365, DOI 10.1109/TVCG.2013.238
   Aigner W., 2023, Visualization of Time-Oriented Data, Vsecond, DOI 10/mf9f
   Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47
   angusespana, About us
   [Anonymous], 2013, Statistik: Fur Sozialwissenschaftler
   [Anonymous], About us
   Archambault Daniel, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P475, DOI 10.1007/978-3-642-36763-2_42
   Archambault D, 2016, INFORM SCIENCES, V330, P495, DOI 10.1016/j.ins.2015.04.017
   Archambault D, 2013, INT J HUM-COMPUT ST, V71, P1044, DOI 10.1016/j.ijhcs.2013.08.004
   Archambault D, 2011, IEEE T VIS COMPUT GR, V17, P539, DOI 10.1109/TVCG.2010.78
   Arleo A., 2022, Computer Graphics Forum
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Backhaus K., 2015, Fortgeschrittene Multivariate Analysemethoden. Eine anwendungsorientierte Einfuhrung (3.
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361, DOI DOI 10.1609/ICWSM.V3I1.13937
   Baur M, 2002, LECT NOTES COMPUT SC, V2265, P463
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Bennett Chris, 2007, PROC CAE, DOI [10.2312/COMPAESTH/COMPAESTH07/057-064, 10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   Bollobás B, 2003, SIAM PROC S, P132
   BONEAU CA, 1960, PSYCHOL BULL, V57, P49, DOI 10.1037/h0041412
   Bonferroni C. E., 1936, Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commerciali di Firenze, V8, P3, DOI DOI 10.4135/9781412961288.N455
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Brandes U., 2003, Information Visualization, V2, P40, DOI 10.1057/palgrave.ivs.9500037
   Brandes U, 2012, LECT NOTES COMPUT SC, V7034, P99
   cc.gatech, Citevis citation datafile
   Collberg C., 2003, Proceedings of the 2003 ACM symposium on Software visualization-SoftVis '03, P77
   Crnovrsanin T., 2017, J. Graph Algorithms Appl., V21, P55
   d3js, About us
   Di Giacomo E, 2024, IEEE T VIS COMPUT GR, V30, P3503, DOI 10.1109/TVCG.2022.3233389
   Diehl S., 2002, Graph Drawing, P23, DOI 10.1007/3-540-36151-03
   Erten C, 2004, PROC SPIE, V5295, P45, DOI 10.1117/12.539245
   Erten C, 2004, LECT NOTES COMPUT SC, V2912, P98
   Fekete J.-D., 2015, P IEEE VIS
   Filipov V, 2022, Arxiv, DOI arXiv:2208.13716
   Filipov V, 2021, IEEE PAC VIS SYMP, P131, DOI 10.1109/PacificVis52677.2021.00025
   Garnier S., 2021, viridis-Colorblind-friendly color maps for R R package version 0.6.2, V1
   Ghani S, 2012, COMPUT GRAPH FORUM, V31, P1205, DOI 10.1111/j.1467-8659.2012.03113.x
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hadlak S., 2015, P EUR C VIS, P1
   Hagberg A., 2020, NETWORKX NETWORK ANA
   Hagberg A. A., 2008, EXPLORING NETWORK ST, P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Hedderich J., 2016, ANGEW STAT, DOI DOI 10.1007/978-3-662-05744-5
   Henry N, 2007, LECT NOTES COMPUT SC, V4663, P288
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kerracher N., 2014, P EUR C VIS
   Linhares C. D., 2017, P S APPL COMP SAC 17, P187, DOI [10.1145/3019612.3019686, DOI 10.1145/3019612.3019686]
   Linhares CDG, 2021, J VISUAL-JAPAN, V24, P1011, DOI 10.1007/s12650-021-00759-x
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Okoe Mershack, 2018, Graph Drawing and Network Visualization. 25th International Symposium, GD 2017. Revised Selected Papers: LNCS 10692, P287, DOI 10.1007/978-3-319-73915-1_23
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Posten H.O., 1984, Robustness of the TwoSample T-Test, P92, DOI [DOI 10.1007/978-94-009-6528-736, 10.1007/978-94-009-6528-723, DOI 10.1007/978-94-009-6528-723, 10.1007/978-94-009-6528-7_23, DOI 10.1007/978-94-009-6528-7_23]
   Purchase H. C., 2002, Empirical Software Engineering, V7, P233, DOI 10.1023/A:1016344215610
   Purchase H. C., 2006, Graph Drawing. 14th International Symposium, GD 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4372), P184
   Purchase HC, 1998, OZCHI 98 - 1998 AUSTRALASIAN COMPUTER HUMAN INTERACTION CONFERENCE, PROCEEDINGS, P80, DOI 10.1109/OZCHI.1998.732199
   Ren D, 2019, NETW SCI, V7, P242, DOI 10.1017/nws.2019.6
   ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267
   Rufiange S, 2014, 2014 SECOND IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P137, DOI 10.1109/VISSOFT.2014.30
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Simonetto P, 2020, IEEE T VIS COMPUT GR, V26, P2373, DOI 10.1109/TVCG.2018.2886901
   surveyjs, SurveyJS-Survey and form JavaScript libraries
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743
   Vallat R, 2018, J. Open Source Softw, V3, P1026, DOI DOI 10.21105/JOSS.01026
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Weiss C., 2005, Basiswissen Medizinische Statistik, V4
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
NR 75
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5847
EP 5860
DI 10.1109/TVCG.2023.3310019
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400064
PM 37647194
OA hybrid
DA 2024-08-05
ER

PT J
AU Li, J
   Kang, D
   Pei, WJ
   Zhe, X
   Zhang, Y
   Bao, LC
   He, ZY
AF Li, Jing
   Kang, Di
   Pei, Wenjie
   Zhe, Xuefei
   Zhang, Ying
   Bao, Linchao
   He, Zhenyu
TI Audio2Gestures: Generating Diverse Gestures From Audio
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Codes; Training; Three-dimensional displays; Dynamics; Decoding; Image
   reconstruction; Hidden Markov models; Cross-model generation; gesture;
   motion generation
ID SCALE
AB People may perform diverse gestures affected by various mental and physical factors when speaking the same sentences. This inherent one-to-many relationship makes co-speech gesture generation from audio particularly challenging. Conventional CNNs/RNNs assume one-to-one mapping, and thus tend to predict the average of all possible target motions, easily resulting in plain/boring motions during inference. So we propose to explicitly model the one-to-many audio-to-motion mapping by splitting the cross-modal latent code into shared code and motion-specific code. The shared code is expected to be responsible for the motion component that is more correlated to the audio while the motion-specific code is expected to capture diverse motion information that is more independent of the audio. However, splitting the latent code into two parts poses extra training difficulties. Several crucial training losses/strategies, including relaxed motion loss, bicycle constraint, and diversity loss, are designed to better train the VAE. Experiments on both 3D and 2D motion datasets verify that our method generates more realistic and diverse motions than previous state-of-the-art methods, quantitatively and qualitatively. Besides, our formulation is compatible with discrete cosine transformation (DCT) modeling and other popular backbones (i.e., RNN, Transformer). As for motion losses and quantitative motion evaluation, we find structured losses/metrics (e.g. STFT) that consider temporal and/or spatial context complement the most commonly used point-wise losses (e.g. PCK), resulting in better motion dynamics and more nuanced motion details. Finally, we demonstrate that our method can be readily used to generate motion sequences with user-specified motion clips on the timeline.
C1 [Li, Jing; He, Zhenyu] Harbin Inst Technol, Shenzhen 518055, Peoples R China.
   [Kang, Di; Bao, Linchao] Tencent AI Lab, Shenzhen 518055, Peoples R China.
C3 Harbin Institute of Technology; Tencent
RP He, ZY (corresponding author), Harbin Inst Technol, Shenzhen 518055, Peoples R China.; Bao, LC (corresponding author), Tencent AI Lab, Shenzhen 518055, Peoples R China.
EM lijing@stu.hit.edu.cn; dkang@tencent.com; wenjiecoder@outlook.com;
   zhexuefei@outlook.com; yinggzhang@tencent.com; linchaobao@gmail.com;
   zhenyuhe@hit.edu.cn
OI li, jing/0000-0002-2162-1004; Bao, Linchao/0000-0001-9543-3754
FU National Natural Science Foundation of China [62172126, U2013210,
   62006060]; Shenzhen Fundamental Research Program
   [JCYJ20220818102415032]; Shenzhen Research Council
   [JCYJ20210324120202006]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62172126, in part by the National
   Natural Science Foundation of China under Grants U2013210, 62006060, in
   part by Shenzhen Fundamental Research Program under Grant
   JCYJ20220818102415032, and in part by Shenzhen Research Council under
   Grant JCYJ20210324120202006.
CR Agarap A.F., 2018, arXiv, DOI 10.48550/arXiv.1803.08375
   Alexanderson S., 2022, arXiv
   Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Ao TL, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555435
   Bai SJ, 2018, Arxiv, DOI [arXiv:1803.01271, DOI 10.48550/ARXIV.1803.01271]
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen X, 2016, ADV NEUR IN, V29
   Cho K., 2014, ARXIV14061078, V1406, P1078, DOI DOI 10.3115/V1/D14-1179
   Defossez Alexandre, 2020, arXiv
   Doersch C, 2021, Arxiv, DOI arXiv:1606.05908
   Donahue J., 2016, Adversarial feature learning
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Ferstl Ylva., 2019, P 12 ACM SIGGRAPH C
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guo CA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2021, DOI 10.1145/3394171.3413635
   Habibie I., 2022, P SPEC INT GROUP COM, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Heusel M., 2017, NeurIPS, P6629
   Huang R., 2021, P INT C LEARN REPR
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kingma D. P., 2014, arXiv
   Kingma DP, 2018, ADV NEUR IN, V31
   Kobyzev I, 2021, IEEE T PATTERN ANAL, V43, P3964, DOI 10.1109/TPAMI.2020.2992934
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kucherenko T, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P11, DOI 10.1145/3397481.3450692
   Larsen A. B. L., 2016, ARXIV151209300, P1558, DOI DOI 10.3390/RS12223815
   Levine S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778861
   Levine S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618518
   Li J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11273, DOI 10.1109/ICCV48922.2021.01110
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Liu HY, 2022, LECT NOTES COMPUT SC, V13667, P612, DOI 10.1007/978-3-031-20071-7_36
   Liu X, 2022, PROC CVPR IEEE, P10452, DOI 10.1109/CVPR52688.2022.01021
   Mao Q, 2019, PROC CVPR IEEE, P1429, DOI 10.1109/CVPR.2019.00152
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   McFee B., 2015, P 14 PYTH SCI C, V8, P18
   "Mixamo, About us
   Paszke A, 2019, Arxiv, DOI [arXiv:1912.01703, DOI 10.48550/ARXIV.1912.01703, 10.48550/ARXIV.1912.01703]
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pavllo D., 2018, 2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids), P299, DOI DOI 10.1109/HUMANOIDS.2018.8624922
   Ruiz AH, 2019, IEEE I CONF COMP VIS, P7133, DOI 10.1109/ICCV.2019.00723
   Shlizerman E, 2018, PROC CVPR IEEE, P7574, DOI 10.1109/CVPR.2018.00790
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Sutskever I, 2014, ADV NEUR IN, V27
   Tevet G, 2022, LECT NOTES COMPUT SC, V13682, P358, DOI 10.1007/978-3-031-20047-2_21
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan XC, 2018, LECT NOTES COMPUT SC, V11209, P276, DOI 10.1007/978-3-030-01228-1_17
   Yazdian PJ, 2022, IEEE INT C INT ROBOT, P3100, DOI 10.1109/IROS47612.2022.9981117
   Yi HW, 2023, Arxiv, DOI arXiv:2212.04420
   Yoon Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417838
   Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI [10.1109/icra.2019.8793720, 10.1109/ICRA.2019.8793720]
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang F, 2023, LECT NOTES COMPUT SC, V13833, P231, DOI 10.1007/978-3-031-27077-2_18
   Zhang JY, 2019, IEEE I CONF COMP VIS, P7113, DOI 10.1109/ICCV.2019.00721
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Y, 2021, PROC CVPR IEEE, P3371, DOI 10.1109/CVPR46437.2021.00338
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu YZ, 2020, PROC CVPR IEEE, P6537, DOI 10.1109/CVPR42600.2020.00657
NR 67
TC 1
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4752
EP 4766
DI 10.1109/TVCG.2023.3276973
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400030
PM 37195841
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Xiao, YQ
   Bai, HM
   Gao, Y
   Hu, B
   Zheng, J
   Cai, XE
   Rao, JS
   Li, XG
   Hao, AM
AF Xiao, Yanqing
   Bai, Hongming
   Gao, Yang
   Hu, Ben
   Zheng, Jia
   Cai, Xiaoe
   Rao, Jiasheng
   Li, Xiaoguang
   Hao, Aimin
TI Interactive Virtual Ankle Movement Controlled by Wrist sEMG Improves
   Motor Imagery: An Exploratory Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Stroke (medical condition); Wrist; Muscles; Legged locomotion;
   Biological system modeling; Real-time systems; VR-based stroke
   rehabilitation training; motor imagery; sEMG-based virtual feedback
ID FUNCTIONAL RECOVERY; ROBOTIC DEVICE; STROKE; REHABILITATION; EMBODIMENT;
   VALIDITY; THREATS; ANGLES; LEGS; HAND
AB Virtual reality (VR) techniques can significantly enhance motor imagery training by creating a strong illusion of action for central sensory stimulation. In this article, we establish a precedent by using surface electromyography (sEMG) of contralateral wrist movement to trigger virtual ankle movement through an improved data-driven approach with a continuous sEMG signal for fast and accurate intention recognition. Our developed VR interactive system can provide feedback training for stroke patients in the early stages, even if there is no active ankle movement. Our objectives are to evaluate: 1) the effects of VR immersion mode on body illusion, kinesthetic illusion, and motor imagery performance in stroke patients; 2) the effects of motivation and attention when utilizing wrist sEMG as a trigger signal for virtual ankle motion; 3) the acute effects on motor function in stroke patients. Through a series of well-designed experiments, we have found that, compared to the 2D condition, VR significantly increases the degree of kinesthetic illusion and body ownership of the patients, and improves their motor imagery performance and motor memory. When compared to conditions without feedback, using contralateral wrist sEMG signals as trigger signals for virtual ankle movement enhances patients' sustained attention and motivation during repetitive tasks. Furthermore, the combination of VR and feedback has an acute impact on motor function. Our exploratory study suggests that the sEMG-based immersive virtual interactive feedback provides an effective option for active rehabilitation training for severe hemiplegia patients in the early stages, with great potential for clinical application.
C1 [Xiao, Yanqing; Rao, Jiasheng] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Biol Sci & Med Engn, Beijing Key Lab Biomat & Neural Regenerat, Beijing 100191, Peoples R China.
   [Bai, Hongming; Gao, Yang; Hu, Ben] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Bai, Hongming; Gao, Yang; Hu, Ben] Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg 2019RU004, Beijing 100050, Peoples R China.
   [Zheng, Jia] Capital Med Univ, Beijing Childrens Hosp, Beijing 100045, Peoples R China.
   [Cai, Xiaoe] Beijing Haidian Hosp, Dept Rehabil Med, Beijing 100080, Peoples R China.
   [Li, Xiaoguang] Capital Med Univ, Sch Basic Med Sci, Dept Neurobiol, Beijing 100069, Peoples R China.
C3 Beihang University; Beihang University; Chinese Academy of Medical
   Sciences - Peking Union Medical College; Capital Medical University;
   Capital Medical University
RP Gao, Y (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.; Li, XG (corresponding author), Capital Med Univ, Sch Basic Med Sci, Dept Neurobiol, Beijing 100069, Peoples R China.
EM xioyanjingx@126.com; 18813139553@163.com; gaoyangvr@buaa.edu.cn;
   huben@buaa.edu.cn; lwc20002@126.com; cxe930316@163.com;
   raojschina@buaa.edu.cn; lxgchina@sina.com; ham@buaa.edu.cn
RI Gao, Yang/JQV-9627-2023
OI Gao, Yang/0000-0002-9149-3554; Zheng, Jia/0009-0007-6407-7436; Rao,
   Jia-Sheng/0000-0002-5196-0912
FU National Natural Science Foundation of China [62002010, 31970970,
   82271403]; Beijing Advanced Innovation Center for Biomedical Engineering
   [ZF138G1714]; CAMS Innovation Fund for Medical Sciences (CIFMS)
   [2019-I2M-5-016]; Beijing Science and Technology Project
   [Z221100007722001]; Huawei Innovation Research Plan [TC20220616019]; Key
   Research and Development Program of Guangzhou [202206060003]; Open
   Project Program of State Key Laboratory of Virtual Reality Technology
   and Systems [VRLAB2023A05]
FX No Statement Available
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2023, Amer. J. Drug AlcoholAbuse, V49, P5
   [Anonymous], 2016, Int. J. Neurorehabilitation, V3
   [Anonymous], 1993, Int. J. Aviation Psychol., V3, P904
   Arteaga MV, 2020, P IEEE RAS-EMBS INT, P416, DOI 10.1109/BioRob49111.2020.9224328
   Artemiadis PK, 2010, IEEE T ROBOT, V26, P393, DOI 10.1109/TRO.2009.2039378
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cesarei De, 2023, Psychol.Res., P1
   Chen SW, 2021, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR-Adjunct54149.2021.00040
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Choi JW, 2020, IEEE T NEUR SYS REH, V28, P1614, DOI 10.1109/TNSRE.2020.2998123
   Clark LA, 2019, PSYCHOL ASSESSMENT, V31, P1412, DOI 10.1037/pas0000626
   Colacino FM, 2012, MED ENG PHYS, V34, P531, DOI 10.1016/j.medengphy.2011.08.012
   Ding QC, 2017, IEEE T NEUR SYS REH, V25, P1518, DOI 10.1109/TNSRE.2016.2639527
   dos Santos LF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0289-4
   Drucker H, 1997, Proceedings the 14th International Conference on Machine Learning, V107, P15, DOI DOI 10.5555/645526.657132
   Fauvel K, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9233137
   Fenker DB, 2008, J COGNITIVE NEUROSCI, V20, P1250, DOI 10.1162/jocn.2008.20086
   Flannelly KJ, 2018, J HEALTH CARE CHAPL, V24, P107, DOI 10.1080/08854726.2017.1421019
   Forrester LW, 2011, NEUROREHAB NEURAL RE, V25, P369, DOI 10.1177/1545968310388291
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fusco G, 2021, PSYCHOL RES-PSYCH FO, V85, P926, DOI 10.1007/s00426-020-01366-5
   Gao Y, 2021, INT SYM MIX AUGMENT, P354, DOI 10.1109/ISMAR-Adjunct54149.2021.00080
   Carrasco DG, 2016, NEUROLOGIA, V31, P43, DOI 10.1016/j.nrl.2013.02.003
   García-Pérez MA, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00325
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Ghassemi M, 2019, IEEE T NEUR SYS REH, V27, P283, DOI 10.1109/TNSRE.2019.2894102
   Ghazizadeh A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33514-3
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Han JD, 2015, IEEE T IND ELECTRON, V62, P4267, DOI 10.1109/TIE.2014.2387337
   HART S G, 1988, P139
   Heald E, 2017, NEUROREHAB NEURAL RE, V31, P583, DOI 10.1177/1545968317704904
   Hill AV, 1938, PROC R SOC SER B-BIO, V126, P136, DOI 10.1098/rspb.1938.0050
   Jarrassé N, 2017, IEEE T NEUR SYS REH, V25, P68, DOI 10.1109/TNSRE.2016.2563222
   Jendrassik E., 1883, "Deusches Arch.Klin. Med., V33, P177
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Kaupp C, 2018, J NEUROPHYSIOL, V119, P1095, DOI 10.1152/jn.00570.2017
   Kawase T, 2014, IEEE SYS MAN CYBERN, P1470, DOI 10.1109/SMC.2014.6974122
   Ke G., 2017, P 31 INT C NEUR INF, V30, P3149, DOI [DOI 10.5555/3294996.3295074, DOI 10.5555/3294996]
   Klarner T, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6040054
   Lamontagne A, 2010, NEUROREHAB NEURAL RE, V24, P457, DOI 10.1177/1545968309355985
   Li KX, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102074
   Li M, 2022, IEEE T VIS COMPUT GR, V28, P3832, DOI 10.1109/TVCG.2022.3203099
   Meng Q, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1166-z
   Mirelman A, 2009, STROKE, V40, P169, DOI 10.1161/STROKEAHA.108.516328
   Okawada M, 2020, RESTOR NEUROL NEUROS, V38, P455, DOI 10.3233/RNN-201030
   Ono Y, 2018, NEUROPSYCHOLOGIA, V114, P134, DOI 10.1016/j.neuropsychologia.2018.04.016
   Pallotti A, 2021, BIOCYBERN BIOMED ENG, V41, P605, DOI 10.1016/j.bbe.2021.03.0030168-8227/
   Panel P.-S. R. G., 1995, Patient Family Gui,
   Pau JWL, 2012, IEEE T BIO-MED ENG, V59, P2586, DOI 10.1109/TBME.2012.2206389
   Pichiorri F, 2015, ANN NEUROL, V77, P851, DOI 10.1002/ana.24390
   Platt JC, 2000, ADV NEUR IN, P61
   Pozeg P, 2017, NEUROLOGY, V89, P1894, DOI 10.1212/WNL.0000000000004585
   Rawat S, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P115, DOI 10.1109/SYSMART.2016.7894501
   Ren YP, 2017, IEEE T NEUR SYS REH, V25, P589, DOI 10.1109/TNSRE.2016.2584003
   Repp BH, 2004, PSYCHOL RES-PSYCH FO, V68, P252, DOI 10.1007/s00426-003-0143-8
   Roosink M, 2016, RESTOR NEUROL NEUROS, V34, P227, DOI 10.3233/RNN-150563
   Ruitenberg MFL, 2022, ANN NY ACAD SCI, V1510, P68, DOI 10.1111/nyas.14731
   Sakai K, 2020, BRAIN COGNITION, V146, DOI 10.1016/j.bandc.2020.105632
   Sakai K, 2018, NEUROCASE, V24, P245, DOI 10.1080/13554794.2019.1566477
   Sasaki A, 2020, J NEUROPHYSIOL, V124, P652, DOI 10.1152/jn.00705.2019
   Schomaker J, 2015, NEUROSCI BIOBEHAV R, V55, P268, DOI 10.1016/j.neubiorev.2015.05.002
   Schomaker J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00918
   Schomaker J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050599
   Tanabe Junpei, 2022, J Phys Ther Sci, V34, P65, DOI 10.1589/jpts.34.65
   Tang ZC, 2016, IEEE T NEUR SYS REH, V24, P1342, DOI 10.1109/TNSRE.2015.2502663
   Tazoe T., 2014, J.Phys.FitnessSportsMed., V3, P181, DOI DOI 10.7600/jpfsm.3.181
   Tham J, 2018, IEEE T PROF COMMUN, V61, P178, DOI 10.1109/TPC.2018.2804238
   Tong YN, 2017, AGING DIS, V8, P364, DOI 10.14336/AD.2016.1012
   Tseng SC, 2010, J NEUROPHYSIOL, V104, P248, DOI 10.1152/jn.00906.2009
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00244
   Wei WT, 2019, IEEE T BIO-MED ENG, V66, P2964, DOI 10.1109/TBME.2019.2899222
   Zhang Q, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00280
   Zhou R, 2018, J NEUROPHYSIOL, V120, P3172, DOI 10.1152/jn.00509.2017
   Zhou R, 2017, J NEUROPHYSIOL, V118, P2507, DOI 10.1152/jn.00663.2016
NR 75
TC 0
Z9 0
U1 3
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5507
EP 5524
DI 10.1109/TVCG.2023.3294342
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400011
PM 37432832
DA 2024-08-05
ER

PT J
AU Ji, B
   Pan, Y
   Yan, YC
   Chen, RZ
   Yang, XK
AF Ji, Bin
   Pan, Ye
   Yan, Yichao
   Chen, Ruizhao
   Yang, Xiaokang
TI StyleVR: Stylizing Character Animations With Normalizing Flows
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Character animation; motion generation; style transfer; normalizing
   flow; virtual reality
AB The significance of artistry in creating animated virtual characters is widely acknowledged, and motion style is a crucial element in this process. There has been a long-standing interest in stylizing character animations with style transfer methods. However, this kind of models can only deal with short-term motions and yield deterministic outputs. To address this issue, we propose a generative model based on normalizing flows for stylizing long and aperiodic animations in the VR scene. Our approach breaks down this task into two sub-problems: motion style transfer and stylized motion generation, both formulated as the instances of conditional normalizing flows with multi-class latent space. Specifically, we encode high-frequency style features into the latent space for varied results and control the generation process with style-content labels for disentangled edits of style and content. We have developed a prototype, StyleVR, in Unity, which allows casual users to apply our method in VR. Through qualitative and quantitative comparisons, we demonstrate that our system outperforms other methods in terms of style transfer as well as stochastic stylized motion generation.
C1 [Ji, Bin; Pan, Ye; Yan, Yichao; Chen, Ruizhao; Yang, Xiaokang] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Pan, Y (corresponding author), Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
EM bin.ji@sjtu.edu.cn; whitneypanye@sjtu.edu.cn; yanyichao@sjtu.edu.cn;
   stelledge@sjtu.edu.cn; xkyang@sjtu.edu.cn
OI Ji, Bin/0000-0002-8981-5251; Chen, Ruizhao/0000-0002-3056-0186
FU Shanghai Sailing Program [20YF1421200]; National Natural Science
   Foundation of China (NSFC) [62102255, 62201342]; Shanghai Municipal
   Science and Technology Major Project [2021SHZDZX0102]
FX This work was supported in part by Shanghai Sailing Program under Grant
   20YF1421200, in part by the National Natural Science Foundation of China
   (NSFC) under Grant 62102255, in part by the National Natural Science
   Foundation of China (NSFC) under Grant 62201342 and in part by Shanghai
   Municipal Science and Technology Major Project under Grant
   2021SHZDZX0102.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392469
   Alexanderson G. E., 2020, arXiv
   Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Amaya K, 1996, PROC GRAPH INTERF, P222
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Child R, 2019, Arxiv, DOI arXiv:1904.10509
   Dinh L, 2017, Arxiv, DOI [arXiv:1605.08803, DOI 10.48550/ARXIV.1605.08803]
   Du Han., 2019, Eurographics 2019 - Short Papers, DOI DOI 10.2312/EGS.20191002
   Garcia R., 2019, P 12 ACM SIGGRAPH C, P1
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Holden D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392440
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Huang RZ, 2021, Arxiv, DOI arXiv:2006.06119
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Izmailov P., 2020, International Conference on Machine Learning, P4615
   Li PZ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530157
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   Lockwood Noah., 2012, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '12, P43, DOI DOI 10.2312/SCA/SCA12/043-052
   Ma L., 2020, P S INT 3D GRAPH GAM, P1
   Mason I, 2018, COMPUT GRAPH FORUM, V37, P143, DOI 10.1111/cgf.13555
   Mason I, 2022, P ACM COMPUT GRAPH, V5, DOI 10.1145/3522618
   Kingma DP, 2018, Arxiv, DOI [arXiv:1807.03039, DOI 10.48550/ARXIV.1807.03039]
   Pan Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P759, DOI [10.1109/VRW50115.2020.00-45, 10.1109/VRW50115.2020.00230]
   Petrovich M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10965, DOI 10.1109/ICCV48922.2021.01080
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Salimans T, 2016, ADV NEUR IN, V29
   Smith HJ, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340254
   Starke S, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530178
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   Taylor G., 2009, P 26 ANN INT C MACHI
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Unuma M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P91, DOI 10.1145/218380.218419
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vogel P., 2018, P IEEE C VIRT REAL 3, P1
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P14, DOI 10.1109/TVCG.2019.2938520
   Wen YH, 2021, PROC CVPR IEEE, P13607, DOI 10.1109/CVPR46437.2021.01340
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Xu Z, 2022, PROC CVPR IEEE, P11625, DOI 10.1109/CVPR52688.2022.01134
   Ye H, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392404
   Yumer ME, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925955
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
NR 49
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4183
EP 4196
DI 10.1109/TVCG.2023.3259183
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700023
PM 37030765
DA 2024-08-05
ER

PT J
AU Vohra, SK
   Harth, P
   Isoe, Y
   Bahl, A
   Fotowat, H
   Engert, F
   Hege, HC
   Baum, D
AF Vohra, Sumit Kumar
   Harth, Philipp
   Isoe, Yasuko
   Bahl, Armin
   Fotowat, Haleh
   Engert, Florian
   Hege, Hans-Christian
   Baum, Daniel
TI A Visual Interface for Exploring Hypotheses About Neural Circuits
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neurons; Neural circuits; Visualization; Imaging; Image reconstruction;
   Behavioral sciences; Data visualization; Human-centered computing;
   scientific visualization; visualization systems and tools; web-based
   interaction
ID BRAIN; VISUALIZATION
AB One of the fundamental problems in neurobiological research is to understand how neural circuits generate behaviors in response to sensory stimuli. Elucidating such neural circuits requires anatomical and functional information about the neurons that are active during the processing of the sensory information and generation of the respective response, as well as an identification of the connections between these neurons. With modern imaging techniques, both morphological properties of individual neurons as well as functional information related to sensory processing, information integration and behavior can be obtained. Given the resulting information, neurobiologists are faced with the task of identifying the anatomical structures down to individual neurons that are linked to the studied behavior and the processing of the respective sensory stimuli. Here, we present a novel interactive tool that assists neurobiologists in the aforementioned tasks by allowing them to extract hypothetical neural circuits constrained by anatomical and functional data. Our approach is based on two types of structural data: brain regions that are anatomically or functionally defined, and morphologies of individual neurons. Both types of structural data are interlinked and augmented with additional information. The presented tool allows the expert user to identify neurons using Boolean queries. The interactive formulation of these queries is supported by linked views, using, among other things, two novel 2D abstractions of neural circuits. The approach was validated in two case studies investigating the neural basis of vision-based behavioral responses in zebrafish larvae. Despite this particular application, we believe that the presented tool will be of general interest for exploring hypotheses about neural circuits in other species, genera and taxa.
C1 [Vohra, Sumit Kumar; Harth, Philipp; Hege, Hans-Christian; Baum, Daniel] Zuse Inst Berlin ZIB, Dept Visual & Data Ctr Comp, D-14195 Berlin, Germany.
   [Isoe, Yasuko; Fotowat, Haleh; Engert, Florian] Harvard Univ, Dept Mol & Cellular Biol, Cambridge, MA 02138 USA.
   [Bahl, Armin] Univ Konstanz, Ctr Adv Study Collect Behav, D-78464 Constance, Germany.
C3 Zuse Institute Berlin; Harvard University; University of Konstanz
RP Vohra, SK (corresponding author), Zuse Inst Berlin ZIB, Dept Visual & Data Ctr Comp, D-14195 Berlin, Germany.
EM vohra@zib.de; harth@zib.de; yasuko_isoe@fas.harvard.edu;
   armin.bahl@uni-konstanz.de; haleh.fotowat@wyss.harvard.edu;
   florian@mcb.harvard.edu; hege@zib.de; baum@zib.de
OI Baum, Daniel/0000-0003-1550-7245; Isoe, Yasuko/0000-0002-1391-7921;
   Hege, Hans-Christian/0000-0002-6574-0988; Bahl,
   Armin/0000-0001-7591-5860; Harth, Philipp/0000-0001-8831-3893; Vohra,
   Sumit Kumar/0000-0003-2443-7461
FU National Institute of Neurological Disorders and Stroke (NINDS) of the
   National Institutes of Health (NIH) [1U19NS104653]; Deutsche
   Forschungsgemeinschaft (DFG); SPP 2041 Computational Connectomics
   [347210657]; NIH [U19NS104653, 1R01NS124017]; National Science
   Foundation [IIS-1912293]; Simons Foundation [SCGB 542973]; Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) through
   Germany's Excellence Strategy [EXC 2117 422037984]; Emmy Noether Program
   [429442687]; Zukunftskolleg Konstanz
FX This work was supported in part by the National Institute of
   Neurological Disorders and Stroke (NINDS) of the National Institutes of
   Health (NIH) under Grant 1U19NS104653, and in part by the Deutsche
   Forschungsgemeinschaft (DFG), SPP 2041 Computational Connectomics, under
   Grant 347210657. The work of Florian Engert received funding from the
   NIH under Grants U19NS104653 and 1R01NS124017, in part by the National
   Science Foundation under Grant IIS-1912293, and in part by the Simons
   Foundation under Grant SCGB 542973. The work of Armin Bahl was supported
   in part by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) through Germany's Excellence Strategy under Grant EXC 2117
   422037984, in part by the Emmy Noether Program under Grant 429442687,
   and in part by the Zukunftskolleg Konstanz.
CR Abouzied A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P207
   Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Allen Institute, 2019, Documentation: Allen mouse brain connectivity atlas
   [Anonymous], 2021, React complex tree
   [Anonymous], 2016, Neuroglancer: WebGL-based viewer for volumetric data
   [Anonymous], 2022, FishExplorer: A multiscale, explorative atlas of the larval zebrafishh's brain
   [Anonymous], 2022, The larval standard brain
   [Anonymous], 2020, ZFIN-Anatomy atlases and resources
   [Anonymous], 2010, Gunicorn-Python WSGI HTTP Server for UNIX
   [Anonymous], 2013, BabylonJs: The WebGL-based rendering engine
   Bahl A, 2020, NAT NEUROSCI, V23, P94, DOI 10.1038/s41593-019-0534-9
   Beyer J, 2022, COMPUT GRAPH FORUM, V41, P573, DOI 10.1111/cgf.14574
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandt R, 2005, J COMP NEUROL, V492, P1, DOI 10.1002/cne.20644
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bruckner S, 2009, IEEE T VIS COMPUT GR, V15, P1497, DOI 10.1109/TVCG.2009.121
   Cantarelli M, 2018, PHILOS T R SOC B, V373, DOI 10.1098/rstb.2017.0380
   Chen WF, 2018, CHINESE J ELECTRON, V27, P889, DOI 10.1049/cje.2018.04.007
   Claudi F, 2021, ELIFE, V10, DOI 10.7554/eLife.65751
   Dercksen V. J., 2012, P EUR WORKSH VIS COM, P17, DOI [10.2312/VCBM/VCBM12/017-024, DOI 10.2312/VCBM/VCBM12/017-024]
   Dunn TW, 2016, NEURON, V89, P613, DOI 10.1016/j.neuron.2015.12.021
   Fornito Alex, 2016, Fundamentals of brain network analysis
   Fotowat H, 2022, bioRxiv, DOI [10.1101/2022.06.23.497366, 10.1101/2022.06.23.497366, DOI 10.1101/2022.06.23.497366]
   Friedrich RW, 2021, ANNU REV NEUROSCI, V44, P275, DOI 10.1146/annurev-neuro-110220-013050
   Ganglberger F., 2018, P EUR WORKSH VIS COM, P77
   Ganglberger F, 2022, COMPUT GRAPH-UK, V105, P12, DOI 10.1016/j.cag.2022.04.014
   Ganglberger F, 2019, COMPUT GRAPH-UK, V82, P304, DOI 10.1016/j.cag.2019.05.032
   Gerhard Stephan, 2011, Front Neuroinform, V5, P3, DOI 10.3389/fninf.2011.00003
   Gleeson P, 2019, NEURON, V103, P395, DOI 10.1016/j.neuron.2019.05.019
   Göbel W, 2007, PHYSIOLOGY, V22, P358, DOI 10.1152/physiol.00032.2007
   Helmbrecht TO, 2018, NEURON, V100, P1429, DOI 10.1016/j.neuron.2018.10.021
   Hildebrand DGC, 2017, NATURE, V545, P345, DOI 10.1038/nature22356
   Kuβ A., 2008, P EUR WORKSH VIS COM, P177
   Kunst M, 2019, NEURON, V103, P21, DOI 10.1016/j.neuron.2019.04.034
   Kuss A, 2010, COMPUT GRAPH FORUM, V29, P1003, DOI 10.1111/j.1467-8659.2009.01703.x
   Leventidis A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2303, DOI 10.1145/3318464.3389767
   Likert R., 1932, Archives of Psychology, V22, P55
   Lin CY, 2011, IEEE PAC VIS SYMP, P35, DOI 10.1109/PACIFICVIS.2011.5742370
   Margulies DS, 2013, NEUROIMAGE, V80, P445, DOI 10.1016/j.neuroimage.2013.04.111
   Matejek B, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15027-7
   Maye A, 2006, INT J NEUROSCI, V116, P431, DOI 10.1080/00207450500505860
   Milyaev N, 2012, BIOINFORMATICS, V28, P411, DOI 10.1093/bioinformatics/btr677
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Ohyama T, 2015, NATURE, V520, P633, DOI 10.1038/nature14297
   Pastor L, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104652
   Pfister Hanspeter., 2014, Scientific Visualization, P221
   Plaza SM, 2022, FRONT NEUROINFORM, V16, DOI 10.3389/fninf.2022.896292
   Randlett O, 2015, NAT METHODS, V12, P1039, DOI 10.1038/NMETH.3581
   Saalfeld S, 2009, BIOINFORMATICS, V25, P1984, DOI 10.1093/bioinformatics/btp266
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Scheibel W, 2020, IVAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 3: IVAPP, P273, DOI 10.5220/0009153902730280
   Schirner M, 2022, NEUROIMAGE, V251, DOI 10.1016/j.neuroimage.2022.118973
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Schwanke S, 2019, NEUROINFORMATICS, V17, P163, DOI 10.1007/s12021-018-9389-6
   Sorger J, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P73, DOI 10.1109/BioVis.2013.6664349
   Swoboda N, 2017, COMPUT GRAPH FORUM, V36, P160, DOI 10.1111/cgf.12792
   Swoboda N., 2014, P EUR WORKSH VIX COM, P107
   Takemura S, 2013, NATURE, V500, P175, DOI 10.1038/nature12450
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Yao YY, 2016, NEURON, V89, P598, DOI 10.1016/j.neuron.2015.12.036
NR 61
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3945
EP 3958
DI 10.1109/TVCG.2023.3243668
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700087
PM 37022819
DA 2024-08-05
ER

PT J
AU Zhao, MY
   Huang, XS
   Jiang, JE
   Mou, LT
   Yan, DM
   Ma, L
AF Zhao, Mingyang
   Huang, Xiaoshui
   Jiang, Jingen
   Mou, Luntian
   Yan, Dong-Ming
   Ma, Lei
TI Accurate Registration of Cross-Modality Geometry via Consistent
   Clustering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Geometry; Three-dimensional displays; Laser
   radar; Tensors; Clustering algorithms; Solid modeling; Cross-modality
   geometry; point cloud registration; 3D reconstruction; adaptive fuzzy
   clustering; CAD
ID ITERATIVE CLOSEST POINT; ICP
AB The registration of unitary-modality geometric data has been successfully explored over past decades. However, existing approaches typically struggle to handle cross-modality data due to the intrinsic difference between different models. To address this problem, in this article, we formulate the cross-modality registration problem as a consistent clustering process. First, we study the structure similarity between different modalities based on an adaptive fuzzy shape clustering, from which a coarse alignment is successfully operated. Then, we optimize the result using fuzzy clustering consistently, in which the source and target models are formulated as clustering memberships and centroids, respectively. This optimization casts new insight into point set registration, and substantially improves the robustness against outliers. Additionally, we investigate the effect of fuzzier in fuzzy clustering on the cross-modality registration problem, from which we theoretically prove that the classical Iterative Closest Point (ICP) algorithm is a special case of our newly defined objective function. Comprehensive experiments and analysis are conducted on both synthetic and real-world cross-modality datasets. Qualitative and quantitative results demonstrate that our method outperforms state-of-the-art approaches with higher accuracy and robustness. Our code is publicly available at https://github.com/zikai1/CrossModReg.
C1 [Zhao, Mingyang] Chinese Acad Sci, Beijing Acad Artificial Intelligence, Inst Automat, Beijing 100045, Peoples R China.
   [Zhao, Mingyang; Jiang, Jingen; Yan, Dong-Ming] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100045, Peoples R China.
   [Huang, Xiaoshui] Shanghai AI Lab, Shanghai 200433, Peoples R China.
   [Jiang, Jingen; Yan, Dong-Ming] Chinese Acad Sci, State Key Lab Multimodal Artificial Intelligence, Inst Automat, Beijing 100045, Peoples R China.
   [Jiang, Jingen; Yan, Dong-Ming] Univ Chinese Acad Sci, Sch AI, Beijing 101408, Peoples R China.
   [Mou, Luntian] Beijing Univ Technol, Beijing Inst Artificial Intelligence, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100021, Peoples R China.
   [Ma, Lei] Peking Univ, Natl Biomed Imaging Ctr, Beijing 100871, Peoples R China.
   [Ma, Lei] Peking Univ, Sch Comp Sci, Beijing Acad Artificial Intelligence, Beijing 100871, Peoples R China.
   [Ma, Lei] Peking Univ, Sch Comp Sci, Natl Key Lab Multimedia Informat Proc, Beijing 100871, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; Institute of Automation, CAS; Shanghai Artificial
   Intelligence Laboratory; Chinese Academy of Sciences; Institute of
   Automation, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; Beijing University of Technology; Peking
   University; Peking University; Peking University
RP Yan, DM (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100045, Peoples R China.; Yan, DM (corresponding author), Chinese Acad Sci, State Key Lab Multimodal Artificial Intelligence, Inst Automat, Beijing 100045, Peoples R China.; Ma, L (corresponding author), Peking Univ, Natl Biomed Imaging Ctr, Beijing 100871, Peoples R China.; Ma, L (corresponding author), Peking Univ, Sch Comp Sci, Beijing Acad Artificial Intelligence, Beijing 100871, Peoples R China.; Ma, L (corresponding author), Peking Univ, Sch Comp Sci, Natl Key Lab Multimedia Informat Proc, Beijing 100871, Peoples R China.
EM zhaomingyang16@mails.ucas.ac.cn; huangxiaoshui@163.com;
   jiangjingen@ia.ac.cn; ltmou@bjut.edu.cn; yandongming@gmail.com;
   lei.ma@pku.edu.cn
OI Ma, Lei/0000-0001-6024-3854; Yan, Dong-Ming/0000-0003-2209-2404; Huang,
   Xiaoshui/0000-0002-3579-538X
FU National Key R&D Program of China [2022ZD0116305]; National Natural
   Science Foundation of China [62172415]; Open Research Fund Program of
   State Key Laboratory of Hydroscience and Engineering, Tsinghua
   University [klhse-2022-D-04]
FX This work was supported in part by National Key R&D Program of China
   under Grant 2022ZD0116305, in part by the National Natural Science
   Foundation of China under Grant 62172415, and in part by the Open
   Research Fund Program of State Key Laboratory of Hydroscience and
   Engineering, Tsinghua University under Grants klhse-2022-D-04.
CR Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Avetisyan A, 2019, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2019.00272
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bolles RC, 1981, INT JOINT C ARTIFICI, P637, DOI DOI 10.5555/1623264.1623272
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Campbell D, 2015, IEEE I CONF COMP VIS, P4292, DOI 10.1109/ICCV.2015.488
   CHARALAMBOUS C, 1976, INT J SYST SCI, V7, P377, DOI 10.1080/00207727608941924
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Eckart B, 2018, LECT NOTES COMPUT SC, V11219, P730, DOI 10.1007/978-3-030-01267-0_43
   Ferrari V, 2022, IEEE T VIS COMPUT GR, V28, P1608, DOI 10.1109/TVCG.2020.3021534
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forsyth J., 2003, Comput. Vis. A ModernApproach, V17, P21
   Gao W, 2019, PROC CVPR IEEE, P11087, DOI 10.1109/CVPR.2019.01135
   Ghahremani P, 2022, IEEE T VIS COMPUT GR, V28, P4951, DOI 10.1109/TVCG.2021.3109460
   Harders M, 2009, IEEE T VIS COMPUT GR, V15, P138, DOI 10.1109/TVCG.2008.63
   Hartley I., 1997, "IEEETrans.PatternAnal. Mach. Intell., V19, P593
   Huang X., 2016, P INT C DIG IM COMP, P1
   Huang XS, 2019, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2019.00268
   Huang XS, 2017, IEEE T IMAGE PROCESS, V26, P3261, DOI 10.1109/TIP.2017.2695888
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Jubran Ibrahim., 2021, IEEE INT C COMPUT VI, P13269
   Kwon SH, 1998, ELECTRON LETT, V34, P2176, DOI 10.1049/el:19981523
   Liao QF, 2021, IEEE T PATTERN ANAL, V43, P3229, DOI 10.1109/TPAMI.2020.2978477
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674
   Magnusson M., 2009, Ph.D. dissertation
   Mellado N, 2016, IEEE T VIS COMPUT GR, V22, P2160, DOI 10.1109/TVCG.2015.2505287
   Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Myronenko X., 2009, IEEETrans.PatternAnal. Mach. Intell., V19, P580
   Pavlov AL, 2018, IEEE INT CONF ROBOT, P3407
   Peng FR, 2014, IEEE IMAGE PROC, P2026, DOI 10.1109/ICIP.2014.7025406
   Pomerleau F., 2015, Trends Robotics, V4, P1, DOI DOI 10.1561/2300000035
   SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Tazir ML, 2018, ROBOT AUTON SYST, V108, P66, DOI 10.1016/j.robot.2018.07.003
   Wang WN, 2007, FUZZY SET SYST, V158, P2095, DOI 10.1016/j.fss.2007.03.004
   Wang Y., 2019, INT C NEURAL INF PRO, P8812
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Weinmann M., 2013, ISPRS ANN PHOTOGRAMM, V2, P313, DOI DOI 10.5194/ISPRSANNALS-II-5-W2-313-2013
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiaoshui Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11363, DOI 10.1109/CVPR42600.2020.01138
   Yan FL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980241
   Yan ZH, 2022, IEEE T VIS COMPUT GR, V28, P4304, DOI 10.1109/TVCG.2021.3086113
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang JY, 2022, IEEE T PATTERN ANAL, V44, P3450, DOI 10.1109/TPAMI.2021.3054619
   Zhao MY, 2022, IEEE T IMAGE PROCESS, V31, P7449, DOI 10.1109/TIP.2022.3223793
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
NR 56
TC 2
Z9 2
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4055
EP 4067
DI 10.1109/TVCG.2023.3247169
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700043
PM 37027717
DA 2024-08-05
ER

PT J
AU Zhao, TM
   Gao, P
   Tian, T
   Ma, JY
   Tian, JW
AF Zhao, Tianming
   Gao, Peng
   Tian, Tian
   Ma, Jiayi
   Tian, Jinwen
TI From Noise Addition to Denoising: A Self-Variation Capture Network for
   Point Cloud Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Noise reduction; Noise measurement; Manifolds;
   Optimization; Three-dimensional displays; Surface cleaning; Commonality
   capture; noise perturbation; point clouds denoising; self-variation
AB Point clouds obtained from 3D scanners are often noisy and cannot be directly used for subsequent high-level tasks. In this article, we propose a novel point cloud optimization method capable of denoising and homogenizing point clouds. Our idea is based on the assumption that the noise is generally much smaller than the effective signal. We perform noise perturbation on the noisy point cloud to get a new noisy point cloud, called self-variation point cloud. The noisy point cloud and self-variation point cloud have different noise distribution, but the same point cloud distribution. We compute the potential commonality between two noisy point clouds to obtain a clean point cloud. To implement our idea, we propose a Self-Variation Capture Network (SVCNet). We perturb the point cloud features in the latent space to obtain self-variation feature vectors, and capture the commonality between two noisy feature vectors through the feature aggregation and averaging. In addition, an edge constraint module is introduced to suppress low-pass effects during denoising. Our denoising method does not take into account the noise characteristics, and can filter the drift noise located on the underlying surface, resulting in a uniform distribution of the generated point cloud. The experimental results show that our algorithm outperforms the current state-of-the-art algorithms, especially in generating more uniform point clouds. In addition, extended experiments demonstrate the potential of our algorithm for point clouds upsampling.
C1 [Zhao, Tianming; Gao, Peng; Tian, Tian; Tian, Jinwen] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Multispectral Informat Intelligent Pr, Wuhan 430074, Peoples R China.
   [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.
C3 Huazhong University of Science & Technology; Wuhan University
RP Tian, T (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Multispectral Informat Intelligent Pr, Wuhan 430074, Peoples R China.
EM tming@hust.edu.cn; gaopengde@hust.edu.cn; ttian@hust.edu.cn;
   jyma2010@gmail.com; jwtian@mail.hust.edu.cn
OI Tian, Tian/0000-0003-0148-4900; Ma, Jiayi/0000-0003-3264-3265
FU National Natural Science Foundation of China [42071339, 62276192];
   National Key Laboratory Fund [6142113210310]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 42071339 and 62276192 and in part by
   National Key Laboratory Fund under Grant 6142113210310.
CR Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Cazals F, 2005, COMPUT AIDED GEOM D, V22, P121, DOI 10.1016/j.cagd.2004.09.004
   Cazals F, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1404582
   Chen HL, 2023, IEEE T PATTERN ANAL, V45, P2913, DOI 10.1109/TPAMI.2022.3175183
   Chen HH, 2022, INT J COMPUT VISION, V130, P615, DOI 10.1007/s11263-021-01564-7
   Cignoni P., 2008, EUR IT CHAPT C, P129, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai ZH, 2019, Arxiv, DOI [arXiv:1901.02860, DOI 10.48550/ARXIV.1901.02860]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Digne J, 2017, IMAGE PROCESS ON LIN, V7, P278, DOI 10.5201/ipol.2017.179
   Dinesh C, 2018, Arxiv, DOI arXiv:1812.07711
   Dinesh C, 2018, Arxiv, DOI arXiv:1804.10831
   Duan CJ, 2019, INT CONF ACOUST SPEE, P8553, DOI [10.1109/ICASSP.2019.8682812, 10.1109/icassp.2019.8682812]
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Gao W., 2018, P IEEE 4 INT C MULT, P1
   Gschwandtner Michael, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P199, DOI 10.1007/978-3-642-24031-7_20
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239474, 10.1145/1276377.1276406]
   HEISLEY DD, 1991, J CONSUM RES, V18, P257, DOI 10.1086/209258
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   Hu W, 2020, IEEE T SIGNAL PROCES, V68, P2841, DOI 10.1109/TSP.2020.2978617
   Huang H., IEEETrans. Visualization Comput. Graph., DOI [10.1109/TVCG.2021.3137912.3, DOI 10.1109/TVCG.2021.3137912.3]
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Luo ST, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1330, DOI 10.1145/3394171.3413727
   Luo Shitong, 2021, P IEEECVF INT C COMP, P4583
   Mattei E, 2017, COMPUT GRAPH FORUM, V36, P123, DOI 10.1111/cgf.13068
   Nair V., 2010, ICML, P807
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pistilli F, 2021, IEEE J-STSP, V15, P402, DOI 10.1109/JSTSP.2020.3047471
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Schoenenberger Y, 2015, 3DTV CONF
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wei MQ, 2023, IEEE T VIS COMPUT GR, V29, P1357, DOI 10.1109/TVCG.2021.3113463
   Xu LL, 2015, GRAPH MODELS, V82, P160, DOI 10.1016/j.gmod.2015.06.012
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zeng J, 2020, IEEE T IMAGE PROCESS, V29, P3474, DOI 10.1109/TIP.2019.2961429
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhang Z., IEEE Trans. VisualizationComput. Graph., DOI [10.1109/TVCG.2022.3148245.4, DOI 10.1109/TVCG.2022.3148245.4]
NR 44
TC 2
Z9 2
U1 3
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3413
EP 3426
DI 10.1109/TVCG.2022.3231680
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700069
PM 37015380
DA 2024-08-05
ER

PT J
AU Zhong, CL
   Sang, XZ
   Yan, BB
   Li, H
   Chen, D
   Qin, XJ
   Chen, S
   Ye, XQ
AF Zhong, Chongli
   Sang, Xinzhu
   Yan, Binbin
   Li, Hui
   Chen, Duo
   Qin, Xiujuan
   Chen, Shuo
   Ye, Xiaoqian
TI Real-Time High-Quality Computer-Generated Hologram Using Complex-Valued
   Convolutional Neural Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural networks; Computer architecture; Three-dimensional displays; Deep
   learning; Image reconstruction; Holography; Convolution; neural models;
   virtual and augmented reality
ID SPATIAL LIGHT-MODULATOR; ANGULAR SPECTRUM METHOD; 3-DIMENSIONAL DISPLAY;
   PHASE; PROPAGATION; IMAGE
AB Holographic displays are ideal display technologies for virtual and augmented reality because all visual cues are provided. However, real-time high-quality holographic displays are difficult to achieve because the generation of high-quality computer-generated hologram (CGH) is inefficient in existing algorithms. Here, complex-valued convolutional neural network (CCNN) is proposed for phase-only CGH generation. The CCNN-CGH architecture is effective with a simple network structure based on the character design of complex amplitude. A holographic display prototype is set up for optical reconstruction. Experiments verify that state-of-the-art performance is achieved in terms of quality and generation speed in existing end-to-end neural holography methods using the ideal wave propagation model. The generation speed is three times faster than HoloNet and one-sixth faster than Holo-encoder, and the Peak Signal to Noise Ratio (PSNR) is increased by 3 dB and 9 dB, respectively. Real-time high-quality CGHs are generated in 1920 x 1072 and 3840 x 2160 resolutions for dynamic holographic displays.
C1 [Zhong, Chongli; Sang, Xinzhu; Yan, Binbin; Chen, Duo; Qin, Xiujuan; Chen, Shuo; Ye, Xiaoqian] Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing 100876, Peoples R China.
   [Li, Hui] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Tsinghua University
RP Sang, XZ; Yan, BB (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing 100876, Peoples R China.
EM zclda@bupt.edu.cn; xzsang@bupt.edu.cn; yanbinbin@bupt.edu.cn;
   huilijtsd@163.com; chenduo15@aliyun.com; 18801175281@163.com;
   shuochen365@bupt.edu.cn; xiaoqianye@bupt.edu.cn
OI Zhong, Chongli/0000-0001-8917-7512
FU National Natural Science Foundation of China [62075016, 62175017]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 62075016, 62175017.
CR Amano H, 2020, OPT EXPRESS, V28, P5692, DOI 10.1364/OE.387072
   Blinder D, 2021, IEEE T IMAGE PROCESS, V30, P9418, DOI 10.1109/TIP.2021.3125495
   Chakravarthula P, 2021, IEEE T VIS COMPUT GR, V27, P4194, DOI 10.1109/TVCG.2021.3106433
   Chakravarthula P, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417846
   Chakravarthula P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356539
   Chang C, 2020, OPTICA, V7, P1563, DOI 10.1364/OPTICA.406004
   Chen C, 2021, OPT EXPRESS, V29, P15089, DOI 10.1364/OE.425077
   Choi H.-S., 2018, P INT C LEARN REPR, P63
   Choi Suyeon, 2022, SIGGRAPH22 Conference Proceeding: Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, DOI 10.1145/3528233.3530734
   Choi S, 2021, OPTICA, V8, P143, DOI 10.1364/OPTICA.410622
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Eybposh MH, 2020, OPT EXPRESS, V28, P26636, DOI 10.1364/OE.399624
   GERCHBERG RW, 1972, OPTIK, V35, P237
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZH, 2021, APPL OPTICS, V60, pA145, DOI 10.1364/AO.404934
   Horisaki R, 2021, APPL OPTICS, V60, pA323, DOI 10.1364/AO.404151
   Horisaki R, 2018, APPL OPTICS, V57, P3859, DOI 10.1364/AO.57.003859
   Huang HK, 2018, OPT EXPRESS, V26, P17578, DOI 10.1364/OE.26.017578
   Ishii Y, 2022, APPL PHYS B-LASERS O, V128, DOI 10.1007/s00340-022-07753-7
   Khan A, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6662161
   Kim S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459776
   Krajancich B, 2020, IEEE T VIS COMPUT GR, V26, P1871, DOI 10.1109/TVCG.2020.2973443
   Li G, 2016, OPT LETT, V41, P2486, DOI 10.1364/OL.41.002486
   Li H, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.10.102408
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Liu KX, 2022, APPL PHYS LETT, V120, DOI 10.1063/5.0080797
   Ma XL, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.9.095105
   Macedo MCF, 2023, IEEE T VIS COMPUT GR, V29, P1590, DOI 10.1109/TVCG.2021.3117866
   Maimone A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073624
   Matsushima K, 2009, OPT EXPRESS, V17, P19662, DOI 10.1364/OE.17.019662
   Pan YJ, 2016, IEEE T IND INFORM, V12, P1599, DOI 10.1109/TII.2015.2496304
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi L, 2021, NATURE, V591, P234, DOI 10.1038/s41586-020-03152-0
   Slinger C, 2005, COMPUTER, V38, P46, DOI 10.1109/MC.2005.260
   Su P, 2016, J DISP TECHNOL, V12, P1688, DOI 10.1109/JDT.2016.2553440
   Su YF, 2018, OPT COMMUN, V428, P216, DOI 10.1016/j.optcom.2018.07.061
   Su YF, 2018, J OPT SOC AM A, V35, P1477, DOI 10.1364/JOSAA.35.001477
   Sui XM, 2021, OPT EXPRESS, V29, P2597, DOI 10.1364/OE.414299
   Sun F., 2021, Research On Single Fiber Imaging Technology Under Fiber Deformation, P336
   Trabelsi C, 2018, Arxiv, DOI [arXiv:1705.09792, DOI 10.48550/ARXIV.1705.09792]
   Tsang PWM, 2018, PHOTONICS RES, V6, P837, DOI 10.1364/PRJ.6.000837
   Wang F, 2021, OPT EXPRESS, V29, P35442, DOI 10.1364/OE.435966
   Wu JC, 2021, OPT LETT, V46, P2908, DOI 10.1364/OL.425485
   Xiao JS, 2022, J OPT SOC AM A, V39, pA15, DOI 10.1364/JOSAA.440464
   Yang R, 2008, IEEE T VIS COMPUT GR, V14, P84, DOI 10.1109/70410
   Zhang H, 2016, APPL OPTICS, V55, pA154, DOI 10.1364/AO.55.00A154
   Zhang WH, 2020, OPT EXPRESS, V28, P39916, DOI 10.1364/OE.413636
   Zhang WH, 2020, OPT LETT, V45, P1543, DOI 10.1364/OL.385553
   Zhong C., 2022, CCNN-CGH
   Zhou TK, 2021, NAT PHOTONICS, V15, P367, DOI 10.1038/s41566-021-00796-w
NR 51
TC 1
Z9 1
U1 2
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3709
EP 3718
DI 10.1109/TVCG.2023.3239670
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700006
PM 37022034
DA 2024-08-05
ER

PT J
AU Shen, HW
   Kiyokawa, K
AF Shen, Han-Wei
   Kiyokawa, Kiyoshi
TI Message from the Editor-in-Chief and from the Associate Editor-in-Chief
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
AB Welcome to the <italic>13th IEEE Transactions on Visualization and Computer Graphics (TVCG)</italic> special issue on IEEE Virtual Reality and 3D User Interfaces. This volume contains a total of 80 full papers selected for and presented at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR 2024), held in Orlando, Florida, USA, from March 16 to 21, 2024.
C1 [Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
   [Kiyokawa, Kiyoshi] Nara Inst Sci & Technol, Ikoma, Japan.
C3 University System of Ohio; Ohio State University; Nara Institute of
   Science & Technology
RP Shen, HW (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM shen.94@osu.edu; kiyo@is.naist.jp
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 0viii
EP 0viii
DI 10.1109/TVCG.2024.3369809
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400004
OA Bronze
DA 2024-08-05
ER

PT J
AU Hong, JY
   Maciejewski, R
   Trubuil, A
   Isenberg, T
AF Hong, Jiayi
   Maciejewski, Ross
   Trubuil, Alain
   Isenberg, Tobias
TI Visualizing and Comparing Machine Learning Predictions to Improve
   Human-AI Teaming on the Example of Cell Lineage
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cell lineage; comparing ML predictions; human -AI teaming; machine
   learning; plant biology; visual analytics; visualization
ID DIVISION; ANALYTICS; PLATFORM
AB We visualize the predictions of multiple machine learning models to help biologists as they interactively make decisions about cell lineage-the development of a (plant) embryo from a single ovum cell. Based on a confocal microscopy dataset, traditionally biologists manually constructed the cell lineage, starting from this observation and reasoning backward in time to establish their inheritance. To speed up this tedious process, we make use of machine learning (ML) models trained on a database of manually established cell lineages to assist the biologist in cell assignment. Most biologists, however, are not familiar with ML, nor is it clear to them which model best predicts the embryo's development. We thus have developed a visualization system that is designed to support biologists in exploring and comparing ML models, checking the model predictions, detecting possible ML model mistakes, and deciding on the most likely embryo development. To evaluate our proposed system, we deployed our interface with six biologists in an observational study. Our results show that the visual representations of machine learning are easily understandable, and our tool, LineageD+, could potentially increase biologists' working efficiency and enhance the understanding of embryos.
C1 [Hong, Jiayi; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85281 USA.
   [Trubuil, Alain] Univ Paris Saclay, INRAE, F-69100 Villeurbanne, France.
   [Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, F-91120 Palaiseau, France.
C3 Arizona State University; Arizona State University-Tempe; Universite
   Paris Cite; INRAE; Universite Paris Saclay; Universite Paris Saclay;
   Centre National de la Recherche Scientifique (CNRS); Institut
   Polytechnique de Paris; Ecole Polytechnique; Universite Paris Cite;
   Inria
RP Isenberg, T (corresponding author), Univ Paris Saclay, CNRS, Inria, F-91120 Palaiseau, France.
EM jiayi.hong@hotmail.com; rmacieje@asu.edu; alain.trubuil@inra.fr;
   tobias.isenberg@inria.fr
RI Isenberg, Tobias/A-7575-2008
OI Isenberg, Tobias/0000-0001-7953-8644; Hong, Jiayi/0000-0002-1332-5045
FU Inria#x0027;s Naviscope Project
FX No Statement Available
CR [Anonymous], 2022, HUMAN AI TEAMING STA, DOI [10.17226/26355, DOI 10.17226/26355]
   Bajusz D, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/s13321-015-0069-3
   Besson S, 2011, P NATL ACAD SCI USA, V108, P6294, DOI 10.1073/pnas.1011866108
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burkart N, 2021, J ARTIF INTELL RES, V70, P245
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Dietvorst BJ, 2018, MANAGE SCI, V64, P1155, DOI 10.1287/mnsc.2016.2643
   Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863
   Endsley MR, 2022, J COGN ENG DECIS MAK, V16, P179, DOI 10.1177/15553434221133288
   Gil Y, 2019, PROCEEDINGS OF IUI 2019, P614, DOI 10.1145/3301275.3302324
   Harper B., 1993, P 1 ANN MIDATLANTIC, P224
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hong JY, 2022, COMPUT GRAPH FORUM, V41, P195, DOI 10.1111/cgf.14533
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Leggio B, 2019, bioRxiv, DOI [10.1101/785337, 10.1101/785337, DOI 10.1101/785337]
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Martinez P, 2018, PLANT CELL, V30, P2255, DOI 10.1105/tpc.18.00401
   Minc N, 2012, TRENDS CELL BIOL, V22, P193, DOI 10.1016/j.tcb.2012.01.003
   Mohammed R, 2020, INT CONF INFORM COMM, P243, DOI 10.1109/ICICS49469.2020.239556
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Pagendarm H.-G., 1994, PROC EUROGRAPHICS WO, P95
   Patton M. Q., 1990, QUALITATIVE EVALUATI, DOI DOI 10.1002/NUR.4770140111
   Pavlopoulos GA, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-104
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Pierre A, 2016, DEV CELL, V39, P667, DOI 10.1016/j.devcel.2016.11.018
   Rosset A, 2004, J DIGIT IMAGING, V17, P205, DOI 10.1007/s10278-004-1014-6
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Salvador-Martínez I, 2021, NUCLEIC ACIDS RES, V49, pW80, DOI 10.1093/nar/gkab325
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Schroeder WJ, 1996, IEEE VISUAL, P93, DOI 10.1109/VISUAL.1996.567752
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Seo J, 2002, COMPUTER, V35, P80
   Siau K., 2018, Cutter Business Technology Journal, V31, P47
   Speckmann B, 2010, IEEE T VIS COMPUT GR, V16, P881, DOI 10.1109/TVCG.2010.180
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sugawara K, 2022, ELIFE, V11, DOI [10.7554/eLife.69380, 10.7554/eLife.69380.sa1, 10.7554/eLife.69380.sa2]
   Tam GKL, 2017, IEEE T VIS COMPUT GR, V23, P71, DOI 10.1109/TVCG.2016.2598829
   Tinevez JY, 2017, METHODS, V115, P80, DOI 10.1016/j.ymeth.2016.09.016
   Woodring J, 2006, IEEE T VIS COMPUT GR, V12, P909, DOI 10.1109/TVCG.2006.164
NR 47
TC 1
Z9 1
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1956
EP 1969
DI 10.1109/TVCG.2023.3302308
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500003
PM 37665712
OA Green Submitted
DA 2024-08-05
ER

PT J
AU He, TY
   Zhong, YY
   Isenberg, P
   Isenberg, T
AF He, Tingying
   Zhong, Yuanyang
   Isenberg, Petra
   Isenberg, Tobias
TI Design Characterization for Black-and-White Textures in Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Shape; Image color analysis; Bars;
   Encoding; Electronic mail; Aesthetics; textures; icons; black and white;
   visualization; visual representations; categorical data; design;
   perception
ID PERCEPTION; FEATURES; STATISTICS; ELEMENTS; TEXTONS
AB We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures. Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings. We specifically study how to use what we call geometric and iconic textures. Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories. We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters. 30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps. We then had 150 participants rate these designs for aesthetics. Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart.
C1 [He, Tingying; Isenberg, Petra; Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
   [Zhong, Yuanyang] Tencent Technol Shenzhen Co Ltd, Shenzhen, Peoples R China.
C3 Universite Paris Cite; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Saclay; Inria; Tencent
RP He, TY (corresponding author), Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
EM tingying.he@inria.fr; zoniaczhong@tencent.com; petra.isenberg@inria.fr;
   tobias.isenberg@inria.fr
RI He, Tingying/KHW-4844-2024; Isenberg, Tobias/A-7575-2008
OI Isenberg, Petra/0000-0002-2948-6417; He, Tingying/0000-0002-9670-5587;
   Isenberg, Tobias/0000-0001-7953-8644
CR AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   Barla P, 2006, COMPUT GRAPH FORUM, V25, P663, DOI 10.1111/j.1467-8659.2006.00986.x
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bertin J., 1998, Semiologie Graphique, V3rd
   Bertin J., 1983, SEMIOLOGY GRAPHICS D
   Besançon L, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3310432
   Blascheck T, 2023, IEEE PAC VIS SYMP, P187, DOI 10.1109/PacificVis56936.2023.00028
   Borgo R., 2013, P EUR, P39, DOI [DOI 10.2312/CONF/EG2013/STARS/039-063, 10.2312/CONF/EG2013/STARS/039-063]
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Brinton W. C., 1939, Graphic Presentation
   Brinton W. C., 1914, ENG MAGAZINE CO
   Brodatz P., 1966, Textures: A Photographic Album for Artists and Designers, V2
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Chen M, 2013, SYNTHESE, V190, P3421, DOI 10.1007/s11229-012-0183-y
   Cho RY, 2000, PERCEPT PSYCHOPHYS, V62, P735, DOI 10.3758/BF03206920
   CLEVELAND WS, 1985, SCIENCE, V229, P828, DOI 10.1126/science.229.4716.828
   Cockburn A, 2020, COMMUN ACM, V63, P70, DOI 10.1145/3360311
   Cumming G., 2012, UNDERSTANDING NEW ST, DOI DOI 10.4324/9780203807002
   Data visualization society, Global non-profit organization for data visualization practitioners and enthusiasts
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Goffin P, 2014, IEEE T VIS COMPUT GR, V20, P2291, DOI 10.1109/TVCG.2014.2346435
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Hawkins J.K., 1970, Picture processing and psychopictorics, P347
   He Tingying, 2023, IEEE Trans Vis Comput Graph, V29, P363, DOI 10.1109/TVCG.2022.3209390
   Healey CG, 1998, VISUALIZATION '98, PROCEEDINGS, P111, DOI 10.1109/VISUAL.1998.745292
   Higgins J., 2004, An Introduction to Modern Nonparametric Statistics
   Hutchinson H., 2003, P SIGCHI C HUM FACT, P17, DOI 10.1145/642611.642616
   Icons8, Website and icons database
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   JULESZ B, 1981, BIOL CYBERN, V41, P131, DOI 10.1007/BF00335367
   JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34
   JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x
   JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391
   Julesz B, 1962, IRE Transactions on Information Theory, V8, P84, DOI [DOI 10.1109/TIT.1962.1057698, 10.1109/TIT.1962.1057698]
   Kosslyn S. M., 2006, Graph Design for the Eye and Mind, DOI [10.1093/acprof:oso/9780195311846.001.0001, DOI 10.1093/ACPROF:OSO/9780195311846.001.0001]
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Martín D, 2017, COMPUT GRAPH-UK, V67, P24, DOI 10.1016/j.cag.2017.05.001
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Neurath Otto., 2010, From Hieroglyphics to Isotype: A Visual Autobiography
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   Salisbury M. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P101, DOI 10.1145/192161.192185
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Ware C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P203, DOI 10.1145/142750.142791
   Ware C., 2020, Information Visualization: Perception for Design, Vfourth, DOI DOI 10.1016/C2016-0-02395-1
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhong Y., 2020, POSTERS IEEE VIS
NR 53
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1019
EP 1029
DI 10.1109/TVCG.2023.3326941
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500114
PM 37883265
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Piccolotto, N
   Bögl, M
   Muehlmann, C
   Nordhausen, K
   Filzmoser, P
   Schmidt, J
   Miksch, S
AF Piccolotto, Nikolaus
   Boegl, Markus
   Muehlmann, Christoph
   Nordhausen, Klaus
   Filzmoser, Peter
   Schmidt, Johanna
   Miksch, Silvia
TI Data Type Agnostic Visual Sensitivity Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; parameter space analysis; sensitivity analysis;
   spatial blind source separation
ID LARGE-SCALE SYSTEMS; UNCERTAINTY ANALYSIS; SPACE; EXPLORATION;
   ANALYTICS; VISUALIZATION
AB Modern science and industry rely on computational models for simulation, prediction, and data analysis. Spatial blind source separation (SBSS) is a model used to analyze spatial data. Designed explicitly for spatial data analysis, it is superior to popular non-spatial methods, like PCA. However, a challenge to its practical use is setting two complex tuning parameters, which requires parameter space analysis. In this paper, we focus on sensitivity analysis (SA). SBSS parameters and outputs are spatial data, which makes SA difficult as few SA approaches in the literature assume such complex data on both sides of the model. Based on the requirements in our design study with statistics experts, we developed a visual analytics prototype for data type agnostic visual sensitivity analysis that fits SBSS and other contexts. The main advantage of our approach is that it requires only dissimilarity measures for parameter settings and outputs (Fig. 1). We evaluated the prototype heuristically with visualization experts and through interviews with two SBSS experts. In addition, we show the transferability of our approach by applying it to microclimate simulations. Study participants could confirm suspected and known parameter-output relations, find surprising associations, and identify parameter subspaces to examine in the future. During our design study and evaluation, we identified challenging future research opportunities.
C1 [Piccolotto, Nikolaus; Boegl, Markus; Muehlmann, Christoph; Filzmoser, Peter; Miksch, Silvia] TU Wien, Vienna, Austria.
   [Nordhausen, Klaus] Univ Jyvaskyla, Jyvaskyla, Finland.
   [Schmidt, Johanna] VRVis GmbH, Vienna, Austria.
C3 Technische Universitat Wien; University of Jyvaskyla
RP Piccolotto, N (corresponding author), TU Wien, Vienna, Austria.
EM nikolaus.piccolotto@tuwien.ac.at; markus.bogl@tuwien.ac.at;
   christoph.muehlmann@tuwien.ac.at; klaus.k.nordhausen@jyu.fi;
   peter.filzmoser@tuwien.ac.at; johanna.schmidt@vrvis.at;
   silvia.miksch@tuwien.ac.at
RI Nordhausen, Klaus/A-8644-2008
OI Nordhausen, Klaus/0000-0002-3758-8501; Bogl, Markus/0000-0002-8337-4774;
   Miksch, Silvia/0000-0003-4427-5703; Piccolotto,
   Nikolaus/0000-0001-6876-6502; Muehlmann, Christoph/0000-0001-7330-8434;
   Schmidt, Johanna/0000-0002-9638-6344
FU Austrian Science Fund (FWF)
FX No Statement Available
CR Abuzuraiq A. M., 2020, RE ANTHROPOCENE PROC, V1, P485, DOI DOI 10.52842/CONF.CAADRIA.2020.1.4852
   Bachoc F, 2020, BIOMETRIKA, V107, P627, DOI 10.1093/biomet/asz079
   Bar-Joseph Z, 2001, Bioinformatics, V17, pS22, DOI [DOI 10.1093/BIOINFORMATICS/17.SUPPL_1.S22, 10.1093/bioinformatics/17.suppl1.S22, 10.1093/bioinformatics/17.suppl_1.s22]
   Beham M, 2014, IEEE T VIS COMPUT GR, V20, P1693, DOI 10.1109/TVCG.2014.2346626
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Blanch R, 2015, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2015.7156353
   Borgonovo E, 2016, EUR J OPER RES, V248, P869, DOI 10.1016/j.ejor.2015.06.032
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Cacuci DG, 2004, NUCL SCI ENG, V147, P204, DOI 10.13182/04-54CR
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cibulski L., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2022.31808992
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   de Leeuw J., 2005, Encyclopedia of Statistics in Behavioral Science, pbsa612, DOI DOI 10.1002/0470013192.BSA6125
   Desai R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300599
   Doraiswamy H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818134
   Eichner C, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.13894
   Galili T, 2015, BIOINFORMATICS, V31, P3718, DOI 10.1093/bioinformatics/btv428
   Günther T, 2016, COMPUT GRAPH FORUM, V35, P455, DOI 10.1111/cgf.12846
   Gutierrez J.M., 2021, CLIMATE CHANGE 2021, DOI [10.1017/9781009157896.021, DOI 10.1017/9781009157896.021]
   HAMBY DM, 1994, ENVIRON MONIT ASSESS, V32, P135, DOI 10.1007/BF00547132
   Hazarika S, 2020, IEEE T VIS COMPUT GR, V26, P34, DOI 10.1109/TVCG.2019.2934591
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Ilmonen P, 2010, LECT NOTES COMPUT SC, V6365, P229, DOI 10.1007/978-3-642-15995-4_29
   Ionescu-Bujor M, 2004, NUCL SCI ENG, V147, P189, DOI 10.13182/NSE03-105CR
   Iooss B., 2015, Uncertainty Management in Simulation-Optimization of Complex Systems: Algorithms And Applications, V59, P101, DOI [DOI 10.1007/978-1-4899-7547-85, 10.1007/978-1-4899-7547-8_5, DOI 10.1007/978-1-4899-7547-8_5, 10.1007/978-1-4899-7547-85]
   Jankun-Kelly TJ, 2000, IEEE VISUAL, P69, DOI 10.1109/VISUAL.2000.885678
   Jeon H, 2022, IEEE T VIS COMPUT GR, V28, P551, DOI 10.1109/TVCG.2021.3114833
   Kanal L. N., 1982, Handbook of Statistics, V2, P267, DOI [DOI 10.1016/S0169-7161(82)02015-X, 10.1016/s0169-7161(82)02015-x3, DOI 10.1016/S0169-7161(82)02015-X3]
   Knittel J, 2021, IEEE T VIS COMPUT GR, V27, P1374, DOI 10.1109/TVCG.2020.3030420
   Koyama Yuki, 2014, P 27 ANN ACM S US IN, P65, DOI [DOI 10.1145/2642918.2647386, 10.1145/2642918.26473862, DOI 10.1145/2642918.26473862]
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   L'Yi S, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S11-S5
   Ligmann-Zielinska A, 2013, INT J GEOGR INF SCI, V27, P1764, DOI 10.1080/13658816.2013.782613
   Lilburne L, 2009, INT J GEOGR INF SCI, V23, P151, DOI 10.1080/13658810802094995
   Liu Y., 2010, 2010 IEEE 10th International Conference on Data Mining ICDM, P911, DOI 10.1109/icdm.2010.35
   Luboschik M, 2015, COMPUT GRAPH FORUM, V34, P421, DOI 10.1111/cgf.12654
   Luboschik M, 2014, COMPUT GRAPH-UK, V39, P37, DOI 10.1016/j.cag.2013.09.004
   Marks J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P389, DOI 10.1145/258734.258887
   Marrel A, 2011, ENVIRONMETRICS, V22, P383, DOI 10.1002/env.1071
   Matkovic K, 2017, LECT NOTES COMPUT SC, V10410, P199, DOI 10.1007/978-3-319-66808-6_14
   MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.1093/biomet/37.1-2.17
   Muehlmann C, 2022, SPAT STAT-NETH, V47, DOI 10.1016/j.spasta.2021.100574
   Nordhausen K, 2015, MATH GEOSCI, V47, P753, DOI 10.1007/s11004-014-9559-5
   Orban D, 2019, IEEE T VIS COMPUT GR, V25, P256, DOI 10.1109/TVCG.2018.2865051
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Piccolotto N, 2022, COMPUT GRAPH FORUM, V41, P157, DOI 10.1111/cgf.14530
   Piccolotto N., 2023, Computer Graphics Forum, DOI DOI 10.1111/CGF.147852,3
   Piccolotto N, 2022, VIS INFORM, V6, P51, DOI 10.1016/j.visinf.2022.10.002
   Raimbault J, 2019, JASSS-J ARTIF SOC S, V22, DOI 10.18564/jasss.4136
   Rojo IB, 2018, COMPUT GRAPH FORUM, V37, P289, DOI 10.1111/cgf.13420
   Saltelli A, 2002, RISK ANAL, V22, P579, DOI 10.1111/0272-4332.00040
   Saltelli A., 2007, Global Sensitivity Analysis: The Primer, DOI DOI 10.1002/97804707251842
   Saltelli A, 2019, ENVIRON MODELL SOFTW, V114, P29, DOI 10.1016/j.envsoft.2019.01.012
   Schulz A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073688
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Seo J, 2002, COMPUTER, V35, P80
   Sobol I. Y. M., 1990, MATEM MOD, V2, P112, DOI DOI 10.18287/0134-2452-2015-39-4-459-461
   Steed CA, 2013, COMPUT GEOSCI-UK, V61, P71, DOI 10.1016/j.cageo.2013.07.025
   Vuckovic M, 2022, INFORMATION, V13, DOI 10.3390/info13010007
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wattenberg M., 2016, Distill, V1, pe2
   Weissenböck J, 2016, IEEE CONF VIS ANAL, P101, DOI 10.1109/VAST.2016.7883516
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [10.1007/s40745-015-0040-1, DOI 10.1007/S40745-015-0040-1]
   Yang HY, 2021, COMPUT GRAPH FORUM, V40, P275, DOI 10.1111/cgf.14306
   Zhenyu Guo, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P131, DOI 10.1109/VAST.2011.6102450
NR 72
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1106
EP 1116
DI 10.1109/TVCG.2023.3327203
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500029
PM 37922175
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Troidl, J
   Warchol, S
   Choi, J
   Matelsky, J
   Dhanyasi, N
   Wang, XY
   Wester, B
   Wei, DL
   Lichtman, JW
   Pfister, H
   Beyer, J
AF Troidl, Jakob
   Warchol, Simon
   Choi, Jinhan
   Matelsky, Jordan
   Dhanyasi, Nagaraju
   Wang, Xueying
   Wester, Brock
   Wei, Donglai
   Lichtman, Jeff W.
   Pfister, Hanspeter
   Beyer, Johanna
TI VIMO - Visual Analysis of Neuronal Connectivity Motifs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neurons; Visualization; Three-dimensional displays; Synapses;
   Morphology; Brain; Rendering (computer graphics); Visual motif analysis;
   Focus&Context; Scientific visualization; Neuroscience; Connectomics
ID EXPLORATION; TOOL
AB Recent advances in high-resolution connectomics provide researchers with access to accurate petascale reconstructions of neuronal circuits and brain networks for the first time. Neuroscientists are analyzing these networks to better understand information processing in the brain. In particular, scientists are interested in identifying specific small network motifs, i.e., repeating subgraphs of the larger brain network that are believed to be neuronal building blocks. Although such motifs are typically small (e.g., 2-6 neurons), the vast data sizes and intricate data complexity present significant challenges to the search and analysis process. To analyze these motifs, it is crucial to review instances of a motif in the brain network and then map the graph structure to detailed 3D reconstructions of the involved neurons and synapses. We present Vimo, an interactive visual approach to analyze neuronal motifs and motif chains in large brain networks. Experts can sketch network motifs intuitively in a visual interface and specify structural properties of the involved neurons and synapses to query large connectomics datasets. Motif instances (MIs) can be explored in high-resolution 3D renderings. To simplify the analysis of MIs, we designed a continuous focus&context metaphor inspired by visual abstractions. This allows users to transition from a highly-detailed rendering of the anatomical structure to views that emphasize the underlying motif structure and synaptic connectivity. Furthermore, Vimo supports the identification of motif chains where a motif is used repeatedly (e.g., 2-4 times) to form a larger network structure. We evaluate Vimo in a user study and an in-depth case study with seven domain experts on motifs in a large connectome of the fruit fly, including more than 21,000 neurons and 20 million synapses. We find that Vimo enables hypothesis generation and confirmation through fast analysis iterations and connectivity highlighting.
C1 [Troidl, Jakob; Warchol, Simon; Pfister, Hanspeter; Beyer, Johanna] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Dhanyasi, Nagaraju; Wang, Xueying; Lichtman, Jeff W.] Harvard Univ, Dept Cellular& Mol Biol, Cambridge, MA USA.
   [Matelsky, Jordan; Wester, Brock] Johns Hopkins Univ, Appl Phys Lab, Baltimore, MD USA.
   [Matelsky, Jordan] Univ Penn, Dept Bioengn, Philadelphia, PA USA.
   [Choi, Jinhan; Wei, Donglai] Boston Coll, Dept Comp Sci, Chestnut Hill, MA USA.
C3 Harvard University; Harvard University; Johns Hopkins University; Johns
   Hopkins University Applied Physics Laboratory; University of
   Pennsylvania; Boston College
RP Troidl, J (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
EM jakob.troidl@gmail.com; simonwarchol@g.harvard.edu; jinhan.choi@bc.edu;
   Jordan.Matelsky@jhuapl.edu; nagarajudhanyasi@gmail.com;
   snowsd@gmail.com; brock.wester@jhuapl.edu; donglai.wei@bc.edu;
   jeff@mcb.harvard.edu; pfister@g.harvard.edu; jbeyer@g.harvard.edu
OI Pfister, Hanspeter/0000-0002-3620-2582; Warchol,
   Simon/0000-0001-9067-6888
FU NSF
FX No Statement Available
CR Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Bae J. Alexander, 2021, BioRxiv, P2021
   Beyer J, 2022, COMPUT GRAPH FORUM, V41, P573, DOI 10.1111/cgf.14574
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Buhl E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80103-9
   Cakmak E., 2022, arXiv
   Cao Y., 2010, P 18 ACM INT C MULT, P1605, DOI 10.1145/1873951.1874299
   Choi J., 2023, Neuprint Motif Analysis Integration
   Choi J., 2023, Vimo sketches codebase, DOI VCG/vimo-sketches2,8
   Choi J, 2021, INT WOUND J, V18, P647, DOI 10.1111/iwj.13566
   Cook S. A., 1971, Proceedings of the 3rd annual ACM symposium on theory of computing, P151
   Cuenca E, 2022, IEEE T VIS COMPUT GR, V28, P1634, DOI 10.1109/TVCG.2021.3067820
   Dorkenwald S., 2023, Neuronal wiring diagram of an adult brain, DOI [10.1101/2023.06.27.5466561, DOI 10.1101/2023.06.27.5466561]
   Dorkenwald Sven, 2023, bioRxiv, DOI 10.1101/2023.07.26.550598
   Dorkenwald S, 2022, NAT METHODS, V19, P119, DOI 10.1038/s41592-021-01330-0
   Dunne C., 2013, P SIGCHI C HUM FACT, P3247, DOI DOI 10.1145/2470654.2466444
   Egenhofer MJ, 1997, J VISUAL LANG COMPUT, V8, P403, DOI 10.1006/jvlc.1997.0054
   Francis N, 2018, INT CONF MANAGE DATA, P1433, DOI 10.1145/3183713.3190657
   Galili DS, 2022, CURR OPIN INSECT SCI, V54, DOI 10.1016/j.cois.2022.100968
   Ganglberger F, 2022, COMPUT GRAPH-UK, V105, P12, DOI 10.1016/j.cag.2022.04.014
   Gonda F, 2021, COMPUT GRAPH FORUM, V40, P447, DOI 10.1111/cgf.14320
   Haber A., 2023, Neuroscience, DOI [10.1101/2023.03.15.5326111, DOI 10.1101/2023.03.15.5326111]
   Harth P., 2022, EUR WORKSH VIS COMP, DOI [10.2312/vcbm.202211942, DOI 10.2312/VCBM.202211942]
   Hu P, 2023, IEEE T PATTERN ANAL, V45, P3877, DOI 10.1109/TPAMI.2022.3177356
   Hulse BK, 2021, ELIFE, V10, DOI 10.7554/eLife.66039
   Itzkovitz S, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.026127
   Kashani ZRM, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-318
   Li F, 2020, ELIFE, V9, DOI 10.7554/eLife.62576
   Lin A., 2023, Network Statistics of the WholeBrain Connectome of Drosophila, DOI [10.1101/2023., DOI 10.1101/2023]
   Maitin-Shepard J., 2023, FlyEM Neuroglancer Rendering
   Maitin-Shepard Jeremy, 2021, Zenodo, DOI 10.5281/ZENODO.5573294
   Mannino M, 2018, INT CONF MANAGE DATA, P1741, DOI 10.1145/3183713.3193547
   Matejek B, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15027-7
   Matelsky JK, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91025-5
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Pienta R, 2018, IEEE T VIS COMPUT GR, V24, P215, DOI 10.1109/TVCG.2017.2744898
   Plaza SM, 2022, FRONT NEUROINFORM, V16, DOI 10.3389/fninf.2022.896292
   Ribeiro P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3433652
   Bolívar MPR, 2015, PUB ADMIN INF TECH, V8, P1, DOI 10.1007/978-3-319-03167-5_1
   Saalfeld S, 2009, BIOINFORMATICS, V25, P1984, DOI 10.1093/bioinformatics/btp266
   Saff EB, 1997, MATH INTELL, V19, P5, DOI 10.1007/BF03024331
   Scheffer L. K., 2020, Available Brain regions in the hemibrain dataset
   Scheffer LK, 2020, ELIFE, V9, DOI 10.7554/eLife.57443
   Schlegel P, 2021, ELIFE, V10, DOI 10.7554/eLife.66018
   Schlegel Philipp, 2021, Zenodo, DOI 10.5281/ZENODO.5710143
   Schneider-Mizell Casey M, 2024, bioRxiv, DOI 10.1101/2023.01.23.525290
   Schreiber F, 2005, BIOINFORMATICS, V21, P3572, DOI 10.1093/bioinformatics/bti556
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shapson-Coe A, 2021, bioRxiv, DOI [10.1101/2021.05.29.446289, 10.1101/2021.05.29.446289v4, DOI 10.1101/2021.05.29.446289V4, 10.1101/2021.05.29.446289, DOI 10.1101/2021.05.29.446289]
   Sorger J, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P73, DOI 10.1109/BioVis.2013.6664349
   Sporns O, 2004, PLOS BIOL, V2, P1910, DOI 10.1371/journal.pbio.0020369
   Steinberger M, 2011, IEEE T VIS COMPUT GR, V17, P2249, DOI 10.1109/TVCG.2011.183
   Takemura S.-y., 2023, Neuroscience, DOI [10.1101/2023.06.05.543757, DOI 10.1101/2023.06.05.543757]
   Troidl J., 2023, Vimo Example Motifs Sketches, DOI jakobtroidl/neuronal-motifs/tree/main/example_motifs5,8,9
   Troidl J., 2023, Vimo Codebase
   Troidl J, 2022, COMPUT GRAPH FORUM, V41, P183, DOI 10.1111/cgf.14532
   Turner NL, 2022, CELL, V185, P1082, DOI 10.1016/j.cell.2022.01.023
   Udvary D, 2022, CELL REP, V39, DOI 10.1016/j.celrep.2022.110677
   Vohra S. K., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32436682, DOI 10.1109/TVCG.2023.32436682]
   Weaver Charlotte, 2014, Zenodo, DOI 10.5281/ZENODO.11290
   Winding M, 2023, SCIENCE, V379, P995, DOI 10.1126/science.add9330
NR 62
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 748
EP 758
DI 10.1109/TVCG.2023.3327388
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500039
PM 37883279
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Walchshofer, C
   Dhanoa, V
   Streit, M
   Meyer, M
AF Walchshofer, Conny
   Dhanoa, Vaishal
   Streit, Marc
   Meyer, Miriah
TI Transitioning to a Commercial Dashboarding System: Socio-Technical
   Observations and Opportunities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interview study; socio-technical challenges; visual analytics
ID VISUAL ANALYTICS; VISUALIZATION; DISCOVERY; DESIGN
AB Many long-established, traditional manufacturing businesses are becoming more digital and data-driven to improve their production. These companies are embracing visual analytics in these transitions through their adoption of commercial dashboarding systems. Although a number of studies have looked at the technical challenges of adopting these systems, very few have focused on the socio-technical issues that arise. In this paper, we report on the results of an interview study with 17 participants working in a range of roles at a long-established, traditional manufacturing company as they adopted Microsoft Power BI. The results highlight a number of socio-technical challenges the employees faced, including difficulties in training, using and creating dashboards, and transitioning to a modern digital company. Based on these results, we propose a number of opportunities for both companies and visualization researchers to improve these difficult transitions, as well as opportunities for rethinking how we design dashboarding systems for real-world use.
C1 [Walchshofer, Conny; Streit, Marc] Johannes Kepler Univ Linz, Linz, Austria.
   [Dhanoa, Vaishal] Pro 2 Future GmbH, Graz, Austria.
   [Meyer, Miriah] Linkoping Univ, Linkoping, Sweden.
C3 Johannes Kepler University Linz; Linkoping University
RP Walchshofer, C (corresponding author), Johannes Kepler Univ Linz, Linz, Austria.
EM conny.walchshofer@jku.at; vaishali.dhanoa@pro2future.at;
   marc.streit@jku.at; miriah.meyer@liu.se
OI Walchshofer, Conny/0000-0003-3942-8445; Streit,
   Marc/0000-0001-9186-2092; Dhanoa, Vaishali/0000-0002-0493-8616
FU Wallenberg AI, Autonomous Systems and Software Program (WASP)
FX No Statement Available
CR Ahlberg C., 1996, SIGMOD Record, V25, P25, DOI 10.1145/245882.245893
   Akbaba D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581168
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bako Hannah K, 2023, IEEE Trans Vis Comput Graph, V29, P1048, DOI 10.1109/TVCG.2022.3209490
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Baskarada S, 2017, PROGRAM-ELECTRON LIB, V51, P65, DOI 10.1108/PROG-07-2016-0053
   Batch A, 2018, IEEE T VIS COMPUT GR, V24, P278, DOI 10.1109/TVCG.2017.2743990
   Behrisch M., 2018, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2018.28599732, DOI 10.1109/TVCG.2018.28599732]
   Burns A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581524
   Cao Y.-R., 2020, ACM CHI C HUM FACT C, P1, DOI [10.1145/3334480.33830579, DOI 10.1145/3334480.33830579]
   Chen Q, 2022, Arxiv, DOI arXiv:2206.12118
   Crisan A., 2021, ACM CHI C HUM FACT C, P1, DOI [10.1145/3411764.34457752, DOI 10.1145/3411764.34457752]
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   Daradkeh MK, 2019, INFORM TECHNOL PEOPL, V32, P668, DOI 10.1108/ITP-10-2017-0359
   Davenport T., 2020, Harvard Data Science Review, DOI [10.1162/99608f92.55546b4a9, DOI 10.1162/99608F92.55546B4A9]
   Dhanoa V, 2022, COMPUT GRAPH FORUM, V41, P501, DOI 10.1111/cgf.14558
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Eick SG, 2000, IEEE T VIS COMPUT GR, V6, P44, DOI 10.1109/2945.841120
   Elias M, 2011, LECT NOTES COMPUT SC, V6949, P274, DOI 10.1007/978-3-642-23768-3_23
   Fisher Danyel, 2012, Interactions, V19, P50, DOI 10.1145/2168931.2168943
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Hall BD, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545614
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kim M, 2016, PROC INT CONF SOFTW, P96, DOI 10.1145/2884781.2884783
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Liu J., 2019, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2019.29345932,8, DOI 10.1109/TVCG.2019.29345932,8]
   Liu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376533
   Monforte J., 2021, Methods in Psychology, V5, DOI [10.1016/j.metip.2021.100082, DOI 10.1016/J.METIP.2021.100082]
   Mörth E, 2022, Arxiv, DOI [arXiv:2207.03616, 10.48550/ARXIV.2207.03616 9, DOI 10.48550/ARXIV.2207.036169]
   Muller M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300356
   ONeil C., 2013, Doing Data Science: Straight Talk from the Frontline, V8, P9
   Parsons P, 2022, IEEE T VIS COMPUT GR, V28, P665, DOI 10.1109/TVCG.2021.3114959
   Parsons P, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P176, DOI 10.1109/VIS47514.2020.00042
   Perkhofer LM, 2019, J APPL ACCOUNT RES, V20, P497, DOI 10.1108/JAAR-10-2017-0114
   Riche N. H., 2018, Data-Driven Storytelling, P9
   Sallam S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517727
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Sedlmair M., 2010, PROC WORKSHOP TIME E, P79, DOI [DOI 10.1145/2110192.2110204, 10.1145/2110192.21102042,8, DOI 10.1145/2110192.21102042,8]
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Siu A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517678
   Stoiber Christina, 2021, VINCI 2021: The 14th International Symposium on Visual Information Communication and Interaction, DOI 10.1145/3481549.3481558
   Stoiber C., 2019, Visualization onboarding: Learning how to read and use visualizations, DOI [10.31219/osf.io/c38ab, DOI 10.31219/OSF.IO/C38AB]
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Storm M., 2020, Hawaii International Conference on System Sciences 2020, DOI [10.24251/HICSS.2020.663, DOI 10.24251/HICSS.2020.663]
   Streit M, 2019, BIOINFORMATICS, V35, P3140, DOI 10.1093/bioinformatics/btz009
   Tobiasz M, 2009, IEEE T VIS COMPUT GR, V15, P1065, DOI 10.1109/TVCG.2009.162
   Tory M., 2022, IEEE Computer Graphics and Applications, P1, DOI [10.1109/MCG.2021.31365451,2,8,9, DOI 10.1109/MCG.2021.31365451,2,8,9]
   Xu X., 2022, ACM CHI C HUM FACT C, P1, DOI [10.1145/3491102.35018969, DOI 10.1145/3491102.35018969]
   Youssef MA, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102827
   Zhang LS, 2012, IEEE CONF VIS ANAL, P173, DOI 10.1109/VAST.2012.6400554
   Zhang Y., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32094932, DOI 10.1109/TVCG.2022.32094932]
NR 62
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 381
EP 391
DI 10.1109/TVCG.2023.3326525
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500030
PM 37878440
OA hybrid
DA 2024-08-05
ER

PT J
AU Yan, L
   Liang, X
   Guo, HQ
   Wang, B
AF Yan, Lin
   Liang, Xin
   Guo, Hanqi
   Wang, Bei
TI TopoSZ: Preserving Topology in Error-Bounded Lossy Compression
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lossy compression; contour tree; topology preservation; topological data
   analysis; topology in visualization
ID CONTOUR TREES; SCALAR FIELDS; SIMPLIFICATION; VISUALIZATION; SYMMETRY
AB Existing error-bounded lossy compression techniques control the pointwise error during compression to guarantee the integrity of the decompressed data. However, they typically do not explicitly preserve the topological features in data. When performing post hoc analysis with decompressed data using topological methods, preserving topology in the compression process to obtain topologically consistent and correct scientific insights is desirable. In this paper, we introduce TopoSZ, an error-bounded lossy compression method that preserves the topological features in 2D and 3D scalar fields. Specifically, we aim to preserve the types and locations of local extrema as well as the level set relations among critical points captured by contour trees in the decompressed data. The main idea is to derive topological constraints from contour-tree-induced segmentation from the data domain, and incorporate such constraints with a customized error-controlled quantization strategy from the SZ compressor (version 1.4). Our method allows users to control the pointwise error and the loss of topological features during the compression process with a global error bound and a persistence threshold.
C1 [Yan, Lin] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Liang, Xin] Univ Kentucky, Lexington, KY USA.
   [Guo, Hanqi] Ohio State Univ, Columbus, OH USA.
   [Wang, Bei] Univ Utah, Salt Lake City, UT USA.
C3 United States Department of Energy (DOE); Argonne National Laboratory;
   University of Kentucky; University System of Ohio; Ohio State
   University; Utah System of Higher Education; University of Utah
RP Yan, L (corresponding author), Argonne Natl Lab, Lemont, IL 60439 USA.
EM lyan@anl.gov; xliang@uky.edu; guo.2154@osu.edu; beiwang@sci.utah.edu
RI ; Guo, Hanqi/ADW-4234-2022
OI Liang, Xin/0000-0002-0630-1600; Guo, Hanqi/0000-0001-7776-1834
FU DOE
FX No Statement Available
CR Abu-Mostafa YS, 2000, COMPUT MATH APPL, V39, P129, DOI 10.1016/S0898-1221(00)00119-X
   Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   [Anonymous], Energy exascale earth system model
   [Anonymous], 2004, IEEE Scientific Visualization Contest
   [Anonymous], 2016, IEEE Scientific Visualization Contest
   [Anonymous], 2014, Topological Methods in Data Analysis and Visualization III, Theory, Algorithms, and Applications, DOI [DOI 10.1007/978-3-319-04099, 10.1007/978-3-319-04099-8]
   Athawale TM, 2022, IEEE T VIS COMPUT GR, V28, P1955, DOI 10.1109/TVCG.2020.3022359
   Biwer C., 2019, Nyx cosmological simulation dataset, DOI [10.21227/zh6w-kt7212, DOI 10.21227/ZH6W-KT7212]
   Burtscher M, 2009, IEEE T COMPUT, V58, P18, DOI 10.1109/TC.2008.131
   Burtscher M, 2007, IEEE DATA COMPR CONF, P293
   Caldwell PM, 2019, J ADV MODEL EARTH SY, V11, P4095, DOI 10.1029/2019MS001870
   Cappello F, 2019, INT J HIGH PERFORM C, V33, P1201, DOI 10.1177/1094342019853336
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carr H, 2010, COMP GEOM-THEOR APPL, V43, P42, DOI 10.1016/j.comgeo.2006.05.009
   Chiang Y, 2003, COMPUT GRAPH FORUM, V22, P493, DOI 10.1111/1467-8659.00697
   Chow MM, 1997, VISUALIZATION '97 - PROCEEDINGS, P347, DOI 10.1109/VISUAL.1997.663902
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Computer Graphics Laboratory, ABOUT US
   Crawfis R., Tornado data set generator
   Di S, 2019, IEEE T PARALL DISTR, V30, P331, DOI 10.1109/TPDS.2018.2859932
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P2896, DOI 10.1109/TVCG.2013.131
   Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5
   Edelsbrunner H., 2003, P 19 ANN S COMP GEOM, P361, DOI [10.1145/777792.777846, DOI 10.1145/777792.777846]
   Edelsbrunner H., 2010, American Mathematical Society, V3, P12
   Engelke W., 2021, Topological Methods in Data Analysis and Visualization VI. Mathematics and Visualization, DOI [10.1109/TVCG.2014.23464341, DOI 10.1109/TVCG.2014.23464341]
   Gerber S, 2012, J STAT SOFTW, V50, P1
   Golaz JC, 2019, J ADV MODEL EARTH SY, V11, P2089, DOI 10.1029/2018MS001603
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   GZIP, ABOUT US
   HOWARD PG, 1992, INFORM PROCESS MANAG, V28, P749, DOI 10.1016/0306-4573(92)90066-9
   Ibarria L, 2003, COMPUT GRAPH FORUM, V22, P343, DOI 10.1111/1467-8659.00681
   Jayasankar U, 2021, J KING SAUD UNIV-COM, V33, P119, DOI 10.1016/j.jksuci.2018.05.006
   Kai Zhao, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P89, DOI 10.1145/3369583.3392688
   Lakshminarasimhan S, 2011, LECT NOTES COMPUT SC, V6852, P366, DOI 10.1007/978-3-642-23400-2_34
   Liang XD, 2022, IEEE T IND APPL, V58, P1843, DOI 10.1109/TIA.2022.3146103
   Liang X, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356193
   Liang X, 2020, IEEE PAC VIS SYMP, P81, DOI 10.1109/PacificVis48177.2020.6431
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Lohfink AP, 2020, COMPUT GRAPH FORUM, V39, P343, DOI 10.1111/cgf.13985
   Nilsson E., 2020, Levia, DOI [10.31219/osf.io/jqtua1, DOI 10.31219/OSF.IO/JQTUA1]
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Popinet S, 2004, J ATMOS OCEAN TECH, V21, P1575, DOI 10.1175/1520-0426(2004)021<1575:EANSOT>2.0.CO;2
   Popinet S., 2004, ClusterWorld, V2, P12
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Saikia H., 2015, TOPOLOGICAL METHODS, P121, DOI [10.1007/978-3-319-44684-4_7, DOI 10.1007/978-3-319-44684-4_7]
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Schneider J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P293, DOI 10.1109/VISUAL.2003.1250385
   Sohn BS, 2006, IEEE T VIS COMPUT GR, V12, P14, DOI 10.1109/TVCG.2006.16
   Soler M, 2018, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis.2018.00015
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Takahashi S, 2004, GRAPH MODELS, V66, P24, DOI 10.1016/j.gmod.2003.08.002
   Tao DW, 2017, INT PARALL DISTRIB P, P1129, DOI 10.1109/IPDPS.2017.115
   Thomas DM, 2014, IEEE T VIS COMPUT GR, V20, P2427, DOI 10.1109/TVCG.2014.2346332
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P2005, DOI 10.1109/TVCG.2012.228
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2023, IEEE T VIS COMPUT GR, V29, P3489, DOI 10.1109/TVCG.2022.3163349
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Zhang X., 2004, Technical report, P2
   Zhao K, 2021, PROC INT CONF DATA, P1643, DOI 10.1109/ICDE51399.2021.00145
   Zhenhuan Gong, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P239, DOI 10.1109/ICPP.2012.39
   Zstd, about us
NR 68
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1302
EP 1312
DI 10.1109/TVCG.2023.3326920
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500003
PM 37930917
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ye, HY
   Li, CH
   Li, Y
   Wang, CB
AF Ye, Huayuan
   Li, Chenhui
   Li, Yang
   Wang, Changbo
TI InvVis: Large-Scale Data Embedding for Invertible Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Steganography; Image restoration; Visualization;
   Image reconstruction; Metadata; QR codes; Information visualization;
   information steganography; invertible visualization; invertible neural
   network
ID IMAGES; INFORMATION
AB We present InvVis, a new approach for invertible visualization, which is reconstructing or further modifying a visualization from an image. InvVis allows the embedding of a significant amount of data, such as chart data, chart information, source code, etc., into visualization images. The encoded image is perceptually indistinguishable from the original one. We propose a new method to efficiently express chart data in the form of images, enabling large-capacity data embedding. We also outline a model based on the invertible neural network to achieve high-quality data concealing and revealing. We explore and implement a variety of application scenarios of InvVis. Additionally, we conduct a series of evaluation experiments to assess our method from multiple perspectives, including data embedding quality, data restoration accuracy, data encoding capacity, etc. The result of our experiments demonstrates the great potential of InvVis in invertible visualization.
C1 [Ye, Huayuan; Li, Chenhui; Li, Yang; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
C3 East China Normal University
RP Li, CH (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
EM huayuan221@gmail.com; chli@cs.ecnu.edu.cn; yli@cs.ecnu.edu.cn;
   cbwang@cs.ecnu.edu.cn
OI Wang, Changbo/0000-0001-8940-6418; Li, Chenhui/0000-0001-9835-2650; ye,
   huayuan/0009-0008-8208-2017
FU NSFC
FX No Statement Available
CR Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   Almohammad A., 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P215, DOI 10.1109/IPTA.2010.5586786
   Almohammad A, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P544, DOI 10.1109/ARES.2008.72
   Baluja S., 2017, Adv. Neural Inf. Process. Syst. (NIPS), V30, P2
   Bose R. C., 1960, Inf. Control., V3, P3
   Callahan S.P., 2006, P ACM SIGMOD 2006, P745, DOI [10.1145/1142473.1142574, DOI 10.1145/1142473.1142574]
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen Z., 2019, IEEE Trans. Visual. Comput. Graph., V26, P2
   Cheng Ka Leong, 2021, IEEECVF INT C COMPUT, P1991
   Choi J., 2019, COMPUT GRAPH FORUM, P2
   Delforouzi A, 2008, CIRC SYST SIGNAL PR, V27, P247, DOI 10.1007/s00034-008-9019-x
   Dinh L, 2015, Arxiv, DOI [arXiv:1410.8516, 10.48550/arXiv.1410.8516]
   Flower A., 2016, Behav. Modif., V40, P2
   Fridrich J., 2001, IEEE Multimed., V8, P2
   Fu Jiayun, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P2786, DOI 10.1145/3503161.3548286
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Guan ZY, 2023, IEEE T PATTERN ANAL, V45, P372, DOI 10.1109/TPAMI.2022.3141725
   Hota A., 2019, IEEE Trans. Visual. Comput. Graph., V26, P2
   ISO, 2015, ISO/IEC18004:2015, P4
   Jing JP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4713, DOI 10.1109/ICCV48922.2021.00469
   Kawaguchi E., 1999, SPIE, V3528, P2
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2018, Adv. Neural Inf. Process. Syst. (NIPS), V31, P6
   Liu X., 2019, arXiv
   Lu SP, 2021, PROC CVPR IEEE, P10811, DOI 10.1109/CVPR46437.2021.01067
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Moore F., 2017, Polynomial codes over certain finite fields, P3
   N. Earth Science Data Systems, Earthdata. 3
   Paszke A, 2019, ADV NEUR IN, V32
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Por LY, 2008, ELE COM ENG, P689
   Qin J., 2020, Math., V8, P2
   Savva M., 2011, P 24 ANN ACM S US IN, P2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh M, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 5: VISAPP, P309, DOI 10.5220/0010201203090318
   Song S., 2022, IEEE Trans. Visual. Comput. Graph., V1, P2
   Swanson MD, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P558, DOI 10.1109/ICIP.1997.638832
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WAVE D., Qr code
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Wu Y., 2021, P IEEE CVF INT C COM, P14519
   Xiaoyi Yu, 2004, Proceedings. Third International Conference on Image and Graphics, P333
   Yang Y., 2016, IEEE Trans. Visual. Comput. Graph., V23, P2
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu W., 1999, IEEE Trans. Circ. Syst. Video Technol., V9, P2
NR 57
TC 2
Z9 2
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1139
EP 1149
DI 10.1109/TVCG.2023.3326597
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500106
PM 37871072
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, XQ
   Yen, K
   Hu, YF
   Shen, HW
AF Wang, Xiaoqi
   Yen, Kevin
   Hu, Yifan
   Shen, Han-Wei
TI SmartGD: A GAN-Based Graph Drawing Framework for Diverse Aesthetic Goals
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Graph drawing; Deep learning; Generative adversarial networks;
   Stress; Generators; Training data; Deep learning for visualization;
   generative adversarial networks; graph visualization
ID LAYOUTS
AB While a multitude of studies have been conducted on graph drawing, many existing methods only focus on optimizing a single aesthetic aspect of graph layouts, which can lead to sub-optimal results. There are a few existing methods that have attempted to develop a flexible solution for optimizing different aesthetic aspects measured by different aesthetic criteria. Furthermore, thanks to the significant advance in deep learning techniques, several deep learning-based layout methods were proposed recently. These methods have demonstrated the advantages of deep learning approaches for graph drawing. However, none of these existing methods can be directly applied to optimizing non-differentiable criteria without special accommodation. In this work, we propose a novel Generative Adversarial Network (GAN) based deep learning framework for graph drawing, called SmartGD, which can optimize different quantitative aesthetic goals, regardless of their differentiability. To demonstrate the effectiveness and efficiency of SmartGD, we conducted experiments on minimizing stress, minimizing edge crossing, maximizing crossing angle, maximizing shape-based metrics, and a combination of multiple aesthetics. Compared with several popular graph drawing algorithms, the experimental results show that SmartGD achieves good performance both quantitatively and qualitatively.
C1 [Wang, Xiaoqi; Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
   [Yen, Kevin; Hu, Yifan] Yahoo Res, New York, NY 10003 USA.
C3 University System of Ohio; Ohio State University; Yahoo! Inc; Yahoo! Inc
   United States
RP Wang, XQ (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM wang.5502@osu.edu; kevinyen@yahooinc.com; yifanh@gmail.com;
   shen.94@osu.edu
OI Shen, Han-Wei/0000-0002-1211-2320; Yen, Kevin/0000-0002-4338-9680
FU NSF-funded AI Institute [OAC2112606]
FX No Statement Available
CR Ahmed R, 2022, IEEE T VIS COMPUT GR, V28, P2388, DOI 10.1109/TVCG.2022.3155564
   Argyriou E., 2010, P 18 INT S GRAPH DRA, P62
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bekos MA, 2021, COMPUT J, V64, P7, DOI 10.1093/comjnl/bxz133
   Blanchard AE, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00494-3
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Devkota S, 2019, LECT NOTES COMPUT SC, V11904, P291, DOI 10.1007/978-3-030-35802-0_23
   Didimo W, 2011, LECT NOTES COMPUT SC, V6502, P165, DOI 10.1007/978-3-642-18469-7_15
   Dwyer T, 2009, IEEE T VIS COMPUT GR, V15, P961, DOI 10.1109/TVCG.2009.109
   Eades P, 2015, LECT NOTES COMPUT SC, V9411, P502, DOI 10.1007/978-3-319-27261-0_41
   Fey M., 2019, ICLR WORKSHOP REPRES
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Giovannangeli L., 2021, P SPRING INT S GRAPH, P375
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Hu Y., 2005, Mathematica journal, V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Huang WD, 2013, J VISUAL LANG COMPUT, V24, P262, DOI 10.1016/j.jvlc.2011.12.002
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Jiang Liming, 2021, ADV NEURAL INF PROCE, V34, P21655
   Jolicoeur-Martineau A, 2018, Arxiv, DOI arXiv:1807.00734
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kobourov Stephen G., 2013, Handbook of Graph Drawing and Visualization, P383
   Koren Y, 2003, LECT NOTES COMPUT SC, V2697, P496
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Loshchilov I., 2016, arXiv
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Paszke A, 2019, ADV NEUR IN, V32
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Radermacher M., 2019, ACM J. Exp. Algorithmics, V24, P1
   Tiezzi M, 2024, IEEE T NEUR NET LEAR, V35, P4668, DOI 10.1109/TNNLS.2022.3184967
   Wang XQ, 2021, IEEE COMPUT GRAPH, V41, P32, DOI 10.1109/MCG.2021.3093908
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 38
TC 0
Z9 0
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5666
EP 5678
DI 10.1109/TVCG.2023.3306356
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400061
PM 37594870
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Diller, F
   Scheuermann, G
   Wiebel, A
AF Diller, Florian
   Scheuermann, Gerik
   Wiebel, Alexander
TI Visual Cue Based Corrective Feedback for Motor Skill Training in Mixed
   Reality: A Survey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Mixed reality; Augmented reality; Training; Task
   analysis; Sports; Feedback loop; Human-centered computing;
   visualization; visualization techniques and methodologies; interaction
   techniques; virtual and augmented reality
AB When learning a motor skill it is helpful to get corrective feedback from an instructor. This will support the learner to execute the movement correctly. With modern technology, it is possible to provide this feedback via mixed reality. In most cases, this involves visual cues to help the user understand the corrective feedback. We analyzed recent research approaches utilizing visual cues for feedback in mixed reality. The scope of this article is visual feedback for motor skill learning, which involves physical therapy, exercise, rehabilitation etc. While some of the surveyed literature discusses therapeutic effects of the training, this article focuses on visualization techniques. We categorized the literature from a visualization standpoint, including visual cues, technology and characteristics of the feedback. This provided insights into how visual feedback in mixed reality is applied in the literature and how different aspects of the feedback are related. The insights obtained can help to better adjust future feedback systems to the target group and their needs. This article also provides a deeper understanding of the characteristics of the visual cues in general and promotes future, more detailed research on this topic.
C1 [Diller, Florian; Wiebel, Alexander] Hsch Worms Univ Appl Sci, UX Vis Grp, D-67549 Worms, Germany.
   [Scheuermann, Gerik] Univ Leipzig, BSV Grp, D-04109 Leipzig, Germany.
C3 Leipzig University
RP Diller, F (corresponding author), Hsch Worms Univ Appl Sci, UX Vis Grp, D-67549 Worms, Germany.
EM diller@hs-worms.de; scheuermann@informatik.uni-leipzig.de;
   wiebel@hs-worms.de
OI Wiebel, Alexander/0000-0002-6583-3092; Diller,
   Florian/0000-0001-7421-750X
FU ProFIL -Programm zur Forderung des Forschungspersonals, Infrastruktur
   und forschendem Lernenof HSWorms; German Federal Ministry for Economic
   Affairs and Energy [16KN087122]
FX This work was supported in part by ProFIL -Programm zur Forderung des
   Forschungspersonals, Infrastruktur und forschendem Lernenof HSWorms. All
   other work was supported in part by ZIM under Grant 16KN087122 from the
   German Federal Ministry for Economic Affairs and Energy.
CR Afyouni I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247037
   Badampudi C., 2015, P 19 INT C EV ASS SO, P1
   Barioni RR, 2019, SYMP VIRTUAL AUGMENT, P10, DOI 10.1109/SVR.2019.00018
   Booth ATC, 2019, CLIN BIOMECH, V70, P146, DOI 10.1016/j.clinbiomech.2019.08.013
   Booth ATC, 2019, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.01208
   Brennan L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010181
   Butterfield A., 2016, A Dictionary of ComputerScience
   Cao X., 2020, P CHI C HUM FACT COM, P1
   Caserman P, 2022, IEEE T GAMES, V14, P243, DOI 10.1109/TG.2021.3064749
   Clarke Christopher, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P196, DOI 10.1145/3379337.3415591
   Conner Caleb., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P3028
   Davies E., 2003, P SPAC REQ WHEEL MOB, P62
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P537, DOI 10.1109/VR.2018.8446368
   Escalona F, 2020, VIRTUAL REAL-LONDON, V24, P567, DOI 10.1007/s10055-019-00419-4
   Fitts PM, 1967, HUMAN PERFORMANCE
   Furukawa T., 2018, Tohoku-Sec-tion Joint Conve., P213
   Gandhi DBC, 2020, THER CLIN RISK MANAG, V16, P75, DOI 10.2147/TCRM.S206883
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Greenhalgh T, 2005, BRIT MED J, V331, P1064, DOI 10.1136/bmj.38636.593461.68
   Han PH, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875237
   Han Y.-S., 2017, P 8 AUGM HUM INT C, P1
   Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487
   Hilton D, 2011, STUD COMPUT INTELL, V337, P193
   Hoang TN, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971521
   Huber J.J., 2013, APPLYING ED PSYCHOL
   Hülsmann F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00043
   IJsselsteijn Y. D., 2004, P 3 INT C ENT COMP, P46
   Ikeda A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1527, DOI [10.1109/vr.2019.8798196, 10.1109/VR.2019.8798196]
   Ikeda D., 2018, P EUR S VIRT ENV, P171
   Karatsidis A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0419-2
   Kosmalla F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P270, DOI 10.1145/3132272.3134119
   Liebermann DG, 2002, J SPORT SCI, V20, P755, DOI 10.1080/026404102320675611
   LYSAKOWSKI RS, 1982, AM EDUC RES J, V19, P559, DOI 10.2307/1162544
   Ma MH, 2011, STUD COMPUT INTELL, V337, P169
   Marti K. C. S., 2019, Master's Thesis
   Meyer B, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P54, DOI 10.1145/3266037.3266099
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mills KR, 2005, J NEUROL NEUROSUR PS, V76, P32, DOI 10.1136/jnnp.2005.069211
   Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.07.299, 10.1136/bmj.b2700]
   Mohr P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6547, DOI 10.1145/3025453.3025688
   Morone G, 2021, EXPERT REV MED DEVIC, V18, P513, DOI 10.1080/17434440.2021.1927704
   Mostajeran F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1465, DOI [10.1109/vr.2019.8797813, 10.1109/VR.2019.8797813]
   Mubin O, 2022, DISABIL REHABIL-ASSI, V17, P159, DOI 10.1080/17483107.2020.1768309
   Murlowski C, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313250
   Naour T.L, 2019, Front. ICT, V6
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [DOI 10.17011/HT/URN.201611174652, 10.17011/ht/urn.201611174652]
   Oh Y., 2010, Proceedings of Meaningful Play 2010, P1
   Oka M, 2021, PROC SPIE, V11766, DOI 10.1117/12.2591035
   Oshita M, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P82, DOI 10.1109/CW.2018.00025
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Pereira V., 2017, P 11 EAI INT C PERV, P146
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Pucihar KC, 2015, LECT NOTES COMPUT SC, V9299, P523, DOI 10.1007/978-3-319-22723-8_53
   Quevedo WX, 2017, LECT NOTES COMPUT SC, V10325, P166, DOI 10.1007/978-3-319-60928-7_14
   Raffe WL, 2018, IEEE INT CONF SERIOU
   Rutkowski S, 2020, J REHABIL MED, V52, DOI 10.2340/16501977-2755
   Sawan Nedal, 2020, EBEE 2020: 2020 2nd International Conference on E-Business and E-commerce Engineering, P55, DOI 10.1145/3446922.3446932
   Schiza E, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00100
   Schmalstieg T., 2016, Augmented Reality: Principles andPractice
   Schmidt C., 2004, Motor Learning and Performance, P62
   Sekhavat YA, 2018, IEEE T HUM-MACH SYST, V48, P626, DOI 10.1109/THMS.2018.2860579
   Shiro K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1563, DOI [10.1109/vr.2019.8798366, 10.1109/VR.2019.8798366]
   SINGH R, 1978, LINGUISTICS, P79
   Sousa M, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P175, DOI 10.1145/2856767.2856773
   Speicher B. D., 2019, P CHI C HUM FACT COM, P1
   Swinnen SP, 1997, HUM MOVEMENT SCI, V16, P749, DOI 10.1016/S0167-9457(97)00020-1
   Takahashi K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1353, DOI 10.1109/vr.2019.8798005
   Tang R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4123, DOI 10.1145/2702123.2702401
   Taylor JA, 2012, ANN NY ACAD SCI, V1251, P1, DOI 10.1111/j.1749-6632.2011.06430.x
   Trajkova Milka, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191770
   Trepkowski C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P575, DOI [10.1109/VR.2019.8798312, 10.1109/vr.2019.8798312]
   Vidal LT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376268
   Viglialoro RM, 2019, INFORMATION, V10, DOI 10.3390/info10050154
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Ware J.B, 2020, International Patent, Patent No. [WO2020/163163A1, 2020163163]
   Wiehr F., 2016, P CHI C HUM FACT COM, P1998
   Wohlin C., 2014, P 18 INT C EVALUATIO, DOI DOI 10.1145/2601248.2601268
   Yu XY, 2020, INT SYM MIX AUGMENT, P577, DOI 10.1109/ISMAR50242.2020.00085
NR 79
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3121
EP 3134
DI 10.1109/TVCG.2022.3227999
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700064
PM 37015488
OA hybrid
DA 2024-08-05
ER

PT J
AU Liu, JY
   Saquib, N
   Zhutian, C
   Kazi, RH
   Wei, LY
   Fu, HB
   Tai, CL
AF Liu, Jingyuan
   Saquib, Nazmus
   Zhutian, Chen
   Kazi, Rubaiat Habib
   Wei, Li-Yi
   Fu, Hongbo
   Tai, Chiew-Lan
TI PoseCoach: A Customizable Analysis and Visualization System for
   Video-Based Running Coaching
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Videos; Sports; Three-dimensional displays; Data visualization; Data
   analysis; Analytical models; Solid modeling; Human pose; video
   processing; sports data analysis
ID BIOMECHANICS; RELIABILITY
AB Videos are an accessible form of media for analyzing sports postures and providing feedback to athletes. Existing sport-specific systems embed bespoke human pose attributes and thus can be hard to scale for new attributes, especially for users without programming experiences. Some systems retain scalability by directly showing the differences between two poses, but they might not clearly visualize the key differences that viewers would like to pursue. Besides, video-based coaching systems often present feedback on the correctness of poses by augmenting videos with visual markers or reference poses. However, previewing and augmenting videos limit the analysis and visualization of human poses due to the fixed viewpoints in videos, which confine the observation of captured human movements and cause ambiguity in the augmented feedback. To address these issues, we study customizable human pose data analysis and visualization in the context of running pose attributes, such as joint angles and step distances. Based on existing literature and a formative study, we have designed and implemented a system, PoseCoach, to provide feedback on running poses for amateurs by comparing the running poses between a novice and an expert. PoseCoach adopts a customizable data analysis model to allow users' controllability in defining pose attributes of their interests through our interface. To avoid the influence of viewpoint differences and provide intuitive feedback, PoseCoach visualizes the pose differences as part-based 3D animations on a human model to imitate the demonstration of a human coach. We conduct a user study to verify our design components and conduct expert interviews to evaluate the usefulness of the system.
C1 [Liu, Jingyuan; Tai, Chiew-Lan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Saquib, Nazmus] Tero Labs, Santa Clara, CA 95051 USA.
   [Zhutian, Chen] Harvard Univ, Cambridge, MA 02138 USA.
   [Kazi, Rubaiat Habib; Wei, Li-Yi] Adobe Res, San Jose, CA 95110 USA.
   [Fu, Hongbo] City Univ Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Harvard University; Adobe
   Systems Inc.; City University of Hong Kong
RP Liu, JY (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM jliucb@connect.ust.hk; nzm.saquib@gmail.com; ztchen@seas.harvard.edu;
   rhabib@adobe.com; review@liyiwei.org; fuplus@gmail.com; taicl@cse.ust.hk
OI Liu, Jingyuan/0000-0002-4648-5555; Wei, Li-Yi/0000-0002-1076-6339; FU,
   Hongbo/0000-0002-0284-726X
FU Research Grants Council of HKSAR [HKUST16206722]
FX This work was supported by the Research Grants Council of HKSAR under
   Grant HKUST16206722. We thank the anonymous reviewers for the valuable
   feedback and the userstudy participants for their great help.
CR Anderson F., 2013, Proceedings of the 26th annual ACM symposium on User interface software and technology, DOI [10.1145/2501988.2502045, DOI 10.1145/2501988.2502045]
   Aristidou A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275038
   Barre A, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.012
   Bartlett R., 2007, Introduction to Sports Biomechanics: Analysing Human Movement Patterns, V2nd
   Berndt DJ., 1994, P KDD WORKSH SEATTL, P359, DOI DOI 10.5555/3000850.3000887
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Chen HT, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2027, DOI 10.1145/2556288.2557009
   Chen HT, 2018, MULTIMED TOOLS APPL, V77, P23969, DOI 10.1007/s11042-018-5721-2
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Clarke Christopher, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P196, DOI 10.1145/3379337.3415591
   Dreyer D., 2009, ChiRunning: A revolutionary approach to effortless, injury-free running
   Fieraru M, 2021, PROC CVPR IEEE, P9914, DOI 10.1109/CVPR46437.2021.00979
   Fu HB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360641
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hanley B, 2018, J SPORT SCI, V36, P1250, DOI 10.1080/02640414.2017.1372928
   Hay J., 1978, The Biomechanics of Sports Techniques
   Hinrichs R. N., 1990, Multiple Muscle Systems, P694, DOI [10.1007/978-1-4613-9030-5_45, DOI 10.1007/978-1-4613-9030-5_45]
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Kiciroglu S, 2020, PROC CVPR IEEE, P100, DOI 10.1109/CVPR42600.2020.00018
   Kinovea, 2012, A microscope for your videos
   Kuhtz-Buschbeck JP, 2012, J ELECTROMYOGR KINES, V22, P199, DOI 10.1016/j.jelekin.2011.08.014
   Kwon B, 2022, IEEE T SYST MAN CY-S, V52, P533, DOI 10.1109/TSMC.2020.3004338
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mathis A, 2018, NAT NEUROSCI, V21, P1281, DOI 10.1038/s41593-018-0209-y
   Microsoft, 2017, Visual gesture builder (VGB)
   Mirzabekiantz E, 2016, SPRINGER TRAC ADV RO, V111, P299, DOI 10.1007/978-3-319-25739-6_14
   MotionPro, 2018, Motion analysis software for all sports
   Nebeling M., 2015, P 7 ACM SIGCHI S ENG, P142, DOI [10.1145/2774225.2774846, DOI 10.1145/2774225]
   Novacheck TF, 1998, GAIT POSTURE, V7, P77, DOI 10.1016/S0966-6362(97)00038-6
   Once, 2019, Basketball video analysis all-in-one program
   OnForm, 2021, Video analysis for skill development in any sport
   Ortiz-Padilla VE, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083981
   Pipkin A, 2016, J ORTHOP SPORT PHYS, V46, P556, DOI 10.2519/jospt.2016.6280
   Q. System, 2015, A leading provider of precision motion capture and 3D positioning tracking system
   Reinking MF, 2018, INT J SPORTS PHYS TH, V13, P453, DOI 10.26603/ijspt20180453
   Romanov N., 2002, Dr. Nicholas Romanov's pose method of running companion drill book - video I
   Semeraro A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517735
   Seth A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006223
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Stein M., 2018, P INT S BIG DAT VIS, P1
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Su WC, 2023, IEEE T VIS COMPUT GR, V29, P4074, DOI 10.1109/TVCG.2022.3178734
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Suzuki Ryo, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P166, DOI 10.1145/3379337.3415892
   Tang R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4123, DOI 10.1145/2702123.2702401
   Techiques H., 2007, Hudl: Performance analysis tools for sports teams and athletes at every level
   TechSmith, 2011, Coach's eye
   van Oeveren BT, 2024, SPORT BIOMECH, V23, P516, DOI 10.1080/14763141.2021.1873411
   Velloso Eduardo., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1309
   Video4coach, 2010, Video based motion and skill analysis
   Wang Jiachen, 2023, IEEE Trans Vis Comput Graph, V29, P951, DOI 10.1109/TVCG.2022.3209352
   Wang JB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P374, DOI 10.1145/3343031.3350910
   Wei RXY, 2021, BRAZ J PHYS THER, V25, P162, DOI 10.1016/j.bjpt.2020.05.003
   WILLIAMS KR, 1987, J APPL PHYSIOL, V63, P1236, DOI 10.1152/jappl.1987.63.3.1236
   Woniak P. W., 2021, P CHI C HUM FACT COM
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wulf G, 2010, MED EDUC, V44, P75, DOI 10.1111/j.1365-2923.2009.03421.x
   Zecha D, 2018, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON MULTIMEDIA CONTENT ANALYSIS IN SPORTS (MMSPORTS'18), P11, DOI 10.1145/3265845.3265855
NR 63
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3180
EP 3195
DI 10.1109/TVCG.2022.3230855
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700045
PM 37015423
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lyu, Y
   Lu, HX
   Lee, MK
   Schmitt, G
   Lim, BY
AF Lyu, Yan
   Lu, Hangxin
   Lee, Min Kyung
   Schmitt, Gerhard
   Lim, Brian Y.
TI IF-City: Intelligible Fair City Planning to Measure, Explain and
   Mitigate Inequality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Resource management; Visualization; Urban planning; Indexes; Data
   visualization; Buildings; Sociology; Fairness; intelligibility;
   explainable artificial intelligence; resource allocation; urban planning
ID LAND-USE; URBAN; ACCESSIBILITY; EQUITY; NETWORKS; DESIGN
AB With the increasing pervasiveness of Artificial Intelligence (AI), many visual analytics tools have been proposed to examine fairness, but they mostly focus on data scientist users. Instead, tackling fairness must be inclusive and involve domain experts with specialized tools and workflows. Thus, domain-specific visualizations are needed for algorithmic fairness. Furthermore, while much work on AI fairness has focused on predictive decisions, less has been done for fair allocation and planning, which require human expertise and iterative design to integrate myriad constraints. We propose the Intelligible Fair Allocation (IF-Alloc) Framework that leverages explanations of causal attribution (Why), contrastive (Why Not) and counterfactual reasoning (What If, How To) to aid domain experts to assess and alleviate unfairness in allocation problems. We apply the framework to fair urban planning for designing cities that provide equal access to amenities and benefits for diverse resident types. Specifically, we propose an interactive visual tool, Intelligible Fair City Planner (IF-City), to help urban planners to perceive inequality across groups, identify and attribute sources of inequality, and mitigate inequality with automatic allocation simulations and constraint-satisfying recommendations (IF-Plan). We demonstrate and evaluate the usage and usefulness of IF-City on a real neighborhood in New York City, US, with practicing urban planners from multiple countries, and discuss generalizing our findings, application, and framework to other use cases and applications of fair allocation.
C1 [Lyu, Yan] Southeast Univ, Sch Comp Sci & Engn, Nanjing 211189, Peoples R China.
   [Lu, Hangxin; Schmitt, Gerhard] Singapore ETH Ctr, Future Cities Lab, Singapore 138602, Singapore.
   [Lu, Hangxin; Schmitt, Gerhard] Swiss Fed Inst Technol, Dept Architecture, CH-8092 Zurich, Switzerland.
   [Lee, Min Kyung] Univ Texas Austin, Sch Informat, Austin, TX 78712 USA.
   [Lim, Brian Y.] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
C3 Southeast University - China; Swiss Federal Institutes of Technology
   Domain; ETH Zurich; University of Texas System; University of Texas
   Austin; National University of Singapore
RP Lim, BY (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
EM lvyanly@gmail.com; luhangxin@gmail.com; minkyung.lee@austin.utexas.edu;
   schmitt@arch.ethz.ch; brianlim@comp.nus.edu.sg
OI Lim, Brian/0000-0002-0543-2414; Lee, Min Kyung/0000-0002-2696-6546; LYU,
   Yan/0000-0001-9959-9217
FU National Key Research and Development Program of China [2019YFB2102200];
   Singapore Ministry of Education (MOE) Academic Research Fund Tier 2
   [T2EP20121-0040]; Natural Science Foundation of China [62102082];
   Jiangsu Natural Science Foundation of China [BK20210203]; National
   Science Foundation [CNS-1952085, IIS-1939606, DGE-2125858]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2019YFB2102200; in part by the
   Singapore Ministry of Education (MOE) Academic Research Fund Tier 2
   under Grant T2EP20121-0040; in part by the Natural Science Foundation of
   China under Grant 62102082; in part by the Jiangsu Natural Science
   Foundation of China under Grant BK20210203; and in part by National
   Science Foundation under Grants CNS-1952085, IIS-1939606, and
   DGE-2125858.
CR Abdul A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376615
   Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   [Anonymous], 2012, P 20 INT C ADV GEOGR, DOI DOI 10.1145/2424321.2424348
   ANSELIN L, 1995, GEOGR ANAL, V27, P93, DOI 10.1111/j.1538-4632.1995.tb00338.x
   ATKINSON AB, 1970, J ECON THEORY, V2, P244, DOI 10.1016/0022-0531(70)90039-6
   Baruah SK, 1996, ALGORITHMICA, V15, P600, DOI 10.1007/BF01940883
   Beutel A, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P453, DOI 10.1145/3306618.3314234
   Bird S., 2020, Tech. Rep. MSR-TR-2020-32
   Buolamwini J., 2018, C FAIRN ACC TRANSP, V81, P77, DOI DOI 10.2147/OTT.S126905
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Castro J, 2009, COMPUT OPER RES, V36, P1726, DOI 10.1016/j.cor.2008.04.004
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Cheng P, 2021, FORESTS, V12, DOI 10.3390/f12070890
   Corbett-Davies S, 2018, Arxiv, DOI [arXiv:1808.00023, 10.48550/arXiv.1808.00023]
   Das T., 1982, EMPIR ECON, V7, P23, DOI [10.1007/BF02506823, DOI 10.1007/BF02506823]
   Datta A, 2016, P IEEE S SECUR PRIV, P598, DOI 10.1109/SP.2016.42
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Dhurandhar A, 2018, ADV NEUR IN, V31
   Doraiswamy H, 2014, IEEE T VIS COMPUT GR, V20, P2634, DOI 10.1109/TVCG.2014.2346449
   Dwork C., 2012, P 3 INN THEOR COMP S, P214, DOI DOI 10.1145/2090236.2090255
   Fieseler C, 2019, J BUS ETHICS, V156, P987, DOI 10.1007/s10551-017-3607-2
   Foth N, 2013, J TRANSP GEOGR, V29, P1, DOI 10.1016/j.jtrangeo.2012.12.008
   Frick M., 2003, P 3 SWISS TRANSP RES
   Ghodsi An, 2011, Computer Communication Review, V41, P507, DOI 10.1145/2018584.2018586
   Gomez O, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P531, DOI 10.1145/3377325.3377536
   Goodall J.R., 2005, CHI 05, P1403
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Hardt M, 2016, ADV NEUR IN, V29
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hoover EM, 1936, REV ECON STATISTICS, V18, P162, DOI 10.2307/1927875
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Jacono M., 2008, Rep. No. 4
   Jaggi M., 2013, ICML, P427
   Jain R. K., 1984, Eastern Res. Laboratory, Digit. Equip. Corporation, V21, P1
   Joe-Wong C, 2013, IEEE ACM T NETWORK, V21, P1785, DOI 10.1109/TNET.2012.2233213
   Bellamy RKE, 2018, Arxiv, DOI arXiv:1810.01943
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kelly F, 1997, EUR T TELECOMMUN, V8, P33, DOI 10.1002/ett.4460080106
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Kumar A., 2021, P INT C AUT PLAN SCH
   Law M., 2015, Getting to know ArcGIS
   Law PM, 2017, IEEE T VIS COMPUT GR, V23, P231, DOI 10.1109/TVCG.2016.2599378
   Lee MK, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1603, DOI 10.1145/2702123.2702548
   Levin G, 2010, EUROMICRO, P3, DOI 10.1109/ECRTS.2010.34
   Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376590
   Lim BY, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P13
   Lim BY, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P195
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu J, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031587
   Liu MH, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10070439
   Lorenz MO, 1905, J AM STAT ASSOC, V9, P209
   Lu YS, 2022, IEEE T MOBILE COMPUT, V21, P663, DOI 10.1109/TMC.2020.3008315
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lyu Y, 2020, IEEE T VIS COMPUT GR, V26, P811, DOI 10.1109/TVCG.2019.2934657
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   Miller T, 2021, KNOWL ENG REV, V36, DOI 10.1017/S0269888921000102
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Min Kyung Lee, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359283
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Miranda F, 2017, IEEE T VIS COMPUT GR, V23, P791, DOI 10.1109/TVCG.2016.2598585
   Mueller J, 2018, CITIES, V72, P181, DOI 10.1016/j.cities.2017.08.018
   Muller K., 2011, TRANSP RES BOARD 90
   Neutens T, 2010, ENVIRON PLANN A, V42, P1613, DOI 10.1068/a4230
   New York City Department of city planning (DCP), 2005, land use code
   Nyelele C, 2020, URBAN FOR URBAN GREE, V53, DOI 10.1016/j.ufug.2020.126723
   Olah C., 2017, Distill, V2, P7, DOI DOI 10.23915/DISTILL.00007
   Páez A, 2012, J TRANSP GEOGR, V25, P141, DOI 10.1016/j.jtrangeo.2012.03.016
   Pandey A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P822, DOI 10.1145/3461702.3462561
   Popolin Neto M, 2021, IEEE T VIS COMPUT GR, V27, P1427, DOI 10.1109/TVCG.2020.3030354
   Radunovic B, 2007, IEEE ACM T NETWORK, V15, P1073, DOI 10.1109/TNET.2007.896231
   Raman N., 2021, PROC 13 INT JOINT, P363, DOI [10.24963/ijcai.2021/51, DOI 10.24963/IJCAI.2021/51]
   Rambonilaza M, 2007, LANDSCAPE URBAN PLAN, V83, P318, DOI 10.1016/j.landurbplan.2007.05.013
   Reyes M, 2014, LANDSCAPE URBAN PLAN, V125, P38, DOI 10.1016/j.landurbplan.2014.02.002
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rnyi A., 1961, Fourth Berkeley Symposium on Mathematical Statistics and Probability, P547, DOI DOI 10.1021/JP106846B
   Robertson S., 2021, P 2021 CHI C HUMAN F, DOI [DOI 10.1145/3411764.3445748, 10.1145/3411764.3445748]
   Roth A.E, 1988, The Shapley Value: Essays in Honor of Lloyd S. Shapley, DOI 10.1017/CBO9780511528446
   Santos B, 2008, TRANSPORT RES REC, P35, DOI 10.3141/2089-05
   SHORROCKS AF, 1980, ECONOMETRICA, V48, P613, DOI 10.2307/1913126
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]
   Speicher T, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2239, DOI 10.1145/3219819.3220046
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Sühr T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3082, DOI 10.1145/3292500.3330793
   Talen E, 1998, J AM PLANN ASSOC, V64, P22, DOI 10.1080/01944369808975954
   Uhde A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376656
   Verma S, 2018, 2018 IEEE/ACM INTERNATIONAL WORKSHOP ON SOFTWARE FAIRNESS (FAIRWARE 2018), P1, DOI [10.1145/3194770.3194776, 10.23919/FAIRWARE.2018.8452913]
   Wachter S., 2017, SSRN Electronic Journal, V31, P841
   Waddell P, 2002, J AM PLANN ASSOC, V68, P297, DOI 10.1080/01944360208976274
   Wang DD, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934212, 10.1145/3290605.3300831]
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1470, DOI 10.1109/TVCG.2020.3030471
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Xu C., 2020, Google Research
   Xu YF, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4199
   Xu Z, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P905, DOI 10.1145/3219819.3219824
   Yan JN, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376447
   Yoo CY, 2009, JOURNALISM MASS COMM, V86, P401, DOI 10.1177/107769900908600209
   Yu H, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6575
   Zeng W, 2019, COMPUT GRAPH FORUM, V38, P581, DOI 10.1111/cgf.13712
   Zeng W, 2018, IEEE COMPUT GRAPH, V38, P38, DOI 10.1109/MCG.2018.053491730
   Zhang Y., 2017, CityMatrix - An Urban Decision Support System Augmented by Artificial Intelligence
   Zhu Y, 2014, TRANSPORT RES REC, P168, DOI 10.3141/2429-18
NR 110
TC 1
Z9 1
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3749
EP 3766
DI 10.1109/TVCG.2023.3239909
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700038
PM 37022033
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Song, XH
   Liu, C
   Zheng, YY
   Feng, ZL
   Li, LC
   Zhou, K
   Yu, X
AF Song, Xinhui
   Liu, Chen
   Zheng, Youyi
   Feng, Zunlei
   Li, Lincheng
   Zhou, Kun
   Yu, Xin
TI HairStyle Editing via Parametric Controllable Strokes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Hair; Image color analysis; Shape; Stroke (medical condition); Rendering
   (computer graphics); Faces; Pipelines; Hairstyle editing; hairstyle
   transfer; parameterized hair strokes; stroke-controllable
ID IMAGE SYNTHESIS; CAPTURE
AB In this work, we propose a stroke-based hairstyle editing network, dubbed HairstyleNet, allowing users to conveniently change the hairstyles of an image in an interactive fashion. Different from previous works, we simplify the hairstyle editing process where users can manipulate local or entire hairstyles by adjusting the parameterized hair regions. Our HairstyleNet consists of two stages: a stroke parameterization stage and a stroke-to-hair generation stage. In the stroke parameterization stage, we first introduce parametric strokes to approximate the hair wisps, where the stroke shape is controlled by a quadratic B & eacute;zier curve and a thickness parameter. Since rendering strokes with thickness to an image is not differentiable, we opt to leverage a neural renderer to construct the mapping from stroke parameters to a stroke image. Thus, the stroke parameters can be directly estimated from hair regions in a differentiable way, enabling us to flexibly edit the hairstyles of input images. In the stroke-to-hair generation stage, we design a hairstyle refinement network that first encodes coarsely composed images of hair strokes, face, and background into latent representations and then generates high-fidelity face images with desirable new hairstyles from the latent codes. Extensive experiments demonstrate that our HairstyleNet achieves state-of-the-art performance and allows flexible hairstyle manipulation.
C1 [Song, Xinhui; Li, Lincheng] Fuxi AI Lab Netease Inc, Hangzhou 310052, Zhejiang, Peoples R China.
   [Zheng, Youyi; Feng, Zunlei; Zhou, Kun] Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China.
   [Liu, Chen; Yu, Xin] Univ Queensland, Brisbane, Qld 4072, Australia.
C3 Zhejiang University; University of Queensland
RP Li, LC (corresponding author), Fuxi AI Lab Netease Inc, Hangzhou 310052, Zhejiang, Peoples R China.
EM songxinhui@corp.netease.com; yenanliu36@gmail.com;
   youyizheng@zju.edu.cn; zunleifeng@zju.edu.cn;
   lilincheng@corp.netease.com; kunzhou@acm.org; xin.yu@uts.edu.au
OI Yu, Xin/0000-0002-0269-5649; LIU, CHEN/0000-0003-3159-0034; Feng,
   Zunlei/0000-0001-8640-8434
FU ARC-Discovery [DP220100800]; ARC-DECRA [DE230100477]
FX This work was supported in part by the ARC-Discovery under Grant
   DP220100800 and in part by the ARC-DECRA under Grant DE230100477.
CR Abdal R., 2020, P IEEECVF C COMPUTER, P8296
   Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Anokhin Ivan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7485, DOI 10.1109/CVPR42600.2020.00751
   Bin H, 2017, Arxiv, DOI [arXiv:1707.00737, 10.48550/arxiv.1707.00737]
   Brock A, 2019, Arxiv, DOI arXiv:1809.11096
   Chai ML, 2020, Arxiv, DOI arXiv:2004.13297
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012
   Chen S.-Y., 2021, arXiv
   Chen YC, 2020, PROC CVPR IEEE, P5273, DOI 10.1109/CVPR42600.2020.00532
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dong H.-W., 2018, arXiv
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guan SY, 2020, Arxiv, DOI arXiv:2007.01758
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661254
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu MY, 2016, ADV NEUR IN, V29
   Liwen Hu, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601194
   Luo LJ, 2013, PROC CVPR IEEE, P265, DOI 10.1109/CVPR.2013.41
   Luo LJ, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462026
   Luo LJ, 2012, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2012.6247838
   Olszewski Kyle, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7444, DOI 10.1109/CVPR42600.2020.00747
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   Perarnau G, 2016, Arxiv, DOI [arXiv:1611.06355, 10.48550/arXiv.1611.06355]
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Romero A., 2020, arXiv
   Saha R, 2021, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR46437.2021.00202
   Shen Y., 2020, P IEEECVF C COMPUTER, P9243
   Shen YJ, 2022, IEEE T PATTERN ANAL, V44, P2004, DOI 10.1109/TPAMI.2020.3034267
   Shiri F, 2019, INT J COMPUT VISION, V127, P863, DOI 10.1007/s11263-019-01169-1
   Shuai Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P601, DOI 10.1007/978-3-030-58555-6_36
   Simo-Serra E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132703
   Simo-Serra E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925972
   Tan ZT, 2020, Arxiv, DOI arXiv:2010.16417
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Vasu S., 2018, P EUR C COMP VIS WOR, P0
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wei L., 2018, P EUR C COMP VIS, P99
   Wei TY, 2022, PROC CVPR IEEE, P18051, DOI 10.1109/CVPR52688.2022.01754
   Wu YQ, 2022, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR52688.2022.00419
   Xiao CF, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480502
   Yang Y, 2019, Arxiv, DOI arXiv:1911.11394
   Yin WD, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1627, DOI 10.1145/3123266.3123423
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Yu X, 2020, IEEE T PATTERN ANAL, V42, P2148, DOI 10.1109/TPAMI.2019.2914039
   Yu X, 2018, PROC CVPR IEEE, P908, DOI 10.1109/CVPR.2018.00101
   Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275039
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou SC, 2017, Arxiv, DOI arXiv:1705.04932
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11215, P249, DOI 10.1007/978-3-030-01252-6_15
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu P., 2021, arXiv
   Zou Z., 2020, arXiv
NR 76
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3857
EP 3870
DI 10.1109/TVCG.2023.3241894
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700067
PM 37022457
DA 2024-08-05
ER

PT J
AU Cai, ZJ
   Ma, YH
   Lu, F
AF Cai, Zhuojiang
   Ma, Yuhan
   Lu, Feng
TI Robust Dual-Modal Speech Keyword Spotting for XR Headsets
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Speech interaction; extended reality; keyword spotting; multimodal
   interaction
ID RECOGNITION; GESTURE
AB While speech interaction finds widespread utility within the Extended Reality (XR) domain, conventional vocal speech keyword spotting systems continue to grapple with formidable challenges, including suboptimal performance in noisy environments, impracticality in situations requiring silence, and susceptibility to inadvertent activations when others speak nearby. These challenges, however, can potentially be surmounted through the cost-effective fusion of voice and lip movement information. Consequently, we propose a novel vocal-echoic dual-modal keyword spotting system designed for XR headsets. We devise two different modal fusion approches and conduct experiments to test the system's performance across diverse scenarios. The results show that our dual-modal system not only consistently outperforms its single-modal counterparts, demonstrating higher precision in both typical and noisy environments, but also excels in accurately identifying silent utterances. Furthermore, we have successfully applied the system in real-time demonstrations, achieving promising results. The code is available at https://github.com/caizhuojiang/VE-KWS.
C1 [Cai, Zhuojiang; Ma, Yuhan; Lu, Feng] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University
RP Lu, F (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM caizhuojiang@buaa.edu.cn; raphael.mayuhan@buaa.edu.cn;
   lufeng@buaa.edu.cn
OI Lu, Feng/0000-0001-9064-7964; Cai, Zhuojiang/0009-0005-3404-118X
CR Bedri A, 2015, COMPUTER, V48, P54, DOI 10.1109/MC.2015.310
   Berg A, 2021, INTERSPEECH, P4249, DOI 10.21437/Interspeech.2021-1286
   Cheah J. M., 2018, INPROCEED INGS 11 IN, P56, DOI 10.5220
   Chen C., 2014, 2014 IEEE INT C ACOU, P4087, DOI 10.1109/ICASSP.2014.68543702[5]T
   Choi S, 2019, Arxiv, DOI arXiv:1904.03814
   Cioflan C, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC ERA, P82, DOI 10.1109/AICAS54282.2022.9869990
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Ding RW, 2018, IEEE IMAGE PROC, P4138, DOI 10.1109/ICIP.2018.8451096
   Elepfandt M., 2012, INPROCEEDINGS 4 WORK, P1, DOI [10.1145/2401836.24018482[11]I, DOI 10.1145/2401836.24018482[11]I]
   Fung I, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2511, DOI 10.1109/ICASSP.2018.8462280
   Gales MJF, 2017, LECT NOTES ARTIF INT, V10458, P3, DOI 10.1007/978-3-319-66429-3_1
   Gao Y, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411830
   Grinshpoon A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P751, DOI 10.1109/VR.2018.8446259
   Hofe R, 2013, SPEECH COMMUN, V55, P22, DOI 10.1016/j.specom.2012.02.001
   Hombeck J, 2023, Symposium Virtual Re, P123, DOI 10.1109/VR55154.2023.00028
   Kapur A, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P43, DOI 10.1145/3172944.3172977
   Kaur M., Where is "it"? Event Synchronization in Gaze-Speech Input Systems,, V2
   Kim B, 2022, Arxiv, DOI arXiv:2106.04140
   Kimura N, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451552
   Kimura N, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399852
   Kimura N, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300376
   Kumar R, 2018, INTERSPEECH, P1121
   Kunimi Y, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), P26, DOI 10.1145/3519391.3519399
   Lee KS, 2008, IEEE T BIO-MED ENG, V55, P930, DOI 10.1109/TBME.2008.915658
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Li K, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3534621
   Li R, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311831
   López-Espejo I, 2022, IEEE ACCESS, V10, P4169, DOI 10.1109/ACCESS.2021.3139508
   Lopez-Espejo I, 2021, IEEE-ACM T AUDIO SPE, V29, P2254, DOI 10.1109/TASLP.2021.3092567
   Michaely AH, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P272, DOI 10.1109/ASRU.2017.8268946
   Monteiro P, 2021, IEEE T VIS COMPUT GR, V27, P2702, DOI 10.1109/TVCG.2021.3067687
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Prabhavalkar R, 2015, INT CONF ACOUST SPEE, P4704, DOI 10.1109/ICASSP.2015.7178863
   Rantamaa HR, 2022, INT J COMPUT ASS RAD, V17, P1981, DOI 10.1007/s11548-022-02685-1
   Rekimoto J, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P91, DOI 10.1145/3458709.3458941
   Rohlicek J. R., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P627, DOI 10.1109/ICASSP.1989.266505
   ROSE RC, 1990, INT CONF ACOUST SPEE, P129, DOI 10.1109/ICASSP.1990.115555
   Rosenberg A, 2017, INT CONF ACOUST SPEE, P5280, DOI 10.1109/ICASSP.2017.7953164
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1478
   Shi BW, 2022, Arxiv, DOI arXiv:2201.01763
   Sun M, 2016, IEEE W SP LANG TECH, P474, DOI 10.1109/SLT.2016.7846306
   Tang RP, 2018, Arxiv, DOI arXiv:1710.10361
   Thiemann J., 2013, The Diverse Environments Multichannet. Acoustic Noise Database (DEMAND): A database of multichannel environmental noise recordings, DOI [10.1121/1.47995975, DOI 10.1121/1.47995975]
   Tuochao Chen, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P112, DOI 10.1145/3379337.3415879
   Vygon Roman, 2021, Speech and Computer: 23rd International Conference, SPECOM 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12997), P773, DOI 10.1007/978-3-030-87802-3_69
   Wang Y, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10070442
   Wang ZM, 2021, IEEE T HUM-MACH SYST, V51, P524, DOI 10.1109/THMS.2021.3097973
   Warden P, 2018, Arxiv, DOI arXiv:1804.03209
   WILPON JG, 1991, INT CONF ACOUST SPEE, P309, DOI 10.1109/ICASSP.1991.150338
   Xu K, 2018, IEEE INT CONF AUTOMA, P548, DOI 10.1109/FG.2018.00088
   Xu ML, 2020, INTERSPEECH, P2547, DOI 10.21437/Interspeech.2020-1045
   Zhang K., 2023, INPROCEEDINGS OFTHE, P1, DOI [10.1145/3544548.35808011,2,3,4[56]Y., DOI 10.1145/3544548.35808011,2,3,4[56]Y]
   Zhang Ruidong., 2021, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V5, P1
   Zhang YZ, 2021, UBICOMP/ISWC '21 ADJUNCT: PROCEEDINGS OF THE 2021 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2021 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P580, DOI 10.1145/3460418.3480163
   Zhou P, 2019, INT CONF ACOUST SPEE, P6565, DOI 10.1109/ICASSP.2019.8683733
   Zhuang YM, 2016, INTERSPEECH, P938, DOI 10.21437/Interspeech.2016-753
NR 57
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2507
EP 2516
DI 10.1109/TVCG.2024.3372092
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400057
PM 38437114
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Liao, SQ
   Byrd, V
   Popescu, V
AF Liao, Shuqi
   Byrd, Vetria
   Popescu, Voicu
TI PreVR: Variable-Distance Previews for Higher-Order Disocclusion in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Navigation; Task analysis; Virtual environments;
   Three-dimensional displays; Teleportation; Measurement; Disocclusion;
   visualization; navigation; virtual reality
AB The paper introduces PreVR, a method for allowing the user of a VR application to preview a virtual environment (VE) around any number of corners. This way the user can gain line of sight to any part of the VE, no matter how distant or how heavily occluded it is. PreVR relies on a multiperspective visualization that implements a higher-order disocclusion effect with piecewise linear rays that bend multiple times as needed to reach the visualization target. PreVR was evaluated in a user study ($\mathrm{N}=88$) that investigates four points on the VR interface design continuum defined by the maximum disocclusion order $\delta$. In a first control condition (CC0), $\delta=0$, corresponds to conventional VR exploration with no preview capability. In a second control condition (CC1), $\delta=1$, corresponds to the prior art approach of giving the user a preview around the first corner. In a first experimental condition (EC3), $\delta=3$, so PreVR provided up to third-order disocclusion. In a second experimental condition (ECN), $\delta$ was not capped, so PreVR could provide a disocclusion effect of any order, as needed to reach any location in the VE. Participants searched for a stationary target, for a dynamic target moving on a random continuous trajectory, and for a transient dynamic target that appeared at random locations in the maze and disappeared 5s later. The study quantified VE exploration efficiency with four metrics: viewpoint translation, view direction rotation, number of teleportations, and task completion time. Results show that the previews afforded by PreVR bring a significant VE exploration efficiency advantage. ECN outperforms EC3, CC1, and CC0 for all metrics and all tasks, and EC3 frequently outperforms CC1 and CC0.
C1 [Liao, Shuqi; Byrd, Vetria; Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Liao, SQ (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM liao201@purdue.edu; vlbyrd@purdue.edu; popescu@purdue.edu
RI Liao, Shuqi/KRP-3611-2024
OI Liao, Shuqi/0000-0002-9134-6845
FU National Science Foundation
FX No Statement Available
CR 2023 Electronic Arts Inc, 2023, Need for Speed.
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bonferroni C.E., 1935, Studi in Onore del Professore Salvatore Ortu Carboni, P13
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Burns M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409107
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Cohen J., 2013, Statistical power analysis for the behavioral sciences, P6
   Dennison M, 2018, APPL ERGON, V71, P9, DOI 10.1016/j.apergo.2018.03.015
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fisher RA, 1922, J R STAT SOC, V85, P87, DOI 10.2307/2340521
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Kennedy R. S., 1993, The international journal of aviation psychology, V3, P5
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Liao SQ, 2023, Symposium Virtual Re, P530, DOI 10.1109/VR55154.2023.00068
   Lidal E. M., 2012, P 28 SPRING C COMPUT, P47
   Lin YT, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P255, DOI 10.1145/3126594.3126656
   meta, Quest 2 virtual reality headset
   Mirhosseini S, 2017, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2017.7892228
   Nakatani R, 2012, J ADV COMPUT INTELL, V16, P696, DOI 10.20965/jaciii.2012.p0696
   Popescu V, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618504
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Razzaque S, 2005, Redirected walking, P2
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   See ZS, 2018, 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM 2018), P213
   Simeone AL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P598, DOI [10.1109/VR46266.2020.00-22, 10.1109/VR46266.2020.1581330966612]
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Unity Software Inc, 2023, Unity Real-Time Development Platform (Version 2021.3.91)
   Wu ML, 2018, LECT NOTES COMPUT SC, V11162, P240, DOI 10.1007/978-3-030-01790-3_15
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
   Yu JY, 2004, LECT NOTES COMPUT SC, V3022, P14
   Zollmann S., 2014, Image-based X-ray visualization techniques for spatial understanding in outdoor augmented reality, V12, DOI DOI 10.1145/2686612.2686642
NR 44
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2454
EP 2463
DI 10.1109/TVCG.2024.3372068
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200005
PM 38437137
DA 2024-08-05
ER

PT J
AU Wilson, E
   Ibragimov, A
   Proulx, MJ
   Tetali, SD
   Butler, K
   Jain, E
AF Wilson, Ethan
   Ibragimov, Azim
   Proulx, Michael J.
   Tetali, Sai Deep
   Butler, Kevin
   Jain, Eakta
TI Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual
   Reality: Robustness and User Experience
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; privacy; eye tracking
ID EYE-TRACKING; VR; PREDICTION; MOVEMENTS
AB Eye tracking is routinely being incorporated into virtual reality (VR) systems. Prior research has shown that eye tracking data, if exposed, can be used for re-identification attacks [14]. The state of our knowledge about currently existing privacy mechanisms is limited to privacy-utility trade-off curves based on data-centric metrics of utility, such as prediction error, and black-box threat models. We propose that for interactive VR applications, it is essential to consider user-centric notions of utility and a variety of threat models. We develop a methodology to evaluate real-time privacy mechanisms for interactive VR applications that incorporate subjective user experience and task performance metrics. We evaluate selected privacy mechanisms using this methodology and find that re-identification accuracy can be decreased to as low as 14% while maintaining a high usability score and reasonable task performance. Finally, we elucidate three threat scenarios (black-box, black-box with exemplars, and white-box) and assess how well the different privacy mechanisms hold up to these adversarial scenarios. This work advances the state of the art in VR privacy by providing a methodology for end-to-end assessment of the risk of re-identification attacks and potential mitigating solutions. f
C1 [Wilson, Ethan; Ibragimov, Azim; Butler, Kevin; Jain, Eakta] Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
   [Proulx, Michael J.] Meta Real Labs Res, Redmond, WA USA.
   [Tetali, Sai Deep] Meta Real Labs, Burlingame, CA USA.
C3 State University System of Florida; University of Florida
RP Wilson, E (corresponding author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
EM ethanwilson@ufl.edu; a.ibragimov@ufl.edu; michaelproulx@meta.com;
   saideept@meta.com; butler@ufl.edu; ejain@ufl.edu
OI Wilson, Ethan/0000-0003-0944-2641
FU NSF
FX No Statement Available
CR Abrash M., AR and VR. Latency-the sine qua non of
   [Anonymous], Apple vision pro
   [Anonymous], Meta quest pro
   Atienza R, 2016, IEEE REGION 10 SYMP, P110, DOI 10.1109/TENCONSpring.2016.7519387
   Berkovsky S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300451
   Bozkir E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255979
   business.vive, Vive Focus 3 Eye Tracker
   David-John B., 2021, ACM S EYE TRACK RES, P1, DOI [10.1145/3448018.34580081,2,3, DOI 10.1145/3448018.34580081,2,3]
   David-John B, 2023, IEEE T VIS COMPUT GR, V29, P2774, DOI 10.1109/TVCG.2023.3247048
   David-John B, 2022, 2022 ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, ETRA 2022, DOI 10.1145/3517031.3529618
   David-John B, 2021, IEEE T VIS COMPUT GR, V27, P2555, DOI 10.1109/TVCG.2021.3067787
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Duchowski A. T., 2000, P 2000 S EYE TRACK R, P89
   Erdemir E, 2021, IEEE T INF FOREN SEC, V16, P389, DOI 10.1109/TIFS.2020.3013200
   Fernandes AS, 2023, IEEE T VIS COMPUT GR, V29, P2269, DOI 10.1109/TVCG.2023.3247058
   Friedman L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111144
   Garau M., 2003, Proceedings o f SIGCHI, P529, DOI [10.1145/642611.642703, DOI 10.1145/642611.642703]
   George A, 2016, PATTERN RECOGN LETT, V82, P207, DOI 10.1016/j.patrec.2015.11.020
   Gowases Teresia., 2008, Proceedings of the 16th International Conference on Computers in Education (ICCE 2008), P773
   Griffith H, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00959-y
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Jia SH, 2018, 2018 9TH IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (ICBK), P57, DOI 10.1109/ICBK.2018.00016
   John B., 2020, ACM S EYE TRACK RES, P1, DOI [10.1145/3379157.33905122, DOI 10.1145/3379157.33905122]
   John B, 2020, IEEE T VIS COMPUT GR, V26, P1880, DOI 10.1109/TVCG.2020.2973052
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Komogortsev O. V., 2012, Technical Report TXSTATE-CS-TR-2012-6, P6
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   Li JJ, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1793
   Lin L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P510, DOI 10.1109/vr.2019.8797787
   Liu A, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319823
   Liu R, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.792069
   Lohr Dillon, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P276, DOI 10.1109/TBIOM.2022.3167633
   Lohr D. J., 2020, ACM S EYE TRACKING R, P1, DOI DOI 10.1145/3379157.3391420
   Lohr D, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02075-5
   Lohr D, 2022, IEEE T INF FOREN SEC, V17, P3151, DOI 10.1109/TIFS.2022.3201369
   Lopes P., 2020, P 13 ACM SIGGRAPH C, P1, DOI [10.1145/3424636.34269069, DOI 10.1145/3424636.34269069]
   Lungaro P, 2018, IEEE T VIS COMPUT GR, V24, P1535, DOI 10.1109/TVCG.2018.2794119
   magicleap, Magic Leap | Devices
   magicleap, Magic Leap 2 Devices
   Makowski Silvia, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P506, DOI 10.1109/TBIOM.2021.3116875
   Marucci M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84196-8
   McCormick M, 2008, ADV INF SEC, V39, P53
   microsoft, HoloLens 2. hardware. 2
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P409, DOI 10.1109/VR51125.2022.00060
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P563, DOI 10.1109/VR51125.2022.00076
   Monteiro P, 2021, IEEE T VIS COMPUT GR, V27, P2702, DOI 10.1109/TVCG.2021.3067687
   Negin M, 2000, COMPUTER, V33, P70, DOI 10.1109/2.820042
   Normoyle Aline., 2013, Proceedings of motion on games, P141
   Orlov PA, 2015, PERCEPTION, V44, P1136, DOI 10.1177/0301006615594910
   Orquin JL, 2016, J BEHAV DECIS MAKING, V29, P103, DOI 10.1002/bdm.1867
   Papadimitriou S, 2007, ELE COM ENG, P459
   Peng SY, 2022, 2022 ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, ETRA 2022, DOI 10.1145/3517031.3531631
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Reichenberger J, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00035
   Ruhland K., 2015, P ACM SIGGRAPH S APP, P19
   Sammaknejad N, 2017, ADV COGN PSYCHOL, V13, P232, DOI 10.5709/acp-0223-1
   Sanches CL, 2017, PROC INT CONF DOC, P28, DOI 10.1109/ICDAR.2017.377
   Sannon Shruti, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555556
   Schroeder C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376534
   Seele S, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P531, DOI 10.1145/3116595.3116619
   Selinger E., 2023, Privacy Studies Journal, V2, P1, DOI [10.7146/psj.v2i.134656, DOI 10.7146/PSJ.V2I.134656]
   Shadiev R, 2023, COMPUT EDUC, V196, DOI 10.1016/j.compedu.2022.104681
   Shi YM, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101153
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Steil J, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319915
   Sun JL, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.972773
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Ugwitz P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031027
   Vargas-Cuentas NI, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188826
   vive, Vive Pro Eye Overview
   Wan GB, 2019, J AUTISM DEV DISORD, V49, P209, DOI 10.1007/s10803-018-3690-y
   Wang CC, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131911058
   Wei S, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2023, P216, DOI 10.1145/3573381.3596467
   Weier M, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3238301
   Weier M, 2016, COMPUT GRAPH FORUM, V35, P289, DOI 10.1111/cgf.13026
   Xiang H., 2022, 2022 8 INT C IMM LEA, P1, DOI [10.23919/iLRN55037.2022.9815935, DOI 10.23919/ILRN55037.2022.9815935]
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Zhang AT, 2018, IEEE IMAGE PROC, P2660, DOI 10.1109/ICIP.2018.8451219
   Zito GA, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0175-0
NR 83
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2257
EP 2268
DI 10.1109/TVCG.2024.3372032
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400016
PM 38457326
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Jin, YZ
   de Jong, TJA
   Tennekes, M
   Chen, M
AF Jin, Yuanzhe
   de Jong, Tim J. A.
   Tennekes, Martijn
   Chen, Min
TI Radial Icicle Tree (RIT): Node Separation and Area Constancy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tree visualization; icicle tree; sunburst tree; size encoding; area
   constancy; node separation; radial icicle tree; RIT
ID PLOTS
AB Icicles and sunbursts are two commonly-used visual representations of trees. While icicle trees can map data values faithfully to rectangles of different sizes, often some rectangles are too narrow to be noticed easily. When an icicle tree is transformed into a sunburst tree, the width of each rectangle becomes the length of an annular sector that is usually longer than the original width. While sunburst trees alleviate the problem of narrow rectangles in icicle trees, it no longer maintains the consistency of size encoding. At different tree depths, nodes of the same data values are displayed in annular sections of different sizes in a sunburst tree, though they are represented by rectangles of the same size in an icicle tree. Furthermore, two nodes from different subtrees could sometimes appear as a single node in both icicle trees and sunburst trees. In this paper, we propose a new visual representation, referred to as radial icicle tree (RIT), which transforms the rectangular bounding box of an icicle tree into a circle, circular sector, or annular sector while introducing gaps between nodes and maintaining area constancy for nodes of the same size. We applied the new visual design to several datasets. Both the analytical design process and user-centered evaluation have confirmed that this new design has improved the design of icicles and sunburst trees without introducing any relative demerit.
C1 [Jin, Yuanzhe; Chen, Min] Univ Oxford, Oxford, England.
   [de Jong, Tim J. A.; Tennekes, Martijn] Stat Netherlands, The Hague, Netherlands.
C3 University of Oxford
RP Jin, YZ (corresponding author), Univ Oxford, Oxford, England.
EM yuanzhe.jin@eng.ox.ac.uk; tja.dejong@cbs.nl; m.tennekes@cbs.nl;
   min.chen@eng.ox.ac.uk
RI de Jong, Tim/AAB-7813-2019
OI de Jong, Tim/0000-0002-6938-049X
FU Network of European Data Scientists (NeEDS)
FX No Statement Available
CR Abbas SS, 2013, VISION RES, V91, P84, DOI 10.1016/j.visres.2013.08.001
   [Anonymous], 1998, P IEEE S INF VIS
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Brinton W. C., 1939, Graphic presentation, P2
   Cawthon N, 2007, IEEE INT CONF INF VI, P637
   Chen M., 2019, Computer Graphics Forum, V38, P2
   Chen M., 2020, Foundations of Data Visualization, P2
   Chen M, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020228
   Chen M, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020282
   Chen M, 2016, IEEE T VIS COMPUT GR, V22, P2619, DOI 10.1109/TVCG.2015.2513410
   Chevalier F., 2007, ACM INT C PROCEEDING, P90
   Chi E. H., 1998, Proceedings of the SIGCHI conference on Human factors in computing systems, P400
   Chuah MC, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P35, DOI 10.1109/INFVIS.1998.729557
   Correll M., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P2
   Culy C, 2010, IEEE INT CONF INF VI, P98, DOI 10.1109/IV.2010.24
   Dasgupta A, 2012, COMPUT GRAPH FORUM, V31, P1015, DOI 10.1111/j.1467-8659.2012.03094.x
   Ducheyne S, 2009, J DOC, V65, P223, DOI 10.1108/00220410910937598
   Gou L, 2011, IEEE T VIS COMPUT GR, V17, P2449, DOI 10.1109/TVCG.2011.247
   Johnson B. S., 1993, Treemaps: Visualizing Hierarchical and Categorical Data, P2
   Kanjanabose R, 2015, COMPUT GRAPH FORUM, V34, P261, DOI 10.1111/cgf.12638
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   KLEINER B, 1981, J AM STAT ASSOC, V76, P260, DOI 10.2307/2287820
   Kosara R, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P101, DOI [10.1109/VISUAL.2019.8933547, 10.1109/visual.2019.8933547]
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Lam H.-C., 2012, International Scholarly Research Notices, P2
   Li G., 2022, IEEE Transactions on Visualization and Computer Graphics, V2
   Luo S.-J., 2011, IEEE Transactions on Visualization and Computer Graphics, V18, P2
   Maio V., 1990, Perceptual and Motor Skills, V71, P2
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   Morgan MJ, 2005, VISION RES, V45, P2564, DOI 10.1016/j.visres.2005.04.004
   Muramalla S, 2017, IADIS-INT J COMPUT S, V12, P17
   Nachmias J, 2008, VISION RES, V48, P1290, DOI 10.1016/j.visres.2008.02.024
   Nguyen QV, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P85, DOI 10.1109/INFVIS.2002.1173152
   Qi G, 2022, DISPLAYS, V75, DOI 10.1016/j.displa.2022.102325
   Rusu A., 2011, P 15 INT C INF VIS, P2
   Sadahiro Y, 2014, COMPUT ENVIRON URBAN, V45, P24, DOI 10.1016/j.compenvurbsys.2014.02.001
   Schloss KB, 2019, IEEE T VIS COMPUT GR, V25, P810, DOI 10.1109/TVCG.2018.2865147
   Schulz H.-J., 2010, IEEE Transactions on Visualization and Computer Graphics, V17, P2
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Skau D, 2016, COMPUT GRAPH FORUM, V35, P121, DOI 10.1111/cgf.12888
   Stasko J, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P57, DOI 10.1109/INFVIS.2000.885091
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Tan D., 2007, IEEE Transactions on Visualization and Computer Graphics, V13, P2
   Tekusová T, 2008, IEEE INT CONF INF VI, P143, DOI 10.1109/IV.2008.51
   Tennekes M, 2021, COMPUT GRAPH FORUM, V40, P323, DOI 10.1111/cgf.14310
   Tufte E., 2001, The Visual Display of Quantitative Information, V1, P2
   van de Wetering H, 2020, IEEE PAC VIS SYMP, P121, DOI 10.1109/PacificVis48177.2020.4908
   Wang Y., 2020, IEEE Transactions on Visualization and Computer Graphics, V26, P2
   Woodburn L, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P96, DOI [10.1109/VISUAL.2019.8933545, 10.1109/visual.2019.8933545]
   Yang J, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P77, DOI 10.1109/INFVIS.2002.1173151
   Yu Guangchuang, 2020, Curr Protoc Bioinformatics, V69, pe96, DOI 10.1002/cpbi.96
   Zellweger HP, 2016, IEEE INT CONF INF VI, P21, DOI 10.1109/IV.2016.75
   Zheng BY, 2021, IEEE PAC VIS SYMP, P136, DOI 10.1109/PacificVis52677.2021.00026
NR 54
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 251
EP 261
DI 10.1109/TVCG.2023.3327178
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500076
PM 37883266
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Piochowiak, M
   Dachsbacher, C
AF Piochowiak, Max
   Dachsbacher, Carsten
TI Fast Compressed Segmentation Volumes for Scientific Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Segmentation volumes; lossless compression; volume rendering
ID OF-THE-ART; EXPLORATION; BRAIN
AB Voxel-based segmentation volumes often store a large number of labels and voxels, and the resulting amount of data can make storage, transfer, and interactive visualization difficult. We present a lossless compression technique which addresses these challenges. It processes individual small bricks of a segmentation volume and compactly encodes the labelled regions and their boundaries by an iterative refinement scheme. The result for each brick is a list of labels, and a sequence of operations to reconstruct the brick which is further compressed using rANS-entropy coding. As the relative frequencies of operations are very similar across bricks, the entropy coding can use global frequency tables for an entire data set which enables efficient and effective parallel (de)compression. Our technique achieves high throughput (up to gigabytes per second both for compression and decompression) and strong compression ratios of about 1% to 3% of the original data set size while being applicable to GPU-based rendering. We evaluate our method for various data sets from different fields and demonstrate GPU-based volume visualization with on-the-fly decompression, level-of-detail rendering (with optional on-demand streaming of detail coefficients to the GPU), and a caching strategy for decompressed bricks for further performance improvement.
C1 [Piochowiak, Max; Dachsbacher, Carsten] Karlsruhe Inst Technol, Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Piochowiak, M (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM max.piochowiak@kit.edu; dachsbacher@kit.edu
OI Piochowiak, Max/0000-0003-1980-6146
FU Helmholtz Association (HGF)
FX No Statement Available
CR Agus M, 2022, IEEE VIS CONF, P130, DOI 10.1109/VIS54862.2022.00035
   Ai-Thelaya K, 2021, IEEE T VIS COMPUT GR, V27, P645, DOI 10.1109/TVCG.2020.3030451
   Al-Awami AK, 2016, IEEE T VIS COMPUT GR, V22, P738, DOI 10.1109/TVCG.2015.2467441
   Anagnostou K., 2000, P 2000 S VOLUME VISU, P129, DOI [10.1145/353888.353909, DOI 10.1145/353888.353909]
   Berger DR, 2018, FRONT NEURAL CIRCUIT, V12, DOI 10.3389/fncir.2018.00088
   Berghoff M, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03728-7
   Beyer J, 2022, COMPUT GRAPH FORUM, V41, P573, DOI 10.1111/cgf.14574
   Beyer J, 2019, IEEE T VIS COMPUT GR, V25, P1132, DOI 10.1109/TVCG.2018.2864847
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Beyer J, 2013, IEEE COMPUT GRAPH, V33, P50, DOI 10.1109/MCG.2013.55
   Careil V, 2020, COMPUT GRAPH FORUM, V39, P111, DOI 10.1111/cgf.13916
   Choi J, 2021, IEEE ACCESS, V9, P78755, DOI 10.1109/ACCESS.2021.3084066
   Dado B, 2016, COMPUT GRAPH FORUM, V35, P397, DOI 10.1111/cgf.12841
   Dolonius D, 2019, IEEE T VIS COMPUT GR, V25, P1270, DOI 10.1109/TVCG.2017.2741480
   Duda J, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P65, DOI 10.1109/PCS.2015.7170048
   Ernst M., 2004, PROC INT MESHING ROU, P6
   Fowler J. E., 1994, PROC IEEE S VOLUME V, P43, DOI DOI 10.1145/197938.197961
   Google Inc, Neuroglancer
   Guthe S., 2016, 3DTV C TRUE VISION C, P1, DOI [10.1109/3DTV.2016.75488922, DOI 10.1109/3DTV.2016.75488922]
   Hadwiger M, 2018, IEEE T VIS COMPUT GR, V24, P974, DOI 10.1109/TVCG.2017.2744238
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094
   Ihm I, 1999, COMPUT GRAPH FORUM, V18, P3, DOI 10.1111/1467-8659.00298
   Jönsson D, 2014, COMPUT GRAPH FORUM, V33, P27, DOI 10.1111/cgf.12252
   Kämpe V, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462024
   Kobbelt LP, 2001, COMP GRAPH, P57, DOI 10.1145/383259.383265
   Laine S., 2010, Proceedings of the Symposium on Interactive 3D Graphics and Games, P55, DOI DOI 10.1145/1730804.1730814
   Lempitsky V, 2010, PROC CVPR IEEE, P1197, DOI 10.1109/CVPR.2010.5539832
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Mado3 B., 2021, IEEE WORLD S APPL MA, DOI [10.1109/SAMI50585.2021.93786752, DOI 10.1109/SAMI50585.2021.93786752]
   Mados B., 2020, 2020 18th International Conference on Emerging eLearning Technologies and Applications (ICETA), P424, DOI 10.1109/ICETA51985.2020.9379265
   Mados B, 2019, IEEE INT CONF INTELL, P75, DOI [10.1109/INES46365.2019.9109528, 10.1109/ines46365.2019.9109528]
   Matejek Brian, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P781, DOI 10.1007/978-3-319-66182-7_89
   Maurer J, 2022, NONDESTRUCT TEST EVA, V37, P582, DOI 10.1080/10589759.2022.2075865
   Motta A, 2019, SCIENCE, V366, P1093, DOI 10.1126/science.aay3134
   Mueller JH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275087
   Museth Ken, 2021, ACM SIGGRAPH 2021 TA, DOI DOI 10.1145/3450623.3464653
   Newman TS, 2006, COMPUT GRAPH-UK, V30, P854, DOI 10.1016/j.cag.2006.07.021
   Rahman MA, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101274
   RHODES ML, 1985, IEEE T MED IMAGING, V4, P84, DOI 10.1109/TMI.1985.4307701
   Rodríguez MB, 2014, COMPUT GRAPH FORUM, V33, P77, DOI 10.1111/cgf.12280
   Rosenbauer J., 2020, bioRxiv, DOI [10.1101/2020.08.24.264150, DOI 10.1101/2020.08.24.264150]
   Troidl J, 2022, COMPUT GRAPH FORUM, V41, P183, DOI 10.1111/cgf.14532
   Villanueva AJ, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P7, DOI 10.1145/2856400.2856420
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Weissenberger A, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225076
   Weissenböck J, 2014, IEEE PAC VIS SYMP, P153, DOI 10.1109/PacificVis.2014.52
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
NR 50
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 12
EP 22
DI 10.1109/TVCG.2023.3326573
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500073
PM 37871064
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Borhani, Z
   Sharma, P
   Ortega, FR
AF Borhani, Zahra
   Sharma, Prashast
   Ortega, Francisco R.
TI Survey of Annotations in Extended Reality Systems
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Annotation; augmented reality; extended reality; immersive technologies;
   virtual reality
ID VISUALIZATION; DESIGN
AB Annotation in 3D user interfaces such as Augmented Reality (AR) and Virtual Reality (VR) is a challenging and promising area; however, there are not currently surveys reviewing these contributions. In order to provide a survey of annotations for Extended Reality (XR) environments, we conducted a structured literature review of papers that used annotation in their AR/VR systems from the period between 2001 and 2021. Our literature review process consists of several filtering steps which resulted in 103 XR publications with a focus on annotation. We classified these papers based on the display technologies, input devices, annotation types, target object under annotation, collaboration type, modalities, and collaborative technologies. A survey of annotation in XR is an invaluable resource for researchers and newcomers. Finally, we provide a database of the collected information for each reviewed paper. This information includes applications, the display technologies and its annotator, input devices, modalities, annotation types, interaction techniques, collaboration types, and tasks for each paper. This database provides a rapid access to collected data and gives users the ability to search or filter the required information. This survey provides a starting point for anyone interested in researching annotation in XR environments.
C1 [Borhani, Zahra; Ortega, Francisco R.] Colorado State Univ, Ft Collins, CO 80523 USA.
   [Sharma, Prashast] Univ Florida, Gainesville, FL 32611 USA.
C3 Colorado State University; State University System of Florida;
   University of Florida
RP Borhani, Z; Ortega, FR (corresponding author), Colorado State Univ, Ft Collins, CO 80523 USA.
EM zahra.borhani@colostate.edu; prashast.sharma@ufl.edu;
   fortega@colostate.edu
OI Sharma, Prashast/0009-0005-2680-7229
FU NSF [2327569, 2238313, 2223432, 2223459, 2106590, 2016714, 2037417,
   1948254]
FX This work was supported in part by NSF under Grants 2327569,
   2238313,2223432, 2223459, 2106590, 2016714, 2037417, and 1948254.
   Recommendedfor acceptance by Kiyoshi Kiyokawa
CR Abrami Giuseppe, 2020, HT '20: Proceedings of the 31st ACM Conference on Hypertext and Social Media, P177, DOI 10.1145/3372923.3404791
   Adcock M., 2013, P 12 ACM SIGGRAPH IN, P235
   Al-Megren S, 2015, LECT NOTES COMPUT SC, V9299, P156, DOI 10.1007/978-3-319-22723-8_13
   Amma C., 2016, P CHI C HUM FACT COM, P3639
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Austin CR, 2020, CARTOGR GEOGR INF SC, V47, P214, DOI 10.1080/15230406.2019.1696232
   Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Ball R., 2005, CHI'05 extended abstracts on Human factors in computing systems, P1196
   Baumeister J, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY WORKSHOPS, P4, DOI 10.1109/ISMARW.2015.11
   Bell B., 2002, P 15 ANN ACM S USER, P213
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Burigat S., 2006, P 8 C HUM COMP INT M, P239
   Caluya NR, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P866, DOI [10.1109/vr.2019.8798216, 10.1109/VR.2019.8798216]
   Casas S., 2020, SMART SYSTEMS DESIGN, P299
   Chaconas N., 2018, P IEEE C VIRT REAL 3, P1
   Chandler T., 2015, P BIG DAT VIS AN, P8
   Chang YS, 2017, IEEE SYMP 3D USER, P182, DOI 10.1109/3DUI.2017.7893337
   Chang YS, 2017, P IEEE VIRT REAL ANN, P469, DOI 10.1109/VR.2017.7892383
   Chin G, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P11
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   D'Angelo S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2492, DOI 10.1145/2858036.2858499
   Danyluk K, 2022, IEEE T VIS COMPUT GR, V28, P1930, DOI 10.1109/TVCG.2020.3023336
   Dao B, 2013, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2013.6549411
   de Belen R. A. J., 2019, AIMS Electronics and Electrical, V3, P181, DOI [10.3934/electreng.2019.2.181, 10.3934/ElectrEng.2019.2.181]
   Dominic J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P607, DOI [10.1109/VR46266.2020.1581637338566, 10.1109/VR46266.2020.00-21]
   Dow S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1475
   Dunser A., 2008, TR200802 HUM INT TEC
   Edlin L., 2020, P INT C HUM COMP INT, P54
   Emerson L, 2021, INT SYM MIX AUGMENT, P183, DOI 10.1109/ISMAR-Adjunct54149.2021.00045
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fedorov R, 2016, LECT NOTES COMPUT SC, V9768, P281, DOI 10.1007/978-3-319-40621-3_21
   Ferdous HS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300464
   Fiorentino M, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P86, DOI 10.1109/ISMAR.2002.1115077
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   García-Pereira I, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 1: GRAPP, P412, DOI 10.5220/0009193404120419
   García-Pereira I, 2020, MULTIMED TOOLS APPL, V79, P6483, DOI 10.1007/s11042-019-08419-x
   Gasques D., 2021, P CHI C HUM FACT COM, P14
   Gauglitz S., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P449, DOI 10.1145/2642918.2647372
   Gauglitz S., 2014, P 20 ACM S VIRT REAL, P197
   Haller M, 2006, LECT NOTES COMPUT SC, V4282, P185
   Handa D., 2013, P INT C VIRT AUGM MI, P23
   Haouach M, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P337
   Hart JD, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P212, DOI 10.1109/ISMAR-Adjunct.2018.00069
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Hertel J, 2021, INT SYM MIX AUGMENT, P431, DOI 10.1109/ISMAR52148.2021.00060
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hoang T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1419, DOI 10.1145/3025453.3025860
   Hollerer T., 2007, Proceedings of the 2007 workshop on Emerging displays technologies: images and beyond: the future of displays and interacton, P3, DOI [DOI 10.1145/1278240.1278243, 10.1145/1278240.1278243]
   Irlitti A, 2013, INT SYM MIX AUGMENT
   Ishii H., 2007, P CD ROM INT S SYMB, P262
   Kang D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094288
   Kasapakis V., 2018, P INT C AUGM REAL VI, P423
   Ke CZ, 2005, LECT NOTES COMPUT SC, V3784, P836
   Kim H., 2011, P IEEE 10 INT S MIX, P265
   Kim S., 2013, P IEEE INT S MIX AUG, P6
   Kim S., 2004, P ACM SIGGRAPH INT C, P336
   Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714
   Kishishita N, 2014, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2014.6948425
   Koeda M, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P288, DOI 10.1109/ISMAR.2004.15
   Kuhn V., 2020, P INT C HUM COMP INT, P299
   Kumaravel Balasaravanan Thoravi, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P182, DOI 10.1145/3379337.3415827
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Langlotz T., 2013, P 25 AUSTR COMP HUM, P545, DOI [DOI 10.1145/2541016.2541022, 10.1145/2541016.2541022]
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee G. A., 2012, P 11 ACM SIGGRAPH IN, P279
   Leoet J., 2021, P AS CHI S 2021, P132
   Lien KC, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P184, DOI 10.1109/ISMAR.2015.56
   Lin CY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P212, DOI [10.1109/VR46266.2020.00-64, 10.1109/VR46266.2020.1580934001692]
   Lin CY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P3, DOI 10.1109/ISMAR-Adjunct.2018.00021
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Liu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6730, DOI 10.1145/3025453.3025594
   Luo WZ, 2021, INT SYM MIX AUGMENT, P334, DOI 10.1109/ISMAR-Adjunct54149.2021.00076
   MacIntyre B., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P65, DOI 10.1109/ISMAR.2011.6092371
   Madsen JB, 2016, IEEE T VIS COMPUT GR, V22, P1415, DOI 10.1109/TVCG.2016.2518318
   Mahmood T, 2019, INT SYM MIX AUGMENT, P236, DOI 10.1109/ISMAR.2019.00021
   Marner MR, 2013, INT SYM MIX AUGMENT, P39, DOI 10.1109/ISMAR.2013.6671762
   Marques B., 2022, P EUR C COMP SUPP CO, P9
   Marques B, 2022, INT J INTERACT DES M, V16, P419, DOI 10.1007/s12008-021-00798-6
   Marques B, 2022, IEEE T VIS COMPUT GR, V28, P5113, DOI 10.1109/TVCG.2021.3101545
   Marques B, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P567, DOI 10.1109/VRW52623.2021.00166
   Matos T., 2018, P 23 INT ACM C 3D WE, P4
   McNamara A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P36, DOI [10.1109/ISMAR-Adjunct.2016.0033, 10.1109/ISMAR-Adjunct.2016.26]
   Medeiros ML, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P465, DOI 10.1109/ISMAR-Adjunct.2019.00125
   Mehler A, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P150, DOI 10.1145/3209542.3209572
   Mohanty RR, 2018, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2018, VOL 1B
   Mohr P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3337, DOI 10.1145/2702123.2702490
   Mohr-Ziak P., 2020, P ACM CHI C HUM FACT, P12
   Mooser J., 2007, P IEEEACM INT S MIXE, P145
   Morris M. R., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1201
   Noh Seungtak., 2015, ICAT-EGVE, P61
   Nuernberger B, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P129, DOI 10.1145/2993369.2993371
   Nuernberger B, 2016, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2016.7504746
   Nuernberger B, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P149, DOI 10.1109/3DUI.2016.7460046
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Olsson T., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P75, DOI 10.1109/ISMAR.2011.6092372
   Peña AM, 2019, LECT NOTES COMPUT SC, V11575, P338, DOI 10.1007/978-3-030-21565-1_23
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Pick S, 2016, IEEE T VIS COMPUT GR, V22, P1452, DOI 10.1109/TVCG.2016.2518086
   Pick S, 2015, P IEEE VIRT REAL ANN, P261, DOI 10.1109/VR.2015.7223395
   Piumsomboon T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186495
   Piumsomboon T, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P218, DOI 10.1109/ISMAR-Adjunct.2017.72
   Polvi J, 2018, IEEE T VIS COMPUT GR, V24, P2118, DOI 10.1109/TVCG.2017.2709746
   Radu I, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451561
   Raskar R., 2001, Proceedings AFRIGRAPH 2001. 1st International Conference on Computer Graphics, Virtual Reality and Visualisation, P101, DOI 10.1145/513867.513889
   Raskar R, 1999, AUGMENTED REALITY, P63
   Rebol M, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P653, DOI 10.1109/VRW52623.2021.00209
   Reitmayr G., 2007, P IEEEACM INT S MIXE, P67
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Rodrigue M, 2015, P IEEE VIRT REAL ANN, P105, DOI 10.1109/VR.2015.7223331
   Romat H., 2021, P CHI C HUM FACT COM, P4
   Romat H, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P306, DOI 10.1109/VR50410.2021.00053
   Romat H, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P749, DOI 10.1109/VRW52623.2021.00257
   Romat H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300272
   Ryskeldiev B, 2018, COMPANION OF THE 2018 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'18), P373, DOI 10.1145/3272973.3274100
   Sankaran NK, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P664, DOI 10.1109/vr.2019.8798089
   Santos MEC, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P196, DOI 10.1109/ISMAR.2015.62
   Sasikumar P, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P393, DOI 10.1109/ISMAR-Adjunct.2019.000-3
   Schall G, 2008, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2008.4637332
   Schmalstieg D., 2016, Augmented reality: principles and practice
   Selonen P., 2010, P 1 INT WORKSH RESTF, P54
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Skinner P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P145, DOI 10.1109/ISMAR-Adjunct.2018.00054
   Slater M., 2003, PRESENCE CONNECT, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Speicher Maximilian, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3229091
   Sun H., 2016, P 28 AUSTR C COMP HU, P195
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI DOI 10.1145/642611.642626
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tatzgern M, 2013, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2013.6549347
   Tenmoku R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P192
   Teo T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1187, DOI [10.1109/VR.2019.8798128, 10.1109/vr.2019.8798128]
   Teo T, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P406, DOI 10.1145/3292147.3292200
   Thomas Bruce H., 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P33, DOI 10.1109/ISMAR.2006.297791
   Tomlein M., 2018, PROC ACM HUMCOMPUT I, V2, P1
   Utzig S, 2019, AEROSP CONF PROC
   Volmer B, 2018, IEEE T VIS COMPUT GR, V24, P2846, DOI 10.1109/TVCG.2018.2868587
   Wang P, 2020, INT J HUM-COMPUT INT, V36, P1242, DOI 10.1080/10447318.2020.1732140
   Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071
   Wang P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P77, DOI 10.1109/ISMAR-Adjunct.2018.00038
   Wang Z., 2020, P SIGGRAPH AS POST, P1
   Wang Z, 2021, INT J HUM-COMPUT INT, V37, P1799, DOI 10.1080/10447318.2021.1909278
   Weibel N., 2020, P CHI C HUM FACT COM, P4
   Wither J, 2006, INT SYM MIX AUGMENT, P219
   Wither J, 2008, INT SYM MIX AUGMENT, P65, DOI 10.1109/ISMAR.2008.4637326
   Wither J, 2009, COMPUT GRAPH-UK, V33, P679, DOI 10.1016/j.cag.2009.06.001
   Wright W., 2006, Conference on Human Factors in Computing Systems. CHI2006, P801
   Xue T., 2021, P CHI C HUM FACT COM, P1
   Xue T, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P371, DOI 10.1109/AIVR50618.2020.00076
   Yamada S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P727, DOI 10.1109/VR.2018.8446287
   Yang J, 2020, J MULTIMODAL USER IN, V14, P337, DOI 10.1007/s12193-020-00331-1
   Yonemoto Satoshi, 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P418, DOI 10.1007/978-3-319-07458-0_39
NR 156
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5074
EP 5096
DI 10.1109/TVCG.2023.3288869
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400032
PM 37352090
DA 2024-08-05
ER

PT J
AU Hashemian, AM
   Adhikari, A
   Aguilar, IA
   Kruijff, E
   von der Heyde, M
   Riecke, BE
AF Hashemian, Abraham M.
   Adhikari, Ashu
   Aguilar, Ivan A.
   Kruijff, Ernst
   von der Heyde, Markus
   Riecke, Bernhard E.
TI Leaning-Based Interfaces Improve Simultaneous Locomotion and Object
   Interaction in VR Compared to the Handheld Controller
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 3D user interface; dual task; continuous interaction; motion sickness;
   cybersickness; locomotion; travel techniques; virtual reality
ID VIRTUAL ENVIRONMENTS; PERFORMANCE; ORIENTATION; TRAVEL; GAMES
AB Physical walking is often considered the gold standard for VR travel whenever feasible. However, limited free-space walking areas in the real-world do not allow exploring larger-scale virtual environments by actual walking. Therefore, users often require handheld controllers for navigation, which can reduce believability, interfere with simultaneous interaction tasks, and exacerbate adverse effects such as motion sickness and disorientation. To investigate alternative locomotion options, we compared handheld Controller (thumbstick-based) and physical walking versus a seated (HeadJoystick) and standing/stepping (NaviBoard) leaning-based locomotion interface, where seated/standing users travel by moving their head toward the target direction. Rotations were always physically performed. To compare these interfaces, we designed a novel simultaneous locomotion and object interaction task, where users needed to keep touching the center of upward moving target balloons with their virtual lightsaber, while simultaneously staying inside a horizontally moving enclosure. Walking resulted in the best locomotion, interaction, and combined performances while the controller performed worst. Leaning-based interfaces improved user experience and performance compared to Controller, especially when standing/stepping using NaviBoard, but did not reach walking performance. That is, leaning-based interfaces HeadJoystick (sitting) and NaviBoard (standing) that provided additional physical self-motion cues compared to controller improved enjoyment, preference, spatial presence, vection intensity, motion sickness, as well as performance for locomotion, object interaction, and combined locomotion and object interaction. Our results also showed that less embodied interfaces (and in particular the controller) caused a more pronounced performance deterioration when increasing locomotion speed. Moreover, observed differences between our interfaces were not affected by repeated interface usage.
C1 [Hashemian, Abraham M.; Adhikari, Ashu; Aguilar, Ivan A.; Kruijff, Ernst; von der Heyde, Markus; Riecke, Bernhard E.] Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
   [Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, D-53757 St Augustin, Germany.
   [von der Heyde, Markus] Simon Fraser Univ, VdH IT, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University; Hochschule Bonn Rhein Sieg; Simon Fraser
   University
RP Hashemian, AM (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
EM hashemia@sfu.ca; ashua@sfu.ca; ivan_aguilar@sfu.ca;
   ernst.kruijff@h-brs.de; info@vdh-it.de; ber1@sfu.ca
RI ; Riecke, Bernhard/C-6399-2011
OI Kruijff, Ernst/0000-0003-1625-0955; Aguilar, Ivan/0000-0002-8735-4041;
   von der Heyde, Markus/0000-0002-6026-082X; Hashemian, Abraham
   M./0000-0001-8385-4332; Riecke, Bernhard/0000-0001-7974-0850; Adhikari,
   Ashu/0000-0002-2540-6344
FU NSERC [R611547]
FX This work was supported by NSERC under Grant R611547.
CR Adhikari A, 2023, IEEE T VIS COMPUT GR, V29, P5265, DOI 10.1109/TVCG.2022.3207157
   Adhikari A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730334
   Badcock DR, 2015, HUM FACTORS ERGON, P39
   Beckhaus S., 2005, Proc. Comput. Sci. Magic, P1
   Beckhaus Steffi., 2005, New Directions in 3D User Interfaces Workshop of IEEE VR, P57
   Bowman D. A., 1998, Virtual Reality, V3, P120, DOI 10.1007/BF01417673
   Bowman D. A., 1999, Ph.D. dissertation
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Brument H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P680, DOI [10.1109/VR.2019.8797721, 10.1109/vr.2019.8797721]
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Chester MR, 2002, INT J IND ERGONOM, V29, P289, DOI 10.1016/S0169-8141(01)00069-5
   Cunningham DW, 2001, J VISION, V1, P88, DOI 10.1167/1.2.3
   de Winter JCF, 2009, ERGONOMICS, V52, P137, DOI 10.1080/00140130802277521
   Farrell MJ, 1998, J EXP PSYCHOL LEARN, V24, P227, DOI 10.1037/0278-7393.24.1.227
   Field A., 2013, Discovering Statistics using IBM SPSS Statistics, Vthird, P374, DOI DOI 10.1016/B978-012691360-6/50012-4
   Freiberg J., 2015, Master's thesis,
   Games B., 2019, Beat saber
   Griffin NN, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P211, DOI 10.1145/3242671.3242707
   Ha C, 2015, IEEE INT CONF ROBOT, P164, DOI 10.1109/ICRA.2015.7138995
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231, DOI DOI 10.1145/2670473.2670512
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hashemian A. M., 2017, P SOFTW AUGM VIRT RE, P1
   Hashemian AM, 2022, IEEE T VIS COMPUT GR, V28, P1792, DOI 10.1109/TVCG.2020.3025084
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Hashemian AM, 2023, IEEE T VIS COMPUT GR, V29, P1748, DOI 10.1109/TVCG.2021.3131422
   Jerald J., 2016, VR BOOK HUMAN CENTER
   Jong-Won Yoon, 2010, 2010 IEEE Information Theory Workshop (ITW 2010), P69, DOI 10.1109/ITW.2010.5593369
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kitson A., 2015, P 3 ACM S SPATIAL US, P123, DOI DOI 10.1145/2788940.2788956
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Krompiec P, 2019, IEEE ACCESS, V7, P124548, DOI 10.1109/ACCESS.2019.2937937
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   LaViola J.J., 2017, 3D user interfaces: theory and practice
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Lugrin J.-L., 2013, P ACM INT WORKSH IMM, P7, DOI [10.1145/2512142.2512146, 10.1145/2512142, DOI 10.1145/2512142]
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Martel E., 2015, P INT C FDN DIG GAM, P1
   Martel E, 2017, ENTERTAIN COMPUT, V21, P19, DOI 10.1016/j.entcom.2017.04.004
   Mayor J, 2021, IEEE T EMERG TOP COM, V9, P1542, DOI 10.1109/TETC.2019.2915287
   McMahan R. P., 2011, Exploring the effects of higher-fidelity display and interaction for virtual reality games
   McMahan RP, 2015, HUM FACTORS ERGON, P285
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Müller T, 2019, NEUROPSYCHOLOGIA, V123, P141, DOI 10.1016/j.neuropsychologia.2018.04.030
   Natapov D., 2009, Proceedings of Graphics Interface 2009, P223
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Prithul A., 2021, Proc. Graph. Interface, P1
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI [10.1145/1180495.1180517, DOI 10.1145/1180495.1180517]
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Riecke BE, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P147
   Riecke BernhardE., 2012, P ACM S APPL PERCEPT, P17, DOI DOI 10.1145/2338676.2338680
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Rogers K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300644
   Rognon C, 2018, IEEE ROBOT AUTOM LET, V3, P2362, DOI 10.1109/LRA.2018.2810955
   Ruddle R.A., 2013, HUMAN WALKING VIRTUA, P99, DOI [10.1007/978-1-4419-8432-6_5, DOI 10.1007/978-1-4419-8432-6_5]
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Sait MSMY, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P64, DOI 10.1145/3191801.3191814
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Sigurdarson S., 2014, Master's thesis
   Sigurdarson S, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P31, DOI 10.1109/VR.2012.6180874
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Steinicke F., 2013, Human Walking in Virtual Environments
   Tedjokusumo J, 2010, IEEE T SYST MAN CY A, V40, P147, DOI 10.1109/TSMCA.2009.2028432
   van Mier H, 2006, HUM MOVEMENT SCI, V25, P657, DOI 10.1016/j.humov.2006.06.004
   Wells M., 1996, P IEEE C VIRT REAL 3, V97, P1
   Wiedemann D. P., 2020, P 4 INT SCI FICT PRO, P49
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Zhai SM, 2004, PRESENCE-TELEOP VIRT, V13, P113, DOI 10.1162/1054746041382393
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P297, DOI [10.1109/VRW50115.2020.00067, 10.1109/VRW50115.2020.0-209]
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P398, DOI [10.1109/VR46266.2020.00-44, 10.1109/VR46266.2020.1581426770550]
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 79
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4665
EP 4682
DI 10.1109/TVCG.2023.3275111
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400081
PM 37200130
DA 2024-08-05
ER

PT J
AU Lau, CK
   Xia, MH
   Wong, TT
AF Lau, Cheuk-Kit
   Xia, Menghan
   Wong, Tien-Tsin
TI Taming Reversible Halftoning Via Predictive Luminance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image restoration; Image color analysis; Image coding; Gray-scale;
   Color; Predictive coding; Logic gates; Blue-noise; deep learning;
   reversible halftoning
ID IMAGE COMPRESSION; ALGORITHM; COLOR; GRAYSCALE; GRAY
AB Traditional halftoning usually drops colors when dithering images with binary dots, which makes it difficult to recover the original color information. We proposed a novel halftoning technique that converts a color image into a binary halftone with full restorability to its original version. Our novel base halftoning technique consists of two convolutional neural networks (CNNs) to produce the reversible halftone patterns, and a noise incentive block (NIB) to mitigate the flatness degradation issue of CNNs. Furthermore, to tackle the conflicts between the blue-noise quality and restoration accuracy in our novel base method, we proposed a predictor-embedded approach to offload predictable information from the network, which in our case is the luminance information resembling from the halftone pattern. Such an approach allows the network to gain more flexibility to produce halftones with better blue-noise quality without compromising the restoration quality. Detailed studies on the multiple-stage training method and loss weightings have been conducted. We have compared our predictor-embedded method and our novel method regarding spectrum analysis on halftone, halftone accuracy, restoration accuracy, and the data embedding studies. Our entropy evaluation evidences our halftone contains less encoding information than our novel base method. The experiments show our predictor-embedded method gains more flexibility to improve the blue-noise quality of halftones and maintains a comparable restoration quality with a higher tolerance for disturbances.
C1 [Lau, Cheuk-Kit] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Xia, Menghan] Tencent AI Lab, Bellevue, WA 98004 USA.
C3 Chinese University of Hong Kong
RP Lau, CK (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
EM cklau21@cse.cuhk.edu.hk; menghanxyz@gmail.com; ttwong@cse.cuhk.edu.hk
OI Wong, Tien-Tsin/0000-0002-7792-9307; Lau, Cheuk-Kit/0000-0003-3293-8362
FU RGC [4055152]
FX This work was supported by RGC under Grant 4055152. Recommended
   foracceptance by T. Lee.
CR Anastassiou D., 1988, 1988 IEEE International Symposium on Circuits and Systems. Proceedings (Cat. No.88CH2458-8), P507, DOI 10.1109/ISCAS.1988.14975
   [Anonymous], 1987, Digital Halftoning
   Ardizzone L, 2019, Arxiv, DOI [arXiv:1907.02392, 10.48550/arXiv.1907.02392]
   Avinery R, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.178102
   Baronchelli A, 2005, EUR J PHYS, V26, pS69, DOI 10.1088/0143-0807/26/5/S08
   Bayer B. E., 1973, P IEEE INT C COMM, P2611
   Behrmann J, 2019, PROC INT C MACH LEAR, V97, P573
   Bengio Y, 2013, Arxiv, DOI arXiv:1308.3432
   Chandu M., 2013, COLOR IMAGING
   Chang JH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618508
   Chen LM, 1997, IEEE T IMAGE PROCESS, V6, P1202, DOI 10.1109/83.605420
   CROUNSE KR, 1993, IEEE T CIRCUITS-II, V40, P267, DOI 10.1109/82.224318
   de Queiroz RL, 2006, IEEE T IMAGE PROCESS, V15, P1464, DOI 10.1109/TIP.2006.871181
   Dinh L, 2017, Arxiv, DOI [arXiv:1605.08803, DOI 10.48550/ARXIV.1605.08803]
   ESCHBACH R, 1991, J OPT SOC AM A, V8, P1844, DOI 10.1364/JOSAA.8.001844
   Everingham M., 2012, PASCAL VISUAL OBJECT
   FLOYD RW, 1976, P SID, V17, P75
   Freitas PG, 2016, SIGNAL PROCESS-IMAGE, V49, P1, DOI 10.1016/j.image.2016.09.008
   Fung YH, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013013
   Gailly M., 2004, Zlib compression library
   Gao X., 2019, P IEEE CVF INT C COM, P4120
   Han TD, 2019, IEEE INT CONF COMP V, P1483, DOI 10.1109/ICCVW.2019.00186
   Hein Soren., 1993, Delta Modulators, V213, P133
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Huang WB, 2008, EXPERT SYST APPL, V34, P2491, DOI 10.1016/j.eswa.2007.04.013
   Jacobsen JH, 2018, Arxiv, DOI [arXiv:1802.07088, 10.48550/arXiv.1802.07088]
   Kim TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201377
   KIM YT, 1995, IEEE T IMAGE PROCESS, V4, P1296, DOI 10.1109/83.413173
   Kingma DP, 2018, ADV NEUR IN, V31
   Kite TD, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P59, DOI 10.1109/ICIP.1998.723317
   KNUTH DE, 1987, ACM T GRAPHIC, V6, P245, DOI 10.1145/35039.35040
   Kumar D., 2021, P INT C LEARN REPR
   Lagae A., 2008, P SIGGRAPH C CLASS, P93
   Lai JZC, 2003, J VIS COMMUN IMAGE R, V14, P389, DOI 10.1016/S1047-3203(03)00041-5
   Lee JH, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/430235
   Lee JH, 2009, SIGMAP 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P86
   Li X, 2006, IEEE SIGNAL PROC LET, V13, P688, DOI 10.1109/LSP.2006.879465
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P1092, DOI 10.1109/TIP.2018.2872876
   LIMB JO, 1969, AT&T TECH J, V48, P2555, DOI 10.1002/j.1538-7305.1969.tb01187.x
   LIPPEL B, 1971, IEEE T COMMUN TECHN, VCO19, P879, DOI 10.1109/TCOM.1971.1090773
   Liu Y, 2021, PROC CVPR IEEE, P13360, DOI 10.1109/CVPR46437.2021.01316
   Luo T, 2014, IEEE IMAGE PROC, P5492, DOI 10.1109/ICIP.2014.7026111
   Mese M, 2001, IEEE T IMAGE PROCESS, V10, P1566, DOI 10.1109/83.951541
   Mingqing Xiao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P126, DOI 10.1007/978-3-030-58452-8_8
   MITSA T, 1992, J OPT SOC AM A, V9, P1920, DOI 10.1364/JOSAA.9.001920
   Ostromoukhov V, 2004, ACM T GRAPHIC, V23, P488, DOI 10.1145/1015706.1015750
   Ostromoukhov V, 2001, COMP GRAPH, P567, DOI 10.1145/383259.383326
   Pang Y. Qu, 2008, P ACM SIGGRAPH C PAP, P1
   R. I.-R. Bt, 2011, Tech. Rep. ITU-R BT.601-6
   ROETLING PG, 1976, J OPT SOC AM, V66, P985, DOI 10.1364/JOSA.66.000985
   SAID A, 1993, P SOC PHOTO-OPT INS, V2094, P664, DOI 10.1117/12.157984
   Shannon C. E., 2005, Eur. J. Phys., V26
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Son CH, 2014, IEEE T IMAGE PROCESS, V23, P2542, DOI 10.1109/TIP.2014.2319732
   Son CH, 2012, OPT LETT, V37, P2352, DOI 10.1364/OL.37.002352
   Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009
   Spratling MW, 2017, BRAIN COGNITION, V112, P92, DOI 10.1016/j.bandc.2015.11.003
   Tan WM, 2020, IEEE T MULTIMEDIA, V22, P1730, DOI 10.1109/TMM.2019.2959925
   TING MY, 1994, IEEE T IMAGE PROCESS, V3, P854, DOI 10.1109/83.336256
   ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288
   Unal GB, 2001, IEEE T IMAGE PROCESS, V10, P1836, DOI 10.1109/83.974568
   van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WONG PW, 1995, IEEE T IMAGE PROCESS, V4, P486, DOI 10.1109/83.370677
   Xia MH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275080
   Xia Menghan, 2018, ACM Trans.Graph., V37, P1
   Xia W., 2021, P IEEE CVF INT C COM, P14000
   Xiao Y, 2017, I C VIRTUAL REALITY, P213, DOI 10.1109/ICVRV.2017.00051
   Xing JB, 2022, Arxiv, DOI arXiv:2201.12576
   Xiong ZX, 1999, IEEE T IMAGE PROCESS, V8, P1479, DOI 10.1109/83.791977
   Xu ZX, 2017, SIGNAL PROCESS-IMAGE, V52, P111, DOI 10.1016/j.image.2016.12.005
   Yang WC, 2015, MULTIMED TOOLS APPL, V74, P7181, DOI 10.1007/s11042-014-1958-6
   Ye TZ, 2020, IEEE ACCESS, V8, P89670, DOI 10.1109/ACCESS.2020.2994148
   Yen YT, 2021, IEEE IMAGE PROC, P1734, DOI 10.1109/ICIP42928.2021.9506307
   Yu K. J., 1997, COLOR IMAGING DEVICE, P272
   Yue TW, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1450, DOI 10.1109/ICNN.1995.487373
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Y, 2018, ENG APPL ARTIF INTEL, V72, P43, DOI 10.1016/j.engappai.2018.03.012
   Zhao R, 2021, IEEE T IMAGE PROCESS, V30, P6081, DOI 10.1109/TIP.2021.3091902
   Zhou BF, 2003, ACM T GRAPHIC, V22, P437, DOI 10.1145/882262.882289
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 82
TC 0
Z9 0
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4841
EP 4852
DI 10.1109/TVCG.2023.3278691
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400068
PM 37220038
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Lei, N
   Li, ZZ
   Xu, ZB
   Li, Y
   Gu, XF
AF Lei, Na
   Li, Zezeng
   Xu, Zebin
   Li, Ying
   Gu, Xianfeng
TI What's the Situation With Intelligent Mesh Generation: A Survey and
   Perspectives
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deep learning; mesh generation; neural network; polygonal mesh; review;
   survey
ID PARTIAL-DIFFERENTIAL-EQUATIONS; SURFACE RECONSTRUCTION; GEOMETRY;
   NETWORK
AB Intelligent Mesh Generation (IMG) represents a novel and promising field of research, utilizing machine learning techniques to generate meshes. Despite its relative infancy, IMG has significantly broadened the adaptability and practicality of mesh generation techniques, delivering numerous breakthroughs and unveiling potential future pathways. However, a noticeable void exists in the contemporary literature concerning comprehensive surveys of IMG methods. This paper endeavors to fill this gap by providing a systematic and thorough survey of the current IMG landscape. With a focus on 113 preliminary IMG methods, we undertake a meticulous analysis from various angles, encompassing core algorithm techniques and their application scope, agent learning objectives, data types, targeted challenges, as well as advantages and limitations. We have curated and categorized the literature, proposing three unique taxonomies based on key techniques, output mesh unit elements, and relevant input data types. This paper also underscores several promising future research directions and challenges in IMG.
C1 [Lei, Na] Dalian Univ Technol, Int Informat & Software Inst, Dalian 116620, Peoples R China.
   [Li, Zezeng; Xu, Zebin] Dalian Univ Technol, Sch Software, Dalian 116620, Peoples R China.
   [Li, Ying] Jilin Univ, Coll Comp Sci & Technol, Changchun 130015, Peoples R China.
   [Gu, Xianfeng] SUNY Stony Brook, Dept Comp Sci & Appl Math, Stony Brook, NY 11794 USA.
C3 Dalian University of Technology; Dalian University of Technology; Jilin
   University; State University of New York (SUNY) System; State University
   of New York (SUNY) Stony Brook
RP Li, Y (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130015, Peoples R China.
EM nalei@dlut.edu.cn; zezeng.lee@gmail.com; xzb0516@mail.dlut.edu.cn;
   liying@jlu.edu.cn; gu@cs.stonybrook.edu
OI Lei, Na/0000-0003-3361-0756; Gu, Xianfeng David/0000-0001-8226-5851; Li,
   Ying/0000-0002-7804-149X; Li, Zezeng/0000-0001-9064-689X
FU National Key R&D Program of China [2021YFA1003003]; National Natural
   Science Foundation of China [61936002, T2225012]
FX This research was supported by the National Key R&D Program of China
   under Grant 2021YFA1003003 and the National Natural Science Foundation
   of China under Grants 61936002 and T2225012.
CR Abouelaziz I, 2021, IEEE ACCESS, V9, P108200, DOI 10.1109/ACCESS.2021.3094663
   Abouelaziz I, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P617, DOI 10.1109/SITIS.2018.00099
   Abouelaziz I, 2018, IEEE IMAGE PROC, P3533, DOI 10.1109/ICIP.2018.8451763
   Abouelaziz I, 2017, IEEE IMAGE PROC, P755, DOI 10.1109/ICIP.2017.8296382
   Abouelaziz I, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P793, DOI 10.1109/SITIS.2016.130
   AHN CH, 1991, IEEE T MAGN, V27, P4201, DOI 10.1109/20.105028
   Alfonzetti S, 2003, IEEE T MAGN, V39, P1650, DOI 10.1109/TMAG.2003.810325
   Alfonzetti S, 1996, IEEE T MAGN, V32, P1349, DOI 10.1109/20.497496
   Alfonzetti S, 1998, IEEE T MAGN, V34, P3363, DOI 10.1109/20.717791
   Alfonzetti S, 2008, IEEE T MAGN, V44, P1278, DOI 10.1109/TMAG.2007.916035
   [Anonymous], 2021, Renderpeople
   [Anonymous], 2019, axyz
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Azinovi c D., 2022, P IEEE C COMP VIS PA, P6290
   Badki A, 2020, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR42600.2020.00292
   Baorui M., 2021, P INT C MACH LEARN, P7246
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Berger M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451246
   Bertiche H, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9667017
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Boscaini Davide, 2016, Advances in neural information processing systems
   Boulch A, 2021, INT CONF 3D VISION, P940, DOI 10.1109/3DV53792.2021.00102
   Boulch Alexandre, 2022, IEEE C COMPUT VIS PA, P6302
   Bouritsas G, 2019, IEEE I CONF COMP VIS, P7212, DOI 10.1109/ICCV.2019.00731
   Boyi Jiang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P18, DOI 10.1007/978-3-030-58565-5_2
   Bozic A., 2021, Advances in Neural Information Processing Systems, V34, P1403
   Brito AD, 2008, IEEE T NEURAL NETWOR, V19, P1130, DOI 10.1109/TNN.2008.2000390
   Brock A, 2016, Arxiv, DOI arXiv:1608.04236
   Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296
   Cao YP, 2018, LECT NOTES COMPUT SC, V11213, P626, DOI 10.1007/978-3-030-01240-3_38
   Ceylan D., 2019, Advances in Neural Information Processing Systems (NIPS), P490
   Chang AE, 2017, Arxiv, DOI arXiv:1709.06158
   Charrada TB, 2022, COMPUT GRAPH FORUM, V41, P336, DOI 10.1111/cgf.14496
   Chen XH, 2022, ENG COMPUT-GERMANY, V38, P4409, DOI 10.1007/s00366-022-01632-7
   Chen XH, 2021, COMPUT AIDED DESIGN, V141, DOI 10.1016/j.cad.2021.103104
   Chen XH, 2020, ENG APPL COMP FLUID, V14, P391, DOI 10.1080/19942060.2020.1720820
   Chen Z., 2022, ACM Transactions on Graphics (TOG), V41, P1
   Chen ZQ, 2021, PROC CVPR IEEE, P15735, DOI 10.1109/CVPR46437.2021.01548
   Chen ZQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480518
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Chibane J., 2020, Advances in Neural Information Processing Systems, V33, P21638
   Dai A, 2019, PROC CVPR IEEE, P5559, DOI 10.1109/CVPR.2019.00572
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125
   Daroya R, 2020, IEEE COMPUT SOC CONF, P1444, DOI 10.1109/CVPRW50498.2020.00184
   Deng Z, 2023, IEEE T VIS COMPUT GR, V29, P3826, DOI 10.1109/TVCG.2022.3170853
   Dielen A, 2021, COMPUT GRAPH FORUM, V40, P181, DOI 10.1111/cgf.14366
   DOI A, 1991, IEICE TRANS COMMUN, V74, P214
   Du D, 2022, IEEE T VIS COMPUT GR, V28, P2415, DOI 10.1109/TVCG.2020.3030330
   Erler Philipp, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P108, DOI 10.1007/978-3-030-58558-7_7
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Gao Jun., 2020, ADV NEURAL INFORM PR, V33, P9936, DOI DOI 10.48550/ARXIV.2011.01437
   Gao L, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480503
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Guo YF, 2021, LECT NOTES COMPUT SC, V13002, P477, DOI 10.1007/978-3-030-89029-2_37
   Gupta K., 2020, P INT C NEUR INF PRO, V33, P1747
   Hahner S, 2022, IEEE WINT CONF APPL, P2344, DOI 10.1109/WACV51458.2022.00240
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Handa A, 2016, IEEE INT CONF ROBOT, P5737, DOI 10.1109/ICRA.2016.7487797
   Hanocka R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392415
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Henderson Paul, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7495, DOI 10.1109/CVPR42600.2020.00752
   Hertz A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392471
   Hu MS, 2021, J ROCK MECH GEOTECH, V13, P912, DOI 10.1016/j.jrmge.2021.02.002
   Huang JH, 2021, PROC CVPR IEEE, P8928, DOI 10.1109/CVPR46437.2021.00882
   Jiang BY, 2022, PROC CVPR IEEE, P5595, DOI 10.1109/CVPR52688.2022.00552
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Ju T, 2002, ACM T GRAPHIC, V21, P339
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Khan D, 2022, IEEE T VIS COMPUT GR, V28, P1680, DOI 10.1109/TVCG.2020.3016645
   Kitchenham B. e. a., 2007, Technical report EBSE-2007-01, DOI DOI 10.1145/1134285.1134500
   Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Lei JB, 2022, IEEE T PATTERN ANAL, V44, P10068, DOI 10.1109/TPAMI.2021.3135007
   Lei N, 2019, COMPUT AIDED GEOM D, V68, P1, DOI 10.1016/j.cagd.2018.10.005
   Li CL, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3238250
   Li RZ, 2021, INT CONF 3D VISION, P555, DOI 10.1109/3DV53792.2021.00065
   Li TT, 2022, IEEE T CIRC SYST VID, V32, P4667, DOI 10.1109/TCSVT.2021.3135528
   Li X, 2020, I COMP CONF WAVELET, P101, DOI 10.1109/ICCWAMTIP51612.2020.9317479
   Li Y., 2019, P IEEE VIS COMM IM P, P1
   Li ZZ, 2022, INT CONF ACOUST SPEE, P2564, DOI 10.1109/ICASSP43922.2022.9746972
   Liao YY, 2018, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR.2018.00308
   Lim I, 2019, LECT NOTES COMPUT SC, V11131, P349, DOI 10.1007/978-3-030-11015-4_26
   Liu HTD, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392418
   Liu SL, 2021, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR46437.2021.00183
   LOHNER R, 1988, INT J NUMER METH FL, V8, P1135, DOI 10.1002/fld.1650081003
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   LOWTHER DA, 1993, IEEE T MAGN, V29, P1927, DOI 10.1109/20.250785
   Lu P., 2022, J. Phys.Conf. Ser., V2280
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Luo YM, 2021, AAAI CONF ARTIF INTE, V35, P2277
   Ma BR, 2022, PROC CVPR IEEE, P6305, DOI 10.1109/CVPR52688.2022.00621
   Macdonald CB, 2008, J SCI COMPUT, V35, P219, DOI 10.1007/s10915-008-9196-6
   Macdonald CB, 2011, J COMPUT PHYS, V230, P7944, DOI 10.1016/j.jcp.2011.06.021
   Macdonald CB, 2009, SIAM J SCI COMPUT, V31, P4330, DOI 10.1137/080740003
   März T, 2012, SIAM J NUMER ANAL, V50, P3303, DOI 10.1137/120865537
   Masci Jonathan, 2015, P IEEE INT C COMPUTE, P37
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mi ZX, 2020, PROC CVPR IEEE, P967, DOI 10.1109/CVPR42600.2020.00105
   Milano F., 2020, Advances in Neural Information Processing Systems, P952
   Minghua Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P68, DOI 10.1007/978-3-030-58598-3_5
   Mittal P, 2022, PROC CVPR IEEE, P306, DOI 10.1109/CVPR52688.2022.00040
   Munkberg J, 2022, PROC CVPR IEEE, P8270, DOI 10.1109/CVPR52688.2022.00810
   Nash Charlie, 2020, ICML
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pan J, 2023, NEURAL NETWORKS, V157, P288, DOI 10.1016/j.neunet.2022.10.022
   Pan JY, 2019, IEEE I CONF COMP VIS, P9963, DOI 10.1109/ICCV.2019.01006
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pedone M, 2021, INT C PATT RECOG, P10134, DOI 10.1109/ICPR48806.2021.9412352
   Peng S., 2020, COMPUTER VISION ECCV
   Peng S. M., 2004, P 2 INT C COMP GRAPH, P139
   Peng Songyou, 2021, NEURIPS, V34, P13032
   Pietroni N, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459941, 10.1145/3476576.3476737]
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Rakotosaona MJ, 2021, PROC CVPR IEEE, P22, DOI 10.1109/CVPR46437.2021.00009
   Rakotosaona N., 2021, ACM Trans. Graph., V40, P1
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Ray N, 2006, ACM T GRAPHIC, V25, P1460, DOI 10.1145/1183287.1183297
   Remelli E., 2020, P INT C NEUR INF PRO, V33, P22468
   Rios T, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P942, DOI 10.1109/SSCI47803.2020.9308400
   Ruuth SJ, 2008, J COMPUT PHYS, V227, P1943, DOI 10.1016/j.jcp.2007.10.009
   Schult Jonas, 2020, P IEEE CVF C COMP VI, P8612, DOI DOI 10.1109/CVPR42600.2020.00864
   Sharp M., 2020, P EUR C COMP VIS, P762
   Sharp N, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3507905
   Shen T., 2021, Advances in Neural Information Processing Systems, P6087
   Siddiqui Yawar, 2021, P IEEECVF INT C COMP
   Singh VV, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4883, DOI 10.1145/3474085.3475468
   Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91
   Slotnick J., 2014, CFD vision 2030 study: a path to revolutionary computational aerosciences
   Smirnov D, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459797
   Smirnov M., 2020, P INT C LEARN REPR, P1
   Song Z. Cui, 2021, IEEE INT C COMPUT VI, P6514
   Sorkine O., 2003, Symposium on Geometry Processing, P42
   Sulzer R, 2021, COMPUT GRAPH FORUM, V40, P157, DOI 10.1111/cgf.14364
   Sun JM, 2021, PROC CVPR IEEE, P15593, DOI 10.1109/CVPR46437.2021.01534
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tang JP, 2022, IEEE T PATTERN ANAL, V44, P6454, DOI 10.1109/TPAMI.2021.3087358
   Tang JP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6484, DOI 10.1109/ICCV48922.2021.00644
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Tian L, 2009, IEEE IMAGE PROC, P3009, DOI 10.1109/ICIP.2009.5414447
   Tong F, 2020, IEEE ENG MED BIO, P1608, DOI [10.1109/embc44109.2020.9176655, 10.1109/EMBC44109.2020.9176655]
   Venkat A, 2019, IEEE INT CONF COMP V, P2178, DOI 10.1109/ICCVW.2019.00273
   Venkatesh R., 2021, P IEEE INT C COMP VI, P12653
   Wang JW, 2022, INT CONF 3D VISION, P433, DOI 10.1109/3DV57658.2022.00055
   Wang NY, 2021, IEEE T PATTERN ANAL, V43, P3600, DOI 10.1109/TPAMI.2020.2984232
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   [王年华 Wang Nianhua], 2021, [力学学报, Chinese Journal of Theoretical and Applied Mechanics], V53, P740
   Wang P., 2021, PROC NEURIPS, V34, P27171
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang WY, 2019, PROC CVPR IEEE, P1038, DOI 10.1109/CVPR.2019.00113
   Wang YF, 2021, PROC CVPR IEEE, P374, DOI 10.1109/CVPR46437.2021.00044
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wang ZY, 2020, IEEE IMAGE PROC, P2666, DOI [10.1109/ICIP40778.2020.9190842, 10.1109/icip40778.2020.9190842]
   Wei XK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5785, DOI 10.1109/ICCV48922.2021.00575
   Wen C, 2019, IEEE I CONF COMP VIS, P1042, DOI 10.1109/ICCV.2019.00113
   Wen PZ, 2009, CCDC 2009: 21ST CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-6, PROCEEDINGS, P5785, DOI 10.1109/CCDC.2009.5195232
   Wickramasinghe Udaranga, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P299, DOI 10.1007/978-3-030-59719-1_30
   Wickramasinghe U, 2021, PROC CVPR IEEE, P11647, DOI 10.1109/CVPR46437.2021.01148
   Wiersma R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530166
   Williams F., 2022, IEEE C COMPUT VIS PA, P18500
   Williams F, 2019, PROC CVPR IEEE, P10122, DOI 10.1109/CVPR.2019.01037
   Wu RD, 2020, PROC CVPR IEEE, P826, DOI 10.1109/CVPR42600.2020.00091
   Wu XM, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P913, DOI 10.1109/IIH-MSP.2008.110
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Xiong SY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661263
   Yan GW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417832
   Yang DS, 2020, I COMP CONF WAVELET, P122, DOI 10.1109/ICCWAMTIP51612.2020.9317527
   Yang GS, 2021, PROC CVPR IEEE, P15975, DOI 10.1109/CVPR46437.2021.01572
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yangetal X., 2020, IEEE Trans. Vis. Comput. Graph., V26, P3456
   Yao S, 2005, EXPERT SYST APPL, V29, P193, DOI 10.1016/j.eswa.2005.01.019
   Yuan YJ, 2020, IEEE COMPUT SOC CONF, P1105, DOI 10.1109/CVPRW50498.2020.00145
   Zhang ZY, 2020, LECT NOTES COMPUT SC, V12139, P186, DOI 10.1007/978-3-030-50420-5_14
   Zheng Y., 2021, P IEEE INT C COMP VI, P6239
   Zheng Y. Zhu, 2021, Comput. Methods Appl. Mech. Eng., V387
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
   Zhou Yi, 2020, Advances in neural information processing systems, P9251
   Zhu ZH, 2022, PROC CVPR IEEE, P12776, DOI 10.1109/CVPR52688.2022.01245
NR 189
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4997
EP 5017
DI 10.1109/TVCG.2023.3281781
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400027
PM 37262120
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhang, Z
   Li, M
   Zhao, ZY
   Fang, Q
   Fu, XM
AF Zhang, Zheng
   Li, Mo
   Zhao, Zheng-Yu
   Fang, Qing
   Fu, Xiao-Ming
TI Practical Integer-Constrained Cone Construction for Conformal
   Parameterizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Distortion; Optimization; Mesh generation; Merging; Computational
   modeling; Iterative methods; Finite element analysis;
   Integer-constrained cones; conformal parameterizations; IRLS;
   progressive rounding; relocating cones; merging cones
AB We propose a practical method to construct sparse integer-constrained cone singularities with low distortion constraints for conformal parameterizations. Our solution for this combinatorial problem is a two-stage procedure that first enhances sparsity for generating an initialization and then optimizes to reduce the number of cones and the parameterization distortion. Central to the first stage is a progressive process to determine the combinatorial variables, i.e., numbers, locations, and angles of cones. The second stage iteratively conducts adaptive cone relocations and merges close cones for optimization. We extensively test our method on a data set containing 3885 models, demonstrating practical robustness and performance. Our method achieves fewer cone singularities and lower parameterization distortion than state-of-the-art methods.
C1 [Zhang, Zheng] Univ Sci & Technol China, Sch Data Sci, Hefei 230026, Anhui, Peoples R China.
   [Li, Mo; Fu, Xiao-Ming] Univ Sci & Technol China, Sch Data Sci, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Fu, XM (corresponding author), Univ Sci & Technol China, Sch Data Sci, Hefei 230026, Anhui, Peoples R China.
EM zheng1003@mail.ustc.edu.cn; lmo@mail.ustc.edu.cn;
   zyzhao18@mail.ustc.edu.cn; fq1208@mail.ustc.edu.cn; fuxm@ustc.edu.cn
OI Li, Mo/0000-0003-3166-4136; Fang, Qing/0000-0001-7934-6060; Zhao,
   Zheng-Yu/0000-0003-0360-5518; Fu, Xiao-Ming/0000-0001-8479-0107
FU National Natural Science Foundation of China [62272429]; Major Porject
   of Science and Technology of Anhui Province [202203a05020050]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62272429 and in part by the Major
   Porject of Science and Technology of Anhui Province under Grant
   202203a05020050.
CR Alliez P, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P49
   Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   ApS M., 2022, The MOSEK Fusion API for C++ 10.0.43
   Aubin T., 2013, Some Nonlinear Problems in Riemannian Geometry
   Ben-Chen M, 2008, COMPUT GRAPH FORUM, V27, P449, DOI 10.1111/j.1467-8659.2008.01142.x
   Ben-Chen M, 2010, COMPUT GRAPH FORUM, V29, P1701, DOI 10.1111/j.1467-8659.2010.01779.x
   Bommes D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462014
   Bommes D, 2013, COMPUT GRAPH FORUM, V32, P51, DOI 10.1111/cgf.12014
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Campen M, 2014, COMPUT GRAPH FORUM, V33, P69, DOI 10.1111/cgf.12401
   Campen M, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480557
   Campen M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3360511
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   CHERRIER P, 1984, J FUNCT ANAL, V57, P154, DOI 10.1016/0022-1236(84)90094-6
   Crane K, 2010, COMPUT GRAPH FORUM, V29, P1525, DOI 10.1111/j.1467-8659.2010.01761.x
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Desbrun M, 2002, COMPUT GRAPH FORUM, V21, P209, DOI 10.1111/1467-8659.00580
   Dey TK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462017
   Diamanti O, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12426
   Ebke HC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508372
   Fang Q, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480526
   Fang Q, 2020, COMPUT AIDED DESIGN, V126, DOI 10.1016/j.cad.2020.102863
   Farchi N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201375
   Fisher M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239507
   Floudas C., 1995, Nonlinear and Mixed-Integer Optimization: Fundamentals and Applications
   GORRY GA, 1972, MANAGE SCI, V18, P229, DOI 10.1287/mnsc.18.5.229
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Jiang TF, 2014, IEEE T VIS COMPUT GR, V20, P1189, DOI 10.1109/TVCG.2013.250
   Kälberer F, 2007, COMPUT GRAPH FORUM, V26, P375, DOI 10.1111/j.1467-8659.2007.01060.x
   Kharevych L, 2006, ACM T GRAPHIC, V25, P412, DOI 10.1145/1138450.1138461
   Knöppel F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462005
   Konakovic M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925944
   Lei N, 2020, COMPUT METHOD APPL M, V366
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li M, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530118
   Mohimani GH, 2007, LECT NOTES COMPUT SC, V4666, P389
   Myles A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185605
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Sawhney R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132705
   Segall Aviv., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA'16, P85
   Soliman Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201367
   Springborn B, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360676
   Vaxman A, 2016, COMPUT GRAPH FORUM, V35, P545, DOI 10.1111/cgf.12864
   Wang K, 2006, ACM T GRAPHIC, V25, P1041, DOI 10.1145/1141911.1141991
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Zheng XP, 2021, COMPUT METHOD APPL M, V387, DOI 10.1016/j.cma.2021.114146
   Zhong ZC, 2014, GRAPH MODELS, V76, P468, DOI 10.1016/j.gmod.2014.03.011
NR 47
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5227
EP 5239
DI 10.1109/TVCG.2023.3287303
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400080
PM 37335785
DA 2024-08-05
ER

PT J
AU Feng, YCJ
   Wang, XB
   Pan, B
   Wong, KK
   Ren, Y
   Liu, S
   Yan, ZH
   Ma, YX
   Qu, HM
   Chen, W
AF Feng, Yingchaojie
   Wang, Xingbo
   Pan, Bo
   Wong, Kam Kwai
   Ren, Yi
   Liu, Shi
   Yan, Zihan
   Ma, Yuxin
   Qu, Huamin
   Chen, Wei
TI XNLI: Explaining and Diagnosing NLI-Based Visual Data Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Encoding; Data
   analysis; Motion pictures; Prototypes; Natural language interface;
   visual data analysis; explainability
ID MULTIMODAL INTERACTION; NATURAL-LANGUAGE; VISUALIZATION; EXPLORATION;
   FRAMEWORK
AB Natural language interfaces (NLIs) enable users to flexibly specify analytical intentions in data visualization. However, diagnosing the visualization results without understanding the underlying generation process is challenging. Our research explores how to provide explanations for NLIs to help users locate the problems and further revise the queries. We present XNLI, an explainable NLI system for visual data analysis. The system introduces a Provenance Generator to reveal the detailed process of visual transformations, a suite of interactive widgets to support error adjustments, and a Hint Generator to provide query revision hints based on the analysis of user queries and interactions. Two usage scenarios of XNLI and a user study verify the effectiveness and usability of the system. Results suggest that XNLI can significantly enhance task accuracy without interrupting the NLI-based analysis process.
C1 [Feng, Yingchaojie; Pan, Bo; Ren, Yi; Liu, Shi; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Wang, Xingbo; Wong, Kam Kwai] Hong Kong Univ Sci & Technol, Hong Kong 999077, Peoples R China.
   [Yan, Zihan] MIT, Media Lab, Cambridge, MA 02139 USA.
   [Ma, Yuxin] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen 518055, Guangdong, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Hong Kong University of Science & Technology;
   Massachusetts Institute of Technology (MIT); Southern University of
   Science & Technology; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM fycj@zju.edu.cn; xwangeg@cse.ust.hk; bopan@zju.edu.cn;
   kkwongar@cse.ust.hk; rymaster@zju.edu.cn; zju_ls@zju.edu.cn;
   yzihan@media.mit.edu; mayx@sustech.edu.cn; huamin@cse.ust.hk;
   chenvis@zju.edu.cn
RI Ouyang, Fan/GQI-3203-2022
OI WONG, Kam Kwai/0000-0002-2813-1972; Pan, Bo/0009-0009-4561-2469; Wang,
   Xingbo/0000-0001-5693-1128; Feng, Yingchaojie/0000-0002-1418-4635; Chen,
   Wei/0000-0002-8365-4741
FU National Natural Science Foundation of China [62132017]; Fundamental
   Research Funds for the Central Universities [226-2022-00235]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62132017, and in part by the Fundamental Research
   Funds for the Central Universities under Grant 226-2022-00235.
CR [Anonymous], 1966, SOVIET PHYS DOKLADY
   Berant J, 2019, PROC INT CONF DATA, P1570, DOI 10.1109/ICDE.2019.00144
   Bors C, 2019, IEEE COMPUT GRAPH, V39, P61, DOI 10.1109/MCG.2019.2941856
   Brown T. B., 2020, P 34 INT C NEURAL IN, P1
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   Chen R, 2022, IEEE T VIS COMPUT GR, V28, P4127, DOI 10.1109/TVCG.2021.3076222
   Chen Z., 2022, P ACM SIGCHI C HUM F, P15
   Chen Zhutian, 2023, IEEE Trans Vis Comput Graph, V29, P918, DOI 10.1109/TVCG.2022.3209497
   Cox K., 2001, International Journal of Speech Technology, V4, P297, DOI 10.1023/A:1011368926479
   Dhamdhere K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P493, DOI 10.1145/3025171.3025227
   Fast B., 2018, P ACM SIGCHI C HUM F, P1
   Fu SW, 2020, Arxiv, DOI arXiv:2005.03257
   Gaba Aimen, 2023, IEEE Trans Vis Comput Graph, V29, P1211, DOI 10.1109/TVCG.2022.3209456
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Huang Jieying, 2023, IEEE Trans Vis Comput Graph, V29, P1200, DOI 10.1109/TVCG.2022.3209453
   Islam MR, 2022, ANN OPER RES, DOI 10.1007/s10479-021-04465-7
   Jiang E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501870
   Kasica S, 2021, IEEE T VIS COMPUT GR, V27, P957, DOI 10.1109/TVCG.2020.3030462
   Khan M, 2017, PROC VLDB ENDOW, V10, P661, DOI 10.14778/3055330.3055333
   Kumar A., 2016, P OF THE 17 ANN M OF, P304
   Leventidis A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2303, DOI 10.1145/3318464.3389767
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Luo YY, 2021, Arxiv, DOI arXiv:2112.12926
   Luo YY, 2021, INT CONF MANAGE DATA, P1235, DOI 10.1145/3448016.3457261
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Mitra R, 2022, Arxiv, DOI arXiv:2207.00189
   Narechania A, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P597, DOI 10.1145/3397481.3450667
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   powerbi.microsoft.com, Microsoft power BI
   Pu S., 2021, P ACM CHI C HUM FACT, P1
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Setlur Vidya, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P966, DOI 10.1145/3379337.3415813
   Setlur V, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P166, DOI [10.1109/VIS49827.2021.9623324, 10.1109/VIS49827.2021.00041]
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Shen L., 2021, arXiv
   Shrinivasan YB, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1237
   Srinivasan Arjun, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P864, DOI 10.1145/3472749.3474792
   Srinivasan A, 2020, IEEE COMPUT GRAPH, V40, P96, DOI 10.1109/MCG.2020.2986902
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   Srinivasan A, 2019, PROCEEDINGS OF IUI 2019, P661, DOI 10.1145/3301275.3302292
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Srinivasan B., 2020, P ACM SIGCHI C HUM F, P1
   Srinivasan J., 2017, P EUR IEEE VGTC C VI, P55
   Srinivasan N., 2021, P ACM SIGCHI C HUM F, P1
   Tory M, 2019, IEEE CONF VIS ANAL, P93, DOI [10.1109/VAST47406.2019.8986918, 10.1109/vast47406.2019.8986918]
   Wambsganss T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376732
   Wang XB, 2022, Arxiv, DOI arXiv:2201.04868
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Xia M, 2022, Arxiv, DOI arXiv:2204.07741
   Xiong K, 2023, IEEE T VIS COMPUT GR, V29, P2950, DOI 10.1109/TVCG.2022.3144975
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
NR 59
TC 7
Z9 7
U1 6
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3813
EP 3827
DI 10.1109/TVCG.2023.3240003
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700084
PM 37610216
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Mahmood, S
   Mueller, K
AF Mahmood, Salman
   Mueller, Klaus
TI Interactive Subspace Cluster Analysis Guided by Semantic Attribute
   Associations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Semantics; Visual analytics; Data visualization; Three-dimensional
   displays; Task analysis; Standards; Space exploration; Cluster analysis;
   high-dimensional data; multivariate data; subspace clustering; subspace
   analysis
ID HIGH-DIMENSIONAL DATA; VISUAL EXPLORATION
AB Multivariate datasets with many variables are increasingly common in many application areas. Most methods approach multivariate data from a singular perspective. Subspace analysis techniques, on the other hand. provide the user a set of subspaces which can be used to view the data from multiple perspectives. However, many subspace analysis methods produce a huge amount of subspaces, a number of which are usually redundant. The enormity of the number of subspaces can be overwhelming to analysts, making it difficult for them to find informative patterns in the data. In this article, we propose a new paradigm that constructs semantically consistent subspaces. These subspaces can then be expanded into more general subspaces by ways of conventional techniques. Our framework uses the labels/meta-data of a dataset to learn the semantic meanings and associations of the attributes. We employ a neural network to learn a semantic word embedding of the attributes and then divide this attribute space into semantically consistent subspaces. The user is provided with a visual analytics interface that guides the analysis process. We show via various examples that these semantic subspaces can help organize the data and guide the user in finding interesting patterns in the dataset.
C1 [Mahmood, Salman; Mueller, Klaus] SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Mueller, K (corresponding author), SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.
EM samahmood@cs.stonybrook.edu; mueller@cs.stonybrook.edu
OI Mueller, Klaus/0000-0002-0996-8590
FU NSF [IIS 1941613, IIS1527200]
FX This work was partially supported by NSF under Grants IIS 1941613 and
   IIS1527200.
CR Aggarwal CC, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P61, DOI 10.1145/304181.304188
   Assent I., 2007, ACM SIGKDD Explorations Newsletter, V9, P5, DOI DOI 10.1145/1345448.1345451
   Assent I, 2007, IEEE DATA MINING, P409, DOI 10.1109/ICDM.2007.49
   Baumgartner C, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P11, DOI 10.1109/ICDM.2004.10112
   Chen TL, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103665
   Cheng C H, 1999, P 5 ACM SIGKDD INT C, P84, DOI [10.1145/312129.312199, DOI 10.1145/312129.312199]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Erk K., 2009, P 13 C COMP NAT LANG, P65
   Estivill-Castro Vladimir, 2002, ACM SIGKDD Explorations Newsletter, V4, P65, DOI [DOI 10.1145/568574.568575, 10.1145/568574.568575]
   Eysenck M.W., 2018, FUNDAMENTALS COGNITI
   Gansner ER, 2009, LECT NOTES COMPUT SC, V5417, P206, DOI 10.1007/978-3-642-00219-9_20
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2042, DOI 10.1109/TVCG.2013.157
   Greenacre M.J., 2010, BIPLOTS PRACTICE
   Hartigan J. A., 1975, Journal of Statistical Computation and Simulation, V4, P187, DOI 10.1080/00949657508810123
   Hinton G. E., 1986, P 8 ANN C COGN SCI S, P1, DOI DOI 10.1109/69.917563
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Jäckle D, 2017, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2017.8585613
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT, DOI 10.1016/0169-7439(87)80084-92
   Kenter T, 2015, P 24 ACM INT C INF K, P1411, DOI 10.1145/2806416.2806475
   Kim H, 2016, IEEE T VIS COMPUT GR, V22, P131, DOI 10.1109/TVCG.2015.2467615
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lee D., 2021, Information, V13
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Liu S, 2015, COMPUT GRAPH FORUM, V34, P271, DOI 10.1111/cgf.12639
   Mahmood S, 2020, IEEE T VIS COMPUT GR, V26, P2875, DOI 10.1109/TVCG.2019.2895642
   Mikolov T., 2013, ARXIV, DOI DOI 10.48550/ARXIV.1301.3781
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Nam EJ, 2007, IEEE CONF VIS ANAL, P75
   Nam JE, 2013, IEEE T VIS COMPUT GR, V19, P291, DOI 10.1109/TVCG.2012.65
   Peng X, 2020, IEEE T NEUR NET LEAR, V31, P5509, DOI 10.1109/TNNLS.2020.2968848
   Ren J., 2022, arXiv, DOI DOI 10.48550/ARXIV.2210.04142
   Risch J, 2019, DATA TECHNOL APPL, V53, P108, DOI 10.1108/DTA-01-2019-0002
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   Schick T, 2019, Arxiv, DOI arXiv:1904.01617
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Tatu Andrada, 2012, Tsinghua Science and Technology, V17, P419
   Tatu A, 2012, IEEE CONF VIS ANAL, P63, DOI 10.1109/VAST.2012.6400488
   Dang TN, 2014, IEEE PAC VIS SYMP, P73, DOI 10.1109/PacificVis.2014.42
   Turkay C, 2011, IEEE T VIS COMPUT GR, V17, P2591, DOI 10.1109/TVCG.2011.178
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang B, 2018, IEEE T VIS COMPUT GR, V24, P1204, DOI 10.1109/TVCG.2017.2672987
   Wang B, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P37, DOI 10.1109/3DVis.2014.7160098
   Wang JP, 2019, INFORM VISUAL, V18, P94, DOI 10.1177/1473871617733996
   Watanabe K, 2015, IEEE PAC VIS SYMP, P287, DOI 10.1109/PACIFICVIS.2015.7156389
   Yuan XR, 2013, IEEE T VIS COMPUT GR, V19, P2625, DOI 10.1109/TVCG.2013.150
   Zhang ZY, 2012, IEEE PAC VIS SYMP, P17
   Zhou FF, 2016, IEEE PAC VIS SYMP, P128, DOI 10.1109/PACIFICVIS.2016.7465260
NR 50
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4197
EP 4210
DI 10.1109/TVCG.2023.3256376
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700078
PM 37028285
DA 2024-08-05
ER

PT J
AU Xu, RK
   Zhang, L
   Zhang, FL
AF Xu, Rong-Kai
   Zhang, Lei
   Zhang, Fang-Lue
TI Intrinsic Omnidirectional Image Decomposition With Illumination
   Pre-Extraction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Reflectivity; Light sources; Rendering (computer graphics);
   Image decomposition; Geometry; Data mining; Intrinsic decomposition;
   omnidirectional image; reflectance; shading
ID RETINEX; MODEL
AB Capturing an omnidirectional image with a 360-degree field of view entails capturing intricate spatial and lighting details of the scene. Consequently, existing intrinsic image decomposition methods face significant challenges when attempting to separate reflectance and shading components from a low dynamic range (LDR) omnidirectional images. To address this, our article introduces a novel method specifically designed for the intrinsic decomposition of omnidirectional images. Leveraging the unique characteristics of the 360-degree scene representation, we employ a pre-extraction technique to isolate specific illumination information. Subsequently, we establish new constraints based on these extracted details and the inherent characteristics of omnidirectional images. These constraints limit the illumination intensity range and incorporate spherical-based illumination variation. By formulating and solving an objective function that accounts for these constraints, our method achieves a more accurate separation of reflectance and shading components. Comprehensive qualitative and quantitative evaluations demonstrate the superiority of our proposed method over state-of-the-art intrinsic decomposition methods.
C1 [Xu, Rong-Kai; Zhang, Lei] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6012, New Zealand.
C3 Beijing Institute of Technology; Victoria University Wellington
RP Zhang, L (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
EM zjlxxrk@gmail.com; leizhang@bit.edu.cn; fanglue.zhang@vuw.ac.nz
OI Xu, RongKai/0009-0004-2836-2676
FU National Natural Science Foundation of China [62132012]; Marsden Fund
   Council [MFP-20-VUW-180]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62132012, and in part by Marsden Fund Council managed
   by the Royal Society of New Zealand under Grant MFP-20-VUW-180.
CR Armeni I., 2017, arXiv
   Baslamisli AS, 2021, J OPT SOC AM A, V38, DOI 10.1364/JOSAA.414682
   Bell Sean, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601206
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Bonneel N, 2017, COMPUT GRAPH FORUM, V36, P593, DOI 10.1111/cgf.13149
   Das Partha, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P605, DOI 10.1007/978-3-031-25066-8_35
   Das P, 2022, PROC CVPR IEEE, P19758, DOI 10.1109/CVPR52688.2022.01917
   Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932
   Fu G, 2019, IEEE INT CON MULTI, P175, DOI 10.1109/ICME.2019.00038
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Garces E, 2022, INT J COMPUT VISION, V130, P836, DOI 10.1007/s11263-021-01563-8
   Garces E, 2012, COMPUT GRAPH FORUM, V31, P1415, DOI 10.1111/j.1467-8659.2012.03137.x
   Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891
   Gardner MA, 2019, IEEE I CONF COMP VIS, P7174, DOI 10.1109/ICCV.2019.00727
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Kovacs B, 2017, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2017.97
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li J., 2021, P IEEE C COMP VIS PA, p10 586
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Li Z, 2022, PROC CVPR IEEE, P12703, DOI 10.1109/CVPR52688.2022.01238
   Li ZQ, 2022, LECT NOTES COMPUT SC, V13666, P555, DOI 10.1007/978-3-031-20068-7_32
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Luo JD, 2020, IEEE T VIS COMPUT GR, V26, P3434, DOI 10.1109/TVCG.2020.3023565
   Ma WY, 2012, INVERSE PROBL IMAG, V6, P697, DOI 10.3934/ipi.2012.6.697
   Ma WY, 2011, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2011.5995422
   Meka A, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3374753
   Meka A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925907
   Narihira T, 2015, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2015.342
   Nestmeyer T, 2017, PROC CVPR IEEE, P1771, DOI 10.1109/CVPR.2017.192
   Qian YL, 2021, IEEE WINT CONF APPL, P3168, DOI 10.1109/WACV48630.2021.00321
   Sengupta S, 2019, IEEE I CONF COMP VIS, P8597, DOI 10.1109/ICCV.2019.00869
   Shen HL, 2009, APPL OPTICS, V48, P2711, DOI 10.1364/AO.48.002711
   Shen JB, 2011, PROC CVPR IEEE
   Shi J, 2017, PROC CVPR IEEE, P5844, DOI 10.1109/CVPR.2017.619
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang Z., 2021, P IEEE CVF INT C COM, P12538
   Weber H, 2018, INT CONF 3D VISION, P199, DOI 10.1109/3DV.2018.00032
   Xie EZ, 2021, ADV NEUR IN, V34
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yue HJ, 2017, IEEE T IMAGE PROCESS, V26, P3981, DOI 10.1109/TIP.2017.2703078
   Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77
   Zhou H, 2019, IEEE I CONF COMP VIS, P7819, DOI 10.1109/ICCV.2019.00791
   Zhu JS, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555407
   Zhu R, 2022, PROC CVPR IEEE, P2812, DOI 10.1109/CVPR52688.2022.00284
NR 47
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4416
EP 4428
DI 10.1109/TVCG.2024.3366343
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700003
PM 38358860
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Guo, ZX
   Wang, HY
   Deng, HX
   Xu, WE
   Baghaei, N
   Lo, CH
   Liang, HN
AF Guo, Zixuan
   Wang, Hongyu
   Deng, Hanxiao
   Xu, Wenge
   Baghaei, Nilufar
   Lo, Cheng-Hung
   Liang, Hai-Ning
TI Breaking the Isolation: Exploring the Impact of Passthrough in Shared
   Spaces on Player Performance and Experience in VR Exergames
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Passthrough; Exergames; Shared Spaces; Social
   Acceptability; Immersion
AB VR exergames offer an engaging solution to combat sedentary behavior and promote physical activity. However, challenges emerge when playing these games in shared spaces, particularly due to the presence of bystanders. VR's passthrough functionality enables players to maintain awareness of their surrounding environment while immersed in VR gaming, rendering it a promising solution to improve users' awareness of the environment. This study investigates the passthrough's impact on player performance and experiences in shared spaces, involving an experiment with 24 participants that examines Space (Office vs. Corridor) and Passthrough Function (With vs. Without). Results reveal that Passthrough enhances game performance and environmental awareness while reducing immersion. Players prefer an open area to an enclosed room, whether with or without Passthrough, finding it more socially acceptable. Additionally, Passthrough appears to encourage participation among players with higher self-consciousness, potentially alleviating their concerns about being observed by bystanders. Our findings provide valuable insights for designing VR experiences in shared spaces, underscoring the potential of VR's passthrough to enhance user experiences and promote VR adoption in these environments.
C1 [Guo, Zixuan; Wang, Hongyu; Deng, Hanxiao] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou, Peoples R China.
   [Guo, Zixuan] Univ Liverpool, Dept Comp Sci, Liverpool, England.
   [Xu, Wenge] Birmingham City Univ, Sch Comp & Digital Technol, Birmingham, England.
   [Baghaei, Nilufar] Univ Queensland, Sch Elect Engn & Comp Sci, St Lucia, Australia.
   [Lo, Cheng-Hung] Xian Jiaotong Liverpool Univ, Dept Ind Design, Suzhou, Peoples R China.
   [Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; University of Liverpool; Birmingham
   City University; University of Queensland; Xi'an Jiaotong-Liverpool
   University; Xi'an Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
EM Zixuan.Guo16@student.xjtlu.edu.cn; Hongyu.Wang20@student.xjtlu.edu.cn;
   Hanxiao.Deng22@student.xjtlu.edu.cn; Wenge.Xu@bcu.ac.uk;
   nilufar.baghaei@gmail.com; ChengHung.Lo@xjtlu.edu.cn;
   haining.liang@xjtlu.edu.cn
OI Liang, Hai-Ning/0000-0003-3600-8955; deng, han xiao/0009-0005-4587-550X;
   Lo, Cheng-Hung/0000-0002-7199-9339; Baghaei,
   Nilufar/0000-0003-1776-7075; Xu, Wenge/0000-0001-7227-7437
FU This work was partially funded by the Suzhou Municipal Key Laboratory
   for Intelligent Virtual Engineering
FX No Statement Available
CR [Anonymous], 2003, The Journal of Strength & Conditioning Research, V17, P303
   Rico J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P887
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Vergari M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P695, DOI 10.1109/VR50410.2021.00096
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   vonGrunau M, 1995, PERCEPTION, V24, P1297, DOI 10.1068/p241297
   Wang B.-Y., 2022, INPROCEED INGS 35 AN, P1
   Wang J, 2004, J SCI MED SPORT, V7, P174, DOI 10.1016/S1440-2440(04)80007-0
   Williamson M., 2019, INPROCEEDINGS 2019 C, P1
   Xu H.-N., INPROCEEDINGSN
   Xu WG, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29330
NR 12
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2580
EP 2590
DI 10.1109/TVCG.2024.3372114
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400033
PM 38437094
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Tasnim, U
   Islam, R
   Desai, K
   Quarles, J
AF Tasnim, Umama
   Islam, Rifatul
   Desai, Kevin
   Quarles, John
TI Investigating Personalization Techniques for Improved Cybersickness
   Prediction in Virtual Reality Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cybersickness; Brain modeling; Predictive models; Solid modeling;
   Transfer learning; Data models; Physiology; Cybersickness
   Personalization; Cybersickness Prediction; Transfer Learning; Early
   Shaping; Deep Learning; Machine Learning
ID MOTION SICKNESS
AB In recent cybersickness research, there has been a growing interest in predicting cybersickness using real-time physiological data such as heart rate, galvanic skin response, eye tracking, postural sway, and electroencephalogram. However, the impact of individual factors such as age and gender, which are pivotal in determining cybersickness susceptibility, remains unknown in predictive models. Our research seeks to address this gap, underscoring the necessity for a more personalized approach to cybersickness prediction to ensure a better, more inclusive virtual reality experience. We hypothesize that a personalized cybersickness prediction model would outperform non-personalized models in predicting cybersickness. Evaluating this, we explored four personalization techniques: 1) data grouping, 2) transfer learning, 3) early shaping, and 4) sample weighing using an open-source cybersickness dataset. Our empirical results indicate that personalized models significantly improve prediction accuracy. For instance, with early shaping, the Deep Temporal Convolutional Neural Network (DeepTCN) model achieved a 69.7% reduction in RMSE compared to its non-personalized version. Our study provides evidence of personalization techniques' benefits in improving cybersickness prediction. These findings have implications for developing personalized cybersickness prediction models tailored to individual differences, which can be used to develop personalized cybersickness reduction techniques in the future.
C1 [Tasnim, Umama; Islam, Rifatul] Kennesaw State Univ, Kennesaw, GA 30144 USA.
   [Desai, Kevin; Quarles, John] Univ Texas San Antonio, San Antonio, TX USA.
C3 University System of Georgia; Kennesaw State University; University of
   Texas System; University of Texas at San Antonio (UTSA)
RP Islam, R (corresponding author), Kennesaw State Univ, Kennesaw, GA 30144 USA.
EM utasnim@kennesaw.edu; shovonis09@gmail.com; kevin.desai@utsa.edu;
   john.quarles@utsa.edu
OI Islam, Rifatul/0000-0002-4305-9964
FU Intel Corporation
FX No Statement Available
CR Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bengio J., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P41
   Bockelman P., 2017, HCI INT 2017 POSTERS, P1
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chen YT, 2020, NEUROCOMPUTING, V399, P491, DOI 10.1016/j.neucom.2020.03.011
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Ferrari A., 2022, Journal of Reliable Intelligent Environments, P3
   Freiwald Jann Philipp, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P115, DOI 10.1145/3404983.3410022
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Garcia-Agundez A., 2019, International Journal of Virtual Reality, V19, P2
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Islam R, 2022, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR55827.2022.00026
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Islam R, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P148, DOI 10.1109/VRW52623.2021.00035
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Reyes-Lagos JJ, 2015, PHYSIOL BEHAV, V149, P255, DOI 10.1016/j.physbeh.2015.05.041
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/VR.2019.8798334, 10.1109/vr.2019.8798334]
   Jin XB, 2020, LECT NOTES ELECTR EN, V582, P631, DOI 10.1007/978-981-15-0474-7_59
   Kelly J. W., 2023, 2023 IEEE C VIRTUAL, P8
   Kennedy R. S., 1993, The international journal of aviation psychology, V3, P2
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Keshavarz B, 2022, CURR OPIN NEUROL, V35, P107, DOI 10.1097/WCO.0000000000001018
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2019, IEEE I CONF COMP VIS, P10579, DOI 10.1109/ICCV.2019.01068
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Klosterhalfen S, 2005, AVIAT SPACE ENVIR MD, V76, P1051
   Kourtesis P., 2023, IEEE Transactions on Visualization and Computer Graphics, V29, P2
   Kundu RK, 2022, INT SYM MIX AUGMENT, P777, DOI 10.1109/ISMAR55827.2022.00096
   LaViola Jr J. J., 2000, ACM Sigchi Bulletin, V32, P2
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Litleskare S, 2021, PHYSIOL BEHAV, V236, DOI 10.1016/j.physbeh.2021.113422
   Luong T, 2022, INT SYM MIX AUGMENT, P307, DOI 10.1109/ISMAR55827.2022.00046
   MacArthur C., 2021, P 2021 CHI C ONHUMAN, P1
   Martin N, 2020, INT SYM MIX AUGMENT, P387, DOI 10.1109/ISMAR50242.2020.00065
   Martingano AJ, 2022, J MED INTERNET RES, V24, DOI 10.2196/36843
   Melo M., 2021, 2021 INT C GRAPHICS, P1
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nam Y, 2022, CYBERPSYCH BEH SOC N, V25, P135, DOI 10.1089/cyber.2021.0167
   Naqvi SAA, 2015, AUSTRALAS PHYS ENG S, V38, P721, DOI 10.1007/s13246-015-0379-9
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Petri Katharina, 2020, Amer. J. Biomed. Sci., P107, DOI DOI 10.5099/AJ200200107
   Pohlmann KMT, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P277, DOI 10.1109/VRW58643.2023.00066
   Rebenitsch L., 2014, P 27 ANN ACM S USERI, P1
   Reddy G. R., VIRTUAL AUGMENTED MI
   Rennie J. D., 2003, Computers in Biology and Medicine, P6
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Saleem Sehar, 2021, Pakistan Journal of Statistics, V37, P4
   Schneider J., 2021, P INT DATA SCI C, P89
   Siami-Namini S, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1394, DOI 10.1109/ICMLA.2018.00227
   Stanney K. M., 1997, P HUMAN FACTORS ER G, V41, P2
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Tektas M., 2010, Environ-mental Research, Engineering and Management, V51, P3
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Wang YY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P373, DOI 10.1109/VR50410.2021.00060
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
NR 64
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2368
EP 2378
DI 10.1109/TVCG.2024.3372122
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200004
PM 38437124
DA 2024-08-05
ER

PT J
AU Schäfer, M
   Brich, N
   Byska, J
   Marques, SM
   Bednár, D
   Thiel, P
   Kozliková, B
   Krone, M
AF Schaefer, Marco
   Brich, Nicolas
   Byska, Jan
   Marques, Sergio M.
   Bednar, David
   Thiel, Philipp
   Kozlikova, Barbora
   Krone, Michael
TI InVADo: Interactive Visual Analysis of Molecular Docking Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Proteins; Drugs; Visualization; Data visualization; Three-dimensional
   displays; Receptor (biochemistry); Carbon; Molecular docking; AutoDock;
   virtual screening; visual analysis; visualization; clustering;
   protein-ligand interaction
ID PROTOTYPING FRAMEWORK; VISUALIZATION; DISCOVERY; MEGAMOL
AB Molecular docking is a key technique in various fields like structural biology, medicinal chemistry, and biotechnology. It is widely used for virtual screening during drug discovery, computer-assisted drug design, and protein engineering. A general molecular docking process consists of the target and ligand selection, their preparation, and the docking process itself, followed by the evaluation of the results. However, the most commonly used docking software provides no or very basic evaluation possibilities. Scripting and external molecular viewers are often used, which are not designed for an efficient analysis of docking results. Therefore, we developed InVADo, a comprehensive interactive visual analysis tool for large docking data. It consists of multiple linked 2D and 3D views. It filters and spatially clusters the data, and enriches it with post-docking analysis results of protein-ligand interactions and functional groups, to enable well-founded decision-making. In an exemplary case study, domain experts confirmed that InVADo facilitates and accelerates the analysis workflow. They rated it as a convenient, comprehensive, and feature-rich tool, especially useful for virtual screening.
C1 [Schaefer, Marco; Brich, Nicolas; Thiel, Philipp; Krone, Michael] Univ Tubingen, Inst Bioinformat & Med Informat IBMI, D-72074 Tubingen, Germany.
   [Byska, Jan] Univ Bergen, N-5007 Bergen, Norway.
   [Marques, Sergio M.] Masaryk Univ, Loschmidt Labs, Brno 60177, Czech Republic.
   [Marques, Sergio M.] St Annes Univ Hosp Brno, Int Ctr Clin Res, Brno 60200, Czech Republic.
   [Bednar, David; Kozlikova, Barbora] Masaryk Univ, Brno 60177, Czech Republic.
C3 Eberhard Karls University of Tubingen; University of Bergen; Masaryk
   University Brno; St Anne's University Hospital Brno (FNUSA-ICRC);
   Masaryk University Brno
RP Krone, M (corresponding author), Univ Tubingen, Inst Bioinformat & Med Informat IBMI, D-72074 Tubingen, Germany.
EM marco.schaefer@uni-tuebingen.de; nicolas.brich@uni-tuebingen.de;
   jan.byska@gmail.com; smar96@gmail.com; 222755@mail.muni.cz;
   philipp.thiel@uni-tuebingen.de; kozlikova@fi.muni.cz;
   michael.krone@uni-tuebingen.de
RI Marques, Sérgio M./H-8685-2012
OI Marques, Sérgio M./0000-0002-6281-7505; Bednar,
   David/0000-0002-6803-0340; Byska, Jan/0000-0001-9483-7562; Brich,
   Nicolas/0000-0003-3175-0464; Schafer, Marco/0000-0003-3854-6415; Krone,
   Michael/0000-0002-1445-7568
FU German Research Foundation
FX No Statement Available
CR Alberts B., 2002, MOL BIOL CELL
   Bai B, 2021, MOLECULES, V26, DOI 10.3390/molecules26154625
   Banaganapalli B., 2019, Essentials of Bioinformatics: Understanding Bioinformatics: Genes to Proteins, VI, DOI [DOI 10.1007/978-3-030-02634-9_15, 10.1007/978-3-030-02634-9_15]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Byska J, 2019, COMPUT GRAPH FORUM, V38, P441, DOI 10.1111/cgf.13701
   Coleman RG, 2010, J CHEM INF MODEL, V50, P589, DOI 10.1021/ci900397t
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   Eberhardt J, 2021, J CHEM INF MODEL, V61, P3891, DOI 10.1021/acs.jcim.1c00203
   Fährrolfes R, 2017, NUCLEIC ACIDS RES, V45, pW337, DOI 10.1093/nar/gkx333
   Ferreira LG, 2015, MOLECULES, V20, P13384, DOI 10.3390/molecules200713384
   Furmanová K, 2020, COMPUT GRAPH FORUM, V39, P452, DOI 10.1111/cgf.14048
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Furmanová K, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1448-0
   Goodsell DS, 2021, PROTEIN SCI, V30, P31, DOI 10.1002/pro.3934
   Gralka P, 2019, EUR PHYS J-SPEC TOP, V227, P1817, DOI 10.1140/epjst/e2019-800167-5
   Grottel S, 2015, IEEE T VIS COMPUT GR, V21, P201, DOI 10.1109/TVCG.2014.2350479
   Grottel S, 2012, IEEE PAC VIS SYMP, P209, DOI 10.1109/PacificVis.2012.6183593
   Gütlein M, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/s13321-014-0041-7
   Haider N, 2010, MOLECULES, V15, P5079, DOI 10.3390/molecules15085079
   Hermosilla P, 2017, IEEE T VIS COMPUT GR, V23, P731, DOI 10.1109/TVCG.2016.2598825
   Hoetzlein R. C., 2014, PROC GPU TECHNOL C
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Janssen APA, 2019, J CHEM INF MODEL, V59, P1221, DOI 10.1021/acs.jcim.8b00640
   Jurcík A, 2019, IEEE PAC VIS SYMP, P212, DOI 10.1109/PacificVis.2019.00032
   Jurcik A, 2018, BIOINFORMATICS, V34, P3586, DOI 10.1093/bioinformatics/bty386
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Krone M, 2016, COMPUT GRAPH FORUM, V35, P527, DOI 10.1111/cgf.12928
   Laskowski RA, 2011, J CHEM INF MODEL, V51, P2778, DOI 10.1021/ci200227u
   Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1
   Lodish H., 2007, MOL CELL BIOL, V6
   Marques SM, 2021, BIOMEDICINES, V9, DOI 10.3390/biomedicines9040357
   Morris GM, 2009, J COMPUT CHEM, V30, P2785, DOI 10.1002/jcc.21256
   Morris Garrett M., 2008, V443, P365, DOI 10.1007/978-1-59745-177-2_19
   MULLER P, 1994, PURE APPL CHEM, V66, P1077, DOI 10.1351/pac199466051077
   O'Boyle NM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-33
   OneAngstrom, SAMSON
   Osolodkin DI, 2015, EXPERT OPIN DRUG DIS, V10, P959, DOI 10.1517/17460441.2015.1060216
   Pande M, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07803
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   Reina G., 2005, P EUROGRAPHICS IEEE, P177
   Sabando MV, 2020, Arxiv, DOI arXiv:2008.13150
   Salentin S, 2015, NUCLEIC ACIDS RES, V43, pW443, DOI 10.1093/nar/gkv315
   Salmaso V, 2018, FRONT PHARMACOL, V9, DOI 10.3389/fphar.2018.00923
   Sander T, 2015, J CHEM INF MODEL, V55, P460, DOI 10.1021/ci500588j
   Sangster, 1997, OCTANOL WATER PARTIT
   Schafer M., 2019, PROC 2 WORKSHOP MOL, P1
   Schatz K, 2021, COMPUT GRAPH FORUM, V40, P394, DOI 10.1111/cgf.14386
   Shoichet BK, 2002, CURR OPIN CHEM BIOL, V6, P439, DOI 10.1016/S1367-5931(02)00339-3
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Skanberg R., 2018, PROC WORKSHOP MOL GR
   Sterling T, 2015, J CHEM INF MODEL, V55, P2324, DOI 10.1021/acs.jcim.5b00559
   Torres PHM, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20184574
   Trott O, 2010, J COMPUT CHEM, V31, P455, DOI 10.1002/jcc.21334
   Vázquez P, 2018, COMPUT GRAPH FORUM, V37, P391, DOI 10.1111/cgf.13428
   vuetifyjs.com, Vuetify-A material design framework for Vue.js
   Wang GM, 2016, FUTURE MED CHEM, V8, DOI 10.4155/fmc-2016-0143
   Wei WX, 2020, DRUG DISCOV TODAY, V25, P1839, DOI 10.1016/j.drudis.2020.07.017
   Yuan SG, 2017, WIRES COMPUT MOL SCI, V7, DOI 10.1002/wcms.1298
   Zhang BH, 2022, CCF T HIGH PERFORM C, V4, P63, DOI 10.1007/s42514-021-00086-5
NR 61
TC 1
Z9 1
U1 9
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1984
EP 1997
DI 10.1109/TVCG.2023.3337642
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500011
PM 38019636
DA 2024-08-05
ER

PT J
AU Rautek, P
   Zhang, XD
   Woschizka, B
   Theussl, T
   Hadwiger, M
AF Rautek, Peter
   Zhang, Xingdi
   Woschizka, Bernhard
   Theussl, Thomas
   Hadwiger, Markus
TI Vortex Lens: Interactive Vortex Core Line Extraction using Observed Line
   Integral Convolution
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Flow visualization; vortex detection; objectivity; observers; reference
   frames; Lie algebras; visual lens metaphors
ID OF-THE-ART; VECTOR-FIELDS; FLOW PATTERNS; TOPOLOGY; VISUALIZATION;
   VORTICES; MOTIONS
AB This paper describes a novel method for detecting and visualizing vortex structures in unsteady 2D fluid flows. The method is based on an interactive local reference frame estimation that minimizes the observed time derivative of the input flow field v(x,t). A locally optimal reference frame w(x,t) assists the user in the identification of physically observable vortex structures in Observed Line Integral Convolution (LIC) visualizations. The observed LIC visualizations are interactively computed and displayed in a user-steered vortex lens region, embedded in the context of a conventional LIC visualization outside the lens. The locally optimal reference frame is then used to detect observed critical points, where v = w, which are used to seed vortex core lines. Each vortex core line is computed as a solution of the ordinary differential equation (ODE) (center dot)w(t) = w(w(t),t), with an observed critical point as initial condition (w(t(0)),t(0)). During integration, we enforce a strict error bound on the difference between the extracted core line and the integration of a path line of the input vector field, i.e., a solution to the ODE (center dot)v(t) = v(v(t),t). We experimentally verify that this error depends on the step size of the core line integration. This ensures that our method extracts Lagrangian vortex core lines that are the simultaneous solution of both ODEs with a numerical error that is controllable by the integration step size. We show the usability of our method in the context of an interactive system using a lens metaphor, and evaluate the results in comparison to state-of-the-art vortex core line extraction methods.
C1 [Rautek, Peter; Zhang, Xingdi; Hadwiger, Markus] King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal, Saudi Arabia.
   [Theussl, Thomas] King Abdullah Univ Sci & Technol KAUST, Core Labs, Thuwal 239556900, Saudi Arabia.
C3 King Abdullah University of Science & Technology; King Abdullah
   University of Science & Technology
RP Rautek, P (corresponding author), King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal, Saudi Arabia.
EM peter.rautek@kaust.edu.sa; xingdi.zhang@kaust.edu.sa; w-bernhard@gmx.at;
   thomas.theussl@kaust.edu.sa; markus.hadwiger@kaust.edu.sa
OI Rautek, Peter/0000-0003-4821-7404
FU King Abdullah University of Science and Technology (KAUST)
FX No Statement Available
CR ASTARITA G, 1979, J NON-NEWTON FLUID, V6, P69, DOI 10.1016/0377-0257(79)87004-4
   BANKS DC, 1995, IEEE T VIS COMPUT GR, V1, P151, DOI 10.1109/2945.468404
   Bauer D., 2002, Proceedings of the symposium on Data Visualisation 2002, VISSYM '02, Eurographics Association, Aire-la-Ville, Switzerland, Switzerland, P233, DOI [10.2312/VisSym/VisSym02/233-240, DOI 10.2312/VISSYM/VISSYM02/233-240]
   Berenjkoub M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P261, DOI 10.1109/VIS47514.2020.00059
   Bhatia H, 2014, COMPUT GRAPH FORUM, V33, P21, DOI 10.1111/cgf.12358
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Bujack R, 2016, IEEE PAC VIS SYMP, P72, DOI 10.1109/PACIFICVIS.2016.7465253
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Drouot R., 1976, Archiwum Mechaniki Stosowanej, V28, P3
   Globus A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P33, DOI 10.1109/VISUAL.1991.175773
   Günther T, 2020, IEEE T VIS COMPUT GR, V26, P1532, DOI 10.1109/TVCG.2018.2868760
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Günther T, 2016, IEEE T VIS COMPUT GR, V22, P817, DOI 10.1109/TVCG.2015.2467200
   Hadwiger M, 2019, IEEE T VIS COMPUT GR, V25, P1257, DOI 10.1109/TVCG.2018.2864839
   Haller G, 2005, J FLUID MECH, V525, P1, DOI 10.1017/S0022112004002526
   Haller G, 2016, J FLUID MECH, V795, P136, DOI 10.1017/jfm.2016.151
   Haller G, 2021, J FLUID MECH, V908, DOI 10.1017/jfm.2020.937
   Holzapfel G, 2000, Nonlinear Solid Mechanics: A Continuum Approach for Engineering, VIst
   Hunt J. C. R., 1988, P SUMM PROGR 1988 CT, P3
   JEONG J, 1995, J FLUID MECH, V285, P69, DOI 10.1017/S0022112095000462
   Jobard B, 2002, IEEE T VIS COMPUT GR, V8, P211, DOI 10.1109/TVCG.2002.1021575
   Jobard Bruno., 1997, VISUALIZATION SCI CO, P43
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P285, DOI 10.1111/cgf.13689
   Laramee RS, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P131, DOI 10.1109/VISUAL.2003.1250364
   Li G.-S., 2006, Proceedings of the Eighth Joint Eurographics / IEEE VGTC Conference on Visualization, P29
   Lugt H. J., 1979, Recent developments in theoretical and experimental fluid mechanics. Compressible and incompressible flows, P309
   Ogden R. W., 1997, Non-Linear Elastic Deformations, P3
   OKUBO A, 1970, DEEP-SEA RES, V17, P445, DOI 10.1016/0011-7471(70)90059-8
   Parikh N., 2013, Proximal Algorithms, DOI [10.1561/24000000032,6, DOI 10.1561/24000000032,6]
   Peikert R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P263, DOI 10.1109/VISUAL.1999.809896
   PERRY AE, 1994, APPL SCI RES, V53, P357, DOI 10.1007/BF00849110
   PERRY AE, 1987, ANNU REV FLUID MECH, V19, P125, DOI 10.1146/annurev.fluid.19.1.125
   Rautek P, 2021, IEEE T VIS COMPUT GR, V27, P283, DOI 10.1109/TVCG.2020.3030454
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Roth M, 1998, VISUALIZATION '98, PROCEEDINGS, P143, DOI 10.1109/VISUAL.1998.745296
   Sadlo F, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P179, DOI 10.1109/VISUAL.2004.128
   Sahner J., 2005, Proc. EuroVis 2005, P151, DOI DOI 10.2312/VISSYM/EUROVIS05/151-160
   Shen HW, 1997, VISUALIZATION '97 - PROCEEDINGS, P317, DOI 10.1109/VISUAL.1997.663898
   Stalling D., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P249, DOI 10.1145/218380.218448
   Sujudi D., 1995, 12th Computational Fluid Dynamics Conference, P1, DOI [10.2514/6.1995-1715, DOI 10.2514/6.1995-1715]
   Theisel H, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P631
   Theisel H., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P141
   Theisel H, 2021, PHYS FLUIDS, V33, DOI 10.1063/5.0063817
   Tricoche X, 2002, COMPUT GRAPH-UK, V26, P249, DOI 10.1016/S0097-8493(02)00056-0
   Truesdell C., 1965, The Nonlinear Field Theories of Mechanics, DOI [10.1007/978-3-662-10388-3_11,3, DOI 10.1007/978-3-662-10388-3_11,3]
   van Wijk JJ, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P123, DOI 10.1109/VISUAL.2003.1250363
   van Wijk JJ, 2002, ACM T GRAPHIC, V21, P745, DOI 10.1145/566570.566646
   Weinkauf T, 2007, IEEE T VIS COMPUT GR, V13, P1759, DOI 10.1109/TVCG.2007.70545
   WEISS J, 1991, PHYSICA D, V48, P273, DOI 10.1016/0167-2789(91)90088-Q
   Wiebel A, 2011, MATH VIS, P193
   Xie C, 2010, VISUAL INFORMATION COMMUNICATION, P173, DOI 10.1007/978-1-4419-0312-9_11
   Zhang XD, 2022, IEEE T VIS COMPUT GR, V28, P281, DOI 10.1109/TVCG.2021.3115565
NR 53
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 55
EP 65
DI 10.1109/TVCG.2023.3326915
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500121
PM 37874718
DA 2024-08-05
ER

PT J
AU Wen, Z
   Liu, YH
   Tan, SW
   Chen, JY
   Zhu, MF
   Han, DM
   Yin, JW
   Xu, ML
   Chen, W
AF Wen, Zhen
   Liu, Yihan
   Tan, Siwei
   Chen, Jieyi
   Zhu, Minfeng
   Han, Dongming
   Yin, Jianwei
   Xu, Mingliang
   Chen, Wei
TI Quantivine: A Visualization Approach for Large-Scale Quantum Circuit
   Representation and Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Quantum circuit; semantic analysis; visual abstraction; context
   visualization
ID VISUAL ANALYTICS; GRAPH
AB Quantum computing is a rapidly evolving field that enables exponential speed-up over classical algorithms. At the heart of this revolutionary technology are quantum circuits, which serve as vital tools for implementing, analyzing, and optimizing quantum algorithms. Recent advancements in quantum computing and the increasing capability of quantum devices have led to the development of more complex quantum circuits. However, traditional quantum circuit diagrams suffer from scalability and readability issues, which limit the efficiency of analysis and optimization processes. In this research, we propose a novel visualization approach for large-scale quantum circuits by adopting semantic analysis to facilitate the comprehension of quantum circuits. We first exploit meta-data and semantic information extracted from the underlying code of quantum circuits to create component segmentations and pattern abstractions, allowing for easier wrangling of massive circuit diagrams. We then develop Quantivine, an interactive system for exploring and understanding quantum circuits. A series of novel circuit visualizations is designed to uncover contextual details such as qubit provenance, parallelism, and entanglement. The effectiveness of Quantivine is demonstrated through two usage scenarios of quantum circuits with up to 100 qubits and a formal user evaluation with quantum experts. A free copy of this paper and all supplemental materials are available at https://osf.io/2m9yh/?view_only=0aa1618c97244f5093cd7ce15f1431f9.
C1 [Wen, Zhen; Liu, Yihan; Chen, Jieyi; Han, Dongming; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Tan, Siwei; Yin, Jianwei] Zhejiang Univ, Adv Comp & Syst Lab, Hangzhou, Peoples R China.
   [Zhu, Minfeng] Zhejiang Univ, Hangzhou, Peoples R China.
   [Han, Dongming] Hithink Royal Flush Informat Network Co Ltd, Hangzhou, Zhejiang, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Zhengzhou
   University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM wenzhen@zju.edu.cn; lyh1024@zju.edu.cn; siweitan@zju.edu.cn;
   chenjieyi_juraws@zju.edu.cn; minfeng_zhu@zju.edu.cn;
   dongminghan@zju.edu.cn; zjuyjw@cs.zju.edu.cn; iexumingliang@zzu.edu.cn;
   chenvis@zju.edu.cn
RI chen, jieyi/IXM-9530-2023; Chen, Wei/AAR-9817-2020
OI Zhu, Minfeng/0000-0002-6711-3099; Tan, Siwei/0000-0002-0634-8089; Chen,
   Wei/0000-0002-8365-4741; Wen, Zhen/0000-0002-6327-5306
FU National Natural Science Foundation of China
FX No Statement Available
CR Albertoni R., 2005, PROC GIR, P9, DOI [10.1145/1096985.1096989, DOI 10.1145/1096985.1096989]
   Bauer B, 2020, CHEM REV, V120, P12685, DOI 10.1021/acs.chemrev.9b00829
   Bhattacharjee D, 2017, Arxiv, DOI arXiv:1703.08540
   Biamonte J, 2019, COMMUN PHYS-UK, V2, DOI 10.1038/s42005-019-0152-6
   Biamonte J, 2017, NATURE, V549, P195, DOI 10.1038/nature23474
   Biedl T, 1998, COMP GEOM-THEOR APPL, V9, P159, DOI 10.1016/S0925-7721(97)00026-6
   Borner K., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P234, DOI 10.1145/336597.336672
   Brandes U., 2002, Data Visualisation (VISSYM), P159, DOI DOI 10.2312/VISSYM/VISSYM02/159-1643
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Das P, 2021, INT SYMP MICROARCH, P950, DOI 10.1145/3466752.3480059
   Developers C., 2022, Cirq. Zenodo, DOI [10.5281/zenodo.74655771,2, DOI 10.5281/ZENODO.74655771,2]
   Dunne C., 2013, P SIGCHI C HUM FACT, P3247, DOI DOI 10.1145/2470654.2466444
   Egger Daniel J., 2020, IEEE Transactions on Quantum Engineering, V1, DOI 10.1109/TQE.2020.3030314
   Emani PS, 2021, NAT METHODS, V18, P701, DOI 10.1038/s41592-020-01004-3
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P3813, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Fickler R, 2013, SCI REP-UK, V3, DOI 10.1038/srep01914
   Figgatt C, 2019, NATURE, V572, P368, DOI 10.1038/s41586-019-1427-5
   Ghashami M, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P845, DOI 10.1145/2939672.2939800
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Görg C, 2004, LECT NOTES COMPUT SC, V3383, P228
   Green AS, 2013, ACM SIGPLAN NOTICES, V48, P333, DOI 10.1145/2499370.2462177
   Guo D., 2021, P ICLR, DOI [10.48550/arXiv.2009.08366 3, DOI 10.48550/ARXIV.2009.083663]
   Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Hachul Stefan, 2007, Journal of Graph Algorithms and Applications, V11, P345, DOI 10.7155/jgaa.00150
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Han DM, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0013-1
   Han DM, 2021, IEEE COMPUT GRAPH, V41, P18, DOI 10.1109/MCG.2021.3097799
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Huang YP, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P541, DOI 10.1145/3307650.3322213
   Hubregtsen T, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00038-w
   Iten R, 2022, ACM T QUANTUM COMPUT, V3, DOI 10.1145/3498325
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   JavadiAbhari Ali, 2014, ACM C COMP FRONT, P1, DOI [DOI 10.1145/2597917, 10.1145/2597917.2597939, DOI 10.1145/2597917.2597939]
   Jozsa R, 2003, P ROY SOC A-MATH PHY, V459, P2011, DOI 10.1098/rspa.2002.1097
   Kim S., 2010, PROC APGV, P33, DOI [DOI 10.1145/1836248.1836254, 10.1145/1836248.18362542]
   Koutra D., 2014, P 2014 SIAM INT C DA, P91, DOI DOI 10.1137/1.9781611973440.11
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Landauer TK, 2004, P NATL ACAD SCI USA, V101, P5214, DOI 10.1073/pnas.0400341101
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   LeFevre Kristen, 2010, Proceedings of the 2010 SIAM International Conference on Data Mining, P454, DOI DOI 10.1137/1.9781611972801.40
   Li CH, 2017, J VISUAL-JAPAN, V20, P205, DOI 10.1007/s12650-016-0375-5
   Lin SY, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P37, DOI 10.1109/SciVis.2018.8823602
   Liu YK, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186727
   Liu YC, 2021, NAT PHYS, V17, P1013, DOI 10.1038/s41567-021-01287-z
   Maccioni A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1755, DOI 10.1145/2939672.2939856
   Martin A, 2021, PHYS REV RES, V3, DOI 10.1103/PhysRevResearch.3.013167
   Maslov D, 2008, IEEE T COMPUT AID D, V27, P436, DOI 10.1109/TCAD.2007.911334
   Mathioudakis, 2011, P 17 ACM SIGKDD INT, P529, DOI DOI 10.1145/2020408.2020492
   Mehmood Yasir, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P48, DOI 10.1007/978-3-642-40991-2_4
   Miller M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON QUANTUM COMPUTING AND ENGINEERING (QCE 2021) / QUANTUM WEEK 2021, P378, DOI 10.1109/QCE52317.2021.00057
   Mueller C, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P141
   Navlakha S., 2008, P ACM SIGMOD INT C M, P419, DOI DOI 10.1145/1376616.1376661
   Nielsen M. A., 2010, Quantum Computation and Quantum Information, V10th, DOI [10.1017/CBO97805119766671,2,3, DOI 10.1017/CBO97805119766671,2,3]
   North SC, 2002, LECT NOTES COMPUT SC, V2265, P232
   Pan JC, 2020, FRONT INFORM TECH EL, V21, P491, DOI 10.1631/FITEE.1900310
   Preskill J, 2012, Arxiv, DOI arXiv:1203.5813
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Purchase H. C., 2006, Graph Drawing. 14th International Symposium, GD 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4372), P184
   Ruan Shaolun, 2023, IEEE Transactions on Visualization and Computer Graphics, V29, P462, DOI 10.1109/TVCG.2022.3209455
   Sen S., 2017, Proceedings of the 22nd International Conference on Intelligent User Interfaces, P179, DOI DOI 10.1145/3025171.3025233
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Stein SA, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON QUANTUM COMPUTING AND ENGINEERING (QCE 2021) / QUANTUM WEEK 2021, P71, DOI 10.1109/QCE52317.2021.00023
   Svore K, 2018, RWDSL2018: PROCEEDINGS OF THE REAL WORLD DOMAIN SPECIFIC LANGUAGES WORKSHOP 2018, DOI 10.1145/3183895.3183901
   tA v A., 2021, Qiskit: An Open-Source Framework for Quantum Computing
   Tan BC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415620
   Tao RZ, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P641, DOI 10.1145/3519939.3523431
   Tao ZW, 2017, I C VIRTUAL REALITY, P360, DOI 10.1109/ICVRV.2017.00082
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   Wang XM, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-023-2691-y
   Wang YY, 2021, VIS INFORM, V5, P49, DOI 10.1016/j.visinf.2021.12.003
   Weder B, 2020, INT CONF UTIL CLOUD, P279, DOI 10.1109/UCC48980.2020.00046
   Weiden M, 2022, 2022 IEEE/ACM THIRD INTERNATIONAL WORKSHOP ON QUANTUM COMPUTING SOFTWARE (QCS), P1, DOI 10.1109/QCS56647.2022.00006
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Wu YC, 2011, COMPUT GRAPH FORUM, V30, P741, DOI 10.1111/j.1467-8659.2011.01923.x
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Xiong K, 2023, IEEE T VIS COMPUT GR, V29, P2950, DOI 10.1109/TVCG.2022.3144975
   Xu MK, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P625, DOI 10.1145/3519939.3523433
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 83
TC 0
Z9 0
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 573
EP 583
DI 10.1109/TVCG.2023.3327148
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500007
PM 37878443
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ge, T
   Luo, X
   Wang, YH
   Sedlmair, M
   Cheng, ZL
   Zhao, Y
   Liu, X
   Deussen, O
   Chen, BQ
AF Ge, Tong
   Luo, Xu
   Wang, Yunhai
   Sedlmair, Michael
   Cheng, Zhanglin
   Zhao, Ying
   Liu, Xin
   Deussen, Oliver
   Chen, Baoquan
TI Optimally Ordered Orthogonal Neighbor Joining Trees for Hierarchical
   Cluster Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Couplings; Clustering algorithms; Layout; Visualization; Biology;
   Germanium; Sorting; Neighbor joining; leaf ordering; orthogonal layout
ID VISUALIZATION; ALGORITHMS; MODEL
AB We propose to use optimally ordered orthogonal neighbor-joining (O-3 NJ) trees as a new way to visually explore cluster structures and outliers in multi-dimensional data. Neighbor-joining (NJ) trees are widely used in biology, and their visual representation is similar to that of dendrograms. The core difference to dendrograms, however, is that NJ trees correctly encode distances between data points, resulting in trees with varying edge lengths. We optimize NJ trees for their use in visual analysis in two ways. First, we propose to use a novel leaf sorting algorithm that helps users to better interpret adjacencies and proximities within such a tree. Second, we provide a new method to visually distill the cluster tree from an ordered NJ tree. Numerical evaluation and three case studies illustrate the benefits of this approach for exploring multi-dimensional data in areas such as biology or image analysis.
C1 [Ge, Tong; Luo, Xu; Wang, Yunhai] Shandong Univ, Dept Comp Sci, Jinan 250100, Shandong, Peoples R China.
   [Sedlmair, Michael] Univ Stuttgart, D-70174 Stuttgart, Germany.
   [Cheng, Zhanglin] SIAT, Shenzhen VisuCA Key Lab, Shenzhen 518055, Guangdong, Peoples R China.
   [Zhao, Ying] Cent South Univ, Changsha 410017, Hunan, Peoples R China.
   [Liu, Xin] Beijing Genom Inst BGI Shenzhen, Shenzhen 518083, Guangdong, Peoples R China.
   [Deussen, Oliver] Univ Konstanz, D-78464 Constance, Germany.
   [Chen, Baoquan] Peking Univ, Beijing 100871, Peoples R China.
C3 Shandong University; University of Stuttgart; Chinese Academy of
   Sciences; Shenzhen Institute of Advanced Technology, CAS; Central South
   University; Beijing Genomics Institute (BGI); University of Konstanz;
   Peking University
RP Wang, YH (corresponding author), Shandong Univ, Dept Comp Sci, Jinan 250100, Shandong, Peoples R China.
EM tgeconf@gmail.com; luoxu9days@gmail.com; cloudseawang@gmail.com;
   Michael.Sedlmair@visus.uni-stuttgart.de; zl.cheng@siat.ac.cn;
   zhaoying@csu.edu.cn; liuxin@genomics.cn; Oliver.Deussen@uni-konstanz.de;
   baoquan@pku.edu.cn
RI Deussen, Oliver/HKF-2004-2023; Liu, Xin/ABJ-9485-2022
OI Liu, Xin/0000-0003-3256-2940; Luo, Xu/0000-0003-1501-7385; Cheng,
   Zhanglin/0000-0002-3360-2679
FU National Key R&D Program of China [2022ZD0160805]; NSFC [62132017,
   62141217]; Shandong Provincial Natural Science Foundation [ZQ2022JQ32];
   DFG [EXC2117-422037984, 251654672 - TRR 161]; Shenzhen Science and
   Technology Program [GJHZ20210705141402008]
FX This work was supported by the grants of the National Key R&D Program of
   China under Grant 2022ZD0160805, in part by NSFC under Grants 62132017
   and 62141217, in part by Shandong Provincial Natural Science Foundation
   under Grant ZQ2022JQ32 as well as in part by by the DFG (German Research
   Foundation) under Germany's Excellence under Grant
   Strategy-EXC2117-422037984,in part by the Project-ID 251654672 - TRR
   161, and in part by Shenzhen Science and Technology Program under Grant
   GJHZ20210705141402008.
CR Bachmaier C, 2005, LECT NOTES COMPUT SC, V3827, P1110, DOI 10.1007/11602613_110
   Bachmaier C., 2005, Drawing Phylogenetic Trees, DOI [10.1007/11602613110.2Z, DOI 10.1007/11602613110.2Z]
   Backeljau T, 1996, MOL BIOL EVOL, V13, P309, DOI 10.1093/oxfordjournals.molbev.a025590
   Bar-Joseph Z, 2003, BIOINFORMATICS, V19, P1070, DOI 10.1093/bioinformatics/btg030
   Bar-Joseph Z., 2001, Bioinformatics, V17, p$22 $29, DOI [10.1093/bioinformatics/17.supp_1.S22, DOI 10.1093/BIOINFORMATICS/17.SUPP_1.S22]
   Brehmer M., 2014, P IEEE VIS WORKSH TI, P1, DOI DOI 10.1145/2669557.2669559
   Buneman P., 1974, J. Comb. Theory, Ser. B, V17, P48, DOI DOI 10.1016/0095-8956(74)90047-1
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2440, DOI 10.1109/TVCG.2011.193
   Cayton L., 2005, Tech. Rep. 12.1-17
   Chae MH, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022546
   Cuadros AM, 2007, IEEE CONF VIS ANAL, P99, DOI 10.1109/VAST.2007.4389002
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   de Oliveira MCF, 2003, IEEE T VIS COMPUT GR, V9, P378, DOI 10.1109/TVCG.2003.1207445
   Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863
   Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617
   FARACH M, 1995, ALGORITHMICA, V13, P155, DOI 10.1007/BF01188585
   Fraley C, 1999, J CLASSIF, V16, P297, DOI 10.1007/s003579900058
   Franti P., 2017, Clustering datasets
   GRUVAEUS G, 1972, BRIT J MATH STAT PSY, V25, P200, DOI 10.1111/j.2044-8317.1972.tb00491.x
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Halle M., 1990, An essay on stress
   Han J, 2012, MOR KAUF D, P1
   Hebert PDN, 2003, P ROY SOC B-BIOL SCI, V270, P313, DOI 10.1098/rspb.2002.2218
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   KUIPER FK, 1975, BIOMETRICS, V31, P777, DOI 10.2307/2529565
   Landau S., 2011, Cluster Analysis, Vfifth
   Lichman M, 2013, UCI MACHINE LEARNING
   McGuffin MJ, 2010, INFORM VISUAL, V9, P115, DOI 10.1057/ivs.2009.4
   MILLIGAN GW, 1980, PSYCHOMETRIKA, V45, P325, DOI 10.1007/BF02293907
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Nakhleh L, 2005, T PHILOL SOC, V103, P171, DOI 10.1111/j.1467-968X.2005.00149.x
   Paiva JGS, 2011, IEEE T VIS COMPUT GR, V17, P2459, DOI 10.1109/TVCG.2011.212
   Paradis E, 2019, BIOINFORMATICS, V35, P526, DOI 10.1093/bioinformatics/bty633
   Procter JB, 2010, NAT METHODS, V7, pS16, DOI [10.1038/NMETH.1434, 10.1038/nmeth.1434]
   Qi JJ, 2013, NAT GENET, V45, P1510, DOI 10.1038/ng.2801
   Rambaut A, 2008, NATURE, V453, P615, DOI 10.1038/nature06945
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   SAITOU N, 1987, MOL BIOL EVOL, V4, P406, DOI 10.1093/oxfordjournals.molbev.a040454
   Sakai Ryo, 2014, F1000Res, V3, P177, DOI 10.12688/f1000research.4784.1
   Saraçli S, 2013, J INEQUAL APPL, DOI 10.1186/1029-242X-2013-203
   Sebastian P, 2010, P NATL ACAD SCI USA, V107, P14269, DOI 10.1073/pnas.1005338107
   Seo J, 2002, COMPUTER, V35, P80
   Shah SA, 2017, P NATL ACAD SCI USA, V114, P9814, DOI 10.1073/pnas.1700770114
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Simonsen M, 2008, LECT N BIOINFORMAT, V5251, P113, DOI 10.1007/978-3-540-87361-7_10
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Slonim N, 2000, ADV NEUR IN, V12, P617
   SOKAL ROBERT R., 1962, TAXON, V11, P33, DOI 10.2307/1217208
   Telles GP, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2162-x
   Weinkauf T, 2009, COMPUT GRAPH FORUM, V28, P1519, DOI 10.1111/j.1467-8659.2009.01528.x
   Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P515, DOI 10.1145/584792.584877
NR 53
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5034
EP 5046
DI 10.1109/TVCG.2023.3284499
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400062
PM 37294655
DA 2024-08-05
ER

PT J
AU Hu, L
   Zhang, ZH
   Zhong, CY
   Jiang, BY
   Xia, SH
AF Hu, Lei
   Zhang, Zihao
   Zhong, Chongyang
   Jiang, Boyuan
   Xia, Shihong
TI Pose-Aware Attention Network for Flexible Motion Retargeting by Body
   Part
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deep learning; motion processing; motion retargeting
AB Motion retargeting is a fundamental problem in computer graphics and computer vision. Existing approaches usually have many strict requirements, such as the source-target skeletons needing to have the same number of joints or share the same topology. To tackle this problem, we note that skeletons with different structure may have some common body parts despite the differences in joint numbers. Following this observation, we propose a novel, flexible motion retargeting framework. The key idea of our method is to regard the body part as the basic retargeting unit rather than directly retargeting the whole body motion. To enhance the spatial modeling capability of the motion encoder, we introduce a pose-aware attention network (PAN) in the motion encoding phase. The PAN is pose-aware since it can dynamically predict the joint weights within each body part based on the input pose, and then construct a shared latent space for each body part by feature pooling. Extensive experiments show that our approach can generate better motion retargeting results both qualitatively and quantitatively than state-of-the-art methods. Moreover, we also show that our framework can generate reasonable results even for a more challenging retargeting scenario, like retargeting between bipedal and quadrupedal skeletons because of the body part retargeting strategy and PAN.
C1 [Hu, Lei; Zhang, Zihao; Zhong, Chongyang; Jiang, Boyuan; Xia, Shihong] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Hu, Lei; Zhong, Chongyang; Jiang, Boyuan; Xia, Shihong] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Xia, SH (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.; Xia, SH (corresponding author), Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
EM hulei19z@ict.ac.cn; zhangzihao@ict.ac.cn; zhongchongyang@ict.ac.cn;
   jiangboyuan20s@ict.ac.cn; xsh@ict.ac.cn
OI Zhong, Chongyang/0000-0003-0020-1892; Zhang, Zihao/0000-0001-6859-7518;
   Hu, Lei/0000-0001-8938-5071
FU National Key R#x0026;D Program #x201C;Industrial Software#x201D; Special
   Project of China [2022YFB3303202]
FX No Statement Available
CR A. S. Inc, 2021, "Adobe's Mixamo.
   Abdul-Massih M, 2017, COMPUT GRAPH FORUM, V36, P86, DOI 10.1111/cgf.12860
   Aberman K, 2019, Arxiv, DOI arXiv:1905.01680
   Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Baran D., 2009, ACM SIGGRAPH Papers, P1
   Celikcan U, 2015, COMPUT GRAPH FORUM, V34, P216, DOI 10.1111/cgf.12507
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   Gao L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275028
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Guo CA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2021, DOI 10.1145/3394171.3413635
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Heck R, 2006, COMPUT GRAPH FORUM, V25, P459, DOI 10.1111/j.1467-8659.2006.00965.x
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Holden J., 2015, P SIGGRAPH AS TECH B, P1
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jang DK, 2022, Arxiv, DOI arXiv:2202.05274
   Jang WS, 2008, VISUAL COMPUT, V24, P271, DOI 10.1007/s00371-007-0200-1
   Kim M., 2022, arXiv
   Kingma D. P., 2014, arXiv
   Lee J, 1999, COMP GRAPH, P39
   Lee S., 2022, ACM Trans. Graph., V41, P1
   Liao ZYC, 2022, Arxiv, DOI arXiv:2208.00790
   Lim H. J., 2019, P BRIT MACH VIS C
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Ma W., 2010, P ACM SIGGRAPH EUR S, P21, DOI DOI 10.1109/IUCS.2010.5666642
   Petrovich Mathis., 2021, arXiv
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Rempe Davis, 2020, P EUR C COMP VIS ECC, P71, DOI DOI 10.1007/978-3-030-58558-75
   Ren M., 2021, P IEEE CVF C COMP VI
   Seol Y., 2013, P 12 ACM SIGGRAPH EU, P213
   Shi L., 2020, P AS C COMP VIS, P38, DOI DOI 10.1007/978-3-030-69541-5_3
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Starke S, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530178
   Starke S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459881
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Kim SU, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1947
   Vaswani A, 2017, ADV NEUR IN, V30
   Villegas D., 2021, arXiv:2109.07431, P33
   Villegas R, 2018, PROC CVPR IEEE, P8639, DOI 10.1109/CVPR.2018.00901
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Yamane K., 2010, P ACM SIGGRAPH EUR S, P169
   Ye YJ, 2022, Arxiv, DOI [arXiv:2209.05753, DOI 10.48550/ARXIV.2209.05753]
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhang JL, 2022, PROC CVPR IEEE, P13222, DOI 10.1109/CVPR52688.2022.01288
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhong CY, 2022, PROC CVPR IEEE, P6437, DOI 10.1109/CVPR52688.2022.00634
NR 52
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4792
EP 4808
DI 10.1109/TVCG.2023.3277918
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400082
PM 37204962
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Sevastjanova, R
   Hauptmann, H
   Deterding, S
   El-Assady, M
AF Sevastjanova, Rita
   Hauptmann, Hanna
   Deterding, Sebastian
   El-Assady, Mennatallah
TI Personalized Language Model Selection Through Gamified Elicitation of
   Contrastive Concept Preferences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptation models; Task analysis; Games; Data models; Computational
   modeling; Cognitive science; Analytical models; Language model
   personalization; gamification; visual analytics
ID GAMIFICATION
AB Language models are widely used for different Natural Language Processing tasks while suffering from a lack of personalization. Personalization can be achieved by, e.g., fine-tuning the model on training data that is created by the user (e.g., social media posts). Previous work shows that the acquisition of such data can be challenging. Instead of adapting the model's parameters, we thus suggest selecting a model that matches the user's mental model of different thematic concepts in language. In this article, we attempt to capture such individual language understanding of users. In this process, two challenges have to be considered. First, we need to counteract disengagement since the task of communicating one's language understanding typically encompasses repetitive and time-consuming actions. Second, we need to enable users to externalize their mental models in different contexts, considering that language use changes depending on the environment. In this article, we integrate methods of gamification into a visual analytics (VA) workflow to engage users in sharing their knowledge within various contexts. In particular, we contribute the design of a gameful VA playground called Concept Universe. During the four-phased game, the users build personalized concept descriptions by explaining given concept names through representative keywords. Based on their performance, the system reacts with constant visual, verbal, and auditory feedback. We evaluate the system in a user study with six participants, showing that users are engaged and provide more specific input when facing a virtual opponent. We use the generated concepts to make personalized language model suggestions.
C1 [Sevastjanova, Rita] Univ Konstanz, D-78457 Constance, Germany.
   [Hauptmann, Hanna] Univ Utrecht, NL-3584 CS Utrecht, Netherlands.
   [Deterding, Sebastian] Imperial Coll London, London SW7 2BX, England.
   [El-Assady, Mennatallah] ETH, Res Ctr Energy Networks, CH-8092 Zurich, Switzerland.
C3 University of Konstanz; Utrecht University; Imperial College London;
   Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Sevastjanova, R (corresponding author), Univ Konstanz, D-78457 Constance, Germany.
EM rita.sevastjanova@uni-konstanz.de; h.j.hauptmann@uu.nl;
   s.deterding@imperial.ac.uk; melassady@ai.ethz.ch
RI Hauptmann, Hanna/R-3492-2016; Deterding, Sebastian/L-4649-2017
OI Hauptmann, Hanna/0000-0002-6840-5341; SEVASTJANOVA,
   RITA/0000-0002-2629-9579; Deterding, Sebastian/0000-0003-0033-2104;
   El-Assady, Mennatallah/0000-0001-8526-2613
FU Deutsche Forschungsgemein-schaft [BU1806/10-2]; ETH AI Center
FX No Statement Available
CR [Anonymous], 2015, Int. J. Hum.- Comput. Stud., V74, P14
   Arias-Hernandez L. T., 2011, P 44 HAW INT C SYST, P1, DOI DOI 10.1109/HICSS.2011.339
   Bi KP, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1521, DOI 10.1145/3397271.3401192
   Bordia S, 2019, Arxiv, DOI arXiv:1904.03035
   Brandenburg FJ, 1996, LECT NOTES COMPUT SC, V1027, P76, DOI 10.1007/BFb0021792
   Cambridge U.K., 2008, P 1 INSTR C MACH LEA, P1
   Carroll J. R., 1988, of human-Computer Interaction, P45
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Cirqueira L., 2017, AN EST 23 S BRAS SIS, P209
   De Croon R, 2018, IEEE INT CONF HEALT, P53, DOI 10.1109/ICHI.2018.00014
   Deterding S., 2011, P 15 INT AC MINDTREK, DOI DOI 10.1145/2181037.2181040
   Fine AB, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P7
   Glavas A., 2021, P 16 WORKSH INN US N, P110
   Han XC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4238
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Kim Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P866
   King M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2461
   Lafourcade M, 2016, LECT NOTES COMPUT SC, V9612, P258, DOI 10.1007/978-3-319-41754-7_23
   Lanser B, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3477
   Lauscher A., 2020, P DEEP LEARN INS OUT, P43
   Lee HY, 2017, IEEE-ACM T AUDIO SPE, V25, P519, DOI 10.1109/TASLP.2016.2635445
   Lee J., 2011, Academic Exchange Quarterly, V15, P146
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Moreira A, 2007, GRAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL GM/R, P61
   Ostrow KS, 2018, LECT NOTES ARTIF INT, V10947, P381, DOI 10.1007/978-3-319-93843-1_28
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46
   Pham J. M., 2020, P 5 C MACH TRANSL, P617
   Phang J, 2019, Arxiv, DOI arXiv:1811.01088
   Philip J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4465
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Saeed N, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3178155
   Sailer M, 2017, COMPUT HUM BEHAV, V69, P371, DOI 10.1016/j.chb.2016.12.033
   San Vicente I, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P938
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Vaswani A., 2017, Advances in neural information processing systems, P5998
   Venhuizen K., 2013, P INT C COMP SEM, P397
   Zhang J, 2023, J MANAGE INFORM SYST, V40, P401, DOI 10.1080/07421222.2023.2196776
NR 41
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5449
EP 5465
DI 10.1109/TVCG.2023.3296905
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400073
PM 37494152
DA 2024-08-05
ER

PT J
AU Ghaffari, B
   Gatti, D
   Westermann, R
AF Ghaffari, Behdad
   Gatti, Davide
   Westermann, Rudiger
TI Spatio-Temporal Visual Analysis of Turbulent Superstructures in Unsteady
   Flow
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Visualization; Graphics processing units;
   Periodic structures; Data visualization; Feature extraction; Bandwidth;
   Flow visualization; large-scale data techniques; animation and
   motion-related techniques
ID SCALE STRUCTURES; WALL; VISUALIZATION; THERAPIES; FRAMEWORK
AB The large-scale motions in 3D turbulent channel flows, known as Turbulent Superstructures (TSS), play an essential role in the dynamics of small-scale structures within the turbulent boundary layer. However, as of today, there is no common agreement on the spatial and temporal relationships between these multiscale structures. We propose a novel space-time visualization technique for analyzing the temporal evolution of these multiscale structures in their spatial context and, thus, to further shed light on the conceptually different explanations of their dynamics. Since the temporal dynamics of TSS are believed to influence the structures in the turbulent boundary layer, we propose a combination of a 2D space-time velocity plot with an orthogonal 2D plot of projected 3D flow structures, which can interactively span the time and the space axis. Besides flow structures indicating the fluid motion, we propose showing the variations in derived fields as an additional source of explanation. The relationships between the structures in different spatial and temporal scales can be more effectively resolved by using various filtering operations and image registration algorithms. To reduce the information loss due to the non-injective nature of projection, spatial information is encoded into transparency or color. Since the proposed visualization is heavily demanding computational resources and memory bandwidth to stream unsteady flow fields and instantly compute derived 3D flow structures, the implementation exploits data compression, parallel computation capabilities, and high memory bandwidth on recent GPUs via the CUDA compute library.
C1 [Ghaffari, Behdad; Westermann, Rudiger] Tech Univ Munich, D-80333 Munich, Germany.
   [Gatti, Davide] Karlsruhe Inst Technol, D-76131 Karlsruhe, Germany.
C3 Technical University of Munich; Helmholtz Association; Karlsruhe
   Institute of Technology
RP Ghaffari, B (corresponding author), Tech Univ Munich, D-80333 Munich, Germany.
EM behdad.ghaffari@tum.de; davide.gatti@kit.edu; westermann@tum.de
FU German Research Foundation (DFG) [SPP 1881]
FX This work was supported by the German Research Foundation (DFG) within
   the Priority Programme Turbulent Superstructures under Grant SPP 1881.
CR Abe H, 2018, J FLUID MECH, V850, P733, DOI 10.1017/jfm.2018.434
   Adrian RJ, 2007, PHYS FLUIDS, V19, DOI 10.1063/1.2717527
   Amanatides A., 1987, Tech. Papers, P3
   Bujack R, 2020, ENVIRON EARTH SCI, V79, DOI 10.1007/s12665-019-8800-4
   Burger K., 2012, Proc. Vis. Data Anal
   Chernyshenko SI, 2005, J FLUID MECH, V544, P99, DOI 10.1017/S0022112005006506
   Childs H., 2012, High Performance Visualization: Enabling Extreme-Scale Scientific Insight, P357, DOI [DOI 10.1201/B12985, 10.1201/b12985]
   Cimarelli A, 2016, J FLUID MECH, V796, DOI 10.1017/jfm.2016.275
   Del Alamo JC, 2009, J FLUID MECH, V640, P5, DOI 10.1017/S0022112009991029
   Dickey JW, 2009, PUBLIC ADMINISTRATION (P. A.) GENOME PROJECT: CAPTURING MAPPING AND DEPLOYING THE GENES OF P. A., P43
   Dogan E, 2019, FLUID DYN RES, V51, DOI 10.1088/1873-7005/aaca81
   Frasson A, 2019, IEEE PAC VIS SYMP, P202, DOI 10.1109/PacificVis.2019.00031
   Garth K., 2014, Math. Vis., V37, P327
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Guo HQ, 2019, IEEE T VIS COMPUT GR, V25, P2710, DOI 10.1109/TVCG.2018.2856772
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hutchins N, 2007, J FLUID MECH, V579, P1, DOI 10.1017/S0022112006003946
   Hutchins N, 2007, PHILOS T R SOC A, V365, P647, DOI 10.1098/rsta.2006.1942
   Jankowai J, 2020, IEEE T VIS COMPUT GR, V26, P1308, DOI 10.1109/TVCG.2018.2867488
   Jiménez J, 1999, J FLUID MECH, V389, P335, DOI 10.1017/S0022112099005066
   Kai Buerger PolinaKondratieva., 2007, Eurographics, P251
   Kern M, 2021, IEEE T VIS COMPUT GR, V27, P3361, DOI 10.1109/TVCG.2020.2975795
   LELE SK, 1992, J COMPUT PHYS, V103, P16, DOI 10.1016/0021-9991(92)90324-R
   Liu XP, 2019, COMPUT GRAPH FORUM, V38, P300, DOI 10.1111/cgf.13532
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674
   Luchini P, 2006, J COMPUT PHYS, V211, P551, DOI 10.1016/j.jcp.2005.06.003
   Mathis R, 2009, J FLUID MECH, V628, P311, DOI 10.1017/S0022112009006946
   McLoughlin R. S., 2009, Eurographics State Art Rep., P1807
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P3147, DOI 10.1109/TVCG.2019.2920157
   Peterka T., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P580, DOI 10.1109/IPDPS.2011.62
   Pope S., 2000, Turbulent Flows, V35
   Quadrio M, 2003, PHYS FLUIDS, V15, P2219, DOI 10.1063/1.1586273
   Schirski M., 2004, Proceedings of the 2004 ACMSIGGRAPH international conference on Virtual Reality continuum and its applications in industry, P141
   Smits AJ, 2011, ANNU REV FLUID MECH, V43, P353, DOI 10.1146/annurev-fluid-122109-160753
   Sreenivasan KR, 1997, ANNU REV FLUID MECH, V29, P435, DOI 10.1146/annurev.fluid.29.1.435
   Talluru KM, 2014, J FLUID MECH, V746, DOI 10.1017/jfm.2014.132
   Toh S, 2005, J FLUID MECH, V524, P249, DOI 10.1017/S002211200400237X
   Treib Marc, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P279
   Treib M., 2014, Ph.D. dissertation
   Treib M, 2012, IEEE T VIS COMPUT GR, V18, P2169, DOI 10.1109/TVCG.2012.274
   Zachiu C, 2015, PHYS MED BIOL, V60, P9003, DOI 10.1088/0031-9155/60/23/9003
   Zachiua C, 2015, MED PHYS, V42, P4137, DOI 10.1118/1.4922403
   Zhang J, 2018, J VISUAL-JAPAN, V21, P351, DOI 10.1007/s12650-017-0470-2
NR 44
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3346
EP 3358
DI 10.1109/TVCG.2022.3232367
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700052
PM 37015508
DA 2024-08-05
ER

PT J
AU Ma, ZH
   Li, CZ
   Liu, XT
   Wu, HS
   Wen, ZK
AF Ma, Ziheng
   Li, Chengze
   Liu, Xueting
   Wu, Huisi
   Wen, Zhenkun
TI Separating Shading and Reflectance From Cartoon Illustrations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cartoon; deep learning; layer decomposition; shading extraction; shading
   removal
ID INTRINSIC IMAGE DECOMPOSITION
AB Shading plays an important role in cartoon drawings to present the 3D lighting and depth information in a 2D image to improve the visual information and pleasantness. But it also introduces apparent challenges in analyzing and processing the cartoon drawings for different computer graphics and vision applications, such as segmentation, depth estimation, and relighting. Extensive research has been made in removing or separating the shading information to facilitate these applications. Unfortunately, the existing researches only focused on natural images, which are natively different from cartoons since the shading in natural images is physically correct and can be modeled based on physical priors. However, shading in cartoons is manually created by artists, which may be imprecise, abstract, and stylized. This makes it extremely difficult to model the shading in cartoon drawings. Without modeling the shading prior, in the paper, we propose a learning-based solution to separate the shading from the original colors using a two-branch system consisting of two subnetworks. To the best of our knowledge, our method is the first attempt in separating shading information from cartoon drawings. Our method significantly outperforms the methods tailored for natural images. Extensive evaluations have been performed with convincing results in all cases.
C1 [Ma, Ziheng; Liu, Xueting; Wu, Huisi; Wen, Zhenkun] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Guangdong, Peoples R China.
   [Li, Chengze] Caritas Inst Higher Educ, Sch Comp & Informat Sci, Hong Kong 999077, Peoples R China.
C3 Shenzhen University; Saint Francis University Hong Kong
RP Wu, HS (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Guangdong, Peoples R China.
EM 2070276193@email.szu.edu.cn; ljsabc@gmail.com; xtliu@szu.edu.cn;
   hswu@szu.edu.cn; wenzk@szu.edu.cn
RI Li, Chengze/AAU-7168-2021
OI Li, Chengze/0000-0002-1519-750X; Ma, Ziheng/0000-0002-2628-553X; Wu,
   Huisi/0000-0002-0399-9089
FU National Natural Science Foundation of China [61973221, 62002232,
   62273241]; Natural Science Foundation of Guangdong Province, China
   [2019A1515011165]; Major Project of the New Generation of Artificial
   Intelligence [2018AAA0102900]; Research Grants Council of the Hong Kong
   Special Administrative Region, China [UGC/FDS11/E02/21]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61973221, 62002232 and 62273241, inpart
   by the Natural Science Foundation of Guangdong Province, China under
   Grant 2019A1515011165, in part by the Major Project of the New
   Generation of Artificial Intelligence under Grant 2018AAA0102900, and in
   part by the Research Grants Council of the Hong Kong Special
   Administrative Region, China under Grant UGC/FDS11/E02/21.
CR Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Bi S, 2018, Arxiv, DOI arXiv:1807.11226
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Huang Z., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Isola P., 2017, P IEEE C COMP VIS PA, P1125, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Janner M, 2018, Arxiv, DOI arXiv:1711.03678
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li CL, 2017, ACM T INFORM SYST, V36, DOI 10.1145/3091108
   Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Liu YF, 2020, PROC CVPR IEEE, P3245, DOI 10.1109/CVPR42600.2020.00331
   Narihira T, 2015, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2015.7298915
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C., 2011, P ADV NEUR INF PROC, V24, P765
   Selinger Peter, 2003, Potrace: a polygon-based tracing algorithm
   Shen JB, 2013, IEEE T CYBERNETICS, V43, P425, DOI 10.1109/TSMCB.2012.2208744
   Shen L, 2008, PROC CVPR IEEE, P2479
   Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738
   STERNBERG SR, 1983, COMPUTER, V16, P22, DOI 10.1109/MC.1983.1654163
   Wang ZJ, 2019, IEEE INT CONF COMP V, P4310, DOI 10.1109/ICCVW.2019.00531
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 29
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3664
EP 3679
DI 10.1109/TVCG.2023.3239364
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700039
PM 37021997
DA 2024-08-05
ER

PT J
AU Elmqvist, N
   Liu, SX
   Pascucci, V
AF Elmqvist, Niklas
   Liu, Shixia
   Pascucci, Valerio
TI Editorial: Guest Editors' Introduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
C1 [Elmqvist, Niklas] Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.
   [Liu, Shixia] Tsinghua Univ, Sch Software, Beijing, Peoples R China.
   [Pascucci, Valerio] Univ Utah, Sci & Imaging Inst, Salt Lake City, UT USA.
C3 Aarhus University; Tsinghua University; Utah System of Higher Education;
   University of Utah
RP Elmqvist, N (corresponding author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.
EM elm@cs.au.dk
OI Elmqvist, Niklas/0000-0001-5805-5301
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2860
EP 2861
DI 10.1109/TVCG.2024.3373233
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500002
DA 2024-08-05
ER

PT J
AU Ruan, SL
   Liang, ZD
   Guan, Q
   Griffin, P
   Wen, XL
   Lin, YN
   Wang, Y
AF Ruan, Shaolun
   Liang, Zhiding
   Guan, Qiang
   Griffin, Paul
   Wen, Xiaolin
   Lin, Yanna
   Wang, Yong
TI <i>VIOLET</i>: <underline>V</underline>isual
   Analyt<underline>i</underline>cs f<underline>o</underline>r
   Exp<underline>l</underline>ainable Quantum N<underline>e</underline>ural
   Ne<underline>t</underline>works
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; explainable artificial intelligence (XAI); quantum
   machine learning; qunatum neural networks
ID VISUAL ANALYTICS; DESIGN; VISUALIZATION; INFORMATION
AB With the rapid development of Quantum Machine Learning, quantum neural networks (QNN) have experienced great advancement in the past few years, harnessing the advantages of quantum computing to significantly speed up classical machine learning tasks. Despite their increasing popularity, the quantum neural network is quite counter-intuitive and difficult to understand, due to their unique quantum-specific layers (e.g., data encoding and measurement) in their architecture. It prevents QNN users and researchers from effectively understanding its inner workings and exploring the model training status. To fill the research gap, we propose VIOLET, a novel visual analytics approach to improve the explainability of quantum neural networks. Guided by the design requirements distilled from the interviews with domain experts and the literature survey, we developed three visualization views: the Encoder View unveils the process of converting classical input data into quantum states, the Ansatz View reveals the temporal evolution of quantum states in the training process, and the Feature View displays the features a QNN has learned after the training process. Two novel visual designs, i.e., satellite chart and augmented heatmap, are proposed to visually explain the variational parameters and quantum circuit measurements respectively. We evaluate VIOLET through two case studies and in-depth interviews with 12 domain experts. The results demonstrate the effectiveness and usability of VIOLET in helping QNN users and developers intuitively understand and explore quantum neural networks.
C1 [Ruan, Shaolun; Griffin, Paul; Wen, Xiaolin; Wang, Yong] Singapore Management Univ, Singapore 188065, Singapore.
   [Liang, Zhiding] Univ Notre Dame, Notre Dame, IN 46556 USA.
   [Guan, Qiang] Kent State Univ, Kent, OH 44240 USA.
   [Lin, Yanna] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Singapore Management University; University of Notre Dame; University
   System of Ohio; Kent State University; Kent State University Salem; Kent
   State University Kent; Hong Kong University of Science & Technology
RP Wang, Y (corresponding author), Singapore Management Univ, Singapore 188065, Singapore.
EM slruan.2021@phdcs.smu.edu.sg; zliang5@nd.edu; qguan@kent.edu;
   paulgriffin@smu.edu.sg; xiaolinwen@smu.edu.sg; ylindg@connect.ust.hk;
   yongwang@smu.edu.sg
RI ; Griffin, Paul/L-4696-2014
OI Lin, Yanna/0000-0003-3730-0827; Griffin, Paul/0000-0002-1656-421X;
   Griffin, Paul/0000-0003-2294-5980; Ruan, Shaolun/0000-0002-6163-9786;
   Wen, Xiaolin/0000-0002-8562-7640
FU Lee Kong Chian Fellowship
FX No Statement Available
CR Acharya R, 2023, NATURE, V614, P676, DOI 10.1038/s41586-022-05434-1
   Altaisky M.V., 2001, arXiv, DOI [10.48550/arXiv.quant-ph/0107012, DOI 10.48550/ARXIV.QUANT-PH/0107012]
   Altepeter J. B., 2009, P C LAS EL C QUANT E, P1, DOI [10.1364/IQEC.2009.IWC1, DOI 10.1364/IQEC.2009.IWC1]
   [Anonymous], IBMQ Phase Disk
   [Anonymous], "Paddle quantum: Quantum classifier
   [Anonymous], 2019, Quantum Computing: Progress and Prospects
   [Anonymous], "Quantum neural networks
   Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5
   Bardroff PJ, 1996, PHYS REV A, V53, P2736, DOI 10.1103/PhysRevA.53.2736
   Bausch J., 2020, P ADV NEUR INF PROC
   Beer K, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14454-2
   Benedetti M, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab5944
   Bennett CH, 2000, NATURE, V404, P247, DOI 10.1038/35005001
   Blance A, 2021, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2021)212
   BLOCH F, 1946, PHYS REV, V70, P460, DOI 10.1103/PhysRev.70.460
   Cerezo M, 2022, NAT COMPUT SCI, V2, P567, DOI 10.1038/s43588-022-00311-3
   Cerezo M, 2021, NAT REV PHYS, V3, P625, DOI 10.1038/s42254-021-00348-9
   Chalkiadakis I., 2018, "Abrief survey of visualizationmethods for deep learning models from the perspective of explainable AI
   Chandarana P, 2023, PHYS REV APPL, V20, DOI 10.1103/PhysRevApplied.20.014024
   Cheng FR, 2022, IEEE T VIS COMPUT GR, V28, P378, DOI 10.1109/TVCG.2021.3114836
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Chung S., 2016, P FUT INT LEARN MAN
   Daskin A, 2023, Arxiv, DOI arXiv:2301.05549
   Ding YF, 2022, IEEE INTERNET COMPUT, V26, P5, DOI 10.1109/MIC.2021.3133675
   Fong R, 2018, PROC CVPR IEEE, P8730, DOI 10.1109/CVPR.2018.00910
   Galambos M., 2012, Int. J. Adv. Syst. Meas., V5
   Griffin P. R., 2021, "Quantum computing: Computational excellence for society 5.0
   Heese R., 2023, "Explaining quantum circuits with shapley values: Towards explainable quantum machine learning
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Huang HL, 2023, SCI CHINA PHYS MECH, V66, DOI 10.1007/s11433-022-2057-y
   Huang R, 2021, NEUROCOMPUTING, V452, P89, DOI 10.1016/j.neucom.2021.04.074
   Hubregtsen T, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00038-w
   Jia ZA, 2019, ADV QUANTUM TECHNOL, V2, DOI 10.1002/qute.201800077
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kandala A, 2017, NATURE, V549, P242, DOI 10.1038/nature23879
   Karafyllidis IG, 2003, QUANTUM INF PROCESS, V2, P271, DOI 10.1023/B:QINP.0000020076.36114.13
   Keyl M, 2002, PHYS REP, V369, P431, DOI 10.1016/S0370-1573(02)00266-1
   Li W., 2022, A swarm control model based on individual information interaction, P61
   Li WK, 2022, SCI CHINA PHYS MECH, V65, DOI 10.1007/s11433-021-1793-6
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu ZP, 2022, IEEE T VIS COMPUT GR, V28, P2500, DOI 10.1109/TVCG.2022.3148197
   Mäkelä H, 2010, PHYS SCRIPTA, VT140, DOI 10.1088/0031-8949/2010/T140/014054
   Maheshwari D, 2022, IEEE ACCESS, V10, P3705, DOI 10.1109/ACCESS.2021.3139323
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nielsen M.A., 2010, Quantum computation and quantum information, DOI 10.1017/cbo9780511976667
   Oh S, 2020, I C INF COMM TECH CO, P236, DOI 10.1109/ICTC49870.2020.9289439
   Olah C., 2017, Distill, V2, P7, DOI DOI 10.23915/DISTILL.00007
   Park H, 2022, IEEE T VIS COMPUT GR, V28, P813, DOI 10.1109/TVCG.2021.3114858
   Piatrenka I, 2022, LECT NOTES COMPUT SC, P247, DOI 10.1007/978-3-031-08760-8_21
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Rieffel E. G., 2011, Quantum Computing:AGentle Introduction
   Ruan Shaolun, 2023, IEEE Transactions on Visualization and Computer Graphics, V29, P462, DOI 10.1109/TVCG.2022.3209455
   Ruan S., IEEE Trans. Visual. Comput. Graph., DOI [10.1109/TVCG.2023.3332999, DOI 10.1109/TVCG.2023.3332999]
   Ruan SL, 2023, COMPUT GRAPH FORUM, V42, P247, DOI 10.1111/cgf.14827
   Schneider B, 2021, IEEE T BIG DATA, V7, P483, DOI 10.1109/TBDATA.2018.2877350
   Schuld M, 2020, PHYS REV A, V101, DOI 10.1103/PhysRevA.101.032308
   Schuld M, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.040504
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Takaki Y, 2021, PHYS REV A, V103, DOI 10.1103/PhysRevA.103.052414
   Tian JK, 2023, IEEE T PATTERN ANAL, V45, P12321, DOI 10.1109/TPAMI.2023.3272029
   TorchQuantum, About us
   Tyagi Anjul, 2023, IEEE Trans Vis Comput Graph, V29, P299, DOI 10.1109/TVCG.2022.3209361
   Vilone G, 2020, Arxiv, DOI [arXiv:2006.00093, 10.48550/arXiv.2006.00093]
   Wang Q., 2019, P CHI C HUM FACT COM, P12
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1470, DOI 10.1109/TVCG.2020.3030471
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang ZH, 2021, PROC SPIE, V11912, DOI 10.1117/12.2602493
   Wiebe N, 2015, Arxiv, DOI arXiv:1412.3489
   Wilde M M., 2017, Quantum Information Theory, V2nd edn
   Wille R, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P768, DOI 10.23919/DATE51398.2021.9474236
   Williams M. M., 2021, PhD thesis,
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yao Zhang, 2020, Quantum Engineering, V2, DOI 10.1002/que2.34
   Chen SYC, 2020, Arxiv, DOI arXiv:2011.14651
   Zeng HP, 2017, Arxiv, DOI arXiv:1710.05285
   Zhou MG, 2023, RESEARCH-CHINA, V6, DOI 10.34133/research.0134
   Zulehner A., 2019, ICCAD-IEEE ACM INT, P1, DOI DOI 10.1109/iccad45719.2019.8942057
NR 86
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2862
EP 2874
DI 10.1109/TVCG.2024.3388557
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500007
PM 38652613
DA 2024-08-05
ER

PT J
AU Yao, LJ
   Vuillemot, R
   Bezerianos, A
   Isenberg, P
AF Yao, Lijie
   Vuillemot, Romain
   Bezerianos, Anastasia
   Isenberg, Petra
TI Designing for Visualization in Motion: Embedding Visualizations in
   Swimming Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Embedded visualization; sports analytics; design framework;
   visualization in motion
AB We report on challenges and considerations for supporting design processes for visualizations in motion embedded in sports videos. We derive our insights from analyzing swimming race visualizations and motion-related data, building a technology probe, as well as a study with designers. Understanding how to design situated visualizations in motion is important for a variety of contexts. Competitive sports coverage, in particular, increasingly includes information on athlete or team statistics and records. Although moving visual representations attached to athletes or other targets are starting to appear, systematic investigations on how to best support their design process in the context of sports videos are still missing. Our work makes several contributions in identifying opportunities for visualizations to be added to swimming competition coverage but, most importantly, in identifying requirements and challenges for designing situated visualizations in motion. Our investigations include the analysis of a survey with swimming enthusiasts on their motion-related information needs, an ideation workshop to collect designs and elicit design challenges, the design of a technology probe that allows to create embedded visualizations in motion based on real data (Fig. 1), and an evaluation with visualization designers that aimed to understand the benefits of designing directly on videos.
C1 [Yao, Lijie; Isenberg, Petra] Univ Paris Saclay, CNRS, Inria, F-91190 Gif Sur Yvette, France.
   [Bezerianos, Anastasia] Univ Paris Saclay, CNRS, Inria, LISN, F-91190 Gif Sur Yvette, France.
   [Vuillemot, Romain] Univ Lyon, Ecole Cent Lyon, CNRS, UMR5205,LIRIS, F-69134 Lyon, France.
C3 Universite Paris Cite; Universite Paris Saclay; Centre National de la
   Recherche Scientifique (CNRS); Inria; Centre National de la Recherche
   Scientifique (CNRS); Inria; Universite Paris Cite; Universite Paris
   Saclay; Centre National de la Recherche Scientifique (CNRS); Institut
   National des Sciences Appliquees de Lyon - INSA Lyon; Ecole Centrale de
   Lyon
RP Yao, LJ (corresponding author), Univ Paris Saclay, CNRS, Inria, F-91190 Gif Sur Yvette, France.
EM yaolijie0219@gmail.com; romain.vuillemot@ec-lyon.fr;
   anastasiab@gmail.com; petra.isenberg@inria.fr
OI Yao, Lijie/0000-0002-4208-5140; Isenberg, Petra/0000-0002-2948-6417;
   Vuillemot, Romain/0000-0003-1447-6926
FU Agence Nationale de la Recherche
FX No Statement Available
CR Bai L., 2016, PROC C PERVASIVE COM, P1
   Bressa N, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P173, DOI 10.1145/3322276.3322326
   Bucchieri F., 2022, Master's thesis
   Buxton Bill., 2011, Sketching User Experiences: Getting the Design Right and the Right Design
   Chen SW, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P217, DOI 10.1109/ISMAR-Adjunct51615.2020.00064
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chen Zhutian, 2023, IEEE Trans Vis Comput Graph, V29, P918, DOI 10.1109/TVCG.2022.3209497
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Dix Alan, 2003, HUM FAC ER
   FFN, French national swimming federation
   FootoVision, About us
   Holtz Y., From data to vis
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hutchinson H., 2003, P SIGCHI C HUM FACT, P17, DOI 10.1145/642611.642616
   labellmg, Welcome to labellmg
   Lin T., 2020, PROC IMMERSIVE ANALY
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Lin Tica, 2021, P 2021 CHI C HUMAN F, DOI [DOI 10.1145/3411764.3445649, 10.1145/3411764.3445649]
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Oagaz H, 2022, IEEE T VIS COMPUT GR, V28, P4332, DOI 10.1109/TVCG.2021.3086403
   Olympics Aquatics, Welcome to the women's 200 m butterfly final at the Olympics Tokyo 2020
   Park H, 2018, LECT NOTES COMPUT SC, V10918, P725, DOI 10.1007/978-3-319-91797-9_50
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C., 2013, PROC SPORTS DATA VIS
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ribecca S., The Data Visualisation Catalogue
   Roberts JC, 2016, IEEE T VIS COMPUT GR, V22, P419, DOI 10.1109/TVCG.2015.2467271
   Rogers Y., 2023, Interaction design: Beyond human-computer interaction
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   sondages, LimeSurvey
   Sports Dynamics, About us
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Suzuki Ryo, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P166, DOI 10.1145/3379337.3415892
   SwimFlow, The example design made and shared by swimflow
   Tang T, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3484506
   Tang T, 2020, J VISUAL-JAPAN, V23, P707, DOI 10.1007/s12650-020-00644-z
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wu E, 2021, IEEE T VIS COMPUT GR, V27, P2566, DOI 10.1109/TVCG.2021.3067761
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Yao A., 2022, JOURNEE VISU 2022
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   youtube, Tokyo 2020 men's 100 m butterfly final
   youtube, SportBuzzBusiness
   youtube, Tokyo 2020 women's 100 m freestyle final
   youtube, Tokyo 2020 mixed-gender 4100 m medley final
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
NR 56
TC 0
Z9 0
U1 7
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1821
EP 1836
DI 10.1109/TVCG.2023.3341990
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500005
PM 38090861
OA Green Published
DA 2024-08-05
ER

PT J
AU Khan, D
   Bohak, C
   Viola, I
AF Khan, Dawar
   Bohak, Ciril
   Viola, Ivan
TI Dr. KID: Direct Remeshing and K-Set Isometric Decomposition for Scalable
   Physicalization of Organic Shapes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Physicalization; Physical visualization; 3D printing; Isometric
   decomposition; Direct remeshing; Biological structures; Intracellular
   compartments
AB Dr. KID is an algorithm that uses isometric decomposition for the physicalization of potato-shaped organic models in a puzzle fashion. The algorithm begins with creating a simple, regular triangular surface mesh of organic shapes, followed by iterative K-means clustering and remeshing. For clustering, we need similarity between triangles (segments) which is defined as a distance function. The distance function maps each triangle's shape to a single point in the virtual 3D space. Thus, the distance between the triangles indicates their degree of dissimilarity. K-means clustering uses this distance and sorts segments into k classes. After this, remeshing is applied to minimize the distance between triangles within the same cluster by making their shapes identical. Clustering and remeshing are repeated until the distance between triangles in the same cluster reaches an acceptable threshold. We adopt a curvature-aware strategy to determine the surface thickness and finalize puzzle pieces for 3D printing. Identical hinges and holes are created for assembling the puzzle components. For smoother outcomes, we use triangle subdivision along with curvature-aware clustering, generating curved triangular patches for 3D printing. Our algorithm was evaluated using various models, and the 3D-printed results were analyzed. Findings indicate that our algorithm performs reliably on target organic shapes with minimal loss of input geometry.
C1 [Khan, Dawar; Bohak, Ciril; Viola, Ivan] King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal, Saudi Arabia.
C3 King Abdullah University of Science & Technology
RP Khan, D (corresponding author), King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal, Saudi Arabia.
EM dawar.khan@kaust.edu.sa; ciril.bohak@kaust.edu.sa;
   ivan.viola@kaust.edu.sa
RI Viola, Ivan/O-8944-2014
OI Viola, Ivan/0000-0003-4248-6574; Khan, Dawar/0000-0001-5864-1888
FU King Abdullah University of Science and Technology (KAUST)
FX No Statement Available
CR Alliez P, 2008, MATH VIS, P53, DOI 10.1007/978-3-540-33265-7_2
   Bader C, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aas8652
   Bailey MJ, 1998, CURR OPIN STRUC BIOL, V8, P202, DOI 10.1016/S0959-440X(98)80039-0
   Barton M, 2010, COMPUT AIDED GEOM D, V27, P580, DOI 10.1016/j.cagd.2010.04.004
   Casas L, 2015, J CHEM EDUC, V92, P1338, DOI 10.1021/acs.jchemed.5b00147
   Chen DS, 2013, COMPUT GRAPH FORUM, V32, P305, DOI 10.1111/cgf.12050
   Chen XL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818087
   Coffin S., 2006, Geometric puzzle design, P3
   de Freitas AA, 2022, IEEE INT CONF INF VI, P73, DOI 10.1109/IV56949.2022.00021
   Djavaherpour H, 2021, COMPUT GRAPH FORUM, V40, P569, DOI 10.1111/cgf.14330
   Dragicevic Y., 2020, of Human Computer Interaction, P1, DOI DOI 10.1007/978-3-319-27648-9_94-1
   Echavarria KR, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3351343
   Eigensatz M., 2010, P ADV ARCH GEOM C, P3
   Elber G, 2022, COMPUT GRAPH-UK, V102, P339, DOI 10.1016/j.cag.2021.10.014
   Eslambolchilar Parisa, 2023, International Journal of Child-Computer Interaction, DOI 10.1016/j.ijcci.2023.100565
   Fu CW, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778781
   Gavriil K, 2019, COMPUT AIDED DESIGN, V111, P29, DOI 10.1016/j.cad.2019.01.006
   Hidayat W, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS 2019), DOI 10.1109/icicos48119.2019.8982471
   Huard M., 2015, Advances in Architectural Geometry 2014, P2
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jansen Yvonne., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P2593, DOI [DOI 10.1145/2470654, 10.1145/2470654]
   Jiang CG, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459839
   Khan D, 2022, IEEE T VIS COMPUT GR, V28, P1680, DOI 10.1109/TVCG.2020.3016645
   Lin ML, 2023, ACT ADAPT AGING, V47, P348, DOI 10.1080/01924788.2022.2120761
   Liu Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559758
   Liu ZY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459843
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lo KY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618503
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Luo LJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366148
   Mekuc MÄ, 2022, COMPUT METH PROG BIO, V223, DOI 10.1016/j.cmpb.2022.106959
   Mekuc MZ, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103693
   Moere AV, 2008, IEEE INT CONF INF VI, P469, DOI 10.1109/IV.2008.84
   Nguyen N, 2023, IEEE T VIS COMPUT GR, V29, P4198, DOI 10.1109/TVCG.2022.3186146
   Nguyen N, 2021, IEEE T VIS COMPUT GR, V27, P722, DOI 10.1109/TVCG.2020.3030415
   Nicolaidou I, 2021, PROC EUR CONF GAME, P553, DOI 10.34190/GBL.21.016
   Sequin C. H., 2012, FABR SCULPT TRACK SH, P3
   Singh M., 2010, P ACM SIGGRAPH, DOI [10.1145/1833349.17787832,7, DOI 10.1145/1833349.17787832,7]
   Song P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925876
   Song P, 2015, COMPUT AIDED GEOM D, V35-36, P137, DOI 10.1016/j.cagd.2015.03.020
   Song P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366147
   Sun T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766961
   Tang KK, 2019, COMPUT GRAPH FORUM, V38, P291, DOI 10.1111/cgf.13638
   Tosello G, 2019, INT J ADV MANUF TECH, V100, P783, DOI 10.1007/s00170-018-2762-7
   Verdine BN, 2014, TRENDS NEUROSCI EDUC, V3, P7, DOI 10.1016/j.tine.2014.02.005
   Viana MP, 2023, NATURE, V613, P345, DOI 10.1038/s41586-022-05563-7
   Vidal V, 2015, COMPUT GRAPH-UK, V47, P16, DOI 10.1016/j.cag.2014.10.004
   Xin SQ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964992
   Yao MJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818064
   Zhao Jack, 2008, P 3 INT C DIGITAL IN, P343, DOI DOI 10.1145/1413634.1413696
   Zimmer H, 2014, IEEE T VIS COMPUT GR, V20, P1461, DOI 10.1109/TVCG.2014.2307885
   Zimmer H, 2014, GRAPH MODELS, V76, P390, DOI 10.1016/j.gmod.2014.03.009
NR 53
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 705
EP 715
DI 10.1109/TVCG.2023.3326595
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500115
PM 37871062
OA Green Submitted, hybrid, Green Published
DA 2024-08-05
ER

PT J
AU Miftari, E
   Durstewitz, D
   Sadlo, F
AF Miftari, Egzon
   Durstewitz, Daniel
   Sadlo, Filip
TI Visualization of Discontinuous Vector Field Topology
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topology; Manifolds; Eigenvalues and eigenfunctions; Dynamical systems;
   Switches; Orbits; Behavioral sciences; Discontinuous vector field
   topology; equivalence in non-unique flow; non-smooth dynamical systems
ID ATTRACTORS; SEMIFLOWS
AB This paper extends the concept and the visualization of vector field topology to vector fields with discontinuities. We address the non-uniqueness of flow in such fields by introduction of a time-reversible concept of equivalence. This concept generalizes streamlines to streamsets and thus vector field topology to discontinuous vector fields in terms of invariant streamsets. We identify respective novel critical structures as well as their manifolds, investigate their interplay with traditional vector field topology, and detail the application and interpretation of our approach using specifically designed synthetic cases and a simulated case from physics.
C1 [Miftari, Egzon; Durstewitz, Daniel; Sadlo, Filip] Heidelberg Univ, Heidelberg, Germany.
C3 Ruprecht Karls University Heidelberg
RP Miftari, E (corresponding author), Heidelberg Univ, Heidelberg, Germany.
EM egzon.miftari@iwr.uni-heidelberg.de; daniel.durstewitz@zi-mannheim.de;
   sadlo@uni-heidelberg.de
FU Deutsche Forschungsgemeinschaft (DFG)
FX No Statement Available
CR Andronov A. A., 1937, Dokl. Acad. Nauk SSSR, V14, P247
   Asimov D., 1993, Technical report, P2
   Ball JM, 1997, J NONLINEAR SCI, V7, P475, DOI 10.1007/s003329900037
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Fernández-García S, 2012, SIAM J APPL DYN SYST, V11, P1215, DOI 10.1137/120869134
   Glendinning P., 2019, Advanced Courses in Mathematics-CRM Barcelona, V2, P3
   HELMAN J, 1989, COMPUTER, V22, P27, DOI 10.1109/2.35197
   HELMAN JL, 1991, IEEE COMPUT GRAPH, V11, P36, DOI 10.1109/38.79452
   Hofmann L, 2021, COMPUT GRAPH FORUM, V40, P111, DOI 10.1111/cgf.14293
   Hofmann L, 2020, COMPUT GRAPH FORUM, V39, P303, DOI 10.1111/cgf.13982
   Hofmann L, 2018, COMPUT GRAPH FORUM, V37, P301, DOI 10.1111/cgf.13421
   HU SC, 1991, J MATH ANAL APPL, V154, P377, DOI 10.1016/0022-247X(91)90044-Z
   Jeffrey M. R., 2015, P ICOEV LJUBLJ, P10
   Jeffrey M. R., 2018, Hidden Dynamics: The Mathematics of Switches, Decisions and Other Discontinuous Behaviour, V2, P3
   Jeffrey MR, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500875
   Jeffrey MR, 2014, PHYSICA D, V273, P34, DOI 10.1016/j.physd.2014.02.003
   Leine R., 2000, Bifurcations in discontinuous mechanical systems of Filippovtype, P8
   Melnik VS, 1998, SET-VALUED ANAL, V6, P83, DOI 10.1023/A:1008608431399
   Otto M, 2010, COMPUT GRAPH FORUM, V29, P347, DOI 10.1111/j.1467-8659.2009.01604.x
   Scheuermann G, 1997, VISUALIZATION '97 - PROCEEDINGS, P67, DOI 10.1109/VISUAL.1997.663858
   Theisel H, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P225, DOI 10.1109/VISUAL.2003.1250376
   Thieme C, 2019, Arxiv, DOI arXiv:1905.07051
   Weinkauf T., 2004, P EUROGRAPHICS IEEE, P183
NR 23
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 45
EP 54
DI 10.1109/TVCG.2023.3326519
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500075
PM 37878439
DA 2024-08-05
ER

PT J
AU Lin, ZH
   Hu, CX
   Jia, JZ
   Li, S
AF Lin, Zehui
   Hu, Chenxiao
   Jia, Jinzhu
   Li, Sheng
TI Hypothesis Testing for Progressive Kernel Estimation and VCM Framework
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Photonics; Kernel; Estimation; Testing; Analysis of variance; Lighting;
   Merging; bidirectional path sampling; f-test; hypothesis testing; kernel
   estimation; progressive photon mapping; radius; statistical model;
   vertex connection and merging
ID STILL
AB Identifying an appropriate radius for unbiased kernel estimation is crucial for the efficiency of radiance estimation. However, determining both the radius and unbiasedness still faces big challenges. In this paper, we first propose a statistical model of photon samples and associated contributions for progressive kernel estimation, under which the kernel estimation is unbiased if the null hypothesis of this statistical model stands. Then, we present a method to decide whether to reject the null hypothesis about the statistical population (i.e., photon samples) by the F-test in the Analysis of Variance. Hereby, we implement a progressive photon mapping (PPM) algorithm, wherein the kernel radius is determined by this hypothesis test for unbiased radiance estimation. Second, we propose VCM+, a reinforcement of Vertex Connection and Merging (VCM), and derive its theoretically unbiased formulation. VCM+ combines hypothesis testing-based PPM with bidirectional path tracing (BDPT) via multiple importance sampling (MIS), wherein our kernel radius can leverage the contributions from PPM and BDPT. We test our new algorithms, improved PPM and VCM+, on diverse scenarios with different lighting settings. The experimental results demonstrate that our method can alleviate light leaks and visual blur artifacts of prior radiance estimate algorithms. We also evaluate the asymptotic performance of our approach and observe an overall improvement over the baseline in all testing scenarios.
C1 [Lin, Zehui; Hu, Chenxiao; Li, Sheng] Peking Univ, Sch Comp Sci, Beijing 100871, Peoples R China.
   [Li, Sheng] Peking Univ, Natl Biomed Imaging Ctr, Beijing 100871, Peoples R China.
   [Jia, Jinzhu] Peking Univ, Dept Biostat, Beijing, Peoples R China.
   [Jia, Jinzhu] Peking Univ, Ctr Stat Sci, Beijing, Peoples R China.
C3 Peking University; Peking University; Peking University; Peking
   University
RP Li, S (corresponding author), Peking Univ, Sch Comp Sci, Beijing 100871, Peoples R China.
EM zehui@pku.edu.cn; hinevenwob@qq.com; jzjia@math.pku.edu.cn;
   lisheng@pku.edu.cn
OI Hu, Chenxiao/0009-0000-3306-6653; Li, Sheng/0000-0002-8901-2184; Jia,
   Jinzhu/0000-0002-6554-2463
FU National Key Research and Development Program of China [2022ZD0160805];
   NSFC of China [62172013]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2022ZD0160805, and in par tby
   NSFC of China under Grant 62172013.
CR Bathke A, 2004, J STAT PLAN INFER, V126, P413, DOI 10.1016/j.jspi.2003.09.010
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Calder K., 1953, Statistical inference
   COCHRAN WG, 1952, ANN MATH STAT, V23, P315, DOI 10.1214/aoms/1177729380
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Everitt Brian, 1998, The Cambridge Dictionary of Statistics
   FEIRWALS.BJ, 1974, EDUC PSYCHOL MEAS, V34, P789, DOI 10.1177/001316447403400406
   Fisher RA, 1921, Metron, V1, P3
   Georgiev I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366211
   Grittmann P, 2021, COMPUT GRAPH FORUM, V40, P231, DOI 10.1111/cgf.142628
   Hachisuka T., 2012, P SIGGRAPH AS COURS
   Hachisuka T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366210
   Hachisuka T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019633
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409083
   Hachisuka T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866170
   Hachisuka T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618487
   Jakob Wenzel, 2010, Mitsuba renderer
   Jan SL, 2014, BRIT J MATH STAT PSY, V67, P72, DOI 10.1111/bmsp.12006
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kaplanyan AS, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451242
   Knaus C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966404
   Kondapaneni I, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323009
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lafortune E. P., 1993, EDUGRAPHICS '93. First International Conference on Graphics Education. COMPUGRAPHICS '93. Third International Conference on Computational Graphics and Visualization Techniques. Combined Proceedings, P145
   Lin ZH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417822
   Miller R.G., 1997, ANOVA Beyond Basics of Applied Statistics, DOI DOI 10.1201/B15236
   Moore D.S., 2016, Introduction to the Practice of Statistics., V9th
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417804
   Müller T, 2017, COMPUT GRAPH FORUM, V36, P91, DOI 10.1111/cgf.13227
   Qin H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818119
   Rigau J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P260
   Sik M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982411
   Su FJ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530183
   Veach E., 1995, Photorealistic Rendering Techniques, P145
   Veach E., 1997, Robust Monte Carlo Methods for Light Transport Simulation, V1610
   Vorba J., 2011, P CENTR EUR SEM COMP, P25
   Vorba J, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2601097.2601203, 10.1145/2801097.2801203]
   Zhu SL, 2020, COMPUT GRAPH FORUM, V39, P35, DOI 10.1111/cgf.14052
NR 40
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4709
EP 4723
DI 10.1109/TVCG.2023.3274595
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400010
PM 37159325
DA 2024-08-05
ER

PT J
AU Nguyen, W
   Gramann, K
   Gehrke, L
AF Nguyen, Willy
   Gramann, Klaus
   Gehrke, Lukas
TI Modeling the Intent to Interact With VR Using Physiological Features
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Electromyography; Electroencephalography; Muscles; Electrodes; Task
   analysis; Physiology; Brain modeling; Brain-computer interfaces;
   electroencephalography; virtual reality
AB Objective: Mixed-Reality (XR) technologies promise a user experience (UX) that rivals the interactive experience with the real-world. The key facilitators in the design of such a natural UX are that the interaction has zero lag and that users experience no excess mental load. This is difficult to achieve due to technical constraints such as motion-to-photon latency as well as false-positives during gesture-based interaction. Methods: In this paper, we explored the use of physiological features to model the user's intent to interact with a virtual reality (VR) environment. Accurate predictions about when users want to express an interaction intent could overcome the limitations of an interactive device that lags behind the intention of a user. We computed time-domain features from electroencephalography (EEG) and electromyography (EMG) recordings during a grab-and-drop task in VR and cross-validated a Linear Discriminant Analysis (LDA) for three different combinations of (1) EEG, (2) EMG and (3) EEG-EMG features. Results & Conclusion: We found the classifiers to detect the presence of a pre-movement state from background idle activity reflecting the users' intent to interact with the virtual objects (EEG: 62% +/- 10%, EMG: 72% +/- 9%, EEG-EMG: 69% +/- 10%) above simulated chance level. The features leveraged in our classification scheme have a low computational cost and are especially useful for fast decoding of users' mental states. Our work is a further step towards a useful classification of users' intent to interact, as a high temporal resolution and speed of detection is crucial. This facilitates natural experiences through zero-lag adaptive interfaces.
C1 [Nguyen, Willy] Univ Paris Saclay, F-91190 Gif Sur Yvette, France.
   [Gramann, Klaus; Gehrke, Lukas] TU Berlin, D-10623 Berlin, Germany.
C3 Universite Paris Cite; Universite Paris Saclay; Technical University of
   Berlin
RP Nguyen, W (corresponding author), Univ Paris Saclay, F-91190 Gif Sur Yvette, France.
EM willy.nguyen@hotmail.fr; klaus.gramann@tu-berlin.de;
   lukas.gehrke@tu-berlin.de
OI NGUYEN, WILLY/0000-0002-2904-8011; Gramann, Klaus/0000-0003-2673-1832;
   Gehrke, Lukas/0000-0003-3661-1973
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [GR2627/13-1]
FX The work of Lukas Gehrke was supported by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) under Grant
   GR2627/13-1.
CR Bawa A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155799
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Chandra S, 2021, IEEE T BIO-MED ENG, V68, P1389, DOI 10.1109/TBME.2020.3032354
   Chatrian G. E., 1985, American Journal of EEG Technology, V25, P83
   David-John B., 2021, P ACM S EYE TRACK RE, P1
   DEECKE L, 1969, EXP BRAIN RES, V7, P158
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Fischer G, 2001, USER MODEL USER-ADAP, V11, P65, DOI 10.1023/A:1011145532042
   Gehrke L., 2022, Affordances in Everyday Life: A Multidisciplinary Collection of Essays, P173
   Gehrke Lukas, 2022, Figshare, DOI 10.6084/m9.figshare.19345016.v1
   Gehrke L, 2022, J NEURAL ENG, V19, DOI 10.1088/1741-2552/ac69bc
   Gehrke L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300657
   Hermens HJ, 2000, J ELECTROMYOGR KINES, V10, P361, DOI 10.1016/S1050-6411(00)00027-4
   Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159, DOI [DOI 10.1145/302979.303030, 10.1145/302979.303030]
   HUDGINS B, 1993, IEEE T BIO-MED ENG, V40, P82, DOI 10.1109/10.204774
   Jonker T. R., 2020, P CHI AI4HCI WORKSH
   Kasahara S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300873
   Khairuddin IM, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.379
   Kim AKH, 2021, STAT-US, V10, DOI 10.1002/sta4.384
   Kinugasa R, 2023, IEEE ACCESS, V11, P6394, DOI 10.1109/ACCESS.2023.3237557
   Kirchner EA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085060
   Klug M., 2022, bioRxiv
   Kohrs C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146250
   Kosaki T, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P793, DOI 10.1109/ICMA.2017.8015917
   Krol LR, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab5bb5
   Lew Eileen, 2012, Front Neuroeng, V5, P13, DOI 10.3389/fneng.2012.00013
   LIBET B, 1983, ELECTROEN CLIN NEURO, V56, P367, DOI 10.1016/0013-4694(83)90262-6
   Muller-Putz G. R., 2007, P 1 COST NEUR WORKGR
   Niijima A, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545666
   Novak D, 2013, IEEE T BIO-MED ENG, V60, P2645, DOI 10.1109/TBME.2013.2262455
   Pangratz E, 2023, 2023 PROCEEDINGS OF THE 15TH CONFERENCE ON CREATIVITY AND COGNITION, C&C 2023, P129, DOI 10.1145/3591196.3593340
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Saha S, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.578875
   Schultze-Kraft M, 2021, ENEURO, V8, DOI 10.1523/ENEURO.0425-20.2020
   Schultze-Kraft M, 2020, P ROY SOC B-BIOL SCI, V287, DOI 10.1098/rspb.2019.2928
   Schurger A, 2021, TRENDS COGN SCI, V25, P558, DOI 10.1016/j.tics.2021.04.001
   Shibasaki H, 2006, CLIN NEUROPHYSIOL, V117, P2341, DOI 10.1016/j.clinph.2006.04.025
   Suhail TA, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103742
   Trigili E, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0512-1
   Tsukamoto M, 2007, J ROBOT MECHATRON, V19, P381, DOI 10.20965/jrm.2007.p0381
   Winter D. A, 2009, Biomechanics and Motor Control of Human Movement, V2
   Yu DF, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545632
   Zander TO, 2016, P NATL ACAD SCI USA, V113, P14898, DOI 10.1073/pnas.1605155114
   Zhang YX, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555461
NR 44
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5893
EP 5900
DI 10.1109/TVCG.2023.3308787
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400055
PM 37624723
DA 2024-08-05
ER

PT J
AU Zhou, XC
   Li, BS
   Benes, B
   Fei, SL
   Pirk, S
AF Zhou, Xiaochen
   Li, Bosheng
   Benes, Bedrich
   Fei, Songlin
   Pirk, Soren
TI DeepTree: Modeling Trees With Situated Latents
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Solid modeling; Three-dimensional displays; Shape;
   Computational modeling; Neural networks; Pipelines; Botanical tree
   models; deep learning; generative methods; shape modeling
ID VIRTUAL CLIMBING PLANTS
AB In this article, we propose DeepTree, a novel method for modeling trees based on learning developmental rules for branching structures instead of manually defining them. We call our deep neural model "situated latent" because its behavior is determined by the intrinsic state -encoded as a latent space of a deep neural model- and by the extrinsic (environmental) data that is "situated" as the location in the 3D space and on the tree structure. We use a neural network pipeline to train a situated latent space that allows us to locally predict branch growth only based on a single node in the branch graph of a tree model. We use this representation to progressively develop new branch nodes, thereby mimicking the growth process of trees. Starting from a root node, a tree is generated by iteratively querying the neural network on the newly added nodes resulting in the branching structure of the whole tree. Our method enables generating a wide variety of tree shapes without the need to define intricate parameters that control their growth and behavior. Furthermore, we show that the situated latents can also be used to encode the environmental response of tree models, e.g., when trees grow next to obstacles. We validate the effectiveness of our method by measuring the similarity of our tree models and by procedurally generated ones based on a number of established metrics for tree form.
C1 [Zhou, Xiaochen; Li, Bosheng; Benes, Bedrich] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
   [Fei, Songlin] Purdue Univ, Dept Forestry & Nat Resources, W Lafayette, IN 47907 USA.
   [Pirk, Soren] Univ Kiel, Dept Comp Sci, D-24143 Kiel, Germany.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University; University of Kiel
RP Benes, B (corresponding author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
EM zhou1178@purdue.edu; li2343@purdue.edu; bbenes@purdue.edu;
   sfei@purdue.edu; soeren.pirk@gmail.com
RI Benes, Bedrich/A-8150-2016; Fei, Songlin/JTD-3325-2023
OI Benes, Bedrich/0000-0002-5293-2112; Fei, Songlin/0000-0003-2772-0166;
   LI, BOSHENG/0009-0006-6490-1184; Pirk, Soren/0000-0003-1937-9797; Zhou,
   Xiaochen/0000-0003-2280-7799
FU Foundation for Food and Agriculture Research, United States [602757];
   USDA NIFA [2023-68012-38992]
FX This research was partially supported in part by the Foundation for Food
   and Agriculture Research, United States Grant under Grant 602757 to
   Benes, and in part by USDA NIFA, under Grant #2023-68012-38992 to
   Benesand Fei.
CR AONO M, 1984, IEEE COMPUT GRAPH, V4, P10, DOI 10.1109/MCG.1984.276141
   Argudo O, 2020, COMPUT GRAPH FORUM, V39, P174, DOI 10.1111/cgf.13752
   Benes B, 2002, COMP ANIM CONF PROC, P33, DOI 10.1109/CA.2002.1017504
   Bradley D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461952
   Chen B., 2008, ACM Trans. Graph., V27, P38
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deussen O., 2005, Digital Design of Nature: Computer Generated Plants and Organics
   Du SL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182074
   Estrada R, 2015, IEEE T PATTERN ANAL, V37, P1688, DOI 10.1109/TPAMI.2014.2382116
   Greene N., 1989, Computer Graphics, V23, P175, DOI 10.1145/74334.74351
   Guo JW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3394105
   Habel R, 2009, COMPUT GRAPH FORUM, V28, P523, DOI 10.1111/j.1467-8659.2009.01391.x
   Hack J.T., 1957, Studies of longitudinal stream profiles in Virginia and Mary-land, V294, DOI DOI 10.3133/PP294B
   Hädrich T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459954
   Hädrich T, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13106
   Ijiri T, 2006, COMPUT GRAPH FORUM, V25, P617, DOI 10.1111/j.1467-8659.2006.00981.x
   Kohek S, 2015, COMPUTING, V97, P145, DOI 10.1007/s00607-014-0424-7
   Li BS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480525
   Li C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024161
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Liu YC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480486
   Livny Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964948
   Longay A., 2012, P INT S SBIM, P107, DOI DOI 10.2312/SBM/SBM12/107-120
   Makowski M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323039
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Neubert B, 2011, COMPUT GRAPH FORUM, V30, P1708, DOI 10.1111/j.1467-8659.2011.01897.x
   Neubert B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239539
   Niese T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3502220
   Okabe S., 2007, P ACM SIGGRAPH COURS
   Oppenheimer P. E., 1986, Computer Graphics, V20, P55, DOI 10.1145/15886.15892
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Palubicki W, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530146
   Parker SG, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778803
   Pirk S., 2016, P ACM SIGGRAPH COURS
   Pirk S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661252
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185546
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814
   Polasek T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480519
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   Reeves W. T., 1985, Computer Graphics, V19, P313, DOI 10.1145/325165.325250
   Shao H., 2021, P ADV NEUR INF PROC, V34, P4829
   Stava O, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12282
   Talton JO, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944851
   Tan P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409061
   Tan P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239538
   Wang Y. Zhao, 2017, ACM Trans. Graph., V36, p135:1
   Weber J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P119, DOI 10.1145/218380.218427
   Wither J, 2009, COMPUT GRAPH FORUM, V28, P541, DOI 10.1111/j.1467-8659.2009.01394.x
   Wong SK, 2016, COMPUT GRAPH FORUM, V35, P5, DOI 10.1111/cgf.12736
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu H, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289610
   Xu JR, 2021, AI OPEN, V2, P69, DOI 10.1016/j.aiopen.2021.05.002
   Xu L, 2015, COMPUT GRAPH FORUM, V34, P47, DOI 10.1111/cgf.12744
   Zhang XP, 2017, COMPUT GRAPH FORUM, V36, P402, DOI 10.1111/cgf.13088
   Zhao YL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461961
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
NR 57
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5795
EP 5809
DI 10.1109/TVCG.2023.3307887
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400053
PM 37610910
OA Green Submitted
DA 2024-08-05
ER

PT J
AU McGuffin, MJ
   Servera, R
   Forest, M
AF McGuffin, Michael J.
   Servera, Ryan
   Forest, Marie
TI Path Tracing in 2D, 3D, and Physicalized Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Layout; Task analysis; Headphones; Data
   visualization; Mice; Visualization; 3D printing; augmented reality; data
   physicalization; graph visualization; path finding; path following;
   tangible
ID VISUALIZATION; EXPLORATION; INTERFACES; DISPLAYS; STEREO
AB It is common to advise against using 3D to visualize abstract data such as networks, however Ware and Mitchell's 2008 study showed that path tracing in a network is less error prone in 3D than in 2D. It is unclear, however, if 3D retains its advantage when the 2D presentation of a network is improved using edge-routing, and when simple interaction techniques for exploring the network are available. We address this with two studies of path tracing under new conditions. The first study was preregistered, involved 34 users, and compared 2D and 3D layouts that the user could rotate and move in virtual reality with a handheld controller. Error rates were lower in 3D than in 2D, despite the use of edge-routing in 2D and the use of mouse-driven interactive highlighting of edges. The second study involved 12 users and investigated data physicalization, comparing 3D layouts in virtual reality versus physical 3D printouts of networks augmented with a Microsoft HoloLens headset. No difference was found in error rate, but users performed a variety of actions with their fingers in the physical condition which can inform new interaction techniques.
C1 [McGuffin, Michael J.; Servera, Ryan; Forest, Marie] Ecole Technol Super, Montreal, PQ H3C 1K3, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada
RP McGuffin, MJ (corresponding author), Ecole Technol Super, Montreal, PQ H3C 1K3, Canada.
EM michael.mcguffin@etsmtl.ca; servera.ryan@gmail.com;
   marie.forest@etsmtl.ca
OI McGuffin, Michael/0000-0001-7782-5754
FU Microsoft Research; NSERC
FX This work was supported by Microsoft Research and NSERC.
CR Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2325, DOI 10.1109/TVCG.2011.234
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Belcher D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P84, DOI 10.1109/ISMAR.2003.1240691
   Berard F, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4396, DOI 10.1145/3025453.3025806
   Brath R, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P25, DOI 10.1109/3DVis.2014.7160096
   Burch M, 2021, IEEE ACCESS, V9, P4173, DOI 10.1109/ACCESS.2020.3047616
   Cattan E., 2015, P INT C INT TABL SUR, P215
   Collins C, 2007, IEEE T VIS COMPUT GR, V13, P1192, DOI 10.1109/TVCG.2007.70521
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE PAC VIS SYMP, P46, DOI 10.1109/PACIFICVIS.2017.8031578
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Crundall D, 2008, PERCEPT PSYCHOPHYS, V70, P422, DOI 10.3758/PP.70.3.422
   Danyluk K, 2022, IEEE T VIS COMPUT GR, V28, P1930, DOI 10.1109/TVCG.2020.3023336
   dataphys, 2021, Data physicalization wiki
   Dhand NK., 2014, Sample Size Calculator for Comparing Two Paired Proportions
   Di Battista G., 1999, GRAPH DRAWING ALGORI
   docs.microsoft, About us
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Drogemuller A., 2021, P CHI C HUM FACT COM, P1
   Drogemuller A, 2020, J COMPUT LANG, V56, DOI 10.1016/j.cola.2019.100937
   Dwyer T, 2010, LECT NOTES COMPUT SC, V5849, P147, DOI 10.1007/978-3-642-11805-0_15
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Gillet A, 2005, STRUCTURE, V13, P483, DOI 10.1016/j.str.2005.01.009
   github, About Us
   Greffard N, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P19, DOI 10.1109/3DVis.2014.7160095
   Greffard N, 2012, LECT NOTES COMPUT SC, V7034, P215
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Guillon M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2777, DOI 10.1145/2702123.2702375
   Hayatpur D., 2020, P 33 ANN ACM S US IN, P818, DOI DOI 10.1145/3379337.3415878
   Irani P., 2003, ACM Transactions on Computer-Human Interaction, V10, P1, DOI 10.1145/606658.606659
   James R., 2020, P GRAPH INT, P1
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jansen Yvonne., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P2593, DOI [DOI 10.1145/2470654, 10.1145/2470654]
   Kamakura N., 2022, Postures and Movement Patterns of the Human Hand: A Framework for Understanding Hand Activity for Clinicians and Engi- neers
   Kaufmann M., 2001, DRAWING GRAPHS METHO
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   McGuffin M. J., 2022, Preregistration
   McIntire JP, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P1, DOI 10.1109/3DVis.2014.7160093
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   Munzner T., 2014, Visualization Analysis and Design, P117
   Munzner T, 2008, LECT NOTES COMPUT SC, V4950, P134, DOI 10.1007/978-3-540-70956-5_6
   Ramcharitar Adrian., 2018, Proceedings of the 44th Graphics Interface Conference, P123
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Schmidt S., 2010, Proc. ACM Conference on Interactive Tabletops and Surfaces (ITS), P113
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Shneiderman B, 2003, IEEE COMPUT GRAPH, V23, P12, DOI 10.1109/MCG.2003.1242376
   Smiley Jim, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488546
   SOLLENBERGER RL, 1993, HUM FACTORS, V35, P483, DOI 10.1177/001872089303500306
   Taher F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3237, DOI 10.1145/2702123.2702604
   Taher F, 2017, IEEE T VIS COMPUT GR, V23, P451, DOI 10.1109/TVCG.2016.2598498
   Thompson J, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206519
   van Beurden Maurice H. P. H., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P176, DOI 10.1109/QOMEX.2010.5516268
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Walny J, 2018, IEEE T VIS COMPUT GR, V24, P770, DOI 10.1109/TVCG.2017.2745958
   Ware C., 2001, Information Design Journal, V10, P258, DOI 10.1075/idj.10.3.07war
   Ware C, 1996, ACM T GRAPHIC, V15, P121, DOI 10.1145/234972.234975
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wong P. C., 1997, Scientific Visualization: Overviews, Methodologies, and Techniques
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Zou BC, 2022, VISION RES, V198, DOI 10.1016/j.visres.2022.108061
NR 70
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3564
EP 3577
DI 10.1109/TVCG.2023.3238989
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700027
PM 37021998
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ye, YL
   Huang, R
   Zeng, W
AF Ye, Yilin
   Huang, Rong
   Zeng, Wei
TI VISAtlas: An Image-Based Exploration and Query System for Large
   Visualization Collections via Neural Image Embedding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Feature extraction; Task analysis;
   Layout; Taxonomy; Semantics; Visualization collection; image embedding;
   visual query; image visualization; design pattern
ID INFORMATION VISUALIZATION; VISUAL ANALYSIS; KNOWLEDGE; DESIGN; SPACE
AB High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property (i.e., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents VISAtlas, an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of visualizations. Next, we design a coordinated multiple view (CMV) system that enables multi-perspective exploration and design retrieval based on visualization embeddings. Specifically, we design a novel embedding overview that leverages contextual layout framework to preserve the context of the embedding vectors with the associated visualization taxonomies, and density plot and sampling techniques to address the overdrawing problem. We demonstrate in three case studies and one user study the effectiveness of VISAtlas in supporting comparative analysis of visualization collections, exploration of composite visualizations, and image-based retrieval of visualization designs. The studies reveal that real-world visualization collections (e.g., Beagle and VIS30K) better accord with the richness and diversity of visualization designs than synthetic collections (e.g., Data2Vis), inspiring composite visualizations are identified in real-world collections, and distinct design patterns exist in visualizations from different sources.
C1 [Ye, Yilin; Huang, Rong; Zeng, Wei] Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511400, Guangdong, Peoples R China.
   [Ye, Yilin; Huang, Rong; Zeng, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511400, Guangdong, Peoples R China.; Zeng, W (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM yyebd@connect.ust.hk; rhuang421@connect.hkust-gz.edu.cn; weizeng@ust.hk
OI Huang, Rong/0000-0002-6807-3148
FU National Natural Science Foundation of China [62172398]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62172398.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chagas P, 2018, IEEE IJCNN
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   Cheng SH, 2015, IEEE PAC VIS SYMP, P295, DOI 10.1109/PACIFICVIS.2015.7156390
   Colorbrewer2, 2013, About us
   Cox MA., 2008, Handbook of Data Visualization, P315, DOI [10.1007/978-3-540-33037-014, DOI 10.1007/978-3-540-33037-0_14, 10.1007/978-3-540-33037-0_14]
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   Deng DZ, 2022, Arxiv, DOI [arXiv:2203.10476, 10.48550/arXiv.2203.10476, DOI 10.48550/ARXIV.2203.10476]
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Di Caro L, 2010, LECT NOTES ARTIF INT, V6119, P125
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   github, 2018, D3-scale-chromatic
   github, 2016, Colorcet
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gomez SR, 2012, IEEE T VIS COMPUT GR, V18, P2411, DOI 10.1109/TVCG.2012.214
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   Jänicke H, 2010, COMPUT GRAPH FORUM, V29, P1183, DOI 10.1111/j.1467-8659.2009.01667.x
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kim MC, 2016, SCIENTOMETRICS, V107, P123, DOI 10.1007/s11192-015-1830-0
   Li H., 2022, P ACM CHI C HUM FACT, P1
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JY, 2021, IEEE WINT CONF APPL, P1916, DOI 10.1109/WACV48630.2021.00196
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Manolis Savva, 2011, P 24 ANN ACM S USER, P393
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Plant W, 2011, STUD COMPUT INTELL, V346, P3
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Sechler J., 2017, P ACM CHI C HUM FACT, P2049
   Shen QM, 2018, IEEE T VIS COMPUT GR, V24, P1004, DOI 10.1109/TVCG.2017.2744159
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SC, 2023, IEEE T VIS COMPUT GR, V29, P3169, DOI 10.1109/TVCG.2022.3153514
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van der Corput P, 2017, COMPUT GRAPH FORUM, V36, P295, DOI 10.1111/cgf.13188
   van der Corput P, 2016, IEEE PAC VIS SYMP, P152, DOI 10.1109/PACIFICVIS.2016.7465263
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang CL, 2015, INFORM VISUAL, V14, P183, DOI 10.1177/1473871613498519
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Yee K.-P., 2003, P SIGCHI C HUM FACT, P401, DOI DOI 10.1145/642611.642681
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhao BC, 2021, ADV NEUR IN, V34
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
NR 76
TC 3
Z9 3
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3224
EP 3240
DI 10.1109/TVCG.2022.3229023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700076
PM 37015539
DA 2024-08-05
ER

PT J
AU Ibrahim, MT
   Gopi, M
   Majumder, A
AF Ibrahim, Muhammad Twaha
   Gopi, M.
   Majumder, Aditi
TI Real-Time Seamless Multi-Projector Displays on Deformable Surfaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cameras; Calibration; Three-dimensional displays; Shape; Surface
   reconstruction; Real-time systems; Surface fitting; Computing
   Methodologies; Artificial Intelligence; Computer Vision; Image and Video
   Acquisition
ID CALIBRATION
AB Prior works on multi-projector displays have focused primarily on static rigid objects, some focusing on dynamic rigid objects. However, works on projection based displays on deformable dynamic objects have focused only on small scale single projector displays. Tracking a deformable dynamic surface and updating projections precisely in real time on it is a significantly challenging task, even for a single projector system. In this paper, we present the first end-to-end solution for achieving a real-time, seamless display on deformable surfaces using mutliple unsychronized projectors without requiring any prior knowledge of the surface or device parameters. The system first accurately calibrates multiple RGB-D cameras and projectors using the deformable display surface itself, and then using those calibrated devices, tracks the continuous changes in the surface shape. Based on the deformation and projector calibration, the system warps and blends the image content in real-time to create a seamless display on a surface that continuously changes shape. Using multiple projectors and RGB-D cameras, we provide the much desired aspect of scale to the displays on deformable surfaces. Most prior dynamic multi-projector systems assume rigid objects and depend critically on the constancy of surface normals and non-existence of local shape deformations. These assumptions break in deformable surfaces making prior techniques inapplicable. Point-based correspondences become inadequate for calibration, exacerbated with no synchronization between the projectors. A few works address non-rigid objects with several restrictions like targeting semi-deformable surfaces (e.g. human face), or using single coaxial (optically aligned) projector-camera pairs, or temporally synchronized cameras. We break loose from such restrictions and handle multiple projector systems for dynamic deformable fabric-like objects using temporally unsynchronized devices. We devise novel methods using ray and plane-based constraints imposed by the pinhole camera model to address these issues and design new blending methods dependent on 3D distances suitable for deformable surfaces. Finally, unlike all prior work with rigid dynamic surfaces that use a single RGB-D camera, we devise a method that involve all RGB-D cameras for tracking since the surface is not seen completely by a single camera. These methods enable a seamless display at scale in the presence of continuous movements and deformations. This work has tremendous applications on mobile and expeditionary systems where environmentals (e.g. wind, vibrations, suction) cannot be avoided. One can create large displays on tent walls in remote, austere military or emergency operations in minutes to support large scale command and control, mission rehearsal or training operations. It can be used to create displays on mobile and inflatable objects for tradeshows/events and touring edutainment applications.
C1 [Ibrahim, Muhammad Twaha; Gopi, M.; Majumder, Aditi] Univ Calif Irvine, Irvine, CA 92697 USA.
C3 University of California System; University of California Irvine
RP Ibrahim, MT (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.
EM muhammti@uci.edu; gopi@ics.uci.edu; majumder@ics.uci.edu
RI Ibrahim, Muhammad Twaha/ADD-8310-2022
OI Ibrahim, Muhammad Twaha/0000-0001-9286-6124
FU US Air Force
FX No Statement Available
CR Ahmed K. H., 2019, Journal of ElectronicImaging, V28
   Asayama H, 2018, IEEE T VIS COMPUT GR, V24, P1077, DOI 10.1109/TVCG.2017.2657634
   Audet Samuel, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P47, DOI 10.1109/CVPR.2009.5204319
   Bermano A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508416
   Bi W., 2016, P ACM S APPL PERC, P19, DOI [DOI 10.1145/2931002.2931016, 10.1145/2931002.2931016]
   Bouman KL, 2013, IEEE I CONF COMP VIS, P1984, DOI 10.1109/ICCV.2013.455
   Chen R., 2001, CVPRTechnical Sketch, p10Z
   Feng D., 2019, IEEE Transactions on Instru-mentation and Measurement, V69, p11Y
   Fujimoto Y, 2014, IEEE T VIS COMPUT GR, V20, P540, DOI 10.1109/TVCG.2014.25
   Hashimoto R., 2017, International Journal of ComputerGames Technology, p13B
   Hasker E, 2007, IEEE T VIS COMPUT GR, V13, P1368, DOI 10.1109/TVCG.2007.70586
   Hasker ES, 2006, IEEE T VIS COMPUT GR, V12, P1101, DOI 10.1109/TVCG.2006.121
   Huang BY, 2021, IEEE T AUTOM SCI ENG, V18, P1049, DOI 10.1109/TASE.2020.2994223
   Huang BY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P15, DOI 10.1109/ISMAR-Adjunct.2018.00023
   Ibrahim G., 2020, 26 ACM S VIRT REAL S, P1
   Ibrahim M., 2023, 2023 22 IEEE INT S M
   Ibrahim MT, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P905, DOI 10.1109/VRW58643.2023.00295
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Juarez-Salazar V. H., 2019, Optics and Lasersin Engineering, V120, pn21S
   Kagami S, 2019, IEEE T VIS COMPUT GR, V25, P3094, DOI 10.1109/TVCG.2019.2932248
   Kawabe T., 2016, ACM Trans. Appl. Percept., p23P
   Kurth M., 2022, IEEE Transactions on Visualization and Computer Graphics, p25V
   Kurth P, 2018, IEEE T VIS COMPUT GR, V24, P2886, DOI 10.1109/TVCG.2018.2868530
   Lange C., 2017, InProc. of European Association for Computer Graphics:Short Papers, P1
   Lange C., 2016, Augmented Reality, Virtual Reality, and Computer Graph-ics, V9769, p26V
   Lincoln G., 2011, 2011 IEEE VIRT REAL, p28A
   Majumder A, 2005, ACM T GRAPHIC, V24, P118, DOI 10.1145/1037957.1037964
   Miyashita Y., 2018, ACM Trans. Graph., p31D
   Miyazaki N., 2018, 2018 INT WORKSH ADV, p32D
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Narita Y., 2015, P 21 ACM S VIRT REAL, p34G
   Narita Y., 2016, IEEE transactions on visualization and computer graphics, V23, p35T
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Punpongsanon D., 2020, IEEE T VISUALIZATION, p39R
   Punpongsanon D., 2013, SIGGRAPH AS 2013 EM, p37P
   Punpongsanon D., 2015, Virtual Reality, V19, p38P
   Raskar G., 2001, RENDERING TECHNIQUES, V12, p43C
   Raskar M., 1998, EUR WORKSH REND TECH, pn41R
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Raskar Ramesh., 1998, Proceedings of the 25th annual conference on Computer graphics and interactive techniques, P179, DOI DOI 10.1145/280814.280861
   Resch C, 2014, INT SYM MIX AUGMENT, P151, DOI 10.1109/ISMAR.2014.6948421
   Resch H., 2015, IEEE Transactionson Visualization and Computer Graphics, V21, p45P
   Roman P, 2010, IEEE T VIS COMPUT GR, V16, P1623, DOI 10.1109/TVCG.2010.128
   Sajadi A., 2009, IEEE Transactions onVisualization and Computer Graphics, V10, p47B
   Sajadi A., 2010, P 17 ACM S VIRT REAL, p49B
   Sajadi B, 2010, P IEEE VIRT REAL ANN, P155, DOI 10.1109/VR.2010.5444797
   Sajadi B, 2011, IEEE T VIS COMPUT GR, V17, P1209, DOI 10.1109/TVCG.2011.33
   Sen B., 2005, ACM SIGGRAPH 2005 PA, p51M
   Shahpaski L. Ricardo, 2017, P IEEE C COMP VIS PA, P4885
   Shimazu S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P235, DOI 10.1109/ISMAR.2011.6092393
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Siegl M., 2016, InSIGGRAPH ASIA2016 Technical Briefs, p54C
   Siegl M., 2015, ACM Trans. Graph., p55C
   Sueishi T, 2015, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2015.7223330
   Tehrani M., 2019, IEEE Transactions on Visualization and Com-puter Graphics, V27, P2265
   Tehrani M. T., 2023, IEEE Trans-actions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.327743659M, DOI 10.1109/TVCG.2023.327743659M]
   Waldner C., 2008, Emerging displaytechnologies, P1
   Wang LH, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313246
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe M., 2018, SIGGRAPH AS 2018 EM, P1
   Willi A., 2017, 2017 IEEE INT S MIX, p63S
   Yamazaki M., 2011, CVPR 2011 WORKSH, p64L
   Yang LM, 2016, INT SYM MIX AUGMENT, P63, DOI 10.1109/ISMAR.2016.22
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
   Zhou Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P781, DOI 10.1145/2858036.2858329
NR 65
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2527
EP 2537
DI 10.1109/TVCG.2024.3372097
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400002
PM 38437087
DA 2024-08-05
ER

PT J
AU Jackson, B
   Lor, L
   Heggeseth, BC
AF Jackson, Bret
   Lor, Linda
   Heggeseth, Brianna C.
TI Workspace Guardian: Investigating Awareness of Personal Workspace
   Between Co-Located Augmented Reality Users
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mixed reality; augmented reality; three-dimensional displays
AB As augmented reality (AR) systems proliferate and the technology gets smaller and less intrusive, we imagine a future where many AR users will interact in the same physical locations (e.g., in shared work places and public spaces). While previous research has explored AR collaboration in these spaces, our focus is on co-located but independent work. In this paper, we explore co-located AR user behavior and investigate techniques for promoting awareness of personal workspace boundaries. Specifically, we compare three techniques: showing all virtual content, visualizing bounding box outlines of content, and a self-defined workspace boundary. The findings suggest that a self-defined boundary led to significantly more personal workspace encroachments.
C1 [Jackson, Bret; Lor, Linda; Heggeseth, Brianna C.] Macalester Coll, St Paul, MN 55105 USA.
C3 Macalester College
RP Jackson, B (corresponding author), Macalester Coll, St Paul, MN 55105 USA.
EM bjackson@macalester.edu; llor@macalester.edu; bheggese@macalester.edu
FU Clare Booth Luce Foundation
FX No Statement Available
CR [Anonymous], 2023, Proceedings of the ACM on Interactive, Mobile, Wear-able and Ubiquitous Technologies, V6, DOI [10.1145/35695017, DOI 10.1145/35695017]
   Hagan J. R., 2022, INPROCEEDINGS 2022 I, DOI [10.1145/3531073.35310797[42]J.O', DOI 10.1145/3531073.35310797[42]J.O]
   Hagan J. R., 2023, INPROCEEDINGS 2023 C, DOI [10.1145/3544548.35810182[43]J.O', DOI 10.1145/3544548.35810182[43]J.O]
   O'Hagan J, 2021, INT SYM MIX AUGMENT, P211, DOI 10.1109/ISMAR52148.2021.00036
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Paavilainen J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2493, DOI 10.1145/3025453.3025871
   Pierce JL, 2003, REV GEN PSYCHOL, V7, P84, DOI 10.1037/1089-2680.7.1.84
   Poretski J., 2018, P ACM HUMAN COMPUTER, DOI [10.1145/32744112\nR.R, DOI 10.1145/32744112]
   Poretski L, 2021, INT J HUM-COMPUT ST, V150, DOI 10.1016/j.ijhcs.2021.102611
   Wehbe RR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376319
   Wu SX, 2023, Symposium Virtual Re, P631, DOI 10.1109/VR55154.2023.00078
   Yang KT, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P499, DOI 10.1145/3242587.3242630
   Yu JQ, 2022, ETR&D-EDUC TECH RES, V70, P1169, DOI 10.1007/s11423-022-10122-y
   Zibrek K, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419985
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2724
EP 2733
DI 10.1109/TVCG.2024.3372073
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400056
PM 38437099
DA 2024-08-05
ER

PT J
AU Lenz, LS
   Fender, AR
   Chatain, J
   Holz, C
AF Lenz, Lara Sofie
   Fender, Andreas Rene
   Chatain, Julia
   Holz, Christian
TI Comparing Synchronous and Asynchronous Task Delivery in Mixed Reality
   Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Virtual reality; Mixed reality; Switches; Collaboration;
   Asynchronous communication; Training; Mixed Reality; Workspaces;
   Interruptions; Evaluation; Task focus
ID INTERRUPTIONS; WORK
AB Asynchronous digital communication is a widely applied and well-known form of information exchange. Most pieces of technology make use of some variation of asynchronous communication systems, be it messaging or email applications. This allows recipients to process digital messages immediately (synchronous) or whenever they have time (asynchronous), meaning that purely digital interruptions can be mitigated easily. Mixed Reality systems have the potential to not only handle digital interruptions but also interruptions in physical space, e.g., caused by co-workers in workspaces or learning environments. However, the benefits of such systems previously remained untested in the context of Mixed Reality. We conducted a user study (N=26) to investigate the impact that the timing of task delivery has on the participants' performance, workflow, and emotional state. Participants had to perform several cognitively demanding tasks in a Mixed Reality workspace. Inside the virtual workspace, we simulated in-person task delivery either during tasks (i.e., interrupting the participant) or between tasks (i.e., delaying the interruption). Our results show that delaying interruptions has a significant impact on subjective metrics like the perceived performance and workload.
C1 [Lenz, Lara Sofie; Fender, Andreas Rene; Holz, Christian] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   [Chatain, Julia] Swiss Fed Inst Technol, Dept Educ Dev & Technol, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal
   Institutes of Technology Domain; ETH Zurich
RP Fender, AR (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
EM lara.lenz@gmx.ch; progga.af@gmail.com; jchatain@ethz.ch;
   christian.holz@inf.ethz.ch
RI Holz, Christian/AAV-4925-2020
OI Holz, Christian/0000-0001-9655-9519; Fender, Andreas/0000-0002-5903-0736
FU Zurich Information Security and Privacy Center
FX No Statement Available
CR Adler RF, 2013, COMPUT HUM BEHAV, V29, P1441, DOI 10.1016/j.chb.2013.01.040
   Altmann EM, 2014, J EXP PSYCHOL GEN, V143, P215, DOI 10.1037/a0030986
   [Anonymous], 2012, NASA TASK LOAD INDEX (TLX)- Paper and pencil package
   Apple, 2023, Vision pro
   Bailey BP, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P593
   Bailey BP, 2000, IEEE SYS MAN CYBERN, P757, DOI 10.1109/ICSMC.2000.885940
   Bardram JE, 2010, COMPUT SUPP COOP W J, V19, P105, DOI 10.1007/s10606-010-9110-2
   Billinghurst M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1641, DOI 10.1109/ICME.2000.871085
   Blumberg EJ, 2015, HUM FACTORS, V57, P1051, DOI 10.1177/0018720814565189
   Chen A., 2014, AIS Transactions on Human-Computer Interaction, V6, P2
   Chen A, 2018, MIS QUART, V42, P1023, DOI 10.25300/MISQ/2018/13631
   Cutrell E, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P263
   Czerwinski M., 2000, P HCI, V2, P71
   Czerwinski M., 2000, OZCHI 2000 C P, V356, P361
   Czerwinski M., 1991, ACM SIGCHI Bulletin, V23, P38, DOI [DOI 10.1145/126729.1056014, 10.1145/126729.10560142, DOI 10.1145/126729.10560142]
   Danninger M., 2005, P GRAPHICS INTERFACE, P1
   Dubosc C, 2021, COMPUT GRAPH-UK, V101, P82, DOI 10.1016/j.cag.2021.08.011
   Dzardanova E, 2022, VIRTUAL REAL-LONDON, V26, P737, DOI 10.1007/s10055-021-00564-9
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Eyrolle H, 2000, APPL ERGON, V31, P537, DOI 10.1016/S0003-6870(00)00019-3
   Federman JE, 2019, EUR J TRAIN DEV, V43, P490, DOI 10.1108/EJTD-10-2018-0100
   Fender A, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P73, DOI 10.1145/3279778.3279794
   Fender AR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501836
   Fischer J. E., 2010, P 12 INT C HUM COMP, P103, DOI [10.1145/1851600.1851620, DOI 10.1145/1851600.1851620]
   Fitz N, 2019, COMPUT HUM BEHAV, V101, P84, DOI 10.1016/j.chb.2019.07.016
   George C, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P497, DOI 10.1145/3322276:3322363
   George C, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364273
   GILLIE T, 1989, PSYCHOL RES-PSYCH FO, V50, P243, DOI 10.1007/BF00309260
   Gopher D, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P1060
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Hart S. G., 1986, Nasa task load index (tlx)
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   HESS SM, 1994, HUM FAC ERG SOC P, P1173
   Horvitz E., 2003, P 5 INT C MULT INT I, P20, DOI [DOI 10.1145/958432.958440, 10.1145/958432.958440]
   Horvitz E. J., 2013, arXiv
   Jambon F., 1996, HUMAN FACTORS COMPUT, P45, DOI DOI 10.1145/257089.2571282
   Knierim P., 2020, P AUGM HUM INT C AHS, DOI [10.1145/3384657.3384659, DOI 10.1145/3384657.3384659]
   Kushlev K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1011, DOI 10.1145/2858036.2858359
   Lilija K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376604
   Linde C., 1987, Technical report, P2
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Lopez-Rosenfeld M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125772
   Mandler G., 1966, Anxiety and behavior, V1, P2
   Mansi G, 2013, INT J INFORM MANAGE, V33, P591, DOI 10.1016/j.ijinfomgt.2013.01.011
   Mark G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P107
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Meta, 2023, Meta quest 2
   Microsoft, 2023, Azure kinect
   Minassian S. O., 2004, Diverse strategies for interruption management in complex office activities, DOI 10.1.80.2944
   Miyata Y., 1986, User centered system design: New perspectives on humancomputer interaction, P2
   Monk CA, 2004, HUM FACTORS, V46, P650, DOI 10.1518/hfes.46.4.650.56816
   O'Conaill B., 1995, C COMP HUM FACT COMP, P262, DOI [DOI 10.1145/223355.2236651,2, 10.1145/223355.223665, DOI 10.1145/223355.223665, 10.1145/223355.223665.]
   O'Hagan J, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581018
   O'Hagan J, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3531079
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Penichet VMR, 2007, ELECTRON NOTES THEOR, V168, P237, DOI 10.1016/j.entcs.2006.12.007
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132822
   Ratwani R M., 2006, P HUMAN FACTORS ERGO, DOI DOI 10.1177/154193120605000334
   Roo JS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P787, DOI 10.1145/3126594.3126638
   Salvucci DD, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P85
   Sasangohar F, 2017, HUM FACTORS, V59, P628, DOI 10.1177/0018720816689513
   Sykes ER, 2011, INT J INFORM MANAGE, V31, P385, DOI 10.1016/j.ijinfomgt.2010.10.010
   Tinwell A., 2014, Nonverbal Communication In Virtual Worlds, P325
   U. Technologies, 2023, Unity3d engine 2020.3.14
   van Solingen R, 1998, IEEE SOFTWARE, V15, P97, DOI 10.1109/52.714843
   Wilson AD, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P100, DOI 10.1145/3132272.3134144
NR 66
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2776
EP 2784
DI 10.1109/TVCG.2024.3372034
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400042
PM 38437079
DA 2024-08-05
ER

PT J
AU Wang, JL
   Shi, RK
   Li, XD
   Wei, YS
   Liang, HN
AF Wang, Jialin
   Shi, Rongkai
   Li, Xiaodong
   Wei, Yushi
   Liang, Hai-Ning
TI Omnidirectional Virtual Visual Acuity: A User-Centric Visual Clarity
   Metric for Virtual Reality Head-Mounted Displays and Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Measurement; Resists; Rendering (computer graphics);
   Optical imaging; Image resolution; Optical sensors; Virtual reality;
   Head-mounted displays; Measurements; Visual clarity; Passthrough; Render
   resolution; Frame rate
ID PERFORMANCE; LOGMAR
AB Users' perceived image quality of virtual reality head-mounted displays (VR HMDs) is determined by multiple factors, including the HMD's structure, optical system, display and render resolution, and users' visual acuity (VA). Existing metrics such as pixels per degree (PPD) have limitations that prevent accurate comparison of different VR HMDs. One of the main limitations is that not all VR HMD manufacturers released the official PPD or details of their HMDs' optical systems. Without these details, developers and users cannot know the precise PPD or calculate it for a given HMD. The other issue is that the visual clarity varies with the VR environment. Our work has identified a gap in having a feasible metric that can measure the visual clarity of VR HMDs. To address this gap, we present an end-to-end and user-centric visual clarity metric, omnidirectional virtual visual acuity (OVVA), for VR HMDs. OVVA extends the physical visual acuity chart into a virtual format to measure the virtual visual acuity of an HMD's central focal area and its degradation in its noncentral area. OVVA provides a new perspective to measure visual clarity and can serve as an intuitive and accurate reference for VR applications sensitive to visual accuracy. Our results show that OVVA is a simple yet effective metric for comparing VR HMDs and environments.
C1 [Wang, Jialin; Shi, Rongkai; Li, Xiaodong; Wei, Yushi] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou, Peoples R China.
   [Wang, Jialin; Shi, Rongkai; Wei, Yushi] Univ Liverpool, Dept Comp Sci, Liverpool, England.
   [Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Dept Comp, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; University of Liverpool; Xi'an
   Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Sch Adv Technol, Dept Comp, Suzhou, Peoples R China.
EM Jialin.Wang16@student.xjtlu.edu.cn; rongkai.shi19@student.xjtlu.edu.cn;
   Xiaodong.Li22@student.xjtlu.edu.cn; Yushi.Wei21@student.xjtlu.edu.cn;
   haining.liang@xjtlu.edu.cn
RI Wang, Jialin/KFS-9745-2024
OI Wang, Jialin/0000-0002-1990-1293; Liang, Hai-Ning/0000-0003-3600-8955;
   Shi, Rongkai/0000-0001-8845-6034; Wei, Yushi/0000-0002-6003-0557
FU Suzhou Municipal Key Laboratory for Intelligent Virtual Engineering
FX No Statement Available
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   BAILEY IL, 1976, AM J OPTOM PHYS OPT, V53, P740
   Brown R., Compare Virtual Reality Headsets
   Carkeet A, 2021, OPHTHAL PHYSL OPT, V41, P1176, DOI 10.1111/opo.12882
   Chaplin P Kay Nottingham, 2011, NASN Sch Nurse, V26, P221
   Eisenberg E, 2020, PROC SPIE, V11310, DOI 10.1117/12.2546613
   Erickson A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P434, DOI [10.1109/VR46266.2020.1580695145399, 10.1109/VR46266.2020.00-40]
   Eser I, 2008, J REFRACT SURG, V24, P685, DOI 10.3928/1081597X-20080901-07
   Fan Q, 2011, INVEST OPHTH VIS SCI, V52, P6059, DOI 10.1167/iovs.10-7108
   Finger RP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081042
   Guo D, 2010, PROC CVPR IEEE, P515, DOI 10.1109/CVPR.2010.5540170
   Holden B, 2014, EYE, V28, P142, DOI 10.1038/eye.2013.256
   Holladay JT, 2004, J CATARACT REFR SURG, V30, P287, DOI 10.1016/j.jcrs.2004.01.014
   Hussain B, 2006, CLIN EXP OPHTHALMOL, V34, P6, DOI 10.1111/j.1442-9071.2006.01135.x
   Jin JX, 2015, BMC OPHTHALMOL, V15, DOI 10.1186/s12886-015-0052-9
   Jin X, 2022, J INTERIOR DES, V47, P31, DOI 10.1111/joid.12209
   Johnson CA, 1995, OPTOMETRY VISION SCI, V72, P864, DOI 10.1097/00006324-199512000-00004
   JONES RK, 1981, J EXP PSYCHOL HUMAN, V7, P30, DOI 10.1037/0096-1523.7.1.30
   Kappler Elizabeth, 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P2193, DOI 10.1177/1071181322661195
   Lee WJ, 2019, EYE, V33, P1145, DOI 10.1038/s41433-019-0376-4
   Lu T., 2023, Electronic Imaging, V35, P211
   Marsden Janet, 2014, Community Eye Health, V27, P16
   Mataftsi A, 2019, GRAEF ARCH CLIN EXP, V257, P1513, DOI 10.1007/s00417-019-04344-9
   Meta, Stacking the Optical Deck: Introducing Infinite Display + a Primeron Measuring Visual Quality in VR
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Panfili L, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P629, DOI 10.1109/VRW52623.2021.00197
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Piech C, 2020, AAAI CONF ARTIF INTE, V34, P471
   Pimax, Five ways the Crystal is different than other headsets
   Pohl G. S., 2013, P 19 ACM S VIRT REAL, V2, P259, DOI 10.1145/2503713.25037521,6[31]K.
   Rose K, 2000, BRIT J OPHTHALMOL, V84, P1031, DOI 10.1136/bjo.84.9.1031
   Rossi EA, 2010, NAT NEUROSCI, V13, P156, DOI 10.1038/nn.2465
   Sauer Y, 2022, VIRTUAL REAL-LONDON, V26, P1089, DOI 10.1007/s10055-021-00619-x
   Shen H. Y., 2022, MathematicalProblems in Engineering, V2022, DOI [10.1155/2022/12705652[35]D, DOI 10.1155/2022/12705652[35]D]
   Sproule David, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P547, DOI 10.1177/1071181319631488
   Varjo, Technical Specifications of Varjo VR-3
   Vinas M, 2013, OPTOMETRY VISION SCI, V90, P1430, DOI 10.1097/OPX.0000000000000063
   Wang JL, 2023, IEEE T VIS COMPUT GR, V29, P2478, DOI 10.1109/TVCG.2023.3247057
   Wang JL, 2023, VISUAL COMPUT, V39, P3373, DOI 10.1007/s00371-023-02976-x
   Wang JL, 2023, IEEE T GAMES, V15, P252, DOI 10.1109/TG.2022.3178539
   Wang R. Shi, 2022, Proc. ACM Comput. Graph. Interact. Tech., V5, DOI [10.1145/35226101,3[40]J, DOI 10.1145/35226101,3[40]J]
   Wang T, 2021, INT J OPHTHALMOL-CHI, V14, P536, DOI 10.18240/ijo.2021.04.09
   Xiang N, 2023, VISUAL COMPUT, V39, P3661, DOI 10.1007/s00371-023-02964-1
   Yadav N., Technical challenges for typography in AR/VR
   Ying GS, 2018, OPHTHAL EPIDEMIOL, V25, P1, DOI 10.1080/09286586.2017.1320413
   Zaman J., 2023, Annals of Biomedical Engineering, DOI [10.1007/s10439-023-03379-82[47]T, DOI 10.1007/S10439-023-03379-82[47]T]
   Zhan T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101397
NR 47
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2033
EP 2043
DI 10.1109/TVCG.2024.3372127
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400066
PM 38437113
DA 2024-08-05
ER

PT J
AU Braun, D
   Borgo, R
   Sondag, M
   von Landesberger, T
AF Braun, Daniel
   Borgo, Rita
   Sondag, Max
   von Landesberger, Tatiana
TI Reclaiming the Horizon: Novel Visualization Designs for Time-Series Data
   with Large Value Ranges
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Image color analysis; Bars;
   Standards; Market research; Estimation; Visualization techniques;
   time-series; design study; orders of magnitude; logarithmic scale
AB introduce two novel visualization designs to support practitioners in performing identification and discrimination tasks on large value ranges (i.e., several orders of magnitude) in time-series data: (1) The order of magnitude horizon graph, which extends the classic horizon graph; and (2) the order of magnitude line chart, which adapts the log-line chart. These new visualization designs visualize large value ranges by explicitly splitting the mantissa m and exponent e of a value v = m <middle dot> 10(e). We evaluate our novel designs against the most relevant state-of-the-art visualizations in an empirical user study. It focuses on four main tasks commonly employed in the analysis of time-series and large value ranges visualization: identification, discrimination, estimation, and trend detection. For each task we analyze error, confidence, and response time. The new order of magnitude horizon graph performs better or equal to all other designs in identification, discrimination, and estimation tasks. Only for trend detection tasks, the more traditional horizon graphs reported better performance. Our results are domain-independent, only requiring time-series data with large value ranges.
C1 [Braun, Daniel; Sondag, Max; von Landesberger, Tatiana] Univ Cologne, Cologne, Germany.
   [Borgo, Rita] Kings Coll London, London, England.
C3 University of Cologne; University of London; King's College London
RP Braun, D (corresponding author), Univ Cologne, Cologne, Germany.
EM braun@cs.uni-koeln.de; rita.borgo@kcl.ac.uk; sondag@cs.uni-koeln.de;
   landesberger@cs.uni-koeln.de
RI sondag, max/KIJ-0026-2024
OI sondag, max/0000-0003-3309-638X; Braun, Daniel/0000-0002-8824-7184; von
   Landesberger, Tatiana/0000-0002-5279-1444
FU BMBF
FX No Statement Available
CR Adnan M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5444, DOI 10.1145/2858036.2858300
   Aigner W, 2012, COMPUT GRAPH FORUM, V31, P995, DOI 10.1111/j.1467-8659.2012.03092.x
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Aigner W, 2008, IEEE T VIS COMPUT GR, V14, P47, DOI 10.1109/TVCG.2007.70415
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI [DOI 10.1145/2470654.2466441, 10.1145/2470654.24664412,3,4, DOI 10.1145/2470654.24664412,3,4]
   Bartram L, 2011, IEEE T VIS COMPUT GR, V17, P1444, DOI 10.1109/TVCG.2010.237
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2014, IEEE T VIS COMPUT GR, V20, P2261, DOI 10.1109/TVCG.2014.2346428
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Braun D, 2022, IEEE VIS CONF, P125, DOI 10.1109/VIS54862.2022.00034
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Charness G, 2012, J ECON BEHAV ORGAN, V81, P1, DOI 10.1016/j.jebo.2011.08.009
   Clark JH., 1924, AM J PHYSL OPTICS, V5, P269
   Correll M, 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, DOI [DOI 10.1145/2207676.22085562, 10.1145/2207676.2208556, DOI 10.1145/2207676.2208556]
   Diehl A., 2018, Eurographics Conference on Visualization, EuroVis, Short Papers, P61, DOI DOI 10.2312/EUROVISSHORT.20181079
   Federico P, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P273, DOI 10.1145/2598153.2598172
   Few S., 2011, Visual Business Intelligence Newsletter, V3
   Few S., 2005, DM Review, V15, P3
   Few S., 2008, Visual Business Intelligence Newsletter, V1, P2
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   Hawkins E., 2018, Show your stripes
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Hlawatsch M, 2013, COMPUT GRAPH FORUM, V32, P181, DOI 10.1111/cgf.12105
   Hohn M., 2020, EUROVIS 2020 SHORT P, P103, DOI DOI 10.2312/EVS.20201056
   Jabbari A, 2018, ACTES DE LA 30 CONFERENCE FRANCOPHONE SUR L'INTERACTION HOMME-MACHINE - (IHM 2018), P73, DOI 10.1145/3286689.3286694
   Jabbari A, 2018, IEEE PAC VIS SYMP, P116, DOI 10.1109/PacificVis.2018.00023
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Kerracher N, 2015, IEEE T VIS COMPUT GR, V21, P1160, DOI 10.1109/TVCG.2015.2424889
   Kubina R, 2023, BEHAV MODIF, V47, P615, DOI 10.1177/01454455221130002
   Munzner T., 2014, Visualization analysis and design, P3
   Nibley B., 2022, Bitcoin price history: 2009-2023
   Reijner H., 2008, ELECT P VIS08 WORKSH
   Romano A, 2020, HEALTH ECON, V29, P1482, DOI 10.1002/hec.4143
   Saito T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P173, DOI 10.1109/INFVIS.2005.1532144
   Schmitz C., 2022, LIMESURVEY OPEN SOUR
   Sevi S, 2020, CAN J POLIT SCI, V53, P385, DOI 10.1017/S000842392000030X
   Shi CL, 2012, IEEE T VIS COMPUT GR, V18, P2669, DOI 10.1109/TVCG.2012.253
   Stone M., 2008, COLOR IMAGING C, V16, P3
   Vagias W. M., 2006, Likert-type scale response anchors, P4
   Valiati E.R., 2006, P 2006 AVI WORKSHOP, P1, DOI DOI 10.1145/1168149.1168169
   Ware C., 2019, Information Visualization: Perception for Design, P3
   Wertheimer M., 1938, Source Book of Gestalt Psychology, P71, DOI [10.1037/11496-0053, DOI 10.1037/11496-0053, DOI 10.1037/11496-005]
   Yujie Fang, 2020, IOP Conference Series: Materials Science and Engineering, V782, DOI 10.1088/1757-899X/782/2/022013
   Zhao HN, 2017, IEEE T VIS COMPUT GR, V23, P1691, DOI 10.1109/TVCG.2016.2539949
NR 47
TC 0
Z9 0
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1161
EP 1171
DI 10.1109/TVCG.2023.3326576
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500096
PM 37871083
OA Green Published, Green Submitted
DA 2024-08-05
ER

PT J
AU Offenwanger, A
   Brehmer, M
   Chevalier, F
   Tsandilas, T
AF Offenwanger, Anna
   Brehmer, Matthew
   Chevalier, Fanny
   Tsandilas, Theophanis
TI TimeSplines: Sketch-Based Authoring of Flexible and Idiosyncratic
   Timelines
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Temporal Data; interaction design; communication / presentation;
   storytelling; sketch-based interface; lazy data binding
ID VISUALIZATION DESIGN; TIME-SERIES; IMAGES
AB Timelines are essential for visually communicating chronological narratives and reflecting on the personal and cultural significance of historical events. Existing visualization tools tend to support conventional linear representations, but fail to capture personal idiosyncratic conceptualizations of time. In response, we built TimeSplines, a visualization authoring tool that allows people to sketch multiple free-form temporal axes and populate them with heterogeneous, time-oriented data via incremental and lazy data binding. Authors can bend, compress, and expand temporal axes to emphasize or de-emphasize intervals based on their personal importance; they can also annotate the axes with text and figurative elements to convey contextual information. The results of two user studies show how people appropriate the concepts in TimeSplines to express their own conceptualization of time, while our curated gallery of images demonstrates the expressive potential of our approach.
C1 [Offenwanger, Anna; Tsandilas, Theophanis] Univ Paris Saclay, CRNS, Inria, LISN, Paris, France.
   [Brehmer, Matthew] Tableau Res, Amherst, MA USA.
   [Chevalier, Fanny] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
   [Chevalier, Fanny] Univ Toronto, Dept Stat Sci, Toronto, ON, Canada.
C3 Inria; Universite Paris Saclay; Universite Paris Cite; University of
   Toronto; University of Toronto
RP Offenwanger, A (corresponding author), Univ Paris Saclay, CRNS, Inria, LISN, Paris, France.
EM anna.offenwanger@lisn.upsaclay.fr; mbrehmer@tableau.com;
   fanny@dgp.toronto.edu; theophanis.tsandilas@lisn.upsaclay.fr
FU CNRS
FX No Statement Available
CR Agrawala M, 2001, COMP GRAPH, P241, DOI 10.1145/383259.383286
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Akbar S., 2020, P IEEE INT C SMART T, DOI [10.1109/ICoSTA48221.2020.15706140562, DOI 10.1109/ICOSTA48221.2020.15706140562]
   Amini F., 2018, Data-Driven Storytelling, P6
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Beaudouin-Lafon M., 2017, Technical report, P4
   Berends L, 2011, QUAL REP, V16
   Bigelow A, 2017, IEEE T VIS COMPUT GR, V23, P481, DOI 10.1109/TVCG.2016.2598609
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Bohoj M., 2010, P ACM CHI, DOI [10.1145/1753326.17534042, DOI 10.1145/1753326.17534042]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brath R, 2017, IEEE INT CON INF VIS, P96, DOI 10.1109/iV.2017.82
   Brehmer M., 2019, P COMP JOURN C J, P2
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brown J., 2022, The Data Visualization Society State of the Industry Survey
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Byrne L, 2019, INFORM VISUAL, V18, P45, DOI 10.1177/1473871617724212
   Carpendale S., 2017, Information Design Journal, V23, DOI [10.1075/idj.23.1.07thu2, DOI 10.1075/IDJ.23.1.07THU2]
   Chalhoub G, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501833
   Chao W. O., 2010, P INFOVIS POST
   Choe EK, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1143, DOI 10.1145/2556288.2557372
   Chung J. J. Y., 2022, P ACM CHI, DOI [10.1109/TVCG.2017.2743918, DOI 10.1109/TVCG.2017.2743918]
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P468, DOI 10.1109/TVCG.2009.86
   Felice MC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174022
   Fuhrman O, 2010, COGNITIVE SCI, V34, P1430, DOI 10.1111/j.1551-6709.2010.01105.x
   Goel V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00241
   Hammond C., 2012, House of Anansi, V2, P9
   Haroz S., 2015, IEEE TVCG, V22, DOI 0.1109/TVCG.2015.25025872,6
   Hullman J., 2013, P ACM CHI, DOI [10.1145/2470654.24813744, DOI 10.1145/2470654.24813744]
   Hurter C., 2013, P ACM UIST, DOI [10.1145/2501988.25020463,6,9, DOI 10.1145/2501988.25020463,6,9]
   Icastic Consulting, ICATIME: What does time look like?
   Keefe DF, 2008, IEEE T VIS COMPUT GR, V14, P835, DOI 10.1109/TVCG.2008.31
   Khulusi R, 2019, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2019.00038
   Kim N. W., 2017, IEEE TVCG (Proc. InfoVis), V24, DOI [10.1109/TVCG.2017.27441182,3, DOI 10.1109/TVCG.2017.27441182,3]
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300335
   Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714
   Lee B, 2015, IEEE PAC VIS SYMP, P199, DOI 10.1109/PACIFICVIS.2015.7156378
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lin H., 2023, IEEE TVCG (Proc. VIS), V29, DOI 0.1109/TVCG.2022.32094513,4,9
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lupi G., 2016, Dear Data, P3
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Moore J., 2018, Proc. ACM UbiComp, V2, DOI [10.1145/32649384, DOI 10.1145/32649384]
   Otten H, 2018, PROCEEDINGS OF THE IEEE VIS ARTS PROGRAM (VISAP) 2018
   Parsons P, 2022, IEEE T VIS COMPUT GR, V28, P665, DOI 10.1109/TVCG.2021.3114959
   Perin C., 2017, P IEEE VIS ARTS PROG
   Perin C., 2017, IEEE TVCG (Proc. InfoVis), V24, DOI [10.1109/TVCG.2017.27439182,4, DOI 10.1109/TVCG.2017.27439182,4]
   Ren D., 2018, P IEEE EV BELIV, DOI [10.1109/BELIV.2018.86342972,6, DOI 10.1109/BELIV.2018.86342972,6]
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Resnick M., 2005, Design Principles for Tools to Support Creative Thinking, P6
   Romat H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300272
   Rosenberg D., 2013, Cartographies of Time: A History of the Timeline, P2
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Schroeder D., 2015, IEEE transactions on visualization and computer graphics, V22, P3
   Schroeder D., 2010, Proceedings of ACM SIGGRAPH/Eurographics Sketch-Based Interfaces and Modeling, P49
   Shen E., 2014, Journal of Visualization, V17, P3
   Snyder J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300363
   Sterne L., 1805, The Life and Opinions of Tristram Shandy, Gentleman: In Four Volumes, V9, P3
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Thiry E., 2013, P ACM CHI, DOI [10.1145/2470654.24662151,2,3, DOI 10.1145/2470654.24662151,2,3]
   Thudt A., 2014, P ACM DIS PVA WORKSH
   Tolmie P, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P491, DOI 10.1145/2818048.2819992
   Tornatore C, 2011, ING AUTOMOB, P9
   Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476
   Tsandilas T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3255, DOI 10.1145/2702123.2702129
   TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9
   TVERSKY B, 1991, COGNITIVE PSYCHOL, V23, P515, DOI 10.1016/0010-0285(91)90005-9
   Twain M., 1914, Harper's Monthly Magazine, V130
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Walker J, 2016, IEEE T VIS COMPUT GR, V22, P549, DOI 10.1109/TVCG.2015.2467751
   Walny J, 2015, COMPUT GRAPH FORUM, V34, P231, DOI 10.1111/cgf.12635
   Walny J., 2011, P IEEE INT WORKSH VI, DOI 0.1109/VISSOF.2011.6069462
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhao J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1737
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
NR 79
TC 2
Z9 2
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 34
EP 44
DI 10.1109/TVCG.2023.3326520
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500093
PM 37922183
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Shen, QM
   You, ZX
   Yan, X
   Zhang, CZ
   Xu, K
   Zeng, D
   Qin, JB
   Tang, B
AF Shen, Qiaomu
   You, Zhengxin
   Yan, Xiao
   Zhang, Chaozu
   Xu, Ke
   Zeng, Dan
   Qin, Jianbin
   Tang, Bo
TI QEVIS: Multi-Grained Visualization of Distributed Query Execution
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE visual analytics system; distributed query execution; performance
   analysis
AB Distributed query processing systems such as Apache Hive and Spark are widely-used in many organizations for large-scale data analytics. Analyzing and understanding the query execution process of these systems are daily routines for engineers and crucial for identifying performance problems, optimizing system configurations, and rectifying errors. However, existing visualization tools for distributed query execution are insufficient because (i) most of them (if not all) do not provide fine-grained visualization (i.e., the atomic task level), which can be crucial for understanding query performance and reasoning about the underlying execution anomalies, and (ii) they do not support proper linkages between system status and query execution, which makes it difficult to identify the causes of execution problems. To tackle these limitations, we propose QEVIS, which visualizes distributed query execution process with multiple views that focus on different granularities and complement each other. Specifically, we first devise a query logical plan layout algorithm to visualize the overall query execution progress compactly and clearly. We then propose two novel scoring methods to summarize the anomaly degrees of the jobs and machines during query execution, and visualize the anomaly scores intuitively, which allow users to easily identify the components that are worth paying attention to. Moreover, we devise a scatter plot-based task view to show a massive number of atomic tasks, where task distribution patterns are informative for execution problems. We also equip QEVIS with a suite of auxiliary views and interaction methods to support easy and effective cross-view exploration, which makes it convenient to track the causes of execution problems. QEVIS has been used in the production environment of our industry partner, and we present three use cases from real-world applications and user interview to demonstrate its effectiveness. QEVIS is open-source at https://github.com/DBGroup-SUSTech/QEVIS.
C1 [Shen, Qiaomu; Zeng, Dan; Tang, Bo] Southern Univ Sci & Technol, Res Inst Trustworthy Autonomous Syst, Shenzhen, Peoples R China.
   [You, Zhengxin] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
   [Yan, Xiao; Xu, Ke] Huawei Technol Co Ltd, Shenzhen, Peoples R China.
   [Zhang, Chaozu; Qin, Jianbin] Shenzhen Univ, Shenzhen Inst Comp Sci, Shenzhen, Peoples R China.
C3 Southern University of Science & Technology; Southern University of
   Science & Technology; Huawei Technologies; Shenzhen Institute of
   Computing Sciences; Shenzhen University
RP Tang, B (corresponding author), Southern Univ Sci & Technol, Res Inst Trustworthy Autonomous Syst, Shenzhen, Peoples R China.
EM shenqm@sustech.edu.cn; 12250078@mail.sustech.edu.cn;
   yanx@sustech.edu.cn; 12132372@mail.sustech.edu.cn; xuke81@huawei.com;
   zengd@sustech.edu.cn; qinjianbin@szu.edu.cn; tangb3@sustech.edu.cn
RI Shen, Qiaomu/JRW-9498-2023; Zeng, Dan/M-4615-2019
OI Shen, Qiaomu/0000-0002-6510-0964; Zeng, Dan/0000-0002-9036-7791
FU National Key R&D program of China
FX No Statement Available
CR A. S. Foundation, 2023, The apache hadoop project
   Alsubaiee S., 2014, arXiv
   [Anonymous], 2023, Rug plot
   [Anonymous], 2023, dagre-graph layout for javascript
   Apache pig, 2023, About us
   Battle L, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5433, DOI 10.1145/2858036.2858408
   Begoli E, 2018, INT CONF MANAGE DATA, P221, DOI 10.1145/3183713.3190662
   Bittorf MKABV., 2015, P 7 BIENNIAL C INNOV
   Brasseur L, 2005, TECH COMMUN Q, V14, P161, DOI 10.1207/s15427625tcq1402_3
   Carbone P., 2015, Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, V36, P28, DOI DOI 10.1109/IC2EW.2016.56
   Cerullo C, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P109, DOI 10.1109/DEXA.2007.91
   Chaiken R, 2008, PROC VLDB ENDOW, V1, P1265, DOI 10.14778/1454159.1454166
   Chen HD, 2014, IEEE T VIS COMPUT GR, V20, P1683, DOI 10.1109/TVCG.2014.2346594
   Cloudera manager, 2022, Hadoop administration tool
   DiBartolomeo S, 2022, IEEE T VIS COMPUT GR, V28, P324, DOI 10.1109/TVCG.2021.3114756
   Dr, 2023, elephant-monitoring and tuning apache spark jobs on hadoop
   Drebes A., 2014, 7 WORKSHOP PROGRAMMA
   Fujiwara T, 2018, VIS INFORM, V2, P98, DOI 10.1016/j.visint2018.04.010
   Garcia Pinto Vinicius, 2016, 2016 Third Workshop on Visual Performance Analysis (VPA), P17, DOI 10.1109/VPA.2016.008
   Gathani S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376485
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Halperin D, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P881, DOI 10.1145/2588555.2594530
   Investopedia, 2023, US
   Jaakkola H, 2003, LECT NOTES COMPUT SC, V2814, P129
   Jeyakumar V, 2019, INT CONF MANAGE DATA, P333, DOI 10.1145/3299869.3314048
   Kesavan SP, 2020, IEEE PAC VIS SYMP, P206, DOI 10.1109/PacificVis48177.2020.9280
   Khoussainova N, 2012, Arxiv, DOI arXiv:1203.6400
   Leventidis A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2303, DOI 10.1145/3318464.3389767
   Li JK, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P20, DOI [10.1109/VDS48975.2019.8973380, 10.1109/vds48975.2019.8973380]
   Liu HT, 2022, PROCEEDINGS OF THE 13TH SYMPOSIUM ON CLOUD COMPUTING, SOCC 2022, P158, DOI 10.1145/3542929.3563503
   Liu HT, 2022, INT CONF MANAGE DATA, P2417, DOI 10.1145/3514221.3520166
   Liu P, 2020, IEEE IPCCC, DOI 10.1109/IPCCC50635.2020.9391550
   Ma MH, 2020, PROC VLDB ENDOW, V13, P1176, DOI 10.14778/3389133.3389136
   Malik S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2890478
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Moritz D, 2015, COMPUT GRAPH FORUM, V34, P71, DOI 10.1111/cgf.12619
   Nagel WE, 1996, SUPERCOMPUTER, V12, P69
   Prometheus, 2023, About Us
   Saha B, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1357, DOI 10.1145/2723372.2742790
   Sakin SA, 2023, IEEE T VIS COMPUT GR, V29, P788, DOI 10.1109/TVCG.2022.3209375
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sigovan C, 2013, COMPUT GRAPH FORUM, V32, P141, DOI 10.1111/cgf.12101
   Simitsis A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P701, DOI 10.1145/2588555.2594531
   Spark web ui, 2023, About us
   Tan JQ, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.63
   Teoh J, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P465, DOI 10.1145/3357223.3362727
   tez.apache, 2023, Tez ui
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Thusoo A, 2010, PROC INT CONF DATA, P996, DOI 10.1109/ICDE.2010.5447738
   Vavilapalli Vinod Kumar, 2013, Proceedings of the 4th Annual Symposium on Cloud Computing (SOCC), P1
   Wu J, 2020, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST50239.2020.00009
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Yoon DY, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1599, DOI 10.1145/2882903.2915218
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 153
EP 163
DI 10.1109/TVCG.2023.3326930
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500082
PM 37883261
DA 2024-08-05
ER

PT J
AU Wu, GD
   Guo, SN
   Hoffswell, J
   Chan, GYY
   Rossi, RA
   Koh, E
AF Wu, Guande
   Guo, Shunan
   Hoffswell, Jane
   Chan, Gromit Yeuk-Yin
   Rossi, Ryan A.
   Koh, Eunyee
TI Socrates: Data Story Generation via Adaptive Machine-Guided Elicitation
   of User Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Narrative visualization; visual storytelling; conversational agent
ID VISUALIZATIONS; GUIDANCE; MODEL
AB Visual data stories can effectively convey insights from data, yet their creation often necessitates intricate data exploration, insight discovery, narrative organization, and customization to meet the communication objectives of the storyteller. Existing automated data storytelling techniques, however, tend to overlook the importance of user customization during the data story authoring process, limiting the system's ability to create tailored narratives that reflect the user's intentions. We present a novel data story generation workflow that leverages adaptive machine-guided elicitation of user feedback to customize the story. Our approach employs an adaptive plug-in module for existing story generation systems, which incorporates user feedback through interactive questioning based on the conversation history and dataset. This adaptability refines the system's understanding of the user's intentions, ensuring the final narrative aligns with their goals. We demonstrate the feasibility of our approach through the implementation of an interactive prototype: Socrates. Through a quantitative user study with 18 participants that compares our method to a state-of-the-art data story generation algorithm, we show that Socrates produces more relevant stories with a larger overlap of insights compared to human-generated stories. We also demonstrate the usability of Socrates via interviews with three data analysts and highlight areas of future work.
C1 [Wu, Guande] NYU, New York, NY 10012 USA.
   [Guo, Shunan; Hoffswell, Jane; Chan, Gromit Yeuk-Yin; Rossi, Ryan A.; Koh, Eunyee] Adobe Res, San Jose, CA USA.
C3 New York University; Adobe Systems Inc.
RP Wu, GD (corresponding author), NYU, New York, NY 10012 USA.
EM guandewu@nyu.edu; sguo@adobe.com; jhoffs@adobe.com; ychan@adobe.com;
   rrossi@adobe.com; eunyee@adobe.com
RI ; Rossi, Ryan/C-7974-2013
OI Hoffswell, Jane/0000-0002-9871-4575; Guo, Shunan/0000-0001-5355-8399;
   Chan, Gromit Yeuk-Yin/0000-0003-1356-4406; Rossi,
   Ryan/0000-0001-9758-0635; Wu, Guande/0000-0002-9244-173X
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Bach B., 2018, Data-driven storytelling, P2
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cao YR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517648
   Cao YR, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383057
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   Chen Z., 2022, P 2022 CHI C HUMAN F, DOI [10.1145/3491102.35174851,3, DOI 10.1145/3491102.35174851,3]
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chevalier F., 2018, Data-Driven Storytelling, P2
   Cohn N, 2013, COGNITIVE SCI, V37, P413, DOI 10.1111/cogs.12016
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Cook K, 2015, IEEE CONF VIS ANAL, P9, DOI 10.1109/VAST.2015.7347625
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Cutting JE, 2016, PSYCHON B REV, V23, P1713, DOI 10.3758/s13423-016-1051-4
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   DYKES B., 2019, Effective data storytelling: how to drive change with data, narrative and visuals, P2
   Endert A, 2014, J INTELL INF SYST, V43, P411, DOI 10.1007/s10844-014-0304-9
   Endert A, 2012, IEEE T VIS COMPUT GR, V18, P2879, DOI 10.1109/TVCG.2012.260
   Franklin A, 2017, J BIOMED INFORM, V71, P211, DOI 10.1016/j.jbi.2017.05.024
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI DOI 10.1145/1502650.1502695
   Guo Y, 2023, Arxiv, DOI arXiv:2107.14420
   Hariri N., 2012, P 6 ACM C REC SYST, P131, DOI DOI 10.1145/2365952.2365979
   Hinne M., 2011, P DUTCH BELGIUM INFO, P20
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Jannach D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453154
   Kelly D., 2003, Acm Sigir Forum, V37, P4
   Kim N. W., 2019, P 2019 CHI C HUMAN F, P1
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Latif S., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Latif S, 2021, COMPUT GRAPH FORUM, V40, P311, DOI 10.1111/cgf.14309
   Lee B., 2015, IEEE Computer Graphics and Applications, V2
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lei WQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2073, DOI 10.1145/3394486.3403258
   Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769
   Lu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1161
   Meignan D, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2808234
   Miettinen K., 1999, Nonlinear multiobjective optimization, V12, P4
   Mudgal S, 2018, INT CONF MANAGE DATA, P19, DOI 10.1145/3183713.3196926
   Narducci F, 2020, USER MODEL USER-ADAP, V30, P251, DOI 10.1007/s11257-019-09250-7
   Nguyen B. V., 2007, WWW2007 16 INT WORLD, P4
   Panda AK, 2012, INT J ELEC POWER, V40, P9, DOI 10.1016/j.ijepes.2011.12.012
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riche N. H., 2018, Data-driven storytelling, P2
   Rundo L, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103479
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Showkat Dilruba, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479534
   Sperrle F, 2021, COMPUT GRAPH-UK, V100, P93, DOI 10.1016/j.cag.2021.06.016
   Sun M., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P983, DOI 10.1109/TVCG.2022.32094281,2,3,4
   Swanson R, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2362394.2362398
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Whiting S, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P989
   Wojtkowski W., 2002, EUROPEAN SYSTEMS SCI, V5, P1
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Xie ZH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1400, DOI 10.1145/3404835.3462920
   Xu B, 2015, IEEE T KNOWL DATA EN, V27, P102, DOI 10.1109/TKDE.2013.70
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Zhang S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P255, DOI 10.1145/3077136.3080796
   Zhang YM, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2153, DOI 10.1145/3485447.3512088
   Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zheng CB, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517615
   Zheng CB, 2022, IEEE PAC VIS SYMP, P141, DOI 10.1109/PacificVis53943.2022.00023
NR 79
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 131
EP 141
DI 10.1109/TVCG.2023.3327363
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500049
PM 37922178
DA 2024-08-05
ER

PT J
AU Xue, YM
   Paetzold, P
   Kehlbeck, R
   Chen, B
   Kwan, KC
   Wang, YH
   Deussen, O
AF Xue, Yumeng
   Paetzold, Patrick
   Kehlbeck, Rebecca
   Chen, Bin
   Kwan, Kin Chung
   Wang, Yunhai
   Deussen, Oliver
TI Reducing Ambiguities in Line-Based Density Plots by Image-Space
   Colorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trajectory data; times series; density-based visualization; clustering;
   coloring
ID SIMILARITY MEASURES; VISUALIZATION; EDGE; COLORS; UNCERTAINTY; MAPS;
   TREE
AB Line-based density plots are used to reduce visual clutter in line charts with a multitude of individual lines. However, these traditional density plots are often perceived ambiguously, which obstructs the user's identification of underlying trends in complex datasets. Thus, we propose a novel image space coloring method for line-based density plots that enhances their interpretability. Our method employs color not only to visually communicate data density but also to highlight similar regions in the plot, allowing users to identify and distinguish trends easily. We achieve this by performing hierarchical clustering based on the lines passing through each region and mapping the identified clusters to the hue circle using circular MDS. Additionally, we propose a heuristic approach to assign each line to the most probable cluster, enabling users to analyze density and individual lines. We motivate our method by conducting a small-scale user study, demonstrating the effectiveness of our method using synthetic and real-world datasets, and providing an interactive online tool for generating colored line-based density plots.
C1 [Xue, Yumeng] Germany & Shandong Univ, Univ Konstanz, Jinan, Peoples R China.
   [Paetzold, Patrick; Kehlbeck, Rebecca; Chen, Bin; Deussen, Oliver] Univ Konstanz, Constance, Germany.
   [Kwan, Kin Chung] Calif State Univ Sacramento, Sacramento, CA USA.
   [Wang, Yunhai] Shandong Univ, Jinan, Peoples R China.
C3 University of Konstanz; California State University System; California
   State University Sacramento; Shandong University
RP Deussen, O (corresponding author), Univ Konstanz, Constance, Germany.; Wang, YH (corresponding author), Shandong Univ, Jinan, Peoples R China.
EM yumeng.xue@uni-konstanz.de; patrick.paetzold@uni-konstanz.de;
   rebecca.kehlbeck@uni-konstanz.de; bin.chen@uni-konstanz.de;
   kwan@csus.edu; cloudseawang@gmail.com; oliver.deussen@uni-konstanz.de
RI yu, xiao/KFT-1725-2024; Deussen, Oliver/HKF-2004-2023; Chen,
   Zheng/KCY-2338-2024; li, feiyang/KHW-5210-2024
OI Paetzold, Patrick/0000-0002-1315-4602; Xue, Yumeng/0000-0002-8195-517X
FU Deutsche Forschungsgemeinschaft (DFG)
FX No Statement Available
CR [Anonymous], 2017, Acis web services
   [Anonymous], 1999, Proceedings of the Section on Statistical Graphics, American Statistical Association
   [Anonymous], 2023, New york stock exchange
   Artero AO, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P81, DOI 10.1109/INFVIS.2004.68
   Bergman LD, 1995, VISUALIZATION '95 - PROCEEDINGS, P118, DOI 10.1109/VISUAL.1995.480803
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [10.1016/b978-0-08-042415-6.50014-4, DOI 10.1016/B978-0-08-042415-6.50014-4]
   Brewer CynthiaA., 1994, Proc. SPIE, V2171, P54, DOI [DOI 10.1117/12.1753283, DOI 10.1117/12.175328, 10.1117/12.1753283]
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chen CK, 2011, COMPUT GRAPH FORUM, V30, P1941, DOI 10.1111/j.1467-8659.2011.02064.x
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Chen Y, 2007, IEEE T VIS COMPUT GR, V13, P1448, DOI 10.1109/TVCG.2007.70595
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Cox MA., 2008, Handbook of Data Visualization, P315, DOI [10.1007/978-3-540-33037-014, DOI 10.1007/978-3-540-33037-0_14, 10.1007/978-3-540-33037-0_14]
   COX TF, 1991, COMMUN STAT THEORY, V20, P2943, DOI 10.1080/03610929108830679
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   Feng D, 2010, IEEE T VIS COMPUT GR, V16, P980, DOI 10.1109/TVCG.2010.176
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Frantzis A., 2018, Hellenic trench ais data, DOI [10.17882/570405,6,7, DOI 10.17882/570405,6,7]
   Frantzis A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212016
   Fulcher BD, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0048
   Gaffney S., 2004, P 17 INT C NEURAL IN, P2
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   Hochheiser H., 2004, Information Visualization, V3, P1, DOI 10.1057/palgrave.ivs.9500061
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hong MH, 2022, IEEE T VIS COMPUT GR, V28, P987, DOI 10.1109/TVCG.2021.3114783
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Ihaka R., 2003, P DSC, V2
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Jerding DF, 1998, IEEE T VIS COMPUT GR, V4, P257, DOI 10.1109/2945.722299
   Kindlmann G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P299, DOI 10.1109/VISUAL.2002.1183788
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   Lampe OD, 2011, COMPUT GRAPH FORUM, V30, P633, DOI 10.1111/j.1467-8659.2011.01912.x
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Lhuillier A, 2017, COMPUT GRAPH FORUM, V36, P619, DOI 10.1111/cgf.13213
   Liu T., 2021, P CHI C HUMAN FACTOR, DOI [10.1145/3411764.34457512, DOI 10.1145/3411764.34457512]
   Lu KC, 2021, IEEE T VIS COMPUT GR, V27, P475, DOI 10.1109/TVCG.2020.3030406
   Matejka J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2707, DOI 10.1145/2702123.2702585
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   McLoughlin T, 2013, IEEE T VIS COMPUT GR, V19, P1342, DOI 10.1109/TVCG.2012.150
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Moritz D, 2018, Arxiv, DOI arXiv:1808.06019
   Muller M., 2007, Information Retrieval for Music and Motion, DOI [10.1007/978-3-540-74048-3, DOI 10.1007/978-3-540-74048-3_4]
   Novotny M, 2006, IEEE T VIS COMPUT GR, V12, P893, DOI 10.1109/TVCG.2006.170
   OpenStreetMap, 2017, PLANET DUMP
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Petitjean F, 2011, PATTERN RECOGN, V44, P678, DOI 10.1016/j.patcog.2010.09.013
   PHAM B, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P202, DOI 10.1109/VISUAL.1990.146383
   Pomerenke D, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P86, DOI [10.1109/VISUAL.2019.8933706, 10.1109/visual.2019.8933706]
   Rheingans P, 2000, P SOC PHOTO-OPT INS, V3905, P35, DOI 10.1117/12.384882
   ROBERTSON PK, 1986, IEEE COMPUT GRAPH, V6, P24, DOI 10.1109/MCG.1986.276688
   Rössl C, 2012, IEEE T VIS COMPUT GR, V18, P407, DOI 10.1109/TVCG.2011.78
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Salzbrunn T, 2006, IEEE T VIS COMPUT GR, V12, P1601, DOI 10.1109/TVCG.2006.104
   Scheepens R, 2011, IEEE PAC VIS SYMP, P147, DOI 10.1109/PACIFICVIS.2011.5742384
   Scheepens R, 2011, IEEE T VIS COMPUT GR, V17, P2518, DOI 10.1109/TVCG.2011.181
   Silverman B. W., 1986, Density estimation for statistics and data analysis, V26, P2
   Tennekes M, 2014, IEEE T VIS COMPUT GR, V20, P2072, DOI 10.1109/TVCG.2014.2346277
   Thompson David, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P77, DOI 10.1109/LDAV.2013.6675161
   Thony M, 2015, PROCEEDINGS OF THE 6TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON GEOSTREAMING (IWGS) 2015, P33, DOI 10.1145/2833165.2833168
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Trautner T., 2020, Computer Graphics Forum, DOI [10.1111/cgf.140012, DOI 10.1111/CGF.140012]
   TRUMBO BE, 1981, AM STAT, V35, P220, DOI 10.2307/2683294
   van der Zwan M, 2016, IEEE T VIS COMPUT GR, V22, P2550, DOI 10.1109/TVCG.2016.2515611
   Vijaymeena M., 2016, Mach. Learn. Appl. Int. J, V3, P19, DOI DOI 10.5121/MLAIJ.2016.3103
   Wallinger M, 2023, COMPUT GRAPH FORUM, V42, DOI 10.1111/cgf.14789
   Wallinger M, 2022, IEEE T VIS COMPUT GR, V28, P313, DOI 10.1109/TVCG.2021.3114795
   Wang L, 2012, COMPUT GRAPH FORUM, V31, P1305, DOI 10.1111/j.1467-8659.2012.03123.x
   Wattenberg Martin, 2001, PROC SIGCHI EA, P381, DOI DOI 10.1145/634067.6342922
   Wertheimer M., 1938, Source Book of Gestalt Psychology, P71, DOI [10.1037/11496-0053, DOI 10.1037/11496-0053, DOI 10.1037/11496-005]
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wickham H., 2013, Tech. Rep
   Yu HF, 2012, IEEE T VIS COMPUT GR, V18, P1353, DOI 10.1109/TVCG.2011.155
   Yuan J., 2010, P 18 SIGSPATIAL INT, P99, DOI DOI 10.1145/1869790.1869807
   Yuan J., 2011, KDD, P316, DOI [DOI 10.1145/2020408.2020462, 10.1145/2020408.2020462]
   Zeileis A, 2009, COMPUT STAT DATA AN, V53, P3259, DOI 10.1016/j.csda.2008.11.033
   Zeng W, 2019, COMPUT GRAPH FORUM, V38, P581, DOI 10.1111/cgf.13712
   Zhang Z, 2006, INT C PATT RECOG, P1135
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
   Zinsmaier M, 2012, IEEE T VIS COMPUT GR, V18, P2486, DOI 10.1109/TVCG.2012.238
NR 83
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 825
EP 835
DI 10.1109/TVCG.2023.3327149
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500022
PM 37883272
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Zhou, YX
   Yang, WK
   Chen, JS
   Chen, CJ
   Shen, ZY
   Luo, XN
   Yu, LY
   Liu, SX
AF Zhou, Yuxing
   Yang, Weikai
   Chen, Jiashu
   Chen, Changjian
   Shen, Zhiyang
   Luo, Xiaonan
   Yu, Lingyun
   Liu, Shixia
TI Cluster-Aware Grid Layout
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Grid layout; similarity; convexity; compactness; optimization
ID CONVEXITY MEASURE; VISUALIZATION
AB Grid visualizations are widely used in many applications to visually explain a set of data and their proximity relationships. However, existing layout methods face difficulties when dealing with the inherent cluster structures within the data. To address this issue, we propose a cluster-aware grid layout method that aims to better preserve cluster structures by simultaneously considering proximity, compactness, and convexity in the optimization process. Our method utilizes a hybrid optimization strategy that consists of two phases. The global phase aims to balance proximity and compactness within each cluster, while the local phase ensures the convexity of cluster shapes. We evaluate the proposed grid layout method through a series of quantitative experiments and two use cases, demonstrating its effectiveness in preserving cluster structures and facilitating analysis tasks.
C1 [Zhou, Yuxing; Yang, Weikai; Chen, Jiashu; Shen, Zhiyang; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
   [Chen, Changjian] Kuaishou Technol, Beijing, Peoples R China.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Guilin, Peoples R China.
   [Yu, Lingyun] Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.
C3 Tsinghua University; Guilin University of Electronic Technology; Xi'an
   Jiaotong-Liverpool University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
EM yx-zhou19@mails.tsinghua.edu.cn; yangwk21@mails.tsinghua.edu.cn;
   cjs22@mails.tsinghua.edu.cn; chenchangjian@kuaishou.com;
   shenzhiy21@mails.tsinghua.edu.cn; luoxn@guet.edu.cn;
   lingyun.yu@xjtlu.edu.cn; shixia@tsinghua.edu.cn
RI Chen, Changjian/KBA-9462-2024
OI Chen, Changjian/0000-0003-2715-8839
FU National Natural Science Foundation of China
FX No Statement Available
CR Barthel KU, 2023, COMPUT GRAPH FORUM, V42, P261, DOI 10.1111/cgf.14718
   Barthel K.U., VISUALLY EXPLORING M, P289, DOI [10.1002/9781119376996.ch11, DOI 10.1002/9781119376996.CH11]
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425
   Bozeman J. R., 2013, Scientiae Mathematicae Japonicae, V76, P47, DOI DOI 10.32219/ISMS.76.1_472,3
   Chan GYY, 2020, IEEE T VIS COMPUT GR, V26, P981, DOI 10.1109/TVCG.2019.2934280
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Choi J, 2023, IEEE T VIS COMPUT GR, V29, P1424, DOI 10.1109/TVCG.2021.3116656
   Corrado A., 2019, Animals-10 dataset
   Do Carmo M. P., 2016, Differential geometry of curves and surfaces: revised and updated, V2, P3
   Efrat A, 2014, LECT NOTES COMPUT SC, V8871, P452, DOI 10.1007/978-3-662-45803-7_38
   Eppstein David, 2015, International Journal of Computational Geometry & Applications, V25, P101, DOI 10.1142/S0218195915500077
   Felix C, 2017, IEEE T VIS COMPUT GR, V23, P161, DOI 10.1109/TVCG.2016.2598447
   Frey S, 2022, COMPUT GRAPH FORUM, V41, P247, DOI 10.1111/cgf.14537
   Fried O, 2015, COMPUT GRAPH FORUM, V34, P155, DOI 10.1111/cgf.12549
   Halnaut A, 2022, IEEE INT CONF INF VI, P11, DOI 10.1109/IV56949.2022.00012
   HELD A, 1994, PATTERN RECOGN LETT, V15, P611, DOI 10.1016/0167-8655(94)90022-1
   Hilasaca GM, 2021, Arxiv, DOI arXiv:1903.06262
   Huang Jinbin, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209384
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Itoh T, 2009, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2009.4906846
   Kanizsa W., 1976, Vision and artifact, P25
   Keefe DF, 2009, IEEE T VIS COMPUT GR, V15, P1383, DOI 10.1109/TVCG.2009.152
   Kehlbeck R, 2022, IEEE T VIS COMPUT GR, V28, P433, DOI 10.1109/TVCG.2021.3114834
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SC, 2019, AAAI CONF ARTIF INTE, P9977
   Liu XT, 2018, COMPUT GRAPH FORUM, V37, P7, DOI 10.1111/cgf.12526
   Lu M, 2020, IEEE T VIS COMPUT GR, V26, P770, DOI 10.1109/TVCG.2019.2934811
   Major T, 2019, IEEE T VIS COMPUT GR, V25, P576, DOI 10.1109/TVCG.2018.2865151
   Matejka J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173943
   Meulemans W, 2017, IEEE T VIS COMPUT GR, V23, P381, DOI 10.1109/TVCG.2016.2598542
   Muelder C, 2008, IEEE T VIS COMPUT GR, V14, P1301, DOI 10.1109/TVCG.2008.158
   Oppermann M, 2022, IEEE T VIS COMPUT GR, V28, P747, DOI 10.1109/TVCG.2021.3114841
   Pan XJ, 2021, IEEE T VIS COMPUT GR, V27, P2298, DOI 10.1109/TVCG.2019.2948611
   Peura M., 1997, Proceedings of the Third International Workshop on Visual Form. Advances in Visual Form Analysis, P443
   Quadrianto N., 2008, P ADV NEURAL INFORM, P1
   Radford A, 2021, PR MACH LEARN RES, V139
   Rahtu E, 2006, IEEE T PATTERN ANAL, V28, P1501, DOI 10.1109/TPAMI.2006.175
   Rosin PL, 2007, IET IMAGE PROCESS, V1, P182, DOI 10.1049/iet-ipr:20060185
   Rosin PL, 2006, COMPUT VIS IMAGE UND, V103, P101, DOI 10.1016/j.cviu.2006.04.002
   Rottmann Peter, 2023, IEEE Trans Vis Comput Graph, V29, P875, DOI 10.1109/TVCG.2022.3209485
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   Song H, 2017, IEEE T VIS COMPUT GR, V23, P311, DOI 10.1109/TVCG.2016.2598796
   Song Y, 2023, IEEE T VIS COMPUT GR, V29, P1330, DOI 10.1109/TVCG.2021.3113031
   Sonka Milan, 2014, Cengage Learning, P3
   Strong G, 2014, IEEE T MULTIMEDIA, V16, P1045, DOI 10.1109/TMM.2014.2306183
   Todorovic D., 2008, Gestalt principles, V3, P5345, DOI DOI 10.4249/SCHOLARPEDIA.5345
   Torralba A, 2009, VISUAL NEUROSCI, V26, P123, DOI 10.1017/S0952523808080930
   Tu Y., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2022.32251142
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Yang C, 2023, IEEE T VIS COMPUT GR, V29, P3586, DOI 10.1109/TVCG.2022.3165385
   Yoghourdjian V, 2016, IEEE T VIS COMPUT GR, V22, P339, DOI 10.1109/TVCG.2015.2467251
   Yuan Jun, 2023, IEEE Trans Vis Comput Graph, V29, P288, DOI 10.1109/TVCG.2022.3209404
   Zeng W, 2021, IEEE T VIS COMPUT GR, V27, P839, DOI 10.1109/TVCG.2020.3030410
   Zunic J, 2004, IEEE T PATTERN ANAL, V26, P923, DOI 10.1109/TPAMI.2004.19
   Zunic J, 2020, IEEE T PATTERN ANAL, V42, P1394, DOI 10.1109/TPAMI.2019.2898830
NR 61
TC 2
Z9 2
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 240
EP 250
DI 10.1109/TVCG.2023.3326934
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500136
PM 37871055
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Luo, ZJ
   Du, D
   Zhu, HM
   Yu, YZ
   Fu, HB
   Han, XG
AF Luo, Zhongjin
   Du, Dong
   Zhu, Heming
   Yu, Yizhou
   Fu, Hongbo
   Han, Xiaoguang
TI <i>SketchMetaFace:</i> A Learning-Based Sketching Interface for
   High-Fidelity 3D Character Face Modeling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Solid modeling; Faces; Shape; Load modeling;
   Computational modeling; Image reconstruction; Face modeling; neural
   network; sketch-based 3D modeling
AB Modeling 3D avatars benefits various application scenarios such as AR/VR, gaming, and filming. Character faces contribute significant diversity and vividity as a vital component of avatars. However, building 3D character face models usually requires a heavy workload with commercial tools, even for experienced artists. Various existing sketch-based tools fail to support amateurs in modeling diverse facial shapes and rich geometric details. In this article, we present SketchMetaFace - a sketching system targeting amateur users to model high-fidelity 3D faces in minutes. We carefully design both the user interface and the underlying algorithm. First, curvature-aware strokes are adopted to better support the controllability of carving facial details. Second, considering the key problem of mapping a 2D sketch map to a 3D model, we develop a novel learning-based method termed "Implicit and Depth Guided Mesh Modeling" (IDGMM). It fuses the advantages of mesh, implicit, and depth representations to achieve high-quality results with high efficiency. In addition, to further support usability, we present a coarse-to-fine 2D sketching interface design and a data-driven stroke suggestion tool. User studies demonstrate the superiority of our system over existing modeling tools in terms of the ease to use and visual quality of results. Experimental analyses also show that IDGMM reaches a better trade-off between accuracy and efficiency.
C1 [Luo, Zhongjin; Du, Dong; Zhu, Heming; Han, Xiaoguang] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen 518172, Peoples R China.
   [Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 The Chinese University of Hong Kong, Shenzhen; University of Hong Kong;
   City University of Hong Kong
RP Han, XG (corresponding author), Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen 518172, Peoples R China.
EM 220019015@link.cuhk.edu.cn; dongdu@mail.ustc.edu.cn;
   hezhu@mpi-inf.mpg.de; yizhouy@acm.org; fuplus@gmail.com;
   hanxiaoguang@cuhk.edu.cn
RI Du, Dong/AEG-5685-2022; /F-3345-2010
OI Du, Dong/0000-0001-5481-389X; FU, Hongbo/0000-0002-0284-726X; Zhu,
   Heming/0000-0003-3525-9349; /0000-0002-0470-5548; Han,
   Xiaoguang/0000-0003-0162-3296
FU NSFC [62172348]; Project Hetao Shenzhen-HK S&T Cooperation Zone
   [HZQB-KCZYZ-2021067]; National Key R&D Program of China
   [2018YFB1800800]; Shenzhen Outstanding Talents Training Fund [202002];
   Guangdong Research Projects [2017ZT07X152, 2019CX01X104]; Guangdong
   Provincial Key Laboratory of Future Networks of Intelligence
   [2022B1212010001]; Key Area R&D Program of Guangdong Province
   [2018B030338001]; Outstanding Yound Fund of Guangdong Province
   [2023B1515020055]; Shenzhen General Project [JCYJ20220530143604010];
   Hong Kong Research Grants Council [HKU17206218]; Research Grants Council
   of the Hong Kong Special Administrative Region, China [CityU 11212119];
   Centre for Applied Computing and Interactive Media (ACIM) of School of
   Creative Media, CityU
FX This work was supported in part by NSFC under Grant 62172348,in part by
   the Basic Research Project under Grant HZQB-KCZYZ-2021067 through
   project Hetao Shenzhen-HK S&T Cooperation Zone, in part by the National
   Key R&D Program of China under Grant 2018YFB1800800, in part by the
   Shenzhen Outstanding Talents Training Fund under Grant 202002, in part
   by the Guangdong Research Projects under Grants 2017ZT07X152 and
   2019CX01X104, in part by the Guangdong Provincial Key Laboratory of
   Future Networks of Intelligence under Grant 2022B1212010001, in part by
   the Shenzhen Key Laboratory of Big Data and Artificial Intelligence
   under Grant ZDSYS201707251409055, in part by the Key Area R&D Program of
   Guangdong Province under Grant 2018B030338001, in part by Outstanding
   Yound Fund of Guangdong Province under Grant 2023B1515020055, in part by
   Shenzhen General Project under Grant JCYJ20220530143604010, in part by
   Hong Kong Research Grants Council under General Research Funds under
   Grant HKU17206218, in part by Research Grants Council of the Hong Kong
   Special Administrative Region, China under Grant CityU 11212119, and in
   part by the Centre for Applied Computing and Interactive Media (ACIM) of
   School of Creative Media, CityU.
CR Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   Bai ZQ, 2020, PROC CVPR IEEE, P5849, DOI 10.1109/CVPR42600.2020.00589
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bartier PM, 1996, COMPUT GEOSCI, V22, P795, DOI 10.1016/0098-3004(96)00021-0
   Bernhardt A., 2008, P EUR WORKSH SKETCH, P57
   Borosán P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366217
   Botsch M., 2004, P 2004 EUROGRAPHICSA, P185, DOI [10.1145/1057432.1057457, DOI 10.1145/1057432.1057457]
   Cai HR, 2021, Arxiv, DOI arXiv:2004.09190
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen SY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392386
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Cheng ZZ, 2022, LECT NOTES COMPUT SC, V13663, P303, DOI 10.1007/978-3-031-20062-5_18
   Chowdhury PN, 2022, INT CONF 3D VISION, P22, DOI 10.1109/3DV57658.2022.00015
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Delanoy J, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203197
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Du D, 2022, IEEE T VIS COMPUT GR, V28, P2415, DOI 10.1109/TVCG.2020.3030330
   Du D, 2021, COMPUT GRAPH FORUM, V40, P222, DOI 10.1111/cgf.14184
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Fan LB, 2013, COMPUT GRAPH FORUM, V32, P157, DOI 10.1111/cgf.12223
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Gingold Y., 2009, ACM SIGGRAPH ASIA, P1
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guillard B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13003, DOI 10.1109/ICCV48922.2021.01278
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Huang HB, 2017, IEEE T VIS COMPUT GR, V23, P2003, DOI 10.1109/TVCG.2016.2597830
   Iarussi E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2710026
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Isola P., 2017, P IEEE C COMP VIS PA, P1125, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Joshi N. A, 2008, Sustain. Bus. Manage., P49
   Karpenko OA, 2006, ACM T GRAPHIC, V25, P589, DOI 10.1145/1141911.1141928
   Kong Q. Wang, 2022, P ASIAN C COMPUTER V, P1522
   Li BQ, 2016, ACSR ADV COMPUT, V57, P47
   Li C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417763
   Li CL, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3238250
   Li CL, 2017, ACM T INFORM SYST, V36, DOI 10.1145/3091108
   Lipman Y., 2004, P 2004 EUROGRAPHICSA, P175, DOI DOI 10.1145/1057432.1057456
   Liu JF, 2009, COMPUT GRAPH FORUM, V28, P2104, DOI 10.1111/j.1467-8659.2009.01418.x
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Luo L, 2022, Arxiv, DOI arXiv:2209.09043
   Luo Zhongjin, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P854, DOI 10.1145/3472749.3474791
   Mallikarjun BR, 2021, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR46437.2021.00337
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239492, 10.1145/1276377.1276429]
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nishida G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925951
   Olsen L, 2011, IEEE COMPUT GRAPH, V31, P24, DOI 10.1109/MCG.2011.84
   Pan H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766990
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Qi AR, 2021, IEEE T IMAGE PROCESS, V30, P8595, DOI 10.1109/TIP.2021.3118975
   Qiu YD, 2021, PROC CVPR IEEE, P10231, DOI 10.1109/CVPR46437.2021.01010
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Schmidt A., 2009, ACM SIGGRAPH ASIA, P1
   Schmidt R., 2007, ACM SIGGRAPH 2007 courses, P43
   Shao C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185541
   Sharf A, 2006, COMPUT GRAPH FORUM, V25, P389, DOI 10.1111/j.1467-8659.2006.00958.x
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang Jiayun, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13808), P184, DOI 10.1007/978-3-031-25085-9_11
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wu QY, 2018, PROC CVPR IEEE, P7336, DOI 10.1109/CVPR.2018.00766
   Xiao YZ, 2022, AAAI CONF ARTIF INTE, P2839
   Xie XH, 2013, COMPUT GRAPH FORUM, V32, P233, DOI 10.1111/cgf.12200
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Xu P, 2023, IEEE T PATTERN ANAL, V45, P285, DOI 10.1109/TPAMI.2022.3148853
   Zhang SH, 2021, PROC CVPR IEEE, P6008, DOI 10.1109/CVPR46437.2021.00595
   Zhong Y, 2022, COMPUT GRAPH-UK, V106, P237, DOI 10.1016/j.cag.2022.06.005
   Zhong Y, 2021, IEEE T CIRC SYST VID, V31, P3518, DOI 10.1109/TCSVT.2020.3040900
   Zhong Y, 2020, INT CONF 3D VISION, P543, DOI 10.1109/3DV50981.2020.00064
NR 78
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5260
EP 5275
DI 10.1109/TVCG.2023.3291703
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400075
PM 37467083
DA 2024-08-05
ER

PT J
AU Wang, ZX
   Wang, PF
   Wang, PS
   Dong, QJ
   Gao, JJ
   Chen, SM
   Xin, SQ
   Tu, CH
   Wang, WP
AF Wang, Zixiong
   Wang, Pengfei
   Wang, Peng-Shuai
   Dong, Qiujie
   Gao, Junjie
   Chen, Shuangmin
   Xin, Shiqing
   Tu, Changhe
   Wang, Wenping
TI Neural-IMLS: Self-Supervised Implicit Moving Least-Squares Network for
   Surface Reconstruction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Implicit moving least squares; self-supervised neural network; surface
   reconstruction; implicit neural representations
AB Surface reconstruction is a challenging task when input point clouds, especially real scans, are noisy and lack normals. Observing that the Multilayer Perceptron (MLP) and the implicit moving least-square function (IMLS) provide a dual representation of the underlying surface, we introduce Neural-IMLS, a novel approach that directly learns a noise-resistant signed distance function (SDF) from unoriented raw point clouds in a self-supervised manner. In particular, IMLS regularizes MLP by providing estimated SDFs near the surface and helps enhance its ability to represent geometric details and sharp features, while MLP regularizes IMLS by providing estimated normals. We prove that at convergence, our neural network produces a faithful SDF whose zero-level set approximates the underlying surface due to the mutual learning mechanism between the MLP and the IMLS. Extensive experiments on various benchmarks, including synthetic and real scans, show that Neural-IMLS can reconstruct faithful shapes even with noise and missing parts. The source code can be found at https://github.com/bearprin/Neural-IMLS.
C1 [Wang, Zixiong; Wang, Pengfei; Dong, Qiujie; Gao, Junjie; Xin, Shiqing; Tu, Changhe] Shandong Univ, Sch Comp Sci & Technol, Jinan 251600, Peoples R China.
   [Wang, Peng-Shuai] Peking Univ, Wangxuan Inst Comp Technol, Beijing 100871, Peoples R China.
   [Chen, Shuangmin] Qingdao Univ Sci & Technol, Sch Informat & Technol, Qingdao 266101, Shandong, Peoples R China.
   [Wang, Wenping] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.
C3 Shandong University; Peking University; Qingdao University of Science &
   Technology; Texas A&M University System; Texas A&M University College
   Station
RP Xin, SQ (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 251600, Peoples R China.
EM zixiong_wang@outlook.com; 8144756@qq.com; wangps@hotmail.com;
   qiujie.jay.dong@gmail.com; gjjsdnu@163.com; csmqq@163.com;
   xinshiqing@sdu.edu.cn; chtu@sdu.edu.cn; wenping@tamu.edu
RI Wang, Zixiong/JBS-2459-2023
OI Wang, Zixiong/0000-0002-6170-7339; Xin, Shiqing/0000-0001-8452-8723;
   Dong, Qiujie/0000-0001-6271-2546; Wang, Peng-Shuai/0000-0001-9700-8188
FU National Key R#x0026;D Program of China [2022YFB3303200]; National
   Natural Science Foundation of China [62002190, 62272277]; Natural
   Science Foundation of Shandong Province [ZR2020MF036]
FX No Statement Available
CR Atzmon M., 2021, 9 INT C LEARN REPR
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Baorui M., 2021, P INT C MACH LEARN, P7246
   Ben-Shabat Y, 2022, PROC CVPR IEEE, P19301, DOI 10.1109/CVPR52688.2022.01872
   Berger M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451246
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Boulch Alexandre, 2022, IEEE C COMPUT VIS PA, P6302
   Calakli F, 2011, COMPUT GRAPH FORUM, V30, P1993, DOI 10.1111/j.1467-8659.2011.02058.x
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Chaton T, 2020, INT CONF 3D VISION, P190, DOI 10.1109/3DV50981.2020.00029
   Chen C, 2022, LECT NOTES COMPUT SC, V13663, P322, DOI 10.1007/978-3-031-20062-5_19
   Chen ZQ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530108
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Cohen-Steiner D, 2004, VISUAL COMPUT, V20, P4, DOI 10.1007/s00371-003-0217-z
   Erler Philipp, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P108, DOI 10.1007/978-3-030-58558-7_7
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Gropp A, 2020, PR MACH LEARN RES, V119
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Gschwandtner Michael, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P199, DOI 10.1007/978-3-642-24031-7_20
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Hanocka R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392415
   Hou F, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530096
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Huang JH, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555457
   Huang Z., 2022, Surface reconstruction from point clouds: A survey and a benchmark
   Huang ZY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322994
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kazhdan M, 2020, COMPUT GRAPH FORUM, V39, P173, DOI 10.1111/cgf.14077
   Kingma D. P., 2014, arXiv
   Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983
   Kolluri R, 2008, ACM T ALGORITHMS, V4, DOI 10.1145/1361192.1361195
   Laric O., 2012, Three D. Scans
   Lewiner T., 2003, Journal of Graphics Tools, V8, P1, DOI 10.1080/10867651.2003.10487582
   Li MY, 2016, COMPUT AIDED GEOM D, V48, P49, DOI 10.1016/j.cagd.2016.08.001
   Lipman Y., 2021, P INT C MACH LEARN, P6702
   Liu SL, 2021, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR46437.2021.00183
   Ma BR, 2022, PROC CVPR IEEE, P6316, DOI 10.1109/CVPR52688.2022.00622
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Metzer G, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459835
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Peng S., 2020, COMPUTER VISION ECCV
   Peng Songyou, 2021, NEURIPS, V34, P13032
   Rakotosaona MJ, 2021, PROC CVPR IEEE, P22, DOI 10.1109/CVPR46437.2021.00009
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Schroers C, 2014, COMPUT GRAPH FORUM, V33, P195, DOI 10.1111/cgf.12445
   Sellán S, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555441
   Sharma G., 2020, ECCV, P261
   Shen C, 2004, ACM T GRAPHIC, V23, P896, DOI 10.1145/1015706.1015816
   Sitzmann V, 2020, Adv. Neural. Inf. Process. Syst, V33, P7462
   Stutz D, 2018, Arxiv, DOI arXiv:1805.07290
   Sulzer R, 2024, Arxiv, DOI [arXiv:2301.13656, 10.48550/ARXIV.2301.13656]
   Tancik M., 2020, ADV NEURAL INFORM PR, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tang J. H., 2021, P ADV NEUR INF PROC, P12648
   Tang JP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6484, DOI 10.1109/ICCV48922.2021.00644
   Tsang Clement Fuji, 2022, KAOLIN PYTORCH LIB A
   Wang PS, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530087
   Wang YF, 2021, PROC CVPR IEEE, P374, DOI 10.1109/CVPR46437.2021.00044
   Williams F, 2021, PROC CVPR IEEE, P9944, DOI 10.1109/CVPR46437.2021.00982
   Williams F, 2019, PROC CVPR IEEE, P10122, DOI 10.1109/CVPR.2019.01037
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xie YH, 2022, COMPUT GRAPH FORUM, V41, P641, DOI 10.1111/cgf.14505
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
NR 66
TC 1
Z9 1
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5018
EP 5033
DI 10.1109/TVCG.2023.3284233
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400090
PM 37289616
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Burns, A
   Lee, C
   On, T
   Xiong, CY
   Peck, E
   Mahyar, N
AF Burns, Alyxander
   Lee, Christiana
   On, Thai
   Xiong, Cindy
   Peck, Evan
   Mahyar, Narges
TI From Invisible to Visible: Impacts of Metadata in Communicative Data
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Metadata; Encoding; Soft sensors; Stakeholders;
   Organizations; Data mining; trust; transparency; understanding;
   visualization
ID TRANSPARENCY; TRUST; PROVENANCE; KNOWLEDGE; SCIENCE
AB Leaving the context of visualizations invisible can have negative impacts on understanding and transparency. While common wisdom suggests that recontextualizing visualizations with metadata (e.g., disclosing the data source or instructions for decoding the visualizations' encoding) may counter these effects, the impact remains largely unknown. To fill this gap, we conducted two experiments. In Experiment 1, we explored how chart type, topic, and user goal impacted which categories of metadata participants deemed most relevant. We presented 64 participants with four real-world visualizations. For each visualization, participants were given four goals and selected the type of metadata they most wanted from a set of 18 types. Our results indicated that participants were most interested in metadata which explained the visualization's encoding for goals related to understanding and metadata about the source of the data for assessing trustworthiness. In Experiment 2, we explored how these two types of metadata impact transparency, trustworthiness and persuasiveness, information relevance, and understanding. We asked 144 participants to explain the main message of two pairs of visualizations (one with metadata and one without); rate them on scales of transparency and relevance; and then predict the likelihood that they were selected for a presentation to policymakers. Our results suggested that visualizations with metadata were perceived as more thorough than those without metadata, but similarly relevant, accurate, clear, and complete. Additionally, we found that metadata did not impact the accuracy of the information extracted from visualizations, but may have influenced which information participants remembered as important or interesting.
C1 [Burns, Alyxander] Mt Holyoke Coll, South Hadley, MA 01075 USA.
   [Lee, Christiana; On, Thai; Xiong, Cindy; Mahyar, Narges] Univ Massachusetts, Amherst, MA 01003 USA.
   [Peck, Evan] Bucknell Univ, Lewisburg, PA 17837 USA.
C3 Mount Holyoke College; University of Massachusetts System; University of
   Massachusetts Amherst; Bucknell University
RP Burns, A (corresponding author), Mt Holyoke Coll, South Hadley, MA 01075 USA.
EM ajburns@mtholyoke.edu; christianale@umass.edu; ton@umass.edu;
   cindy.xiong@cs.umass.edu; evan.peck@bucknell.edu; nmahyar@cs.umass.edu
OI Xiong Bearfield, Cindy/0000-0002-1451-4083
CR Adar E, 2021, IEEE T VIS COMPUT GR, V27, P946, DOI 10.1109/TVCG.2020.3030375
   Alarcon GM, 2020, SYSTEMS-BASEL, V8, DOI 10.3390/systems8030028
   Alharbi M, 2019, COMPUTERS, V8, DOI 10.3390/computers8010017
   [Anonymous], 2022, PROLIFIC
   [Anonymous], 2022, Qualtrics
   Bach B, 2017, IEEE COMPUT GRAPH, V37, P6, DOI 10.1109/MCG.2017.33
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bates D., 2015, Convergence, V12, P2, DOI DOI 10.18637/JSS.V067.I01
   Battle L, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209901
   Ben Wasike, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmab024
   Borenstein M., 2009, Introduction to Meta-Analysis, V1st
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Davis SB, 2021, INTERDISCIPL SCI REV, V46, P522, DOI 10.1080/03080188.2021.1872874
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Buneman P, 2001, LECT NOTES COMPUT SC, V1973, P316
   Burgess L. C., 2016, Building Trust in Information, P81
   Burns A, 2021, 2021 IEEE WORKSHOP ON VISUALIZATION FOR SOCIAL GOOD (VIS4GOOD 2021), P11, DOI 10.1109/VIS4Good54225.2021.00008
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Cao N., 2016, Overview of Text Visualization Techniques, P11
   Correll M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376222
   Costante E., 2011, 2011 Workshop on Socio-Technical Aspects in Security and Trust, P52, DOI 10.1109/STAST.2011.6059256
   Couper M., 1998, P SUR RES METH SECT, P41
   D'Ignazio C, 2020, STRONG IDEAS SERIES, P97
   Dork Marian., 2013, Conference on Human Factors in Computing Systems, P2189, DOI DOI 10.1145/2468356.2468739
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   Elhamdadi H, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P85, DOI 10.1109/BELIV57783.2022.00014
   Elliott KC, 2014, ENVIRON HEALTH PERSP, V122, P647, DOI 10.1289/ehp.1408107
   Figueiras A, 2014, IEEE INT CONF INF VI, P46, DOI 10.1109/IV.2014.79
   Finch H., 2005, Methodol.: Eur. J. Res. Methods Behav. Social Sci., V1
   Foote MQ, 2011, EDUC STUD MATH, V78, P45, DOI 10.1007/s10649-011-9309-2
   Frank Rebecca D., 2017, Proceedings of the Association for Information Science and Technology, V54, DOI 10.1002/pra2.2017.14505401012
   Fyfe P, 2016, VIC PERIOD REV, V49, P546, DOI 10.1353/vpr.2016.0039
   Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
   Greenland S, 2016, EUR J EPIDEMIOL, V31, P337, DOI 10.1007/s10654-016-0149-3
   Gunn Bill., 2019, ESSENTIAL ESSAYS VOL, V1, P257
   Hall CC, 2007, ORGAN BEHAV HUM DEC, V103, P277, DOI 10.1016/j.obhdp.2007.01.003
   HARAWAY D, 1988, FEMINIST STUD, V14, P575, DOI 10.2307/3178066
   Haroz S, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P46, DOI 10.1109/BELIV.2018.8634427
   Herve M., 2020, Package 'RVAideMemoire', P0
   Holmes AGD., 2020, Shanlax International Journal of Education, V8, P1, DOI [10.34293/education.v8i4.3232, DOI 10.34293/EDUCATION.V8I4.3232]
   Horvath R, 2016, APPL ECON, V48, P5625, DOI 10.1080/00036846.2016.1181833
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Jach HK, 2022, J EXP PSYCHOL GEN, V151, P934, DOI 10.1037/xge0001109
   Jaimes Luis G., 2013, Design, User Experience, and Usability. User Experience in Novel Technological Environments. Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8014, P520, DOI 10.1007/978-3-642-39238-2_57
   Kelton K, 2008, J AM SOC INF SCI TEC, V59, P363, DOI 10.1002/asi.20722
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kiernan M, 2018, HEALTH PSYCHOL, V37, P782, DOI 10.1037/hea0000631
   Kim Y.-S., 2019, P CHI C HUM FACT COM, P1
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Kizilcec RF, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2390, DOI 10.1145/2858036.2858402
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   LAMAL PA, 1990, J SOC BEHAV PERS, V5, P31
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Li N, 2018, JCOM-J SCI COMMUN, V17, DOI 10.22323/2.17020206
   Lin XL, 2016, COMPUT HUM BEHAV, V63, P264, DOI 10.1016/j.chb.2016.05.002
   Luo Y, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01541
   Mack K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445412
   Mayr E., 2019, EUROVIS WORKSHOP TRU, P25, DOI [10.2312/trvis.20191187, DOI 10.2312/TRVIS.20191187, DOI 10.2312/TRVIS.201911872]
   Munzel A, 2016, J RETAIL CONSUM SERV, V32, P96, DOI 10.1016/j.jretconser.2016.06.002
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nightingale Virginia., 2011, The Handbook of Media Audiences
   OReilly J., 2009, P INT BLAIS US C
   Ottley A., 2019, P IEEE EUR S VIS, P121
   Padilla L., 2021, Uncertainty Visualization, P1, DOI DOI 10.1002/9781118445112.STAT08296
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Pirson M, 2011, ORGAN SCI, V22, P1087, DOI 10.1287/orsc.1100.0581
   Pu X., 2021, P CHI C HUM FACT COM, P1
   Quispel A, 2016, INFORM VISUAL, V15, P238, DOI 10.1177/1473871615606478
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Romano A, 2020, HEALTH ECON, V29, P1482, DOI 10.1002/hec.4143
   Rowe WendyE., 2014, SAGE ENCY ACTION RES
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Salem M., 2015, Emerg. Policy Ethics Hum.-Robot Interaction
   Savin-Baden M., 2013, Qualitative Research: The essential guide to theory and practice
   Schnackenberg AK, 2016, J MANAGE, V42, P1784, DOI 10.1177/0149206314525202
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Setlur V, 2022, Arxiv, DOI arXiv:2203.08420
   Sigma Awards, Rough justice: How police are failing survivors of sexual assault
   Sigma Awards, Who gets to breathe clean air in new delhi?
   Sigma Awards, Land-grab universities: How expropriated indig- enous land became the foundation of the land-grant university system
   Sigma Awards, The COVID Tracking Project at The Atlantic
   Sigma Awards, Mapping makoko
   Sigma Awards, About the sigma awards
   Simmhan YL, 2005, SIGMOD REC, V34, P31, DOI 10.1145/1084805.1084812
   Sohn D, 2019, INT J ADVERT, V38, P824, DOI 10.1080/02650487.2018.1536507
   Steve H., 2022, Email communication
   Stokes C., 2021, P WORKSH EXPL OPP CH
   TAYLOR R, 1990, J DIAGN MED SONOG, V6, P219, DOI 10.1177/875647939000600404
   Thomas J, 2009, INFORM VISUAL, V8, P309, DOI 10.1057/ivs.2009.26
   Thompson CG, 2017, BASIC APPL SOC PSYCH, V39, P81, DOI 10.1080/01973533.2016.1277529
   van der Cruijsen CAB, 2010, J ECON PSYCHOL, V31, P388, DOI 10.1016/j.joep.2010.01.007
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Warne R.T., 2014, Practical Assessment, Research, and Evaluation, V19, P17, DOI [DOI 10.7275/SM63-7H70, 10.7275/sm63-7h70]
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Xiong C., 2019, 1 EUROVIS WORKSH TRU, P19
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Xu K, 2020, COMPUT GRAPH FORUM, V39, P757, DOI 10.1111/cgf.14035
   Yakel E., 2013, International Journal of Digital Curation, V8, P143, DOI DOI 10.2218/IJDC.V8I1.251
NR 104
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3427
EP 3443
DI 10.1109/TVCG.2022.3231716
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700066
PM 37015379
DA 2024-08-05
ER

PT J
AU Cortes, CAT
   Thurow, S
   Ong, A
   Sharples, JJ
   Bednarz, T
   Stevens, G
   Favero, DD
AF Cortes, Carlos A. Tirado
   Thurow, Susanne
   Ong, Alex
   Sharples, Jason J.
   Bednarz, Tomasz
   Stevens, Grant
   Favero, Dennis Del
TI Analysis of Wildfire Visualization Systems for Research and Training:
   Are They Up for the Challenge of the Current State of Wildfires?
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Immersive wildfire training; immersive wildfire visualization;
   modelling; simulation; wildfire; wildfire visualization
ID VIRTUAL-REALITY; SIMULATION; DYNAMICS; DESIGN
AB Wildfires affect many regions across the world. The accelerated progression of global warming has amplified their frequency and scale, deepening their impact on human life, the economy, and the environment. The temperature rise has been driving wildfires to behave unpredictably compared to those previously observed, challenging researchers and fire management agencies to understand the factors behind this behavioral change. Furthermore, this change has rendered fire personnel training outdated and lost its ability to adequately prepare personnel to respond to these new fires. Immersive visualization can play a key role in tackling the growing issue of wildfires. Therefore, this survey reviews various studies that use immersive and non-immersive data visualization techniques to depict wildfire behavior and train first responders and planners. This paper identifies the most useful characteristics of these systems. While these studies support knowledge creation for certain situations, there is still scope to comprehensively improve immersive systems to address the unforeseen dynamics of wildfires.
C1 [Cortes, Carlos A. Tirado; Thurow, Susanne; Ong, Alex; Favero, Dennis Del] Univ New South Wales, iCinema Res Ctr, Kensington, NSW 2052, Australia.
   [Sharples, Jason J.] Univ New South Wales, Sch Sci, Canberra, ACT 2600, Australia.
   [Stevens, Grant] Univ New South Wales, Sch Art & Design, Paddington, NSW 2021, Australia.
C3 University of New South Wales Sydney; University of New South Wales
   Sydney; University of New South Wales Sydney
RP Cortes, CAT (corresponding author), Univ New South Wales, iCinema Res Ctr, Kensington, NSW 2052, Australia.
EM c.tirado@unsw.edu.au; s.thurow@unsw.edu.au; alex.ong@unsw.edu.au;
   j.sharples@adfa.edu.au; tomasz.bednarz@gmail.com;
   grant.stevens@unsw.edu.au; d.delfavero@unsw.edu.au
RI Tirado Cortes, Carlos Alfredo/HGB-5257-2022; Bednarz, Tomasz/A-7376-2011
OI Tirado Cortes, Carlos Alfredo/0000-0003-0626-0914; Del Favero,
   Dennis/0000-0002-6761-0992; Bednarz, Tomasz/0000-0001-9240-0922;
   Sharples, Jason/0000-0002-7816-6989
FU Australian Government through the Australian Research Councils Laureate
   funding scheme [FL200100004]
FX This work was supported by the Australian Government through the
   Australian Research Councils Laureate funding scheme under Grant
   FL200100004.
CR A4VR, 2022, Flamecoachs
   Abouali A, 2021, COMBUST FLAME, V234, DOI 10.1016/j.combustflame.2021.111724
   Abram NJ, 2021, COMMUN EARTH ENVIRON, V2, DOI 10.1038/s43247-020-00065-8
   Altintas I, 2015, PROCEDIA COMPUT SCI, V51, P1633, DOI 10.1016/j.procs.2015.05.296
   Anthes C., 2016, P IEEE AER C P, P1
   Badlan RL, 2021, INT J WILDLAND FIRE, V30, P484, DOI 10.1071/WF20040
   Badlan RL, 2021, INT J WILDLAND FIRE, V30, P498, DOI 10.1071/WF20041
   Bednarz T., 2011, P 10 INT C VIRT REAL, P459, DOI [DOI 10.1145/2087756.2087845, 10.1145/2087756, DOI 10.1145/2087756]
   Berntsen K., 2016, Proceedings ofthe Fourth International Conference on Technological Ecosystemsfor Enhancing Multiculturality, P435, DOI [10.1145/3012430.3012553, DOI 10.1145/3012430.3012553]
   Billen MI, 2008, COMPUT GEOSCI-UK, V34, P1056, DOI 10.1016/j.cageo.2007.11.009
   Black J., 2007, Transactions in GIS, V11, P621, DOI 10.1111/j.1467-9671.2007.01063.x
   Bogdos N, 2013, ENVIRON MODELL SOFTW, V46, P182, DOI 10.1016/j.envsoft.2013.03.009
   Bot K, 2022, INVENTIONS-BASEL, V7, DOI 10.3390/inventions7010015
   Braun P., 2022, Virtual Reality Intell. Hardware, V4, P406
   Bryce R., 2010, Information Report NOR-X-417
   Byari M, 2022, CHAOS SOLITON FRACT, V164, DOI 10.1016/j.chaos.2022.112653
   Calandra D, 2023, VIRTUAL REAL-LONDON, V27, P985, DOI 10.1007/s10055-022-00704-9
   Calkin DE, 2021, FORESTS, V12, DOI 10.3390/f12101407
   Castellnou M, 2018, ADVANCES IN FOREST FIRE RESEARCH 2018, P447, DOI 10.14195/978-989-26-16-506_48
   Castellnou M, 2019, FIRE ECOL, V15, DOI 10.1186/s42408-019-0048-6
   Castrillón M, 2011, COMPUT GEOSCI-UK, V37, P390, DOI 10.1016/j.cageo.2010.04.011
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen HS, 2021, AUTOMAT CONSTR, V125, DOI 10.1016/j.autcon.2021.103631
   Chen S. Y., 2022, Front. Psychol., V13
   Chertoff DB, 2010, P IEEE VIRT REAL ANN, P103, DOI 10.1109/VR.2010.5444804
   Clifford R. M., 2018, P IEEE 10 INT C VIRT, P1
   Clifford R. M. S., 2020, Ph.D. dissertation
   Clifford RMS, 2021, VISUAL COMPUT, V37, P63, DOI 10.1007/s00371-020-01816-6
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   Clifford RMS, 2018, 2018 IEEE WORKSHOP ON AUGMENTED AND VIRTUAL REALITIES FOR GOOD (VAR4GOOD)
   Coen JL, 2018, ECOL APPL, V28, P1565, DOI 10.1002/eap.1752
   Coen JL, 2013, J APPL METEOROL CLIM, V52, P16, DOI 10.1175/JAMC-D-12-023.1
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Crawl D, 2017, PROCEDIA COMPUT SCI, V108, P2230, DOI 10.1016/j.procs.2017.05.174
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Daylamani-Zad D, 2022, INT J HUM-COMPUT ST, V162, DOI 10.1016/j.ijhcs.2022.102790
   Denham MM, 2022, ENVIRON MODELL SOFTW, V158, DOI 10.1016/j.envsoft.2022.105526
   Desmond M, 2011, QUAL SOCIOL, V34, P59, DOI 10.1007/s11133-010-9176-7
   Diamond R.M., 1989, DESIGNING IMPROVING
   Bui DT, 2019, J ENVIRON MANAGE, V237, P476, DOI 10.1016/j.jenvman.2019.01.108
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Doroudian S, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P378, DOI 10.1109/VRW55335.2022.00085
   Dwyer G, 2021, AUST J PUBL ADMIN, V80, P602, DOI 10.1111/1467-8500.12476
   Ens B., 2021, P ACM C HUMAN FACTOR, DOI 10.1145/3411764.3446866
   ETC Simulation, 2023, "Advanced disaster management simulator
   Ewer J., 2010, P 5 EUR C COMP FLUID, P14
   Favero D. D., 2021, Theatre Perform. Des., V7, P82, DOI [10.1080/23322551.2021.1919488, DOI 10.1080/23322551.2021.1919488]
   Finney M., 1995, P BISW S FIR ISS SOL, P55
   Finney MA, 2002, CAN J FOREST RES, V32, P1420, DOI 10.1139/X02-068
   FLAIM Systems Pty Ltd, 2023, FLAIM: Fully immersive VR learning solutions for training in hazardous and emergency situations
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Gabbert B., 2020, Wildfire Today
   Galati A, 2021, IEEE T VIS COMPUT GR, V27, P2714, DOI 10.1109/TVCG.2021.3067693
   Grabowski A, 2021, FIRE SAFETY J, V125, DOI 10.1016/j.firesaf.2021.103440
   Green S., 2014, P ACM SIGGRAPH COMP, P1, DOI [10.1145/2633956.2658828, DOI 10.1145/2633956.2658828]
   Hädrich T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459954
   Han YC, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519903
   Haskins J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P57, DOI [10.1109/VRW50115.2020.0-258, 10.1109/VRW50115.2020.00018]
   Heirman J, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P266, DOI 10.1109/AIVR50618.2020.00055
   Hilton JE, 2015, ENVIRON MODELL SOFTW, V67, P118, DOI 10.1016/j.envsoft.2015.01.015
   Hoang RV, 2010, COMPUT GRAPH-UK, V34, P655, DOI 10.1016/j.cag.2010.09.014
   Hodges JL, 2019, FIRE TECHNOL, V55, P2115, DOI 10.1007/s10694-019-00846-4
   Huang H., 2012, P 20 INT C GEOINF, P1
   Jarvis C., 2021, Interactive Data Processing and 3D Visualization of the Solid Earth, P273, DOI [10.1007/978-3-030-90716-7_8, DOI 10.1007/978-3-030-90716-7_8]
   Jeon SG, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364268
   Kalabokidis K, 2016, NAT HAZARD EARTH SYS, V16, P643, DOI 10.5194/nhess-16-643-2016
   Keefe DF, 2009, IEEE T VIS COMPUT GR, V15, P1383, DOI 10.1109/TVCG.2009.152
   KESSEN W, 1966, SCIENCE, V152, P193, DOI 10.1126/science.152.3719.193
   Kim YS, 2006, COMPUT IND, V57, P653, DOI 10.1016/j.compind.2006.02.005
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376675
   Kyron MJ, 2022, ARCH ENVIRON OCCUP H, V77, P282, DOI 10.1080/19338244.2021.1893631
   Lareau NP, 2018, GEOPHYS RES LETT, V45, P13107, DOI 10.1029/2018GL080667
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Lee J., 2010, P 9 ACM SIGGRAPH C V, P299, DOI [10.1145/1900179.1900242, DOI 10.1145/1900179.1900242]
   Lee SC, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19116633
   Leuenberger M, 2018, ENVIRON MODELL SOFTW, V101, P194, DOI 10.1016/j.envsoft.2017.12.019
   Li N, 2022, NAT HAZARDS, V112, P1851, DOI 10.1007/s11069-022-05277-z
   Lino H, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489957
   Liu DL, 2021, J LOSS PREVENT PROC, V71, DOI 10.1016/j.jlp.2021.104505
   Liu DL, 2019, FIRE SAFETY J, V109, DOI 10.1016/j.firesaf.2019.102863
   Liu H., 2021, P IEEE 4 INT EL EN C, P1
   Liu RC, 2021, BIOINFORMATICS, V37, P2033, DOI 10.1093/bioinformatics/btab052
   Lorusso P, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12020223
   Ludus Tech S.L., 2023, Ludus: Virtual reality training for organizations
   Ma C, 2022, GEOSCIENCES, V12, DOI 10.3390/geosciences12060237
   Mandel J, 2014, NAT HAZARD EARTH SYS, V14, P2829, DOI 10.5194/nhess-14-2829-2014
   Manjrekar S, 2014, UKSIM INT CONF COMP, P131, DOI 10.1109/UKSim.2014.20
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P259, DOI 10.1007/978-3-030-01388-2_9
   McCormick PS, 1998, IEEE COMPUT GRAPH, V18, P17, DOI 10.1109/38.656785
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   Mcrae RHD, 2015, NAT HAZARD EARTH SYS, V15, P417, DOI 10.5194/nhess-15-417-2015
   Mcrae RHD, 2013, NAT HAZARDS, V65, P1801, DOI 10.1007/s11069-012-0443-7
   Meng QK, 2023, COMPUT GRAPH-UK, V110, P58, DOI 10.1016/j.cag.2022.12.002
   Morélot S, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104145
   Mossel A, 2021, VIRTUAL REAL-LONDON, V25, P745, DOI 10.1007/s10055-020-00487-x
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Mystakidis S, 2022, EDUC SCI, V12, DOI 10.3390/educsci12040281
   NAFZCO, 2022, Protected by Naffco
   Nahavandi S., 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P11, DOI 10.1007/978-3-030-22871-2_2
   Narciso D, 2023, IEEE T VIS COMPUT GR, V29, P3238, DOI 10.1109/TVCG.2022.3156734
   Narciso D, 2020, MULTIMED TOOLS APPL, V79, P6227, DOI 10.1007/s11042-019-08323-4
   Nur AS, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14174416
   O'Malley N., 2020, The Sydney Morning Herald, P3
   ONEBONSAI, 2023, VR fire training
   Pedram S., 2021, Front. Virtual Reality, V2, P7, DOI [10.3389/frvir.2021.627333/full, DOI 10.3389/FRVIR.2021.627333/FULL]
   Peterson DA, 2021, NPJ CLIM ATMOS SCI, V4, DOI 10.1038/s41612-021-00192-9
   Peterson DA, 2018, NPJ CLIM ATMOS SCI, V1, DOI 10.1038/s41612-018-0039-3
   Pinto D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P130, DOI 10.1109/ICGI47575.2019.8955091
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814
   Preston A, 2019, IEEE COMPUT GRAPH, V39, P72, DOI 10.1109/MCG.2019.2918158
   Pyne StevenJ., 2021, PYROCENE WE CREATED
   RE-liON Group BV, 2022, RE-liON for fire & rescue
   Reality in Virtual Reality Limited, 2021, RiVR
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   Rhyne TM, 2021, IEEE COMPUT GRAPH, V41, P125, DOI 10.1109/MCG.2021.3075258
   Richards L., 2020, 2019-20 Australian bushfires- frequently asked questions: A quick guide
   Rink K, 2020, J HYDROL, V582, DOI 10.1016/j.jhydrol.2019.124507
   Rosenthal A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248617
   Saghafian M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.593466
   Salehi M, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P245, DOI 10.1145/2939672.2939685
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Schumaker NH, 2022, LAND-BASEL, V11, DOI 10.3390/land11081288
   Scott J. H., 2013, Tech. Rep. 315 RMRS-GTR
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Seydi ST, 2022, ECOL INDIC, V140, DOI 10.1016/j.ecolind.2022.108999
   Sha Alan, 2021, Design for TomorrowVolume 2. Proceedings of ICoRD 2021. Smart Innovation, Systems and Technologies (SIST 222), P829, DOI 10.1007/978-981-16-0119-4_67
   Sharma SK, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14071645
   Sharples J. J., 2010, P 6 INT C FOR FIR RE, P15
   Sharples JJ, 2020, FRONT MECH ENG-SWITZ, V5, DOI 10.3389/fmech.2019.00069
   Sharples JJ, 2016, CLIMATIC CHANGE, V139, P85, DOI 10.1007/s10584-016-1811-1
   Shen SJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.597487
   Shuai Yun, 2011, Proceedings of the 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services (ICSDM 2011), P315, DOI 10.1109/ICSDM.2011.5969054
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Simpson CC, 2013, INT J WILDLAND FIRE, V22, P599, DOI 10.1071/WF12072
   Soltani P., 2021, Research Anthology on Business Strategies, Health Factors, and Ethical Implications in Sports and eSports, P734, DOI [10.4018/978-1-7998-7707-3.ch041, DOI 10.4018/978-1-7998-7707-3.CH041]
   Storey MA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245132
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P399, DOI 10.1109/TVCG.2015.2467911
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Sullivan AL, 2009, INT J WILDLAND FIRE, V18, P387, DOI 10.1071/WF06144
   Sullivan AL, 2009, INT J WILDLAND FIRE, V18, P349, DOI 10.1071/WF06143
   Sullivan AL, 2009, INT J WILDLAND FIRE, V18, P369, DOI 10.1071/WF06142
   Piralilou ST, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030672
   Tedim F, 2018, FIRE-BASEL, V1, DOI 10.3390/fire1010009
   Tolhurst K, 2008, AUST J EMERG MANAG, V23, P47
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Trucchia A, 2022, FIRE-BASEL, V5, DOI 10.3390/fire5010030
   Trucchia A, 2020, FIRE-BASEL, V3, DOI 10.3390/fire3030026
   Vahdatikhaki F, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102853
   van Dam A, 2002, COMPUT GRAPH-UK, V26, P535, DOI 10.1016/S0097-8493(02)00113-9
   Visner M, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11020037
   VR Vision Group, 2021, Alchemy systems fire safety VR training
   VSTEP BV, Response simulator
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   Wahlqvist J, 2021, SAFETY SCI, V136, DOI 10.1016/j.ssci.2020.105145
   Waidelich S, 2018, J COMPUT SCI TECHNOL, V18, P239, DOI 10.24215/16666038.18.e27
   Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071
   Wang Z., 2017, P 4 ACM WORKSH MAN M, P19, DOI [10.1145/3080546.3080549, DOI 10.1145/3080546.3080549]
   Wang ZJ, 2023, VIRTUAL REAL-LONDON, V27, P1145, DOI 10.1007/s10055-022-00718-3
   Weir J., 2017, P BUSHF NAT HAZ CRC
   Weissker Tim, 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2524, DOI 10.1109/TVCG.2021.3067756
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Wijkmark C. H., 2022, P 1 IEEE INT C COGN
   Wildfire Training Solutions Inc, 2022, Lorby wildfire response
   Williams BJ, 2013, FOREST ECOL MANAG, V294, P107, DOI 10.1016/j.foreco.2012.12.008
   Williams-Bell FM, 2015, FIRE TECHNOL, V51, P553, DOI 10.1007/s10694-014-0398-1
   Witt P. W., 1954, Audiovisual Commun. Rev., V2, P291
   WOLFRAM S, 1984, NATURE, V311, P419, DOI 10.1038/311419a0
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu R, 2016, IEEE IND ELEC, P4964, DOI 10.1109/IECON.2016.7793478
   Xi MZ, 2014, 2014 IEEE VIRTUAL REALITY (VR), P139, DOI 10.1109/VR.2014.6802090
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Xu L, 2021, J MANAGE ENG, V37, DOI 10.1061/(ASCE)ME.1943-5479.0000879
   Xu Z, 2014, ADV ENG SOFTW, V68, P1, DOI 10.1016/j.advengsoft.2013.10.004
   XVR Simulation B.V, 2021, XVR simulation platform
   Yan FT, 2020, MULTIMED TOOLS APPL, V79, P31541, DOI 10.1007/s11042-020-08863-0
   Yang L, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P453, DOI 10.1109/CIC.2018.00068
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   You JW, 2022, COMPUT GRAPH-UK, V103, P109, DOI 10.1016/j.cag.2022.01.009
   Yu XH, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12101523
   Zhang Q, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020397
   Zhou XJ, 2021, VIRTUAL REAL-LONDON, V25, P421, DOI 10.1007/s10055-020-00465-3
NR 186
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4285
EP 4303
DI 10.1109/TVCG.2023.3258440
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700046
PM 37030767
DA 2024-08-05
ER

PT J
AU Di Giacomo, E
   Didimo, W
   Liotta, G
   Montecchiani, F
   Tappini, A
AF Di Giacomo, Emilio
   Didimo, Walter
   Liotta, Giuseppe
   Montecchiani, Fabrizio
   Tappini, Alessandra
TI Comparative Study and Evaluation of Hybrid Visualizations of Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Analytical models; Layout; Computational
   modeling; Social networking (online); Sparse matrices; Evaluation;
   hybrid visualizations; network visualization; user study
ID COMMUNITY; NETWORK; ALGORITHMS; CHORDLINK; NODETRIX; USER
AB Hybrid visualizations combine different metaphors into a single network layout, in order to help humans in finding the "right way" of displaying the different portions of the network, especially when it is globally sparse and locally dense. We investigate hybrid visualizations in two complementary directions: (i) On the one hand, we evaluate the effectiveness of different hybrid visualization models through a comparative user study; (ii) On the other hand, we estimate the usefulness of an interactive visualization that integrates all the considered hybrid models together. The results of our study provide some hints about the usefulness of the different hybrid visualizations for specific tasks of analysis and indicates that integrating different hybrid models into a single visualization may offer a valuable tool of analysis.
C1 [Di Giacomo, Emilio; Didimo, Walter; Liotta, Giuseppe; Montecchiani, Fabrizio; Tappini, Alessandra] Univ Perugia, Dept Engn, I-06123 Perugia, Italy.
C3 University of Perugia
RP Tappini, A (corresponding author), Univ Perugia, Dept Engn, I-06123 Perugia, Italy.
EM emilio.digiacomo@unipg.it; walter.didimo@unipg.it;
   giuseppe.liotta@unipg.it; fabrizio.montecchiani@unipg.it;
   alessandra.tappini@unipg.it
RI ; Liotta, Giuseppe/I-4638-2015
OI Tappini, Alessandra/0000-0001-9192-2067; Di Giacomo,
   Emilio/0000-0002-9794-1928; Montecchiani, Fabrizio/0000-0002-0543-8912;
   Liotta, Giuseppe/0000-0002-2886-9694
FU MIUR [20174LF3T8]
FX This work was supported in part by MIUR under Grant 20174LF3T8,
CR Abuthawabeh A., 2013, P 1 IEEE WORK C SOFT, P1
   Alper B., 2013, P 2013 ANN C HUM FAC, P483
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Angelini P., 2017, J. Graph Algorithms Appl., V21, P731, DOI DOI 10.7155/JGAA.00437
   Angelini P., 2020, PLANAR GRAPHS, P211
   Angelini P, 2020, ALGORITHMS, V13, DOI 10.3390/a13080194
   Angelini P, 2018, LECT NOTES COMPUT SC, V11282, P67, DOI 10.1007/978-3-030-04414-5_5
   Angori L, 2022, IEEE T VIS COMPUT GR, V28, P1288, DOI 10.1109/TVCG.2020.3016055
   Angori L, 2019, LECT NOTES COMPUT SC, V11904, P276, DOI 10.1007/978-3-030-35802-0_22
   [Anonymous], 2002, Testing For Normality, DOI 10.1201/9780203910894
   [Anonymous], 2015, NodeTrix Javascript
   Bach B, 2013, INT J SEMANT WEB INF, V9, P17, DOI 10.4018/ijswis.2013100102
   Bachmaier C, 2010, DISCRETE APPL MATH, V158, P159, DOI 10.1016/j.dam.2009.09.002
   Bar-Joseph Z., 2001, Bioinformatics, V17, P522
   Batagelj V, 2011, IEEE T VIS COMPUT GR, V17, P1587, DOI 10.1109/TVCG.2010.265
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Bedi P, 2016, WIRES DATA MIN KNOWL, V6, P115, DOI 10.1002/widm.1178
   Besa JJ, 2019, LEIBNIZ INT PR INFOR, V144, DOI 10.4230/LIPIcs.ESA.2019.19
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Burch M, 2021, IEEE ACCESS, V9, P4173, DOI 10.1109/ACCESS.2020.3047616
   Christensen Johanne, 2014, Smart Graphics. 12th International Symposium (SG 2014). Proceedings: LNCS 8698, P174, DOI 10.1007/978-3-319-11650-1_17
   Conover W.J., 1980, Practical nonparametric statistics, Vsecond
   Da Lozzo G., 2018, J. Graph Algorithms Appl., V22, P139, DOI [10.7155/jgaa.00461, DOI 10.7155/JGAA.00461]
   Di Giacomo Emilio, 2018, Graph Drawing and Network Visualization. 25th International Symposium, GD 2017. Revised Selected Papers: LNCS 10692, P479, DOI 10.1007/978-3-319-73915-1_37
   Di Giacomo E., 2021, INT S GRAPH DRAWING, P21
   Di Giacomo E, 2021, THEOR COMPUT SCI, V896, P19, DOI 10.1016/j.tcs.2021.09.044
   Di Giacomo E, 2019, ALGORITHMICA, V81, P3464, DOI 10.1007/s00453-019-00585-6
   Di Giacomo E, 2019, LECT NOTES COMPUT SC, V11355, P148, DOI 10.1007/978-3-030-10564-8_12
   Didimo Walter, 2008, Journal of Graph Algorithms and Applications, V12, P267, DOI 10.7155/jgaa.00167
   Didimo W, 2018, COMPUT GRAPH FORUM, V37, P288, DOI 10.1111/cgf.13266
   Didimo W, 2014, J VISUAL LANG COMPUT, V25, P433, DOI 10.1016/j.jvlc.2014.01.002
   Didimo W, 2014, INFORM SCIENCES, V260, P185, DOI 10.1016/j.ins.2013.09.048
   Dogrusoz U, 2009, INFORM SCIENCES, V179, P980, DOI 10.1016/j.ins.2008.11.017
   Duncan C. A., 2013, Handbook of Graph Drawing and Visualization, P223, DOI DOI 10.1201/B15385/HANDBOOK-GRAPH-DRAWING-VISUALIZATION-ROBERTO-TAMASSIA
   Flake GW, 2002, COMPUTER, V35, P66, DOI 10.1109/2.989932
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Hadlak S, 2011, IEEE T VIS COMPUT GR, V17, P2334, DOI 10.1109/TVCG.2011.213
   HAREL D, 1988, COMMUN ACM, V31, P514, DOI 10.1145/42411.42414
   Henry N, 2008, IEEE T VIS COMPUT GR, V14, P1317, DOI 10.1109/TVCG.2008.141
   Henry N, 2007, LECT NOTES COMPUT SC, V4663, P288
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Kaufmann M., 2001, DRAWING GRAPHS METHO
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kindermann P., 2022, P 38 EUR WORKSH COMP, P1
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Ley M., 2002, String Processing and Information Retrieval. 9th International Symposium, SPIRE 2002. Proceedings (Lecture Notes in Computer Science Vol.2476), P1
   Liotta G, 2022, LECT NOTES COMPUT SC, V13453, P383, DOI 10.1007/978-3-031-15914-5_28
   Liotta G, 2021, THEOR COMPUT SCI, V874, P59, DOI 10.1016/j.tcs.2021.05.012
   Liotta G, 2020, LECT NOTES COMPUT SC, V12011, P617, DOI 10.1007/978-3-030-38919-2_51
   Mahmoud H, 2014, LECT N BIOINFORMAT, V8452, P62, DOI 10.1007/978-3-319-09042-9_5
   Mangan S, 2003, P NATL ACAD SCI USA, V100, P11980, DOI 10.1073/pnas.2133841100
   Matuszewski C, 1999, LECT NOTES COMPUT SC, V1731, P217
   Melancon G., 2006, P AVI WORKSH TIM ERR, P1
   Muelder C, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P231
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Okoe M, 2015, COMPUT GRAPH FORUM, V34, P451, DOI 10.1111/cgf.12657
   Omote H, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P85
   Onnela JP, 2004, EUR PHYS J B, V38, P353, DOI 10.1140/epjb/e2004-00128-7
   Porter Mason A, 2009, Notices of the American Mathematical Society, V56, P1082, DOI DOI 10.1103/PHYSREVE.69.066133
   Purchase Helen C., 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P451, DOI 10.1007/978-3-642-36763-2_40
   Purchase H. C., 1997, ACM J. Exp. Algorithmics, V2
   Purchase H. C., 2012, Experimental Human -Computer Interaction: A Practical Guide with Visual Examples
   Purchase HC, 1998, J VISUAL LANG COMPUT, V9, P647, DOI 10.1006/jvlc.1998.0093
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Rufiange S, 2013, IEEE T VIS COMPUT GR, V19, P2556, DOI 10.1109/TVCG.2013.149
   Saket B, 2014, IEEE T VIS COMPUT GR, V20, P2231, DOI 10.1109/TVCG.2014.2346422
   Sindre G., 1993, Proceedings 1993 IEEE Symposium on Visual Languages (Cat. No.93TH0562-9), P287, DOI 10.1109/VL.1993.269613
   Stasko J., 2014, P 5 WORKSH TIM ERR N, P46, DOI [DOI 10.1145/2669557.26695792,9, 10.1145/2669557.2669579, DOI 10.1145/2669557.2669579]
   Stasko J., 2013, P POST IEEE INFOVIS
   Sugiyama K., 2002, GRAPH DRAWING APPL S
   van Dijk RE, 2014, ECOL LETT, V17, P1141, DOI 10.1111/ele.12320
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wu H, 2010, LECT NOTES COMPUT SC, V6215, P337
   Yang XS, 2017, IEEE T VIS COMPUT GR, V23, P181, DOI 10.1109/TVCG.2016.2598472
   Zhao SD, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2005.1532129
NR 77
TC 3
Z9 3
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3503
EP 3515
DI 10.1109/TVCG.2022.3233389
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700029
PM 37018276
OA hybrid
DA 2024-08-05
ER

PT J
AU Guo, JW
   Liu, YC
   Song, X
   Liu, HY
   Zhang, XP
   Cheng, ZL
AF Guo, Jianwei
   Liu, Yanchao
   Song, Xin
   Liu, Haoyu
   Zhang, Xiaopeng
   Cheng, Zhanglin
TI Line-Based 3D Building Abstraction and Polygonal Surface Reconstruction
   From Images
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 3D reconstruction; 3D line cloud; scene abstraction; polygonal mesh
   model
ID STRUCTURE-FROM-MOTION; STEREO; REPRESENTATION; SCENE; EDGE
AB Textureless objects, repetitive patterns and limited computational resources pose significant challenges to man-made structure reconstruction from images, because feature-points-based reconstruction methods usually fail due to the lack of distinct texture or ambiguous point matches. Meanwhile multi-view stereo approaches also suffer from high computational complexity. In this article, we present a new framework to reconstruct 3D surfaces for buildings from multi-view images by leveraging another fundamental geometric primitive: line segments. To this end, we first propose a new multi-resolution line segment detector to extract 2D line segments from each image. Then, we construct a 3D line cloud by introducing an improved Line3D++ algorithm to match 2D line segments from different images. Finally, we reconstruct a complete and manifold surface mesh from 3D line segments by formulating a Bayesian probabilistic modeling problem, which accurately generates a set of underlying planes. This output model is simple and has low performance requirements for hardware devices. Experimental results demonstrate the validity of the proposed approach and its ability to generate abstract and compact surface meshes from the 3D line cloud with low computational costs.
C1 [Guo, Jianwei; Liu, Yanchao; Liu, Haoyu; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Liu, Yanchao; Liu, Haoyu] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
   [Song, Xin; Cheng, Zhanglin] Chinese Acad Sci, Shenzhen Inst Adv Technol SIAT, Shenzhen Key Lab Visual Comp & Analyt VisuCA, Shenzhen 518055, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Cheng, ZL (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol SIAT, Shenzhen Key Lab Visual Comp & Analyt VisuCA, Shenzhen 518055, Peoples R China.
EM jianwei.guo@nlpr.ia.ac.cn; liuyanchao18@mails.ucas.ac.cn;
   xinsong.1990@gmail.com; liuhaoyu2020@ia.ac.cn; xiaopeng.zhang@ia.ac.cn;
   zhanglin.cheng@gmail.com
OI Liu, Yanchao/0000-0002-2571-7628; Cheng, Zhanglin/0000-0002-3360-2679
FU National Natural Science Foundation of China [62172416, U22B2034,
   U21A20515, 61972388]; Shenzhen Science and Technology Program
   [JCYJ20180507182222355, GJHZ20210705141402008]; Youth Innovation
   Promotion Association of the Chinese Academy of Sciences [2022131]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62172416, U22B2034, U21A20515 and
   61972388, in part by Shenzhen Science and Technology Program under
   Grants JCYJ20180507182222355 and GJHZ20210705141402008, and in part by
   the Youth Innovation Promotion Association of the Chinese Academy of
   Sciences under Grant 2022131.
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Almazàn EJ, 2017, PROC CVPR IEEE, P5854, DOI 10.1109/CVPR.2017.620
   Araújo AMC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107115
   Baillard C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P559, DOI 10.1109/CVPR.1999.784966
   Baillard C., 1999, Conference on Automatic Extraction of GIS Objects from Digital Imagery, IAPRS, V32, P69
   Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001
   Bay H, 2005, PROC CVPR IEEE, P329
   Bay H, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P496
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Boulch A, 2014, COMPUT GRAPH FORUM, V33, P55, DOI 10.1111/cgf.12431
   Bullen P. S., 2013, Handbook of means and their inequalities
   Chen JY, 2003, PATTERN RECOGN, V36, P943, DOI 10.1016/S0031-3203(02)00128-0
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Elqursh A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3049, DOI 10.1109/CVPR.2011.5995512
   Fabbri R, 2016, INT J COMPUT VISION, V120, P324, DOI 10.1007/s11263-016-0912-7
   Fuhrmann S, 2015, COMPUT GRAPH-UK, V53, P44, DOI 10.1016/j.cag.2015.09.003
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Gu Y., 2013, P 5 HIGH PERF GRAPH, P81
   Vu HH, 2012, IEEE T PATTERN ANAL, V34, P889, DOI 10.1109/TPAMI.2011.172
   Hofer Manuel, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P535, DOI 10.1109/3DV.2014.14
   Hofer M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.92
   Hofer M, 2017, COMPUT VIS IMAGE UND, V157, P167, DOI 10.1016/j.cviu.2016.03.017
   Hofer M, 2015, LECT NOTES COMPUT SC, V9358, P237, DOI 10.1007/978-3-319-24947-6_19
   Jain A, 2010, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2010.5539781
   Kaiser A, 2019, COMPUT GRAPH FORUM, V38, P167, DOI 10.1111/cgf.13451
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Lafarge F, 2010, IEEE T IMAGE PROCESS, V19, P1683, DOI 10.1109/TIP.2010.2045695
   Langlois PA, 2019, INT CONF 3D VISION, P553, DOI 10.1109/3DV.2019.00067
   Li ML, 2016, LECT NOTES COMPUT SC, V9908, P54, DOI 10.1007/978-3-319-46493-0_4
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Limberger FA, 2015, PATTERN RECOGN, V48, P2043, DOI 10.1016/j.patcog.2014.12.020
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Lu XH, 2015, IEEE IMAGE PROC, P507, DOI 10.1109/ICIP.2015.7350850
   Luo YC, 2022, Arxiv, DOI arXiv:2208.11948
   Micusik B, 2017, INT J COMPUT VISION, V124, P65, DOI 10.1007/s11263-016-0971-9
   Micusik B, 2015, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2015.7298936
   Monszpart A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766995
   Mullner D., 2011, PREPRINT, DOI 10.48550/ARXIV.1109.2378
   Mura C, 2014, COMPUT GRAPH-UK, V44, P20, DOI 10.1016/j.cag.2014.07.005
   Nan LL, 2017, IEEE I CONF COMP VIS, P2372, DOI 10.1109/ICCV.2017.258
   Nan LL, 2015, COMPUT GRAPH FORUM, V34, P217, DOI 10.1111/cgf.12554
   Ramalingam S, 2013, IEEE I CONF COMP VIS, P497, DOI 10.1109/ICCV.2013.67
   Salaün Y, 2016, LECT NOTES COMPUT SC, V9911, P801, DOI 10.1007/978-3-319-46478-7_49
   Schindler G, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P846
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417
   Smith Paul, 2006, Bellbird, V1, P17
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sugiura T, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P264, DOI 10.1109/3DV.2015.37
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang JL, 2016, IEEE T VIS COMPUT GR, V22, P1760, DOI 10.1109/TVCG.2015.2461163
   Witt J, 2014, IEEE INT CONF ROBOT, P2029, DOI 10.1109/ICRA.2014.6907128
   Wu C., 2011, VisualSFM: A visual structure from motion system
   Zebedin L, 2008, LECT NOTES COMPUT SC, V5305, P873, DOI 10.1007/978-3-540-88693-8_64
   Zhang G, 2015, IEEE T ROBOT, V31, P1364, DOI 10.1109/TRO.2015.2489498
   Zhang LL, 2014, J VIS COMMUN IMAGE R, V25, P904, DOI 10.1016/j.jvcir.2014.02.013
   Zhang L, 2022, IEEE T VIS COMPUT GR, V28, P2879, DOI 10.1109/TVCG.2020.3045450
   Zhao K, 2022, IEEE T PATTERN ANAL, V44, P4793, DOI 10.1109/TPAMI.2021.3077129
NR 66
TC 5
Z9 6
U1 6
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3283
EP 3297
DI 10.1109/TVCG.2022.3230369
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700063
PM 37015424
DA 2024-08-05
ER

PT J
AU Miandji, E
   Tongbuasirilai, T
   Hajisharif, S
   Kavoosighafi, B
   Unger, J
AF Miandji, Ehsan
   Tongbuasirilai, Tanaboon
   Hajisharif, Saghi
   Kavoosighafi, Behnaz
   Unger, Jonas
TI FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF
   Acquisition
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Dictionaries; Image reconstruction; Compressed sensing;
   Sensors; Optimization; Rendering (computer graphics); Rendering;
   compressed sensing; multiple measurement vector; SOMP; BRDF measurement;
   BRDF reconstruction
ID REFLECTANCE; ALGORITHMS; RECOVERY; FIELD
AB Efficient and accurate BRDF acquisition of real world materials is a challenging research problem that requires sampling millions of incident light and viewing directions. To accelerate the acquisition process, one needs to find a minimal set of sampling directions such that the recovery of the full BRDF is accurate and robust given such samples. In this article, we formulate BRDF acquisition as a compressed sensing problem, where the sensing operator is one that performs sub-sampling of the BRDF signal according to a set of optimal sample directions. To solve this problem, we propose the Fast and Robust Optimal Sampling Technique (FROST) for designing a provably optimal sub-sampling operator that places light-view samples such that the recovery error is minimized. FROST casts the problem of designing an optimal sub-sampling operator for compressed sensing into a sparse representation formulation under the Multiple Measurement Vector (MMV) signal model. The proposed reformulation is exact, i.e. without any approximations, hence it converts an intractable combinatorial problem into one that can be solved with standard optimization techniques. As a result, FROST is accompanied by strong theoretical guarantees from the field of compressed sensing. We perform a thorough analysis of FROST-BRDF using a 10-fold cross-validation with publicly available BRDF datasets and show significant advantages compared to the state-of-the-art with respect to reconstruction quality. Finally, FROST is simple, both conceptually and in terms of implementation, it produces consistent results at each run, and it is at least two orders of magnitude faster than the prior art.
C1 [Miandji, Ehsan] Linkoping Univ, Dept Sci & Technol, Comp Graph, S-58183 Linkoping, Sweden.
   [Hajisharif, Saghi] Linkoping Univ, Comp Graph & Image Proc CGIP Lab, S-58183 Linkoping, Sweden.
   [Kavoosighafi, Behnaz] Linkoping Univ, Comp Graph & Image Proc, S-58183 Linkoping, Sweden.
   [Unger, Jonas] Linkoping Univ, Comp Graph, S-58183 Linkoping, Sweden.
   [Tongbuasirilai, Tanaboon] Linkoping Univ, S-58183 Linkoping, Sweden.
   [Tongbuasirilai, Tanaboon] Kasetsart Univ, Bangkok 10900, Thailand.
C3 Linkoping University; Linkoping University; Linkoping University;
   Linkoping University; Linkoping University; Kasetsart University
RP Miandji, E (corresponding author), Linkoping Univ, Dept Sci & Technol, Comp Graph, S-58183 Linkoping, Sweden.
EM ehsan.miandji@liu.se; tanaboon.to@ku.th; saghi.hajisharif@liu.se;
   behnaz.kavoosighafi@liu.se; jonas.unger@liu.se
OI Unger, Jonas/0000-0002-7765-1747; Kavoosighafi,
   Behnaz/0000-0002-1951-7515; Hajisharif, Saghi/0000-0002-0176-5852;
   Tongbuasirilai, Tanaboon/0000-0002-3239-8581
FU European Union [956585]
FX This work was supported by European Union's Horizon 2020 research and
   innovation programme under the Marie Skodowska-Curie under Grant Grant
   956585 (PRIME).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aittala M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766967
   Bagher MM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2907941
   Ben-Artzi A, 2006, ACM T GRAPHIC, V25, P945, DOI 10.1145/1141911.1141979
   Bilgili A, 2011, COMPUT GRAPH FORUM, V30, P2427, DOI 10.1111/j.1467-8659.2011.02072.x
   Blanz V, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P293, DOI 10.1109/TDPVT.2004.1335212
   Boss M, 2019, Arxiv, DOI arXiv:1910.05148
   Boss M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12664, DOI 10.1109/ICCV48922.2021.01245
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen Z, 2022, IEEE T PATTERN ANAL, V44, P9380, DOI 10.1109/TPAMI.2021.3129537
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dupuy J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275059
   Elad M, 2007, IEEE T SIGNAL PROCES, V55, P5695, DOI 10.1109/TSP.2007.900760
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Ghosh A, 2010, INT J COMPUT VISION, V90, P183, DOI 10.1007/s11263-008-0151-7
   Guarnera D, 2016, COMPUT GRAPH FORUM, V35, P625, DOI 10.1111/cgf.12867
   Guo Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417779
   Hajisharif S, 2020, COMPUT GRAPH FORUM, V39, P463, DOI 10.1111/cgf.13944
   Han NN, 2021, IEEE SIGNAL PROC LET, V28, P1320, DOI 10.1109/LSP.2021.3089434
   Henzler P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480507
   Jakob W, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601139
   Kang KZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356492
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Kautz J, 1999, SPRING EUROGRAP, P247
   Kim J, 2020, IEEE T INFORM THEORY, V66, P5072, DOI 10.1109/TIT.2020.2986917
   Lavoué G, 2021, COMPUT GRAPH FORUM, V40, P327, DOI 10.1111/cgf.142636
   Lawrence J, 2004, ACM T GRAPHIC, V23, P496, DOI 10.1145/1015706.1015751
   Lensch H. P. A., 2005, P ACM SIGGRAPH 2005, P1
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Li ZQ, 2018, LECT NOTES COMPUT SC, V11207, P74, DOI 10.1007/978-3-030-01219-9_5
   Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262
   Löw J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077350
   Mannino M., 2016, P EUR WORKSH MAT APP, P19
   Marschner SR, 1999, SPRING EUROGRAP, P131
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Matusik W., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P241
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Miandji E., 2018, Ph.D. dissertation
   Miandji E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3269980
   Miandji E, 2017, IEEE SIGNAL PROC LET, V24, P1646, DOI 10.1109/LSP.2017.2753939
   Miandji E, 2015, COMPUT GRAPH FORUM, V34, P33, DOI 10.1111/cgf.12539
   Nicodemus F. E., 1992, Geometrical Considerations and Nomenclature for Reflectance, P94
   Nielsen JB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818085
   Otani H, 2019, LECT NOTES COMPUT SC, V11542, P483, DOI 10.1007/978-3-030-22514-8_48
   Peers P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477929
   Pharr M., 2010, PHYS BASED RENDERING
   Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63
   Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4
   Rubinstein R., 2012, Ph.D. dissertation
   Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11
   Sen P, 2011, IEEE T VIS COMPUT GR, V17, P487, DOI 10.1109/TVCG.2010.46
   Sen P, 2009, COMPUT GRAPH FORUM, V28, P609, DOI 10.1111/j.1467-8659.2009.01401.x
   Seylan N, 2013, WSCG 2013, FULL PAPERS PROCEEDINGS, P88
   Shi L, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417781
   Soler C, 2018, COMPUT GRAPH FORUM, V37, P135, DOI 10.1111/cgf.13348
   Sun TC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275026
   Sztrajman A, 2021, COMPUT GRAPH FORUM, V40, P332, DOI 10.1111/cgf.14335
   Tongbuasirilai T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3533427
   Tongbuasirilai T, 2020, VISUAL COMPUT, V36, P855, DOI 10.1007/s00371-019-01664-z
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944
   Wang RM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2557449
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   Xu YY, 2014, INVERSE PROBL IMAG, V8, P901, DOI 10.3934/ipi.2014.8.901
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Xu ZX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982396
   Zhou XL, 2021, COMPUT GRAPH FORUM, V40, P315, DOI 10.1111/cgf.142635
   Zupancic B., 2013, P SIGGRAPH AS 2013
NR 72
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4390
EP 4402
DI 10.1109/TVCG.2024.3355200
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700081
PM 38231803
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Pisha, L
   Yadegari, S
AF Pisha, Louis
   Yadegari, Shahrokh
TI Specular Path Generation and Near-Reflective Diffraction in Interactive
   Acoustical Simulations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Diffraction; Reflection; Computational modeling; Solid modeling;
   Acoustics; Real-time systems; Graphics processing units; graph and tree
   search strategies; neural nets; parallel algorithms; raytracing; virtual
   reality
ID SOUND-PROPAGATION; EDGE; MODEL
AB Most systems for simulating sound propagation in a virtual environment for interactive applications use ray- or path-based models of sound. With these models, the "early" (low-order) specular reflection paths play a key role in defining the "sound" of the environment. However, the wave nature of sound, and the fact that smooth objects are approximated by triangle meshes, pose challenges for creating realistic approximations of the reflection results. Existing methods which produce accurate results are too slow to be used in most interactive applications with dynamic scenes. This paper presents a method for reflections modeling called spatially sampled near-reflective diffraction (SSNRD), based on an existing approximate diffraction model, Volumetric Diffraction and Transmission (VDaT). The SSNRD model addresses the challenges mentioned above, produces results accurate to within 1-2 dB on average compared to edge diffraction, and is fast enough to generate thousands of paths in a few milliseconds in large scenes. This method encompasses scene geometry processing, path trajectory generation, spatial sampling for diffraction modeling, and a small deep neural network (DNN) to produce the final response of each path. All steps of the method are GPU-accelerated, and NVIDIA RTX real-time ray tracing hardware is used for spatial computing tasks beyond just traditional ray tracing.
C1 [Pisha, Louis; Yadegari, Shahrokh] Univ Calif San Diego, Sonic Arts Res & Dev Qualcomm Inst, San Diego, CA 92093 USA.
C3 University of California System; University of California San Diego
RP Pisha, L (corresponding author), Univ Calif San Diego, Sonic Arts Res & Dev Qualcomm Inst, San Diego, CA 92093 USA.
EM lpisha@ucsd.edu; sdy@ucsd.edu
OI Pisha, Louis A/0000-0001-5307-4263; Yadegari,
   Shahrokh/0000-0001-7617-2325
CR Agafonkin Volodymyr., 2019, Fast icosphere mesh
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   Anderson Richard J, 1991, P 23 ANN ACM S THEOR, P370, DOI [DOI 10.1145/103418.103458, 10.1145/103418.103458]
   Antani L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077348
   BIOT MA, 1957, J ACOUST SOC AM, V29, P381, DOI 10.1121/1.1908899
   Blender community, 2020, BMesh design document
   Botteldooren D, 1995, J ACOUST SOC AM, V98, P3302, DOI 10.1121/1.413817
   Calamia P.T., 2007, EURASIP J. Appl. Signal Process, V2007, P186
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Chaitanya CRA, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392459
   Clevert DA, 2016, Arxiv, DOI [arXiv:1511.07289, DOI 10.48550/ARXIV.1511.07289]
   Embrechts JJ, 2000, J ACOUST SOC AM, V107, P2068, DOI 10.1121/1.428489
   Evangelou I., 2021, Journal of Computer Graphics Techniques (JCGT), V10, P25
   Google, 2016, Resonance audio-fundamental concepts
   GOURAUD H, 1971, IEEE T COMPUT, VC 20, P623, DOI 10.1109/T-C.1971.223313
   Hrádek J, 2003, COMPUT GEOSCI-UK, V29, P741, DOI 10.1016/S0098-3004(03)00037-2
   Ioffe Sergey, 2015, INT C MACHINE LEARNI, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Kharya Paresh, 2020, TensorFloat-32 in the A100 GPUaccelerates AI training, HPC up to 20X
   KOUYOUMJIAN RG, 1974, P IEEE, V62, P1448, DOI 10.1109/PROC.1974.9651
   McDowell S, 2019, PyTorch C API
   Microsoft Game Dev, 2022, Project acoustics overview-what is projectacoustics?
   Morrical N, 2022, IEEE T VIS COMPUT GR, V28, P2852, DOI 10.1109/TVCG.2020.3042930
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Morrical S., 2021, Tracing Gems II, P625
   Morton G. M., 1966, International Business Machines Co
   Murphy D, 2007, IEEE SIGNAL PROC MAG, V24, P55, DOI 10.1109/MSP.2007.323264
   NVIDIA Corporation., 2022, CUDA zone
   NVIDIA Corporation, 2022, NVIDIA OptiX ray tracing engine
   NVIDIA Corporation, 2022, NVIDIA OptiX 7.4 programming guide: Accelera-tion structures
   NVIDIA Corporation, 2018, VRWorks-audio
   NVIDIA Corporation, 2022, NVIDIA RTX platform
   NVIDIA Corporation, 2017, VRWorks audio SDK in-depth
   Pisha L, 2020, J ACOUST SOC AM, V148, P1922, DOI 10.1121/10.0002115
   Pohl A., 2013, Ph.D. dissertation
   Raghuvanshi N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201339
   Rosen M, 2020, COMPUT GRAPH FORUM, V39, P39, DOI 10.1111/cgf.14099
   Saarelma J, 2018, 2018 AES INTERNATIONAL CONFERENCE ON SPATIAL REPRODUCTION - AESTHETICS AND SCIENCE
   Savioja L, 2015, J ACOUST SOC AM, V138, P708, DOI 10.1121/1.4926438
   Schissler C, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459751
   Schissler C, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2943779
   Schissler C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601216
   Schissler D., 2011, P AUD ENG SOC C 41 I, P1
   Schubert S, 2019, IEEE INT VEH SYM, P653, DOI [10.1109/ivs.2019.8813862, 10.1109/IVS.2019.8813862]
   Stephenson UM, 2010, ACTA ACUST UNITED AC, V96, P516, DOI 10.3813/AAA.918304
   Summers JE, 2013, J ACOUST SOC AM, V133, P3673, DOI 10.1121/1.4802650
   Svensson UP, 1999, J ACOUST SOC AM, V106, P2331, DOI 10.1121/1.428071
   TROPF H, 1981, ANGEW INFORM, P71
   Tsingos N, 2001, COMP GRAPH, P545, DOI 10.1145/383259.383323
   Turing, 2019, NVIDIA Turing GPU Architecture: Graphics Reinvented. Whitepaper
   Wald I, 2022, OWL: A node graph "wrapper" library for OptiX 7
   Wald Ingo., 2020, The elephant on RTX - first light, or: Ray tracing Disney's MoanaIsland using RTX, OptiX, and OWL
   Wilkie A, 2014, COMPUT GRAPH FORUM, V33, P123, DOI 10.1111/cgf.12419
   Zellmann S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P96, DOI 10.1109/VIS47514.2020.00026
NR 53
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3609
EP 3621
DI 10.1109/TVCG.2023.3238662
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700060
PM 37022015
DA 2024-08-05
ER

PT J
AU Sharma, M
   Bin Masood, T
   Thygesen, SS
   Linares, M
   Hotz, I
   Natarajan, V
AF Sharma, Mohit
   Bin Masood, Talha
   Thygesen, Signe Sidwall
   Linares, Mathieu
   Hotz, Ingrid
   Natarajan, Vijay
TI Continuous Scatterplot Operators for Bivariate Analysis and Study of
   Electronic Transitions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Orbits; Lenses; Pipelines; Isosurfaces; Space vehicles;
   Behavioral sciences; Bivariate field analysis; continuous scatterplot;
   fiber surface; control polygon; visual analysis; electronic transitions
ID FIBER SURFACES; HISTOGRAMS
AB Electronic transitions in molecules due to the absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of electronic transitions, namely which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this article, we present a novel approach for the analysis of a bivariate field and show its applicability to the study of electronic transitions. This approach is based on two novel operators, the continuous scatterplot (CSP) lens operator and the CSP peel operator, that enable effective visual analysis of bivariate fields. Both operators can be applied independently or together to facilitate analysis. The operators motivate the design of control polygon inputs to extract fiber surfaces of interest in the spatial domain. The CSPs are annotated with a quantitative measure to further support the visual analysis. We study different molecular systems and demonstrate how the CSP peel and CSP lens operators help identify and study donor and acceptor characteristics in molecular systems.
C1 [Sharma, Mohit; Natarajan, Vijay] Indian Inst Sci, Dept Comp Sci & Automat, Bengaluru 560012, Karnataka, India.
   [Bin Masood, Talha; Thygesen, Signe Sidwall; Linares, Mathieu; Hotz, Ingrid] Linkoping Univ, Dept Sci & Technol ITN, S-58183 Linkoping, Sweden.
   [Hotz, Ingrid] Indian Inst Sci, Bengaluru 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore; Linkoping University;
   Indian Institute of Science (IISC) - Bangalore
RP Sharma, M (corresponding author), Indian Inst Sci, Dept Comp Sci & Automat, Bengaluru 560012, Karnataka, India.
EM mohitsharma@iisc.ac.in; talha.bin.masood@liu.se;
   signe.sidwall.thygesen@liu.se; mathieu.linares@liu.se;
   ingrid.hotz@liu.se; vijayn@iisc.ac.in
RI ; linares, mathieu/C-5791-2008
OI Hotz, Ingrid/0000-0001-7285-0483; Sharma, Mohit/0000-0002-9153-7465;
   Sidwall Thygesen, Signe/0000-0001-9156-647X; Natarajan,
   Vijay/0000-0002-7956-1470; linares, mathieu/0000-0002-9720-5429; Bin
   Masood, Talha/0000-0001-5352-1086
FU Indo-Swedish joint network project [DST/INT/SWD/VR/P-02/2019]; VR
   [2018-07085, 2018-05973]; MoE Govt. of India; Swarnajayanti Fellowship
   from DST India [DST/SJF/ETA-02/2015-16]; Mindtree Chair research grant;
   SeRC (Swedish e-Science Research Center); Swedish Research Council (VR)
   [2019-05487]
FX This work was supported in part by an Indo-Swedish joint network project
   under Grant DST/INT/SWD/VR/P-02/2019 and in part by VR under Grant
   2018-07085, in part by the MoE Govt. of India, a Swarnajayanti
   Fellowship from DST India under Grant DST/SJF/ETA-02/2015-16, in part by
   a Mindtree Chair research grant, in part by the SeRC (Swedish e-Science
   Research Center), in part by the Swedish Research Council (VR) under
   Grant 2019-05487.SST is associated to the Wallenberg AI, Autonomous
   Systems and Software Program (WASP). The computations were enabled by
   resources provided by the Swedish National Infrastructure for Computing
   (SNIC) with NSC partially funded by the VR under Grant 2018-05973.
CR AURENHAMMER F, 1987, SIAM J COMPUT, V16, P78, DOI 10.1137/0216006
   Ayachit U., 2015, PARAVIEW GUIDE PARAL
   Bachthaler S, 2008, IEEE T VIS COMPUT GR, V14, P1428, DOI 10.1109/TVCG.2008.119
   Blecha C, 2019, IEEE PAC VIS SYMP, P189, DOI 10.1109/PacificVis.2019.00030
   Carr H, 2015, COMPUT GRAPH FORUM, V34, P241, DOI 10.1111/cgf.12636
   Carr H, 2006, IEEE T VIS COMPUT GR, V12, P1259, DOI 10.1109/TVCG.2006.168
   Edelsbrunner H, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P242, DOI 10.1145/1377676.1377720
   Frisch M. J., Gaussian
   García G, 2013, PHYS CHEM CHEM PHYS, V15, P20210, DOI 10.1039/c3cp53740d
   Guido CA, 2013, J CHEM THEORY COMPUT, V9, P3118, DOI 10.1021/ct400337e
   Haranczyk M, 2008, J CHEM THEORY COMPUT, V4, P689, DOI 10.1021/ct800043a
   Huet L, 2020, J CHEM THEORY COMPUT, V16, P4543, DOI 10.1021/acs.jctc.0c00296
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Kim H. W., 2019, inMolecular Spectroscopy: A. Quantum Chemistry Approach, V1
   Klacansky P, 2017, IEEE T VIS COMPUT GR, V23, P1782, DOI 10.1109/TVCG.2016.2570215
   Le Bahers T, 2011, J CHEM THEORY COMPUT, V7, P2498, DOI 10.1021/ct200308m
   Lehmann DJ, 2010, IEEE T VIS COMPUT GR, V16, P1291, DOI 10.1109/TVCG.2010.146
   Martin RL, 2003, J CHEM PHYS, V118, P4775, DOI 10.1063/1.1558471
   Bin Masood T, 2021, COMPUT GRAPH FORUM, V40, P287, DOI 10.1111/cgf.14307
   Morgan F., 2000, GEOMETRIC MEASURE TH
   Mulliken RS, 1932, PHYS REV, V41, P49, DOI 10.1103/PhysRev.41.49
   Nagaraj S, 2011, IEEE T VIS COMPUT GR, V17, P182, DOI 10.1109/TVCG.2010.64
   Raith F, 2019, IEEE T VIS COMPUT GR, V25, P1122, DOI 10.1109/TVCG.2018.2864846
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Scheidegger CE, 2008, IEEE T VIS COMPUT GR, V14, P1659, DOI 10.1109/TVCG.2008.160
   Sharma M, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P96, DOI 10.1109/VIS49827.2021.9623300
   Stone D. J., 2011, inGPU Computing Gems Emerald Edition, ser. Applications of GPUComputing Series, P5
   Thygesen SS, 2022, COMPUT GRAPH FORUM, V41, P333, DOI 10.1111/cgf.14544
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2017, IEEE T VIS COMPUT GR, V23, P960, DOI 10.1109/TVCG.2016.2599017
NR 30
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3532
EP 3544
DI 10.1109/TVCG.2023.3237768
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700002
PM 37021886
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Tian, Y
   Bai, HL
   Zhao, SD
   Fu, CW
   Yu, C
   Qin, HZ
   Wang, Q
   Heng, PA
AF Tian, Yang
   Bai, Hualong
   Zhao, Shengdong
   Fu, Chi-Wing
   Yu, Chun
   Qin, Haozhao
   Wang, Qiong
   Heng, Pheng-Ann
TI Kine-Appendage: Enhancing Freehand VR Interaction Through
   Transformations of Virtual Appendages
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Visualization; Tracking; Hardware; Haptic interfaces;
   Performance evaluation; Headphones; Visual kinesthetic feedback; virtual
   appendage; visual transformation; isomorphic typing
ID FEEDBACK; DESIGN
AB Kinesthetic feedback, the feeling of restriction or resistance when hands contact objects, is essential for natural freehand interaction in VR. However, inducing kinesthetic feedback using mechanical hardware can be cumbersome and hard to control in commodity VR systems. We propose the kine-appendage concept to compensate for the loss of kinesthetic feedback in virtual environments, i.e., a virtual appendage is added to the user's avatar hand; when the appendage contacts a virtual object, it exhibits transformations (rotation and deformation); when it disengages from the contact, it recovers its original appearance. A proof-of-concept kine-appendage technique, BrittleStylus, was designed to enhance isomorphic typing. Our empirical evaluations demonstrated that (i) BrittleStylus significantly reduced the uncorrected error rate of naive isomorphic typing from 6.53% to 1.92% without compromising the typing speed; (ii) BrittleStylus could induce the sense of kinesthetic feedback, the degree of which was parity with that induced by pseudo-haptic (+ visual cue) methods; and (iii) participants preferred BrittleStylus over pseudo-haptic (+ visual cue) methods because of not only good performance but also fluent hand movements.
C1 [Tian, Yang; Bai, Hualong; Qin, Haozhao] Guangxi Univ, Guangxi Key Lab Multimedia Commun & Network Techno, Nanning 530004, Guangxi, Peoples R China.
   [Zhao, Shengdong] Natl Univ Singapore, NUS HCI lab, Singapore 119077, Singapore.
   [Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Univ Hong Kong, Inst Med Intelligence & XR, Hong Kong, Peoples R China.
   [Yu, Chun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Wang, Qiong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Comp Vis & Virtual Real Tec, Shenzhen 518055, Guangdong, Peoples R China.
C3 Guangxi University; National University of Singapore; Chinese University
   of Hong Kong; Chinese University of Hong Kong; Tsinghua University;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Tian, Y (corresponding author), Guangxi Univ, Guangxi Key Lab Multimedia Commun & Network Techno, Nanning 530004, Guangxi, Peoples R China.
EM ytian@gxu.edu.cn; baihl@st.gxu.edu.cn; zhaosd@comp.nus.edu.sg;
   cwfu@cse.cuhk.edu.hk; chunyu@tsinghua.edu.cn; haozhaoqin@st.gxu.edu.cn;
   wangqiong@siat.ac.cn; pheng@cse.cuhk.edu.hk
OI Fu, Chi Wing/0000-0002-5238-593X; Heng, Pheng Ann/0000-0003-3055-5034
FU National Natural Science Foundation of China [62171145, 62072452];
   Key-Area Research and Development Program of Guangdong Province, China
   [2019B010149002]; Guangdong Provincial Basic and Applied Basic Research
   Fund- Regional Joint Fund [2020B1515130004]; Research Grants Council of
   the Hong Kong Special Administrative Region, China [T45-401/22-N];
   National Research Foundation, Singapore [AISG2-RP-2020-016]; Ministry of
   Education, Singapore; MOE Academic Research Fund Tier 2 programme
   [MOE-T2EP20221-0010]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62171145 and 62072452, in part by
   Key-Area Research and Development Program of Guangdong Province, China
   under Grant 2019B010149002, in part by Guangdong Provincial Basic and
   Applied Basic Research Fund- Regional Joint Fund under Grant
   2020B1515130004, in part by the Research Grants Council of the Hong Kong
   Special Administrative Region, China under Grant T45-401/22-N, in part
   by National Research Foundation, Singapore under its AI Singapore
   Programme AISG Award under Grant AISG2-RP-2020-016, and in part by the
   Ministry of Education, Singapore, under its MOE Academic Research Fund
   Tier 2 programme under Grant MOE-T2EP20221-0010.
CR AAlzayat M., 2019, Quantitative Measure-ment of Tool Embodiment for Virtual Reality Input Alternatives, P11
   Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   [Anonymous], HTC Vive Pro
   [Anonymous], Oculus Integration SDK.
   [Anonymous], Gorrila Arm.
   [Anonymous], Optitrack Motion Capture System
   [Anonymous], HTC VIVE hand tracking SDK.
   [Anonymous], Levenshtein Distance
   [Anonymous], Oculus quest
   [Anonymous], LEAP MOTION
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Balakrishnan R., 1997, Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, P303, DOI DOI 10.1145/258549.258764
   Ban Y, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P991, DOI 10.1109/WHC49131.2021.9517129
   Benko H., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1263
   Blake J, 2009, IEEE-ASME T MECH, V14, P606, DOI 10.1109/TMECH.2008.2010934
   Bouzit M, 2002, IEEE-ASME T MECH, V7, P256, DOI 10.1109/TMECH.2002.1011262
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Dube T. J., 2019, International Conference on Human-Computer Interaction, P419
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Endo T, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P458, DOI 10.1109/WHC.2009.4810812
   Farbiz Z. H., 2007, P C ACM SIGGRAPH, P140, DOI DOI 10.1145/1280720.1280873
   Fashimpaur J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382888
   Gruenbaum PE, 1997, PRESENCE-TELEOP VIRT, V6, P118, DOI 10.1162/pres.1997.6.1.118
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Jackson L. B., 2020, P S SPAT US INT, P1
   Jiang HY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P692, DOI [10.1109/VR46266.2020.1581236395562, 10.1109/VR46266.2020.00-12]
   Kang H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P38, DOI [10.1109/VR.2019.8798300, 10.1109/vr.2019.8798300]
   Kohli L, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P129, DOI 10.1109/3DUI.2010.5444703
   Kron A, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P16, DOI 10.1109/HAPTIC.2003.1191219
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee EC, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P259, DOI [10.1109/VR.2019.8798154, 10.1109/vr.2019.8798154]
   Lijuan Liu, 2020, HCI International 2020 - Late Breaking Papers. Digital Human Modeling and Ergonomics, Mobility and Intelligent Environments. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12429), P316, DOI 10.1007/978-3-030-59987-4_23
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Lopes P., 2013, P SIGCHI C HUM FACT, P2577, DOI [DOI 10.1145/2470654.2481355EVENT-PLACE:PARIS,FRANCE, DOI 10.1145/2470654.2481355, 10.1145/2470654.2481355]
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Lopes P, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P11, DOI 10.1145/2807442.2807443
   Mackenzie I.S., 2003, P ACM C HUMAN FACTOR, P113
   MCNEELY WA, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P336, DOI 10.1109/VRAIS.1993.380761
   NASA TLX, ABOUT US
   Ni T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2473
   Perry JC, 2007, IEEE-ASME T MECH, V12, P408, DOI 10.1109/TMECH.2007.901934
   Pfeiffer M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2505, DOI 10.1145/2702123.2702190
   Pham W., 2019, P 25 ACM S VIRT REAL, P1
   Prachyabrued M, 2016, IEEE T VIS COMPUT GR, V22, P1718, DOI 10.1109/TVCG.2015.2456917
   Richardson Mark., 2020, P 33 ANN ACM S US IN, P686
   Rietzler F., 2018, Breakingthe Tracking: Enabling Weight Perception Using Perceivable TrackingOffsets, P1
   Rietzler M., 2018, P CHI C HUM FACT COM, P1
   Rietzler M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P913, DOI 10.1145/3332165.3347871
   Schneider D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P805, DOI [10.1109/VRW50115.2020.00253, 10.1109/VRW50115.2020.00-22]
   Shapira L, 2016, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2016.23
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Simon R. T., 2014, P ACM INT S WEAR COM, P67
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Tamaki E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P543
   Tian Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376557
   Tsetserukou K., 2010, P 1 AUGM HUM INT C, P1
   Vogel D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P657
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yokokohji Y, 2003, SPRINGER TRAC ADV RO, V6, P499
   Yu R, 2020, IEEE T VIS COMPUT GR, V26, P2094, DOI 10.1109/TVCG.2020.2973056
NR 64
TC 1
Z9 1
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3298
EP 3313
DI 10.1109/TVCG.2022.3230746
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700033
PM 37015422
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Bearfield, CX
   van Weelden, L
   Waytz, A
   Franconeri, S
AF Bearfield, Cindy Xiong
   van Weelden, Lisanne
   Waytz, Adam
   Franconeri, Steven
TI Same Data, Diverging Perspectives: The Power of Visualizations to Elicit
   Competing Interpretations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Annotations; Market research; Bars;
   Image color analysis; Data mining; Affordances; annotations; bar chart;
   decisions; line chart; predictions; table; visual saliency;
   visualization design
ID SALIENCE; BAR
AB People routinely rely on data to make decisions, but the process can be riddled with biases. We show that patterns in data might be noticed first or more strongly, depending on how the data is visually represented or what the viewer finds salient. We also demonstrate that viewer interpretation of data is similar to that of 'ambiguous figures' such that two people looking at the same data can come to different decisions. In our studies, participants read visualizations depicting competitions between two entities, where one has a historical lead (A) but the other has been gaining momentum (B) and predicted a winner, across two chart types and three annotation approaches. They either saw the historical lead as salient and predicted that A would win, or saw the increasing momentum as salient and predicted B to win. These results suggest that decisions can be influenced by both how data are presented and what patterns people find visually salient.
C1 [Bearfield, Cindy Xiong] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [van Weelden, Lisanne] Univ Utrecht, NL-3584 Utrecht, Netherlands.
   [Waytz, Adam] Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
   [Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
C3 University System of Georgia; Georgia Institute of Technology; Utrecht
   University; Northwestern University; Northwestern University
RP Bearfield, CX (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM cxiong@gatech.edu
OI Xiong Bearfield, Cindy/0000-0002-1451-4083
FU NSF
FX No Statement Available
CR Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Albers D., 2014, J. Vis., V14, P1056
   Alves T, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P201, DOI 10.1109/VIS47514.2020.00047
   Andrews R., 2019, Info We Trust: How to Inspire the World With Data
   [Anonymous], 2014, Qualtrics [software]
   ATTNEAVE F, 1971, SCI AM, V225, P62, DOI 10.1038/scientificamerican1271-62
   Barocas S, 2017, COMMUN ACM, V60, P23, DOI 10.1145/3144172
   Bearfield CX, 2024, IEEE T VIS COMPUT GR, V30, P5097, DOI 10.1109/TVCG.2023.3289292
   Black E., 2012, IBM and the Holocaust: The Strategic Alliance Between Nazi Germany and America's Most Powerful Corporation-Expanded Edition
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Bose D, 2022, REV FINANC STUD, V35, P5094, DOI 10.1093/rfs/hhac027
   Bostock M., 2012, The New York Times
   Bylinskii Z, 2017, Arxiv, DOI arXiv:1709.09215
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Ceja CR, 2021, IEEE T VIS COMPUT GR, V27, P1054, DOI 10.1109/TVCG.2020.3030422
   Chun MM, 2011, ANNU REV PSYCHOL, V62, P73, DOI 10.1146/annurev.psych.093008.100427
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Dominitz J, 2011, J APPL ECONOMET, V26, P352, DOI 10.1002/jae.1225
   Egeth HE, 2010, ACTA PSYCHOL, V135, P130, DOI 10.1016/j.actpsy.2010.05.012
   Feng M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173711
   Fosco C., 2020, P 33 ANN ACM S USER, P249, DOI DOI 10.1145/3379337.3415825
   Franken IHA, 2005, PERS INDIV DIFFER, V39, P991, DOI 10.1016/j.paid.2005.04.004
   FUNDER DC, 1991, J PERS SOC PSYCHOL, V60, P773, DOI 10.1037/0022-3514.60.5.773
   Gaba A, 2024, IEEE T VIS COMPUT GR, V30, P327, DOI 10.1109/TVCG.2023.3327192
   Gaba Aimen, 2023, IEEE Trans Vis Comput Graph, V29, P1211, DOI 10.1109/TVCG.2022.3209456
   Harmon-Jones E., 2019, An Introduction to Cognitive Dissonance Theory and an Overview of Current Perspectives on the Theory
   Hawley ST, 2008, PATIENT EDUC COUNS, V73, P448, DOI 10.1016/j.pec.2008.07.023
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hill S., 2018, J. Inf. Syst. Appl. Res., V11, P1
   Hofman J. M., 2022, P ACM CHI C HUM FACT, P1
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Holder Eli, 2023, IEEE Trans Vis Comput Graph, V29, P624, DOI 10.1109/TVCG.2022.3209377
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Inbar Ohad, 2007, P 14 EUR C COGN ERG, P185, DOI DOI 10.1145/1362550.1362587
   Jänicke H, 2010, COMPUT GRAPH FORUM, V29, P1183, DOI 10.1111/j.1467-8659.2009.01667.x
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Jones B., 2019, Avoiding data pitfalls: how to steer clear of common blunders when working with data and presenting analysis and visualizations
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kim D. H., 2021, P ACM CHI C HUM FACT, P1
   Klein N, 2018, P NATL ACAD SCI USA, V115, P13222, DOI 10.1073/pnas.1805327115
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kool W, 2010, J EXP PSYCHOL GEN, V139, P665, DOI 10.1037/a0020198
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Li XM, 2022, Q J ECON, V137, P1849, DOI 10.1093/qje/qjac025
   Luo Y, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01541
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mantri Prateek, 2023, IEEE Trans Vis Comput Graph, V29, P1005, DOI 10.1109/TVCG.2022.3209467
   Matzen LE, 2018, IEEE T VIS COMPUT GR, V24, P563, DOI 10.1109/TVCG.2017.2743939
   Michal AL, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0059-2
   Michal AL, 2016, PSYCHON B REV, V23, P1802, DOI 10.3758/s13423-016-1047-0
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Ottley A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3251, DOI 10.1145/2702123.2702590
   Schneider H, 2017, LECT NOTES COMPUT SC, V10515, P374, DOI 10.1007/978-3-319-67687-6_25
   Schuhmacher D., 2017, "Package 'transport'," R Package Version, V1
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P972, DOI 10.1109/TVCG.2022.3209409
   Shin M, 2023, IEEE T VIS COMPUT GR, V29, P2980, DOI 10.1109/TVCG.2022.3146329
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Stolper C. D., 2016, Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   THEEUWES J, 1991, PERCEPT PSYCHOPHYS, V50, P184, DOI 10.3758/BF03212219
   Theeuwes J, 2010, ACTA PSYCHOL, V135, P77, DOI 10.1016/j.actpsy.2010.02.006
   Torsney-Weir T., 2015, P WORKSH VIS DEC MAK
   Tversky B., 2014, Handbook of Human Centric Visualization, P3
   Vora S., 2019, The Power of Data Storytelling
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Xiong C., 2019, 1 EUROVIS WORKSH TRU, P19
   Xiong CY, 2024, IEEE T VIS COMPUT GR, V30, P3487, DOI 10.1109/TVCG.2022.3232959
   Xiong Cindy, 2023, IEEE Trans Vis Comput Graph, V29, P493, DOI 10.1109/TVCG.2022.3209405
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yarbus A.L., 1967, Eye Movements and Vision
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Ziemkiewicz C, 2013, IEEE T VIS COMPUT GR, V19, P1109, DOI 10.1109/TVCG.2012.180
NR 88
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2995
EP 3007
DI 10.1109/TVCG.2024.3388515
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500003
PM 38619945
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Li, YR
   Wang, JP
   Aboagye, P
   Yeh, CCM
   Zheng, Y
   Wang, L
   Zhang, W
   Ma, KL
AF Li, Yiran
   Wang, Junpeng
   Aboagye, Prince
   Yeh, Chin-Chia Michael
   Zheng, Yan
   Wang, Liang
   Zhang, Wei
   Ma, Kwan-Liu
TI Visual Analytics for Efficient Image Exploration and User-Guided Image
   Captioning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Analytical models; Training; Image segmentation;
   Transformers; Snow; Heating systems; Machine learning; visual analytics;
   data-centric AI; pre-trained language-image models; image captioning
ID VISION
AB Recent advancements in pre-trained language-image models have ushered in a new era of visual comprehension. Leveraging the power of these models, this article tackles two issues within the realm of visual analytics: (1) the efficient exploration of large-scale image datasets and identification of data biases within them; (2) the evaluation of image captions and steering of their generation process. On the one hand, by visually examining the captions generated from language-image models for an image dataset, we gain deeper insights into the visual contents, unearthing data biases that may be entrenched within the dataset. On the other hand, by depicting the association between visual features and textual captions, we expose the weaknesses of pre-trained language-image models in their captioning capability and propose an interactive interface to steer caption generation. The two parts have been coalesced into a coordinated visual analytics system, fostering the mutual enrichment of visual and textual contents. We validate the effectiveness of the system with domain practitioners through concrete case studies with large-scale image datasets.
C1 [Li, Yiran; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
   [Wang, Junpeng; Aboagye, Prince; Yeh, Chin-Chia Michael; Zheng, Yan; Wang, Liang; Zhang, Wei] Visa Res, Foster City, CA 94404 USA.
C3 University of California System; University of California Davis
RP Li, YR (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM ranli@ucdavis.edu; junpenwa@visa.com; priaboag@visa.com; miyeh@visa.com;
   yazheng@visa.com; liawang@visa.com; wzhan@visa.com; klma@ucdavis.edu
OI Wang, Junpeng/0000-0002-1130-9914; Li, Yiran/0000-0001-5204-4935; Ma,
   Kwan-Liu/0000-0001-8086-0366
FU NIBIB
FX No Statement Available
CR Aflalo E, 2022, PROC CVPR IEEE, P21374, DOI 10.1109/CVPR52688.2022.02072
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   [Anonymous], TEXTBLOB SIMPLIFIED
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bauerle A., 2023, P EUR C VIS SHORT PA, DOI [10.2312/evs.20231051, DOI 10.2312/EVS.20231051]
   Bertucci D., IEEE Trans. Vis. Comput. Graph., V29, P320
   Bird S., 2009, Natural Language Processing with Python, DOI DOI 10.5555/1717171
   Brade S., 2023, P 36 ANN ACM S US IN, P1
   Cao KL, 2021, IEEE T VIS COMPUT GR, V27, P3289, DOI 10.1109/TVCG.2020.2969185
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong ZH, 2020, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis48177.2020.1031
   Dosovitskiy A., 2021, P 9 INT C LEARN REPR
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P295, DOI 10.1109/TVCG.2023.3327168
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Junnan Li, 2021, Advances in neural information processing systems, P9694
   Karpathy A., "t-SNE visualization of CNN codes
   Kaul S, 2022, IEEE T VIS COMPUT GR, V28, P998, DOI 10.1109/TVCG.2021.3114779
   Kazemzadeh S., 2014, EMNLP, DOI DOI 10.3115/V1/D14-1086
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kirillov A, 2023, Arxiv, DOI arXiv:2304.02643
   Li DX, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-DEMO 2023, VOL 3, P31
   Li JN, 2022, PR MACH LEARN RES
   Li YR, 2023, IEEE T VIS COMPUT GR, V29, P2888, DOI 10.1109/TVCG.2023.3261935
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   OpenAI, 2023, Gpt-4 technical report
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P146, DOI 10.1109/visual.2019.8933677
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Smilkov D., 2016, Statist. Mach. Learn., V1050
   Strickland E., 2022, IEEE Spectr., V59, P22
   Strobelt H, 2022, IEEE T VIS COMPUT GR, V28, P1106, DOI 10.1109/TVCG.2021.3114845
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]
   Vaswani A., 2017, PROC NEURIPS, V30, P5998
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang JP, 2023, Arxiv, DOI arXiv:2307.07712
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang ZJ, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P132
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Yeh C, 2023, Arxiv, DOI arXiv:2305.03210
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
NR 59
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2875
EP 2887
DI 10.1109/TVCG.2024.3388514
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500016
PM 38625780
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Gao, BY
   Shao, T
   Tu, HW
   Ma, QZ
   Liu, ZT
   Han, T
AF Gao, Bo Yu
   Shao, Tong
   Tu, Huawei
   Ma, Qizi
   Liu, Zitao
   Han, Teng
TI Exploring Bimanual Haptic Feedback for Spatial Search in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bimanual Haptic Feedback; Spatial Search; Controllers; Virtual Reality
ID DISPLAY; DESIGN; GUIDANCE
AB Spatial search tasks are common and crucial in many Virtual Reality (VR) applications. Traditional methods to enhance the performance of spatial search often employ sensory cues such as visual, auditory, or haptic feedback. However, the design and use of bimanual haptic feedback with two VR controllers for spatial search in VR remains largely unexplored. In this work, we explored bimanual haptic feedback with various combinations of haptic properties, where four types of bimanual haptic feedback were designed, for spatial search tasks in VR. Two experiments were designed to evaluate the effectiveness of bimanual haptic feedback on spatial direction guidance and search in VR. The results from the first experiment reveal that our proposed bimanual haptic schemes significantly enhanced the recognition of spatial directions in terms of accuracy and speed compared to spatial audio feedback. The second experiment's findings suggest that the performance of bimanual haptic feedback was comparable to or even better than the visual arrow, especially in reducing the angle of head movement and enhancing searching targets behind the participants, which was supported by subjective feedback as well. Based on these findings, we have derived a set of design recommendations for spatial search using bimanual haptic feedback in VR.
C1 [Gao, Bo Yu; Shao, Tong; Ma, Qizi; Liu, Zitao] Jinan Univ, Guangzhou, Peoples R China.
   [Tu, Huawei] La Trobe Univ, Melbourne, Australia.
   [Han, Teng] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Han, Teng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
C3 Jinan University; La Trobe University; Chinese Academy of Sciences;
   Institute of Software, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Gao, BY (corresponding author), Jinan Univ, Guangzhou, Peoples R China.; Tu, HW (corresponding author), La Trobe Univ, Melbourne, Australia.
EM bygao@jnu.edu.cn; shaot@stu2021.jnu.edu.cn; h.tu@latrobe.edu.au;
   202334511026@stu.jnu.edu.cn; liuzitao@jnu.edu.cn; hanteng@iscas.ac.cn
OI Gao, BoYu/0000-0001-8523-2828; Tu, Huawei/0000-0001-9689-9767
FU National Key R&D Program of China
FX No Statement Available
CR Azadi M, 2014, IEEE T HAPTICS, V7, P14, DOI 10.1109/TOH.2013.2296051
   Bala P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300925
   Bark K, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P71
   Beattie D, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P189, DOI 10.1145/2639189.2641206
   Bial D., 2011, CHI'11, P1273
   Binetti N, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102032
   Boll S, 2011, IEEE PERVAS COMPUT, V10, P35, DOI 10.1109/MPRV.2011.39
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Boukhris Sabrine, 2017, Human-Computer Interaction: Interaction Contexts. 19th International Conference, held as part of HCI International 2017. Proceedings: LNCS 10272, P35, DOI 10.1007/978-3-319-58077-7_3
   Brown C, 2017, P IEEE VIRT REAL ANN, P377, DOI 10.1109/VR.2017.7892334
   Chang HY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P927, DOI 10.1145/3242587.3242588
   Chen TZ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281516
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Cosgun A, 2014, IEEE INT CONF ROBOT, P6350, DOI 10.1109/ICRA.2014.6907796
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   Elsayed H, 2023, PROCEEDINGS OF THE 4TH AUGMENTED HUMANS INTERNATIONAL CONFERENCE 2023, AHS2023, P35, DOI 10.1145/3582700.3582701
   Erp J. B. V., 2005, ACM Transactions on Applied Perception (TAP), P106, DOI DOI 10.1145/1060581.1060585
   Gao BY, 2021, J SYST ARCHITECT, V117, DOI 10.1016/j.sysarc.2021.102096
   Gao B, 2019, INT J HUM-COMPUT INT, V35, P831, DOI 10.1080/10447318.2018.1498654
   Gao B, 2018, INT CONF BIG DATA, P475, DOI 10.1109/BigComp.2018.00076
   García-Valle G, 2016, LECT NOTES COMPUT SC, V9775, P251, DOI 10.1007/978-3-319-42324-1_25
   Geronazzo M, 2016, INT J HUM-COMPUT ST, V85, P4, DOI 10.1016/j.ijhcs.2015.08.004
   Günther S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P273, DOI 10.1145/3197768.3197785
   HART S G, 1988, P139
   Hulin Thomas, 2011, IEEE International Conference on Robotics and Automation, P3441
   Jones LA, 2008, HUM FACTORS, V50, P90, DOI 10.1518/001872008X250638
   Kaul OB, 2017, LECT NOTES COMPUT SC, V10516, P289, DOI 10.1007/978-3-319-68059-0_19
   Kaul OB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3729, DOI 10.1145/3025453.3025684
   Kiss F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174191
   Kron A, 2004, IEEE INT CONF ROBOT, P1968, DOI 10.1109/ROBOT.2004.1308112
   Lange D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376803
   Lindeman R. W., 2006, Virtual Reality, V9, P203, DOI DOI 10.1007/S10055-005-0010-6
   Lindeman R.W., 2005, CHI'05, P271, DOI DOI 10.1145/1054972.1055010
   Marquardt A, 2020, IEEE T VIS COMPUT GR, V26, P3389, DOI 10.1109/TVCG.2020.3023605
   Meier A., 2015, P 2 INT WORKSHOP SEN, P1
   Meli L, 2014, IEEE T BIO-MED ENG, V61, P1318, DOI 10.1109/TBME.2014.2303052
   Meshram A, 2014, INT SYM MIX AUGMENT, P53, DOI 10.1109/ISMAR.2014.6948409
   Meshram VV, 2019, IEEE T HUM-MACH SYST, V49, P449, DOI 10.1109/THMS.2019.2931745
   Minamizawa K, 2008, LECT NOTES COMPUT SC, V5024, P458, DOI 10.1007/978-3-540-69057-3_59
   Mirzaei M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222794
   Morioka M, 2006, J SOUND VIB, V295, P633, DOI 10.1016/j.jsv.2006.01.029
   Murayama J., 2004, P EUROHAPTICS 2004, P138
   Nonino E, 2021, INT SYM MIX AUGMENT, P310, DOI 10.1109/ISMAR-Adjunct54149.2021.00070
   Nukarinen T, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P345, DOI 10.1109/WHC.2015.7177736
   Oliveira VAD, 2014, LECT NOTES COMPUT SC, V8619, P104, DOI 10.1007/978-3-662-44196-1_14
   Oliveira VAD, 2014, LECT NOTES COMPUT SC, V8618, P309, DOI 10.1007/978-3-662-44193-0_39
   Panëels S, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P407, DOI 10.1109/WHC.2013.6548443
   Peer A, 2008, IEEE-ASME T MECH, V13, P416, DOI 10.1109/TMECH.2008.2001690
   Peiris RL, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300400
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Plaisier Myrthe A., 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P127, DOI 10.1007/978-3-642-31404-9_22
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Renner P, 2017, IEEE SYMP 3D USER, P186, DOI 10.1109/3DUI.2017.7893338
   Ro H, 2017, IEEE SYS MAN CYBERN, P2873, DOI 10.1109/SMC.2017.8123063
   Rothe S, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3143421
   Ryu N., 2021, P 2021 CHI C HUMAN F, P1
   Schmitz A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P63, DOI [10.1109/VR46266.2020.00-80, 10.1109/VR46266.2020.1581102716289]
   Sherrick C., 1991, The psychology of touch, P189
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Song Q., 2022, CHI C HUMAN FACTORS, P1
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   Talvas A, 2014, IEEE T HAPTICS, V7, P285, DOI 10.1109/TOH.2014.2314456
   Tan H., 2003, A haptic back display for attentional and directional cueing
   Tan HZ, 2010, IEEE T HAPTICS, V3, P98, DOI 10.1109/ToH.2009.46
   Ternes D, 2008, LECT NOTES COMPUT SC, V5024, P199, DOI 10.1007/978-3-540-69057-3_24
   Tsai HR, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445262
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/ToH.2012.51, 10.1109/TOH.2012.51]
   Unity, Xr interaction toolkit
   van Erp J. B., 2007, Tactile displays for navigation and orientation: perception and behaviour
   Velázquez R, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040578
   Wagner U, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581423
   Wallgrün JO, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P83, DOI [10.1109/VR46266.2020.1581092881445, 10.1109/VR46266.2020.00-78]
   Wang D., 2006, Computational auditory scene analysis: Principles, algorithms, and applications
   Wang Y., 2020, P 2020 CHI C HUMAN F, P1
   Wang YL, 2016, INT J HUM-COMPUT ST, V89, P24, DOI 10.1016/j.ijhcs.2016.01.004
   Way T P, 1997, IEEE Trans Rehabil Eng, V5, P81, DOI 10.1109/86.559353
   Wenbai Xue, 2022, Cross-Cultural Design. Applications in Learning, Arts, Cultural Heritage, Creative Industries, and Virtual Reality: 14th International Conference, CCD 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Proceedings. Lecture Notes in Computer Science (13312), P520, DOI 10.1007/978-3-031-06047-2_39
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   Wightman F.L., 1997, BINAURAL SPATIAL HEA, P1
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yamazaki Y, 2023, Symposium Virtual Re, P276, DOI 10.1109/VR55154.2023.00043
   Yoshimura A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1255, DOI 10.1109/vr.2019.8798327
NR 82
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2422
EP 2433
DI 10.1109/TVCG.2024.3372045
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400032
PM 38437136
DA 2024-08-05
ER

PT J
AU Hoshikawa, Y
   Fujita, K
   Takashima, K
   Fjeld, M
   Kitamura, Y
AF Hoshikawa, Yukai
   Fujita, Kazuyuki
   Takashima, Kazuki
   Fjeld, Morten
   Kitamura, Yoshifumi
TI RedirectedDoors plus : Door-Opening Redirection with Dynamic Haptics in
   Room-Scale VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Robots; Legged locomotion; Visualization; Guidelines;
   Virtual environments; Wheels; Redirected Walking; Visuo-haptic
   redirection; Encounter-type haptic device; Virtual reality
ID WALKING; REAL
AB RedirectedDoors is a visuo-haptic door-opening redirection technique in VR, and it has shown promise in its ability to efficiently compress the physical space required for a room-scale VR experience. However, its previous implementation has only supported laboratory experiments with a single door opening at a fixed location. To significantly expand this technique for room-scale VR, we have developed RedirectedDoors+, a robot-based system that permits consecutive door-opening redirection with haptics. Specifically, our system is mainly achieved with the use of three components: (1) door robots, a small number of wheeled robots equipped with a doorknob-like prop, (2) a robot-positioning algorithm that arbitrarily positions the door robots to provide the user with just-in-time haptic feedback during door opening, and (3) a user-steering algorithm that determines the redirection gain for every instance of door opening to keep the user away from the boundary of the play area. Results of simulated VR exploration in six virtual environments reveal our system's performance relative to user walking speed, paths, and number of door robots, from which we derive its usage guidelines. We then conduct a user study ($N=12$) in which participants experience a walkthrough application using the actual system. The results demonstrate that the system is able to provide haptic feedback while redirecting the user within a limited play area.
C1 [Hoshikawa, Yukai; Fujita, Kazuyuki; Takashima, Kazuki; Kitamura, Yoshifumi] Tohoku Univ, Sendai, Miyagi, Japan.
   [Fjeld, Morten] Univ Bergen, Bergen, Norway.
   [Fjeld, Morten] Chalmers Univ Technol, Gothenburg, Sweden.
C3 Tohoku University; University of Bergen; Chalmers University of
   Technology
RP Hoshikawa, Y (corresponding author), Tohoku Univ, Sendai, Miyagi, Japan.
EM yukai.hoshikawa.r4@alumni.tohoku.ac.jp; k-fujita@riec.tohoku.ac.jp;
   takashima@riec.tohoku.ac.jp; Morten.Fjeld@uib.no;
   kitamura@riec.tohoku.ac.jp
OI Fujita, Kazuyuki/0000-0002-1039-0167; /0000-0002-9562-5147
FU JSPS
FX No Statement Available
CR Abdullah M, 2018, IEEE HAPTICS SYM, P334, DOI 10.1109/HAPTICS.2018.8357197
   Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   Achberger Alexander, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P841, DOI 10.1145/3472749.3474790
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bouzbib G., 2020, Association for Computing Machinery, P209, DOI [10.1145/3379337.34158911,3[6, DOI 10.1145/3379337.34158911,3[6]
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Castelli L, 2008, COMPUT HUM BEHAV, V24, P1643, DOI 10.1016/j.chb.2007.06.005
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Ciumedean C., 2020, InProc. SUI. Associ-ation for Computing Machinery, DOI [10.1145/3385959.34184532[11]R, DOI 10.1145/3385959.34184532[11]R]
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Gonzalez Eric J., 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P236, DOI 10.1145/3379337.3415870
   He ZY, 2017, UIST'17 ADJUNCT: ADJUNCT PUBLICATION OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P17, DOI 10.1145/3131785.3131795
   Hirt C, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P524, DOI 10.1109/VR51125.2022.00072
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Horie A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P260, DOI 10.1109/VR50410.2021.00048
   Hoshikawa K., 2022, INPROC SIGGRAPH ASIA, DOI [10.1145/3550472.35584051,2[18]Y, DOI 10.1145/3550472.35584051,2[18]Y]
   Hoshikawa Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P464, DOI 10.1109/VR51125.2022.00066
   Insko B. E., 2001, PhD thesis
   International Organization for Standardization, ISO/TS 15066:2016
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253, DOI 10.1145/1152399.11524512[23]P
   Kudry Peter, 2022, RACS '22: Proceedings of the Conference on Research in Adaptive and Convergent Systems, P178, DOI 10.1145/3538641.3561507
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Mack A, 2003, CURR DIR PSYCHOL SCI, V12, P180, DOI 10.1111/1467-8721.01256
   Martin NAA, 2013, PROC CIRP, V7, P509, DOI 10.1016/j.procir.2013.06.024
   Matsumoto K, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365705
   Matsumoto K, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132821
   Matsumoto K, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P105, DOI 10.1109/3DUI.2016.7460038
   Matsumoto Y., 2016, InProc. SIGGRAPH Emerging Technologies, DOI [10.1145/2929464.29294822[28]K., DOI 10.1145/2929464.29294822[28]K]
   Mendez S., 2022, INPROC SIGGRAPH ASIA, DOI [10.1145/3550472.35584063, DOI 10.1145/3550472.35584063]
   Mercado VR, 2021, IEEE T HAPTICS, V14, P449, DOI 10.1109/TOH.2021.3061150
   Mortezapoor S, 2023, Symposium Virtual Re, P297, DOI 10.1109/VR55154.2023.00045
   Nagai K, 2015, SIGGRAPH ASIA 2015 HAPTIC MEDIA AND CONTENTS DESIGN (SA'15), DOI 10.1145/2818384.2818403
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Onishi Y, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545615
   Peck TC, 2021, IEEE COMPUT GRAPH, V41, P133, DOI 10.1109/MCG.2021.3113455
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Razzaque Z., 2001, EUROGRAPHICS 2001 SH, P289, DOI 10.2312/egs.20011036
   Salomoni Paola, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P387, DOI 10.1109/CCNC.2016.7444811
   Schmelter T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451264
   Shaqiri A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25298-8
   Simeone AL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P598, DOI [10.1109/VR46266.2020.00-22, 10.1109/VR46266.2020.1581330966612]
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P59, DOI 10.1145/3196709.3196792
   Steinicke F., 2008, Proceedings of the Virtual Reality International Conference (VRIC), P15
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Suma D. M., 2011, INIEEE VR WORKSHOPS, P33
   Suzuki R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376523
   Tao YJ, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545682
   Teng SY, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P639, DOI 10.1145/3332165.3347958
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Wang CH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P331, DOI [10.1109/VR.2019.8798255, 10.1109/vr.2019.8798255]
   Wang YT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376286
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2023, IEEE INT CONF ROBOT, P12478, DOI 10.1109/ICRA48891.2023.10160996
   Yamaguchi K, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P43, DOI 10.1145/2983310.2985746
   Yamaguchi S., 2023, INSIGGRAPHASIA 2023, DOI [10.1145/3610541.36145741,3[63]K, DOI 10.1145/3610541.36145741,3[63]K]
   Yan Yixian, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P223, DOI 10.1145/3379337.3415859
   Yu R, 2017, IEEE SYMP 3D USER, P116, DOI 10.1109/3DUI.2017.7893327
   Zank M, 2017, IEEE SYMP 3D USER, P120, DOI 10.1109/3DUI.2017.7893328
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 67
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2276
EP 2286
DI 10.1109/TVCG.2024.3372105
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400071
PM 38466596
OA hybrid
DA 2024-08-05
ER

PT J
AU Kim, H
   Jeon, SB
   Lee, IK
AF Kim, Hyunjeong
   Jeon, Sang-Bin
   Lee, In-Kwon
TI Locomotion Techniques for Dynamic Environments: Effects on Spatial
   Knowledge and User Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Locomotion technique; Dynamic environment; Spatial knowledge; user
   experience; Redirected walking; teleportation; joystick
ID WALKING-IN-PLACE; REDIRECTED WALKING; VIRTUAL-REALITY; MOVEMENT; TRAVEL
AB Various locomotion techniques are used to navigate and find way through space in virtual environments (VE), and each technique provides different experiences and performances to users. Previous studies have primarily focused on static environments, whereas there is a need for research from a different perspective of dynamic environments because there are many moving objects in VE, such as other users. In this study, we compare the effects of different locomotion techniques on the user's spatial knowledge and experience, depending on whether the virtual objects are moving or not. The investigated locomotion techniques include joystick, teleportation, and redirected walking (RDW), all commonly used for VR navigation. The results showed that the differences in spatial knowledge and user experience provided by different locomotion techniques can vary depending on whether the environment is static or dynamic. Our results also showed that for a given VE, there are different locomotion techniques that induce fewer collisions between the user and other objects, or reduce the time it takes the user to perform a given task. This study suggests that when designing a locomotion interface for a specific VR application, it is possible to improve the user's spatial knowledge and experience by recommending different locomotion techniques depending on the degree of environment dynamism and and type of task.
C1 [Kim, Hyunjeong; Jeon, Sang-Bin; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Yonsei, South Korea.
C3 Yonsei University
RP Lee, IK (corresponding author), Yonsei Univ, Dept Comp Sci, Yonsei, South Korea.
EM hcihjkim@yonsei.ac.kr; ludens0508@yonsei.ac.kr; iklee@yonsei.ac.kr
OI Kim, Hyunjeong/0000-0003-0156-5436; Lee, In-Kwon/0000-0002-1534-1882
FU National Research Foundation of Korea
FX No Statement Available
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Allen Gary., 2004, HUMAN SPATIAL MEMORY
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2288, DOI 10.1109/TVCG.2022.3150466
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Basili P, 2013, GAIT POSTURE, V37, P385, DOI 10.1016/j.gaitpost.2012.08.003
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Bohannon RW, 1997, AGE AGEING, V26, P15, DOI 10.1093/ageing/26.1.15
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bolte F., 2011, P VIRT REAL INT C, V1
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Buttussi F, 2023, INT J HUM-COMPUT ST, V177, DOI 10.1016/j.ijhcs.2023.103067
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chihak BJ, 2010, J EXP PSYCHOL HUMAN, V36, P1535, DOI 10.1037/a0020560
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Cohen J., 1988, Statistical power analysis for the behavioral sciences
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   CUTTING JE, 1995, PSYCHOL REV, V102, P627, DOI 10.1037/0033-295X.102.4.627
   Darken RP, 2002, HUM FAC ER, P493
   Erickson KI, 2011, P NATL ACAD SCI USA, V108, P3017, DOI 10.1073/pnas.1015950108
   Fan CW, 2023, Symposium Virtual Re, P53, DOI 10.1109/VR55154.2023.00021
   Frissen I, 2011, EXP BRAIN RES, V212, P163, DOI 10.1007/s00221-011-2717-9
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   HART S G, 1988, P139
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Huang S.-K., 2023, IEEE transactions on visualizationand computer graphics, V2
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kim H, 2018, PSYCHIAT INVEST, V15, P935, DOI 10.30773/pi.2018.06.28.3
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lee S.-B., 2023, arXiv preprintarXiv:2306.11433, V2
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Martinez ES, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P270, DOI 10.1109/VR51125.2022.00046
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Mousas C, 2021, VISUAL COMPUT, V37, P2823, DOI 10.1007/s00371-021-02202-6
   NCD Risk Factor Collaboration (NCD-RisC), 2016, Elife, V5, DOI 10.7554/eLife.13410
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Olivier Anne-Helene, 2018, IEEE Transactions on Visualization and Computer Graphics, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Prinz LM, 2023, IEEE T VIS COMPUT GR, V29, P5208, DOI 10.1109/TVCG.2022.3206915
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Razzaque S., 2005, Redirected walking
   Reason J.T., 1975, Motion sickness, V2
   Rebenitsch L., 2015, The ACM Magazine for Students, V22, P46
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Sanz FA, 2015, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2015.7223327
   Scavarelli R. J., 2017, P 2017 CHI C HUM FAC, P2915, DOI DOI 10.1145/3027063.3053180
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Williams B, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265961
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
NR 66
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2184
EP 2194
DI 10.1109/TVCG.2024.3372074
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400021
PM 38437127
DA 2024-08-05
ER

PT J
AU Li, M
   Pan, JJ
   Li, Y
   Gao, Y
   Qin, H
   Shen, Y
AF Li, Ming
   Pan, Junjun
   Li, Yu
   Gao, Yang
   Qin, Hong
   Shen, Yang
TI Multimodal Physiological Analysis of Impact of Emotion on Cognitive
   Control in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cognitive control; emotion; physiological signal; deep learning
AB Cognitive control is often perplexing to elucidate and can be easily influenced by emotions. Understanding the individual cognitive control level is crucial for enhancing VR interaction and designing adaptive and self-correcting VR/AR applications. Emotions can reallocate processing resources and influence cognitive control performance. However, current research has primarily emphasized the impact of emotional valence on cognitive control tasks, neglecting emotional arousal. In this study, we comprehensively investigate the influence of emotions on cognitive control based on the arousal-valence model. A total of 26 participants are recruited, inducing emotions through VR videos with high ecological validity and then performing related cognitive control tasks. Leveraging physiological data including EEG, HRV, and EDA, we employ classification techniques such as SVM, KNN, and deep learning to categorize cognitive control levels. The experiment results demonstrate that high-arousal emotions significantly enhance users' cognitive control abilities. Utilizing complementary information among multi-modal physiological signal features, we achieve an accuracy of 84.52% in distinguishing between high and low cognitive control. Additionally, time-frequency analysis results confirm the existence of neural patterns related to cognitive control, contributing to a better understanding of the neural mechanisms underlying cognitive control in VR. Our research indicates that physiological signals measured from both the central and autonomic nervous systems can be employed for cognitive control classification, paving the way for novel approaches to improve VR/AR interactions.
C1 [Li, Ming; Pan, Junjun; Gao, Yang] Beihang Univ, Beijing, Peoples R China.
   [Li, Yu; Shen, Yang] Beijing Normal Univ, Beijing, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Stony Brook, NY USA.
C3 Beihang University; Beijing Normal University; State University of New
   York (SUNY) System; State University of New York (SUNY) Stony Brook
RP Pan, JJ; Gao, Y (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM minglee@buaa.edu.cn; pan_junjun@buaa.edu.cn; yu.li@mail.bnu.edu.cn;
   gaoyangvr@buaa.edu.cn; qin@cs.stonybrook.edu; shenyang@bnu.edu.cn
RI Gao, Yang/JQV-9627-2023
OI Gao, Yang/0000-0002-9149-3554; , Junjun/0000-0002-7991-9540; QIN,
   HONG/0000-0001-7699-1355
FU National Key R&D Program of China
FX No Statement Available
CR Alfeld P., 1984, Computer-Aided Geometric Design, V1, P169, DOI 10.1016/0167-8396(84)90029-3
   Antonenko P, 2010, EDUC PSYCHOL REV, V22, P425, DOI 10.1007/s10648-010-9130-y
   Ben Abdessalem H, 2017, LECT NOTES ARTIF INT, V10512, P133, DOI 10.1007/978-3-319-67615-9_12
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cao RC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P729, DOI 10.1109/VR50410.2021.00100
   Chaumon M, 2015, J NEUROSCI METH, V250, P47, DOI 10.1016/j.jneumeth.2015.02.025
   Chiossi F, 2022, IT-INF TECHNOL, V64, P133, DOI 10.1515/itit-2022-0035
   Chiossi Francesco, 2023, EXTENDED ABSTRACTS 2, P1
   Clements GM, 2023, NEUROIMAGE, V270, DOI 10.1016/j.neuroimage.2023.119956
   Clements GM, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.621620
   Clements JM, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P451, DOI 10.1109/VR.2018.8446068
   Clore GL, 2007, TRENDS COGN SCI, V11, P393, DOI 10.1016/j.tics.2007.08.005
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dolcos F, 2006, J NEUROSCI, V26, P2072, DOI 10.1523/JNEUROSCI.5042-05.2006
   Fairclough SH, 2005, INT J PSYCHOPHYSIOL, V56, P171, DOI 10.1016/j.ijpsycho.2004.11.003
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Fitzgibbon SP, 2007, J CLIN NEUROPHYSIOL, V24, P232, DOI 10.1097/WNP.0b013e3180556926
   Gerry L, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188479
   Gonthier C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01822
   Gray JR, 2004, CURR DIR PSYCHOL SCI, V13, P46, DOI 10.1111/j.0963-7214.2004.00272.x
   Hinault T, 2019, HUM BRAIN MAPP, V40, P80, DOI 10.1002/hbm.24356
   Jacoby M, 2013, IEEE T NEUR SYS REH, V21, P182, DOI 10.1109/TNSRE.2012.2235184
   Johannessen E, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106393
   Johnson JA, 2005, CEREB CORTEX, V15, P1609, DOI 10.1093/cercor/bhi039
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Lawhern VJ, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aace8c
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Li M, 2022, IEEE T VIS COMPUT GR, V28, P3832, DOI 10.1109/TVCG.2022.3203099
   Linnenbrink-Garcia L, 2011, CONTEMP EDUC PSYCHOL, V36, P1, DOI 10.1016/j.cedpsych.2010.11.004
   Loewenstein G, 2003, SER AFFECTIVE SCI, P619
   Luong T, 2022, IEEE T VIS COMPUT GR, V28, P5154, DOI 10.1109/TVCG.2021.3110459
   Luong T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P809, DOI [10.1109/VR.2019.8798029, 10.1109/vr.2019.8798029]
   MacPherson MK, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.10.021
   Mahjoory K, 2019, NEUROIMAGE, V188, P135, DOI 10.1016/j.neuroimage.2018.12.001
   Mayer R. E., 2005, The Cambridge handbook of multimedia learning, DOI DOI 10.1017/CBO9780511816819
   McCorry LK, 2007, AM J PHARM EDUC, V71, DOI 10.5688/aj710478
   Munoz John E., 2021, Adaptive Instructional Systems. Design and Evaluation. Third International Conference, AIS 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings, P559, DOI 10.1007/978-3-030-77857-6_40
   Parsons TD, 2018, IEEE T AFFECT COMPUT, V9, P66, DOI 10.1109/TAFFC.2016.2569086
   PEKRUN R, 1992, APPL PSYCHOL-INT REV, V41, P359, DOI 10.1111/j.1464-0597.1992.tb00712.x
   Plass JL, 2019, EDUC PSYCHOL REV, V31, P339, DOI 10.1007/s10648-019-09473-5
   Pratiher Sawon, 2022, Affective physiological state analysis and interpretable predictive modeling of marksmanship in Go/NoGo VR shootingdifficulty task
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sadaghiani S, 2016, TRENDS COGN SCI, V20, P805, DOI 10.1016/j.tics.2016.09.004
   Somarathna R, 2023, IEEE T AFFECT COMPUT, V14, P2626, DOI 10.1109/TAFFC.2022.3181053
   Stogios N, 2021, NPJ SCHIZOPHR, V7, DOI 10.1038/s41537-021-00151-6
   Stoll FM, 2016, CEREB CORTEX, V26, P1715, DOI 10.1093/cercor/bhv006
   Storbeck J, 2016, COGNITION EMOTION, V30, P925, DOI 10.1080/02699931.2015.1034091
   Straub E, 2020, COGNITION EMOTION, V34, P807, DOI 10.1080/02699931.2019.1666799
   Sztajzel J, 2004, SWISS MED WKLY, V134, P514
   Tian F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256211
   Vortmann LM, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3463507
   Xiong RL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185122
NR 55
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2044
EP 2054
DI 10.1109/TVCG.2024.3372101
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400072
PM 38437118
DA 2024-08-05
ER

PT J
AU Wang, SY
   Yan, H
   Isaacs, KE
   Sun, YF
AF Wang, Shaoyu
   Yan, Hang
   Isaacs, Katherine E.
   Sun, Yifan
TI Visual Exploratory Analysis for Designing Large-Scale Network-on-Chip
   Architectures: A Domain Expert-Led Design Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Computer architecture;
   Network-on-chip; Behavioral sciences; Synchronization; Collaboration;
   design study; network-on-chip; performance analysis
ID NOC; BYPASS; ATTACK
AB Visualization design studies bring together visualization researchers and domain experts to address yet unsolved data analysis challenges stemming from the needs of the domain experts. Typically, the visualization researchers lead the design study process and implementation of any visualization solutions. This setup leverages the visualization researchers' knowledge of methodology, design, and programming, but the availability to synchronize with the domain experts can hamper the design process. We consider an alternative setup where the domain experts take the lead in the design study, supported by the visualization experts. In this study, the domain experts are computer architecture experts who simulate and analyze novel computer chip designs. These chips rely on a Network-on-Chip (NOC) to connect components. The experts want to understand how the chip designs perform and what in the design led to their performance. To aid this analysis, we develop Vis4Mesh, a visualization system that provides spatial, temporal, and architectural context to simulated NOC behavior. Integration with an existing computer architecture visualization tool enables architects to perform deep-dives into specific architecture component behavior. We validate Vis4Mesh through a case study and a user study with computer architecture researchers. We reflect on our design and process, discussing advantages, disadvantages, and guidance for engaging in a domain expert-led design studies.
C1 [Wang, Shaoyu; Yan, Hang] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
   [Isaacs, Katherine E.] Univ Utah, Salt Lake City, UT 84112 USA.
   [Sun, Yifan] William & Mary, Williamsburg, VA 23185 USA.
C3 Huazhong University of Science & Technology; Utah System of Higher
   Education; University of Utah
RP Sun, YF (corresponding author), William & Mary, Williamsburg, VA 23185 USA.
EM wsyy0619@gmail.com; iyanhang@gmail.com; kisaacs@sci.utah.edu;
   ysun25@wm.edu
RI Shaoyu, Wang/HSH-3251-2023
OI Yan, Hang/0000-0002-3386-8784; Sun, Yifan/0000-0003-3532-6521; Isaacs,
   Katherine/0000-0002-9947-928X
FU National Science Foundation
FX No Statement Available
CR Akbaba D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581168
   Ariel A, 2010, INT SYM PERFORM ANAL, P164, DOI 10.1109/ISPASS.2010.5452029
   Ascia G, 2020, INT SYMP NETW CHIP
   Bashir J, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241713
   Bharadwaj S, 2021, INT SYMP NETW CHIP, P49, DOI 10.1145/3479876.3481590
   Bhatele A, 2016, INT PARALL DISTRIB P, P93, DOI 10.1109/IPDPS.2016.123
   Bisht B, 2022, IEEE DES TEST, V39, P39, DOI 10.1109/MDAT.2022.3202998
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brown K.A., 2014, PROC 21 EUR MPI USER, DOI DOI 10.1145/2642769.2642789
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen C, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241585
   Chen ZQ, 2022, IEEE DES TEST, V39, P48, DOI 10.1109/MDAT.2022.3204201
   Cheng SH, 2014, 2014 FIRST WORKSHOP ON VISUAL PERFORMANCE ANALYSIS (VPA), P9, DOI 10.1109/VPA.2014.7
   Devkota S, 2021, IEEE T VIS COMPUT GR, V27, P667, DOI 10.1109/TVCG.2020.3030357
   Fujiwara T, 2017, IEEE CONF VIS ANAL, P59, DOI 10.1109/VAST.2017.8585646
   Gogte V., 2015, PROC 8 INT WORKSHOP, P21, DOI [10.1145/2835512.2835518, DOI 10.1145/2835512.2835518]
   González JA, 2021, INT SYMP NETW CHIP, P61
   Grammatikakis MD, 2021, INT SYMP NETW CHIP, P75, DOI 10.1145/3479876.3481598
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   Haynes R., 2001, Proceedings 2001 IEEE International Conference on Cluster Computing, P295, DOI 10.1109/CLUSTR.2001.959990
   Isaacs KE, 2012, 2012 SC COMPANION: HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SCC), P1380
   Joseph JM, 2021, INT SYMP NETW CHIP, P15, DOI 10.1145/3479876.3481591
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung DC, 2020, INT SYMP NETW CHIP
   Kaeli D., 2015, PROC WORKSHOP COMPUT, P1, DOI [10.1145/2795122.2795125, DOI 10.1145/2795122.2795125]
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Koh LC, 2011, IEEE INT CONF INF VI, P90, DOI 10.1109/IV.2011.32
   Krichene H, 2021, INT SYMP NETW CHIP, P9, DOI 10.1145/3479876.3481588
   Kulkarni VJ, 2021, INT SYMP NETW CHIP, P21, DOI 10.1145/3479876.3481597
   Landge AG, 2012, IEEE T VIS COMPUT GR, V18, P2467, DOI 10.1109/TVCG.2012.286
   Landstorfer J, 2014, IEEE CONF VIS ANAL, P73, DOI 10.1109/VAST.2014.7042483
   Lang I, 2021, INT SYMP NETW CHIP, P55, DOI 10.1145/3479876.3481593
   León GM, 2020, COMPUT GRAPH FORUM, V39, P291, DOI 10.1111/cgf.13981
   Leyva N, 2022, IEEE DES TEST, V39, P58, DOI 10.1109/MDAT.2022.3202996
   Li Y, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241709
   Li ZM, 2022, IEEE DES TEST, V39, P79, DOI 10.1109/MDAT.2022.3202993
   Luan H, 2022, IEEE DES TEST, V39, P5, DOI 10.1109/MDAT.2022.3202997
   Luan H, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241708
   Mallappa U, 2022, IEEE DES TEST, V39, P16, DOI 10.1109/MDAT.2022.3202994
   Manju R, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241711
   McCarthy CM, 2014, 2014 First Workshop on Visual Performance Analysis (VPA), P24, DOI 10.1109/VPA.2014.10
   McKenna S, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12904
   Moller L., 2009, PROC 4 INT TEST WORK, P1, DOI [10.1109/IDT.2009.5404105, DOI 10.1109/IDT.2009.5404105]
   Monemi A, 2021, INT SYMP NETW CHIP, P41, DOI 10.1145/3479876.3481601
   Muñoz-Martínez F, 2021, INT SYMP NETW CHIP, P1, DOI 10.1145/3479876.3481602
   Ou YH, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241710
   Petrisko D, 2020, INT SYMP NETW CHIP
   Psistakis A, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241587
   Sarihi A, 2021, INT SYMP NETW CHIP, P29, DOI 10.1145/3479876.3481592
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shalaby A, 2021, INT SYMP NETW CHIP, P67, DOI 10.1145/3479876.3481595
   Simon SA., 2015, Ecological Modeling and Fire, P1, DOI [10.2312/eurovisshort.20151137, DOI 10.2312/EUROVISSHORT.20151137]
   Sobhani V, 2022, IEEE DES TEST, V39, P70, DOI 10.1109/MDAT.2022.3204199
   Sudusinghe C, 2022, IEEE DES TEST, V39, P28, DOI 10.1109/MDAT.2022.3202995
   Sudusinghe C, 2021, INT SYMP NETW CHIP, P35, DOI 10.1145/3479876.3481589
   Summers K. L., 2004, Information Visualization, V3, P209, DOI 10.1057/palgrave.ivs.9500079
   Sun YF, 2021, COMPUT GRAPH FORUM, V40, P239, DOI 10.1111/cgf.14303
   Sun YF, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P197, DOI 10.1145/3307650.3322230
   Sun YF, 2016, I S WORKL CHAR PROC, P13, DOI 10.1109/IISWC.2016.7581262
   Theisen L, 2014, 2014 FIRST WORKSHOP ON VISUAL PERFORMANCE ANALYSIS (VPA), P17, DOI 10.1109/VPA.2014.6
   Vatsavai SS, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241712
   Wang JS, 2016, THIRD ACM INTERNATIONAL WORKSHOP ON MANY-CORE EMBEDDED SYSTEMS (MES 2016), P18, DOI 10.1145/2934495.2949544
   Williams K, 2020, IEEE T VIS COMPUT GR, V26, P1118, DOI 10.1109/TVCG.2019.2934285
   Yin JM, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241583
   Zhang Yixuan, 2023, IEEE Trans Vis Comput Graph, V29, P1037, DOI 10.1109/TVCG.2022.3209493
NR 65
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1970
EP 1983
DI 10.1109/TVCG.2023.3337173
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500004
PM 38015697
DA 2024-08-05
ER

PT J
AU Chen, LF
   Wang, H
   Ouyang, Y
   Zhou, Y
   Wang, NY
   Li, Q
AF Chen, Longfei
   Wang, He
   Ouyang, Yang
   Zhou, Yang
   Wang, Naiyu
   Li, Quan
TI FSLens: A Visual Analytics Approach to Evaluating and Optimizing the
   Spatial Layout of Fire Stations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatiotemporal Analysis; Multi-criteria Decision Making; Visualization
ID LOCATION MODEL; HIERARCHY PROCESS; SITE SELECTION; OPTIMIZATION
AB The provision of fire services plays a vital role in ensuring the safety of residents' lives and property. The spatial layout of fire stations is closely linked to the efficiency of fire rescue operations. Traditional approaches have primarily relied on mathematical planning models to generate appropriate layouts by summarizing relevant evaluation criteria. However, this optimization process presents significant challenges due to the extensive decision space, inherent conflicts among criteria, and decision-makers' preferences. To address these challenges, we propose FSLens, an interactive visual analytics system that enables in-depth evaluation and rational optimization of fire station layout. Our approach integrates fire records and correlation features to reveal fire occurrence patterns and influencing factors using spatiotemporal sequence forecasting. We design an interactive visualization method to explore areas within the city that are potentially under-resourced for fire service based on the fire distribution and existing fire station layout. Moreover, we develop a collaborative human-computer multi-criteria decision model that generates multiple candidate solutions for optimizing firefighting resources within these areas. We simulate and compare the impact of different solutions on the original layout through well-designed visualizations, providing decision-makers with the most satisfactory solution. We demonstrate the effectiveness of our approach through one case study with real-world datasets. The feedback from domain experts indicates that our system helps them to better identify and improve potential gaps in the current fire station layout.
C1 [Chen, Longfei; Wang, He; Ouyang, Yang; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Chen, Longfei; Wang, He; Ouyang, Yang; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
   [Zhou, Yang; Wang, Naiyu] Zhejiang Univ, Coll Civil Engn & Architecture, Hangzhou, Peoples R China.
C3 ShanghaiTech University; Zhejiang University
RP Li, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.; Li, Q (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
EM chenlf@shanghaitech.edu.cn; wanghe1@shanghaitech.edu.cn;
   ouyy@shanghaitech.edu.cn; yang-zhou@zju.edu.cn; naiyuwang@zju.edu.cn;
   liquan@shanghaitech.edu.cn
OI , Yang/0009-0000-5841-7659; Chen, Longfei/0009-0002-4596-8093; Wang,
   He/0009-0003-2550-6139
FU Research and System Development of Resilient Urban Fire Risk and Fire
   Safety Dynamic Assessment Technology Based on Multiple Data Sources
FX No Statement Available
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   Aruldoss M., 2013, American Journal of Information Systems, V1, P31, DOI [10.12691/ajis-1-1-5, DOI 10.12691/AJIS-1-1-5]
   Badri MA, 1998, EUR J OPER RES, V110, P243, DOI 10.1016/S0377-2217(97)00247-6
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   BATTA R, 1989, TRANSPORT SCI, V23, P277, DOI 10.1287/trsc.23.4.277
   Benesty J, 2009, Noise Reduction in Speech Processing, V2, P1, DOI [DOI 10.1007/978-3-642-00296-05, 10.1109/5.771073, DOI 10.1007/978-3-642-00296-0_5]
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Borgo R., 2013, Eurographics 2013-State of the Art Reports, DOI DOI 10.2312/CONF/EG2013/STARS/039
   Carenini Giuseppe, 2004, Proceedings of the working conference on Advanced visual interfaces, P150
   Chaudhary P, 2016, SOCIO-ECON PLAN SCI, V53, P60, DOI 10.1016/j.seps.2015.10.001
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Church R., 1974, Papers in Regional Science, V32, P101, DOI DOI 10.1007/BF01942293
   Church R. L., 1999, Geographical information systems, V1, P2
   DASKIN MS, 1983, TRANSPORT SCI, V17, P48, DOI 10.1287/trsc.17.1.48
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Doeksen G. A., 1976, Southern Journal of Agricultural Economics, V8, P121
   Düzçeker A, 2021, PROC CVPR IEEE, P15319, DOI 10.1109/CVPR46437.2021.01507
   Echeverria F, 2018, DYNA-BILBAO, V93, DOI 10.6036/8408
   Erden T, 2010, NAT HAZARD EARTH SYS, V10, P2127, DOI 10.5194/nhess-10-2127-2010
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Hailesilassie T, 2016, Arxiv, DOI arXiv:1610.05267
   Hilton BN, 2011, INFORM VISUAL, V10, P82, DOI 10.1057/ivs.2010.14
   HOGG JM, 1968, OPER RES QUART, V19, P275, DOI 10.2307/3008620
   Karamshuk D, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P793
   Karpathy A, 2015, Arxiv, DOI [arXiv:1506.02078, DOI 10.48550/ARXIV.1506.02078]
   Kiran KC, 2018, GEOGR RES-AUST, V56, P270, DOI 10.1111/1745-5871.12288
   Li Q, 2020, COMPUT GRAPH FORUM, V39, P483, DOI 10.1111/cgf.13996
   Liu DL, 2020, FIRE SAFETY J, V118, DOI 10.1016/j.firesaf.2020.103238
   Liu DL, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196632
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Lundberg SM, 2017, ADV NEUR IN, V30
   Luo JL, 2019, CASE STUD THERM ENG, V14, DOI 10.1016/j.csite.2019.100495
   Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100
   Mehler A, 2006, IEEE T VIS COMPUT GR, V12, P765, DOI 10.1109/TVCG.2006.179
   Miller B. L., 1995, Complex systems, V9, P5
   Monarchi D. E., 1977, Decision Sciences, V8, P211
   Murray AT, 2013, FIRE SAFETY J, V62, P64, DOI 10.1016/j.firesaf.2013.03.002
   N. NFPA, 2010, 1710 standard for the organization and deployment of fire suppression operations, emergency medical operations, and special operations to the public by career fire departments, P6
   Olah C., 2015, Understanding lstm networks, P5
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Pellegrini AFA, 2018, NATURE, V553, P194, DOI 10.1038/nature24668
   PLANE DR, 1977, OPER RES, V25, P563, DOI 10.1287/opre.25.4.563
   Reilly J.M., 1985, Fire Technology, V21, P181, DOI [10.1007/BF01039973, DOI 10.1007/BF01039973]
   Robin C, 2022, Arxiv, DOI arXiv:2210.13648
   SCHILLING DA, 1980, EUR J OPER RES, V5, P1, DOI 10.1016/0377-2217(80)90067-3
   SCHREUDER JAM, 1981, EUR J OPER RES, V6, P212, DOI 10.1016/0377-2217(81)90210-1
   Sen A., 2011, The Gibbard random dictatorship theorem: A generalization and a new proof, P2
   Shi XJ, 2015, ADV NEUR IN, V28
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stein M., 2016, 12th European International Farming Systems Association (IFSA) Symposium, Social and technological transformation of farming systems: Diverging and converging pathways, 12-15 July 2016, Harper Adams University, Newport, Shropshire, UK, P1
   Tan C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Tekin SF, 2023, Arxiv, DOI arXiv:2102.00696
   TOREGAS C, 1971, OPER RES, V19, P1363, DOI 10.1287/opre.19.6.1363
   Tzeng GH, 2011, MULTIPLE ATTRIBUTE DECISION MAKING: METHODS AND APPLICATIONS, P1
   Uddin MS, 2020, NAT HAZARDS, V102, P1475, DOI 10.1007/s11069-020-03981-2
   WEAVER JR, 1985, TRANSPORT SCI, V19, P58, DOI 10.1287/trsc.19.1.58
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Xin-ming Dong, 2018, Procedia Engineering, V211, P124, DOI 10.1016/j.proeng.2017.12.129
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Xu ZS, 2021, CASE STUD THERM ENG, V25, DOI 10.1016/j.csite.2021.100957
   Yang LL, 2007, EUR J OPER RES, V181, P903, DOI 10.1016/j.ejor.2006.07.003
   Yu B, 2018, Arxiv, DOI arXiv:1709.04875
   Yu YF, 2012, PROCEEDINGS OF THE 2012 EIGHTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2012), P328, DOI 10.1109/CIS.2012.80
   Zhang C., 2022, IEEE Trans. Vis. Comput. Graphics, V29, P767
   Zhang GW, 2019, CASE STUD THERM ENG, V14, DOI 10.1016/j.csite.2019.100426
   Zhang JW, 2014, IEEE T VIS COMPUT GR, V20, P1843, DOI 10.1109/TVCG.2014.2346898
   Zhongming Z., 2009, Ministry of housing and urban-rural development of the people's republic of china, P2
NR 69
TC 1
Z9 1
U1 5
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 847
EP 857
DI 10.1109/TVCG.2023.3327077
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500094
PM 37878448
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zafar, A
   Yang, D
   Chen, GN
AF Zafar, Adeel
   Yang, Di
   Chen, Guoning
TI Extract and Characterize Hairpin Vortices in Turbulent Flows
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Turbulent flow; vortices; hairpin vortex extraction
ID OF-THE-ART; IDENTIFICATION; VISUALIZATION; DYNAMICS; TRACKING; FIELDS
AB Hairpin vortices are one of the most important vortical structures in turbulent flows. Extracting and characterizing hairpin vortices provides useful insight into many behaviors in turbulent flows. However, hairpin vortices have complex configurations and might be entangled with other vortices, making their extraction difficult. In this work, we introduce a framework to extract and separate hairpin vortices in shear driven turbulent flows for their study. Our method first extracts general vortical regions with a region-growing strategy based on certain vortex criteria (e.g., $\lambda_{2}$) and then separates those vortices with the help of progressive extraction of ($\lambda_{2}$) iso-surfaces in a top-down fashion. This leads to a hierarchical tree representing the spatial proximity and merging relation of vortices. After separating individual vortices, their shape and orientation information is extracted. Candidate hairpin vortices are identified based on their shape and orientation information as well as their physical characteristics. An interactive visualization system is developed to aid the exploration, classification, and analysis of hairpin vortices based on their geometric and physical attributes. We also present additional use cases of the proposed system for the analysis and study of general vortices in other types of flows.
C1 [Zafar, Adeel; Yang, Di; Chen, Guoning] Univ Houston, Houston, TX 77004 USA.
C3 University of Houston System; University of Houston
RP Zafar, A (corresponding author), Univ Houston, Houston, TX 77004 USA.
EM azafar3@uh.edu; diyang@uh.edu; gchen16@uh.edu
OI Chen, Guoning/0000-0003-0581-6415
FU NSF OAC
FX No Statement Available
CR Adrian RJ, 2007, PHYS FLUIDS, V19, DOI 10.1063/1.2717527
   Bai X, 2019, IEEE ACCESS, V7, P106336, DOI 10.1109/ACCESS.2019.2931781
   Banks D. C., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P132, DOI 10.1109/VISUAL.1994.346327
   Berenjkoub M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P261, DOI 10.1109/VIS47514.2020.00059
   Berenjkoub M, 2019, IEEE T VIS COMPUT GR, V25, P1246, DOI 10.1109/TVCG.2018.2864817
   Bremer PT, 2016, COMM APP MATH COM SC, V11, P37, DOI 10.2140/camcos.2016.11.37
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Chakraborty P, 2005, J FLUID MECH, V535, P189, DOI 10.1017/S0022112005004726
   CHONG MS, 1990, PHYS FLUIDS A-FLUID, V2, P765, DOI 10.1063/1.857730
   Deng L, 2019, J VISUAL-JAPAN, V22, P65, DOI 10.1007/s12650-018-0523-1
   FIELD DA, 1988, COMMUN APPL NUMER M, V4, P709, DOI 10.1002/cnm.1630040603
   Franz K, 2018, INT GEOSCI REMOTE SE, P6887, DOI 10.1109/IGARSS.2018.8519261
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Hadwiger M, 2019, IEEE T VIS COMPUT GR, V25, P1257, DOI 10.1109/TVCG.2018.2864839
   Haller G, 2005, J FLUID MECH, V525, P1, DOI 10.1017/S0022112004002526
   Haller G, 2016, J FLUID MECH, V795, P136, DOI 10.1017/jfm.2016.151
   Haller G, 2015, ANNU REV FLUID MECH, V47, P137, DOI 10.1146/annurev-fluid-010313-141322
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hunt J.C., 1988, Studying Turbulence Using Numerical Simulation Databases, P2
   HUNT JCR, 1987, T CAN SOC MECH ENG, V11, P21, DOI 10.1139/tcsme-1987-0004
   JEONG J, 1995, J FLUID MECH, V285, P69, DOI 10.1017/S0022112095000462
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P285, DOI 10.1111/cgf.13689
   KIM J, 1987, J FLUID MECH, V177, P133, DOI 10.1017/S0022112087000892
   Lguensat R, 2018, INT GEOSCI REMOTE SE, P1764, DOI 10.1109/IGARSS.2018.8518411
   Li M, 2019, PHYS FLUIDS, V31, DOI 10.1063/1.5099650
   Lugt H. J., 1979, Recent developments in theoretical and experimental fluid mechanics. Compressible and incompressible flows, P309
   Michalak LP, 2018, TOPOL METHOD NONL AN, V52, P749, DOI 10.12775/TMNA.2018.029
   Nguyen DB, 2023, IEEE T VIS COMPUT GR, V29, P1531, DOI 10.1109/TVCG.2021.3124729
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Nguyen DB, 2021, COMPUT GRAPH FORUM, V40, P22, DOI 10.1111/cgf.14093
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P719, DOI 10.1109/TVCG.2019.2934367
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P3147, DOI 10.1109/TVCG.2019.2920157
   OKUBO A, 1970, DEEP-SEA RES, V17, P445, DOI 10.1016/0011-7471(70)90059-8
   Peikert R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P263, DOI 10.1109/VISUAL.1999.809896
   Pobitzer A, 2011, COMPUT GRAPH FORUM, V30, P1789, DOI 10.1111/j.1467-8659.2011.01901.x
   Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x
   ROBINSON SK, 1991, ANNU REV FLUID MECH, V23, P601, DOI 10.1146/annurev.fluid.23.1.601
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Sadarjoen IA, 2000, COMPUT GRAPH-UK, V24, P333, DOI 10.1016/S0097-8493(00)00029-7
   Salzbrunn T, 2008, VISUAL COMPUT, V24, P1039, DOI 10.1007/s00371-007-0204-x
   Salzbrunn T, 2006, IEEE T VIS COMPUT GR, V12, P1601, DOI 10.1109/TVCG.2006.104
   Schneider D, 2008, IEEE T VIS COMPUT GR, V14, P1475, DOI 10.1109/TVCG.2008.143
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Sujudi D., 1995, 12 COMP FLUID DYN C, P1715
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Kreveld M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P212, DOI 10.1145/262839.269238
   Wang YQ, 2021, VISUAL COMPUT, V37, P261, DOI 10.1007/s00371-020-01797-6
   Weinkauf T, 2007, IEEE T VIS COMPUT GR, V13, P1759, DOI 10.1109/TVCG.2007.70545
   Weinkauf T, 2010, IEEE T VIS COMPUT GR, V16, P1225, DOI 10.1109/TVCG.2010.198
   WEISS J, 1991, PHYSICA D, V48, P273, DOI 10.1016/0167-2789(91)90088-Q
   Wiebel A, 2011, MATH VIS, P193
   Wu J.-Z., 2006, Vorticity and Vortex Dynamics, P519, DOI [10.1007/978-3-540-29028-5_10, DOI 10.1007/978-3-540-29028-5_10]
   Zafar A., IEEE VISUALIZATION 2, V5, P7
NR 55
TC 1
Z9 1
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 716
EP 726
DI 10.1109/TVCG.2023.3326603
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500128
PM 37874728
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zheng, JT
   Zhang, E
   Zhang, Y
AF Zheng, Jinta
   Zhang, Eugene
   Zhang, Yue
TI Interactive Design and Optics-Based Visualization of Arbitrary
   Non-Euclidean Kaleidoscopic Orbifolds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Kaleidoscopic Orbifolds; Orbifold Visualization; Math Visualization;
   Orbifold Construction; Spherical Geometry; Hyperbolic Geometry
ID SURFACES
AB Orbifolds are a modern mathematical concept that arises in the research of hyperbolic geometry with applications in computer graphics and visualization. In this paper, we make use of rooms with mirrors as the visual metaphor for orbifolds. Given any arbitrary two-dimensional kaleidoscopic orbifold, we provide an algorithm to construct a Euclidean, spherical, or hyperbolic polygon to match the orbifold. This polygon is then used to create a room for which the polygon serves as the floor and the ceiling. With our system that implements Mobius transformations, the user can interactively edit the scene and see the reflections of the edited objects. To correctly visualize non-Euclidean orbifolds, we adapt the rendering algorithms to account for the geodesics in these spaces, which light rays follow. Our interactive orbifold design system allows the user to create arbitrary two-dimensional kaleidoscopic orbifolds. In addition, our mirror-based orbifold visualization approach has the potential of helping our users gain insight on the orbifold, including its orbifold notation as well as its universal cover, which can also be the spherical space and the hyperbolic space.
C1 [Zheng, Jinta; Zhang, Eugene; Zhang, Yue] Oregon State Univ, Corvallis, OR 97331 USA.
C3 Oregon State University
RP Zheng, JT (corresponding author), Oregon State Univ, Corvallis, OR 97331 USA.
EM zhenjint@eecs.oregonstate.edu; zhange@eecs.oregonstate.edu;
   zhangyue@oregonstate.edu
OI Zhang, Yue/0000-0002-8467-2781; Zhang, Eugene/0000-0003-4752-3119
FU NSF
FX No Statement Available
CR Aigerman N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073615
   Aigerman N, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982412
   Aigerman N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818099
   Anderson J. W, 2005, Hyperbolic Geometry, DOI DOI 10.1007/1-84628-220-9
   [Anonymous], Irrlicht engine
   Basmajian A, 2006, Arxiv, DOI arXiv:math/0603457
   Berger P, 2015, VISUAL COMPUT, V31, P93, DOI 10.1007/s00371-013-0913-2
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Conway J., 2008, Ak Peters Series, DOI DOI 10.1201/B21368
   Cooper D., 2000, MSJ Memoirs, V5, DOI DOI 10.2969/MSJMEMOIRS/00501C020
   COXETER H.S.M., 1998, Non-euclidean geometry
   Giaccari S, 2023, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2023)173
   Greaves G, 2012, J ALGEBRA, V372, P560, DOI 10.1016/j.jalgebra.2012.09.006
   Conway JH, 2018, Arxiv, DOI arXiv:1804.03055
   Hanson Andrew J, 2005, ACM SIGGRAPH 2005 CO, P1, DOI [DOI 10.1145/1198555.1198701, 10.1145/1198555.1198701]
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Hitchman M. P., 2009, Geometry with an introduction to cosmic topology
   Humphreys J. F., 1996, Oxford Science Publications, V5
   Jakob Wenzel, 2010, Mitsuba renderer
   Kälberer F, 2007, COMPUT GRAPH FORUM, V26, P375, DOI 10.1111/j.1467-8659.2007.01060.x
   Miley P., 1998, A Study of Orbifolds
   Nieser M, 2012, IEEE T VIS COMPUT GR, V18, P865, DOI 10.1109/TVCG.2011.118
   Nieser M, 2010, LECT NOTES COMPUT SC, V6130, P161, DOI 10.1007/978-3-642-13411-1_11
   Novello T, 2020, COMPUT GRAPH-UK, V93, P61, DOI 10.1016/j.cag.2020.09.014
   OShea D., 2007, The Poincare Conjecture: In Search of the Shape of the Universe, DOI DOI 10.5860/CHOICE.45-0926
   Palacios J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276446, 10.1145/1239451.1239506]
   Palacios J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130844
   Palacios J, 2016, IEEE T VIS COMPUT GR, V22, P1248, DOI 10.1109/TVCG.2015.2484343
   Qu BT, 2021, IEEE T VIS COMPUT GR, V27, P583, DOI 10.1109/TVCG.2020.3030431
   Roy L, 2019, IEEE T VIS COMPUT GR, V25, P1102, DOI 10.1109/TVCG.2018.2864768
   Roy L, 2018, IEEE T VIS COMPUT GR, V24, P843, DOI 10.1109/TVCG.2017.2744038
   Thurston WP., 1997, Three-Dimensional Geometry and Topology, Princeton Mathematical Series 35, DOI DOI 10.1515/9781400865321
   van Wijk J., 2005, Visualization of the genus of knots, P01, DOI DOI 10.1109/VISUAL.2005.1532843
   Williams F., 2016, SIGGRAPH ASIA 2016 T, DOI DOI 10.1145/3005358.3005368
   Zeller R, 2021, COMPUT AIDED GEOM D, V90, DOI 10.1016/j.cagd.2021.102027
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
NR 36
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1292
EP 1301
DI 10.1109/TVCG.2023.3326927
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500074
PM 37874711
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ban, YK
   Ujitoko, Y
AF Ban, Yuki
   Ujitoko, Yusuke
TI Age and Gender Differences in the Pseudo-Haptic Effect on Computer Mouse
   Operation in a Desktop Environment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Mice; Visualization; Adaptive optics; Optical
   sensors; Cultural differences; Optical modulation; Haptics;
   pseudo-haptics; individual difference
ID SEX-DIFFERENCES; DEVELOPMENTAL-CHANGES; INFORMATION; VISION;
   INTEGRATION; PERCEPTION; FEEDBACK; ILLUSION
AB Pseudo-haptics is a method that can provide a haptic sensation without requiring a physical haptic device. The effect of pseudo-haptics is known to depend on the individual, but it is unclear which factors cause individual differences. As the first study establishing a calibration method for these differences in future research, we examined the differences in the pseudo-haptic effect on mouse cursor operation in a desktop environment depending on the age and gender of the user. We conducted an online experiment and collected data from more than 400 participants. The participants performed a task of lifting a virtual object with a mouse pointer. We found that the effect of pseudo-haptics was greater in younger or male participants than in older or female participants. We also found that the effect of pseudo-haptics, which varied with age and gender, can be explained by habituation to the mouse in daily life and the accuracy of detecting the pointer position using vision or proprioception. Specifically, the pseudo-haptic effect was higher for those who used the mouse more frequently and had higher accuracy in identifying the pointer position using proprioception or vision. The results of the present study not only indicate the factors that cause age and gender differences but also provide hints for calibrating these differences.
C1 [Ban, Yuki] Univ Tokyo, Grad Sch Frontier Sci, Tokyo 1138654, Japan.
   [Ujitoko, Yusuke] NTT Corp, NTT Commun Sci Labs, Tokyo 1008116, Japan.
C3 University of Tokyo; Nippon Telegraph & Telephone Corporation
RP Ban, YK (corresponding author), Univ Tokyo, Grad Sch Frontier Sci, Tokyo 1138654, Japan.
EM ban@edu.k.u-tokyo.ac.jp; yusuke.ujitoko@gmail.com
RI Ujitoko, Yusuke/AAV-2457-2021
OI Ujitoko, Yusuke/0000-0001-6059-9324; Ban, Yuki/0000-0001-7349-6383
FU JSPS KAKENHI [19K20315, 21H03478]
FX This work was supported by JSPS KAKENHI under Grants 19K20315 and
   21H03478. Recommended for acceptance by M. Marchal
CR ADAMS E, 1962, J PHILOS, V59, P177, DOI 10.2307/2023734
   Ariff G, 2002, J NEUROSCI, V22, P7721
   Ban Y, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P991, DOI 10.1109/WHC49131.2021.9517129
   Ban YK, 2018, IEEE HAPTICS SYM, P278, DOI 10.1109/HAPTICS.2018.8357188
   Ban Y, 2014, IEEE HAPTICS SYM, P557, DOI 10.1109/HAPTICS.2014.6775516
   Bertelsen AS, 2020, FOODS, V9, DOI 10.3390/foods9020146
   Bjorka H., 2007, P INT C EN INT
   Block HJ, 2020, MULTISENS RES, V34, P93, DOI 10.1163/22134808-bja10032
   Bremner AJ, 2016, CHILD DEV, V87, P962, DOI 10.1111/cdev.12511
   Declerck C, 2002, PERCEPT MOTOR SKILL, V94, P3
   DeLoach LJ, 1998, ANESTH ANALG, V86, P102, DOI 10.1097/00000539-199801000-00020
   Dewar R. E., 1967, Psychon. Sci., V9, P345
   Doherty MJ, 2010, DEVELOPMENTAL SCI, V13, P714, DOI 10.1111/j.1467-7687.2009.00931.x
   Dresslar F. B., 1894, Amer.J.Psychol., V6, P313, DOI [10.2307/1411644, DOI 10.2307/1411644]
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   FRAISSE P, 1956, Q J EXP PSYCHOL, V8, P114, DOI 10.1080/17470215608416810
   Gepshtein S, 2003, CURR BIOL, V13, P483, DOI 10.1016/S0960-9822(03)00133-7
   Haaland D. L., 1993, Psychol.Aging, V8
   HANLEY C, 1965, CHILD DEV, V36, P437, DOI 10.1111/j.1467-8624.1965.tb05307.x
   Hisanaga S, 2016, SCI REP-UK, V6, DOI 10.1038/srep35265
   Honda T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00760
   Horiguchi T, 2016, LECT NOTES COMPUT SC, V9753, P156, DOI 10.1007/978-3-319-39483-1_15
   Kashihara G., 2015, IEICE Trans., VJ98-D, P104
   Kawabe T, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.811881
   Knudson J. Woodland, 2012, Comprehensive Psychol., V1, P24
   Kokubun A, 2014, IEEE HAPTICS SYM, P415, DOI 10.1109/HAPTICS.2014.6775491
   Krishna A, 2008, J CONSUM RES, V34, P807, DOI 10.1086/523286
   KROSNICK JA, 1991, APPL COGNITIVE PSYCH, V5, P213, DOI 10.1002/acp.2350050305
   Lcuyer A., 2004, P P SIGCHI C HUM FAC, P239, DOI [10.1145/985692.985723, DOI 10.1145/985692.985723]
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lécuyer A, 2001, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2001.913777
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   LEIBOWITZ HW, 1967, AM J PSYCHOL, V80, P105, DOI 10.2307/1420548
   Maguinness C, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00795
   MASSARO DW, 1986, J EXP CHILD PSYCHOL, V41, P93, DOI 10.1016/0022-0965(86)90053-6
   Naceri A, 2011, PRESENCE-TELEOP VIRT, V20, P254, DOI 10.1162/PRES_a_00048
   Noelting G., 1961, La Structuration Progressive De La Figure De Muller-LyerEn Fonction De La Repetition Chez L'enfant Et L'adulte
   Nomoto A, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875216
   NYSSEN R, 1956, ACTA PSYCHOL, V12, P157, DOI 10.1016/0001-6918(56)90016-6
   Oppenheimer DM, 2009, J EXP SOC PSYCHOL, V45, P867, DOI 10.1016/j.jesp.2009.03.009
   Papageorgiou C, 2020, PHYSIOL MEAS, V41, DOI 10.1088/1361-6579/abb2eb
   Peck J, 2003, J CONSUM RES, V30, P430, DOI 10.1086/378619
   Piaget J., 2013, The Mechanisms of Perception
   Rietzler F., 2018, P CHI C HUM FACT COM, P1
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   ROSS HE, 1987, NEUROPSYCHOLOGIA, V25, P841, DOI 10.1016/0028-3932(87)90122-9
   Samad M., 2019, P CHI C HUM FACT COM, P1
   Sandström CI, 1953, ACTA PSYCHOL, V9, P82, DOI 10.1016/0001-6918(53)90005-5
   SANTOSTEFANO S, 1963, Percept Mot Skills, V17, P23
   Schmidt L, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00915
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Shaqiri A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25298-8
   Sigmundsson H, 2007, SEX ROLES, V57, P181, DOI 10.1007/s11199-007-9228-y
   Skinner R. L., 1984, Clin. Orthopaedics Related Res., P51
   Skoura X, 2008, CORTEX, V44, P1271, DOI 10.1016/j.cortex.2007.07.008
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Taima Y, 2014, IEEE HAPTICS SYM, P175, DOI 10.1109/HAPTICS.2014.6775451
   Takamuku S, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2015.0864
   Ujitoko Y, 2021, IEEE T HAPTICS, V14, P699, DOI 10.1109/TOH.2021.3077619
   Ujitoko Y, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P181, DOI [10.1109/whc.2019.8816100, 10.1109/WHC.2019.8816100]
   Ujitoko Y, 2019, IEEE T VIS COMPUT GR, V25, P1981, DOI 10.1109/TVCG.2019.2898820
   van Mensvoort K., 2002, Proceedings Designing Interactive Systems, P345
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
NR 65
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5566
EP 5580
DI 10.1109/TVCG.2023.3295389
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400077
PM 37450361
OA Bronze
DA 2024-08-05
ER

PT J
AU Machuca, MDB
   Israel, JH
   Keefe, DF
   Stuerzlinger, W
AF Machuca, Mayra Donaji Barrera
   Israel, Johann Habakuk
   Keefe, Daniel F.
   Stuerzlinger, Wolfgang
TI Toward More Comprehensive Evaluations of 3D Immersive Sketching,
   Drawing, and Painting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Bibliographies; Task analysis; Art;
   Visualization; Creativity; Painting; Information interfaces and
   representation (HCI); artificial; augmented; and virtual realities;
   evaluation/ methodology
ID CONCEPTUAL DESIGN; CREATIVITY; USABILITY; SURFACES; THINKING; SHAPE
AB To understand current practice and explore the potential for more comprehensive evaluations of 3D immersive sketching, drawing, and painting, we present a survey of evaluation methodologies used in existing 3D sketching research, a breakdown and discussion of important phases (sub-tasks) in the 3D sketching process, and a framework that suggests how these factors can inform evaluation strategies in future 3D sketching research. Existing evaluations identified in the survey are organized and discussed within three high-level categories: 1) evaluating the 3D sketching activity, 2) evaluating 3D sketching tools, and 3) evaluating 3D sketching artifacts. The new framework suggests targeting evaluations to one or more of these categories and identifying relevant user populations. In addition, building upon the discussion of the different phases of the 3D sketching process, the framework suggests to evaluate relevant sketching tasks, which may range from low-level perception and hand movements to high-level conceptual design. Finally, we discuss limitations and challenges that arise when evaluating 3D sketching, including a lack of standardization of evaluation methods and multiple, potentially conflicting, ways to evaluate the same task and user interface usability; we also identify opportunities for more holistic evaluations. We hope the results can contribute to accelerating research in this domain and, ultimately, broad adoption of immersive sketching systems.
C1 [Machuca, Mayra Donaji Barrera] Dalhousie Univ, Halifax, NS B3H 4R2, Canada.
   [Israel, Johann Habakuk] HTW Berlin, D-10318 Berlin, Germany.
   [Keefe, Daniel F.] Univ Minnesota, Minneapolis, MN 55455 USA.
   [Stuerzlinger, Wolfgang] Simon Fraser Univ, Vancouver, BC V5A 1S6, Canada.
C3 Dalhousie University; University of Minnesota System; University of
   Minnesota Twin Cities; Simon Fraser University
RP Machuca, MDB (corresponding author), Dalhousie Univ, Halifax, NS B3H 4R2, Canada.
EM mbarrera@dal.ca; johannhabakuk.israel@htw-berlin.de; dfk@umn.edu;
   w.s@sfu.ca
OI Israel, Johann Habakuk/0000-0002-8513-6892; Keefe,
   Daniel/0000-0002-7039-2340; Barrera Machuca, Mayra
   Donaji/0000-0002-8057-7103; Stuerzlinger, Wolfgang/0000-0002-7110-5024
CR ACM, 2021, "ACM digital library.
   An SG, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P183, DOI 10.1145/3122986.3123002
   [Anonymous], 1980, Experiences in visual thinking
   [Anonymous], 2021, P CHI C HUM FACT COM
   Arora R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3459090
   Arora R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173759
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Auda J, 2021, LECT NOTES COMPUT SC, V12936, P195, DOI 10.1007/978-3-030-85607-6_14
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Barnet Sylvan., 2015, A Short Guide to Writing About ART
   Barrera Machuca M.D, P CREAT COGN NEW YOR
   Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Boddien C, 2017, PROCEEDINGS OF THE 2017 ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG 17), P101, DOI 10.1145/3103010.3121029
   Bohari U, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P177, DOI 10.1145/3172944.3172985
   Bruno M. L., 2002, P 14 C INT ING GRAF
   Buxton W., 2007, SketchingUserExperiences:GettingtheDesignRightandtheRight Design
   Cannavo Alberto, 2021, Interactivity and Game Creation. 9th EAI International Conference, ArtsIT 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 367), P291, DOI 10.1007/978-3-030-73426-8_17
   Chellali A.Chellali, P 5 JOINT VIRT REAL
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Chittenden T, 2018, J CONTEMP PAINTING, V4, P381, DOI 10.1386/jcp.4.2.381_1
   Cohen DJ, 1997, J EXP PSYCHOL HUMAN, V23, P609, DOI 10.1037/0096-1523.23.3.609
   Cordier F, 2011, IEEE T VIS COMPUT GR, V17, P1650, DOI 10.1109/TVCG.2010.258
   Deering M.F., 1995, "ACM Trans. Comput.-Hum. Interact., V2, P220
   Dey S., 2003, P 8 ACM S SOLID MODE, V3, P302, DOI DOI 10.1145/781606.781627
   Donath D., 1996, Design Computation, Collaboration, Reasoning, Pedagogy. Proceedings of the ACADIA 1996 Conference, P201
   Dorta T, 2016, INT J ARCHIT COMPUT, V14, P87, DOI 10.1177/1478077116638921
   Drey J., 2020, P CHI C HUM FACT COM, P1
   Dudley JJ, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P241, DOI 10.1145/3196709.3196737
   Ekstromer J., 2018, Virtual reality sketchingfor design ideation, P9
   Elsayed H., 2020, P 26 ACM S VIRT REAL
   Elsevier, 2021, "ScienceDirect.
   Eroglu S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P475, DOI 10.1109/VR.2018.8446595
   Fehling P., inKultur und Informatik.
   Fiorentino A. E., 2005, P 13 INT C CENTR EUR, P131
   Fleisch T, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P275, DOI 10.1109/SMI.2004.1314514
   Fleury S, 2021, THINK SKILLS CREAT, V40, DOI 10.1016/j.tsc.2021.100828
   FRONT, 2007, "Sketch furniture by front.
   Fuge M, 2012, COMPUT AIDED DESIGN, V44, P1020, DOI 10.1016/j.cad.2011.05.009
   Fuhrmann S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601163
   Gardner D., 2006, P 7 AUSTR US INT C, P177
   Giunchi D, 2021, PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2021, P144, DOI 10.1145/3452918.3458806
   Giunchi S., 2019, P 17 INT C VIRT REAL
   Google, 2020, "Tiltbrush.
   Google, 2021, "Google scholar.
   GOULD JD, 1985, COMMUN ACM, V28, P300, DOI 10.1145/3166.3170
   Grey J, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P761, DOI 10.1109/IV.2002.1028866
   Grossman T., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P121, DOI 10.1145/503376.503398
   Hacker W, 1999, SPRACHE KOGNIT, V18, P88, DOI 10.1024//0253-4533.18.34.88
   Hagbi N, 2010, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2010.5444806
   Haggvik A., 2017, Ph.D. dissertation
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hassenzahl M., 2003, Mensch & Computer 2003: Interaktion in Bewegung, P187, DOI [DOI 10.1007/978-3-322-80058-9_19, 10.1007/978-3-322-80058-9_19, DOI 10.1007/978-3-322-80058-919]
   Herman LM, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P612, DOI 10.1145/3325480.3326579
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Houzangbe S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.958223
   Huang R., 2018, J. Comput. Inf. Sci. Eng., V18
   Huo K, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P37, DOI 10.1145/3024969.3024995
   IEEE, 2021, "IEEEXplore
   Israel JH, 2009, COMPUT GRAPH-UK, V33, P462, DOI 10.1016/j.cag.2009.05.005
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Jackson D., 2011, P SKETCH REC WORKSH
   Jetter R., 2020, P CHI C HUM FACT COM, P1
   Ji-Young Oh, 2006, Designing Interactive Systems. DIS2006, P80
   Johnson Seth., 2016, Proceedings of the 2016 ACM Companion on Interactive Surfaces and Spaces, P107
   Joundi J., 2020, Proceedings of the Design Society: DESIGN Conference, V1, P225, DOI [DOI 10.1017/DSD.2020.61, https://doi.org/10.1017/dsd.2020.61]
   Jung A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2749458
   Kang S., 2021, P 27 ACM S VIRT REAL
   Keefe D.F., 2001, P 2001 S INTERACTIVE, P85
   Keefe DF, 2008, IEEE T VIS COMPUT GR, V14, P835, DOI 10.1109/TVCG.2008.31
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   Keefe DF, 2005, IEEE COMPUT GRAPH, V25, P18, DOI 10.1109/MCG.2005.34
   Keefe R. C., 2008, P IEEE S 3D US INT, P51
   Keeley D., 2018, Master's thesis
   Kennedy S., 2018, Refractory: J.Entertainment Media, V30
   Kim KH, 2006, CREATIVITY RES J, V18, P3, DOI 10.1207/s15326934crj1801_2
   Kim S.-G., 2018, P CHI C HUM FACT COM
   Kim Y, 2017, Arxiv, DOI arXiv:1704.02724
   Kim Y, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P797, DOI 10.1145/2984511.2984567
   Krs V, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073603
   Kwan H., 2019, P CHI C HUM FACT COM, P1
   Kwon J, 2010, IEICE T INF SYST, VE93D, P167, DOI 10.1587/transinf.E93.D.167
   Laing S, 2020, DESIGN STUD, V71, DOI 10.1016/j.destud.2020.100965
   Leal D., 2011, Graph. Interface, P49
   Lee J.H, 2020, P CHI C HUM FACT COM, P1
   Leiva C., 2020, P CHI C HUM FACT COM, P1
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   Lorusso M., 2021, Comput.-Aided Des. Appl., V19, P256
   Lorusso M., 2020, Comput.-Aided Des.Appl., V18, P383
   MacDonald C.M., 2013, Proc. ExtendedAbstr. Hum. Factors Comput. Syst, P1969, DOI DOI 10.1145/2468356.2468714
   Machuca MDB, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364254
   Machuca MDB, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P36, DOI 10.1145/3267782.3267786
   Makela W., 2005, P IEEE VR WORKSH, P70
   Maurya S, 2021, J ENG DESIGN, V32, P1, DOI 10.1080/09544828.2020.1851662
   McGraw E., 2017, P S SKETCH BAS INT M
   Merriam-Webster, 2020, "Ideation.
   Mohanty RR, 2018, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2018, VOL 1B
   Mu M., 2022, P IEEE 28 INT C ENG, P1
   Mu M, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13365-2
   Nam J, 2017, LEONARDO, V50, P94, DOI 10.1162/LEON_a_01226
   Norman D.A., 2002, DESIGN EVERYDAY THIN
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Oh W., 2005, Sketch-BasedInterfaces Model, P81
   Olivier P, 2019, COMPUT GRAPH-UK, V82, P203, DOI 10.1016/j.cag.2019.05.027
   Oti A, 2021, COMPUT GRAPH-UK, V94, P111, DOI 10.1016/j.cag.2020.10.007
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1136/bmj.n160]
   Pakanen M, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P393, DOI 10.1145/3152832.3156613
   Panda P., 2021, Proc. Creativity Cogn.
   Peng H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174153
   Perkunder Helen., 2010, Proceedings of the Seventh Sketch-Based Interfaces and Modeling Symposium, SBIM '10, P127
   Prats M, 2009, DESIGN STUD, V30, P503, DOI 10.1016/j.destud.2009.04.002
   Qian J, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P205, DOI 10.1145/3461778.3462098
   Rasmussen J., Information Processing and Human-Machine Interaction:An Approach to Cognitive Engineering, P198
   rkmen R., 2022, P CHI C HUM FACT COM
   Romat H, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P306, DOI 10.1109/VR50410.2021.00053
   Rosales E, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480511
   Rosales E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322970
   Rowe PeterG., 1991, DESIGN THINKING
   Rubin C.B., 2002, P ACM SIGGRAPH C ABS
   Saalfeld A., 2016, P EUR WORKSH VIS COM, P123, DOI [10.2312/vcbm.20161280, DOI 10.2312/VCBM.20161280, DOI 10.5555/3061507.3061528]
   Satter K, 2015, J COMPUT INF SCI ENG, V15, DOI 10.1115/1.4029750
   Schkolne S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P261, DOI 10.1145/365024.365114
   Schon D. A., 1983, REFLECTIVE PRACTITIO
   Schott M, 2009, COMPUT GRAPH FORUM, V28, P855, DOI 10.1111/j.1467-8659.2009.01464.x
   Schubert G., 2012, P 32 ANN C ASS COMP, P409
   Schurch R., 2012, Proceedings of the 2012 IEEE International Conference on Imaging Systems and Techniques (IST), P409, DOI 10.1109/IST.2012.6295555
   Seichter H., 2003, P 8 INT C COMP AID A, P209
   Semmo Amir., 2017, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, V5, P1
   Seo M., 2018, P C HUM FACT COMP SY, P1
   Seybold C., 2020, Product Lifecycle Management Enabling Smart,, V594, P297
   Shankar S, 2017, AI EDAM, V31, P376, DOI 10.1017/S0890060416000512
   Sketch G., 2020, "Gravity sketch.
   Snibbe S. Anderson, 1998, P 3 PHANT US GROUP
   Stadler H., 2020, P DES SOC INT C ENG, P1375
   Sung-A Jang, 2014, Distributed, Ambient, and Pervasive Interactions. Second International Conference (DAPI 2014) Held as Part of HCI International 2014. Proceedings: LNCS 8530, P130, DOI 10.1007/978-3-319-07788-8_13
   Tano S, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P245, DOI 10.1109/ISM.2014.54
   Tchalenko J, 2009, VISION RES, V49, P791, DOI 10.1016/j.visres.2009.02.012
   Thoravi Kumaravel B., P CHI C HUM FACT COM, P1
   Tversky B., 2002, 2002 AAAI SPRING S S, P148
   van der Horst S, 2021, PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, TEI 2021, DOI 10.1145/3430524.3446068
   Van Goethem S., 2020, Advances in Usability, User Experience, Wearable and As-sistive Technology, P69
   VanGoethem S., 2021, Proc. Des. Soc.,, P3339
   Vermeeren A.P., 2010, P 6 NORD C HUM COMP, P521, DOI [DOI 10.1145/1868914.1868973, 10.1145/1868914.1868973]
   Vistisen P., 2019, P 7 ECAADE REG INT S, P25
   Wacker P, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P25, DOI 10.1145/3267782.3267788
   Wacker P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300849
   Wang SX, 2021, INT SYM MIX AUGMENT, P362, DOI 10.1109/ISMAR-Adjunct54149.2021.00082
   Wang SX, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P156, DOI 10.1109/ISMAR-Adjunct.2019.00-58
   Wesche H.-P., 2001, P ACM S VIRT REAL SO, P167
   Wiese E., 2010, P 7 SKETCH BASED INT, P135
   Xin M., 2008, P 2008 ACM S VIRT RE, P223, DOI DOI 10.1145/1450579.1450627
   Xu HN, 2022, IEEE T HUM-MACH SYST, V52, P1352, DOI 10.1109/THMS.2022.3186592
   Xu PF, 2019, IEEE T VIS COMPUT GR, V25, P2927, DOI 10.1109/TVCG.2018.2860016
   Xu WJ, 2018, LECT NOTES COMPUT SC, V10922, P240, DOI 10.1007/978-3-319-91131-1_19
   Xue Yu, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P372, DOI 10.1145/3472749.3474756
   Yang EK, 2020, DIGIT CREAT, V31, P82, DOI 10.1080/14626268.2020.1726964
   Yang XZ, 2018, ETR&D-EDUC TECH RES, V66, P1231, DOI 10.1007/s11423-018-9604-z
   Ye H, 2022, IEEE T VIS COMPUT GR, V28, P2809, DOI 10.1109/TVCG.2020.3049006
   Yee Y., 2009, P INT UI WORKSH SKET, P1
   Yilmaz S., 2008, P KOR JPN DES ENG WO
   Yu R., 2021, P CHI C HUM FACT COM
   Yuan Q, 2021, COMPUT GRAPH-UK, V94, P132, DOI 10.1016/j.cag.2020.12.001
   Yue YT, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3693, DOI 10.1145/3025453.3025792
   Zhilyaeva A., 2022, "annadreambrush.
   Zhu XQ, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1764
   Zou QY, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P968, DOI 10.1109/VRW55335.2022.00335
NR 166
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4648
EP 4664
DI 10.1109/TVCG.2023.3276291
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400085
PM 37186537
DA 2024-08-05
ER

PT J
AU Wen, JH
   Wang, BH
   Barbic, J
AF Wen, Jiahao
   Wang, Bohan
   Barbic, Jernej
TI Large-Strain Surface Modeling Using Plasticity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Differential geometry; fundamental forms; large strain; plasticity;
   shape modeling; surfaces; large rotations
ID RECONSTRUCTION; ANIMATION
AB Modeling arbitrarily large deformations of surfaces smoothly embedded in three-dimensional space is challenging. We give a new method to represent surfaces undergoing large spatially varying rotations and strains, based on differential geometry, and surface first and second fundamental forms. Methods that penalize the difference between the current shape and the rest shape produce sharp spikes under large strains, and variational methods produce wiggles, whereas our method naturally supports large strains and rotations without any special treatment. For stable and smooth results, we demonstrate that the deformed surface has to locally satisfy compatibility conditions (Gauss-Codazzi equations) on the first and second fundamental forms. We then give a method to locally modify the surface first and second fundamental forms in a compatible way. We use those fundamental forms to define surface plastic deformations, and finally recover output surface vertex positions by minimizing the surface elastic energy under the plastic deformations. We demonstrate that our method makes it possible to smoothly deform triangle meshes to large spatially varying strains and rotations, while meeting user constraints.
C1 [Wen, Jiahao; Barbic, Jernej] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
   [Wang, Bohan] Univ Southern Calif, Los Angeles, CA 90089 USA.
   [Wang, Bohan] MIT, Los Angeles, CA USA.
C3 University of Southern California; University of Southern California;
   Massachusetts Institute of Technology (MIT)
RP Barbic, J (corresponding author), Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
EM jiahaow@usc.edu; bohanwan@usc.edu; jnb@usc.edu
OI Wang, Bohan/0000-0003-1439-1455; Wen, Jiahao/0000-0002-7175-653X
FU NSF [IIS-1911224]; Bosch Research; Adobe Research; Annenberg Fellowship
FX This work was supported in part by NSF under Grant IIS-1911224, in part
   by Bosch Research, and in part by Adobe Research. The work of Jiahao Wen
   and Bohan Wang were supported by the Annenberg Fellowship. Recommended
   for acceptance by Y. He.
CR Alexa M., 2006, P ACM SIGGRAPH COURS
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bargteil AW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239467
   Botsch M, 2004, ACM T GRAPHIC, V23, P630, DOI 10.1145/1015706.1015772
   Botsch M, 2006, P EUR S GEOM PROC, DOI 10.2312/SGP/SGP06/011-020
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Bouaziz S, 2012, COMPUT GRAPH FORUM, V31, P1657, DOI 10.1111/j.1467-8659.2012.03171.x
   Chen HY, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201395
   Chen W, 2018, COMPUT GRAPH FORUM, V37, P112, DOI 10.1111/cgf.13236
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Deuss M., 2015, SHAPEOP A ROBUST EXT, P505
   Esturo JM, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682627
   Geoffrey Irving, 2004, P S COMP AN, P131, DOI DOI 10.1145/1028523.1028541
   Gilles B, 2006, LECT NOTES COMPUT SC, V4190, P289
   Gilles B, 2010, MED IMAGE ANAL, V14, P291, DOI 10.1016/j.media.2010.01.006
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jacobson A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964973
   Kircher S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356685
   Knitro A., 2019, About us
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y., 2004, P 2004 EUROGRAPHICSA, P175, DOI DOI 10.1145/1057432.1057456
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, PROC GRAPH INTERF, P239
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Petersen P., 2016, Classical differential geometry. lecture notes
   Schmid J, 2009, RECENT ADVANCES IN THE 3D PHYSIOLOGICAL HUMAN, P3, DOI 10.1007/978-1-84882-565-9_1
   Sifakis E., 2015, Finite Element Method Simulation of 3D De- formable Solids
   Sorkine O, 2007, Proc. Symposium on Geometry Processing, V4, P109, DOI [DOI 10.1145/1281991.1282006, 10.1145/1073204.1073323]
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Volino P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559762
   Wang BH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3443703
   Wang Y, 2012, COMPUT GRAPH FORUM, V31, P2277, DOI 10.1111/j.1467-8659.2012.03153.x
   Wang Y., 2021, ACM Trans Graph, V40, P1
   Wang Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766952
   Weischedel C., 2012, A discrete geometric view on shear-deformable shell models
NR 41
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5183
EP 5197
DI 10.1109/TVCG.2023.3289811
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400008
PM 37368795
DA 2024-08-05
ER

PT J
AU Han, D
   Lee, R
   Kim, K
   Kang, H
AF Han, Dongheun
   Lee, Roun
   Kim, Kyeongmin
   Kang, Hyeongyeop
TI VR-HandNet: A Visually and Physically Plausible Hand Manipulation System
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tracking; Three-dimensional displays; Shape; Physics; Grasping; Deep
   learning; Visualization; Hand manipulation; physics-based animation;
   reinforcement learning; virtual reality
AB This study aims to allow users to perform dexterous hand manipulation of objects in virtual environments with hand-held VR controllers. To this end, the VR controller is mapped to the virtual hand and the hand motions are dynamically synthesized when the virtual hand approaches an object. At each frame, given the information about the virtual hand, VR controller input, and hand-object spatial relations, the deep neural network determines the desired joint orientations of the virtual hand model in the next frame. The desired orientations are then converted into a set of torques acting on hand joints and applied to a physics simulation to determine the hand pose at the next frame. The deep neural network, named VR-HandNet, is trained with a reinforcement learning-based approach. Therefore, it can produce physically plausible hand motion since the trial-and-error training process can learn how the interaction between hand and object is performed under the environment that is simulated by a physics engine. Furthermore, we adopted an imitation learning paradigm to increase visual plausibility by mimicking the reference motion datasets. Through the ablation studies, we validated the proposed method is effectively constructed and successfully serves our design goal. A live demo is demonstrated in the supplementary video.
C1 [Han, Dongheun; Lee, Roun; Kim, Kyeongmin; Kang, Hyeongyeop] Kyung Hee Univ, Dept Software Convergence, IIIXR LAB, Yongin 17104, Gyeonggi Do, South Korea.
C3 Kyung Hee University
RP Kang, H (corresponding author), Kyung Hee Univ, Dept Software Convergence, IIIXR LAB, Yongin 17104, Gyeonggi Do, South Korea.
EM hand32@khu.ac.kr; dlfhdns@khu.ac.kr; kgm031189@gmail.com;
   siamiz@khu.ac.kr
OI Han, DongHeun/0000-0001-7693-7674; Kim, KyeongMin/0000-0001-5168-9563;
   Kang, HyeongYeop/0000-0001-5292-4342
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2020R1F1A1076528]
FX . This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education under Grant NRF-2020R1F1A1076528.
CR Andrews S, 2013, COMPUT GRAPH-UK, V37, P830, DOI 10.1016/j.cag.2013.04.007
   Andrychowicz M, 2020, INT J ROBOT RES, V39, P3, DOI 10.1177/0278364919887447
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bergamin K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356536
   Bonardi A, 2020, IEEE ROBOT AUTOM LET, V5, P3533, DOI 10.1109/LRA.2020.2977835
   Chen T., 2022, C ROBOT LEARNING, P297
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Christen S., 2021, arXiv
   Christen S, 2019, IEEE INT CONF ROBOT, P2161, DOI [10.1109/ICRA.2019.8794065, 10.1109/icra.2019.8794065]
   Clevert DA, 2016, Arxiv, DOI [arXiv:1511.07289, DOI 10.48550/ARXIV.1511.07289]
   Delrieu T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P266, DOI [10.1109/VR46266.2020.1581332505844, 10.1109/VR46266.2020.00-58]
   Fernández UJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094193
   Freeman CD, 2021, Arxiv, DOI arXiv:2106.13281
   Garcia-Hernando G, 2020, IEEE INT C INT ROBOT, P9561, DOI 10.1109/IROS45743.2020.9340947
   Grady P, 2021, PROC CVPR IEEE, P1471, DOI 10.1109/CVPR46437.2021.00152
   Gupta A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3786, DOI 10.1109/IROS.2016.7759557
   Haidacher S, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1597, DOI 10.1109/ROBOT.2002.1014771
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   Ho J., 2016, Advances in neural information processing systems, V29, P4565
   Höll M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P175, DOI 10.1109/VR.2018.8448284
   Humberston B., 2015, P 14 ACM SIGGRAPH EU, P63
   Jiang HW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11087, DOI 10.1109/ICCV48922.2021.01092
   Jiang YF, 2021, PROCEEDINGS OF ACM SIGGRAPH SYMPOSIUM ON COMPUTER ANIMATION, SCA 2021, DOI 10.1145/3475946.3480950
   Jorg S., 2020, P SIGGRAPH ASIA2020, P1
   KANEKO M, 1994, IEEE T ROBOTIC AUTOM, V10, P355, DOI 10.1109/70.294210
   Karunratanakul K, 2020, INT CONF 3D VISION, P333, DOI 10.1109/3DV50981.2020.00043
   Kim JS, 2019, IEEE INT C INT ROBOT, P3235, DOI [10.1109/iros40897.2019.8968088, 10.1109/IROS40897.2019.8968088]
   Kingma D. P., 2014, arXiv
   Kumar V, 2016, Arxiv, DOI arXiv:1611.05095
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Levine S, 2016, J MACH LEARN RES, V17
   Li Y, 2007, IEEE T VIS COMPUT GR, V13, P732, DOI [10.1109/TVCG.2007.1033, 10.1109/TVCG.2007.1033.]
   Liu C. K., 2008, P ACM SIGGRAPH EUR S, P163
   Liu CK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531365
   Liu YX, 2018, IEEE INT CONF ROBOT, P1118
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Mnih V, 2016, PR MACH LEARN RES, V48
   Oculus VR, 2017, Distance grab sample now available in oculus unity sample framework
   Oprea S, 2019, COMPUT GRAPH-UK, V83, P77, DOI 10.1016/j.cag.2019.07.003
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459670, 10.1145/3197517.3201311]
   Radosavovic I, 2021, IEEE INT C INT ROBOT, P7865, DOI 10.1109/IROS51168.2021.9636557
   Rajeswaran A, 2018, Arxiv, DOI [arXiv:1709.10087, DOI 10.48550/ARXIV.1709.10087]
   Schulman J, 2018, Arxiv, DOI [arXiv:1506.02438, 10.48550/arXiv.1506.02438]
   Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Sermanet P, 2017, Arxiv, DOI arXiv:1612.06699
   Song P, 2018, VISUAL COMPUT, V34, P257, DOI 10.1007/s00371-016-1333-x
   Verschoor M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P183, DOI 10.1109/VR.2018.8447555
   Voigt-Antons JN, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123085
   Wei Quan, 2020, 2020 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS). Proceedings, P772, DOI 10.1109/ICITBS49701.2020.00169
   Ye YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185537
   Yu H, 2022, MULTIMEDIA SYST, V28, P1845, DOI 10.1007/s00530-021-00874-7
   Zhang H, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322998
   Zhang H, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459830, 10.1145/3448978]
NR 54
TC 3
Z9 3
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4170
EP 4182
DI 10.1109/TVCG.2023.3255991
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700036
PM 37028286
DA 2024-08-05
ER

PT J
AU Meidiana, A
   Hong, SH
   Cai, SJ
   Torkel, M
   Eades, P
AF Meidiana, Amyra
   Hong, Seok-Hee
   Cai, Shijun
   Torkel, Marnijati
   Eades, Peter
TI SubLinearForce: Fully Sublinear-Time Force Computation for Large Complex
   Graph Drawing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Force; Runtime; Measurement; Resistance; Approximation algorithms;
   Springs; Scalability; Graph drawing; force-directed algorithms;
   sublinear-time algorithms
ID SPARSIFICATION; ALGORITHM
AB Recent works in graph visualization attempt to reduce the runtime of repulsion force computation of force-directed algorithms using sampling. However, they fail to reduce the runtime for attraction force computation to sublinear in the number of edges. We present the SubLinearForce framework for a fully sublinear-time force computation algorithm for drawing large complex graphs. More precisely, we present new sublinear-time algorithms for the attraction force computation of force-directed algorithms. We then integrate them with sublinear-time repulsion force computation to give a fully sublinear-time force computation. Extensive experiments show that our algorithms compute layouts on average 80% faster than the existing linear-time force computation algorithm, while obtaining significantly better quality metrics such as edge crossing and shape-based metrics.
C1 [Meidiana, Amyra; Hong, Seok-Hee; Cai, Shijun; Torkel, Marnijati; Eades, Peter] Univ Sydney, Sydney, NSW 2006, Australia.
C3 University of Sydney
RP Meidiana, A (corresponding author), Univ Sydney, Sydney, NSW 2006, Australia.
EM amyra.meidiana@sydney.edu.au; seokhee.hong@sydney.edu.au;
   shijun.cai@sydney.edu.au; marnijati.torkel@sydney.edu.au;
   peter.eades@sydney.edu.au
FU ARC (Australian Research Council) DP (Discovery Project) [DP180102553]
FX This work was supported by ARC (Australian Research Council) DP
   (Discovery Project) under grant DP180102553.
CR Nguyen A, 2017, IEEE PAC VIS SYMP, P21, DOI 10.1109/PACIFICVIS.2017.8031574
   Archambault D, 2007, IEEE T VIS COMPUT GR, V13, P305, DOI 10.1109/TVCG.2007.46
   Arleo A, 2016, LECT NOTES COMPUT SC, V9801, P3, DOI 10.1007/978-3-319-50106-2_1
   Auber D., 2017, Encyclopedia of Social Network Analysis and Mining, P1, DOI [10.1007/978-1-4614-7163-9_315-1, DOI 10.1007/978-1-4614-7163-9_315-1]
   BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0
   Battista G. D., 1998, Graph drawing: algorithms for the visualization of graphs
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandes U., 2016, Encyclopedia of Algorithms, P768
   Eades Peter, 2018, Graph Drawing and Network Visualization. 25th International Symposium, GD 2017. Revised Selected Papers: LNCS 10692, P272, DOI 10.1007/978-3-319-73915-1_22
   Eades P., 2017, J. Graph Algorithms Appl., V21, P29, DOI [10.7155/jgaa.00405, DOI 10.7155/JGAA.00405]
   Eades Peter, 1984, Congressus Numerantium, V42, P149
   Eades Peter., 1991, Drawing Free Trees
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Kobourov SG, 2012, Arxiv, DOI [arXiv:1201.3011, 10.48550/arxiv.1201.3011, 10.48550/arXiv.1201.3011]
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Gove R, 2019, COMPUT GRAPH FORUM, V38, P739, DOI 10.1111/cgf.13724
   Gove R, 2019, SYMP LARG DATA ANAL, P1, DOI [10.1109/LDAV48142.2019.8944364, 10.1109/ldav48142.2019.8944364]
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Hagberg A. A., 2008, EXPLORING NETWORK ST, P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003
   Hong S.-H., 2020, P IEEE PAC VIS S, P146
   Hong SH, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P1843, DOI 10.1145/3341105.3373976
   Hong SH, 2019, LECT NOTES COMPUT SC, V11904, P139, DOI 10.1007/978-3-030-35802-0_11
   Hong SH, 2018, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis.2018.00011
   Hu J., 2019, P INT C COMPL NETW T, P216
   Hu Y., 2005, Mathematica journal, V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI [DOI 10.1111/J.1469-8137.1912.TB05611.X, 10.1111/J.1469-8137.1912.TB05611.X]
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kobourov S. G., 2000, P INT SUMP GRAPH DRA, P222
   Leskovec Jure, 2006, KDD 06, P631
   Meidiana A, 2021, IEEE PAC VIS SYMP, P166, DOI 10.1109/PacificVis52677.2021.00030
   Meidiana A, 2021, IEEE PAC VIS SYMP, P146, DOI 10.1109/PacificVis52677.2021.00027
   Meidiana A, 2019, SYMP LARG DATA ANAL, P73, DOI [10.1109/LDAV48142.2019.8944358, 10.1109/ldav48142.2019.8944358]
   Meyerhenke H, 2015, LECT NOTES COMPUT SC, V9411, P30, DOI 10.1007/978-3-319-27261-0_3
   Ortmann M, 2016, LECT NOTES COMPUT SC, V9801, P18, DOI 10.1007/978-3-319-50106-2_2
   Quigley A., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P197
   Spielman DA, 2007, ANN IEEE SYMP FOUND, P29, DOI 10.1109/FOCS.2007.56
   Spielman DA, 2011, SIAM J COMPUT, V40, P1913, DOI 10.1137/080734029
   Spielman DA, 2011, SIAM J COMPUT, V40, P981, DOI 10.1137/08074489X
   SUGIYAMA K, 1995, J VISUAL LANG COMPUT, V6, P217, DOI 10.1006/jvlc.1995.1013
   Tamassia R., 2016, Discrete mathematics and its applications
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743
   van Ham F, 2008, COMPUT GRAPH FORUM, V27, P975, DOI 10.1111/j.1467-8659.2008.01232.x
   WALKER AJ, 1974, ELECTRON LETT, V10, P127, DOI 10.1049/el:19740097
   Walshaw C., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P171
   Wu YH, 2017, IEEE T VIS COMPUT GR, V23, P401, DOI 10.1109/TVCG.2016.2598867
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 46
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3386
EP 3399
DI 10.1109/TVCG.2022.3233287
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700018
DA 2024-08-05
ER

PT J
AU Kern, F
   Tschanter, J
   Latoschik, ME
AF Kern, Florian
   Tschanter, Jonathan
   Latoschik, Marc Erich
TI Handwriting for Text Input and the Impact of XR Displays, Surface
   Alignments, and Sentence Complexities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE VR; AR; XR; physically aligned; mid-air; text input; handwriting;
   digital ink; recognition; phrase set; digital twin
ID RECOGNITION; ONLINE; PEN
AB Text input is desirable across various eXtended Reality (XR) use cases and is particularly crucial for knowledge and office work. This article compares handwriting text input between Virtual Reality (VR) and Video See-Through Augmented Reality (VST AR), facilitated by physically aligned and mid-air surfaces when writing simple and complex sentences. In a 2x2x2 experimental design, 72 participants performed two ten-minute handwriting sessions, each including ten simple and ten complex sentences representing text input in real-world scenarios. Our developed handwriting application supports different XR displays, surface alignments, and handwriting recognition based on digital ink. We evaluated usability, user experience, task load, text input performance, and handwriting style. Our results indicate high usability with a successful transfer of handwriting skills to the virtual domain. XR displays and surface alignments did not impact text input speed and error rate. However, sentence complexities did, with participants achieving higher input speeds and fewer errors for simple sentences (17.85 WPM, 0.51% MSD ER) than complex sentences (15.07 WPM, 1.74% MSD ER). Handwriting on physically aligned surfaces showed higher learnability and lower physical demand, making them more suitable for prolonged handwriting sessions. Handwriting on mid-air surfaces yielded higher novelty and stimulation ratings, which might diminish with more experience. Surface alignments and sentence complexities significantly affected handwriting style, leading to enlarged and more connected cursive writing in both mid-air and for simple sentences. The study also demonstrated the benefits of using XR controllers in a pen-like posture to mimic styluses and pressure-sensitive tips on physical surfaces for input detection. We additionally provide a phrase set of simple and complex sentences as a basis for future text input studies, which can be expanded and adapted.
C1 [Kern, Florian; Tschanter, Jonathan; Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
   [Tschanter, Jonathan] Univ Wurzburg, PIIS Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Kern, F (corresponding author), Univ Wurzburg, HCI Grp, Wurzburg, Germany.
EM florian.kern@uni-wuerzburg.de; jonathan.tschanter@uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
OI Tschanter, Jonathan/0000-0002-6983-6063; Kern,
   Florian/0000-0001-7092-4872
FU German Federal Ministry of Education and Research
FX No Statement Available
CR Adams H, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P792, DOI 10.1109/VR51125.2022.00101
   Arif AS, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P100, DOI 10.1109/TIC-STH.2009.5444533
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P23, DOI [10.1109/VRW50115.2020.00012, 10.1109/VRW50115.2020.0-264]
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.00-67, 10.1109/VR46266.2020.1581205539914]
   Biener V, 2023, HUM-COMPUT INT-SPRIN, P21, DOI 10.1007/978-3-031-05804-2_2
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Bowers B, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P220, DOI 10.1109/VRW52623.2021.00048
   Bowers B, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P1, DOI 10.1109/VRW50115.2020.0-268
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brown C. M. L., 1988, P HUMAN FACTORS SOC, P381, DOI [10.1177/1541931288032005332,8, DOI 10.1177/1541931288032005332,8]
   Bunke H., 1995, Pattern Recognition, V28, P1399, DOI 10.1016/0031-3203(95)00013-P
   Chen C, 2022, INT SYM MIX AUGMENT, P384, DOI 10.1109/ISMAR55827.2022.00054
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Cheng YF, 2022, INT SYM MIX AUGMENT, P150, DOI 10.1109/ISMAR55827.2022.00029
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Elmgren R., 2017, Handwriting in VR as a Text Input Method, P9
   Fang FY, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3569461
   Field AP, 2017, BEHAV RES THER, V98, P19, DOI 10.1016/j.brat.2017.05.013
   Fourrier N, 2023, IEEE T VIS COMPUT GR, V29, P4438, DOI 10.1109/TVCG.2023.3320215
   Gerth S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01308
   González G, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P109, DOI 10.1007/978-1-84882-352-5_11
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   HART S G, 1988, P139
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Karthi M., 2020, Procedia Comput. Sci., V172, P1016, DOI 10.1016/j.procs.2020.05.1492,9
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kern F., 2023, 2023 IEEE INT S MIX, P74, DOI 10.1109/ISMAR-Adjunct60411.2023.00023
   Kern Florian, 2023, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2023.3247098
   Kern F, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P502, DOI 10.1109/VRW58643.2023.00109
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489949
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489940
   Kern F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684498
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kiefer M, 2015, ADV COGN PSYCHOL, V11, P136, DOI 10.5709/acp-0178-7
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Kristensson P. O., 2012, P OFTHE 2012 ACM INT, P29, DOI [10.1145/2166966166972 3, DOI 10.1145/21669661669723, DOI 10.1145/2166966.2166972]
   Kristensson PO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P567
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   MacKenzie I.S., 2003, CHI'03 Extended Abstracts on Human Factors in Computing Systems, CHI EA'03, P754, DOI [DOI 10.1145/765891.765971, 10.1145/765891.765971]
   Mair P, 2020, BEHAV RES METHODS, V52, P464, DOI 10.3758/s13428-019-01246-w
   McGill M, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3490495
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   Morehead K, 2019, EDUC PSYCHOL REV, V31, P753, DOI 10.1007/s10648-019-09468-2
   Morehead K, 2019, MEMORY, V27, P807, DOI 10.1080/09658211.2019.1569694
   Mueller PA, 2014, PSYCHOL SCI, V25, P1159, DOI 10.1177/0956797614524581
   Curran K., 2006, Telematics and Informatics, V23, P1, DOI 10.3844/jcssp.2005.189.199
   Askvik EO, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01810
   Pham D.-M., 2019, 25 ACM S VIRTUAL REA, P1, DOI [10.1145/3359996.33642652,3,9, DOI 10.1145/3359996.33642652,3,9]
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364264
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Schmalstieg D., 2016, Addison-Wesley usability and HCI series
   Schrepp D. M., 2019, User Experience Questionnaire Handbook, P6
   Selin A.-S., 2003, Pencil grip: a descriptive model and four empirical studies, V3, P9
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   van der Meer ALH, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00706
   Vashist Prem Chand, 2020, 2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM). Proceedings, P456, DOI 10.1109/ICCAKM46823.2020.9051464
   Venkatakrishnan R, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560817
   Vertanen K., 2011, P 13 INT C HUM COMP, P295, DOI [DOI 10.1145/2037373.2037418, 10.1145/2037373.20374183,5,9]
   Viciana-Abad R, 2010, PRESENCE-TELEOP VIRT, V19, P197, DOI 10.1162/pres.19.3.197
   Westermeier F, 2023, 29TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2023, DOI 10.1145/3611659.3617227
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Wilcox R. R., 2017, Introduction to robust estimation and hypothesis testing, V4th, P6
   Zielasko D., 2020, PhD Thesis,
   Zielasko D, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809589
NR 72
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2357
EP 2367
DI 10.1109/TVCG.2024.3372124
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400035
PM 38442066
OA hybrid
DA 2024-08-05
ER

PT J
AU Nair, V
   Guo, WB
   Wang, R
   O'Brien, JF
   Rosenberg, L
   Song, D
AF Nair, Vivek
   Guo, Wenbo
   Wang, Rui
   O'Brien, James F.
   Rosenberg, Louis
   Song, Dawn
TI Berkeley Open Extended Reality Recordings 2023 (BOXRR-23): 4.7 Million
   Motion Capture Recordings from 105,000 XR Users
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Recording; Motion capture; X reality; Brushes; Tracking; Games;
   Internet; Dataset; virtual reality; extended reality; motion capture;
   big data
AB Extended reality (XR) devices such as the Meta Quest and Apple Vision Pro have seen a recent surge in attention, with motion tracking "telemetry" data lying at the core of nearly all XR and metaverse experiences. Researchers are just beginning to understand the implications of this data for security, privacy, usability, and more, but currently lack large-scale human motion datasets to study. The BOXRR-23 dataset contains 4,717,215 motion capture recordings, voluntarily submitted by 105,852 XR device users from over 50 countries. BOXRR-23 is over 200 times larger than the largest existing motion capture research dataset and uses a new, highly efficient and purpose-built XR Open Recording (XROR) file format.
C1 [Nair, Vivek; O'Brien, James F.; Song, Dawn] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Guo, Wenbo] Purdue Univ, W Lafayette, IN USA.
   [Wang, Rui] Carnegie Mellon, Pittsburgh, PA USA.
   [Rosenberg, Louis] Unanimous, Pismo Beach, CA USA.
C3 University of California System; University of California Berkeley;
   Purdue University System; Purdue University; Carnegie Mellon University
RP Nair, V (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM vcn@berkeley.edu; henrygwb@purdue.edu; ruiwang3@andrew.cmu.edu;
   job@berkeley.edu; louis@unanimous.ai; dawnsong@berkeley.edu
OI O'Brien, James/0000-0001-9513-0542; Rosenberg, Louis/0000-0003-3457-1429
FU Minderoo foundation
FX No Statement Available
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Dent S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258000
   Douglas A., 2012, Applied Computing, V1
   Du YM, 2023, PROC CVPR IEEE, P481, DOI 10.1109/CVPR52729.2023.00054
   Durbin J., 2017, Report: Vive Users Are 95 Percent Male And Spend 5 Hours Per Week in VR, P6
   Fan L., 2022, 36 C NEUR INF PROC S
   FROMM C, 1977, NEUROSCI LETT, V5, P259, DOI 10.1016/0304-3940(77)90076-3
   Gebru T, 2021, Arxiv, DOI arXiv:1803.09010
   Ghorbani S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253157
   Holland S, 2018, Thedataset nutrition label: A framework to drive higher data quality standards, V1, P7
   Hoyet L., 2012, P ACM SIGGRAPH S INT, P79, DOI DOI 10.1145/2159616.2159630
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang P., 2022, Avatarposer: Articulated full-body pose tracking from sparse motionsensing, V4
   Ke Q., LightGBM: A Highly Efficient Gradient Boosting Decision Tree
   Kingma D. P., 2014, arXiv
   Koch E., 2021, Reduced, reused andrecycled: The life of a dataset in machine learning research, V6
   Liebers M., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34455282, DOI 10.1145/3411764.34455282]
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Mandery C, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P329, DOI 10.1109/ICAR.2015.7251476
   Miller E. Han, 2023, A large-scale study of personal identifiability of virtual reality motion overtime, V2, P5
   Miller F., 2020, Scientific Reports, V10, P10, DOI [10.1038/s41598-020-74486-y2,3,6[28]M.R., DOI 10.1038/S41598-020-74486-Y2,3,6[28]M.R]
   Miller R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P311, DOI [10.1109/VRW50115.2020.00070, 10.1109/VRW50115.2020.0-206]
   Moore AG, 2021, INT SYM MIX AUGMENT, P221, DOI 10.1109/ISMAR52148.2021.00037
   Muller T., 2007, Documentation mocap database hdm05, V2
   Nair C., 2023, Inferring private personal attributes of virtualreality users from head and hand motion data, V4
   Nair G. M., 2023, Going incognito in the metaverse, V4
   Nair V., 2023, Results of the 2023 census ofbeat saber users: Virtual reality gaming population insights and factorsaffecting virtual reality e-sports performance, V5
   Nair V, 2023, PROCEEDINGS OF THE 32ND USENIX SECURITY SYMPOSIUM, P895
   Nair W., 2023, Unique identification of 50,000+ virtual reality users from head& hand motion data
   Nair W., 2023, Deep motionmasking for secure, usable, and scalable real-time anonymization of virtualreality motion data, V4
   Pagano P., 2022, Bias andunfairness in machine learning models: a systematic literature review,, V6
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Ponton JL, 2022, COMPUT GRAPH FORUM, V41, P107, DOI 10.1111/cgf.14628
   Rahman D., 2021, 35 C NEUR INF PROC S
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Torre J. K., 2008, database, V2
   Tricomi P. P., 2022, You can't hide behind your headset: User profiling in augmented and virtual reality, P2
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Trumble M., 2017, 2017 BRIT MACH VIS C, P2
   Vitaladevuni S. N. P., 2007, PhD thesis
   Wobbeking J., 2022, Beat Saber generated more revenue in 2021 than the next five biggest apps combined, P1
NR 44
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2239
EP 2246
DI 10.1109/TVCG.2024.3372087
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400074
PM 38437078
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Vallageas, V
   Aissaoui, R
   Willaert, I
   Labbé, DR
AF Vallageas, Valentin
   Aissaoui, Rachid
   Willaert, Iris
   Labbe, David R.
TI Embodying a self-avatar with a larger leg: its impacts on motor control
   and dynamic stability
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE H.5.1 [Information Interfaces and Presentation]: Multimedia Information
   Systems-Artificial, Augmented, and Virtual Realities; H.5.2 [Information
   Interfaces and Presentation]: User Interfaces-Evaluation/Methodology
ID ANTICIPATORY POSTURAL ADJUSTMENTS; CENTER-OF-MASS; GAIT INITIATION;
   BODY; OWNERSHIP; REPRESENTATION; EMBODIMENT; LOCATION; SENSE; ARM
AB Several studies have shown that users of immersive virtual reality can feel high levels of embodiment in self-avatars that have different morphological proportions than those of their actual bodies. Deformed and unrealistic morphological modifications are accepted by embodied users, underlying the adaptability of one's mental map of their body (body schema) in response to incoming sensory feedback. Before initiating a motor action, the brain uses the body schema to plan and sequence the necessary movements. Therefore, embodiment in a self-avatar with a different morphology, such as one with deformed proportions, could lead to changes in motor planning and execution. In this study, we aimed to measure the effects on movement planning and execution of embodying a self-avatar with an enlarged lower leg on one side. Thirty participants embodied an avatar without any deformations, and with an enlarged dominant or non-dominant leg, in randomized order. Two different levels of embodiment were induced, using synchronous or asynchronous visuotactile stimuli. In each condition, participants performed a gait initiation task. Their center of mass and center of pressure were measured, and the margin of stability (MoS) was computed from these values. Their perceived level of embodiment was also measured, using a validated questionnaire. Results show no significant changes on the biomechenical variables related to dynamic stability. Embodiment scores decreased with asynchronous stimuli, without impacting the measures related to stability. The body schema may not have been impacted by the larger virtual leg. However, deforming the self-avatar's morphology could have important implications when addressing individuals with impaired physical mobility by subtly influencing action execution during a rehabilitation protocol.
C1 [Vallageas, Valentin; Aissaoui, Rachid; Willaert, Iris; Labbe, David R.] Ecole Technol Super, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada
RP Vallageas, V (corresponding author), Ecole Technol Super, Montreal, PQ, Canada.
EM valentin.vallageas.1@etsmtl.net; rachid.aissaoui@etsmtl.ca;
   iris.willaert.1@ens.etsmtl.ca; david.labbe@etsmtl.ca
CR [Anonymous], 2017, Int. J. Hum. Factors Model. Simul., V5, P306, DOI [10.1504/IJHFMS.2017.087016, DOI 10.1504/IJHFMS.2017.087016]
   [Anonymous], 2013, Anthropometric Survey of U.S. Marine Corps Personnel: Methods and Summary Statistics
   [Anonymous], 2012, World J. Orthop., V3, P75, DOI [10.5312/wjo.v3.i6.75, DOI 10.5312/WJO.V3.I6.75]
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Asai T, 2015, EXP BRAIN RES, V233, P777, DOI 10.1007/s00221-014-4153-0
   Azuma T, 2007, GAIT POSTURE, V26, P526, DOI 10.1016/j.gaitpost.2006.11.203
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bernardi NF, 2013, EXP BRAIN RES, V226, P585, DOI 10.1007/s00221-013-3467-7
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Buetler KA, 2022, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.787487
   Caderby T, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00127
   Camponogara I, 2023, NEUROSCI BIOBEHAV R, V151, DOI 10.1016/j.neubiorev.2023.105228
   Charbonneau P., 2017, 2017 INT C VIRTUALRE, P1, DOI [10.1109/ICVR.2017.8007535, DOI 10.1109/ICVR.2017.8007535]
   D'Angelo M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32238-z
   Day BL, 2018, HAND CLINIC, V159, P107, DOI 10.1016/B978-0-444-63916-5.00006-9
   Dupraz L, 2023, PSYCHOL RES-PSYCH FO, V87, P462, DOI 10.1007/s00426-022-01675-x
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Fabre M, 2020, GAIT POSTURE, V80, P246, DOI 10.1016/j.gaitpost.2020.06.002
   Fuchs X, 2016, SCI REP-UK, V6, DOI 10.1038/srep24362
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hof AL, 2005, J BIOMECH, V38, P1, DOI 10.1016/j.jbiomech.2004.03.025
   Imaizumi S, 2016, CONSCIOUS COGN, V45, P75, DOI 10.1016/j.concog.2016.08.019
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kondo S., 2018, ICAT EGVE 2018 INT C, DOI [10.2312/EGVE.20181310, DOI 10.2312/EGVE.20181310]
   Kording KP, 2006, TRENDS COGN SCI, V10, P319, DOI 10.1016/j.tics.2006.05.003
   Lafond D, 2004, J BIOMECH, V37, P1421, DOI 10.1016/S0021-9290(03)00251-3
   Laha B, 2016, PRESENCE-VIRTUAL AUG, V25, P129, DOI 10.1162/PRES_a_00251
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lilija K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P455, DOI 10.1109/VR50410.2021.00069
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Matamala-Gomez M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01962
   Mille ML, 1998, NEUROSCI LETT, V242, P61, DOI 10.1016/S0304-3940(98)00047-0
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Newport R, 2010, EXP BRAIN RES, V204, P385, DOI 10.1007/s00221-009-2104-y
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Patchay S, 2003, GAIT POSTURE, V18, P85, DOI 10.1016/S0966-6362(02)00167-4
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Popovic I. P. I., 2000, J. Biomech., P10
   Preston C, 2011, NEUROCASE, V17, P473, DOI 10.1080/13554794.2010.532504
   Serino A, 2013, CONSCIOUS COGN, V22, P1239, DOI 10.1016/j.concog.2013.08.013
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Tajadura-Jiménez A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2943, DOI 10.1145/2702123.2702374
   Tajadura-Jiménez A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00689
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Walsh LD, 2011, J PHYSIOL-LONDON, V589, P3009, DOI 10.1113/jphysiol.2011.204941
   Welniarz Q, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.644059
   Willaert I, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P783, DOI 10.1109/VRW55335.2022.00247
   WINTER DA, 1993, NEUROSCI RES COMMUN, V12, P141
   Winter DA, 2009, The Biomechanics and Motor Control of Human Gait: Normal, Elderly and Pathological, DOI [10.1002/9780470549148, DOI 10.1002/9780470549148]
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yiou E, 2017, WORLD J ORTHOP, V8, P815, DOI 10.5312/wjo.v8.i11.815
   Yiou E, 2016, EXP BRAIN RES, V234, P1363, DOI 10.1007/s00221-015-4319-4
NR 60
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2066
EP 2076
DI 10.1109/TVCG.2024.3372084
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400023
PM 38437132
DA 2024-08-05
ER

PT J
AU Feng, BY
   Varshney, A
AF Feng, Brandon Yushan
   Varshney, Amitabh
TI Neural Subspaces for Light Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Light fields; Neural networks; Videos; Image color analysis; Image
   coding; Encoding; Dictionaries; Implicit neural representations; light
   field compression; neural fields; volumetric videos
ID COMPRESSION; ALGORITHM
AB We introduce a framework for compactly representing light field content with the novel concept of neural subspaces. While the recently proposed neural light field representation achieves great compression results by encoding a light field into a single neural network, the unified design is not optimized for the composite structures exhibited in light fields. Moreover, encoding every part of the light field into one network is not ideal for applications that require rapid transmission and decoding. We recognize this problem's connection to subspace learning. We present a method that uses several small neural networks, specializing in learning the neural subspace for a particular light field segment. Moreover, we propose an adaptive weight sharing strategy among those small networks, improving parameter efficiency. In effect, this strategy enables a concerted way to track the similarity among nearby neural subspaces by leveraging the layered structure of neural networks. Furthermore, we develop a soft-classification technique to enhance the color prediction accuracy of neural representations. Our experimental results show that our method better reconstructs the light field than previous methods on various light field scenes. We further demonstrate its successful deployment on encoding light fields with irregular viewpoint layout and dynamic scene content.
C1 [Feng, Brandon Yushan; Varshney, Amitabh] Univ Maryland, Dept Comp Sci, College Pk, MD 20770 USA.
C3 University System of Maryland; University of Maryland College Park
RP Feng, BY (corresponding author), Univ Maryland, Dept Comp Sci, College Pk, MD 20770 USA.
EM yfeng97@umd.edu; varshney@umd.edu
RI Feng, Brandon Y./ABH-3517-2021
OI Feng, Brandon Y./0000-0001-7003-9128; Varshney,
   Amitabh/0000-0002-9873-2212
FU NSF
FX No Statement Available
CR Abdi A, 2017, INT CONF ACOUST SPEE, P3689, DOI 10.1109/ICASSP.2017.7952845
   Adams A., 2008, The stanford light field archive
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bemana M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417827
   Bergman P., 2021, Advances in Neural Information Processing Systems, P172
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Chang CL, 2006, IEEE T IMAGE PROCESS, V15, P793, DOI 10.1109/TIP.2005.863954
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Dib E, 2019, IEEE IMAGE PROC, P3751, DOI [10.1109/ICIP.2019.8803756, 10.1109/icip.2019.8803756]
   Feng BY, 2022, LECT NOTES COMPUT SC, V13663, P138, DOI 10.1007/978-3-031-20062-5_9
   Feng BY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14204, DOI 10.1109/ICCV48922.2021.01396
   Feng S., 2022, P ACM SIGGRAPH AS C, P1
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Hajisharif S, 2019, COMPUT GRAPH FORUM, V38, P265, DOI 10.1111/cgf.13835
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jagmohan A, 2003, CONF REC ASILOMAR C, P830
   Jiang XR, 2017, IEEE J-STSP, V11, P1132, DOI 10.1109/JSTSP.2017.2747078
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Koniaris C, 2019, IEEE T VIS COMPUT GR, V25, P1666, DOI 10.1109/TVCG.2018.2818156
   Le Pendu M, 2020, IEEE IMAGE PROC, P2606, DOI [10.1109/icip40778.2020.9190719, 10.1109/ICIP40778.2020.9190719]
   Le Pendu M, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922099
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Magnor M, 2000, IEEE T CIRC SYST VID, V10, P338, DOI 10.1109/76.836278
   Mairal J., 2009, P 26 INT C MACHINE L
   Meng XX, 2021, IEEE T VIS COMPUT GR, V27, P3350, DOI 10.1109/TVCG.2020.2975801
   Miandji E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3269980
   Miandji J., 2013, P SIGGRAPH AS TECH B, P1
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Nystad J., 2012, P 4 ACM SIGGRAPH EUR, P105, DOI 10.2312/EGGH/HPG12/105-114
   Pendu A., 2020, P IEEE INT C COMP PH, P1
   Pratapa S, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13755
   Pratapa S, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317018
   Sitzmann V, 2020, Adv. Neural. Inf. Process. Syst, V33, P7462
   Sitzmann V, 2021, ADV NEUR IN, V34
   STEWART GW, 1992, IEEE T SIGNAL PROCES, V40, P1535, DOI 10.1109/78.139256
   Sulam J, 2018, IEEE T SIGNAL PROCES, V66, P4090, DOI 10.1109/TSP.2018.2846226
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tancik M., 2020, ADV NEURAL INFORM PR, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tancik M, 2021, PROC CVPR IEEE, P2845, DOI 10.1109/CVPR46437.2021.00287
   Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566
   Wang B, 2013, PROC CVPR IEEE, P468, DOI 10.1109/CVPR.2013.67
   Winkler S, 2003, PROC SPIE, V5203, P371, DOI 10.1117/12.512550
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Zhang Y., 2021, Implicit neural video compression
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhu XQ, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P30
NR 47
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1685
EP 1695
DI 10.1109/TVCG.2022.3224674
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500011
PM 36455094
OA hybrid
DA 2024-08-05
ER

PT J
AU Wang, M
   Chen, ZY
   Cai, WC
   Steinicke, F
AF Wang, Miao
   Chen, Ze-Yin
   Cai, Wen-Chuan
   Steinicke, Frank
TI Transferable Virtual-Physical Environmental Alignment With Redirected
   Walking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Redirected walking; virtual-physical environmental alignment;
   reinforcement learning
AB Several advanced redirected walking techniques have been proposed in recent years to improve natural walking in virtual environments. One active and important research challenge of redirected walking focuses on the alignment of virtual and physical environments by redirection gains. If both environments are aligned, physical objects appear at the same positions as their virtual counterparts. When a user arrives at such a virtual object, she can touch the corresponding physical object providing passive haptic feedback. When multiple transferable virtual or physical target positions exist, the alignment can exploit multiple options, but the process requires more complicated solutions. In this paper, we study the problem of virtual-physical environmental alignment at multiple transferable target positions, and introduce a novel reinforcement learning-based redirected walking method. We design a novel comprehensive reward function that dynamically determines virtual-physical target matching and updates virtual target weights for reward computation. We evaluate our method through various simulated experiments as well as real user tests. The results show that our method obtains less physical distance error for environmental alignment and requires fewer resets than state-of-the-art techniques.
C1 [Wang, Miao; Chen, Ze-Yin; Cai, Wen-Chuan] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Wang, Miao] Zhongguancun Lab, Beijing 100094, Peoples R China.
   [Steinicke, Frank] Univ Hamburg, Dept Informat, D-22605 Hamburg, Germany.
C3 Beihang University; Zhongguancun Laboratory; University of Hamburg
RP Wang, M (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM miaow@buaa.edu.cn; chenzeyin9867@buaa.edu.cn; wenchuancai@buaa.edu.cn;
   frank.steinicke@uni-hamburg.de
RI Steinicke, Frank/AAC-2976-2020
OI Steinicke, Frank/0000-0001-9879-7414
FU National Natural Science Foundation of China
FX No Statement Available
CR [Anonymous], 2022, 2sync house scale vr: Connect virtual and real worlds
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2277, DOI 10.1109/TVCG.2022.3150500
   Bolas E. A., 2015, ICAT EGVE 2015 INT C, P93, DOI DOI 10.2312/EGVE.20151315
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Chen H., 2017, P 21 ACM SIGGRAPH S, P1
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Dynkin E. B., 1965, MARKOV PROCESSES, P77, DOI 10.1007/978-3-662-00031-1_4
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kim D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR50410.2021.00091
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253, DOI 10.1145/1152399.11524512[23]P
   Konda VR, 2000, ADV NEUR IN, V12, P1008
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.00-70, 10.1109/VR46266.2020.1581309443724]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   Min DH, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P164, DOI [10.1109/VR46266.2020.00-69, 10.1109/VR46266.2020.1581308731108]
   Multon F., 2013, Human Walking in Virtual Environments: Perception, Technology, and Applications
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Razzaque Z., 2001, EUROGRAPHICS 2001 SH, P289, DOI 10.2312/egs.20011036
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Schulman J, 2018, Arxiv, DOI [arXiv:1506.02438, 10.48550/arXiv.1506.02438]
   Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]
   Silver D, 2014, PR MACH LEARN RES, V32
   Steinicke F, 2010, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2010.5444790
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma E.A, 2015, P ACM SIGGRAPH EM TE, P1
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343
   Thomas J., 2020, P 26 ACM S VIRT REAL, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Wang LL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P651, DOI [10.1109/VRW50115.2020.00176, 10.1109/VRW50115.2020.00-99]
   Wang LL, 2019, IEEE T VIS COMPUT GR, V25, P2083, DOI 10.1109/TVCG.2019.2898782
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Ye ZM, 2021, INT SYM MIX AUGMENT, P239, DOI 10.1109/ISMAR52148.2021.00039
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P3327, DOI 10.1109/TVCG.2022.3158609
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 52
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1696
EP 1709
DI 10.1109/TVCG.2022.3224073
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500007
PM 36417720
DA 2024-08-05
ER

PT J
AU Prasad, V
   van Sloun, RJG
   Elzen, SV
   Vilanova, A
   Pezzotti, N
AF Prasad, Vidya
   van Sloun, Ruud J. G.
   Elzen, Stef van den
   Vilanova, Anna
   Pezzotti, Nicola
TI The <i>Transform-and-Perform</i> Framework: Explainable Deep Learning
   Beyond Classification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; explainable AI; framework; deep learning;
   high-dimensional-to-high-dimensional translation; XAI
ID VISUAL ANALYTICS; INTERACTIVE ANALYSIS
AB In recent years, visual analytics (VA) has shown promise in alleviating the challenges of interpreting black-box deep learning (DL) models. While the focus of VA for explainable DL has been mainly on classification problems, DL is gaining popularity in high-dimensional-to-high-dimensional (H-H) problems such as image-to-image translation. In contrast to classification, H-H problems have no explicit instance groups or classes to study. Each output is continuous, high-dimensional, and changes in an unknown non-linear manner with changes in the input. These unknown relations between the input, model and output necessitate the user to analyze them in conjunction, leveraging symmetries between them. Since classification tasks do not exhibit some of these challenges, most existing VA systems and frameworks allow limited control of the components required to analyze models beyond classification. Hence, we identify the need for and present a unified conceptual framework, the Transform-and-Perform framework (T&P), to facilitate the design of VA systems for DL model analysis focusing on H-H problems. T&P provides a checklist to structure and identify workflows and analysis strategies to design new VA systems, and understand existing ones to uncover potential gaps for improvements. The goal is to aid the creation of effective VA systems that support the structuring of model understanding and identifying actionable insights for model improvements. We highlight the growing need for new frameworks like T&P with a real-world image-to-image translation application. We illustrate how T&P effectively supports the understanding and identification of potential gaps in existing VA systems.
C1 [Prasad, Vidya; Elzen, Stef van den; Vilanova, Anna; Pezzotti, Nicola] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5600 AZ Eindhoven, Netherlands.
   [van Sloun, Ruud J. G.] Eindhoven Univ Technol, Dept Elect Engn, NL-5612 AZ Eindhoven, Netherlands.
   [van Sloun, Ruud J. G.; Pezzotti, Nicola] Philips Res, NL-5656 AE Eindhoven, Netherlands.
C3 Eindhoven University of Technology; Eindhoven University of Technology;
   Philips; Philips Research
RP Prasad, V (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5600 AZ Eindhoven, Netherlands.
EM v.prasad@tue.nl; r.j.g.v.sloun@tue.nl; s.j.v.d.elzen@tue.nl;
   a.vilanova@tue.nl; n.pezzotti@tue.nl
RI van Sloun, Ruud/AGX-0436-2022
OI van Sloun, Ruud/0000-0003-2845-0495; van den Elzen,
   Stef/0000-0003-1245-0503; Vilanova, Anna/0000-0002-1034-737X; Prasad,
   Vidya/0000-0002-9296-3693
CR [Anonymous], 2017, Facets-know your data
   Barbu A, 2019, ADV NEUR IN, V32
   Buongiorno D, 2021, NEUROCOMPUTING, V452, P549, DOI 10.1016/j.neucom.2020.06.139
   Caballero HSG, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13667
   Cashman D, 2020, IEEE T VIS COMPUT GR, V26, P863, DOI 10.1109/TVCG.2019.2934261
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Cohen TS, 2016, PR MACH LEARN RES, V48
   D'Amour A, 2020, Arxiv, DOI arXiv:2011.03395
   Darestani Mohammad Zalbagi, 2021, PR MACH LEARN RES
   Das N, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P271, DOI 10.1109/VIS47514.2020.00061
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L., 2012, IEEE Signal Process. Mag., V29, P141
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Ghorbani A., 2020, ARXIV PREPRINT ARXIV, V33, P5922
   Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095
   Han X, 2017, MED PHYS, V44, P1408, DOI 10.1002/mp.12155
   Harfiya LN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092952
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Hendrycks D, 2018, P INT C LEARN REPR
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Huang XY, 2021, COMPUT GRAPH FORUM, V40, P227, DOI 10.1111/cgf.14302
   Hund Michael, 2016, Brain Inform, V3, P233, DOI 10.1007/s40708-016-0043-5
   Iwana BK, 2019, IEEE INT CONF COMP V, P4176, DOI 10.1109/ICCVW.2019.00513
   Jacobsen J.-H., 2019, P INT C LEARN REPR
   Jaderberg M, 2015, ADV NEUR IN, V28
   Janik A., 2019, P C MACH LEARN METH
   Jeong S, 2022, COMPUT GRAPH FORUM, V41, P85, DOI 10.1111/cgf.14524
   Jia Y, 2019, INTERSPEECH, P1123, DOI 10.21437/Interspeech.2019-1951
   Kahng M., 2016, P WORKSH HUM LOOP DA, P1
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kaji S, 2019, RADIOL PHYS TECHNOL, V12, P235, DOI 10.1007/s12194-019-00520-y
   Kastryulin S, 2022, Arxiv, DOI [arXiv:2203.07809, 10.1109/ACCESS.2023.3243466]
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Li G, 2021, IEEE T VIS COMPUT GR, V27, P1364, DOI 10.1109/TVCG.2020.3030461
   Li H, 2018, ADV NEUR IN, V31
   Lin DJ, 2021, J MAGN RESON IMAGING, V53, P1015, DOI 10.1002/jmri.27078
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Bronstein MMM, 2021, Arxiv, DOI [arXiv:2104.13478, DOI 10.48550/ARXIV.2104.13478]
   Ma YX, 2021, IEEE T VIS COMPUT GR, V27, P1385, DOI 10.1109/TVCG.2020.3028888
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   McNutt A, 2021, COMPUT GRAPH FORUM, V40, P61, DOI 10.1111/cgf.14289
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nikolov Stanislav, 2021, J Med Internet Res, V23, pe26151, DOI 10.2196/26151
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Park C., 2021, P EUR C VIS
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Raidou R. G., 2016, P EG VIS COMP BIOL M, P193
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sacha D, 2017, NEUROCOMPUTING, V268, P164, DOI 10.1016/j.neucom.2017.01.105
   Sagad Hamid., 2019, 2 WORKSHOP MACHINE L, P19, DOI DOI 10.2312/MLVIS.20191160
   Schlegel U., 2020, P INT WORKSH MACH LE, P7
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sietzen S, 2021, COMPUT GRAPH FORUM, V40, P253, DOI 10.1111/cgf.14418
   Smilkov D., 2016, P NEUR INF PROC SYST
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   van Sloun RJG, 2020, P IEEE, V108, P11, DOI 10.1109/JPROC.2019.2932116
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Zbontar J, 2019, Arxiv, DOI arXiv:1811.08839
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JP, 2017, Arxiv, DOI arXiv:1706.09092
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
NR 79
TC 3
Z9 3
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1502
EP 1515
DI 10.1109/TVCG.2022.3219248
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300001
PM 36327191
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, C
   Wei, GS
   Wei, GD
   Wang, WP
   Zhou, YF
AF Wang, Chen
   Wei, Guangshun
   Wei, Guodong
   Wang, Wenping
   Zhou, Yuanfeng
TI Tooth Alignment Network Based on Landmark Constraints and Hierarchical
   Graph Structure
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teeth; Point cloud compression; Feature extraction; Dentistry;
   Three-dimensional displays; Shape; Solid modeling; Orthodontics; tooth
   landmark; tooth alignment; hierarchical graph neural network
ID NEURAL-NETWORK
AB Automatic tooth alignment target prediction is vital in shortening the planning time of orthodontic treatments and aligner designs. Generally, the quality of alignment targets greatly depends on the experience and ability of dentists and has enormous subjective factors. Therefore, many knowledge-driven alignment prediction methods have been proposed to help inexperienced dentists. Unfortunately, existing methods tend to directly regress tooth motion, which lacks clinical interpretability. Tooth anatomical landmarks play a critical role in orthodontics because they are effective in aiding the assessment of whether teeth are in close arrangement and normal occlusion. Thus, we consider anatomical landmark constraints to improve tooth alignment results. In this article, we present a novel tooth alignment neural network for alignment target predictions based on tooth landmark constraints and a hierarchical graph structure. We detect the landmarks of each tooth first and then construct a hierarchical graph of jaw-tooth-landmark to characterize the relationship between teeth and landmarks. Then, we define the landmark constraints to guide the network to learn the normal occlusion and predict the rigid transformation of each tooth during alignment. Our method achieves better results with the architecture built for tooth data and landmark constraints and has better explainability than previous methods with regard to clinical tooth alignments.
C1 [Wang, Chen; Wei, Guangshun; Zhou, Yuanfeng] Shandong Univ, Sch Software, Jinan 250100, Peoples R China.
   [Wei, Guodong; Wang, Wenping] Univ Hong Kong, Hong Kong, Peoples R China.
   [Wang, Wenping] Texas A&M Univ, College Stn, TX 77843 USA.
C3 Shandong University; University of Hong Kong; Texas A&M University
   System; Texas A&M University College Station
RP Zhou, YF (corresponding author), Shandong Univ, Sch Software, Jinan 250100, Peoples R China.
EM chen.wang@mail.sdu.edu.cn; guangshunwei@gmail.com; gdwei@cs.hku.hk;
   wenping@cs.hku.hk; yfzhou@sdu.edu.cn
RI Zhou, Yuanfeng/AAT-4670-2020
OI Wang, Chen/0000-0001-7162-4687; Wei, Guangshun/0000-0002-6045-4392; Wei,
   Guodong/0000-0001-6975-9865
FU National Key R#x0026;D Plan on Strategic International Scientific and
   Technological Innovation Cooperation Special Project
FX No Statement Available
CR ANDREWS LF, 1972, AMER J ORTHODONTICS, V62, P296, DOI 10.1016/S0002-9416(72)90268-0
   Atwood J, 2016, ADV NEUR IN, V29
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Chang YB, 2010, IEEE T MED IMAGING, V29, P1652, DOI 10.1109/TMI.2010.2049526
   Chen RN, 2019, LECT NOTES COMPUT SC, V11766, P873, DOI 10.1007/978-3-030-32248-9_97
   Chen W, 2020, PROC CVPR IEEE, P4232, DOI 10.1109/CVPR42600.2020.00429
   Cheng C, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0269-4
   Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]
   Cui ZM, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101949
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198252
   Defferrard M, 2016, ADV NEUR IN, V29
   Du GG, 2021, ARTIF INTELL REV, V54, P1677, DOI 10.1007/s10462-020-09888-5
   Fischer K, 2021, PROC CVPR IEEE, P313, DOI 10.1109/CVPR46437.2021.00038
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Guodong Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P481, DOI 10.1007/978-3-030-58555-6_29
   He W., 2020, P IEEE CVF C COMP VI, P11629, DOI [10.1109/CVPR42600.2020.01165, DOI 10.1109/CVPR42600.2020.01165]
   Hinterstoisser S., 2012, ACCV, P548
   Hu FY, 2019, Arxiv, DOI arXiv:1902.06667
   Huang J, 2020, Advances in Neural Information Processing Systems, P6315
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Kondo T, 2004, IEEE T MED IMAGING, V23, P350, DOI 10.1109/TMI.2004.824235
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li YJ, 2017, Arxiv, DOI arXiv:1511.05493
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Ma Q, 2020, COMPUT GRAPH FORUM, V39, P267, DOI 10.1111/cgf.14143
   Ma Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P723, DOI 10.1145/3292500.3330982
   Micheli A, 2009, IEEE T NEURAL NETWOR, V20, P498, DOI 10.1109/TNN.2008.2010350
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shah S, 2006, 2006 BIOMETRICS SYMPOSIUM: SPECIAL SESSION ON RESEARCH AT THE BIOMETRIC CONSORTIUM CONFERENCE, P137
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wada K., 2020, PROC IEEECVF C COMPU, P14540
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wei GS, 2022, COMPUT AIDED GEOM D, V94, DOI 10.1016/j.cagd.2022.102077
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xiaoshuang Li, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P105, DOI 10.1007/978-3-030-59716-0_11
   Xu XJ, 2019, IEEE T VIS COMPUT GR, V25, P2336, DOI 10.1109/TVCG.2018.2839685
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yang LC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417771
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Zanjani FG, 2019, LECT NOTES COMPUT SC, V11768, P128, DOI 10.1007/978-3-030-32254-0_15
   Zhang SB, 2021, PROC CVPR IEEE, P1065, DOI 10.1109/CVPR46437.2021.00112
NR 49
TC 0
Z9 0
U1 8
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1457
EP 1469
DI 10.1109/TVCG.2022.3218028
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300012
PM 36315543
DA 2024-08-05
ER

PT J
AU Guo, YH
   Luo, YC
   Lu, KR
   Li, LF
   Yang, HZ
   Yuan, XR
AF Guo, Yuhan
   Luo, Yuchu
   Lu, Keer
   Li, Linfang
   Yang, Haizheng
   Yuan, Xiaoru
TI LiberRoad: Probing into the Journey of Chinese Classics Through Visual
   Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; digital humanities; spatial uncertainty; trajectory
   visualization; book movement; historical data
ID TEMPORAL EVENT SEQUENCES; VISUALIZATION; UNCERTAINTY; MOVEMENT;
   GEOVISUALIZATION; FLOW
AB Books act as a crucial carrier of cultural dissemination in ancient times. This work involves joint efforts between visualization and humanities researchers, aiming at building a holistic view of the cultural exchange and integration between China and Japan brought about by the overseas circulation of Chinese classics. Book circulation data consist of uncertain spatiotemporal trajectories, with multiple dimensions, and movement across hierarchical spaces forms a compound network. LiberRoad visualizes the circulation of books collected in the Imperial Household Agency of Japan, and can be generalized to other book movement data. The LiberRoad system enables a smooth transition between three views (Location Graph, map, and timeline) according to the desired perspectives (spatial or temporal), as well as flexible filtering and selection. The Location Graph is a novel uncertainty-aware visualization method that employs improved circle packing to represent spatial hierarchy. The map view intuitively shows the overall circulation by clustering and allows zooming into single book trajectory with lenses magnifying local movements. The timeline view ranks dynamically in response to user interaction to facilitate the discovery of temporal events. The evaluation and feedback from the expert users demonstrate that LiberRoad is helpful in revealing movement patterns and comparing circulation characteristics of different times and spaces.
C1 [Guo, Yuhan; Luo, Yuchu; Lu, Keer; Yuan, Xiaoru] Peking Univ, Sch AI, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing, Peoples R China.
   [Li, Linfang; Yang, Haizheng] Peking Univ, Ctr Ancient Chinese Class & Arch, Beijing, Peoples R China.
   [Li, Linfang; Yang, Haizheng] Peking Univ, Dept Chinese Language & Literature, Beijing, Peoples R China.
C3 Peking University; Peking University; Peking University; Peking
   University
RP Yuan, XR (corresponding author), Peking Univ, Sch AI, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing, Peoples R China.
EM yuhan.guo@pku.edu.cn; luoyuchu@pku.edu.cn; keer.lu@outlook.com;
   llfang@pku.edu.cn; haizheng@pku.edu.cn; xiaoru.yuan@pku.edu.cn
OI Guo, Yuhan/0009-0004-3857-7486; Yuan, Xiaoru/0000-0002-7233-980X
FU NSFC
FX No Statement Available
CR Andrienko G., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P161, DOI 10.1109/VAST.2011.6102454
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Andrienko G, 2013, IEEE T VIS COMPUT GR, V19, P1078, DOI 10.1109/TVCG.2012.311
   Andrienko G, 2008, INFORM VISUAL, V7, P173, DOI 10.1057/ivs.2008.23
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   Andrienko N, 2012, KUNSTL INTELL, V26, P241, DOI 10.1007/s13218-012-0177-4
   Bach B., 2015, P C INF VIS
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brodlie K, 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [DOI 10.1007/978-1-4471-2804-56, 10.1007/978-1-4471-2804-5_6, DOI 10.1007/978-1-4471-2804-5_6]
   Burch M., 2008, P WORK C ADV VIS INT, P75
   C. CERL, 2015, Material evidence in incunabula
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Crnovrsanin Tarik, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P11, DOI 10.1109/VAST.2009.5332593
   Deitrick S., 2006, Progress in Spatial Data Handling, P719, DOI [DOI 10.1007/3-540-35589-845, 10.1007/3-540-35589-845, DOI 10.1007/3-540-35589-8_45]
   Dodge S, 2008, INFORM VISUAL, V7, P240, DOI 10.1057/palgrave.ivs.9500182
   Eppstein D., 1998, P ANN ACM SIAM S DIS, P619
   Fischer MT, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P81, DOI 10.1109/VIS49827.2021.9623305
   Geon Cho, 1997, INFORMS Journal on Computing, V9, P431, DOI 10.1287/ijoc.9.4.431
   Görtler J, 2018, IEEE T VIS COMPUT GR, V24, P719, DOI 10.1109/TVCG.2017.2743959
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Guo DS, 2014, IEEE T VIS COMPUT GR, V20, P2043, DOI 10.1109/TVCG.2014.2346271
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Ilagcrstrand T., 1970, Regional Science Association, V24
   Kraak M.-J., 2003, P 21 INT CART C ICC, P1988
   Krautli Florian., 2013, Proc. Electronic Visualisation and the Arts 2013, P61
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Y., 2013, From Manuscripts to Block-prints: Research on Chinese and Japanese Edition of "Analects".
   Liu Y., 2018, The Documentation, V170, P77
   Lu J., 1990, The Circulation and Influence of Chinese Classics in Japan
   Luo Y., 2022, Big Data Research, V8, P74
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Munroe R., 2013, Movie narrative charts
   Panagiotidou Georgia, 2023, IEEE Trans Vis Comput Graph, V29, P635, DOI 10.1109/TVCG.2022.3209436
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Rosenberg D., 2010, Cartographies of Time: A History of the Timeline
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Sun X., 2017, Journal of Social Science Front, P113
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Thudt A., 2013, P EUR C VIS
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   Wang TD, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P457
   Wang W., 2006, P SIGCHI C HUM FACT, P517
   Wang Y., 2003, Research on the "Book Road"between China and Japan
   Wang Y., 1992, Studies on the History of Chinese and Japanese Classic Exchanges
   Wang ZC, 2014, INT CONF BIG DATA, P13, DOI 10.1109/BIGCOMP.2014.6741397
   Wang ZC, 2014, IEEE T VIS COMPUT GR, V20, P1813, DOI 10.1109/TVCG.2014.2346746
   Ware C, 2006, IEEE COMPUT GRAPH, V26, P14, DOI 10.1109/MCG.2006.93
   Weiskopf D, 2022, FRONT BIOINFORM, V2, DOI 10.3389/fbinf.2022.793819
   Windhager F, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030029
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Xing Y., 2022, EUROVIS SHORT PAPERS
   Yang H., 2020, A Compilation of Engraved Versions of "Records of the Grand Historian"in Japan
   Yang H., 2022, Library Tribune, V42, P131
   Yang H., 2017, Research on "Records of the Grand Historian
   Yang H., 2020, Peking University Center for Ancient Chinese Documentation Studies Journal, V21, P256
   Zhang WX, 2022, IEEE T VIS COMPUT GR, V28, P1982, DOI 10.1109/TVCG.2022.3150467
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
   Zhao JF, 2008, INFORM VISUAL, V7, P198, DOI 10.1057/palgrave.ivs.9500184
NR 68
TC 1
Z9 1
U1 5
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 529
EP 539
DI 10.1109/TVCG.2023.3326944
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500002
PM 37874725
DA 2024-08-05
ER

PT J
AU He, JB
   Wang, XB
   Wong, KK
   Huang, XJ
   Chen, CJ
   Chen, ZX
   Wang, FJ
   Zhu, M
   Qu, HM
AF He, Jianben
   Wang, Xingbo
   Wong, Kam Kwai
   Huang, Xijie
   Chen, Changjian
   Chen, Zixin
   Wang, Fengjie
   Zhu, Min
   Qu, Huamin
TI <i>VideoPro:</i> A Visual Analytics Approach for Interactive Video
   Programming
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interactive machine learning; data programming; video exploration and
   analysis
AB Constructing supervised machine learning models for real-world video analysis require substantial labeled data, which is costly to acquire due to scarce domain expertise and laborious manual inspection. While data programming shows promise in generating labeled data at scale with user-defined labeling functions, the high dimensional and complex temporal information in videos poses additional challenges for effectively composing and evaluating labeling functions. In this paper, we propose VideoPro, a visual analytics approach to support flexible and scalable video data programming for model steering with reduced human effort. We first extract human-understandable events from videos using computer vision techniques and treat them as atomic components of labeling functions. We further propose a two-stage template mining algorithm that characterizes the sequential patterns of these events to serve as labeling function templates for efficient data labeling. The visual interface of VideoPro facilitates multifaceted exploration, examination, and application of the labeling templates, allowing for effective programming of video data at scale. Moreover, users can monitor the impact of programming on model performance and make informed adjustments during the iterative programming process. We demonstrate the efficiency and effectiveness of our approach with two case studies and expert interviews.
C1 [He, Jianben; Wang, Xingbo; Wong, Kam Kwai; Huang, Xijie; Chen, Zixin; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Chen, Changjian] Tsinghua Univ, Beijing, Peoples R China.
   [Wang, Fengjie; Zhu, Min] Sichuang Univ, Chengdu, Peoples R China.
C3 Hong Kong University of Science & Technology; Tsinghua University;
   Sichuan University
RP Wang, XB (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM jhebt@ust.hk; xwangeg@ust.hk; kkwongar@ust.hk; xhuangbs@ust.hk;
   changjianchen.me@gmail.com; zchendf@ust.hk; wangfengjie@stu.scu.edu.cn;
   zhumin@scu.edu.cn; huamin@ust.hk
RI 0, 0/KEE-7704-2024; chen, zixin/JSL-6007-2023; Chen,
   Zixin/GQZ-7920-2022; Chen, Changjian/KBA-9462-2024; Huang,
   Xijie/KOD-4309-2024; 陈, 梓昕/GQP-6896-2022; Wang, Xingbo/JHS-6567-2023;
   ZHU, JIALI/JNE-3065-2023; xu, lingzhi/JVZ-8748-2024
OI Chen, Changjian/0000-0003-2715-8839; Wang, Xingbo/0000-0001-5693-1128;
   WONG, Kam Kwai/0000-0002-2813-1972
FU ITF PRP
FX No Statement Available
CR Abernethy B., 2013, Human Kinetics, V8
   Afzal S, 2023, ACM T INTERACT INTEL, V13, DOI 10.1145/3576935
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bernard J, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3439333
   Bernard J, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13406
   Blascheck T, 2016, IEEE CONF VIS ANAL, P141, DOI 10.1109/VAST.2016.7883520
   Cansik, 2022, yolo-hand-detection
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Choi M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300460
   Contributors M., Openmmlab's next generation video understanding toolbox and benchmark
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   Deng D., 2021, P CHI, P1, DOI DOI 10.1145/3411764.34454312
   Fan Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P420, DOI 10.1007/978-3-030-58548-8_25
   Feng YCJ, 2023, Arxiv, DOI arXiv:2307.09036
   Grimmeisen B, 2023, VISUAL COMPUT, V39, P5097, DOI 10.1007/s00371-022-02648-2
   Grunwald P. D., 2007, The Minimum Description Length Principle (Adaptive Computation and Machine Learning), P4
   Halter G, 2019, COMPUT GRAPH FORUM, V38, P119, DOI 10.1111/cgf.13676
   Hamill J., 2006, Biomechanical basis of human movement, P8
   Höferlin B, 2015, INFORM VISUAL, V14, P10, DOI 10.1177/1473871613488571
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoque Md Naimul, 2023, IEEE Trans Vis Comput Graph, V29, P74, DOI 10.1109/TVCG.2022.3209466
   Hosseininasab A, 2019, AAAI CONF ARTIF INTE, P1495
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Jiao LC, 2022, IEEE T NEUR NET LEAR, V33, P3195, DOI 10.1109/TNNLS.2021.3053249
   Jingwei Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10233, DOI 10.1109/CVPR42600.2020.01025
   Khayat M, 2020, IEEE T VIS COMPUT GR, V26, P874, DOI 10.1109/TVCG.2019.2934266
   Kurby CA, 2008, TRENDS COGN SCI, V12, P72, DOI 10.1016/j.tics.2007.11.004
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Lasecki WalterS., 2014, Proceedings of the 27th annual acm symposium on user interface software and technology, P551
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li JC, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4568
   Li KC, 2022, Arxiv, DOI arXiv:2201.04676
   Liang P. P., 2023, INT C LEARNING REPRE
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Meng1994412, 2022, smile_detection
   Moehrmann J, 2011, LECT NOTES COMPUT SC, V6761, P618, DOI 10.1007/978-3-642-21602-2_67
   Morrow B, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P1, DOI [10.1109/VISUAL.2019.8933582, 10.1109/visual.2019.8933582]
   Ou L. Mi, 2022, P IEEECVF C COMPUTER, P20133
   Parry ML, 2011, IEEE T VIS COMPUT GR, V17, P1747, DOI 10.1109/TVCG.2011.208
   Price W, 2022, PROC CVPR IEEE, P13760, DOI 10.1109/CVPR52688.2022.01340
   Ratner A., 2016, PROC NEURIPS, P2
   Ratner A, 2017, PROC VLDB ENDOW, V11, P269, DOI 10.14778/3157794.3157797
   Schoning J., 2019, Advances in Information and Communication Networks, P346, DOI [10.1007/978-3-030-03402-3_232, DOI 10.1007/978-3-030-03402-3_232]
   Settles B., 1994, Machine Learning, V15, P7
   Soomro K., 2012, arXiv
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/VAST47406.2019.8986917, 10.1109/vast47406.2019.8986917]
   Sun JJ, 2021, PROC CVPR IEEE, P2875, DOI [10.1109/CVPR46437.2021.00290, 10.1109/cvpr46437.2021.00290]
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Vahdani E, 2023, IEEE T PATTERN ANAL, V45, P4302, DOI 10.1109/TPAMI.2022.3193611
   Wang JC, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3688, DOI 10.1145/3447548.3467104
   Wang M, 2021, arXiv
   Wang X, 2022, AAAI CONF ARTIF INTE, P12665
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang XB, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376726
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P3441, DOI 10.1109/TVCG.2021.3067200
   Wongvichayakul Kittamet, 2023, IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON51785.2023.10311940
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang Y, 2021, Arxiv, DOI arXiv:2111.09276
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zeng HP, 2023, IEEE T VIS COMPUT GR, V29, P3685, DOI 10.1109/TVCG.2022.3169175
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang JY, 2022, Arxiv, DOI arXiv:2202.05433
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhang Y, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517612
   Zhou JH, 2023, IEEE T VIS COMPUT GR, V29, P809, DOI 10.1109/TVCG.2022.3209391
NR 83
TC 2
Z9 2
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 87
EP 97
DI 10.1109/TVCG.2023.3326586
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500005
PM 37871060
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Snyder, LS
   Heer, J
AF Snyder, Luke S.
   Heer, Jeffrey
TI DIVI: Dynamically Interactive Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interaction; Visualization Tools; Charts; SVG; Exploratory Data Analysis
ID TOOLKIT; LYRA
AB Dynamically Interactive Visualization (DIVI) is a novel approach for orchestrating interactions within and across static visualizations. DIVI deconstructs Scalable Vector Graphics charts at runtime to infer content and coordinate user input, decoupling interaction from specification logic. This decoupling allows interactions to extend and compose freely across different tools, chart types, and analysis goals. DIVI exploits positional relations of marks to detect chart components such as axes and legends, reconstruct scales and view encodings, and infer data fields. DIVI then enumerates candidate transformations across inferred data to perform linking between views. To support dynamic interaction without prior specification, we introduce a taxonomy that formalizes the space of standard interactions by chart element, interaction type, and input event. We demonstrate DIVI's usefulness for rapid data exploration and analysis through a usability study with 13 participants and a diverse gallery of dynamically interactive visualizations, including single chart, multi-view, and cross-tool configurations.
C1 [Snyder, Luke S.; Heer, Jeffrey] Univ Washington, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle
RP Snyder, LS (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM snyderl@cs.washington.edu; jheer@cs.washington.edu
FU Moore Foundation software
FX No Statement Available
CR Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brosz M. A., 2013, P 26 ANN ACM S US IN, P97, DOI [10.1145/2501988.2502046.19, DOI 10.1145/2501988.2502046.19]
   Choi J, 2015, IEEE T VIS COMPUT GR, V21, P1087, DOI 10.1109/TVCG.2015.2414454
   Davila K, 2021, IEEE T PATTERN ANAL, V43, P3799, DOI 10.1109/TPAMI.2020.2992028
   Dey A. K., 2005, ACM Transactions on Computer-Human Interaction (TOCHI), V12, P4
   Github, 2022, About us
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, P 27 ANN ACM S USER, V14, P253, DOI [10.1145/2642918.2647411, DOI 10.1145/2642918.26474112, DOI 10.1145/2642918.2647411]
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Liu C, 2024, Arxiv, DOI arXiv:2303.14476
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lu M, 2017, IEEE PAC VIS SYMP, P61
   Lu S., 2022, D3-annotation
   Manolis Savva, 2011, P 24 ANN ACM S USER, P393
   Masson D., 2023, P 2023 CHI C HUMAN F, P1
   matplotlib, 2022, About Us
   McDaniel R.G., 1999, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '99, P442
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI [10.1145/345513.345282, DOI 10.1145/345513.345282]
   plotly, 2022, About Us
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ren D., 2018, IEEE transactions on visualization and computer graphics, V25, P2
   Saket B, 2019, Arxiv, DOI arXiv:1907.08345
   Saket B, 2019, COMPUT GRAPH FORUM, V38, P663, DOI 10.1111/cgf.13718
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Sedig K., 2013, AIS Transactions on Human-Computer Interaction, V5, P2
   Srinivasan A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376782
   Tableau, 2022, ABOUT US
   uwdata.github, 2022, About Us
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI DOI 10.1007/978-3-319-24277-4
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 39
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 403
EP 413
DI 10.1109/TVCG.2023.3327172
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500100
PM 37889812
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Chen, YZ
   Gao, SJ
   Tu, PX
   Chen, XJ
AF Chen, Yizhou
   Gao, Shuojie
   Tu, Puxun
   Chen, Xiaojun
TI Automatic 3D Teeth Reconstruction From Five Intra-Oral Photos Using
   Parametric Teeth Model
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teeth; Three-dimensional displays; Shape; Solid modeling; Image
   reconstruction; Dentistry; Image restoration; Statistical shape
   modeling; parametric teeth model; teeth contour extraction; teeth
   reconstruction
AB Orthodontic treatment is a lengthy process that requires regular in-person dental monitoring, making remote dental monitoring a viable alternative when face-to-face consultation is not possible. In this study, we propose an improved 3D teeth reconstruction framework that automatically restores the shape, arrangement, and dental occlusion of upper and lower teeth from five intra-oral photographs to aid orthodontists in visualizing the condition of patients in virtual consultations. The framework comprises a parametric model that leverages statistical shape modeling to describe the shape and arrangement of teeth, a modified U-net that extracts teeth contours from intra-oral images, and an iterative process that alternates between finding point correspondences and optimizing a compound loss function to fit the parametric teeth model to predicted teeth contours. We perform a five-fold cross-validation on a dataset of 95 orthodontic cases and report an average Chamfer distance of 1.0121 mm(2) and an average Dice similarity coefficient of 0.7672 on all the test samples in the cross-validation, demonstrating a significant improvement compared with the previous work. Our teeth reconstruction framework provides a feasible solution for visualizing 3D teeth models in remote orthodontic consultations.
C1 [Chen, Yizhou; Gao, Shuojie; Tu, Puxun] Shanghai Jiao Tong Univ, Inst Biomed Mfg & Life Qual Engn, Sch Mech Engn, Shanghai 200240, Peoples R China.
   [Chen, Xiaojun] Shanghai Jiao Tong Univ, Inst Med Robot, Sch Mech Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Chen, XJ (corresponding author), Shanghai Jiao Tong Univ, Inst Med Robot, Sch Mech Engn, Shanghai 200240, Peoples R China.
EM yizhou.chen@sjtu.edu.cn; gaoshuojie@sjtu.edu.cn; puxuntu@sjtu.edu.cn;
   xiaojunchen@sjtu.edu.cn
OI Tu, Puxun/0000-0003-4809-9081; CHEN, YIZHOU/0000-0003-3693-7893; Gao,
   Shuojie/0000-0002-0186-8413
FU National Natural Science Foundation of China [81971709, M-0019,
   82011530141]; Foundation of Science and Technology Commission of
   Shanghai Municipality [20490740700]; Shanghai Pudong Science and
   Technology Development Fund [PKX2021-R04]; Shanghai Jiao Tong University
   Foundation on Medical and Technological Joint Science Research
   [YG2019ZDA06, YG2021ZD21, YG2021QN72, YG2022QN056]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 81971709, M-0019, and 82011530141, in
   part by the Foundation of Science and Technology Commission of Shanghai
   Municipality under Grant 20490740700, in part by Shanghai Pudong Science
   and Technology Development Fund under Grant PKX2021-R04, in part by
   Shanghai Jiao Tong University Foundation on Medical and Technological
   Joint Science Research under Grants YG2019ZDA06, YG2021ZD21,
   YG2021QN72,and YG2022QN056.
CR Abdelrahim A.S., 2012, P IEEE COMP SOC C CO, P64
   Abdelrehim A. A., 2013, P INT MICCAI WORKSH, P44
   Alldieck T, 2022, PROC CVPR IEEE, P1496, DOI 10.1109/CVPR52688.2022.00156
   Berlinet C., 2011, Reproducing Kernel Hilbert Spaces inProbability and Statistics
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chen L.-C., 2018, P EUR C COMP VIS ECC, P801, DOI DOI 10.1007/978-3-030-01234-2_49
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Farag Aly., 2012, International MICCAI Workshop on Medical Computer Vision, P263
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   Hartley R., 2003, Computer Vision
   He H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091015
   Hong-Seok P, 2015, PROCEDIA ENGINEER, V100, P1174, DOI 10.1016/j.proeng.2015.01.481
   Jackson AS, 2019, LECT NOTES COMPUT SC, V11132, P64, DOI 10.1007/978-3-030-11018-5_6
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lüthi M, 2018, IEEE T PATTERN ANAL, V40, P1860, DOI 10.1109/TPAMI.2017.2739743
   Ma J, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102035
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Morales A, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100400
   Mostafa E, 2014, IEEE IMAGE PROC, P4285, DOI 10.1109/ICIP.2014.7025870
   Mustafa A, 2021, PROC CVPR IEEE, P14469, DOI 10.1109/CVPR46437.2021.01424
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Özyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X
   Revilla-Leon M, 2021, J AM DENT ASSOC, V152, P669, DOI 10.1016/j.adaj.2021.05.018
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler J, 2002, J Orthod, V29, P158, DOI 10.1093/ortho/29.2.158
   Schoukens J, 2019, IEEE CONTR SYST MAG, V39, P28, DOI 10.1109/MCS.2019.2938121
   Song WN, 2021, AAAI CONF ARTIF INTE, V35, P566
   Styner MA, 2003, LECT NOTES COMPUT SC, V2732, P63
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wirtz A, 2021, PROC SPIE, V11596, DOI 10.1117/12.2582253
   Wu CL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980233
   Yang LC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417771
   Yuan Liang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12262), P400, DOI 10.1007/978-3-030-59713-9_39
   Zheng S. Li, 2017, Statistical Shape and DeformationAnalysis: Methods, Implementation and Applications
NR 38
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4780
EP 4791
DI 10.1109/TVCG.2023.3277914
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400098
PM 37204961
DA 2024-08-05
ER

PT J
AU Childs, E
   Mohammad, F
   Stevens, L
   Burbelo, H
   Awoke, A
   Rewkowski, N
   Manocha, D
AF Childs, Elizabeth
   Mohammad, Ferzam
   Stevens, Logan
   Burbelo, Hugo
   Awoke, Amanuel
   Rewkowski, Nicholas
   Manocha, Dinesh
TI An Overview of Enhancing Distance Learning Through Emerging Augmented
   and Virtual Reality Technologies
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computer aided instruction; Education; Virtual reality; Headphones;
   Visualization; Pandemics; Sensors; Human-centered computing-Human
   computer interaction (HCI)-Interaction paradigms-Mixed / augmented
   reality; Human-centered computing-Human computer interaction
   (HCI)-Interaction paradigms-Virtual reality
ID SOCIAL-INTERACTION; EDUCATION
AB Although distance learning presents a number of interesting educational advantages as compared to in-person instruction, it is not without its downsides. We first assess the educational challenges presented by distance learning as a whole and identify 4 main challenges that distance learning currently presents as compared to in-person instruction: the lack of social interaction, reduced student engagement and focus, reduced comprehension and information retention, and the lack of flexible and customizable instructor resources. After assessing each of these challenges in-depth, we examine how AR/VR technologies might serve to address each challenge along with their current shortcomings, and finally outline the further research that is required to fully understand the potential of AR/VR technologies as they apply to distance learning.
C1 [Childs, Elizabeth; Mohammad, Ferzam; Stevens, Logan; Burbelo, Hugo; Awoke, Amanuel; Rewkowski, Nicholas; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Childs, E (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM ehchilds@terpmail.umd.edu; fmoham18@terpmail.umd.edu;
   lsteven7@terpmail.umd.edu; hburbelo@terpmail.umd.edu;
   aawoke@terpmail.umd.edu; nick1@umd.edu; dmanocha@umd.edu
OI Childs, Elizabeth/0000-0002-5768-6029; Manocha,
   Dinesh/0000-0001-7047-9801
CR Abd Majid F., 2019, Asian Journal of University Education, V15, P51, DOI DOI 10.24191/AJUE.V15I2.7556
   Acosta-Tello E., 2015, J. Instructional Pedagogies, V17
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   [Anonymous], 1980, Social Interaction And Cognitive Development
   [Anonymous], Zoom video conferencing plans pricing
   [Anonymous], 1993, Early Childhood Res. Quart., DOI DOI 10.1016/S0885-2006(05)80078-X
   Archana M. V., 2014, Int. J. Sci. Eng. Res., V5
   Ayoubi A., 2020, Ikea lanches augmented reality application
   BankMyCell, 2021, MANY SMARTPHONES ARE
   BEARISON DJ, 1986, MERRILL PALMER QUART, V32, P51
   Bergmann J, 2012, PHI DELTA KAPPAN, V94, P25, DOI 10.1177/003172171209400206
   Billinghurst M, 2000, BT TECHNOL J, V18, P80, DOI 10.1023/A:1026582022824
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Blackboard, 2018, Blackboard to acquire Elluminate and Wimba
   Blanco C., 2020, The 2020 duolingo language report
   Carter EW, 2005, RES PRACT PERS SEV D, V30, P179, DOI 10.2511/rpsd.30.4.179
   Chandrasekera Tilanka, 2018, Design and Technology Education: An International Journal, V23, P55
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen CJ, 2005, J RES TECHNOL EDUC, V38, P123, DOI 10.1080/15391523.2005.10782453
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Dumford AD, 2018, J COMPUT HIGH EDUC, V30, P452, DOI 10.1007/s12528-018-9179-z
   Dunser A., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P107, DOI [10.1145/2414536.2414554, DOI 10.1145/2414536.2414554]
   Egglestone S. R., 2006, P S US INT SOFTW TEC
   Eutsler L, 2021, EDUC TECHNOL SOC, V24, P28
   Everysight, 2020, Raptor everysight
   Ferrer-Torregrosa J, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0757-3
   Fidan M, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103635
   Fuste A., 2019, HyperCubes: A Playful Introduction to Compu- tational Thinking in Augmented Reality, DOI DOI 10.1145/3341215.3356264
   Ghuman JK, 1998, INFANT YOUNG CHILD, V11, P21
   Giang V., 2013, Bus. Insider, V18
   Google, 2020, Google cardboard
   Google, 2020, Google AR & VR
   Greenberg G, 1998, IEEE TECHNOL SOC MAG, V17, P36, DOI 10.1109/44.735862
   Hampshire A., 2006, Proceedings of the 18th Australia conference on Computer-Human Interaction: Design: Activities, Artefacts and Environments, P409
   Hanoa E., 2021, Kahoot! reaches 5 billion players after a year of recordhigh growth
   Henderson SJ, 2011, INT SYM MIX AUGMENT
   Hong J, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P15, DOI 10.1145/3341215.3356327
   Horváth I, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.673826
   Huttner JP, 2017, AMCIS 2017 PROCEEDINGS
   James W.B., 1995, New Directions for Adult and Continuing Education, P19, DOI DOI 10.1002/ACE.36719956705
   Johnson Adrian S., 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P169, DOI 10.1007/978-3-642-39405-8_20
   Jorgensen D., 2002, Reference Librarian, P3
   Keller J., 2000, How to integrate learner motivation planning into lesson planning: The arcs model approach
   Kerawalla L., 2006, Virtual Reality, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Khan T, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7208494
   Kiryakova G., 2014, P 9 INT BALK ED SCI
   Küçük S, 2016, ANAT SCI EDUC, V9, P411, DOI 10.1002/ase.1603
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   lenovo, 2020, Oculus Rift S-3D virtual reality system
   Li Y., 2010, P 3 INT C ADV COMP T
   Lin Y, 2022, COMPUT APPL ENG EDUC, V30, P396, DOI 10.1002/cae.22462
   Lytridis C, 2018, EDUC SCI, V8, DOI 10.3390/educsci8010006
   Maloney D., 2020, Proc. ACM Hum.-Comput. Interact., V4
   Marcy V., 2001, Perspective on Physician Assistant Education, V12, P117
   McBrien JL, 2009, INT REV RES OPEN DIS, V10
   medium, 2020, Mobile augmented reality in 2019
   Michael N, 2017, MULTIMED TOOLS APPL, V76, P14169, DOI 10.1007/s11042-016-3808-1
   Microsoft, 2020, Hololens 2
   Mikropoulos T. A., 1998, Education and Information Technologies, V3, P137, DOI 10.1023/A:1009687025419
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Mtebe J. S., 2015, International Journal of Education and Development Using Information and Communication Technology (IJEDICT), V11, P51
   Mystakidis S, 2020, INT CONF INFORM INTE, P365, DOI 10.1109/iisa50023.2020.9284417
   Mystakidis S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052412
   National teacher and principal survey (ntps), Average age of teachers and percentage distribution of teachers, by age category, school type, and main teaching assignment: 2017-18
   Pejoska J, 2016, BRIT J EDUC TECHNOL, V47, P474, DOI 10.1111/bjet.12442
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/vr.2019.8798174, 10.1109/VR.2019.8798174]
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   QuiverVision, 2020, About quiver education
   Rambach Jason, 2021, Virtual, Augmented and Mixed Reality. 13th International Conference, VAMR 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings, P653, DOI 10.1007/978-3-030-77599-5_45
   Raskar Ramesh., 1998, Proceedings of the 25th annual conference on Computer graphics and interactive techniques, P179, DOI DOI 10.1145/280814.280861
   Rotellar C, 2016, AM J PHARM EDUC, V80, DOI 10.5688/ajpe80234
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Schoop E., 2016, P 2016 CHI C EXT ABS, P1607, DOI [10.1145/2851581, DOI 10.1145/2851581, DOI 10.1145/2851581.2892429]
   Seichter H, 2008, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2008.4637354
   Simpson O, 2013, OPEN LEARN, V28, P105, DOI 10.1080/02680513.2013.847363
   Southgate E, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P38, DOI [10.23919/iLRN47897.2020.9155121, 10.23919/ilrn47897.2020.9155121]
   Steinberg RN, 2000, AM J PHYS, V68, pS37, DOI 10.1119/1.19517
   Stott A., 2013, Surrey, BC, Canada, V8, P1
   suits-different, 2019, About us
   Hoang TN, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P253, DOI 10.1145/3196709.3196724
   Tzima S, 2019, EDUC SCI, V9, DOI 10.3390/educsci9020099
   Ventura S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02509
   Vora LJ, 2015, Int J Modern Trends Eng Res, V2, P281
   WICKENS CD, 1992, 1992 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1 AND 2, P842, DOI 10.1109/ICSMC.1992.271688
   Within Unlimited, 2020, Wonderscope: An augmented reality iOS app for kids
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Xiong JH, 2020, OSA CONTINUUM, V3, P2730, DOI 10.1364/OSAC.400900
   Youngblut C., 1997, Educational uses of virtual reality technology
   Yuen S., 2011, J. Educ. Technol. Develop. Exchange, V119
   Zhao JY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P155, DOI [10.1109/vr.2019.8797867, 10.1109/VR.2019.8797867]
NR 94
TC 0
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4480
EP 4496
DI 10.1109/TVCG.2023.3264577
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400026
PM 37037228
DA 2024-08-05
ER

PT J
AU Lan, J
   Zhou, Z
   Xie, X
   Wu, YH
   Zhang, H
   Wu, YC
AF Lan, Ji
   Zhou, Zheng
   Xie, Xiao
   Wu, Yanhong
   Zhang, Hui
   Wu, Yingcai
TI MediVizor: Visual Mediation Analysis of Nominal Variables
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Exploratory causal analysis; information visualization; visual
   analytics; mediation analysis
ID ANALYTICS; MODEL; USER
AB Mediation analysis is crucial for diagnosing indirect causal relations in many scientific fields. However, mediation analysis of nominal variables requires examining and comparing multiple total effects and their corresponding direct/indirect causal effects derived from mediation models. This process is tedious and challenging to achieve with classical analysis tools such as Excel tables. In this study, we worked closely with experts from two scientific domains to design MediVizor, a visualization system that enables experts to conduct visual mediation analysis of nominal variables. The visualization design allows users to browse and compare multiple total effects together with the direct/indirect effects that compose them. The design also allows users to examine to what extent the positive and negative direct/indirect effects contribute to and reduce the total effects, respectively. We conducted two case studies separately with the experts from the two domains, sports and communication science, and a user study with common users to evaluate the system and design. The positive feedback from experts and common users demonstrates the effectiveness and generalizability of the system.
C1 [Lan, Ji; Wu, Yanhong; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhou, Zheng; Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sport Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhou, Z (corresponding author), Zhejiang Univ, Dept Sport Sci, Hangzhou 310027, Zhejiang, Peoples R China.
EM lanjizju@zju.edu.cn; zhouzhengzju@zju.edu.cn; xxie@zju.edu.cn;
   yanhongwu@zju.edu.cn; zhang_hui@zju.edu.cn; ycwu@zju.edu.cn
RI ; LAN, JI/M-2006-2018
OI , Hui/0000-0003-0601-3905; Zhou, Zheng/0000-0002-6319-942X; LAN,
   JI/0000-0002-8658-8620; Wu, Yanhong/0009-0008-8762-5041
FU NSFC [62072400, 62202424]; Collaborative Innovation Center of Artificial
   Intelligence
FX This work was supported in part by NSFC under Grants 62072400 and
   62202424 and in part by the Collaborative Innovation Center of
   Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU).
CR Bae J, 2017, COMPUT GRAPH FORUM, V36, P411, DOI 10.1111/cgf.13198
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Barth L, 2019, INFORM VISUAL, V18, P110, DOI 10.1177/1473871618799500
   Bekos MA, 2010, ALGORITHMICA, V57, P436, DOI 10.1007/s00453-009-9283-6
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Dutilh G, 2009, PSYCHON B REV, V16, P1026, DOI 10.3758/16.6.1026
   Eells WC, 1926, J AM STAT ASSOC, V21, P119, DOI 10.2307/2277140
   Elmqvist N, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P189, DOI 10.1109/INFVIS.2003.1249025
   Gershuny J., 2017, United Kingdom Time Use Survey, 2014-2015
   de Zúñiga HG, 2021, INFORM COMMUN SOC, V24, P201, DOI 10.1080/1369118X.2019.1642933
   Hoque MN, 2022, IEEE T VIS COMPUT GR, V28, P4728, DOI 10.1109/TVCG.2021.3102051
   Husain F, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P121, DOI [10.1109/VIS49827.2021.00032, 10.1109/VIS49827.2021.9623318]
   Imai K, 2010, PSYCHOL METHODS, V15, P309, DOI 10.1037/a0020761
   Ji XN, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.03.003
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Kadaba N.R., 2009, Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization, APGV '09, P77, DOI [10.1145/1620993.1621009, DOI 10.1145/1620993.1621009]
   Kadaba NR, 2007, IEEE T VIS COMPUT GR, V13, P1254, DOI 10.1109/TVCG.2007.70528
   Kale A, 2022, IEEE T VIS COMPUT GR, V28, P1150, DOI 10.1109/TVCG.2021.3114824
   Kim JJ, 2022, J VISUAL-JAPAN, V25, P741, DOI 10.1007/s12650-021-00825-4
   Kosara R., 2010, P BELIV 10 WORKSH TI, P63, DOI [10.1145/2110192.2110202, DOI 10.1145/2110192.2110202]
   Lam T., 2010, Synth. Lectures Visual., V1, P35
   Li CL, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2022.06.001
   Li H, 2021, J COMPUT-MEDIAT COMM, V26, P403, DOI 10.1093/jcmc/zmab016
   Lin JH, 2013, J COMMUN, V63, P682, DOI 10.1111/jcom.12044
   Lu JH, 2019, IEEE PAC VIS SYMP, P112, DOI 10.1109/PacificVis.2019.00021
   Mansoor H, 2021, VIS INFORM, V5, P39, DOI 10.1016/j.visinf.2021.07.001
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Osborne T, 2004, ECON SOC, V33, P430, DOI 10.1080/0308514042000285224
   Rifon NJ, 2004, J ADVERTISING, V33, P29, DOI 10.1080/00913367.2004.10639151
   Salanova M, 2005, J APPL PSYCHOL, V90, P1217, DOI 10.1037/0021-9010.90.6.1217
   Siirtola H, 2019, IEEE INT CON INF VIS, P151, DOI 10.1109/IV.2019.00034
   SIMKIN D, 1987, J AM STAT ASSOC, V82, P454, DOI 10.2307/2289447
   Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919
   Tingley D, 2014, J STAT SOFTW, V59
   Tominski C, 2021, VIS INFORM, V5, P28, DOI 10.1016/j.visinf.2021.06.004
   Wang HX, 2021, VIS INFORM, V5, P82, DOI 10.1016/j.visinf.2021.09.001
   Wang J, 2023, IEEE T VIS COMPUT GR, V29, P5342, DOI 10.1109/TVCG.2022.3207929
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   Yang YL, 2017, IEEE T VIS COMPUT GR, V23, P411, DOI 10.1109/TVCG.2016.2598885
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
   Yoon GY, 2023, J VISUAL-JAPAN, V26, P289, DOI 10.1007/s12650-022-00876-1
   Zhang HJ, 2023, J VISUAL-JAPAN, V26, P723, DOI 10.1007/s12650-022-00899-8
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4853
EP 4866
DI 10.1109/TVCG.2023.3282801
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400029
PM 37276102
DA 2024-08-05
ER

PT J
AU Li, J
   Gao, Y
   Dai, J
   Li, S
   Hao, AM
   Qin, H
AF Li, Jin
   Gao, Yang
   Dai, Ju
   Li, Shuai
   Hao, Aimin
   Qin, Hong
TI MPMNet: A Data-Driven MPM Framework for Dynamic Fluid-Solid Interaction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Numerical models; Solid modeling; Computational modeling; Solids; Neural
   networks; Couplings; Mathematical models; Data-driven simulation; neural
   networks; physics-based simulation; fluid-solid interaction
ID EULER
AB High-accuracy, high-efficiency physics-based fluid-solid interaction is essential for reality modeling and computer animation in online games or real-time Virtual Reality (VR) systems. However, the large-scale simulation of incompressible fluid and its interaction with the surrounding solid environment is either time-consuming or suffering from the reduced time/space resolution due to the complicated iterative nature pertinent to numerical computations of involved Partial Differential Equations (PDEs). In recent years, we have witnessed significant growth in exploring a different, alternative data-driven approach to addressing some of the existing technical challenges in conventional model-centric graphics and animation methods. This article showcases some of our exploratory efforts in this direction. One technical concern of our research is to address the central key challenge of how to best construct the numerical solver effectively and how to best integrate spatiotemporal/dimensional neural networks with the available MPM's pressure solvers. In particular, we devise the MPMNet, a hybrid data-driven framework supporting the popular and powerful MPM, to combine the comprehensive properties of MPM in numerically handling physical behaviors ranging from fluid to deformable solids and the high efficiency of data-driven models. At the architectural level, our MPMNet comprises three primary components: A data processing module to describe the physical properties by way of the input fields; A deep neural network group to learn the spatiotemporal features; And an iterative refinement process to continue to reduce possible numerical errors. The goal of these special technical developments is to aim at involved numerical acceleration while preserving physical accuracy, realizing efficient and accurate fluid-solid interactions in a data-driven fashion. The extensive experimental results verify that our MPMNet can tremendously speed up the computation compared with the popular numerical methods as the complexity of interaction scenes increases while better retaining the numerical accuracy.
C1 [Li, Jin; Gao, Yang; Li, Shuai] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Dai, Ju; Hao, Aimin] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Hao, Aimin] Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg 2019RU004, Beijing 100050, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Beihang University; Peng Cheng Laboratory; Chinese Academy of Medical
   Sciences - Peking Union Medical College; State University of New York
   (SUNY) System; State University of New York (SUNY) Stony Brook
RP Hao, AM (corresponding author), Peng Cheng Lab, Shenzhen 518066, Peoples R China.; Hao, AM (corresponding author), Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg 2019RU004, Beijing 100050, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM lijin2019@buaa.edu.cn; gaoyangvr@buaa.edu.cn; daij@pcl.ac.cn;
   lishuaiouc@126.com; ham@buaa.edu.cn; qin@cs.stonybrook.edu
RI Gao, Yang/JQV-9627-2023
OI Gao, Yang/0000-0002-9149-3554; Li, Jin/0009-0009-3097-8193; Dai,
   Ju/0000-0002-9397-8539; QIN, HONG/0000-0001-7699-1355
CR Barrett R., 1994, Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods, DOI [10.1137/1.9781611971538, DOI 10.1137/1.9781611971538]
   Bonet J, 2008, NONLINEAR CONTINUUM MECHANICS FOR FINITE ELEMENT ANALYSIS, 2ND EDITION, P1, DOI 10.1017/CBO9780511755446
   Cao Y, 2022, Arxiv, DOI arXiv:2210.02573
   Chen LW, 2023, COMPUT FLUIDS, V250, DOI 10.1016/j.compfluid.2022.105707
   Chentanez N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964977
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Daviet G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925877
   Demidov D, 2019, LOBACHEVSKII J MATH, V40, P535, DOI 10.1134/S1995080219050056
   Fang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392438
   Fang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322968
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Fei Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201392
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Gagniere S, 2020, COMPUT GRAPH FORUM, V39, P1, DOI 10.1111/cgf.14096
   Gao Y, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095151
   Gao Y, 2021, IEEE T VIS COMPUT GR, V27, P4483, DOI 10.1109/TVCG.2021.3107597
   Gao Y, 2020, COMPUT GRAPH FORUM, V39, P180, DOI 10.1111/cgf.14010
   Gao Y, 2019, VISUAL COMPUT, V35, P1741, DOI 10.1007/s00371-018-1569-8
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Golub GH., 2013, MATRIX COMPUTATIONS, DOI 10.56021/9781421407944
   Guo Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201346
   Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201293
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Jiang C., 2016, ACM SIGGRAPH 2016 CO, P1
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P59, DOI 10.1111/cgf.13619
   Kingma D. P., 2014, arXiv
   Kolen J., 2001, A field guide to dynamical recurrent neural networks, DOI 10.1109/9780470544037.ch14
   Koschier D, 2022, COMPUT GRAPH FORUM, V41, P737, DOI 10.1111/cgf.14508
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Li C, 2021, IEEE T VIS COMPUT GR, V27, P3867, DOI 10.1109/TVCG.2020.2991217
   Li X., 2021, Comput. Methods Appl. Mechanics Eng, V390
   Li Yunzhu, 2019, P 7 INT C LEARN REPR
   Li Yunzhu, 2020, INT C MACHINE LEARNI, P5927
   Peng C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1901
   Prantl L., 2022, P C NEUR INF PROC SY, P1
   Ram D, 2015, P 14 ACM SIGGRAPH EU, P157
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Robinson-Mosher A, 2011, J COMPUT PHYS, V230, P1547, DOI 10.1016/j.jcp.2010.11.021
   Sanchez-Gonzalez A., 2020, P 37 INT C MACHINE L, P8459, DOI DOI 10.48550/ARXIV.2002.09405
   Stam J., 2003, P GAM DEV C, V18
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Su HZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459820
   SULSKY D, 1994, COMPUT METHOD APPL M, V118, P179, DOI 10.1016/0045-7825(94)00033-6
   SULSKY D, 1995, COMPUT PHYS COMMUN, V87, P236, DOI 10.1016/0010-4655(94)00170-7
   Takahashi T, 2021, AAAI CONF ARTIF INTE, V35, P6138
   Tang JW, 2022, COMPUT GRAPH-UK, V107, P186, DOI 10.1016/j.cag.2022.07.016
   Teng Y, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980229
   Tompson J, 2017, PR MACH LEARN RES, V70
   Tumanov E, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451261
   Um K., 2020, Advances in Neural Information Processing Systems, V33, P6111
   Um K, 2018, COMPUT GRAPH FORUM, V37, P171, DOI 10.1111/cgf.13522
   Ummenhofer B., 2019, INT C LEARN REPR
   Wang S, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340259
   Wiewel S, 2020, COMPUT GRAPH FORUM, V39, P15, DOI 10.1111/cgf.14097
   Wiewel S, 2019, COMPUT GRAPH FORUM, V38, P71, DOI 10.1111/cgf.13620
   Wolper J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392428
   Wolper J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322949
   Xiao XY, 2019, COMPUT GRAPH FORUM, V38, P431, DOI 10.1111/cgf.13649
   Xiao XY, 2020, IEEE T VIS COMPUT GR, V26, P1454, DOI 10.1109/TVCG.2018.2873375
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yang C, 2016, COMPUT ANIMAT VIRT W, V27, P415, DOI 10.1002/cav.1695
   YOON S, 1988, AIAA J, V26, P1025, DOI 10.2514/3.10007
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 64
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4694
EP 4708
DI 10.1109/TVCG.2023.3272156
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400047
PM 37126612
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lu, ZX
   He, XW
   Guo, YZ
   Liu, XH
   Wang, HM
AF Lu, Zixuan
   He, Xiaowei
   Guo, Yuzhong
   Liu, Xuehui
   Wang, Huamin
TI Projective Peridynamic Modeling of Hyperelastic Membranes With Contact
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mathematical models; Convergence; Computational modeling; Real-time
   systems; Graphics processing units; Deformation; Software; Hyperelastic
   membranes; projective peridynamics; semi-implicit successive
   substitution method (SISSM); contact handling
AB Real-time simulation of hyperelastic membranes like cloth still faces a lot of challenges, such as hyperplasticity modeling and contact handling. In this study, we propose projective peridynamics that uses a local-global strategy to enable fast and robust simulation of hyperelastic membranes with contact. In the global step, we propose a semi-implicit strategy to linearize the governing equation for hyperelastic materials that are modeled with peridynamics. By decomposing the first Piola-Kirchhoff stress tensor into a positive and a negative part, successive substitutions can be taken to solve the nonlinear problems. Convergence is guaranteed by further addressing the overshooting problem. Since our global step solve requires no energy summation and dot product operations over the entire problem, it fits into GPU implementation perfectly. In the local step, we further present a GPU-friendly gradient descent method to prevent interpenetration by solving an optimization problem independently. Putting the global and local solves together, experiments show that our method is robust and efficient in simulating complex models of membranes involving hyperelastic materials and contact.
C1 [Lu, Zixuan; He, Xiaowei; Guo, Yuzhong; Liu, Xuehui] Chinese Acad Sci, Inst Software, Beijing 100045, Peoples R China.
   [Lu, Zixuan] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
   [Wang, Huamin] Style3D, Hangzhou 310012, Zhejiang, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP He, XW; Liu, XH (corresponding author), Chinese Acad Sci, Inst Software, Beijing 100045, Peoples R China.
EM luzx@ios.ac.cn; xiaowei@iscas.ac.cn; guoyuzhong@iscas.ac.cn;
   lxh@ios.ac.cn; wanghmin@gmail.com
OI he, xiao wei/0000-0002-8870-2482; Wang, Huamin/0000-0002-8153-2337
FU National Key R & D Program of China [2021YFB1715800]; National Natural
   Science Foundation of China [61872345]; Youth Innovation Pro-motion
   Association, CAS [2019109]
FX This work was supported in part by the National Key R & D Program of
   China under Grant 2021YFB1715800, in part by the National Natural
   Science Foundation of China under Grant 61872345, in part by Youth
   Innovation Pro-motion Association, CAS under Grant 2019109.
CR [Anonymous], 1966, Pacific J. Math., V16, P1
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bender M., 2015, Eurographics Tut. Notes
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Geoffrey Irving, 2004, P S COMP AN, P131, DOI DOI 10.1145/1028523.1028541
   Gerstle W, 2007, NUCL ENG DES, V237, P1250, DOI 10.1016/j.nucengdes.2006.10.002
   Gibson B., 1997, Tech. Rep. TR-97-19
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   He XW, 2018, IEEE T VIS COMPUT GR, V24, P2589, DOI 10.1109/TVCG.2017.2755646
   Javili A, 2019, MATH MECH SOLIDS, V24, P3714, DOI 10.1177/1081286518803411
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Lan L, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530069
   Lehoucq RB, 2008, J MECH PHYS SOLIDS, V56, P1566, DOI 10.1016/j.jmps.2007.08.004
   Li MC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459767
   Li MC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392425
   Liu TT, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2990496
   Liu TT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508406
   Macklin Miles, 2021, MIG '21: Motion, Interaction and Games, DOI 10.1145/3487983.3488289
   Madenci E, 2014, Peridynamic Theory and Its Applications, DOI [10.1007/978-1-4614-8465-3, DOI 10.1007/978-1-4614-8465-3]
   McAdams A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964932
   Mott PH, 2013, PHYS SCRIPTA, V87, DOI 10.1088/0031-8949/87/05/055404
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller Matthias., 2014, P ACM SIGGRAPHEUROGR, P149, DOI DOI 10.1145/2343483.2343501
   Narain M., 2016, P ACM SIGGRAPH EUR S, P21
   Nocedal J., 1999, Numerical optimization
   Ogden R, 2013, Non-Linear Elastic Deformations
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   Peng Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201290
   Poisson S.-D, 1828, Ann Chimie et Physique, V37, P337
   Provot Xavier, 1997, P EUR WORKSH COMP AN, P177
   Reddy JN., 2006, THEORY ANAL ELASTIC
   Silling SA, 2008, J ELASTICITY, V93, P13, DOI 10.1007/s10659-008-9163-3
   Silling SA, 2007, J ELASTICITY, V88, P151, DOI 10.1007/s10659-007-9125-1
   Silling SA, 2005, COMPUT STRUCT, V83, P1526, DOI 10.1016/j.compstruc.2004.11.026
   Silling SA, 2000, J MECH PHYS SOLIDS, V48, P175, DOI 10.1016/S0022-5096(99)00029-0
   Tamstorf R, 2013, GRAPH MODELS, V75, P362, DOI 10.1016/j.gmod.2013.07.001
   Tang M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275005
   Teran J., 2005, Proc_2005_ACM_SIGGRAPH/Eurograph_Symp_Comp Anim, P181
   Tupek MR, 2013, COMPUT METHOD APPL M, V263, P20, DOI 10.1016/j.cma.2013.04.012
   Wang BL, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3460775
   Wang HM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980236
   Wu LH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3430025
   Wu XL, 2001, COMPUT GRAPH FORUM, V20, pC349
   Xu HY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766917
   Xu LY, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13553
NR 47
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4601
EP 4614
DI 10.1109/TVCG.2023.3271511
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400066
PM 37115842
DA 2024-08-05
ER

PT J
AU Tajdari, F
   Huysmans, T
   Song, Y
AF Tajdari, Farzam
   Huysmans, Toon
   Song, Yu
TI Non-Rigid Registration Via Intelligent Adaptive Feedback Control
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deformation; Shape; Surface treatment; Cost function; Geometry;
   Three-dimensional displays; Iterative methods; Adaptive control; global
   asymptotic stability; ANFIS predictor; mesh quality; shape descriptor;
   non-rigid registration
AB Preserving features or local shape characteristics of a mesh using conventional non-rigid registration methods is always difficult, as the preservation and deformation are competing with each other. The challenge is to find a balance between these two terms in the process of the registration, especially in presence of artefacts in the mesh. We present a non-rigid Iterative Closest Points (ICP) algorithm which addresses the challenge as a control problem. An adaptive feedback control scheme with global asymptotic stability is derived to control the stiffness ratio for maximum feature preservation and minimum mesh quality loss during the registration process. A cost function is formulated with the distance term and the stiffness term where the initial stiffness ratio value is defined by an Adaptive Neuro-Fuzzy Inference System (ANFIS)-based predictor regarding the source mesh and the target mesh topology, and the distance between the correspondences. During the registration process, the stiffness ratio of each vertex is continuously adjusted by the intrinsic information, represented by shape descriptors, of the surrounding surface as well as the steps in the registration process. Besides, the estimated process-dependent stiffness ratios are used as dynamic weights for establishing the correspondences in each step of the registration. Experiments on simple geometric shapes as well as 3D scanning datasets indicated that the proposed approach outperforms current methodologies, especially for the regions where features are not eminent and/or there exist interferences between/among features, due to its ability to embed the inherent properties of the surface in the process of the mesh registration.
C1 [Tajdari, Farzam; Huysmans, Toon; Song, Yu] Delft Univ Technol, Fac Ind Design Engn, NL-2628 Delft, Netherlands.
   [Tajdari, Farzam] Tech Univ Eindhoven, Dept Mech Engn, Dynam & Control D&C Grp, NL-5612 AZ Eindhoven, Netherlands.
   [Huysmans, Toon] Univ Antwerp, Imec Vis Lab, Dept Phys, B-2000 Antwerp, Belgium.
C3 Delft University of Technology; Eindhoven University of Technology;
   University of Antwerp; Interuniversity Microelectronics Centre
RP Tajdari, F (corresponding author), Delft Univ Technol, Fac Ind Design Engn, NL-2628 Delft, Netherlands.
EM f.tajdari@tudelft.nl; t.huysmans@tudelft.nl; y.song@tudelft.nl
RI Song, Yu/M-6102-2017
OI Song, Yu/0000-0002-9542-1312
FU Dutch NWO Next UPPS - Integrated design methodology for Ultra
   Personalised Products and Services project [15470]
FX No Statement Available
CR Aguilar WG, 2017, LECT NOTES COMPUT SC, V10306, P585, DOI 10.1007/978-3-319-59147-6_50
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Antepara O, 2021, INT J NUMER METH FL, V93, P481, DOI 10.1002/fld.4893
   Astrom K.J., 1995, INSTRUMENT SOC AM
   Blackwell S., 2002, Tech. Rep.2002-06-01, V1
   Charlie N, 2020, "nricp-Non-rigid iterative closest point
   Chaudhury A, 2020, IEEE T IMAGE PROCESS, V29, P8735, DOI 10.1109/TIP.2020.3019649
   Cirrottola L, 2021, J COMPUT PHYS, V433, DOI 10.1016/j.jcp.2021.110177
   Dai H, 2018, ICEBT 2018: PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS AND E-TECHNOLOGY, P48, DOI 10.1145/3241748.3241773
   Davis TA, 2004, ACM T MATH SOFTWARE, V30, P196, DOI 10.1145/992200.992206
   Dekker M, 1986, Mathematical Programming, V4
   Dryden I.L., 2016, Statistical Shape Analysis: with Applications in R, V995, DOI DOI 10.1002/9781119072492
   Fan JF, 2019, MED IMAGE ANAL, V54, P193, DOI 10.1016/j.media.2019.03.006
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gaudio JE, 2022, IEEE T AUTOMAT CONTR, V67, P5440, DOI 10.1109/TAC.2021.3126243
   Guo KW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083722
   Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004
   Hirose O, 2020, "Executable source code
   Hirose O, 2021, IEEE T PATTERN ANAL, V43, P2269, DOI 10.1109/TPAMI.2020.2971687
   Ibragimov B., 2017, Statistical Shape and Deformation Analysis, P89
   Jiang T, 2017, VISUAL COMPUT, V33, P891, DOI 10.1007/s00371-017-1390-9
   Jin C, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000902
   Jin HZ, 2018, IEEE-ASME T MECH, V23, P2896, DOI 10.1109/TMECH.2018.2873232
   Khalil H. K., 2002, Nonlinear systems, V3
   Kim D, 2010, IEEE SIGNAL PROC LET, V17, P402, DOI 10.1109/LSP.2009.2039888
   Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974
   Lee WS, 2000, IMAGE VISION COMPUT, V18, P355, DOI 10.1016/S0262-8856(99)00057-8
   Lewis F. L., 2012, Optimal control
   Li K, 2019, IEEE T VIS COMPUT GR, V25, P2255, DOI 10.1109/TVCG.2018.2832136
   Liang LM, 2018, OPT LASER ENG, V100, P141, DOI 10.1016/j.optlaseng.2017.08.005
   LIU A, 1994, BIT, V34, P268, DOI 10.1007/BF01955874
   MATLAB, 2019, Fuzzy Membership Function in MATLAB
   Matsopoulos GK, 2005, MED IMAGE ANAL, V9, P237, DOI 10.1016/j.media.2004.09.002
   Min CB, 2021, IET IMAGE PROCESS, V15, P1144, DOI 10.1049/ipr2.12093
   Minnoye ALM, 2022, PROCEEDINGS OF ASME 2022 INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, IDETC-CIE2022, VOL 2
   Myronenko A., 2010, "Executable source code
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Oktay O, 2017, IEEE T MED IMAGING, V36, P332, DOI 10.1109/TMI.2016.2597270
   Peters JR, 2015, SPINE J, V15, P1000, DOI 10.1016/j.spinee.2015.01.016
   Qingqiong Deng, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P888, DOI 10.1109/ICICISYS.2010.5658814
   RUSSIAN3DSCANNER, 2019, Wrap 3.4
   Sahillioglu Y, 2020, VISUAL COMPUT, V36, P1705, DOI 10.1007/s00371-019-01760-0
   Shirani S, 2006, IEEE T MULTIMEDIA, V8, P411, DOI 10.1109/TMM.2005.864349
   Sketchfab, 2020, "Thoracic-vertebrae 3D models
   Slotine J.-J. E., 1991, Applied nonlinear control
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tajdari Farzam, 2020, Proceedings of the 10th International Conference on Computer and Knowledge Engineering (ICCKE 2020), P579, DOI 10.1109/ICCKE50421.2020.9303652
   Tajdari F, 2022, PROCEEDINGS OF ASME 2022 INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, IDETC-CIE2022, VOL 2
   Tajdari F, 2022, PROCEEDINGS OF ASME 2022 INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, IDETC-CIE2022, VOL 2
   Tajdari F, 2023, J VIB CONTROL, V29, P5511, DOI 10.1177/10775463221137141
   Tajdari F, 2021, IEEE INT CONF ROBOT, P12701, DOI 10.1109/ICRA48506.2021.9561010
   Tajdari F, 2022, IEEE T IMAGE PROCESS, V31, P1841, DOI 10.1109/TIP.2022.3148822
   Tajdari F, 2021, IEEE T VEH TECHNOL, V70, P8567, DOI 10.1109/TVT.2021.3099736
   Tajdari F, 2021, IFAC PAPERSONLINE, V54, P271, DOI 10.1016/j.ifacol.2021.06.051
   Tajdari F, 2022, J VIB CONTROL, V28, P2678, DOI 10.1177/10775463211019177
   Tajdari F, 2022, IEEE T INTELL TRANSP, V23, P939, DOI 10.1109/TITS.2020.3018873
   Tajdari F, 2019, RSI INT CONF ROBOT M, P248, DOI [10.1109/ICRoM48714.2019.9071883, 10.1109/icrom48714.2019.9071883]
   Tajdari M, 2022, ENG COMPUT-GERMANY, V38, P4061, DOI 10.1007/s00366-022-01742-2
   Tajdari M, 2021, COMPUT METHOD APPL M, V374, DOI 10.1016/j.cma.2020.113590
   Tang S, 2012, PROC SPIE, V8290, DOI 10.1117/12.912153
   Tazir M. L., 2018, P INT C INT AUT SYST, P730
   Toschi I, 2021, ISPRS J PHOTOGRAMM, V172, P160, DOI 10.1016/j.isprsjprs.2020.12.005
   Valette S, 2008, IEEE T VIS COMPUT GR, V14, P369, DOI 10.1109/TVCG.2007.70430
   Visioli A, 2006, ADV IND CONTROL, P1
   Wang SB, 2020, IEEE T IND INFORM, V16, P6816, DOI 10.1109/TII.2020.2971056
   Wilke HJ, 2021, J ANAT, V238, P626, DOI 10.1111/joa.13323
   Williams R. L, 2007, Linear Stat.-Space Control Systems
   Xi P., 2007, Graphics Interface Conference 2007, P19
   Xi P, 2007, Anal. Segmented Hum.Body Scans, P19
   Yang JY, 2015, COMPUT GRAPH FORUM, V34, P89, DOI 10.1111/cgf.12699
   Yao ZW, 2021, MEASUREMENT, V177, DOI 10.1016/j.measurement.2021.109274
   Zhang J, 2018, CHINA PERSPECTIVE, P1, DOI 10.1080/10255842.2018.1484914
NR 72
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4910
EP 4926
DI 10.1109/TVCG.2023.3283990
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400074
PM 37289615
DA 2024-08-05
ER

PT J
AU Tan, BY
   Qin, HX
   Zhang, XX
   Wang, YQ
   Xiang, T
   Chen, BQ
AF Tan, Boyuan
   Qin, Hongxing
   Zhang, Xiaoxi
   Wang, Yiqun
   Xiang, Tao
   Chen, Baoquan
TI Using Multi-Level Consistency Learning for Partial-to-Partial Point
   Cloud Registration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Feature extraction; Task analysis;
   Three-dimensional displays; Pipelines; Learning systems; Visualization;
   Attention; consistency; partial overlap; point cloud registration
ID CONSENSUS
AB Point cloud registration is a basic task in computer vision and computer graphics. Recently, deep learning-based end-to-end methods have made great progress in this field. One of the challenges of these methods is to deal with partial-to-partial registration tasks. In this work, we propose a novel end-to-end framework called MCLNet that makes full use of multi-level consistency for point cloud registration. First, the point-level consistency is exploited to prune points located outside overlapping regions. Second, we propose a multi-scale attention module to perform consistency learning at the correspondence-level for obtaining reliable correspondences. To further improve the accuracy of our method, we propose a novel scheme to estimate the transformation based on geometric consistency between correspondences. Compared to baseline methods, experimental results show that our method performs well on smaller-scale data, especially with exact matches. The reference time and memory footprint of our method are relatively balanced, which is more beneficial for practical applications.
C1 [Tan, Boyuan] Chongqing Univ Posts & Telecommun, Key Lab Data Engn & Visual Comp, Chongqing 400065, Peoples R China.
   [Qin, Hongxing] Chongqing Univ, Chongqing 400065, Peoples R China.
   [Qin, Hongxing] Chongqing Univ Posts & Telecommun, Chongqing 400065, Peoples R China.
   [Zhang, Xiaoxi] Sichuan Int Studies Univ, Chongqing 400031, Peoples R China.
   [Wang, Yiqun; Xiang, Tao] Chongqing Univ, Chongqing 400044, Peoples R China.
   [Chen, Baoquan] Peking Univ, Beijing 100871, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing
   University; Chongqing University of Posts & Telecommunications; Sichuan
   International Studies University; Chongqing University; Peking
   University
RP Qin, HX (corresponding author), Chongqing Univ, Chongqing 400065, Peoples R China.
EM tanboyuan20@163.com; qinhx@cqu.edu.cn; xiaoxizhang@sisu.edu.cn;
   yiqun.wang@cqu.edu.cn; txiang@cqu.edu.cn; baoquan@pku.edu.cn
OI Wang, Yiqun/0000-0003-1942-5597
FU National Key R&D Program of China [2022ZD0160804]; NSFC [62272071]; NSFC
   of Chongqing [CSTB2022NSCQ-MSX0924]; Sichuan Science and Technology
   Program [2021YFQ0056]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2022ZD0160804, in part by NSFC under Grant 62272071, in part
   by NSFC of Chongqing CSTB2022NSCQ-MSX0924, and in part by Sichuan
   Science and Technology Program under Grant 2021YFQ0056.
CR Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Bai XY, 2021, PROC CVPR IEEE, P15854, DOI 10.1109/CVPR46437.2021.01560
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Cao AQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13209, DOI 10.1109/ICCV48922.2021.01298
   Chen H., 2022, P ACM SIGGRAPH C P, P1
   Chen Z, 2022, PROC CVPR IEEE, P13211, DOI 10.1109/CVPR52688.2022.01287
   Choi S, 2016, Arxiv, DOI [arXiv:1602.02481, DOI 10.48550/ARXIV.1602.02481]
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fu KX, 2023, IEEE T PATTERN ANAL, V45, P6183, DOI [10.1109/TPAMI.2022.3204713, 10.1109/CVPR46437.2021.00878]
   Glorot X., 2011, P 14 INT C ART INT S, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Hezroni I, 2021, Arxiv, DOI arXiv:2110.03016
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SY, 2021, PROC CVPR IEEE, P4265, DOI 10.1109/CVPR46437.2021.00425
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kingma D. P., 2014, arXiv
   Li Jiahao, 2020, PROC EUR C COMPUT VI, P378, DOI [DOI 10.1007/978-3-030-58586-0_23, 10.1007/978-3-030-58586-0_23]
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qin Z, 2022, PROC CVPR IEEE, P11133, DOI 10.1109/CVPR52688.2022.01086
   Quan SW, 2020, IEEE T GEOSCI REMOTE, V58, P7380, DOI 10.1109/TGRS.2020.2982221
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusinkiewicz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323037
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarode V, 2019, Arxiv, DOI arXiv:1908.07906
   Sarode V, 2020, INT CONF 3D VISION, P1029, DOI 10.1109/3DV50981.2020.00113
   Segal A., 2009, P ROB SCI SYST SEATT, P168
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Y., 2019, ADV NEURAL INFORM PR, P8814, DOI DOI 10.48550/ARXIV.1910.12240
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wentao Yuan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P733, DOI 10.1007/978-3-030-58558-7_43
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu H, 2022, AAAI CONF ARTIF INTE, P2848
   Xu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3112, DOI 10.1109/ICCV48922.2021.00312
   Yan ZH, 2022, IEEE T VIS COMPUT GR, V28, P4304, DOI 10.1109/TVCG.2021.3086113
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Yang JQ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3058552
   Yew ZJ, 2022, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR52688.2022.00656
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhao C., 2021, arXiv
   Zhou QY, 2018, Arxiv, DOI arXiv:1801.09847
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184
NR 49
TC 1
Z9 1
U1 3
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4881
EP 4894
DI 10.1109/TVCG.2023.3280171
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400003
PM 37235469
DA 2024-08-05
ER

PT J
AU Zheng, JW
   Hsu, JY
   Li, CC
   Lin, IC
AF Zheng, Jia-Wen
   Hsu, Jhen-Yung
   Li, Chih-Chia
   Lin, I-Chen
TI Characteristic-Preserving Latent Space for Unpaired Cross-Domain
   Translation of 3D Point Clouds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape transfer; shape characteristics; unpaired learning; 3D point cloud
   generative model
ID NETWORK
AB This article aims at unpaired shape-to-shape transformation for 3D point clouds, for instance, turning a chair to its table counterpart. Recent work for 3D shape transfer or deformation highly relies on paired inputs or specific correspondences. However, it is usually not feasible to assign precise correspondences or prepare paired data from two domains. A few methods start to study unpaired learning, but the characteristics of a source model may not be preserved after transformation. To overcome the difficulty of unpaired learning for transformation, we propose alternately training the autoencoder and translators to construct shape-aware latent space. This latent space based on novel loss functions enables our translators to transform 3D point clouds across domains and maintain the consistency of shape characteristics. We also crafted a test dataset to objectively evaluate the performance of point-cloud translation. The experiments demonstrate that our framework can construct high-quality models and retain more shape characteristics during cross-domain translation compared to the state-of-the-art methods. Moreover, we also present shape editing applications with our proposed latent space, including shape-style mixing and shape-type shifting, which do not require retraining a model.
C1 [Zheng, Jia-Wen; Hsu, Jhen-Yung; Li, Chih-Chia; Lin, I-Chen] Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, IC (corresponding author), Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu 30010, Taiwan.
EM alicegogohaha.cs07g@nctu.edu.tw; yunyung.cs08@nycu.edu.tw;
   nycu.309553007.cs09@nycu.edu.tw; ichenlin@cs.nctu.edu.tw
OI Lin, I-Chen/0000-0001-9924-4723
FU Ministry of Science and Technology, Taiwan [MOST 109-2221-E-009-122-MY3]
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan under Grant MOST 109-2221-E-009-122-MY3.
CR [Anonymous], 2012, ACM Trans. Graph.
   Boulch Alexandre, 2017, P WORKSH 3D OBJ RETR, V3, P17, DOI [10.2312/3dor.20171047, DOI 10.2312/3DOR.20171047]
   Chen QM, 2022, PROC CVPR IEEE, P18593, DOI 10.1109/CVPR52688.2022.01806
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen ZQ, 2021, PROC CVPR IEEE, P15735, DOI 10.1109/CVPR46437.2021.01548
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gao L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275028
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Gulrajani I., 2017, NIPS, P5767
   Huang FC, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073654, 10.1145/3137609]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2014, arXiv
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li B, 2020, IEEE ACCESS, V8, P83782, DOI 10.1109/ACCESS.2020.2992554
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Li CC, 2023, P ACM COMPUT GRAPH, V6, DOI 10.1145/3585508
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li K, 2019, IEEE T VIS COMPUT GR, V25, P2255, DOI 10.1109/TVCG.2018.2832136
   Li RH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459766
   Li XZ, 2022, IEEE T VIS COMPUT GR, V28, P4503, DOI 10.1109/TVCG.2021.3092570
   Li YS, 2022, IEEE T VIS COMPUT GR, V28, P3499, DOI 10.1109/TVCG.2021.3069195
   Lim I, 2019, COMPUT GRAPH FORUM, V38, P99, DOI 10.1111/cgf.13792
   Liu MY, 2017, ADV NEUR IN, V30
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Liu ZJ, 2019, ADV NEUR IN, V32
   Lu XQ, 2022, IEEE T VIS COMPUT GR, V28, P1835, DOI 10.1109/TVCG.2020.3026785
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mo KC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356527
   Odena A, 2017, PR MACH LEARN RES, V70
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Rethage D, 2018, LECT NOTES COMPUT SC, V11208, P625, DOI 10.1007/978-3-030-01225-0_37
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Shu DW, 2019, IEEE I CONF COMP VIS, P3858, DOI 10.1109/ICCV.2019.00396
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Tuzel, 2016, Advances in Neural Information Processing Systems, P469
   Valsesia G., 2019, P INT C LEARN REPR M, P49
   Wang I, 2015, Sci. Syst.
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xie CL, 2021, PROC CVPR IEEE, P4617, DOI 10.1109/CVPR46437.2021.00459
   Yan ZH, 2022, IEEE T VIS COMPUT GR, V28, P4304, DOI 10.1109/TVCG.2021.3086113
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yang J, 2018, GRAPH MODELS, V98, P1, DOI 10.1016/j.gmod.2018.05.003
   Yang KZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459873
   Yang XB, 2020, IEEE T VIS COMPUT GR, V26, P3446, DOI 10.1109/TVCG.2020.3023634
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yin KX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12436, DOI 10.1109/ICCV48922.2021.01223
   Yin KX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356494
   Yin KX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201288
   Zamorski M, 2019, Arxiv, DOI arXiv:1811.07605
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 65
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5212
EP 5226
DI 10.1109/TVCG.2023.3287923
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400095
PM 37339041
DA 2024-08-05
ER

PT J
AU Skrodzki, M
   van Geffen, H
   Chaves-de-Plaza, NF
   Höllt, T
   Eisemann, E
   Hildebrandt, K
AF Skrodzki, Martin
   van Geffen, Hunter
   Chaves-de-Plaza, Nicolas F.
   Hollt, Thomas
   Eisemann, Elmar
   Hildebrandt, Klaus
TI Accelerating Hyperbolic t-SNE
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dimensionality reduction; t-SNE; hyperbolic embedding; acceleration
   structure
ID DIMENSIONALITY REDUCTION; MDS
AB The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This article introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.
C1 [Skrodzki, Martin; van Geffen, Hunter; Chaves-de-Plaza, Nicolas F.; Hollt, Thomas; Eisemann, Elmar; Hildebrandt, Klaus] Delft Univ Technol, NL-2628CD Delft, Netherlands.
C3 Delft University of Technology
RP Skrodzki, M (corresponding author), Delft Univ Technol, NL-2628CD Delft, Netherlands.
EM m.skrodzki@tudelft.nl; huntervangeffen@gmail.com;
   n.f.chavesdeplaza@tudelft.nl; T.Hollt-1@tudelft.nl;
   e.eisemann@tudelft.nl; k.a.hildebrandt@tudelft.nl
OI Chaves-de-Plaza, Nicolas F./0000-0003-4971-3151; Skrodzki,
   Martin/0000-0002-8126-0511; Hildebrandt, Klaus/0000-0002-9196-3923
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [455095046]; Varian; Siemens Healthineers Company, through the Holland
   PTC-Varian Consortium [2019022]; Surcharge for Top Consortia for
   Knowledge and Innovation (TKIs) Ministry of Economic Affairs and Climate
FX The work of Martin Skrodzki was supported by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) under Grant
   455095046. The work of Nicolas F. Chaves-de-Plaza was supported in
   partby Varian, a Siemens Healthineers Company, through the Holland
   PTC-Varian Consortium under Grant 2019022, and in part by the Surcharge
   for Top Consortia for Knowledge and Innovation (TKIs) from the Ministry
   of Economic Affairs and Climate.
CR Andrews TS, 2021, NAT PROTOC, V16, P1, DOI 10.1038/s41596-020-00409-w
   Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkina AC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13055-y
   Bläsius T, 2018, IEEE ACM T NETWORK, V26, P920, DOI 10.1109/TNET.2018.2810186
   Bo hm J.N., 2022, J. Mach. Learn. Res., V23, P1
   Boguñá M, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1063
   Cannon J.W., 1997, Flavors Geometr., V31, P2
   Cao XF, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2023.109302
   Cho M, 2017, ADV NEUR IN, V30
   Conway J. H., 2008, The Symmetries of Things, DOI [10.1201/b21368, DOI 10.1201/B21368]
   Cvetkovski A., 2016, Appl. Math. Inf. Sci., V10, P125, DOI [10.18576/amis/100112, DOI 10.18576/AMIS/100112]
   Eppstein D., 2021, P INT S GRAPH DRAW N, P343, DOI DOI 10.1007/978-3-030-92931-2
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Friedrich T, 2015, IEEE INFOCOM SER, DOI 10.1109/INFOCOM.2015.7218533
   Ganea OE, 2018, ADV NEUR IN, V31
   Gulcehre C, 2018, Arxiv, DOI arXiv:1805.09786
   Guo YH, 2022, PROC CVPR IEEE, P11, DOI 10.1109/CVPR52688.2022.00011
   Ingram S, 2009, IEEE T VIS COMPUT GR, V15, P249, DOI 10.1109/TVCG.2008.85
   Isozaki H., 2014, Introduction to Spectral Theory and Inverse Problem on Asymptotically Hyperbolic Manifolds, V32, P11, DOI DOI 10.2969/MSJMEMOIRS/03201C010
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Keller-Ressel M, 2020, J COMPLEX NETW, V8, DOI 10.1093/comnet/cnaa002
   Klimovskaia A, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16822-4
   Kobak D, 2021, NAT BIOTECHNOL, V39, DOI 10.1038/s41587-020-00809-z
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kopczynski E., 2021, arXiv
   Krioukov D, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.036106
   Krumsiek J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022649
   Lamping J., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P401
   Lin Y.-W. E., 2023, P 40 INT C MACH LEAR
   Linderman GC, 2019, NAT METHODS, V16, P243, DOI 10.1038/s41592-018-0308-4
   Lou A., 2020, International conference on machine learning, P6393
   Miller J, 2022, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis53943.2022.00016
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P486, DOI 10.1109/TVCG.2021.3114820
   Nickel M, 2017, Advances in Neural Information Processing Systems, P6341
   Ontrup J, 2006, NEURAL NETWORKS, V19, P751, DOI 10.1016/j.neunet.2006.05.015
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Pirolli P., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P506, DOI 10.1145/365024.365337
   Plass M, 2018, SCIENCE, V360, DOI 10.1126/science.aaq1723
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sala F, 2018, PR MACH LEARN RES, V80
   Sarkar R, 2012, LECT NOTES COMPUT SC, V7034, P355
   Senning J. R., 2019, Tech. Rep.
   van de Ruit M, 2022, IEEE T VIS COMPUT GR, V28, P614, DOI 10.1109/TVCG.2021.3114817
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verbeek K, 2016, COMP GEOM-THEOR APPL, V59, P1, DOI 10.1016/j.comgeo.2016.08.003
   von Looz M, 2015, LECT NOTES COMPUT SC, V9472, P467, DOI 10.1007/978-3-662-48971-0_40
   Walter JA, 2004, INFORM SYST, V29, P273, DOI 10.1016/j.is.2003.10.002
   Wang JP, 2022, IEEE T VIS COMPUT GR, V28, P4141, DOI 10.1109/TVCG.2021.3076749
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu ZJ, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-02027-x
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xiao H., 2022, P C EMP METH NAT LAN, P5228
   Zhang Chenyang, 2023, IEEE Trans Vis Comput Graph, V29, P767, DOI 10.1109/TVCG.2022.3209440
   Zhou YS, 2022, NEURAL COMPUT, V34, P1637, DOI 10.1162/neco_a_01504
   Zhou YS, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102225
   Zhou YS, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aaq1458
NR 62
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4403
EP 4415
DI 10.1109/TVCG.2024.3364841
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700070
PM 38345956
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wei, ZZ
   Zhu, QT
   Min, C
   Chen, YS
   Wang, GP
AF Wei, Zizhuang
   Zhu, Qingtian
   Min, Chen
   Chen, Yisong
   Wang, Guoping
TI Bidirectional Hybrid LSTM Based Recurrent Neural Network for Multi-View
   Stereo
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Costs; Feature extraction; Three-dimensional displays; Runtime; Point
   cloud compression; Image reconstruction; Recurrent neural networks; 3D
   reconstruction; deep learning; multi-view stereo; recurrent neural
   network; point clouds
AB Recently, deep learning based multi-view stereo (MVS) networks have demonstrated their excellent performance on various benchmarks. In this paper, we present an effective and efficient recurrent neural network (RNN) for accurate and complete dense point cloud reconstruction. Instead of regularizing the cost volume via conventional 3D CNN or unidirectional RNN like previous attempts, we adopt a bidirectional hybrid Long Short-Term Memory (LSTM) based structure for cost volume regularization. The proposed bidirectional recurrent regularization is able to perceive full-space context information comparable to 3D CNNs while saving runtime memory. For post-processing, we introduce a visibility based approach for depth map refinement to obtain more accurate dense point clouds. Extensive experiments on DTU, Tanks and Temples and ETH3D datasets demonstrate that our method outperforms previous state-of-the-art MVS methods and exhibits high memory efficiency at runtime.
C1 [Wei, Zizhuang; Zhu, Qingtian; Min, Chen; Chen, Yisong; Wang, Guoping] Peking Univ, Dept EECS, Beijing 100871, Peoples R China.
C3 Peking University
RP Wang, GP (corresponding author), Peking Univ, Dept EECS, Beijing 100871, Peoples R China.
EM weizizhuang@pku.edu.cn; zqt@stu.pku.edu.cn; minchen@stu.pku.edu.cn;
   chenyisong@pku.edu.cn; wgp@pku.edu.cn
FU National Key Technology Research and Development Program of China
   [2017YFB1002601]; National Natural Science Foundation of China (NSFC)
   [61632003]
FX This work was supported in part by the National Key Technology Research
   and Development Program of China under Grant 2017YFB1002601, in part by
   the National Natural Science Foundation of China (NSFC) under Grant
   61632003.
CR Aanæs H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162
   Cheng S, 2020, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR42600.2020.00260
   Fuhrmann Simon, 2014, P EUR WORKSH GRAPH C, P11, DOI DOI 10.2312/GCH.20141299
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Hongwei Yi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P766, DOI 10.1007/978-3-030-58545-7_44
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Jianfeng Yan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P674, DOI 10.1007/978-3-030-58548-8_39
   Kar A, 2017, Arxiv, DOI arXiv:1708.05375
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kingma D. P., 2014, arXiv
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kuhn A, 2020, INT CONF 3D VISION, P404, DOI 10.1109/3DV50981.2020.00050
   Liu HM, 2020, PATTERN RECOGN, V99, DOI 10.1016/j.patcog.2019.107112
   Luo KY, 2020, PROC CVPR IEEE, P1587, DOI 10.1109/CVPR42600.2020.00166
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Ma XJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5712, DOI 10.1109/ICCV48922.2021.00568
   OpenMVS, 2015, About us
   Paszke A, 2017, P 31 C NEUR INF PROC, P1
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   tanksandtemples, 2017, Tanks-and-temples
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xu QS, 2020, Arxiv, DOI arXiv:2007.07714
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12508
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12516
   Xu QS, 2019, PROC CVPR IEEE, P5478, DOI 10.1109/CVPR.2019.00563
   Yang JY, 2020, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR42600.2020.00493
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2020, PROC CVPR IEEE, P1787, DOI 10.1109/CVPR42600.2020.00186
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   Zhang JY, 2023, INT J COMPUT VISION, V131, P199, DOI 10.1007/s11263-022-01697-3
NR 41
TC 6
Z9 6
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3062
EP 3073
DI 10.1109/TVCG.2022.3165860
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700051
PM 35394911
DA 2024-08-05
ER

PT J
AU Benda, B
   Rheault, B
   Lin, YN
   Ragan, ED
AF Benda, Brett
   Rheault, Benjamin
   Lin, Yanna
   Ragan, Eric D.
TI Examining Effects of Technique Awareness on the Detection of Remapped
   Hands in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Legged locomotion; Meters; Virtual environments; Turning;
   Three-dimensional displays; Bending; virtual reality; interaction
   techniques; human perception
ID REDIRECTED WALKING; ROTATION
AB Input remapping techniques have been widely explored to allow users in virtual reality to exceed both their own physical abilities, the limitations of physical space, or to facilitate interactions with real-world objects. Often considered is how these techniques can be applied to achieve maximum utility, but still be undetectable to users to maintain a sense of immersion and presence. Existing psychophysical methods used to determine these detection thresholds have known limitations: they are highly conservative lower bounds for detection and do not account for complex usage of the technique. Our work describes and evaluates a method for estimating detection that reduces these limitations and yields meaningful upper bounds. We present the findings of our work where we apply this method to a well-explored hand motion scaling technique. In wholly unaware cases, we determined that users may detect their hand speed as abnormal at around 3.37 times the normal speed, compared to a scale factor of 1.47 that was estimated using traditional methods when users knew the motion scaling was occurring. A considerable number of participants in unaware cases (12 of 56) never detected their hand speed increasing at all, even at the maximum scale factor of 5.0. The study demonstrates just how conservative the thresholds generated by traditional psychophysical methods can be compared to detection during naive usage, and our method can be modified and applied easily to other techniques.
C1 [Benda, Brett; Rheault, Benjamin; Lin, Yanna; Ragan, Eric D.] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32603 USA.
C3 State University System of Florida; University of Florida
RP Benda, B (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32603 USA.
EM brett.benda@ufl.edu; brheault@ufl.edu; linyanna@ufl.edu; eragan@ufl.edu
OI Benda, William/0000-0002-1825-6392
FU DARPA Perceptually-enabled Task Guidance (PTG) Program
FX No Statement Available
CR Abrahamyan A, 2016, P NATL ACAD SCI USA, V113, pE3548, DOI 10.1073/pnas.1518786113
   Auteri C., 2013, The International Journal of Virtual Reality, V12, P66
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Baloup M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300331, 10.1109/africon46755.2019.9133906]
   Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Bolte B., 2010, P 17 ACM S VIRTUAL R, P11
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Carvalheiro C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1146, DOI 10.1145/2964284.2964293
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Clarence A, 2022, INT SYM MIX AUGMENT, P612, DOI 10.1109/ISMAR55827.2022.00078
   Cohn BA, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P74, DOI 10.1109/AIVR50618.2020.00024
   CORNSWEET TN, 1962, AM J PSYCHOL, V75, P485, DOI 10.2307/1419876
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P341, DOI 10.1109/VR.2018.8448285
   Dennison MS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1858, DOI [10.1109/vr.2019.8798297, 10.1109/VR.2019.8798297]
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.00-38, 10.1109/VR46266.2020.1581285352835]
   Farell B., 1999, Vision research: A practical guide to laboratory methods, V5, P129
   Feick M, 2023, Symposium Virtual Re, P194, DOI 10.1109/VR55154.2023.00035
   Feuchtner T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P31, DOI 10.1145/3242587.3242594
   Frees S, 2005, P IEEE VIRT REAL ANN, P99
   Gescheider George A., 1997, Psychophysics - The Fundamentals, P261, DOI DOI 10.4324/9780203774458
   Gonzalez EJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364248
   Gonzalez EJ, 2019, ADJUNCT PUBLICATION OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'19 ADJUNCT), P4, DOI 10.1145/3332167.3357096
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Han DT, 2018, IEEE T VIS COMPUT GR, V24, P1467, DOI 10.1109/TVCG.2018.2794659
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Insko B. Edward, 2001, PASSIVE HAPTICS SIGN
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kingdom F. A. A., 2010, PSYCHOPHYSICS PRACTI
   Kohm K, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3561055
   LaViola J.J., 2017, 3D user interfaces: theory and practice
   Lilija K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P455, DOI 10.1109/VR50410.2021.00069
   Linares D, 2016, R J, V8, P122
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.00-83, 10.1109/VR46266.2020.1581165829725]
   Murillo RAM, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P759, DOI 10.1145/3126594.3126605
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Porssut T, 2022, IEEE T VIS COMPUT GR, V28, P3193, DOI 10.1109/TVCG.2021.3057797
   Poupyrev I., 1996, Proceedings of the 9th Annual A CM Symposium on User Interface Software and Technology, P79, DOI DOI 10.1145/237091.237102
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Razzaque S., 2005, Redirected walking
   Riecke B. E., 2012, P ACM S APPL PERCEPT, P17
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Tieri G, 2015, EXP BRAIN RES, V233, P1247, DOI 10.1007/s00221-015-4202-3
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Van Someren M., 1994, The think aloud method: a practical approach to modelling cognitive, V11, P29
   Vogel D., 2005, Proceedings of the 18th annual ACM symposium on User interface software and technology, P33, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Watson AB, 2017, J VISION, V17, DOI 10.1167/17.3.10
   Weise M., 2020, i-com, V19, P67, DOI [10.1515/icom-2020-0011, DOI 10.1515/ICOM-2020-0011]
   You C, 2022, INT SYM MIX AUGMENT, P603, DOI 10.1109/ISMAR55827.2022.00077
   Zenner A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P75, DOI 10.1109/VR50410.2021.00028
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
NR 62
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2651
EP 2661
DI 10.1109/TVCG.2024.3372054
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400005
PM 38437116
DA 2024-08-05
ER

PT J
AU Curiel, RC
   Nakamura, T
   Kuzuoka, H
   Kanaya, T
   Prahm, C
   Matsumoto, K
AF Curiel, Rodrigo Cerecero
   Nakamura, Takuto
   Kuzuoka, Hideaki
   Kanaya, Takafumi
   Prahm, Cosima
   Matsumoto, Keigo
TI Virtual Reality Self Co-Embodiment: An Alternative to Mirror Therapy for
   Post-Stroke Upper Limb Rehabilitation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human-centered computing; user interfaces; virtual reality;
   rehabilitation techniques; virtual embodiment; stroke recovery; motor
   imagery
ID STROKE
AB We present Virtual Reality Self Co-embodiment, a new method for post-stroke upper limb rehabilitation. It is inspired by mirror therapy, where the patient's healthy arm is involved in recovering the affected arm's motion. By tracking the user's head, wrists, and fingers' positions, our new approach allows the handicapped arm to control a digital avatar in order to pursue a reaching task. We apply the concept of virtual co-embodiment to use the information from the unaffected arm and complete the affected limb's impaired motion, which is our added unique feature. This requires users to mechanically involve the incapacitated area as much as possible, prioritizing actual movement rather than the sole imagination of it. As a result, subjects will see a seemingly normally functional virtual arm primarily controlled by their handicapped extremity, but with the constant support of their healthy limb's motion. Our experiment compares the task execution performance and embodiment perceived when interacting with both mirror therapy and our proposed technique. We found that our approach's provided sense of ownership is mildly impacted by users' motion planning response times, which mirror therapy does not exhibit. We also observed that mirror therapy's sense of ownership is moderately affected by the subject's proficiency while executing the assigned task, which our new method did not display. The results indicate that our proposed method provides similar embodiment and rehabilitation capabilities to those perceived from existing mirror therapy. This experiment was performed in healthy individuals to have an unbiased comparison of how mirror therapy's and VRSelfCo's task performance and degree of virtual embodiment compare, but future work explores the possibility of applying this new approach to actual post-stroke patients.
C1 [Curiel, Rodrigo Cerecero; Nakamura, Takuto; Kuzuoka, Hideaki; Kanaya, Takafumi; Matsumoto, Keigo] Univ Tokyo, Tokyo, Japan.
   [Prahm, Cosima] Med Univ Vienna, Vienna, Austria.
C3 University of Tokyo; Medical University of Vienna
RP Curiel, RC (corresponding author), Univ Tokyo, Tokyo, Japan.
EM rodrigo.curiel@cyber.t.u-tokyo.ac.jp; n.takuto@cyber.t.u-tokyo.ac.jp;
   kuzuoka@cyber.t.u-tokyo.ac.jp; kanaya-nii@cyber.t.u-tokyo.ac.jp;
   cosima.prahm@med.uni-tuebingen.de; matsumoto@cyber.t.u-tokyo.ac.jp
OI Kuzuoka, Hideaki/0000-0003-1252-7814; Prahm, Cosima/0000-0001-9379-5110;
   Nakamura, Takuto/0000-0003-3866-4745; Matsumoto,
   Keigo/0000-0002-0038-0678
FU New Energy and Industrial Technology Development Organization
FX No Statement Available
CR [Anonymous], 2019, Singapore Med J, V60, DOI 10.11622.20191582[3]C.S.
   Cha K, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00957-6
   Chohan P. K., Long-term complications ofstroke and secondary prevention: an overview for primary care physicians
   Choy CS, 2023, BIOMED ENG ONLINE, V22, DOI 10.1186/s12938-023-01124-9
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Gandhi A., 2020, Ther Clin Risk Manag., DOI [10.7748/ns2012.07.26.44.35.c91912, DOI 10.7748/NS2012.07.26.44.35.C91912]
   Jaques Silva, 2023, Stroke Researchand Treatment., DOI [10.1155/2023/50806992, DOI 10.1155/2023/50806992]
   Jo H., 2022, Brain Sciences, V12, DOI [10.3390/brainsci120302972, DOI 10.3390/BRAINSCI120302972]
   Kirch W, 2008, Encyclopedia of Public Health, P1090, DOI [DOI 10.1007/978-1-4020-5614-7_2569, DOI 10.1007/978-1-4020-5614-7-2569, 10.1007/978-1-4020-5614-72569, DOI 10.1007/978-1-4020-5614-72569]
   Li P., 2021, Frontiers in Neurology, V12, DOI 10.3389.2021.7742473
   Mar C., 2020, The self-avatar follower effect in virtual reality, P18, DOI [10.1109/VR46266.2020.000193[13]P, DOI 10.1109/VR46266.2020.000193[13]P]
   Mateos-Aparicio P, 2019, FRONT CELL NEUROSCI, V13, DOI 10.3389/fncel.2019.00066
   Medicine N., 2023, NM Stroke and Cerebrovascular Care, P2
   Meta Platforms Inc, 2021, Oculus SDK for Windows., V4
   N. Group, 2016, NOI Resources., V5
   Ota T, 2023, IEEE ACCESS, V11, P50841, DOI 10.1109/ACCESS.2023.3279269
   Puderbaugh P. D., NIH Bookshelf, V2
   Regenbrecht S., 2014, Proceedingsof the IEEE, V102, DOI [10.1109/JPROC.2013.22941782[19]D, DOI 10.1109/JPROC.2013.22941782[19]D]
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Sabate B. Gonzalez, 2004, Neuropsychologia, V42, DOI [10.1016/j.neuropsychologia.2003.12.0153[21]A, DOI 10.1016/J.NEUROPSYCHOLOGIA.2003.12.0153[21]A]
   Salagean E., Meetingyour virtual twin: Effects of photorealism and personalization on embod-\n[1]K
   Samuelkamaleshkumar S, 2014, ARCH PHYS MED REHAB, V95, P2000, DOI 10.1016/j.apmr.2014.06.020
   Shapi'i A, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/493562
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709
   Stippich C, 2002, NEUROSCI LETT, V331, P50, DOI 10.1016/S0304-3940(02)00826-1
   Studios B., 2022, Unity's Asset Store., P4
   Thieme H, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008449.pub3
   Torres-Parada M., 2020, Nrazilian Journal of Physical Therapy., DOI 10.1016.bjpt.2019.02.0101
   Unity Technologies, 2020, Animation Rigging., P4
   Vural SP, 2016, ARCH PHYS MED REHAB, V97, P575, DOI 10.1016/j.apmr.2015.12.008
   Wittkopf PG, 2017, REV ASSOC MED BRAS, V63, P1000
   Xu Q, 2017, CLIN REHABIL, V31, P1583, DOI 10.1177/0269215517705689
   Zhu Y, 2013, NEURAL REGEN RES, V8, P2389, DOI 10.3969/j.issn.1673-5374.2013.25.010
NR 33
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2390
EP 2399
DI 10.1109/TVCG.2024.3372035
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400027
PM 38437102
DA 2024-08-05
ER

PT J
AU Gupta, K
   Zhang, YW
   Gunasekaran, TS
   Krishna, N
   Pai, YS
   Billinghurst, M
AF Gupta, Kunal
   Zhang, Yuewei
   Gunasekaran, Tamil Selvan
   Krishna, Nanditha
   Pai, Yun Suen
   Billinghurst, Mark
TI CAEVR: Biosignals-Driven Context-Aware Empathy in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE empathy; VR; metaverse; physiology; emotion; context-aware; virtual
   agents
ID SEX-DIFFERENCES; EXPERIENCE; ATTENTION; EMOTION; THETA; FLOW
AB There is little research on how Virtual Reality (VR) applications can identify and respond meaningfully to users' emotional changes. In this paper, we investigate the impact of Context-Aware Empathic VR (CAEVR) on the emotional and cognitive aspects of user experience in VR. We developed a real-time emotion prediction model using electroencephalography (EEG), electrodermal activity (EDA), and heart rate variability (HRV) and used this in personalized and generalized models for emotion recognition. We then explored the application of this model in a context-aware empathic (CAE) virtual agent and an emotion-adaptive (EA) VR environment. We found a significant increase in positive emotions, cognitive load, and empathy toward the CAE agent, suggesting the potential of CAEVR environments to refine user-agent interactions. We identify lessons learned from this study and directions for future work.
C1 [Gupta, Kunal; Zhang, Yuewei; Gunasekaran, Tamil Selvan; Pai, Yun Suen; Billinghurst, Mark] Univ Auckland, Auckland, New Zealand.
   [Krishna, Nanditha] Amrita Vishwa Vidyapeetham, Amritapuri, India.
C3 University of Auckland; Amrita Vishwa Vidyapeetham; Amrita Vishwa
   Vidyapeetham Amritapuri
RP Gupta, K (corresponding author), Univ Auckland, Auckland, New Zealand.
EM kunal.gupta@auckland.ac.nz; yzhb544@aucklanduni.ac.nz;
   themastergts007@gmail.com; nandithakrish4@gmail.com;
   yspai1412@gmail.com; mark.billinghurst@auckland.ac.nz
OI Krishna, Nanditha/0000-0001-5536-4993; Pai, Yun
   Suen/0000-0002-6090-2837; Gupta, Kunal/0000-0003-3963-8856; Zhang,
   Yuewei/0000-0002-3829-445X
FU Empathic Computing
FX No Statement Available
CR Abowd G. D., 2000, ACM Transactions on Computer-Human Interaction, V7, P29, DOI 10.1145/344949.344988
   Aftanas LI, 2001, NEUROSCI LETT, V310, P57, DOI 10.1016/S0304-3940(01)02094-8
   Almazan C. B., 2010, PhD thesis, P2
   Appelhans BM, 2006, REV GEN PSYCHOL, V10, P229, DOI 10.1037/1089-2680.10.3.229
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Basar E, 2001, INT J PSYCHOPHYSIOL, V39, P241, DOI 10.1016/S0167-8760(00)00145-8
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Bouchard S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036169
   Bratman M., 1987, Intentions, Plans, and Practical Reasoning, P4
   Brdiczka O, 2009, IEEE T AUTOM SCI ENG, V6, P588, DOI 10.1109/TASE.2008.2004965
   Brosch T, 2013, SWISS MED WKLY, V143, DOI 10.4414/smw.2013.13786
   Bunglowala A.Bunglowala., 2015, International Journal of Research in Advent Technology, P371
   Castro-Meneses LJ, 2020, ETR&D-EDUC TECH RES, V68, P181, DOI 10.1007/s11423-019-09681-4
   Chang Z, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.995090
   Chartrand T. L., 2005, The new unconscious, P334, DOI DOI 10.1093/ACPROF:OSO/9780195307696.003
   Coan JA, 2006, PSYCHOL SCI, V17, P1032, DOI 10.1111/j.1467-9280.2006.01832.x
   Csikszentmihalyi M., 2014, Flow and the foundations of positive psychology, V10, P3
   Csikszentmihalyi M., 1992, OPTIMAL EXPERIENCE P, P3
   Cuff BMP, 2016, EMOT REV, V8, P144, DOI 10.1177/1754073914558466
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Davidson RJ, 1998, COGNITION EMOTION, V12, P307, DOI 10.1080/026999398379628
   Davis M. H., 2018, Empathy: A social psychological approach, P2
   de Graaf MMA, 2013, ROBOT AUTON SYST, V61, P1476, DOI 10.1016/j.robot.2013.07.007
   Dennemont Y, 2013, L N INST COMP SCI SO, V109, P30
   Devlin HC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110470
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Diaz FM, 2013, PSYCHOL MUSIC, V41, P42, DOI 10.1177/0305735611415144
   Fraser K, 2012, MED EDUC, V46, P1055, DOI 10.1111/j.1365-2923.2012.04355.x
   Gross JJ, 2015, PSYCHOL INQ, V26, P1, DOI 10.1080/1047840X.2014.940781
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Gumbheer CP, 2022, EDUC INF TECHNOL, V27, P7491, DOI 10.1007/s10639-022-10942-8
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.1581313729558, 10.1109/VR46266.2020.000-5]
   Gupta Kunal., 2020, 26th ACM Symposium on Virtual Reality Software and Technology. VRST'20, DOI DOI 10.1145/3385956.3422122
   Hart S. G., 1986, Nasa task load index (tlx), V1, P5
   Hatfield E., 1993, Current directions in psychological science, V2, P96, DOI [10.1111/1467-8721.ep10770953, DOI 10.1111/14678721.EP10770953, DOI 10.1111/1467-8721.EP10770953]
   Hess U, 2014, SOC PERSONAL PSYCHOL, V8, P45, DOI 10.1111/spc3.12083
   Hoffman M. L., 2001, Empathy and moral development: Implications for caring and justice, P2
   HOFFMAN ML, 1977, PSYCHOL BULL, V84, P712, DOI 10.1037/0033-2909.84.4.712
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hurlbert AC, 2007, CURR BIOL, V17, pR623, DOI 10.1016/j.cub.2007.06.022
   IJsselsteijn W. A., 2013, The game experience questionnaire, P5
   Jarvela Simo, 2021, ACM Transactions on Social Computing, V4, DOI 10.1145/3449358
   Jurcak V, 2007, NEUROIMAGE, V34, P1600, DOI 10.1016/j.neuroimage.2006.09.024
   Knapp M. L., 2002, Handbook of interpersonal communication, P2
   KWALLEK N, 1988, PERCEPT MOTOR SKILL, V66, P123, DOI 10.2466/pms.1988.66.1.123
   Lampen Eva, 2020, Virtual, Augmented and Mixed Reality. Industrial and Everyday Life Applications. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12191), P91, DOI 10.1007/978-3-030-49698-2_7
   Lang PJ., 1980, TECHNOLOGY MENTAL HL, P119
   Lee S., 2004, C ARTIFICIAL REALITY, P2
   Liang Hui, 2023, 2023 9th International Conference on Virtual Reality (ICVR), P361, DOI 10.1109/ICVR57957.2023.10169325
   Liew TW, 2020, INFORM LEARN SCI, V121, P117, DOI 10.1108/ILS-11-2019-0124
   Linehan M. M., 1993, Skills training manual for treating borderline personality disorder, P4
   Lockwood PL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096555
   Lorenzetti V, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00390
   Makowski D, 2021, BEHAV RES METHODS, V53, P1689, DOI 10.3758/s13428-020-01516-y
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   Miller EK, 2015, DAEDALUS-US, V144, P112, DOI 10.1162/DAED_a_00320
   Moldoveanu A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131810365
   Moon J, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124623
   Oatley K, 2014, TRENDS COGN SCI, V18, P134, DOI 10.1016/j.tics.2013.12.004
   Ortega E, 2018, APPL PSYCHOPHYS BIOF, V43, P75, DOI 10.1007/s10484-017-9386-9
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Pinilla A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.630731
   Piumsomboon Thammathip, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P38, DOI 10.1109/ISUVR.2017.20
   POPE AT, 1995, BIOL PSYCHOL, V40, P187, DOI 10.1016/0301-0511(95)05116-3
   Prendinger H, 2004, LECT NOTES COMPUT SC, V3068, P53
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Preston SD, 2007, EMPATHY IN MENTAL ILLNESS, P428, DOI 10.1017/CBO9780511543753.024
   Raja A, 2023, PROCEEDINGS OF 2023 MENSCH UND COMPUTER, MUC 2023, P354, DOI 10.1145/3603555.3608525
   Rashkin H, 2019, Arxiv, DOI arXiv:1811.00207
   Rheinberg F., 2003, Die erfassung des flowerlebens, P5
   Rodrigues SH, 2015, INTERACT COMPUT, V27, P371, DOI 10.1093/iwc/iwu001
   Rosenzweig Margaret Quinn, 2012, Nurse Pract, V37, P1, DOI 10.1097/01.NPR.0000408626.24599.9e
   Ryan N. S., 1998, Computer applications in archaeology, P2
   SCHILIT BN, 1994, IEEE NETWORK, V8, P22, DOI 10.1109/65.313011
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seehausen M, 2016, BRAIN COGNITION, V103, P50, DOI 10.1016/j.bandc.2015.11.004
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709
   Sheldon KM, 2015, J COLL STUDENT DEV, V56, P261, DOI 10.1353/csd.2015.0027
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Stavrou NA, 2007, SPORT PSYCHOL, V21, P438, DOI 10.1123/tsp.21.4.438
   Sturmer S., 2009, PSYCHOL PROSOCIAL BE
   Thompson NM, 2019, PROG BRAIN RES, V247, P273, DOI 10.1016/bs.pbr.2019.03.024
   Tielman ML, 2017, TECHNOL HEALTH CARE, V25, P1081, DOI 10.3233/THC-170899
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yigitbas E., 2019, P MENSCH COMPUTER 20, P885, DOI DOI 10.1145/3340764.3349525
NR 88
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2671
EP 2681
DI 10.1109/TVCG.2024.3372130
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400013
PM 38437090
DA 2024-08-05
ER

PT J
AU Hiroi, Y
   Hiraki, T
   Itoh, Y
AF Hiroi, Yuichi
   Hiraki, Takefumi
   Itoh, Yuta
TI StainedSweeper: Compact, Variable-Intensity Light-Attenuation Display
   with Sweeping Tunable Retarders
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Light attenuation display; see-through display; augmented reality;
   time-multiplexing; polarized color filter
AB Light Attenuation Displays (LADs) are a type of Optical See-Through Head-Mounted Display (OST-HMD) that present images by attenuating incoming light with a pixel-wise polarizing color filter. Although LADs can display images in bright environments, there is a trade-off between the number of Spatial Light Modulators (SLMs) and the color gamut and contrast that can be expressed, making it difficult to achieve both high-fidelity image display and a small form factor. To address this problem, we propose StainedSweeper, a LAD that achieves both the wide color gamut and the variable intensity with a single SLM. Our system synchronously controls a pixel-wise Digital Micromirror Device (DMD) and a nonpixel polarizing color filter to pass light when each pixel is the desired color. By sweeping this control at high speed, the human eye perceives images in a time-multiplexed, integrated manner. To achieve this, we develop the OST-HMD design using a reflective Solc filter as a polarized color filter and a color reproduction algorithm based on the optimization of the time-multiplexing matrix for the selected primary color filters. Our proof-of-concept prototype showed that our single SLM design can produce subtractive images with variable contrast and a wider color gamut than conventional LADs.
C1 [Hiroi, Yuichi; Hiraki, Takefumi] Cluster Metaverse Lab, Tokyo, Japan.
   [Itoh, Yuta] Univ Tokyo, Tokyo, Japan.
C3 University of Tokyo
RP Hiroi, Y (corresponding author), Cluster Metaverse Lab, Tokyo, Japan.
EM y.hiroi@cluster.mu; t.hiraki@cluster.mu; yuta.itoh@iii.u-tokyo.ac.jp
OI Itoh, Yuta/0000-0002-5901-797X; Hiroi, Yuichi/0000-0001-8567-6947
FU JST FOREST
FX No Statement Available
CR Abu Aisheh M, 2023, NANOPHOTONICS-BERLIN, V12, P1115, DOI 10.1515/nanoph-2022-0656
   Abuleil MJ, 2014, OPT LETT, V39, P5487, DOI 10.1364/OL.39.005487
   Wilson A, 2022, IEEE T VIS COMPUT GR, V28, P4113, DOI 10.1109/TVCG.2021.3076069
   Xu YB, 2020, OPT EXPRESS, V28, P29740, DOI 10.1364/OE.402812
   Yang GW, 2010, APPL OPTICS, V49, P1280, DOI 10.1364/AO.49.001280
   YEH P, 1977, J OPT SOC AM, V67, P423, DOI 10.1364/JOSA.67.000423
   Zhang JG, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16223-1
   Zhang Y, 2023, IEEE T VIS COMPUT GR, V29, P2700, DOI 10.1109/TVCG.2023.3247064
   Zhang Y, 2021, OPT EXPRESS, V29, P42751, DOI 10.1364/OE.444904
NR 9
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2682
EP 2692
DI 10.1109/TVCG.2024.3372058
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400067
PM 38437084
DA 2024-08-05
ER

PT J
AU Novotny, J
   Laidlaw, DH
AF Novotny, Johannes
   Laidlaw, David H.
TI Evaluating Text Reading Speed in VR Scenes and 3D Particle
   Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Three-dimensional displays; Rendering (computer
   graphics); Task analysis; Two-dimensional displays; Resists; Data
   visualization; Virtual Reality; Scientific Visualization; Text
   Representation; Human-Computer Interaction; Perception
ID IMMERSIVE VIRTUAL-REALITY; LEGIBILITY; DISPLAYS; ACUITY; STATE
AB This work reports how text size and other rendering conditions affect reading speeds in a virtual reality environment and a scientific data analysis application. Displaying text legibly yet space-efficiently is a challenging problem in immersive displays. Effective text displays that enable users to read at their maximum speed must consider the variety of virtual reality (VR) display hardware and possible visual exploration tasks. We investigate how text size and display parameters affect reading speed and legibility in three state-of-the-art VR displays: two head-mounted displays and one CAVE. In our perception experiments, we establish limits where reading speed declines as the text size approaches the so-called critical print sizes (CPS) of individual displays, which can inform the design of uniform reading experiences across different VR systems. We observe an inverse correlation between display resolution and CPS. Yet, even in high-fidelity VR systems, the measured CPS was larger than in comparable physical text displays, highlighting the value of increased VR display resolutions in certain visualization scenarios. Our findings indicate that CPS can be an effective metric for evaluating VR display usability. Additionally, we evaluate the effects of text panel placement, orientation, and occlusion-reducing rendering methods on reading speeds in generic volumetric particle visualizations. Our study provides insights into the trade-off between text representation and legibility in cluttered immersive environments with specific suggestions for visualization designers and highlight areas for further research.
C1 [Novotny, Johannes] VRVis Zentrum Virtual Real & Visualisierung GmbH, Vienna, Austria.
   [Novotny, Johannes; Laidlaw, David H.] Brown Univ, Providence, RI 02912 USA.
C3 Brown University
RP Novotny, J (corresponding author), VRVis Zentrum Virtual Real & Visualisierung GmbH, Vienna, Austria.; Novotny, J (corresponding author), Brown Univ, Providence, RI 02912 USA.
EM jnovotny@vrvis.at; david_laidlaw@brown.edu
OI Laidlaw, David/0000-0002-3411-7376; Novotny,
   Johannes/0000-0001-6442-6172
FU National Science Foundation
FX No Statement Available
CR Ali K., 2005, Journal of WSCG, V13, P1
   [Anonymous], 2014, PROCVCBM, DOI [10.2312/vcbm.20141192, DOI 10.2312/VCBM.20141192]
   Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Borg O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129902
   Bowman D. A., 2003, P ACM S VIRT REAL SO, P81, DOI [10.1145/1008653.1008669, DOI 10.1145/1008653.1008669]
   Büttner A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P663, DOI [10.1109/VRW50115.2020.00-93, 10.1109/VRW50115.2020.00182]
   Calabrèse A, 2016, INVEST OPHTH VIS SCI, V57, P3836, DOI 10.1167/iovs.16-19580
   Chen J, 2004, P IEEE VIRT REAL ANN, P181, DOI 10.1109/VR.2004.1310072
   Cheung SH, 2008, INVEST OPHTH VIS SCI, V49, P828, DOI 10.1167/iovs.07-0555
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Dingler T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188695
   Dittrich Elisabeth, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P149, DOI 10.1007/978-3-642-39405-8_18
   Dobres J, 2018, APPL ERGON, V70, P240, DOI 10.1016/j.apergo.2018.03.007
   Elliott DB, 2016, OPHTHAL PHYSL OPT, V36, P355, DOI 10.1111/opo.12310
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Garcia-Hernandez R. J., 2016, PROCAEROCONF, P1
   Grout Cameron., 2015, P 15 NZ C HUMAN COMP, P9, DOI DOI 10.1145/2808047.2808055
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Iyer J, 2017, WEB3D 2017, DOI 10.1145/3055624.3075958
   Jankowski J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1321
   Kenyon A, 2014, 2014 IEEE VIRTUAL REALITY (VR), P89, DOI 10.1109/VR.2014.6802065
   Kilpelaeinen M, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1243387
   Laha B, 2014, IEEE T VIS COMPUT GR, V20, P513, DOI 10.1109/TVCG.2014.20
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lee H, 2023, VIRTUAL REAL-LONDON, V27, P829, DOI 10.1007/s10055-022-00693-9
   Manghisi VM, 2017, PRESENCE-TELEOP VIRT, V26, P1, DOI 10.1162/PRES_a_00285
   Mayr S, 2017, DISPLAYS, V48, P41, DOI 10.1016/j.displa.2017.03.002
   MILLS CB, 1987, COMPUT SURV, V19, P329, DOI 10.1145/45075.46162
   Moran A, 2015, IEEE HIGH PERF EXTR
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Olshannikova E., 2015, J BIG DATA-GER, V2, P22, DOI 10.1186/s40537-015-0031-2
   Orlosky J, 2014, MOB COMPUT COMMUN RE, V18, P20, DOI 10.1145/2636242.2636246
   Polys N.F., 2005, Proceedings of ACM Symposium on Virtual Reality Software and Technology (VRST), P46, DOI 10.1145/1101616.1101626
   Radner W, 2014, GRAEF ARCH CLIN EXP, V252, P1297, DOI 10.1007/s00417-014-2646-y
   Rzayev R., 2021, PROCCHI, P1
   Sadana R, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P41, DOI 10.1145/3009939.3009946
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Silva JNA, 2018, JACC-BASIC TRANSL SC, V3, P420, DOI 10.1016/j.jacbts.2017.11.009
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   Wei CX, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P721, DOI [10.1109/VR46266.2020.1581590322523, 10.1109/VR46266.2020.000-9]
   Williams DR, 2001, CUSTOMIZED CORNEAL ABLATION, P11
   yougowords, You go words-word finder
   Zhao JY, 2019, GEO-SPAT INF SCI, V22, P237, DOI 10.1080/10095020.2019.1621544
NR 47
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2602
EP 2612
DI 10.1109/TVCG.2024.3372093
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200002
PM 38437104
DA 2024-08-05
ER

PT J
AU Samuel, S
   Elvezio, C
   Khan, S
   Bitzer, LZ
   Moss-Salentijn, L
   Feiner, S
AF Samuel, Sara
   Elvezio, Carmine
   Khan, Salaar
   Bitzer, Laureen Zubiaurre
   Moss-Salentijn, Letty
   Feiner, Steven
TI Visuo-Haptic VR and AR Guidance for Dental Nerve Block Education
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dentistry; Haptic interfaces; Visualization; Three-dimensional displays;
   Training; Teeth; Electronic mail; Virtual reality; visualization
   techniques; mixed reality; augmented reality; health care information
   systems
AB The inferior alveolar nerve block (IANB) is a dental anesthetic injection that is critical to the performance of many dental procedures. Dental students typically learn to administer an IANB through videos and practice on silicone molds and, in many dental schools, on other students. This causes significant stress for both the students and their early patients. To reduce discomfort and improve clinical outcomes, we created an anatomically informed virtual reality headset-based educational system for the IANB. It combines a layered 3D anatomical model, dynamic visual guidance for syringe position and orientation, and active force feedback to emulate syringe interaction with tissue. A companion mobile augmented reality application allows students to step through a visualization of the procedure on a phone or tablet. We conducted a user study to determine the advantages of preclinical training with our IANB simulator. We found that in comparison to dental students who were exposed only to traditional supplementary study materials, dental students who used our IANB simulator were more confident administering their first clinical injections, had less need for syringe readjustments, and had greater success in numbing patients.
C1 [Samuel, Sara; Elvezio, Carmine; Feiner, Steven] Columbia Univ, Dept Comp Sci, Columbia, NY 10027 USA.
   [Khan, Salaar; Bitzer, Laureen Zubiaurre; Moss-Salentijn, Letty] Columbia Univ, Coll Dent Med, New York, NY USA.
C3 Columbia University; Columbia University
RP Elvezio, C (corresponding author), Columbia Univ, Dept Comp Sci, Columbia, NY 10027 USA.
EM sas2361@columbia.edu; carmine@cs.columbia.edu;
   srk2143@cumc.columbia.edu; laz1@cumc.columbia.edu;
   lm23@cumc.columbia.edu; feiner@cs.columbia.edu
OI Feiner, Steven/0000-0001-9978-7090; Samuel, Sara/0009-0002-7802-7732;
   Zubiaurre Bitzer, Laureen/0000-0002-1059-4063; Moss-Salentijn,
   Letty/0009-0003-3716-8915
FU Columbia University Provost's Hybrid Learning Course Redesign and
   Delivery
FX No Statement Available
NR 0
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2839
EP 2848
DI 10.1109/TVCG.2024.3372125
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400069
PM 38498761
DA 2024-08-05
ER

PT J
AU Weissker, T
   Franzgrote, M
   Kuhlen, T
AF Weissker, Tim
   Franzgrote, Matthis
   Kuhlen, Torsten
TI Try This for Size: Multi-Scale Teleportation in Immersive Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; 3D User Interfaces; 3D Navigation; Head-Mounted
   Display; Multi-Scale
ID NAVIGATION
AB The ability of a user to adjust their own scale while traveling through virtual environments enables them to inspect tiny features being ant-sized and to gain an overview of the surroundings as a giant. While prior work has almost exclusively focused on steering-based interfaces for multi-scale travel, we present three novel teleportation-based techniques that avoid continuous motion flow to reduce the risk of cybersickness. Our approaches build on the extension of known teleportation workflows and suggest specifying scale adjustments either simultaneously with, as a connected second step after, or separately from the user's new horizontal position. The results of a two-part user study with 30 participants indicate that the simultaneous and connected specification paradigms are both suitable candidates for effective and comfortable multi-scale teleportation with nuanced individual benefits. Scale specification as a separate mode, on the other hand, was considered less beneficial. We compare our findings to prior research and publish the executable of our user study to facilitate replication and further analyses.
C1 [Weissker, Tim; Franzgrote, Matthis; Kuhlen, Torsten] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
C3 RWTH Aachen University
RP Weissker, T (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM me@tim-weissker.de; matthis.franzgrote@rwth-aachen.de;
   kuhlen@vr.rwth-aachen.de
RI ; Kuhlen, Torsten/A-1059-2017
OI Franzgrote, Matthis/0009-0002-6632-3841; Weissker,
   Tim/0000-0001-9119-811X; Kuhlen, Torsten/0000-0003-2144-4367
FU Ministry of Economic Affairs
FX No Statement Available
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Argelaguet F, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P269, DOI 10.1145/2993369.2993391
   Argelaguet F, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P123, DOI 10.1109/3DUI.2014.7027325
   Bacim F, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P67
   Bhandari J., 2018, P 44 GRAPHICS INTERF, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018.223, DOI 10.20380/GI2018.223]
   Bimberg P, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489893
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   Cho Isaac, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P133, DOI 10.1109/3DUI.2015.7131738
   Cho I, 2018, IEEE T VIS COMPUT GR, V24, P1331, DOI 10.1109/TVCG.2017.2668405
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cohen J., 1988, Statistical power analysis for the behavioral sciences
   Elvezio C, 2017, P IEEE VIRT REAL ANN, P475, DOI 10.1109/VR.2017.7892386
   Field A., 2013, Discovering Statistics using IBM SPSS Statistics, Vthird, P374, DOI DOI 10.1016/B978-012691360-6/50012-4
   Funk M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300377
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   HART S G, 1988, P139
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kim J., 2017, P 27 INT C ARTIFICIA, P153, DOI DOI 10.5555/3298830.32988592
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   Kulik A, 2017, PRESENCE-VIRTUAL AUG, V26, P297, DOI [10.1162/pres_a_00297, 10.1162/PRES_a_00297]
   Kunert A., 2014, P 17 ACM C COMPUTER, P1388
   Langbehn E, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P211, DOI 10.1109/3DUI.2016.7460054
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Le Chenechal Morgan, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P18, DOI 10.1109/3DCVE.2016.7563562
   Lee JI, 2023, Symposium Virtual Re, P680, DOI 10.1109/VR55154.2023.00083
   Lee P., 2020, P 26 ACM S VIRTUAL R, DOI [10.1145/3385956.34189612[30]A., DOI 10.1145/3385956.3418961]
   Matviienko A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501983
   McCrae James., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P7, DOI DOI 10.1145/1507149.1507151
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Mori S., 2023, Journal of Information Processing, V31, P392, DOI [10.2197/ipsjjip.31.3922,3, DOI 10.2197/IPSJJIP.31.3922,3]
   Pausch R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P399, DOI 10.1145/218380.218495
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Badr AS, 2023, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1075811
   Song D., 1994, IEEE Computational Science and Engineering, V1, P53
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Valentine JC, 2015, BASIC APPL SOC PSYCH, V37, P260, DOI 10.1080/01973533.2015.1060240
   Ware C., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P127, DOI 10.1145/253284.253319
   Weissker Tim, 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2524, DOI 10.1109/TVCG.2021.3067756
   Weissker T., 2024, Try This for Size: Multi-Scale Teleportation in Immersive Virtual Reality (User Study Executable), DOI [10.5281/zenodo.105228832, DOI 10.5281/ZENODO.105228832]
   Weissker T., 2024, Try This for Size: Multi-Scale Teleportation in Immersive Virtual Reality (Study Data), DOI [10.5281/zenodo.105228297, DOI 10.5281/ZENODO.105228297]
   Weissker T, 2023, IEEE T VIS COMPUT GR, V29, P2467, DOI 10.1109/TVCG.2023.3247114
   Weissker T, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P363, DOI 10.1109/VRW52623.2021.00073
   Weissker T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI [10.1109/VR.2019.8797807, 10.1109/vr.2019.8797807]
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Xia HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P853, DOI 10.1145/3242587.3242597
   Zhang N., 2020, P 26 ACM S VIRTUAL R, DOI [10.1145/3385956.34189493[49]D, DOI 10.1145/3385956.3418949]
   ZHANG X., 2002, Proceedings of the 4th International Conference on Collaborative Virtual Environments, p, P31, DOI [10.1145/571878.5718841,3, DOI 10.1145/571878.5718841,3]
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
   Zielasko D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P693, DOI 10.1109/VR51125.2022.00090
NR 58
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2298
EP 2308
DI 10.1109/TVCG.2024.3372043
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200001
PM 38437134
DA 2024-08-05
ER

PT J
AU Yang, WK
   Guo, YK
   Wu, J
   Wang, Z
   Guo, LZ
   Li, YF
   Liu, SX
AF Yang, Weikai
   Guo, Yukai
   Wu, Jing
   Wang, Zheng
   Guo, Lan-Zhe
   Li, Yu-Feng
   Liu, Shixia
TI Interactive Reweighting for Mitigating Label Quality Issues
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Training data; Noise measurement; Annotations; Bipartite
   graph; Visualization; Data visualization; Bipartite graph visualization;
   sample reweighting; training data quality
ID VISUAL ANALYTICS; SYSTEM
AB Label quality issues, such as noisy labels and imbalanced class distributions, have negative effects on model performance. Automatic reweighting methods identify problematic samples with label quality issues by recognizing their negative effects on validation samples and assigning lower weights to them. However, these methods fail to achieve satisfactory performance when the validation samples are of low quality. To tackle this, we develop Reweighter, a visual analysis tool for sample reweighting. The reweighting relationships between validation samples and training samples are modeled as a bipartite graph. Based on this graph, a validation sample improvement method is developed to improve the quality of validation samples. Since the automatic improvement may not always be perfect, a co-cluster-based bipartite graph visualization is developed to illustrate the reweighting relationships and support the interactive adjustments to validation samples and reweighting results. The adjustments are converted into the constraints of the validation sample improvement method to further improve validation samples. We demonstrate the effectiveness of Reweighter in improving reweighting results through quantitative evaluation and two case studies.
C1 [Yang, Weikai; Guo, Yukai; Wang, Zheng; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
   [Wu, Jing] Cardiff Univ, Cardiff, Wales.
   [Guo, Lan-Zhe; Li, Yu-Feng] Nanjing Univ, Nanjing, Jiangsu, Peoples R China.
C3 Tsinghua University; Cardiff University; Nanjing University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM yangwk21@mails.tsinghua.edu.cn; gyj22@mails.tsinghua.edu.cn;
   wuj11@cardiff.ac.uk; zheng-wa19@mails.tsinghua.edu.cn;
   guolz@lamda.nju.edu.cn; liyf@nju.edu.cn; shixia@tsinghua.edu.cn
OI Wang, Zheng/0009-0004-0575-5936; Guo, Yukai/0009-0000-9651-3617; Wu,
   Jing/0000-0001-5123-9861; Guo, Lan-Zhe/0000-0001-8965-1288
FU National Natural Science Foundation of China
FX No Statement Available
CR Bäuerle A, 2020, COMPUT GRAPH FORUM, V39, P195, DOI 10.1111/cgf.13973
   Boyd S., 2004, Convex optimization, DOI [DOI 10.1017/CBO9780511804441, 10.1017/CBO9780511804441]
   Chakrabarti D., 2012, Graph Mining: Laws Tools and Case studies
   Chakrabarti Deepayan, 2004, KDD, P79
   Chatterjee S, 2020, P INT C LEARN REPR
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Choi J, 2023, IEEE T VIS COMPUT GR, V29, P1424, DOI 10.1109/TVCG.2021.3116656
   Dennig FL, 2019, IEEE CONF VIS ANAL, P69, DOI [10.1109/vast47406.2019.8986940, 10.1109/VAST47406.2019.8986940]
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   GANSNER ER, 1993, IEEE T SOFTWARE ENG, V19, P214, DOI 10.1109/32.221135
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gray RM, 2011, ENTROPY AND INFORMATION THEORY , SECOND EDITION, P395, DOI 10.1007/978-1-4419-7970-4
   Gu KR, 2023, MACH LEARN, V112, P1871, DOI 10.1007/s10994-022-06207-7
   Halter G, 2019, COMPUT GRAPH FORUM, V38, P119, DOI 10.1111/cgf.13676
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Hlawatsch M, 2014, IEEE T VIS COMPUT GR, V20, P1590, DOI 10.1109/TVCG.2014.2322594
   Hoang DA, 2022, Arxiv, DOI arXiv:2208.08132
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khayat M, 2020, IEEE T VIS COMPUT GR, V26, P874, DOI 10.1109/TVCG.2019.2934266
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu YP, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2568
   Manolis Savva, 2011, P 24 ANN ACM S USER, P393
   Moehrmann J, 2011, LECT NOTES COMPUT SC, V6761, P618, DOI 10.1007/978-3-642-21602-2_67
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Park JH, 2021, IEEE T VIS COMPUT GR, V27, P2869, DOI 10.1109/TVCG.2019.2953026
   Park JH, 2016, IEEE CONF VIS ANAL, P21, DOI 10.1109/VAST.2016.7883508
   Ren MY, 2018, PR MACH LEARN RES, V80
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Robertson S., 2023, P CHI C HUM FACT COM, P1
   Robinson I, 2020, Arxiv, DOI arXiv:2002.05687
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Shu J, 2019, ADV NEUR IN, V32
   Snyder LS, 2020, IEEE T VIS COMPUT GR, V26, P558, DOI 10.1109/TVCG.2019.2934614
   Soares A, 2017, IEEE COMPUT GRAPH, V37, P28, DOI 10.1109/MCG.2017.3621221
   Song C. Li, 2022, IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3225554.[9]X, DOI 10.1109/TVCG.2022.3225554.[9]X]
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/VAST47406.2019.8986917, 10.1109/vast47406.2019.8986917]
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Wang RX, 2018, IEEE T NEUR NET LEAR, V29, P2568, DOI 10.1109/TNNLS.2017.2699783
   Wang XM, 2020, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST50239.2020.00006
   Wang YX, 2017, PR MACH LEARN RES, V70
   Whang SE, 2020, PROC VLDB ENDOW, V13, P3429, DOI 10.14778/3415478.3415562
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xu YJ, 2021, PROC CVPR IEEE, P144, DOI 10.1109/CVPR46437.2021.00021
   Yang M., 2023, Comput. Vis. Media, early access
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yeshchenko A, 2022, IEEE T VIS COMPUT GR, V28, P3050, DOI 10.1109/TVCG.2021.3050071
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang B., 2021, Advances in Neural Information Processing Systems
   Zhang XY, 2023, IEEE PAC VIS SYMP, P167, DOI [10.1109/PacificVis56936.2023.00026, 10.1145/3608164.3608188]
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhang Zizhao, 2021, P IEEE CVF INT C COM, P725
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
NR 69
TC 1
Z9 1
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1837
EP 1852
DI 10.1109/TVCG.2023.3345340
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500004
PM 38127601
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Athawale, TM
   Triana, B
   Kotha, T
   Pugmire, D
   Rosen, P
AF Athawale, Tushar M.
   Triana, Bryan
   Kotha, Tanmay
   Pugmire, Dave
   Rosen, Paul
TI A Comparative Study of the Perceptual Sensitivity of Topological
   Visualizations to Feature Variations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Perception & cognition; computational topology-based techniques;
   comparison and similarity
ID OF-THE-ART; FIBER SURFACES; PERSISTENCE; EXTRACTION; UNAWARE
AB Color maps are a commonly used visualization technique in which data are mapped to optical properties, e.g., color or opacity. Color maps, however, do not explicitly convey structures (e.g., positions and scale of features) within data. Topology-based visualizations reveal and explicitly communicate structures underlying data. Although our understanding of what types of features are captured by topological visualizations is good, our understanding of people's perception of those features is not. This paper evaluates the sensitivity of topology-based isocontour, Reeb graph, and persistence diagram visualizations compared to a reference color map visualization for synthetically generated scalar fields on 2-manifold triangular meshes embedded in 3D. In particular, we built and ran a human-subject study that evaluated the perception of data features characterized by Gaussian signals and measured how effectively each visualization technique portrays variations of data features arising from the position and amplitude variation of a mixture of Gaussians. For positional feature variations, the results showed that only the Reeb graph visualization had high sensitivity. For amplitude feature variations, persistence diagrams and color maps demonstrated the highest sensitivity, whereas isocontours showed only weak sensitivity. These results take an important step toward understanding which topology-based tools are best for various data and task scenarios and their effectiveness in conveying topological variations as compared to conventional color mapping.
C1 [Athawale, Tushar M.; Pugmire, Dave] Oak Ridge Natl Lab, Oak Ridge, TN 37831 USA.
   [Triana, Bryan] Univ S Florida, Tampa, FL USA.
   [Kotha, Tanmay; Rosen, Paul] Univ Utah, Salt Lake City, UT USA.
C3 United States Department of Energy (DOE); Oak Ridge National Laboratory;
   State University System of Florida; University of South Florida; Utah
   System of Higher Education; University of Utah
RP Athawale, TM (corresponding author), Oak Ridge Natl Lab, Oak Ridge, TN 37831 USA.
EM athawaletm@ornl.gov; bryantriana@usf.edu; tanmay@mail.usf.edu;
   pugmire@ornl.gov; paul.rosen@utah.edu
RI Rosen, Paul/GXM-8609-2022
OI Rosen, Paul/0000-0002-0873-9518; Athawale, Tushar/0000-0003-3163-6274
FU U.S. Department of Energy
FX No Statement Available
CR Anderson EW, 2011, COMPUT GRAPH FORUM, V30, P791, DOI 10.1111/j.1467-8659.2011.01928.x
   Bauer U., 2014, P 30 ANN S COMPUTATI, P464
   Blender Online Community, 2018, Blender-a 3D modelling and rendering package
   Bollen B, 2023, IEEE T VIS COMPUT GR, V29, P1168, DOI 10.1109/TVCG.2022.3209395
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brecheisen R, 2009, IEEE T VIS COMPUT GR, V15, P1441, DOI 10.1109/TVCG.2009.170
   Bremer PT, 2007, J PHYS CONF SER, V78, DOI 10.1088/1742-6596/78/1/012007
   Bremer PT, 2010, IEEE T VIS COMPUT GR, V16, P248, DOI 10.1109/TVCG.2009.69
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Cacuci D, 2003, Theory, V1, DOI DOI 10.1201/9780203498798
   Cacuci D., 2005, Applications to Large-Scale Systems, VII, P2
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carr H, 2015, COMPUT GRAPH FORUM, V34, P241, DOI 10.1111/cgf.12636
   Carrière M, 2017, PR MACH LEARN RES, V70
   Chan YH, 2013, IEEE T VIS COMPUT GR, V19, P1768, DOI 10.1109/TVCG.2013.20
   Chen F, 2013, COMPUT AIDED GEOM D, V30, P557, DOI 10.1016/j.cagd.2012.03.019
   cnr, Digital Shape Workbench-Shape Repository. Shape repository
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Comission Internationale de l'eclairage, 1977, Color Res. Appl., V2, P5, DOI [10.1002/j.1520-6378.1977.tb00102.x, DOI 10.1002/J.1520-6378.1977.TB00102.X]
   Cooper PS, 2021, NEUROIMAGE, V245, DOI 10.1016/j.neuroimage.2021.118628
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P249, DOI 10.1109/TVCG.2012.115
   Doraiswamy H, 2012, IEEE T VIS COMPUT GR, V18, P146, DOI 10.1109/TVCG.2011.37
   Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2010, American Mathematical Society, V2, P3
   Edelsbrunner H, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P242, DOI 10.1145/1377676.1377720
   Engelke W., 2021, Topologybased feature design and tracking for multi-center cyclones, P71, DOI DOI 10.1007/978-3-030-83500-2_5
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Fechner G. T., 1948, Elements of psychophysics, DOI DOI 10.1037/11304-0265
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Forsberg AS, 2009, IEEE T VIS COMPUT GR, V15, P1219, DOI 10.1109/TVCG.2009.126
   Gasparovic E., 2019, arXiv, DOI 10.48550/arXiv.1908.000632
   Hajij M, 2020, ALGORITHMS, V13, DOI 10.3390/a13100258
   Hansen CJ, 2017, SPACE SCI REV, V213, P475, DOI 10.1007/s11214-014-0079-x
   Hauser H., 2007, Topological-based Methods in Visualization, DOI [10.1007/978-3-540-70823-02, DOI 10.1007/978-3-540-70823-02]
   Hilton A, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P381, DOI 10.1109/ICIP.1996.560840
   Hosmer D. W., 2013, Applied Logistic Regression: Third Edition, V398, DOI DOI 10.1002/9781118548387
   Jankowai J, 2020, IEEE T VIS COMPUT GR, V26, P1308, DOI 10.1109/TVCG.2018.2867488
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Junyi Tu, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P99, DOI 10.1007/978-3-030-33720-9_8
   Kosara R, 2003, IEEE COMPUT GRAPH, V23, P20, DOI 10.1109/MCG.2003.1210860
   Kruger J, 1999, J PERS SOC PSYCHOL, V77, P1121, DOI 10.1037/0022-3514.77.6.1121
   Laidlaw DH, 2005, IEEE T VIS COMPUT GR, V11, P59, DOI 10.1109/TVCG.2005.4
   Lan FF, 2023, Arxiv, DOI arXiv:2306.01186
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Liu RC, 2014, J VISUAL-JAPAN, V17, P157, DOI 10.1007/s12650-014-0207-4
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Luo MR, 2006, COLOR RES APPL, V31, P320, DOI 10.1002/col.20227
   Makram M., 2014, International Journal of Image Processing (IJIP), V8, P17
   Masood T. B., 2021, Topological Methods in Data Analysis and Visualization VI-Theory, Applications, and Software, V9, P4
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Morozov D., 2013, TOPOINVIS TOPOLOGICA
   Morse M, 1930, P NATL ACAD SCI USA, V16, P777, DOI 10.1073/pnas.16.11.777
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Natarajan V, 2008, MATH VIS, P237, DOI 10.1007/978-3-540-72630-2_14
   Nauleau F, 2022, SYMP LARG DATA ANAL, P50, DOI 10.1109/LDAV57265.2022.9966403
   Njeru DK, 2023, COMP M BIO BIO E-IV, V11, P812, DOI 10.1080/21681163.2022.2113824
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x
   printablemodels, Free3d
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Reininghaus J, 2015, PROC CVPR IEEE, P4741, DOI 10.1109/CVPR.2015.7299106
   Rogowitz E. E., 1996, Computers in Physics, V10, P268
   Rosen P., 2021, Topological Methods in Data Analysis and Visualization VI, P87, DOI [DOI 10.1007/978-3-030-83500-2_6, 10.1007/978-3-030-83500-2_62, DOI 10.1007/978-3-030-83500-2_62]
   Saltelli A., 2008, Global Sensitivity Analysis: The Primer, DOI DOI 10.1002/97804707251842,5
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sohn BS, 2006, IEEE T VIS COMPUT GR, V12, P14, DOI 10.1109/TVCG.2006.16
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   threejs, Three.js JavaScript 3D Library
   Tierny J, 2017, MATH VIS, P1, DOI 10.1007/978-3-319-71507-0
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2017, IEEE T VIS COMPUT GR, V23, P960, DOI 10.1109/TVCG.2016.2599017
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Tricoche X., 2002, Schriftenreihe Fachbereich Informatik, P2
   University of Michigan, 1969, Bluelink anatomy (@bluelinkanatomy) [8-86582]
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Varakin DA, 2004, HUM-COMPUT INTERACT, V19, P389, DOI 10.1207/s15327051hci1904_9
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Yu-Hsuan Chan, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P43, DOI 10.1109/VAST.2010.5652460
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 88
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1074
EP 1084
DI 10.1109/TVCG.2023.3326592
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500069
PM 37871073
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Castelo, S
   Rulff, J
   McGowan, E
   Steers, B
   Wu, GD
   Chen, SY
   Roman, I
   Lopez, R
   Brewer, E
   Zhao, C
   Qian, J
   Cho, K
   He, H
   Sun, Q
   Vo, H
   Bello, J
   Krone, M
   Silva, C
AF Castelo, Sonia
   Rulff, Joao
   McGowan, Erin
   Steers, Bea
   Wu, Guande
   Chen, Shaoyu
   Roman, Iran
   Lopez, Roque
   Brewer, Ethan
   Zhao, Chen
   Qian, Jing
   Cho, Kyunghyun
   He, He
   Sun, Qi
   Vo, Huy
   Bello, Juan
   Krone, Michael
   Silva, Claudio
TI <i>ARGUS:</i> Visualization of AI-Assisted Task Guidance in AR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data Models; Image and Video Data; Temporal Data; Application Motivated
   Visualization; AR/VR/Immersive
ID VIDEO
AB The concept of augmented reality (AR) assistants has captured the human imagination for decades, becoming a staple of modern science fiction. To pursue this goal, it is necessary to develop artificial intelligence (AI)-based methods that simultaneously perceive the 3D environment, reason about physical tasks, and model the performer, all in real-time. Within this framework, a wide variety of sensors are needed to generate data across different modalities, such as audio, video, depth, speech, and time-of-flight. The required sensors are typically part of the AR headset, providing performer sensing and interaction through visual, audio, and haptic feedback. AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world. Therefore, developing such assistants is a challenging task. We propose ARGUS, a visual analytics system to support the development of intelligent AR assistants. Our system was designed as part of a multi-year-long collaboration between visualization researchers and ML and AR experts. This co-design process has led to advances in the visualization of ML in AR. Our system allows for online visualization of object, action, and step detection as well as offline analysis of previously recorded AR sessions. It visualizes not only the multimodal sensor data streams but also the output of the ML models. This allows developers to gain insights into the performer activities as well as the ML models, helping them troubleshoot, improve, and fine-tune the components of the AR assistant.
C1 [Castelo, Sonia; Rulff, Joao; McGowan, Erin; Steers, Bea; Wu, Guande; Chen, Shaoyu; Roman, Iran; Lopez, Roque; Brewer, Ethan; Zhao, Chen; Qian, Jing; Cho, Kyunghyun; He, He; Sun, Qi; Vo, Huy; Bello, Juan; Krone, Michael; Silva, Claudio] NYU, New York, NY 10012 USA.
C3 New York University
RP Castelo, S (corresponding author), NYU, New York, NY 10012 USA.
EM s.castelo@nyu.edu; jlrulff@nyu.edu; erin.mcgowan@nyu.edu;
   bs3639@nyu.edu; guandewu@nyu.edu; sc6439@nyu.edu; irr2020@nyu.edu;
   rlopez@nyu.edu; ethan.brewer@nyu.edu; cz1285@nyu.edu; jq2267@nyu.edu;
   kyunghyun.cho@nyu.edu; hh2291@nyu.edu; qs2053@nyu.edu; huy.vo@nyu.edu;
   jpbello@nyu.edu; mk8949@nyu.edu; csilva@nyu.edu
OI Rulff, Joao/0000-0003-3341-7059; Silva, Claudio/0000-0003-2452-2295;
   Bello, Juan Pablo/0000-0001-8561-5204; McGowan,
   Erin/0000-0002-7565-3052; Wu, Guande/0000-0002-9244-173X; Roman, Iran
   R./0000-0003-3781-7244; Chen, Shaoyu/0000-0002-1856-6294
FU DARPA
FX No Statement Available
CR Aigner W., 2011, HUMAN COMPUTER INTER, DOI DOI 10.1007/978-0-85729-079-3
   ARGUS, 2023, Augmented reality guidance and user-modeling system
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Beams R, 2022, J DIGIT IMAGING, V35, P1409, DOI 10.1007/s10278-022-00622-x
   Becher M, 2022, IEEE COMPUT GRAPH, V42, P33, DOI 10.1109/MCG.2022.3157961
   Bohus D., 2021, CORR
   Bostock Michael., D3.js
   Bozkir E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255979
   Caudell T. P., 1991, Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences (Cat. No.91TH0394-7), P659, DOI 10.1109/HICSS.1992.183317
   DARPA, Perceptually-enabled task guidance (PTG)
   David-John B, 2021, IEEE T VIS COMPUT GR, V27, P2555, DOI 10.1109/TVCG.2021.3067787
   del Amo IF, 2018, PROCEDIA MANUF, V19, P148, DOI 10.1016/j.promfg.2018.01.021
   Duan Y, 2021, OPT COMMUN, V482, DOI 10.1016/j.optcom.2020.126567
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Felix C, 2018, IEEE T VIS COMPUT GR, V24, P657, DOI 10.1109/TVCG.2017.2746018
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Foxglove, Foxglove-Visualizing and debugging your robotics data, V3
   Funk M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P185, DOI 10.1145/2700648.2809853
   Girdhar R, 2022, PROC CVPR IEEE, P16081, DOI 10.1109/CVPR52688.2022.01563
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Hsu CT, 2004, SIGNAL PROCESS-IMAGE, V19, P81, DOI 10.1016/j.image.2003.10.001
   Jiang T., 2020, Journal of Medical Internet Research, DOI [10.2196/168522, DOI 10.2196/168522]
   Kazakos E, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P855, DOI 10.1109/ICASSP39728.2021.9413376
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Lin A. S., 2020, P 58 ANN M ASS COMP, P4871, DOI DOI 10.18653/V1/2020.ACL-MAIN.440
   Lin K.Q., 2022, arXiv
   Liu C.-F., 2018, P 20 INT C HUMAN COM, P395, DOI [10.1145/3236112.3236174, DOI 10.1145/3236112.3236174]
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   M. O. Source, React
   Marriott Kim, 2018, Lecture Notes in Computer Science, DOI DOI 10.1007/978-3-030-01388-2
   Microsoft, 2022, Using the windows device portal
   Microsoft, TypeScript
   Miknis M, 2015, INT CONF SYST SIGNAL, P153, DOI 10.1109/IWSSIP.2015.7314200
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MIT Lincoln Laboratory, 2022, PTG evaluation tasks, V1
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nair V, 2023, Arxiv, DOI arXiv:2306.06459
   Nijholt A, 2022, LECT NOTES COMPUT SC, V13326, P304, DOI 10.1007/978-3-031-05431-0_21
   Pase S., 2012, P INT C E LEARNING E, P4
   Puladi B, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/34781
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramirez S., FastAPI
   Schmeil A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P267, DOI 10.1109/VR.2007.352497
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Steedly D, 2005, IEEE I CONF COMP VIS, P1300
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI DOI 10.1145/642611.642626
   three.js, about us
   Ungureanu D., CORR
   Xiao FY, 2020, Arxiv, DOI arXiv:2001.08740
   Xuetong Sun, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3365678
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhang ZQ, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P520
   Zheng XJS, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2125, DOI 10.1145/2702123.2702305
   Zhou KY, 2022, Arxiv, DOI arXiv:2103.02503
   Zhou XY, 2022, LECT NOTES COMPUT SC, V13669, P350, DOI 10.1007/978-3-031-20077-9_21
NR 58
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1313
EP 1323
DI 10.1109/TVCG.2023.3327396
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500061
PM 37917526
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Chen, Q
   Chen, N
   Shuai, W
   Wu, GD
   Xu, Z
   Tong, HH
   Cao, N
AF Chen, Qing
   Chen, Nan
   Shuai, Wei
   Wu, Guande
   Xu, Zhe
   Tong, Hanghang
   Cao, Nan
TI Calliope-Net: Automatic Generation of Graph Data Facts via Annotated
   Node-Link Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graph Data; Application Motivated Visualization; Automatic
   Visualization; Narrative Visualization; Authoring Tools
ID INFORMATION VISUALIZATION; NARRATIVE VISUALIZATION; NETWORKS; INSIGHTS
AB Graph or network data are widely studied in both data mining and visualization communities to review the relationship among different entities and groups. The data facts derived from graph visual analysis are important to help understand the social structures of complex data, especially for data journalism. However, it is challenging for data journalists to discover graph data facts and manually organize correlated facts around a meaningful topic due to the complexity of graph data and the difficulty to interpret graph narratives. Therefore, we present an automatic graph facts generation system, Calliope-Net, which consists of a fact discovery module, a fact organization module, and a visualization module. It creates annotated node-link diagrams with facts automatically discovered and organized from network data. A novel layout algorithm is designed to present meaningful and visually appealing annotated graphs. We evaluate the proposed system with two case studies and an in-lab user study. The results show that Calliope-Net can benefit users in discovering and understanding graph data facts with visually pleasing annotated visualizations.
C1 [Chen, Qing; Chen, Nan; Shuai, Wei; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
   [Wu, Guande] NYU, New York, NY USA.
   [Xu, Zhe] Univ Illinois Champaign Urbana, Champaign, IL USA.
C3 Tongji University; New York University; University of Illinois System;
   University of Illinois Urbana-Champaign
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
EM qingchen@tongji.edu.cn; christy05.chen@gmail.com;
   shuaiwei@tongji.edu.cn; guandewu@nyu.edu; zhexu3@illinois.edu;
   hanghang.tong@gmail.com; nan.cao@tongji.edu.cn
OI Cao, Nan/0000-0003-1316-7515
FU NSFC
FX No Statement Available
CR Ahn JW, 2014, IEEE T VIS COMPUT GR, V20, P365, DOI 10.1109/TVCG.2013.238
   Aisch G., 2011, Connecting the dots behind the 2016 presidential candidates
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361, DOI DOI 10.1609/ICWSM.V3I1.13937
   Bennett Chris, 2007, PROC CAE, DOI [10.2312/COMPAESTH/COMPAESTH07/057-064, 10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631
   Bounegru L, 2017, DIGIT JOURNAL, V5, P699, DOI 10.1080/21670811.2016.1186497
   Brath R., 2018, IEEE VIS WORKSHOP VI
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Campbell EM, 2017, J INFECT DIS, V216, P1053, DOI 10.1093/infdis/jix307
   Chabot C., 2003, Tableau Software, V6
   Chen Q, 2024, IEEE T VIS COMPUT GR, V30, P4429, DOI 10.1109/TVCG.2023.3261320
   Chen Y, 2009, IEEE PAC VIS SYMP, P49, DOI 10.1109/PACIFICVIS.2009.4906837
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Cohen S., 2004, The bush money machine
   Demiralp Cagatay, 2017, arXiv
   Deodhar M., 2022, arXiv
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Eiter Thomas, 1994, Computing discrete frechet distance
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P150, DOI 10.1145/347090.347121
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Freeman Linton, 2004, A Study in the Sociology of Science, V1, P159, DOI DOI 10.4135/9781446294413.N3
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Hart J., 2021, Storycraft: The Complete Guide to Writing Narrative Nonfiction
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Huang W., 2005, Layout effects: Comparison of sociogram drawing conventions
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Ilbo J., 2012, Social network analysis of high-ranking officials in s. korean government
   Kaneider D., 2013, ITS 13, P61, DOI DOI 10.1145/2512349.2512809
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300335
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   KNUTH DE, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P41
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Latif S., 2019, EUROVIS SHORT PAPERS, P115
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Lazar J., 2017, Research methods in human-computer interaction, V2nd, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Luo YY, 2020, PROC INT CONF DATA, P733, DOI 10.1109/ICDE48307.2020.00069
   Mafrur R, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1123, DOI 10.1145/3269206.3271744
   Marsh B., 2015, Chris christie and the lane closings: A spectator's guide
   Matei S, 2011, INT J HUM-COMPUT INT, V27, P405, DOI 10.1080/10447318.2011.544971
   Nettleton DF, 2013, COMPUT SCI REV, V7, P1, DOI 10.1016/j.cosrev.2012.12.001
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   OCCRP, 2011, The proxy platform
   Pohl M., 2009, COMPUTATIONAL AESTHE, P49, DOI [DOI 10.2312/COMPAESTH/COMPAESTH09/049-056, 10.5555/2381286.2381296]
   Pretorius AJ, 2014, LECT NOTES COMPUT SC, V8380, P77, DOI 10.1007/978-3-319-06793-3_5
   Procter R., 2011, How riot rumours spread on twitter
   Purchase HC, 2000, INTERACT COMPUT, V13, P147, DOI 10.1016/S0953-5438(00)00032-1
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Romat H, 2021, IEEE T VIS COMPUT GR, V27, P2329, DOI 10.1109/TVCG.2019.2950932
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stack Overflow, 2021, Stack overflow tag network
   Tang B, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1509, DOI 10.1145/3035918.3035922
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Von Daniels J., Die ttipdealer
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wikipedia contributors, 2021, Les miserables-Wikipedia, the free encyclopedia
   Wu HY, 2016, 32ND SPRING CONFERENCE ON COMPUTER GRAPHICS (SCCG 2016), P41, DOI 10.1145/2948628.2948642
   Zhang Peng B. Z., 2022, 2022 4 INT C ADV COM, DOI DOI 10.1109/CTISC54888.2022.9849754
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
NR 78
TC 1
Z9 1
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 562
EP 572
DI 10.1109/TVCG.2023.3326925
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500051
PM 37874720
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Feyer, SP
   Pinaud, B
   Kobourov, S
   Brich, N
   Krone, M
   Kerren, A
   Behrisch, M
   Schreiber, F
   Klein, K
AF Feyer, Stefan P.
   Pinaud, Bruno
   Kobourov, Stephen
   Brich, Nicolas
   Krone, Michael
   Kerren, Andreas
   Behrisch, Michael
   Schreiber, Falk
   Klein, Karsten
TI 2D, 2.5D, or 3D? An Exploratory Study on Multilayer Network
   Visualisations in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Three-dimensional displays; Data
   visualization; Taxonomy; Nonhomogeneous media; Surveys; Network;
   Guidelines; VisDesign; HumanQuant; CompSystems
ID OF-THE-ART; GRAPHS; DETAIL
AB Relational information between different types of entities is often modelled by a multilayer network (MLN) - a network with subnetworks represented by layers. The layers of an MLN can be arranged in different ways in a visual representation, however, the impact of the arrangement on the readability of the network is an open question. Therefore, we studied this impact for several commonly occurring tasks related to MLN analysis. Additionally, layer arrangements with a dimensionality beyond 2D, which are common in this scenario, motivate the use of stereoscopic displays. We ran a human subject study utilising a Virtual Reality headset to evaluate 2D, 2.5D, and 3D layer arrangements. The study employs six analysis tasks that cover the spectrum of an MLN task taxonomy, from path finding and pattern identification to comparisons between and across layers. We found no clear overall winner. However, we explore the task-to-arrangement space and derive empirical-based recommendations on the effective use of 2D, 2.5D, and 3D layer arrangements for MLNs.
C1 [Feyer, Stefan P.; Klein, Karsten] Univ Konstanz, Life Sci Informat, Constance, Germany.
   [Pinaud, Bruno] Univ Bordeaux, CNRS, Bordeaux INP, UMR 5800,LaBRI, Talence, France.
   [Kobourov, Stephen] Univ Arizona, Tucson, AZ USA.
   [Brich, Nicolas; Krone, Michael] Univ Tubingen, D-55411 Tubingen, Germany.
   [Krone, Michael] NYU, New York, NY USA.
   [Kerren, Andreas] Linkoping Univ, Linkoping, Sweden.
   [Kerren, Andreas] Linnaeus Univ, Vaxjo, Sweden.
   [Behrisch, Michael] Univ Utrecht, Utrecht, Netherlands.
   [Schreiber, Falk] Univ Konstanz, Constance, Germany.
   [Schreiber, Falk] Monash Univ, Melbourne, Australia.
C3 University of Konstanz; Universite de Bordeaux; Centre National de la
   Recherche Scientifique (CNRS); University of Arizona; Eberhard Karls
   University of Tubingen; New York University; Linkoping University;
   Linnaeus University; Utrecht University; University of Konstanz; Monash
   University
RP Feyer, SP (corresponding author), Univ Konstanz, Life Sci Informat, Constance, Germany.
EM stefan.feyer@uni-konstanz.de; bruno.pinaud@u-bordeaux.fr;
   kobourov@cs.arizona.edu; nicolas.brich@uni-tuebingen.de;
   michael.krone@uni-tuebingen.de; andreas.kerren@liu.se; m.behrisch@uu.nl;
   falk.schreiber@uni-konstanz.de; karsten.klein@uni-konstanz.de
RI Kerren, Andreas/AAV-9187-2020; Kobourov, Stephen/A-3016-2008
OI Kerren, Andreas/0000-0002-0519-2537; Feyer, Stefan
   Paul/0009-0004-8574-0741; Kobourov, Stephen/0000-0002-0477-2724;
   Behrisch, Michael/0000-0002-1102-103X; Krone,
   Michael/0000-0002-1445-7568; Brich, Nicolas/0000-0003-3175-0464
FU DFG
FX No Statement Available
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Baggag A, 2018, EPJ DATA SCI, V7, DOI 10.1140/epjds/s13688-018-0139-7
   Bardoscia M, 2021, NAT REV PHYS, V3, P490, DOI 10.1038/s42254-021-00322-5
   Becker SO, 2020, AM SOCIOL REV, V85, P857, DOI 10.1177/0003122420948059
   Berger P, 2019, IEEE INT CON INF VIS, P261, DOI 10.1109/IV.2019.00051
   Bianconi G, 2018, MULTILAYER NETWORKS: STRUCTURE AND FUNCTION, DOI 10.1093/oso/9780198753919.001.0001
   Bornhofen S, 2020, APPL NETW SCI, V5, DOI 10.1007/s41109-020-00295-x
   Brandes U, 2004, LECT NOTES COMPUT SC, V2912, P111
   Brandes U., 2004, J Integr Bioinform, V1, P11, DOI [10.1515/jib-2004-2, DOI 10.1515/JIB-2004-2, 10.1515/jib-2004-23,8, DOI 10.1515/JIB-2004-23,8]
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Chimani M., 2013, Handbook of Graph Drawing and Visualization, P543
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Cuenca E, 2022, IEEE T VIS COMPUT GR, V28, P1634, DOI 10.1109/TVCG.2021.3067820
   De Domenico M, 2015, J COMPLEX NETW, V3, P159, DOI 10.1093/comnet/cnu038
   Dickison M. E., 2016, Visualizing Multilayer Networks, P79, DOI DOI 10.1017/CBO9781139941907.0052
   Doutreligne S, 2014, SYMP LARG DATA ANAL, P109, DOI 10.1109/LDAV.2014.7013213
   Drogemuller A, 2020, J COMPUT LANG, V56, DOI 10.1016/j.cola.2019.100937
   Estrada E, 2020, PHYS REP, V869, P1, DOI 10.1016/j.physrep.2020.07.005
   Greffard N, 2012, LECT NOTES COMPUT SC, V7034, P215
   Hammoud Zaynab, 2020, Big Data Analytics, V5, P1, DOI 10.1186/s41044-020-00046-0
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Interdonato R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100246
   Joos L, 2022, IEEE T VIS COMPUT GR, V28, P3651, DOI 10.1109/TVCG.2022.3203001
   Kerren A., 2014, LNCS, V8380, DOI DOI 10.1007/978-3-319-06793-3
   Kerren A, 2014, IEEE COMPUT GRAPH, V34, P69, DOI 10.1109/MCG.2014.122
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Korkut EH, 2023, VIRTUAL REAL-LONDON, V27, P1447, DOI 10.1007/s10055-023-00753-8
   Kotlarek J, 2020, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis48177.2020.4722
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.1581122519414, 10.1109/VR46266.2020.00-23]
   Liu TY, 2022, NUCLEIC ACIDS RES, V50, pW551, DOI 10.1093/nar/gkac352
   Maes A, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0006
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   McGee F., 2021, Visual Analysis of Multilayer Networks, DOI DOI 10.2200/S01094ED1V01Y202104VIS0122,3,4,6,9
   Murray P, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1443-5
   Nicholson DN, 2020, COMPUT STRUCT BIOTEC, V18, P1414, DOI 10.1016/j.csbj.2020.05.017
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Ossi L., Multilayer Network Exploration Tool in virtual reality
   Pirch S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22570-w
   Pohl M., 2019, WORKSH VIS MULT NETW
   Prouzeau A, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P241, DOI 10.1145/3343055.3359709
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase H., 2012, Experimental Human-Computer Interaction: A Practical Guide With Visual Examples, DOI DOI 10.1017/CBO97805118445225
   Rhyne TM, 2021, IEEE COMPUT GRAPH, V41, P125, DOI 10.1109/MCG.2021.3075258
   Roberts J. C., 2021, Computer Graphics and Visual Computing (CGVC), DOI DOI 10.2312/CGVC.20211309
   Roberts JC, 2014, LECT NOTES COMPUT SC, V8380, P127, DOI 10.1007/978-3-319-06793-3_7
   Santos A, 2022, NAT BIOTECHNOL, V40, P692, DOI 10.1038/s41587-021-01145-6
   Schreiber F, 2014, LECT NOTES COMPUT SC, V8380, P175, DOI 10.1007/978-3-319-06793-3_9
   Seok-Hee Hong, 2007, Journal of Graph Algorithms and Applications, V11, P371, DOI 10.7155/jgaa.00151
   SHOEMAKE K, 1992, GRAPH INTER, P151
   Sorger J, 2021, COMPUT GRAPH FORUM, V40, P241, DOI 10.1111/cgf.14417
   Sorger J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P144, DOI 10.1109/AIVR46125.2019.00030
   Unity Technologies, Unity
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Waagmeester A, 2020, ELIFE, V9, DOI 10.7554/eLife.52614
   Walsh B, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3173, DOI 10.1145/3340531.3412776
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Yang Y., 2006, P ACM INT C VIRT REA, P377, DOI [10.1145/1128923.1128992, DOI 10.1145/1128923.1128992]
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Zheng SJ, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa344
   Zhou GY, 2018, NUCLEIC ACIDS RES, V46, pW514, DOI 10.1093/nar/gky510
NR 67
TC 3
Z9 3
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 469
EP 479
DI 10.1109/TVCG.2023.3327402
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500124
PM 37883262
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, XB
   Huang, RF
   Jin, ZH
   Fang, TQ
   Qu, HM
AF Wang, Xingbo
   Huang, Renfei
   Jin, Zhihua
   Fang, Tianqing
   Qu, Huamin
TI <i>CommonsenseVIS</i>: Visualizing and Understanding Commonsense
   Reasoning Capabilities of Natural Language Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Commonsense reasoning; Context modeling; Analytical models; Natural
   language processing; Benchmark testing; Task analysis; Data models;
   visual analytics; XAI; natural language processing
AB Recently, large pretrained language models have achieved compelling performance on commonsense benchmarks. Nevertheless, it is unclear what commonsense knowledge the models learn and whether they solely exploit spurious patterns. Feature attributions are popular explainability techniques that identify important input concepts for model outputs. However, commonsense knowledge tends to be implicit and rarely explicitly presented in inputs. These methods cannot infer models' implicit reasoning over mentioned concepts. We present CommonsenseVIS, a visual explanatory system that utilizes external commonsense knowledge bases to contextualize model behavior for commonsense question-answering. Specifically, we extract relevant commonsense knowledge in inputs as references to align model behavior with human knowledge. Our system features multi-level visualization and interactive model probing and editing for different concepts and their underlying relations. Through a user study, we show that CommonsenseVIS helps NLP experts conduct a systematic and scalable visual analysis of models' relational reasoning over concepts in different situations.
C1 [Wang, Xingbo] Cornell Univ, Weill Cornell Med Coll, Ithaca, NY 14850 USA.
   [Wang, Xingbo; Huang, Renfei; Jin, Zhihua; Fang, Tianqing; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Cornell University; Weill Cornell Medicine; Hong Kong University of
   Science & Technology
RP Wang, XB (corresponding author), Cornell Univ, Weill Cornell Med Coll, Ithaca, NY 14850 USA.; Wang, XB (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM xingbo.wang@connect.ust.hk; rhuangan@ust.hk; zjinak@ust.hk;
   tfangaa@ust.hk; huamin@ust.hk
RI Fang, Tianqing/JJF-2802-2023
FU Hong Kong Theme-based Research Scheme
FX No Statement Available
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Ayoub J, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102569
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bertviz J. Vig., 2019, ICLR WORKSH DEB MACH
   Bhagavatula C., 2020, INT C LEARN REPR
   Bian N, 2024, Arxiv, DOI arXiv:2303.16421
   Bisk Y., 2020, AAAI, DOI [10.1609/aaai.v34i05.62391,2,4, DOI 10.1609/AAAI.V34I05.62391,2,4]
   Boggust A., 2022, P CHI, P1, DOI [10.1145/3491102.35019652,3,9, DOI 10.1145/3491102.35019652,3,9]
   Boratko M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1122
   Bordes A., 2013, Advances in Neural Information Processing Systems, V26
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Chen Hanjie, 2020, P 58 ANN M ASS COMPU, P5919, DOI DOI 10.18653/V1/2020
   Cui LY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P683
   Dai DM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8493
   De Cao N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6491
   Dinu Georgiana, 2015, ICLR
   Feldhus N., 2022, arXiv
   Feng YL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1295
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P3813, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Huang LF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2391
   Hwang JD, 2021, AAAI CONF ARTIF INTE, V35, P6384
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Jin ZH, 2024, IEEE T VIS COMPUT GR, V30, P3594, DOI 10.1109/TVCG.2023.3236380
   Kaushik Divyansh, 2020, INT C LEARN REPR
   Khashabi D, 2022, Arxiv, DOI arXiv:2202.12359
   Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896
   Li Xiang Lorraine., 2022, P 2022 C EMPIRICAL M, P11838, DOI 10.18653/v1/2022.emnlp-main.812
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liang P. P., 2022, ICLR
   Lin BY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4611
   Lin BY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1504
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829
   Liu JC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3154
   Lourie N, 2021, AAAI CONF ARTIF INTE, V35, P13480
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma KX, 2021, AAAI CONF ARTIF INTE, V35, P13507
   Manning C. D., 1999, Foundations of Statistical Natural Language Processing
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Meng K., 2023, ICLR
   Meng K., 2022, ICLR
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Mitchell E., 2022, ICLR
   Mostafazadeh N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4569
   Ouyang L., NEURIPS
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Poyiadzi R, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P344, DOI 10.1145/3375627.3375850
   Raffel C, 2020, J MACH LEARN RES, V21
   Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932
   Reif Emily, 2019, ADV NEURAL INFORM PR, P8594
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381
   Sap M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4463
   Sap M, 2019, AAAI CONF ARTIF INTE, P3027
   Schwab P., 2019, Advances in Neural Information Processing Systems, P10220
   Shwartz V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4615
   Singh S., 2021, FINDINGS ASS COMPUTA, P883, DOI 10.18653/v1/2021.findings-acl.781,2
   Slack D., 2021, Advances in neural information processing systems, P62
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Talmor A., 2021, NeurIPS Datasets and Benchmarks Track, V1
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tandon N, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P523, DOI 10.1145/2556195.2556245
   Tenney I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P107
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Voita E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P183
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wu Tongshuang., 2021, P ACL IJC NLP 2021, P6707
   Xu Yichong, 2022, P 31 INT JOINT C ART, P2762, DOI 10.24963/ijcai.2022/3831,2
   Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535
   Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791
   Zhang HM, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4004
   Zhou XH, 2020, AAAI CONF ARTIF INTE, V34, P9733
NR 77
TC 2
Z9 2
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 273
EP 283
DI 10.1109/TVCG.2023.3327153
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500135
PM 37883264
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Yeh, C
   Chen, Y
   Wu, A
   Chen, C
   Viégas, F
   Wattenberg, M
AF Yeh, Catherine
   Chen, Yida
   Wu, Aoyu
   Chen, Cynthia
   Viegas, Fernanda
   Wattenberg, Martin
TI AttentionViz: A Global View of Transformer Attention
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Transformer; Attention; NLP; Computer Vision; Visual Analytics
AB Transformer models are revolutionizing machine learning, but their inner workings remain mysterious. In this work, we present a new visualization technique designed to help researchers understand the self-attention mechanism in transformers that allows these models to learn rich, contextual relationships between elements of a sequence. The main idea behind our method is to visualize a joint embedding of the query and key vectors used by transformer models to compute attention. Unlike previous attention visualization techniques, our approach enables the analysis of global patterns across multiple input sequences. We create an interactive visualization tool, AttentionViz (demo: http://attentionviz.com), based on these joint query-key embeddings, and use it to study attention mechanisms in both language and vision transformers. We demonstrate the utility of our approach in improving model understanding and offering new insights about query-key interactions through several application scenarios and expert feedback.
C1 [Yeh, Catherine; Chen, Yida; Wu, Aoyu; Chen, Cynthia; Viegas, Fernanda; Wattenberg, Martin] Harvard Univ, Cambridge, MA 02138 USA.
C3 Harvard University
RP Yeh, C; Wattenberg, M (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM catherineyeh@g.harvard.edu; yidachen@g.harvard.edu;
   aoyuwu@g.harvard.edu; cynthiachen@college.harvard.edu;
   fernanda@g.harvard.edu; wattenberg@g.harvard.edu
OI Wu, Aoyu/0000-0001-9187-9265; Chen, Yida/0000-0002-4018-6095
CR Aflalo E, 2022, PROC CVPR IEEE, P21374, DOI 10.1109/CVPR52688.2022.02072
   Arendt DL, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P259, DOI 10.1145/3377325.3377514
   Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Carter S., 2019, Distill, V4, DOI [10.23915/distill.000151, DOI 10.23915/DISTILL.000151]
   Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chi Ethan A., 2020, P 58 ANN M ASS COMP, P5564, DOI DOI 10.18653/V1/2020.ACL-MAIN.493
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Coenen A, 2019, ADV NEUR IN, V32
   Cordonnier J.-B., 2020, 8 INT C LEARN REPR A, DOI [10.48550/arXiv.1911.035842, DOI 10.48550/ARXIV.1911.035842]
   Dehghani M., 2023, arXiv
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A., 2021, 9 INT C LEARN REPR, DOI [10.48550/arXiv.2010.119291,2,7, DOI 10.48550/ARXIV.2010.119291,2,7]
   Elhage N., 2022, arXiv, DOI 10.48550/arxiv.2209.10652
   Elhage Nelson, 2021, Transformer Circuits Thread
   Ghiasi A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.06727
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Ji XN, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.03.003
   Jiang Chao, 2020, P 58 ANN M ASS COMPU, P7943, DOI 10.18653/v1/2020.acl-main.709
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT, DOI 10.1016/0169-7439(87)80084-92
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Lidwell W., 2010, Universal principles of design, revised and updated: 125 ways to enhance usability, influence perception, increase appeal, make better design decisions, and teach through design, P9
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241
   Liu SS, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P36, DOI 10.13697/j.cnki.32-1449/tu.2018.01.013
   Ma J, 2023, IEEE T NEUR NET LEAR, DOI [10.1109/IECON51785.2023.10312727, 10.1109/TNNLS.2023.3270479]
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Mehrani P, 2023, Arxiv, DOI [arXiv:2303.01542, DOI 10.48550/ARXIV.2303.01542, 10.48550/arXiv.2303.01542, DOI 10.3389/FCOMP.2023.1178450]
   Miaschi Alessio., 2020, P 28 INT C COMPUTATI, P745, DOI 10.18653/v1/2020.coling-main.65
   Naseer M, 2021, ADV NEUR IN, V34
   Olah C., 2017, Distill, V2, DOI [10.23915/distill.000079, DOI 10.23915/DISTILL.000079]
   Olsson Catherine, 2022, arXiv
   Oquab M, 2024, Arxiv, DOI arXiv:2304.07193
   Park C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P146, DOI 10.1109/visual.2019.8933677
   Park N., 2022, 10 INT C LEARN REPR, DOI [10.48550/arXiv.2202.06709 2, DOI 10.48550/ARXIV.2202.067092]
   Prokosch E, 1933, LANGUAGE, V9, P89, DOI 10.2307/409519
   Radford, 2018, OPENAI BLOG
   Radford A., 2019, OpenAI blog, V1, P9
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   Sivaraman V, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P418, DOI 10.1145/3490099.3511137
   Smilkov D, 2016, Arxiv, DOI arXiv:1611.05469
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2018, Arxiv, DOI [arXiv:1803.07416, 10.48550/arXiv.1803.07416, DOI 10.48550/ARXIV.1803.07416]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P63
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Wang A, 2019, ADV NEUR IN, V32
   Wang K., 2022, arXiv
   Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008
   Wang ZJ, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P132
   Wei JS, 2022, Arxiv, DOI arXiv:2206.07682
   Yang S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11782, DOI 10.1109/ICCV48922.2021.01159
NR 62
TC 3
Z9 3
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 262
EP 272
DI 10.1109/TVCG.2023.3327163
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500105
PM 37883259
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Fan, YT
   Zhu, LF
   Wang, H
   Song, AG
AF Fan, Yuting
   Zhu, Lifeng
   Wang, Hui
   Song, Aiguo
TI Synthesize Personalized Training for Robot-Assisted Upper Limb
   Rehabilitation With Diversity Enhancement
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Optimization; Task analysis; Games; Trajectory; End effectors;
   Robot kinematics; Exercise planning; multi-objective optimization;
   serious game; upper limb rehabilitation
ID MOTOR FUNCTION; RECOVERY; CARE; STRENGTH; THERAPY
AB For upper limb rehabilitation, the robot-assisted technique in combination with serious games requires well-specified training plans. For the best quality of the rehabilitation process, customized game levels for each user are desired, while it is labor-intensive to design and adjust game levels for different individuals. We work on generating training content for a desktop end-effector rehabilitation robot and propose a method to automatically generate individualized training plans. By modeling the search of the training motions as finding optimal hand paths and trajectories, we introduce solving the design problem with a multi-objective optimization (MO) solver. We further improve the MO solver to enhance the diversity of the solutions. With the proposed approach, our system is capable of automatically generating various training plans considering the training intensity and dexterity of each joint in the upper limb. In addition, the enhanced diversity avoids repeated training plans, which helps motivate the user in the rehabilitation. We test our method with different requirements on the training plans and validate the solutions.
C1 [Fan, Yuting; Zhu, Lifeng; Song, Aiguo] Southeast Univ, Sch Instrument Sci & Engn, State Key Lab Bioelect, Jiangsu Key Lab Remote Measurement & Control, Nanjing 211189, Jiangsu, Peoples R China.
   [Wang, Hui] Chinese Acad Sci, Hefei Inst Phys Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.
C3 Southeast University - China; Chinese Academy of Sciences; Hefei
   Institutes of Physical Science, CAS
RP Zhu, LF (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, State Key Lab Bioelect, Jiangsu Key Lab Remote Measurement & Control, Nanjing 211189, Jiangsu, Peoples R China.
EM fanyuting981026@163.com; lfzhulf@gmail.com; wanghui@iim.ac.cn;
   a.g.song@seu.edu.cn
OI Song, Aiguo/0000-0002-1982-6780
FU NSFC [92148205]; Jiangsu Key Research and Development Plan; Natural
   Science Foundation of Jiangsu Province [BK20211159]
FX This work was supported in part by NSFC under Grant 92148205, in part by
   the Jiangsu Key Research and Development Plan, and in part by the
   Natural Science Foundation of Jiangsu Province under Grant BK20211159.
CR Ada L, 1996, HUM MOVEMENT SCI, V15, P671, DOI 10.1016/0167-9457(96)00015-2
   Aldwin C. M., 2017, Health,Illness, and Optimal Aging: Biological and Psychosocial Perspectives
   Almeida Y, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 5: HEALTHINF, P845, DOI 10.5220/0009369108450853
   Bandyopadhyay S, 2008, IEEE T EVOLUT COMPUT, V12, P269, DOI 10.1109/TEVC.2007.900837
   González JC, 2017, COGN SYST RES, V43, P232, DOI 10.1016/j.cogsys.2016.09.003
   Colombo R, 2012, IEEE T NEUR SYS REH, V20, P276, DOI 10.1109/TNSRE.2012.2195679
   Desrosiers J, 1999, EXP GERONTOL, V34, P393, DOI 10.1016/S0531-5565(99)00018-2
   Doumas I, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00889-1
   Eckert M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020354
   Faria Ana Lucia, 2018, JMIR Rehabil Assist Technol, V5, pe10714, DOI 10.2196/10714
   Gonzalez-Mendoza A., 2019, P 16 INT C EL ENG CO, P1
   Hammedi W, 2017, J SERV MANAGE, V28, P640, DOI 10.1108/JOSM-04-2016-0116
   Hocine N, 2015, USER MODEL USER-ADAP, V25, P65, DOI 10.1007/s11257-015-9154-6
   Huang HK, 2018, IEEE T VIS COMPUT GR, V24, P2516, DOI 10.1109/TVCG.2017.2761820
   Ishibuchi H, 2008, IEEE C EVOL COMPUTAT, P2419, DOI 10.1109/CEC.2008.4631121
   Islam M., 2017, Adv Robot Autom, V6, P2
   KENDZIERSKI D, 1991, J SPORT EXERCISE PSY, V13, P50, DOI 10.1123/jsep.13.1.50
   Khan HA, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188523
   Khanafer S, 2021, EXP BRAIN RES, V239, P2285, DOI 10.1007/s00221-021-06143-3
   Knaepen K, 2014, IEEE T NEUR SYS REH, V22, P1128, DOI 10.1109/TNSRE.2014.2324153
   Krakauer JW, 2006, CURR OPIN NEUROL, V19, P84, DOI 10.1097/01.wco.0000200544.29915.cc
   Krebs HI, 2007, IEEE T NEUR SYS REH, V15, P327, DOI 10.1109/TNSRE.2007.903899
   Krebs HI, 2000, J REHABIL RES DEV, V37, P639
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   Langhorne P, 2011, LANCET, V377, P1693, DOI 10.1016/S0140-6736(11)60325-5
   Lee S, 2018, IEEE T NEUR SYS REH, V26, P125, DOI 10.1109/TNSRE.2017.2755667
   Lee SH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58630-2
   Li WW, 2022, IEEE T VIS COMPUT GR, V28, P1993, DOI 10.1109/TVCG.2022.3150510
   Li WW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392393
   Lum PS, 2002, ARCH PHYS MED REHAB, V83, P952, DOI 10.1053/apmr.2001.33101
   Maciejasz P, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-3
   Magermans DJ, 2005, CLIN BIOMECH, V20, P591, DOI 10.1016/j.clinbiomech.2005.02.006
   Meadmore KL, 2019, TOP STROKE REHABIL, V26, P94, DOI 10.1080/10749357.2018.1544845
   Miao Q, 2023, IEEE T COGN DEV SYST, V15, P2031, DOI 10.1109/TCDS.2021.3072096
   Morita Y, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P300, DOI 10.1109/ROBIO.2009.4913020
   Morone G, 2020, EXPERT REV MED DEVIC, V17, P223, DOI 10.1080/17434440.2020.1733408
   Muratori LM, 2013, J HAND THER, V26, P94, DOI 10.1016/j.jht.2012.12.007
   Nef Tobias, 2009, 11th International Congress of the IUPESM. Medical Physics and Biomedical Engineering. World Congress 2009. Neuroengineering, Neural Systems, Rehabilitation and Prosthetics, P127, DOI 10.1007/978-3-642-03889-1_35
   OptiTrack, 2020, Optitrack for movement sciences
   Otten A, 2015, IEEE-ASME T MECH, V20, P2285, DOI 10.1109/TMECH.2014.2375272
   Pereira F, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0578-9
   Phinyomark A, 2012, EXPERT SYST APPL, V39, P7420, DOI 10.1016/j.eswa.2012.01.102
   Pizzolato S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186132
   Pollock A, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010820.pub2
   Rawal A, 2018, CLIN BIOMECH, V54, P78, DOI 10.1016/j.clinbiomech.2018.03.009
   Rego P, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P349
   Reis E, 2019, PHYS THER REV, V24, P84, DOI 10.1080/10833196.2019.1639012
   Rosen J, 2005, 2005 12TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, P532
   Siddique T, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060842
   Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221
   Suman B, 2006, J OPER RES SOC, V57, P1143, DOI 10.1057/palgrave.jors.2602068
   W. H. Organization, 2006, Neurological Disorders: Public Health Challenges
   Wang HD, 2017, IEEE T CYBERNETICS, V47, P1510, DOI 10.1109/TCYB.2016.2550502
   Xie B, 2018, IEEE T VIS COMPUT GR, V24, P1661, DOI 10.1109/TVCG.2018.2793618
   Yu L, 2016, COMPUT METH PROG BIO, V128, P100, DOI 10.1016/j.cmpb.2016.02.012
   Zhang YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300784
   Zhou S.-H., 2016, J. Control Decis., V3, P19
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
NR 58
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5705
EP 5718
DI 10.1109/TVCG.2023.3308940
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400065
PM 37639418
DA 2024-08-05
ER

PT J
AU Fu, Y
   Stasko, J
AF Fu, Yu
   Stasko, John
TI More Than Data Stories: Broadening the Role of Visualization in
   Contemporary Journalism
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surveys; Bridges; Computational modeling; Biological system modeling;
   Instruments; Data visualization; Journalism; data visualization;
   computational journalism; data-driven storytelling
ID INFORMATION VISUALIZATION; NARRATIVE VISUALIZATION; AUTOMATED
   JOURNALISM; INTERACTIVE FEATURES; VISUAL ANALYTICS; NEWS; DESIGN;
   REFLECTIONS; EXPLORATION; GENERATION
AB Data visualization and journalism are deeply connected. From early infographics to recent data-driven storytelling, visualization has become an integrated part of contemporary journalism, primarily as a communication artifact to inform the general public. Data journalism, harnessing the power of data visualization, has emerged as a bridge between the growing volume of data and our society. Visualization research that centers around data storytelling has sought to understand and facilitate such journalistic endeavors. However, a recent metamorphosis in journalism has brought broader challenges and opportunities that extend beyond mere communication of data. We present this article to enhance our understanding of such transformations and thus broaden visualization research's scope and practical contribution to this evolving field. We first survey recent significant shifts, emerging challenges, and computational practices in journalism. We then summarize six roles of computing in journalism and their implications. Based on these implications, we provide propositions for visualization research concerning each role. Ultimately, by mapping the roles and propositions onto a proposed ecological model and contextualizing existing visualization research, we surface seven general topics and a series of research agendas that can guide future visualization research at this intersection.
C1 [Fu, Yu] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
   [Stasko, John] Georgia Inst Technol, Coll Comp, Atlanta, GA USA.
C3 University System of Georgia; Georgia Institute of Technology;
   University System of Georgia; Georgia Institute of Technology
RP Fu, Y (corresponding author), Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
EM fuyu@gatech.edu; stasko@cc.gatech.edu
OI Fu, Yu/0000-0001-5076-6299
CR Abebe R, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P252, DOI 10.1145/3351095.3372871
   Ahva L., 2019, The Handbook of Journalism Studies, P38, DOI [10.4324/9781315167497-3, DOI 10.4324/9781315167497-3]
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Anderson B., 2006, Imagined Communities: Reflections on the Origin and Spread of Nationalism
   [Anonymous], 2019, VisualizeNews
   [Anonymous], 2008, Why democracies need an unlovable press
   [Anonymous], 2006, Proceedings of the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization, DOI [10.1145/1168149.1168158, DOI 10.1145/1168149.1168158]
   [Anonymous], 2020, TheNew York Times
   Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [10.1080/1364557032000119616, DOI 10.1080/1364557032000119616, https://doi.org/10.1080/1364557032000119616]
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Boczkowski PJ, 2012, HUM COMMUN RES, V38, P1, DOI 10.1111/j.1468-2958.2011.01418.x
   Bogost S., 2012, Newsgames: Journalism at Play
   Bongshin Lee, 2021, Foundations and Trends in Human-Computer Interaction, V14, P1, DOI 10.1561/1100000081
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Boss K, 2017, IFLA J-INT FED LIBR, V43, P150, DOI 10.1177/0340035216686355
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bounegru L., 2012, DATA JOURNALISM HDB
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Broussard M., 2015, Newspaper Research Journal, V36, P299
   Broussard M., 2012, Archiving data journalism
   Broussard M, 2018, DIGIT JOURNAL, V6, P1206, DOI 10.1080/21670811.2018.1505437
   Bruns A, 2011, BRAZ JOURNAL RES, V7, P117, DOI 10.25200/BJR.v7n2.2011.355
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Burrell J, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951715622512
   C. I. of Health Research, 2010, A guide to knowledge synthesis-CIHR
   Cairo A., 2012, The Functional Art: An Introduction to Information Graphics and Visualization
   Cao J. L. E., 2023, P CHI C HUM FACT COM, DOI [10.1145/3544548.3581472113A, DOI 10.1145/3544548.3581472113A]
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   Carlson M, 2015, DIGIT JOURNAL, V3, P416, DOI 10.1080/21670811.2014.976412
   Carlson Matt., 2020, The Handbook of Journalism Studies, P123
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Chen H., 2022, P CHI C HUM FACT COM, DOI [10.1145/3491102.3517485112Y, DOI 10.1145/3491102.3517485112Y]
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen Zhutian, 2023, IEEE Trans Vis Comput Graph, V29, P918, DOI 10.1109/TVCG.2022.3209497
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chevalier F., 2018, Data -Driven Storytelling, P151
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Chung DS, 2008, J COMPUT-MEDIAT COMM, V13, P658, DOI 10.1111/j.1083-6101.2008.00414.x
   Chung DS, 2008, MASS COMMUN SOC, V11, P375, DOI 10.1080/15205430701791048
   Coddington M, 2015, DIGIT JOURNAL, V3, P331, DOI 10.1080/21670811.2014.976400
   Cohen S., 2011, The Data Journalism Handbook
   Cohen S, 2011, COMMUN ACM, V54, P66, DOI 10.1145/2001269.2001288
   Conlen Matthew, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1, DOI 10.1145/3472749.3474731
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Correll M, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P1, DOI 10.1109/BELIV57783.2022.00005
   Danziger M., 2008, Information visualization for the people
   Diakopoulos N., 2011, A Functional Roadmap for Innovation in Computational Journalism [WWW Document]
   Diakopoulos N, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1717
   Diakopoulos N, 2017, DIGIT JOURNAL, V5, P809, DOI 10.1080/21670811.2016.1208053
   Diakopoulos N, 2015, DIGIT JOURNAL, V3, P398, DOI 10.1080/21670811.2014.976411
   Domingo D, 2008, J COMPUT-MEDIAT COMM, V13, P680, DOI 10.1111/j.1083-6101.2008.00415.x
   Domingo D, 2008, JOURNAL PRACT, V2, P326, DOI 10.1080/17512780802281065
   Dong ES, 2020, LANCET INFECT DIS, V20, P533, DOI 10.1016/S1473-3099(20)30120-1
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Erickson T., 2000, ACM Transactions on Computer-Human Interaction, V7, P59, DOI 10.1145/344949.345004
   Eslami M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P153, DOI 10.1145/2702123.2702556
   Fan A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502138
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Flaxman S, 2016, PUBLIC OPIN QUART, V80, P298, DOI 10.1093/poq/nfw006
   Flew T, 2012, JOURNAL PRACT, V6, P157, DOI 10.1080/17512786.2011.616655
   Fu J., 2022, P CHI C HUM FACT COM, DOI [10.1145/3491102.3502078118S, DOI 10.1145/3491102.3502078118S]
   G. T. G. Center, 2008, JOURN 3G FUT TECHN F
   Gillmor D., 2006, WE MEDIA GRASSROOTS
   Görg C, 2014, INFORM VISUAL, V13, P336, DOI 10.1177/1473871613495674
   Görg C, 2013, IEEE T VIS COMPUT GR, V19, P1646, DOI 10.1109/TVCG.2012.324
   Graefe A., 2016, Columbia journalism school, graduate school of journalism, tow center for digital journalism
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Graves L., 2016, Deciding Whats True: The Rise of Political Fact-Checking in American Journalism
   Gray J., 2012, The Data Journalism Handbook: How Journalists Can Use Data to Improve News
   Gynnild A, 2014, JOURNALISM, V15, P713, DOI 10.1177/1464884913486393
   Haim M, 2018, DIGIT JOURNAL, V6, P330, DOI 10.1080/21670811.2017.1338145
   Hamilton F., 2009, P REP CTR ADV STUD B, P27
   Hammond P, 2017, JOURNALISM, V18, P408, DOI 10.1177/1464884915620205
   Hayes GR, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1993060.1993065
   Hayes Gillian R., 2014, Knowing by Doing: Action Research as an Approach to HCI, P49, DOI [10.1007/978-1-4939-0378-83, DOI 10.1007/978-1-4939-0378-83]
   Herdel V, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501881
   Hermida A., 2011, Mechanisms of participation: How audience options shape the conversation Participatory Journalism, P11, DOI [10.1002/9781444340747.ch2, DOI 10.1002/9781444340747.CH2]
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Holan A. D., 2020, Politifact
   Holovaty Adrian., 2006, A fundamental Way Newspaper Sites Need to Change"
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Houston B., 2021, The history of data journalism: A historical take on every critical breakthrough from the 1950s until today
   Howard A. B., 2014, The art and science of data-driven journalism, DOI [10.7916/D8Q531V1?ref=https://githubhelp.com, DOI 10.7916/D8Q531V1?REF=HTTPS://GITHUBHELP.COM]
   Hujanen J, 2004, NEW MEDIA SOC, V6, P383, DOI 10.1177/1461444804042521
   Hullman J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P1170, DOI 10.1145/2675133.2675207
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Hutchins E. L., 1985, Human-Computer interaction, V1, P311, DOI [10.1207/s15327051hci0104_2, DOI 10.1207/S15327051HCI0104_2]
   Isenberg P, 2018, LECT NOTES COMPUT SC, V11190, P165, DOI 10.1007/978-3-030-01388-2_6
   Jones S., 2005, Gatewatching: Collaborative Online News Production
   Kang YA, 2011, IEEE T VIS COMPUT GR, V17, P570, DOI 10.1109/TVCG.2010.84
   Karduni A., 2018, P INT AAAI C WEB SOC, P151
   Karduni A, 2019, PROCEEDINGS OF IUI 2019, P312, DOI 10.1145/3301275.3302320
   Kastrenakes J., 2020, The VergeMay
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kosara R., 2016, eagereyesJul.
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kovach B., 2014, The elements of journalism, VRevised and updated third edition
   Ladd JM, 2012, WHY AMERICANS HATE THE MEDIA AND HOW IT MATTERS, P1
   LaFrance A., 2019, Nieman ReportsFeb
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Lee BS, 2020, IEEE COMPUT GRAPH, V40, P82, DOI 10.1109/MCG.2020.2968244
   Lee B, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206602
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee S, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519711
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Leppanen L, 2017, P INLG, P188, DOI [10.18653/v1/w17-3528, DOI 10.18653/V1/W17-3528]
   Leppänen L, 2020, MEDIA COMMUN-LISBON, V8, P39, DOI 10.17645/mac.v8i3.3022
   Lewis SC, 2015, DIGIT JOURNAL, V3, P447, DOI 10.1080/21670811.2014.976418
   Lewis SC, 2015, DIGIT JOURNAL, V3, P19, DOI 10.1080/21670811.2014.927986
   Lewis SC, 2010, JOURNAL PRACT, V4, P163, DOI 10.1080/14616700903156919
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   Lupi S., 2016, Dear Data
   Lupton D, 2017, NEW MEDIA SOC, V19, P1599, DOI 10.1177/1461444817717515
   McCurdy N, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P10, DOI 10.1145/2993901.2993916
   McNair B, 2009, INT COMMUN ASSOC HAN, P237
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Meijer I.C., 2019, The Handbook of Journalism Studies, P389, DOI [DOI 10.4324/9781315167497-25, https://doi.org/10.4324/9781315167497-25]
   Mele N., 2017, COMBATING FAKE NEWS
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   MEYER P, 1988, JOURNALISM QUART, V65, P567, DOI 10.1177/107769908806500301
   Meyer Philip., 2002, PRECISION JOURNALISM, V4th
   Mittelstadt B, 2016, INT J COMMUN-US, V10, P4991
   Munson S., 2021, P INT AAAI C WEB SOC, P419, DOI DOI 10.1609/ICWSM.V7I1.14429
   Munzner T, 2008, LECT NOTES COMPUT SC, V4950, P134, DOI 10.1007/978-3-540-70956-5_6
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P1009, DOI 10.1109/TVCG.2021.3114827
   Nicoletti L., 2021, The Pudding
   Nigro N., 2022, Hamilton 2.0 dashboard
   Norman D., 1993, THINGS MAKE US SMART
   Oh C., 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI DOI 10.1145/3313831.3376811
   Otten JJ, 2015, HEALTH AFFAIR, V34, P1901, DOI 10.1377/hlthaff.2015.0642
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Parasie S, 2013, NEW MEDIA SOC, V15, P853, DOI 10.1177/1461444812463345
   Pariser E., 2011, The Filter Bubble: How the New Personalized Web Is Changing What We Read and How We Think, DOI DOI 10.5860/CHOICE.50-0926
   Pavlik J., 2000, Journalism Studies, V1, P229, DOI [https://doi.org/10.1080/14616700050028226, DOI 10.1080/14616700050028226, 10.1080/14616700050028226]
   Pavlik J V., 2001, Journalism and new media, DOI DOI 10.7312/PAVL11482
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Peters C, 2013, RETHINKING JOURNALISM: TRUST AND PARTICIPATION IN A TRANSFORMED NEWS LANDSCAPE, P1
   Pham MT, 2014, RES SYNTH METHODS, V5, P371, DOI 10.1002/jrsm.1123
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Powers E, 2017, DIGIT JOURNAL, V5, P1315, DOI 10.1080/21670811.2017.1286943
   Powers M, 2012, J COMMUN INQ, V36, P24, DOI 10.1177/0196859911426009
   Rashkin H., 2017, P 2017 C EMP METH NA, P2931
   Reeves Stuart, 2005, P SIGCHI C HUM FACT, P741, DOI DOI 10.1145/1054972.1055074
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Riche C., 2018, Data-DrivenStorytelling
   Robinson S., 2010, Convergence: The International Journal of Research into New Media Technologies, V16, P125
   Rogowitz E. E., 1996, Computers in Physics, V10, P268
   Saket B, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P133, DOI 10.1145/2993901.2993903
   Samek W, 2017, Arxiv, DOI arXiv:1708.08296
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Schudson M., 2008, Hedgehog Rev., V10, P7
   Scott B., 2005, Telev. New Media, V6, P89, DOI DOI 10.1177/1527476403255824
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shin M, 2023, IEEE T VIS COMPUT GR, V29, P2980, DOI 10.1109/TVCG.2022.3146329
   Shoemaker P. J., 2019, The Handbook of Journalism Studies, V2nd
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Singer J.B., 2011, Participatory journalism: Guarding open gates at online newspapers
   Sprague D, 2012, INFORM VISUAL, V11, P106, DOI 10.1177/1473871611433710
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stasko J., 2014, P 5 WORKSH TIM ERR N, P46, DOI [DOI 10.1145/2669557.26695792,9, 10.1145/2669557.2669579, DOI 10.1145/2669557.2669579]
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Stroud E. Van Duyn, 2016, Engaging News Project, P1
   Sunstein CR, 2017, CORNELL LAW REV, V102, P1431
   Tang T, 2020, J VISUAL-JAPAN, V23, P707, DOI 10.1007/s12650-020-00644-z
   The White House, 2022, We just learned that President Biden's first year in office was the strongest year for economic growth since 1984
   Thompson Z., 2021, P CHI C HUM FACT COM, DOI [10.1145/3411764.3445747110M, DOI 10.1145/3411764.3445747110M]
   Thudt A., 2018, DATA DRIVEN STORYTEL, P59
   Thurman N., 2019, The handbook of journalism studies, P180
   Thurman N, 2012, JOURNALISM STUD, V13, P775, DOI 10.1080/1461670X.2012.664341
   Usher N., 2016, Interactive Journalism: Hackers, Data, and Code, DOI [10.5406/j.ctt1hfr048, DOI 10.5406/J.CTT1HFR048]
   Usher N., 2009, Michael Schudson: Why democracies need an unlovable press
   VAN DALEN A., 2020, The Handbook of Journalism studies, V2a, P356, DOI DOI 10.4324/9781315167497-23
   Vázquez-Herrero J, 2020, STUD BIG DATA, V70, P29, DOI 10.1007/978-3-030-36315-4_3
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Wahl-Jorgensen K., 2019, The handbook of journalism studies, P3
   WahlJorgensen K, 2009, INT COMMUN ASSOC HAN, P1
   Wall E, 2022, IEEE T VIS COMPUT GR, V28, P966, DOI 10.1109/TVCG.2021.3114862
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wattenberg M, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P1, DOI 10.1109/INFVIS.2005.1532122
   Wohlin C., 2014, P 18 INT C EVALUATIO, DOI DOI 10.1145/2601248.2601268
   Wolfgang JD, 2016, DIGIT JOURNAL, V4, P764, DOI 10.1080/21670811.2015.1090882
   Young ML, 2018, JOURNAL PRACT, V12, P115, DOI 10.1080/17512786.2016.1270171
   Zamith R, 2014, DIGIT JOURNAL, V2, P558, DOI 10.1080/21670811.2014.882066
   Zhang Yixuan, 2023, IEEE Trans Vis Comput Graph, V29, P1037, DOI 10.1109/TVCG.2022.3209493
   Zhi S., 2019, P CHI C HUM FACT COM, P1, DOI [10.1145/3290605.3300499148C, DOI 10.1145/3290605.3300499148C]
   Zhou JW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581318
   Zimmerman J., 2014, Ways of knowing in HCI, P167, DOI [DOI 10.1007/978-1-4939-0378-8_8, 10.1007/978-1-4939-0378-88, DOI 10.1007/978-1-4939-0378-8]
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 208
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5240
EP 5259
DI 10.1109/TVCG.2023.3287585
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400009
PM 37339040
DA 2024-08-05
ER

PT J
AU Wu, Q
   Bauer, D
   Doyle, MJ
   Ma, KL
AF Wu, Qi
   Bauer, David
   Doyle, Michael J.
   Ma, Kwan-Liu
TI Interactive Volume Visualization via Multi-Resolution Hash Encoding
   Based Neural Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Implicit neural representation; path tracing; ray marching; volume
   visualization
ID SUPERRESOLUTION; FRAMEWORK
AB Implicit neural networks have demonstrated immense potential in compressing volume data for visualization. However, despite their advantages, the high costs of training and inference have thus far limited their application to offline data processing and non-interactive rendering. In this article, we present a novel solution that leverages modern GPU tensor cores, a well-implemented CUDA machine learning framework, an optimized global-illumination-capable volume rendering algorithm, and a suitable acceleration data structure to enable real-time direct ray tracing of volumetric neural representations. Our approach produces high-fidelity neural representations with a peak signal-to-noise ratio (PSNR) exceeding 30 dB, while reducing their size by up to three orders of magnitude. Remarkably, we show that the entire training step can fit within a rendering loop, bypassing the need for pre-training. Additionally, we introduce an efficient out-of-core training strategy to support extreme-scale volume data, making it possible for our volumetric neural representation training to scale up to terascale on a workstation with an NVIDIA RTX 3090 GPU. Our method significantly outperforms state-of-the-art techniques in terms of training time, reconstruction quality, and rendering performance, making it an ideal choice for applications where fast and accurate visualization of large-scale volume data is paramount.
C1 [Wu, Qi; Bauer, David; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
   [Doyle, Michael J.] Intel Corp, Santa Clara, CA 95054 USA.
C3 University of California System; University of California Davis; Intel
   Corporation
RP Wu, Q (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM qadwu@ucdavis.edu; davbauer@ucdavis.edu; michael1.doyle@intel.com;
   klma@ucdavis.edu
OI Bauer, David/0000-0002-1327-3054; Ma, Kwan-Liu/0000-0001-8086-0366; WU,
   Qi/0000-0003-0342-9366
FU U.S. Department of Energy [DE-SC0019486]; Intel oneAPI Center of
   Excellence grant
FX No Statement Available
CR Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580
   Brownlee C., 2021, Ray Tracing Gems II: Next Gener, P725, DOI [10.1007/978-1-4842-7185-8_45, DOI 10.1007/978-1-4842-7185-8_45]
   Crassin C., 2009, P 2009 S INT 3D GRAP, P15, DOI DOI 10.1145/1507149.1507152
   Engel K., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P123, DOI 10.1109/LDAV.2011.6092330
   Fogal T., 2010, P VIS MOD VIS WORKSH, P139, DOI DOI 10.2312/EGGH/HPG10/057-066
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gobbetti E, 2008, VISUAL COMPUT, V24, P797, DOI 10.1007/s00371-008-0261-9
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Hadadan S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480569
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Harris D., 2010, Digital design and computer architecture
   Hofmann N., 2021, Ray Tracing Gems, VII, P699
   Intel Corporation, 2022, Intel open volume kernel library
   Jain S., 2017, P LARG SCAL DAT AN V, P1187
   Kim D, 2024, Arxiv, DOI arXiv:2208.04448
   Kingma D. P., 2014, arXiv
   Klacansky P, Open Scientific Visualization Datasets
   Laine Samuli, 2013, Proceedings of the 5th High-Performance Graphics Conference, P137, DOI [10.1145/2492045.2492060, DOI 10.1145/2492045.2492060]
   LaMar E., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P355, DOI 10.1109/VISUAL.1999.809908
   Lee M, 2015, J FLUID MECH, V774, P395, DOI 10.1017/jfm.2015.268
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459812
   Muller Thomas, 2021, TINY CUDA NEURAL NET
   Novák J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661292
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pharr M., 2016, Physically based rendering: From theory to implementation
   Rieth M, 2022, COMBUST FLAME, V239, DOI 10.1016/j.combustflame.2021.111740
   Sarton J, 2020, IEEE T VIS COMPUT GR, V26, P3008, DOI 10.1109/TVCG.2019.2912752
   Sitzmann V, 2020, Adv. Neural. Inf. Process. Syst, V33, P7462
   Szirmay-Kalos L, 2011, COMPUT GRAPH FORUM, V30, P85, DOI 10.1111/j.1467-8659.2010.01831.x
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tancik M., 2020, ADV NEURAL INFORM PR, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1
   Vaswani A., 2017, Advances in neural information processing systems, P5998
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Woodcock E.R., 1965, PROC C APPL COMPUTIN, P557
   Wu Q., 2022, P EUR S PAR GRAPH VI, P37
   Wurster SW, 2023, IEEE T VIS COMPUT GR, V29, P5483, DOI 10.1109/TVCG.2022.3214420
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Zellmann S., 2022, P 22 EUR S PAR GRAPH, P61
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou ZL, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095178
   Zimmermann K., 2000, P IEEE S VOL VIS, P7
NR 52
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5404
EP 5418
DI 10.1109/TVCG.2023.3293121
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400056
PM 37418398
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Jiang, YR
   Chen, SY
   Fu, HB
   Gao, L
AF Jiang, Yue-Ren
   Chen, Shu-Yu
   Fu, Hongbo
   Gao, Lin
TI Identity-Aware and Shape-Aware Propagation of Face Editing in Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Videos; Shape; Faces; Three-dimensional displays; Codes; Aerospace
   electronics; Semantics; Editing propagation; face editing; video editing
ID MANIPULATION; IMAGE
AB The development of deep generative models has inspired various facial image editing methods, but many of them are difficult to be directly applied to video editing due to various challenges ranging from imposing 3D constraints, preserving identity consistency, ensuring temporal coherence, etc. To address these challenges, we propose a new framework operating on the StyleGAN2 latent space for identity-aware and shape-aware edit propagation on face videos. In order to reduce the difficulties of maintaining the identity, keeping the original 3D motion, and avoiding shape distortions, we disentangle the StyleGAN2 latent vectors of human face video frames to decouple the appearance, shape, expression, and motion from identity. An edit encoding module is used to map a sequence of image frames to continuous latent codes with 3D parametric control and is trained in a self-supervised manner with identity loss and triple shape losses. Our model supports propagation of edits in various forms: I. direct appearance editing on a specific keyframe, II. implicit editing of face shape via a given reference image, and III. existing latent-based semantic edits. Experiments show that our method works well for various forms of videos in the wild and outperforms an animation-based approach and the recent deep generative techniques.
C1 [Jiang, Yue-Ren; Chen, Shu-Yu; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100045, Peoples R China.
   [Jiang, Yue-Ren; Gao, Lin] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; City University of Hong Kong
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100045, Peoples R China.; Gao, L (corresponding author), Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
EM jiangyueren19s@ict.ac.cn; chenshuyu@ict.ac.cn; hongbofu@cityu.edu.hk;
   gaolin@ict.ac.cn
OI FU, Hongbo/0000-0002-0284-726X
FU National Natural Science Foundation of China [62102403, 61872440];
   Beijing Municipal Natural Science Foundation for Distinguished Young
   Scholars [JQ21013]; China Postdoctoral Science Foundation [2022M713205];
   Open Research Projects of Zhejiang Lab [2021KE0AB06]; Youth Innovation
   Promotion Association CAS; Centre for Applied Computing and Interactive
   Media (ACIM) of School of Creative Media, CityU
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62102403 and 61872440, in part by the
   Beijing Municipal Natural Science Foundation for Distinguished Young
   Scholars under Grant JQ21013, in part by China Postdoctoral Science
   Foundation under Grant 2022M713205, in part by the Open Research
   Projects of Zhejiang Lab under Grant 2021KE0AB06, in part by Youth
   Innovation Promotion Association CAS, and in part by the Centre for
   Applied Computing and Interactive Media (ACIM) of School of Creative
   Media, CityU.
CR Abdal R., 2020, P IEEECVF C COMPUTER, P8296
   Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Alaluf Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459805
   Alaluf Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6691, DOI 10.1109/ICCV48922.2021.00664
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bonettini N, 2021, INT C PATT RECOG, P5012, DOI 10.1109/ICPR48806.2021.9412711
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chai YJ, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0133-7
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Chen BJ, 2023, IEEE T VIS COMPUT GR, V29, P3617, DOI 10.1109/TVCG.2022.3166159
   Chen RW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2003, DOI 10.1145/3394171.3413630
   Chen SY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459760
   Collins E, 2020, PROC CVPR IEEE, P5770, DOI 10.1109/CVPR42600.2020.00581
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Denton E, 2020, Arxiv, DOI arXiv:1906.06439
   Ge WY, 2024, Arxiv, DOI arXiv:2110.03309
   Goetschalckx L, 2019, IEEE I CONF COMP VIS, P5743, DOI 10.1109/ICCV.2019.00584
   Harkonen E, 2020, C NEUR INF PROC SYST
   He Zhenliang, 2021, P IEEECVF INT C COMP, P14408
   Heusel M., 2017, NeurIPS, P6629
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336
   Jiang K, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555377
   Jiang WT, 2020, PROC CVPR IEEE, P5193, DOI 10.1109/CVPR42600.2020.00524
   Kagaya M, 2011, IEEE T VIS COMPUT GR, V17, P74, DOI 10.1109/TVCG.2010.25
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2021, ADV NEUR IN, V34
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kasten Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480546
   Lei CY, 2019, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2019.00387
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li XY, 2022, IEEE T VIS COMPUT GR, V28, P2938, DOI 10.1109/TVCG.2021.3049419
   Ling JW, 2023, IEEE T VIS COMPUT GR, V29, P3630, DOI 10.1109/TVCG.2022.3166666
   Liu FL, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530056
   Ma LQ, 2012, COMPUT GRAPH-UK, V36, P1005, DOI 10.1016/j.cag.2012.08.001
   Mallikarjun BR, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459765
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Roich D, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3544777
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Saharia C, 2023, IEEE T PATTERN ANAL, V45, P4713, DOI 10.1109/TPAMI.2022.3204461
   Shen Y., 2020, P IEEECVF C COMPUTER, P9243
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Shi M, 2023, IEEE T VIS COMPUT GR, V29, P2965, DOI 10.1109/TVCG.2022.3146000
   Shu YZ, 2022, IEEE T VIS COMPUT GR, V28, P3376, DOI 10.1109/TVCG.2021.3067201
   Siarohin A., 2019, ADV NEURAL INFORM PR, V32, P7137
   Su WC, 2023, IEEE T VIS COMPUT GR, V29, P4074, DOI 10.1109/TVCG.2022.3178734
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Tewari A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417803
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Texler O, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392453
   Nguyen T, 2021, PROC CVPR IEEE, P13300, DOI 10.1109/CVPR46437.2021.01310
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Tzaban R, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555382
   Voynov A., 2022, arXiv
   Wang T.-C., 2019, P ADV NEUR INF PROC, P5013
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Yuxiang, 2021, P IEEECVF INT C COMP, P6721
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Wu ZZ, 2021, PROC CVPR IEEE, P12858, DOI 10.1109/CVPR46437.2021.01267
   Xiao CX, 2011, IEEE T VIS COMPUT GR, V17, P1135, DOI 10.1109/TVCG.2010.125
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
   Yao X., 2021, P IEEECVF INT C COMP, P13789
   Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou Peng, 2021, arXiv
   Zhu YH, 2021, PROC CVPR IEEE, P4832, DOI 10.1109/CVPR46437.2021.00480
   Zhuang JT, 2020, ADV NEUR IN, V33
NR 74
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3444
EP 3456
DI 10.1109/TVCG.2023.3235364
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700019
PM 37018564
DA 2024-08-05
ER

PT J
AU Ma, XH
   Yu, YX
   Wu, HZ
   Zhou, K
AF Ma, Xiaohe
   Yu, Yaxin
   Wu, Hongzhi
   Zhou, Kun
TI Efficient Reflectance Capture With a Deep Gated Mixture-of-Experts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Image reconstruction; Decoding; Optimization; Light emitting
   diodes; Cameras; Neural networks; Anisotropic reflectance; computational
   illumination; SVBRDF
ID REPRESENTATION; APPEARANCE
AB We present a novel framework to efficiently acquire anisotropic reflectance in a pixel-independent fashion, using a deep gated mixture-of-experts. While existing work employs a unified network to handle all possible input, our network automatically learns to condition on the input for enhanced reconstruction. We train a gating module that takes photometric measurements as input and selects one out of a number of specialized decoders for reflectance reconstruction, essentially trading generality for quality. A common pre-trained latent-transform module is also appended to each decoder, to offset the burden of the increased number of decoders. In addition, the illumination conditions during acquisition can be jointly optimized. The effectiveness of our framework is validated on a wide variety of challenging near-planar samples with a lightstage. Compared with the state-of-the-art technique, our quality is improved with the same number of input images, and our input image number can be reduced to about 1/3 for equal-quality results. We further generalize the framework to enhance a state-of-the-art technique on non-planar reflectance scanning.
C1 [Ma, Xiaohe; Yu, Yaxin; Wu, Hongzhi; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
   [Zhou, Kun] ZJU FaceUn Joint Lab Intelligent G, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Wu, HZ (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
EM xiaohema1998@gmail.com; 22021283@zju.edu.cn; hwu@acm.org;
   kunzhou@acm.org
OI Ma, Xiaohe/0009-0000-8924-2046
FU NSF China [62022072, 62227806]; Zhejiang Provincial Key RD Program
   [2022C01057]; XPLORER PRIZE
FX This work was partially supported in part by NSF China under Grants
   62022072 & 62227806, in part by Zhejiang Provincial Key R&D Program
   under Grant 2022C01057, and in part by the XPLORER PRIZE
CR Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917
   Aittala M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766967
   Aittala M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461978
   Chen GJ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601180
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dong Y, 2019, VIS INFORM, V3, P59, DOI 10.1016/j.visinf.2019.07.003
   Dong Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778835
   Gao D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417767
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Ghosh A, 2009, COMPUT GRAPH FORUM, V28, P1161, DOI 10.1111/j.1467-8659.2009.01493.x
   Guarnera D, 2016, COMPUT GRAPH FORUM, V35, P625, DOI 10.1111/cgf.12867
   Guo J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459854
   Guo J, 2020, IEEE T VIS COMPUT GR, V26, P1476, DOI 10.1109/TVCG.2018.2872709
   Guo Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417779
   Henzler P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480507
   Hu BY, 2020, COMPUT GRAPH FORUM, V39, P157, DOI 10.1111/cgf.13920
   Hui Z, 2017, IEEE I CONF COMP VIS, P5372, DOI 10.1109/ICCV.2017.573
   Kang KZ, 2023, IEEE T VIS COMPUT GR, V29, P1450, DOI 10.1109/TVCG.2021.3117370
   Kang KZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356492
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949
   Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Morales JL, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049669
   Ma XH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459679
   Marschner SR, 1999, SPRING EUROGRAP, P131
   Nam G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275017
   Nam G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980220
   Rainer G, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13921
   Ren PR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964940
   Riquelme C, 2021, Arxiv, DOI [arXiv:2106.05974, arXiv:2106.05974]
   Shazeer Noam, 2017, arXiv, DOI DOI 10.48550/ARXIV.1701.06538
   Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944
   Walter B., 2007, P 18 EUR C REND TECH, P195, DOI [10.2312/EGWR/EGSR07/195-206, DOI 10.2312/EGWR/EGSR07/195-206]
   Wang JP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360640
   Weinmann R., 2015, SIGGRAPH Asia Courses
   Weyrich T, 2008, FOUND TRENDS COMPUT, V4, P75, DOI 10.1561/0600000022
   Zhou XL, 2021, COMPUT GRAPH FORUM, V40, P315, DOI 10.1111/cgf.142635
NR 41
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4246
EP 4256
DI 10.1109/TVCG.2023.3261872
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700053
PM 37030776
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Song, SC
   Li, CH
   Li, D
   Chen, JT
   Wang, CB
AF Song, Sicheng
   Li, Chenhui
   Li, Dong
   Chen, Juntong
   Wang, Changbo
TI GraphDecoder: Recovering Diverse Network Graphs From Visualization
   Images via Attention-Aware Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Attention mechanism; chart mining; information visualization; network
   graph; semantic segmentation
ID CHART IMAGES; INFORMATION; RELIABILITY; EXTRACTION; FIGURES
AB DNGs are diverse network graphs with texts and different styles of nodes and edges, including mind maps, modeling graphs, and flowcharts. They are high-level visualizations that are easy for humans to understand but difficult for machines. Inspired by the process of human perception of graphs, we propose a method called GraphDecoder to extract data from raster images. Given a raster image, we extract the content based on a neural network. We built a semantic segmentation network based on U-Net. We increase the attention mechanism module, simplify the network model, and design a specific loss function to improve the model's ability to extract graph data. After this semantic segmentation network, we can extract the data of all nodes and edges. We then combine these data to obtain the topological relationship of the entire DNG. We also provide an interactive interface for users to redesign the DNGs. We verify the effectiveness of our method by evaluations and user studies on datasets collected on the internet and generated datasets.
C1 [Song, Sicheng; Li, Chenhui; Li, Dong; Chen, Juntong; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
C3 East China Normal University
RP Li, CH; Wang, CB (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
EM scsong@stu.ecnu.edu.cn; chli@cs.ecnu.edu.cn;
   51194501141@stu.ecnu.edu.cn; jtchen@stu.ecnu.edu.cn;
   cbwang@cs.ecnu.edu.cn
RI Chen, Juntong/KBV-8278-2024
OI Chen, Juntong/0000-0001-9343-4032; Li, Chenhui/0000-0001-9835-2650;
   Wang, Changbo/0000-0001-8940-6418
FU NSFC [62072183]
FX This work was supported by the NSFC under Grant 62072183.
CR Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Alper B., 2013, P 2013 ANN C HUM FAC, P483
   ANTV, 2018, About us
   Auer C., 2012, P INT S GRAPH DRAW, P529
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balaji A, 2018, Arxiv, DOI arXiv:1812.10636
   Berlingerio M, 2012, Arxiv, DOI arXiv:1209.2684
   Böschen F, 2018, MULTIMED TOOLS APPL, V77, P29475, DOI 10.1007/s11042-018-6162-7
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brynjolfsson E, 2016, AM ECON REV, V106, P133, DOI 10.1257/aer.p20161016
   Burns R, 2019, COMPUT INTELL-US, V35, P955, DOI 10.1111/coin.12227
   Buzan T., 1983, Use Both Sides of Your Brain
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Chollet F., 2015, Keras
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cleveland W. S., 1985, The Elements of Graphing Data
   Cook C, 2001, EDUC PSYCHOL MEAS, V61, P697, DOI 10.1177/00131640121971356
   Dai WJ, 2018, J VISUAL LANG COMPUT, V48, P101, DOI 10.1016/j.jvlc.2018.08.005
   datadigitization, 2021, Dagra data digitizer
   Davila K, 2021, IEEE T PATTERN ANAL, V43, P3799, DOI 10.1109/TPAMI.2020.2992028
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   De P, 2018, IEEE INT ADV COMPUT, P20, DOI 10.1109/IADCC.2018.8692104
   Flower A, 2016, BEHAV MODIF, V40, P396, DOI 10.1177/0145445515616105
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Giovannangeli L, 2020, VIS INFORM, V4, P86, DOI 10.1016/j.visinf.2020.04.002
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Hu J., 2018, SQUEEZE AND EXCITATI, P7132
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kadic AJ, 2016, J CLIN EPIDEMIOL, V74, P119, DOI 10.1016/j.jclinepi.2016.01.002
   Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim D, 2018, PROC CVPR IEEE, P4167, DOI 10.1109/CVPR.2018.00438
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P465, DOI 10.1007/978-981-15-3863-6_51
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MN, 2019, SOC SCI COMPUT REV, V37, P248, DOI 10.1177/0894439318755336
   Liu X., 2019, arXiv
   Liu Y, 2013, PROC SPIE, V8654, DOI 10.1117/12.2008467
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo JY, 2021, IEEE WINT CONF APPL, P1916, DOI 10.1109/WACV48630.2021.00196
   Ma KF, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540016
   Manolis Savva, 2011, P 24 ANN ACM S USER, P393
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Mitchell M., 2020, Markummitchell/engauge-digitizer: Non- release, DOI [10.5281/zenodo.3941227, DOI 10.5281/ZENODO.3941227]
   Molla MKI, 2003, LECT NOTES COMPUT SC, V2690, P865
   Nassi I., 1973, SIGPLAN Notices, V8, P12, DOI 10.1145/953349.953350
   Oktay O., 2018, P 1 C MED IM DEEP LE, P1, DOI 10.48550/arXiv.1804.03999
   Oldenhof M, 2020, J CHEM INF MODEL, V60, P4506, DOI 10.1021/acs.jcim.0c00459
   Opmanis R., 2018, P 13 INT JOINT C COM, P184
   Pin-Shan Chen P., 1976, ACM Transactions on Database Systems, V1, P9, DOI 10.1145/320434.320440
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Reddy VK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P190, DOI 10.1109/CGVIS.2015.7449920
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song S., IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3153514.2I, DOI 10.1109/TVCG.2022.3153514.2I]
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   WILDER RL, 1978, AM MATH MON, V85, P720, DOI 10.2307/2321676
   Wu J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1200
   Wu RQ, 2009, J COMPUT SCI TECHNOL, V9, P58
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Yun XL, 2019, LECT NOTES COMPUT SC, V11901, P232, DOI 10.1007/978-3-030-34120-6_19
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
   Zhou FF, 2021, J VISUAL-JAPAN, V24, P419, DOI 10.1007/s12650-020-00702-6
NR 84
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3074
EP 3088
DI 10.1109/TVCG.2022.3225554
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700086
PM 36449586
DA 2024-08-05
ER

PT J
AU Jeong, S
   Kim, J
   Lee, J
AF Jeong, Sihyun
   Kim, Jinwook
   Lee, Jeongmi
TI The Differential Effects of Multisensory Attentional Cues on Task
   Performance in VR Depending on the Level of Cognitive Load and Cognitive
   Capacity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Cognitive load; Visualization; Particle measurements;
   Atmospheric measurements; Search problems; Usability; Virtual Reality;
   Performance; Cognitive Load; Multisensory; Attentional Cue; Cognitive
   Capacity
ID WORKING-MEMORY; GAME; METAANALYSIS; KNOWLEDGE; TACTILE; SEARCH; AGE
AB As the utilization of VR is expanding across diverse fields, research on devising attentional cues that could optimize users' task performance in VR has become crucial. Since the cognitive load imposed by the context and the individual's cognitive capacity are representative factors that are known to determine task performance, we aimed to examine how the effects of multisensory attentional cues on task performance are modulated by the two factors. For this purpose, we designed a new experimental paradigm in which participants engaged in dual (N-back, visual search) tasks under different levels of cognitive load while an attentional cue (visual, tactile, or visuotactile) was presented to facilitate search performance. The results showed that multi-sensory attentional cues are generally more effective than uni-sensory cues in enhancing task performance, but the benefit of multi-sensory cues changes according to the level of cognitive load and the individual's cognitive capacity; the amount of benefit increases as the cognitive load is higher and the cognitive capacity is lower. The findings of this study provide practical implications for designing attentional cues to enhance VR task performance, considering both the complexity of the VR context and users' internal characteristics.
C1 [Jeong, Sihyun; Kim, Jinwook; Lee, Jeongmi] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, J (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM sihyunlyujeong@gmail.com; jinwook.kim31@kaist.ac.kr; jeongmi@kaist.ac.kr
RI ; Lee, Jeongmi/D-1912-2018
OI Kim, Jinwook/0000-0002-1962-5815; Lee, Jeongmi/0000-0002-3403-8117;
   Jeong, Sihyun/0000-0002-5690-7213
FU National Research Foundation of Korea
FX No Statement Available
CR Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Bailey R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559757
   Bediou B, 2018, PSYCHOL BULL, V144, P77, DOI 10.1037/bul0000130
   Boot WR, 2008, ACTA PSYCHOL, V129, P387, DOI 10.1016/j.actpsy.2008.09.005
   BRITTON BK, 1982, J VERB LEARN VERB BE, V21, P421, DOI 10.1016/S0022-5371(82)90709-5
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Chiossi Y., 2023, Proc. ACM Hum.-Comput. Interact, V7
   Chittaro L., Proceedings of the Working Conference on Advanced Visual Interfaces, ser. AVI '04. New York, NY, USA: ACM, P267
   Colzato LS, 2013, PSYCHOL RES-PSYCH FO, V77, P234, DOI 10.1007/s00426-012-0415-2
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Gateau T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121279
   Gray R, 2002, EXP BRAIN RES, V145, P50, DOI 10.1007/s00221-002-1085-x
   Greenwood PM, 1999, PERCEPT PSYCHOPHYS, V61, P837, DOI 10.3758/BF03206901
   Grogorick S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P563, DOI 10.1109/VR.2018.8446215
   Hamad A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191811278
   Hambrick DZ, 2002, COGNITIVE PSYCHOL, V44, P339, DOI 10.1006/cogp.2001.0769
   Hart S., 1982, INEIGHTH S PSYCHOL D, P478
   Hart S. G., 2006, PROCEEDINGSOF HUMAN, V50, P2
   Hart S.G., 1986, Human Productivity Enhancement, P396
   Hauck C, 2022, PSYCHOL RES-PSYCH FO, V86, P2128, DOI 10.1007/s00426-021-01640-0
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122
   Kane MJ, 2007, J EXP PSYCHOL LEARN, V33, P615, DOI 10.1037/0278-7393.33.3.615
   Kim J, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0261298
   KIRCHNER WK, 1958, J EXP PSYCHOL, V55, P352, DOI 10.1037/h0043688
   Kosch T, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3582272
   Lange T. C., 2020, INPROCEEDINGS THE202, P1
   Lee BC, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101780
   Li G, 2020, J COGNITIVE NEUROSCI, V32, P1438, DOI 10.1162/jocn_a_01560
   Liu JS, 2021, IEEE T VIS COMPUT GR, V27, P4311, DOI 10.1109/TVCG.2021.3106476
   Longstaffe KA, 2014, ATTEN PERCEPT PSYCHO, V76, P49, DOI 10.3758/s13414-013-0575-1
   Marner MR, 2013, INT SYM MIX AUGMENT, P39, DOI 10.1109/ISMAR.2013.6671762
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Matthews F. Tian, 2020, Virtual Reality Intelligent Hardware, P330, DOI DOI 10.1016/J.VRIH.2020.07.006
   Michail G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30007-6
   Miyake S, 2001, INT J PSYCHOPHYSIOL, V40, P233, DOI 10.1016/S0167-8760(00)00191-4
   Ngo MK, 2010, ATTEN PERCEPT PSYCHO, V72, P1654, DOI 10.3758/APP.72.6.1654
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Peng C, 2019, IEEE ACCESS, V7, P68878, DOI 10.1109/ACCESS.2019.2918846
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.neuro.13.1.25
   pro Andrius Productions, 2016, Unity asset store, proprototype collection
   Putze F, 2019, IEEE ENG MED BIO, P3103, DOI [10.1109/embc.2019.8856386, 10.1109/EMBC.2019.8856386]
   Ramkumar A, 2017, INT J HUM-COMPUT INT, V33, P123, DOI 10.1080/10447318.2016.1220729
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Soret P., 2019, INPROCEEDINGS 11 ACM, P1
   Soto-Faraco S, 2005, PSYCHON B REV, V12, P1024, DOI 10.3758/BF03206438
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Steenbergen L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144364
   Stock AK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04828-w
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Talsma D, 2005, J COGNITIVE NEUROSCI, V17, P1098, DOI 10.1162/0898929054475172
   Tiraboschi GA, 2019, J COGN ENHANCE, V3, P436, DOI 10.1007/s41465-019-00130-x
   Townsend F. G., 1983, CUP Archive, V5, P6
   Trejo N. J., 2007, Foundations of Augmented Cognition, P13
   Unsworth N, 2015, PSYCHOL SCI, V26, P759, DOI 10.1177/0956797615570367
   van Ede F, 2012, J NEUROSCI, V32, P10408, DOI 10.1523/JNEUROSCI.1337-12.2012
   Wan CJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18375-y
   Whelan R. R., 2007, nEducational Research Review, P1
   Wickens C.D., 1991, Multiple-task performance, P3
   Wickens CD, 2008, HUM FACTORS, V50, P449, DOI 10.1518/001872008X288394
   Yuan B, 2011, UNIVERSAL ACCESS INF, V10, P81, DOI 10.1007/s10209-010-0189-5
   Zagermann J, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P78, DOI 10.1145/2993901.2993908
   Zhang XC, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142416727
   Ziv R., 2022, Scientific Reports, V12, P2
NR 68
TC 1
Z9 1
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2703
EP 2712
DI 10.1109/TVCG.2024.3372126
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400051
PM 38437135
DA 2024-08-05
ER

PT J
AU Saeedpour-Parizi, MR
   Williams, NL
   Wong, TM
   Guan, PL
   Manocha, D
   Erkelens, IM
AF Saeedpour-Parizi, Mohammad R.
   Williams, Niall L.
   Wong, Tim
   Guan, Phillip
   Manocha, Dinesh
   Erkelens, Ian M.
TI Perceptual Thresholds for Radial Optic Flow Distortion in Near-Eye
   Stereoscopic Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Radial optic flow; perceptual thresholds; motion perception;
   vergence-accommodation conflict; blink suppression
ID INDIVIDUAL-DIFFERENCES; VIRTUAL ENVIRONMENTS; SIMULATOR SICKNESS;
   SENSITIVITY; MOTION
AB We provide the first perceptual quantification of user's sensitivity to radial optic flow artifacts and demonstrate a promising approach for masking this optic flow artifact via blink suppression. Near-eye HMOs allow users to feel immersed in virtual environments by providing visual cues, like motion parallax and stereoscopy, that mimic how we view the physical world. However, these systems exhibit a variety of perceptual artifacts that can limit their usability and the user's sense of presence in VR. One well-known artifact is the vergence-accommodation conflict (VAC). Varifocal displays can mitigate VAC, but bring with them other artifacts such as a change in virtual image size (radial optic flow) when the focal plane changes. We conducted a set of psychophysical studies to measure users' ability to perceive this radial flow artifact before, during, and after self-initiated blinks. Our results showed that visual sensitivity was reduced by a factor of 10 at the start and for similar to 70 ms after a blink was detected. Pre- and post-blink sensitivity was, on average, similar to 0.15% image size change during normal viewing and increased to similar to 1.5- 2.0% during blinks. Our results imply that a rapid (under 70 ms) radial optic flow distortion can go unnoticed during a blink. Furthermore, our results provide empirical data that can be used to inform engineering requirements for both hardware design and software-based graphical correction algorithms for future varifocal near-eye displays. Our project website is available at https://gamma.umd.edu/ROF/.
C1 [Saeedpour-Parizi, Mohammad R.; Wong, Tim; Guan, Phillip; Erkelens, Ian M.] Meta Real Labs Res, Burlingame, CA USA.
   [Williams, Niall L.; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Williams, NL (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM rezasaeedpour@meta.com; niallw.phd@gmail.com; tlwong@meta.com;
   philguan@meta.com; dmanocha@umd.edu; ian.erkelens@meta.com
OI Manocha, Dinesh/0000-0001-7047-9801
FU Link Foundation Modeling, Simulation, Training
FX No Statement Available
CR Adier R. A., 1970, Physiology of the Eye: Clinical Applica non, P3
   Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Ang JWA, 2020, J VISION, V20, DOI 10.1167/jov.20.10.2
   Barfield W., 1995, Virmal Reality, V1, P1
   Bax M. R., 2002, IMAGE, P9
   Bharadwaj SR, 2009, J VISION, V9, DOI 10.1167/9.11.4
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bristow D, 2005, CURR BIOL, V15, P1296, DOI 10.1016/j.cub.2005.06.025
   Bruce V., 2003, Visuti perception: Physiology, psychology, & ecology, P2
   Clifford CWG, 1999, VISION RES, V39, P2213, DOI 10.1016/S0042-6989(98)00314-9
   Cuturi L. E., 2014, Current Biology, V24, P3
   Doughty MJ, 2002, OPTOMETRY VISION SCI, V79, P439, DOI 10.1097/00006324-200207000-00013
   Ehrenstein W. IL, 1999, Modern techniques in neuroscience research, P2
   Erketens M., 2020, SID S, V51, P2
   FREEMAN TCA, 1992, VISION RES, V32, P81, DOI 10.1016/0042-6989(92)90115-Y
   Gescheider G. A., 2013, Psychophysics: the fundamentals, V1, P2
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Goettker A, 2020, J SOC INF DISPLAY, V28, P509, DOI 10.1002/jsid.912
   Guan P., 2022, ACM SIGGRAPH 2022 C, V2, P4
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Hettinger J., 1992, Presence, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Holmqvist K., 2017, Faradigms and measures, V3, P5
   Hoppe D, 2018, P NATL ACAD SCI USA, V115, P2246, DOI 10.1073/pnas.1714220115
   Hung G. K., 1989, Experimenial neumlogy, V105, P8
   HUNG GK, 1990, EXP NEUROL, V110, P291, DOI 10.1016/0014-4886(90)90041-P
   Jones JA, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS, P77, DOI 10.1109/CTS.2015.7210403
   Joshi MR, 2015, VISION RES, V110, P68, DOI 10.1016/j.visres.2015.03.006
   Keeley S., 2023, P AAAI C ARTIFICIAL, V37, P40
   Kennedy R. S., 2010, Applied ergonomics, V41, P3
   Kooijman L, 2024, BEHAV RES METHODS, V56, P2292, DOI 10.3758/s13428-023-02148-8
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lafer-Sousa R, 2015, CURR BIOL, V25, pR545, DOI 10.1016/j.cub.2015.04.053
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Lappe M, 1999, TRENDS COGN SCI, V3, P329, DOI 10.1016/S1364-6613(99)01364-9
   LaValle S. M., 2023, Virtual reality, P2
   Lee B, 2020, PROC SPIE, V11304, DOI 10.1117/12.2551400
   Leigh R. J., 2015, Contemporary Neurology, P3
   LIEBERMAN HR, 1982, BEHAV RES METH INSTR, V14, P21, DOI 10.3758/BF03202110
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   LUCE RD, 1958, PSYCHOL REV, V65, P222, DOI 10.1037/h0039821
   Lueder E, 2012, WILEY-SID SER DISPL, P1
   MANNING KA, 1984, VISION RES, V24, P521, DOI 10.1016/0042-6989(84)90105-6
   MORRONE MC, 1995, NATURE, V376, P507, DOI 10.1038/376507a0
   Nakano T, 2009, P ROY SOC B-BIOL SCI, V276, P3635, DOI 10.1098/rspb.2009.0828
   Nguyen A., 2018, P 24 ACM S VIRM REAL, P3
   Nguyen A., 2020, P 26 ACM S VIRM REAL, P1
   Owen L, 2021, Arxiv, DOI arXiv:2104.09549
   Piszczek M., 2023, Compensation of magnification variations in varifocal hmds by using a virtual camera, P2
   Rambold H, 2002, J NEUROPHYSIOL, V88, P1220, DOI 10.1152/jn.2002.88.3.1220
   Regan D., 1985, JOSA A, P3
   Robinett W., 1992, Presence: Teleoperators & VirmalEnvironmenis, V1, P6
   Rolland J. P., 1993, Citeseer, P6
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Snowden RJ, 1996, J COGNITIVE NEUROSCI, V8, P435, DOI 10.1162/jocn.1996.8.5.435
   Snowden RJ, 1997, CURR BIOL, V7, P717, DOI 10.1016/S0960-9822(06)00329-0
   TOATES FM, 1972, PHYSIOL REV, V52, P828, DOI 10.1152/physrev.1972.52.4.828
   Tyler CW, 2012, J VISION, V12, DOI 10.1167/12.11.21
   VOLKMANN FC, 1986, VISION RES, V26, P1401, DOI 10.1016/0042-6989(86)90164-1
   WATSON BA, 1995, VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM '95, PROCEEDINGS, P172
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Williams N. L., 2019, IEEE transactions on visualizazion and computer graphics, V25, P8
   WITKIN HA, 1949, J PERS, V18, P145, DOI 10.1111/j.1467-6494.1949.tb01237.x
   Zenner A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580888
   Zenner A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P75, DOI 10.1109/VR50410.2021.00028
   Zhan T., 2020, PhooniX, V1, P6
   Zhan T, 2020, ADV OPT MATER, V8, DOI 10.1002/adom.201901360
   Zhao Y., 2023, ACM SIGGRAPH 2023 Emerging Technologies 1-3, P1
NR 68
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2570
EP 2579
DI 10.1109/TVCG.2024.3372075
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400019
PM 38437086
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Cabric, F
   Bjarnadóttir, MV
   Ling, M
   Rafnsdóttir, GL
   Isenberg, P
AF Cabric, Florent
   Bjarnadottir, Margret Vilborg
   Ling, Meng
   Rafnsdottir, Guobjorg Linda
   Isenberg, Petra
TI Eleven Years of Gender Data Visualization: A Step Towards More Inclusive
   Gender Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; gender; visual gender representation; ethics
ID COLOR; CATEGORIES; SEX
AB We present an analysis of the representation of gender as a data dimension in data visualizations and propose a set of considerations around visual variables and annotations for gender-related data. Gender is a common demographic dimension of data collected from study or survey participants, passengers, or customers, as well as across academic studies, especially in certain disciplines like sociology. Our work contributes to multiple ongoing discussions on the ethical implications of data visualizations. By choosing specific data, visual variables, and text labels, visualization designers may, inadvertently or not, perpetuate stereotypes and biases. Here, our goal is to start an evolving discussion on how to represent data on gender in data visualizations and raise awareness of the subtleties of choosing visual variables and words in gender visualizations. In order to ground this discussion, we collected and coded gender visualizations and their captions from five different scientific communities (Biology, Politics, Social Studies, Visualisation, and Human-Computer Interaction), in addition to images from Tableau Public and the Information Is Beautiful awards showcase. Overall we found that representation types are community-specific, color hue is the dominant visual channel for gender data, and nonconforming gender is under-represented. We end our paper with a discussion of considerations for gender visualization derived from our coding and the literature and recommendations for large data collection bodies. A free copy of this paper and all supplemental materials are available at https://osf.io/v9ams/.
C1 [Cabric, Florent; Isenberg, Petra] Univ Paris Saclay, CNRS, Inria, LISN, Paris, France.
   [Bjarnadottir, Margret Vilborg] Univ Maryland, Robert H Smith Sch Business, College Pk, MD USA.
   [Ling, Meng] Ohio State Univ, Columbus, OH USA.
   [Rafnsdottir, Guobjorg Linda] Univ Iceland, Fac Social & Human Sci, Reykjavik, Iceland.
C3 Universite Paris Saclay; Universite Paris Cite; Centre National de la
   Recherche Scientifique (CNRS); Inria; University System of Maryland;
   University of Maryland College Park; University System of Ohio; Ohio
   State University; University of Iceland
RP Cabric, F (corresponding author), Univ Paris Saclay, CNRS, Inria, LISN, Paris, France.
EM florent.cabric@inria.fr; mbjarnad@umd.edu; ling.253@osu.edu; glr@hi.is;
   petra.isenberg@inria.fr
OI Ling, Meng/0000-0001-6597-5448; Rafnsdottir, Gudbjorg
   LINDA/0000-0003-2662-5773; Isenberg, Petra/0000-0002-2948-6417
FU Inria
FX No Statement Available
CR Aikhenvald A. Y., 2016, How gender shapes theworld, DOI DOI 10.1093/ACPROF:OSO/9780198723752.001.0001
   Ainsworth C, 2015, NATURE, V518, P288, DOI 10.1038/518288a
   [Anonymous], 2012, Sex Roles, P3
   [Anonymous], 2012, P C HUMAN FACTORS CO
   [Anonymous], 2012, Biology of Sex Differences, P3
   [Anonymous], 2012, Politics & Gender, P3
   Bauer GR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178043
   Baumer EPS, 2022, COMPUT GRAPH FORUM, V41, P1, DOI 10.1111/cgf.14518
   Beeckman M. S., 2021, Colornamer-r package
   Beischel WJ, 2021, PSYCHOL SEX ORIENTAT, V8, P1, DOI 10.1037/sgd0000449
   Bertin J., 2011, Semiology of Graphics: Diagrams Networks Maps, P3
   Bolin A., 1999, Perspectives on Human Sexuality, P5
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2476, DOI 10.1109/TVCG.2013.155
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bradley A., 2015, P 41 GRAPHICS INTERF, P9
   Brown T. N., Exploring international priorities and best practices for the collection of data about gender minorities a focus on south america
   Cecchini M, 2019, SOCIETIES, V9, DOI 10.3390/soc9040079
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Colaco R., 2021, A global call to action for gender-inclusive data collection and use, DOI DOI 10.3768/RTIPRESS.2021.PB.0026.2112
   Colmenarejo AB, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P107, DOI 10.1145/3514094.3534158
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Cover R., 2018, EMERGENT IDENTITIES, DOI [DOI 10.4324/9781315104348, 10.4324/9781315104348]
   Cunningham SJ, 2011, BRIT J PSYCHOL, V102, P598, DOI 10.1111/j.2044-8295.2011.02023.x
   Data Visualization Society, Information Is Beautiful Awards
   Demir Ü, 2020, COLOR RES APPL, V45, P871, DOI 10.1002/col.22522
   Dhawka P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581086
   Diekman A. B., 2010, The Sage Handbook of Prejudice, Stereotyping, and Discrimination, DOI [DOI 10.4135/9781446200919.N13, 10.4135/9781446200919.n132, DOI 10.4135/9781446200919.N132]
   DIgnazio C., 2020, Strong Ideas Series, DOI DOI 10.7551/MITPRESS/11805.001.00011,2
   Dork Marian., 2013, Conference on Human Factors in Computing Systems, P2189, DOI DOI 10.1145/2468356.2468739
   Dragga S, 2001, TECH COMMUN, V48, P265
   Federal Statistical Surveys of USA, 2023, Recommendations on the best practices for the collection of sexual orientation and gender identity data on federal statistical surveys
   Floricel C, 2022, IEEE T VIS COMPUT GR, V28, P151, DOI 10.1109/TVCG.2021.3114810
   Fortmann-Roe S, 2013, COLOR RES APPL, V38, P196, DOI 10.1002/col.20734
   Fugate JMB, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00206
   Haines EL, 2016, PSYCHOL WOMEN QUART, V40, P353, DOI 10.1177/0361684316634081
   Haslanger S., 2017, Applied Ethics, V6th, P2
   Hawkins J. K., 1970, Picture Processing and Psychopictorics, P4
   Hidalgo C., DATA USA
   Holman L, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004956
   Hyde JS, 2019, AM PSYCHOL, V74, P171, DOI 10.1037/amp0000307
   IEEE VIS, 2012, Visualization & Visual Analytics
   Isenberg P, 2011, IEEE T VIS COMPUT GR, V17, P2469, DOI 10.1109/TVCG.2011.160
   It's Pronounced Metrosexual, 2018, The genderbread person v4
   Janosko J., 2020, 2020 gender rates and totals
   Jonauskaite D, 2019, SEX ROLES, V80, P630, DOI 10.1007/s11199-018-0955-z
   Karniol R, 2011, SEX ROLES, V65, P119, DOI 10.1007/s11199-011-9989-1
   Kliger D, 2012, J SOCIO-ECON, V41, P738, DOI 10.1016/j.socec.2012.07.003
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   LoBue V, 2011, BRIT J DEV PSYCHOL, V29, P656, DOI 10.1111/j.2044-835X.2011.02027.x
   McElroy D., 2020, Signs & Symbols of the World: Over 1,001 Visual Signs Explained. Complete Illustrated Encyclopedia, P5
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Mochizuki M, 2023, CURR PSYCHOL, V42, P31590, DOI 10.1007/s12144-022-04179-4
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Muehlenhard CL, 2011, SEX ROLES, V64, P791, DOI 10.1007/s11199-011-9932-5
   Munzner T., 2014, A K Peters Visualization Series, V1st, DOI DOI 10.1201/B175118
   Muth L. C., 2018, An alternative to pink & blue: Colors for gender data
   Nash J, 2023, J BRAND MANAG, DOI 10.1057/s41262-023-00310-3
   Nelson R, 2023, CULT HEALTH SEX, V25, P711, DOI 10.1080/13691058.2022.2092213
   Offenwanger A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445383
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Pinna B., 2011, Gestalt Theory, V33, P8
   Robards B., 2020, Tumblr as a Space of Learning, Connecting, and Identity Formation for LGBTIQ+ Young People, P281, DOI DOI 10.3998/MPUB.115370552
   Rogowitz B. E., 2019, Diversity in Visualization, Synthesis Lectures on Visualization, P63, DOI DOI 10.2200/S00894ED1V01Y201901VIS0102
   Sarvghad A, 2023, IEEE T VIS COMPUT GR, V29, P3340, DOI 10.1109/TVCG.2022.3158236
   Scheuerman M. K., 2021, P C HUMAN FACTORS CO, DOI DOI 10.1145/3411764.34457428,9
   Schwabish J., 2021, Do no harm guide: applying equity awareness in data visualization
   Semin GR, 2014, J CONSUM PSYCHOL, V24, P217, DOI 10.1016/j.jcps.2013.09.003
   Stroessner SJ, 2020, J EXP SOC PSYCHOL, V87, DOI 10.1016/j.jesp.2019.103915
   Sugimoto CR, 2013, NATURE, V504, P211, DOI 10.1038/504211a
   Szafir D. A., 2018, Interactions, V25, P26, DOI [DOI 10.1145/3231772, 10.1145/32317721, DOI 10.1145/32317721]
   Tableau Software LLC, Tableau public
   Tate CC, 2013, J SEX RES, V50, P767, DOI 10.1080/00224499.2012.690110
   Tovanich N, 2022, IEEE T VIS COMPUT GR, V28, P497, DOI 10.1109/TVCG.2021.3114787
   Trans Student Educational Resources, 2015, GEND UN
   Trimm D, 2012, IEEE T VIS COMPUT GR, V18, P2809, DOI 10.1109/TVCG.2012.288
   UK, 2010, Types of discrimination ('protected characteristics')
   USA, Types of discrimination ('protected characteristics')
   van Tilburg M, 2015, PSYCHOL MARKET, V32, P422, DOI 10.1002/mar.20789
   Vivienne S, 2023, J GENDER STUD, V32, P498, DOI 10.1080/09589236.2021.2000852
   Wall E, 2022, IEEE T VIS COMPUT GR, V28, P966, DOI 10.1109/TVCG.2021.3114862
   Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275
   Westbrook L, 2015, GENDER SOC, V29, P534, DOI 10.1177/0891243215584758
   Winter S, 2016, LANCET, V388, P390, DOI 10.1016/S0140-6736(16)00683-8
   Wu YC, 2012, IEEE T VIS COMPUT GR, V18, P2526, DOI 10.1109/TVCG.2012.285
NR 84
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 316
EP 326
DI 10.1109/TVCG.2023.3327369
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500108
PM 37910407
OA Green Submitted, Green Published
DA 2024-08-05
ER

PT J
AU Feng, YF
   Shen, LY
   Li, X
   Yuan, CM
   Jiang, X
AF Feng, Yi-Fei
   Shen, Li-Yong
   Li, Xin
   Yuan, Chun-Ming
   Jiang, Xing
TI Patching Non-Uniform Extraordinary Points
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE NURBS; T-splines; extraordinary points; capping
ID SUBDIVISION SURFACES; ISOGEOMETRIC ANALYSIS; POLYNOMIAL SPLINES; NURBS;
   CAD
AB Smooth surfaces from an arbitrary topological control grid have been widely studied, which are mostly generalized from splines with uniform knot intervals. These methods fail to work well on extraordinary points (EPs) whose edges have varying knot intervals. This article presents a patching solution for arbitrary topological 2-manifold control grid with non-uniform knots that defines one bi-cubic Bezier patch per control grid face except those faces with EPs. Experimental results demonstrate that the new solution can improve the surface quality for non-uniform parameterization. Applications in surface reconstruction, arbitrary sharp features on the complex surface and tool path planning for the new surface representation are also provided in the paper.
C1 [Feng, Yi-Fei] UCAS, Beijing 101408, Peoples R China.
   [Shen, Li-Yong; Li, Xin] UCAS, Beijing 230026, Anhui, Peoples R China.
   Univ Sci & Technol China, AMSS, Hefei 100045, Peoples R China.
   [Yuan, Chun-Ming] AMSS CAS, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Academy of Mathematics & System
   Sciences, CAS
RP Li, X (corresponding author), UCAS, Beijing 230026, Anhui, Peoples R China.
EM fengyifei15@mails.ucas.ac.cn; lyshen@ucas.ac.cn; lixustc@ustc.edu.cn;
   cmyuan@mmrc.iss.ac.cn; jiangxin@buaa.edu.cn
RI Li, Xin/B-1324-2012; Shen, Li-Yong/P-9693-2015
OI Li, Xin/0000-0003-0477-7098; Shen, Li-Yong/0000-0001-5769-4814; ?,
   ??/0000-0003-3349-533X
FU National Key Research and Development Program of China [2020YFA0713703];
   Beijing Natural Science Foundation [Z190004]; NSFC [61872332]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFA0713703, in part by
   Beijing Natural Science Foundation under Grant Z190004, and in part by
   NSFC under Grant 61872332.
CR Biermann H, 2000, COMP GRAPH, P113, DOI 10.1145/344779.344841
   Cashman TJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531352
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Deng JS, 2008, GRAPH MODELS, V70, P76, DOI 10.1016/j.gmod.2008.03.001
   DeRose T., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P85, DOI 10.1145/280814.280826
   Dokken T, 2013, COMPUT AIDED GEOM D, V30, P331, DOI 10.1016/j.cagd.2012.12.005
   Eck M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P325, DOI 10.1145/237170.237271
   Farin G. E., 2002, NURBS Curves and Surfaces: From Projective Geometry toPractical Use
   Forsey D. R., 1988, Computer Graphics, V22, P205, DOI 10.1145/378456.378512
   Huang JW, 2018, COMPUT GRAPH FORUM, V37, P147, DOI 10.1111/cgf.13498
   Hughes TJR, 2005, COMPUT METHOD APPL M, V194, P4135, DOI 10.1016/j.cma.2004.10.008
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Karciauskas K, 2022, COMPUT AIDED DESIGN, V150, DOI 10.1016/j.cad.2022.103310
   Karciauskas K, 2022, COMPUT GRAPH-UK, V102, P370, DOI 10.1016/j.cag.2021.10.008
   Karciauskas K, 2021, COMPUT AIDED GEOM D, V86, DOI 10.1016/j.cagd.2021.101978
   Karciauskas K, 2020, COMPUT AIDED GEOM D, V83, DOI 10.1016/j.cagd.2020.101934
   Karciauskas K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3136954
   Kosinka J, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12258
   Kovacs D, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766972
   Kruskal J. B., 1956, Proceedings of the American Mathematical society, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.1090/S0002-9939-1956-0078686-7]
   Lai YK, 2006, COMPUT AIDED DESIGN, V38, P800, DOI 10.1016/j.cad.2006.04.007
   Li XF, 2016, ACTA OCEANOL SIN, V35, P1
   Li X, 2019, COMPUT METHOD APPL M, V352, P606, DOI 10.1016/j.cma.2019.04.036
   Li X, 2012, COMPUT AIDED GEOM D, V29, P63, DOI 10.1016/j.cagd.2011.08.005
   Ma WY, 2005, COMPUT AIDED DESIGN, V37, P693, DOI 10.1016/j.cad.2004.08.008
   Majeed M, 2017, COMPUT METHOD APPL M, V316, P547, DOI 10.1016/j.cma.2016.08.013
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   MORETON HP, 1992, COMP GRAPH, V26, P167, DOI 10.1145/142920.134035
   Müller K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805969
   Müller K, 2006, ACM T GRAPHIC, V25, P268, DOI 10.1145/1138450.1138455
   Peters J, 2000, COMP GRAPH, P255, DOI 10.1145/344779.344908
   Peters J., 2019, SMAI J. Comput. Math., VS5, P183
   Peters U., 2008, Subdivision Methods for Geometric Design
   Pottmann H, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P8, DOI 10.1109/PCCGA.2002.1167835
   Scott MA, 2013, COMPUT METHOD APPL M, V254, P197, DOI 10.1016/j.cma.2012.11.001
   Sederberg T. W., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P387, DOI 10.1145/280814.280942
   Sederberg TN, 2003, ACM T GRAPHIC, V22, P477, DOI 10.1145/882262.882295
   Sederberg TW, 2004, ACM T GRAPHIC, V23, P276, DOI 10.1145/1015706.1015715
   Shi XQ, 2004, COMPUT AIDED DESIGN, V36, P413, DOI 10.1016/S0010-4485(03)00111-8
   Tian YF, 2020, COMPUT GRAPH FORUM, V39, P232, DOI 10.1111/cgf.14014
   Toshniwal D, 2017, COMPUT METHOD APPL M, V327, P411, DOI 10.1016/j.cma.2017.06.008
   Wei XD, 2021, INT J NUMER METH ENG, V122, P2117, DOI 10.1002/nme.6608
   Wei XD, 2015, COMPUT METHOD APPL M, V291, P1, DOI 10.1016/j.cma.2015.03.019
   Zhao HS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201338
NR 44
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4683
EP 4693
DI 10.1109/TVCG.2023.3271669
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400024
PM 37126614
DA 2024-08-05
ER

PT J
AU Li, YQ
   Yin, WT
   Li, JB
   Xie, XJ
AF Li, Yuqi
   Yin, Wenting
   Li, Jiabao
   Xie, Xijiong
TI Physics-Based Efficient Full Projector Compensation Using Only Natural
   Images
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Full projector compensation; projector display; matrix factorization
ID RADIOMETRIC COMPENSATION; DISPLAY; SYSTEM
AB Achieving practical full projector compensation requires the projection display to adapt quickly to textured projection surfaces and unexpected movements without interrupting the display procedure. A possible solution to achieve this involves using a projector and an RGB camera and correcting both color and geometry by directly capturing and analyzing the projected natural image content, without the need for additional patterns. In this study, we approach full projector compensation as a numerical optimization problem and present a physics-based framework that can handle both geometric calibration and radiometric compensation for a Projector-camera system (Procams), using only a few sampling natural images. Within the framework, we decouple and estimate the Procams' factors, such as the response function of the projector, the correspondence between the projector and camera, and the reflectance of projection surfaces. This approach provides an interpretable and flexible solution to adapt to the changes in geometry and reflectance caused by movements. Benefitting from the physics-based scheme, our method guarantees both accurate color calculation and efficient movement and reflectance estimation. Our experimental results demonstrate that our method surpasses other state-of-the-art end-to-end full projector compensation methods, with superior image quality, reduced computational time, lower memory consumption, greater geometric accuracy, and a more compact network architecture.
C1 [Li, Yuqi] Ningbo Univ, Ningbo 315211, Peoples R China.
C3 Ningbo University
RP Li, YQ (corresponding author), Ningbo Univ, Ningbo 315211, Peoples R China.
EM liyuqi1@nbu.edu.cn; 2011082084@nbu.edu.cn; 2011082305@nbu.edu.cn;
   xiexijiong@nbu.edu.cn
OI Yin, Wenting/0009-0000-1760-7560; Li, Jiabao/0000-0002-0679-1101
FU Ningbo Innovation Challenge Project [2022T001]; Zhejiang Engineering
   Research Center of Advanced Mass Spectrometry and Clinical Application
FX No Statement Available
CR [Anonymous], 1992, JOSA A, V9, P507
   Asayama H, 2018, IEEE T VIS COMPUT GR, V24, P1077, DOI 10.1109/TVCG.2017.2657634
   Behrmann J, 2019, PROC INT C MACH LEAR, V97, P573
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber D., 2008, ACM SIGGRAPH CLASSES, P1
   Cotting D, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P100, DOI 10.1109/ISMAR.2004.30
   Fujii K, 2005, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.2005.41
   Grossberg MD, 2004, PROC CVPR IEEE, P452
   Grundhöfer A, 2015, IEEE T IMAGE PROCESS, V24, P5086, DOI 10.1109/TIP.2015.2478388
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Grundhöfer A, 2008, IEEE T VIS COMPUT GR, V14, P97, DOI 10.1109/TVCG.2007.1052
   Hashimoto N, 2021, VISUAL COMPUT, V37, P175, DOI 10.1007/s00371-019-01790-8
   Hashimoto N, 2017, INT J COMPUT GAMES T, V2017, DOI 10.1155/2017/4936285
   Huang BY, 2022, IEEE T PATTERN ANAL, V44, P2953, DOI 10.1109/TPAMI.2021.3050124
   Huang BY, 2021, IEEE T AUTOM SCI ENG, V18, P1049, DOI 10.1109/TASE.2020.2994223
   Huang BY, 2021, IEEE T VIS COMPUT GR, V27, P2725, DOI 10.1109/TVCG.2021.3067771
   Huang H., 2020, P IEEE CVF INT C COM, P7164
   Huang H., 2019, P IEEE CVF C COMP VI, P6810
   Huang TH, 2017, IEEE T IMAGE PROCESS, V26, P147, DOI 10.1109/TIP.2016.2592799
   Ibrahim G., 2020, P 26 ACM S VIRT REAL, P1
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Ignatov A, 2020, IEEE COMPUT SOC CONF, P2275, DOI 10.1109/CVPRW50498.2020.00276
   Iwai D, 2015, IEEE T VIS COMPUT GR, V21, P462, DOI 10.1109/TVCG.2015.2391861
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Jiang Shihao, 2021, P IEEE CVF INT C COM, P9772
   Juang A., 2007, IEEE C COMPUT VIS PA, P1
   Kagami S, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214927
   Kageyama Y, 2022, IEEE T VIS COMPUT GR, V28, P2223, DOI 10.1109/TVCG.2022.3150465
   Li Q., 2021, P IEEE CVF INT C COM, P2672
   Li Q. Yuan, 2013, P 19 ACM S VIRT REAL, P201
   Li YQ, 2018, COMPUT GRAPH FORUM, V37, P365, DOI 10.1111/cgf.13368
   Li YQ, 2018, VISUAL COMPUT, V34, P1773, DOI 10.1007/s00371-017-1469-3
   Li YQ, 2013, CHIN OPT LETT, V11, DOI 10.3788/COL201311.113301
   Liang JX, 2021, OPT EXPRESS, V29, P43899, DOI 10.1364/OE.447031
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977
   Qi M, 2021, Arxiv, DOI arXiv:2111.01511
   Resch C, 2014, INT SYM MIX AUGMENT, P151, DOI 10.1109/ISMAR.2014.6948421
   Sajadi B, 2012, IEEE T VIS COMPUT GR, V18, P381, DOI 10.1109/TVCG.2011.271
   Sajadi B, 2011, IEEE T VIS COMPUT GR, V17, P1209, DOI 10.1109/TVCG.2011.33
   Sajadi B, 2010, LECT NOTES COMPUT SC, V6314, P72, DOI 10.1007/978-3-642-15561-1_6
   Shahpaski M, 2017, PROC CVPR IEEE, P3596, DOI 10.1109/CVPR.2017.383
   Sugimoto M, 2021, IEEE T VIS COMPUT GR, V27, P4161, DOI 10.1109/TVCG.2021.3106511
   Takeda S, 2016, IEEE T VIS COMPUT GR, V22, P1424, DOI 10.1109/TVCG.2016.2518136
   Tehrani MA, 2021, IEEE T VIS COMPUT GR, V27, P2265, DOI 10.1109/TVCG.2019.2950942
   Terai H., 2021, arXiv
   Tone D, 2020, IEEE T VIS COMPUT GR, V26, P2030, DOI 10.1109/TVCG.2020.2973444
   Tsukamoto J, 2015, IEEE T VIS COMPUT GR, V21, P1221, DOI 10.1109/TVCG.2015.2459905
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yang G., 2001, P INT C CENTR EUR CO, P328
   Yang LM, 2016, INT SYM MIX AUGMENT, P63, DOI 10.1109/ISMAR.2016.22
   Yuqi Li, 2012, 2012 International Conference on Virtual Reality and Visualization (ICVRV 2012), P7, DOI 10.1109/ICVRV.2012.15
NR 53
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4968
EP 4982
DI 10.1109/TVCG.2023.3281681
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400079
PM 37256799
DA 2024-08-05
ER

PT J
AU Loi, I
   Zacharaki, EI
   Moustakas, K
AF Loi, Iliana
   Zacharaki, Evangelia I.
   Moustakas, Konstantinos
TI Machine Learning Approaches for 3D Motion Synthesis and Musculoskeletal
   Dynamics Estimation: A Survey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computer graphics; animation; motion prediction; motion synthesis;
   machine learning; biomechanical simulation
AB The inference of 3D motion and dynamics of the human musculoskeletal system has traditionally been solved using physics-based methods that exploit physical parameters to provide realistic simulations. Yet, such methods suffer from computational complexity and reduced stability, hindering their use in computer graphics applications that require real-time performance. With the recent explosion of data capture (mocap, video) machine learning (ML) has started to become popular as it is able to create surrogate models harnessing the huge amount of data stemming from various sources, minimizing computational time (instead of resource usage), and most importantly, approximate real-time solutions. The main purpose of this paper is to provide a review and classification of the most recent works regarding motion prediction, motion synthesis as well as musculoskeletal dynamics estimation problems using ML techniques, in order to offer sufficient insight into the state-of-the-art and draw new research directions. While the study of motion may appear distinct to musculoskeletal dynamics, these application domains provide jointly the link for more natural computer graphics character animation, since ML-based musculoskeletal dynamics estimation enables modeling of more long-term, temporally evolving, ergonomic effects, while offering automated and fast solutions. Overall, our review offers an in-depth presentation and classification of ML applications in human motion analysis, unlike previous survey articles focusing on specific aspects of motion prediction.
C1 [Loi, Iliana; Zacharaki, Evangelia I.; Moustakas, Konstantinos] Univ Patras, Dept Elect & Comp Engn, Patras 26504, Greece.
   [Zacharaki, Evangelia I.] Univ Miami, Miller Sch Med, Miami, FL 33136 USA.
C3 University of Patras; University of Miami
RP Loi, I (corresponding author), Univ Patras, Dept Elect & Comp Engn, Patras 26504, Greece.
EM loi@ceid.upatras.gr; exz187@med.miami.edu; moustakas@ece.upatras.gr
OI Loi, Iliana/0000-0001-9112-0638; Zacharaki,
   Evangelia/0000-0001-8228-0437; Moustakas,
   Konstantinos/0000-0001-7617-227X
FU EACEA - Erasmus+ [101082688]
FX This work was supported by the EACEA - Erasmus+ under Grant 101082688 -
   Project: EMMBIOME. Recommended for acceptance byT. Komura.
CR Sigurdsson GA, 2018, Arxiv, DOI arXiv:1804.09626
   Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392469
   Alemi O, 2019, Arxiv, DOI arXiv:1903.08356
   Aliakbarian S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11313, DOI 10.1109/ICCV48922.2021.01114
   Aliakbarian S, 2020, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR42600.2020.00527
   [Anonymous], 2003, CMU graphics lab. Carnegie mellon university motion capture database
   [Anonymous], 2018, Adobe systems incs Mixamo
   Aristidou A, 2023, IEEE T VIS COMPUT GR, V29, P3519, DOI 10.1109/TVCG.2022.3163676
   Bergamin K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356536
   Briq R, 2022, Arxiv, DOI arXiv:2206.06741
   Burton WS, 2021, J BIOMECH, V123, DOI 10.1016/j.jbiomech.2021.110439
   Cai YJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11625, DOI 10.1109/ICCV48922.2021.01144
   Cao Z., 2020, ECCV, P387, DOI [10.1007/978-3-030-58452-8_23, DOI 10.1007/978-3-030-58452-8_23]
   Chang ZY, 2022, Arxiv, DOI arXiv:2212.08526
   Cheema N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376701
   Chen WH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2131, DOI 10.1145/3394171.3413669
   Cho K., 2014, ARXIV14061078, V1406, P1078, DOI DOI 10.3115/V1/D14-1179
   Chollet F., 2017, Deep learning with Python, DOI DOI 10.1186/S12859-020-03546-X
   Cui QJ, 2020, PROC CVPR IEEE, P6518, DOI 10.1109/CVPR42600.2020.00655
   Dao TT, 2019, MED BIOL ENG COMPUT, V57, P1049, DOI 10.1007/s11517-018-1940-y
   Ehsani K, 2020, PROC CVPR IEEE, P221, DOI 10.1109/CVPR42600.2020.00030
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Fregly BJ, 2012, J ORTHOP RES, V30, P503, DOI 10.1002/jor.22023
   Giarmatzis G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236933
   Gomes TL, 2020, IEEE WINT CONF APPL, P3355, DOI 10.1109/WACV45572.2020.9093395
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guo C, 2022, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR52688.2022.00509
   Guo CA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2021, DOI 10.1145/3394171.3413635
   Guo W, 2022, PROC CVPR IEEE, P13043, DOI 10.1109/CVPR52688.2022.01271
   Halilaj E, 2018, J BIOMECH, V81, P1, DOI 10.1016/j.jbiomech.2018.09.009
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Hassan M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11354, DOI 10.1109/ICCV48922.2021.01118
   Hassan M, 2019, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2019.00237
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Honda Y., 2020, P 31 BRIT MACH VIS C
   Hwang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112455
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang YF, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322966
   Jin X, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8899880
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972
   Lee S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459774
   Li JM, 2021, INT CONF 3D VISION, P771, DOI 10.1109/3DV53792.2021.00086
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Li PZ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530157
   Li RL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13381, DOI 10.1109/ICCV48922.2021.01315
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Liu DW, 2022, MEASUREMENT, V198, DOI 10.1016/j.measurement.2022.111344
   Liu ZG, 2021, Arxiv, DOI arXiv:2103.09755
   Liu ZG, 2019, PROC CVPR IEEE, P9996, DOI 10.1109/CVPR.2019.01024
   Loi I, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.648356
   Ma HB, 2022, PROC CVPR IEEE, P8151, DOI 10.1109/CVPR52688.2022.00799
   Ma J., 2022, arXiv
   Ma TZ, 2022, PROC CVPR IEEE, P6427, DOI 10.1109/CVPR52688.2022.00633
   Maeda T, 2022, PROC CVPR IEEE, P6417, DOI 10.1109/CVPR52688.2022.00632
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Mao W, 2022, PROC CVPR IEEE, P8141, DOI 10.1109/CVPR52688.2022.00798
   Mao W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13289, DOI 10.1109/ICCV48922.2021.01306
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Men QH, 2022, COMPUT GRAPH-UK, V102, P634, DOI 10.1016/j.cag.2021.09.014
   Mourot L, 2020, Arxiv, DOI arXiv:2007.01151
   Mourot L, 2022, Arxiv, DOI arXiv:2208.04598
   Muller M., 2007, Documentation mocap database hdm05
   Nowakowski K, 2022, MED BIOL ENG COMPUT, V60, P1745, DOI 10.1007/s11517-022-02567-3
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Park J., 2022, arXiv
   Pavlou M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.646415
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459670, 10.1145/3197517.3201311]
   Peng XB, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275014
   Pu JF, 2022, Arxiv, DOI arXiv:2207.03682
   Punnakkal AR, 2021, PROC CVPR IEEE, P722, DOI 10.1109/CVPR46437.2021.00078
   Raab S, 2023, Arxiv, DOI arXiv:2302.05905
   Raab S, 2022, Arxiv, DOI arXiv:2206.08010
   Rane L, 2019, ANN BIOMED ENG, V47, P778, DOI 10.1007/s10439-018-02190-0
   Rasouli A, 2020, Arxiv, DOI arXiv:2007.00095
   Ren JL, 2019, IEEE INT CONF ROBOT, P5076, DOI [10.1109/icra.2019.8794187, 10.1109/ICRA.2019.8794187]
   Risvas K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P119, DOI [10.1109/VRW50115.2020.0-250, 10.1109/VRW50115.2020.00026]
   Rudenko A, 2020, INT J ROBOT RES, V39, P895, DOI 10.1177/0278364920917446
   Salzmann T, 2022, PROC CVPR IEEE, P6447, DOI 10.1109/CVPR52688.2022.00635
   Seth A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006223
   Seth A, 2011, PROC IUTAM, V2, P212, DOI 10.1016/j.piutam.2011.04.021
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shen YJ, 2020, IEEE T VIS COMPUT GR, V26, P2620, DOI 10.1109/TVCG.2019.2893247
   Shi MY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3407659
   Shu LM, 2018, J BIOMECH, V77, P146, DOI 10.1016/j.jbiomech.2018.07.008
   Shu T., 2016, P 25 INT JOINT C ART
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sohane A, 2022, COMPUT J, V65, P1167, DOI 10.1093/comjnl/bxaa160
   Starke S, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530178
   Starke S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459881
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   Stetter BJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173690
   Taheri Omid, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P581, DOI 10.1007/978-3-030-58548-8_34
   Tang YY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P935
   Tevet Guy, 2022, arXiv
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wang H, 2021, IEEE T VIS COMPUT GR, V27, P216, DOI 10.1109/TVCG.2019.2936810
   Wang JP, 2019, IEEE ACCESS, V7, P92465, DOI 10.1109/ACCESS.2019.2927606
   Wang JB, 2022, PROC CVPR IEEE, P20428, DOI 10.1109/CVPR52688.2022.01981
   Wang JB, 2021, PROC CVPR IEEE, P12201, DOI 10.1109/CVPR46437.2021.01203
   Wang X, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/104535
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P14, DOI 10.1109/TVCG.2019.2938520
   Wei Mao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P474, DOI 10.1007/978-3-030-58568-6_28
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Xie K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11512, DOI 10.1109/ICCV48922.2021.01133
   Yang JT, 2021, P I MECH ENG I-J SYS, V235, P180, DOI 10.1177/0959651820945814
   Yasar MS, 2021, arXiv
   Yuan Y, 2022, Arxiv, DOI arXiv:2212.02500
   Yuan Ye, 2020, Advances in Neural Information Processing Systems, V33, P21763, DOI 10.48550/arXiv.2006.07364
   Yun K., 2012, 2012 IEEE COMP SOC C, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhang J, 2022, Arxiv, DOI arXiv:2207.01435
   Zhang Y, 2021, PROC CVPR IEEE, P3371, DOI 10.1109/CVPR46437.2021.00338
   Zhang ZB, 2022, IEEE ROBOT AUTOM LET, V7, P8949, DOI 10.1109/LRA.2022.3188892
   Zhong CY, 2022, PROC CVPR IEEE, P6437, DOI 10.1109/CVPR52688.2022.00634
   Zhu YA, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101811
NR 120
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5810
EP 5829
DI 10.1109/TVCG.2023.3308753
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400083
PM 37624722
OA hybrid
DA 2024-08-05
ER

PT J
AU Oreshkin, BN
   Valkanas, A
   Harvey, FG
   Menard, LS
   Bocquelet, F
   Coates, MJ
AF Oreshkin, Boris N.
   Valkanas, Antonios
   Harvey, Felix G.
   Menard, Louis-Simon
   Bocquelet, Florent
   Coates, Mark J.
TI Motion In-Betweening via Deep Δ-Interpolator
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; in-betweening; interpolation; transformer; neural networks;
   human motion
AB We show that the task of synthesizing human motion conditioned on a set of key frames can be solved more accurately and effectively if a deep learning based interpolator operates in the delta mode using the spherical linear interpolator as a baseline. We empirically demonstrate the strength of our approach on publicly available datasets achieving state-of-the-art performance. We further generalize these results by showing that the Delta-regime is viable with respect to the reference of the last known frame (also known as the zero-velocity model). This supports the more general conclusion that operating in the reference frame local to input frames is more accurate and robust than in the global (world) reference frame advocated in previous work.
C1 [Oreshkin, Boris N.] Unity Technol, San Francisco, CA 94103 USA.
   [Valkanas, Antonios; Coates, Mark J.] McGill Univ, Montreal, PQ H3A 0G4, Canada.
C3 McGill University
RP Oreshkin, BN (corresponding author), Unity Technol, San Francisco, CA 94103 USA.
EM boris.oreshkin@gmail.com; antonios.valkanas@mail.mcgill.ca;
   c212.felixh@gmail.com; louissimon.menard@unity3d.com;
   florent.bocquelet@unity3d.com; mark.coates@mcgill.ca
OI Valkanas, Antonios/0009-0001-1234-0016
FU Mitacs through the Mitacs Accelerate program
FX This work was supported by Mitacs through the Mitacs Accelerate program.
CR Abe Y., 2004, P 2004 ACM SIGGRAPHE, P173
   Beane A., 2012, 3D Animation Essentials
   Chai JX, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239459
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Duan YL, 2022, AAAI CONF ARTIF INTE, P4459
   Duan YL, 2021, Arxiv, DOI arXiv:2103.00776
   Geleijn R, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P579, DOI 10.1109/VRW52623.2021.00172
   Gopalakrishnan A, 2019, PROC CVPR IEEE, P12108, DOI 10.1109/CVPR.2019.01239
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Guo CA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2021, DOI 10.1145/3394171.3413635
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Harvey FG, 2018, SA'18: SIGGRAPH ASIA 2018 TECHNICAL BRIEFS, DOI 10.1145/3283254.3283277
   Holden D., 2015, P SIGGRAPH EUR S COM, P165, DOI DOI 10.1145/2786784.2786788
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Ji S. W., 2010, Tech. Rep.
   Kao HK, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P147, DOI 10.1145/3394171.3413848
   Kaufmann M, 2020, INT CONF 3D VISION, P918, DOI 10.1109/3DV50981.2020.00102
   Kingma D. P., 2014, arXiv
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Li JM, 2021, INT CONF 3D VISION, P771, DOI 10.1109/3DV53792.2021.00086
   Li RL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13381, DOI 10.1109/ICCV48922.2021.01315
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Ngo J. T., 1993, Computer Graphics Proceedings, P343, DOI 10.1145/166117.166160
   Oreshkin B. N., 2021, P INT C LEARN REPR
   Oreshkin B. N., 2022, P INT C LEARN REPR
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Petrovich M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10965, DOI 10.1109/ICCV48922.2021.01080
   Press O., 2022, P INT C LEARN REPR
   Qin J, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555454
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1237, DOI 10.1145/3240508.3241388
   Tang XJ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530090
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2021, IEEE T VIS COMPUT GR, V27, P216, DOI 10.1109/TVCG.2019.2936810
   Wang H, 2015, IEEE T VIS COMPUT GR, V21, P18, DOI 10.1109/TVCG.2014.2327976
   Wang HS, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108424
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
NR 43
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5693
EP 5704
DI 10.1109/TVCG.2023.3309107
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400071
PM 37639420
DA 2024-08-05
ER

PT J
AU Garretón, M
   Morini, F
   Celhay, P
   Dörk, M
   Parra, D
AF Garreton, Manuela
   Morini, Francesca
   Celhay, Pablo
   Doerk, Marian
   Parra, Denis
TI Attitudinal Effects of Data Visualizations and Illustrations in Data
   Stories
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Attitude change; data stories; emotions; quantitative and qualitative
   evaluation
ID NEGATIVE AFFECT; NEWS; COMMUNICATION; MEMORABILITY; RECOGNITION;
   PHOTOGRAPHS; VALIDATION; RESPONSES; PICTURE; MEMORY
AB Journalism has become more data-driven and inherently visual in recent years. Photographs, illustrations, infographics, data visualizations, and general images help convey complex topics to a wide audience. The way that visual artifacts influence how readers form an opinion beyond the text is an important issue to research, but there are few works about this topic. In this context, we research the persuasive, emotional and memorable dimensions of data visualizations and illustrations in journalistic storytelling for long-form articles. We conducted a user study and compared the effects which data visualizations and illustrations have on changing attitude towards a presented topic. While visual representations are usually studied along one dimension, in this experimental study, we explore the effects on readers' attitudes along three: persuasion, emotion, and information retention. By comparing different versions of the same article, we observe how attitudes differ based on the visual stimuli present, and how they are perceived when combined. Results indicate that the narrative using only data visualization elicits a stronger emotional impact than illustration-only visual support, as well as a significant change in the initial attitude about the topic. Our findings contribute to a growing body of literature on how visual artifacts may be used to inform and influence public opinion and debate. We present ideas for future work to generalize the results beyond the domain studied, the water crisis.
C1 [Garreton, Manuela; Parra, Denis] Pontificia Univ Catolica Chile, Dept Comp Sci, Santiago 8331150, Chile.
   [Morini, Francesca; Doerk, Marian] Univ Appl Sci Potsdam, Urban Complex Lab, D-14469 Potsdam, Germany.
   [Celhay, Pablo] Pontificia Univ Catolica Chile, Santiago 8331150, Chile.
C3 Pontificia Universidad Catolica de Chile; Pontificia Universidad
   Catolica de Chile
RP Garretón, M (corresponding author), Pontificia Univ Catolica Chile, Dept Comp Sci, Santiago 8331150, Chile.
EM manuela.garreton@uc.cl; morini@fh-potsdam.de; pacelhay@uc.cl;
   doerk@fh-potsdam.de; dparra@ing.puc.cl
RI Parra, Denis/D-1388-2014
OI Parra, Denis/0000-0001-9878-8761; Dork, Marian/0000-0002-3469-7841;
   Morini, Francesca/0000-0002-5677-8175; Garreton,
   Manuela/0000-0003-4626-3984
FU ANID; Millennium Science Initiative Programs [ICN17_002, ICN2021_004];
   Basal Funds [FB210017]; German Federal Ministry of Education and
   Research; Bundesministerium fur Bildung und Forschungunder Grant [FK
   13FH126PX6]
FX This work was supported in part by ANID - Doctorate Grant and partially
   funded in part by ANID, Millennium Science Initiative Programs under
   Grants ICN17_002 (IMFD) and ICN2021_004 (iHealth), in part by Basal
   Funds under Grant FB210017 (CENIA), and in part by the German Federal
   Ministry of Education and Research, Bundesministerium fur Bildung und
   Forschungunder Grant FK 13FH126PX6.
CR Albarracin D., 2008, Attitudes and Attitude Change
   [Anonymous], 2019, GUARDIAN
   [Anonymous], 2019, The New York Times
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Barrett LF, 1999, CURR DIR PSYCHOL SCI, V8, P10, DOI 10.1111/1467-8721.00003
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Besancon L., 2017, P 29 C FRANC INT HOM, P11
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P630, DOI 10.1109/TVCG.2018.2865142
   Bless H., 2001, Social Influence: Direct and Indirect Processes, P167
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bounegru L., 2012, DATA JOURNALISM HDB
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Brantner C, 2011, J MASS COMMUN Q, V88, P523, DOI 10.1177/107769901108800304
   Bucher HJ, 2006, COMMUNICATIONS-GER, V31, P347, DOI 10.1515/COMMUN.2006.022
   Byrne L, 2016, IEEE T VIS COMPUT GR, V22, P509, DOI 10.1109/TVCG.2015.2467321
   CACIOPPO JT, 1984, ADV CONSUM RES, V11, P673
   Campbell Sarah, 2019, Information Design Journal, V25, P71, DOI 10.1075/idj.25.1.06cam
   Card S. K., 1999, Using Vision to Think, P1
   Charmaz K., 2013, Estrategias de investigacion cualitativa, VIII., P270
   D'Ignazio C, 2020, STRONG IDEAS SERIES, P97
   David P, 1998, HUM COMMUN RES, V25, P180, DOI 10.1111/j.1468-2958.1998.tb00442.x
   DIgnazio C., 2016, P WORKSH VIS DIG HUM
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Dufey M., 2012, REV IBEROAMERICANA D, V34, P157
   Garry M, 2007, APPL COGNITIVE PSYCH, V21, P995, DOI 10.1002/acp.1362
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Hohman F., 2020, Distill.
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Iyer A, 2006, EUR J SOC PSYCHOL, V36, P635, DOI 10.1002/ejsp.316
   Jacobson S, 2016, JOURNALISM, V17, P527, DOI 10.1177/1464884914568079
   Jones J.G., 2017, Persuasion in society
   Kelders SM, 2012, J MED INTERNET RES, V14, P17, DOI 10.2196/jmir.2104
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kensicki L.J., 2001, Journal of Communication Inquiry, V25, P147, DOI [10.1177/0196839901025002005, DOI 10.1177/0196839901025002005, DOI 10.1177/0196859901025002005]
   Kim Y.-S., 2019, P CHI C HUM FACT COM, P1
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   King C, 2005, JOURNALISM MASS COMM, V82, P623, DOI 10.1177/107769900508200309
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Krzywinski M, 2013, NAT METHODS, V10, P921, DOI 10.1038/nmeth.2659
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Matthes J, 2009, J MASS COMMUN Q, V86, P349, DOI 10.1177/107769900908600206
   Mitchelstein E., 2009, JOURNALISM, V10, P562, DOI [DOI 10.1177/1464884909106533, 10.1177/1464884909106533]
   Morseletto N, 2017, ENVIRON SCI POLICY, V78, P40, DOI 10.1016/j.envsci.2017.08.021
   Moya M., 1999, Psicologia Social, P153
   Obie HO, 2019, J COMPUT LANG, V52, P113, DOI 10.1016/j.cola.2019.04.006
   Ohira H, 1998, PERS SOC PSYCHOL B, V24, P986, DOI 10.1177/0146167298249006
   Pandey AV, 2014, IEEE T VIS COMPUT GR, V20, P2211, DOI 10.1109/TVCG.2014.2346419
   Parrott S, 2019, J BROADCAST ELECTRON, DOI 10.1080/08838151.2019.1681860
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Peña-Araya V, 2020, IEEE T VIS COMPUT GR, V26, P375, DOI 10.1109/TVCG.2019.2934807
   Petty R.E., 2010, Advanced social psychology: The state of the science, P217, DOI [10.1016/B978-0-12-375000-6.00040-9, DOI 10.1016/B978-0-12-375000-6.00040-9]
   Petty RE, 2015, COGNITION EMOTION, V29, P1, DOI 10.1080/02699931.2014.967183
   Powell TE, 2015, J COMMUN, V65, P997, DOI 10.1111/jcom.12184
   Rall K, 2016, J HUM RIGHTS PRACT, V8, P171, DOI 10.1093/jhuman/huw011
   Reardon K. K., 1991, Persuasion in Practice
   Reuters, 2019, The race to save the river ganges
   Riche NH, 2018, Data-Driven Storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Rodriguez L., 2011, Journal of Visual Literacy, V30, P48, DOI DOI 10.1080/23796529.2011.11674684
   Sawyer A., 1982, Cognitive Responses in Persuasion, P237
   Schneider Birgit., 2014, Image Politics of Climate Change: Visualizations, Imaginations, Documentations
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Svicarovic L., 2021, P EUROVIS SHORT PAP, P79
   Thompson ER, 2007, J CROSS CULT PSYCHOL, V38, P227, DOI 10.1177/0022022106297301
   TindallFord S, 1997, J EXP PSYCHOL-APPL, V3, P257, DOI 10.1037/1076-898X.3.4.257
   van Beek L, 2020, ENVIRON SCI POLICY, V114, P497, DOI 10.1016/j.envsci.2020.09.011
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weber W., 2018, Studies in communication sciences, V2018, P191, DOI [10.24434/j.scoms.2018.01.013, DOI 10.24434/J.SCOMS.2018.01.013]
NR 74
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4039
EP 4054
DI 10.1109/TVCG.2023.3248319
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700075
PM 37027584
OA hybrid
DA 2024-08-05
ER

PT J
AU Li, RY
   Han, BX
   Li, HW
   Ma, LF
   Zhang, XR
   Zhao, Z
   Liao, HE
AF Li, Ruiyang
   Han, Boxuan
   Li, Haowei
   Ma, Longfei
   Zhang, Xinran
   Zhao, Zhe
   Liao, Hongen
TI A Comparative Evaluation of Optical See-Through Augmented Reality in
   Surgical Guidance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; optical see-through; surgical guidance; head-mounted
   display; autostereoscopic image overlay
ID TOTAL HIP-ARTHROPLASTY; IMAGE OVERLAY; CONTEXT VISUALIZATION; MOUNTED
   DISPLAYS; VIDEO SEE; NAVIGATION; SYSTEM; REGISTRATION; PLACEMENT; FOCUS
AB During traditional surgeries, planning and instrument guidance is displayed on an external screen. Recent developments of augmented reality (AR) techniques can overcome obstacles including hand-eye discoordination and heavy mental load. Among these AR technologies, optical see-through (OST) schemes with stereoscopic displays can provide depth perception and retain the physical scene for safety considerations. However, limitations still exist in certain AR systems and the influence of these factors on surgical performance is yet to explore. To this end, experiments of multi-scale surgical tasks were carried out to compare head-mounted display (HMD) AR and autostereoscopic image overlay (AIO) AR, concerning objective performance and subjective evaluation. To solely analyze effects brought by display techniques, the tracking system in each included display system was identical and similar tracking accuracy was proved by a preliminary experiment. Focus and context rendering was utilized to enhance in-situ visualization for surgical guidance. Latency values of all display systems were assessed and a delay experiment proved the latency differences had no significant impact on user performance. Results of multi-scale surgical tasks showed that HMD outperformed in detailed operations probably due to stable resolution along the depth axis, while AIO had better performance in larger-scale operations for better depth perception. This article helps point out the critical limitations of current OST AR techniques and potentially promotes the progress of AR applications in surgical guidance.
C1 [Li, Ruiyang; Han, Boxuan; Li, Haowei; Ma, Longfei; Zhang, Xinran; Liao, Hongen] Tsinghua Univ, Sch Med, Dept Biomed Engn, Beijing 100084, Peoples R China.
   [Zhao, Zhe] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Dept Orthopaed, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Liao, HE (corresponding author), Tsinghua Univ, Sch Med, Dept Biomed Engn, Beijing 100084, Peoples R China.
EM liruiruiyang@outlook.com; hbxbobo@hotmail.com;
   lihaowei19991202@gmail.com; malongfei@tsinghua.edu.cn;
   zhangxinran@tsinghua.edu.cn; zhaozhao_02@163.com; liao@tsinghua.edu.cn
OI Zhang, Xinran/0000-0001-9049-2691; haowei, li/0000-0001-6558-1369; Li,
   Ruiyang/0000-0003-3880-068X; Liao, Hongen/0000-0003-3847-9347
FU National Natural Science Foundation of China [82027807, U22A2051,
   81901844]; National Key Research and Development Program of China
   [2022YFC2405200]; Beijing Municipal Natural Science Foundation [7212202,
   L192013]; Institute for Intelligent Healthcare, Tsinghua University
   [2022ZLB001]; Tsinghua-Foshan Innovation Special Fund [2021THFS0104]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 82027807, U22A2051, and 81901844, in
   partby the National Key Research and Development Program of China under
   Grant 2022YFC2405200, in part by Beijing Municipal Natural Science
   Foundation under Grants 7212202 and L192013, in part by Institute for
   Intelligent Healthcare, Tsinghua University under Grant 2022ZLB001, and
   in part by Tsinghua-Foshan Innovation Special Fund under Grant
   2021THFS0104.
CR Abbey B, 2008, NAT PHYS, V4, P394, DOI 10.1038/nphys896
   ADAMS L, 1990, IEEE COMPUT GRAPH, V10, P43, DOI 10.1109/38.55152
   Alexander C, 2020, J ARTHROPLASTY, V35, P1636, DOI 10.1016/j.arth.2020.01.025
   [Anonymous], 2010, ADV BIOMEDICAL SENSI, DOI [DOI 10.1007/978-3-642-05167-8_17, 10.1007/978-3-642-05167-8_17]
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Bichlmeier C., 2007, Proc. IEEE ACM Int. Sym. on Mix. Aug. Reality, P1, DOI [DOI 10.1109/ISMAR.2007.4538837, DOI 10.1109/ISMAR.2007.4538837.18M]
   Biedermann R, 2005, J BONE JOINT SURG BR, V87B, P762, DOI 10.1302/0301-620X.87B6
   Birlo M, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2022.102361
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Casari FA, 2021, CURR REV MUSCULOSKE, V14, P192, DOI 10.1007/s12178-021-09699-3
   Condino S, 2020, IEEE T BIO-MED ENG, V67, P411, DOI 10.1109/TBME.2019.2914517
   Cutolo F, 2014, INT SYM MIX AUGMENT, P393
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   El-Hariri H, 2018, HEALTHC TECHNOL LETT, V5, P189, DOI 10.1049/htl.2018.5061
   Ewurum CH, 2018, ADV EXP MED BIOL, V1093, P47, DOI 10.1007/978-981-13-1396-7_4
   Fan ZC, 2016, J DISP TECHNOL, V12, P1185, DOI 10.1109/JDT.2016.2569452
   Feng J.E, 2019, JBJS Rev., V7
   Fotouhi J, 2021, IEEE T MED IMAGING, V40, P765, DOI 10.1109/TMI.2020.3037013
   Furman AA, 2021, CURR REV MUSCULOSKE, V14, P397, DOI 10.1007/s12178-021-09728-1
   Gavaghan KA, 2011, IEEE T BIO-MED ENG, V58, P1855, DOI 10.1109/TBME.2011.2126572
   Han BX, 2022, INT J MED ROBOT COMP, V18, DOI 10.1002/rcs.2404
   HART S G, 1988, P139
   Heinrich F, 2020, IEEE T VIS COMPUT GR, V26, P3568, DOI 10.1109/TVCG.2020.3023637
   Tran HH, 2011, LECT NOTES COMPUT SC, V6891, P81, DOI 10.1007/978-3-642-23623-5_11
   Kalkofen D, 2009, IEEE T VIS COMPUT GR, V15, P193, DOI 10.1109/TVCG.2008.96
   Kersten-Oertel M, 2014, IEEE T VIS COMPUT GR, V20, P391, DOI 10.1109/TVCG.2013.240
   Learmonth ID, 2007, LANCET, V370, P1508, DOI 10.1016/S0140-6736(07)60457-7
   Lerotic M, 2007, LECT NOTES COMPUT SC, V4792, P102
   Liao H, 2004, IEEE T INF TECHNOL B, V8, P114, DOI 10.1109/TITB.2004.826734
   Liao HG, 2013, COMPUT MED IMAG GRAP, V37, P81, DOI 10.1016/j.compmedimag.2013.04.001
   Liao HE, 2010, IEEE T BIO-MED ENG, V57, P1476, DOI 10.1109/TBME.2010.2040278
   Liebmann F, 2019, INT J COMPUT ASS RAD, V14, P1157, DOI 10.1007/s11548-019-01973-7
   Liu H, 2018, ANN BIOMED ENG, V46, P1595, DOI 10.1007/s10439-018-2055-1
   Ma LF, 2017, INT J COMPUT ASS RAD, V12, P2205, DOI 10.1007/s11548-017-1652-z
   Macedo MCF, 2015, COMPUT GRAPH-UK, V53, P196, DOI 10.1016/j.cag.2015.09.007
   Martin-Gomez A, 2022, IEEE T VIS COMPUT GR, V28, P4156, DOI 10.1109/TVCG.2021.3079849
   Mavrogenis AF, 2013, ORTHOPEDICS, V36, P631, DOI 10.3928/01477447-20130724-10
   Mezger U, 2013, LANGENBECK ARCH SURG, V398, P501, DOI 10.1007/s00423-013-1059-4
   Müller M, 2013, INT J COMPUT ASS RAD, V8, P663, DOI 10.1007/s11548-013-0828-4
   Ogawa H, 2018, J ARTHROPLASTY, V33, P1833, DOI 10.1016/j.arth.2018.01.067
   Peters TM, 2006, PHYS MED BIOL, V51, pR505, DOI 10.1088/0031-9155/51/14/R01
   Qian L, 2017, INT J COMPUT ASS RAD, V12, P901, DOI 10.1007/s11548-017-1564-y
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Scheerlinck T, 2014, ACTA ORTHOP BELG, V80, P336
   Shen FY, 2013, INT J COMPUT ASS RAD, V8, P169, DOI 10.1007/s11548-012-0775-5
   Tarwala R, 2011, CURR REV MUSCULOSKE, V4, P151, DOI 10.1007/s12178-011-9086-7
   Wang HX, 2016, INT ORTHOP, V40, P1941, DOI 10.1007/s00264-015-3028-8
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Wen R, 2014, COMPUT METH PROG BIO, V116, P68, DOI 10.1016/j.cmpb.2013.12.018
   Xu K, 2014, INT J SURG, V12, P528, DOI 10.1016/j.ijsu.2014.02.014
   Zhang RW, 2021, J MECH MED BIOL, V21, DOI 10.1142/S0219519421500676
   Zhang XR, 2017, IEEE T BIO-MED ENG, V64, P1815, DOI 10.1109/TBME.2016.2624632
NR 53
TC 1
Z9 1
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4362
EP 4374
DI 10.1109/TVCG.2023.3260001
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700047
PM 37030748
DA 2024-08-05
ER

PT J
AU Wang, Y
   Bâce, M
   Bulling, A
AF Wang, Yao
   Bace, Mihai
   Bulling, Andreas
TI Scanpath Prediction on Information Visualisations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Predictive models; Computational
   modeling; Hidden Markov models; Gaze tracking; Task analysis; Gaze
   behaviour analysis; MASSVIS; scanpath prediction; visual attention;
   visual saliency
ID EYE FIXATION; METRICS; MODEL
AB We propose Unified Model of Saliency and Scanpaths (UMSS)- a model that learns to predict multi-duration saliency and scanpaths (i.e. sequences of eye fixations) on information visualisations. Although scanpaths provide rich information about the importance of different visualisation elements during the visual exploration process, prior work has been limited to predicting aggregated attention statistics, such as visual saliency. We present in-depth analyses of gaze behaviour for different information visualisation elements (e.g. Title, Label, Data) on the popular MASSVIS dataset. We show that while, overall, gaze patterns are surprisingly consistent across visualisations and viewers, there are also structural differences in gaze dynamics for different elements. Informed by our analyses, UMSS first predicts multi-duration element-level saliency maps, then probabilistically samples scanpaths from them. Extensive experiments on MASSVIS show that our method consistently outperforms state-of-the-art methods with respect to several, widely used scanpath and saliency evaluation metrics. Our method achieves a relative improvement in sequence score of 11.5% for scanpath prediction, and a relative improvement in Pearson correlation coefficient of up to 23.6% for saliency prediction. These results are auspicious and point towards richer user models and simulations of visual attention on visualisations without the need for any eye tracking equipment.
C1 [Wang, Yao; Bace, Mihai; Bulling, Andreas] Univ Stuttgart, Inst Visualisat & Interact Syst, Stuttgart, Germany.
C3 University of Stuttgart
RP Wang, Y (corresponding author), Univ Stuttgart, Inst Visualisat & Interact Syst, Stuttgart, Germany.
EM yao.wang@vis.uni-stuttgart.de; Bace@vis.uni-stuttgart.de;
   andreas.bulling@vis.uni-stuttgart.de
OI Wang, Yao/0000-0002-3633-8623
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [251654672-TRR 161]; Swiss National Science Foundation (SNSF) Early
   Postdoc. Mobility Fellowship [199991]; European Research Council
   [801708]
FX The work of Yao Wang was funded by the Deutsche Forschungsgemeinschaft
   (DFG, German Research Foundation) under Grant 251654672-TRR 161. The
   work of Mihai Bace was funded by the Swiss National Science Foundation
   (SNSF) Early Postdoc. Mobility Fellowship under Grant 199991. The work
   of Andreas Bulling was funded by the European Research Council under
   Grant 801708.
CR Assens M, 2017, IEEE INT CONF COMP V, P2331, DOI 10.1109/ICCVW.2017.275
   Assens M, 2019, LECT NOTES COMPUT SC, V11133, P406, DOI 10.1007/978-3-030-11021-5_25
   Bao WT, 2020, NEUROCOMPUTING, V404, P154, DOI 10.1016/j.neucom.2020.03.060
   Beck F, 2017, MATH VIS, P113, DOI 10.1007/978-3-319-47024-5_7
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Berndt DJ., 1994, P KDD WORKSH SEATTL, P359, DOI DOI 10.5555/3000850.3000887
   Boccignone G., 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P29, DOI 10.1109/EUVIP.2010.5699099
   Boccignone V., 2019, P INT S FORM METH, P131, DOI DOI 10.1007/978-3-030-54994-7_10
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brockmann D, 2000, NEUROCOMPUTING, V32, P643, DOI 10.1016/S0925-2312(00)00227-7
   Burch L., 2017, EyeTracking and Visualization: Foundations, Techniques, and Applications
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Bylinskii Z, 2017, MATH VIS, P235, DOI 10.1007/978-3-319-47024-5_14
   Chen M., 2021, P IEEE CVF C COMP VI
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, LECT NOTES COMPUT SC, V9914, P302, DOI 10.1007/978-3-319-48881-3_21
   Coutrot A, 2018, BEHAV RES METHODS, V50, P362, DOI 10.3758/s13428-017-0876-8
   Cristino F, 2010, BEHAV RES METHODS, V42, P692, DOI 10.3758/BRM.42.3.692
   Droste R, 2020, Arxiv, DOI arXiv:2003.05477
   Faggi L, 2020, Arxiv, DOI arXiv:2006.11035
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Feit L., 2020, P ACM S EYE TRACK RE, P1
   Fosco C., 2020, P 33 ANN ACM S USER, P249, DOI DOI 10.1145/3379337.3415825
   Fosco C, 2020, PROC CVPR IEEE, P4472, DOI 10.1109/CVPR42600.2020.00453
   Gupta P, 2018, IEEE WINT CONF APPL, P1529, DOI 10.1109/WACV.2018.00171
   Harezlak K, 2014, PROCEDIA COMPUT SCI, V35, P1073, DOI 10.1016/j.procs.2014.08.194
   Hu ZM, 2021, IEEE T VIS COMPUT GR, V27, P2681, DOI 10.1109/TVCG.2021.3067779
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   Islam M, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101837
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jarodzka K., 2010, P 2010 S EYE TRACKIN, P211, DOI DOI 10.1145/1743666.1743718
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Komogortsev OV, 2010, IEEE T BIO-MED ENG, V57, P2635, DOI 10.1109/TBME.2010.2057429
   Kümmerer M, 2022, J VISION, V22, DOI 10.1167/jov.22.5.7
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kummerer T., 2017, J. Vis., V17, P1147, DOI [DOI 10.1167/17.10.1147, 10.1167/17.10.1147]
   Kurzhals B., 2014, P 5 WORKSH TIM ERR N, P61
   Leiva L. A., 2020, P 22 INT C HUM COMP, P1
   Li WS, 2019, IEEE ACCESS, V7, P14488, DOI 10.1109/ACCESS.2019.2894275
   Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316
   Matzen L, 2020, Arxiv, DOI arXiv:2009.14465
   Matzen LE, 2018, IEEE T VIS COMPUT GR, V24, P563, DOI 10.1109/TVCG.2017.2743939
   Matzen LE, 2017, LECT NOTES ARTIF INT, V10284, P176, DOI 10.1007/978-3-319-58628-1_15
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Muller M., 2007, Information Retrieval for Music and Motion, DOI [10.1007/978-3-540-74048-3, DOI 10.1007/978-3-540-74048-3_4]
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Nguyen T.H.D., 2015, P WORKSH EYE TRACK V, P23
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   Pan SW, 2020, CHAOS, V30, DOI 10.1063/5.0010886
   Pang XF, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982422
   Pirinen A, 2018, PROC CVPR IEEE, P6945, DOI 10.1109/CVPR.2018.00726
   Salverda M. K., 2017, Res.Methods Psycholinguistics Neurobiol. Lang.: A Practical Guide, V9, P89
   Scholl BJ, 2007, MIND LANG, V22, P563, DOI 10.1111/j.1468-0017.2007.00321.x
   Shen CY, 2014, LECT NOTES COMPUT SC, V8695, P33, DOI 10.1007/978-3-319-10584-0_3
   Shojaeizadeh M, 2016, LECT NOTES COMPUT SC, V9737, P465, DOI 10.1007/978-3-319-40250-5_44
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Staub A, 2013, PSYCHON B REV, V20, P1304, DOI 10.3758/s13423-013-0444-x
   Sun WJ, 2021, IEEE T PATTERN ANAL, V43, P2101, DOI 10.1109/TPAMI.2019.2956930
   Verma A, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902643
   Wang M., 2022, P S EYE TRACK RES AP, P1
   Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423
   Wang YX, 2017, COGN PROCESS, V18, P87, DOI 10.1007/s10339-016-0781-6
   Wloka C, 2018, PROC CVPR IEEE, P3184, DOI 10.1109/CVPR.2018.00336
   Xia C, 2019, IEEE T IMAGE PROCESS, V28, P3502, DOI 10.1109/TIP.2019.2897966
   Xu PM, 2015, Arxiv, DOI [arXiv:1504.06755, DOI 10.48550/ARXIV.1504.06755]
   Xu PM, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3299, DOI 10.1145/2858036.2858479
   Yang ZB, 2020, PROC CVPR IEEE, P190, DOI [10.1109/cvpr42600.2020.00027, 10.1109/CVPR42600.2020.00027]
   Zanca D, 2018, Arxiv, DOI arXiv:1802.02534
   Zanca D, 2020, IEEE T PATTERN ANAL, V42, P2983, DOI 10.1109/TPAMI.2019.2920636
   Zhang XC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174198
NR 72
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3902
EP 3914
DI 10.1109/TVCG.2023.3242293
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700071
PM 37022407
OA Green Accepted, Green Submitted
DA 2024-08-05
ER

PT J
AU Zeng, W
   Chen, X
   Hou, YH
   Shao, LD
   Chu, Z
   Chang, R
AF Zeng, Wei
   Chen, Xi
   Hou, Yihan
   Shao, Lingdan
   Chu, Zhe
   Chang, Remco
TI Semi-Automatic Layout Adaptation for Responsive Multiple-View
   Visualization Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Layout; Mobile handsets; Bars;
   Stacking; Design methodology; Multiple-view visualization; responsive
   design; layout adaptation; mobile devices
ID PATTERNS
AB Multiple-view (MV) visualizations have become ubiquitous for visual communication and exploratory data visualization. However, most existing MV visualizations are designed for the desktop, which can be unsuitable for the continuously evolving displays of varying screen sizes. In this article, we present a two-stage adaptation framework that supports the automated retargeting and semi-automated tailoring of a desktop MV visualization for rendering on devices with displays of varying sizes. First, we cast layout retargeting as an optimization problem and propose a simulated annealing technique that can automatically preserve the layout of multiple views. Second, we enable fine-tuning for the visual appearance of each view, using a rule-based auto configuration method complemented with an interactive interface for chart-oriented encoding adjustment. To demonstrate the feasibility and expressivity of our proposed approach, we present a gallery of MV visualizations that have been adapted from the desktop to small displays. We also report the result of a user study comparing visualizations generated using our approach with those by existing methods. The outcome indicates that the participants generally prefer visualizations generated using our approach and find them to be easier to use.
C1 [Zeng, Wei; Hou, Yihan] Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511400, Peoples R China.
   [Zeng, Wei; Hou, Yihan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Chen, Xi; Shao, Lingdan; Chu, Zhe] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 100045, Peoples R China.
   [Chen, Xi; Shao, Lingdan; Chu, Zhe] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
   [Chang, Remco] Tufts Univ, Medford, MA 02155 USA.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS; Tufts
   University
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511400, Peoples R China.
EM weizeng@hkust-gz.edu.cn; xi.chen2@siat.ac.cn;
   yhou073@connect.hkust-gz.edu.cn; ld.shao@siat.ac.cn; zhe.chu@siat.ac.cn;
   remco@cs.tufts.edu
OI Hou, Yihan/0000-0002-1459-8766; Chang, Remco/0000-0002-6484-6430; Zeng,
   Wei/0000-0002-5600-8824
FU National Natural Science Foundation of China [62172398]; National
   Science Foundation [OAC-1940175, OAC-1939945, OAC-2118201, IIS-1452977]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62172398 and in part by the National
   Science Foundation under Grants OAC-1940175, OAC-1939945, OAC-2118201,
   and IIS-1452977.
CR Agrawala M, 2001, COMP GRAPH, P241, DOI 10.1145/383259.383286
   Andrews A., 2017, P EUR C VIS, P113, DOI 10.2312/eurp.20171182
   Andrews K., 2018, P MOB VIS WORKSH CHI
   [Anonymous], 2004, Intelligent User Interfaces, DOI [10.1145/964442.964461, DOI 10.1145/964442.964461]
   Badam SK, 2021, INFORM VISUAL, V20, P229, DOI 10.1177/14738716211038614
   Baldonado M. Q. W., 2000, Proceedings of the Conference on Advanced Visual Interfaces, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P630, DOI 10.1109/TVCG.2018.2865142
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Brehmer M, 2019, IEEE T VIS COMPUT GR, V25, P619, DOI 10.1109/TVCG.2018.2865234
   Chen R, 2022, IEEE T VIS COMPUT GR, V28, P4127, DOI 10.1109/TVCG.2021.3076222
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen YL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P37, DOI 10.1145/3123266.3123274
   Chung HY, 2015, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2015.7347628
   Drucker S.M., 2013, P OF THE SIGCHI C ON, P2301
   Eisensten Jacob., 2001, IUI 01 P 6 INT C INT, P69
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   esri, ArcGIS Dashboards
   Filonik Daniel, 2013, Persuasive Technology. 8th International Conference, PERSUASIVE 2013. Proceedings, P51, DOI 10.1007/978-3-642-37157-8_8
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Hinderman B., 2015, Building Resp.nsive Data Visualization for the Web
   Hoffswell J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376777
   Horak S. K., 2018, P CHI C HUM FACT COM, P1
   Horak T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300846
   Jacobs C, 2003, ACM T GRAPHIC, V22, P838, DOI 10.1145/882262.882353
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jo J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2660, DOI 10.1145/3025453.3025752
   Johns Hopkins Coronavirus Resource Center, COVID-19 dashboard
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kieffer S, 2016, IEEE T VIS COMPUT GR, V22, P349, DOI 10.1109/TVCG.2015.2467451
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P129, DOI 10.1109/TVCG.2021.3114782
   Kim H, 2021, COMPUT GRAPH FORUM, V40, P459, DOI 10.1111/cgf.14321
   Kulkarni Chinmay., 2011, CHI, V2011, P1573, DOI DOI 10.1145/1979742.1979810
   Langner R, 2019, IEEE T VIS COMPUT GR, V25, P608, DOI 10.1109/TVCG.2018.2865235
   Langner R, 2018, IEEE T VIS COMPUT GR, V24, P626, DOI 10.1109/TVCG.2017.2744019
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Matkovic K, 2008, IEEE INT CONF INF VI, P215, DOI 10.1109/IV.2008.87
   microsoft, Power BI
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI [10.1145/345513.345282, DOI 10.1145/345513.345282]
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   Park S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173758
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Roberts JC, 2014, IEEE COMPUT GRAPH, V34, P26, DOI 10.1109/MCG.2014.82
   Sadana R, 2016, COMPUT GRAPH FORUM, V35, P261, DOI 10.1111/cgf.12902
   Sadana R, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P265, DOI 10.1145/2598153.2598163
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Shao LD, 2021, J VISUAL-JAPAN, V24, P1237, DOI 10.1007/s12650-021-00781-z
   Shervashidze N, 2011, J MACH LEARN RES, V12, P2539
   Spotfire, about us
   Tableau, About us
   Wang SD, 2023, IEEE T VIS COMPUT GR, V29, P1610, DOI 10.1109/TVCG.2021.3126478
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Weaver C, 2010, IEEE T VIS COMPUT GR, V16, P192, DOI 10.1109/TVCG.2009.94
   Wong B, 2011, NAT METHODS, V8, P5, DOI 10.1038/nmeth0111-5
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Wu YC, 2013, IEEE T VIS COMPUT GR, V19, P278, DOI 10.1109/TVCG.2012.114
   Yigitbasioglu Ogan M., 2012, International Journal of Accounting Information Systems, V13, P41, DOI 10.1016/j.accinf.2011.08.002
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
NR 64
TC 0
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3798
EP 3812
DI 10.1109/TVCG.2023.3240356
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700054
PM 37022242
DA 2024-08-05
ER

PT J
AU Guarese, R
   Pretty, E
   Renata, A
   Polson, D
   Zambetta, F
AF Guarese, Renan
   Pretty, Emma
   Renata, Aidan
   Polson, Deb
   Zambetta, Fabio
TI Exploring Audio Interfaces for Vertical Guidance in Augmented Reality
   via Hand-Based Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Sonification; Navigation; Cataracts;
   Three-dimensional displays; Blindness; Audio interfaces; augmented and
   mixed reality; assistive technologies
ID VIRTUAL-REALITY; BLIND; SYSTEM
AB This research proposes an evaluation of pitch-based sonification methods via user experiments in real-life scenarios, specifically vertical guidance, with the aim of standardizing the use of audio interfaces in AR in guidance tasks. Using literature on assistive technology for people who are blind or visually impaired, we aim to generalize their applicability to a broader population and for different use cases. We propose and test sonification methods for vertical guidance in a series of hand-navigation assessments with users without visual feedback. Including feedback from a visually impaired expert in digital accessibility, results (N=19) outlined that methods that do not rely on memorizing pitch had the most promising accuracy and self-reported workload performances. Ultimately, we argue for audio AR's ability to enhance user performance in different scenarios, from video games to finding objects in a pantry.
C1 [Guarese, Renan; Pretty, Emma; Zambetta, Fabio] RMIT Univ, Sch Comp Technol, Melbourne, Australia.
   [Renata, Aidan] Deakin Univ, Sch Psychol, Geelong, Australia.
   [Polson, Deb] RMIT Univ, Sch Design, Melbourne, Australia.
C3 Royal Melbourne Institute of Technology (RMIT); Deakin University; Royal
   Melbourne Institute of Technology (RMIT)
RP Guarese, R (corresponding author), RMIT Univ, Sch Comp Technol, Melbourne, Australia.
EM renan.guarese@rmit.edu.au; emma.pretty@rmit.edu.au;
   aidan.renata@research.deakin.edu.au; debra.polson@rmit.edu.au;
   fabio.zambetta@rmit.edu.au
OI Polson, Deb/0000-0002-5625-5980; Pretty, Emma/0000-0002-5108-5740;
   Renata, Aidan/0009-0001-8593-1757; Guarese, Renan/0000-0003-1206-5701
FU Australian Technology Network of Universities
FX No Statement Available
CR Ahmetovic D, 2023, INT J HUM-COMPUT ST, V177, DOI 10.1016/j.ijhcs.2023.103057
   Arons B., 1992, J. Amer. Voice I/O Soc., V12, P35
   Bandara D, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8121014
   Baranski P, 2015, C HUM SYST INTERACT, P173, DOI 10.1109/HSI.2015.7170662
   Barde A., 2020, Journal of the Audio Engineering Society
   Bigham C., 2010, P 23ND ANN ACM S USE, P333, DOI [10.1145/, DOI 10.1145/1866029]
   Binetti N, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102032
   Bourhim E, 2022, LECT NOTE NETW SYST, V418, P277, DOI 10.1007/978-3-030-96308-8_25
   Branham SM, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2373, DOI 10.1145/2702123.2702511
   Bruno F, 2019, OCEAN ENG, V190, DOI 10.1016/j.oceaneng.2019.106487
   Bujacz M., 2008, 2008 Conference on Human System Interactions, P888, DOI 10.1109/HSI.2008.4581561
   Campos P., 2011, Human-Computer Interaction-INTERACT 2011, P584
   Chaudary B, 2023, VIRTUAL REAL-LONDON, V27, P141, DOI 10.1007/s10055-021-00536-z
   Chaudary B, 2017, L N INST COMP SCI SO, V181, P9, DOI 10.1007/978-3-319-49655-9_2
   Coughlan B., An audio-based3d spatial guidance ar system for blind users
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   Delle Monache S, 2022, DESIGN STUD, V83, DOI 10.1016/j.destud.2022.101134
   Dinelli C, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7020136
   Faltaous Sarah, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P254, DOI 10.1145/3428361.3428389
   Fritsche P, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY AND RESCUE ROBOTICS (SSRR), P96, DOI 10.1109/SSRR.2017.8088146
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Gruenefeld U, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501821
   Gruenefeld U, 2018, AUTOMOTIVEUI'18: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P221, DOI 10.1145/3239060.3239080
   Guarese D., 2023, IN2023IEEE INT S MIX, P1
   Guarese R., 2022, INOZCHI 22 P 34 AUST, V11, DOI [10.1145/3572921.3572929[31]J, DOI 10.1145/3572921.3572929[31]J]
   Guarese R, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P324, DOI 10.1109/VRW58643.2023.00074
   Guarese R, 2023, Symposium Virtual Re, P184, DOI 10.1109/VR55154.2023.00034
   Günther S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P273, DOI 10.1145/3197768.3197785
   Guerreiro J, 2023, IEEE T VIS COMPUT GR, V29, P2763, DOI 10.1109/TVCG.2023.3247094
   Guerreiro J, 2020, INT J HUM-COMPUT ST, V135, DOI 10.1016/j.ijhcs.2019.102369
   HART S G, 1988, P139
   Hermann T., 2011, The Sonification Handbook
   Holton B., 2015, A review of the be my eyes remote sighted helper app for appleios
   Hu XH, 2022, IEEE T NEUR SYS REH, V30, P1621, DOI 10.1109/TNSRE.2022.3182661
   Huber H.-C., Navi-a proof-of-concept of a mobile navigational aid for visually impaired based on the mi-crosoft kinect
   Jain Y. Teng, Proc. ACM Hum.-Comput. Interact., V7, DOI [10.1145/3579496[39]M.S., DOI 10.1145/3579496[39]M.S]
   Jensen MS, 2011, WIRES COGN SCI, V2, P529, DOI 10.1002/wcs.130
   Kasowski J, 2023, J VISION, V23, DOI 10.1167/jov.23.5.5
   Katz BFG, 2012, VIRTUAL REAL-LONDON, V16, P253, DOI 10.1007/s10055-012-0213-6
   Kaul M., 2016, 2016 CHI EA SAN JOS, P2533
   Keenan RY, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3378576
   Kerdegari Y. Kim, Head-mounted sensory augmen-tation device: Comparing haptic and audio modality
   Kim DH, 2023, INT SYM MIX AUGMENT, P990, DOI 10.1109/ISMAR59233.2023.00115
   Krösl K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P655, DOI [10.1109/VR.2019.8798239, 10.1109/vr.2019.8798239]
   Lee Y, 2021, J COMPUT DES ENG, V8, P756, DOI 10.1093/jcde/qwab012
   Lepora N. F., 2016, Biomimetic and Biohybrid Systems, P107
   Lin JC, 2021, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD014953.pub2
   Liu Y, 2018, ELIFE, V7, DOI 10.7554/eLife.37841
   Liu YC, 2017, LANCET, V390, P600, DOI 10.1016/S0140-6736(17)30544-5
   Löcken A, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119894
   Lovreglio R, 2020, SAFETY SCI, V128, DOI 10.1016/j.ssci.2020.104750
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Marquardt A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281525
   Marques Bernardo, 2022, MUM '22: Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia, P276, DOI 10.1145/3568444.3570587
   Martin D, 2023, IEEE T VIS COMPUT GR, V29, P2446, DOI 10.1109/TVCG.2023.3247102
   Mascetti S, 2016, INT J HUM-COMPUT ST, V85, P16, DOI 10.1016/j.ijhcs.2015.08.003
   May B., 2019, INPROCEEDINGS 2019IN, P155, DOI [DOI 10.21785/ICAD2019.008[57]K.R, 10.21785/icad2019.008, DOI 10.21785/ICAD2019.008]
   Miesenberger K., 2020, Computers HelpingPeople with Special Needs, P475
   Nair Vishnu, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P538, DOI 10.1145/3472749.3474768
   Nair V, 2022, PROCEEDINGS OF THE 24TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2022, DOI 10.1145/3517428.3544802
   Navolio N, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00231
   Neuhoff R., 2002, P 2002INTERNATIONAL
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Paré S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247448
   Schall MC, 2013, HUM FACTORS, V55, P643, DOI 10.1177/0018720812462029
   Schöne B, 2021, VIRTUAL REAL-LONDON, V25, P209, DOI 10.1007/s10055-020-00450-w
   Schofield A. Dasys, 2010, Journal of EmergencyManagement, V8, P45
   Senan B., 2022, INPROCEEDINGS 17 INT, P187, DOI [10.1145/3561212.3561239[71]B.A., DOI 10.1145/3561212.3561239[71]B.A]
   Smith BA, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174090
   Unertl R. J., 2016, Usability: Making It Realfrom Concepts to Implementation and End-User Adoption, P165, DOI [10.1007/978-3-319-20765-09[73]Y, DOI 10.1007/978-3-319-20765-09[73]Y]
   Wang YW, 2022, INT J HUM-COMPUT INT, V38, P837, DOI 10.1080/10447318.2021.1970434
   Wu RJ, 2023, INT SYM MIX AUGMENT, P1045, DOI 10.1109/ISMAR59233.2023.00121
   Yang J, 2022, J AUDIO ENG SOC, V70, P788, DOI 10.17743/jaes.2022.0048
   Yang J, 2020, J MULTIMODAL USER IN, V14, P337, DOI 10.1007/s12193-020-00331-1
   Zhao Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376516
   Zijlstra A.T., 2017, Master's thesis
NR 78
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2818
EP 2828
DI 10.1109/TVCG.2024.3372040
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400044
PM 38437120
DA 2024-08-05
ER

PT J
AU Heagerty, J
   Li, SD
   Lee, ER
   Bhattacharyya, S
   Bista, S
   Brawn, B
   Feng, BY
   Jabbireddy, S
   Jaja, J
   Kacorri, H
   Li, DV
   Yarnell, D
   Zwicker, M
   Varshney, A
AF Heagerty, Jonathan
   Li, Sida
   Lee, Eric
   Bhattacharyya, Shuvra
   Bista, Sujal
   Brawn, Barbara
   Feng, Brandon Y.
   Jabbireddy, Susmija
   Jaja, Joseph
   Kacorri, Hernisa
   Li, David
   Yarnell, Derek
   Zwicker, Matthias
   Varshney, Amitabh
TI HoloCamera: Advanced Volumetric Capture for Cinematic-Quality VR
   Applications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Volumetric Capture; Light Fields; Holoportation; Multi-camera Array
AB High-precision virtual environments are increasingly important for various education, simulation, training, performance, and entertainment applications. We present HoloCamera, an innovative volumetric capture instrument to rapidly acquire, process, and create cinematic-quality virtual avatars and scenarios. The HoloCamera consists of a custom-designed free-standing structure with 300 high-resolution RGB cameras mounted with uniform spacing spanning the four sides and the ceiling of a room-sized studio. The light field acquired from these cameras is streamed through a distributed array of GPUs that interleave the processing and transmission of 4K resolution images. The distributed compute infrastructure that powers these RGB cameras consists of 50 Jetson AGX Xavier boards, with each processing unit dedicated to driving and processing imagery from six cameras. A high-speed Gigabit Ethernet network fabric seamlessly interconnects all computing boards. In this systems paper, we provide an in-depth description of the steps involved and lessons learned in constructing such a cutting-edge volumetric capture facility that can be generalized to other such facilities. We delve into the techniques employed to achieve precise frame synchronization and spatial calibration of cameras, careful determination of angled camera mounts, image processing from the camera sensors, and the need for a resilient and robust network infrastructure. To advance the field of volumetric capture, we are releasing a high-fidelity static light-field dataset, which will serve as a benchmark for further research and applications of cinematic-quality volumetric light fields.
C1 [Heagerty, Jonathan; Li, Sida; Lee, Eric; Bhattacharyya, Shuvra; Bista, Sujal; Brawn, Barbara; Feng, Brandon Y.; Jabbireddy, Susmija; Jaja, Joseph; Kacorri, Hernisa; Li, David; Yarnell, Derek; Zwicker, Matthias; Varshney, Amitabh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Heagerty, J (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM jheager2@umd.edu; sidali@umd.edu; erclee2@gmail.com; ssb@umd.edu;
   sujal@umd.edu; bbrawn@umd.edu; yfeng97@umd.edu; jsreddy@umd.edu;
   josephj@umd.edu; hernisa@umd.edu; dli7319@umd.edu; derek@umiacs.umd.edu;
   zwicker@umd.edu; varshney@cs.umd.edu
RI Feng, Brandon Y./ABH-3517-2021
OI Feng, Brandon Y./0000-0001-7003-9128; Li, Sida/0000-0003-2601-821X;
   Kacorri, Hernisa/0000-0002-7798-308X; Bhattacharyya,
   Shuvra/0000-0001-7719-1106; JaJa, joseph/0000-0002-8620-5650
FU NSF
FX No Statement Available
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2767
EP 2775
DI 10.1109/TVCG.2024.3372123
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400031
PM 38564356
DA 2024-08-05
ER

PT J
AU Westermeier, F
   Brübach, L
   Wienrich, C
   Latoschik, ME
AF Westermeier, Franziska
   Bruebach, Larissa
   Wienrich, Carolin
   Latoschik, Marc Erich
TI Assessing Depth Perception in VR and Video See-Through AR: A Comparison
   on Distance Judgment, Performance, and Preference
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Depth perception; VR; AR; video see-through; egocentric distance
   judgment; task performance; user preference
ID VIRTUAL-REALITY; AUGMENTED REALITY; ANOVA
AB Spatial User Interfaces along the Reality-Virtuality continuum heavily depend on accurate depth perception. However, current display technologies still exhibit shortcomings in the simulation of accurate depth cues, and these shortcomings also vary between Virtual or Augmented Reality (VR, AR: eXtended Reality (XR) for short). This article compares depth perception between VR and Video See-Through (VST) AR. We developed a digital twin of an existing office room where users had top erform five depth-dependent tasks in VR and VST AR. Thirty-two participants took part in a user study using a 1 x 4 within-subjects design. Our results reveal higher misjudgment rates in VST AR due to conflicting depth cues between virtual and physical content. Increased head movements observed in participants were interpreted as a compensatory response to these conflicting cues. Furthermore, a longer task completion time in the VST AR condition indicates a lower task performance in VST AR. Interestingly, while participants rated the VR condition as easier and contrary to the increased misjudgments and lower performance with the VST AR display, a majority still expressed a preference for the VST AR experience. We discuss and explain these findings with the high visual dominance and referential power of the physical content in the VST AR condition, leading to a higher spatial presence and plausibility.
C1 [Westermeier, Franziska] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Westermeier, Franziska; Bruebach, Larissa] Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp, Wurzburg, Germany.
   [Wienrich, Carolin] Univ Wurzburg, PIIS Grp, Wurzburg, Germany.
   [Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; University of Wurzburg;
   University of Wurzburg
RP Westermeier, F (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.; Westermeier, F (corresponding author), Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp, Wurzburg, Germany.
EM franziska.westermeier@uni-wuerzburg.de;
   larissa.bruebach@uni-wuerzburg.de; carolin.wienrich@uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
OI Brubach, Larissa/0000-0003-0171-7305; Wienrich,
   Carolin/0000-0003-3052-7172; Westermeier, Franziska/0000-0003-2534-4857
FU Bavarian State Ministry For Digital Affairs
FX No Statement Available
CR Adams H, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P792, DOI 10.1109/VR51125.2022.00101
   [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Ballestin G, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P184, DOI 10.1109/ISMAR-Adjunct.2018.00063
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Bodenheimer B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P35
   Brubach L, 2022, IEEE T VIS COMPUT GR, V28, P2267, DOI 10.1109/TVCG.2022.3150496
   Cidota MA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P172, DOI [10.1109/ISMAR-Adjunct.2016.61, 10.1109/ISMAR-Adjunct.2016.0070]
   Cooper EA, 2023, ANNU REV VIS SCI, V9, P455, DOI 10.1146/annurev-vision-111022-123758
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Gagnon HC, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407933
   HART S G, 1988, P139
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   HARWELL MR, 1992, J EDUC STAT, V17, P315, DOI 10.2307/1165127
   HENRY D, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P33, DOI 10.1109/VRAIS.1993.380801
   Howard I. P., 2002, Depth perception, V2, P2
   Hubona GS, 2005, LECT NOTES COMPUT SC, V3345, P104
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Kelly JW, 2023, IEEE T VIS COMPUT GR, V29, P4978, DOI 10.1109/TVCG.2022.3196606
   Kelly JW, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.850471
   Kern Florian, 2023, 2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct), P74, DOI 10.1109/ISMAR-Adjunct60411.2023.00023
   Kern Florian, 2023, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2023.3247098
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489949
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Krichenbauer M, 2018, IEEE T VIS COMPUT GR, V24, P1038, DOI 10.1109/TVCG.2017.2658570
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, DOI [10.1111/j.1083-6101.1997.tb0, 10.1111/j.1083-6101.1997.tb00072.x., 10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X, 10.1111/J.1083-6101.1997.TB00072.X/4080403]
   Lugrin J.L., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P49, DOI [10.1145/2503713.25037305, DOI 10.1145/2503713.2503730]
   Messing R., 2005, ACM Transactions on Applied Perception, V2, P234, DOI [DOI 10.1145/1077399.1077403, 10.1145/1077399.10774032,3,9]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Normand Jean-Marie., 2012, Proceedings of the 3rd Augmented Human International Conference, P18, DOI [DOI 10.1145/2160125.2160143, 10.1145/2160125.2160143]
   Oberdörfer S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679277
   Pfeil K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445223
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/vr.2019.8798174, 10.1109/VR.2019.8798174]
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Vallat R, 2018, J. Open Source Softw, V3, P1026, DOI DOI 10.21105/JOSS.01026
   Vaziri K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P336, DOI 10.1109/VR50410.2021.00056
   Vorderer P., 2003, Report to the European Community, Project Presence: MEC (IST-2001- 37661), P6
   Westermeier F, 2023, 29TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2023, DOI 10.1145/3611659.3617227
   Westermeier F, 2023, IEEE T VIS COMPUT GR, V29, P2680, DOI 10.1109/TVCG.2023.3247046
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Willemsen P., 2004, The effects of head-mounted display mechanics on distance judgments in virtual environments. page, P35, DOI [DOI 10.1145/1012551.1012558, 10.1145/1012551.10125582,3,8]
NR 47
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2140
EP 2150
DI 10.1109/TVCG.2024.3372061
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400029
PM 38437131
OA hybrid
DA 2024-08-05
ER

PT J
AU Xu, SZ
   Huang, K
   Fan, CW
   Zhang, SH
AF Xu, Sen-Zhe
   Huang, Kui
   Fan, Cheng-Wei
   Zhang, Song-Hai
TI Spatial Contraction Based on Velocity Variation for Natural Walking in
   Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Contracts; Visualization; Aerospace electronics;
   Virtual environments; Three-dimensional displays; Space stations;
   Virtual reality; spatial contraction; locomotion; redirected walking;
   velocity
ID SPEED
AB Virtual Reality (VR) offers an immersive 3D digital environment, but enabling natural walking sensations without the constraints of physical space remains a technological challenge. Previous VR locomotion methods, including game controller, teleportation, treadmills, walking-in-place, and redirected walking (RDW), have made strides towards overcoming this challenge. However, these methods also face limitations such as possible unnaturalness, additional hardware requirements, or motion sickness risks. This paper introduces "Spatial Contraction (SC)", an innovative VR locomotion method inspired by the phenomenon of Lorentz contraction in Special Relativity. Similar to the Lorentz contraction, our SC contracts the virtual space along the user's velocity direction in response to velocity variation. The virtual space contracts more when the user's speed is high, whereas minimal or no contraction happens at low speeds. We provide a virtual space transformation method for spatial contraction and optimize the user experience in smoothness and stability. Through SC, VR users can effectively traverse a longer virtual distance with a shorter physical walking. Different from locomotion gains, the spatial contraction effect is observable by the user and aligns with their intentions, so there is no inconsistency between the user's proprioception and visual perception. SC is a general locomotion method that has no special requirements for VR scenes. The experimental results of our live user studies in various virtual scenarios demonstrate that SC has a significant effect in reducing both the number of resets and the physical walking distance users need to cover. Furthermore, experiments have also demonstrated that SC has the potential for integration with existing locomotion techniques such as RDW.
C1 [Xu, Sen-Zhe; Huang, Kui; Fan, Cheng-Wei; Zhang, Song-Hai] Tsinghua Univ, Beijing, Peoples R China.
   [Zhang, Song-Hai] Qinghai Univ, Qinghai, Peoples R China.
C3 Tsinghua University; Qinghai University
RP Xu, SZ (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM xsz15@tsinghua.org.cn; huangk21@mails.tsinghua.edu.cn;
   fcw20@mails.tsinghua.edu.cn; shz@tsinghua.edu.cn
OI Huang, Kui/0009-0005-5411-581X; Xu, Sen-Zhe/0000-0003-2669-7814
FU National Key Research and Development Program of China
FX No Statement Available
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Anderson FC, 2001, J BIOMECH ENG-T ASME, V123, P381, DOI 10.1115/1.1392310
   ANDRIACCHI TP, 1977, J BIOMECH, V10, P261, DOI 10.1016/0021-9290(77)90049-5
   Azmandian T., Physical SpaceRequirements for Redirected Walking: How Size and Shape Affect Per-formance
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Boletsis C, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6090072
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Cakmak H., INACM SIGGRAPH 2014, DOI [10.1145/2614066.26141052[11]Z.-Y, DOI 10.1145/2614066.26141052[11]Z.-Y]
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cherni N., 2020, International Journal of Virtual Reality, DOI [10.20870/IJVR.2020.20.1.31832,3,6[13]C, DOI 10.20870/IJVR.2020.20.1.31832,3,6[13]C]
   Ciumedean C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P389, DOI 10.1109/VRW52623.2021.00081
   Darken W. R., 1997, INACM SYMPOSIUMNON U, DOI [10.1145/263407.2635503, DOI 10.1145/263407.2635503]
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Grechkin J., 2016, P ACM S APPL PERC SA, P113, DOI [10.1145/2931002.29310182[19]J, DOI 10.1145/2931002.2931018]
   Han J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P167, DOI 10.1109/VR51125.2022.00035
   Interrante B., 2007, IN2007 IEEE S 3D USE, DOI [10.1109/3DUI.2007.3407913[21]R.S., DOI 10.1109/3DUI.2007.3407913[21]R.S]
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kim D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P379, DOI 10.1109/VR51125.2022.00057
   Lai CY, 2020, INT SYM MIX AUGMENT, P627, DOI 10.1109/ISMAR50242.2020.00091
   LaViola Jr E., 2017, Addison-Wesley Professional, V2
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Lugrin JL, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364780
   Martinez ES, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P270, DOI 10.1109/VR51125.2022.00046
   Marwecki P., 2018, InUser Interface Software andTechnology, DOI [10.1145/3242587.32426483[32]D, DOI 10.1145/3242587.32426483[32]D]
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P327, DOI 10.1145/2993369.2996348
   Medina R., 2008, P HUMAN FACTORS ERGO, P3, DOI [10.1177/1541931208052027043[34]J, DOI 10.1177/1541931208052027043[34]J]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Mohler B., 2015, ICAT EGVE2015 INT C, DOI [10.2312/egve.201513152,6[6]E.R, DOI 10.2312/EGVE.201513152,6[6]E.R]
   Nescher T, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P15, DOI 10.1109/CW.2012.10
   Selzer MN, 2022, VIRTUAL REAL-LONDON, V26, P1459, DOI 10.1007/s10055-022-00640-8
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Prinz T., 2022, IEEE transactions on visualizationand computer graphics, DOI [10.1109/TVCG.2022.32069152,6[38]S, DOI 10.1109/TVCG.2022.32069152,6[38]S]
   Pyo H., 2021, Ap-plied Sciences, V11, DOI [10.3390/app110942233[39]Y.Y., DOI 10.3390/APP110942233[39]Y.Y]
   Qian YY, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P130, DOI 10.1145/3267782.3267798
   Razzaque Z., 2001, InEurographics 2001-Short Presentations, DOI [10.2312/egs.200110362[41]B.E., DOI 10.2312/EGS.200110362[41]B.E]
   Riecke D., 2021, IN2021 IEEE C VIRTUA, DOI [10.1109/vrw52623.2021.000752[42]M.M., DOI 10.1109/VRW52623.2021.000752[42]M.M]
   Samson MM, 2001, AGING CLIN EXP RES, V13, P16, DOI 10.1007/BF03351489
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke G., 2009, JVRB-Journal of Virtual Reality and Broadcasting, V6, DOI [10.20385/1860-2037/6.2009.22,6[46]F, DOI 10.20385/1860-2037/6.2009.22,6[46]F]
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Waller D, 2007, BEHAV RES METHODS, V39, P835, DOI 10.3758/BF03192976
   Wang Z.-Y., 2022, IEEE Transac-tions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32240733[55]L.E., DOI 10.1109/TVCG.2022.32240733[55]L.E]
   Warren LE, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P163, DOI 10.1145/3131277.3134359
   Xu SZ, 2024, IEEE T VIS COMPUT GR, V30, P1916, DOI 10.1109/TVCG.2023.3251648
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P3327, DOI 10.1109/TVCG.2022.3158609
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
NR 58
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2444
EP 2453
DI 10.1109/TVCG.2024.3372109
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400025
PM 38437083
DA 2024-08-05
ER

PT J
AU Zhang, TY
   Shen, YR
   Zhao, GR
   Wang, L
   Chen, XM
   Bai, L
   Zhou, YF
AF Zhang, Tongyu
   Shen, Yiran
   Zhao, Guangrong
   Wang, Lin
   Chen, Xiaoming
   Bai, Lu
   Zhou, Yuanfeng
TI Swift-Eye: Towards Anti-blink Pupil Tracking for Precise and Robust
   High-Frequency Near-Eye Movement Analysis with Event Cameras
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Eye tracking; event camera; feature fusion
ID GAZE; TECHNOLOGY
AB Eye tracking has shown great promise in many scientific fields and daily applications, ranging from the early detection of mental health disorders to foveated rendering in virtual reality (VR). These applications all call for a robust system for high-frequency near-eye movement sensing and analysis in high precision, which cannot be guaranteed by the existing eye tracking solutions with CCD/CMOS cameras. To bridge the gap, in this paper, we propose Swift-Eye, an offline precise and robust pupil estimation and tracking framework to support high-frequency near-eye movement analysis, especially when the pupil region is partially occluded. Swift-Eye is built upon the emerging event cameras to capture the high-speed movement of eyes in high temporal resolution. Then, a series of bespoke components are designed to generate high-quality near-eye movement video at a high frame rate over kilohertz and deal with the occlusion over the pupil caused by involuntary eye blinks. According to our extensive evaluations on EV-Eye, a large-scale public dataset for eye tracking using event cameras, Swift-Eye shows high robustness against significant occlusion. It can improve the IoU and F1-score of the pupil estimation by 20% and 12.5% respectively, compared with the second-best competing approach, when over 80% of the pupil region is occluded by the eyelid. Lastly, it provides continuous and smooth traces of pupils in extremely high temporal resolution and can support high-frequency eye movement analysis and a number of potential applications, such as mental health diagnosis, behaviour-brain association, etc. The implementation details and source codes can be found at https://github.com/ztysdu/Swift-Eye.
C1 [Zhang, Tongyu; Shen, Yiran; Zhao, Guangrong; Zhou, Yuanfeng] Shandong Univ, Sch Software, Jinan, Peoples R China.
   [Bai, Lu] Shandong Univ, C FAIR, Jinan, Peoples R China.
   [Bai, Lu] Shandong Res Inst Ind Technol, Dezhou, Peoples R China.
   [Chen, Xiaoming] Beijing Technol & Business Univ, Beijing, Peoples R China.
   [Wang, Lin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Shandong University; Shandong University; Beijing Technology & Business
   University; Hong Kong University of Science & Technology
RP Shen, YR (corresponding author), Shandong Univ, Sch Software, Jinan, Peoples R China.; Bai, L (corresponding author), Shandong Univ, C FAIR, Jinan, Peoples R China.; Bai, L (corresponding author), Shandong Res Inst Ind Technol, Dezhou, Peoples R China.
EM tongyu.zhang@mail.sdu.edu.cn; yiran.shen@sdu.edu.cn;
   guangrong.zhao@sdu.edu.cn; linwang@ust.hk; xiaoming.chen@btbu.edu.cn;
   lubai@sdu.edu.cn; yfzhou@sdu.edu.cn
RI wang, Lin/GQO-7901-2022
OI wang, Lin/0000-0002-7485-4493; Shen, Yiran/0000-0003-1385-1480; Chen,
   Xiaoming/0000-0002-7503-3021; Zhao, Guangrong/0000-0002-4703-9397
FU National Natural Science Foundation of China
FX No Statement Available
CR ABRAMS RA, 1989, J EXP PSYCHOL HUMAN, V15, P529, DOI 10.1037/0096-1523.15.3.529
   Adhanom IB, 2023, VIRTUAL REAL-LONDON, V27, P1481, DOI 10.1007/s10055-022-00738-z
   Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   Bao YW, 2023, Symposium Virtual Re, P22, DOI 10.1109/VR55154.2023.00018
   Boraston Z, 2007, J PHYSIOL-LONDON, V581, P893, DOI 10.1113/jphysiol.2007.133587
   Clarke AH, 2002, BEHAV RES METH INS C, V34, P549, DOI 10.3758/BF03195484
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Eckstein MK, 2017, DEV COGN NEUROS-NETH, V25, P69, DOI 10.1016/j.dcn.2016.11.001
   Feng Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P399, DOI 10.1109/VR51125.2022.00059
   Fernandes AS, 2023, IEEE T VIS COMPUT GR, V29, P2269, DOI 10.1109/TVCG.2023.3247058
   foveator, Extreme eye tracking with event cameras
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Halir R, 1998, WSCG '98, VOL 1, P125
   Harezlak K, 2018, COMPUT MED IMAG GRAP, V65, P176, DOI 10.1016/j.compmedimag.2017.04.006
   inivation, DAVIS346 Event Camera
   Kiili K, 2014, INT J SERIOUS GAMES, V1, P51, DOI 10.17083/ijsg.v1i2.15
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Kothari RS, 2021, IEEE T VIS COMPUT GR, V27, P2757, DOI 10.1109/TVCG.2021.3067765
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li D., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P79, DOI DOI 10.1109/CVPR.2005.531
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lohr Dillon, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P276, DOI 10.1109/TBIOM.2022.3167633
   Majaranta P., 2014, ADV PHYSIOLOGICAL CO, P39, DOI DOI 10.1007/978-1-4471-6392-33
   Makowski S., 2020, IEEEIAPR INT JOINT, P1, DOI [DOI 10.1109/IJCB48548.2020.9304900, DOI 10.1109/ijcb48548.2020.9304900]
   Rappa NA, 2022, INTERACT LEARN ENVIR, V30, P1338, DOI 10.1080/10494820.2019.1702560
   Singh R, 2023, Symposium Virtual Re, P205, DOI 10.1109/VR55154.2023.00036
   Suvorov R, 2021, arXiv
   Tao L, 2020, NEUROL SCI, V41, P1697, DOI 10.1007/s10072-020-04310-y
   Tulyakov S, 2021, PROC CVPR IEEE, P16150, DOI 10.1109/CVPR46437.2021.01589
   Vaswani A, 2017, ADV NEUR IN, V30
   wikipedia, Wikipedia blinking
   wikipedia, Wikipedia saccade
   Wu Zhengyang., 2019, Eyenet: A multi-task network for off-axis eye gaze estimation and user understanding
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Zhao G., 2023, 37 C NEURAL INFORM P
   Zhou Y, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P7331, DOI 10.1145/3503161.3548541
NR 40
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2077
EP 2086
DI 10.1109/TVCG.2024.3372039
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400003
PM 38437077
DA 2024-08-05
ER

PT J
AU Maack, RGC
   Lukasczyk, J
   Tierny, J
   Hagen, H
   Maciejewski, R
   Garth, C
AF Maack, Robin G. C.
   Lukasczyk, Jonas
   Tierny, Julien
   Hagen, Hans
   Maciejewski, Ross
   Garth, Christoph
TI Parallel Computation of Piecewise Linear Morse-Smale Segmentations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Morse-smale complex; segmentation; topology; visualization; watershed
   transformation
ID EFFICIENT COMPUTATION; COMPLEXES; SIMPLIFICATION; SIMULATION; SURFACES;
   DISTANCE
AB This article presents a well-scaling parallel algorithm for the computation of Morse-Smale (MS) segmentations, including the region separators and region boundaries. The segmentation of the domain into ascending and descending manifolds, solely defined on the vertices, improves the computational time using path compression and fully segments the border region. Region boundaries and region separators are generated using a multi-label marching tetrahedra algorithm. This enables a fast and simple solution to find optimal parameter settings in preliminary exploration steps by generating an MS complex preview. It also poses a rapid option to generate a fast visual representation of the region geometries for immediate utilization. Two experiments demonstrate the performance of our approach with speedups of over an order of magnitude in comparison to two publicly available implementations. The example section shows the similarity to the MS complex, the useability of the approach, and the benefits of this method with respect to the presented datasets. We provide our implementation with the paper.
C1 [Maack, Robin G. C.; Lukasczyk, Jonas; Hagen, Hans; Garth, Christoph] RPTU Kaiserslautern Landau, D-67663 Kaiserslautern, Germany.
   [Tierny, Julien] Sorbonne Univ, CNRS, F-75006 Paris, France.
   [Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85281 USA.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique
   (CNRS); Arizona State University; Arizona State University-Tempe
RP Maack, RGC (corresponding author), RPTU Kaiserslautern Landau, D-67663 Kaiserslautern, Germany.
EM maack@rhrk.uni-kl.de; jl@jluk.de; julien.tierny@sorbonne-universite.fr;
   hagen@cs.uni-kl.de; rmacieje@asu.edu; garth@cs.uni-kl.de
OI Lukasczyk, Jonas/0000-0001-6650-770X; Garth,
   Christoph/0000-0003-1669-8549; Hagen, Hans/0000-0001-5626-963X; Maack,
   Robin Georg Claus/0000-0002-2414-3351
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR Atallah M. J., 2010, Algorithms and Theory of Computation Handbook, V2nd, P82
   Banchoff T. F., 1967, Journal of Differential Geometry, V1, P245, DOI DOI 10.4310/JDG/1214428092
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Beucher S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1928
   Beucher S., 1979, P INT WORKSH IM PROC
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3
   Carr H, 2006, IEEE T VIS COMPUT GR, V12, P231, DOI 10.1109/TVCG.2006.22
   Chouchane M, 2019, ACS OMEGA, V4, P11141, DOI 10.1021/acsomega.9b01279
   Cook AW, 2004, J FLUID MECH, V511, P333, DOI 10.1017/S0022112004009681
   Danovaro E, 2003, LECT NOTES COMPUT SC, V2616, P386
   Danovaro E., 2003, Proceedings ACM GIS 2003 - The 11th International Symposium on Advances in Geographic Information Systems, P63, DOI DOI 10.1145/956676.956685
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   DOI A, 1991, IEICE TRANS COMMUN, V74, P214
   Dong S, 2006, ACM T GRAPHIC, V25, P1057, DOI 10.1145/1141911.1141993
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Edelsbrunner H., 2009, Computational Topology: An Introduction
   Edelsbrunner H., 2003, P 19 ANN S COMP GEOM, P361, DOI [10.1145/777792.777846, DOI 10.1145/777792.777846]
   Fellegara R., 2014, PROC 22 ACM SIGSPATI, P223
   Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650
   Forman R., 2002, Seminaire Lotharingien de Combinatoire, V48, pB48c
   Gabrielyan Y, 2022, IEEE IMAGE PROC, P1501, DOI 10.1109/ICIP46576.2022.9897372
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2007, IEEE T VIS COMPUT GR, V13, P1440, DOI 10.1109/TVCG.2007.70552
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2016, IEEE T VIS COMPUT GR, V22, P916, DOI 10.1109/TVCG.2015.2467432
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Gyulassy A, 2012, INT PARALL DISTRIB P, P484, DOI 10.1109/IPDPS.2012.52
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Homberg U., 2014, Topological Methods in Data Analysis and Visualization, VIII, P235
   King H, 2005, EXP MATH, V14, P435, DOI 10.1080/10586458.2005.10128941
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Lewiner T, 2013, COMPUT AIDED GEOM D, V30, P609, DOI 10.1016/j.cagd.2012.03.012
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Masood T. B, 2021, Topological Methods in Data Analysis and Visualization VI: Theory, Applications, and Software
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Meyer F., 1993, Mathematical morphology and its applications to signal processing, P70
   Milnor J., 1963, Morse theory, V51
   Müller TM, 2014, COMP MATER SCI, V81, P205, DOI 10.1016/j.commatsci.2013.08.013
   Najman L, 1993, PROC MATH MORPHOL AP, P76
   Nielson GM, 1997, VISUALIZATION '97 - PROCEEDINGS, P229, DOI 10.1109/VISUAL.1997.663887
   NIELSON GM, 1991, VISUALIZATION 91, P83
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Peterka T., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P105, DOI 10.1109/LDAV.2011.6092324
   Pierre G, 2023, IEEE Trans. Vis. Comput. Graph.
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Seidel R, 2005, SIAM J COMPUT, V34, P515, DOI 10.1137/S0097539703439088
   Shivashankar N, 2012, IEEE T VIS COMPUT GR, V18, P1757, DOI 10.1109/TVCG.2011.284
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Soille P., 2004, Morphological Image Analysis, DOI [10.1007/978-3-662-05088-0, DOI 10.1007/978-3-662-05088-0]
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Stoev SL, 2000, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2000.885672
   Subhash V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P36, DOI 10.1109/VIS47514.2020.00014
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   TTK Contributers, 2021, TTK Tutorial Data
   TTK Contributers, 2020, TTK Data Repository
   Venkat A, 2022, IEEE T VIS COMPUT GR, V28, P76, DOI 10.1109/TVCG.2021.3114819
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Weinkauf T, 2010, COMPUT GRAPH FORUM, V29, P1221, DOI 10.1111/j.1467-8659.2009.01702.x
   Weinstein D, 2000, IEEE VISUAL, P283, DOI 10.1109/VISUAL.2000.885706
   Yeghiazaryan V, 2018, IEEE WINT CONF APPL, P577, DOI 10.1109/WACV.2018.00069
   ZHANG N., 2006, Proceedings of Eurographics Symposium on Point-Based Graphics 2006, P145
NR 72
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1942
EP 1955
DI 10.1109/TVCG.2023.3261981
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500009
PM 37030777
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Davis, R
   Pu, XY
   Ding, YR
   Hall, BD
   Bonilla, K
   Feng, M
   Kay, M
   Harrison, L
AF Davis, Russell
   Pu, Xiaoying
   Ding, Yiren
   Hall, Brian D.
   Bonilla, Karen
   Feng, Mi
   Kay, Matthew
   Harrison, Lane
TI The Risks of Ranking: Revisiting Graphical Perception to Model
   Individual Differences in Visualization Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Visualization; Correlation;
   Observers; Bars; Sociology; graphical perception; individual differences
ID REGRESSION; LITERACY; DESIGN
AB Graphical perception studies typically measure visualization encoding effectiveness using the error of an "average observer", leading to canonical rankings of encodings for numerical attributes: e.g., position > area > angle > volume. Yet different people may vary in their ability to read different visualization types, leading to variance in this ranking across individuals not captured by population-level metrics using "average observer" models. One way we can bridge this gap is by recasting classic visual perception tasks as tools for assessing individual performance, in addition to overall visualization performance. In this article we replicate and extend Cleveland and McGill's graphical comparison experiment using Bayesian multilevel regression, using these models to explore individual differences in visualization skill from multiple perspectives. The results from experiments and modeling indicate that some people show patterns of accuracy that credibly deviate from the canonical rankings of visualization effectiveness. We discuss implications of these findings, such as a need for new ways to communicate visualization effectiveness to designers, how patterns in individuals' responses may show systematic biases and strategies in visualization judgment, and how recasting classic visual perception tasks as tools for assessing individual performance may offer new ways to quantify aspects of visualization literacy. Experiment data, source code, and analysis scripts are available at the following repository: https://osf.io/8ub7t/?view_only=9be4798797404a4397be3c6fc2a68cc0 .
C1 [Davis, Russell; Ding, Yiren; Feng, Mi; Harrison, Lane] Worcester Polytech Inst, Worcester, MA 01609 USA.
   [Bonilla, Karen] Worcester Polytech Inst, Dept Comp Sci, VIEW Grp, Worcester, MA 01609 USA.
   [Pu, Xiaoying] Univ Calif Merced, Merced, CA 95343 USA.
   [Hall, Brian D.] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Kay, Matthew] Northwestern Univ, Comp Sci & Commun Studies, Evanston, IL 60208 USA.
C3 Worcester Polytechnic Institute; Worcester Polytechnic Institute;
   University of California System; University of California Merced;
   University of Michigan System; University of Michigan; Northwestern
   University
RP Ding, YR (corresponding author), Worcester Polytech Inst, Worcester, MA 01609 USA.
EM rdavis@wpi.edu; xpu@ucmerced.edu; yding5@wpi.edu; briandh@umich.edu;
   kbonilla@wpi.edu; mfeng2@wpi.edu; mjskay@northwestern.edu;
   ltharrison@wpi.edu
RI Kay, Matthew/AAN-2490-2021
OI Kay, Matthew/0000-0001-9446-0419; Harrison, Lane/0000-0003-3029-2799;
   Ding, Yiren/0000-0001-8983-9117
FU National Science Foundation
FX No Statement Available
CR Adler D., 1966, Elements of Psychophysics
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   [Anonymous], 2010, 28 ACM INT C COMMUN
   BAIRD JC, 1970, PERCEPT PSYCHOPHYS, V8, P358, DOI 10.3758/BF03212608
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Berinato S., 2016, GOOD CHARTS HBR GUID
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Burkner PC, 2017, Arxiv, DOI [arXiv:1705.11123, 10.48550/arXiv.1705.11123, DOI 10.48550/ARXIV.1705.11123]
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dillon A, 1996, INT J HUM-COMPUT ST, V45, P619, DOI 10.1006/ijhc.1996.0071
   EKMAN G, 1968, PERCEPT MOTOR SKILL, V26, P815, DOI 10.2466/pms.1968.26.3.815
   EKMAN G, 1958, J PSYCHOL, V45, P287, DOI 10.1080/00223980.1958.9916259
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Firat EE, 2022, INFORM VISUAL, V21, P285, DOI 10.1177/14738716221081831
   Gabry J, 2019, J ROY STAT SOC A, V182, P389, DOI 10.1111/rssa.12378
   Gajos Krzysztof, 2005, UIST P ANN ACM S US, P173, DOI [DOI 10.1145/1095034.1095063, 10.1145/1095034.1095063]
   Gajos KZ, 2010, ARTIF INTELL, V174, P910, DOI 10.1016/j.artint.2010.05.005
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Gelman A, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19100555
   Gelman Andrew., 2020, arXiv, DOI DOI 10.48550/ARXIV.2011.01808
   Green T. M., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P203, DOI 10.1109/VAST.2010.5653587
   Harrison L., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, USA, P2949, DOI [10.1145/2470654.24814109, DOI 10.1145/2470654.24814109, DOI 10.1145/2470654.2481410]
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Hedeker D, 2008, BIOMETRICS, V64, P627, DOI 10.1111/j.1541-0420.2007.00924.x
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Hollands JG, 2001, APPL COGNITIVE PSYCH, V15, P413, DOI 10.1002/acp.714
   Hullman J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1461
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   HURLBERT SH, 1984, ECOL MONOGR, V54, P187, DOI 10.2307/1942661
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Knoblauch K, 2008, J STAT SOFTW, V25, P1
   Kong N, 2010, IEEE T VIS COMPUT GR, V16, P990, DOI 10.1109/TVCG.2010.186
   Kosara R, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P101, DOI [10.1109/VISUAL.2019.8933547, 10.1109/visual.2019.8933547]
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lewandowski D, 2009, J MULTIVARIATE ANAL, V100, P1989, DOI 10.1016/j.jmva.2009.04.008
   Liu F, 2018, STAT METHODS MED RES, V27, P1024, DOI 10.1177/0962280216650699
   Liu ZL, 2020, COMPUT GRAPH FORUM, V39, P693, DOI 10.1111/cgf.14033
   Lu M, 2022, IEEE T VIS COMPUT GR, V28, P718, DOI 10.1109/TVCG.2021.3114874
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   McElreath R., 2016, Rethinking: An R package for fitting and manipulating Bayesian models
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Peissner D., 2012, 4 ACM SIGCHI S ENG I, P81
   Pinheiro J., 2018, R package
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Reinecke K, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P11, DOI 10.1145/2556288.2557052
   Reinecke P., 2011, 16 INT C INTELL USER, P453
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Smithson M, 2006, PSYCHOL METHODS, V11, P54, DOI 10.1037/1082-989X.11.1.54
   Srinivasan M., 2018, CHI C HUM FACTORS CO, P1
   STEVENS SS, 1958, PSYCHOL BULL, V55, P177, DOI 10.1037/h0044251
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Yuan L, 2019, PSYCHON B REV, V26, P669, DOI 10.3758/s13423-018-1525-7
   Ziemkiewicz C, 2013, IEEE T VIS COMPUT GR, V19, P1109, DOI 10.1109/TVCG.2012.180
   Ziemkiewicz C, 2009, COMPUT GRAPH FORUM, V28, P911, DOI 10.1111/j.1467-8659.2009.01442.x
NR 70
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1756
EP 1771
DI 10.1109/TVCG.2022.3226463
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500010
PM 37015487
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Xia, MH
   Echevarria, J
   Xie, MS
   Wong, TT
AF Xia, Menghan
   Echevarria, Jose
   Xie, Minshan
   Wong, Tien-Tsin
TI LF2MV: Learning an Editable Meta-View Towards Light Field Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Compact representation; editing propagation; light field; representation
   learning
ID RECONSTRUCTION
AB Light fields are 4D scene representations that are typically structured as arrays of views or several directional samples per pixel in a single view. However, this highly correlated structure is not very efficient to transmit and manipulate, especially for editing. To tackle this issue, we propose a novel representation learning framework that can encode the light field into a single meta-view that is both compact and editable. Specifically, the meta-view composes of three visual channels and a complementary meta channel that is embedded with geometric and residual appearance information. The visual channels can be edited using existing 2D image editing tools, before reconstructing the whole edited light field. To facilitate edit propagation against occlusion, we design a special editing-aware decoding network that consistently propagates the visual edits to the whole light field upon reconstruction. Extensive experiments show that our proposed method achieves competitive representation accuracy and meanwhile enables consistent edit propagation.
C1 [Xia, Menghan; Xie, Minshan; Wong, Tien-Tsin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Echevarria, Jose] Adobe Syst Inc, San Jose, CA 95110 USA.
C3 Chinese University of Hong Kong; Adobe Systems Inc.
RP Xia, MH (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
EM menghanxyz@gmail.com; echevarr@adobe.com; msxie@cse.cuhk.edu.hk;
   ttwong@cse.cuhk.edu.hk
OI Wong, Tien-Tsin/0000-0002-7792-9307; Echevarria,
   Jose/0000-0001-6802-0911
FU Research Grants Council of the Hong Kong Special Administrative Region
FX No Statement Available
CR Alperovich A, 2018, PROC CVPR IEEE, P9145, DOI 10.1109/CVPR.2018.00953
   Beigpour S., 2018, J. Perceptual imag., V1
   Birklbauer C, 2012, COMPUT GRAPH FORUM, V31, P295, DOI 10.1111/j.1467-8659.2012.03008.x
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen KW, 2015, IEEE INT CON MULTI
   Conti C, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574667
   Conti C, 2011, IEEE IMAGE PROC, P961, DOI 10.1109/ICIP.2011.6116721
   Cun XD, 2020, AAAI CONF ARTIF INTE, V34, P10680
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Guo M., 2018, AS C COMP VIS, P50
   Hart D, 2020, IEEE WINT CONF APPL, P99, DOI [10.1109/wacv45572.2020.9093478, 10.1109/WACV45572.2020.9093478]
   Heber S, 2016, PROC CVPR IEEE, P3746, DOI 10.1109/CVPR.2016.407
   Hériard-Dubreuil B, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954495
   Hu WB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417764
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Inagaki Y, 2018, LECT NOTES COMPUT SC, V11211, P431, DOI 10.1007/978-3-030-01234-2_26
   Jarabo A., 2011, P IBERO AM S COMP GR
   Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601125
   Jin X, 2018, IEEE T IMAGE PROCESS, V27, P3954, DOI 10.1109/TIP.2018.2832449
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]
   Kingma D. P., 2014, arXiv
   Le Pendu M, 2018, IEEE T IMAGE PROCESS, V27, P1981, DOI 10.1109/TIP.2018.2791864
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li JQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440760
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Liu D., 2016, P IEEE INT C MULT EX, P1, DOI [10.1109/ICMEW.2016.7574674, DOI 10.1109/ICMEW.2016.7574674]
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Miandji E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3269980
   Ng R., 2005, [31] R. Ng, M. Levoy, M. Bredif, G. Duval, M. Horowitz, and P. Hanrahan, "Light field photography with a hand-held plenoptic camera," Stanford University Com- puter Science Tech Report CSTR 2005-02, 2005.
   Ni LX, 2019, COMPUT GRAPH FORUM, V38, P425, DOI 10.1111/cgf.13849
   Perra C, 2016, IEEE INT CONF MULTI
   Raj A. S., 2016, STANFORD LYTRO LIGHT
   Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3
   Seitz SM, 2002, INT J COMPUT VISION, V48, P115, DOI 10.1023/A:1016046923611
   Srinivasan PP, 2019, PROC CVPR IEEE, P175, DOI 10.1109/CVPR.2019.00026
   Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246
   Vadathya AK, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P328, DOI 10.1109/ACPR.2017.142
   Vagharshakyan S, 2015, IEEE IMAGE PROC, P1379, DOI 10.1109/ICIP.2015.7351026
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LF, 2005, IEEE T VIS COMPUT GR, V11, P25
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Xinrui Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8087, DOI 10.1109/CVPR42600.2020.00811
   Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9
   Yoo J, 2019, IEEE I CONF COMP VIS, P9035, DOI 10.1109/ICCV.2019.00913
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 58
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1672
EP 1684
DI 10.1109/TVCG.2022.3220773
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500012
PM 36350869
DA 2024-08-05
ER

PT J
AU Arunkumar, A
   Padilla, L
   Bae, GY
   Bryan, C
AF Arunkumar, Anjana
   Padilla, Lace
   Bae, Gi-Yeul
   Bryan, Chris
TI Image or Information? Examining the Nature and Impact of Visualization
   Perceptual Classification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Economics; Sports;
   Meteorology; Geology; Information Visualization; Human-Centered
   Computing; Perception & Cognition; Takeaways
ID COMMUNICATION
AB How do people internalize visualizations: as images or information? In this study, we investigate the nature of internalization for visualizations (i.e., how the mind encodes visualizations in memory) and how memory encoding affects its retrieval. This exploratory work examines the influence of various design elements on a user's perception of a chart. Specifically, which design elements lead to perceptions of visualization as an image (aims to provide visual references, evoke emotions, express creativity, and inspire philosophic thought) or as information (aims to present complex data, information, or ideas concisely and promote analytical thinking)? Understanding how design elements contribute to viewers perceiving a visualization more as an image or information will help designers decide which elements to include to achieve their communication goals. For this study, we annotated 500 visualizations and analyzed the responses of 250 online participants, who rated the visualizations on a bilinear scale as 'image' or 'information.' We then conducted an in-person study (n = 101) using a free recall task to examine how the image/information ratings and design elements impacted memory. The results revealed several interesting findings: Image-rated visualizations were perceived as more aesthetically 'appealing,' 'enjoyable,' and 'pleasing.' Information-rated visualizations were perceived as less 'difficult to understand' and more aesthetically 'likable' and 'nice,' though participants expressed higher 'positive' sentiment when viewing image-rated visualizations and felt less 'guided to a conclusion.' The presence of axes and text annotations heavily influenced the likelihood of participants rating the visualization as 'information.' We also found different patterns among participants that were older. Importantly, we show that visualizations internalized as 'images' are less effective in conveying trends and messages, though they elicit a more positive emotional judgment, while 'informative' visualizations exhibit annotation focused recall and elicit a more positive design judgment. We discuss the implications of this dissociation between aesthetic pleasure and perceived ease of use in visualization design.
C1 [Arunkumar, Anjana; Bae, Gi-Yeul; Bryan, Chris] Arizona State Univ, Tempe, AZ 85281 USA.
   [Padilla, Lace] Northeastern Univ, Boston, MA USA.
C3 Arizona State University; Arizona State University-Tempe; Northeastern
   University
RP Arunkumar, A (corresponding author), Arizona State Univ, Tempe, AZ 85281 USA.
EM aarunku5@asu.edu; l.padilla@northeastern.edu; giyeulbae@asu.edu;
   cbryan16@asu.edu
FU U.S. National Science Foundation
FX No Statement Available
CR Adar E, 2021, IEEE T VIS COMPUT GR, V27, P946, DOI 10.1109/TVCG.2020.3030375
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Arnheim R., 1969, Art and visual perception: A psychology of the creative eye, P2
   Arunkumar A, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P51, DOI 10.1109/VIS49827.2021.9623282
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bertini E, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P206, DOI 10.1109/VIS47514.2020.00048
   Bloom BS, 2020, Taxonomy of educational objectives: the classification of educational goals. Book 1, Cognitive domain
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Bradley A. J., 2021, Approaching humanities questions using slow visual search interfaces, V2, P9
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bryan C, 2020, VIS INFORM, V4, P41, DOI 10.1016/j.visinf.2020.08.001
   Buchanan R., 1992, Design Issues, V8, P5, DOI [10.2307/1511637, https://doi.org/10.2307/1511637]
   Burkhard RA, 2004, IEEE INFOR VIS, P519, DOI 10.1109/IV.2004.1320194
   Burlinson D., 2020, Journal of Vision, V20, P1
   Burns A., 2021, IEEE transactions on visualization and computer graphics, V28, P2
   Cairo A., 2016, New Riders, P2
   Card S. K., 1999, Readings in information visualization: using vision to think, V579, P1
   Chan CS, 1997, J ARCHIT PLAN RES, V14, P52
   Chen C., 2005, IEEE computer graphics and applications, V25, P3
   CLEVELAND WS, 1987, J ROY STAT SOC A STA, V150, P192, DOI 10.2307/2981473
   Cohen J., 2013, Statistical power analysis for the behavioral sciences, P5
   Conklin J., 2005, A taxonomy for learning, teaching, and assessing: A revision of bloom's taxonomy of educational objectives complete edition, P2
   Di Bartolomeo S., 2023, Doom or deliciousness: Challenges and opportunities for visualization in the age of generative models, P3
   Dick M, 2014, DIGIT JOURNAL, V2, P490, DOI 10.1080/21670811.2013.841368
   Emerson J., 2018, Practice, V171, P2
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Few S., 2009, Now you see it: simple visualization techniques for quantitative analysis, V1, P2
   Few S., 2011, The chartjunk debate-a close examination of recent findings, V2020. 2
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Garcia-Retamero R, 2013, CURR DIR PSYCHOL SCI, V22, P392, DOI 10.1177/0963721413491570
   Hair J. F., 2009, Multivariate data analysis
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   He T., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P363, DOI DOI 10.1109/TVCG.2022.32093902,3
   Healey CG, 2004, ACM T GRAPHIC, V23, P64, DOI 10.1145/966131.966135
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Heer J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1029
   Hogarth W., 1753, The analysis of beauty: Written with a view of fixing the fluctuating ideas of taste, P3
   Houts PS, 2006, PATIENT EDUC COUNS, V61, P173, DOI 10.1016/j.pec.2005.05.004
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Iliinsky N., 2011, Designing data visualizations: Representing informational Relationships, P2
   Isola P., 2011, Advances in neural information processing systems, V24, P2
   John-Steiner VeraP., 1997, Notebooks of the mind: Explorations of thinking
   Kefi H., 2010, Emerging Systems Approaches in Information Technologies: Concepts, Theories, and Applications, P5
   Keim D, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2013.54
   Kennedy H, 2016, INFORM COMMUN SOC, V19, P715, DOI 10.1080/1369118X.2016.1153126
   Kerpedjiev S, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P97, DOI 10.1109/INFVIS.1998.729564
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kirk A., 2012, Packt publishing LTD, P2
   KOSSLYN SM, 1976, MEM COGNITION, V4, P291, DOI 10.3758/BF03213178
   KOSSLYN SM, 1977, COGNITIVE PSYCHOL, V9, P52, DOI 10.1016/0010-0285(77)90004-4
   Lambert S., 2016, And what do i do now? using data visualization for social change, P2
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Leonards U, 2002, EXP BRAIN RES, V146, P172, DOI 10.1007/s00221-002-1175-9
   Lupi G., 2017, Print Magazine, V30, P2
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mahyar N., Towards a taxonomy for evaluating user engagement in information visualization, V1, P5
   Maughan L, 2007, J BRAND MANAG, V14, P335, DOI 10.1057/palgrave.bm.2550074
   MITCHELL WJT, 1984, NEW LITERARY HIST, V15, P503, DOI 10.2307/468718
   Munzner T., 2014, Visualization Analysis and Design, P2
   Ovans A., 2014, Harvard Business Review, V2
   Padilla LMK, 2020, J EXP PSYCHOL-APPL, V26, P1, DOI 10.1037/xap0000245
   Pandey A., 1912, IEEE Transactions on Visualization and Computer Graphics, P2
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Roberts J. C., 2015, PERSONAL VISUALIZATI, P2
   Shen L., 2021, P 23 EUR C VIS SHORT, DOI [DOI 10.2312/EVS.20211061, 10.2312/evs.20211061]
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Tas AC, 2020, PSYCHOL AGING, V35, P565, DOI 10.1037/pag0000450
   Tractinsky N, 2000, INTERACT COMPUT, V13, P127, DOI 10.1016/S0953-5438(00)00031-X
   Tufte E.R., 1991, OPTOMETRY VISION SCI, V68, P322, DOI DOI 10.1097/00006324-199104000-00013
   Tufte E. R., 1985, The Journal for Healthcare Quality (JHQ), V7, P2
   TVERSKY B, 1989, J EXP PSYCHOL GEN, V118, P387, DOI 10.1037/0096-3445.118.4.387
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Wang Zezhong., 2019, Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, CHI'19, p253:1
   Wanzer DL, 2021, EVAL PROGRAM PLANN, V84, DOI 10.1016/j.evalprogplan.2020.101896
   Ware C., 2019, Information visualization: perception for design, V1, P2
   Wood J, 2012, IEEE T VIS COMPUT GR, V18, P2749, DOI 10.1109/TVCG.2012.262
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI DOI 10.1145/1377966.1377971
NR 84
TC 0
Z9 0
U1 11
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1030
EP 1040
DI 10.1109/TVCG.2023.3326919
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500064
PM 37874713
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Fu, Y
   Stasko, J
AF Fu, Yu
   Stasko, John
TI HoopInSight: Analyzing and Comparing Basketball Shooting Performance
   Through Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE sports data visualization; sports analytics; visual comparison;
   basketball
AB Data visualization has the power to revolutionize sports. For example, the rise of shot maps has changed basketball strategy by visually illustrating where "good/bad" shots are taken from. As a result, professional basketball teams today take shots from very different positions on the court than they did 20 years ago. Although the shot map has transformed many facets of the game, there is still much room for improvement to support richer and more complex analytical tasks. More specifically, we believe that the lack of sufficient interactivity to support various analytical queries and the inability to visually compare differences across situations are significant limitations of current shot maps. To address these limitations and showcase new possibilities, we designed and developed HoopInSight, an interactive visualization system that centers around a novel spatial comparison visual technique, enhancing the capabilities of shot maps in basketball analytics. This article presents the system, with a focus on our proposed visual technique and its accompanying interactions, all designed to promote comparison of two different scenarios. Furthermore, we provide reflections on and a discussion of relevant issues, including considerations for designing spatial comparison techniques, the scalability and transferability of this approach, and the benefits and pitfalls of designing as domain experts.
C1 [Fu, Yu; Stasko, John] Georgia Inst Technol, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Fu, Y (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM fuyu@gatech.edu; john.stasko@cc.gatech.edu
OI Fu, Yu/0000-0001-5076-6299
CR Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Basketball-Reference.com, 2022, Glossary-Effective Field Goal
   BBallytics, 2021, Is the mid-range really dead?
   Beshai P., 2014, Technical report, V2, P3
   Buchanan L., 2016, New York Times, P8
   Cervone D., 2014, P SPORTS ANALYTICS C, P2
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chung DHS, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.25
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Endert A., 2011, P GRAPHICS INTERFACE, P8
   Yu F, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502078
   Gamio L., 2016, Washington Post, P8
   Gels J., Basketball terms-terminology
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Goldsberry K., 2019, Sprawlball: A visual tour of the new era of the NBA, P1
   Goldsberry K., The death of midrange
   Goldsberry Kirk., 2012, 2012 MIT Sloan Sports Analytics Conference, V9, P12
   Hickson D., 2003, P HAWAII INT C STAT, P2
   Hu GY, 2021, STAT-US, V10, DOI 10.1002/sta4.324
   Jiao JY, 2021, J QUANT ANAL SPORTS, V17, P77, DOI 10.1515/jqas-2019-0106
   Krause J., BASKETBALL SKILLS DR
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Lin T., 2021, P 2021 CHI C HUMAN F, p461:1, DOI [10.1145/3411764.34456492, DOI 10.1145/3411764.34456492]
   Lin TC, 2023, IEEE COMPUT GRAPH, V43, P84, DOI 10.1109/MCG.2022.3222042
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Losada AG, 2016, IEEE COMPUT GRAPH, V36, P58, DOI 10.1109/MCG.2016.124
   McNabb L, 2019, INFORMATION, V10, DOI 10.3390/info10100302
   Meko T., 2020, The Washington Post, P8
   Miller A, 2014, PR MACH LEARN RES, V32
   Natarajan S., 2022, Meet the data visualization king of basketball Twitter: Todd Whitehead, P2
   NBA, 2012, Advanced stats: eFG%
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Patel S., 2022, An API client package to access the APIs for NBA.com
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Reich BJ, 2006, AM STAT, V60, P3, DOI 10.1198/000313006X90305
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sha L, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3185596
   Strauss B., 2019, The Washington PostApr, P1
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Whitehead T., 2021, Steph Curry's record-breaking 2974 career threes
   Wickham H, 2012, ENVIRONMETRICS, V23, P382, DOI 10.1002/env.2152
   Wong YL, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P1, DOI 10.1109/BELIV.2018.8634026
   Wu Yihong, 2023, IEEE Trans Vis Comput Graph, V29, P929, DOI 10.1109/TVCG.2022.3209373
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Yau N., Goodbye, mid-range shot | flowingdata
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zhi QY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300499
NR 52
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 858
EP 868
DI 10.1109/TVCG.2023.3326910
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500130
PM 37871051
DA 2024-08-05
ER

PT J
AU He, HA
   Walny, J
   Thoma, S
   Carpendale, S
   Willett, W
AF He, Helen Ai
   Walny, Jagoda
   Thoma, Sonja
   Carpendale, Sheelagh
   Willett, Wesley
TI Enthusiastic and Grounded, Avoidant and Cautious: Understanding Public
   Receptivity to Data and Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Diverse audiences; Information receptivity; Information visualization;
   Open data
ID INFORMATION VISUALIZATION; TRUST; DESIGN; GRAPH
AB Despite an abundance of open data initiatives aimed to inform and empower "general" audiences, we still know little about the ways people outside of traditional data analysis communities experience and engage with public data and visualizations. To investigate this gap, we present results from an in-depth qualitative interview study with 19 participants from diverse ethnic, occupational, and demographic backgrounds. Our findings characterize a set of lived experiences with open data and visualizations in the domain of energy consumption, production, and transmission. This work exposes information receptivity - an individual's transient state of willingness or openness to receive information -as a blind spot for the data visualization community, complementary to but distinct from previous notions of data visualization literacy and engagement. We observed four clusters of receptivity responses to data- and visualization-based rhetoric: Information-Avoidant, Data-Cautious, Data-Enthusiastic, and Domain-Grounded. Based on our findings, we highlight research opportunities for the visualization community. This exploratory work identifies the existence of diverse receptivity responses, highlighting the need to consider audiences with varying levels of openness to new information. Our findings also suggest new approaches for improving the accessibility and inclusivity of open data and visualization initiatives targeted at broad audiences. A free copy of this paper and all supplemental materials are available at https://OSF.IO/MPQ32.
C1 [He, Helen Ai; Walny, Jagoda; Thoma, Sonja; Willett, Wesley] Univ Calgary, Calgary, AB, Canada.
   [Carpendale, Sheelagh] Simon Fraser Univ, Burnaby, BC, Canada.
C3 University of Calgary; Simon Fraser University
RP Willett, W (corresponding author), Univ Calgary, Calgary, AB, Canada.
EM helen.he1@ucalgary.ca; jkwalny@ucalgary.ca; me@sonjathoma.ca;
   sheelagh@sfu.ca; wesley.willett@ucalgary.ca
OI Carpendale, Sheelagh/0000-0002-5127-9780; Willett,
   Wesley/0000-0002-6793-3062
FU National Energy Board (NEB) of Canada; Canada Research Chairs Program
FX This study was funded by a research grant from the National Energy Board
   (NEB) of Canada with support from the Canada Research Chairs Program.
   Thanks to our participants and to our VIS 2021 and VIS 2023 reviewers
   for their invaluable input.
CR Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   American Psychological Association, 2019, Publication Manual of the American Psychological Association, V7th, P3
   Anderson EW, 2011, COMPUT GRAPH FORUM, V30, P791, DOI 10.1111/j.1467-8659.2011.01928.x
   [Anonymous], 2011, OECD Better Life Index
   Anshari M, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P140, DOI 10.1145/3195106.3195172
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bakx K., 2019, CBC
   Barbosa L, 2014, BIG DATA-US, V2, P144, DOI 10.1089/big.2014.0020
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Burns A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581524
   Card S. K., 1999, Readings in information visualization: using vision to think, P2
   Carpendale S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186325
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Corbin J., 2015, Basics of Qualitative Research, V4th, P3
   Correll M, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P1, DOI 10.1109/BELIV57783.2022.00005
   D'Ignazio Catherine, 2017, Information Design Journal, V23, P6, DOI 10.1075/idj.23.1.03dig
   Diakopoulos N, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1717
   Elliott J. K., 2019, Global NewsJune 21
   Emanuel AS, 2015, SOC SCI MED, V147, P113, DOI 10.1016/j.socscimed.2015.10.058
   Engebretsen M, 2020, NORD REV, V41, P33, DOI 10.2478/nor-2020-0004
   Ferretti G, 2019, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL GOVERNMENT RESEARCH (DGO2019): GOVERNANCE IN THE AGE OF ARTIFICIAL INTELLIGENCE, P25, DOI 10.1145/3325112.3325230
   Gapminder, 2006, Gapminder tools
   Golman R, 2017, J ECON LIT, V55, P96, DOI 10.1257/jel.20151245
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Harboe G, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P95, DOI 10.1145/2702123.2702561
   Harrison L., 2013, The role of emotion in visualization, P8
   He H. A., 2019, Open Technical Report, DOI [10.11575/PRISM/372734, DOI 10.11575/PRISM/372734]
   Heer J, 2009, COMMUN ACM, V52, P87, DOI 10.1145/1435417.1435439
   Huang DD, 2015, IEEE T VIS COMPUT GR, V21, P420, DOI 10.1109/TVCG.2014.2359887
   Huang WD, 2009, INFORM VISUAL, V8, P139, DOI 10.1057/ivs.2009.10
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Huron S., IEEE VIS PEDAGOGY DA
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Kassen M, 2013, GOV INFORM Q, V30, P508, DOI 10.1016/j.giq.2013.05.012
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kirkup K., 2019, Global NewsApril 24
   Knowles ES, 2007, FRONT SOC PSYCHOL, P83
   Knudsen S., CHI Extended Abstracts, P1
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Markant D., 2023, P CHI, DOI [10.1145/3544548.3581330, DOI 10.1145/3544548.3581330]
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   Microsoft, 2019, Power BI, V2, P9
   Munzner T., 2014, Visualization Analysis and Design, P2
   National Energy Board of Canada, 2019, Technical Report NE2-23E-PDF, P2
   Oster E, 2013, AM ECON REV, V103, P804, DOI 10.1257/aer.103.2.804
   Pandey AV, 2014, IEEE T VIS COMPUT GR, V20, P2211, DOI 10.1109/TVCG.2014.2346419
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Plutchik R., 1980, Emotion: Theory, research, P3, DOI [10.1016/B978-0-12-558701-3.50007-7, DOI 10.1016/B978-0-12-558701-3.50007-7]
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Rendgen S., 2012, TASCHEN, V2
   Rendgen S., 2018, The Minard System: The Complete Statistical Graphics of Charles-Joseph Minard, P2
   Riche NH, 2018, Data-Driven Storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Rowley J, 2012, INT J MARKET RES, V54, P93, DOI 10.2501/IJMR-54-1-093-110
   Sagarin BJ, 2004, RESISTANCE AND PERSUASION, P259
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Scupin R, 1997, HUM ORGAN, V56, P233, DOI 10.17730/humo.56.2.x335923511444655
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Sicherman N, 2016, REV FINANC STUD, V29, P863, DOI 10.1093/rfs/hhv073
   Siebenhaar KU, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.567905
   Siegrist M, 2000, RISK ANAL, V20, P353, DOI 10.1111/0272-4332.203034
   Snyder J., 2019, National PostJune 18
   Soroya SH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102440
   Subramonyam H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300628
   Tableau Inc, 2019, Tableau, V2, P9
   Tasker J. P., 2019, CBCMay 23
   Treasury Board Secretariat of Canada, 2018, Canada's 2018-2020 National Action Plan on Open Government
   Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476
   Twyman M, 2008, JUDGM DECIS MAK, V3, P111
   Vainio A, 2017, RISK ANAL, V37, P557, DOI 10.1111/risa.12640
   Vetrò A, 2016, GOV INFORM Q, V33, P325, DOI 10.1016/j.giq.2016.02.001
   Viegas F.B., 2008, Hawaii International Conference on System Sciences, P159
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Vossoughian N., 2011, Otto Neurath: The Language of the Global Polis, P2
   Walny J, 2020, IEEE COMPUT GRAPH, V40, P57, DOI 10.1109/MCG.2020.2968906
   Wieczorkowski J, 2019, 3RD INTERNATIONAL CONFERENCE ON E-COMMERCE, E-BUSINESS AND E-GOVERNMENT, ICEEG 2019, P15, DOI 10.1145/3340017.3340022
   Willett W, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3131
   Wilson J., 2019, CBCFebruary 20
NR 87
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1435
EP 1445
DI 10.1109/TVCG.2023.3326917
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500099
PM 37871069
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Huang, ZY
   He, Q
   Maher, K
   Deng, XM
   Lai, YK
   Ma, CX
   Qin, SF
   Liu, YJ
   Wang, HA
AF Huang, Zeyuan
   He, Qiang
   Maher, Kevin
   Deng, Xiaoming
   Lai, Yu-Kun
   Ma, Cuixia
   Qin, Sheng-Feng
   Liu, Yong-Jin
   Wang, Hongan
TI SpeechMirror: A Multimodal Visual Analytics System for Personalized
   Reflection of Online Public Speaking Effectiveness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Speech; Public speaking; Visual analytics; Interviews; Data
   visualization; Speech enhancement; Reflection; Visual Analytics;
   Multimodal Analysis; Public Speaking; Online Presentation
ID VISUALIZATION; PITCH
AB As communications are increasingly taking place virtually, the ability to present well online is becoming an indispensable skill. Online speakers are facing unique challenges in engaging with remote audiences. However, there has been a lack of evidence-based analytical systems for people to comprehensively evaluate online speeches and further discover possibilities for improvement. This paper introduces SpeechMirror, a visual analytics system facilitating reflection on a speech based on insights from a collection of online speeches. The system estimates the impact of different speech techniques on effectiveness and applies them to a speech to give users awareness of the performance of speech techniques. A similarity recommendation approach based on speech factors or script content supports guided exploration to expand knowledge of presentation evidence and accelerate the discovery of speech delivery possibilities. SpeechMirror provides intuitive visualizations and interactions for users to understand speech factors. Among them, SpeechTwin, a novel multimodal visual summary of speech, supports rapid understanding of critical speech factors and comparison of different speech samples, and SpeechPlayer augments the speech video by integrating visualization of the speaker's body language with interaction, for focused analysis. The system utilizes visualizations suited to the distinct nature of different speech factors for user comprehension. The proposed system and visualization techniques were evaluated with domain experts and amateurs, demonstrating usability for users with low visualization literacy and its efficacy in assisting users to develop insights for potential improvement.
C1 [Huang, Zeyuan; He, Qiang; Deng, Xiaoming; Ma, Cuixia; Wang, Hongan] Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing, Peoples R China.
   [Huang, Zeyuan; He, Qiang; Deng, Xiaoming; Ma, Cuixia; Wang, Hongan] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Maher, Kevin] Diatom Design LLC Co, Mckittrick, CA USA.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci Informat, Cardiff, Wales.
   [Qin, Sheng-Feng] Northumbria Univ, Sch Design, Newcastle Upon Tyne, England.
   [Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Cardiff
   University; Northumbria University; Tsinghua University
RP Ma, CX; Wang, HA (corresponding author), Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing, Peoples R China.; Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, Beijing, Peoples R China.
EM zeyuan2020@iscas.ac.cn; heqiang2022@iscas.ac.cn; kevintmaher@gmail.com;
   xiaoming@iscas.ac.cn; LaiY4@cardiff.ac.uk; cuixia@iscas.ac.cn;
   sheng-feng.qin@northumbria.ac.uk; liuyongjin@tsinghua.edu.cn;
   hongan@iscas.ac.cn
OI ma, cui xia/0000-0003-3999-7429; Huang, Zeyuan/0000-0002-2639-0487; Qin,
   Shengfeng/0000-0001-8538-8136; he, qiang/0009-0006-2140-1681; Lai,
   Yukun/0000-0002-2094-5680; deng, xiao ming/0000-0001-8576-1201; Maher,
   Kevin/0000-0002-6486-4866
FU National Key R&D Program of China
FX No Statement Available
CR Alemi O., 2014, P 2014 INT WORKSHOP, P37, DOI [10.1145/2617995.26180023, DOI 10.1145/2617995.26180023]
   Gutiérrez PA, 2016, IEEE T KNOWL DATA EN, V28, P127, DOI 10.1109/TKDE.2015.2457911
   Arriaga O, 2017, Arxiv, DOI arXiv:1710.07557
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Batista GEAPA, 2014, DATA MIN KNOWL DISC, V28, P634, DOI 10.1007/s10618-013-0312-3
   Bird S., 2009, Natural language processing with Python: analyzing text with the natural language toolkit, V5
   Blair-Early A, 2008, DES ISSUES, V24, P85, DOI 10.1162/desi.2008.24.3.85
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bottinger M., 2020, Foundations of Data Visualization, P297, DOI [10.1007/978-3-030-34444-3, DOI 10.1007/978-3-030-34444-3]
   Cer D, 2018, Arxiv, DOI arXiv:1803.11175
   CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077
   Contributors M., 2022, Openmmlab pose estimation toolbox and benchmark
   D'Angelo S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173923
   Deng XM, 2023, IEEE T PATTERN ANAL, V45, P932, DOI 10.1109/TPAMI.2022.3159725
   Donovan J., 2014, Speaker, Leader, Champion: Succeed at Work Through the Power of Public Speaking, featuring the prize-winning speeches of Toastmasters World Champions, P3
   Echeverria V., 2014, Proceedings of the 2014 ACM workshop on Multimodal Learning Analytics Workshop and Grand Challenge, P53, DOI [DOI 10.1145/2666633.2666641, DOI 10.1145/2666633.26666411,2]
   Geitgey Adam, 2018, face recognition
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Green E. P., 2021, Healthy Presentations, P87
   Higuch K, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P571, DOI 10.1145/3172944.3172960
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jadoul Y, 2018, J PHONETICS, V71, P1, DOI 10.1016/j.wocn.2018.07.001
   Jiang W., 2022, arXiv
   Kirchhoff K., 2018, Cmu pronouncing dictionary (cmudict)
   Kravvaris D., 2014, IFIP INT C ARTIFICIA, P60
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YS, 2019, 2019 IEEE 7TH INTERNATIONAL CONFERENCE ON CONTROL, MECHATRONICS AND AUTOMATION (ICCMA 2019), P299, DOI [10.1109/iccma46720.2019.8988728, 10.1109/bigcomp.2019.8679261, 10.1109/ICCMA46720.2019.8988728]
   Luzardo G., 2014, P 2014 ACM WORKSHOP, P37, DOI [DOI 10.1145/2666633.2666639, 10.1145/2666633.26666391,2, DOI 10.1145/2666633.26666391,2]
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   McLean S., 2015, Business Communication for Success. Business Communication for Success, P3
   Microsoft, Azure cognitive speech to text service
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Niewiadomski R, 2014, COVERBAL SYNCHRONY IN HUMAN-MACHINE INTERACTION, P269
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P284, DOI 10.1145/2993148.2993176
   Ochoa X, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS, P360, DOI 10.1145/3170358.3170406
   Pallets, Flask's documentation (1.1.x)
   PLAGENHOEF S, 1983, RES Q EXERCISE SPORT, V54, P169, DOI 10.1080/02701367.1983.10605290
   Potter R. L., 2022, Technical Writing Essentials, P1
   Quoidbach J, 2014, J EXP PSYCHOL GEN, V143, P2057, DOI 10.1037/a0038025
   Ramanarayanan V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P23, DOI 10.1145/2818346.2820765
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rimol M., 2021, Gartner says the majority of technology products and services will be built by professionals outside of it by 2024, P2
   Sanchez P., 2021, Presenting Virtually: Communicate and Connect with Online Audiences. Duarte Guide, V1
   Schaefer RS, 2016, PSYCHON B REV, V23, P548, DOI 10.3758/s13423-015-0934-0
   Schneider J, 2017, J COMPUT ASSIST LEAR, V33, P164, DOI 10.1111/jcal.12175
   Sharma R, 2018, IEEE WINT CONF APPL, P476, DOI 10.1109/WACV.2018.00058
   Sieyers B, 2019, P ROY SOC B-BIOL SCI, V286, DOI 10.1098/rspb.2019.0513
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   South L, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P241, DOI 10.1109/VIS47514.2020.00055
   Spakov O, 2007, ELEKTRON ELEKTROTECH, P55
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tanveer M. I., 2018, Awe the Audience: How the Narrative Trajectories Affect Audience Perception in Public Speaking, P1
   Tanveer MI, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P863, DOI 10.1145/2733373.2806350
   Teodorescu HN, 2020, INT C ELECT COMPUT
   Tsai TJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2534
   Tu ZG, 2023, IEEE T PATTERN ANAL, V45, P9469, DOI 10.1109/TPAMI.2023.3247907
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XY, 2020, IEEE VLSI TEST SYMP, DOI 10.1109/vts48691.2020.9107600
   Wörtwein T, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P43, DOI 10.1145/2818346.2820762
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zeng Haipeng, 2022, IEEE Transactions on Visualization and Computer Graphics
   Zhang F.Z., 2022, CVPR, P20104
   Zhang FZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13299, DOI 10.1109/ICCV48922.2021.01307
   Zhang J. R., 2012, P 20 ACM INT C MULTI, P1389, DOI [10.1145/2393347.23964991,2, DOI 10.1145/2393347.23964991,2]
NR 71
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 606
EP 616
DI 10.1109/TVCG.2023.3326932
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500027
PM 37871082
OA Green Accepted, Green Submitted
DA 2024-08-05
ER

PT J
AU Moreira, G
   Hosseini, M
   Nipu, MNA
   Lage, M
   Ferreira, N
   Miranda, F
AF Moreira, Gustavo
   Hosseini, Maryam
   Nipu, Md Nafiul Alam
   Lage, Marcos
   Ferreira, Nivan
   Miranda, Fabio
TI The Urban Toolkit: A Grammar-Based Framework for Urban Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Urban visual analytics; Urban analytics; Urban data; Visualization
   toolkit
ID VISUALIZATION; BUILDINGS; VULNERABILITY; INFORMATION; EXPLORATION;
   MODELS; SYSTEM; FLOOD; VEGA
AB While cities around the world are looking for smart ways to use new advances in data collection, management, and analysis to address their problems, the complex nature of urban issues and the overwhelming amount of available data have posed significant challenges in translating these efforts into actionable insights. In the past few years, urban visual analytics tools have significantly helped tackle these challenges. When analyzing a feature of interest, an urban expert must transform, integrate, and visualize different thematic (e.g., sunlight access, demographic) and physical (e.g., buildings, street networks) data layers, oftentimes across multiple spatial and temporal scales. However, integrating and analyzing these layers require expertise in different fields, increasing development time and effort. This makes the entire visual data exploration and system implementation difficult for programmers and also sets a high entry barrier for urban experts outside of computer science. With this in mind, in this paper, we present the Urban Toolkit (UTK), a flexible and extensible visualization framework that enables the easy authoring of web-based visualizations through a new high-level grammar specifically built with common urban use cases in mind. In order to facilitate the integration and visualization of different urban data, we also propose the concept of knots to merge thematic and physical urban layers. We evaluate our approach through use cases and a series of interviews with experts and practitioners from different domains, including urban accessibility, urban planning, architecture, and climate science. UTK is available at urbantk.org.
C1 [Moreira, Gustavo; Miranda, Fabio] Univ Illinois, Chicago, IL 60614 USA.
   [Hosseini, Maryam] MIT, Cambridge, MA USA.
   [Nipu, Md Nafiul Alam; Lage, Marcos] Univ Fed Fluminense, Niteroi, Brazil.
   [Ferreira, Nivan] Univ Fed Pernambuco, Caruaru, Brazil.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; Massachusetts Institute of
   Technology (MIT); Universidade Federal Fluminense; Universidade Federal
   de Pernambuco
RP Moreira, G (corresponding author), Univ Illinois, Chicago, IL 60614 USA.
EM gmorei3@uic.edu; maryamh@mit.edu; mnipu2@uic.edu; mlage@ic.uff.br;
   nivan@cin.ufpe.br; fabiom@uic.edu
RI Lage, Marcos/K-4098-2012; Moreira, Gustavo/V-5636-2019
OI Lage, Marcos/0000-0003-3868-8886; Ferreira, Nivan/0000-0001-6631-4609;
   Miranda, Fabio/0000-0001-8612-5805
FU University of Illinois' Discovery Partners Institute (DPI), CNPq
FX No Statement Available
CR Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Angelini M, 2019, COMPUT GRAPH FORUM, V38, P237, DOI 10.1111/cgf.13685
   Avini R, 2019, SUSTAIN CITIES SOC, V45, P378, DOI 10.1016/j.scs.2018.10.026
   Batty M., 2014, Urban Design, V132, P2
   Bokeh, About us
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Chakraborty A, 2015, J AM PLANN ASSOC, V81, P18, DOI 10.1080/01944363.2015.1038576
   Chang R, 2007, IEEE T VIS COMPUT GR, V13, P1169, DOI 10.1109/TVCG.2007.70574
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   Chippendale T, 2015, GERONTOLOGIST, V55, P575, DOI 10.1093/geront/gnu019
   Cornel D, 2019, COMPUT GRAPH FORUM, V38, P25, DOI 10.1111/cgf.13669
   Cornel D, 2015, COMPUT GRAPH FORUM, V34, P331, DOI 10.1111/cgf.12645
   Correa CD, 2006, IEEE T VIS COMPUT GR, V12, P1069, DOI 10.1109/TVCG.2006.144
   deck.gl, About us
   Delaney B, 2000, IEEE COMPUT GRAPH, V20, P10, DOI 10.1109/38.844365
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Doraiswamy H, 2018, INT CONF MANAGE DATA, P1693, DOI 10.1145/3183713.3193559
   Doraiswamy H, 2018, IEEE COMPUT GRAPH, V38, P26, DOI 10.1109/MCG.2018.053491728
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Garcia-Zanabria G, 2022, IEEE T VIS COMPUT GR, V28, P4000, DOI 10.1109/TVCG.2021.3111146
   Hemmersam P, 2015, J URBAN TECHNOL, V22, P45, DOI 10.1080/10630732.2015.1073898
   Hosseini M., 2022, CVPR 2022 AVA ACCESS, DOI [10.48550/ARXIV.2206 .13677 8, DOI 10.48550/ARXIV.2206.136778]
   Hosseini M, 2022, SUSTAIN CITIES SOC, V79, DOI 10.1016/j.scs.2021.103630
   Houle K., 2008, Winter performance assessment of permeable pavements: A comparative study of porous asphalt, pervious concrete, and conventional asphalt in a northern climate, P8
   Hu K., 2017, A usability study of ArcGIS Pro: Scaffolding an intuitive and fluid geovisualization workflow, P9
   Ichinose T, 2017, ENERG BUILDINGS, V136, P199, DOI 10.1016/j.enbuild.2016.11.064
   Jiang F, 2022, SUSTAIN CITIES SOC, V78, DOI 10.1016/j.scs.2021.103645
   Kim H, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517455
   Kindlmann G, 2016, IEEE T VIS COMPUT GR, V22, P867, DOI 10.1109/TVCG.2015.2467449
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   Lee B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580754
   Lee C., 2017, Building boom in Boston casts shadows on history and public space
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   Malik A, 2014, IEEE T VIS COMPUT GR, V20, P1863, DOI 10.1109/TVCG.2014.2346926
   Matplotlib, ABOUT US
   Miranda F, 2019, IEEE T VIS COMPUT GR, V25, P1559, DOI 10.1109/TVCG.2018.2802945
   Miranda F, 2017, IEEE T VIS COMPUT GR, V23, P791, DOI 10.1109/TVCG.2016.2598585
   Mota Roberta, 2023, IEEE Trans Vis Comput Graph, V29, P1277, DOI 10.1109/TVCG.2022.3209474
   Neuville R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030236
   NYC OpenData, About us
   Ortner T, 2017, IEEE T VIS COMPUT GR, V23, P1139, DOI 10.1109/TVCG.2016.2520920
   Palliwal A, 2021, COMPUT ENVIRON URBAN, V86, DOI 10.1016/j.compenvurbsys.2020.101584
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Rautek P, 2014, IEEE T VIS COMPUT GR, V20, P2388, DOI 10.1109/TVCG.2014.2346318
   Redweik P, 2017, INT J DISAST RISK SC, V8, P308, DOI 10.1007/s13753-017-0141-x
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Saha M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517460
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shih M, 2019, IEEE T VIS COMPUT GR, V25, P1050, DOI 10.1109/TVCG.2018.2864841
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Speckmann B, 2010, IEEE T VIS COMPUT GR, V16, P881, DOI 10.1109/TVCG.2010.180
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   Tableau, About us
   Tang JH, 2022, ENVIRON IMPACT ASSES, V97, DOI 10.1016/j.eiar.2022.106864
   Trifacta, About us
   Twardzik E, 2019, GAIT POSTURE, V68, P437, DOI 10.1016/j.gaitpost.2018.12.028
   Vuckovic M, 2022, INFORMATION, V13, DOI 10.3390/info13010007
   Wang PC, 2021, SUSTAIN CITIES SOC, V72, DOI 10.1016/j.scs.2021.103035
   Wang S., 2021, Urban Informatics, P663, DOI 10.1007/978-981-15-8983-6_36
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Yap W, 2022, COMPUT ENVIRON URBAN, V96, DOI 10.1016/j.compenvurbsys.2022.101825
   Yixian Zheng, 2016, IEEE Transactions on Big Data, V2, P276, DOI 10.1109/TBDATA.2016.2586447
   Zeng W, 2018, IEEE COMPUT GRAPH, V38, P38, DOI 10.1109/MCG.2018.053491730
   Ziegler P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581370
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
NR 74
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1402
EP 1412
DI 10.1109/TVCG.2023.3326598
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500131
PM 37871086
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Morini, F
   Eschenbacher, A
   Hartmann, J
   Dörk, M
AF Morini, Francesca
   Eschenbacher, Anna
   Hartmann, Johanna
   Dork, Marian
TI From Shock to Shift: Data Visualization for Constructive Climate
   Journalism
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Constructive Climate Journalism; Frameworks; Storytelling; Journalism
ID DESIGN; REFLECTIONS; SCIENCE
AB We present a multi-dimensional, multi-level, and multi-channel approach to data visualization for the purpose of constructive climate journalism. Data visualization has assumed a central role in environmental journalism and is often used in data stories to convey the dramatic consequences of climate change and other ecological crises. However, the emphasis on the catastrophic impacts of climate change tends to induce feelings of fear, anxiety, and apathy in readers. Climate mitigation, adaptation, and protection-all highly urgent in the face of the climate crisis-are at risk of being overlooked. These topics are more difficult to communicate as they are hard to convey on varying levels of locality, involve multiple interconnected sectors, and need to be mediated across various channels from the printed newspaper to social media platforms. So far, there has been little research on data visualization to enhance affective engagement with data about climate protection as part of solution-oriented reporting of climate change. With this research we characterize the unique challenges of constructive climate journalism for data visualization and share findings from a research and design study in collaboration with a national newspaper in Germany. Using the affordances and aesthetics of travel postcards, we present Klimakarten, a data journalism project on the progress of climate protection at multiple spatial scales (from national to local), across five key sectors (agriculture, buildings, energy, mobility, and waste), and for print and online use. The findings from quantitative and qualitative analysis of reader feedback confirm our overall approach and suggest implications for future work.
C1 [Morini, Francesca] Sodertorn Univ, Huddinge, Sweden.
   [Morini, Francesca; Dork, Marian] Univ Appl Sci Potsdam, Potsdam, Germany.
   [Eschenbacher, Anna; Hartmann, Johanna] Filmunivers Babelsberg, Potsdam, Germany.
C3 Sodertorn University
RP Morini, F (corresponding author), Sodertorn Univ, Huddinge, Sweden.
EM francesca.morini@sh.se; anna.eschenbacher@filmuniversitaet.de;
   johanna.hartmann@filmuniversitaet.de; doerk@fh-potsdam.de
OI Eschenbacher, Anna/0009-0000-3996-784X; Morini,
   Francesca/0000-0002-5677-8175; Dork, Marian/0000-0002-3469-7841
FU Bundesministerium fr Bildung und Forschung
FX No Statement Available
CR Agin S., 2022, Ph.D. dissertation
   Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   [Anonymous], 2017, P CHI C HUM FACT COM, DOI [DOI 10.1145/3027063.3053113, 10.1145, 10.1145/3027063, DOI 10.1145/3027063]
   [Anonymous], 2023, Climate protection (mitigation)
   [Anonymous], 2003, Public participation in sustainability science: a handbook
   [Anonymous], 2008, Proc. Digit. Earth Summit Geoinformatics
   Appelgren E, 2021, DIGIT JOURNAL, V9, P755, DOI 10.1080/21670811.2020.1827965
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Attfield S, 2011, WSDM WORKSH US MOD W
   Auer C, 2021, ONE EARTH, V4, P1074, DOI 10.1016/j.oneear.2021.07.015
   Bieh-Zimmert O, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2445, DOI 10.1109/BigData.2015.7364039
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Dasgupta A, 2016, COMPUT SCI ENG, V18, P92, DOI 10.1109/MCSE.2016.7
   Dasgupta A, 2015, IEEE T VIS COMPUT GR, V21, P996, DOI 10.1109/TVCG.2015.2413774
   Eden S., 1996, PUBLIC UNDERST SCI, V5, P183, DOI [DOI 10.1088/0963-6625/5/3/001, 10.1088/0963-6625/5/3/001]
   Garretón M, 2024, IEEE T VIS COMPUT GR, V30, P4039, DOI 10.1109/TVCG.2023.3248319
   Hartmann J, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460357
   Hasebrink U, 2020, MEDIA COMMUN-LISBON, V8, P293, DOI 10.17645/mac.v8i3.3191
   Heyer J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376887
   Hickman C, 2020, J SOC WORK PRACT, V34, P411, DOI 10.1080/02650533.2020.1844166
   Hiippala T, 2020, Data Visualization in Society, P277
   Hogele M., 2019, Taz-transformation aus sicht der leser*innen und nutzer*innen
   Höhle J, 2023, ENVIRON EDUC RES, V29, P1659, DOI 10.1080/13504622.2023.2182746
   Höijer B, 2010, PUBLIC UNDERST SCI, V19, P717, DOI 10.1177/0963662509348863
   Hullman J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P1170, DOI 10.1145/2675133.2675207
   Hung Y. -H., 2018, P IEEE C INFORM VISU, V5
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kuthe A, 2019, J ENVIRON EDUC, V50, P172, DOI 10.1080/00958964.2019.1598927
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Lorenzoni I, 2007, GLOBAL ENVIRON CHANG, V17, P445, DOI 10.1016/j.gloenvcha.2007.01.004
   Lu JH, 2020, IEEE COMPUT GRAPH, V40, P18, DOI 10.1109/MCG.2020.2968249
   Lumley S, 2022, COMPUT GRAPH-UK, V103, P19, DOI 10.1016/j.cag.2021.12.007
   Lupi G., 2016, DEAR DATA
   McInerny GJ, 2014, TRENDS ECOL EVOL, V29, P148, DOI 10.1016/j.tree.2014.01.003
   Moore SA, 2019, GEOFORUM, V102, P267, DOI 10.1016/j.geoforum.2017.03.003
   Patela M, 2007, LAND USE POLICY, V24, P546, DOI 10.1016/j.landusepol.2006.02.005
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Postcard, 2023, About us
   Regattieri L. L., 2014, DATAWIZ2014 DATA VIS, V1210, P51
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Russell A, 2023, JOURNALISM, V24, P1387, DOI 10.1177/14648849221113119
   Sallam S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517727
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sheppard S. R. J., 2008, PROCS DIGITAL DESIGN, P20
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sidiropoulos EA, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P156, DOI 10.1109/SMAP.2016.7753402
   Stoiber C, 2019, COMPUT GRAPH FORUM, V38, P699, DOI 10.1111/cgf.13721
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Von Luxburg U, 2012, J MACHINE LEARN RES, P65
   Wiedemann G, 2018, LECT NOTES COMPUT SC, V11186, P313, DOI 10.1007/978-3-030-01159-8_30
   Windhager F, 2019, P EG WORKSH VIS ENV, DOI [10.2312/envirvis.20191098, DOI 10.2312/ENVIRVIS.20191098]
   Wolf J, 2011, WIRES CLIM CHANGE, V2, P547, DOI 10.1002/wcc.120
   Wood J, 2014, IEEE T VIS COMPUT GR, V20, P2171, DOI 10.1109/TVCG.2014.2346323
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
NR 57
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1413
EP 1423
DI 10.1109/TVCG.2023.3327185
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500025
PM 37922181
OA hybrid
DA 2024-08-05
ER

PT J
AU Yan, L
   Guo, HQ
   Peterka, T
   Wang, B
   Wang, JL
AF Yan, Lin
   Guo, Hanqi
   Peterka, Thomas
   Wang, Bei
   Wang, Jiali
TI TROPHY: A Topologically Robust Physics-Informed Tracking Framework for
   Tropical Cyclones
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature tracking; robustness; topology-based methods in visualization;
   applications; climate science; tropical cyclones
ID SIMPLIFICATION; VISUALIZATION
AB Tropical cyclones (TCs) are among the most destructive weather systems. Realistically and efficiently detecting and tracking TCs are critical for assessing their impacts and risks. In particular, the eye is a signature feature of a mature TC. Therefore, knowing the eyes' locations and movements is crucial for both operational weather forecasts and climate risk assessments. Recently, a multilevel robustness framework has been introduced to study the critical points of time-varying vector fields. The framework quantifies the robustness (i.e., structural stability) of critical points across varying neighborhoods. By relating the multilevel robustness with critical point tracking, the framework has demonstrated its potential in cyclone tracking. An advantage is that it identifies cyclonic features using only 2D wind vector fields, which is encouraging as most tracking algorithms require multiple dynamic and thermodynamic variables at different altitudes. A disadvantage is that the framework does not scale well computationally for datasets containing a large number of cyclones. This paper introduces a topologically robust physics-informed tracking framework (TROPHY) for TC tracking. The main idea is to integrate physical knowledge of TC to drastically improve the computational efficiency of multilevel robustness framework for large-scale climate datasets. First, during preprocessing, we propose a physics-informed feature selection strategy to filter 90% of critical points that are short-lived and have low stability, thus preserving good candidates for TC tracking. Second, during in-processing, we impose constraints during the multilevel robustness computation to focus only on physics-informed neighborhoods of TCs. We apply TROPHY to 30 years of 2D wind fields from reanalysis data in ERA5 and generate a number of TC tracks. In comparison with the observed tracks, we demonstrate that TROPHY can capture TC characteristics (e.g., frequency, intensity, duration, latitudes with maximum intensity, and genesis) that are comparable to and sometimes even better than a well-validated TC tracking algorithm that requires multiple dynamic and thermodynamic scalar fields.
C1 [Yan, Lin; Peterka, Thomas; Wang, Jiali] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Guo, Hanqi] Ohio State Univ, Columbus, OH USA.
   [Wang, Bei] Univ Utah, Salt Lake City, UT USA.
C3 United States Department of Energy (DOE); Argonne National Laboratory;
   University System of Ohio; Ohio State University; Utah System of Higher
   Education; University of Utah
RP Yan, L (corresponding author), Argonne Natl Lab, Lemont, IL 60439 USA.
EM lyan@anl.gov; guo.2154@osu.edu; tpeterka@mcs.anl.gov;
   beiwang@sci.utah.edu; jialiwang@anl.gov
RI Guo, Hanqi/ADW-4234-2022
OI Guo, Hanqi/0000-0001-7776-1834
FU Wind Energy Technologies Office of the DOE. Argonne National Laboratory
   is a US Department of Energy laboratory managed by UChicago Argonne, LLC
FX No Statement Available
CR [Anonymous], 2014, TOPOLOGICAL METHODS, DOI DOI 10.1007/978-3-319-04099-8_21,2
   Bell SS, 2018, J CLIMATE, V31, P2217, DOI 10.1175/JCLI-D-17-0548.1
   Biswas M., 2018, Developmental Testbed Center, P2
   Blackwell KG, 2000, MON WEATHER REV, V128, P4002, DOI 10.1175/1520-0493(2000)129<4002:TEOHDA>2.0.CO;2
   Bourdin S., 2022, EGUsphere [preprint], P1, DOI [10.5194/egusphere-2022-179, DOI 10.5194/EGUSPHERE-2022-179]
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Camargo SJ, 2002, WEATHER FORECAST, V17, P1152, DOI 10.1175/1520-0434(2002)017<1152:ITDATO>2.0.CO;2
   Chang PL, 2009, WEATHER FORECAST, V24, P245, DOI 10.1175/2008WAF2222112.1
   Copernicus Climate Change Service,, about Us
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P2896, DOI 10.1109/TVCG.2013.131
   Edelsbrunner H, 2008, COMP GEOM-THEOR APPL, V41, P149, DOI 10.1016/j.comgeo.2007.11.001
   Engelke W., 2021, Topologybased feature design and tracking for multi-center cyclones, P71, DOI DOI 10.1007/978-3-030-83500-2_5
   Enz B. M., 2022, Geoscientific Model Development Discussions, P1, DOI [DOI 10.5194/GMD-2022-2792, DOI 10.5194/GMD-2022-279]
   Garth C, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P329, DOI 10.1109/VISUAL.2004.107
   Guo HQ, 2021, IEEE T VIS COMPUT GR, V27, P3463, DOI 10.1109/TVCG.2021.3073399
   HELMAN J, 1989, COMPUTER, V22, P27, DOI 10.1109/2.35197
   HELMAN JL, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P6, DOI 10.1109/VISUAL.1990.146359
   Hodges K, 2017, J CLIMATE, V30, P5243, DOI [10.1175/jcli-d-16-0557.1, 10.1175/JCLI-D-16-0557.1]
   Holland G, 2014, CLIM DYNAM, V42, P617, DOI 10.1007/s00382-013-1713-0
   Jankowai J, 2019, COMPUT GRAPH FORUM, V38, P337, DOI 10.1111/cgf.13693
   Kepert JD, 2005, MON WEATHER REV, V133, P2406, DOI 10.1175/MWR2980.1
   Kleppek S, 2008, GEOPHYS RES LETT, V35, DOI 10.1029/2008GL033880
   Knaff JA, 2014, J CLIMATE, V27, P455, DOI 10.1175/JCLI-D-13-00096.1
   Knapp KR, 2010, B AM METEOROL SOC, V91, P363, DOI 10.1175/2009BAMS2755.1
   Kossin JP, 2013, J CLIMATE, V26, P9960, DOI 10.1175/JCLI-D-13-00262.1
   Lee WC, 2000, MON WEATHER REV, V128, P1925, DOI 10.1175/1520-0493(2000)128<1925:TCKSRF>2.0.CO;2
   Marchok T, 2021, J APPL METEOROL CLIM, V60, P1265, DOI 10.1175/JAMC-D-20-0175.1
   Nilsson E., 2020, Levia, DOI [10.31219/osf.io/jqtua1, DOI 10.31219/OSF.IO/JQTUA1]
   Reininghaus J, 2012, IEEE T VIS COMPUT GR, V18, P1563, DOI 10.1109/TVCG.2011.269
   Simmerman S, 2013, COMPUT SCI ENG, V15, P46, DOI 10.1109/MCSE.2012.92
   Sivaramakrishnan M., 1966, P 12 C RAD MET NORM, P1
   Skraba P, 2016, IEEE T VIS COMPUT GR, V22, P1683, DOI 10.1109/TVCG.2016.2534538
   Skraba P, 2015, IEEE T VIS COMPUT GR, V21, P930, DOI 10.1109/TVCG.2015.2440250
   Skraba P, 2014, IEEE PAC VIS SYMP, P49, DOI 10.1109/PacificVis.2014.17
   Sohn BS, 2006, IEEE T VIS COMPUT GR, V12, P14, DOI 10.1109/TVCG.2006.16
   Taylor A. A., 2008, 19 C PROB STAT
   Theisel H., 2003, P S DAT VIS 2003 GRE, P2
   Tricoche X, 2001, IEEE VISUAL, P159, DOI 10.1109/VISUAL.2001.964507
   Tricoche X, 2002, COMPUT GRAPH-UK, V26, P249, DOI 10.1016/S0097-8493(02)00056-0
   Tricoche X, 2001, SPRING EUROGRAP, P117
   Ullrich PA, 2017, GEOSCI MODEL DEV, V10, P1069, DOI 10.5194/gmd-10-1069-2017
   Walsh KJE, 2016, WIRES CLIM CHANGE, V7, P65, DOI 10.1002/wcc.371
   Wang B, 2013, COMPUT GRAPH FORUM, V32, P221, DOI 10.1111/cgf.12109
   Wang B., 2017, Topological Methods in Data Analysis and Visualization, P221, DOI [10.1007/978-3-030-43036-8_14, DOI 10.1007/978-3-030-43036-8_14]
   Wang B., 2017, Modeling, Analysis, and Visualization of Anisotropy, P3, DOI [10.1007/978-3-319-61358-1_19, DOI 10.1007/978-3-319-61358-1_19]
   Weinkauf T, 2011, IEEE T VIS COMPUT GR, V17, P770, DOI 10.1109/TVCG.2010.93
   Willoughby HE, 1998, MON WEATHER REV, V126, P3053, DOI 10.1175/1520-0493(1998)126<3053:TCET>2.0.CO;2
   Wischgoll T, 2001, IEEE T VIS COMPUT GR, V7, P165, DOI 10.1109/2945.928168
   Yan L, 2022, Arxiv, DOI arXiv:2209.11708
   Yan WK, 2008, EXPERT SYST APPL, V34, P643, DOI 10.1016/j.eswa.2006.10.013
   Yang WC, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2108397118
   Zarzycki CM, 2021, J APPL METEOROL CLIM, V60, P643, DOI 10.1175/JAMC-D-20-0149.1
   Zarzycki CM, 2017, GEOPHYS RES LETT, V44, P1141, DOI 10.1002/2016GL071606
NR 55
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1249
EP 1259
DI 10.1109/TVCG.2023.3326905
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500120
PM 37930920
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hirao, Y
   Amemiya, T
   Narumi, T
   Argelaguet, F
   Lecuyer, A
AF Hirao, Yutaro
   Amemiya, Tomohiro
   Narumi, Takuji
   Argelaguet, Ferran
   Lecuyer, Anatole
TI Leveraging Tendon Vibration to Enhance Pseudo-Haptic Perceptions in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cross-modal integration; maximum likelyhood estimation; pseudo-haptics;
   tendon vibration; virtual reality
ID ANTAGONIST MUSCLE VIBRATION; INDUCED ILLUSIONS; FORCE SENSATION; MOTOR
   IMAGERY; H-REFLEX; MOVEMENT; POSITION; SENSES; INFORMATION; ACTIVATION
AB Pseudo-haptic techniques are used to modify haptic perception by appropriately changing visual feedback to body movements. Based on the knowledge that tendon vibration can affect our somatosensory perception, this article proposes a method for leveraging tendon vibration to enhance pseudo-haptics during free arm motion. Three experiments were performed to examine the impact of tendon vibration on the range and resolution of pseudo-haptics. The first experiment investigated the effect of tendon vibration on the detection threshold of the discrepancy between visual and physical motion. The results indicated that vibrations applied to the inner tendons of the wrist and elbow increased the threshold, suggesting that tendon vibration can augment the applicable visual motion gain by approximately 13% without users detecting the visual/physical discrepancy. Furthermore, the results demonstrate that tendon vibration acts as noise on haptic motion cues. The second experiment assessed the impact of tendon vibration on the resolution of pseudo-haptics by determining the just noticeable difference in pseudo-weight perception. The results suggested that the tendon vibration does not largely compromise the resolution of pseudo-haptics. The third experiment evaluated the equivalence between the weight perception triggered by tendon vibration and that by visual motion gain, that is, the point of subjective equality. The results revealed that vibration amplifies the weight perception and its effect was equivalent to that obtained using a gain of 0.64 without vibration, implying that the tendon vibration also functions as an additional haptic cue. Our results provide design guidelines and future work for enhancing pseudo-haptics with tendon vibration.
C1 [Hirao, Yutaro; Amemiya, Tomohiro; Narumi, Takuji] Univ Tokyo, Bunkyo City, Tokyo 1138654, Japan.
   [Argelaguet, Ferran; Lecuyer, Anatole] Univ Rennes, INRIA, IRISA, CNRS, F-35042 Rennes, France.
C3 University of Tokyo; Universite de Rennes; Inria; Centre National de la
   Recherche Scientifique (CNRS)
RP Hirao, Y (corresponding author), Univ Tokyo, Bunkyo City, Tokyo 1138654, Japan.
EM hirao@cyber.t.u-tokyo.ac.jp; amemiya@vr.u-tokyo.ac.jp;
   narumi@cyber.t.u-tokyo.ac.jp; ferran.argelaguet@inria.fr;
   anatole.lecuyer@inria.fr
RI ; Narumi, Takuji/K-3925-2014
OI Lecuyer, Anatole/0000-0002-1409-244X; Amemiya,
   Tomohiro/0000-0002-7079-9167; Narumi, Takuji/0000-0002-9010-1491; Hirao,
   Yutaro/0000-0003-3546-3454
FU MEXT Grant-in-Aid for Scientific Research (S) [19H05661]; JSPS
   Grant-in-Aidfor Scientific Research (A) [21H04883]; Grant-in-Aid for
   JSPS Fellows [21J12284]
FX This work was supported in part by the MEXT Grant-in-Aid for Scientific
   Research (S) under Grant 19H05661, in part by the JSPS Grant-in-Aidfor
   Scientific Research (A) under Grant 21H04883, and in part by the
   Grant-in-Aid for JSPS Fellows under Grant 21J12284.
CR [Anonymous], 1966, Muscular Afferents and Motor Control, P177
   [Anonymous], 1974, Amer. J. Phys. Med. Rehabil., V53, P143
   Argelaguet F, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2501599
   Ariff G, 2002, J NEUROSCI, V22, P7721
   Ban YK, 2018, IEEE HAPTICS SYM, P278, DOI 10.1109/HAPTICS.2018.8357188
   Bock O, 2007, J NEUROSCI METH, V160, P246, DOI 10.1016/j.jneumeth.2006.09.010
   Brun C, 2015, NEUROSCIENCE, V310, P268, DOI 10.1016/j.neuroscience.2015.09.052
   BURKE D, 1976, J PHYSIOL-LONDON, V261, P673, DOI 10.1113/jphysiol.1976.sp011580
   Burns F. P., 2006, P ACM S VIRT REAL SO, P3, DOI DOI 10.1145/1180495.1180499
   CAFARELLI E, 1981, EXP NEUROL, V74, P331, DOI 10.1016/0014-4886(81)90173-4
   CAFARELLI E, 1986, MED SCI SPORT EXER, V18, P516
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Fallon JB, 2007, MUSCLE NERVE, V36, P21, DOI 10.1002/mus.20796
   Finney D.J., 1971, Probit Analysis, V3rd, DOI DOI 10.1007/BF02431962
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Fusco G, 2021, PSYCHOL RES-PSYCH FO, V85, P926, DOI 10.1007/s00426-020-01366-5
   GILHODES JC, 1986, EXP BRAIN RES, V61, P395
   Gonzales TI, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00896
   GOODWIN GM, 1972, BRAIN, V95, P705, DOI 10.1093/brain/95.4.705
   Hachisu T, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Honda T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00760
   Hultborn H, 1996, EXP BRAIN RES, V108, P450
   INGLIS JT, 1990, EXP BRAIN RES, V81, P573, DOI 10.1007/BF02423506
   JOHNSTON WA, 1986, ANNU REV PSYCHOL, V37, P43, DOI 10.1146/annurev.ps.37.020186.000355
   JONES LA, 1985, EXP NEUROL, V87, P35, DOI 10.1016/0014-4886(85)90131-1
   Keigo U, 2022, LECT NOTES COMPUT SC, V13235, P93, DOI 10.1007/978-3-031-06249-0_11
   Kitada R, 2002, NEUROSCIENCE, V109, P701, DOI 10.1016/S0306-4522(01)00495-X
   Kito T, 2006, BRAIN RES, V1114, P75, DOI 10.1016/j.brainres.2006.07.062
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Lcuyer A., 2004, P P SIGCHI C HUM FAC, P239, DOI [10.1145/985692.985723, DOI 10.1145/985692.985723]
   Le Franc S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242416
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Luu BL, 2011, J PHYSIOL-LONDON, V589, P3135, DOI 10.1113/jphysiol.2011.208447
   MCCLOSKE.DI, 1974, EXP NEUROL, V42, P220, DOI 10.1016/0014-4886(74)90019-3
   MCCLOSKEY DI, 1973, BRAIN RES, V61, P119, DOI 10.1016/0006-8993(73)90521-0
   Monjo F, 2018, EXP BRAIN RES, V236, P1997, DOI 10.1007/s00221-018-5280-9
   Naito E, 1999, J NEUROSCI, V19, P6134, DOI 10.1523/JNEUROSCI.19-14-06134.1999
   Narumi T, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P334, DOI 10.1109/WHC.2017.7989924
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Porro CA, 1996, J NEUROSCI, V16, P7688
   Proske U, 2019, EXP BRAIN RES, V237, P589, DOI 10.1007/s00221-018-5460-7
   Proske U, 2012, PHYSIOL REV, V92, P1651, DOI 10.1152/physrev.00048.2011
   Pusch A., 2011, P 13 INT C MULT INT, P57
   Rietzler F., 2018, P CHI C HUM FACT COM, P1
   RUNESON S, 1983, J EXP PSYCHOL GEN, V112, P585, DOI 10.1037/0096-3445.112.4.585
   Samad E., 2019, P CHI C HUM FACT COM, P1
   Schofield M. R., Tech-nol. Health Care, V23, P129
   SHADMEHR R, 1994, J NEUROSCI, V14, P3208
   SITTIG AC, 1987, EXP BRAIN RES, V67, P33, DOI 10.1007/BF00269450
   Stellmacher C, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.754511
   Taima Y, 2014, IEEE HAPTICS SYM, P175, DOI 10.1109/HAPTICS.2014.6775451
   Takamuku S, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2015.0864
   Taylor MW, 2017, MULTISENS RES, V30, P25, DOI 10.1163/22134808-00002544
   Thyrion C, 2009, J NEUROSCI, V29, P8483, DOI 10.1523/JNEUROSCI.0683-09.2009
   Tsuge M, 2012, EXP BRAIN RES, V223, P541, DOI 10.1007/s00221-012-3281-7
   Ujitoko Y, 2021, IEEE T HAPTICS, V14, P699, DOI 10.1109/TOH.2021.3077619
   Ujitoko Y, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P181, DOI [10.1109/whc.2019.8816100, 10.1109/WHC.2019.8816100]
   Ujitoko Y, 2019, IEEE T VIS COMPUT GR, V25, P1981, DOI 10.1109/TVCG.2019.2898820
   Ushiyama Keigo, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P185, DOI 10.1007/978-3-030-58147-3_21
   Ushiyama K, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451834
   Weiss Y, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581223
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
   Wood SA, 1996, J PHYSIOL-LONDON, V497, P279, DOI 10.1113/jphysiol.1996.sp021767
NR 65
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5861
EP 5874
DI 10.1109/TVCG.2023.3310001
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400054
PM 37647196
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Prasad, V
   van Sloun, RJG
   Vilanova, A
   Pezzotti, N
AF Prasad, Vidya
   van Sloun, Ruud J. G.
   Vilanova, Anna
   Pezzotti, Nicola
TI ProactiV: Studying Deep Learning Model Behavior Under Input
   Transformations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; explainable AI; deep learning; domain shifts; model
   behavior; robustness; image-to-image translation
ID INTERACTIVE ANALYSIS
AB Deep learning (DL) models have shown performance benefits across many applications, from classification to image-to-image translation. However, low interpretability often leads to unexpected model behavior once deployed in the real world. Usually, this unexpected behavior is because the training data domain does not reflect the deployment data domain. Identifying a model's breaking points under input conditions and domain shifts, i.e., input transformations, is essential to improve models. Although visual analytics (VA) has shown promise in studying the behavior of model outputs under continually varying inputs, existing methods mainly focus on per-class or instance-level analysis. We aim to generalize beyond classification where classes do not exist and provide a global view of model behavior under co-occurring input transformations. We present a DL model-agnostic VA method (ProactiV) to help model developers proactively study output behavior under input transformations to identify and verify breaking points. ProactiV relies on a proposed input optimization method to determine the changes to a given transformed input to achieve the desired output. The data from this optimization process allows the study of global and local model behavior under input transformations at scale. Additionally, the optimization method provides insights into the input characteristics that result in desired outputs and helps recognize model biases. We highlight how ProactiV effectively supports studying model behavior with example classification and image-to-image translation tasks.
C1 [Prasad, Vidya; Vilanova, Anna; Pezzotti, Nicola] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
   [van Sloun, Ruud J. G.] Philips Res, NL-5656 AE Eindhoven, Netherlands.
   [van Sloun, Ruud J. G.] Eindhoven Univ Technol, Dept Elect Engn, NL-5612 AZ Eindhoven, Netherlands.
   [Pezzotti, Nicola] Philips Med Syst, NL-5656 AE Eindhoven, Netherlands.
C3 Eindhoven University of Technology; Philips; Philips Research; Eindhoven
   University of Technology; Philips; Philips Healthcare
RP Prasad, V (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
EM v.prasad@tue.nl; r.j.g.v.sloun@tue.nl; a.vilanova@tue.nl;
   n.pezzotti@tue.nl
OI van Sloun, Ruud JG/0000-0003-2845-0495; Vilanova,
   Anna/0000-0002-1034-737X; Prasad, Vidya/0000-0002-9296-3693
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Barbastathis G, 2019, OPTICA, V6, P921, DOI 10.1364/OPTICA.6.000921
   Barbu A, 2019, ADV NEUR IN, V32
   Buongiorno D, 2021, NEUROCOMPUTING, V452, P549, DOI 10.1016/j.neucom.2020.06.139
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Cohen G, 2017, Arxiv, DOI arXiv:1702.05373
   Cohen TS, 2016, PR MACH LEARN RES, V48
   D'Amour A, 2020, Arxiv, DOI arXiv:2011.03395
   Darestani M. Z., 2021, INT C MACHINE LEARNI, P2433
   Das N, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P271, DOI 10.1109/VIS47514.2020.00061
   Drenkow N, 2022, Arxiv, DOI arXiv:2112.00639
   Erhan D, 2009, ISUALIZING HIGHER LA, V1341, P1
   Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Grill J.B., 2020, P 34 INT C NEUR INF, V33, P21271, DOI [10.48550/arXiv.2006.07733, DOI 10.48550/ARXIV.2006.07733]
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Hendrycks D, 2018, P INT C LEARN REPR
   Huang JB, 2022, Arxiv, DOI arXiv:2204.01888
   Hui L., 2021, P INT C LEARN REPR
   Huynh T, 2022, IEEE WINT CONF APPL, P986, DOI 10.1109/WACV51458.2022.00106
   Jacobsen J.-H., 2019, P INT C LEARN REPR
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kabir H. M. Dipu, 2023, IEEE Transactions on Artificial Intelligence, P1165, DOI 10.1109/TAI.2022.3185179
   Kastryulin S, 2023, IEEE ACCESS, V11, P14154, DOI 10.1109/ACCESS.2023.3243466
   Kaul S, 2022, IEEE T VIS COMPUT GR, V28, P998, DOI 10.1109/TVCG.2021.3114779
   Kobyzev I, 2021, IEEE T PATTERN ANAL, V43, P3964, DOI 10.1109/TPAMI.2020.2992934
   Koh PW, 2021, PR MACH LEARN RES, V139
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Li QF, 2020, PROC CVPR IEEE, P7243, DOI 10.1109/CVPR42600.2020.00727
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Nichol A, 2022, PR MACH LEARN RES
   Olson ML, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P36, DOI 10.1109/VIS49827.2021.9623289
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Park C., 2021, P EUR C VIS
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pei KX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P1, DOI 10.1145/3132747.3132785
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Prasad V, 2024, IEEE T VIS COMPUT GR, V30, P1502, DOI 10.1109/TVCG.2022.3219248
   Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saunshi N, 2022, PR MACH LEARN RES, P19250
   Shen YJ, 2022, IEEE T PATTERN ANAL, V44, P2004, DOI 10.1109/TPAMI.2020.3034267
   Sietzen S, 2021, COMPUT GRAPH FORUM, V40, P253, DOI 10.1111/cgf.14418
   Sriram Anuroop, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12262), P64, DOI 10.1007/978-3-030-59713-9_7
   Suo JL, 2021, Arxiv, DOI arXiv:2109.08880
   Tang H, 2019, IEEE IJCNN
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tian YC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P303, DOI 10.1145/3180155.3180220
   Turkay C, 2019, Arxiv, DOI arXiv:1812.08032
   Tyagi Anjul, 2023, IEEE Trans Vis Comput Graph, V29, P299, DOI 10.1109/TVCG.2022.3209361
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1417, DOI 10.1109/TVCG.2020.3030449
   Zbontar J, 2019, Arxiv, DOI arXiv:1811.08839
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
   Zheng S, 2016, PROC CVPR IEEE, P4480, DOI 10.1109/CVPR.2016.485
NR 63
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5651
EP 5665
DI 10.1109/TVCG.2023.3301722
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400001
PM 37535493
OA Green Published
DA 2024-08-05
ER

PT J
AU Shan, ZY
   Yang, Q
   Ye, R
   Zhang, YJ
   Xu, YL
   Xu, XZ
   Liu, S
AF Shan, Ziyu
   Yang, Qi
   Ye, Rui
   Zhang, Yujie
   Xu, Yiling
   Xu, Xiaozhong
   Liu, Shan
TI GPA-Net:No-Reference Point Cloud Quality Assessment With Multi-Task
   Graph Convolutional Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Measurement; Feature extraction; Distortion;
   Convolution; Task analysis; Multitasking; Graph convolutional network;
   multi-task learning; point cloud; quality assessment
ID MODEL
AB With the rapid development of 3D vision, point cloud has become an increasingly popular 3D visual media content. Due to the irregular structure, point cloud has posed novel challenges to the related research, such as compression, transmission, rendering and quality assessment. In these latest researches, point cloud quality assessment (PCQA) has attracted wide attention due to its significant role in guiding practical applications, especially in many cases where the reference point cloud is unavailable. However, current no-reference metrics which based on prevalent deep neural network have apparent disadvantages. For example, to adapt to the irregular structure of point cloud, they require preprocessing such as voxelization and projection that introduce extra distortions, and the applied grid-kernel networks, such as Convolutional Neural Networks, fail to extract effective distortion-related features. Besides, they rarely consider the various distortion patterns and the philosophy that PCQA should exhibit shift, scaling, and rotation invariance. In this paper, we propose a novel no-reference PCQA metric named the Graph convolutional PCQA network (GPA-Net). To extract effective features for PCQA, we propose a new graph convolution kernel, i.e., GPAConv, which attentively captures the perturbation of structure and texture. Then, we propose the multi-task framework consisting of one main task (quality regression) and two auxiliary tasks (distortion type and degree predictions). Finally, we propose a coordinate normalization module to stabilize the results of GPAConv under shift, scale and rotation transformations. Experimental results on two independent databases show that GPA-Net achieves the best performance compared to the state-of-the-art no-reference PCQA metrics, even better than some full-reference metrics in some cases.
C1 [Shan, Ziyu; Ye, Rui; Zhang, Yujie; Xu, Yiling] Shanghai Jiao Tong Univ, Cooperat Media Innovat Ctr, Shanghai 200240, Peoples R China.
   [Yang, Qi; Xu, Xiaozhong; Liu, Shan] Tencent Media Lab, Shenzhen 518054, Peoples R China.
C3 Shanghai Jiao Tong University
RP Xu, YL (corresponding author), Shanghai Jiao Tong Univ, Cooperat Media Innovat Ctr, Shanghai 200240, Peoples R China.
EM shanziyu@sjtu.edu.cn; chinoyang@tencent.com; yr991129@sjtu.edu.cn;
   yujie19981026@sjtu.edu.cn; yl.xu@sjtu.edu.cn; xiaozhongxu@tencent.com;
   shanl@tencent.com
OI , Shan/0000-0002-1442-1207; Ye, Rui/0009-0007-5998-8200; Shan,
   Ziyu/0000-0002-3346-4261; Zhang, Yujie/0000-0002-5534-0198; Yang,
   Qi/0000-0002-4274-3457
FU National Key R#x0026;D Program of China [2018YFE0206700]; National
   Natural Science Foundation of China [61971282, U20A20185]
FX No Statement Available
CR Alexiou E, 2018, IEEE INT CON MULTI
   Alexiou E, 2017, IEEE INT WORKSH MULT
   Golestaneh SA, 2020, Arxiv, DOI arXiv:2006.03783
   Ao S, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107186
   Bletterer A, 2022, IEEE T VIS COMPUT GR, V28, P2822, DOI 10.1109/TVCG.2020.3042588
   Bro R, 2008, J CHEMOMETR, V22, P135, DOI 10.1002/cem.1122
   Chetouani A, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455967
   Fan Y, 2022, Arxiv, DOI arXiv:2206.05054
   Hou JW, 2020, IEEE IMAGE PROC, P3463, DOI 10.1109/ICIP40778.2020.9191241
   Kovács E, 2012, ANN MATH INFORM, V40, P175
   Li AB, 2022, NEUROCOMPUTING, V500, P307, DOI 10.1016/j.neucom.2022.05.043
   Li XZ, 2022, IEEE T VIS COMPUT GR, V28, P4503, DOI 10.1109/TVCG.2021.3092570
   Lin ZH, 2020, PROC CVPR IEEE, P1797, DOI 10.1109/CVPR42600.2020.00187
   Liu Q, 2023, IEEE T VIS COMPUT GR, V29, P3642, DOI 10.1109/TVCG.2022.3167151
   Liu Q, 2021, IEEE T CIRC SYST VID, V31, P4645, DOI 10.1109/TCSVT.2021.3100282
   Liu Q, 2021, IEEE T MULTIMEDIA, V23, P3278, DOI 10.1109/TMM.2020.3023294
   Liu Q, 2021, IEEE T IMAGE PROCESS, V30, P6623, DOI 10.1109/TIP.2021.3096060
   Liu SK, 2019, PROC CVPR IEEE, P1871, DOI 10.1109/CVPR.2019.00197
   Liu YX, 2022, APPL GEOPHYS, DOI 10.1007/s11770-022-0970-2
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Mekuria R., 2016, document ISO/IEC MPEG 16332
   Meynet G, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123147
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Perry S, 2020, IEEE IMAGE PROC, P3428, DOI 10.1109/ICIP40778.2020.9191308
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su HL, 2019, IEEE IMAGE PROC, P3182, DOI [10.1109/icip.2019.8803298, 10.1109/ICIP.2019.8803298]
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Tian D, 2017, IEEE IMAGE PROC, P3460, DOI 10.1109/ICIP.2017.8296925
   Tliba Marouane, 2022, QoEVMA '22: Proceedings of the 2nd Workshop on Quality of Experience in Visual Multimedia Applications, P63, DOI 10.1145/3552469.3555710
   Vaswani A., 2017, PROC NEURIPS, V30, P5998
   Video Quality Experts Group, 2000, VQEG M OTT CAN MARCH
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Watson A. B., 1997, P EL IM SCI TECHN C, P277
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xu L, 2017, IEEE T CIRC SYST VID, V27, P1833, DOI 10.1109/TCSVT.2016.2543099
   Yang Q, 2022, IEEE T PATTERN ANAL, V44, P3015, DOI 10.1109/TPAMI.2020.3047083
   Yang Q, 2022, PROC CVPR IEEE, P21147, DOI 10.1109/CVPR52688.2022.02050
   Yang Q, 2023, IEEE T PATTERN ANAL, V45, P6037, DOI 10.1109/TPAMI.2022.3213831
   Yang Q, 2021, IEEE T MULTIMEDIA, V23, P3877, DOI 10.1109/TMM.2020.3033117
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zhang YJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1230, DOI 10.1145/3474085.3475294
   Zhang ZC, 2022, IEEE T CIRC SYST VID, V32, P7618, DOI 10.1109/TCSVT.2022.3186894
   Zhao H, 2020, IEEE INT SYM BROADB, DOI 10.1109/BMSB49480.2020.9379524
   Zhou HR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4945, DOI 10.1109/ICCV48922.2021.00492
NR 52
TC 3
Z9 3
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4955
EP 4967
DI 10.1109/TVCG.2023.3282802
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400028
PM 37379183
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, C
   Jiang, RX
   Chai, ML
   He, MM
   Chen, DD
   Liao, J
AF Wang, Can
   Jiang, Ruixiang
   Chai, Menglei
   He, Mingming
   Chen, Dongdong
   Liao, Jing
TI <i>NeRF-Art:</i> Text-Driven Neural Radiance Fields Stylization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Text-driven stylization; neural radiance fields; CLIP
ID TO-IMAGE TRANSLATION
AB As a powerful representation of 3D scenes, the neural radiance field (NeRF) enables high-quality novel view synthesis from multi-view images. Stylizing NeRF, however, remains challenging, especially in simulating a text-guided style with both the appearance and the geometry altered simultaneously. In this paper, we present NeRF-Art, a text-guided NeRF stylization approach that manipulates the style of a pre-trained NeRF model with a simple text prompt. Unlike previous approaches that either lack sufficient geometry deformations and texture details or require meshes to guide the stylization, our method can shift a 3D scene to the target style characterized by desired geometry and appearance variations without any mesh guidance. This is achieved by introducing a novel global-local contrastive learning strategy, combined with the directional constraint to simultaneously control both the trajectory and the strength of the target style. Moreover, we adopt a weight regularization method to effectively suppress cloudy artifacts and geometry noises which arise easily when the density field is transformed during geometry stylization. Through extensive experiments on various styles, we demonstrate that our method is effective and robust regarding both single-view stylization quality and cross-view consistency.
C1 [Wang, Can; Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
   [Jiang, Ruixiang] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China.
   [Chai, Menglei] Snap Inc, Santa Monica, CA 90405 USA.
   [He, Mingming] Netflix, Los Gatos, CA 95032 USA.
   [Chen, Dongdong] Microsoft Cloud AI, Redmond, WA 98052 USA.
C3 City University of Hong Kong; Hong Kong Polytechnic University; Netflix,
   Inc.
RP Liao, J (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
EM cwang355-c@my.cityu.edu.hk; rui-x.jiang@connect.polyu.hk;
   cmlatsim@gmail.com; mheah@connect.ust.hk; cddlyf@gmail.com;
   jingliao@cityu.edu.hk
OI LIAO, Jing/0000-0001-7014-5377; Ruixiang, JIANG/0000-0001-8666-6767;
   wang, can/0000-0002-5102-1464; Chen, Dongdong/0000-0002-4642-4373
FU Research Grants Council (RGC) of Hong Kong [CityU 11216122, CityU
   9229102]
FX This work was supported in part by the General Research Fund (GRF) under
   Grant CityU 11216122, and in part by the Research Matching Grant Scheme
   (RMGS) under Grant CityU 9229102 from the Research Grants Council (RGC)
   of Hong Kong.
CR Arandjelovic R, 2021, arXiv
   Barron JT, 2022, PROC CVPR IEEE, P5460, DOI 10.1109/CVPR52688.2022.00539
   Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580
   Cao X, 2020, IEEE WINT CONF APPL, P3326, DOI 10.1109/WACV45572.2020.9093513
   Chefer H, 2022, LECT NOTES COMPUT SC, V13673, P695, DOI 10.1007/978-3-031-19778-9_40
   Chen DD, 2018, PROC CVPR IEEE, P6654, DOI 10.1109/CVPR.2018.00696
   Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chiang Pei-Ze, 2022, P IEEE CVF WINT C AP, P1475
   Deng KL, 2022, Arxiv, DOI arXiv:2107.02791
   Deng NC, 2022, IEEE T VIS COMPUT GR, V28, P3854, DOI 10.1109/TVCG.2022.3203102
   Fan ZW, 2022, Arxiv, DOI arXiv:2204.01943
   Gal R, 2021, Arxiv, DOI arXiv:2108.00946
   Gao C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5692, DOI 10.1109/ICCV48922.2021.00566
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Geiger M.NiemeyerandA., 2021, P IEEE CVF C COMP VI, P11453
   Guo J., 2021, ACM Trans. Graph, V40, P15
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Höllein L, 2022, Arxiv, DOI arXiv:2112.01530
   Hong FZ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530094
   Huang H.-P., 2021, IEEE CVF INT C COMP, P13869
   Huang JL, 2022, IEEE T MULTIMEDIA, V24, P1435, DOI 10.1109/TMM.2021.3065230
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang YH, 2022, PROC CVPR IEEE, P18321, DOI 10.1109/CVPR52688.2022.01780
   Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094
   Jain Ajay, 2021, P IEEE CVF INT C COM, P5885
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Klehm O, 2014, IEEE T VIS COMPUT GR, V20, P983, DOI 10.1109/TVCG.2014.13
   Kolkin N, 2019, PROC CVPR IEEE, P10043, DOI 10.1109/CVPR.2019.01029
   Kreutzer J., 2021, arXiv, DOI DOI 10.48550/ARXIV.2103.00020
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Li GH, 2023, IEEE T PATTERN ANAL, V45, P6923, DOI 10.1109/TPAMI.2021.3074057
   Li YJ, 2017, ADV NEUR IN, V30
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Liao J, 2017, Arxiv, DOI arXiv:1705.01088
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Lin S., 2022, P IEEE CVF WINT C AP, P238
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu HTD, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275047
   Liu Steven, 2021, P IEEECVF INT C COMP, P5773
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Ma L., 2021, arXiv
   Michel O., 2021, arXiv
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mller T., 2022, arXiv, DOI 10.1145/3528223.3530127
   Mordvintsev A., 2018, Distill, V3, pe12, DOI [DOI 10.23915/DISTILL.00012, 10. 23915/distill.00012]
   Mu Fangzhou., 3d photo stylization: Learning to generate stylized novel views from a single image
   Niemeyer M., 2021, arXiv
   Noguchi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5742, DOI 10.1109/ICCV48922.2021.00571
   Park K, 2021, Arxiv, DOI arXiv:2106.13228
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park T., 2020, EUR C COMP VIS, P319, DOI [DOI 10.1007/978-3-030-58545-719, 10.1007/978-3-030-58545-719, DOI 10.1007/978-3-030-58545-7_19]
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Pumarola Albert, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P10313, DOI 10.1109/CVPR46437.2021.01018
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ramon E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5600, DOI 10.1109/ICCV48922.2021.00557
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schwarz K., 2020, ADV NEURAL INFORM PR, V33, P20154, DOI DOI 10.48550/ARXIV.2007.02442
   Sheng P. Li, 2019, IEEE Trans. Vis. Comput. Graph., V25, P6
   Shu YZ, 2022, IEEE T VIS COMPUT GR, V28, P3376, DOI 10.1109/TVCG.2021.3067201
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Wang C., 2021, arXiv
   Wang KK, 2023, IEEE T VIS COMPUT GR, V29, P5097, DOI 10.1109/TVCG.2022.3202503
   Wang P., 2021, PROC NEURIPS, V34, P27171
   Wei T., 2021, arXiv
   Xian WQ, 2021, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR46437.2021.00930
   Xinghao Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P614, DOI 10.1007/978-3-030-58539-6_37
   Yang GW, 2023, IEEE T VIS COMPUT GR, V29, P5124, DOI 10.1109/TVCG.2022.3204608
   Yariv L., 2021, ADV NEURAL INFORM PR, P4805, DOI DOI 10.48550/ARXIV.2106.12052
   Ye ZP, 2023, IEEE T VIS COMPUT GR, V29, P2203, DOI 10.1109/TVCG.2021.3126659
   Yin Kangxue, 2021, P IEEE CVF INT C COM, P12456
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Zhang H, 2023, IEEE T VIS COMPUT GR, V29, P4891, DOI 10.1109/TVCG.2022.3192713
   Zhang K., 2022, arXiv
   Zhang K, 2020, Arxiv, DOI arXiv:2010.07492
   Zhang M, 2022, IEEE T VIS COMPUT GR, V28, P2926, DOI 10.1109/TVCG.2020.3041487
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhao YD, 2015, IEEE T VIS COMPUT GR, V21, P229, DOI 10.1109/TVCG.2014.2355221
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 93
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4983
EP 4996
DI 10.1109/TVCG.2023.3283400
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400058
PM 37279137
DA 2024-08-05
ER

PT J
AU Pan, RS
   Wang, ZY
   Wei, YT
   Gao, H
   Ou, GC
   Cao, CC
   Xu, JL
   Xu, T
   Chen, W
AF Pan, Rusheng
   Wang, Zhiyong
   Wei, Yating
   Gao, Han
   Ou, Gongchang
   Cao, Caleb Chen
   Xu, Jingli
   Xu, Tong
   Chen, Wei
TI Towards Efficient Visual Simplification of Computational Graphs in Deep
   Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Computational modeling; Tensors; Layout; Bit error rate;
   Graph drawing; Computational efficiency; Deep neural networks;
   computational graphs; graph visualization; graph layout; visual
   simplifications
ID OF-THE-ART; LEARNING-MODELS; VISUALIZATION; EXPLORATION
AB A computational graph in a deep neural network (DNN) denotes a specific data flow diagram (DFD) composed of many tensors and operators. Existing toolkits for visualizing computational graphs are not applicable when the structure is highly complicated and large-scale (e.g., BERT (Devlin et al. 2019)). To address this problem, we propose leveraging a suite of visual simplification techniques, including a cycle-removing method, a module-based edge-pruning algorithm, and an isomorphic subgraph stacking strategy. We design and implement an interactive visualization system that is suitable for computational graphs with up to 10 thousand elements. Experimental results and usage scenarios demonstrate that our tool reduces 60% elements on average and hence enhances the performance for recognizing and diagnosing DNN models. Our contributions are integrated into an open-source DNN visualization toolkit, namely, MindInsight [2].
C1 [Pan, Rusheng; Wang, Zhiyong; Wei, Yating; Xu, Jingli; Xu, Tong; Chen, Wei] Zhejiang Univ, Stake key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Gao, Han; Ou, Gongchang; Cao, Caleb Chen] Huawei Technol Co Ltd, Distributed Data Lab, Shenzhen 518129, Peoples R China.
C3 Zhejiang University; Huawei Technologies
RP Chen, W (corresponding author), Zhejiang Univ, Stake key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM panrusheng@zju.edu.cn; zerowangzy@outlook.com; weiyating@zju.edu.cn;
   gaohan19@huawei.com; ougongchang@huawei.com; caleb.cao@huawei.com;
   xu1220341948@gmail.com; xutong8@zju.edu.cn; chenvis@zju.edu.cn
OI Chen, Wei/0000-0002-8365-4741
FU National Natural Science Foundation of China [62132017]; Fundamental
   Research Funds for the Central Universities [226-2022-00235]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62132017, and in part by the Fundamental
   Research Funds for the Central Universities under Grant 226-2022-00235.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Bäuerle A, 2021, IEEE T VIS COMPUT GR, V27, P2980, DOI 10.1109/TVCG.2021.3057483
   Balzer M, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P133
   BATINI C, 1986, IEEE T SOFTWARE ENG, V12, P538, DOI 10.1109/TSE.1986.6312901
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chollet F., 2015, Keras
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   Du MN, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1358, DOI 10.1145/3219819.3220099
   Eades Q., 1996, Graph Drawing, P101, DOI DOI 10.1007/3-540-62495-3_41
   Eades Q.-W., 1996, Graph Drawing, P1
   Ehrlinger L, 2019, LECT NOTES COMPUT SC, V11706, P227, DOI 10.1007/978-3-030-27615-7_17
   Eschbach W., 2006, J. Graph Algorithms Appl., V10, P141
   Estébanez C, 2014, SOFTWARE PRACT EXPER, V44, P681, DOI 10.1002/spe.2179
   GANSNER ER, 1993, IEEE T SOFTWARE ENG, V19, P214, DOI 10.1109/32.221135
   Gunning D, 2019, AI MAG, V40, P44, DOI 10.1609/aimag.v40i2.2850
   gwding, 2016, The draw-convnet repository on github
   He K., 2015, ICCV, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Huang XD, 2006, J VISUAL LANG COMPUT, V17, P225, DOI 10.1016/j.jvlc.2005.10.003
   Jia J. J., 2019, Mach. Learn. Syst., P1
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulesza T., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces. IUI'15, P126, DOI [10.1145/2678025.2701399, DOI 10.1145/2678025.2701399]
   Larman C., 2012, Applying UMLand Patterns: An Introduction to Object Oriented Analysis and Designand Interative Development, P127
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   lutzroeder, 2017, The NETRON repository on github
   mindspore-ai, 2020, The MindSpore repository on github
   mindspore-ai, 2020, The MindInsight repository on github
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Owhadi H, 2022, RES MATH SCI, V9, DOI 10.1007/s40687-022-00320-8
   PaddlePaddle, 2016, The VisualDL repository on github
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Quigley A., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P197
   Samek W, 2017, PREPRINT
   Sander G., 1995, Graph Drawing. DIMACS International Workshop, GD'94. Proceedings, P194
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schaffer D., 1996, ACM Transactions on Computer-Human Interaction, V3, P162, DOI DOI 10.1145/230562.230577
   Shi X., 2015, Advances in neural information processing systems, V28, P802, DOI [10.5555/2969239.2969329, 10.48550/arXiv.1506.04214, DOI 10.48550/ARXIV.1506.04214, DOI 10.5555/2969239.2969329]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spönemann M, 2010, LECT NOTES COMPUT SC, V5849, P135, DOI 10.1007/978-3-642-11805-0_14
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Sun MY, 2016, IEEE T VIS COMPUT GR, V22, P310, DOI 10.1109/TVCG.2015.2467813
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   waleedka, 2018, The HiddenLayer repository on github
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xu K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174237
   yu4u, 2018, The convnet-drawer repository on github
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
NR 68
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3359
EP 3373
DI 10.1109/TVCG.2022.3230832
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700062
PM 37015673
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, XJ
   Lv, QX
   Chen, G
   Zhang, J
   Wei, ZQ
   Dong, JY
   Fu, HB
   Zhu, ZP
   Liu, JX
   Jin, XG
AF Wang, Xinjie
   Lv, Qingxuan
   Chen, Guo
   Zhang, Jing
   Wei, Zhiqiang
   Dong, Junyu
   Fu, Hongbo
   Zhu, Zhipeng
   Liu, Jingxin
   Jin, Xiaogang
TI MobileSky: Real-Time Sky Replacement for Mobile AR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Real-time systems; Cameras; Streaming media; Image color analysis;
   Performance evaluation; Motion segmentation; Task analysis; Mobile
   augmented reality; semantic segmentation; sky replacement
ID IMAGE SEGMENTATION; VIDEO
AB We present MobileSky, the first automatic method for real-time high-quality sky replacement for mobile AR applications. The primary challenge of this task is how to extract sky regions in camera feed both quickly and accurately. While the problem of sky replacement is not new, previous methods mainly concern extraction quality rather than efficiency, limiting their application to our task. We aim to provide higher quality, both spatially and temporally consistent sky mask maps for all camera frames in real time. To this end, we develop a novel framework that combines a new deep semantic network called FSNet with novel post-processing refinement steps. By leveraging IMU data, we also propose new sky-aware constraints such as temporal consistency, position consistency, and color consistency to help refine the weakly classified part of the segmentation output. Experiments show that our method achieves an average of around 30 FPS on off-the-shelf smartphones and outperforms the state-of-the-art sky replacement methods in terms of execution speed and quality. In the meantime, our mask maps appear to be visually more stable across frames. Our fast sky replacement method enables several applications, such as AR advertising, art making, generating fantasy celestial objects, visually learning about weather phenomena, and advanced video-based visual effects. To facilitate future research, we also create a new video dataset containing annotated sky regions with IMU data.
C1 [Wang, Xinjie; Lv, Qingxuan; Wei, Zhiqiang; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao 266005, Shandong, Peoples R China.
   [Chen, Guo; Zhang, Jing; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
   [Zhu, Zhipeng; Liu, Jingxin] Guangdong OPPO Mobile Telecommun Corp Ltd, Dongguan 523860, Peoples R China.
C3 Ocean University of China; Zhejiang University; City University of Hong
   Kong
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM wangxinjie@ouc.edu.cn; lvqingxuan@stu.ouc.edu.cn; guo_chenoo@zju.edu.cn;
   jing_z99@163.com; weizhiqiang@ouc.edu.cn; dongjunyu@ouc.edu.cn;
   hongbofu@cityu.edu.hk; zhuzhipeng@oppo.com; liujingxin@oppo.com;
   jin@cad.zju.edu.cn
OI Dong, Junyu/0000-0001-7012-2087; /0000-0003-3157-7358; FU,
   Hongbo/0000-0002-0284-726X; Jin, Xiaogang/0000-0001-7339-2920
FU Shandong Provincial Natural Science Foundation of China [ZR2021QF124];
   China Postdoctoral Science Foundation [2021M703031]; Open Project
   Program of the State Key Lab of CAD&CG , Zhejiang University [A2219];
   National Natural Science Foundation of China [62036010]; Key R&D Program
   of Zhejiang [2022C03126]
FX The work of Xinjie Wang was supported in part by the Shandong Provincial
   Natural Science Foundation of China under Grant ZR2021QF124, in part by
   China Postdoctoral Science Foundation under Grant 2021M703031, andin
   part by the Open Project Program of the State Key Lab of CAD&CG under
   Grant A2219, Zhejiang University. The work of Xiaogang Jin was supported
   inpart by the National Natural Science Foundation of China under Grant
   62036010 and in part by the Key R&D Program of Zhejiang under Grant
   2022C03126.
CR Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   BROWN MB, 1974, J AM STAT ASSOC, V69, P364, DOI 10.2307/2285659
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chen L.-C., 2018, P EUR C COMP VIS ECC, P801, DOI DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, 10.48550/arXiv.1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Cho SH, 2020, Arxiv, DOI arXiv:2002.03651
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Delgado JMD, 2020, ADV ENG INFORM, V45, DOI 10.1016/j.aei.2020.101122
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Guo YH, 2019, AAAI CONF ARTIF INTE, P8368
   Halperin T, 2019, COMPUT GRAPH FORUM, V38, P207, DOI 10.1111/cgf.13631
   He J. Sun, 2009, IEEE transactions on pattern analysis and machine intelligence, V28, P1, DOI [DOI 10.1109/TPAMI.2010.168, 10.1109/CVPRW.2009.5206515]
   He KM, 2015, Arxiv, DOI [arXiv:1505.00996, DOI 10.48550/ARXIV.1505.00996]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hou QQ, 2019, IEEE I CONF COMP VIS, P4129, DOI 10.1109/ICCV.2019.00423
   Jiang XT, 2020, Arxiv, DOI arXiv:2002.12418
   Jung S., 2022, P CHI C HUM FACT COM, P1
   Kaufman L, 2012, COMPUT GRAPH FORUM, V31, P2528, DOI 10.1111/j.1467-8659.2012.03225.x
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Likert R., 1932, ARCH PSYCHOL, V22, P5, DOI DOI 10.4135/9781412961288.N454
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu C, 2019, PROC CVPR IEEE, P10978, DOI 10.1109/CVPR.2019.01124
   Liu J. Xie, 2021, IEEE Trans. Multimedia, V24, P2727
   Liu SG, 2022, IEEE T MULTIMEDIA, V24, P1299, DOI 10.1109/TMM.2021.3063605
   Lobo J, 2007, INT J ROBOT RES, V26, P561, DOI 10.1177/0278364907079276
   Loesdau M, 2014, LECT NOTES COMPUT SC, V8509, P203, DOI 10.1007/978-3-319-07998-1_23
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336
   Meister Philippe, 2022, Journal of Air Transportation, P113, DOI 10.2514/1.D0308
   Mihail R. P., 2016, P IEEE WINT C APPL C, P6
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Paszke A, 2016, Arxiv, DOI arXiv:1606.02147
   Paszke A, 2019, ADV NEUR IN, V32
   Poudel R. P. K., 2019, arXiv
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sun Y., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P11120
   Sun YN, 2021, PROC CVPR IEEE, P6971, DOI 10.1109/CVPR46437.2021.00690
   Szeliski R, 2011, TEXTS COMPUT SCI, P1
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tan MX, 2019, Arxiv, DOI [arXiv:1907.09595, DOI 10.48550/ARXIV.1907.09595]
   Tang JW, 2019, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2019.00317
   Tao LT, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531374
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tobias OJ, 2002, IEEE T IMAGE PROCESS, V11, P1457, DOI 10.1109/TIP.2002.806231
   Tran Y., 2020, P CVPR WORKSH COMP V, P1
   Tsai YH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925942
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu M., 2019, P 8 ACM EUR EXPR S C, P21, DOI DOI 10.2312/EXP.20191073
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zou ZX, 2022, IEEE T IMAGE PROCESS, V31, P5067, DOI 10.1109/TIP.2022.3192717
NR 71
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4304
EP 4320
DI 10.1109/TVCG.2023.3257840
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700014
PM 37030763
DA 2024-08-05
ER

PT J
AU Wei, YT
   Wang, ZY
   Wang, ZW
   Dai, Y
   Ou, GC
   Gao, H
   Yang, HT
   Wang, Y
   Cao, CC
   Weng, LX
   Lu, JY
   Zhu, RC
   Chen, W
AF Wei, Yating
   Wang, Zhiyong
   Wang, Zhongwei
   Dai, Yong
   Ou, Gongchang
   Gao, Han
   Yang, Haitao
   Wang, Yue
   Cao, Caleb Chen
   Weng, Luoxuan
   Lu, Jiaying
   Zhu, Rongchen
   Chen, Wei
TI Visual Diagnostics of Parallel Performance in Training Large-Scale DNN
   Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Data visualization; Computational modeling; Solid modeling;
   Parallel processing; Performance evaluation; Data models; Deep neural
   network; model training; parallel performance; visual analysis
ID VISUALIZATION; FLOW
AB Diagnosing the cluster-based performance of large-scale deep neural network (DNN) models during training is essential for improving training efficiency and reducing resource consumption. However, it remains challenging due to the incomprehensibility of the parallelization strategy and the sheer volume of complex data generated in the training processes. Prior works visually analyze performance profiles and timeline traces to identify anomalies from the perspective of individual devices in the cluster, which is not amenable for studying the root cause of anomalies. In this article, we present a visual analytics approach that empowers analysts to visually explore the parallel training process of a DNN model and interactively diagnose the root cause of a performance issue. A set of design requirements is gathered through discussions with domain experts. We propose an enhanced execution flow of model operators for illustrating parallelization strategies within the computational graph layout. We design and implement an enhanced Marey's graph representation, which introduces the concept of time-span and a banded visual metaphor to convey training dynamics and help experts identify inefficient training processes. We also propose a visual aggregation technique to improve visualization efficiency. We evaluate our approach using case studies, a user study and expert interviews on two large-scale models run in a cluster, namely, the PanGu-alpha 13B model (40 layers), and the Resnet model (50 layers).
C1 [Wei, Yating; Wang, Zhiyong; Wang, Zhongwei; Dai, Yong; Weng, Luoxuan; Lu, Jiaying; Zhu, Rongchen; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Ou, Gongchang; Gao, Han; Yang, Haitao; Wang, Yue; Cao, Caleb Chen] Huawei Technol Co Ltd, Distributed Data Lab, Shenzhen 518129, Peoples R China.
C3 Zhejiang University; Huawei Technologies
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM weiyating@zju.edu.cn; zerowangzy@zju.edu.cn; wzw09@zju.edu.cn;
   daiyong@zju.edu.cn; ougongchang@huawei.com; gaohan19@huawei.com;
   yanghaitao1@huawei.com; wangyue53@huawei.com; caochen.hkust@gmail.com;
   lukeweng@zju.edu.cn; 3180103570@zju.edu.cn; zrccrz@zju.edu.cn;
   chenvis@zju.edu.cn
OI Weng, Luoxuan/0000-0003-4350-9141; Lu, Jiaying/0009-0008-3578-346X
FU National Natural Science Foundation of China [62132017]; Fundamental
   Research Funds for the Central Universities [226-2022-00235]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62132017 and in part by the Fundamental
   Research Funds for the Central Universities under Grant 226-2022-00235.
CR Abadi M., 2016, arXiv
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Amodei D, 2016, PR MACH LEARN RES, V48
   Bach B., 2014, P EUR C VIS, DOI [10.2312/eurovisstar.2014117125, DOI 10.2312/EUROVISSTAR.2014117125]
   Dean J., 2012, Advances in Neural Information Processing Systems, P1232
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Fujiwara T, 2017, IEEE CONF VIS ANAL, P59, DOI 10.1109/VAST.2017.8585646
   Gang Xian, 2021, 2021 7th International Conference on Computer and Communications (ICCC), P1436, DOI 10.1109/ICCC54389.2021.9674694
   Gantt HenryL., 1919, Organizing for Work
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Gu T., 2018, IEEE Trans. Computat. Social Syst., V5, P1
   Guo H., 2018, P S PAR GRAPH VIS, P91, DOI 10.5555/3293524.3293533
   Harlap A, 2018, Arxiv, DOI arXiv:1806.03377
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Huang YP, 2019, ADV NEUR IN, V32
   Jia Z., 2019, P MACHINE LEARNING S, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Luz S, 2007, IEEE INT CONF INF VI, P197
   Milash B., 1996, P C COMP HUM FACT CO, P392
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646
   Palomo C, 2016, IEEE T VIS COMPUT GR, V22, P170, DOI 10.1109/TVCG.2015.2467592
   Shazeer N., 2018, ADV NEURAL INF PROCE, P1
   Keskar NS, 2017, Arxiv, DOI arXiv:1712.07628
   Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Tufte E. R., 1985, TLS-TIMES LIT SUPPL, V7, P15
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   Vaswani A, 2017, ADV NEUR IN, V30
   WAUGH SJ, 1995, J OPT SOC AM A, V12, P2305, DOI 10.1364/JOSAA.12.002305
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Yamazaki M, 2019, Arxiv, DOI arXiv:1903.12650
   Yang SH, 2020, Arxiv, DOI arXiv:2002.07526
   Zeng W, 2024, arXiv
NR 41
TC 2
Z9 2
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3915
EP 3929
DI 10.1109/TVCG.2023.3243228
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700059
PM 37022820
DA 2024-08-05
ER

PT J
AU Zhou, H
   Ma, R
   Zhang, LX
   Gao, L
   Mahdavi-Amiri, A
   Zhang, H
AF Zhou, Hang
   Ma, Rui
   Zhang, Ling-Xiao
   Gao, Lin
   Mahdavi-Amiri, Ali
   Zhang, Hao
TI SAC-GAN: Structure-Aware Image Composition
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Transforms; Semantics; Three-dimensional displays; Image edge
   detection; Codes; Coherence; Structure-aware image composition;
   self-supervision; GANs
ID VISION
AB We introduce an end-to-end learning framework for image-to-image composition, aiming to plausibly compose an object represented as a cropped patch from an object image into a background scene image. As our approach emphasizes more on semantic and structural coherence of the composed images, rather than their pixel-level RGB accuracies, we tailor the input and output of our network with structure-aware features and design our network losses accordingly, with ground truth established in a self-supervised setting through the object cropping. Specifically, our network takes the semantic layout features from the input scene image, features encoded from the edges and silhouette in the input object patch, as well as a latent code as inputs, and generates a 2D spatial affine transform defining the translation and scaling of the object patch. The learned parameters are further fed into a differentiable spatial transformer network to transform the object patch into the target image, where our model is trained adversarially using an affine transform discriminator and a layout discriminator. We evaluate our network, coined SAC-GAN, for various image composition scenarios in terms of quality, composability, and generalizability of the composite images. Comparisons are made to state-of-the-art alternatives, including Instance Insertion, ST-GAN, CompGAN and PlaceNet, confirming superiority of our method.
C1 [Zhou, Hang; Mahdavi-Amiri, Ali; Zhang, Hao] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   [Ma, Rui] Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
   [Ma, Rui] Minist Educ, Engn Res Ctr Knowledge Driven Human Machine Intell, Changchun 130012, Peoples R China.
   [Zhang, Ling-Xiao; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing 100045, Peoples R China.
C3 Simon Fraser University; Jilin University; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Ma, R (corresponding author), Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
EM zhouhang2991@gmail.com; ruim@jlu.edu.cn; zhanglingxiao@ict.ac.cn;
   gaolin@ict.ac.cn; amahdavi@sfu.ca; haoz@sfu.ca
OI Zhang, Ling-Xiao/0000-0001-8922-7639; Zhang, Hao/0000-0003-1991-119X;
   Zhou, Hang/0000-0001-7860-8452; Ma, Rui/0000-0002-3477-1466
FU NSERC Discovery [611370]; National Natural Science Funds of China
   [62202199]
FX This work was supported in part by NSERC Discovery under Grant 611370,
   and in part by National Natural Science Funds of China under Grant
   62202199.
CR Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   Antoniou A., 2017, Data augmentation generative adversarial networks
   Azadi S, 2020, INT J COMPUT VISION, V128, P2570, DOI 10.1007/s11263-020-01336-9
   Bhattad A., 2020, AR XIV201005907
   Brinkmann R., 2008, ART SCI DIGITAL COMP
   Chang T.-Y., 2020, P AS C COMP VIS, P509
   Chaudhuri S, 2020, COMPUT GRAPH FORUM, V39, P643, DOI 10.1111/cgf.14020
   Chen BC, 2019, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2019.00861
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Y, 2021, PROC CVPR IEEE, P7226, DOI 10.1109/CVPR46437.2021.00715
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Ding H., IEEE T PATTERN ANAL, DOI 10.1109/ΡΑΙ2022.3217852
   Ding HH, 2020, IEEE T IMAGE PROCESS, V29, P3520, DOI 10.1109/TIP.2019.2962685
   Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146
   Einabadi F, 2021, COMPUT GRAPH FORUM, V40, P315, DOI 10.1111/cgf.14283
   Fu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10913, DOI 10.1109/ICCV48922.2021.01075
   Fu H, 2021, INT J COMPUT VISION, V129, P3313, DOI 10.1007/s11263-021-01534-z
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gu JQ, 2022, PROC CVPR IEEE, P12084, DOI 10.1109/CVPR52688.2022.01178
   Guo M., 2020, ARXIV
   Heusel M., 2017, NeurIPS, P6629
   Hong S., 2018, P ADV NEUR INF PROC, P2713
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin JC, 2021, IEEE INT CONF COMP V, P2951, DOI 10.1109/ICCVW54120.2021.00330
   Jocher G., 2021, Yolov5
   Karsch K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602146
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Kim T, 2017, PR MACH LEARN RES, V70
   Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276381
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Le Moing G, 2021, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR46437.2021.00922
   Lee D, 2018, ADV NEUR IN, V31
   Lin CH, 2018, PROC CVPR IEEE, P9455, DOI 10.1109/CVPR.2018.00985
   Lingzhi Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P566, DOI 10.1007/978-3-030-58601-0_34
   Liu D., 2020, P IEEE CVF C COMP VI, P8136
   Liu Liangxi, 2021, ARXIV
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mitra NJ, 2013, Eurographics State-of-the-art Report (STAR), P175
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   Niu L., 2021, ARXIV
   Ntavelis Evangelos, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P394, DOI 10.1007/978-3-030-58542-6_24
   Ost J, 2021, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR46437.2021.00288
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Porter T., 1984, P SIGGRAPH, P253, DOI [DOI 10.1145/964965.808606, 10.1145/964965.808606]
   Radford A, 2021, PR MACH LEARN RES, V139
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Tan FW, 2018, IEEE WINT CONF APPL, P1519, DOI 10.1109/WACV.2018.00170
   Tao Andrew, 2020, Arxiv
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wang J, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/969456
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang YF, 2021, PROC CVPR IEEE, P5106, DOI 10.1109/CVPR46437.2021.00507
   Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139
   Wenyan Cong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8391, DOI 10.1109/CVPR42600.2020.00842
   Xu Z., 2017, ARXIV
   Yang BB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13759, DOI 10.1109/ICCV48922.2021.01352
   Yang ZP, 2022, PROC CVPR IEEE, P7754, DOI 10.1109/CVPR52688.2022.00761
   Yi RJ, 2018, LECT NOTES COMPUT SC, V11213, P321, DOI 10.1007/978-3-030-01240-3_20
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yifan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P438, DOI 10.1007/978-3-030-58607-2_26
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhan FN, 2019, PROC CVPR IEEE, P3648, DOI 10.1109/CVPR.2019.00377
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao S., 2020, P INT C LEARN REPR, P1
   Zhou SY, 2022, LECT NOTES COMPUT SC, V13677, P373, DOI 10.1007/978-3-031-19790-1_23
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 74
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3151
EP 3165
DI 10.1109/TVCG.2022.3226689
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700035
PM 37015486
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Koval, M
   Jansen, Y
   Chevalier, F
AF Koval, Morgane
   Jansen, Yvonne
   Chevalier, Fanny
TI Animating Hypothetical Trips to Communicate Space-Based Temporal
   Uncertainty on Digital Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Animation; Visualization; Data visualization; Task
   analysis; Substrates; Geometry; geospatial visualization; hypothetical
   outcome plot; uncertainty visualization
ID TIME; VISUALIZATION; PERCEPTION; PATTERNS; MOVEMENT
AB This paper explores a novel approach to communicating plausible space-based temporal variability of travel durations. Digital maps most often only convey single numerical values as the estimated duration for a path and this piece of information does not account for the multiple scenarios hidden behind this point estimate, nor for the temporal uncertainty along the route (e.g., the likelihood of being slowed down at an intersection). We explore conveying this uncertainty by animating hypothetical trips onto maps in the form of moving dots along one or more paths. We conducted a study with 16 participants and observed that they were able to correctly extract and infer simple information from our uncertainty visualizations but that identifying moving dots' changes in speed is a more complex task. We discuss design challenges and implications for future visualizations of space-based temporal uncertainty.
C1 [Koval, Morgane] Univ Bordeaux, Inria Ctr, F-33000 Bordeaux, France.
   [Jansen, Yvonne] Univ Bordeaux, CNRS, Inria, LaBRI, F-33000 Bordeaux, France.
   [Chevalier, Fanny] Univ Toronto, Toronto, ON M5S 1A1, Canada.
C3 Universite de Bordeaux; Universite de Bordeaux; Inria; Centre National
   de la Recherche Scientifique (CNRS); University of Toronto
RP Koval, M (corresponding author), Univ Bordeaux, Inria Ctr, F-33000 Bordeaux, France.
EM morgane.koval@inria.fr; yvonne.jansen@cnrs.fr; fanny@cs.toronto.edu
RI ; Jansen, Yvonne/A-9998-2015
OI Chevalier, Fanny/0000-0002-5585-7971; Jansen, Yvonne/0000-0001-5092-551X
FU ANR Ember
FX No Statement Available
CR Aerts J.C., 2003, CARTOGR GEOGR INF SC, V30, P249, DOI DOI 10.1559/152304003100011180
   Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   Andrienko N, 2004, P WORK C ADV VIS INT, P417
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   [Anonymous], 1992, Cartogr. Perspect, DOI DOI 10.14714/CP13.1000
   Bach B, 2015, COMPUT GRAPH FORUM, V34, P31, DOI 10.1111/cgf.12615
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Bach C., 2018, P 5 BIENN TRANSD IM, P1, DOI [10.6084/m9.figshare.6104705.8B, DOI 10.6084/M9.FIGSHARE.6104705.8B]
   Bartram L., 1997, P WORKSH NEW PAR INF, P3, DOI 10.1145/275519.275520
   Bartram L., 2009, P 5 EUR C COMP AESTH, P129, DOI [DOI 10.2312/COM, 10.2312/COMPAESTH/COMPAESTH09/129-136, DOI 10.2312/COMPAESTH/COMPAESTH09/129-136]
   Bartram L. R., 2001, PhD thesis
   Bertin Jacques, 1983, Semiology of graphics
   Bies Sandra, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P511, DOI 10.1007/978-3-642-36763-2_45
   Bilbily V., 2021, P 34 ANN ACM S US IN, P484, DOI [10.1145/3472749.3474764, DOI 10.1145/3472749.3474764]
   Blenkinsop S., 2000, Cartographica: Int. J. Geographic Inf. Geovisualization, V37, P1, DOI [10.3138/3645-4V22-0M23-3T52, DOI 10.3138/3645-4V22-0M23-3T52]
   Boyandin I, 2012, COMPUT GRAPH FORUM, V31, P1005, DOI 10.1111/j.1467-8659.2012.03093.x
   Brosz M. A., 2013, P 26 ANN ACM S US IN, P97, DOI [10.1145/2501988.2502046.19, DOI 10.1145/2501988.2502046.19]
   Buchin K, 2014, LECT NOTES COMPUT SC, V8728, P18, DOI 10.1007/978-3-319-11593-1_2
   Buschmann S, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P174, DOI 10.1109/CW.2014.32
   Chevalier F., 2016, P INT WORK C ADV VIS, P280, DOI 10.1145/2909132.2909255
   Deitrick S, 2015, ANN ASSOC AM GEOGR, V105, P531, DOI 10.1080/00045608.2015.1012635
   Ehlschlaeger CR, 1997, COMPUT GEOSCI, V23, P387, DOI 10.1016/S0098-3004(97)00005-8
   Evans BJ, 1997, COMPUT GEOSCI, V23, P409, DOI 10.1016/S0098-3004(97)00011-3
   Fekete JD, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P289
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fish C, 2011, CARTOGR GEOGR INF SC, V38, P350, DOI 10.1559/15230406384350
   Gatalsky P, 2004, IEEE INFOR VIS, P145, DOI 10.1109/IV.2004.1320137
   Goldsberry K., 2009, Cartographica, V44, P201, DOI [10.3138/carto.44.3.201, DOI 10.3138/CARTO.44.3.201]
   Griffin AL, 2006, ANN ASSOC AM GEOGR, V96, P740, DOI 10.1111/j.1467-8306.2006.00514.x
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Han PKJ, 2012, PATIENT EDUC COUNS, V86, P106, DOI 10.1016/j.pec.2011.01.033
   Harrower M., 2007, The Cartographic Journal, V44, P313
   Harrower M., 2007, Cartographica, Int. J. Geographic Inf. Geovisualization, V42, P349, DOI [10.3138/carto.42.4.349, DOI 10.3138/CARTO.42.4.349]
   Hong S, 2017, IEEE PAC VIS SYMP, P81, DOI 10.1109/PACIFICVIS.2017.8031582
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Kaiser C, 2010, LECT NOTES COMPUT SC, V6292, P85, DOI 10.1007/978-3-642-15300-6_7
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Koval M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502010
   Kraak M.-J., 2003, P 21 INT CART C ICC, P1988
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Nagel T, 2017, LEONARDO, V50, P511, DOI 10.1162/LEON_a_01234
   Padilla M. Kay, 2021, Uncertainty Visualization, P1, DOI [10.1002/9781118445112.stat08296.48C, DOI 10.1002/9781118445112.STAT08296.48C]
   Perin C, 2018, IEEE T VIS COMPUT GR, V24, P698, DOI 10.1109/TVCG.2017.2743918
   Preston A, 2023, IEEE T VIS COMPUT GR, V29, P3746, DOI 10.1109/TVCG.2022.3171443
   Rhee I, 2011, IEEE ACM T NETWORK, V19, P630, DOI 10.1109/TNET.2011.2120618
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Rosling H, 2011, J EPIDEMIOL GLOB HEA, V1, P11, DOI 10.1016/j.jegh.2011.07.001
   Scheepens R, 2016, IEEE T VIS COMPUT GR, V22, P379, DOI 10.1109/TVCG.2015.2467112
   Spiegelhalter D, 2017, ANNU REV STAT APPL, V4, P31, DOI 10.1146/annurev-statistics-010814-020148
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Tang Anthony., 2008, AVI '08: Proceedings of the Working Conference on Advanced Visual Interfaces 2008, P191, DOI DOI 10.1145/1385569.1385601
   Thompson W., 1996, Cartographica: The International Journal for Geographic Information and Geovisualization, V33, P17
   Xie LWH, 2024, IEEE T VIS COMPUT GR, V30, P5198, DOI 10.1109/TVCG.2023.3286392
   Yusof N, 2016, INT J GEOGR INF SCI, V30, P1486, DOI 10.1080/13658816.2015.1135928
NR 59
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2942
EP 2954
DI 10.1109/TVCG.2024.3388517
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500014
PM 38619949
OA Green Published
DA 2024-08-05
ER

PT J
AU Liang, ZC
   Liu, JH
   Dasari, M
   Wang, FX
AF Liang, Zhicheng
   Liu, Junhua
   Dasari, Mallesham
   Wang, Fangxin
TI Fumos: Neural Compression and Progressive Refinement for Continuous
   Point Cloud Video Streaming
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Streaming media; Point cloud compression; Deep learning; Virtual Reality
   (VR); User Experience
ID ATTRIBUTE COMPRESSION; CHALLENGES
AB Point cloud video (PCV) offers watching experiences in photorealistic 3D scenes with six-degree-of-freedom (6-DoF), enabling a variety of VR and AR applications. The user's Field of View (FoV) is more fickle with 6-DoF movement than 3-DoF movement in 360-degree video. PCV streaming is extremely bandwidth-intensive. However, current streaming systems require hundreds of Mbps bandwidth, exceeding the bandwidth capabilities of commodity devices. To save bandwidth, FoV-adaptive streaming predicts a user's FoV and only downloads point cloud data falling in the predicted FoV. But it is difficult to accurately predict the user's FoV even 2-3 seconds before playback due to 6-DoF. Misprediction of FoV or network bandwidth dips results in frequent stalls. To avoid rebuffering, existing systems would cause incomplete FoV and degraded experience, deteriorating the user's quality of experience (QoE). In this paper, we describe Fumos, a novel system that preserves interactive experience by avoiding playback stalls while maintaining high perceptual quality and high compression rate. We find a research gap in inter-frame redundant utilization and progressive mechaism. Fumos has three crucial designs, including (1) Neural compression framework with inter-frame coding, namely N-PCC, which achieves both bandwidth efficiency and high fidelity. (2) Progressive refinement streaming framework that enables continuous playback by incrementally upgrading a fetched portion to a higher quality (3) System-level adaptation that employs Lyapunov optimization to jointly optimize the long-term user QoE. Experimental results demonstrate that Fumos significantly outperforms Draco, achieving an average decoding rate acceleration of over 260x. Moreover, the proposed compression framework N-PCC attains remarkable BD-Rate gains, averaging 91.7% and 51.7% against the state-of-the-art point cloud compression methods G-PCC and V-PCC, respectively.
C1 [Liang, Zhicheng; Liu, Junhua; Wang, Fangxin] Chinese Univ Hong Kong, Future Network Intelligence Inst, Shenzhen, Peoples R China.
   [Liang, Zhicheng; Liu, Junhua; Wang, Fangxin] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen, Peoples R China.
   [Dasari, Mallesham] Carnegie Mellon Univ, Pittsburgh, PA USA.
   [Wang, Fangxin] Guangdong Prov Key Lab, Future Networks Intelligence, Shenzhen, Peoples R China.
C3 The Chinese University of Hong Kong, Shenzhen; The Chinese University of
   Hong Kong, Shenzhen; Carnegie Mellon University
RP Wang, FX (corresponding author), Chinese Univ Hong Kong, Future Network Intelligence Inst, Shenzhen, Peoples R China.; Wang, FX (corresponding author), Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen, Peoples R China.; Wang, FX (corresponding author), Guangdong Prov Key Lab, Future Networks Intelligence, Shenzhen, Peoples R China.
EM zhichengliang1@link.cuhk.edu.cn; junhualiu@cuhk.edu.cn;
   m.dasari@northeastern.edu; wangfangxin@cuhk.edu.cn
OI LIANG, Zhicheng/0009-0008-9015-8907
FU Basic Research
FX No Statement Available
CR [Anonymous], Draco 3d data compression
   [Anonymous], 2021, Geometry based point cloud compression (g-pcc) test model
   Ball‚ J, 2018, Arxiv, DOI arXiv:1802.01436
   Balle Johannes, 2017, 5 INT C LEARNING REP
   Cheng Yihua, 2022, arXiv
   Chopra L, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2379, DOI 10.1145/3442381.3450070
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   de Queiroz RL, 2018, IEEE SIGNAL PROC LET, V25, P739, DOI 10.1109/LSP.2018.2823701
   dEon Eugene, 2017, ISO/IEC JTC1/SC29 Joint WG11/WG1 (MPEG/JPEG) input document WG11M40059/WG1M74006, V7, P11
   Fu CY, 2022, AAAI CONF ARTIF INTE, P625
   Furht B., 2012, Motion estimation algorithms for video compression, V379
   Gao LY, 2021, IEEE IMAGE PROC, P3373, DOI 10.1109/ICIP42928.2021.9506631
   Garcia DC, 2020, IEEE T IMAGE PROCESS, V29, P313, DOI 10.1109/TIP.2019.2931466
   Garcia DC, 2017, IEEE IMAGE PROC, P1412, DOI 10.1109/ICIP.2017.8296514
   Ghabashneh E, 2023, PROCEEDINGS OF THE 2023 ACM SIGCOMM 2023 CONFERENCE, SIGCOMM 2023, P516, DOI 10.1145/3603269.3604876
   Graham B, 2015, Sparse 3d convolutional neural networks
   Graziosi D, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.12
   Guan Yongjie, 2023, P 29 ANN INT C MOBIL
   Guarda AFR, 2021, IEEE J-STSP, V15, P415, DOI 10.1109/JSTSP.2020.3047520
   Guo CJ, 2018, IEEE COMMUN LETT, V22, P2563, DOI 10.1109/LCOMM.2018.2873005
   Han B, 2020, MOBICOM '20: PROCEEDINGS OF THE 26TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2020), P137, DOI 10.1145/3372224.3380888
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosseini M, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P25, DOI 10.1145/3210424.3210429
   Huang LL, 2020, PROC CVPR IEEE, P1310, DOI 10.1109/CVPR42600.2020.00139
   Huang TX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P890, DOI 10.1145/3343031.3351061
   Jin YL, 2023, Arxiv, DOI arXiv:2309.05658
   Kingma Diederik, 2015, INT C LEARN REPR ICL
   Lai ZQ, 2020, IEEE T MOBILE COMPUT, V19, P1586, DOI 10.1109/TMC.2019.2913364
   Lee Kyungjin, 2020, P 26 ANN INT C MOB C, P1
   Li JW, 2022, IEEE T IND ELECTRON, V69, P13394, DOI 10.1109/TIE.2022.3144590
   Li J, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148922
   Liu JH, 2023, Symposium Virtual Re, P173, DOI [10.1109/VR55154.2023.00033, 10.1007/978-3-031-31733-0_16]
   Liu Y, 2022, PROCEEDINGS OF THE 2022 THE 28TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, ACM MOBICOM 2022, P514, DOI 10.1145/3495243.3517027
   Liu Z, 2021, IEEE NETWORK, V35, P202, DOI 10.1109/MNET.101.2000364
   MacMillan K, 2021, PROCEEDINGS OF THE 2021 ACM INTERNET MEASUREMENT CONFERENCE, IMC 2021, P229, DOI 10.1145/3487552.3487842
   Mei LF, 2020, COMPUT NETW, V182, DOI 10.1016/j.comnet.2020.107515
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Mekuria Rufael, 2016, P MM 16 P 24 ACM INT, P1222, DOI DOI 10.1145/2964284.2973806
   Pang Jiahao, 2022, APCCPA '22: Proceedings of the 1st International Workshop on Advances in Point Cloud Compression, Processing and Analysis, P11, DOI 10.1145/3552457.3555727
   Park J, 2019, IEEE J EM SEL TOP C, V9, P149, DOI 10.1109/JETCAS.2019.2898622
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Que ZZ, 2021, PROC CVPR IEEE, P6038, DOI 10.1109/CVPR46437.2021.00598
   Ren MY, 2018, PROC CVPR IEEE, P8711, DOI 10.1109/CVPR.2018.00908
   Schnabel Ruwen, 2006, PBG@ SIGGRAPH, V3
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Sheng XH, 2022, IEEE T IMAGE PROCESS, V31, P3399, DOI 10.1109/TIP.2022.3170722
   Sivaraman V, 2023, Arxiv, DOI arXiv:2209.10507
   Spiteri K, 2020, IEEE ACM T NETWORK, V28, P1698, DOI 10.1109/TNET.2020.2996964
   Subramanyam S, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3669, DOI 10.1145/3394171.3413535
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang Haotian, 2022, P MACHINE LEARNING S, V4, P302
   van der Hooft J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2405, DOI 10.1145/3343031.3350917
   Wang JQ, 2021, IEEE T CIRC SYST VID, V31, P4909, DOI 10.1109/TCSVT.2021.3051377
   Wang JQ, 2021, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC50243.2021.00015
   Xu Yi, 2017, P ISO IEC JTC1 SC29, V1, P8
   Xu Yiling, 2018, ZTE Communications, V16, P8
   Xu YQ, 2021, IEEE T CIRC SYST VID, V31, P1968, DOI 10.1109/TCSVT.2020.3015901
   Yili Jin, 2022, 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P600, DOI 10.1109/VRW55335.2022.00151
   Ying ZY, 2022, INT SYMP MICROARCH, P282, DOI 10.1109/MICRO56248.2022.00031
   Zhang A, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P137
   Zhang C, 2014, IEEE IMAGE PROC, P2066, DOI 10.1109/ICIP.2014.7025414
   Zink M, 2019, P IEEE, V107, P639, DOI 10.1109/JPROC.2019.2894817
NR 63
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2849
EP 2859
DI 10.1109/TVCG.2024.3372096
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400038
PM 38437108
DA 2024-08-05
ER

PT J
AU Zhou, YQ
   Popescu, V
AF Zhou, Yuqi
   Popescu, Voicu
TI CloVR: Fast-Startup Low-Latency Cloud VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Servers; Rendering (computer graphics); Visualization; Geometry; Low
   latency communication; Headphones; Cloud computing; Cloud VR; Near-Far
   Partitioning
AB VR headsets have limited rendering capability, which limits the size and detail of the virtual environment (VE) that can be used in VR applications. One solution is cloud VR, where the "thin" VR clients are assisted by a server. This paper describes Cio VR, a cloud VR system that provides fast loading times, as needed to let users see and interact with the VE quickly at session startup or after teleportation. The server reduces the original VE to a compact representation through near-far partitioning. The server renders the far region to an environment map which it sends to the client together with the near region geometry, from which the client renders quality frames locally, with low latency. The near region starts out small and grows progressively, with strict visual continuity, minimizing startup time. The low-latency and fast-startup advantages of CloVR have been validated in a user study where groups of 8 participants wearing all-in-one VR headsets (Quest 2's) were supported by a laptop server to run a collaborative VR application with a 25 million triangle VE.
C1 [Zhou, Yuqi; Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Zhou, YQ (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM zhou1168@purdue.edu; popescu@purdue.edu
FU National Science Foundation
FX No Statement Available
CR [Anonymous], Oculus headset
   [Anonymous], Unity 3d engine
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI [10.1145/360349.360353, 10.1145/965143.563322]
   Feng TT, 2020, IEEE T MULTIMEDIA, V22, P2963, DOI 10.1109/TMM.2019.2962313
   Fink L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P88, DOI [10.1109/VR.2019.8798283, 10.1109/vr.2019.8798283]
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Han B, 2020, MOBICOM '20: PROCEEDINGS OF THE 26TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2020), P137, DOI 10.1145/3372224.3380888
   He J, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P482, DOI 10.1145/3210240.3210323
   Hladky J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356530
   IBM Corp, 2022, IBM SPSS Statistics
   Kämäräinen T, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1181, DOI 10.1145/3240508.3240620
   Kelkkanen V, 2021, INT J COMPUT GAMES T, V2021, DOI 10.1155/2021/6676644
   Kim J, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406187
   Koch T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451266
   Lai ZQ, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P409, DOI 10.1145/3117811.3117815
   Lee J., 2020, InProc. ACM MobiCom, V2
   Liu TY, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P881, DOI 10.1109/MICRO50266.2020.00076
   Luebke B. Watson, 2002, Level ofDetail for 3D Graphics, V2
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Mehrabi A, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3429441
   Nadir Z, 2021, IEEE NETWORK, V35, P299, DOI 10.1109/MNET.121.2100172
   Park J, 2021, IEEE T VIS COMPUT GR, V27, P2746, DOI 10.1109/TVCG.2021.3067768
   Popescu V, 2022, INT SYM MIX AUGMENT, P35, DOI 10.1109/ISMAR55827.2022.00017
   Qian F, 2019, HOTMOBILE '19 - PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P135, DOI 10.1145/3301293.3302358
   Qian F, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P99, DOI 10.1145/3241539.3241565
   Schollmeyer A, 2017, IEEE T VIS COMPUT GR, V23, P1285, DOI 10.1109/TVCG.2017.2657078
   Schütz M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P103, DOI [10.1109/vr.2019.8798284, 10.1109/VR.2019.8798284]
   Stengel M, 2021, MMSYS '21: PROCEEDINGS OF THE 2021 MULTIMEDIA SYSTEMS CONFERENCE, P159, DOI 10.1145/3458305.3463379
   Stotko S., 2018, CoRR, abs/1805.03709
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilcoxon F., 1992, Individual comparisons by ranking methods, P5
   Zhang A, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P137
   Zhao SM, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533563
   Zhou P, 2021, IEEE T NETW SCI ENG, V8, P419, DOI 10.1109/TNSE.2020.3038998
   Zhou Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3452097
NR 35
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2337
EP 2346
DI 10.1109/TVCG.2024.3372059
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400006
PM 38437098
DA 2024-08-05
ER

PT J
AU Giovannangeli, L
   Lalanne, F
   Auber, D
   Giot, R
   Bourqui, R
AF Giovannangeli, Loann
   Lalanne, Frederic
   Auber, David
   Giot, Romain
   Bourqui, Romain
TI Toward Efficient Deep Learning for Graph Drawing (DL4GD)
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Graph drawing; Deep learning; Task analysis; Training;
   Measurement; Computational modeling; deep learning; graph neural
   network; graph convolution
ID LAYOUTS
AB Due to their great performance in many challenges, Deep Learning (DL) techniques keep gaining popularity in many fields. They have been adapted to process graph data structures to solve various complicated tasks such as graph classification and edge prediction. Eventually, they reached the Graph Drawing (GD) task. This article is an extended version of the previously published (DNN)(2) and presents a framework to leverage DL techniques for graph drawing (DL4GD). We demonstrate how it is possible to train a Deep Learning model to extract features from a graph and project them into a graph layout. The method proposes to leverage efficient Convolutional Neural Networks, adapting them to graphs using Graph Convolutions. The graph layout projection is learned by optimizing a cost function that does not require any ground truth layout, as opposed to prior work. This paper also proposes an implementation and benchmark of the framework to study its sensitivity to certain deep learning-related conditions. As the field is novel, and many questions remain to be answered, we do not focus on finding the most optimal implementation of the method, but rather contribute toward a better understanding of the approach potential. More precisely, we study different learning strategies relative to the models training datasets. Finally, we discuss the main advantages and limitations of DL4GD.
C1 [Giovannangeli, Loann; Lalanne, Frederic; Auber, David; Giot, Romain; Bourqui, Romain] Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
C3 Inria; Universite de Bordeaux; Centre National de la Recherche
   Scientifique (CNRS)
RP Bourqui, R (corresponding author), Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
EM Loann.Giovannangeli@u-bordeaux.fr; Frederic.Lalanne@u-bordeaux.fr;
   David.Auber@u-bordeaux.fr; Romain.Giot@u-bordeaux.fr;
   Romain.Bourqui@u-bordeaux.fr
RI Giot, Romain/F-6747-2011
OI Giot, Romain/0000-0002-0638-7504; Auber, David/0000-0002-1114-8612;
   Giovannangeli, Loann/0000-0002-9395-6495
FU Nouvelle-Aquitaine Region Project
FX No Statement Available
CR Abu-El-Haija S, 2020, PR MACH LEARN RES, V115, P841
   Ahmed R, 2020, Arxiv, DOI arXiv:2008.05584
   Auber D., 2018, Encyclopedia of Social Network Analysis and Mining, P3185
   Brandes U, 2003, LECT NOTES COMPUT SC, V2832, P568
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188467
   Defferrard M, 2017, Arxiv, DOI arXiv:1606.09375
   Dongen S., 2000, GRAPH CLUSTERING FLO
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Frick A., 1994, INT S GRAPH DRAW, P388, DOI DOI 10.1007/3-540-58950-3_393
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Giovannangeli L., 2021, P SPRING INT S GRAPH, P375
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Gutwenger C, 1998, LECT NOTES COMPUT SC, V1547, P167
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YF, 2012, IEEE PAC VIS SYMP, P33, DOI 10.1109/PacificVis.2012.6183571
   Jankun-Kelly TJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P59, DOI 10.1109/INFVIS.2003.1249009
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Kingma D. P., 2014, arXiv
   Klimenta M., 2012, P INT S GRAPH DRAW, P55
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Meidiana A, 2021, IEEE PAC VIS SYMP, P146, DOI 10.1109/PacificVis52677.2021.00027
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   NEMENYI P, 1962, BIOMETRICS, V18, P263
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Purchase HC, 1996, LECT NOTES COMPUT SC, V1027, P435, DOI 10.1007/BFb0021827
   Romero A., 2018, INT C LEARN REPR, P2920, DOI DOI 10.48550/ARXIV.1710.10903
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tiezzi M, 2024, IEEE T NEUR NET LEAR, V35, P4668, DOI 10.1109/TNNLS.2022.3184967
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang XQ, 2021, IEEE COMPUT GRAPH, V41, P32, DOI 10.1109/MCG.2021.3093908
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xie Y, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105578
   Xu K., 2019, INT C LEARNING REPRE, P1
   Leow YY, 2019, Arxiv, DOI arXiv:1904.06915
   You JX, 2019, PR MACH LEARN RES, V97
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 53
TC 2
Z9 2
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1516
EP 1532
DI 10.1109/TVCG.2022.3222186
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300008
PM 36378788
OA Green Published
DA 2024-08-05
ER

PT J
AU Gray, K
   Li, MW
   Ahmed, R
   Rahman, MK
   Azad, A
   Kobourov, S
   Borner, K
AF Gray, Kathryn
   Li, Mingwei
   Ahmed, Reyan
   Rahman, Md. Khaledur
   Azad, Ariful
   Kobourov, Stephen
   Borner, Katy
TI A Scalable Method for Readable Tree Layouts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Force-directed; readability; tree layouts
ID VISUALIZATION; GRAPHS
AB Large tree structures are ubiquitous and real-world relational datasets often have information associated with nodes (e.g., labels or other attributes) and edges (e.g., weights or distances) that need to be communicated to the viewers. Yet, scalable, easy to read tree layouts are difficult to achieve. We consider tree layouts to be readable if they meet some basic requirements: node labels should not overlap, edges should not cross, edge lengths should be preserved, and the output should be compact. There are many algorithms for drawing trees, although very few take node labels or edge lengths into account, and none optimizes all requirements above. With this in mind, we propose a new scalable method for readable tree layouts. The algorithm guarantees that the layout has no edge crossings and no label overlaps, and optimizes one of the remaining aspects: desired edge lengths and compactness. We evaluate the performance of the new algorithm by comparison with related earlier approaches using several real-world datasets, ranging from a few thousand nodes to hundreds of thousands of nodes. Tree layout algorithms can be used to visualize large general graphs, by extracting a hierarchy of progressively larger trees. We illustrate this functionality by presenting several map-like visualizations generated by the new tree layout algorithm.
C1 [Gray, Kathryn; Li, Mingwei; Ahmed, Reyan; Kobourov, Stephen] Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
   [Rahman, Md. Khaledur; Azad, Ariful] Indiana Univ, Dept Comp Sci, Bloomington, IN 47405 USA.
   [Borner, Katy] Indiana Univ, SLIS, Bloomington, IN 47408 USA.
C3 University of Arizona; Indiana University System; Indiana University
   Bloomington; Indiana University System; Indiana University Bloomington
RP Ahmed, R (corresponding author), Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
EM ryngray@email.arizona.edu; mwli@email.arizona.edu;
   abureyanahmed@email.arizona.edu; morahma@iu.edu; azad@iu.edu;
   kobourov@cs.arizona.edu; katy@indiana.edu
RI Kobourov, Stephen/A-3016-2008
OI Kobourov, Stephen/0000-0002-0477-2724; Ahmed, Reyan/0000-0001-6830-9053;
   Borner, Katy/0000-0002-3321-6137
FU NSF
FX No Statement Available
CR Ahmed R., 2019, ACM J. Exp. Algorithmics, V24
   [Anonymous], 2020, OpenLayers
   Arleo A, 2019, IEEE T PARALL DISTR, V30, P754, DOI 10.1109/TPDS.2018.2869805
   Bachmaier C, 2005, LECT NOTES COMPUT SC, V3827, P1110, DOI 10.1007/11602613_110
   Ballen CJ, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001630
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361, DOI DOI 10.1609/ICWSM.V3I1.13937
   BAVELAS A, 1950, J ACOUST SOC AM, V22, P723
   Blanch R, 2015, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2015.7156353
   Bonacich P, 2007, SOC NETWORKS, V29, P555, DOI 10.1016/j.socnet.2007.04.002
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boyack KW, 2005, SCIENTOMETRICS, V64, P351, DOI 10.1007/s11192-005-0255-6
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Burd K., 2018, P C ADV VIS INT, p31:1
   Chandra L., 2001, Parallel Programming in OpenMP
   Chimani Markus., 2011, Handbook of Graph Drawing and Visualization, P543
   Choi JH, 2000, BIOINFORMATICS, V16, P1056, DOI 10.1093/bioinformatics/16.11.1056
   EADES P, 1990, DISCRETE APPL MATH, V28, P111, DOI 10.1016/0166-218X(90)90110-X
   Eades Peter, 1984, Congressus Numerantium, V42, P149
   Efrat A, 2010, ACM T SENSOR NETWORK, V7, DOI 10.1145/1807048.1807057
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gajer P., 2004, Computational Geometry: Theory and Applications, V29, P3
   Gansner E., 2009, Proceedings of the ACM Conference on Recommender Systems, P345, DOI DOI 10.1145/1639714.1639784
   Gansner ER, 2010, IEEE PAC VIS SYMP, P201, DOI 10.1109/PACIFICVIS.2010.5429590
   Gansner ER, 2009, LECT NOTES COMPUT SC, V5417, P206, DOI 10.1007/978-3-642-00219-9_20
   Gansner ER, 1998, LECT NOTES COMPUT SC, V1547, P364
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Hadany R, 2001, DISCRETE APPL MATH, V113, P3, DOI 10.1016/S0166-218X(00)00389-9
   Nguyen QH, 2018, Arxiv, DOI arXiv:1801.07008
   Hu Y., 2005, Mathematica journal, V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Hug LA, 2016, NAT MICROBIOL, V1, DOI [10.1038/NMICROBIOL.2016.48, 10.1038/nmicrobiol.2016.48]
   Kittivorawong C, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P101, DOI 10.1109/VIS47514.2020.00027
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Kobourov S., 2014, EuroVis-Short Papers, P31
   Koren Y, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P137, DOI 10.1109/INFVIS.2002.1173159
   Leow T., 2019, P WORKSH REPRESENTAT, P1
   Letunic I, 2021, NUCLEIC ACIDS RES, V49, pW293, DOI 10.1093/nar/gkab301
   Luboschik M, 2008, IEEE T VIS COMPUT GR, V14, P1237, DOI 10.1109/TVCG.2008.152
   Marriott K, 2003, CONSTRAINTS, V8, P143, DOI 10.1023/A:1022371615202
   McGuffin MJ, 2010, INFORM VISUAL, V9, P115, DOI 10.1057/ivs.2009.4
   Mote K, 2007, INFORM VISUALIZATION, V6, P249, DOI [10.1057/palgrave.ivs.9500163, DOI 10.1057/PALGRAVE.IVS.9500163]
   Nachmanson L, 2016, LECT NOTES COMPUT SC, V9801, P33, DOI 10.1007/978-3-319-50106-2_3
   Nguyen QV, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P85, DOI 10.1109/INFVIS.2002.1173152
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Purchase H. C., 2002, Empirical Software Engineering, V7, P233, DOI 10.1023/A:1016344215610
   Rahman MK, 2020, IEEE DATA MINING, P442, DOI 10.1109/ICDM50108.2020.00053
   Rahman MK, 2020, IEEE PAC VIS SYMP, P16, DOI 10.1109/PacificVis48177.2020.3756
   REINGOLD EM, 1981, IEEE T SOFTWARE ENG, V7, P223, DOI 10.1109/TSE.1981.234519
   Schulz H. -J., 2015, P 17 EUR C VIS, P1
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Sun D, 2005, PROG COMPREHEN, P317
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wiese R, 2004, MATH VIS, P173
   Zager LA, 2008, APPL MATH LETT, V21, P86, DOI 10.1016/j.aml.2007.01.006
NR 55
TC 2
Z9 3
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1564
EP 1578
DI 10.1109/TVCG.2023.3274572
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300011
PM 37159326
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Cao, AQ
   Xie, X
   Zhou, MX
   Zhang, H
   Xu, ML
   Wu, YC
AF Cao, Anqi
   Xie, Xiao
   Zhou, Mingxu
   Zhang, Hui
   Xu, Mingliang
   Wu, Yingcai
TI Action-Evaluator: A Visualization Approach for Player Action Evaluation
   in Soccer
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Soccer Visualization; Player Evaluation; Design Study
ID VISUAL ANALYSIS; ANALYTICS
AB In soccer, player action evaluation provides a fine-grained method to analyze player performance and plays an important role in improving winning chances in future matches. However, previous studies on action evaluation only provide a score for each action, and hardly support inspecting and comparing player actions integrated with complex match context information such as team tactics and player locations. In this work, we collaborate with soccer analysts and coaches to characterize the domain problems of evaluating player performance based on action scores. We design a tailored visualization of soccer player actions that places the action choice together with the tactic it belongs to as well as the player locations in the same view. Based on the design, we introduce a visual analytics system, Action-Evaluator, to facilitate a comprehensive player action evaluation through player navigation, action investigation, and action explanation. With the system, analysts can find players to be analyzed efficiently, learn how they performed under various match situations, and obtain valuable insights to improve their action choices. The usefulness and effectiveness of this work are demonstrated by two case studies on a real-world dataset and an expert interview.
C1 [Cao, Anqi; Zhou, Mingxu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Zhejiang, Peoples R China.
   [Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Engn Res Ctr Intelligent Swarm Syst, Minist Educ, Sch Comp & Artificial Intelligence, Zhengzhou, Peoples R China.
   [Xu, Mingliang] Natl Supercomp Ctr, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhengzhou University
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
EM caoanqi@zju.edu.cn; xxie@zju.edu.cn; zhoumingxu@zju.edu.cn;
   zhang_hui@zju.edu.cn; iexumingliang@zzu.edu.cn; ycwu@zju.edu.cn
OI , Hui/0000-0003-0601-3905; Zhou, Mingxu/0009-0002-8479-2844
FU National Key R&D Program of China
FX No Statement Available
CR Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   Beal R, 2019, KNOWL ENG REV, V34, DOI 10.1017/S0269888919000225
   Bransen Lotte, 2019, Machine Learning and Data Mining for Sports Analytics. 5th International Workshop, MLSA 2018 Co-located with ECML/PKDD 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11330), P3, DOI 10.1007/978-3-030-17274-9_1
   Bransen L., 2019, 2019 SLOAN SPORTS AN, P2
   Bransen L, 2019, J QUANT ANAL SPORTS, V15, P97, DOI 10.1515/jqas-2018-0020
   Brooks J, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P49, DOI 10.1145/2939672.2939695
   Cao A., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32071471, DOI 10.1109/TVCG.2022.32071471]
   Cervone D., 2014, P SPORTS ANALYTICS C, P2
   Decroos T., 2017, P ECML PKDD WORKSH M, VVolume 1971, P11
   Decroos T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1851, DOI 10.1145/3292500.3330758
   Decroos T, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P223, DOI 10.1145/3219819.3219832
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Fernandez J., 2019, 2019 SLOAN SPORTS AN, P2
   Fernández J, 2021, MACH LEARN, V110, P1389, DOI 10.1007/s10994-021-05989-6
   Fernandez-Navarro J, 2016, J SPORT SCI, V34, P2195, DOI 10.1080/02640414.2016.1169309
   Franks A., 2015, SLOAN SPORTS ANALYTI, P2
   Goldsberry K., 2012, P SLOAN SPORTS ANALY, P2
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gray J, 1996, PROC INT CONF DATA, P152, DOI 10.1109/ICDE.1996.492099
   Gudmundsson Joachim, 2017, ACM Computing Surveys, V50, DOI 10.1145/3054132
   Ishikawa Y, 2018, VIS INFORM, V2, P60, DOI 10.1016/j.visint2018.04.007
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Lage M, 2016, IEEE COMPUT GRAPH, V36, P28, DOI 10.1109/MCG.2016.101
   Lan J, 2022, J VISUAL-JAPAN, V25, P143, DOI 10.1007/s12650-021-00772-0
   Le H. M., 2017, 2017 SLOAN SPORTS AN
   Liu G., 2020, P 34 C NEURAL INFORM, P18704
   Liu GL, 2020, DATA MIN KNOWL DISC, V34, P1531, DOI 10.1007/s10618-020-00705-9
   Liu HY, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.10.002
   Losada AG, 2016, IEEE COMPUT GRAPH, V36, P58, DOI 10.1109/MCG.2016.124
   McHale IG, 2012, INTERFACES, V42, P339, DOI 10.1287/inte.1110.0589
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Moon B., 2013, WORKSHOP SPORTS DATA, P2
   Ono JP, 2018, COMPUT GRAPH FORUM, V37, P491, DOI 10.1111/cgf.13436
   Pappalardo L, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3343172
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Perin C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P887, DOI 10.1145/2556288.2557379
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Pileggi H, 2012, IEEE T VIS COMPUT GR, V18, P2819, DOI 10.1109/TVCG.2012.263
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Power P, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1605, DOI 10.1145/3097983.3098051
   Rusu A, 2011, IEEE INT CONF INF VI, P194, DOI 10.1109/IV.2011.57
   Rusu A, 2010, IEEE INT CONF INF VI, P207, DOI 10.1109/IV.2010.39
   Ryoo M, 2018, MULTIMED TOOLS APPL, V77, P15603, DOI 10.1007/s11042-017-5137-4
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Schulte O., 2017, 2017 SLOAN SPORTS AN, P9
   Seebacher D, 2023, IEEE T VIS COMPUT GR, V29, P1920, DOI 10.1109/TVCG.2021.3134814
   Shao L., 2016, Electronic Imaging, P1
   StatsBomb, StatsBomb Open Data
   Stein M, 2019, J SPORT SCI, V37, P2774, DOI 10.1080/02640414.2019.1652541
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang HX, 2021, VIS INFORM, V5, P82, DOI 10.1016/j.visinf.2021.09.001
   Wang Jiachen, 2023, IEEE Trans Vis Comput Graph, V29, P951, DOI 10.1109/TVCG.2022.3209352
   Wang WT, 2016, J VISUAL-JAPAN, V19, P515, DOI 10.1007/s12650-015-0337-3
   WhoScored, 2022, WhoScored.com: Football Statistics | Football Live Scores
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu Yihong, 2023, IEEE Trans Vis Comput Graph, V29, P929, DOI 10.1109/TVCG.2022.3209373
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
NR 65
TC 0
Z9 0
U1 5
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 880
EP 890
DI 10.1109/TVCG.2023.3326524
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500078
PM 37878455
DA 2024-08-05
ER

PT J
AU de Souza, CVF
   Bonnet, SM
   de Oliveira, D
   Cataldi, M
   Miranda, F
   Lage, M
AF de Souza, Carolina Veiga Ferreira
   Bonnet, Suzanna Maria
   de Oliveira, Daniel
   Cataldi, Marcio
   Miranda, Fabio
   Lage, Marcos
TI PROWIS: A Visual Approach for Building, Managing, and Analyzing Weather
   Simulation Ensembles at Runtime
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Meteorology; Data visualization; Weather forecasting; Visualization;
   Atmospheric modeling; Runtime; Predictive models; Weather visualization;
   Ensemble visualization; Provenance management; WRF visual setup
ID VISUALIZATION; FLOW; TOOL
AB Weather forecasting is essential for decision-making and is usually performed using numerical modeling. Numerical weather models, in turn, are complex tools that require specialized training and laborious setup and are challenging even for weather experts. Moreover, weather simulations are data-intensive computations and may take hours to days to complete. When the simulation is finished, the experts face challenges analyzing its outputs, a large mass of spatiotemporal and multivariate data. From the simulation setup to the analysis of results, working with weather simulations involves several manual and error-prone steps. The complexity of the problem increases exponentially when the experts must deal with ensembles of simulations, a frequent task in their daily duties. To tackle these challenges, we propose ProWis: an interactive and provenance-oriented system to help weather experts build, manage, and analyze simulation ensembles at runtime. Our system follows a human-in-the-loop approach to enable the exploration of multiple atmospheric variables and weather scenarios. ProWis was built in close collaboration with weather experts, and we demonstrate its effectiveness by presenting two case studies of rainfall events in Brazil.
C1 [de Souza, Carolina Veiga Ferreira; de Oliveira, Daniel; Cataldi, Marcio; Lage, Marcos] Univ Fed Fluminense, Niteroi, Brazil.
   [de Souza, Carolina Veiga Ferreira] Univ Illinois, Champaign, IL USA.
   [Bonnet, Suzanna Maria] Univ Fed Rio De Janeiro, Rio De Janeiro, Brazil.
   [Miranda, Fabio] Univ Illinois, Chicago, IL USA.
C3 Universidade Federal Fluminense; University of Illinois System;
   University of Illinois Urbana-Champaign; Universidade Federal do Rio de
   Janeiro; University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
RP de Souza, CVF (corresponding author), Univ Fed Fluminense, Niteroi, Brazil.
EM carolinavfs@id.uff.br; suzanna@lma.ufrj.br; marcio.cataldi@gmail.com;
   fabiom@uic.edu; mlage@ic.uff.br
RI Lage, Marcos/K-4098-2012
OI Lage, Marcos/0000-0003-3868-8886; Miranda, Fabio/0000-0001-8612-5805
FU CNPq
FX No Statement Available
CR Behrens HW, 2018, PROC VLDB ENDOW, V11, P1906, DOI 10.14778/3229863.3236221
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Callahan S.P., 2006, P ACM SIGMOD 2006, P745, DOI [10.1145/1142473.1142574, DOI 10.1145/1142473.1142574]
   Center for Ocean-Land-Atmosphere Studies, 2021, Grid analysis and display system (GrADS)
   Coen JL, 2013, J APPL METEOROL CLIM, V52, P16, DOI 10.1175/JAMC-D-12-023.1
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Davies T, 2014, Q J ROY METEOR SOC, V140, P185, DOI 10.1002/qj.2127
   de Oliveira D. C., 2019, Synthesis Lectures on Data Management, V14, P1, DOI DOI 10.2200/S00915ED1V01Y201904DTM0601
   de Souza CVF, 2022, COMPUT GRAPH-UK, V104, P162, DOI 10.1016/j.cag.2022.01.007
   Diehl A, 2015, COMPUT GRAPH FORUM, V34, P381, DOI 10.1111/cgf.12650
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Grell GA, 2005, ATMOS ENVIRON, V39, P6957, DOI 10.1016/j.atmosenv.2005.04.027
   Koop D., 2018, Encyclopedia of Database Systems, P2
   Li SM, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10090488
   McCreight James, 2021, Zenodo, DOI 10.5281/ZENODO.4479912
   Mizutori M., 2020, The human cost of disasters: An overview of the last 20 years (2000-2019)
   National Oceanic and Atmospheric Administration, 2013, WRF Domain Wizard
   Nikfal A, 2023, ENVIRON MODELL SOFTW, V160, DOI 10.1016/j.envsoft.2022.105591
   NOAA Pacific Marine Environmental Laboratory, 2012, Ferret
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Rautenhaus M, 2015, GEOSCI MODEL DEV, V8, P2329, DOI 10.5194/gmd-8-2329-2015
   Rautenhaus M, 2018, IEEE T VIS COMPUT GR, V24, P3268, DOI 10.1109/TVCG.2017.2779501
   Santos E, 2013, COMPUT SCI ENG, V15, P94, DOI 10.1109/MCSE.2013.15
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   School of Ocean and Earth Science and Technology of the University of Hawaii, 2019, The Generic Mapping Tools (GMT)
   Skamarock W. C., 2005, Technical report, P3
   Stitz H, 2019, IEEE T VIS COMPUT GR, V25, P120, DOI 10.1109/TVCG.2018.2865024
   University Corporation for Atmospheric, 2019, The NCAR command language
   University Corporation for Atmospheric Research, 2019, Definition of network common data form (NetCDF)
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Warner TT., 2010, NUMERICAL WEATHER CL, P1
   Waser J, 2011, IEEE T VIS COMPUT GR, V17, P1872, DOI 10.1109/TVCG.2011.225
   Watanabe K, 2022, SYMP LARG DATA ANAL, P5, DOI 10.1109/LDAV57265.2022.9966393
   Weather Meteorological Organization, 1999, Guide to public weather services practices, P1
   Williams DN, 2013, COMPUTER, V46, P68, DOI 10.1109/MC.2013.119
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
NR 36
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 738
EP 747
DI 10.1109/TVCG.2023.3326514
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500043
PM 37871065
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Li, HRY
   Appleby, G
   Brumar, CD
   Chang, RM
   Suh, A
AF Li, Harry
   Appleby, Gabriel
   Brumar, Camelia Daniela
   Chang, Remco
   Suh, Ashley
TI Knowledge Graphs in Practice: Characterizing their Users, Challenges,
   and Visualization Opportunities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Knowledge graphs; Data visualization; Interviews; Task analysis; Data
   models; Standards organizations; Semantics; visualization techniques and
   methodologies; human factors; visual communication
ID VISUAL ANALYSIS; PERFORMANCE
AB This study presents insights from interviews with nineteen Knowledge Graph (KG) practitioners who work in both enterprise and academic settings on a wide variety of use cases. Through this study, we identify critical challenges experienced by KG practitioners when creating, exploring, and analyzing KGs that could be alleviated through visualization design. Our findings reveal three major personas among KG practitioners - KG Builders, Analysts, and Consumers - each of whom have their own distinct expertise and needs. We discover that KG Builders would benefit from schema enforcers, while KG Analysts need customizable query builders that provide interim query results. For KG Consumers, we identify a lack of efficacy for node-link diagrams, and the need for tailored domain-specific visualizations to promote KG adoption and comprehension. Lastly, we find that implementing KGs effectively in practice requires both technical and social solutions that are not addressed with current tools, technologies, and collaborative workflows. From the analysis of our interviews, we distill several visualization research directions to improve KG usability, including knowledge cards that balance digestibility and discoverability, timeline views to track temporal changes, interfaces that support organic discovery, and semantic explanations for AI and machine learning predictions.
C1 [Li, Harry; Suh, Ashley] MIT Lincoln Lab, Lincoln, NE 02420 USA.
   [Li, Harry; Appleby, Gabriel; Brumar, Camelia Daniela; Chang, Remco; Suh, Ashley] Tufts Univ, Somerville, MA 02155 USA.
C3 Lincoln Laboratory; Tufts University
RP Li, HRY (corresponding author), MIT Lincoln Lab, Lincoln, NE 02420 USA.; Li, HRY (corresponding author), Tufts Univ, Somerville, MA 02155 USA.
EM harry.li@ll.mit.edu; gabriel.appleby@tufts.edu;
   camelia_daniela.brumar@tufts.edu; remco.chang@tufts.edu;
   ashley.suh@ll.mit.edu
OI Li, Harry/0000-0002-2288-6039; Chang, Remco/0000-0002-6484-6430; Suh,
   Ashley/0000-0001-6513-8447
FU National Science Foundation
FX No Statement Available
CR Abu-Salih B, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103076
   Ahmad S, 2021, 2021 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC 2021), P25, DOI 10.1109/VAHC53616.2021.00009
   AlKhamissi B., 2022, arXiv
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Angelini M, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5030031
   Angles R., 2023, Proc. ACM Manag. Data, V1, DOI [10.1145/3589778 9, DOI 10.1145/35897789]
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Aurisano J., 2016, P VIS, V8
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361, DOI DOI 10.1609/ICWSM.V3I1.13937
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bonatti Piero Andrea, 2019, Dagstuhl Reports, V8, DOI [DOI 10.4230/DAGREP.8.9.29, 10.4230/DagRep.8.9.292, DOI 10.4230/DAGREP.8.9.292]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI 10.1191/1478088706qp063oa
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Cashman D, 2021, IEEE T VIS COMPUT GR, V27, P1731, DOI 10.1109/TVCG.2020.3030443
   Chan B, 2008, IEEE T VIS COMPUT GR, V14, P1213, DOI 10.1109/TVCG.2008.178
   Chen XJ, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112948
   DeCuir-Gunby JT, 2011, FIELD METHOD, V23, P136, DOI 10.1177/1525822X10388468
   Ehrlinger L., 2016, SEMANTiCS (Posters, Demos, SuCCESS), V48, P2
   Ell Basil, 2014, The Semantic Web: Trends and Challenges. 11th International Conference (ESWC 2014). Proceedings: LNCS 8465, P426, DOI 10.1007/978-3-319-07443-6_29
   Ferré S, 2017, SEMANT WEB, V8, P405, DOI 10.3233/SW-150208
   Francis N, 2018, INT CONF MANAGE DATA, P1433, DOI 10.1145/3183713.3190657
   Gal A, 2014, PROC VLDB ENDOW, V7, P1711, DOI 10.14778/2733004.2733068
   Gan YJ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2030
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Gómez-Romero J, 2018, FUTURE GENER COMP SY, V89, P224, DOI 10.1016/j.future.2018.06.015
   Gottschalk S, 2018, LECT NOTES COMPUT SC, V10843, P272, DOI 10.1007/978-3-319-93417-4_18
   Grafkin P., 2016, BIR WORKSH, P255
   Guo QY, 2022, IEEE T KNOWL DATA EN, V34, P3549, DOI 10.1109/TKDE.2020.3028705
   Hagberg A., 2008, Technical report, P4
   Helmers S. A., 2015, Microsoft Visio 2016 Step By Step: MS Visio 2016 Ste by Ste_p1, P9
   Hemberg Erik, 2021, arXiv
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Hogan A, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447772
   Hong S. R., 2020, Proc. CHI, V4, DOI DOI 10.1145/33928782
   Huang Jieying, 2023, IEEE Trans Vis Comput Graph, V29, P1200, DOI 10.1109/TVCG.2022.3209453
   Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956
   Husain F, 2021, 2021 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC 2021), P30, DOI 10.1109/VAHC53616.2021.00010
   Jing Han, 2011, Proceedings 2011 6th International Conference on Pervasive Computing and Applications (ICPCA 2011), P363, DOI 10.1109/ICPCA.2011.6106531
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kivela M., 2019, Dagstuhl Reports, V9, P1, DOI DOI 10.4230/DAGREP.9.2.12
   Klein K., 2022, Dagstuhl Rep, V12, P67, DOI [10.4230/DagRep.12.1.672,7, DOI 10.4230/DAGREP.12.1.672,7]
   Latif S, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P156, DOI 10.1109/VIS49827.2021.9623313
   Lecue F, 2020, SEMANT WEB, V11, P41, DOI 10.3233/SW-190374
   Lee B., 2006, P BELIV, P1, DOI [10.1145/1168149.11681686,9, DOI 10.1145/1168149.11681686,9]
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lissandrini M., 2022, CIDR, V22, P10
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   MacQueen KM., 1998, Cultural Anthropology Methods, V10, P31, DOI [DOI 10.1177/1525822X980100020301, 10.1177/1525822X980100020301]
   Miller J. J., 2013, Proc. SAIS, V2324, P2
   Mitra R, 2022, IEEE VIS CONF, P6, DOI 10.1109/VIS54862.2022.00010
   Mosca A., 2019, EuroVis 2019-Short Papers, DOI DOI 10.2312/EVS.20191173
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Neo4J, Neo4j Bloom
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P544, DOI 10.1109/TVCG.2018.2865149
   Partl C, 2016, COMPUT GRAPH FORUM, V35, P71, DOI 10.1111/cgf.12883
   Passi Samir, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274405
   Paulheim H, 2017, SEMANT WEB, V8, P489, DOI 10.3233/SW-160218
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Rossi A, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3424672
   Rudin C., 2019, Harvard Data Science Review, V1, DOI 10.1162/99608f92.5a8a3a3d
   Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   SHNEIDERMAN B, 1984, COMPUT SURV, V16, P265, DOI 10.1145/2514.2517
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]
   stardog, Stardog, an enterprise Knowledge Graph platform
   Storey Margaret-Anne D., 2005, P 2005 ACM S SOFTWAR, P193, DOI DOI 10.1145/1056018.1056045
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Suresh H, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445088
   Tiddi I, 2020, STUD SEMANTIC WEB, V47, P1, DOI 10.3233/SSW47
   Toussaint E, 2022, PROC VLDB ENDOW, V15, P2613, DOI 10.14778/3551793.3551818
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Waagmeester A, 2020, ELIFE, V9, DOI 10.7554/eLife.52614
   Wikipedia, Wikidata Statistics
   Wongsuphasawat K, 2019, Arxiv, DOI arXiv:1911.00568
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Xiao GH, 2019, DATA INTELLIGENCE, V1, P201, DOI 10.1162/dint_a_00011
   Yoon Y, 2013, S VIS LANG HUM CEN C, P119, DOI 10.1109/VLHCC.2013.6645254
NR 81
TC 1
Z9 1
U1 5
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 584
EP 594
DI 10.1109/TVCG.2023.3326904
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DT8M9
UT WOS:001134418500001
PM 38096099
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lin, YN
   Li, HT
   Yang, LN
   Wu, AY
   Qu, HM
AF Lin, Yanna
   Li, Haotian
   Yang, Leni
   Wu, Aoyu
   Qu, Huamin
TI InkSight: Leveraging Sketch Interaction for Documenting Chart Findings
   in Computational Notebooks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Documentation; Data analysis; Visualization; Codes;
   Natural languages; Data models; Computational Notebook; Sketch-based
   Interaction; Exploratory Data Analysis
AB Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users' specific interests. In response to these limitations, we present InkSight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user's intent. InkSight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch. Upon receiving a user's sketch, InkSight identifies the sketch type and corresponding selected data items. Subsequently, it filters data fact types based on the sketch and selected data items before employing existing automatic data fact recommendation algorithms to infer data facts. Using large language models (GPT-3.5), InkSight converts data facts into effective natural language documentation. Users can conveniently fine-tune the generated documentation within InkSight. A user study with 12 participants demonstrated the usability and effectiveness of InkSight in expressing user intent and facilitating chart finding documentation.
C1 [Lin, Yanna; Li, Haotian; Yang, Leni; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wu, Aoyu] Harvard Univ, Cambridge, MA USA.
C3 Hong Kong University of Science & Technology; Harvard University
RP Yang, LN (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM ylindg@connect.ust.hk; haotian.li@connect.ust.hk;
   lyangbb@connect.ust.hk; aoyuwu@seas.harvard.edu; huamin@cse.ust.hk
OI Yang, Leni/0000-0003-4527-4905; Lin, Yanna/0000-0003-3730-0827
FU HK RGC GRF
FX No Statement Available
CR Akers D., 2006, Proceedings of the ACM Symposium on User Interface Software and Technology, P33, DOI DOI 10.1145/1166253.1166260
   Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   Browne J., 2011, P ACM INT C INT TABL, P154, DOI [DOI 10.1145/2076354.20763832,9, 10.1145/2076354.2076383, DOI 10.1145/2076354.2076383]
   Chao W. O., 2010, P 2010 IEEE INF C PO
   Chattopadhyay S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376729
   Chen X, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174070
   Chen YR, 2022, INT CONF MANAGE DATA, P1711, DOI 10.1145/3514221.3526166
   Chen Z., 2022, P 2022 CHI C HUM FAC, DOI DOI 10.1145/3491102.35174853
   Choi J, 2022, IEEE VIS CONF, P40, DOI 10.1109/VIS54862.2022.00017
   Chung J. J. Y., 2022, P 2022 CHI C HUM FAC, P1, DOI [10.1145/3491102.35018192,9, DOI 10.1145/3491102.35018192,9]
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   EPPerson W, 2022, COMPUT GRAPH FORUM, V41, P145, DOI 10.1111/cgf.14529
   Holz C, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P213
   jupyter, Project Jupyter Home
   Kantharaj S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4005
   Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Li H., 2023, P 2023 CHI C HUM FAC, DOI DOI 10.1145/3544548.35809651,2,3,8,9
   Li HT, 2023, Arxiv, DOI arXiv:2304.08366
   Lin YN, 2024, IEEE T VIS COMPUT GR, V30, P4108, DOI 10.1109/TVCG.2023.3251344
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Mishra P, 2022, J COMPUT LANG, V69, DOI 10.1016/j.cola.2022.101107
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Obeid J., 2020, P 13 INT C NAT LANG, P2
   online.stat, Interquartile Range (IQR) method.
   OpenAI, 2023, Gpt-4 technical report
   Pandey Aditeya, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209421
   platform.openai, GPT-3.5
   Posit, about us
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Ryall K., 2005, P 2005 CHI C HUM FAC, P1765, DOI [10.1145/1056808.10570172, DOI 10.1145/1056808.10570172]
   Shen L., 2021, P 23 EUR C VIS SHORT, DOI [DOI 10.2312/EVS.20211061, 10.2312/evs.20211061]
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Siddiqui T, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P51, DOI 10.1145/3318464.3389722
   Song S., 2023, P 2023 CHI C HUM FAC, P2
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sutherland I. E., 1963, Sketchpad, a Man-Machine Graphical Communication System, P2
   Tohidi M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1243
   Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275
   Wang AY, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3489465
   Wang FJ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580753
   Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wattenberg Martin, 2001, PROC SIGCHI EA, P381, DOI DOI 10.1145/634067.6342922
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Yifan Wu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P152, DOI 10.1145/3379337.3415851
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yu CH, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.628832
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zheng CB, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517615
NR 58
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 944
EP 954
DI 10.1109/TVCG.2023.3327170
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500133
PM 37878446
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Guo, JP
   Zhang, WX
   Ye, CY
   Fu, XM
AF Guo, Jia-Peng
   Zhang, Wen-Xiang
   Ye, Chunyang
   Fu, Xiao-Ming
TI Robust Coarse Cage Construction With Small Approximation Errors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Complexity theory; Robustness; Manifolds; Approximation error;
   Approximation algorithms; Filtering; Geometry; cage construction;
   conformal tetrahedral meshing; mesh complexity; tetrahedral subdivision
ID LOCAL REFINEMENT; SUBDIVISION
AB We propose a robust and automatic method to construct manifold cages for 3D triangular meshes. The cage contains hundreds of triangles to tightly enclose the input mesh without self-intersections. To generate such cages, our algorithm consists of two phases: (1) construct manifold cages satisfying the tightness, enclosing, and intersection-free requirements and (2) reduce mesh complexities and approximation errors without violating the enclosing and intersection-free requirements. To theoretically make the first stage have those properties, we combine the conformal tetrahedral meshing and tetrahedral mesh subdivision. The second step is a constrained remeshing process using explicit checks to ensure that the enclosing and intersection-free constraints are always satisfied. Both phases use a hybrid coordinate representation, i.e., rational numbers and floating point numbers, combined with exact arithmetic and floating point filtering techniques to guarantee the robustness of geometric predicates with a favorable speed. We extensively test our method on a data set of over 8500 models, demonstrating robustness and performance. Compared to other state-of-the-art methods, our method possesses much stronger robustness.
C1 [Guo, Jia-Peng] Univ Sci & Technol China, Sch Data Sci, Hefei 230026, Anhui, Peoples R China.
   [Zhang, Wen-Xiang; Ye, Chunyang; Fu, Xiao-Ming] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Fu, XM (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.
EM gjp171499@mail.ustc.edu.cn; zwx111@mail.ustc.edu.cn;
   yechyang@mail.ustc.edu.cn; fuxm@ustc.edu.cn
OI Fu, Xiao-Ming/0000-0001-8479-0107
FU National Natural Science Foundation of China [62272429]; Major Project
   of Science and Technology of Anhui Province [202203a05020050]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62272429 and in part by the Major
   Project of Science and Technology of Anhui Province under Grant
   202203a05020050.
CR Attene M, 2020, COMPUT AIDED DESIGN, V126, DOI 10.1016/j.cad.2020.102856
   Attene M, 2009, COMPUT AIDED GEOM D, V26, P850, DOI 10.1016/j.cagd.2009.06.002
   Ben-Chen Mirela., 2009, P 2009 ACM SIGGRAPH, P67, DOI [10.1145/1599470.1599479, DOI 10.1145/1599470.1599479]
   Bey J, 1995, COMPUTING, V55, P355, DOI 10.1007/BF02238487
   Botsch M., 2004, P 2004 EUROGRAPHICSA, P185, DOI [10.1145/1057432.1057457, DOI 10.1145/1057432.1057457]
   Brönnimann H, 2001, DISCRETE APPL MATH, V109, P25, DOI 10.1016/S0166-218X(00)00231-6
   Bronnimann Herve, 2022, CGAL User and Reference Manual, V5.5
   Burkhart D, 2010, COMPUT GRAPH FORUM, V29, P117, DOI 10.1111/j.1467-8659.2009.01581.x
   Calderon S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073714
   Casti S, 2019, COMPUT GRAPH-UK, V81, P140, DOI 10.1016/j.cag.2019.04.004
   Chen X, 2014, COMPUT ANIMAT VIRT W, V25, P447, DOI 10.1002/cav.1577
   Cheng XX, 2019, COMPUT GRAPH-UK, V82, P163, DOI 10.1016/j.cag.2019.05.019
   Cherchi G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417818
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Deng ZJ, 2011, J COMPUT SCI TECH-CH, V26, P538, DOI 10.1007/s11390-011-1153-4
   Diazzi L, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480564
   Doi A, 1997, FIFTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P206, DOI 10.1109/PCCGA.1997.626208
   Escobar JM, 2005, COMPUT STRUCT, V83, P2423, DOI 10.1016/j.compstruc.2005.03.022
   Faraj N, 2012, COMPUT GRAPH-UK, V36, P562, DOI 10.1016/j.cag.2012.03.020
   Forest C, 2005, MED IMAGE ANAL, V9, P113, DOI 10.1016/j.media.2004.11.003
   Fortune S, 1996, ACM T GRAPHIC, V15, P223, DOI 10.1145/231731.231735
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   García FG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487232
   Greiner G, 2000, VISUAL COMPUT, V16, P357, DOI 10.1007/PL00007214
   Hemmer M., 2022, CGAL user and reference manual
   Hu KM, 2017, IEEE T VIS COMPUT GR, V23, P2560, DOI 10.1109/TVCG.2016.2632720
   Hu YX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323011
   Hu YX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201353
   Jiang ZS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417769
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Ju T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409075
   Khan D, 2022, IEEE T VIS COMPUT GR, V28, P1680, DOI 10.1109/TVCG.2020.3016645
   Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983
   Le B. H., 2017, P 21 ACM SIGGRAPH S, P1
   Li C, 2015, VISUAL COMPUT, V31, P937, DOI 10.1007/s00371-015-1117-8
   Liao WT, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459794
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Liu AW, 1996, MATH COMPUT, V65, P1183, DOI 10.1090/S0025-5718-96-00748-X
   Liu YJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818076
   Liu ZY, 2021, COMPUT AIDED DESIGN, V139, DOI 10.1016/j.cad.2021.103080
   Liu ZY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459843
   Meyer A., 2008, Real Numbers Comput., P47
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   Platis N, 2003, COMPUT GRAPH FORUM, V22, P107, DOI 10.1111/1467-8659.00653
   Portaneri C, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530152
   Sacht L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818093
   Sander PV, 2000, COMP GRAPH, P327, DOI 10.1145/344779.344935
   Schaefer S., 2004, P EUR ACM SIGGRAPH S, P147
   Stuart A., 2013, P ACM SIGGRAPH C MOT
   Wang BL, 2022, COMPUT GRAPH FORUM, V41, P355, DOI 10.1111/cgf.14479
   Wang BL, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3460775
   Wang BL, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392426
   Xian CH, 2015, COMPUT ANIMAT VIRT W, V26, P173, DOI 10.1002/cav.1571
   Xian CH, 2012, VISUAL COMPUT, V28, P21, DOI 10.1007/s00371-011-0595-6
   Xian CH, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P21, DOI 10.1109/SMI.2009.5170159
   Yang XS, 2013, VISUAL COMPUT, V29, P369, DOI 10.1007/s00371-012-0739-3
   Yang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392434
   Yifan W, 2020, PROC CVPR IEEE, P72, DOI 10.1109/CVPR42600.2020.00015
   Zhang WX, 2022, COMPUT GRAPH FORUM, V41, P237, DOI 10.1111/cgf.14471
   Zhao Y, 2009, J COMPUT SCI TECH-CH, V24, P47, DOI 10.1007/s11390-009-9213-8
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
   Zhou QN, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925901
NR 63
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4234
EP 4245
DI 10.1109/TVCG.2023.3255207
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700074
PM 37028283
DA 2024-08-05
ER

PT J
AU Liu, XQ
   Li, JT
   Lu, GD
AF Liu, Xinqi
   Li, Jituo
   Lu, Guodong
TI Modeling Realistic Clothing From a Single Image Under Normal Guide
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Clothing mask; clothing modeling; normal map; realistic wrinkles
   distribution; single image; stylized cloth
AB We propose a robust and highly realistic clothing modeling method to generate a 3D clothing model with visually consistent clothing style and wrinkles distribution from a single RGB image. Notably, this entire process only takes a few seconds. Our high-quality clothing results benefit from the idea of combining learning and optimization, making it highly robust. First, we use the neural networks to predict the normal map, a clothing mask, and a learning-based clothing model from input images. The predicted normal map can effectively capture high-frequency clothing deformation from image observations. Then, by introducing a normal-guided clothing fitting optimization, the normal maps are used to guide the clothing model to generate realistic wrinkles details. Finally, we utilize a clothing collar adjustment strategy to stylize clothing results using predicted clothing masks. An extended multi-view version of the clothing fitting is naturally developed, which can further improve the realism of the clothing without tedious effort. Extensive experiments have proven that our method achieves state-of-the-art clothing geometric accuracy and visual realism. More importantly, it is highly adaptable and robust to in-the-wild images. Further, our method can be easily extended to multi-view inputs to improve realism. In summary, our method can provide a low-cost and user-friendly solution to achieve realistic clothing modeling.
C1 [Liu, Xinqi; Li, Jituo; Lu, Guodong] Zhejiang Univ, Inst Design Engn, Sch Mech Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Liu, Xinqi; Li, Jituo; Lu, Guodong] Zhejiang Univ, Robot Inst, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Li, JT (corresponding author), Zhejiang Univ, Inst Design Engn, Sch Mech Engn, Hangzhou 310027, Zhejiang, Peoples R China.
EM liuxinqi@zju.edu.cn; jituo_li@zju.edu.cn; lugd@zju.edu.cn
OI Liu, Xinqi/0000-0002-9105-2417
FU Key Technologies Research and Development Program [2022YFB3303103];
   National Natural Science Foundation of China [52275276]; Research
   Funding of Zhejiang University Robotics Institute
FX This work was supported in part by the Key Technologies Research and
   Development Program under Grant 2022YFB3303103, in part by the National
   Natural Science Foundation of China under Grant 52275276,and in part by
   the Research Funding of Zhejiang University Robotics Institute.
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Baraff D, 2003, ACM T GRAPHIC, V22, P862, DOI 10.1145/882262.882357
   Bertiche H, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480479
   Bhatnagar Bharat Lal, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P311, DOI 10.1007/978-3-030-58536-5_19
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Boyi Jiang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P18, DOI 10.1007/978-3-030-58565-5_2
   Bozic A, 2021, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR46437.2021.00150
   Bridson S., 2005, P ACM SIGGRAPH EUR S
   Chen JC, 2021, Arxiv, DOI arXiv:2106.13629
   Chen X, 2021, Arxiv, DOI arXiv:1904.02601
   Chen X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11574, DOI 10.1109/ICCV48922.2021.01139
   Chibane Julian, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P717, DOI 10.1007/978-3-030-66096-3_48
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Corona E, 2021, PROC CVPR IEEE, P11870, DOI 10.1109/CVPR46437.2021.01170
   Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125
   Decaudin P, 2006, COMPUT GRAPH FORUM, V25, P625, DOI 10.1111/j.1467-8659.2006.00982.x
   Deng B., 2020, LNCS, P612, DOI DOI 10.1007/978-3-030-58571-636
   Dou M., 2017, ACM Trans. Graph.., V36, P1
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276438
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Gundogdu E, 2022, IEEE T PATTERN ANAL, V44, P181, DOI 10.1109/TPAMI.2020.3010886
   Halimi O., 2022, arXiv
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   He J., 2021, INT C NEURAL INF PRO, P9276
   Heming Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P512, DOI 10.1007/978-3-030-58452-8_30
   Jiang BY, 2022, PROC CVPR IEEE, P5595, DOI 10.1109/CVPR52688.2022.00552
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kingma D. P., 2014, arXiv
   Kocabas M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11107, DOI 10.1109/ICCV48922.2021.01094
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Lähner Z, 2018, LECT NOTES COMPUT SC, V11208, P698, DOI 10.1007/978-3-030-01225-0_41
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Li Z, 2022, LECT NOTES COMPUT SC, V13661, P322, DOI 10.1007/978-3-031-19769-7_19
   Liang JB, 2018, COMPUT GRAPH FORUM, V37, P21, DOI 10.1111/cgf.13509
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma QL, 2020, PROC CVPR IEEE, P6468, DOI 10.1109/CVPR42600.2020.00650
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Moon G, 2022, LECT NOTES COMPUT SC, V13662, P184, DOI 10.1007/978-3-031-20086-1_11
   Muller M., 2008, P 5 WORKSH VIRT REAL, P1
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Nealen A., 2006, PROC INT C COMPUT GR, P381, DOI [10.1145/1174429.1174494, DOI 10.1145/1174429.1174494]
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Patel Chaitanya, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7363, DOI 10.1109/CVPR42600.2020.00739
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Pons-Moll G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073711
   PROVOT X, 1995, GRAPH INTER, P147
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Saito S, 2021, PROC CVPR IEEE, P2885, DOI 10.1109/CVPR46437.2021.00291
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Santesteban I, 2022, PROC CVPR IEEE, P8130, DOI 10.1109/CVPR52688.2022.00797
   Santesteban I, 2021, PROC CVPR IEEE, P11758, DOI 10.1109/CVPR46437.2021.01159
   Scholz V, 2005, COMPUT GRAPH FORUM, V24, P439, DOI 10.1111/j.1467-8659.2005.00869.x
   Sun Y, 2019, IEEE I CONF COMP VIS, P5348, DOI 10.1109/ICCV.2019.00545
   Tiwari Garvita, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P1, DOI 10.1007/978-3-030-58580-8_1
   Tiwari G, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11688, DOI 10.1109/ICCV48922.2021.01150
   Tiwari L, 2021, IEEE INT CONF COMP V, P1416, DOI 10.1109/ICCVW54120.2021.00163
   Wang HM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459787
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Xiu YL, 2022, PROC CVPR IEEE, P13286, DOI 10.1109/CVPR52688.2022.01294
   Xu HY, 2020, PROC CVPR IEEE, P6183, DOI 10.1109/CVPR42600.2020.00622
   Yu T, 2021, PROC CVPR IEEE, P5742, DOI 10.1109/CVPR46437.2021.00569
   Yu T, 2020, IEEE T PATTERN ANAL, V42, P2523, DOI 10.1109/TPAMI.2019.2928296
   Yuan Y, 2021, PROC CVPR IEEE, P7155, DOI 10.1109/CVPR46437.2021.00708
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
   Zhang HW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11426, DOI 10.1109/ICCV48922.2021.01125
   Zhao H, 2022, PROC CVPR IEEE, P15883, DOI 10.1109/CVPR52688.2022.01544
   Zheng ZR, 2022, IEEE T PATTERN ANAL, V44, P3170, DOI 10.1109/TPAMI.2021.3050505
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 78
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3995
EP 4007
DI 10.1109/TVCG.2023.3245583
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700088
PM 37027566
DA 2024-08-05
ER

PT J
AU Wang, ZY
   Wang, YY
   Yan, SQ
   Zhu, ZZ
   Zhang, KJ
   Wei, HK
AF Wang, Ziyao
   Wang, Yiye
   Yan, Shiqi
   Zhu, Zhongzheng
   Zhang, Kanjian
   Wei, Haikun
TI Redirected Walking on Omnidirectional Treadmill
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Device integration; haptic feedback; locomotion interfaces;
   omnidirectional treadmill; redirected walking
ID VIRTUAL ENVIRONMENTS; CONTROLLER
AB Redirected walking (RDW) and omnidirectional treadmill (ODT) are two effective solutions to the natural locomotion interface in virtual reality. ODT fully compresses the physical space and can be used as the integration carrier of all kinds of devices. However, the user experience varies in different directions of ODT, and the premise of interaction between users and integrated devices is a good match between virtual and real objects. RDW technology uses visual cues to guide the user's location in physical space. Based on this principle, combining RDW technology with ODT to guide the user's walking direction through visual cues can effectively improve user experience on ODT and make full use of various devices integrated on ODT. This paper explores the novel prospects of combining RDW technology with ODT and formally puts forward the concept of O-RDW (ODT-based RDW). Two baseline algorithms, i.e., OS2MD (ODT-based steer to multi-direction), and OS2MT (ODT-based steer to multi-target), are proposed to combine the merits of both RDW and ODT. With the help of the simulation environment, this paper quantitatively analyzes the applicable scenarios of the two algorithms and the influence of several main factors on the performance. Based on the conclusions of the simulation experiments, the two O-RDW algorithms are successfully applied in the practical application case of multi-target haptic feedback. Combined with the user study, the practicability and effectiveness of O-RDW technology in practical use are further verified.
C1 [Wang, Ziyao; Wang, Yiye; Yan, Shiqi; Zhu, Zhongzheng; Zhang, Kanjian; Wei, Haikun] Southeast Univ, Nanjing 211189, Jiangning, Peoples R China.
C3 Southeast University - China
RP Wei, HK (corresponding author), Southeast Univ, Nanjing 211189, Jiangning, Peoples R China.
EM zy_wang@seu.edu.cn; wangyiye@seu.edu.cn; sqyan@seu.edu.cn;
   zzzhu@seu.edu.cn; kjzhang@seu.edu.cn; hkwei@seu.edu.cn
OI Wei, Haikun/0000-0002-6667-3166
FU National Natural Science Foundation of China [61773118, 61973083];
   Science and Technology Project of State Grid Corporation of China
   [SGTJDK00DYJS2000148]; Key Laboratory of Measurement and Control of
   Complex Systems of Engineering, Ministry of Education, Nanjing, China
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61773118 and 61973083, in part by
   Science and Technology Project of State Grid Corporation of
   China(Intelligent operation and maintenance technology of distributed
   photovoltaic system SGTJDK00DYJS2000148), the Key Laboratory of
   Measurement and Control of Complex Systems of Engineering, Ministry of
   Education, Nanjing 210096, China.
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Ang YY, 2018, ADV INTELL SYST, V696, P367, DOI 10.1007/978-981-10-7386-1_32
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Bridson R., 2007, ACM SIGGRAPH, V10, P1, DOI DOI 10.1145/1278780.1278807
   Cakmak T., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P1, DOI DOI 10.1145/2614066.2614105
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Cinelli M, 2012, EXP BRAIN RES, V219, P175, DOI 10.1007/s00221-012-3077-9
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hosoi J, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 EMERGING TECHNOLOGIES, DOI 10.1145/3476122.3484848
   Huang JY, 2003, IEEE T MULTIMEDIA, V5, P39, DOI 10.1109/TMM.2003.808822
   Iwata H, 2000, ROBOTICS RESEARCH, P275
   Iwata H, 1999, P IEEE VIRT REAL ANN, P286, DOI 10.1109/VR.1999.756964
   KatVr, 2015, Kat walk mini walking tutorials
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kim SW, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68362-y
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253, DOI 10.1145/1152399.11524512[23]P
   Langbehn E., 2018, Redirected Walking in Vir- tual Reality, DOI [10.1007/978-3319-08234-9253-1.1-11, DOI 10.1007/978-3319-08234-9253-1.1-11]
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Lee H, 2016, INT CONF UBIQ ROBOT, P889, DOI 10.1109/URAI.2016.7734002
   Lohse AL, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809587
   Matsukura H, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P127, DOI 10.1109/VR.2012.6180915
   Metsis V, 2017, 2017 INTERNATIONAL SYMPOSIUM ON WEARABLE ROBOTICS AND REHABILITATION (WEROB), P33
   Moon T., 2004, 11 ACM S VIRTUAL REA, P122, DOI DOI 10.1145/1077534.1077558
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Ogiwara Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P567, DOI [10.1109/VRW50115.2020.0-141, 10.1109/VRW50115.2020.00135]
   Pyo SH, 2018, IEEE INT CONF ROBOT, P760
   Razzaque S., 2005, Redirected walking
   Razzaque Z., 2001, EUROGRAPHICS 2001 SH, P289, DOI 10.2312/egs.20011036
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Rietzler M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5669, DOI 10.1145/3025453.3026009
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Steinicke F., 2013, Human Walking in Virtual Environments, V2
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Suzuki M., 2019, P VIRT REAL INT C VR, P39
   Swapp D, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P71, DOI 10.1109/3DUI.2010.5444717
   Thomas J., 2020, P 26 ACM S VIRT REAL, P1
   Wang ZY, 2023, IEEE T VIS COMPUT GR, V29, P5538, DOI 10.1109/TVCG.2022.3216211
   Wang ZY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P382, DOI [10.1109/VR46266.2020.1580802970259, 10.1109/ICEDME50972.2020.00092, 10.1109/VR46266.2020.00-46]
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
   Zenner A, 2021, IEEE T VIS COMPUT GR, V27, P2627, DOI 10.1109/TVCG.2021.3067777
   Zenner A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P549, DOI [10.1109/VRW50115.2020.0-150, 10.1109/VRW50115.2020.00126]
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 63
TC 0
Z9 0
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3884
EP 3901
DI 10.1109/TVCG.2023.3244359
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700012
PM 37027618
DA 2024-08-05
ER

PT J
AU Zhao, D
   Li, J
   Li, HY
   Xu, L
AF Zhao, Dong
   Li, Jia
   Li, Hongyu
   Xu, Long
TI Stripe Sensitive Convolution for Omnidirectional Image Dehazing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Convolution; Distortion; Feature extraction; Kernel; Estimation;
   Three-dimensional displays; Layout; Omnidirectional image dehazing;
   omnidirectional image depth estimation; stripe sensitive convolution;
   virtual reality
ID SALIENCY; VR
AB The haze in a scenario may affect the 360 photo/video quality and the immersive 360(degrees) virtual reality (VR) experience. The recent single image dehazing methods, to date, have been only focused on plane images. In this work, we propose a novel neural network pipeline for single omnidirectional image dehazing. To create the pipeline, we build the first hazy omnidirectional image dataset, which contains both synthetic and real-world samples. Then, we propose a new stripe sensitive convolution (SSConv) to handle the distortion problems due to the equirectangular projections. The SSConv calibrates distortion in two steps: 1) extracting features using different rectangular filters and, 2) learning to select the optimal features by a weighting of the feature stripes (a series of rows in the feature maps). Subsequently, using SSConv, we design an end-to-end network that jointly learns haze removal and depth estimation from a single omnidirectional image. The estimated depth map is leveraged as the intermediate representation and provides global context and geometric information to the dehazing module. Extensive experiments on challenging synthetic and real-world omnidirectional image datasets demonstrate the effectiveness of SSConv, and our network attains superior dehazing performance. The experiments on practical applications also demonstrate that our method can significantly improve the 3-D object detection and 3-D layout performances for hazy omnidirectional images.
C1 [Zhao, Dong; Li, Jia; Li, Hongyu] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Li, Jia] Peng Cheng Lab, Shenzhen 518000, Peoples R China.
   [Xu, Long] Chinese Acad Sci, Natl Space Sci Ctr, Beijing 100190, Peoples R China.
C3 Beihang University; Peng Cheng Laboratory; Chinese Academy of Sciences;
   National Space Science Center, CAS
RP Li, J (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.; Li, J (corresponding author), Peng Cheng Lab, Shenzhen 518000, Peoples R China.
EM zhaodong@buaa.edu.cn; jiali@buaa.edu.cn; hongyuli@buaa.edu.cn;
   lxu@nao.cas.cn
OI Xu, Long/0000-0002-9286-2876; Zhao, Dong/0000-0003-3754-1524; Li,
   Jia/0000-0002-4346-8696
FU National Natural Science Foundation of China [62132002, 11790305]; Peng
   Cheng Laboratory Cloud Brain [PCL2021A13]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62132002 and 11790305, and in part by
   Peng Cheng Laboratory Cloud Brain under Grant PCL2021A13.
CR Armeni I., 2017, arXiv
   Baslamisli AS, 2018, LECT NOTES COMPUT SC, V11210, P289, DOI 10.1007/978-3-030-01231-1_18
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bertel T, 2019, IEEE T VIS COMPUT GR, V25, P1828, DOI 10.1109/TVCG.2019.2898799
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chang AE, 2017, Arxiv, DOI arXiv:1709.06158
   Chen DW, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P92, DOI [10.1109/VR46266.2020.1581216087067, 10.1109/VR46266.2020.00-77]
   Chen HX, 2021, IEEE SIGNAL PROC LET, V28, P334, DOI 10.1109/LSP.2021.3050712
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen Z, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6742, DOI 10.1109/ICASSP.2018.8461630
   Coors B, 2018, LECT NOTES COMPUT SC, V11213, P525, DOI 10.1007/978-3-030-01240-3_32
   de La Garanderie GP, 2018, LECT NOTES COMPUT SC, V11217, P812, DOI 10.1007/978-3-030-01261-8_48
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Du RF, 2021, IEEE COMPUT GRAPH, V41, P99, DOI 10.1109/MCG.2021.3080320
   gabarron, 2017, The Gabarron foundationunveils its unique VR experiences (vir-tual reality)
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Hu J., 2018, SQUEEZE AND EXCITATI, P7132
   Hu J, 2018, ADV NEUR IN, V31
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167, 10.48550/arXiv.1502.03167]
   Isola P., 2017, P IEEE C COMP VIS PA, P1125, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Kingma D. P., 2014, arXiv
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lee Y, 2019, PROC CVPR IEEE, P9173, DOI 10.1109/CVPR.2019.00940
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Li H., 2018, ARXIV180510180, P1, DOI DOI 10.48550/ARXIV.1805.10180
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu HY, 2020, Arxiv, DOI arXiv:2008.10320
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Lo S.-Y., 2019, P ACM MULT AS, P1, DOI DOI 10.1145/3338533.3366558
   Luo BC, 2018, IEEE T VIS COMPUT GR, V24, P1545, DOI 10.1109/TVCG.2018.2794071
   Ma GX, 2020, IEEE T VIS COMPUT GR, V26, P3535, DOI 10.1109/TVCG.2020.3023636
   Marañes C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P73, DOI [10.1109/VR46266.2020.00-79, 10.1109/VR46266.2020.1580727911717]
   Marrinan T, 2021, IEEE T VIS COMPUT GR, V27, P2587, DOI 10.1109/TVCG.2021.3067780
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Pintore Giovanni, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P432, DOI 10.1007/978-3-030-58598-3_26
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Reed P., 2020, "Virtual reality
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Su Y.-C., 2017, ADV NEURAL INF PROCE, P529
   Tateno K, 2018, LECT NOTES COMPUT SC, V11220, P732, DOI 10.1007/978-3-030-01270-0_43
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wallgrün JO, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P83, DOI [10.1109/VR46266.2020.1581092881445, 10.1109/VR46266.2020.00-78]
   Wang LL, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P170, DOI 10.1109/VR50410.2021.00038
   Wang M, 2020, INT SYM MIX AUGMENT, P174, DOI [10.1109/ISMAR50242.2020.00040, 10.1109/1SMA1R50242.2020.00040]
   Wang M, 2020, COMPUT VIS MEDIA, V6, P3, DOI 10.1007/s41095-020-0162-z
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P666, DOI 10.1007/978-3-030-58517-4_39
   Won C, 2019, IEEE INT CONF ROBOT, P6073, DOI [10.1109/ICRA.2019.8793823, 10.1109/icra.2019.8793823]
   Woo S., 2018, BRIT MACHINE VISION, V2018, P147, DOI DOI 10.48550/ARXIV.1807.06514
   Xu Z., 2018, P BRIT MACH VIS C
   Young J, 2019, IEEE T VIS COMPUT GR, V25, P1908, DOI 10.1109/TVCG.2019.2898737
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P1975, DOI 10.1109/TCSVT.2019.2912145
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2020, IEEE IMAGE PROC, P3458, DOI 10.1109/ICIP40778.2020.9191158
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
NR 72
TC 0
Z9 0
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3516
EP 3531
DI 10.1109/TVCG.2022.3233900
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700013
PM 37018251
DA 2024-08-05
ER

PT J
AU Zhong, FH
   Xue, ML
   Zhang, J
   Zhang, F
   Ban, R
   Deussen, O
   Wang, YH
AF Zhong, Fahai
   Xue, Mingliang
   Zhang, Jian
   Zhang, Fan
   Ban, Rui
   Deussen, Oliver
   Wang, Yunhai
TI Force-Directed Graph Layouts Revisited: A New Force Based on the
   T-Distribution
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Computational modeling; Force; Stress; Springs; Scalability;
   Graphics processing units; Graph layout; force directed placement;
   student's t-distribution; FFT
ID DRAWING LARGE GRAPHS; STRESS MODEL; ALGORITHM
AB In this article, we propose the t-FDP model, a force-directed placement method based on a novel bounded short-range force (t-force) defined by Student's t-distribution. Our formulation is flexible, exerts limited repulsive forces for nearby nodes and can be adapted separately in its short- and long-range effects. Using such forces in force-directed graph layouts yields better neighborhood preservation than current methods, while maintaining low stress errors. Our efficient implementation using a Fast Fourier Transform is one order of magnitude faster than state-of-the-art methods and two orders faster on the GPU, enabling us to perform parameter tuning by globally and locally adjusting the t-force in real-time for complex graphs. We demonstrate the quality of our approach by numerical evaluation against state-of-the-art approaches and extensions for interactive exploration.
C1 [Zhong, Fahai; Xue, Mingliang; Wang, Yunhai] Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Peoples R China.
   [Zhang, Jian] Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100045, Peoples R China.
   [Zhang, Fan] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 265600, Peoples R China.
   [Ban, Rui] CITC, Intelligent Network Design Inst, Beijing 100022, Peoples R China.
   [Deussen, Oliver] Univ Konstanz, Comp & Informat Sci, D-78464 Constance, Germany.
C3 Shandong University; Chinese Academy of Sciences; Computer Network
   Information Center, CAS; Shandong Technology & Business University;
   University of Konstanz
RP Wang, YH (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Peoples R China.
EM zhongfahai@gmail.com; xml95007@gmail.com; zhangjian@sccas.cn;
   zhangfan@sdtbu.edu.cn; banrui1@chinaunicom.cn;
   Oliver.Deussen@uni-konstanz.de; cloudseawang@gmail.com
RI Zhang, Fan/GLT-6231-2022
OI Zhang, Fan/0000-0002-0343-3499; Xue, Mingliang/0000-0001-8842-1667;
   Zhang, Jian/0000-0003-1348-8124; Zhong, Fahai/0000-0002-0971-0821
FU National Key Research& Development Plan of China [2019YFB1704201];
   Shandong Provincial Natural Science Foundation [ZR2022JQ32]; NSFC
   [62132017, 62141217]; Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) under Germany's Excellence Strategy [EXC 2117 -
   422037984]
FX This work was supported in part by the National Key Research&
   Development Plan of China under Grant 2019YFB1704201, in part by the
   Shandong Provincial Natural Science Foundation under Grant
   ZR2022JQ32,and in part by the NSFC under Grants 62132017 and 62141217,
   as well as by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) under Germany's Excellence Strategy - EXC 2117 - 422037984.
CR Amid E., 2019, arXiv, DOI 10.48550/arXiv.1910.00204
   BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361, DOI DOI 10.1609/ICWSM.V3I1.13937
   Biedl T, 1998, COMP GEOM-THEOR APPL, V9, P159, DOI 10.1016/S0925-7721(97)00026-6
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Chan DM, 2018, INT SYM COMP ARCHIT, P330, DOI [10.1109/CAHPC.2018.8645912, 10.1109/SBAC-PAD.2018.00060]
   Chen LS, 2009, J AM STAT ASSOC, V104, P209, DOI 10.1198/jasa.2009.0111
   Chen Y, 2019, J VISUAL-JAPAN, V22, P625, DOI 10.1007/s12650-019-00551-y
   Chimani M., 2013, Handbook of Graph Drawing and Visualization, P543
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Douglas Carroll J., 1998, Multidimensional Scaling
   Dwyer T, 2009, COMPUT GRAPH FORUM, V28, P991, DOI 10.1111/j.1467-8659.2009.01449.x
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   EPPERSON JF, 1987, AM MATH MON, V94, P329, DOI 10.2307/2323093
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gansner ER, 2013, IEEE T VIS COMPUT GR, V19, P927, DOI 10.1109/TVCG.2012.299
   Gove R, 2019, COMPUT GRAPH FORUM, V38, P739, DOI 10.1111/cgf.13724
   Greengard L. F., 1987, PhD dissertation, DOI [10.5555/913529, DOI 10.5555/913529]
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Hu Y., 2005, Mathematica journal, V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Hu YF, 2009, IEEE PAC VIS SYMP, P129, DOI 10.1109/PACIFICVIS.2009.4906847
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Khoury M, 2012, COMPUT GRAPH FORUM, V31, P975, DOI 10.1111/j.1467-8659.2012.03090.x
   Kobak D, 2021, NAT BIOTECHNOL, V39, DOI 10.1038/s41587-020-00809-z
   Kobourov S. G., 2013, Force-Directed Drawing Algorithms
   Koren Y, 2009, LECT NOTES COMPUT SC, V5417, P193, DOI 10.1007/978-3-642-00219-9_19
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Kumar P., 2009, P 2009 ACM S APPL CO, P1800
   Lam S. K., 2015, P 2 WORKSH LLYM COMP, P1
   Lee B., 2006, P 2006 AVI WORKSHOP, P1, DOI [10.1145/1168149.1168168, DOI 10.1145/1168149.1168168]
   Leskovec J., 2014, SNAP Datasets: Stanford Large Network Dataset Collection
   Linderman GC, 2019, NAT METHODS, V16, P243, DOI 10.1038/s41592-018-0308-4
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Noack Andreas, 2007, Journal of Graph Algorithms and Applications, V11, P453, DOI 10.7155/jgaa.00154
   Pearson K., 1895, PHILOS T R SOC A, V186, P343, DOI DOI 10.1098/RSTA.1895.0010
   Peixoto Tiago P, 2017, Figshare
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Schneider J., 2006, Stochastic Optimization
   Tang J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P287, DOI 10.1145/2872427.2883041
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Walshaw C., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P171
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 48
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3650
EP 3663
DI 10.1109/TVCG.2023.3238821
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700017
PM 37021999
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Krüger, M
   Gerrits, T
   Römer, T
   Kuhlen, T
   Weissker, T
AF Krueger, Marcel
   Gerrits, Tim
   Roemer, Timon
   Kuhlen, Torsten
   Weissker, Tim
TI IntenSelect plus : Enhancing Score-Based Selection in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Three-dimensional displays; Task analysis; Usability;
   Virtual environments; Shape; Engines; Virtual Reality; 3D User
   Interfaces; 3D Interaction; Selection; Score-Based Selection; Temporal
   Selection; IntenSelect
ID OBJECT SELECTION
AB Object selection in virtual environments is one of the most common and recurring interaction tasks. Therefore, the used technique can critically influence a system's overall efficiency and usability. IntenSelect is a scoring-based selection-by-volume technique that was shown to offer improved selection performance over conventional raycasting in virtual reality. This initial method, however, is most pronounced for small spherical objects that converge to a point-like appearance only, is challenging to parameterize, and has inherent limitations in terms of flexibility. We present an enhanced version of IntenSelect called IntenSelect+ designed to overcome multiple shortcomings of the original IntenSelect approach. In an empirical within-subjects user study with 42 participants, we compared IntenSelect+ to IntenSelect and conventional raycasting on various complex object configurations motivated by prior work. In addition to replicating the previously shown benefits of IntenSelect over raycasting, our results demonstrate significant advantages of IntenSelect+ over IntenSelect regarding selection performance, task load, and user experience. We, therefore, conclude that IntenSelect+ is a promising enhancement of the original approach that enables faster, more precise, and more comfortable object selection in immersive virtual environments.
C1 [Krueger, Marcel; Gerrits, Tim; Roemer, Timon; Kuhlen, Torsten; Weissker, Tim] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
C3 RWTH Aachen University
RP Krüger, M (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM krueger@vis.rwth-aachen.de; gerrits@vr.rwth-aachen.de;
   t.roemer@vr.rwth-aachen.de; kuhlen@vr.rwth-aachen.de; me@tim-weissker.de
RI Kuhlen, Torsten/A-1059-2017
OI Kuhlen, Torsten/0000-0003-2144-4367; Weissker, Tim/0000-0001-9119-811X;
   Kruger, Marcel/0000-0002-0085-268X
FU German Federal Ministry of Education and Research
FX No Statement Available
CR Argelaguet F., 2008, P VRST 2008, P43
   Argelaguet F, 2008, LECT NOTES COMPUT SC, V5166, P45, DOI 10.1007/978-3-540-85412-8_5
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Belgardt M., 2023, RWTH VR Group Unreal Engine Toolkit, DOI [10.5281/zenodo.102457472, DOI 10.5281/ZENODO.102457472]
   Besancon L., 2021, Computer Graphics Forum, V40, P2
   Bowman D., 2001, USING PINCH GLOVES T
   Bowman D. A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P26, DOI 10.1145/323663.323667
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Cohen J., 1988, Statistical power analysis for the behavioral sciences
   de Haan G., 2005, EUROGRAPHICS S VIRTU, DOI [10.2312/EGVE/IPT_EGVE2005/201-2091,2,3, DOI 10.2312/EGVE/IPT_EGVE2005/201-2091,2,3]
   de Haan G., 2006, EUROGRAPHICS S VIRTU, P109
   Ericson C., 2004, Real-time Collision Detection., P4
   Field A., 2013, Discovering Statistics using IBM SPSS Statistics, Vthird, P374, DOI DOI 10.1016/B978-012691360-6/50012-4
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   Grossman T., 2006, P 19 ACM S US INT SO, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Han D., 2022, P VRST 2022, P1
   HART S G, 1988, P139
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Huang S., 2019, Virtual Reality & Intelligent Hardware, V1, P251
   Kim W, 2022, VIRTUAL REAL-LONDON, V26, P1573, DOI 10.1007/s10055-022-00649-z
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LaViola J.J., 2017, 3D user interfaces: theory and practice
   Li HY, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-1517-3
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.00-83, 10.1109/VR46266.2020.1581165829725]
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Mine M.R., 1995, Technical Report
   Moore AG, 2018, INT J HUM-COMPUT ST, V120, P36, DOI 10.1016/j.ijhcs.2018.07.003
   Ortega M, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2013.6550208
   Pavlovych Andriy., 2012, Proceedings of Graphics Interface 2012 (GI' 12), P109
   Poupyrev I, 1999, J VISUAL LANG COMPUT, V10, P19, DOI 10.1006/jvlc.1998.0112
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, V8517, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.1007/978-3-319-07668-3_37, DOI 10.1007/978-3-319-07668-337]
   Steed A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P103, DOI 10.1109/TRIDUI.2006.1618279
   Steinicke F, 2006, COMPUT IMAGING VIS, V32, P320, DOI 10.1007/1-4020-4179-9_46
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wang YH, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.607165
   Weise Matthias, 2020, i-com: Journal of Interactive Media, V19, P67, DOI 10.1515/icom-2020-0011
   Weller R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684677
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376876
   Wyss HP, 2006, IEEE Symposium on 3D User Interfaces 2006, Proceedings, P59, DOI 10.1109/TRIDUI.2006.1618271
   Xu WG, 2022, INT SYM MIX AUGMENT, P131, DOI 10.1109/ISMAR55827.2022.00027
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Zhao L., 2024, IEEE Transactions on Visualization and Computer Graphics
NR 46
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2829
EP 2838
DI 10.1109/TVCG.2024.3372077
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200003
PM 38437105
DA 2024-08-05
ER

PT J
AU Guillou, P
   Vidal, J
   Tierny, J
AF Guillou, Pierre
   Vidal, Jules
   Tierny, Julien
TI Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for
   Scalar Data - An Algorithm and a Benchmark
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE discrete Morse theory; persistence diagrams; scalar data; Topological
   data analysis
ID TOPOLOGICAL SIMPLIFICATION; EFFICIENT COMPUTATION; COMPLEXES
AB This paper introduces an efficient algorithm for persistence diagram computation, given an input piecewise linear scalar field f defined on a d-dimensional simplicial complex K, with d <= 3. Our work revisits the seminal algorithm "PairSimplices" (Edelsbrunner et al. 2002), (Zomorodian, 2010) with discrete Morse theory (DMT) (Forman, 1998), (Robins et al. 2011), which greatly reduces the number of input simplices to consider. Further, we also extend to DMT and accelerate the stratification strategy described in "PairSimplices" (Edelsbrunner et al. 2002), (Zomorodian, 2010) for the fast computation of the 0th and (d - 1)th diagrams, noted D-0(f) and Dd-1(f ). Minima-saddle persistence pairs (D-0(f )) and saddle-maximum persistence pairs (Dd-1(f )) are efficiently computed by processing, with a Union-Find, the unstable sets of 1-saddles and the stable sets of (d - 1)-saddles. This fast precomputation for the dimensions 0 and (d - 1) enables an aggressive specialization of (Bauer et al. 2014) to the 3D case, which results in a drastic reduction of the number of input simplices for the computation of D-1(f ), the intermediate layer of the sandwich. Finally, we document several performance improvements via shared-memory parallelism. We provide an open-source implementation of our algorithm for reproducibility purposes. Extensive experiments indicate that our algorithm improves by two orders of magnitude the time performance of the seminal "PairSimplices" algorithm it extends. Moreover, it also improves memory footprint and time performance over a selection of 14 competing approaches, with a substantial gain over the fastest available approaches, while producing a strictly identical output.
C1 [Guillou, Pierre; Vidal, Jules; Tierny, Julien] CNRS, F-75005 Paris, France.
   [Guillou, Pierre; Vidal, Jules; Tierny, Julien] Sorbonne Univ, F-75005 Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne Universite
RP Tierny, J (corresponding author), CNRS, F-75005 Paris, France.
EM pierre.guillou@lip6.fr; jules.vidal@lip6.fr;
   julien.tierny@sorbonne-universite.fr
OI Vidal, Jules/0000-0002-1154-4391
FU European Commission
FX No Statement Available
CR Adams Henry, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P129, DOI 10.1007/978-3-662-44199-2_23
   [Anonymous], 1999, TOPOLOGY P
   Atallah M. J., 2010, Algorithms and Theory of Computation Handbook, V2nd, P82
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Barannikov S., 1994, Advances in Soviet Mathematics, V21, P93
   Bauer, 2019, RIPSER EFFICIENT COM, DOI DOI 10.1186/s13059-016-0980-6
   Bauer U., 2014, P TOP METH DAT AN VI, P103
   Bauer U., 2014, 2014 P M ALGORITHM E, P31, DOI DOI 10.1137/1.9781611973198.4
   Bauer U, 2017, J SYMB COMPUT, V78, P76, DOI 10.1016/j.jsc.2016.03.008
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bin Masood T., 2019, P TOP METH DAT AN VI, P327
   Bock A, 2018, IEEE T VIS COMPUT GR, V24, P812, DOI 10.1109/TVCG.2017.2743980
   Boissonnat J., 2020, P INT S COMP GEOM, P1
   Boissonnat JD, 2015, ALGORITHMICA, V73, P607, DOI 10.1007/s00453-015-9999-4
   Boissonnat JD, 2014, ALGORITHMICA, V70, P406, DOI 10.1007/s00453-014-9887-3
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P918
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Chen C., 2011, P 27 EUR WORKSH COMP, V11, P197
   Chen F, 2013, COMPUT AIDED GEOM D, V30, P557, DOI 10.1016/j.cagd.2012.03.019
   Chiang YJ, 2005, COMP GEOM-THEOR APPL, V30, P165, DOI 10.1016/j.comgeo.2004.05.002
   Cormen T. H., 2009, Introduction to Algorithms, V3rd
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   de Silva V, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/12/124003
   de Silva V, 2011, DISCRETE COMPUT GEOM, V45, P737, DOI 10.1007/s00454-011-9344-x
   Delgado-Friedrichs O., 2020, Digital image analysis using discrete Morse theory and persistent homology
   Dey T.K., 2014, P 30 ANN S COMPUTATI, P345, DOI [DOI 10.1145/2582112.2582165, 10.1145/2582112.2582165]
   Dey TK, 2019, LECT NOTES COMPUT SC, V11382, P123, DOI 10.1007/978-3-030-10828-1_10
   Doraiswamy H, 2021, IEEE T VIS COMPUT GR, V27, P561, DOI 10.1109/TVCG.2020.3030441
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2009, Computational Topology: An Introduction
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Forman R., 2002, Sem. Lothar. Combin, V48
   Freudenthal H, 1942, ANN MATH, V43, P580, DOI 10.2307/1968813
   Frosini P., 1999, Pattern Recognition and Image Analysis, V9, P596
   Garin A., 2020, P INT S COMP GEOM, P1
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8
   Gueunet C., 2019, P EUR S PAR GRAPH VI, P27
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A., 2011, P TOP METH DAT AN VI, P31
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Hebrail G, 2012, Individual household electric power consumption Data Set
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Henselman G, 2017, Arxiv, DOI arXiv:1606.00199
   Henselman-Petrusek G., 2018, Eirene.jl package for homological Algebra
   Iuricich F, 2022, IEEE T VIS COMPUT GR, V28, P4966, DOI 10.1109/TVCG.2021.3110663
   Kaji S., 2020, Cubical Ripser: Software for computing persistent homology of image and volume data
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Klacansky P., 2020, "Open scientific visualization data sets
   Kontak M, 2019, PROCEEDINGS OF URGENTHPC: 2019 FIRST IEEE/ACM INTERNATIONAL WORKSHOP ON HPC FOR URGENT DECISION MAKING (URGENTHPC), P7, DOI 10.1109/UrgentHPC49580.2019.00007
   Kruskal JB., 1978, MULTIDIMENSIONAL SCA
   KUHN HW, 1960, IBM J RES DEV, V4, P518, DOI 10.1147/rd.45.0518
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Maadasamy S, 2012, INT C HIGH PERFORM
   Maria Clement, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P167, DOI 10.1007/978-3-662-44199-2_28
   Milnor J., 1963, Morse theory, V51
   Mischaikow K, 2013, DISCRETE COMPUT GEOM, V50, P330, DOI 10.1007/s00454-013-9529-6
   Morozov D., 2017, Dionysus2
   Morozov D, 2020, PROCEEDINGS OF THE 32ND ACM SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES (SPAA '20), P555, DOI 10.1145/3350755.3400244
   Morse M., 1934, The Calculus of Variations in the Large, V8th ed., DOI 10.1090/coll/018
   Nanda V., 2021, Perseus, the persistent homology software
   Nigmetov A., 2021, Oineus
   Oesterling P, 2011, IEEE T VIS COMPUT GR, V17, P1547, DOI 10.1109/TVCG.2011.27
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Parsa S, 2012, P 28 ANN S COMP GEOM, P269
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239509, 10.1145/1276377.1276449]
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Saul Nathaniel, 2021, Zenodo
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, IEEE T VIS COMPUT GR, V18, P1757, DOI 10.1109/TVCG.2011.284
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Smirnov D., 2017, PROC TOPOLOGICAL MET, P19
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   Soler M, 2018, SYMP LARG DATA ANAL, P23, DOI 10.1109/LDAV.2018.8739196
   Soler M, 2018, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis.2018.00015
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tauzin G, 2021, J MACH LEARN RES, V22
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P2005, DOI 10.1109/TVCG.2012.228
   Tralie CJ., 2018, J OPEN SOURCE SOFTW, V3, P925, DOI [DOI 10.21105/JOSS.00925, 10.21105/joss.00925]
   Van Kreveld M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P212, DOI 10.1145/262839.269238
   Vidal J., 2021, P IEEE 11 S LARG DAT, P1
   Vidal J, 2021, IEEE T VIS COMPUT GR, V27, P2833, DOI 10.1109/TVCG.2021.3060500
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   WAGNER H., 2012, Topological methods in data analysis and visualization II: theory, algorithms, and applications, P91, DOI [DOI 10.1007/978-3-642-23175-97, 10.1007/978-3-642-23175-97]
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P330, DOI 10.1109/TVCG.2007.47
NR 103
TC 2
Z9 2
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1897
EP 1915
DI 10.1109/TVCG.2023.3238008
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500001
PM 37021884
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Neuhauser, C
   Stumpfegger, J
   Westermann, R
AF Neuhauser, Christoph
   Stumpfegger, Josef
   Westermann, Ruediger
TI Adaptive Sampling of 3D Spatial Correlations for Focus plus Context
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Correlation; Three-dimensional displays; Meteorology; Visualization;
   Graphics processing units; Layout; Weather forecasting; Chord diagrams;
   correlation sampling; ensemble analysis
ID VISUAL ANALYSIS; ENSEMBLE; UNCERTAINTY; SENSITIVITY; TOOL
AB Visualizing spatial correlations in 3D ensembles is challenging due to the vast amounts of information that need to be conveyed. Memory and time constraints make it unfeasible to pre-compute and store the correlations between all pairs of domain points. We propose the embedding of adaptive correlation sampling into chord diagrams with hierarchical edge bundling to alleviate these constraints. Entities representing spatial regions are arranged along the circular chord layout via a space-filling curve, and Bayesian optimal sampling is used to efficiently estimate the maximum occurring correlation between any two points from different regions. Hierarchical edge bundling reduces visual clutter and emphasizes the major correlation structures. By selecting an edge, the user triggers a focus diagram in which only the two regions connected via this edge are refined and arranged in a specific way in a second chord layout. For visualizing correlations between two different variables, which are not symmetric anymore, we switch to showing a full correlation matrix. This avoids drawing the same edges twice with different correlation values. We introduce GPU implementations of both linear and non-linear correlation measures to further reduce the time that is required to generate the context and focus views, and to even enable the analysis of correlations in a 1000-member ensemble.
C1 [Neuhauser, Christoph; Stumpfegger, Josef; Westermann, Ruediger] Tech Univ Munich, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Neuhauser, C (corresponding author), Tech Univ Munich, D-80333 Munich, Germany.
EM christoph.neuhauser@tum.de; ga87tux@mytum.de; westermann@tum.de
OI Westermann, Rudiger/0000-0002-3394-0731; Neuhauser,
   Christoph/0000-0002-0290-1991
CR Ancell B, 2007, MON WEATHER REV, V135, P4117, DOI 10.1175/2007MWR1904.1
   Chen CK, 2011, IEEE PAC VIS SYMP, P27, DOI 10.1109/PACIFICVIS.2011.5742369
   Dalelane C, 2023, EARTH SYST DYNAM, V14, P17, DOI 10.5194/esd-14-17-2023
   Demir I., 2016, SIGGRAPH ASIA 2016 S, DOI DOI 10.1145/3002151.3002165
   Farokhmanesh F., 2023, Modeling Vision, and Visualization
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Hazarika S, 2018, IEEE T VIS COMPUT GR, V24, P934, DOI 10.1109/TVCG.2017.2744099
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Kumpf A, 2019, IEEE T VIS COMPUT GR, V25, P98, DOI 10.1109/TVCG.2018.2864901
   Necker T, 2020, Q J ROY METEOR SOC, V146, P1423, DOI 10.1002/qj.3744
   Nocke T, 2015, NONLINEAR PROC GEOPH, V22, P545, DOI 10.5194/npg-22-545-2015
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Rautenhaus M, 2015, GEOSCI MODEL DEV, V8, P2329, DOI 10.5194/gmd-8-2329-2015
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Torn RD, 2008, MON WEATHER REV, V136, P663, DOI 10.1175/2007MWR2132.1
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wilks DS, 2016, B AM METEOROL SOC, V97, P2263, DOI 10.1175/BAMS-D-15-00267.1
NR 20
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1608
EP 1623
DI 10.1109/TVCG.2023.3326855
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300004
PM 37874723
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hnatyshyn, R
   Zhao, JQ
   Perez, D
   Ahrens, J
   Maciejewski, R
AF Hnatyshyn, Rostyslav
   Zhao, Jieqiong
   Perez, Danny
   Ahrens, James
   Maciejewski, Ross
TI MolSieve: A Progressive Visual Analytics System for Molecular Dynamics
   Simulations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trajectory; Analytical models; Biological system modeling; Visual
   analytics; Three-dimensional displays; Computational modeling; Data
   models; Molecular dynamics; time-series analysis; visual analytics
ID VISUALIZATION
AB Molecular Dynamics (MD) simulations are ubiquitous in cutting-edge physio-chemical research. They provide critical insights into how a physical system evolves over time given a model of interatomic interactions. Understanding a system's evolution is key to selecting the best candidates for new drugs, materials for manufacturing, and countless other practical applications. With today's technology, these simulations can encompass millions of unit transitions between discrete molecular structures, spanning up to several milliseconds of real time. Attempting to perform a brute-force analysis with data-sets of this size is not only computationally impractical, but would not shed light on the physically-relevant features of the data. Moreover, there is a need to analyze simulation ensembles in order to compare similar processes in differing environments. These problems call for an approach that is analytically transparent, computationally efficient, and flexible enough to handle the variety found in materials-based research. In order to address these problems, we introduce MolSieve, a progressive visual analytics system that enables the comparison of multiple long-duration simulations. Using MolSieve, analysts are able to quickly identify and compare regions of interest within immense simulations through its combination of control charts, data-reduction techniques, and highly informative visual components. A simple programming interface is provided which allows experts to fit MolSieve to their needs. To demonstrate the efficacy of our approach, we present two case studies of MolSieve and report on findings from domain collaborators.
C1 [Hnatyshyn, Rostyslav; Zhao, Jieqiong; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85287 USA.
   [Perez, Danny; Ahrens, James] Los Alamos Natl Lab, Los Alamos, NM USA.
C3 Arizona State University; Arizona State University-Tempe; United States
   Department of Energy (DOE); Los Alamos National Laboratory
RP Hnatyshyn, R (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM rhnatysh@asu.edu; jzhao@asu.edu; danny_perez@lanl.gov; ahrens@lanl.gov;
   rmacieje@asu.edu
RI Zhao, Jieqiong/HLH-8586-2023
OI Zhao, Jieqiong/0000-0002-4303-7722
FU Exascale Computing Project
FX No Statement Available
CR Ackland GJ, 2006, PHYS REV B, V73, DOI 10.1103/PhysRevB.73.054104
   Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   Arias-Hernandez R., 2011, PROC HAWAII INT CONF, DOI DOI 10.1109/HICSS.2011.3397
   BEKKER H, 1993, PHYSICS COMPUTING '92, P252
   Bostock M., 2011, D3
   Brehm M, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0005078
   Byska J, 2019, COMPUT GRAPH FORUM, V38, P441, DOI 10.1111/cgf.13701
   Chae J, 2019, IEEE INT CONF BIG DA, P1759, DOI 10.1109/BigData47090.2019.9006048
   Deuflhard P, 2005, LINEAR ALGEBRA APPL, V398, P161, DOI 10.1016/j.laa.2004.10.026
   Dreher M, 2014, FARADAY DISCUSS, V169, P119, DOI 10.1039/c3fd00142c
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   FastAPI, 2019, About us
   Fekete J.-D., 2019, Dagstuhl Reports, V8, DOI DOI 10.4230/DAGREP.8.10.14
   Furnas G. W., 2006, Conference on Human Factors in Computing Systems. CHI2006, P999
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Larsen AH, 2017, J PHYS-CONDENS MAT, V29, DOI 10.1088/1361-648X/aa680e
   HONEYCUTT JD, 1987, J PHYS CHEM-US, V91, P4950, DOI 10.1021/j100303a014
   Huang R, 2018, PHYS REV MATER, V2, DOI 10.1103/PhysRevMaterials.2.126002
   Huang R, 2017, J CHEM PHYS, V147, DOI 10.1063/1.4996922
   Jonsson H., 1998, CLASSICAL QUANTUM DY, P385, DOI DOI 10.1142/3816
   Jurcik A, 2018, BIOINFORMATICS, V34, P3586, DOI 10.1093/bioinformatics/bty386
   KARPLUS M, 1990, NATURE, V347, P631, DOI 10.1038/347631a0
   Kern M, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad083
   Kincaid R, 2010, IEEE T VIS COMPUT GR, V16, P900, DOI 10.1109/TVCG.2010.193
   Kühne TD, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0007045
   Larsen PM, 2016, MODEL SIMUL MATER SC, V24, DOI 10.1088/0965-0393/24/5/055007
   LOWRY CA, 1995, IIE TRANS, V27, P800, DOI 10.1080/07408179508936797
   Martinez X, 2020, BIOCHEM SOC T, V48, P499, DOI 10.1042/BST20190621
   Massobrio C, 2015, SPRINGER SER MATER S, V215, P1, DOI 10.1007/978-3-319-15675-0
   Misra P. K., 2012, Physics of Condensed Matter, P567, DOI DOI 10.1016/B978-0-12-384954-0.00017-7
   Perez D, 2016, J CHEM THEORY COMPUT, V12, P18, DOI 10.1021/acs.jctc.5b00916
   Perez D, 2015, COMP MATER SCI, V100, P90, DOI 10.1016/j.commatsci.2014.12.011
   Perez D, 2009, ANN REP COMP CHEM, V5, P79, DOI 10.1016/S1574-1400(09)00504-0
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   React, 2019, About us
   Redona S., 2016, SAMSON: Software for adaptive modeling and simulation of nanosystems
   Redux, 2019, About us
   Reuter B, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5064530
   Schatz K, 2019, EUR PHYS J-SPEC TOP, V227, P1725, DOI 10.1140/epjst/e2019-800162-y
   Scheurer M, 2018, BIOPHYS J, V114, P577, DOI 10.1016/j.bpj.2017.12.003
   Shalloway D, 1996, J CHEM PHYS, V105, P9986, DOI 10.1063/1.472830
   Shewhart W. A., 1986, Statistical Method from the Viewpoint of Quality Control, P5
   Skanberg R, 2018, WORKSH MOL GRAPH VIS, P19, DOI [DOI 10.2312/MOLVA.20181102, 10.2312/molva.20181102]
   Stukowski A, 2010, MODEL SIMUL MATER SC, V18, DOI 10.1088/0965-0393/18/1/015012
   Thompson AP, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108171
   Tian Z, 2023, METALS-BASEL, V13, DOI 10.3390/met13020415
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Ulbrich P, 2023, IEEE T VIS COMPUT GR, V29, P581, DOI 10.1109/TVCG.2022.3209411
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wickham H., 2011, Technical report, P5
   Wu GQ, 2022, J VISUAL-JAPAN, V25, P31, DOI 10.1007/s12650-021-00769-9
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   ZOU PF, 1994, ACTA CRYSTALLOGR A, V50, P714, DOI 10.1107/S0108767394003740
NR 54
TC 1
Z9 1
U1 5
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 727
EP 737
DI 10.1109/TVCG.2023.3326584
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500111
PM 37938968
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Shi, CH
   Cui, WW
   Liu, CZ
   Zheng, CB
   Zhang, HD
   Luo, Q
   Ma, XJ
AF Shi, Chuhan
   Cui, Weiwei
   Liu, Chengzhong
   Zheng, Chengbo
   Zhang, Haidong
   Luo, Qiong
   Ma, Xiaojuan
TI NL2Color: Refining Color Palettes for Charts with Natural Language
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE chart; color palette; natural language; large language model
ID VISUALIZATION
AB Choice of color is critical to creating effective charts with an engaging, enjoyable, and informative reading experience. However, designing a good color palette for a chart is a challenging task for novice users who lack related design expertise. For example, they often find it difficult to articulate their abstract intentions and translate these intentions into effective editing actions to achieve a desired outcome. In this work, we present NL2Color, a tool that allows novice users to refine chart color palettes using natural language expressions of their desired outcomes. We first collected and categorized a dataset of 131 triplets, each consisting of an original color palette of a chart, an editing intent, and a new color palette designed by human experts according to the intent. Our tool employs a large language model (LLM) to substitute the colors in original palettes and produce new color palettes by selecting some of the triplets as few-shot prompts. To evaluate our tool, we conducted a comprehensive two-stage evaluation, including a crowd-sourcing study (N=71) and a within-subjects user study (N=12). The results indicate that the quality of the color palettes revised by NL2Color has no significantly large difference from those designed by human experts. The participants who used NL2Color obtained revised color palettes to their satisfaction in a shorter period and with less effort.
C1 [Shi, Chuhan] Southeast Univ, Nanjing, Peoples R China.
   [Shi, Chuhan; Liu, Chengzhong; Zheng, Chengbo; Luo, Qiong; Ma, Xiaojuan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Cui, Weiwei; Zhang, Haidong] Microsoft Res Asia, Beijing, Peoples R China.
   [Luo, Qiong] Hong Kong Univ Sci & Technol Guangzhou, Hong Kong, Peoples R China.
C3 Southeast University - China; Hong Kong University of Science &
   Technology; Microsoft; Microsoft Research Asia
RP Shi, CH (corresponding author), Southeast Univ, Nanjing, Peoples R China.; Shi, CH (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM cshiag@connect.ust.hk; weiweicu@microsoft.com;
   chengzhong.liu@connect.ust.hk; cb.zheng@connect.ust.hk;
   haizhang@microsoft.com; luo@cse.ust.hk; mxj@cse.ust.hk
OI Luo, Qiong/0000-0002-2861-9492
FU HKUST 30 for 30
FX No Statement Available
CR adobe, Adobe Illustrator
   adobe, A. Adobe Photoshop
   Adobe, Adobe color
   Bahng H, 2018, LECT NOTES COMPUT SC, V11216, P443, DOI 10.1007/978-3-030-01258-8_27
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brewer C., 1994, Visualization in modern cartography
   Brown T. B., 2020, P 34 INT C NEURAL IN, P1
   coloplast, ABOUT US
   coolingzone, about us
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Feng Y., 2023, IEEE Transactions on Visualization and Computer Graphics
   github, Vega-Lite
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   HART S G, 1988, P139
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Inkscape, ABOUT US
   Kaur H., 2019, CHI 19
   Kenter T, 2015, P 24 ACM INT C INF K, P1411, DOI 10.1145/2806416.2806475
   Kim Tae Soo, 2022, P 2022 CHI C HUM FAC, P1
   Krause M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4627
   Kumar IP, 2020, ADV INTELL SYST COMP, V1079, P921, DOI 10.1007/978-981-15-1097-7_78
   Li Y., 2021, P 2021 CHI C HUM FAC, P1
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Lu H., 2012, CHI, P2875
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   materialise, US
   Meier BJ, 2004, IEEE COMPUT GRAPH, V24, P64, DOI 10.1109/MCG.2004.1297012
   Mishra S, 2022, Arxiv, DOI arXiv:2109.07830
   palestinianfeministcollective, About us
   Peng YF, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P389, DOI [10.1109/icccbda.2019.8725717, 10.1109/ICCCBDA.2019.8725717]
   Qiu Qianru, 2022, P 27 INT C INT US IN, P26, DOI [DOI 10.1145/3490100.3516450, 10.1145/3490100.3516450]
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Rashid MM, 2022, LECT NOTES ARTIF INT, V13281, P3, DOI 10.1007/978-3-031-05936-0_1
   Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760
   Schloss KB, 2019, IEEE T VIS COMPUT GR, V25, P810, DOI 10.1109/TVCG.2018.2865147
   Setlur V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P216, DOI 10.1109/VIS47514.2020.00050
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Shugrina M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300686
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   So D., 2021, Advances in Neural Information Processing Systems, V34, P6010
   Stern M.K., 2010, The Corsini Encyclopedia of Psychology
   Tseng C, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581416
   Tuli M., 2022, Advances in Neural Information Processing Systems, V35, P19441
   Voigt H, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P348
   vor der Brück T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1827
   Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wijffelaars M, 2008, COMPUT GRAPH FORUM, V27, P743, DOI 10.1111/j.1467-8659.2008.01203.x
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Yan L., 2021, P 2021 CHI C HUM FAC, P1
   Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4252, DOI 10.1109/TVCG.2021.3085327
   Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388
   Zeileis A, 2019, Arxiv, DOI arXiv:1903.06490
NR 57
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 814
EP 824
DI 10.1109/TVCG.2023.3326522
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500091
PM 37871067
DA 2024-08-05
ER

PT J
AU Hu, T
   Xu, HY
   Luo, LJ
   Yu, T
   Zheng, ZR
   Zhang, H
   Liu, YB
   Zwicker, M
AF Hu, Tao
   Xu, Hongyi
   Luo, Linjie
   Yu, Tao
   Zheng, Zerong
   Zhang, He
   Liu, Yebin
   Zwicker, Matthias
TI HVTR plus plus : Image and Pose Driven Human Avatars Using Hybrid
   Volumetric-Textural Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Three-dimensional displays; Avatars;
   Geometry; Image resolution; Pipelines; Telepresence; Video-based
   characters; full-body avatar; neural rendering; deep; hybrid
AB Recent neural rendering methods have made great progress in generating photorealistic human avatars. However, these methods are generally conditioned only on low-dimensional driving signals (e.g., body poses), which are insufficient to encode the complete appearance of a clothed human. Hence they fail to generate faithful details. To address this problem, we exploit driving view images (e.g., in telepresence systems) as additional inputs. We propose a novel neural rendering pipeline, Hybrid Volumetric-Textural Rendering (HVTR++), which synthesizes 3D human avatars from arbitrary driving poses and views while staying faithful to appearance details efficiently and at high quality. First, we learn to encode the driving signals of pose and view image on a dense UV manifold of the human body surface and extract UV-aligned features, preserving the structure of a skeleton-based parametric model. To handle complicated motions (e.g., self-occlusions), we then leverage the UV-aligned features to construct a 3D volumetric representation based on a dynamic neural radiance field. While this allows us to represent 3D geometry with changing topology, volumetric rendering is computationally heavy. Hence we employ only a rough volumetric representation using a pose- and image-conditioned downsampled neural radiance field (PID-NeRF), which we can render efficiently at low resolutions. In addition, we learn 2D textural features that are fused with rendered volumetric features in image space. The key advantage of our approach is that we can then convert the fused features into a high-resolution, high-quality avatar by a fast GAN-based textural renderer. We demonstrate that hybrid rendering enables HVTR++ to handle complicated motions, render high-quality avatars under user-controlled poses/shapes, and most importantly, be efficient at inference time. Our experimental results also demonstrate state-of-the-art quantitative results.
C1 [Hu, Tao; Zwicker, Matthias] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
   [Xu, Hongyi] ByteDanceInc, Intelligent Creat Lab, Beijing 100086, Peoples R China.
   [Luo, Linjie; Yu, Tao; Zheng, Zerong; Zhang, He; Liu, Yebin] Tsinghua Univ, Dept Automat, Beijing 100190, Peoples R China.
C3 University System of Maryland; University of Maryland College Park;
   Tsinghua University
RP Hu, T (corresponding author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
EM taohu@umd.edu; hongyixu@bytedance.com; linjie.luo@bytedance.com;
   ytrock@mail.tsinghua.edu.cn; zzr18@mails.tsinghua.edu.cn;
   zhanghe3d@gmail.com; liuyebin@mail.tsinghua.edu.cn; zwicker@cs.umd.edu
RI Hu, Tao/JRY-5446-2023
OI Hu, Tao/0000-0002-3741-3701; Zheng, Zerong/0000-0003-1339-2480; Zwicker,
   Matthias/0000-0001-8630-5515; Zhang, He/0000-0002-7280-6746
FU NSFC [62125107, 62171255]; Guoqiang Institute of Tsinghua University
   [2021GQG0001]; NSF [1813583]
FX The work of Yebin Liu was supported in part by the NSFC under Grant
   62125107. The work of Tao Yu was supported in part by the NSFC under
   Grant 62171255 and in part by Guoqiang Institute of Tsinghua University
   under Grant 2021GQG0001. The work of Matthias Zwicker was supported by
   NSF under Grant 1813583. Work partly conducted during Tao Hu's
   internship at ByteDance.
CR Bagautdinov T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459850
   Borshukov G., 2003, P ACM SIGGRAPH, P16
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Deng B., 2020, LNCS, P612, DOI DOI 10.1007/978-3-030-58571-636
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Grigorev A, 2019, PROC CVPR IEEE, P12127, DOI 10.1109/CVPR.2019.01241
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Habermann M, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459749
   He T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11026, DOI 10.1109/ICCV48922.2021.01086
   Hensel M, 2017, ADV NEUR IN, V30
   Hu T., 2021, P INT C COMP VIS, P14528
   Hu T, 2022, INT CONF 3D VISION, P197, DOI 10.1109/3DV57658.2022.00032
   Huang JW, 2020, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR42600.2020.00163
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Jakob Wenzel, 2010, Mitsuba renderer
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Kingma D., 2015, P INT C LEARN REPR, P273
   Kratzwald B, 2018, Arxiv, DOI arXiv:1711.11453
   Kwon Y, 2021, Arxiv, DOI arXiv:2109.07448
   Lawrence J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480490
   Liu LJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480528
   Liu LJ, 2021, IEEE T VIS COMPUT GR, V27, P4009, DOI 10.1109/TVCG.2020.2996594
   Liu LJ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3333002
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Lombardi S, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3476576.3476608, 10.1145/3450626.3459863]
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma QL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10954, DOI 10.1109/ICCV48922.2021.01079
   Ma QL, 2021, PROC CVPR IEEE, P16077, DOI 10.1109/CVPR46437.2021.01582
   Ma QL, 2020, PROC CVPR IEEE, P6468, DOI 10.1109/CVPR42600.2020.00650
   Martin-Brualla R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275099
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz M, 2019, Arxiv, DOI arXiv:1901.06802
   Mihajlovic M, 2021, PROC CVPR IEEE, P10456, DOI 10.1109/CVPR46437.2021.01032
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8
   Palafox P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12675, DOI 10.1109/ICCV48922.2021.01246
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Patel Chaitanya, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7363, DOI 10.1109/CVPR42600.2020.00739
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Prokudin S, 2021, IEEE WINT CONF APPL, P1809, DOI 10.1109/WACV48630.2021.00185
   Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899
   Raj A, 2021, PROC CVPR IEEE, P3721, DOI 10.1109/CVPR46437.2021.00372
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Remelli E., 2022, P ACM SIGGRAPH, P1
   Saito S, 2021, PROC CVPR IEEE, P2885, DOI 10.1109/CVPR46437.2021.00291
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Sarkar K., 2020, P EUR C COMP VIS, V12356, P596
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V., 2019, Advances in Neural Information Processing Systems, P1119
   Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tiwari G, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11688, DOI 10.1109/ICCV48922.2021.01150
   Wang Shaofei, 2021, P INT C NEUR INF PRO, V34, P2810
   Wang T.-H., 2018, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng CY, 2022, Arxiv, DOI arXiv:2201.04127
   Xiang DL, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480545
   Xiu YL, 2022, PROC CVPR IEEE, P13286, DOI 10.1109/CVPR52688.2022.01294
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   Xu H., 2021, ADV NEURAL INFORM PR, V34, P14955
   Yang JL, 2018, LECT NOTES COMPUT SC, V11211, P245, DOI 10.1007/978-3-030-01234-2_15
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng Y., 2021, P IEEE INT C COMP VI, P6239
   Zheng ZR, 2022, IEEE T PATTERN ANAL, V44, P3170, DOI 10.1109/TPAMI.2021.3050505
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
NR 79
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5478
EP 5492
DI 10.1109/TVCG.2023.3297721
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400014
PM 37478036
DA 2024-08-05
ER

PT J
AU Le Guillou, E
   Will, M
   Guillou, P
   Lukasczyk, J
   Fortin, P
   Garth, C
   Tierny, J
AF Le Guillou, Eve
   Will, Michael
   Guillou, Pierre
   Lukasczyk, Jonas
   Fortin, Pierre
   Garth, Christoph
   Tierny, Julien
TI TTK is Getting MPI-Ready
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Pipelines; Parallel processing; Data structures; Memory management;
   Topology; Clustering algorithms; Software algorithms; Topological data
   analysis; high-performance computing; distributed-memory algorithms
ID TOPOLOGICAL SIMPLIFICATION; PARALLEL COMPUTATION; ALGORITHMS; EXTRACTION
AB This system paper documents the technical foundations for the extension of the Topology ToolKit (TTK) to distributed-memory parallelism with the Message Passing Interface (MPI). While several recent papers introduced topology-based approaches for distributed-memory environments, these were reporting experiments obtained with tailored, mono-algorithm implementations. In contrast, we describe in this paper a versatile approach (supporting both triangulated domains and regular grids) for the support of topological analysis pipelines, i.e., a sequence of topological algorithms interacting together, possibly on distinct numbers of processes. While developing this extension, we faced several algorithmic and software engineering challenges, which we document in this paper. Specifically, we describe an MPI extension of TTK's data structure for triangulation representation and traversal, a central component to the global performance and generality of TTK's topological implementations. We also introduce an intermediate interface between TTK and MPI, both at the global pipeline level, and at the fine-grain algorithmic level. We provide a taxonomy for the distributed-memory topological algorithms supported by TTK, depending on their communication needs and provide examples of hybrid MPI+thread parallelizations. Detailed performance analyses show that parallel efficiencies range from 20% to 80% (depending on the algorithms), and that the MPI-specific preconditioning introduced by our framework induces a negligible computation time overhead. We illustrate the new distributed-memory capabilities of TTK with an example of advanced analysis pipeline, combining multiple algorithms, run on the largest publicly available dataset we have found (120 billion vertices) on a standard cluster with 64 nodes (for a total of 1536 cores). Finally, we provide a roadmap for the completion of TTK's MPI extension, along with generic recommendations for each algorithm communication category.
C1 [Le Guillou, Eve; Guillou, Pierre; Tierny, Julien] Sorbonne Univ, CNRS, F-75005 Paris, France.
   [Le Guillou, Eve; Will, Michael] Univ Lille, F-75005 Paris, France.
   [Fortin, Pierre] Univ Lille, CNRS, UMR 9189, Cent Lille,CRIStAL, F-59000 Lille, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique
   (CNRS); Universite de Lille; Centre National de la Recherche
   Scientifique (CNRS); Universite de Lille; Centrale Lille
RP Le Guillou, E (corresponding author), Sorbonne Univ, CNRS, F-75005 Paris, France.; Le Guillou, E (corresponding author), Univ Lille, F-75005 Paris, France.
EM eve.le_guillou@sorbonne-universite.fr; mswill@rptu.de;
   Pierre.Guillou@sorbonne-universite.fr; lukasczyk@rptu.de;
   pierre.fortin@univ-lille.fr; garth@rptu.de;
   Julien.Tierny@sorbonne-universite.fr
OI Lukasczyk, Jonas/0000-0001-6650-770X; Le Guillou,
   Eve/0009-0008-6123-2039; Will, Michael/0009-0007-1344-3694; Garth,
   Christoph/0000-0003-1669-8549; Fortin, Pierre/0000-0003-3117-9122
FU European Commission [ERC-2019-COG "TORI"]
FX No Statement Available
CR Acharya A, 2015, IEEE PAC VIS SYMP, P271, DOI 10.1109/PACIFICVIS.2015.7156387
   Ahrens J., 2005, Visualization handbook, P717, DOI DOI 10.1016/B978-012387582-2/50038-1
   Bachthaler S, 2008, IEEE T VIS COMPUT GR, V14, P1428, DOI 10.1109/TVCG.2008.119
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Bauer U., 2014, 2014 P M ALGORITHM E, P31, DOI DOI 10.1137/1.9781611973198.4
   Bauer U, 2017, J SYMB COMPUT, V78, P76, DOI 10.1016/j.jsc.2016.03.008
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Bock A, 2018, IEEE T VIS COMPUT GR, V24, P812, DOI 10.1109/TVCG.2017.2743980
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr HA, 2022, SYMP LARG DATA ANAL, P15, DOI 10.1109/LDAV57265.2022.9966394
   Carr HA, 2021, IEEE T VIS COMPUT GR, V27, P2437, DOI 10.1109/TVCG.2019.2948616
   Chazal F, 2013, J ACM, V60, DOI 10.1145/2535927
   Doraiswamy H, 2021, IEEE T VIS COMPUT GR, V27, P561, DOI 10.1109/TVCG.2020.3030441
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2004, Jacobi Sets of Multiple Morse Functions
   Edelsbrunner H., 2009, Computational Topology: An Introduction
   Edwards H. C., 2010, Tech. Rep. SAND-2010-1192
   Favelier G., 2016, P IEEE SCIVIS CONT
   Forman R., 2001, Sem. Lothar. Combin., V48
   Freudenthal H, 1942, ANN MATH, V43, P580, DOI 10.2307/1968813
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Gueunet C., 2019, P EUR S PAR GRAPH VI, P27
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Guillou P, 2024, IEEE T VIS COMPUT GR, V30, P1897, DOI 10.1109/TVCG.2023.3238008
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2016, IEEE T VIS COMPUT GR, V22, P916, DOI 10.1109/TVCG.2015.2467432
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Huang X, 2021, PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, ICS 2021, P367, DOI 10.1145/3447818.3460358
   Ibanez DA, 2016, ACM T MATH SOFTWARE, V42, DOI 10.1145/2814935
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Klacansky P., 2020, "Open scientific visualization data sets
   Klacansky P, 2017, IEEE T VIS COMPUT GR, V23, P1782, DOI 10.1109/TVCG.2016.2570215
   KUHN HW, 1960, IBM J RES DEV, V4, P518, DOI 10.1147/rd.45.0518
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Liu GX, 2024, IEEE T VIS COMPUT GR, V30, P1271, DOI 10.1109/TVCG.2023.3327182
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Maack RGC, 2024, IEEE T VIS COMPUT GR, V30, P1942, DOI 10.1109/TVCG.2023.3261981
   Maadasamy S, 2012, INT C HIGH PERFORM
   Maljovec D, 2016, IEEE PAC VIS SYMP, P64, DOI 10.1109/PACIFICVIS.2016.7465252
   Masood T. B., 2019, P TOP METH DAT AN VI, P327
   Message Passing Interface Forum, 2021, MESSAGE PASSING INTE
   Morozov D., 2014, P TOP METH DAT AN VI, VIII, P89
   Morozov D, 2016, SYMP LARG DATA ANAL, P29, DOI 10.1109/LDAV.2016.7874307
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Nauleau F, 2022, SYMP LARG DATA ANAL, P50, DOI 10.1109/LDAV57265.2022.9966403
   Nigmetov A., 2020, "Reeber: A. library for shared- and distributed-memory parallel computation of merge trees
   Nigmetov A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356188
   Olejniczak M, 2023, PHYS CHEM CHEM PHYS, V25, P5942, DOI 10.1039/d2cp05893f
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   OpenMP Architecture Review Board, 2020, "OpenMP application program interface version 5.1
   Pascucci V, 2004, ALGORITHMICA, V38, P249, DOI 10.1007/s00453-003-1052-3
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Smirnov D., 2020, P TOP METH DAT AN VI, VV, P19
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2017, IEEE T VIS COMPUT GR, V23, P960, DOI 10.1109/TVCG.2016.2599017
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P2005, DOI 10.1109/TVCG.2012.228
   TTK Contributors, 2022, "TTK online example database
   TTK Contributors, 2020, "TTK Data
   Werner K, 2021, IEEE T VIS COMPUT GR, V27, P3585, DOI 10.1109/TVCG.2021.3076875
   Zhang W., 2019, J. Open Source Softw., V4, P1370, DOI 10.21105/joss.01370
NR 67
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5875
EP 5892
DI 10.1109/TVCG.2024.3390219
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400076
PM 38630564
DA 2024-08-05
ER

PT J
AU Willett, NS
   de Goes, F
   Fleischer, K
   Meyer, M
   Burrows, C
AF Willett, Nora S.
   de Goes, Fernando
   Fleischer, Kurt
   Meyer, Mark
   Burrows, Chris
TI Stylizing Ribbons: Computing Surface Contours With Temporally Coherent
   Orientations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Cameras; Animation; Geometry; Surface
   fitting; Strips; Point cloud compression; Line work; non-photorealistic
   rendering; stylization; surface contours; silhouettes; shadow edges
AB Line work is a core element for the stylization of computer animations used by recent shows. However, existing stylization techniques are limited to edge treatments based on brush strokes or textures applied solely on top of curves. In this work, we propose new stylization effects by offering artists direct control over the inside and outside of surface contours. To this end, we introduce a method that creates ribbons, geometry strips of possibly varying width, that extrude from each side of the surface contour with temporally coherent orientations. Our contributions include the generation of spatially and temporally consistent normal orientations along visible contours and a trimming routine that converts arrangements of offset curves into ribbons free of intersections. We demonstrate the expressiveness and versatility of stylized ribbons by applying various effects on both character and shadow edges from animation sequences.
C1 [Willett, Nora S.; de Goes, Fernando; Fleischer, Kurt; Meyer, Mark; Burrows, Chris] Pixar Animat Studios Emeryville, Emeryville, CA 94608 USA.
RP Willett, NS (corresponding author), Pixar Animat Studios Emeryville, Emeryville, CA 94608 USA.
EM noraw@pixar.com; fernando@pixar.com; kurt@pixar.com; mmeyer@pixar.com;
   cburrows@pixar.com
OI de Goes, Fernando/0009-0007-7331-0674; Willett, Nora/0000-0002-3932-2758
CR Amenta N, 1998, GRAPH MODEL IM PROC, V60, P125, DOI 10.1006/gmip.1998.0465
   Asente P. J., 2010, P 7 SKETCH BAS INT M, P33
   B'enard P., 2010, International Symposium on Non-Photorealistic Animation and Rendering (NPAR), P91
   Barill G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201337
   Ben-Zvi N, 2016, COMPUT GRAPH FORUM, V35, P18, DOI 10.1111/cgf.12729
   Bénard P, 2019, FOUND TRENDS COMPUT, V11, P1, DOI 10.1561/0600000075
   Bénard P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461929
   Bénard P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2558307
   Bessmeltsev M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3202661
   Bnard P., 2012, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, P37
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Buchholz N., 2011, P S NONPH AN REND, P85
   Chlumsky V, 2018, COMPUT GRAPH FORUM, V37, P273, DOI 10.1111/cgf.13265
   Cole F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531334
   Coleman P., 2020, P ACM SIGGRAPH TALKS, P1
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   DeCarlo D, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P63
   DeCarlo Doug., 2004, P INT S NONPHOTOREAL, P15, DOI DOI 10.1145/987657.987661
   DeCoro C, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P77
   Dimian D., 2019, P ACM SIGGRAPH COMP, P1
   Docter K., 2020, Soul
   Eisemann E, 2008, COMPUT GRAPH FORUM, V27, P1199, DOI 10.1111/j.1467-8659.2008.01258.x
   Grabli S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731056
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Hertzmann A, 2020, PERCEPTION, V49, P439, DOI 10.1177/0301006620908207
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Hornung Alexander., 2006, Proceedings of the fourth Eurographics symposium on Geometry processing, SGP '06, P41, DOI DOI 10.2312/SGP/SGP06/041-050
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Hunter S., 2020, Out
   Jacobson A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461916
   Jamriska O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323006
   Jiang G., 2022, EUROGRAPHICS S RENDE
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kahrs J, 2012, Paperman
   Kalnins RD, 2003, ACM T GRAPHIC, V22, P856, DOI 10.1145/882262.882355
   Karsch K., 2011, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Non-Photorealistic Animation and Rendering, NPAR '11, P35
   Kilgard MJ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392458
   Lengyel J., 2001, P 2001 S INTERACTIVE, P227
   Lenssen Jan Eric, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11244, DOI 10.1109/CVPR42600.2020.01126
   Liu CX, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3544778
   Liu DF, 2020, PROC CVPR IEEE, P5427, DOI 10.1109/CVPR42600.2020.00547
   Liu E., 2018, ACM Trans. Graph., V37, P1
   Liu M., 2021, P IEEE CVF INT C COM
   Liu XT, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818067
   Metzer G, 2021, Arxiv, DOI arXiv:2105.01604
   Müller AC, 2014, J MACH LEARN RES, V15, P2055
   Mullen P, 2010, COMPUT GRAPH FORUM, V29, P1733, DOI 10.1111/j.1467-8659.2010.01782.x
   Nehab D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392392
   Northrup J. D., 2000, P 1 INT S NONPH AN R, P31, DOI [10.1145/340916.340920, DOI 10.1145/340916.340920]
   Pablos S., 2019, Klaus
   Persichetti P. Ramsey, 2018, Spider-Man: Into the Spider-Verse
   Postolski M, 2014, COMPUT VIS IMAGE UND, V129, P89, DOI 10.1016/j.cviu.2014.07.003
   Simo-Serra E, 2016, ACM T GRAPH, V35, P1, DOI DOI 10.1145/2897824.2925972
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Todo H, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276399
   Whited E., 2012, ACM SIGGRAPH TALKS, P1
   Zheng M., 2017, P S NONPH AN REND, P1
NR 57
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5623
EP 5634
DI 10.1109/TVCG.2023.3304641
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400096
PM 37578913
OA hybrid
DA 2024-08-05
ER

PT J
AU Martin-Gomez, A
   Li, HW
   Song, TY
   Yang, S
   Wang, GZ
   Ding, H
   Navab, N
   Zhao, Z
   Armand, M
AF Martin-Gomez, Alejandro
   Li, Haowei
   Song, Tianyu
   Yang, Sheng
   Wang, Guangzhi
   Ding, Hui
   Navab, Nassir
   Zhao, Zhe
   Armand, Mehran
TI STTAR: Surgical Tool Tracking Using Off-the-Shelf Augmented Reality
   Head-Mounted Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; computer-assisted medical procedures; navigation;
   tracking
AB The use of Augmented Reality (AR) for navigation purposes has shown beneficial in assisting physicians during the performance of surgical procedures. These applications commonly require knowing the pose of surgical tools and patients to provide visual information that surgeons can use during the performance of the task. Existing medical-grade tracking systems use infrared cameras placed inside the Operating Room (OR) to identify retro-reflective markers attached to objects of interest and compute their pose. Some commercially available AR Head-Mounted Displays (HMDs) use similar cameras for self-localization, hand tracking, and estimating the objects' depth. This work presents a framework that uses the built-in cameras of AR HMDs to enable accurate tracking of retro-reflective markers without the need to integrate any additional electronics into the HMD. The proposed framework can simultaneously track multiple tools without having previous knowledge of their geometry and only requires establishing a local network between the headset and a workstation. Our results show that the tracking and detection of the markers can be achieved with an accuracy of 0.09 +/- 0.06 mm on lateral translation, 0.42 +/- 0.32 mm on longitudinal translation and 0.80 +/- 0.39(degrees) for rotations around the vertical axis. Furthermore, to showcase the relevance of the proposed framework, we evaluate the system's performance in the context of surgical procedures. This use case was designed to replicate the scenarios of k-wire insertions in orthopedic procedures. For evaluation, seven surgeons were provided with visual navigation and asked to perform 24 injections using the proposed framework. A second study with ten participants served to investigate the capabilities of the framework in the context of more general scenarios. Results from these studies provided comparable accuracy to those reported in the literature for AR-based navigation procedures.
C1 [Martin-Gomez, Alejandro; Armand, Mehran] Johns Hopkins Univ, Whiting Sch Engn, Lab Computat Sensing & Robot, Baltimore, MD 21218 USA.
   [Armand, Mehran] Johns Hopkins Univ, Sch Med, Dept Orthopaed Surg, Baltimore, MD 21205 USA.
   [Li, Haowei; Yang, Sheng; Wang, Guangzhi; Ding, Hui] Tsinghua Univ, Dept Biomed Engn, Beijing 100190, Peoples R China.
   [Song, Tianyu; Zhao, Zhe] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Dept Orthopaed, Beijing 100190, Peoples R China.
   [Song, Tianyu; Navab, Nassir; Zhao, Zhe] Tech Univ Munich, Chair Comp Aided Med Procedures & Augmented Real, Dept Informat, D-80333 Munich, Germany.
C3 Johns Hopkins University; Johns Hopkins University; Tsinghua University;
   Tsinghua University; Technical University of Munich
RP Martin-Gomez, A (corresponding author), Johns Hopkins Univ, Whiting Sch Engn, Lab Computat Sensing & Robot, Baltimore, MD 21218 USA.
EM alejandro.martin@jhu.edu; lihaowei19991202@gmail.com;
   tianyu.song@tum.de; yangs19@mails.tsinghua.edu.cn;
   wgz-dea@tsinghua.edu.cn; dinghui@tsinghua.edu.cn; nassir.navab@tum.de;
   zhaozhao_02@163.com; mehran.armand@jhuapl.edu
OI Wang, Guangzhi/0000-0002-4677-1041; Song, Tianyu/0000-0002-8428-9651;
   Martin-Gomez, Alejandro/0000-0001-9341-3477; haowei,
   li/0000-0001-6558-1369; Armand, Mehran/0000-0003-1028-8303; Yang,
   Sheng/0000-0001-9901-7512
FU National Institutes of Health [R01-EB023939, R01-EB016703,
   R01-AR080315]; National Natural Science Foundation of China [U20A20389];
   Tsinghua University Initiative Scientific Research Program
   [20197010009]; Laboratory Innovation Fund of Tsinghua University
FX This work was supported by the National Institutes of Health under
   Grants R01-EB023939, R01-EB016703, and R01-AR080315, in part by the
   National Natural Science Foundation of China under Grant U20A20389,in
   part by the Tsinghua University Initiative Scientific Research Program
   under Grant 20197010009, and in part by the Laboratory Innovation Fund
   of Tsinghua University.
CR Andress S, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021209
   Casari FA, 2021, CURR REV MUSCULOSKE, V14, P192, DOI 10.1007/s12178-021-09699-3
   Desh G., 2018, J. Neurointerventional Surg., V10, P1187
   Fida B, 2018, UPDATES SURG, V70, P389, DOI 10.1007/s13304-018-0567-8
   Fotouhi J, 2021, IEEE T MED IMAGING, V40, P765, DOI 10.1109/TMI.2020.3037013
   Fotouhi J, 2019, INT J COMPUT ASS RAD, V14, P913, DOI 10.1007/s11548-019-01943-z
   Fotouhi J, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021205
   Gibby JT, 2019, INT J COMPUT ASS RAD, V14, P525, DOI 10.1007/s11548-018-1814-7
   Gsaxner C, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489863
   Jud L, 2020, BMC MUSCULOSKEL DIS, V21, DOI 10.1186/s12891-020-3110-2
   Kamphuis C, 2014, PERSPECT MED EDUC, V3, P300, DOI 10.1007/s40037-013-0107-7
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kunz C., 2020, Curz Directions Riomeil. Fing, V6
   Lahini M.S., 2019, P INT C INT COMPN, P716
   Li E. H., 2020, Augmented Reality in Education. A New Technology for Teaching and Learning, P111, DOI DOI 10.1007/978-3-030-42156-47
   Liebmann F, 2019, INT J COMPUT ASS RAD, V14, P1157, DOI 10.1007/s11548-019-01973-7
   Liu H, 2018, ANN BIOMED ENG, V46, P1595, DOI 10.1007/s10439-018-2055-1
   Martin-Gomez A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P735, DOI [10.1109/VR.2019.8798135, 10.1109/vr.2019.8798135]
   Mehrfard A, 2021, COMP M BIO BIO E-IV, V9, P233, DOI 10.1080/21681163.2020.1835559
   Molina CA, 2019, J NEUROSURG-SPINE, V31, P139, DOI 10.3171/2018.12.SPINE181142
   Müller F, 2020, SPINE J, V20, P621, DOI 10.1016/j.spinee.2019.10.012
   Ortega G, 2008, ARCH ORTHOP TRAUM SU, V128, P1123, DOI 10.1007/s00402-007-0500-y
   Peters T.M., 2018, Mixed and Augmented Reality in Medicine, DOI DOI 10.1201/9781315157702
   Rahman R, 2020, SURG INNOV, V27, P88, DOI 10.1177/1553350619871787
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Spirig JM, 2021, EUR SPINE J, V30, P3731, DOI 10.1007/s00586-021-06950-w
   Ungureanu D, 2020, Arxiv, DOI [arXiv:2008.11239, DOI 10.48550/ARXIV.2008.11239]
   Viehöfer AF, 2020, BMC MUSCULOSKEL DIS, V21, DOI 10.1186/s12891-020-03373-4
   Yoon JW, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1770
NR 29
TC 7
Z9 7
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3578
EP 3593
DI 10.1109/TVCG.2023.3238309
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700040
PM 37021885
OA Green Accepted, Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Qu, LZ
   Shang, JX
   Han, XG
   Fu, HB
AF Qu, Linzi
   Shang, Jiaxiang
   Han, Xiaoguang
   Fu, Hongbo
TI ReenactArtFace: Artistic Face Image Reenactment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Three-dimensional displays; Image reconstruction; Videos;
   Geometry; Generators; Fitting; 3DMM; artistic faces; face reenactment;
   generative models
AB Large-scale datasets and deep generative models have enabled impressive progress in human face reenactment. Existing solutions for face reenactment have focused on processing real face images through facial landmarks by generative models. Different from real human faces, artistic human faces (e.g., those in paintings, cartoons, etc.) often involve exaggerated shapes and various textures. Therefore, directly applying existing solutions to artistic faces often fails to preserve the characteristics of the original artistic faces (e.g., face identity and decorative lines along face contours) due to the domain gap between real and artistic faces. To address these issues, we present ReenactArtFace, the first effective solution for transferring the poses and expressions from human videos to various artistic face images. We achieve artistic face reenactment in a coarse-to-fine manner. First, we perform 3D artistic face reconstruction, which reconstructs a textured 3D artistic face through a 3D morphable model (3DMM) and a 2D parsing map from an input artistic image. The 3DMM can not only rig the expressions better than facial landmarks but also render images under different poses/expressions as coarse reenactment results robustly. However, these coarse results suffer from self-occlusions and lack contour lines. Second, we thus perform artistic face refinement by using a personalized conditional adversarial generative model (cGAN) fine-tuned on the input artistic image and the coarse reenactment results. For high-quality refinement, we propose a contour loss to supervise the cGAN to faithfully synthesize contour lines. Quantitative and qualitative experiments demonstrate that our method achieves better results than the existing solutions.
C1 [Qu, Linzi; Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
   [Shang, Jiaxiang] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Han, Xiaoguang] Chinese Univ Hong Kong, SSE, Shenzhen 518172, Peoples R China.
C3 City University of Hong Kong; Hong Kong University of Science &
   Technology; The Chinese University of Hong Kong, Shenzhen
RP Fu, HB (corresponding author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
EM linziqu2-c@my.cityu.edu.hk; jshang@cse.ust.hk; hanxiaoguang@cuhk.edu.cn;
   hongbofu@cityu.edu.hk
OI Qu, Linzi/0000-0002-8731-5501; FU, Hongbo/0000-0002-0284-726X; Han,
   Xiaoguang/0000-0003-0162-3296; Shang, Jiaxiang/0000-0001-7161-9765
FU Adobe; Centre for Applied Computing and Interactive Media (ACIM) of the
   School of Creative Media, City University of Hong Kong
FX This work was supported by unrestricted gifts from Adobe and the Centre
   for Applied Computing and Interactive Media (ACIM) of the School of
   Creative Media, City University of Hong Kong.
CR Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Burkov E., 2020, P IEEE CVF C COMP VI, P13786
   Chen AP, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3470848
   Chen C. Wang, 2020, P IEEE CVF C COMP VI, P13518
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741
   Fiser J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073660
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Futschik D, 2021, COMPUT GRAPH FORUM, V40, P563, DOI 10.1111/cgf.142655
   Gecer B, 2021, PROC CVPR IEEE, P7624, DOI 10.1109/CVPR46437.2021.00754
   Goodfellow I., 2014, Adv. NeuralInf. Process. Syst., V2
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   Heusel H., 2017, inProc. Adv. Neural Inf. Process. Syst., V45
   Huang PH, 2020, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR42600.2020.00711
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jiaxiang Shang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P53, DOI 10.1007/978-3-030-58555-6_4
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Lin YM, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104190
   Lipman Y., 2004, P 2004 EUROGRAPHICSA, P175, DOI DOI 10.1145/1057432.1057456
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Lu YX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480484
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nagano K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356568
   Nagrani A, 2018, Arxiv, DOI [arXiv:1706.08612, DOI 10.21437/INTERSPEECH.2017-950]
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rao S., 2020, Proc. SIGGRAPH Asia Posters, P1
   Ren YR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13739, DOI 10.1109/ICCV48922.2021.01350
   Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968
   Siarohin A, 2021, PROC CVPR IEEE, P13648, DOI 10.1109/CVPR46437.2021.01344
   Siarohin S., 2019, Adv. Neural Inf. Process.Syst.
   Sun P, 2021, Arxiv, DOI arXiv:2011.00269
   Texler A, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451270
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tripathy S, 2021, IEEE WINT CONF APPL, P1328, DOI 10.1109/WACV48630.2021.00137
   Tu XG, 2022, IEEE T CIRC SYST VID, V32, P1805, DOI 10.1109/TCSVT.2021.3083257
   Wang D., 2022, arXiv
   Wang TC, 2021, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR46437.2021.00991
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Yaniv J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322984
   Yao GM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1773, DOI 10.1145/3394171.3413865
   Zakharov Egor, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P524, DOI 10.1007/978-3-030-58610-2_31
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang JN, 2020, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR42600.2020.00537
   Zhang Y.., 2019, arXiv
   Zhou H, 2020, PROC CVPR IEEE, P5910, DOI 10.1109/CVPR42600.2020.00595
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 53
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4080
EP 4092
DI 10.1109/TVCG.2023.3253184
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700001
PM 37028041
DA 2024-08-05
ER

PT J
AU Ramirez, JR
   Rautek, P
   Bohak, C
   Strnad, O
   Zhang, ZY
   Li, S
   Viola, I
   Heidrich, W
AF Ramirez, Julio Rey
   Rautek, Peter
   Bohak, Ciril
   Strnad, Ondrej
   Zhang, Zheyuan
   Li, Sai
   Viola, Ivan
   Heidrich, Wolfgang
TI GPU Accelerated 3D Tomographic Reconstruction and Visualization From
   Noisy Electron Microscopy Tilt-Series
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image reconstruction; Noise reduction; Uncertainty; Three-dimensional
   displays; Iterative methods; Visualization; Electron microscopy;
   Cryo-ET; electron tomography; GPU acceleration; tilt-series; tomographic
   reconstruction; visualization
ID ALGEBRAIC RECONSTRUCTION; IMAGE-RECONSTRUCTION; UNCERTAINTY
   VISUALIZATION; PLATFORM; ART
AB We present a novel framework for 3D tomographic reconstruction and visualization of tomograms from noisy electron microscopy tilt-series. Our technique takes as an input aligned tilt-series from cryogenic electron microscopy and creates denoised 3D tomograms using a proximal jointly-optimized approach that iteratively performs reconstruction and denoising, relieving the users of the need to select appropriate denoising algorithms in the pre-reconstruction or post-reconstruction steps. The whole process is accelerated by exploiting parallelism on modern GPUs, and the results can be visualized immediately after the reconstruction using volume rendering tools incorporated in the framework. We show that our technique can be used with multiple combinations of reconstruction algorithms and regularizers, thanks to the flexibility provided by proximal algorithms. Additionally, the reconstruction framework is open-source and can be easily extended with additional reconstruction and denoising methods. Furthermore, our approach enables visualization of reconstruction error throughout the iterative process within the reconstructed tomogram and on projection planes of the input tilt-series. We evaluate our approach in comparison with state-of-the-art approaches and additionally show how our error visualization can be used for reconstruction evaluation.
C1 [Ramirez, Julio Rey; Rautek, Peter; Bohak, Ciril; Strnad, Ondrej; Viola, Ivan; Heidrich, Wolfgang] King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal 23955, Saudi Arabia.
   [Zhang, Zheyuan; Li, Sai] Tsinghua Univ, Sch Life Sci, Beijing 100084, Peoples R China.
C3 King Abdullah University of Science & Technology; Tsinghua University
RP Ramirez, JR (corresponding author), King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal 23955, Saudi Arabia.
EM julio.reyramirez@kaust.edu.sa; peter.rautek@kaust.edu.sa;
   ciril.bohak@kaust.edu.sa; ondrej.strnad@kaust.edu.sa;
   zheyuanzhang@tsinghua.edu.cn; sai@tsinghua.edu.cn;
   ivan.viola@kaust.edu.sa; wolfgang.heidrich@kaust.edu.sa
RI Li, Sai/AAC-5187-2019; Viola, Ivan/O-8944-2014
OI Li, Sai/0000-0002-9353-0355; Heidrich, Wolfgang/0000-0002-4227-8508;
   Strnad, Ondrej/0000-0002-8077-4692; Viola, Ivan/0000-0003-4248-6574
FU King Abdullah University of Science and Technology through a Competitive
   Research Grant (CRG); VCC Center Competitive Funding (CCF)
   [BAS/1/1680-01-01]; Tsinghua University Spring Breeze Fund
   [2021Z99CFZ004]; National Natural Science Foundation of China [32171195]
FX This work was supported in part by the King Abdullah University of
   Science and Technology through a Competitive Research Grant (CRG), in
   part by the VCC Center Competitive Funding (CCF) under Grant
   BAS/1/1680-01-01, in part by the Tsinghua University Spring Breeze Fund
   under Grant 2021Z99CFZ004, and in part by the National Natural Science
   Foundation of China under Grant 32171195.
CR ANDERSEN AH, 1984, ULTRASONIC IMAGING, V6, P81, DOI 10.1016/0161-7346(84)90008-7
   ANDERSEN AH, 1989, IEEE T MED IMAGING, V8, P50, DOI 10.1109/42.20361
   Appel A., 1968, Proceedings of the April 30-May 2, 1968, spring joint computer conference, P37, DOI DOI 10.1145/1468075.1468082
   Bailey D.L., 2005, Posi- tron Emission Tomography, V2
   Bepler T, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18952-1
   Böhning J, 2022, STRUCTURE, V30, P408, DOI 10.1016/j.str.2021.12.010
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3
   BRACEWELL RN, 1967, ASTROPHYS J, V150, P427, DOI 10.1086/149346
   Brodlie K, 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [DOI 10.1007/978-1-4471-2804-56, 10.1007/978-1-4471-2804-5_6, DOI 10.1007/978-1-4471-2804-5_6]
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Budinger T. F., 1979, Image reconstruction from projections. Implementation and applications, P147
   Dinesha V, 2012, VISUAL COMPUT, V28, P265, DOI 10.1007/s00371-011-0614-7
   Ding GL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49267-x
   Donati L., 2020, PhD Thesis
   FELDKAMP LA, 1984, J OPT SOC AM A, V1, P612, DOI 10.1364/JOSAA.1.000612
   Frangakis AS, 2021, J STRUCT BIOL, V213, DOI 10.1016/j.jsb.2021.107804
   Frikel J, 2013, APPL COMPUT HARMON A, V34, P117, DOI 10.1016/j.acha.2012.03.005
   GILBERT P, 1972, J THEOR BIOL, V36, P105, DOI 10.1016/0022-5193(72)90180-4
   Gillmann C, 2021, COMPUT GRAPH FORUM, V40, P665, DOI 10.1111/cgf.14333
   GORDON R, 1970, J THEOR BIOL, V29, P471, DOI 10.1016/0022-5193(70)90109-8
   Goris B, 2013, ULTRAMICROSCOPY, V127, P40, DOI 10.1016/j.ultramic.2012.07.003
   Gürsoy D, 2014, J SYNCHROTRON RADIAT, V21, P1188, DOI 10.1107/S1600577514013939
   Han RM, 2017, J STRUCT BIOL, V199, P196, DOI 10.1016/j.jsb.2017.07.008
   Hansen PC, 2018, NUMER ALGORITHMS, V79, P107, DOI 10.1007/s11075-017-0430-x
   Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661260
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Hsieh, 2015, COMPUT TOMOGR, DOI DOI 10.1117/3.2197756
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Huettel S. A., 2014, Functional Magnetic Resonance Imaging, V1
   Iudin A, 2016, NAT METHODS, V13, P387, DOI 10.1038/nmeth.3806
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Kak A. C., 1988, Principles of computerized tomographic imaging, DOI 10.1118/1.1455742
   Kak A. C., 2001, Principles of computerized tomo- graphic imaging, P37
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Kniss JM, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P287
   Kremer JR, 1996, J STRUCT BIOL, V116, P71, DOI 10.1006/jsbi.1996.0013
   Kuba J, 2021, J MICROSC-OXFORD, V281, P112, DOI 10.1111/jmi.12939
   Li S, 2022, TRENDS BIOCHEM SCI, V47, P173, DOI 10.1016/j.tibs.2021.08.005
   Lindholm S, 2010, IEEE T VIS COMPUT GR, V16, P1301, DOI 10.1109/TVCG.2010.195
   Liu YT, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33957-8
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Nguyen T. K., 2010, P IEEE EG 8 INT S VO, P53, DOI DOI 10.2312/VG/VG10/053-060
   Ni T, 2022, NAT PROTOC, V17, P421, DOI 10.1038/s41596-021-00648-5
   Noo F, 2002, PHYS MED BIOL, V47, P2525, DOI 10.1088/0031-9155/47/14/311
   Ollinger JM, 1997, IEEE SIGNAL PROC MAG, V14, P43, DOI 10.1109/79.560323
   Palovcak E, 2020, IUCRJ, V7, P1142, DOI 10.1107/S2052252520013184
   Parikh N., 2014, Found. Trends Opt., V1, P127, DOI 10.1561/2400000003
   Pyle E, 2021, BIOCHEM J, V478, P1827, DOI 10.1042/BCJ20200715
   Radermacher M., 1992, Electron Tomography, P245
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sorzano COS, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/6482567
   STEARNS CW, 1987, IEEE T NUCL SCI, V34, P374, DOI 10.1109/TNS.1987.4337366
   Su M., 2018, Generative adversarial networks as a tool to recover structural information from cryo-electron microscopy data
   Suetens P, 2017, FUNDAMENTALS OF MEDICAL IMAGING, 3RD EDITION, P1, DOI 10.1017/9781316671849
   Trampert P, 2018, ULTRAMICROSCOPY, V191, P1, DOI 10.1016/j.ultramic.2018.04.001
   Trifonov Borislav., 2006, EUROGRAPHICS S RENDE, P51
   Turk M, 2020, FEBS LETT, V594, P3243, DOI 10.1002/1873-3468.13948
   van Aarle W, 2016, OPT EXPRESS, V24, P25129, DOI 10.1364/OE.24.025129
   van Aarle W, 2015, ULTRAMICROSCOPY, V157, P35, DOI 10.1016/j.ultramic.2015.05.002
   Veach E., 1998, ROBUST MONTE CARLO M, pAAI9837162
   Venkatakrishnan SV, 2015, IEEE TRANS COMPUT IM, V1, P1, DOI 10.1109/TCI.2014.2371751
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang G, 2018, IEEE T MED IMAGING, V37, P1289, DOI 10.1109/TMI.2018.2833635
   Wang TH, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.4.043504
   Westover L. A., 1991, Splatting: A parallel, feed-forward volume ren- dering algorithm
   Würfl T, 2018, IEEE T MED IMAGING, V37, P1454, DOI 10.1109/TMI.2018.2833499
   Xu JQ, 2019, INVERSE PROBL, V35, DOI 10.1088/1361-6420/ab08f9
   Xue L, 2022, NATURE, V610, P205, DOI 10.1038/s41586-022-05255-2
   Yan R, 2019, J STRUCT BIOL, V206, P183, DOI 10.1016/j.jsb.2019.03.002
   Yao HP, 2020, CELL, V183, P730, DOI 10.1016/j.cell.2020.09.018
   Zang GM, 2018, LECT NOTES COMPUT SC, V11220, P145, DOI 10.1007/978-3-030-01270-0_9
NR 72
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3331
EP 3345
DI 10.1109/TVCG.2022.3230445
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700037
PM 37015451
OA hybrid
DA 2024-08-05
ER

PT J
AU Wong, KK
   Wang, XB
   Wang, Y
   He, JB
   Zhang, R
   Qu, HM
AF Wong, Kam Kwai
   Wang, Xingbo
   Wang, Yong
   He, Jianben
   Zhang, Rong
   Qu, Huamin
TI Anchorage: Visual Analysis of Satisfaction in Customer Service Videos
   Via Anchor Events
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Videos; Customer services; Behavioral sciences; Customer satisfaction;
   Visual analytics; Visualization; Data visualization; video data; video
   visualization; visual analytics
ID EMOTIONS; FUTURE
AB Delivering customer services through video communications has brought new opportunities to analyze customer satisfaction for quality management. However, due to the lack of reliable self-reported responses, service providers are troubled by the inadequate estimation of customer services and the tedious investigation into multimodal video recordings. We introduce Anchorage, a visual analytics system to evaluate customer satisfaction by summarizing multimodal behavioral features in customer service videos and revealing abnormal operations in the service process. We leverage the semantically meaningful operations to introduce structured event understanding into videos which help service providers quickly navigate to events of their interest. Anchorage supports a comprehensive evaluation of customer satisfaction from the service and operation levels and efficient analysis of customer behavioral dynamics via multifaceted visualization views. We extensively evaluate Anchorage through a case study and a carefully-designed user study. The results demonstrate its effectiveness and usability in assessing customer satisfaction using customer service videos. We found that introducing event contexts in assessing customer satisfaction can enhance its performance without compromising annotation precision. Our approach can be adapted in situations where unlabelled and unstructured videos are collected along with sequential records.
C1 [Wong, Kam Kwai; Wang, Xingbo; He, Jianben; Zhang, Rong; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wang, Yong] Singapore Management Univ, Singapore 178902, Singapore.
C3 Hong Kong University of Science & Technology; Singapore Management
   University
RP Wang, Y (corresponding author), Singapore Management Univ, Singapore 178902, Singapore.
EM kkwongar@connect.ust.hk; xingbo.wang@connect.ust.hk;
   yongwang@smu.edu.sg; jhebt@connect.ust.hk; rzhangab@connect.ust.hk;
   huamin@cse.ust.hk
OI Wang, Xingbo/0000-0001-5693-1128; WONG, Kam Kwai/0000-0002-2813-1972
FU  [FSUST19-CWB09]
FX This work was supported in part by under grant FSUST19-CWB09.
CR Al-Otaibi S, 2018, INT J ADV COMPUT SC, V9, P106
   Ando A, 2020, IEEE-ACM T AUDIO SPE, V28, P715, DOI 10.1109/TASLP.2020.2966857
   [Anonymous], 2018, ISO 10004: 2018
   Blascheck T, 2016, IEEE CONF VIS ANAL, P141, DOI 10.1109/VAST.2016.7883520
   Bredin H, 2020, INT CONF ACOUST SPEE, P7124, DOI [10.1109/ICASSP40776.2020.9052974, 10.1109/icassp40776.2020.9052974]
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Chen D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3002
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Cheshin A, 2018, ORGAN BEHAV HUM DEC, V144, P97, DOI 10.1016/j.obhdp.2017.10.002
   de Pinto MG, 2020, IEEE CONF EVOL ADAPT, DOI 10.1109/eais48028.2020.9122698
   Deng D., 2021, P CHI C HUM FACT COM
   Generosi A, 2018, IEEE I C CONS ELECT
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Guo SN, 2022, IEEE T VIS COMPUT GR, V28, P4531, DOI 10.1109/TVCG.2021.3093585
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Höferlin B, 2015, INFORM VISUAL, V14, P10, DOI 10.1177/1473871613488571
   Kumar S, 2019, INFORM FUSION, V52, P41, DOI 10.1016/j.inffus.2018.11.001
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Liljander V, 1997, INT J SERV IND MANAG, V8, P148, DOI 10.1108/09564239710166272
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Liu Z. X., 2019, Design, User Experience, and Usability. Practice and Case Studies, P183
   Liu ZC, 2017, COMPUT GRAPH FORUM, V36, P527, DOI 10.1111/cgf.13208
   Lou J, 2010, PROTEIN ENG DES SEL, V23, P311, DOI 10.1093/protein/gzq001
   Ma CX, 2020, J COMPUT SCI TECH-CH, V35, P576, DOI 10.1007/s11390-020-0271-2
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   McDuff D, 2015, IEEE T AFFECT COMPUT, V6, P223, DOI 10.1109/TAFFC.2014.2384198
   McDuff D, 2012, IEEE T AFFECT COMPUT, V3, P456, DOI 10.1109/T-AFFC.2012.19
   Morrow B, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P1, DOI [10.1109/VISUAL.2019.8933582, 10.1109/visual.2019.8933582]
   Nguyen PH, 2019, IEEE T VIS COMPUT GR, V25, P2838, DOI 10.1109/TVCG.2018.2859969
   Oliver R. L., 2010, Satisfaction: A Behavioral Perspective on the Consumer, V2nd, P2
   Park Y., 2009, P 18 ACM C INF KNOWL, P1387, DOI 10.1145/1645953.1646128
   Peterson R.A., 1992, Journal of the Academy of Marketing Science, V20, P61, DOI DOI 10.1007/BF02723476
   Polack PJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3152888
   Liang PP, 2022, Arxiv, DOI arXiv:2207.00056
   Qi D., 2021, arXiv
   González-Rodríguez MR, 2020, TELEMAT INFORM, V51, DOI 10.1016/j.tele.2020.101404
   Saberi M, 2017, BUS PROCESS MANAG J, V23, P574, DOI 10.1108/BPMJ-02-2015-0018
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   See A, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P1
   Seng KP, 2018, IEEE T HUM-MACH SYST, V48, P266, DOI 10.1109/THMS.2017.2695613
   Shi CL, 2014, IEEE T VIS COMPUT GR, V20, P1733, DOI 10.1109/TVCG.2014.2346912
   Slim M, 2018, INT MULTICONF SYST, P502, DOI 10.1109/SSD.2018.8570588
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Sugianto N., 2018, P IEEE 15 INT C ADV, P1
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tronvoll B, 2011, J SERV MANAGE, V22, P111, DOI 10.1108/09564231111106947
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang XB, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376726
   Wong A., 2004, Managing Service Quality: An International Journal, V14, P365
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Xu W, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P117
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118
   Ye N., 2000, P IEEE SYST MAN CYB
   Yeshchenko A, 2022, IEEE T VIS COMPUT GR, V28, P3050, DOI 10.1109/TVCG.2021.3050071
   Yolcu G, 2020, J AMB INTEL HUM COMP, V11, P237, DOI 10.1007/s12652-019-01310-5
   Zeng HP, 2023, IEEE T VIS COMPUT GR, V29, P3685, DOI 10.1109/TVCG.2022.3169175
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang Q, 2020, MARKET SCI, V39, P285, DOI 10.1287/mksc.2019.1215
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhou JH, 2023, IEEE T VIS COMPUT GR, V29, P809, DOI 10.1109/TVCG.2022.3209391
NR 68
TC 2
Z9 2
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4008
EP 4022
DI 10.1109/TVCG.2023.3245609
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700092
PM 37027780
OA Green Submitted, Green Accepted
DA 2024-08-05
ER

PT J
AU Yang, SP
   Zhao, YL
   Luo, YZ
   Wang, H
   Sun, HY
   Li, C
   Cai, BH
   Jin, XG
AF Yang, Sipeng
   Zhao, Yunlu
   Luo, Yuzhe
   Wang, He
   Sun, Hongyu
   Li, Chen
   Cai, Binghuang
   Jin, Xiaogang
TI MNSS: Neural Supersampling Framework for Real-Time Rendering on Mobile
   Devices
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Real-time systems; Image reconstruction;
   Image resolution; Videos; Artificial intelligence; Neural networks; Deep
   learning; neural supersampling; real-time rendering
ID IMAGE SUPERRESOLUTION; QUALITY ASSESSMENT
AB Although neural supersampling has achieved great success in various applications for improving image quality, it is still difficult to apply it to a wide range of real-time rendering applications due to the high computational power demand. Most existing methods are computationally expensive and require high-performance hardware, preventing their use on platforms with limited hardware, such as smartphones. To this end, we propose a new supersampling framework for real-time rendering applications to reconstruct a high-quality image out of a low-resolution one, which is sufficiently lightweight to run on smartphones within a real-time budget. Our model takes as input the renderer-generated low resolution content and produces high resolution and anti-aliased results. To maximize sampling efficiency, we propose using an alternate sub-pixel sample pattern during the rasterization process. This allows us to create a relatively small reconstruction model while maintaining high image quality. By accumulating new samples into a high-resolution history buffer, an efficient history check and re-usage scheme is introduced to improve temporal stability. To our knowledge, this is the first research in pushing real-time neural supersampling on mobile devices. Due to the absence of training data, we present a new dataset containing 57 training and test sequences from three game scenes. Furthermore, based on the rendered motion vectors and a visual perception study, we introduce a new metric called inter-frame structural similarity (IF-SSIM) to quantitatively measure the temporal stability of rendered videos. Extensive evaluations demonstrate that our supersampling model outperforms existing or alternative solutions in both performance and temporal stability.
C1 [Yang, Sipeng; Zhao, Yunlu; Luo, Yuzhe; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Wang, He] Univ Leeds, Sch Comp, Leeds LS2 9JT, England.
   [Sun, Hongyu; Li, Chen; Cai, Binghuang] OPPO US Res Ctr, Bellevue, WA 98005 USA.
C3 Zhejiang University; University of Leeds
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM 12121024@zju.edu.cn; yunlu.zhao@zju.edu.cn; 22221149@zju.edu.cn;
   realcrane@gmail.com; dr.sunhongyu@gmail.com; chenlixyz@gmail.com;
   bhcai8@gmail.com; jin@cad.zju.edu.cn
OI Wang, He/0000-0002-2281-5679; Sun, Hongyu/0009-0002-4118-4777; Jin,
   Xiaogang/0000-0001-7339-2920; Luo, Yuzhe/0009-0008-5796-6144
FU Key R#x0026;D Program of Zhejiang [2023C01047]; National Natural Science
   Foundation of China [62036010, 61972344]
FX This work was supported in part by Key R&D Program of Zhejiang under
   Grant 2023C01047, and in part by the National Natural Science Foundation
   of China under Grants 62036010, 61972344.
CR Akeley K., 1993, Computer Graphics Proceedings, P109, DOI 10.1145/166117.166131
   AMD, 2022, Fidelityfx super resolution 2.0
   AMD, 2021, Fidelityfx super resolution
   Aydin TO, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866187
   Barten PGJ, 2004, P SOC PHOTO-OPT INS, V5294, P231, DOI 10.1117/12.537476
   Blackwell H. R., 1972, Visual Psychophysics, P78
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Chan KCK, 2021, PROC CVPR IEEE, P4945, DOI 10.1109/CVPR46437.2021.00491
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Damera-Venkata N, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477935
   Deore M., 2017, Hexagon DSP CPU offload
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Dou H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1891, DOI 10.1145/3394171.3413590
   Dunham I, 2012, NATURE, V489, P57, DOI 10.1038/nature11247
   Edelsten A., 2019, P GAM DEV C
   El Mansouri J. E., 2016, P GAM DEV C
   Fuoli D, 2019, IEEE INT CONF COMP V, P3476, DOI 10.1109/ICCVW.2019.00431
   Games E., 2021, Unreal engine 4.27: Screen percentage with temporal upsam- ple
   Guo J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480531
   Guo J, 2017, AAAI CONF ARTIF INTE, P4053
   HOBBY JD, 1990, ACM T GRAPHIC, V9, P262, DOI 10.1145/78964.78966
   Huang Y, 2015, ADV NEUR IN, V28
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jimenez J, 2012, COMPUT GRAPH FORUM, V31, P355, DOI 10.1111/j.1467-8659.2012.03014.x
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karis B., 2014, P ADV REAL TIM REND, V1, P1
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim SY, 2019, IEEE IMAGE PROC, P2831, DOI [10.1109/ICIP.2019.8803297, 10.1109/icip.2019.8803297]
   Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu E., 2020, P GPU TECHN C
   Liu HY, 2022, Arxiv, DOI arXiv:2007.12928
   Liu SL, 2021, IEEE COMPUT SOC CONF, P2480, DOI 10.1109/CVPRW53098.2021.00281
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x
   Mueller JH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3446790
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Poynton C, 2012, DIGITAL VIDEO AND HD: ALGORITHMS AND INTERFACES, 2ND EDITION, P1
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Thomas MM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417786
   U. Technologies, 2005, Unity engine
   Vaidyanathan K., 2014, P HIGH PERF GRAPH, P9
   Wang LD, 2018, IEEE ENG MED BIO, P514, DOI 10.1109/EMBC.2018.8512300
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wei XY, 2021, Arxiv, DOI arXiv:2108.06915
   Xiao L, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392376
   Yang L, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.14018
   Yang L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618481
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P1500, DOI 10.1109/LSP.2020.3013518
   Zeng Z, 2021, COMPUT GRAPH FORUM, V40, P79, DOI 10.1111/cgf.142616
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 58
TC 1
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4271
EP 4284
DI 10.1109/TVCG.2023.3259141
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700089
PM 37030766
DA 2024-08-05
ER

PT J
AU Li, JC
   Lai, CF
   Zhang, H
   Yuan, XR
AF Li, Jincheng
   Lai, Chufan
   Zhang, Hai
   Yuan, Xiaoru
TI PM-Vis: A Visual Analytics System for Tracing and Analyzing the
   Evolution of Pottery Motifs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Spatiotemporal phenomena; Urban
   areas; Documentation; Visual analytics; Semantics; Pottery motif
   evolution analysis; image analysis; spatial-temporal analysis; visual
   analytics
ID VISUALIZATION; SPACE; SIMILARITY; REDUCTION
AB In Chinese archaeological research, analyzing the evolution of motifs in ancient pottery is crucial for studying the spread and growth of cultures across various eras and regions. However, such analyses are often challenging due to the complexities of identifying motifs with evolutionary connections that may manifest concurrent changes in appearance, space, and time, compounded by ineffective documentation. We propose PM-Vis, a visual analytics system for tracing and analyzing the evolution of pottery motifs. PM-Vis is anchored in a "selection-organization-documentation" workflow. In the selection stage, we design a three-fold projection paired with a motif-based search mechanism, displaying the appearance similarity and temporal and spatial proximities of all motifs or a specific motif, aiding users in selecting motifs with evolutionary connections. The organization stage helps users establish the evolutionary sequence and segment the selected motifs into distinct evolutionary phases. Finally, the documentation stage enables users to record their observations and insights through various forms of annotation. We demonstrate the usefulness and effectiveness of PM-Vis through two case studies, expert feedback, and a user study.
C1 [Li, Jincheng; Yuan, Xiaoru] Peking Univ, Natl Key Lab Gen Artificial Intelligence, Beijing 100871, Peoples R China.
   [Li, Jincheng; Yuan, Xiaoru] Peking Univ, Sch Intelligence Sci & Technol, Beijing 100871, Peoples R China.
   [Li, Jincheng] Peking Univ, Ctr Computat Sci & Engn, Beijing 100871, Peoples R China.
   [Lai, Chufan] Chinese Acad Sci, Technol & Engn Ctr Space Utilizat, Beijing 100045, Peoples R China.
   [Zhang, Hai] Peking Univ, Sch Archaeol & Museol, Beijing 100871, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
C3 Peking University; Peking University; Peking University; Chinese Academy
   of Sciences; Technology & Engineering Center for Space Utilization, CAS;
   Peking University; Peking University
RP Yuan, XR (corresponding author), Peking Univ, Natl Key Lab Gen Artificial Intelligence, Beijing 100871, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Sch Intelligence Sci & Technol, Beijing 100871, Peoples R China.
EM jincheng.li@pku.edu.cn; laichufan@csu.ac.cn; haizhang@pku.edu.cn;
   xiaoru.yuan@pku.edu.cn
OI Yuan, Xiaoru/0000-0002-7233-980X; Li, Jincheng/0000-0003-2328-3624
FU NSFC
FX No Statement Available
CR Bechtold S., 2010, 11 INT S VIRT REAL A, P79
   Bederson BB, 2002, ACM T GRAPHIC, V21, P833, DOI 10.1145/571647.571649
   Beham M, 2014, IEEE T VIS COMPUT GR, V20, P1693, DOI 10.1109/TVCG.2014.2346626
   Castermans T, 2019, IEEE T VIS COMPUT GR, V25, P2969, DOI 10.1109/TVCG.2018.2865361
   Chen SM, 2017, COMPUT GRAPH FORUM, V36, P563, DOI 10.1111/cgf.13211
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   de Bruijn O., 2000, Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '00), P189, DOI DOI 10.1145/345513.345309
   DUNNELL RC, 1970, AM ANTIQUITY, V35, P305, DOI 10.2307/278341
   Ellis G, 2007, IEEE T VIS COMPUT GR, V13, P1216, DOI 10.1109/TVCG.2007.70535
   github, Rembg
   Guo YH, 2024, IEEE T VIS COMPUT GR, V30, P529, DOI 10.1109/TVCG.2023.3326944
   Gupta N, 2017, J ARCHAEOL METHOD TH, V24, P852, DOI 10.1007/s10816-016-9298-7
   Hadlak S., 2015, P 17 EUR C VIS STAT, P1
   Han J., 2019, Cultural Relics Central China, V5, P60
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He XY, 2019, J VISUAL-JAPAN, V22, P897, DOI 10.1007/s12650-019-00584-3
   Hochman Nadav, 2013, First Monday, V18, P32, DOI 10.5210/fm.v18i7.4711
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kapler T, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P25, DOI 10.1109/INFVIS.2004.27
   Karl S., 2021, P 19 EUR WORKSH GRAP
   Karl S, 2022, IT-INF TECHNOL, V64, P195, DOI 10.1515/itit-2022-0006
   Keim DA, 1998, VISUALIZATION '98, PROCEEDINGS, P181, DOI 10.1109/VISUAL.1998.745301
   Kirillov A, 2023, Arxiv, DOI arXiv:2304.02643
   Krishnamachari S, 1999, IEEE SYMP COMP COMMU, P301, DOI 10.1109/ISCC.1999.780837
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   National Museum of China, 2010, Ancient China in Artifacts
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   Nocaj A, 2012, IEEE T VIS COMPUT GR, V18, P2546, DOI 10.1109/TVCG.2012.250
   Pak M, 2017, INT CONF COMP APPL I, P367
   Rafiei D, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P375
   Rice PrudenceM., 1987, Pottery Analysis: A Sourcebook
   Saraiya P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P225, DOI 10.1109/INFVIS.2005.1532151
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Shu W, 2019, IOP CONF SER-MAT SCI, V573, DOI 10.1088/1757-899X/573/1/012012
   STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162
   Su B., 1965, Acta Archaeo- logica Sinica, P51
   Su B., 1988, Southeast Culture, P1
   tableau, Tableau 10 color palette
   Tainter Joseph, 1988, The collapse of complex societies
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Laarhoven P.J., 1987, Simulated annealing, P7, DOI [DOI 10.1007/978-94-015-7744-12, DOI 10.1007/978-94-015-7744-1_2]
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Waldeck C, 2004, IEEE INFOR VIS, P494, DOI 10.1109/IV.2004.1320190
   Wang C., 2015, Proc. SPIE Vis. Data Anal.
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang LY, 2020, J ARCHAEOL SCI-REP, V33, DOI 10.1016/j.jasrep.2020.102554
   [王立夫 Wang Lifu], 2022, [中国陶瓷, China's Ceramics], V58, P78
   Wang R., 2010, Cultural Relics, P46
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Worring M, 2016, IEEE T MULTIMEDIA, V18, P2217, DOI 10.1109/TMM.2016.2614380
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Ye L., 2022, Ceram. Stud., V37, P29
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu Y., 2022, BaiHua, P62
   Zhang A., 2022, Archaeology, P78
   Zhang P., 2005, Chinese Painted Pottery Atlas
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu Y., 2021, Cultural Relics Southern China, P82
   [宗立成 Zong Licheng], 2022, [中国陶瓷, China's Ceramics], V58, P94
NR 65
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3022
EP 3034
DI 10.1109/TVCG.2024.3388525
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500004
PM 38619950
DA 2024-08-05
ER

PT J
AU Mikawa, Y
   Fukiage, T
AF Mikawa, Yuri
   Fukiage, Taiki
TI Low-Latency Ocular Parallax Rendering and Investigation of Its Effect on
   Depth Perception in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ocular parallax; eye's front-nodal-point tracking; low-latency feedback
   system; depth perception; binocular fusion
ID EYE-MOVEMENTS; GAZE-CONTINGENT; PUPIL CENTER; MOTION; STEREOPSIS; SHIFT
AB With a demand for an immersive experience in virtual/augmented reality (VR/AR) displays, recent efforts have incorporated eye states, such as focus and fixation, into display graphics. Among these, ocular parallax, a small parallax generated by eye rotation, has received considerable attention for its impact on depth perception. However, the substantial latency of head-mounted displays (HMDs) has made it challenging to accurately assess its true effect during free eye movements. To address this issue, we propose a high-speed (360 Hz) and low-latency (4.8 ms) ocular parallax rendering system with a custom-built eye tracker. Using this proposed system, we conducted an investigation to determine the latency requirements necessary for achieving perceptually stable ocular parallax rendering. Our findings indicate that, in binocular viewing, ocular parallax rendering is perceived as significantly less stable than conventional rendering when the latency exceeds 43.72 ms at 1.3 D and 21.50 ms at 2.0 D. We also evaluated the effects of ocular parallax rendering on binocular fusion and monocular depth perception under free viewing conditions. The results demonstrated that ocular parallax rendering can enhance binocular fusion but has a limited impact on depth perception under monocular viewing conditions when latency is minimized.
C1 [Mikawa, Yuri; Fukiage, Taiki] NTT Commun Labs, Tokyo, Japan.
RP Mikawa, Y (corresponding author), NTT Commun Labs, Tokyo, Japan.
EM yuri.mikawa@gmail.com; taiki.fukiage@ntt.com
FU JST, ACT-X
FX No Statement Available
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Atchison DA, 2017, HANDBOOK OF VISUAL OPTICS: FUNDAMENTALS AND EYE OPTICS, VOL I, P235
   Atchison DA, 2014, INVEST OPHTH VIS SCI, V55, P5862, DOI 10.1167/iovs.14-14212
   Bernhard M., 2014, Proceedings of the Symposium on Eye Tracking Research and Applications, P111
   BINGHAM GP, 1993, VISION RES, V33, P777, DOI 10.1016/0042-6989(93)90197-5
   Chwesiuk R., 2016, InEurographics (Posters), P13
   Dierkes K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319819
   Dierkes K, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204525
   Duchowski D. H., 2014, P ACM S APPL PERC, P39, DOI DOI 10.1145/2628257.2628259
   Ebner C, 2022, IEEE T VIS COMPUT GR, V28, P2256, DOI 10.1109/TVCG.2022.3150504
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Frey J, 2011, J NEUROSCI, V31, P17069, DOI 10.1523/JNEUROSCI.2192-11.2011
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gharat A, 2012, J NEUROPHYSIOL, V108, P1228, DOI 10.1152/jn.00840.2011
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Guestrin E. D., 2010, PhD thesis, P2
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   HALPERN DL, 1991, VISION RES, V31, P1611, DOI 10.1016/0042-6989(91)90137-T
   Hsiao L, 2022, ACM SIGCOMM COMP COM, V52, P11, DOI 10.1145/3523230.3523233
   Ishii I, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1916, DOI 10.1109/ROBOT.1999.770388
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Jang C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275069
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Jones JA, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P221, DOI 10.1109/3DUI.2016.7460055
   Kane D, 2014, J NEUROSCI, V34, P1397, DOI 10.1523/JNEUROSCI.1652-13.2014
   Kellnhofer P, 2014, PROC SPIE, V9011, DOI 10.1117/12.2032389
   Kim D, 2012, IEEE T CIRC SYST VID, V22, P811, DOI 10.1109/TCSVT.2012.2186738
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Kudo H., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P34, DOI 10.1109/ICSMC.1999.825203
   Kudo H, 1998, P ANN INT IEEE EMBS, V20, P3180, DOI 10.1109/IEMBS.1998.746169
   Kudo H, 2000, P ANN INT IEEE EMBS, V22, P548, DOI 10.1109/IEMBS.2000.900798
   Lai CC, 2015, IEEE T CIRC SYST VID, V25, P24, DOI 10.1109/TCSVT.2014.2329362
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Le Chenechal M., 2018, ICAT EGVE 2018
   LIT A, 1949, AM J PSYCHOL, V62, P159, DOI 10.2307/1418457
   Lu C, 2020, INT SYM MIX AUGMENT, P320, DOI 10.1109/ISMAR50242.2020.00058
   Maiello G, 2014, J VISION, V14, DOI 10.1167/14.8.13
   Maimone A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073624
   Mekni A., 2014, APPL COMPUTATIONAL S, V20, P205
   Mikawa Y, 2022, IEEE T VIS COMPUT GR, V28, P4016, DOI 10.1109/TVCG.2021.3111085
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Mizushina H, 2023, IEEE T IND APPL, V59, P7813, DOI 10.1109/TIA.2023.3302275
   Nawrot M, 2003, VISION RES, V43, P1553, DOI 10.1016/S0042-6989(03)00144-5
   Ng A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P453
   Oberhauser M, 2017, COGN TECHNOL WORK, V19, P263, DOI 10.1007/s10111-017-0421-7
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   PRESTRUDE AM, 1971, VISION RES, V11, P351, DOI 10.1016/0042-6989(71)90246-X
   Pupil Labs GmbH, 2021, Pupil Labs VR/AR, P2
   Reingold EM, 2003, HUM FACTORS, V45, P307, DOI 10.1518/hfes.45.2.307.27235
   ROGERS BJ, 1974, VISION RES, V14, P181, DOI 10.1016/0042-6989(74)90099-6
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Shuhaiber JH, 2004, ARCH SURG-CHICAGO, V139, P170, DOI 10.1001/archsurg.139.2.170
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Swirski N., 2013, P PETMEI, P1
   Watanabe Y., 2015, 22 INT DISPL WORKSH, P1421
   Wedel R., 2017, Review of Marketing Research, V2, P123, DOI 10.4324/9781351550932-5
   Wexler M, 2001, NATURE, V409, P85, DOI 10.1038/35051081
   Zannoli M, 2016, J VISION, V16, DOI 10.1167/16.6.17
   Zhao ZT, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-35834-4
NR 61
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2228
EP 2238
DI 10.1109/TVCG.2024.3372078
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400026
PM 38442067
DA 2024-08-05
ER

PT J
AU Mishra, S
   Corro-Flores, M
   Krum, D
   Forouzesh, N
AF Mishra, Shivam
   Corro-Flores, Missael
   Krum, David
   Forouzesh, Negin
TI Molecular Docking Improved with Human Spatial Perception Using Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Proteins; Three-dimensional displays; Visualization; Drugs; Force;
   Trajectory; Virtual reality; Molecular Dynamics Simulation; Molecular
   Docking; Virtual Reality
ID HIV-1 PROTEASE
AB Adaptive steered molecular dynamics (ASMD) is a computational biophysics method in which an external force is applied to a selected set of atoms or a specific reaction coordinate to induce a particular molecular motion. Virtual reality (VR) based methods for protein-ligand docking are beneficial for visualizing on-the-fly interactive molecular dynamics and performing promising docking trajectories. In this paper, we propose a novel method to guide ASMD with optimal trajectories collected from human experiences using interactive molecular dynamics in virtual reality (iMD-VR). We also explain the benefits of using VR as a tool for expediting the process of ligand binding, outlining an experimental protocol that enables iMD-VR users to guide Amprenavir into and out of the binding pockets of HIV-1 protease and recreate their respective crystallographic binding poses within 5 minutes. Later, we discuss our analysis of the results from iMD-VR-assisted ASMD simulation and assess its performance compared to a standard ASMD simulation. From the accuracy point of view, our proposed method calculates higher Potential Mean Force (PMF) values consistently relative to a standard ASMD simulation with an almost twofold increase in all the experiments. Finally, we describe the novelty of the research and discuss results showcasing a faster and more effective convergence of the ligand to the protein's binding site as compared to a standard molecular dynamics simulation, proving the effectiveness of VR in the field of drug discovery. Future work includes the development of an artificial intelligence algorithm capable of predicting optimal binding trajectories for many protein-ligand pairs, as well as the required force needed to steer the ligand to follow the said trajectory.
C1 [Mishra, Shivam; Krum, David; Forouzesh, Negin] Calif State Univ Los Angeles, Dept Comp Sci, Los Angeles, CA 90032 USA.
   [Corro-Flores, Missael] Calif State Univ Los Angeles, Dept Phys & Astron, Los Angeles, CA USA.
C3 California State University System; California State University Los
   Angeles; California State University System; California State University
   Los Angeles
RP Mishra, S (corresponding author), Calif State Univ Los Angeles, Dept Comp Sci, Los Angeles, CA 90032 USA.
EM smishra7@calstatela.edu; mcorrof@calstatela.edu; dkrum@calstatela.edu;
   neginf@calstatela.edu
OI Forouzesh, Negin/0000-0003-2293-0391; Corro-Flores,
   Missael/0009-0008-3079-1460
FU NSF
FX No Statement Available
CR Bharatam P. V., 2021, Drug Discovery and Development, V1, P137, DOI [DOI 10.1007/978-981-15-5534-36, 10.1007/978-981-15-5534-3_6]
   Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Brik A, 2003, ORG BIOMOL CHEM, V1, P5, DOI 10.1039/b208248a
   Calvelo M, 2020, COMPUT STRUCT BIOTEC, V18, P2621, DOI 10.1016/j.csbj.2020.09.018
   Case DA, 2016, AMBER 2016
   Case DA, 2023, J CHEM INF MODEL, V63, P6183, DOI 10.1021/acs.jcim.3c01153
   Deeks HM, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228461
   Forouzesh N, 2021, MOLECULES, V26, DOI 10.3390/molecules26082383
   Hilty D. M., 2020, Journal of Technology in Behavioral Science, V5, P178, DOI DOI 10.1007/S41347-020-00126-X
   Jamieson-Binnie A. D., 2020, ACM SIGGRAPH 2020 IM, DOI [10.1145/3388536.3407891, DOI 10.1145/3388536.3407891]
   Jarzynski C, 1997, PHYS REV LETT, V78, P2690, DOI 10.1103/PhysRevLett.78.2690
   Jorgensen WL, 2004, SCIENCE, V303, P1813, DOI 10.1126/science.1096361
   KIM EE, 1995, J AM CHEM SOC, V117, P1181, DOI 10.1021/ja00108a056
   Kingsley LJ, 2019, J MOL GRAPH MODEL, V89, P234, DOI 10.1016/j.jmgm.2019.03.010
   Li R., 2019, Ccamlr Science, V26, P2
   Lütjens M, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010009
   Mahanti M., 2016, Flap dynamics in aspartic proteases: A computational perspective, P2
   Maier JA, 2015, J CHEM THEORY COMPUT, V11, P3696, DOI 10.1021/acs.jctc.5b00255
   Mishra N., 2012, Algorithms and Methods in Structural Bioinformatics, P1
   O'Connor MB, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5092590
   Onufriev A, 2004, PROTEINS, V55, P383, DOI 10.1002/prot.20033
   Ozer G, 2010, J CHEM THEORY COMPUT, V6, P3026, DOI 10.1021/ct100320g
   Poyade M, 2021, ACS CHEM HEALTH SAFE, V28, P55, DOI 10.1021/acs.chas.0c00105
   Salo-Ahen OMH, 2021, PROCESSES, V9, DOI 10.3390/pr9010071
   Shakya D. S., 2019, Journal of Innovative Image Processing, V1, P102
   Simmerling C, 2002, J AM CHEM SOC, V124, P11258, DOI 10.1021/ja0273851
   Walters RK, 2022, EXPERT OPIN DRUG DIS, V17, P685, DOI 10.1080/17460441.2022.2079632
   Wang JM, 2004, J COMPUT CHEM, V25, P1157, DOI 10.1002/jcc.20035
   Zonta N, 2009, ANTIVIR RES, V82, pA74, DOI 10.1016/j.antiviral.2009.02.196
NR 29
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2269
EP 2275
DI 10.1109/TVCG.2024.3372128
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400007
PM 38451773
DA 2024-08-05
ER

PT J
AU Wang, YX
   Ling, HB
   Huang, BY
AF Wang, Yuxi
   Ling, Haibin
   Huang, Bingyao
TI ViComp: Video Compensation for Projector-Camera Systems
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptation models; Image color analysis; Distortion; Training;
   Reflectivity; Computational modeling; Synchronization; Projector
   compensation; Video compensation; Spatial augmented reality;
   Projector-camera system; Continuous projection mapping
ID STRUCTURED-LIGHT; ADAPTATION
AB Projector video compensation aims to cancel the geometric and photometric distortions caused by non-ideal projection surfaces and environments when projecting videos. Most existing projector compensation methods start by projecting and capturing a set of sampling images, followed by an offline compensation model training step. Thus, abundant user effort is required before the users can watch the video. Moreover, the sampling images have little prior knowledge of the video content and may lead to suboptimal results. To address these issues, this paper builds a video compensation system that can online adapt the compensation parameters. Our approach consists of five threads and can perform compensation, projection, capturing, and short-term and long-term model updates in parallel. Due to the parallel mechanism, rather than projecting and capturing hundreds of sampling images and training the model offline, we can directly use the projected and captured video frames for model updates on the fly. To quickly apply to the new environment, we introduce a deep learning-based compensation model that integrates a fixed transformer-based method and a novel CNN-based network. Moreover, for fast convergence and to reduce error accumulation during fine-tuning, we present a strategy that cooperates with short-term and long-term memory model updates. Experiments show that it significantly outperforms state-of-the-art baselines.
C1 [Wang, Yuxi] Hangzhou Dianzi Univ, Hangzhou, Peoples R China.
   [Ling, Haibin] SUNY Stony Brook, Stony Brook, NY USA.
   [Huang, Bingyao] Southwest Univ, Chongqing, Peoples R China.
C3 Hangzhou Dianzi University; State University of New York (SUNY) System;
   State University of New York (SUNY) Stony Brook; Southwest University -
   China
RP Huang, BY (corresponding author), Southwest Univ, Chongqing, Peoples R China.
EM yxwang@hdu.edu.cn; haibin.ling@stonybrook.edu; bhuang@swu.edu.cn
OI Huang, Bingyao/0000-0002-8647-5730; Ling, Haibin/0000-0003-4094-8413
FU Nature Science Foundation of China
FX No Statement Available
CR Akiyama R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P741, DOI 10.1109/VRW55335.2022.00226
   B. O. Community, 2018, Blender-a 3D modelling and rendering package
   Bimber O, 2005, COMPUTER, V38, P48, DOI 10.1109/MC.2005.17
   Bimber O., 2006, IEEE VIRTUAL REALITY, P320
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Bokaris P.-A., 2015, EUR C COMP VIS WORKS, P2
   Bokaris PA, 2015, IEEE IMAGE PROC, P2675, DOI 10.1109/ICIP.2015.7351288
   Brahma D, 2023, PROC CVPR IEEE, P3582, DOI 10.1109/CVPR52729.2023.00349
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Döbler M, 2023, PROC CVPR IEEE, P7704, DOI 10.1109/CVPR52729.2023.00744
   Erel Yotam, 2023, IEEE Trans Vis Comput Graph, V29, P4339, DOI 10.1109/TVCG.2023.3320256
   Fujii K, 2005, PROC CVPR IEEE, P1180
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Hamasaki T, 2018, IEEE T VIS COMPUT GR, V24, P1457, DOI 10.1109/TVCG.2018.2793659
   Hashimoto N, 2021, VISUAL COMPUT, V37, P175, DOI 10.1007/s00371-019-01790-8
   Hashimoto N, 2017, INT J COMPUT GAMES T, V2017, DOI 10.1155/2017/4936285
   Huang BY, 2022, IEEE T PATTERN ANAL, V44, P2953, DOI 10.1109/TPAMI.2021.3050124
   Huang BY, 2021, IEEE T VIS COMPUT GR, V27, P2725, DOI 10.1109/TVCG.2021.3067771
   Huang BY, 2019, PROC CVPR IEEE, P6803, DOI 10.1109/CVPR.2019.00697
   Huang ZY, 2022, LECT NOTES COMPUT SC, V13677, P668, DOI 10.1007/978-3-031-19790-1_40
   Ibrahim MT, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P905, DOI 10.1109/VRW58643.2023.00295
   Iwasawa Y, 2021, ADV NEUR IN
   Kagami S, 2019, IEEE T VIS COMPUT GR, V25, P3094, DOI 10.1109/TVCG.2019.2932248
   Kageyama Y, 2022, IEEE T VIS COMPUT GR, V28, P2223, DOI 10.1109/TVCG.2022.3150465
   Kemmoku Y, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P288, DOI [10.1109/ISMAR-Adjunct.2016.88, 10.1109/ISMAR-Adjunct.2016.0097]
   Kingma D. P., 2014, arXiv
   Kurth Philipp, 2020, 2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), P174, DOI 10.1109/ISMAR50242.2020.00039
   Li Y., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Low KL, 2003, P IEEE VIRT REAL ANN, P110
   Majumder A, 2015, P IEEE VIRT REAL ANN, P339, DOI 10.1109/VR.2015.7223434
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Miyatake Y, 2023, IEEE T VIS COMPUT GR, V29, P2005, DOI 10.1109/TVCG.2021.3136214
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nguyen AT, 2023, PROC CVPR IEEE, P24162, DOI 10.1109/CVPR52729.2023.02314
   Özacar K, 2015, P IEEE VIRT REAL ANN, P255, DOI 10.1109/VR.2015.7223392
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park H, 2008, IEEE T CIRC SYST VID, V18, P110, DOI 10.1109/TCSVT.2007.903322
   Raskar R., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P109, DOI 10.1109/VR.2000.840488
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roosendaal T., 2012, cloud.blender.org/spring.
   Roosendaal T., 2008, Big buck bunny
   Shahpaski M, 2017, PROC CVPR IEEE, P3596, DOI 10.1109/CVPR.2017.383
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shih KT, 2021, IEEE T IMAGE PROCESS, V30, P418, DOI 10.1109/TIP.2020.3036768
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Souek T., 2020, arXiv
   Sugimoto M, 2021, IEEE T VIS COMPUT GR, V27, P4161, DOI 10.1109/TVCG.2021.3106511
   Sun Y., 2020, PMLR, V119, P9229
   Tarvainen A, 2017, ADV NEUR IN, V30
   Ueda T, 2020, IEEE T VIS COMPUT GR, V26, P2051, DOI 10.1109/TVCG.2020.2973496
   Wang D., 2021, INT C LEARN REPR
   Wang Q, 2022, PROC CVPR IEEE, P7191, DOI 10.1109/CVPR52688.2022.00706
   Wang YM, 2017, IEEE IMAGE PROC, P2726, DOI 10.1109/ICIP.2017.8296778
   Wang YX, 2023, Symposium Virtual Re, P135, DOI 10.1109/VR55154.2023.00029
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe Y, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P52, DOI 10.1109/ISMAR.2017.22
   Yuqi Li, 2012, 2012 International Conference on Virtual Reality and Visualization (ICVRV 2012), P7, DOI 10.1109/ICVRV.2012.15
   Zheng RD, 2018, IEEE INT SYMP CIRC S
NR 60
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2347
EP 2356
DI 10.1109/TVCG.2024.3372079
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400012
PM 38437096
DA 2024-08-05
ER

PT J
AU Bach, B
   Keck, M
   Rajabiyazdi, F
   Losev, T
   Meirelles, I
   Dykes, J
   Laramee, RS
   Alkadi, M
   Stoiber, C
   Huron, S
   Perin, C
   Morais, L
   Aigner, W
   Kosminsky, D
   Boucher, M
   Knudsen, S
   Manataki, A
   Aerts, J
   Hinrichs, U
   Roberts, JC
   Carpendale, S
AF Bach, Benjamin
   Keck, Mandy
   Rajabiyazdi, Fateme
   Losev, Tatiana
   Meirelles, Isabel
   Dykes, Jason
   Laramee, Robert S.
   Alkadi, Mashael
   Stoiber, Christina
   Huron, Samuel
   Perin, Charles
   Morais, Luiz
   Aigner, Wolfgang
   Kosminsky, Doris
   Boucher, Magdalena
   Knudsen, Soren
   Manataki, Areti
   Aerts, Jan
   Hinrichs, Uta
   Roberts, Jonathan C.
   Carpendale, Sheelagh
TI Challenges and Opportunities in Data Visualization Education: A Call to
   Action
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data Visualization; Education; Challenges
ID FORMAL EDUCATION; DESIGN; REFLECTIONS; LITERACY; NEED
AB This paper is a call to action for research and discussion on data visualization education. As visualization evolves and spreads through our professional and personal lives, we need to understand how to support and empower a broad and diverse community of learners in visualization. Data Visualization is a diverse and dynamic discipline that combines knowledge from different fields, is tailored to suit diverse audiences and contexts, and frequently incorporates tacit knowledge. This complex nature leads to a series of interrelated challenges for data visualization education. Driven by a lack of consolidated knowledge, overview, and orientation for visualization education, the 21 authors of this paper-educators and researchers in data visualization-identify and describe 19 challenges informed by our collective practical experience. We organize these challenges around seven themes People, Goals & Assessment, Environment, Motivation, Methods, Materials, and Change. Across these themes, we formulate 43 research questions to address these challenges. As part of our call to action, we then conclude with 5 cross-cutting opportunities and respective action items: embrace DIVERSITY+INCLUSION, build COMMUNITIES, conduct RESEARCH, act AGILE, and relish RESPONSIBILITY. We aim to inspire researchers, educators and learners to drive visualization education forward and discuss why, how, who and where we educate, as we learn to use visualization to address challenges across many scales and many domains in a rapidly changing world:
C1 [Bach, Benjamin; Alkadi, Mashael; Manataki, Areti; Hinrichs, Uta] Univ Edinburgh, Edinburgh, Scotland.
   [Keck, Mandy] Univ Appl Sci Upper Austria, Wels, Austria.
   [Rajabiyazdi, Fateme] Carleton Univ, Ottawa, ON, Canada.
   [Losev, Tatiana; Carpendale, Sheelagh] Simon Fraser Univ, Burnaby, BC, Canada.
   [Meirelles, Isabel] OCAD Univ, Toronto, ON, Canada.
   [Dykes, Jason] City Univ London, London, England.
   [Morais, Luiz] Univ Fed Pernambuco, Recife, Brazil.
   [Laramee, Robert S.] Univ Nottingham, Nottingham, England.
   [Stoiber, Christina; Aigner, Wolfgang; Boucher, Magdalena] Univ Appl Sci St Polten, St Polten, Austria.
   [Huron, Samuel] Telecom Paris, Paris, France.
   [Perin, Charles] Univ Victoria, Victoria, BC, Canada.
   [Kosminsky, Doris] Univ Fed Rio De Janeiro, Rio De Janeiro, Brazil.
   [Knudsen, Soren] Univ Copenhagen, Copenhagen, Denmark.
   [Aerts, Jan] Hasselt Univ, Hasselt, Belgium.
   [Roberts, Jonathan C.] Bangor Univ, Bangor, Wales.
C3 University of Edinburgh; Carleton University; Simon Fraser University;
   City University London; Universidade Federal de Pernambuco; University
   of Nottingham; IMT - Institut Mines-Telecom; Institut Polytechnique de
   Paris; Telecom Paris; University of Victoria; Universidade Federal do
   Rio de Janeiro; University of Copenhagen; Hasselt University; Bangor
   University
RP Bach, B (corresponding author), Univ Edinburgh, Edinburgh, Scotland.
EM bbach@ed.ac.uk; Mandy.Keck@fh-hagenberg.at;
   fateme.rajabiyazdi@carleton.ca; tatiana_losev@sfu.ca;
   imeirelles@ocadu.ca; J.Dykes@city.ac.uk;
   robert.laramee@nottingham.ac.uk; m.alkadi@sms.ed.ac.uk;
   Christina.Stoiber@fhstp.ac.at; samuel.huron@telecom-paris.fr;
   cperin@uvic.ca; lamm@cin.ufpe.br; Wolfgang.Aigner@fhstp.ac.at;
   doriskos@eba.ufrj.br; Magdalena.Boucher@fhstp.ac.at; soekn@itu.dk;
   A.Manataki@st-andrews.ac.uk; jan.aerts@belvis.io; uhinrich@ed.ac.uk;
   j.c.roberts@bangor.ac.uk; sheelagh@sfu.ca
OI Losev, Tatiana/0000-0002-0363-8072; Laramee, Robert
   S/0000-0002-3874-6145; Stoiber, Christina/0000-0002-1764-1467;
   Meirelles, Isabel/0000-0001-8111-6002; Huron,
   Samuel/0000-0002-9319-8559; Manataki, Areti/0000-0003-3698-8535; Aerts,
   Jan/0000-0002-6416-2717; Morais, Luiz Augusto/0000-0002-5506-9473; Keck,
   Mandy/0000-0002-5821-8016
FU EPSRC
FX No Statement Available
CR Adar Eytan, 2023, IEEE Trans Vis Comput Graph, V29, P268, DOI 10.1109/TVCG.2022.3209402
   Adhikari A., 2021, Harvard Data Science Review, V2, DOI DOI 10.1162/99608F92.CB0FA8D24
   Aerts J., 2022, ALTVIS
   Aerts J, 2021, IEEE COMPUT GRAPH, V41, P15, DOI 10.1109/MCG.2021.3116042
   AlKadi Mashael, 2023, IEEE Trans Vis Comput Graph, V29, P907, DOI 10.1109/TVCG.2022.3209487
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Amabili L, 2021, IEEE COMPUT GRAPH, V41, P71, DOI 10.1109/MCG.2021.3115446
   [Anonymous], 2005, Illuminating the path: The research and development agenda for visual analytics
   [Anonymous], 2015, Herdsa Review of Higher Education, DOI DOI 10.1111/HEA.12037_26
   Archambault D., 2023, COMPUTER GRAPHICS forum, V42
   Bach B., 2023, Dagstuhl Reports, V12
   Bach B., 2022, 4 IEEE WORKSHOP VISU
   Bach B., 2023, Dagstuhl Reports, V12, DOI [10.4230/DagRep.12.6.832,3, DOI 10.4230/DAGREP.12.6.832,3]
   Bach B., 2018, VISBIA AVI
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Bach B, 2021, IEEE COMPUT GRAPH, V41, P13, DOI 10.1109/MCG.2021.3117412
   Balchin W. G. V., 1976, The American Cartographer, V3, P33, DOI [10.1559/1523040767840802212, DOI 10.1559/1523040767840802212]
   Ballentine Brian, 2022, Communication Design Quarterly, P24, DOI 10.1145/3507454.3507457
   Bao C, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501891
   Beasley ZJ, 2021, IEEE COMPUT GRAPH, V41, P59, DOI 10.1109/MCG.2021.3115387
   Bertling J. G., 2021, Art Education, V74, P44, DOI [10.1080/00043125.2020.1852381, DOI 10.1080/00043125.2020.1852381]
   Beyer J, 2021, IEEE COMPUT GRAPH, V41, P37, DOI 10.1109/MCG.2021.3115413
   Biggs J., 2011, Teaching for Quality Learning at University, V4, P5
   Bishop F, 2020, IEEE T VIS COMPUT GR, V26, P451, DOI 10.1109/TVCG.2019.2934804
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P1407, DOI 10.1109/TVCG.2018.2802520
   Bloom B., 1956, Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain, V2nd, P5
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowler RD, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502107
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Brandt MJ, 2014, J EXP SOC PSYCHOL, V50, P217, DOI 10.1016/j.jesp.2013.10.005
   Brooks C, 2021, INT J ARTIF INTELL E, V31, P516, DOI 10.1007/s40593-021-00262-2
   Brown A.H., 2019, The essentials of instructional design: Connecting fundamental principles with process and practice, DOI DOI 10.4324/9780429439698
   Burch M, 2020, J VISUAL-JAPAN, V23, P895, DOI 10.1007/s12650-020-00659-6
   Byrd VL, 2021, IEEE COMPUT GRAPH, V41, P25, DOI 10.1109/MCG.2021.3115396
   Cairo A., 2019, How Charts Lie, P4
   Carpendale M. S. T., 2003, Technical report, DOI DOI 10.11575/PRISM/30495
   Catherine DIgnazio R. B., 2018, Digital Humanities Quarterly, P2
   Chen CM, 2005, IEEE COMPUT GRAPH, V25, P12, DOI 10.1109/MCG.2005.91
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Corneli J., 2018, PROC ANN CONVENTION
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   D'Ignazio C., 2020, DATA VISUALIZATION S, P207, DOI [10.2307/j.ctvzgb8c7.194, DOI 10.2307/J.CTVZGB8C7.194, 10.2307/j.ctvzgb8c7.19, DOI 10.2307/J.CTVZGB8C7.19]
   Daneshzand Foroozan, 2023, IEEE Trans Vis Comput Graph, V29, P225, DOI 10.1109/TVCG.2022.3209365
   Dewey J., 1938, Experience and education
   Diehl A., 2018, EUROVIS SHORT PAPERS, V6, P7
   Domik G, 2000, IEEE COMPUT GRAPH, V20, P16, DOI 10.1109/38.851744
   Domik G, 2012, IEEE COMPUT GRAPH, V32, P87, DOI 10.1109/MCG.2012.18
   Drucker J, 2011, DIGIT HUMANITIES Q, V5
   Elmqvist N, 2012, IEEE COMPUT GRAPH, V32, P84, DOI 10.1109/MCG.2012.55
   Ens B., 2021, PROC CHI ACM, DOI [10.1145/3411764.34468662,7, DOI 10.1145/3411764.34468662,7]
   Firat E. E., 2019, Dialogue with the Creative Economy, Special Issue on Visualization, V4, P146, DOI DOI 10.22398/2525-2828.412146-1602,8
   Firat EE, 2022, INFORM VISUAL, V21, P285, DOI 10.1177/14738716221081831
   Friedman A., 2021, PEDAGOGY DATA VIS WO
   Gaisch M, 2020, J APPL RES HIGH EDUC, V12, P137, DOI 10.1108/JARHE-03-2018-0048
   Garrison DR, 2016, THINKING COLLABORATIVELY: LEARNING IN A COMMUNITY OF INQUIRY, P1
   Ge LW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581406
   Goodyear P, 2021, ETR&D-EDUC TECH RES, V69, P445, DOI 10.1007/s11423-020-09926-7
   Graham E, 2017, ENGL STUD, V98, P449, DOI 10.1080/0013838X.2017.1332021
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   He SQ, 2017, IEEE T VIS COMPUT GR, V23, P561, DOI 10.1109/TVCG.2016.2599338
   Hearst M., 2015, IEEE VIS 2015 Panel: Vis, the next generation: Teaching across the researcherpractitioner gap
   Henshaw AL, 2018, J POLITICAL SCI EDUC, V14, P423, DOI 10.1080/15512169.2017.1419875
   Huron S., 1 IEEE VIS WORKSHOP
   Huron S., 2 IEEE VIS WORKSHOP
   Huron S., 2014, PROC 2014 C DESIGNIN, DOI DOI 10.1145/2598510.25985662,6,7
   Huron S, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1409, DOI 10.1145/3064663.3064798
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Johnson C., 2005, NIH-NSF Visualization Research Challenges Report, P2
   Johnson C. G., 2006, Baltic Sea, P120, DOI DOI 10.1145/1315803.13158255
   Johnson G., 2004, PROC IEEE VISUALIZAT, P569, DOI DOI 10.1109/VISUAL.2004.78
   Joshi A., 1 IEEE VIS WORKSHOP
   Joshi A., 2 IEEE VIS WORKSHOP
   Kahn J, 2021, LEARN MEDIA TECHNOL, V46, P128, DOI 10.1080/17439884.2020.1826962
   Kammer D., 2021, P 2 IEEE VISACTIVITI
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Keck M., 2023, EDUVIS WORKSHOP VISU
   Keck M, 2021, IEEE COMPUT GRAPH, V41, P80, DOI 10.1109/MCG.2021.3115416
   Kerren A, 2008, LECT NOTES COMPUT SC, V4950, P65, DOI 10.1007/978-3-540-70956-5_4
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Knox H, 2018, MATER DIGIT, P1
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Laramee R., 2014, Future Challenges and Unsolved Problems in Multi-field Visualization, P205, DOI DOI 10.1007/978-1-4471-6497-5
   Lave J., 1991, SITUATED LEARNING LE
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee V., 2018, Instructional Technology and Learning Sciences Faculty Public., P4
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Leifler E, 2020, INT J LESSON LEARN S, V9, P221, DOI 10.1108/IJLLS-01-2020-0003
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Liu X., 2023, Information Visualization, V22, DOI DOI 10.1177/147387162211269921,7
   Losev T, 2022, IEEE COMPUT GRAPH, V42, P64, DOI 10.1109/MCG.2022.3209605
   Loy A, 2019, J STAT EDUC, V27, P2, DOI 10.1080/10691898.2018.1564638
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   May R., 2010, IEEE VIS
   McGettrick A, 2005, COMPUT J, V48, P42, DOI 10.1093/comjnl/bxh064
   McNutt A., 2018, VISGUIDES 2 WORKSHOP, P1
   Melton R., 2014, Objectives, Competencies and Learning Outcomes: Developing Instructional Materials in Open and Distance Learning, P4
   Moere AV, 2007, COMPUTER-AIDED ARCHITECTURAL DESIGN FUTURES (CAAD FUTURES) 2007, P71, DOI 10.1007/978-1-4020-6528-6_6
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murtazin K., 2020, PROC FRONT EDUC CONF, P1, DOI [DOI 10.1109/fie44824.2020.9274264, 10.1109/FIE44824.2020.9274264, DOI 10.1109/FIE44824.2020.9274264]
   Owen GS, 2013, IEEE COMPUT GRAPH, V33, P14, DOI 10.1109/MCG.2013.57
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Parsons P, 2022, IEEE T VIS COMPUT GR, V28, P665, DOI 10.1109/TVCG.2021.3114959
   Pereira D, 2016, ASSESS EVAL HIGH EDU, V41, P1008, DOI 10.1080/02602938.2015.1055233
   Perin C., 2014, Theses, P6
   Perin C, 2021, IEEE COMPUT GRAPH, V41, P48, DOI 10.1109/MCG.2021.3115417
   Portner H.-O., 2022, Climate change 2022: impacts, adaptation and vulnerability. IPCC, DOI [10.1017/9781009325844.001, DOI 10.1017/9781009325844.001, 10.1017/9781009325844]
   Preves S, 2009, TEACH SOCIOL, V37, P245, DOI 10.1177/0092055X0903700303
   Riche N. H., 2018, Data-driven storytelling, DOI [10.1201/97813152815752, DOI 10.1201/97813152815752]
   Roberts JC, 2022, 2022 IEEE 4TH WORKSHOP ON VISUALIZATION GUIDELINES IN RESEARCH, DESIGN, AND EDUCATION (VISGUIDES 2022), P23, DOI 10.1109/VisGuides57787.2022.00009
   Roberts JC, 2016, IEEE T VIS COMPUT GR, V22, P419, DOI 10.1109/TVCG.2015.2467271
   Romanelli F, 2009, AM J PHARM EDUC, V73, DOI 10.5688/aj730109
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Rushmeier H., 2006, PROC IEEE VISUALIZAT, P2
   Rushmeier H, 2007, IEEE COMPUT GRAPH, V27, P12, DOI 10.1109/MCG.2007.156
   Ryan L, 2019, IEEE COMPUT GRAPH, V39, P95, DOI 10.1109/MCG.2018.2889526
   Saket B, 2020, IEEE T VIS COMPUT GR, V26, P482, DOI 10.1109/TVCG.2019.2934534
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Schofield T, 2013, C&C'13: PROCEEDINGS OF THE 9TH ACM CONFERENCE ON CREATIVITY & COGNITION 2013, P175
   Schunk D., 2014, Motivation in Education: Theory, Research, and Applications, P5
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Setiawan E. P., 2021, IndoMS-Journal on Mathematics Education, V12, P427, DOI [10.22342/jme.12.3.13202.427-448, DOI 10.22342/JME.12.3.13202.427-448]
   Syeda UH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376829
   Tedre M, 2023, ACM T COMPUT EDUC, V23, DOI 10.1145/3487049
   Tsai YS, 2020, ASSESS EVAL HIGH EDU, V45, P554, DOI 10.1080/02602938.2019.1676396
   Turkay C, 2017, LECT NOTES COMPUT SC, V10410, P191, DOI 10.1007/978-3-319-66808-6_13
   Tygel A. F., 2016, Journal of Community Informatics, V12, P108
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Wang ZZ, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299043
   Wenger E., 1999, Communities of practice: Learning, meaning, and identity, V4, P5
   Wileman R. E., 1993, Visual Communicating, P2
   Wood J., 2022, IEEE 2022 ALTVIS WOR, P7
   Wun T, 2016, COMPUT GRAPH FORUM, V35, P111, DOI 10.1111/cgf.12887
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 138
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 649
EP 660
DI 10.1109/TVCG.2023.3327378
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500139
PM 37934634
OA Green Published, Green Accepted
DA 2024-08-05
ER

PT J
AU Dasu, K
   Kuo, YH
   Ma, KL
AF Dasu, Keshav
   Kuo, Yun-Hsin
   Ma, Kwan-Liu
TI Character-Oriented Design for Visual Data Storytelling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Storytelling; Explanatory; Narrative visualization; Visual metaphor
ID NARRATIVE VISUALIZATION; TELLING STORIES; GENERATION
AB When telling a data story, an author has an intention they seek to convey to an audience. This intention can be of many forms such as to persuade, to educate, to inform, or even to entertain. In addition to expressing their intention, the story plot must balance being consumable and enjoyable while preserving scientific integrity. In data stories, numerous methods have been identified for constructing and presenting a plot. However, there is an opportunity to expand how we think and create the visual elements that present the story. Stories are brought to life by characters; often they are what make a story captivating, enjoyable, memorable, and facilitate following the plot until the end. Through the analysis of 160 existing data stories, we systematically investigate and identify distinguishable features of characters in data stories, and we illustrate how they feed into the broader concept of "character-oriented design". We identify the roles and visual representations data characters assume as well as the types of relationships these roles have with one another. We identify characteristics of antagonists as well as define conflict in data stories. We find the need for an identifiable central character that the audience latches on to in order to follow the narrative and identify their visual representations. We then illustrate "character-oriented design" by showing how to develop data characters with common data story plots. With this work, we present a framework for data characters derived from our analysis; we then offer our extension to the data storytelling process using character-oriented design. To access our supplemental materials please visit https://chaorientdesignds.github.io/.
C1 [Dasu, Keshav; Kuo, Yun-Hsin; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Dasu, K (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM kdasu@ucdavis.edu; yskuo@ucdavis.edu; klma@ucdavis.edu
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   [Anonymous], 2005, Screenplay: The foundations of screenwriting
   [Anonymous], 2001, INT C VIRT STOR
   [Anonymous], 2014, T. N. Y. Times
   [Anonymous], 2015, Systems, P1459, DOI 10.1145/
   Azad K., 2019, Colorized math equations
   B. Bach, about us
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Bradbury JD, 2020, INFORM VISUAL, V19, P339, DOI 10.1177/1473871620925071
   Bran R, 2010, PROCD SOC BEHV, V2, P1790, DOI 10.1016/j.sbspro.2010.03.986
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Cai YD, 2007, LECT NOTES COMPUT SC, V4469, P260
   Cai Z, 2015, IEEE PAC VIS SYMP, P99, DOI 10.1109/PACIFICVIS.2015.7156363
   Campbell J., 1949, The hero with a thousand faces
   Carter Shan, 2016, Distill, DOI [DOI 10.23915/DISTILL.00004, 10.23915/distill.00004]
   Cavazza M., 2001, P CAST 2001, P139
   Charles F, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P609, DOI 10.1109/VSMM.2001.969719
   Chu T., 2014, Money wins elections
   Coats E., Pixar's 22 rules of storytelling
   Cruz Pedro, 2019, Information Design Journal, V25, P6, DOI 10.1075/idj.25.1.01cru
   Dasu K, 2021, IEEE T VIS COMPUT GR, V27, P935, DOI 10.1109/TVCG.2020.3030412
   Dasu K, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P1, DOI 10.1109/SciVis.2018.8823624
   Data Visualization Society, Information Is Beautiful Awards
   Dudukovic NM, 2004, APPL COGNITIVE PSYCH, V18, P125, DOI 10.1002/acp.953
   Fink EJ, 2014, DRAMATIC STORY STRUCTURE: A PRIMER FOR SCREENWRITERS, P1
   Forster E.M., 2010, Aspects of the Novel
   Fritz C, 2007, J ARCHAEOL METHOD TH, V14, P48, DOI 10.1007/s10816-007-9027-3
   GAPMINDER.ORG, about us
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Gove R, 2021, IEEE SYM VIS CYB SEC, P1, DOI 10.1109/VizSec53666.2021.00005
   Halloran N., 2021, How sure are climate scientists, really?
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hohman Fred, 2020, Distill, V5, pe28, DOI [10.23915/distill.00028, DOI 10.23915/DISTILL.00028]
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Interactive P., Out of sight, out of mind
   Isenberg P, 2018, LECT NOTES COMPUT SC, V11190, P165, DOI 10.1007/978-3-030-01388-2_6
   Kang JA, 2020, J CONSUM BEHAV, V19, P47, DOI 10.1002/cb.1793
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Lan XY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517530
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Li YN, 2015, 8TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION (VINCI 2015), P121, DOI 10.1145/2801040.2801062
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Ojo A, 2018, DIGIT JOURNAL, V6, P693, DOI 10.1080/21670811.2017.1403291
   Petridis S, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P187, DOI 10.1145/3325480.3325503
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Reuters, 2020, How powerful was the beirut blast?
   Risch JS, 2008, Arxiv, DOI arXiv:0809.0884
   Sallaberry A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146368
   Sarica HC, 2016, COMPUT EDUC, V94, P298, DOI 10.1016/j.compedu.2015.11.016
   Scarr S., 2020, Covid-19: The pace of death
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shen D, 2008, NINETEEN CENT LIT, V63, P321, DOI 10.1525/ncl.2008.63.3.321
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stolper C. D., 2016, Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Truby J., 2008, The Anatomy of Story: 22 Steps to Becoming a Master Storyteller, V1st
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang SM, 2015, IEEE COMPUT GRAPH, V35, P82, DOI 10.1109/MCG.2015.74
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Woolf W., about us
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Zhao Z., 2015, DATA COMICS SEQUENTI
NR 73
TC 0
Z9 0
U1 9
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 98
EP 108
DI 10.1109/TVCG.2023.3326578
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500112
PM 37871068
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Elhamdadi, H
   Stefkovics, A
   Beyer, J
   Moerth, E
   Pfister, H
   Bearfield, CX
   Nobre, C
AF Elhamdadi, Hamza
   Stefkovics, Adam
   Beyer, Johanna
   Moerth, Eric
   Pfister, Hanspeter
   Bearfield, Cindy Xiong
   Nobre, Carolina
TI Vistrust: a Multidimensional Framework and Empirical Study of Trust in
   Data Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trust; visualization; science; framework
ID COGNITION; UNCERTAINTY; EDUCATION; EMOTION
AB Trust is an essential aspect of data visualization, as it plays a crucial role in the interpretation and decision-making processes of users. While research in social sciences outlines the multi-dimensional factors that can play a role in trust formation, most data visualization trust researchers employ a single-item scale to measure trust. We address this gap by proposing a comprehensive, multidimensional conceptualization and operationalization of trust in visualization. We do this by applying general theories of trust from social sciences, as well as synthesizing and extending earlier work and factors identified by studies in the visualization field. We apply a two-dimensional approach to trust in visualization, to distinguish between cognitive and affective elements, as well as between visualization and data-specific trust antecedents. We use our framework to design and run a large crowd-sourced study to quantify the role of visual complexity in establishing trust in science visualizations. Our study provides empirical evidence for several aspects of our proposed theoretical framework, most notably the impact of cognition, affective responses, and individual differences when establishing trust in visualizations.
C1 [Elhamdadi, Hamza; Bearfield, Cindy Xiong] UMass Amherst, Amherst, MA USA.
   [Stefkovics, Adam] REN Ctr Social Sci, HUN, Budapest, Hungary.
   [Beyer, Johanna; Pfister, Hanspeter] Harvard Univ, Cambridge, MA USA.
   [Moerth, Eric] Harvard Med Sch, Boston, MA USA.
   [Nobre, Carolina] Univ Toronto, Toronto, ON, Canada.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   Harvard University; Harvard University; Harvard Medical School;
   University of Toronto
RP Nobre, C (corresponding author), Univ Toronto, Toronto, ON, Canada.
EM helhamdadi@umass.edu; stefkovics.adam@tk.hu; jbeyer@g.harvard.edu;
   ericmoerth@g.harvard.edu; hpfister@g.harvard.edu;
   cindy.xiong@cs.umass.edu; cnobre@cs.toronto.edu
OI Pfister, Hanspeter/0000-0002-3620-2582; Morth, Eric/0000-0003-1625-0146;
   Stefkovics, Adam/0000-0003-4961-7792; Elhamdadi,
   Hamza/0009-0006-8767-0681; Xiong Bearfield, Cindy/0000-0002-1451-4083;
   Beyer, Johanna/0000-0002-3505-9171; Nobre, Carolina/0000-0002-2892-0509
FU NSF
FX No Statement Available
CR Artz D, 2007, J WEB SEMANT, V5, P58, DOI 10.1016/j.websem.2007.03.002
   Atoyan Hasmik, 2006, P 18 C INT HOMM MACH, P115, DOI [10.1145/1132736.1132751, DOI 10.1145/1132736.1132751]
   Beauxis-Aussalet E., IEEE Computer Graphics and Applications, V41
   BERG J, 1995, GAME ECON BEHAV, V10, P122, DOI 10.1006/game.1995.1027
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Bhandari U, 2019, INFORM MANAGE-AMSTER, V56, P85, DOI 10.1016/j.im.2018.07.003
   Borgonovi F, 2012, BRIT J SOCIOL, V63, P146, DOI 10.1111/j.1468-4446.2011.01397.x
   CACIOPPO JT, 1982, J PERS SOC PSYCHOL, V42, P116, DOI 10.1037/0022-3514.42.1.116
   Carlin RE, 2018, BRIT J POLIT SCI, V48, P115, DOI 10.1017/S0007123415000526
   Chua RYJ, 2008, ACAD MANAGE J, V51, P436
   Coelho GLD, 2020, ASSESSMENT, V27, P1870, DOI 10.1177/1073191118793208
   Costante E., 2011, 2011 Workshop on Socio-Technical Aspects in Security and Trust, P52, DOI 10.1109/STAST.2011.6059256
   Dang JH, 2020, TRENDS COGN SCI, V24, P267, DOI 10.1016/j.tics.2020.01.007
   Dasgupta A, 2017, IEEE T VIS COMPUT GR, V23, P271, DOI 10.1109/TVCG.2016.2598544
   Dimoka A, 2010, MIS QUART, V34, P373
   Duncan S, 2007, COGNITION EMOTION, V21, P1184, DOI 10.1080/02699930701437931
   Dunn JR, 2005, J PERS SOC PSYCHOL, V88, P736, DOI 10.1037/0022-3514.88.5.736
   Elhamdadi H, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P85, DOI 10.1109/BELIV57783.2022.00014
   Elhamdadi H, 2022, Arxiv, DOI arXiv:2209.14340
   Evans AM, 2008, J RES PERS, V42, P1585, DOI 10.1016/j.jrp.2008.07.011
   Gutzwiller Robert S., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P217, DOI 10.1177/1071181319631201
   HOCH SJ, 1991, J CONSUM RES, V17, P492, DOI 10.1086/208573
   Hooghe M, 2012, INTELLIGENCE, V40, P604, DOI 10.1016/j.intell.2012.08.006
   Jahansoozi J, 2006, J MANAG DEV, V25, P942, DOI 10.1108/02621710610708577
   Jian Jiun-Yin, 2000, INT J COGNITIVE ERGO, V4, P53, DOI DOI 10.1207/S15327566IJCE0401_04
   Jun Zheng, 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P141, DOI 10.1145/503376.503402
   Kelton K, 2008, J AM SOC INF SCI TEC, V59, P363, DOI 10.1002/asi.20722
   Kiesler S., 1997, Human values and the design of computer technology, P2
   Kim Y. S., 2020, Designing Belief-driven Interactions with Data
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Kock N, 2012, J ASSOC INF SYST, V13, P546, DOI 10.17705/1jais.00302
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Landwehr JR, 2020, J EXP SOC PSYCHOL, V90, DOI 10.1016/j.jesp.2020.103997
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Liao M., 2022, USER TRUST RECOMMEND, P1, DOI [10.1145/3491102.35019362, DOI 10.1145/3491102.35019362]
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Mayr E., 2019, EUROVIS WORKSHOP TRU, P1, DOI [10.2312/trvis.201911872,3,4, DOI 10.2312/TRVIS.201911872,3,4]
   MCALLISTER DJ, 1995, ACAD MANAGE J, V38, P24, DOI 10.5465/256727
   Myers CD, 2016, POLIT ANAL, V24, P492, DOI 10.1093/pan/mpw026
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Padilla Lace, 2023, IEEE Trans Vis Comput Graph, V29, P12, DOI 10.1109/TVCG.2022.3209457
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Rieh S. Y., 1998, Journal of The American Society for Information Science and Technology-JASIS, V35, P3
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Schnackenberg AK, 2016, J MANAGE, V42, P1784, DOI 10.1177/0149206314525202
   Sohn S, 2017, J RETAIL CONSUM SERV, V36, P137, DOI 10.1016/j.jretconser.2017.01.008
   Sturgis P, 2010, INTELLIGENCE, V38, P45, DOI 10.1016/j.intell.2009.11.006
   Thorndike EL, 1920, J APPL PSYCHOL, V4, P25, DOI 10.1037/h0071663
   Tomlinson EC, 2020, J ORGAN BEHAV, V41, P535, DOI 10.1002/job.2448
   van der Bles AM, 2020, P NATL ACAD SCI USA, V117, P7672, DOI 10.1073/pnas.1913678117
   van der Bles AM, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181870
   WETZEL CG, 1981, J EXP SOC PSYCHOL, V17, P427, DOI 10.1016/0022-1031(81)90049-4
   Xiong C., 2019, 1 EUROVIS WORKSH TRU, P19
   Yin MY, 2019, IEEE CONF WIREL MOB, DOI [10.1109/wimob.2019.8923576, 10.1145/3290605.3300509]
   Yu K., 2016, P 2016 C US MOD AD P, P223, DOI DOI 10.1145/2930238.2930290
   Yu K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P307, DOI 10.1145/3025171.3025219
   Zehrung R, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445195
   Zhang P, 2013, MIS QUART, V37, P247
   Zhang Y., 2022, Association for Computing Machinery, DOI [10.1145/3491102.35018892,9, DOI 10.1145/3491102.35018892,9]
   Zhou JL, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312962
   Zhou M. X., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P392, DOI 10.1145/274644.274698
NR 62
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 348
EP 358
DI 10.1109/TVCG.2023.3326579
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500083
PM 37922171
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Jiang, ZH
   Chen, HD
   Zhou, R
   Deng, J
   Zhang, XC
   Zhao, RN
   Xie, C
   Wang, YF
   Ngai, ECH
AF Jiang, Zhihan
   Chen, Handi
   Zhou, Rui
   Deng, Jing
   Zhang, Xinchen
   Zhao, Running
   Xie, Cong
   Wang, Yifang
   Ngai, Edith C. H.
TI <i>HealthPrism:</i> A Visual Analytics System for Exploring Children's
   Physical and Mental Health Profiles with Multimodal Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual Analytics; Health Profiling; Multimodal Learning; Context Data;
   Motion Data
ID VISUALIZATION; RESILIENCE; DASHBOARDS
AB The correlation between children's personal and family characteristics (e.g., demographics and socioeconomic status) and their physical and mental health status has been extensively studied across various research domains, such as public health, medicine, and data science. Such studies can provide insights into the underlying factors affecting children's health and aid in the development of targeted interventions to improve their health outcomes. However, with the availability of multiple data sources, including context data (i.e., the background information of children) and motion data (i.e., sensor data measuring activities of children), new challenges have arisen due to the large-scale, heterogeneous, and multimodal nature of the data. Existing statistical hypothesis-based and learning model-based approaches have been inadequate for comprehensively analyzing the complex correlation between multimodal features and multi-dimensional health outcomes due to the limited information revealed. In this work, we first distill a set of design requirements from multiple levels through conducting a literature review and iteratively interviewing 11 experts from multiple domains (e.g., public health and medicine). Then, we propose HealthPrism, an interactive visual and analytics system for assisting researchers in exploring the importance and influence of various context and motion features on children's health status from multi-level perspectives. Within HealthPrism, a multimodal learning model with a gate mechanism is proposed for health profiling and cross-modality feature importance comparison. A set of visualization components is designed for experts to explore and understand multimodal data freely. We demonstrate the effectiveness and usability of HealthPrism through quantitative evaluation of the model performance, case studies, and expert interviews in associated domains.
C1 [Jiang, Zhihan; Chen, Handi; Zhou, Rui; Deng, Jing; Zhang, Xinchen; Zhao, Running; Ngai, Edith C. H.] Univ Hong Kong, Hong Kong, Peoples R China.
   [Xie, Cong] Tencent, Shenzhen, Peoples R China.
   [Wang, Yifang] Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
C3 University of Hong Kong; Tencent; Northwestern University
RP Wang, YF (corresponding author), Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
EM zhjiang@connect.hku.hk; hdchen@connect.hku.hk; zackery@connect.hku.hk;
   u3008395@connect.hku.hk; u3008407@connect.hku.hk; rnzhao@connect.hku.hk;
   xie.cong@outlook.com; yifang.wang@kellogg.northwestern.edu;
   chngai@eee.hku.hk
OI Zhou, Rui/0009-0002-3229-0324; Chen, Handi/0000-0002-4223-3502; Zhang,
   Xinchen/0000-0003-3650-7332; Wang, Yifang/0000-0001-6267-9440; Jiang,
   Zhihan/0000-0003-4857-7143
FU GRF
FX No Statement Available
CR Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Arras L., 2017, WASSA, P159, DOI DOI 10.18653/V1/W17-5221
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bernard J, 2019, IEEE T VIS COMPUT GR, V25, P1615, DOI 10.1109/TVCG.2018.2803829
   Bradley RH, 2002, ANNU REV PSYCHOL, V53, P371, DOI 10.1146/annurev.psych.53.100901.135233
   Brown CD, 2006, CHEMOMETR INTELL LAB, V80, P24, DOI 10.1016/j.chemolab.2005.05.004
   Cao L, 2022, IEEE T MULTIMEDIA, V24, P87, DOI 10.1109/TMM.2020.3046867
   Chang JX, 2023, Arxiv, DOI arXiv:2302.01115
   Charette RN, 2005, IEEE SPECTRUM, V42, P42, DOI 10.1109/MSPEC.2005.1502528
   Chen C, 2019, AAAI CONF ARTIF INTE, P865
   Cheng FR, 2022, IEEE T VIS COMPUT GR, V28, P378, DOI 10.1109/TVCG.2021.3114836
   Choi E, 2016, ADV NEUR IN, V29
   Connor KM, 2003, DEPRESS ANXIETY, V18, P76, DOI 10.1002/da.10113
   Duangsoithong R, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P247, DOI 10.1109/ICAPR.2009.36
   Dudley JJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3185517
   Echarts.js, About us
   Eckelt K., 2022, IEEE VIS WORKSHOP VI, P2022, DOI [10.1101/2022.08.16.5036222, DOI 10.1101/2022.08.16.5036222]
   Elshehaly M, 2021, IEEE T VIS COMPUT GR, V27, P689, DOI 10.1109/TVCG.2020.3030424
   Garber CE, 2010, BMC GERIATR, V10, DOI 10.1186/1471-2318-10-6
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Hakone A, 2017, IEEE T VIS COMPUT GR, V23, P601, DOI 10.1109/TVCG.2016.2598588
   Hara S, 2018, PR MACH LEARN RES, V84
   HARRINGTON PD, 1993, ANAL CHEM, V65, P2167, DOI 10.1021/ac00063a042
   Herdman M, 2011, QUAL LIFE RES, V20, P1727, DOI 10.1007/s11136-011-9903-x
   Huang TW, 2020, Arxiv, DOI arXiv:2007.03519
   Huber F., 2018, A logical introduction to probability and induction, V5, P6
   Jayalakshmi T., 2011, International Journal of Computer Theory and Engineering, V3, P1793, DOI [DOI 10.7763/IJCTE.2011.V3.288, 10.7763/IJCTE.2011.V3.288]
   Jiang ZH, 2023, IEEE T MOBILE COMPUT, V22, P1401, DOI 10.1109/TMC.2021.3110592
   Jiang ZH, 2023, PROC ACM INTERACT MO, V7, DOI 10.1145/3580800
   Jylhä M, 2009, SOC SCI MED, V69, P307, DOI 10.1016/j.socscimed.2009.05.013
   Kaminski M., 2013, The stochastic perturbation method for computational mechanics, DOI [10.1002/9781118481844.ch15, DOI 10.1002/9781118481844.CH15]
   Kaplan MS, 2001, AM J PREV MED, V21, P306, DOI 10.1016/S0749-3797(01)00364-6
   Karl M., 2017, INT C LEARNING REPRE, DOI [10.48550/arXiv.1605.06432 3, DOI 10.48550/ARXIV.1605.064323]
   Karn S.K., 2003, Economic and Political Weekly, P3575
   Kato T, 2005, MOL PSYCHIATR, V10, P622, DOI 10.1038/sj.mp.4001662
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Kwon BC, 2016, IEEE T VIS COMPUT GR, V22, P71, DOI 10.1109/TVCG.2015.2467555
   Lee JJ, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/15403
   Loorak MH, 2016, IEEE T VIS COMPUT GR, V22, P409, DOI 10.1109/TVCG.2015.2467325
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma C, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P825, DOI 10.1145/3292500.3330984
   Ma HD, 2014, IEEE COMMUN MAG, V52, P29, DOI 10.1109/MCOM.2014.6871666
   Malarvizhi R., 2012, International Journal of Engineering Research and Development, V5, P4
   Mansoor H, 2021, IEEE COMPUT GRAPH, V41, P96, DOI 10.1109/MCG.2021.3062474
   Masten A. S., 2002, Handbook of Positive Psychology, P3
   Matkovic K, 2008, IEEE INT CONF INF VI, P215, DOI 10.1109/IV.2008.87
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mollyn V, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3550284
   Moon S, 2022, Arxiv, DOI arXiv:2210.14395
   Munzner T., 2014, Visualization analysis and design, P6
   Polanin JR, 2021, PSYCHOL BULL, V147, P115, DOI 10.1037/bul0000314
   Rew L, 2001, J NURS SCHOLARSHIP, V33, P33, DOI 10.1111/j.1547-5069.2001.00033.x
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Scheer J, 2022, J MED INTERNET RES, V24, DOI 10.2196/38041
   Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00392-9
   Tolomei G, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P465, DOI 10.1145/3097983.3098039
   U. D. of Health and H. Services, 2000, Health disparities: Bridging the gap, P2
   Varni James W, 2005, Expert Rev Pharmacoecon Outcomes Res, V5, P705, DOI 10.1586/14737167.5.6.705
   Vue.js, About us
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Waring J, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101822
   World Health Organization, 2008, Pacific physical activity guidelines for adults: Framework for accelerating the communication of physical activity guidelines, P2
   World Health Organization, 2010, Global recommendations on physical activity for health, P3
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Zhang ZY, 2013, IEEE T VIS COMPUT GR, V19, P1895, DOI 10.1109/TVCG.2013.89
   Zhou Binbin, 2023, Personal and Ubiquitous Computing, P599, DOI 10.1007/s00779-020-01456-6
   Zhuang MD, 2022, IEEE T VIS COMPUT GR, V28, P1715, DOI 10.1109/TVCG.2022.3147154
NR 69
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1205
EP 1215
DI 10.1109/TVCG.2023.3326943
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500065
PM 37874717
DA 2024-08-05
ER

PT J
AU Shen, LX
   Zhang, YZ
   Zhang, HD
   Wang, Y
AF Shen, Leixian
   Zhang, Yizhi
   Zhang, Haidong
   Wang, Yun
TI Data Player: Automatic Generation of Data Videos with
   Narration-Animation Interplay
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Narration-animation interplay; Data video; Human-AI
   collaboration
ID VISUALIZATION; STORIES
AB Data visualizations and narratives are often integrated to convey data stories effectively. Among various data storytelling formats, data videos have been garnering increasing attention. These videos provide an intuitive interpretation of data charts while vividly articulating the underlying data insights. However, the production of data videos demands a diverse set of professional skills and considerable manual labor, including understanding narratives, linking visual elements with narration segments, designing and crafting animations, recording audio narrations, and synchronizing audio with visual animations. To simplify this process, our paper introduces a novel method, referred to as Data Player, capable of automatically generating dynamic data videos with narration-animation interplay. This approach lowers the technical barriers associated with creating data videos rich in narration. To enable narration-animation interplay, Data Player constructs references between visualizations and text input. Specifically, it first extracts data into tables from the visualizations. Subsequently, it utilizes large language models to form semantic connections between text and visuals. Finally, Data Player encodes animation design knowledge as computational low-level constraints, allowing for the recommendation of suitable animation presets that align with the audio narration produced by text-to-speech technologies. We assessed Data Player's efficacy through an example gallery, a user study, and expert interviews. The evaluation results demonstrated that Data Player can generate high-quality data videos that are comparable to human-composed ones.
C1 [Shen, Leixian] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Zhang, Yizhi] Cornell Univ, Ithaca, NY USA.
   [Zhang, Haidong; Wang, Yun] Microsoft Res Asia MSRA, Beijing, Peoples R China.
   [Shen, Leixian; Zhang, Yizhi] MSRA, Beijing, Peoples R China.
C3 Hong Kong University of Science & Technology; Cornell University
RP Wang, Y (corresponding author), Microsoft Res Asia MSRA, Beijing, Peoples R China.
EM lshenaj@connect.ust.hk; yz2668@cornell.edu; haizhang@microsoft.com;
   wangyun@microsoft.com
CR Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Badam S. K., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P5
   Cao YN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581472
   Chen Q., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Chen ZT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1109/TENCON55691.2022.9978005, 10.1145/3491102.3517485]
   Cheng H, 2022, COMPUT GRAPH FORUM, V41, P527, DOI 10.1111/cgf.14560
   Chi Peggy, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P677, DOI 10.1145/3472749.3474778
   Chi Peggy, 2020, P 33 ANN ACM S USER, P279, DOI 10.1145/3379337
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24
   deeplearning, Chatgpt prompt engineering for developers
   ffmpeg, Ffmpeg multimedia framework
   Ge T, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.14005
   Ge T., 2021, P 2021 CHI C HUM FAC, P1
   greensock, Gsap animation platform
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hohman F, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P151, DOI [10.1109/visual.2019.8933695, 10.1109/VISUAL.2019.8933695]
   Hook J, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P43, DOI 10.1145/3210825.3210826
   Kim DH, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P423, DOI 10.1145/3242587.3242617
   Kim Y., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2
   Kim Y, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P201, DOI [10.1109/VIS49827.2021.9623291, 10.1109/VIS49827.2021.00048]
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775
   Latif S., 2021, IEEE Transactions on Visualization and Computer Graphics
   Li HT, 2023, Arxiv, DOI arXiv:2304.08366
   Li HT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502048
   Li W., 2023, P 2023 CHI C HUM FAC, V1, P1
   Lin Y., 2023, IEEE Transactions on Visualization and Computer Graphics, V14, P9
   Liu V., 2022, P 2022 CHI C HUM FAC, P1
   Luo Y., 2023, Proceedings of the ACM on Management of Data, SIGMOD'23, V1, P1
   Masson D., 2023, ACM C HUM FACT COMP
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Metoyer R, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P503, DOI 10.1145/3172944.3173007
   microsoft, Microsoft azure text-to-speech service
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Ruoff M., P 2023 CHI C HUM FAC, P1
   Russell D. M., 2014, Ways of Knowing in HCI, P3
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075
   Shen Hua, 2023, arXiv
   Shen L., 2021, P 23 EUR C VIS SHORT, DOI [DOI 10.2312/EVS.20211061, 10.2312/evs.20211061]
   Shen L., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159
   Shen LX, 2022, DATA SCI ENG, V7, P354, DOI 10.1007/s41019-022-00195-3
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Swearngin A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376593
   Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974
   Thompson J., 2021, P ACM C HUM FACT COM, P2
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI [10.1006/ijhc.2002.1017, 10.1006/ijhc.1017]
   Wang Y., 2023, WonderFlow: Narration-Centric Design of Animated Data Videos, P1
   Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wang Y, 2021, COMPUT GRAPH FORUM, V40, P507, DOI 10.1111/cgf.14325
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Xie L., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Xu H., 2014, P 27 ANN ACM S US IN, P243, DOI DOI 10.1145/2642918.2647398
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
NR 68
TC 2
Z9 2
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 109
EP 119
DI 10.1109/TVCG.2023.3327197
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500118
PM 37922173
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wurster, SW
   Xiong, TY
   Shen, HW
   Guo, HQ
   Peterka, T
AF Wurster, Skylar W.
   Xiong, Tianyu
   Shen, Han-Wei
   Guo, Hanqi
   Peterka, Tom
TI Adaptively Placed Multi-Grid Scene Representation Networks for
   Large-Scale Data Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Adaptation models; Data models; Solid modeling; Computer
   architecture; Rendering (computer graphics); Encoding; Scene
   representation network; deep learning; scientific visualization; volume
   rendering
AB Scene representation networks (SRNs) have been recently proposed for compression and visualization of scientific data. However, state-of-the-art SRNs do not adapt the allocation of available network parameters to the complex features found in scientific data, leading to a loss in reconstruction quality. We address this shortcoming with an adaptively placed multi-grid SRN (APMGSRN) and propose a domain decomposition training and inference technique for accelerated parallel training on multi-GPU systems. We also release an open-source neural volume rendering application that allows plug-and-play rendering with any PyTorch-based SRN. Our proposed APMGSRN architecture uses multiple spatially adaptive feature grids that learn where to be placed within the domain to dynamically allocate more neural network resources where error is high in the volume, improving state-of-the-art reconstruction accuracy of SRNs for scientific data without requiring expensive octree refining, pruning, and traversal like previous adaptive models. In our domain decomposition approach for representing large-scale data, we train an set of APMGSRNs in parallel on separate bricks of the volume to reduce training time while avoiding overhead necessary for an out-of-core solution for volumes too large to fit in GPU memory. After training, the lightweight SRNs are used for realtime neural volume rendering in our open-source renderer, where arbitrary view angles and transfer functions can be explored.
C1 [Wurster, Skylar W.] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Wurster, SW (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM wurster.18@osu.edu; xiong.336@osu.edu; hwshen@cse.ohio-state.edu;
   guo.2154@osu.edu; tpeterka@mcs.anl.gov
RI ; Guo, Hanqi/ADW-4234-2022
OI Wurster, Skylar/0000-0001-6685-615X; Guo, Hanqi/0000-0001-7776-1834
FU US Department of Energy SciDAC program
FX No Statement Available
CR Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Chen AP, 2022, LECT NOTES COMPUT SC, V13692, P333, DOI 10.1007/978-3-031-19824-3_20
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Han J, 2023, IEEE T VIS COMPUT GR, V29, P4951, DOI 10.1109/TVCG.2022.3197203
   Hohlein K., 2022, Vision, Modeling, and Visualization, DOI [10.2312/vmv.202211982, DOI 10.2312/VMV.202211982]
   Kingma D., 2015, P INT C LEARN REPR S, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Lee M, 2015, J FLUID MECH, V774, P395, DOI 10.1017/jfm.2015.268
   Li RL, 2022, Arxiv, DOI arXiv:2210.04847
   Li Y, 2008, J TURBUL, V9, P1, DOI 10.1080/14685240802376389
   Liang X, 2023, IEEE T BIG DATA, V9, P485, DOI 10.1109/TBDATA.2022.3201176
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu L., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   Mildenhall B., 2020, PROC EUROPEAN C COMP
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Muller T., tiny-cuda-nn
   Paszke A, 2019, ADV NEUR IN, V32
   Perlman E., 2007, PROC ACMIEEE C SUPER, P1
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Sitzmann V., 2020, Proc. NeurIPS
   Takikawa Towaki, 2021, arXiv
   Tancik M., 2020, ADV NEURAL INFORM PR, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tancik M, 2022, PROC CVPR IEEE, P8238, DOI 10.1109/CVPR52688.2022.00807
   Treib M, 2012, IEEE T VIS COMPUT GR, V18, P2169, DOI 10.1109/TVCG.2012.274
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Wu Q., 2023, Hyperinr: A fast and predictive hypernetwork for implicit neural representations via knowledge distillation, V3, P9
   Wu Q, 2022, Arxiv, DOI arXiv:2207.11620
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Zhao K, 2021, PROC INT CONF DATA, P1643, DOI 10.1109/ICDE51399.2021.00145
NR 35
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 965
EP 974
DI 10.1109/TVCG.2023.3327194
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500072
PM 37883276
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhang, Y
   Jiang, RK
   Xie, LWH
   Zhao, YH
   Liu, C
   Ding, TH
   Chen, SM
   Yuan, XR
AF Zhang, Yu
   Jiang, Ruike
   Xie, Liwenhan
   Zhao, Yuheng
   Liu, Can
   Ding, Tianhong
   Chen, Siming
   Yuan, Xiaoru
TI OldVisOnline: Curating a Dataset of Historical Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Historical visualization; dataset; digital humanities; data labeling
ID ART
AB With the increasing adoption of digitization, more and more historical visualizations created hundreds of years ago are accessible in digital libraries online. It provides a unique opportunity for visualization and history research. Meanwhile, there is no large-scale digital collection dedicated to historical visualizations. The visualizations are scattered in various collections, which hinders retrieval. In this study, we curate the first large-scale dataset dedicated to historical visualizations. Our dataset comprises 13K historical visualization images with corresponding processed metadata from seven digital libraries. In curating the dataset, we propose a workflow to scrape and process heterogeneous metadata. We develop a semi-automatic labeling approach to distinguish visualizations from other artifacts. Our dataset can be accessed with OldVisOnline, a system we have built to browse and label historical visualizations. We discuss our vision of usage scenarios and research opportunities with our dataset, such as textual criticism for historical visualizations. Drawing upon our experience, we summarize recommendations for future efforts to improve our dataset.
C1 [Zhang, Yu] Univ Oxford, Dept Comp Sci, Oxford, England.
   [Jiang, Ruike; Liu, Can; Yuan, Xiaoru] Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.
   [Jiang, Ruike; Liu, Can; Yuan, Xiaoru] Peking Univ, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
   [Zhao, Yuheng; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Xie, Liwenhan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Ding, Tianhong] Huawei Technol, Fundamental Software Innovat Lab, Shenzhen, Peoples R China.
C3 University of Oxford; Peking University; Peking University; Fudan
   University; Hong Kong University of Science & Technology; Huawei
   Technologies
RP Yuan, XR (corresponding author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Sch Intelligence Sci & Technol, Beijing, Peoples R China.; Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
EM yuzhang94@outlook.com; jiangrk@pku.edu.cn; liwenhan.xie@connect.ust.hk;
   yuhengzhao@fudan.edu.cn; can.liu@pku.edu.cn; dingtianhong@huawei.com;
   simingchen@fudan.edu.cn; xiaoru.yuan@pku.edu.cn
RI Xie, Liwenhan/HLV-8177-2023
OI Xie, Liwenhan/0000-0002-2601-6313; Liu, Can/0000-0002-1175-0734; Zhao,
   Yuheng/0000-0003-1573-8772; Yuan, Xiaoru/0000-0002-7233-980X; Jiang,
   Ruike/0000-0002-5001-5310; Zhang, Yu/0000-0002-9035-0463
FU NSFC
FX No Statement Available
CR [Anonymous], 2019, ISO 8601-1:2019
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Beck F, 2016, IEEE T VIS COMPUT GR, V22, P180, DOI 10.1109/TVCG.2015.2467757
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   British Library, 1973, British library
   Cartographic Research Laboratory, Alabama maps
   Chen C, 2023, COMPUT GRAPH FORUM, V42, P449, DOI 10.1111/cgf.14855
   Chen J, 2022, Arxiv, DOI arXiv:2209.07533
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831
   Crissaff L, 2018, IEEE COMPUT GRAPH, V38, P91, DOI 10.1109/MCG.2017.377152546
   Deng D., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.32135652,7
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Digital Public Library of America, 2013, Digital public library of America
   Dodson R., 1994, Snow's cholera map
   Foster C., 2017, P DIG HUM C DH 17, V7, P8
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Friendly M., 2001, Milestones in the history of thematic cartography, statistical graphics, and data visualization, V1, P2
   Friendly M, 2010, AM STAT, V64, P174, DOI 10.1198/tast.2010.09154
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   International Image Interoperability Framework, 2011, International image interoperability framework
   International Organization for Standardization, 2007, ISO 639-3:2007 Codes for the representation of names of languages-Part 3: Alpha-3 code for comprehensive coverage of languages
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Kahle B. L., 1996, Internet archive
   Kerle N, 2009, IEEE T GEOSCI REMOTE, V47, P2392, DOI 10.1109/TGRS.2008.2010853
   Khulusi R, 2019, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2019.00038
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Klein L., 2022, Harvard Data Science Review, V4, DOI [10.1162/99608f92.5dec149c2,7,8, DOI 10.1162/99608F92.5DEC149C2,7,8]
   Klokan Technologies GmbH, Old maps online
   Koch T., 2004, Cartographica, V39, P1, DOI [DOI 10.3138/B123-8124-4390-5792, https://doi.org/10.3138/B123-8124-4390-5792]
   Kosara R, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P162, DOI 10.1145/2993901.2993909
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kucher K, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/3132169
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Kulesza T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3075, DOI 10.1145/2556288.2557238
   Lee PS, 2018, IEEE T BIG DATA, V4, P117, DOI 10.1109/TBDATA.2017.2689038
   Library of Congress, LIB C DIG COLL
   Lima M., 2014, The Book of Trees: Visualizing Branches of Knowledge, P1
   Lin Y., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32513442, DOI 10.1109/TVCG.2023.32513442]
   Liu XX, 2023, INFORM VISUAL, V22, P3, DOI 10.1177/14738716221126992
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Marey E.-J., 1878, La Methode Graphique dans les Sciences Experimentales et Principalement en Physiologie et en Medecine, P20
   Minard C. J., 1869, Carte figurative des pertes successives en hommes de l'armee francaise dans la campagne de russie 1812-1813, P1
   Modley R., 1938, Telefact: 1938-1945 by pictograph corporation
   Munzner T., 2014, Visualization Analysis and Design, P2
   National Library of France, Gallica
   Oppermann M, 2022, IEEE T VIS COMPUT GR, V28, P747, DOI 10.1109/TVCG.2021.3114841
   Owain G., 1489, Hen Almanac Cymreig & C., P9
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Peabody E. P., 1856, Chronological History of the United States: Arranged with Plates on Bem's Principle, P15
   Pflüger H, 2020, IEEE T VIS COMPUT GR, V26, P3063, DOI 10.1109/TVCG.2019.2908166
   Playfair W., 1801, The Statistical Breviary: Shewing, on a Principle Entirely New, the Resources of Every State and Kingdom in Europe, P3
   Playfair W., 1801, The Commercial and Political Atlas: Representing, by Means of Stained Copper-Plate Charts, the Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the Whole of the Eighteenth Century, Vthird, P36
   Priestley J., 1803, Lectures on History and General Policy, P262
   Priestley J., 1764, A Description of a Chart of Biography, P7
   Radford A, 2021, PR MACH LEARN RES, V139
   Rendgen S., 2019, History of Information Graphics, P1
   Robinson A.H., 1967, IMAGO MUNDI, V21, P95, DOI [10.1016/0169-328x(95)00056-x, DOI 10.1016/0169-328X(95)00056-X]
   Rumsey D., David Rumsey map collection
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Settles B., 2009, Active learning literature survey, P5
   Settles B., 2011, P C EMP METH NAT LAN, P5
   Shiode N, 2015, INT J HEALTH GEOGR, V14, DOI 10.1186/s12942-015-0011-y
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Simonyan A., 2014, arXiv
   Snow J., 1855, On the Mode of Communication of Cholera, P44
   Snow J., 1936, Snow on Cholera: Being a Reprint of Two Papers by John Snow, M.D., P44
   Stoppel S, 2017, IEEE T VIS COMPUT GR, V23, P861, DOI 10.1109/TVCG.2016.2599211
   Sutherland I. E., 1963, Sketchpad, a Man-Machine Graphical Communication System, P2
   Tufte E. R., 1983, The Visual Display of Quantitative Information, P1
   von Spaeth O., 2000, Centaurus, V42, P159
   Wikimedia Foundation, 2004, Wikimedia commons
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Ye YL, 2024, IEEE T VIS COMPUT GR, V30, P3224, DOI 10.1109/TVCG.2022.3229023
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhang Y., 2023, ACM Transactions on Interactive Intelligent Systems, DOI DOI 10.1145/35945525
   Zhang Y, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517612
   Zhang Y, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3412848
NR 91
TC 1
Z9 1
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 551
EP 561
DI 10.1109/TVCG.2023.3326908
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500123
PM 37874726
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Angelini, M
   Blasilli, G
   Lenti, S
   Santucci, G
AF Angelini, Marco
   Blasilli, Graziano
   Lenti, Simone
   Santucci, Giuseppe
TI A Visual Analytics Conceptual Framework for Explorable and Steerable
   Partial Dependence Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Predictive models; Computational modeling; Machine learning; Analytical
   models; Visual analytics; Market research; Behavioral sciences; partial
   dependence plot; visual analytics
AB Machine learning techniques are a driving force for research in various fields, from credit card fraud detection to stock analysis. Recently, a growing interest in increasing human involvement has emerged, with the primary goal of improving the interpretability of machine learning models. Among different techniques, Partial Dependence Plots (PDP) represent one of the main model-agnostic approaches for interpreting how the features influence the prediction of a machine learning model. However, its limitations (i.e., visual interpretation, aggregation of heterogeneous effects, inaccuracy, and computability) could complicate or misdirect the analysis. Moreover, the resulting combinatorial space can be challenging to explore both computationally and cognitively when analyzing the effects of more features at the same time. This article proposes a conceptual framework that enables effective analysis workflows, mitigating state-of-the-art limitations. The proposed framework allows for exploring and refining computed partial dependences, observing incrementally accurate results, and steering the computation of new partial dependences on user-selected subspaces of the combinatorial and intractable space. With this approach, the user can save both computational and cognitive costs, in contrast with the standard monolithic approach that computes all the possible combinations of features on all their domains in batch. The framework is the result of a careful design process involving experts' knowledge during its validation and informed the development of a prototype, W4SP(1), that demonstrates its applicability traversing its different paths. A case study shows the advantages of the proposed approach.
C1 [Angelini, Marco; Lenti, Simone] Roma Sapienza Univ Rome, I-00185 Rome, Italy.
RP Lenti, S (corresponding author), Roma Sapienza Univ Rome, I-00185 Rome, Italy.
EM angelini@dis.uniroma1.it; blasilli@diag.uniroma1.it;
   lenti@diag.uniroma1.it; santucci@diag.uniroma1.it
RI ; Santucci, Giuseppe/F-3907-2011
OI Angelini, Marco/0000-0001-9051-6972; Blasilli,
   Graziano/0000-0003-3339-6403; Santucci, Giuseppe/0000-0003-4350-1123;
   Lenti, Simone/0000-0001-8281-3723
CR Angelini G., 2018, Informatics, V5
   Apley DW, 2020, J ROY STAT SOC B, V82, P1059, DOI 10.1111/rssb.12377
   Berk RA, 2013, CRIMINOL PUBLIC POL, V12, P513, DOI 10.1111/1745-9133.12047
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Britton M, 2019, Arxiv, DOI arXiv:1904.00561
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chipman HA, 2010, ANN APPL STAT, V4, P266, DOI 10.1214/09-AOAS285
   Collaris J. J., 2020, P 13 INT S VIS INF C
   Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
   Dua D., 2017, UCI Machine Learning Repository
   Fekete D., 2019, Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik
   Floricel C, 2022, IEEE T VIS COMPUT GR, V28, P151, DOI 10.1109/TVCG.2021.3114810
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2003, STAT MED, V22, P1365, DOI 10.1002/sim.1501
   Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095
   Green DP, 2012, PUBLIC OPIN QUART, V76, P491, DOI 10.1093/poq/nfs036
   Greenwell BM, 2017, R J, V9, P421
   Gromping U., 2020, Tech. Rep.
   Hastie T., 2009, ELEMENTS STAT LEARNI, DOI DOI 10.1007/978-0-387-84858-7
   Hogräfer M, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3531229
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Kwon B.C., 2020, P 37 INT C MACH LEAR, DOI [10.13140/RG.2.2.35685.63208, DOI 10.13140/RG.2.2.35685.63208]
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Lundberg SM, 2017, ADV NEUR IN, V30
   Greenwell BM, 2018, Arxiv, DOI [arXiv:1805.04755, 10.48550/arXiv.1805.04755]
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Molnar C, 2021, Interpretable Machine Learning: A Guide for Making Black Box Models Explainable
   Moosbauer J., 2021, Advances in Neural Information Processing Systems, V34, P2280
   Mulder JD, 1999, FUTURE GENER COMP SY, V15, P119, DOI 10.1016/S0167-739X(98)00047-8
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   RAO R, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P318, DOI 10.1145/191666.191776
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ribeiro M. T., 2016, KDD 16 P 22 ACM SIGK, DOI [DOI 10.1145/2939672.2939778, 10.1145/2939672.2939778]
   Richer A., IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3231230.52M, DOI 10.1109/TVCG.2022.3231230.52M]
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Sankaran M, 2008, GLOBAL ECOL BIOGEOGR, V17, P236, DOI 10.1111/j.1466-8238.2007.00360.x
   SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605
   Silverman B., 1986, DENSITY ESTIMATION S, DOI [10.1201/9781315140919, DOI 10.1201/9781315140919]
   Sorensen TA, 2012, ACTA PSYCHOL, V140, P158, DOI 10.1016/j.actpsy.2012.04.004
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sturges HA, 1926, J AM STAT ASSOC, V21, P65, DOI 10.1080/01621459.1926.10502161
   Talbot J, 2012, IEEE T VIS COMPUT GR, V18, P2613, DOI 10.1109/TVCG.2012.196
   Tamagnini J., 2017, P 2 WORKSH HUM IN TH
   Ribeiro MT, 2016, Arxiv, DOI [arXiv:1606.05386, DOI 10.48550/ARXIV.1606.05386]
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   van den Elzen S, 2013, COMPUT GRAPH FORUM, V32, P191, DOI 10.1111/cgf.12106
   Van Someren Y. F., The Think Aloud Method:A Practical Approach to Modelling Cognitive, V11
   vanLiere R, 1997, FUTURE GENER COMP SY, V12, P441, DOI 10.1016/S0167-739X(96)00029-5
   Wang C, 2020, Arxiv, DOI arXiv:2011.02149
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhao QY, 2021, J BUS ECON STAT, V39, P272, DOI 10.1080/07350015.2019.1624293
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zhu XZ, 2019, BIORESOURCE TECHNOL, V288, DOI 10.1016/j.biortech.2019.121527
NR 56
TC 2
Z9 2
U1 4
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4497
EP 4513
DI 10.1109/TVCG.2023.3263739
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400033
PM 37027262
OA Green Published
DA 2024-08-05
ER

PT J
AU Chittaro, L
AF Chittaro, Luca
TI Improving Knowledge Retention and Perceived Control Through Serious
   Games: A Study About Assisted Emergency Evacuation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Educational games; user interaction; user study; disability; training;
   safety
ID SELF-EFFICACY; EXTERNAL CONTROL; SAFETY LOCUS; INVOLVEMENT; PERFORMANCE;
   EXPERIENCE; PROMOTE; DESIGN
AB Digital games for education and training, also called serious games (SGs), have shown beneficial effects on learning in several studies. In addition, some studies are suggesting that SGs could improve user's perceived control, which affects the likelihood that the learned content will be applied in the real world. However, most SG studies tend to focus on immediate effects, providing no indication on knowledge and perceived control over time, especially in contrast with nongame approaches. Moreover, SG research on perceived control has focused mainly on self-efficacy, disregarding the complementary construct of locus of control (LOC). This article advances both lines of research, assessing user's knowledge and LOC over time, with a SG as well as traditional printed materials that teach the same content. Results show that the SG was more effective than printed materials for knowledge retention over time, and a better retention outcome was found also for LOC. An additional contribution of the paper is the proposal of a novel SG that targets the inclusivity goal of safe evacuation for all, extending SG research to a domain not dealt with before, i.e., assisting persons with disabilities in emergencies.
C1 [Chittaro, Luca] Univ Udine, Human Comp Interact Lab, Dept Math Comp Sci & Phys, I-33100 Udine, Italy.
C3 University of Udine
RP Chittaro, L (corresponding author), Univ Udine, Human Comp Interact Lab, Dept Math Comp Sci & Phys, I-33100 Udine, Italy.
EM luca.chittaro@uniud.it
OI CHITTARO, Luca/0000-0001-5975-4294
FU Friuli Venezia Giulia region
FX This work was supported by the Friuli Venezia Giulia region through the
   Project Servizi avanzati per il soccorso sanitario al disabile basati su
   tecnologie ICTinnovative (Advanced emergency medical services for the
   disabled based oninnovative ICT technologies). Recommended for
   acceptance by J. Stefanucci.
CR Alrehaili EA, 2022, INTERACT LEARN ENVIR, V30, P922, DOI 10.1080/10494820.2019.1703008
   [Anonymous], International day of sign languages
   Arthur E. A., 2013, Individual andTeam Skill Decay: The Science and Implications for Practice
   Bandura A, 2001, ANNU REV PSYCHOL, V52, P1, DOI 10.1146/annurev.psych.52.1.1
   Bandura A., 1997, Social learning theory, DOI DOI 10.1891/0889-8391.13.2.158
   Boyce K, 2017, FIRE SAFETY J, V91, P28, DOI 10.1016/j.firesaf.2017.05.004
   Boyle EA, 2016, COMPUT EDUC, V94, P178, DOI 10.1016/j.compedu.2015.11.003
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Buttussi F, 2013, INT J MED INFORM, V82, P798, DOI 10.1016/j.ijmedinf.2013.05.007
   Center for Development and Disability, Tips for first responders, V5
   Chee EJM, 2019, GAMES HEALTH J, V8, P187, DOI 10.1089/g4h.2018.0073
   Chittaro L, 2022, IEEE T VIS COMPUT GR, V28, P1573, DOI 10.1109/TVCG.2020.3022340
   Chittaro L, 2019, INT J HUM-COMPUT ST, V127, P112, DOI 10.1016/j.ijhcs.2018.07.006
   Chittaro L, 2016, IEEE T VIS COMPUT GR, V22, P1527, DOI 10.1109/TVCG.2015.2443787
   Chittaro L, 2015, COMPUT HUM BEHAV, V50, P508, DOI 10.1016/j.chb.2015.03.074
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Clark DB, 2016, REV EDUC RES, V86, P79, DOI 10.3102/0034654315582065
   Cohen B.H., 2013, EXPLAINING PSYCHOL S
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Dankbaar MEW, 2017, BMC MED EDUC, V17, DOI 10.1186/s12909-016-0836-5
   Din ZU, 2019, SAFETY SCI, V115, P176, DOI 10.1016/j.ssci.2019.02.005
   Dipartimento dei Vigili del Fuoco, 2004, Il soccorso alle persone disabili
   Federal Aviation Administration, 2022, Advisory Circular AC 120- 32A
   Fu FL, 2009, COMPUT EDUC, V52, P101, DOI 10.1016/j.compedu.2008.07.004
   Grau Rosa, 2002, Int J Occup Saf Ergon, V8, P23
   Haghani M, 2019, J ADV TRANSPORT, V2019, DOI 10.1155/2019/2380348
   HCI Lab University of Udine, Help!-The serious game for IoS
   HCI Lab University of Udine, Help!-The serious game for android
   HOYT MF, 1973, J RES PERS, V7, P288, DOI 10.1016/0092-6566(73)90043-3
   Hu H, 2021, GAMES HEALTH J, V10, P139, DOI 10.1089/g4h.2020.0140
   Hu LY, 2021, FRONT PEDIATR, V9, DOI 10.3389/fped.2021.645776
   Huang JL, 2012, TRANSPORT RES F-TRAF, V15, P358, DOI 10.1016/j.trf.2011.09.002
   Huang LY, 2016, COMPUT HUM BEHAV, V55, P1085, DOI 10.1016/j.chb.2015.10.029
   Hung CM, 2014, J COMPUT EDUC, V1, P151, DOI 10.1007/s40692-014-0008-8
   Hunter DR, 2012, INT J AVIAT PSYCHOL, V22, P144, DOI 10.1080/10508414.2012.663244
   Hunter DR, 2002, AVIAT SPACE ENVIR MD, V73, P1184
   Jabbar AIA, 2015, REV EDUC RES, V85, P740, DOI 10.3102/0034654315577210
   Jones J.W., 1993, J BUS PSYCHOL, V7, P449, DOI DOI 10.1007/BF01013758
   Katz-Navon T, 2007, INT J HEALTH CARE Q, V20, P572, DOI 10.1108/09526860710822716
   Lee YH, 2015, CYBERPSYCH BEH SOC N, V18, P669, DOI 10.1089/cyber.2015.0165
   LEVENSON H, 1973, J CONSULT CLIN PSYCH, V41, P397, DOI 10.1037/h0035357
   Levenson H., 1981, Research with the locus of control construct, P15, DOI DOI 10.1016/B978-0-12-443201-7.50006-3
   Li DD, 2013, COMPUT HUM BEHAV, V29, P257, DOI 10.1016/j.chb.2012.09.002
   Meluso A, 2012, COMPUT EDUC, V59, P497, DOI 10.1016/j.compedu.2011.12.019
   MONTAG I, 1987, J APPL PSYCHOL, V72, P339, DOI 10.1037/0021-9010.72.3.339
   Peng W, 2009, HEALTH COMMUN, V24, P115, DOI 10.1080/10410230802676490
   Rahouti A, 2021, FIRE TECHNOL, V57, P3041, DOI 10.1007/s10694-021-01098-x
   Reich J.W., 2017, Perceived Control
   ROTTER JB, 1966, PSYCHOL MONOGR, V80, P1, DOI 10.1037/h0092976
   Samsung for Business, "Your phone is now more powerful than your PC
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Semeraro F, 2017, RESUSCITATION, V116, P27, DOI 10.1016/j.resuscitation.2017.04.038
   Skinner EA, 1996, J PERS SOC PSYCHOL, V71, P549, DOI 10.1037/0022-3514.71.3.549
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Song X, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3057280
   Sung HY, 2013, COMPUT EDUC, V63, P43, DOI 10.1016/j.compedu.2012.11.019
   Tubelo RA, 2019, INT J MED INFORM, V130, DOI 10.1016/j.ijmedinf.2019.08.004
   Wang LX, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121777
   Wuebker L.J., 1986, Journal of Business and Psychology, V1, P19, DOI [DOI 10.1007/BF01014164, 10.1007/BF01014164]
   You XQ, 2013, ACCIDENT ANAL PREV, V57, P131, DOI 10.1016/j.aap.2013.03.036
NR 60
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5339
EP 5349
DI 10.1109/TVCG.2023.3292473
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400092
PM 37405887
OA Bronze, Green Submitted
DA 2024-08-05
ER

PT J
AU Edirimuni, DD
   Lu, XQ
   Li, G
   Robles-Kelly, A
AF Edirimuni, Dasith de Silva
   Lu, Xuequan
   Li, Gang
   Robles-Kelly, Antonio
TI Contrastive Learning for Joint Normal Estimation and Point Cloud
   Filtering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Filtering; Point cloud compression; Estimation; Three-dimensional
   displays; Task analysis; Noise measurement; Training; Contrastive
   learning; machine learning; normal estimation; point cloud filtering
ID SURFACE
AB Point cloud filtering and normal estimation are two fundamental research problems in the 3D field. Existing methods usually perform normal estimation and filtering separately and often show sensitivity to noise and/or inability to preserve sharp geometric features such as corners and edges. In this article, we propose a novel deep learning method to jointly estimate normals and filter point clouds. We first introduce a 3D patch based contrastive learning framework, with noise corruption as an augmentation, to train a feature encoder capable of generating faithful representations of point cloud patches while remaining robust to noise. These representations are consumed by a simple regression network and supervised by a novel joint loss, simultaneously estimating point normals and displacements that are used to filter the patch centers. Experimental results show that our method well supports the two tasks simultaneously and preserves sharp features and fine details. It generally outperforms state-of-the-art techniques on both tasks.
C1 [Edirimuni, Dasith de Silva; Lu, Xuequan; Li, Gang; Robles-Kelly, Antonio] Deakin Univ, Sch Informat Technol, Waurn Ponds, VIC 3216, Australia.
   [Robles-Kelly, Antonio] Def Sci & Technol Grp, Edinburg, SA 5111, Australia.
C3 Deakin University; Defence Science & Technology
RP Lu, XQ (corresponding author), Deakin Univ, Sch Informat Technol, Waurn Ponds, VIC 3216, Australia.
EM dtdesilva@deakin.edu.au; xuequan.lu@deakin.edu.au;
   gang.li@deakin.edu.au; antonio.robles-kelly@deakin.edu.au
OI de Silva Edirimuni, Dasith/0000-0003-4997-5434; Lu,
   Xuequan/0000-0003-0959-408X
CR Adamson A, 2006, ACM T GRAPHIC, V25, P671, DOI 10.1145/1141911.1141940
   Afham M, 2022, PROC CVPR IEEE, P9892, DOI 10.1109/CVPR52688.2022.00967
   Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Alliegro A, 2021, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR46437.2021.00460
   Alliez P., 2007, P 5 EUROGRAPHICS S G, P39
   Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0
   Bekiroglu Y, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105335
   Ben-Shabat Y., 2020, P 16 EUR C COMP VIS, P34
   Ben-Shabat Y, 2019, PROC CVPR IEEE, P10104, DOI 10.1109/CVPR.2019.01035
   Boulch A, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12983
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Dey T. K., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P39, DOI 10.1109/PBG.2005.194062
   Du B, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3133, DOI 10.1145/3474085.3475458
   Gschwandtner Michael, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P199, DOI 10.1007/978-3-642-24031-7_20
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239474, 10.1145/1276377.1276406]
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Hadsell R., 2006, Computer vision and pattern recognition, 2006 IEEE computer society conference on, V2, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Hou J, 2021, PROC CVPR IEEE, P15582, DOI 10.1109/CVPR46437.2021.01533
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Jiang JC, 2023, Arxiv, DOI arXiv:2110.06632
   Kim Y, 2021, J MECH SCI TECHNOL, V35, P3131
   Kolluri R, 2008, ACM T ALGORITHMS, V4, DOI 10.1145/1361192.1361195
   Lal S, 2021, PROC CVPR IEEE, P12482, DOI 10.1109/CVPR46437.2021.01230
   Lenssen Jan Eric, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11244, DOI 10.1109/CVPR42600.2020.01126
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Li B, 2010, COMPUT GRAPH-UK, V34, P94, DOI 10.1016/j.cag.2010.01.004
   Li MT, 2022, PROC CVPR IEEE, P14910, DOI 10.1109/CVPR52688.2022.01451
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Liao YY, 2022, Arxiv, DOI arXiv:2109.13410
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276405, 10.1145/1239451.1239473]
   Lu DN, 2020, COMPUT AIDED DESIGN, V125, DOI 10.1016/j.cad.2020.102860
   Lu XQ, 2022, IEEE T VIS COMPUT GR, V28, P1835, DOI 10.1109/TVCG.2020.3026785
   Lu XQ, 2016, IEEE T VIS COMPUT GR, V22, P1181, DOI 10.1109/TVCG.2015.2500222
   Luo CX, 2021, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR46437.2021.00320
   Luo Shitong, 2021, P IEEECVF INT C COMP, P4583
   Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Remil O, 2017, COMPUT GRAPH FORUM, V36, P63, DOI 10.1111/cgf.13272
   Roveri R, 2018, COMPUT GRAPH FORUM, V37, P87, DOI 10.1111/cgf.13344
   Serna Andres, 2014, 3rd International Conference on Pattern Recognition Applications and Methods (ICPRAM 2014). Proceedings, P819
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Urech PRW, 2020, LANDSCAPE URBAN PLAN, V203, DOI 10.1016/j.landurbplan.2020.103903
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wang SY, 2022, COMPUT AIDED DESIGN, V150, DOI 10.1016/j.cad.2022.103281
   Wang Z., 2020, P BRIT MACH VIS C
   Xie SN, 2020, Arxiv, DOI arXiv:2007.10985
   Yoon M, 2007, COMPUT AIDED DESIGN, V39, P408, DOI 10.1016/j.cad.2007.02.008
   Yu L., 2018, EC-Net: An EdgeAware Point Set Consolidation Network
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhang J., 2020, IEEE Access, V8
   Zhang J, 2019, IEEE T VIS COMPUT GR, V25, P1693, DOI 10.1109/TVCG.2018.2827998
   Zhang J, 2013, COMPUT GRAPH-UK, V37, P697, DOI 10.1016/j.cag.2013.05.008
   Zhu Runsong, 2021, P IEEE CVF INT C COM, P6118
NR 62
TC 2
Z9 2
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4527
EP 4541
DI 10.1109/TVCG.2023.3263866
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400004
PM 37030701
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hou, SY
   Tao, HY
   Bao, HJ
   Xu, WW
AF Hou, Shuaiying
   Tao, Hongyu
   Bao, Hujun
   Xu, Weiwei
TI A Two-Part Transformer Network for Controllable Motion Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Solid modeling; Training; Transformers;
   Manifolds; Correlation; Biological system modeling; Human motion
   synthesis; transformer; deep learning; heterogeneous motion; body parts
AB Although part-based motion synthesis networks have been investigated to reduce the complexity of modeling heterogeneous human motions, their computational cost remains prohibitive in interactive applications. To this end, we propose a novel two-part transformer network that aims to achieve high-quality, controllable motion synthesis results in real-time. Our network separates the skeleton into the upper and lower body parts, reducing the expensive cross-part fusion operations, and models the motions of each part separately through two streams of auto-regressive modules formed by multi-head attention layers. However, such a design might not sufficiently capture the correlations between the parts. We thus intentionally let the two parts share the features of the root joint and design a consistency loss to penalize the difference in the estimated root features and motions by these two auto-regressive modules, significantly improving the quality of synthesized motions. After training on our motion dataset, our network can synthesize a wide range of heterogeneous motions, like cartwheels and twists. Experimental and user study results demonstrate that our network is superior to state-of-the-art human motion synthesis networks in the quality of generated motions.
C1 [Hou, Shuaiying; Tao, Hongyu; Bao, Hujun; Xu, Weiwei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Xu, WW (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM 11721044@zju.edu.cn; 3170102625@zju.edu.cn; bao@cad.zju.edu.cn;
   18058700512@163.com
OI Hou, Shuaiying/0000-0003-0689-9240; Xu, Weiwei/0000-0003-3756-3539; Bao,
   Hujun/0000-0002-2662-0334
FU National Natural Science Foundation of China [61732016]; Information
   Technology Center and State Key Lab of CAD&CG at Zhejiang University
FX Weiwei Xu is partially supported by the National Natural Science
   Foundation of China under Grant 61732016. And we also thank the support
   provided by the Information Technology Center and State Key Lab of
   CAD&CG at Zhejiang University.
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Adobe, 2021, Mixamo
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, 10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Baevski A, 2020, Arxiv, DOI [arXiv:2006.11477, DOI 10.48550/ARXIV.2006.11477]
   Bengio S, 2015, Arxiv, DOI arXiv:1506.03099
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Chen WH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2131, DOI 10.1145/3394171.3413669
   Corona E, 2020, PROC CVPR IEEE, P6990, DOI 10.1109/CVPR42600.2020.00702
   Cui QJ, 2020, PROC CVPR IEEE, P6518, DOI 10.1109/CVPR42600.2020.00655
   Degardin B., 2022, P IEEE CVF WINT C AP, P1150
   Dhariwal P, 2020, Arxiv, DOI [arXiv:2005.00341, DOI 10.48550/ARXIV.2005.00341]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Ghosh A, 2023, Arxiv, DOI arXiv:2103.14675
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Holden D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392440
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hou SY, 2023, Arxiv, DOI arXiv:2101.12276
   Huang RZ, 2021, Arxiv, DOI arXiv:2006.06119
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jang DK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3516429
   Kim Y., 2014, C EMP METH NAT LANG, P1746, DOI DOI 10.3115/V1/D14-1181
   Lee K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459826
   Lee K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275071
   Lee S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459774
   Li Jiaman, 2020, arXiv
   Li K., 2022, arXiv
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Li RL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13381, DOI 10.1109/ICCV48922.2021.01315
   Li SY, 2022, PROC CVPR IEEE, P11040, DOI 10.1109/CVPR52688.2022.01077
   Li ZM, 2018, Arxiv, DOI arXiv:1707.05363
   Ling C., 1998, Kdd, P73, DOI DOI 10.5555/3000292.3000304
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315
   Liu Z, 2021, Arxiv, DOI arXiv:2103.14030
   Liu ZG, 2021, AAAI CONF ARTIF INTE, V35, P2225
   Loshchilov I, 2019, Arxiv, DOI [arXiv:1711.05101, 10.48550/arXiv.1711.05101, DOI 10.48550/ARXIV.1711.05101]
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Oord A.v.d., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459670, 10.1145/3197517.3201311]
   Perez J., 2021, P 14 ACM SIGGRAPH C, P1
   Ping Yu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P18, DOI 10.1007/978-3-030-58577-8_2
   Sebastian Grassia F., 1998, Journal of graphics tools, V3, P29, DOI [DOI 10.1080/10867651.1998.10487493, 10.1080/10867651.1998.10487493]
   Shi MY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3407659
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Starke S, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530178
   Starke S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459881
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   Tang X., 2022, arXiv
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Vaswani A., 2017, PROC NEURIPS, V30, P5998
   Villegas R, 2018, PROC CVPR IEEE, P8639, DOI 10.1109/CVPR.2018.00901
   Wang H, 2021, IEEE T VIS COMPUT GR, V27, P216, DOI 10.1109/TVCG.2019.2936810
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang X, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/104535
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P14, DOI 10.1109/TVCG.2019.2938520
   Wei Mao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P474, DOI 10.1007/978-3-030-58568-6_28
   Won J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459761
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Yan W., 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.10157
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
NR 66
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5047
EP 5062
DI 10.1109/TVCG.2023.3284402
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400037
PM 37294654
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Benda, B
   Sargunam, SP
   Nourani, M
   Ragan, ED
AF Benda, Brett
   Sargunam, Shyam Prathish
   Nourani, Mahsan
   Ragan, Eric D.
TI An Evaluation of View Rotation Techniques for Seated Navigation in
   Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Turning; Tracking; Teleportation; Virtual
   environments; Navigation; Three-dimensional displays; Human-centered
   computing; human-computer interaction; virtual reality
ID HEAD MOVEMENTS; ENVIRONMENTS; LOCOMOTION; TRAVEL
AB Head tracking is commonly used in VR applications to allow users to naturally view 3D content using physical head movement, but many applications also support turning with hand-held controllers. Controller and joystick controls are convenient for practical settings where full 360-degree physical rotation is not possible, such as when the user is sitting at a desk. Though controller-based rotation provides the benefit of convenience, previous research has demonstrated that virtual or joystick-controlled view rotation to have drawbacks of sickness and disorientation compared to physical turning. To combat such issues, researchers have considered various techniques such as speed adjustments or reduced field of view, but data is limited on how different variations for joystick rotation influences sickness and orientation perception. Our studies include different variations of techniques such as joystick rotation, resetting, and field-of-view reduction. We investigate trade-offs among different techniques in terms of sickness and the ability to maintain spatial orientation. In two controlled experiments, participants traveled through a sequence of rooms and were tested on spatial orientation, and we also collected subjective measures of sickness and preference. Our findings indicate a preference by users towards directly-manipulated joystick-based rotations compared to user-initiated resetting and minimal effects of technique on spatial awareness.
C1 [Benda, Brett; Nourani, Mahsan; Ragan, Eric D.] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
   [Sargunam, Shyam Prathish] Autodesk, San Rafael, CA 94903 USA.
C3 State University System of Florida; University of Florida; Autodesk,
   Inc.
RP Benda, B (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
EM brett.benda@ufl.edu; shyam.prathish@gmail.com; mahsannourani@ufl.edu;
   eragan@ufl.edu
OI Benda, William/0000-0002-1825-6392
CR Adhikari A, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P370, DOI 10.1109/VRW52623.2021.00074
   Bacim F., 2013, P GRAPH INT, P25
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Bolte B., 2011, P VIRT REAL INT C
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Cohen J., 2013, APPL MULTIPLE REGRES
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   Davis S., 2014, P C INT ENT, P1
   Farmani Y., 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI201 8.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Jay C, 2003, PRESENCE-VIRTUAL AUG, V12, P268, DOI 10.1162/105474603765879521
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Langbehn Eike, 2019, P MENSCH COMP NEW YO, P235, DOI DOI 10.1145/3340764.3340778
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Lee JY, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145697
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Ngoc LL, 2013, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VR.2013.6549359
   McCauley M. E., 1992, Teleoperators and Virtual Environments, V1, P311, DOI [10.1162/pres.1992.1.3.311, DOI 10.1162/PRES.1992.1.3.311]
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Morganti Francesca, 2014, Stud Health Technol Inform, V196, P278
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Poupyrev I., 1999, CHI'99 extended abstracts on Human factors in computing systems, P256, DOI DOI 10.1145/632716.632874
   Prabhat, 2008, IEEE T VIS COMPUT GR, V14, P551, DOI 10.1109/TVCG.2007.70433
   Ragan E. D., 2012, P JOINT VIRT REAL C, P81
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Ragan ED, 2013, IEEE T VIS COMPUT GR, V19, P886, DOI 10.1109/TVCG.2012.163
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Razzaque Z., 2001, EUROGRAPHICS 2001 SH, P289, DOI 10.2312/egs.20011036
   Riecke BernhardE., 2012, P ACM S APPL PERCEPT, P17, DOI DOI 10.1145/2338676.2338680
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Ryge AN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P675, DOI 10.1109/VR.2018.8446206
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Slater M., 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI [10.1145/210079.210084, DOI 10.1145/210079.210084]
   Stebbins T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P377, DOI [10.1109/vr.2019.8797994, 10.1109/VR.2019.8797994]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Ware C., 1990, Computer Graphics, V24, P175, DOI 10.1145/91394.91442
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   WELLS MJ, 1990, OPT ENG, V29, P870, DOI 10.1117/12.55672
   Weniger G, 2011, NEUROPSYCHOLOGIA, V49, P518, DOI 10.1016/j.neuropsychologia.2010.12.031
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Zielasko D., 2018, P IEEE VR WORKSH EV, P1
   Zielasko D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P693, DOI 10.1109/VR51125.2022.00090
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P398, DOI [10.1109/VR46266.2020.00-44, 10.1109/VR46266.2020.1581426770550]
   Zielasko D, 2017, 2017 IEEE 3RD WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/WEVR.2017.7957707
NR 55
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4257
EP 4270
DI 10.1109/TVCG.2023.3258693
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700048
PM 37030847
DA 2024-08-05
ER

PT J
AU Kawabe, T
   Ujitoko, Y
AF Kawabe, Takahiro
   Ujitoko, Yusuke
TI Softness Perception of Visual Objects Controlled by Touchless Inputs:
   The Role of Effective Distance of Hand Movements
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deformation; Visualization; Cameras; Material properties; Springs;
   Monitoring; Fabrics; Material perception; pseudo-haptics; touchless
   inputs; softness
ID HAPTIC FEEDBACK; SEEING LIQUIDS; RATIO
AB Feedback on the material properties of a visual object is essential in enhancing the users' perceptual experience of the object when users control the object with touchless inputs. Focusing on the softness perception of the object, we examined how the effective distance of hand movements influenced the degree of the object's softness perceived by users. In the experiments, participants moved their right hand in front of a camera which tracked their hand position. A textured 2D or 3D object on display deformed depending on the participant's hand position. In addition to establishing a ratio of deformation magnitude to the distance of hand movements, we altered the effective distance of hand movement, within which the hand movement could deform the object. Participants rated the strength of perceived softness (Experiments 1 and 2) and other perceptual impressions (Experiment 3). A longer effective distance produced a softer impression of the 2D and 3D objects. The saturation speed of object deformation due to the effective distance was not a critical determinant. The effective distance also modulated other perceptual impressions than softness. The role of the effective distance of hand movements on perceptual impressions of objects under touchless control is discussed.
C1 [Kawabe, Takahiro; Ujitoko, Yusuke] NTT Corp, NTT Commun Sci Labs, Atsugi, Kanagawa 2430198, Japan.
C3 Nippon Telegraph & Telephone Corporation
RP Kawabe, T (corresponding author), NTT Corp, NTT Commun Sci Labs, Atsugi, Kanagawa 2430198, Japan.
EM takkawabe@gmail.com; yusuke.ujitoko@gmail.com
RI Ujitoko, Yusuke/AAV-2457-2021; Kawabe, Takahiro/V-3676-2017
OI Ujitoko, Yusuke/0000-0001-6059-9324; Kawabe,
   Takahiro/0000-0002-9888-8866
CR Adelson EH, 2001, PROC SPIE, V4299, P1, DOI 10.1117/12.429489
   Argelaguet F, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2501599
   Ban YK, 2018, IEEE HAPTICS SYM, P278, DOI 10.1109/HAPTICS.2018.8357188
   Ban Y, 2014, IEEE HAPTICS SYM, P557, DOI 10.1109/HAPTICS.2014.6775516
   Bi W., 2016, P ACM S APPL PERC, P19, DOI [DOI 10.1145/2931002.2931016, 10.1145/2931002.2931016]
   Bi WY, 2019, J VISION, V19, DOI 10.1167/19.5.18
   Bi WY, 2018, J VISION, V18, DOI 10.1167/18.5.12
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Cauquis J, 2022, 28TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2022, DOI 10.1145/3562939.3565607
   De Paolis LT, 2022, VIRTUAL REAL-LONDON, V26, P1551, DOI 10.1007/s10055-022-00647-1
   Dominjon L, 2005, P IEEE VIRT REAL ANN, P19
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Fakhoury E, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P88, DOI 10.1109/WHC.2015.7177696
   Fleming R. W., 2016, Annu. Rev. Vis. Sci., V3, P1
   Fleming RW, 2014, VISION RES, V94, P62, DOI 10.1016/j.visres.2013.11.004
   Gaffary Y, 2017, IEEE T VIS COMPUT GR, V23, P2372, DOI 10.1109/TVCG.2017.2735078
   Gaucher P, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P55, DOI 10.1109/3DUI.2013.6550197
   Georgiou O, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299030
   Greaves GN, 2011, NAT MATER, V10, P823, DOI [10.1038/NMAT3134, 10.1038/nmat3134]
   Habibi P, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102600
   Hachisu T., 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P327, DOI 10.1109/ISVRI.2011.5759662
   Hachisu T., 2015, Haptic Interaction, P297
   Hachisu T, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Harrington K, 2018, AUTOMOTIVEUI'18: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P11, DOI 10.1145/3239060.3239089
   Hirao Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P305, DOI [10.1109/VRW50115.2020.0-207, 10.1109/VRW50115.2020.00069]
   Jung PG, 2015, IEEE T IND INFORM, V11, P485, DOI 10.1109/TII.2015.2405413
   Kawabe T, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.811881
   Kawabe T, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.652781
   Kawabe T, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.612368
   Kawabe T, 2020, IEEE T HAPTICS, V13, P18, DOI 10.1109/TOH.2019.2961883
   Kawabe T, 2015, VISION RES, V109, P125, DOI 10.1016/j.visres.2014.07.003
   Kawabe Takahiro, 2016, P ACM S APPL PERC, P121, DOI [DOI 10.1145/2931002.2931008, 10.1145/2931002.2931008]
   Kawasaki T., 2019, Scientific reports, V9, P1, DOI [10.1038/s41598-018-37186-2, DOI 10.1038/S41598-018-37186-2]
   Kim J, 2022, IEEE ACCESS, V10, P5129, DOI 10.1109/ACCESS.2022.3140438
   Le TR, 2015, EUR MICROW CONF, P371, DOI 10.1109/EuMC.2015.7345777
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Li QS, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57204-1
   Malecki K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186620
   Mandryk R., 2018, P CHI C HUM FACT COM, P1
   McIntosh J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2332, DOI 10.1145/2858036.2858093
   Ota Yusuke, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P33, DOI 10.1007/978-3-030-58147-3_4
   Paulun VC, 2020, J VISION, V20, DOI 10.1167/jov.20.6.6
   Paulun VC, 2017, J VISION, V17, DOI 10.1167/17.1.20
   Paulun VC, 2015, VISION RES, V115, P163, DOI 10.1016/j.visres.2015.01.023
   Polhemus, 2012, 3SpaceR fastrakR user manual
   Samae M, 2019, BIOMED ENG INT CONF, DOI 10.1145/3290605.3300550
   Sato M., 2016, P ACM SIGGRAPH, P1
   Schmidt F, 2017, J VISION, V17, DOI 10.1167/17.3.18
   Srinivasan M. A., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P555
   Ujitoko Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05864-x
   Ujitoko Y, 2021, IEEE T HAPTICS, V14, P699, DOI 10.1109/TOH.2021.3077619
   Ujitoko Y, 2019, IEEE T VIS COMPUT GR, V25, P1981, DOI 10.1109/TVCG.2019.2898820
   van Assen JJR, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1008018
   Van Assen JJR, 2018, CURR BIOL, V28, P452, DOI 10.1016/j.cub.2017.12.037
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   Watanabe J., 2013, ITE Trans. Media Technol. Appl., V1, P199
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yabe S.-I., 2014, P INT C ART REAL TEL, P1
   Zhao N, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS (BSN)
NR 60
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4154
EP 4169
DI 10.1109/TVCG.2023.3254522
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700065
PM 37028284
DA 2024-08-05
ER

PT J
AU Xiao, WP
   Xu, C
   Mai, JJ
   Xu, XM
   Li, Y
   Li, CZ
   Liu, XT
   He, SF
AF Xiao, Wenpeng
   Xu, Cheng
   Mai, Jiajie
   Xu, Xuemiao
   Li, Yue
   Li, Chengze
   Liu, Xueting
   He, Shengfeng
TI Appearance-Preserved Portrait-to-Anime Translation via Proxy-Guided
   Domain Adaptation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptation models; Training; Strain; Shape; Semantics; Faces; Deformable
   models; Portrait-to-anime translation; coser portrait proxy; domain
   adaptation
ID GENERATIVE ADVERSARIAL NETWORKS
AB Converting a human portrait to anime style is a desirable but challenging problem. Existing methods fail to resolve this problem due to the large inherent gap between two domains that cannot be overcome by a simple direct mapping. For this reason, these methods struggle to preserve the appearance features in the original photo. In this article, we discover an intermediate domain, the coser portrait (portraits of humans costuming as anime characters), that helps bridge this gap. It alleviates the learning ambiguity and loosens the mapping difficulty in a progressive manner. Specifically, we start from learning the mapping between coser and anime portraits, and present a proxy-guided domain adaptation learning scheme with three progressive adaptation stages to shift the initial model to the human portrait domain. In this way, our model can generate visually pleasant anime portraits with well-preserved appearances given the human portrait. Our model adopts a disentangled design by breaking down the translation problem into two specific subtasks of face deformation and portrait stylization. This further elevates the generation quality. Extensive experimental results show that our model can achieve visually compelling translation with better appearance preservation and perform favorably against the existing methods both qualitatively and quantitatively. Our code and datasets are available at https://github.com/NeverGiveU/PDA-Translation.
C1 [Xiao, Wenpeng; Xu, Cheng; Xu, Xuemiao; Li, Yue] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Mai, Jiajie] Kings Coll London, London WC2R 2LS, England.
   [Xu, Xuemiao] Minist Educ, Key Lab Big Data & Intelligent Robot & Guangdong, State Key Lab Subtrop Bldg Sci, Prov Key Lab Computat Intelligence & Cyberspace In, Guangdong Province510641, Guangzhou, Peoples R China.
   [Li, Chengze; Liu, Xueting] Caritas Inst Higher Educ, Hong Kong, Peoples R China.
   [He, Shengfeng] Singapore Management Univ, Sch Comp & Informat Syst, Singapore 188065, Singapore.
C3 South China University of Technology; University of London; King's
   College London; Saint Francis University Hong Kong; Singapore Management
   University
RP Xu, XM (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.; He, SF (corresponding author), Singapore Management Univ, Sch Comp & Informat Syst, Singapore 188065, Singapore.
EM wpxiao.littleblack@gmail.com; cschengxu@gmail.com; k20035517@kcl.ac.uk;
   xuemx@scut.edu.cn; liyue@scut.edu.cn; czli@cihe.edu.hk;
   tliu@cihe.edu.hk; shengfenghe7@gmail.com
RI He, Shengfeng/E-5682-2016; Li, Chengze/AAU-7168-2021; Xu,
   Cheng/HZL-1279-2023
OI He, Shengfeng/0000-0002-3802-4644; Li, Chengze/0000-0002-1519-750X; Liu,
   Xueting/0000-0002-0868-5353
FU Guangdong International Technology Cooperation Project
   [2022A0505050009]; Key-Area Research and Development Program of
   Guangdong Province, China [2020B010165004, 2020B010166003]; National
   Natural Science Foundation of China [61972162]; Guangdong International
   Science and Technology Cooperation Project [2021A0505030009]; Guangdong
   Natural Science Foundation [2021A1515012625]; Guangzhou Basic and
   Applied Research Project [202102021074]; CCF-Tencent Open Research fund
   under Grant CCF-Tencent [RAGR20210114]; Research Grants Council of the
   Hong Kong Special Administrative Region, China, Project
   [UGC/FDS11/E02/21]
FX This work was supported in part by Guangdong International Technology
   Cooperation Project under Grant 2022A0505050009, in part by the Key-Area
   Research and Development Program of Guangdong Province, China under
   Grants 2020B010165004 and 2020B010166003, in part by the National
   Natural Science Foundation of China under Grant 61972162, in part by
   Guangdong International Science and Technology Cooperation Project under
   Grant 2021A0505030009, in part by Guangdong Natural Science Foundation
   under Grant 2021A1515012625, in part by Guangzhou Basic and Applied
   Research Project under Grant 202102021074, in part by CCF-Tencent Open
   Research fund under Grant CCF-Tencent RAGR20210114, and in part by Grant
   from the Research Grants Council of the Hong Kong Special Administrative
   Region, China, Project under Grant UGC/FDS11/E02/21.
CR [Anonymous], 2021, "Danbooru2020: A large-scale crowdsourced and tagged anime illustration dataset
   Back J., 2021, arXiv
   Cao Kaidi, 2018, ACM Trans. on Graph., V37, P1, DOI [10.1145/3272127.3275046, DOI 10.1145/3272127.3275046]
   Cheng JX, 2021, PROC CVPR IEEE, P134, DOI 10.1109/CVPR46437.2021.00020
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chong D., 2021, arXiv
   Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang G, 2021, Adv. Neural Inf. Process. Syst., V34, P11920
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Heusel M., 2017, NeurIPS, P6629
   Huang JL, 2022, IEEE T MULTIMEDIA, V24, P1435, DOI 10.1109/TMM.2021.3065230
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P., 2017, P IEEE C COMP VIS PA, P1125, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jang W, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459860
   Karras T., 2018, INT C LEARNING REPRE
   Karras T, 2020, Arxiv, DOI [arXiv:2006.06676, 10.48550/arXiv.2006.06676, DOI 10.48550/ARXIV.2006.06676]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim J., 2020, INT C LEARN REPR, P1
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li B, 2022, IEEE T MULTIMEDIA, V24, P4077, DOI 10.1109/TMM.2021.3113786
   Li HL, 2011, IEEE T MULTIMEDIA, V13, P1230, DOI 10.1109/TMM.2011.2168814
   Liu M.-Y., 2017, ADV NEURAL INFORM PR, V30, P700, DOI DOI 10.48550/ARXIV.1703.00848
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Pinkney JNM, 2020, Arxiv, DOI arXiv:2010.05334
   Nagadomi, 2014, lbpcascade_animeface
   Paszke A, 2019, ADV NEUR IN, V32
   Rosin PL, 2022, COMPUT VIS MEDIA, V8, P445, DOI 10.1007/s41095-021-0255-3
   Shi J.-Q., IEEE Trans. Vis.Comp. Graph., DOI [10.1109/TVCG.2022.3146000.11R, DOI 10.1109/TVCG.2022.3146000.11R]
   Shu YZ, 2022, IEEE T VIS COMPUT GR, V28, P3376, DOI 10.1109/TVCG.2021.3067201
   Song GX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459771
   Su H, 2021, AAAI CONF ARTIF INTE, V35, P2611
   Sun Y. Hou, 2021, P IEEE CVF INT C COM, p11 761
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei YX, 2021, PROC CVPR IEEE, P13380, DOI 10.1109/CVPR46437.2021.01318
   Wu RZ, 2019, Arxiv, DOI arXiv:1907.01424
   Xu C, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3554739
   Xu W. Qu, IEEETrans. Vis. Comp. Graph., DOI [10.1109/TVCG.2022.3174656.10M., DOI 10.1109/TVCG.2022.3174656.10M]
   Yao Y., 2020, P COMP VIS ECCV 2020, P775
   Ye ZP, 2023, IEEE T VIS COMPUT GR, V29, P2203, DOI 10.1109/TVCG.2021.3126659
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang W., 2014, inSIGGRAPH Asia, P1
   Zhang Y, 2017, IEEE T IMAGE PROCESS, V26, P464, DOI 10.1109/TIP.2016.2628581
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3104
EP 3120
DI 10.1109/TVCG.2022.3228707
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700032
PM 37015410
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Rodrigues, N
   Dennig, FL
   Brandt, V
   Keim, DA
   Weiskopf, D
AF Rodrigues, Nils
   Dennig, Frederik L.
   Brandt, Vincent
   Keim, Daniel A.
   Weiskopf, Daniel
TI Comparative Evaluation of Animated Scatter Plot Transitions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Data visualization; Task analysis; Three-dimensional
   displays; Visual analytics; Splines (mathematics); Shape; Visualization;
   scatter plot; animation; quantitative user study; multidimensional data;
   coordinated and multiple views
AB Scatter plots are popular for displaying 2D data, but in practice, many data sets have more than two dimensions. For the analysis of such multivariate data, it is often necessary to switch between scatter plots of different dimension pairs, e.g., in a scatter plot matrix (SPLOM). Alternative approaches include a "grand tour" for an overview of the entire data set or creating artificial axes from dimensionality reduction (DR). A cross-cutting concern in all techniques is the ability of viewers to find correspondence between data points in different views. Previous work proposed animations to preserve the mental map between view changes and to trace points as well as clusters between scatter plots of the same underlying data set. In this article, we evaluate a variety of spline- and rotation-based view transitions in a crowdsourced user study focusing on ecological validity. Using the study results, we assess each animation's suitability for tracing points and clusters across view changes. We evaluate whether the order of horizontal and vertical rotation is relevant for task accuracy. The results show that rotations with an orthographic camera or staged expansion of a depth axis significantly outperform all other animation techniques for the traceability of individual points. Further, we provide a ranking of the animated transition techniques for traceability of individual points. However, we could not find any significant differences for the traceability of clusters. Furthermore, we identified differences by animation direction that could guide further studies to determine potential confounds for these differences. We publish the study data for reuse and provide the animation framework as a D3.js plug-in.
C1 [Rodrigues, Nils; Keim, Daniel A.] Univ Stuttgart, Visualizat Res Ctr VISUS, D-70174 Stuttgart, Germany.
   [Dennig, Frederik L.; Keim, Daniel A.] Univ Konstanz, D-78464 Constance, Germany.
   [Brandt, Vincent] Univ Stuttgart, Stuttgart, Germany.
C3 University of Stuttgart; University of Konstanz; University of Stuttgart
RP Rodrigues, N (corresponding author), Univ Stuttgart, Visualizat Res Ctr VISUS, D-70174 Stuttgart, Germany.
EM nils.rodrigues@visus.uni-stuttgart.de;
   frederik.l.dennig@uni-konstanz.de; st161848@stud.uni-stuttgart.de;
   daniel.a.keim@uni-konstanz.de; daniel.weiskopf@visus.uni-stuttgart.de
RI Weiskopf, Daniel/KWT-7459-2024
OI Dennig, Frederik L./0000-0003-1116-8450; Weiskopf,
   Daniel/0000-0003-1174-1026
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR [Anonymous], AMAZON MECH TURK
   ARMSTRONG RL, 1987, PERCEPT MOTOR SKILL, V64, P359, DOI 10.2466/pms.1987.64.2.359
   ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011
   Baudisch Patrick., 2001, 14 ANN ACM S USER IN, P31, DOI DOI 10.1145/502348.502354
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandt V., 2024, D3-plugin for animated scatter plot transi- tions
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Cao YN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581472
   Chevalier F, 2014, IEEE T VIS COMPUT GR, V20, P2241, DOI 10.1109/TVCG.2014.2346424
   Chyung SY (Yonnie)., 2020, Perf Improv, V59, P6, DOI DOI 10.1002/PFI.21920
   Cleveland W. S., 1988, Dynamic Graphics for Statistics
   Dragicevic P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2009
   Drucker S., 2015, Tech. Rep. MSR-TR-2015-65
   Du F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P289
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Footovision, 2023, Footovision: Level up your game
   Gadhave K, 2021, INFORM VISUAL, V20, P207, DOI 10.1177/14738716211038604
   Guo Y, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13179709
   Haji-Abolhassani A, 2013, J VISION, V13, DOI 10.1167/13.3.29
   HART S G, 1988, P139
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Jolliffe T., 2002, Principal Component Analysis, DOI [10.1007/698835, DOI 10.1007/698835]
   Kim Y, 2019, COMPUT GRAPH FORUM, V38, P541, DOI 10.1111/cgf.13709
   Kriglstein S., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P30, DOI 10.1109/IV.2012.16
   Mcilreavy L, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.5.7
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   MILLER GA, 1956, IRE T INFORM THEOR, V2, P129, DOI 10.1109/TIT.1956.1056815
   Nakakoji K, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P77, DOI 10.1109/IV.2001.942042
   Perin C, 2018, IEEE T VIS COMPUT GR, V24, P698, DOI 10.1109/TVCG.2017.2743918
   Prolific Academic Ltd, 2001, Prolific-Quickly find research participants you can trust
   Purves D., 2001, NEUROSCIENCE
   Nguyen QV, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.09.004
   Quinlan J.R., 1993, Proceedings of the 10th International Conference of Machine Learning, P236, DOI DOI 10.1016/B978-1-55860-307-3.50037-X
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   ROBINSON DA, 1965, J PHYSIOL-LONDON, V180, P569, DOI 10.1113/jphysiol.1965.sp007718
   Rodrigues N., 2024, Interactive demo of study: Evaluation of animated scat- ter plot transitions
   Rodrigues N., 2024, DaRUS, DOI [10.18419/darus-3451, DOI 10.18419/DARUS-3451]
   Rodrigues N., 2020, P GRAPH INT C, P382, DOI [10.20380/G12020.38, DOI 10.20380/G12020.38]
   Rodrigues N., 2022, OSF Preregistration, DOI [10.17605/OSE.IO/3E6G4, DOI 10.17605/OSE.IO/3E6G4]
   Rottach KG, 1996, VISION RES, V36, P2189, DOI 10.1016/0042-6989(95)00302-9
   Sanftmann H, 2012, IEEE T VIS COMPUT GR, V18, P1969, DOI 10.1109/TVCG.2012.35
   Schulz C, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P112, DOI 10.1145/2993901.2993907
   Stiftelsen Gapminder, Gapminder tools
   Taylor T.H., 2010, Encyclopedia of Research Design. Ceiling Effect, P133, DOI [DOI 10.4135/9781412961288.N44, 10.4135/9781412961288, DOI 10.4135/9781412961288]
   Tekusová T, 2007, IEEE INT CONF INF VI, P101
   Thomas JG, 2022, PSYCHOTHER RES, V32, P128, DOI 10.1080/10503307.2021.1909770
   Tominski C, 2021, VIS INFORM, V5, P28, DOI 10.1016/j.visinf.2021.06.004
   Utts J.M., 2005, SEEING STAT
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P2487, DOI 10.1109/TVCG.2017.2750689
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
NR 53
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2929
EP 2941
DI 10.1109/TVCG.2024.3388558
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500011
PM 38625781
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ai, H
   Cao, ZD
   Lu, HN
   Chen, C
   Ma, J
   Zhou, PY
   Kim, TK
   Hui, P
   Wang, L
AF Ai, Hao
   Cao, Zidong
   Lu, Haonan
   Chen, Chen
   Ma, Jian
   Zhou, Pengyuan
   Kim, Tae-Kyun
   Hui, Pan
   Wang, Lin
TI Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via
   Transformer-Based 360° Image Outpainting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 360 image outpainting; virtual scene creation; vision transformer
AB 360 degrees images, with a field-of-view (FoV) of 180 degrees x 360 degrees, provide immersive and realistic environments for emerging virtual reality (VR) applications, such as virtual tourism, where users desire to create diverse panoramic scenes from a narrow FoV photo they take from a viewpoint via portable devices. It thus brings us to a technical challenge: 'How to allow the users to freely create diverse and immersive virtual scenes from a narrow FoV image with a specified viewport?' To this end, we propose a transformer-based 360 degrees image outpainting framework called Dream360, which can generate diverse, high-fidelity, and high-resolution panoramas from user-selected viewports, considering the spherical properties of 360 degrees images. Compared with existing methods, e.g., [3], which primarily focus on inputs with rectangular masks and central locations while overlooking the spherical property of 360 degrees images, our Dream360 offers higher outpainting flexibility and fidelity based on the spherical representation. Dream360 comprises two key learning stages: (I) codebook-based panorama outpainting via Spherical-VQGAN (S-VQGAN), and (II) frequency-aware refinement with a novel frequency-aware consistency loss. Specifically, S-VQGAN learns a sphere-specific codebook from spherical harmonic (SH) values, providing a better representation of spherical data distribution for scene modeling. The frequency-aware refinement matches the resolution and further improves the semantic consistency and visual fidelity of the generated results. Our Dream360 achieves significantly lower Frechet Inception Distance (FID) scores and better visual fidelity than existing methods. We also conducted a user study involving 15 participants to interactively evaluate the quality of the generated results in VR, demonstrating the flexibility and superiority of our Dream360 framework.
C1 [Ai, Hao; Cao, Zidong; Hui, Pan; Wang, Lin] HKUST GZ, Guangzhou, Peoples R China.
   [Lu, Haonan; Chen, Chen; Ma, Jian] OPPO, Shenzhen, Peoples R China.
   [Zhou, Pengyuan] USTC, Hefei, Peoples R China.
   [Kim, Tae-Kyun] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Kim, Tae-Kyun] ICI PLC, London, England.
   [Hui, Pan; Wang, Lin] HKUST, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Korea Advanced Institute of Science & Technology (KAIST);
   Imperial Chemical Industries; Hong Kong University of Science &
   Technology
RP Ai, H (corresponding author), HKUST GZ, Guangzhou, Peoples R China.
EM aihao199712@gmail.com; zcao740@connect.hkust-gz.edu.cn;
   luhaonan@oppo.com; chenchen4@oppo.com; majian2@oppo.com;
   pyzhou@ustc.edu.cn; kimtaekyun@kaist.ac.kr; panhui@ust.hk;
   linwang@ust.hk
OI Zhou, Pengyuan/0000-0002-7909-4059
FU OPPO Research Fund
FX No Statement Available
CR Ai H, 2023, PROC CVPR IEEE, P13273, DOI 10.1109/CVPR52729.2023.01275
   Akimoto N, 2022, PROC CVPR IEEE, P11431, DOI 10.1109/CVPR52688.2022.01115
   Akimoto N, 2019, IEEE IMAGE PROC, P4704, DOI [10.1109/icip.2019.8803435, 10.1109/ICIP.2019.8803435]
   Ardouin J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P3, DOI 10.1109/VR.2014.6802042
   Arora N, 2022, IEEE T VIS COMPUT GR, V28, P2135, DOI 10.1109/TVCG.2022.3150473
   Cai M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13910, DOI 10.1109/ICCV48922.2021.01367
   Cao Mingdeng, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1731, DOI 10.1109/CVPRW59228.2023.00174
   Chang HW, 2022, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR52688.2022.01103
   Chen YB, 2022, LECT NOTES COMPUT SC, V13677, P170, DOI 10.1007/978-3-031-19790-1_11
   Chen ZX, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555447
   Cheng YC, 2022, PROC CVPR IEEE, P11421, DOI 10.1109/CVPR52688.2022.01114
   Eder Marc, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12423, DOI 10.1109/CVPR42600.2020.01244
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Fuchs F. B., 2020, Advances in Neural Information Processing Systems, V34
   Fuoli D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2340, DOI 10.1109/ICCV48922.2021.00236
   Gal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459836
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Han S. W., 2020, arXiv
   Hara T, 2021, AAAI CONF ARTIF INTE, V35, P1513
   Hensel M, 2017, ADV NEUR IN, V30
   Iketani S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P615, DOI [10.1109/VRW50115.2020.0-117, 10.1109/VRW50115.2020.00158]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang LM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13899, DOI 10.1109/ICCV48922.2021.01366
   Jin X, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02367-3
   Jung S, 2021, AAAI CONF ARTIF INTE, V35, P1734
   Kim K, 2021, IEEE WINT CONF APPL, P2121, DOI 10.1109/WACV48630.2021.00217
   Liao K, 2023, Arxiv, DOI arXiv:2204.08563
   Lil YJ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P1, DOI 10.1109/VR51125.2022.00017
   Liu CL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P575, DOI 10.1109/VRW50115.2020.00285
   Liu KL, 2019, IEEE I CONF COMP VIS, P6391, DOI 10.1109/ICCV.2019.00648
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marrinan T., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P1
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mirza M., 2014, ARXIV
   Parmar G, 2022, PROC CVPR IEEE, P11400, DOI 10.1109/CVPR52688.2022.01112
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng JL, 2021, PROC CVPR IEEE, P10770, DOI 10.1109/CVPR46437.2021.01063
   Pessoa S, 2010, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2010.5444836
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Ramamoorthi R, 2004, ACM T GRAPHIC, V23, P1004, DOI 10.1145/1027411.1027416
   Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Singhal U., 2020, NeurIPS, V2, P4
   Sumantri JS, 2020, IEEE WINT CONF APPL, P2375, DOI [10.1109/WACV45572.2020.9093582, 10.1109/wacv45572.2020.9093582]
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   van den Oord A, 2017, ADV NEUR IN, V30
   Vaswani A, 2017, ADV NEUR IN, V30
   Vermast A, 2023, IEEE T VIS COMPUT GR, V29, P2547, DOI 10.1109/TVCG.2023.3247462
   Walker J, 2016, Arxiv, DOI arXiv:1606.07873
   Wallgrün JO, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P83, DOI [10.1109/VR46266.2020.1581092881445, 10.1109/VR46266.2020.00-78]
   Wang JH, 2023, Arxiv, DOI arXiv:2308.14686
   Wang LL, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P170, DOI 10.1109/VR50410.2021.00038
   Wang M., 2014, ACM Transactions on Graphics (TOG), V33, P2
   Wang M, 2020, INT SYM MIX AUGMENT, P174, DOI [10.1109/ISMAR50242.2020.00040, 10.1109/1SMA1R50242.2020.00040]
   Wang TF, 2022, PROC CVPR IEEE, P11369, DOI 10.1109/CVPR52688.2022.01109
   Wang Y, 2019, PROC CVPR IEEE, P1399, DOI 10.1109/CVPR.2019.00149
   Wu TH, 2024, Arxiv, DOI arXiv:2307.03177
   Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991
   Xin HG, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480563
   Xu D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P703, DOI [10.1109/VRW50115.2020.00202, 10.1109/VRW50115.2020.00-73]
   Yang CA, 2022, PROC CVPR IEEE, P15596, DOI 10.1109/CVPR52688.2022.01517
   Yu YC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P69, DOI 10.1145/3474085.3475436
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao L, 2020, PROC CVPR IEEE, P5740, DOI 10.1109/CVPR42600.2020.00578
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhu YC, 2020, IEEE T MULTIMEDIA, V22, P2331, DOI 10.1109/TMM.2019.2957986
NR 68
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2734
EP 2744
DI 10.1109/TVCG.2024.3372085
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400065
PM 38437117
DA 2024-08-05
ER

PT J
AU Bernal-Berdun, E
   Vallejo, M
   Sun, Q
   Serrano, A
   Gutierrez, D
AF Bernal-Berdun, Edurne
   Vallejo, Mateo
   Sun, Qi
   Serrano, Ana
   Gutierrez, Diego
TI Modeling the Impact of Head-Body Rotations on Audio-Visual Spatial
   Perception for Virtual Reality Applications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Audio-Visual Spatial Perception
ID SPACE; LOCALIZATION; COMPRESSION; THRESHOLDS
AB Humans perceive the world by integrating multimodal sensory feedback, including visual and auditory stimuli, which holds true in virtual reality (VR) environments. Proper synchronization of these stimuli is crucial for perceiving a coherent and immersive VR experience. In this work, we focus on the interplay between audio and vision during localization tasks involving natural head-body rotations. We explore the impact of audio-visual offsets and rotation velocities on users' directional localization acuity for various viewing modes. Using psychometric functions, we model perceptual disparities between visual and auditory cues and determine offset detection thresholds. Our findings reveal that target localization accuracy is affected by perceptual audio-visual disparities during head-body rotations, but remains consistent in the absence of stimuli-head relative motion. We then showcase the effectiveness of our approach in predicting and enhancing users' localization accuracy within realistic VR gaming applications. To provide additional support for our findings, we implement a natural VR game wherein we apply a compensatory audio-visual offset derived from our measured psychometric functions. As a result, we demonstrate a substantial improvement of up to 40% in participants' target localization accuracy. We additionally provide guidelines for content creation to ensure coherent and seamless VR experiences.
C1 [Bernal-Berdun, Edurne; Vallejo, Mateo; Serrano, Ana; Gutierrez, Diego] Univ Zaragoza, I3A, Zaragoza, Spain.
   [Sun, Qi] NYU, New York, NY USA.
C3 University of Zaragoza; New York University
RP Bernal-Berdun, E (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM edurnebernal@unizar.es; mvallejo@unizar.es; qisun@nyu.edu;
   anase@unizar.es; diegog@unizar.es
OI Vallejo Dominguez, Mateo/0009-0008-8365-2405; Bernal-Berdun,
   Edurne/0000-0002-5275-8652; Sun, Qi/0000-0002-3094-5844
FU European Union's Horizon 2020 research and innovation program
FX No Statement Available
CR ARNOULT MD, 1950, AM J PSYCHOL, V63, P229, DOI 10.2307/1418926
   Berger CC, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00021
   Berghi D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P667, DOI [10.1109/VRW50115.2020.00-91, 10.1109/VRW50115.2020.00184]
   CARPENTER RHS, 1988, MOVEMENTS EYES, V2
   Chen LH, 2013, ATTEN PERCEPT PSYCHO, V75, P790, DOI 10.3758/s13414-013-0475-4
   Chenechal M. L., 2018, INT C ARTIFICIAL REA
   Dufour A, 2007, NEUROPSYCHOLOGIA, V45, P447, DOI 10.1016/j.neuropsychologia.2006.05.027
   Duinkharjav B., 2022, ACM Transactions on Graphics (TOG), V41, P1
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Freeman TCA, 2017, J EXP PSYCHOL HUMAN, V43, P371, DOI 10.1037/xhp0000321
   Fukusima SS, 1997, J EXP PSYCHOL HUMAN, V23, P86, DOI 10.1037/0096-1523.23.1.86
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Genzel D, 2018, P NATL ACAD SCI USA, V115, P4264, DOI 10.1073/pnas.1712058115
   Grantham DW, 2003, J ACOUST SOC AM, V114, P1009, DOI 10.1121/1.1590970
   Hu ZM, 2023, IEEE T VIS COMPUT GR, V29, P1992, DOI 10.1109/TVCG.2021.3138902
   Huang HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1109/TAFFC.2019.2901456, 10.1145/3290605.3300851]
   Iachini T, 2012, APPL COGNITIVE PSYCH, V26, P757, DOI 10.1002/acp.2856
   Kim E, 2021, ERGONOMICS, V64, P891, DOI 10.1080/00140139.2020.1869320
   Kim H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P120, DOI 10.1109/VR.2019.8798247
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P2080, DOI 10.1109/TVCG.2022.3150514
   Krajancich B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459784
   Kytö M, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P49, DOI 10.1109/ISMAR.2015.18
   Larsson P, 2010, HUM-COMPUT INT-SPRIN, P143, DOI 10.1007/978-1-84882-733-2_8
   LESTER G, 1969, ACTA PSYCHOL, V31, P375, DOI 10.1016/0001-6918(69)90094-8
   Leung J, 2008, P NATL ACAD SCI USA, V105, P6492, DOI 10.1073/pnas.0710837105
   Lewald J, 2001, EUR J NEUROSCI, V13, P2268, DOI 10.1046/j.0953-816x.2001.01608.x
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Narbutt M., 2017, INT C VIRTUAL SYSTEM, P1
   Nidiffer AR, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32673-y
   Odegaard B, 2017, PEERJ, V5, DOI 10.7717/peerj.3143
   PERROTT DR, 1990, J ACOUST SOC AM, V87, P1728, DOI 10.1121/1.399421
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Potter T, 2022, FRONT SIGNAL PROC-SW, V2, DOI 10.3389/frsip.2022.904866
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Prinz Jesse J., 2006, Contemporary debates in cognitive science, P22
   Ross J, 1997, NATURE, V386, P598, DOI 10.1038/386598a0
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Seitz AR, 2006, CURR BIOL, V16, P1422, DOI 10.1016/j.cub.2006.05.048
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Shams L, 2010, PHYS LIFE REV, V7, P269, DOI 10.1016/j.plrev.2010.04.006
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Sosa Y, 2010, BRAIN COGNITION, V73, P229, DOI 10.1016/j.bandc.2010.05.007
   Stenzel H, 2018, 2018 AES INTERNATIONAL CONFERENCE ON AUDIO FOR VIRTUAL AND AUGMENTED REALITY
   THURLOW WR, 1970, AM J PSYCHOL, V83, P112, DOI 10.2307/1420861
   Van Barneveld DCPBM, 2010, EUR J NEUROSCI, V31, P920, DOI 10.1111/j.1460-9568.2010.07113.x
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Wexler M, 2005, TRENDS COGN SCI, V9, P431, DOI 10.1016/j.tics.2005.06.018
   Yoonessi A, 2011, J VISION, V11, DOI 10.1167/11.9.13
   Zhang J, 2018, IEEE T VIS COMPUT GR, V24, P1671, DOI 10.1109/TVCG.2018.2793679
NR 50
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2624
EP 2632
DI 10.1109/TVCG.2024.3372112
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200006
PM 38446650
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Salagean, A
   Wu, M
   Fletcher, G
   Cosker, D
   Fraser, DS
AF Salagean, Anca
   Wu, Michelle
   Fletcher, George
   Cosker, Darren
   Fraser, Danae Stanton
TI The Utilitarian Virtual Self - Using Embodied Personalized Avatars to
   Investigate Moral Decision-Making in Semi-Autonomous Vehicle Dilemmas
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ethics; Avatars; Motor drives; Decision making; Automobiles; Electronic
   mail; Vehicles; Human-centered computing-Empirical studies in HCI;
   Virtual reality; Usability testing
ID BODY OWNERSHIP; ENVIRONMENTS; JUDGMENT; SENSE; EXPERIENCE; BEHAVIOR
AB Embodied personalized avatars are a promising new tool to investigate moral decision-making by transposing the user into the "middle of the action" in moral dilemmas. Here, we tested whether avatar personalization and motor control could impact moral decision-making, physiological reactions and reaction times, as well as embodiment, presence and avatar perception. Seventeen participants, who had their personalized avatars created in a previous study, took part in a range of incongruent (i.e., harmful action led to better overall outcomes) and congruent (i.e., harmful action led to trivial outcomes) moral dilemmas as the drivers of a semi-autonomous car. They embodied four different avatars (counterbalanced - personalized motor control, personalized no motor control, generic motor control, generic no motor control). Overall, participants took a utilitarian approach by performing harmful actions only to maximize outcomes. We found increased physiological arousal (SCRs and heart rate) for personalized avatars compared to generic avatars, and increased SCRs in motor control conditions compared to no motor control. Participants had slower reaction times when they had motor control over their avatars, possibly hinting at more elaborate decision-making processes. Presence was also higher in motor control compared to no motor control conditions. Embodiment ratings were higher for personalized avatars, and generally, personalization and motor control were perceptually positive features. These findings highlight the utility of personalized avatars and open up a range of future research possibilities that could benefit from the affordances of this technology and simulate, more closely than ever, real-life action.
C1 [Salagean, Anca] Univ Bath, Comp Sci Dept, Bath, England.
   [Salagean, Anca; Fraser, Danae Stanton] Univ Bath, Psychol Dept, Bath, England.
   [Wu, Michelle; Fletcher, George; Cosker, Darren] Univ Bath, CAMERA, Bath, England.
   [Cosker, Darren] Microsoft UK, London, England.
C3 University of Bath; University of Bath; University of Bath
RP Salagean, A (corresponding author), Univ Bath, Comp Sci Dept, Bath, England.; Salagean, A (corresponding author), Univ Bath, Psychol Dept, Bath, England.
EM as3101@bath.ac.uk; mw2634@bath.ac.uk; gf321@bath.ac.uk;
   dpc22@bath.ac.uk; pssds@bath.ac.uk
OI Cosker, Darren/0000-0001-5177-4741; Stanton Fraser,
   Danae/0000-0002-3062-731X
FU Bristol and Bath Creative R&D funded by the AHRC Creative Industries
   Cluster Programme
FX No Statement Available
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Azuma MC, 2023, ERGONOMICS, V66, P246, DOI 10.1080/00140139.2022.2076906
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Bartl A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694617
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654
   Boucsein W, 2012, PSYCHOPHYSIOLOGY, V49, P1017, DOI 10.1111/j.1469-8986.2012.01384.x
   Braithwaite JJ., 2013, Psychophysiology, V49, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Brown H., 2021, Doctoral Thesis
   Caserman P, 2020, IEEE T VIS COMPUT GR, V26, P3089, DOI 10.1109/TVCG.2019.2912607
   Conway P, 2013, J PERS SOC PSYCHOL, V104, P216, DOI 10.1037/a0031021
   Cushman F, 2013, PERS SOC PSYCHOL REV, V17, P273, DOI 10.1177/1088868313495594
   Cushman F, 2012, EMOTION, V12, P2, DOI 10.1037/a0025071
   Farmer H, 2012, CONSCIOUS COGN, V21, P1242, DOI 10.1016/j.concog.2012.04.011
   Faulhaber AK, 2019, SCI ENG ETHICS, V25, P399, DOI 10.1007/s11948-018-0020-x
   Figner B., 2011, A handbook of process tracing methods for decision research: A critical review and user's guide, P163
   Francis KB, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13909-9
   Francis KB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164374
   Frank DA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49411-7
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gawronski B, 2017, SOC NEUROSCI-UK, V12, P626, DOI 10.1080/17470919.2016.1248787
   Geisslinger M, 2023, NAT MACH INTELL, V5, P137, DOI 10.1038/s42256-022-00607-z
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07
   Greene JD, 2004, NEURON, V44, P389, DOI 10.1016/j.neuron.2004.09.027
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   Greene JD, 2008, COGNITION, V107, P1144, DOI 10.1016/j.cognition.2007.11.004
   Hazra A, 2016, INDIAN J DERMATOL, V61, P10, DOI 10.4103/0019-5154.173988
   Horn C, 2006, GROUNDWORK FOR THE METAPHYSICS OF MORALS, P1, DOI 10.1515/9783110204551
   Kallioinen Noa, 2019, Front Psychol, V10, P2415, DOI 10.3389/fpsyg.2019.02415
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kirchmair L, 2023, NAT MACH INTELL, V5, P814, DOI 10.1038/s42256-023-00706-5
   Koenigs M, 2007, NATURE, V446, P908, DOI 10.1038/nature05631
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Lin JH, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.974652
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Mendez MF, 2005, COGN BEHAV NEUROL, V18, P193, DOI 10.1097/01.wnn.0000191292.17964.bb
   Mill J. S., 1998, Utilitarianism
   Navarrete CD, 2012, EMOTION, V12, P364, DOI 10.1037/a0025561
   Ni BK, 2023, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1063607
   Niforatos E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376788
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pan X., 2011, P HCI 2011 25 BCS C, V25, P46, DOI DOI 10.14236/EWIC/HCI2011.26
   Pan XN, 2011, LECT NOTES COMPUT SC, V6975, P52, DOI 10.1007/978-3-642-24571-8_6
   Patil I, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00501
   Patil I, 2014, SOC NEUROSCI-UK, V9, P94, DOI 10.1080/17470919.2013.870091
   Patil M. M., 2020, Journal of Personality and Social Psychology, P1
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Pyasik M, 2021, COGNITION, V212, DOI 10.1016/j.cognition.2021.104693
   Qian LX, 2023, TECHNOL FORECAST SOC, V188, DOI 10.1016/j.techfore.2022.122267
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Reynolds CJ, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.06.005
   Salagean A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581182
   Salagean A, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3487563
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Skulmowski A, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00426
   Slater M., 2020, FRONT VIRTUAL REAL, V1, P1, DOI DOI 10.3389/FRVIR.2020.00001
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, ANU PSICOL, V40, P193
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sood S, 2005, ORGAN BEHAV HUM DEC, V98, P144, DOI 10.1016/j.obhdp.2005.05.005
   Sütfeld LR, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00122
   Tassy S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00250
   Thomson J., 1986, RIGHTS RESTITUTION R
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133
   Uijong J, 2019, IEEE T VIS COMPUT GR, V25, P1898, DOI 10.1109/TVCG.2019.2899227
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang Huarong, 2023, Engineering Psychology and Cognitive Ergonomics: 20th International Conference, EPCE 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14018), P560, DOI 10.1007/978-3-031-35389-5_39
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf E, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1031093
   Wu TLY, 2019, INT J HUM-COMPUT INT, V35, P1569, DOI 10.1080/10447318.2018.1555736
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Youssef FF, 2012, PSYCHONEUROENDOCRINO, V37, P491, DOI 10.1016/j.psyneuen.2011.07.017
   Zhu AR, 2022, PERS INDIV DIFFER, V186, DOI 10.1016/j.paid.2021.111356
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 79
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2162
EP 2172
DI 10.1109/TVCG.2024.3372121
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400018
PM 38437115
DA 2024-08-05
ER

PT J
AU Li, H
   Yang, XR
   Zhai, HJ
   Liu, YQ
   Bao, HJ
   Zhang, GF
AF Li, Hai
   Yang, Xingrui
   Zhai, Hongjia
   Liu, Yuqian
   Bao, Hujun
   Zhang, Guofeng
TI Vox-Surf: Voxel-Based Implicit Surface Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surface reconstruction; Image reconstruction; Geometry; Rendering
   (computer graphics); Three-dimensional displays; Feature extraction;
   Surface treatment; Implicit representation; surface reconstruction;
   scene editing
AB Virtual content creation and interaction play an important role in modern 3D applications. Recovering detailed 3D models from real scenes can significantly expand the scope of its applications and has been studied for decades in the computer vision and computer graphics community. In this work, we propose Vox-Surf, a voxel-based implicit surface representation. Our Vox-Surf divides the space into finite sparse voxels, where each voxel is a basic geometry unit that stores geometry and appearance information on its corner vertices. Due to the sparsity inherited from the voxel representation, Vox-Surf is suitable for almost any scene and can be easily trained end-to-end from multiple view images. We utilize a progressive training process to gradually cull out empty voxels and keep only valid voxels for further optimization, which greatly reduces the number of sample points and improves inference speed. Experiments show that our Vox-Surf representation can learn fine surface details and accurate colors with less memory and faster rendering than previous methods. The resulting fine voxels can also be considered as the bounding volumes for collision detection, which is useful in 3D interactions. We also show the potential application of Vox-Surf in scene editing and augmented reality. The source code is publicly available at https://github.com/zju3dv/Vox-Surf.
C1 [Li, Hai; Zhai, Hongjia; Bao, Hujun; Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yang, Xingrui] Univ Bristol, Visual Informat Lab, Bristol BS8 1TL, England.
   [Liu, Yuqian] SenseTime, Autonomous Driving Grp, Shanghai 200233, Peoples R China.
C3 Zhejiang University; University of Bristol
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM garyli@zju.edu.cn; x.yang@bristol.ac.uk; zhj1999@zju.edu.cn;
   liuyuqian@senseauto.com; baohujun@zju.edu.cn; zhangguofeng@zju.edu.cn
RI liu, yuqian/ITV-9412-2023
OI Zhang, Guofeng/0000-0001-5661-8430; Yang, Xingrui/0000-0001-6812-3072;
   Li, Hai/0000-0002-5114-6566; Zhai, Hongjia/0000-0002-7729-8787; Bao,
   Hujun/0000-0002-2662-0334
FU National Natural Science Foundation of China
FX No Statement Available
CR Azinovic D, 2022, Arxiv, DOI arXiv:2104.04532
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Darmon F, 2022, PROC CVPR IEEE, P6250, DOI 10.1109/CVPR52688.2022.00616
   Deng KL, 2022, Arxiv, DOI arXiv:2107.02791
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gropp A., 2020, PMLR, P3789
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Laine S, 2011, IEEE T VIS COMPUT GR, V17, P1048, DOI 10.1109/TVCG.2010.240
   Li H, 2020, INT CONF 3D VISION, P1098, DOI 10.1109/3DV50981.2020.00120
   Liao YY, 2022, Arxiv, DOI arXiv:2109.13410
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu J. Gu, 2020, ADV NEURAL INF PROCE
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Munkberg J, 2022, PROC CVPR IEEE, P8270, DOI 10.1109/CVPR52688.2022.00810
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nair V., 2010, ICML, P807
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Oechsle M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5569, DOI 10.1109/ICCV48922.2021.00554
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Rematas Konstantinos, 2021, arXiv
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Seitz S. M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [DOI 10.1109/CVPR.2006.19, https://doi.org/10.1109/CVPR.2006.19]
   Sitzmann V., 2019, Advances in Neural Information Processing Systems, P1119
   Sun J., 2022, PROC SPECIALINT GROU
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Wang L., 2021, Adv. Neural Inf. Process. Syst., p27 171
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Yang BB, 2022, LECT NOTES COMPUT SC, V13676, P597, DOI 10.1007/978-3-031-19787-1_34
   Yariv L, 2021, ADV NEUR IN
   Yariv Lior, 2020, P ADV NEURAL INFORM
   Yu Alex, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P4576, DOI 10.1109/CVPR46437.2021.00455
NR 43
TC 1
Z9 1
U1 12
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1743
EP 1755
DI 10.1109/TVCG.2022.3225844
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500002
PM 36459607
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Assor, A
   Prouzeau, A
   Hachet, M
   Dragicevic, P
AF Assor, Ambre
   Prouzeau, Arnaud
   Hachet, Martin
   Dragicevic, Pierre
TI Handling Non-Visible Referents in Situated Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Taxonomy; Models; Frameworks; Theory; Mobile; AR/VR/Immersive;
   Specialized Input/Display Hardware
ID MIXED REALITY; TAXONOMY
AB Situated visualizations are a type of visualization where data is presented next to its physical referent (i.e., the physical object, space, or person it refers to), often using augmented-reality displays. While situated visualizations can be beneficial in various contexts and have received research attention, they are typically designed with the assumption that the physical referent is visible. However, in practice, a physical referent may be obscured by another object, such as a wall, or may be outside the user's visual field. In this paper, we propose a conceptual framework and a design space to help researchers and user interface designers handle non-visible referents in situated visualizations. We first provide an overview of techniques proposed in the past for dealing with non-visible objects in the areas of 3D user interfaces, 3D visualization, and mixed reality. From this overview, we derive a design space that applies to situated visualizations and employ it to examine various trade-offs, challenges, and opportunities for future research in this area.
C1 [Assor, Ambre; Prouzeau, Arnaud; Hachet, Martin; Dragicevic, Pierre] Univ Bordeaux, Inria, CNRS, Bordeaux, France.
C3 Universite de Bordeaux; Inria; Centre National de la Recherche
   Scientifique (CNRS)
RP Assor, A (corresponding author), Univ Bordeaux, Inria, CNRS, Bordeaux, France.
EM ambre.assor@inria.fr; arnaud.prouzeau@inria.fr; martin.hachet@inria.fr;
   pierre.dragicevic@inria.fr
OI Assor, Ambre/0000-0003-3304-4459; Prouzeau, Arnaud/0000-0003-3800-5870;
   Hachet, Martin/0000-0003-3889-2529
FU Agence Nationale de la Recherche (ANR)
FX No Statement Available
CR Ajanki A, 2011, VIRTUAL REAL-LONDON, V15, P161, DOI 10.1007/s10055-010-0183-5
   Alce G, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P81, DOI 10.1109/ISMAR-Adjunct.2017.37
   Andújar C, 2004, COMPUT GRAPH FORUM, V23, P499, DOI 10.1111/j.1467-8659.2004.00781.x
   Andujar C, 2010, PRESENCE-TELEOP VIRT, V19, P499, DOI 10.1162/pres_a_00018
   Ardouin J., 2012, PROCVRST
   Arpaia P, 2021, IEEE SENS J, V21, P11176, DOI 10.1109/JSEN.2021.3059636
   Avery B., 2007, PROC ISMAR, P285, DOI DOI 10.1109/ISMAR.2007.4538869
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Baudisch P., 2003, P CHI, P481, DOI [DOI 10.1145/642611.6426951,2, 10.1145/642611.642695]
   Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   Bell B., 2002, P 15 ANN ACM S USER, P213
   Bichlmeier C, 2007, LECT NOTES COMPUT SC, V4791, P434
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Blanco R., 2019, IEEE VIS 2019
   Bluff A, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/33599973365682
   Bork F., 2019, PROC ISMAR, DOI [10.1109/ISMAR-Adjunct.2019.00-283, DOI 10.1109/ISMAR-ADJUNCT.2019.00-283]
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Boudell JA, 2019, APPL PLANT SCI, V7, DOI 10.1002/aps3.11311
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Caggianese Giuseppe, 2019, 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS), P390, DOI 10.1109/SITIS.2019.00069
   Card M., 1999, Readings in information visualization: using vision to think, DOI [10.5555/3006797, DOI 10.5555/3006797]
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Chittaro L., 2003, PROC WEB 3D, DOI [10.1145/636593.636598, DOI 10.1145/636593.636598]
   Chittaro L., Proceedings of the Working Conference on Advanced Visual Interfaces, ser. AVI '04. New York, NY, USA: ACM, P267
   Coffey Dane., 2011, Symposium on Interactive 3D Graphics and Games, P191, DOI DOI 10.1145/1944745.1944777
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Drey T., 2018, Data Visualisation using Augmented Reality with a Focus set on Head Mounted Displays and Collaborative Tasks
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Elvins T. T., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P21, DOI 10.1145/263407.263504
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   Eren MT, 2018, VISUAL COMPUT, V34, P405, DOI 10.1007/s00371-016-1346-5
   Fan K., 2014, PROC AH, DOI [10.1145/2582051.2582100, DOI 10.1145/2582051.2582100]
   Fedosov A., 2014, PROC EICS
   Foyle D. C., 2005, PROC HCI INT
   Frey J., 2014, Proceedings of the 27 th Annual ACM Symposium on User Interface Software and Technology, P301
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Ghosh S., 2015, PROC CHI
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Gruenefeld U., 2018, MobileHCI
   Gruenefeld U., 2018, PROC MOBILEHCI
   Gruenefeld U., 2018, MobileHCI, DOI [10.1145/3236112.3236115, DOI 10.1145/3236112.3236115]
   Gustafson S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P787
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hirose K, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P75
   Holstius D., 2004, Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, P215, DOI DOI 10.1145/1013115.1013145
   Ilie A., 2004, Presence: Teleoperators and Virtual Environments, V13
   Ishiguro Yoshio., 2011, P 2 AUGMENTED HUMAN, P8
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jo H, 2011, COMPUT GRAPH-UK, V35, P841, DOI 10.1016/j.cag.2011.04.005
   Johansen J.D., 2002, SIGNS USE INTRO SEMI
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kantonen T, 2010, P IEEE VIRT REAL ANN, P179, DOI 10.1109/VR.2010.5444792
   Kristoffersson A, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/902316
   Kritzler M, 2017, IOT'17: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS, P197, DOI 10.1145/3131542.3140274
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Laaki H, 2019, IEEE ACCESS, V7, P20325, DOI 10.1109/ACCESS.2019.2897018
   Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511
   Livingston M. A., 2013, HUMAN FACTORS AUGMEN, P67, DOI DOI 10.1007/978-1-4614-4205-9_4
   Lubos P, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927939
   Macedo L. F., 2021, IEEE TVCG
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Mercier-Ganady J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P33, DOI 10.1109/VR.2014.6802047
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mizuno F., 2009, PROC IFMB
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Mori Shohei, 2017, IPSJ Transactions on Computer Vision and Applications, V9, P1, DOI [10.1186/s41074-017-0028-1, DOI 10.1186/S41074-017-0028-1]
   Nam JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P747, DOI [10.1109/vr.2019.8797871, 10.1109/VR.2019.8797871]
   Pausch R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P399, DOI 10.1145/218380.218495
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Qiu C., 2019, Virtual Real Intel Hardw, V1, P597, DOI DOI 10.1016/J.VRIH.2019.10.002
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Satriadi K., 2023, CHI
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Seo DW, 2016, COMPUT IND, V76, P11, DOI 10.1016/j.compind.2015.11.003
   Sherman W. R., 2003, Presence: Teleoperators & Virtual Environments, V12
   Siu T., 2013, PROC CHI
   Sousa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4057, DOI 10.1145/3025453.3025566
   Sukan M., 2014, PROCUIST
   Tachi S, 2003, ADV ROBOTICS, V17, P199, DOI 10.1163/156855303764018468
   Tachi S, 2011, IEEE INT C INT ROBOT, P157, DOI 10.1109/IROS.2011.6048151
   Tao F., 2019, Digital Twin Driven Smart Manu- facturing, DOI DOI 10.1016/B978-0-12-817630-6.00003-5
   Tatzgern M, 2015, PERVASIVE MOB COMPUT, V18, P55, DOI 10.1016/j.pmcj.2014.08.010
   Thomas BH, 2018, LECT NOTES COMPUT SC, V11190, P185, DOI 10.1007/978-3-030-01388-2_7
   Truman S., 2020, PROC FDG, V69, DOI [10.1145/3402942.34029943, DOI 10.1145/3402942.34029943]
   Vermeulen J, 2012, S VIS LANG HUM CEN C, P89, DOI 10.1109/VLHCC.2012.6344490
   Wang XY, 2014, COMPUT IND, V65, P314, DOI 10.1016/j.compind.2013.11.012
   White S, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P119, DOI 10.1109/TRIDUI.2006.1618281
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Willett W., 2021, IEEE TVCG, V2021, DOI [10.1109/TVCG.2021.31148444,8,9, DOI 10.1109/TVCG.2021.31148444,8,9]
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wither J, 2009, COMPUT GRAPH-UK, V33, P679, DOI 10.1016/j.cag.2009.06.001
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
NR 97
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1336
EP 1346
DI 10.1109/TVCG.2023.3327361
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500014
PM 37878456
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Bae, SS
   Fujiwara, T
   Ynnerman, A
   Do, EYL
   Rivera, ML
   Szafir, DA
AF Bae, S. Sandra
   Fujiwara, Takanori
   Ynnerman, Anders
   Do, Ellen Yi-Luen
   Rivera, Michael L.
   Szafir, Danielle Albers
TI A Computational Design Pipeline to Fabricate Sensing Network
   Physicalizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Physicalization; tangible interfaces; 3D printing; computational
   fabrication; design automation; network data
ID INTERACTIVE VISUALIZATION; EXPLORATION; PROVENANCE; MODELS
AB Interaction is critical for data analysis and sensemaking. However, designing interactive physicalizations is challenging as it requires cross-disciplinary knowledge in visualization, fabrication, and electronics. Interactive physicalizations are typically produced in an unstructured manner, resulting in unique solutions for a specific dataset, problem, or interaction that cannot be easily extended or adapted to new scenarios or future physicalizations. To mitigate these challenges, we introduce a computational design pipeline to 3D print network physicalizations with integrated sensing capabilities. Networks are ubiquitous, yet their complex geometry also requires significant engineering considerations to provide intuitive, effective interactions for exploration. Using our pipeline, designers can readily produce network physicalizations supporting selection-the most critical atomic operation for interaction-by touch through capacitive sensing and computational inference. Our computational design pipeline introduces a new design paradigm by concurrently considering the form and interactivity of a physicalization into one cohesive fabrication workflow. We evaluate our approach using (i) computational evaluations, (ii) three usage scenarios focusing on general visualization tasks, and (iii) expert interviews. The design paradigm introduced by our pipeline can lower barriers to physicalization research, creation, and adoption.
C1 [Bae, S. Sandra; Do, Ellen Yi-Luen; Rivera, Michael L.] Univ Colorado, Boulder, CO 80309 USA.
   [Fujiwara, Takanori; Ynnerman, Anders] Linkoping Univ, Linkoping, Sweden.
   [Szafir, Danielle Albers] Univ North Carolina Chapel Hill, Chapel Hill, NC USA.
C3 University of Colorado System; University of Colorado Boulder; Linkoping
   University; University of North Carolina; University of North Carolina
   Chapel Hill; University of North Carolina School of Medicine
RP Bae, SS (corresponding author), Univ Colorado, Boulder, CO 80309 USA.
EM sandra.bae@colorado.edu; takanori.fujiwara@liu.se;
   anders.ynnerman@liu.se; ellen.do@colorado.edu; mrivera@colorado.edu;
   danielle.szafir@cs.unc.edu
OI Rivera, Michael/0000-0002-5998-8039; Do, Ellen
   Yi-Luen/0000-0002-9948-6375; Ynnerman, Anders/0000-0002-9466-9826; Bae,
   Sandra/0000-0002-2023-6219
FU U.S. National Science Foundation
FX No Statement Available
CR Ahmed R, 2022, IEEE T VIS COMPUT GR, V28, P2388, DOI 10.1109/TVCG.2022.3155564
   Allahverdi K, 2018, COMPUT GRAPH FORUM, V37, P439, DOI 10.1111/cgf.13432
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Ang KD, 2019, COMPUT GRAPH-UK, V85, P42, DOI 10.1016/j.cag.2019.09.004
   [Anonymous], 2023, Supplemental Material
   Arduino, 2023, Arduino Documentation
   Bae SS, 2023, IEEE T VIS COMPUT GR, V29, P257, DOI 10.1109/TVCG.2022.3209442
   Bae SS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501939
   Barabasi AL, 2016, NETWORK SCIENCE, P1
   Bennett Chris, 2007, PROC CAE, DOI [10.2312/COMPAESTH/COMPAESTH07/057-064, 10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brown R., 2003, Phys Teach, V41, P483, DOI [10.1119/1.1625209, DOI 10.1119/1.1625209]
   Burstyn J, 2015, LECT NOTES COMPUT SC, V9296, P332, DOI 10.1007/978-3-319-22701-6_25
   Cohen J. S., 2003, Computer Algebra and Symbolic Computation: Mathematical Methods, DOI [10.1201/9781439863701, DOI 10.1201/9781439863701]
   Daneshzand Foroozan, 2023, IEEE Trans Vis Comput Graph, V29, P225, DOI 10.1109/TVCG.2022.3209365
   Davidson S., 2023, Grasshopper-algorithmic modeling for Rhino
   de Freitas AA, 2022, IEEE INT CONF INF VI, P73, DOI 10.1109/IV56949.2022.00021
   Dehmamy N, 2018, NATURE, V563, P676, DOI 10.1038/s41586-018-0726-6
   Dijkshoorn A, 2020, IEEE SENS J, V20, P14218, DOI 10.1109/JSEN.2020.3007249
   Djavaherpour H, 2021, COMPUT GRAPH FORUM, V40, P569, DOI 10.1111/cgf.14330
   Drogemuller A., 2021, PROC CHI ACM, DOI [10.1145/3411764.34457041, DOI 10.1145/3411764.3445704]
   ESD Association, 2020, Fundamentals of electrostatic discharge: Part fivedevice sensitivity and testing
   FOLEY JD, 1984, IEEE COMPUT GRAPH, V4, P13, DOI 10.1109/MCG.1984.6429355
   Freksa C, 2019, SPAT COGN COMPUT, V19, P46, DOI 10.1080/13875868.2018.1531415
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Fujiwara T, 2018, VIS INFORM, V2, P213, DOI 10.1016/j.visinf.2018.12.002
   FURER M, 1992, PROCEEDINGS OF THE THIRD ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P317
   García IL, 2021, PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, TEI 2021, DOI 10.1145/3430524.3440627
   Gerber S, 2010, IEEE T VIS COMPUT GR, V16, P1271, DOI 10.1109/TVCG.2010.213
   Grabkowska D., 2023, What Made Me
   Grosse-Puppendahl T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3293, DOI 10.1145/3025453.3025808
   Hagberg A. A., 2008, EXPLORING NETWORK ST, P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003
   Hayes M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.875
   He L, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3495000
   Herman Bridger, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488542
   Hermann T., 1999, Advances in Intelligent Computing and Multimedia Systems, P189
   Hu Guosheng, 2022, 2022 8th International Conference on Virtual Reality (ICVR), P126, DOI 10.1109/ICVR55215.2022.9847779
   Huang HH, 2023, INFORM VISUAL, V22, P169, DOI 10.1177/14738716231157082
   Huang YJ, 2017, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2017.8031577
   Huron Samuel, 2014, P 2014 C DES INT SYS, P433, DOI [DOI 10.1145/2598510.2598566, DOI 10.1145/ONDESIGNINGINTERACTIVESYSTEMS(DIS'2598510.2598566]
   Hurtienne J, 2020, IEEE COMPUT GRAPH, V40, P61, DOI 10.1109/MCG.2020.3025385
   iSANMATE, 2014, Wood filament PLA+, P1733, DOI [10.1145/2556288.2557046, DOI 10.1145/2556288.2557046]
   Ishiguro Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1733, DOI 10.1145/2556288.2557046
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Jansen Yvonne., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P2593, DOI [DOI 10.1145/2470654, 10.1145/2470654]
   Jin YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P701, DOI 10.1145/3332165.3347905
   Kelly JW, 2011, PSYCHON B REV, V18, P1119, DOI 10.3758/s13423-011-0162-1
   Kerren A, 2014, LECT NOTES COMPUT SC, V8380, P1, DOI 10.1007/978-3-319-06793-3_1
   Le Goc M, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/2984511.2984547
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   McGuffin M. J., 2023, IEEE Trans Vis Comput Graph, P1
   Meurer A, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.103
   Newman M, 2018, Networks: An Introduction, VSecond, DOI DOI 10.1093/ACPROF:OSO/9780199206650.001.0001/ACPROF-9780199206650
   Ngo TD, 2018, COMPOS PART B-ENG, V143, P172, DOI 10.1016/j.compositesb.2018.02.012
   Noren L., 2011, Infographics inspire art | R. Justin Stewart
   Paszke A, 2019, ADV NEUR IN, V32
   Patnaik B, 2023, IEEE T VIS COMPUT GR, V29, P5282, DOI 10.1109/TVCG.2022.3209631
   Peixoto Tiago P, 2017, Figshare
   Peixoto Tiago P., 2020, Netzschleuder: the network catalogue, repository and centrifuge
   ProtoPasta, 2023, Conductive PLA
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Robert McNeel & Associates, 2023, Rhinoceros
   Roberts JC, 2014, IEEE COMPUT GRAPH, V34, P26, DOI 10.1109/MCG.2014.82
   Rosling H., 2014, Global population growth, box by box
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savage Valkyrie, 2014, UIST '14, P3
   Schmitz M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300684
   Schmitz M, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P253, DOI 10.1145/2807442.2807503
   Schönborn KJ, 2016, SCI POL REP, P195, DOI 10.1007/978-3-319-31833-2_7
   Soh WS, 2009, APMC: 2009 ASIA PACIFIC MICROWAVE CONFERENCE, VOLS 1-5, P1285, DOI 10.1109/APMC.2009.5384455
   Stusak S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3247, DOI 10.1145/2702123.2702248
   Stusak S, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P92, DOI 10.1145/2839462.2839476
   Stusak S, 2014, IEEE T VIS COMPUT GR, V20, P2201, DOI 10.1109/TVCG.2014.2352953
   Swaminathan S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3845, DOI 10.1145/2556288.2557310
   Taher F, 2017, IEEE T VIS COMPUT GR, V23, P451, DOI 10.1109/TVCG.2016.2598498
   Thrun M. C., 2016, PROC WSCG, P7
   Tuinenga PW., 1995, SPICE: a guide to circuit simulation and analysis using PSpice
   Vasquez J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376425
   Verhulsdonck G, 2007, SIGDOC'07: PROCEEDINGS OF THE 25TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P26
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Vishwanathan S.V.N., 2009, AISTATS, V5, P488
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Weller MichaelPhiletus., 2008, Proc. of TEI '08, P39
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Willis KDD, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P589
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Ynnerman A, 2018, IEEE COMPUT GRAPH, V38, P13, DOI 10.1109/MCG.2018.032421649
   Ynnerman A, 2016, COMMUN ACM, V59, P72, DOI 10.1145/2950040
NR 94
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 913
EP 923
DI 10.1109/TVCG.2023.3327198
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500062
PM 37906495
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hull, M
   Pednekar, V
   Murray, H
   Roy, N
   Tung, E
   Routray, S
   Guerin, C
   Chen, J
   Wang, ZJ
   Lee, S
   Roozbahani, M
   Chau, DH
AF Hull, Matthew
   Pednekar, Vivian
   Murray, Hannah
   Roy, Nimisha
   Tung, Emmanuel
   Routray, Susanta
   Guerin, Connor
   Chen, Justin
   Wang, Zijie J.
   Lee, Seongmin
   Roozbahani, Mahdi
   Chau, Duen Horng
TI VISGRADER: Automatic Grading of D3 Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Automatic grading; D3 visualization; large class; Selenium; Gradescope
   grading platform
AB Manually grading D3 data visualizations is a challenging endeavor, and is especially difficult for large classes with hundreds of students. Grading an interactive visualization requires a combination of interactive, quantitative, and qualitative evaluation that are conventionally done manually and are difficult to scale up as the visualization complexity, data size, and number of students increase. We present VisGrader, a first-of-its kind automatic grading method for D3 visualizations that scalably and precisely evaluates the data bindings, visual encodings, interactions, and design specifications used in a visualization. Our method enhances students' learning experience, enabling them to submit their code frequently and receive rapid feedback to better inform iteration and improvement to their code and visualization design. We have successfully deployed our method and auto-graded D3 submissions from more than 4000 students in a visualization course at Georgia Tech, and received positive feedback for expanding its adoption.
C1 [Hull, Matthew; Pednekar, Vivian; Murray, Hannah; Roy, Nimisha; Tung, Emmanuel; Routray, Susanta; Guerin, Connor; Chen, Justin; Wang, Zijie J.; Lee, Seongmin; Roozbahani, Mahdi; Chau, Duen Horng] Georgia Inst Technol, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Hull, M (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM matthewhull@gatech.edu; vpednekar3@gatech.edu; hmurray9@gatech.edu;
   nroy9@gatech.edu; tunge@gatech.edu; sroutray@gatech.edu;
   cguerin6@gatech.edu; chen3001@gatech.edu; jayw@gatech.edu;
   seongmin@gatech.edu; mahdir@gatech.edu; polo@gatech.edu
OI Wang, Zijie Jay/0000-0003-4360-1423; Roozbahani, M.
   Mahdi/0000-0001-5462-1409
CR Ahmed UZ, 2020, 2020 ACM/IEEE 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING EDUCATION AND TRAINING (ICSE-SEET 2020), P139, DOI 10.1145/3377814.3381703
   [Anonymous], 2023, CS6242 Data and Visual Analytics
   [Anonymous], 2023, CS448B-Data Visualization
   [Anonymous], 2022, CS5630/CS6630-Visualization for Data Science
   [Anonymous], 2023, Enrollment history of CS6242 Data and Visual Analytics
   [Anonymous], 2022, CS171-Visualization
   [Anonymous], 2022, CSE512-Data Visualization
   [Anonymous], 2019, CS444-Data Visualization
   Battle L, 2022, IEEE VIS CONF, P1, DOI 10.1109/VIS54862.2022.00009
   Blackboard Inc, 2023, Blackboard LMS
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   D2L Corporation, 2023, Brightspace LMS
   Ed Discussion, 2023, About us
   Elavsky F., 2021, Chartability
   Gao J., 2016, PROC ACM C INNOVATIO, P53, DOI [10.1145/2899415.28994402,3, DOI 10.1145/2899415.28994402,3]
   Godefroid P, 2005, ACM SIGPLAN NOTICES, V40, P213, DOI 10.1145/1064978.1065036
   Gradescope Inc, 2020, Gradescope
   Gramoli V., 2016, PROC AUSTRALASIAN CO, P1, DOI DOI 10.1145/2843043.28430703,7
   Gulwani S, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P41, DOI 10.1145/2635868.2635912
   Harper Jonathan, 2014, P 27 ANN ACM S USER, V14, P253, DOI [10.1145/2642918.2647411, DOI 10.1145/2642918.26474112, DOI 10.1145/2642918.2647411]
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hull M, 2021, Arxiv, DOI arXiv:2110.11227
   Instructure Inc, 2023, Canvas LMS
   Joyner D., 2022, Teaching at Scale: Improving Access, Outcomes, and Impact Through Digital Instruction, DOI DOI 10.4324/97810032748348
   Lo LYH, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P11, DOI [10.1109/visual.2019.8933751, 10.1109/VISUAL.2019.8933751]
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Maicus E, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P1145, DOI 10.1145/3328778.3366954
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Moodle PTY Ltd, 2023, Moodle LMS
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Open JS Foundation, 2023, WebHint
   Parihar S, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P92, DOI 10.1145/3059009.3059026
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Segura S, 2016, IEEE T SOFTWARE ENG, V42, P805, DOI 10.1109/TSE.2016.2532875
   SGW Communications, 2023, Sakai LMS
   Sherman M., 2013, J. Comput. Sci. Coll., V28, P69, DOI 10.5555/2460156.24601713,4,7
   Shin S, 2023, Arxiv, DOI arXiv:2303.06537
   Software Freedom Conservancy, 2021, Selenium Action Chain
   Software Freedom Conservancy, 2021, Selenium
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wilcox C., 2015, Proc. 2015 SIGCSE, P90, DOI [10.1145/2676723.2677226, DOI 10.1145/2676723.2677226]
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
NR 48
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 617
EP 627
DI 10.1109/TVCG.2023.3327181
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500013
PM 37883258
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Kim, DH
   Choi, S
   Kim, J
   Setlur, V
   Agrawala, M
AF Kim, Dae Hyun
   Choi, Seulgi
   Kim, Juho
   Setlur, Vidya
   Agrawala, Maneesh
TI EC: A Tool for Guiding Chart and Caption Emphasis&lt;sc/&gt;&lt;sc/&gt;
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Chart and text takeaways; visual prominence; authoring; captions
ID VISUALIZATION
AB Recent work has shown that when both the chart and caption emphasize the same aspects of the data, readers tend to remember the doubly-emphasized features as takeaways; when there is a mismatch, readers rely on the chart to form takeaways and can miss information in the caption text. Through a survey of 280 chart-caption pairs in real-world sources (e.g., news media, poll reports, government reports, academic articles, and Tableau Public), we find that captions often do not emphasize the same information in practice, which could limit how effectively readers take away the authors' intended messages. Motivated by the survey findings, we present Emphasischecker, an interactive tool that highlights visually prominent chart features as well as the features emphasized by the caption text along with any mismatches in the emphasis. The tool implements a time-series prominent feature detector based on the Ramer-Douglas-Peucker algorithm and a text reference extractor that identifies time references and data descriptions in the caption and matches them with chart data. This information enables authors to compare features emphasized by these two modalities, quickly see mismatches, and make necessary revisions. A user study confirms that our tool is both useful and easy to use when authoring charts and captions.
C1 [Kim, Dae Hyun; Choi, Seulgi; Kim, Juho] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Kim, Dae Hyun; Agrawala, Maneesh] Stanford Univ, Stanford, CA USA.
   [Setlur, Vidya] Tableau Res, Amherst, MA USA.
   [Agrawala, Maneesh] Roblox, San Mateo, CA USA.
C3 Korea Advanced Institute of Science & Technology (KAIST); Stanford
   University
RP Kim, DH (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM dhkim16@cs.stanford.edu; igules8925@kaist.ac.kr; juhokim@kaist.ac.kr;
   vsetlur@tableau.com; maneesh@cs.stanford.edu
RI Kim, Dae Hyun/JJD-4264-2023; Kim, Juho/A-7091-2016
OI Kim, Dae Hyun/0000-0002-8657-9986; Kim, Juho/0000-0001-6348-4127; Choi,
   Seulgi/0000-0002-9334-0471; Setlur, Vidya/0000-0003-3722-406X; Agrawala,
   Maneesh/0000-0002-8996-7327
FU Brown Institute for Media Innovation
FX No Statement Available
CR [Anonymous], 2023, The New York Times
   [Anonymous], 2023, Vox Media
   [Anonymous], 2023, ABOUT US
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P661, DOI 10.1109/TVCG.2018.2865119
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Beck F, 2017, IEEE T VIS COMPUT GR, V23, P1576, DOI 10.1109/TVCG.2017.2674958
   Biderman A. D., 1979, Information Design Journal, V4, P232, DOI [10.1075/idj.1.4.03bid2, DOI 10.1075/IDJ.1.4.03BID2]
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Carberry S., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P581, DOI 10.1145/1148170.1148270
   Chang AX, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3735
   Chen CR, 2019, Arxiv, DOI [arXiv:1906.02850, 10.48550/arXiv.1906.02850]
   Chen C, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P482, DOI 10.1145/3341162.3345601
   Chen D., 2014, P 2014 C EMP METH NA, P740, DOI DOI 10.3115/V1/D14-1082
   Chen Z., 2022, PROC CHI ACM, V95, DOI [10.1145/3491102.35174852, DOI 10.1145/3491102.35174852]
   CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P289, DOI 10.2307/2288843
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Demiralp Cagatay, 2017, arXiv
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Douglas D. H., 1973, Can. Cartogr., V10, P112, DOI [10.3138/FM57-6770-U75U-7727, DOI 10.3138/FM57-6770-U75U-7727]
   Earnest L., The First Three Spelling Checkers
   Elzer S, 2011, ARTIF INTELL, V175, P526, DOI 10.1016/j.artint.2010.10.003
   Elzer Stephanie, 2007, P 43 ANN M ASS COMP, P223
   Fasciano M., 1996, 8 INT NAT LANG GEN W, P2
   Finkel Jenny Rose, 2005, P ACL
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Goffin P., 2015, C INF VIS INFOVIS, P2
   Google, Use Smart Compose
   Google, Check Your Spelling & Grammar in Google Docs
   Google, Fix Spelling & Grammar as You Type in Gmail
   Gould J. D., 1976, Eye Movements and Psychological Processes, P2
   Grammarly, 2023, US
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   International Monetary Fund, 2023, ABOUT US
   Jugel U, 2014, PROC VLDB ENDOW, V7, P797, DOI 10.14778/2732951.2732953
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Khan A, 2015, INT J HUM-COMPUT ST, V83, P94, DOI 10.1016/j.ijhcs.2015.07.001
   Kim D. H., 2021, P 2021 CHI C HUM FAC, V610, DOI [10.1145/3411764.34454431,2,3,7,9, DOI 10.1145/3411764.34454431,2,3,7,9]
   Kim DH, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P423, DOI 10.1145/3242587.3242617
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   LanguageTool, 2023, About us
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   Latif Shahid, 2018, PROC EUROVIS, P91, DOI [DOI 10.2312/EUROVISSHORT.20181084, 10.5555/3290776.3290796, DOI 10.5555/3290776.3290796]
   LibreOffice, 2023, Checking Spelling and Grammar
   Lin AY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P873, DOI 10.1145/3178876.3186135
   Lundgard A, 2022, IEEE T VIS COMPUT GR, V28, P1073, DOI 10.1109/TVCG.2021.3114770
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Merriam-Webster, 2023, About Us
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Microsoft, 2023, Editor Settings in Outlook.com and Outlook on the Web
   Mitkov R., 2014, Anaphora Resolution, DOI [10.4324/97813158400869, DOI 10.4324/97813158400869]
   Obeid J., 2020, P 13 INT C NAT LANG, P2
   Ottley A., 2012, Technical Report 2012-02, P2
   Ottley A., 2019, P IEEE EUR S VIS, P121
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Pew Research Center, 2023, About us
   Pinheiro Joao, 2022, arXiv
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Qian X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2792, DOI 10.1145/3442381.3449923
   Ramer U., 1972, Computer Graphics and Image Processing, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]
   Rong KX, 2017, PROC VLDB ENDOW, V10, P1358, DOI 10.14778/3137628.3137645
   Rosen P, 2021, IEEE T VIS COMPUT GR, V27, P1536, DOI 10.1109/TVCG.2020.3030421
   Springer Nature, 2023, About us
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Subbiah M., 2020, P 34 INT C NEUR INF, V159, DOI [10. 48550/arXiv.2005.14165 9, DOI 10.48550/ARXIV.2005.141659]
   Sweller J., 2011, Cognitive load theory, P111, DOI [DOI 10.1007/978-1-4419-8126-4_9, 10.1007/978-1-4419-8126-4_92]
   Tableau Public, 2023, About us
   Tableau Software, 2023, About us
   The British Broadcasting Corporation (BBC), 2023, About us
   Tufte E. R., 2001, The visual display of quantitative information, P2
   U.S. Department of the Treasury, 2023, About us
   unibo, About us
   Whitacre MP, 2016, INT J SCI MATH EDUC, V14, P1387, DOI 10.1007/s10763-015-9677-7
   Wikimedia Commons, 2023, about us
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   WolframAlpha, 2023, About us
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Zhu HZ, 2022, Arxiv, DOI [arXiv:2205.01263, 10.48550/arXiv.2205.01263, DOI 10.48550/ARXIV.2205.01263]
NR 81
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 120
EP 130
DI 10.1109/TVCG.2023.3327150
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500032
PM 37922182
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Kruchten, N
   Mcnutt, AM
   Mcguffin, MJ
AF Kruchten, Nicolas
   Mcnutt, Andrew M.
   Mcguffin, Michael J.
TI Metrics-Based Evaluation and Comparison of Visualization Notations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Usability; Data visualization; Visualization; Libraries;
   Task analysis; Grammar; Notation; Evaluation; Language design; API
   design; Domain-specific languages
ID API USABILITY; GRAMMAR
AB A visualization notation is a recurring pattern of symbols used to author specifications of visualizations, from data transformation to visual mapping. Programmatic notations use symbols defined by grammars or domain-specific languages (e.g. ggplot2, dplyr, Vega-Lite) or libraries (e.g. Matplotlib, Pandas). Designers and prospective users of grammars and libraries often evaluate visualization notations by inspecting galleries of examples. While such collections demonstrate usage and expressiveness, their construction and evaluation are usually ad hoc, making comparisons of different notations difficult. More rarely, experts analyze notations via usability heuristics, such as the Cognitive Dimensions of Notations framework. These analyses, akin to structured close readings of text, can reveal design deficiencies, but place a burden on the expert to simultaneously consider many facets of often complex systems. To alleviate these issues, we introduce a metrics-based approach to usability evaluation and comparison of notations in which metrics are computed for a gallery of examples across a suite of notations. While applicable to any visualization domain, we explore the utility of our approach via a case study considering statistical graphics that explores 40 visualizations across 9 widely used notations. We facilitate the computation of appropriate metrics and analysis via a new tool called NotaScope. We gathered feedback via interviews with authors or maintainers of prominent charting libraries (n = 6). We find that this approach is a promising way to formalize, externalize, and extend evaluations and comparisons of visualization notations.
C1 [Kruchten, Nicolas; Mcguffin, Michael J.] Ecole Technol Super, Montreal, PQ, Canada.
   [Mcnutt, Andrew M.] Univ Chicago, Chicago, IL USA.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   University of Chicago
RP Kruchten, N (corresponding author), Ecole Technol Super, Montreal, PQ, Canada.
EM nicolas@kruchten.com; mcnutt@uchicago.edu; michael.mcguffin@etsmtl.ca
OI McNutt, Andrew/0000-0001-8255-4258
FU NSERC
FX No Statement Available
CR Albuquerque D, 2015, J SYST SOFTWARE, V101, P245, DOI 10.1016/j.jss.2014.11.051
   AntV, 2022, Antv-spec
   Bares A, 2020, IEEE COMPUT GRAPH, V40, P84, DOI 10.1109/MCG.2020.2993889
   Bokeh, 2023, Bokeh
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Brandt J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1589
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Clarke S., 2004, Dr. Dobb's, P2
   de la Mora FL, 2018, 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING TECHNOLOGIES RESULTS (ICSE-NIER), P37, DOI 10.1145/3183399.3183418
   Devanbu P, 2016, PROC INT CONF SOFTW, P108, DOI 10.1145/2884781.2884812
   Dolan S., jq.
   Fenton N., 2014, Software Metrics: A Rigorous and Practical Approach
   Flynn C., PyPI stats: matplotlib
   Frick V, 2018, PROC IEEE INT CONF S, P264, DOI 10.1109/ICSME.2018.00036
   Green T. R. G., 1989, People and Computers V. Proceedings of the Fifth Conference of the British Computer Society Human-Computer Interaction Specialist Group, P443
   Hopper T., 2020, Python plotting for exploratory data analysis
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   IVERSON KE, 1980, COMMUN ACM, V23, P444, DOI 10.1145/358896.358899
   Kim H, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517455
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P129, DOI 10.1109/TVCG.2021.3114782
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Klint P, 2005, ACM T SOFTW ENG METH, V14, P331, DOI 10.1145/1072997.1073000
   Kusner MJ, 2017, PR MACH LEARN RES, V70
   Lee B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580754
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   McKinney W., 2010, P 9 PYTH SCI C, P56, DOI [DOI 10.25080/MAJORA-92BF1922-00A, 10.25080/Majora-92bf1922-00a]
   McNutt A, 2021, COMPUT GRAPH FORUM, V40, P61, DOI 10.1111/cgf.14289
   McNutt A., 2021, ACM CHI, P1
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   McNutt A, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P1, DOI 10.1109/VIS4DH51463.2020.00005
   McNutt Andrew M, 2023, IEEE Trans Vis Comput Graph, V29, P160, DOI 10.1109/TVCG.2022.3209460
   MEAD A, 1992, STATISTICIAN, V41, P27, DOI 10.2307/2348634
   Mooney P., 2022, Kaggle survey 2022: Data scientists in the USA
   Moretti F., 2013, Distant reading, P2
   Muller K., styler: Non-invasive pretty printing of R code
   Muth L., 2016, One chart, twelve charting libraries
   Pandas team, Chart visualization-pandas 1.5.3 documentation
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pezoa F, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P263, DOI 10.1145/2872427.2883029
   Plotly, Low-code data apps
   Pu X., 2021, ACM CHI EA, P1, DOI DOI 10.1145/3411763.34504061,9
   Pu XY, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580837
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   Python Software Foundation, Black python code formatter
   Rakotondravony Noelle, 2023, IEEE Trans Vis Comput Graph, V29, P1189, DOI 10.1109/TVCG.2022.3209367
   Rauf I, 2019, COMPUT SCI REV, V33, P49, DOI 10.1016/j.cosrev.2019.05.001
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Rocklin M., 2022, How popular is Matplotlib?
   Russell D. M., 2016, PROC ACM AVI, P7, DOI [DOI 10.1145/2909132.29332878, DOI 10.1145/2909132.29332876]
   Saber D., 2016, A dramatic tour through Python's data visualization landscape (including ggplot and Altair)
   Sarma A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580726
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Scheller T, 2015, INFORM SOFTWARE TECH, V61, P145, DOI 10.1016/j.infsof.2015.01.009
   Schetinger V, 2023, COMPUT GRAPH FORUM, V42, P423, DOI 10.1111/cgf.14841
   Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159
   Shull F., 2008, GUIDE ADV EMPIRICAL, DOI DOI 10.1007/978-1-84800-044-5
   Terrastruct, 2023, Text to diagram: Community list of comparisons between text to diagram tools
   Texel PP, 2015, IEEE SOUTHEASTCON
   Tidyverse team, Tidyverse design guide
   TPC, 2007, TPC-E
   Treesitter, An incremental parsing system for programming tools
   VanderPlas J., 2018, J OPEN SOURCE SOFTW, V3, P1057, DOI [DOI 10.21105/JOSS.01057, 10.21105/joss.01057]
   Vargas EL, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P245, DOI 10.1145/3368089.3409711
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Vega, 2023, Vega datasets
   Vega-Lite team, Contributing to Vega-Lite
   Vickers P, 2013, IEEE T VIS COMPUT GR, V19, P1048, DOI 10.1109/TVCG.2012.294
   Wang AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502123
   Waskom ML., 2021, J OPEN SOURCE SOFTW, V6, P3021, DOI DOI 10.21105/JOSS.03021
   Wickham H., 2019, J Open Source Softw, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/JOSS.01686]
   Wickham H., 2023, Dplyr: A grammar of data manipulation
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L., 2005, Statistics and Computing, DOI DOI 10.1007/0-387-28695-03,7,12
   Wongsuphasawat K., 2020, Navigating the wide world of data visualization libraries
   Wongsuphasawat K, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P131, DOI 10.1109/VIS47514.2020.00033
   Wood J., 2018, Comment on arc mark / pie chart
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Wu AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517618
   Xie Y., formatR: Format R code automatically
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Yang S, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P4846, DOI 10.1145/3534678.3542621
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
   Zuk Torre, 2006, P WORKSH TIM ERR NOV, P1, DOI DOI 10.1145/1168149.1168162
NR 94
TC 0
Z9 0
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 425
EP 435
DI 10.1109/TVCG.2023.3326907
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500095
PM 37874719
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Schmidt, J
   Pointner, B
   Miksch, S
AF Schmidt, Johanna
   Pointner, Bernhard
   Miksch, Silvia
TI Visual Analytics for Understanding Draco's Knowledge Base
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Aggregates; Task analysis; Recommender systems;
   Costs; Bars; Visual analytics; Visual Analytics; Hypergraph
   visualization; Rule-based recommendation systems
ID OF-THE-ART; VISUALIZATION; DESIGN; COMMUNITIES
AB Draco has been developed as an automated visualization recommendation system formalizing design knowledge as logical constraints in ASP (Answer-Set Programming). With an increasing set of constraints and incorporated design knowledge, even visualization experts lose overview in Draco and struggle to retrace the automated recommendation decisions made by the system. Our paper proposes an Visual Analytics (VA) approach to visualize and analyze Draco's constraints. Our VA approach is supposed to enable visualization experts to accomplish identified tasks regarding the knowledge base and support them in better understanding Draco. We extend the existing data extraction strategy of Draco with a data processing architecture capable of extracting features of interest from the knowledge base. A revised version of the ASP grammar provides the basis for this data processing strategy. The resulting incorporated and shared features of the constraints are then visualized using a hypergraph structure inside the radial-arranged constraints of the elaborated visualization. The hierarchical categories of the constraints are indicated by arcs surrounding the constraints. Our approach is supposed to enable visualization experts to interactively explore the design rules' violations based on highlighting respective constraints or recommendations. A qualitative and quantitative evaluation of the prototype confirms the prototype's effectiveness and value in acquiring insights into Draco's recommendation process and design constraints.
C1 [Schmidt, Johanna; Pointner, Bernhard] VRVis Zentrum Virtual Real & Visualisierung Forsc, Vienna, Austria.
   [Miksch, Silvia] TU Wien, Ctr Visual Analyt Sci & Technol CVAST, Vienna, Austria.
C3 Technische Universitat Wien
RP Schmidt, J (corresponding author), VRVis Zentrum Virtual Real & Visualisierung Forsc, Vienna, Austria.
EM johanna.schmidt@vrvis.at; pointner@vrvis.at; silvia.miksch@tuwien.ac.at
OI Schmidt, Johanna/0000-0002-9638-6344; Miksch, Silvia/0000-0003-4427-5703
FU BMK
FX No Statement Available
CR Alborzi F, 2017, Arxiv, DOI [arXiv:1703.09218, 10.48550/arXiv.1703.09218, DOI 10.48550/ARXIV.1703.09218]
   Alsallakh B., 2014, EuroVis (STARs), DOI DOI 10.2312/EUROVISSTAR.20141170
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Burch M, 2008, COMPUT GRAPH FORUM, V27, P823, DOI 10.1111/j.1467-8659.2008.01213.x
   Burch Michael, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P603
   Cameron M., 2003, P 5 ACM SIGPLAN INT, P56, DOI [10.1145/888251.888258, DOI 10.1145/888251.888258]
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   Chaturvedi S, 2014, COMPUT GRAPH FORUM, V33, P52, DOI 10.1111/cgf.12400
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Ehsan H, 2016, PROC INT CONF DATA, P731, DOI 10.1109/ICDE.2016.7498285
   Febbraro O., 2011, Logic Programming and Nonmonotonic Reasoning, P2
   Gebser M., 2012, Synthesis Lectures on Artificial Intelligence and Machine Learning, V6, P1, DOI [10.2200/S00457ED1V01Y201211AIM019, DOI 10.2200/S00457ED1V01Y201211AIM019]
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI DOI 10.1145/1502650.1502695
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hopfner M, 2003, PROG COMPREHEN, P290
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Humayoun S. R., 2016, P INT WORKING C ADV, P314, DOI [10.1145/2909132.29260725, DOI 10.1145/2909132.29260725]
   Kaur P, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P266, DOI 10.5220/0006175002660273
   Kubernatova P., 2019, Data Management Technologies and Applications, P2
   Lewis C, 1982, Method in Cognitive Interface Design
   Lhuillier A, 2017, COMPUT GRAPH FORUM, V36, P619, DOI 10.1111/cgf.13213
   Lifschitz V., 2019, Answer Set Programming, V1st, P3
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Mueller C, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P141
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nielsen F., 2016, Introduction to HPC with MPI for Data Science, DOI DOI 10.1007/978-3-319-21903-5_8
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Pointner B., 2022, An Interactive Visualization Approach to Tackle Design Constraints in a Rule-Based Recommendation System, DOI [10.34726/hss.2022.870631, DOI 10.34726/HSS.2022.870631]
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Saket, 2018, ABS180706641 CORR
   Santos J. M., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P24, DOI 10.1109/IV.2012.15
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Schulz HJ, 2006, INFORMATION VISUALIZATION-BOOK, P166
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulzrinne Henning, 2013, Proceedings of the 2013 12th International Conference on Telecommunications (ConTEL 2013), P3
   Seo J., 2005, Information Visualization, V4, P96, DOI 10.1057/palgrave.ivs.9500091
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sinha R., 2002, CHI'02 Extended Abstracts on Human Factors in Computing Systems, P830, DOI [DOI 10.1145/506443.506619, 10.1145/506443.506619]
   Stasko J, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P57, DOI 10.1109/INFVIS.2000.885091
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   Vehlow C, 2015, COMPUT GRAPH FORUM, V34, P277, DOI 10.1111/cgf.12512
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Viegas F., 2017, US Patent, Patent No. 201662401647
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang W., 2006, P SIGCHI C HUM FACT, P517
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Woodburn L, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P96, DOI [10.1109/VISUAL.2019.8933545, 10.1109/visual.2019.8933545]
   Zhou H, 2015, J VISUAL-JAPAN, V18, P159, DOI 10.1007/s12650-014-0271-9
   Zhou M., 1998, Second International Conference on Cooperative Multimodal Communication (CMC 1998), P43, DOI [10.1007/3-540-45520-5/_42, DOI 10.1007/3-540-45520-5/_42]
NR 53
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 392
EP 402
DI 10.1109/TVCG.2023.3326912
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500050
PM 37874727
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Shi, Y
   Chen, BC
   Chen, Y
   Jin, ZC
   Xu, K
   Jiao, XH
   Gao, T
   Cao, N
AF Shi, Yang
   Chen, Bingchang
   Chen, Ying
   Jin, Zhuochen
   Xu, Ke
   Jiao, Xiaohan
   Gao, Tian
   Cao, Nan
TI Supporting Guided Exploratory Visual Analysis on Time Series Data with
   Reinforcement Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time Series Data; Exploratory Visual Analysis; Reinforcement Learning
ID VISUALIZATION; GENERATION; GUIDANCE
AB The exploratory visual analysis (EVA) of time series data uses visualization as the main output medium and input interface for exploring new data. However, for users who lack visual analysis expertise, interpreting and manipulating EVA can be challenging. Thus, providing guidance on EVA is necessary and two relevant questions need to be answered. First, how to recommend interesting insights to provide a first glance at data and help develop an exploration goal. Second, how to provide step-by-step EVA suggestions to help identify which parts of the data to explore. In this work, we present a reinforcement learning (RL)-based system, Visail, which generates EVA sequences to guide the exploration of time series data. As a user uploads a time series dataset, Visail can generate step-by-step EVA suggestions, while each step is visualized as an annotated chart combined with textual descriptions. The RL-based algorithm uses exploratory data analysis knowledge to construct the state and action spaces for the agent to imitate human analysis behaviors in data exploration tasks. In this way, the agent learns the strategy of generating coherent EVA sequences through a well-designed network. To evaluate the effectiveness of our system, we conducted an ablation study, a user study, and two case studies. The results of our evaluation suggested that Visail can provide effective guidance on supporting EVA on time series data.
C1 [Shi, Yang; Chen, Bingchang; Chen, Ying; Jiao, Xiaohan; Gao, Tian; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
   [Shi, Yang; Chen, Bingchang; Chen, Ying; Jiao, Xiaohan; Gao, Tian; Cao, Nan] Huawei Cloud Comp Technol Co Ltd, Shenzhen, Peoples R China.
C3 Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.; Cao, N (corresponding author), Huawei Cloud Comp Technol Co Ltd, Shenzhen, Peoples R China.
EM yangshi.idvx@tongji.edu.cn; 2131933@tongji.edu.cn;
   2131926@tongji.edu.cn; chjzcjames@gmail.com; lukexuke@gmail.com;
   xh_xiaohan@tongji.edu.cn; gaotian@tongji.edu.cn; nan.cao@tongji.edu.cn
OI Cao, Nan/0000-0003-1316-7515
FU NSFC
FX No Statement Available
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Assaker J., 2022, Covid-19 global dataset
   Bar El O, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1527, DOI 10.1145/3318464.3389779
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Behrisch M, 2014, IEEE CONF VIS ANAL, P43, DOI 10.1109/VAST.2014.7042480
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chatfield Ch., 2003, ANAL TIME SERIES INT, DOI DOI 10.4324/9780203491683
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen Y, 2009, IEEE PAC VIS SYMP, P49, DOI 10.1109/PACIFICVIS.2009.4906837
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Deng Dazhen, 2023, IEEE Trans Vis Comput Graph, V29, P690, DOI 10.1109/TVCG.2022.3209468
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Ehrenberg A. S. C., 1979, Applied Statistics, V28, P79, DOI [10.2307/23468181, DOI 10.2307/23468181]
   Franceschi JY, 2019, ADV NEUR IN, V32
   FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051
   Fujiwara T, 2021, IEEE T VIS COMPUT GR, V27, P1601, DOI 10.1109/TVCG.2020.3028889
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Gotz D, 2009, P 14 INT C INT US IN, P315, DOI DOI 10.1145/1502650.1502695
   Guo TZ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P751
   Hao M., 2011, SPIE, V7868, P194, DOI [10.1117/12.8721696, DOI 10.1117/12.8721696]
   Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159, DOI [DOI 10.1145/302979.303030, 10.1145/302979.303030]
   Huang S., 2022, INT FLAIRS C P, V35, DOI [10.32473/flairs.v35i.1305846, DOI 10.32473/FLAIRS.V35I.1305846]
   Key Alicia, 2012, P 2012 ACM SIGMOD IN, P681, DOI [10.1145/2213836.2213931, DOI 10.1145/2213836.2213931]
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Law P.-M., 2020, 2020 IEEE VIS C VIS, DOI [10.1109/vis47514.2020.000432, DOI 10.1109/VIS47514.2020.000432]
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Law PM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300409
   Law PM, 2019, IEEE T VIS COMPUT GR, V25, P427, DOI 10.1109/TVCG.2018.2864526
   Lee DJL, 2022, IEEE T VIS COMPUT GR, V28, P4225, DOI 10.1109/TVCG.2021.3085751
   Li WC, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581452
   Lu JH, 2020, IEEE COMPUT GRAPH, V40, P18, DOI 10.1109/MCG.2020.2968249
   Lv C, 2022, J VISUAL-JAPAN, V25, P575, DOI 10.1007/s12650-021-00807-6
   Ma PC, 2021, INT CONF MANAGE DATA, P1262, DOI 10.1145/3448016.3457267
   Moshagen M, 2010, INT J HUM-COMPUT ST, V68, P689, DOI 10.1016/j.ijhcs.2010.05.006
   Ola O., 2014, Online Journal of Public Health Informatics, V5, DOI DOI 10.5210/OJPHI.V5I3.4933
   Personnaz Aurelien, 2021, aiDM '21: Fourth Workshop in Exploiting AI Techniques for Data Management, P16, DOI 10.1145/3464509.3464884
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riedl MO, 2010, J ARTIF INTELL RES, V39, P217, DOI 10.1613/jair.2989
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi DQ, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P58, DOI [10.1109/VDS48975.2019.8973383, 10.1109/vds48975.2019.8973383]
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P972, DOI 10.1109/TVCG.2022.3209409
   Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337
   Shumway RH, 2017, Time series analysis and its applications, DOI DOI 10.1007/978-3-319-52452-8
   Sips M, 2012, IEEE T VIS COMPUT GR, V18, P2899, DOI 10.1109/TVCG.2012.191
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Tang H, 2019, J VISUAL-JAPAN, V22, P1005, DOI 10.1007/s12650-019-00586-1
   TUDelft, 2020, Gwa-t-12 bitbrains
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Vollmer M., 2020, PHYSIONET, DOI [10.13026/CHD5-T9468, DOI 10.13026/CHD5-T9468]
   Pham V, 2020, 2020 IEEE VISUALIZATION IN DATA SCIENCE (VDS 2020), P42, DOI 10.1109/VDS51726.2020.00009
   Walker J, 2016, IEEE T VIS COMPUT GR, V22, P549, DOI 10.1109/TVCG.2015.2467751
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wongsuphasawat Krist, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P27, DOI 10.1109/VAST.2009.5332595
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Xiao S., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.48550/ARXIV.2304.146309, DOI 10.48550/ARXIV.2304.146309]
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Yu L, 2010, COMPUT GRAPH FORUM, V29, P2271, DOI 10.1111/j.1467-8659.2010.01816.x
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhao J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1737
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
NR 77
TC 0
Z9 0
U1 5
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1172
EP 1182
DI 10.1109/TVCG.2023.3327200
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500132
PM 37883260
DA 2024-08-05
ER

PT J
AU Xiao, SS
   Huang, SZ
   Lin, Y
   Ye, YL
   Zeng, W
AF Xiao, Shishi
   Huang, Suizi
   Lin, Yue
   Ye, Yilin
   Zeng, Wei
TI Let the Chart Spark: Embedding Semantic Context into Chart with
   Text-to-Image Generative Model
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE pictorial visualization; generative model; authoring tool
ID VISUALIZATION; DESIGN
AB Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative models. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the design practices identified from empirical research into existing pictorial visualizations. We further develop an interactive visual interface that integrates a text analyzer, editing module, and evaluation module to enable users to generate, modify, and assess pictorial visualizations. We experimentally demonstrate the usability of our tool, and conclude with a discussion of the potential of using text-to-image generative models combined with an interactive interface for visualization design.
C1 [Xiao, Shishi; Huang, Suizi; Lin, Yue; Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol Guangzhou, Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
   [Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
EM sxiao713@connect.hkust-gz.edu.cn; shuang310@connect.hkust-gz.edu.cn;
   ylin491@connect.hkust-gz.edu.cn; yyebd@connect.hkust-gz.edu.cn;
   weizeng@hkust-gz.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Brooks T, 2023, PROC CVPR IEEE, P18392, DOI 10.1109/CVPR52729.2023.01764
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Byrne L, 2019, INFORM VISUAL, V18, P45, DOI 10.1177/1473871617724212
   Chefer H, 2023, Arxiv, DOI arXiv:2301.13826
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Coelho D, 2020, COMPUT GRAPH FORUM, V39, P593, DOI 10.1111/cgf.14004
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Dhariwal P, 2021, ADV NEUR IN, V34
   Ermon S, 2022, Denoising diffusion implicit models, V2, P4
   Few S., 2011, Visual Business Intelligence Newsletter, P6
   Frans Kevin., 2022, ADV NEURAL INFORM PR, V35, P5207
   Gal R., 2023, P ICML
   Gal R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530164
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Hartmann F., 2017, European Modernism and the Information Society, P2
   Hertz A., 2023, P ICML
   Ho J., 2020, Adv. Neural. Inf. Process. Syst, V33, P6840, DOI DOI 10.48550/ARXIV.2006.11239
   Holmes N., 2022, Joyful Infographics: A Friendly, Human Approach to Data, P2
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Iluz S, 2023, Arxiv, DOI [arXiv:2303.01818, 10.1145/3592123, DOI 10.1145/3592123]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Li HT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502048
   Li YH, 2023, PROC CVPR IEEE, P22511, DOI 10.1109/CVPR52729.2023.02156
   Lu M., 2020, P ACM CHI, P1
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Moere AV, 2011, INFORM VISUAL, V10, P356, DOI 10.1177/1473871611415996
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Qin XB, 2022, LECT NOTES COMPUT SC, V13678, P38, DOI 10.1007/978-3-031-19797-0_3
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, Hierarchical text-conditional image generation with clip latents, DOI 10.48550/arXiv.2204.06125
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Rashid MM, 2022, LECT NOTES ARTIF INT, V13281, P3, DOI 10.1007/978-3-031-05936-0_1
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ruiz N, 2023, Arxiv, DOI arXiv:2208.12242
   Saharia C., 2022, ADV NEURAL INF PROCE, V35, P36479
   Schetinger V, 2023, COMPUT GRAPH FORUM, V42, P423, DOI 10.1111/cgf.14841
   Schramowski P, 2023, PROC CVPR IEEE, P22522, DOI 10.1109/CVPR52729.2023.02157
   Shi Y., 2022, IEEE Trans. Vis. Comput. Graph., V29, P236, DOI [10.1109/TVCG.2022.32094861,2,3, DOI 10.1109/TVCG.2022.32094861,2,3]
   Song K., 2020, 33 ADV NEUR INF PROC, V33, P16857, DOI DOI 10.48550/ARXIV.2004.09297
   Tufte E. R., 2001, The Visual Display of Quantitative Information, Vsecond, P6
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wu JQ, 2023, Arxiv, DOI arXiv:2304.01919
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Xiao SS, 2023, COMPUT GRAPH FORUM, V42, P311, DOI 10.1111/cgf.14832
   Ying Lu, 2023, IEEE Trans Vis Comput Graph, V29, P331, DOI 10.1109/TVCG.2022.3209447
   Yu JH, 2022, Arxiv, DOI [arXiv:2206.10789, 10.48550/arXiv.2206.10789]
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhang L, 2023, Arxiv, DOI [arXiv:2302.05543, 10.48550/ARXIV.2302.05543]
NR 61
TC 2
Z9 2
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 284
EP 294
DI 10.1109/TVCG.2023.3326913
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500011
PM 37878451
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Raveendranath, B
   Sarno, DM
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Rohith
   Venkatakrishnan, Roshan
   Raveendranath, Balagopal
   Sarno, Dawn M.
   Robb, Andrew C.
   Lin, Wen-Chieh
   Babu, Sabarish V.
TI The Effects of Auditory, Visual, and Cognitive Distractions on
   Cybersickness in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Active exploration; cybersickness; distractions; electrodermal activity;
   information recall; pain reduction; spatial memory; virtual motion;
   virtual reality
ID MOTION SICKNESS; EXPOSURE; EFFICACY; DRIVERS; MUSIC; AGE
AB Cybersickness (CS) is one of the challenges that has hindered the widespread adoption of Virtual Reality (VR). Consequently, researchers continue to explore novel means to mitigate the undesirable effects associated with this affliction, one that may require a combination of remedies as opposed to a solitary stratagem. Inspired by research probing into the use of distractions as a means to control pain, we investigated the efficacy of this countermeasure against CS, studying how the introduction of temporally time-gated distractions affects this malady during a virtual experience featuring active exploration. Downstream of this, we studied how other aspects of the VR experience are affected by this intervention. We discuss the results of a between-subjects study manipulating the presence, sensory modality, and nature of periodic and short-lived (5-12 seconds) distractor stimuli across four experimental conditions: 1) no-distractors (ND); 2) auditory distractors (AD); 3) visual distractors (VD); 4) cognitive distractors (CD). Two of these conditions (VD and AD) formed a yoked control design wherein every matched pair of 'seers' and 'hearers' was periodically exposed to distractors that were identical in terms of content, temporality, duration, and sequence. In the CD condition, each participant had to periodically perform a 2-back working memory task, the duration and temporality of which was matched to distractors presented in each matched pair of the yoked conditions. These three conditions were compared to a baseline control group featuring no distractions. Results indicated that the reported sickness levels were lower in all three distraction groups in comparison to the control group. The intervention also increased the amount of time users were able to endure the VR simulation and avoided causing detriments to spatial memory and virtual travel efficiency. Overall, it appears that it may be possible to make users less consciously aware and bothered by the symptoms of CS, thereby reducing its perceived severity.
C1 [Venkatakrishnan, Rohith; Venkatakrishnan, Roshan; Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
   [Raveendranath, Balagopal; Sarno, Dawn M.] Clemson Univ, Dept Psychol, Clemson, SC 29634 USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 Clemson University; Clemson University; National Yang Ming Chiao Tung
   University
RP Venkatakrishnan, R (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM rohithv@g.clemson.edu; rvenkat@g.clemson.edu; braveen@g.clemson.edu;
   dmsarno@g.clemson.edu; arobb@clemson.edu; wclin@cs.nctu.edu.tw;
   sbabu@clemson.edu
RI Venkatakrishnan, Rohith/JCE-8736-2023; Venkatakrishnan,
   Roshan/JDC-3508-2023
OI Venkatakrishnan, Rohith/0000-0002-8484-3915; Venkatakrishnan,
   Roshan/0000-0002-6538-627X; Babu, Sabarish/0000-0002-8348-0534; Sarno,
   Dawn/0000-0001-5605-5957; Robb, Andrew/0000-0002-0398-5576
FU US National Science Foundation [2007435]; Taiwan's National Science and
   Technology Council [109-2221-E-009-123-MY3]
FX This work was supported in part by the US National Science Foundation
   (CISE IIS HCC) under Grant 2007435 and in part by Taiwan's National
   Science and Technology Council under Grant 109-2221-E-009-123-MY3.
CR Açikel BY, 2018, SIMULAT GAMING, V49, P27, DOI 10.1177/1046878117750417
   Adhanom I, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.848001
   Ang S, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P428, DOI 10.1109/VR51125.2022.00062
   [Anonymous], 1973, Attention and effort
   Barhorst-Cates EM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163785
   Bolas M., 2017, US Patent, Patent No. [9,645,395, 9645395]
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Braithwaite JJ., 2013, Psychophysiology, V49, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Budhiraja P, 2017, Arxiv, DOI arXiv:1710.02599
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Carnegie Kieran., 2015, Mitigating visual discomfort on head mounted displays using estimated gaze dependent depth of field
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Cheung B, 2005, AVIAT SPACE ENVIR MD, V76, P1099
   Chu H, 2012, J ALTERN COMPLEM MED, V18, P494, DOI 10.1089/acm.2011.0366
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Critchley HD, 2002, NEUROSCIENTIST, V8, P132, DOI 10.1177/107385840200800209
   D'Amour S, 2017, EXP BRAIN RES, V235, P2811, DOI 10.1007/s00221-017-5009-1
   Davis S., 2014, P C INT ENT, P1
   Davis S., 2015, P 11 AUSTR C INT ENT, P3
   Dawson ME., 2017, The electrodermal system
   de Siqueira AG, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P606, DOI 10.1109/VR50410.2021.00086
   DiZio P, 1997, ADV HUM FACT ERGON, V21, P893
   Estrada A, 2007, AVIAT SPACE ENVIR MD, V78, P408
   Farmani Y., 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI201 8.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   FERNANDEZ E, 1989, PAIN, V38, P123, DOI 10.1016/0304-3959(89)90230-3
   Fisher DL, 2006, INJURY PREV, V12, P25, DOI 10.1136/ip.2006.012021
   Galvez-Garcia G, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102931
   Gálvez-García G, 2017, APPL ERGON, V58, P13, DOI 10.1016/j.apergo.2016.05.004
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   GUEDRY F E Jr, 1964, Acta Otolaryngol, V58, P377, DOI 10.3109/00016486409121398
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   HART S G, 1988, P139
   Heinrichs WL, 2008, WORLD J SURG, V32, P161, DOI 10.1007/s00268-007-9354-2
   Hettinger J., 1992, Presence, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Hong Y, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281519
   Horberry T, 2006, ACCIDENT ANAL PREV, V38, P185, DOI 10.1016/j.aap.2005.09.007
   HU SQ, 1991, AVIAT SPACE ENVIR MD, V62, P308
   Huang YH, 2021, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2021), DOI 10.1145/3474451.3476236
   Ihemedu-Steinke QC, 2017, LECT NOTES COMPUT SC, V10280, P521, DOI 10.1007/978-3-319-57987-0_42
   James Craig., 2017, The effects of post-processing techniques on simulator sickness in virtual reality
   Johnson Malcolm H, 2005, Curr Pain Headache Rep, V9, P90, DOI 10.1007/s11916-005-0044-1
   JungHa Park, 2020, The International Journal of Advanced Culture Technology, V8, P89
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Keshavarz B., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications, P648
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2015, EXP BRAIN RES, V233, P1353, DOI 10.1007/s00221-015-4209-9
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kolasinski E.M., 1995, Simulator sickness in virtual environments., V1027
   Kooijman L.., 2022, IEEE INT C SYST MAN, P1057, DOI [10.1109/SMCS3654.2022.9945475, DOI 10.1109/SMCS3654.2022.9945475, 10.1109/SMC53654.2022.9945475, DOI 10.1109/SMC53654.2022.9945475]
   Kwok KKK, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P91, DOI 10.1109/ISMAR-Adjunct.2018.00041
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee JohnD., 2008, DRIVER DISTRACTION T, P31, DOI DOI 10.1201/9781420007497.CH3
   Legrain V, 2009, PAIN, V144, P230, DOI 10.1016/j.pain.2009.03.020
   Lien HC, 2003, AM J PHYSIOL-GASTR L, V284, pG481, DOI 10.1152/ajpgi.00164.2002
   Lim K, 2021, VIRTUAL REAL-LONDON, V25, P331, DOI 10.1007/s10055-020-00457-3
   Lin YX, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419984
   Lindner K., 2009, Modern Psychol. Stud., V15, P6
   Liu HM, 2020, INT SYM MIX AUGMENT, P566, DOI 10.1109/ISMAR50242.2020.00084
   Liu SH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P817, DOI [10.1109/VR.2019.8798158, 10.1109/vr.2019.8798158]
   Loup G, 2019, INT J HUM-COMPUT INT, V35, P1270, DOI 10.1080/10447318.2018.1519164
   Malloy KM, 2010, CLIN PSYCHOL REV, V30, P1011, DOI 10.1016/j.cpr.2010.07.001
   McCarthy Cameron, 2016, 2016 IEEE EMBS International Student Conference (ISC), DOI 10.1109/EMBSISC.2016.7508621
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   McCauley M. E., 1992, Teleoperators and Virtual Environments, V1, P311, DOI [10.1162/pres.1992.1.3.311, DOI 10.1162/PRES.1992.1.3.311]
   Meusel C. R., 2014, Exploring mental effort and nausea via electrodermal activity within scenario-based tasks
   MILLER JC, 1993, AVIAT SPACE ENVIR MD, V64, P813
   Milleville-Pennel I, 2015, ACCIDENT ANAL PREV, V74, P192, DOI 10.1016/j.aap.2014.10.021
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   MONEY KE, 1970, PHYSIOL REV, V50, P1, DOI 10.1152/physrev.1970.50.1.1
   Monk AF, 2011, BEHAV RES METHODS, V43, P888, DOI 10.3758/s13428-011-0074-z
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Nelson W. T., 2000, P HUM FACT ERG SOC A
   Ng AKT, 2020, DISPLAYS, V61, DOI 10.1016/j.displa.2019.08.004
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Norouzi N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225162
   Osborne J.W., 2000, Practical Assessment, Research, Evaluation, V7, DOI DOI 10.7275/PMGN-ZX89
   Palmisano S, 2022, VIRTUAL REAL-LONDON, V26, P1373, DOI 10.1007/s10055-022-00634-6
   Pouke M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P665, DOI 10.1109/VR.2018.8446078
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Qionghua W, 2019, Arxiv, DOI arXiv:1903.12617
   Ranney T. A., 2001, Citeseer, Tech. Rep. 2001-06-0177
   Reason J. T., 1975, Motion Sickness
   Rebenitsch L., 2015, XRDS: Crossroads, The ACM Magazine for Students, V22, P46
   REDD WH, 1987, J CONSULT CLIN PSYCH, V55, P391, DOI 10.1037/0022-006X.55.3.391
   Regan E. C., 1993, INT APPL MIL PSYCH S
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Richardson DC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68253-2
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Samson MM, 2001, AGING CLIN EXP RES, V13, P16, DOI 10.1007/BF03351489
   Sang FDYP, 2003, J TRAVEL MED, V10, P108, DOI 10.2310/7060.2003.31768
   Sang FDYP, 2003, AVIAT SPACE ENVIR MD, V74, P998
   Seno T, 2011, ATTEN PERCEPT PSYCHO, V73, P1467, DOI 10.3758/s13414-011-0129-3
   Sepich NC, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.943409
   Sherman CR, 2002, J TRAVEL MED, V9, P251
   Snijders TA, 2012, MULTILEVEL ANAL INTR
   Sousa TLV, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00892
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Stein M., 2012, Aviation Psychology and Applied Human Factors, V2, P11, DOI [10.1027/2192-0923/a000022, DOI 10.1027/2192-0923/A000022]
   Strayer DL, 2011, PSYCHOL LEARN MOTIV, V54, P29, DOI 10.1016/B978-0-12-385527-5.00002-4
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Trutoiu LC, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P190
   Tu F. K., 2020, PhD thesis
   VASTERLING J, 1993, J BEHAV MED, V16, P65, DOI 10.1007/BF00844755
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Venkatakrishnan R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1201, DOI [10.1109/vr.2019.8797728, 10.1109/VR.2019.8797728]
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P672, DOI [10.1109/VR46266.2020.1581256520838, 10.1109/VR46266.2020.00-14]
   Wald J, 2000, J BEHAV THER EXP PSY, V31, P249, DOI 10.1016/S0005-7916(01)00009-X
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wickens C.D., 1984, Varieties of Attention, P63
   Wickens C. D., 1980, Attention and performance VIII, V8, P239
   Wu F, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P103, DOI 10.1109/VR51125.2022.00028
   Zhou C, 2019, IEEE INT CONF MOB, P72, DOI 10.1109/MASSW.2019.00021
   Zyla-Labs, 2022, Woord
NR 121
TC 4
Z9 4
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5350
EP 5369
DI 10.1109/TVCG.2023.3293405
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400094
PM 37418399
DA 2024-08-05
ER

PT J
AU de Silva, A
   Zhao, MA
   Stewart, D
   Khan, FH
   Dusek, G
   Davis, J
   Pang, A
AF de Silva, Akila
   Zhao, Mona
   Stewart, Donald
   Khan, Fahim Hasan
   Dusek, Gregory
   Davis, James
   Pang, Alex
TI RipViz: Finding Rip Currents by Learning Pathline Behavior
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Videos; Behavioral sciences; Visualization; Optical flow; Noise
   measurement; Bathymetry; Task analysis; anomaly detection; Flow
   visualization; 2D unsteady flow fields; pathlines; LSTM autoencoders
AB We present a hybrid machine learning and flow analysis feature detection method, RipViz, to extract rip currents from stationary videos. Rip currents are dangerous strong currents that can drag beachgoers out to sea. Most people are either unaware of them or do not know what they look like. In some instances, even trained personnel such as lifeguards have difficulty identifying them. RipViz produces a simple, easy to understand visualization of rip location overlaid on the source video. With RipViz, we first obtain an unsteady 2D vector field from the stationary video using optical flow. Movement at each pixel is analyzed over time. At each seed point, sequences of short pathlines, rather a single long pathline, are traced across the frames of the video to better capture the quasi-periodic flow behavior of wave activity. Because of the motion on the beach, the surf zone, and the surrounding areas, these pathlines may still appear very cluttered and incomprehensible. Furthermore, lay audiences are not familiar with pathlines and may not know how to interpret them. To address this, we treat rip currents as a flow anomaly in an otherwise normal flow. To learn about the normal flow behavior, we train an LSTM autoencoder with pathline sequences from normal ocean, foreground, and background movements. During test time, we use the trained LSTM autoencoder to detect anomalous pathlines (i.e., those in the rip zone). The origination points of such anomalous pathlines, over the course of the video, are then presented as points within the rip zone. RipViz is fully automated and does not require user input. Feedback from domain expert suggests that RipViz has the potential for wider use.
C1 [de Silva, Akila; Zhao, Mona; Stewart, Donald; Khan, Fahim Hasan; Davis, James; Pang, Alex] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA.
   [Dusek, Gregory] NOAA, Silver Spring, MD USA.
C3 University of California System; University of California Santa Cruz;
   National Oceanic Atmospheric Admin (NOAA) - USA
RP de Silva, A; Pang, A (corresponding author), Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA.
EM audesilv@ucsc.edu; yzhao172@ucsc.edu; dolstewa@ucsc.edu;
   fkhan4@ucsc.edu; gregory.dusek@noaa.gov; davis@cs.ucsc.edu;
   pang@soe.ucsc.edu
OI Khan, Fahim Hasan/0000-0003-3130-6259; de Silva,
   Akila/0000-0002-7553-7270; Dusek, Gregory/0000-0003-0289-1356; Davis,
   James/0000-0002-1413-2616
FU Southeast Coastal Ocean Observing Regional Association (SECOORA); NOAA
   [NA20NOS0120220]
FX This report was prepared in part as a result of work sponsored by the
   Southeast Coastal Ocean Observing Regional Association (SECOORA) with
   NOAA financial assistance under Grant NA20NOS0120220.
CR Ba L.J., 2016, arXiv, DOI DOI 10.48550/ARXIV.1607.06450
   Berenjkoub M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P261, DOI 10.1109/VIS47514.2020.00059
   BOWEN AJ, 1969, J GEOPHYS RES, V74, P5467, DOI 10.1029/JC074i023p05467
   Bürger K, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P71
   Carmo BS, 2004, LECT NOTES COMPUT SC, V3216, P451
   Castelle B, 2016, EARTH-SCI REV, V163, P1, DOI 10.1016/j.earscirev.2016.09.008
   Chen J., 2019, Biodiesel Production: Technologies, Challenges, and Future Prospects, P229
   Chen N. J., 2011, Interfaces, V5, P1
   Chollet F., 2015, KERAS
   de Silva A, 2021, COAST ENG, V166, DOI 10.1016/j.coastaleng.2021.103859
   Ellis S., 2022, Shore Beach, V90, P50
   Gary A., 2000, Dr. Dobb's J. Softw. Tools, V3, P122
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Haller MC, 2014, J WATERW PORT COAST, V140, P115, DOI 10.1061/(ASCE)WW.1943-5460.0000229
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Holman R, 2013, ANNU REV MAR SCI, V5, P95, DOI 10.1146/annurev-marine-121211-172408
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P285, DOI 10.1111/cgf.13689
   Klein AHDF, 2003, J COASTAL RES, P107
   Leatherman J., 2011, Rip Currents: Beach Safety, Phys-ical Oceanography, and Wave Modeling, V1st, DOI [10.1201/b10916.21, DOI 10.1201/B10916.21]
   Leatherman S., Techniques for detecting and measur-ing rip currents
   Liu L., 2020, Int. J. Comput. Vis, V3, P1, DOI [10.35840/2631-5033/1814, DOI 10.35840/2631-5033/1814]
   Lodha SK, 2000, IEEE VISUAL, P343, DOI 10.1109/VISUAL.2000.885714
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674
   Lushine J.B., 1991, National Weather Digest, V16, P13
   Ma J, 2013, PROC SPIE, V8654, DOI 10.1117/12.2001887
   MacMahan J., 2011, J. Coastal Res., V27, P3, DOI [10.2112/JCOAS-TRES-D-11-00024.1, DOI 10.2112/JCOAS-TRES-D-11-00024.1]
   Marchesin S, 2010, IEEE T VIS COMPUT GR, V16, P1578, DOI 10.1109/TVCG.2010.212
   Maryan C, 2019, APPL SOFT COMPUT, V78, P84, DOI 10.1016/j.asoc.2019.02.017
   Mori I, 2022, IEEE ACCESS, V10, P6483, DOI 10.1109/ACCESS.2022.3140340
   Nair V., 2010, ICML, P807
   Paolacci G, 2010, JUDGM DECIS MAK, V5, P411
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Philip A., 2016, P EUR IEEE VGTC C VI, P19
   Rashid AH, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533849
   Rashid I., 2020, INT C NEURAL INF PRO, P172, DOI [10.1007/978-3-030-63823-821.36A.H., DOI 10.1007/978-3-030-63823-821.36A.H, 10.1007/978-3-030-63823-8_21]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Sane S, 2020, COMPUT GRAPH FORUM, V39, P785, DOI 10.1111/cgf.14036
   Shadden SC, 2005, PHYSICA D, V212, P271, DOI 10.1016/j.physd.2005.10.007
   Simoudis E., 1996, KDD 96 P 2 INT C KNO, P226
   Tao J, 2013, IEEE T VIS COMPUT GR, V19, P393, DOI 10.1109/TVCG.2012.143
   Theisel H., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P141
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yu HF, 2012, IEEE T VIS COMPUT GR, V18, P1353, DOI 10.1109/TVCG.2011.155
   Zhang SF, 2018, IEEE SYS MAN CYBERN, P415, DOI 10.1109/SMC.2018.00080
NR 45
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3930
EP 3944
DI 10.1109/TVCG.2023.3243834
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700005
PM 37022897
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Leventhal, S
   Gyulassy, A
   Heimann, M
   Pascucci, V
AF Leventhal, Samuel
   Gyulassy, Attila
   Heimann, Mark
   Pascucci, Valerio
TI Exploring Classification of Topological Priors With Machine Learning for
   Feature Extraction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image segmentation; Machine learning; Semantics; Task analysis;
   Labeling; Training; Topology; Computational topology; feature detection;
   graph learning; graph neural networks; machine learning; Morse-Smale
   complex; scientific visualization; segmentation; topological data
   analysis
ID SEGMENTATION; PERSISTENCE; MODEL; SHAPE
AB In many scientific endeavors, increasingly abstract representations of data allow for new interpretive methodologies and conceptualization of phenomena. For example, moving from raw imaged pixels to segmented and reconstructed objects allows researchers new insights and means to direct their studies toward relevant areas. Thus, the development of new and improved methods for segmentation remains an active area of research. With advances in machine learning and neural networks, scientists have been focused on employing deep neural networks such as U-Net to obtain pixel-level segmentations, namely, defining associations between pixels and corresponding/referent objects and gathering those objects afterward. Topological analysis, such as the use of the Morse-Smale complex to encode regions of uniform gradient flow behavior, offers an alternative approach: first, create geometric priors, and then apply machine learning to classify. This approach is empirically motivated since phenomena of interest often appear as subsets of topological priors in many applications. Using topological elements not only reduces the learning space but also introduces the ability to use learnable geometries and connectivity to aid the classification of the segmentation target. In this article, we describe an approach to creating learnable topological elements, explore the application of ML techniques to classification tasks in a number of areas, and demonstrate this approach as a viable alternative to pixel-level classification, with similar accuracy, improved execution time, and requiring marginal training data.
C1 [Leventhal, Samuel; Gyulassy, Attila; Pascucci, Valerio] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
   [Leventhal, Samuel; Gyulassy, Attila; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
   [Heimann, Mark] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
C3 Utah System of Higher Education; University of Utah; Utah System of
   Higher Education; University of Utah; United States Department of Energy
   (DOE); Lawrence Livermore National Laboratory
RP Leventhal, S (corresponding author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.; Leventhal, S (corresponding author), Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
EM samlev@cs.utah.edu; jediati@sci.utah.edu; heimann2@llnl.gov;
   pascucci@sci.utah.edu
RI pascucci, Valerio/GXF-0616-2022
OI pascucci, Valerio/0000-0002-8877-2042; Gyulassy,
   Attila/0000-0002-6046-8022; Leventhal, Samuel/0000-0003-2454-0311
FU NSF OAC [2138811]; NSF CI CoE [2127548]; Department of Energy(DoE)
   [DE-FE0031880]; Intel one API Centers of Excellence at University of
   Utah; Exascale Computing Project [17-SC-20-SC]; NNSA; UT-Battelle, LLC
   [DE-AC05-00OR22725]; U.S. DoE [DE-AC52-07NA27344]; LDRD Program
   [21-ERD-012]
FX This work was supported in part by NSF OAC under Grant 2138811,in part
   by NSF CI CoE under Grant 2127548, in part by Department of Energy(DoE)
   under Grant DE-FE0031880, in part by the Intel one API Centers of
   Excellence at University of Utah, in part by the Exascale Computing
   Project under Grant 17-SC-20-SC, a collaborative effort of the DoE and
   the NNSA,in part by UT-Battelle, LLC under Grant DE-AC05-00OR22725, in
   part by the U.S. DoE by Lawrence Livermore National Laboratory under
   Grant DE-AC52-07NA27344, and in part by LDRD Program under Grant
   21-ERD-012.
CR Acciai L, 2016, NEUROINFORMATICS, V14, P353, DOI 10.1007/s12021-016-9310-0
   Achanta A., 2010, Tech. Rep. 149300
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Acharjya P. P., 2012, Int. J. Comput. Appl., V52, P6
   Banerjee S, 2020, NAT MACH INTELL, V2, P585, DOI 10.1038/s42256-020-0227-9
   Bendich P, 2007, ANN IEEE SYMP FOUND, P536, DOI 10.1109/FOCS.2007.45
   Beucher S., 1931, P IEEE INT C AC SPEE, P1928
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P139, DOI 10.1109/VISUAL.2003.1250365
   Chen F, 2013, PROC CVPR IEEE, P1870, DOI 10.1109/CVPR.2013.244
   Dey TK, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), P520, DOI 10.1145/3347146.3359348
   Dingding Liu, 2011, Machine Learning and Data Mining in Pattern Recognition. Proceedings 7th International Conference, MLDM 2011, P484, DOI 10.1007/978-3-642-23199-5_36
   Eberle AL, 2015, J MICROSC-OXFORD, V259, P114, DOI 10.1111/jmi.12224
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   Eslami SMA, 2014, INT J COMPUT VISION, V107, P155, DOI 10.1007/s11263-013-0669-1
   Forman R., 2002, Sem. Lothar. Combin, V48
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Funke J, 2019, IEEE T PATTERN ANAL, V41, P1669, DOI 10.1109/TPAMI.2018.2835450
   Gillette TA, 2011, NEUROINFORMATICS, V9, P233, DOI 10.1007/s12021-011-9117-y
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Gyulassy A., 2018, "MSCEER: Morse-Smale complex extraction, exploration, reasoning
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Harer H Edelsbrunner J., 2010, COMPUTATIONAL TOPOLO
   Hebbalaguppe R, 2013, 2013 1ST IEEE WORKSHOP ON USER-CENTERED COMPUTER VISION (UCCV), P19, DOI 10.1109/UCCV.2013.6530803
   Hongjuan G., 2009, Comput. Eng., V35, DOI [10.3969/j.issn.1000-3428.2009.03.090, DOI 10.3969/J.ISSN.1000-3428.2009.03.090]
   Hu XL, 2021, Arxiv, DOI arXiv:2103.09992
   Januszewski M, 2018, NAT METHODS, V15, P605, DOI 10.1038/s41592-018-0049-4
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Klibisz A, 2017, LECT NOTES COMPUT SC, V10553, P285, DOI 10.1007/978-3-319-67558-9_33
   Konyushkova K, 2015, IEEE I CONF COMP VIS, P2974, DOI 10.1109/ICCV.2015.340
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Lindeberg T., 1994, J. Appl. Statist., V21, P270
   Mayer J, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0068-z
   McDonald T, 2021, IEEE T VIS COMPUT GR, V27, P744, DOI 10.1109/TVCG.2020.3030363
   Moor M., 2020, INT C MACH LEARN, P7045
   Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4
   Pachitariu A. M., 2013, INT C NEURAL INF PRO, P1745
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pape C, 2019, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00006
   Pascucci Valerio., 2010, Topological Methods in Data Analysis and Visualization: Theory, Algorithms, and Applications
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petruzza S, 2020, IEEE T VIS COMPUT GR, V26, P140, DOI 10.1109/TVCG.2019.2934620
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Ramadan H, 2020, COMPUT VIS MEDIA, V6, P355, DOI 10.1007/s41095-020-0177-5
   Ricci P, 2022, PROG BIOPHYS MOL BIO, V168, P52, DOI 10.1016/j.pbiomolbio.2021.07.003
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Shih CT, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.687182
   Sonka V., 2014, Image Processing, Analysis, andMachine Vision
   Sweet C. P., 1998, FLTK Revision
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   van der Merwe EL, 2010, EXP EYE RES, V91, P118, DOI 10.1016/j.exer.2010.04.016
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Venkat A, 2022, IEEE T VIS COMPUT GR, V28, P76, DOI 10.1109/TVCG.2021.3114819
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang C-C, 2017, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1706.02216
   Wilburn DB, 2016, J PROTEOMICS, V135, P12, DOI 10.1016/j.jprot.2015.06.007
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Zhao Q, 2020, PR MACH LEARN RES, V108, P2896
   Zhu Y. Yan, 2020, P 34 INT C NEUR INF
NR 66
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3959
EP 3972
DI 10.1109/TVCG.2023.3248632
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700009
PM 37027638
DA 2024-08-05
ER

PT J
AU Chen, XJ
   Liu, QH
   Chen, YH
   Wang, RH
   You, Y
   Deng, WX
   Chen, W
   Wang, XS
AF Chen, Xiaojiao
   Liu, Qinghua
   Chen, Yonghao
   Wang, Ruihan
   You, Yang
   Deng, Wanxin
   Chen, Wei
   Wang, Xiaosong
TI ColorNetVis: An Interactive Color Network Analysis System for Exploring
   the Color Composition of Traditional Chinese Painting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Painting; Visualization; Humanities; Shape;
   Clothing; Analytical models; Color analysis; color network; traditional
   chinese painting; visual analytic
ID DIFFERENCE
AB In the field of digital humanities, color research aims to discover explanations for painting history and color usage habits. However, researchers analyzing color relationships is challenging and time-consuming, as it requires color extraction and a detailed review of many painting images for reference and comparison of color relationships. In our work, we propose ColorNetVis, an interactive color network analysis tool that enables researchers to explore color relationships through color networks. The core of ColorNetVis is a bipartite network model that establishes a bipartite relationship between colors and Chinese painting within a scope based on color difference measurement. It constructs a one-mode color network through projection algorithms and similarity calculation methods to discover the relationship between colors. We propose a coordinated set of views to demonstrate the combination of determined color networks with painting types and real-world attributes. We use color space view, color attribute distribution view, and single color query components to assist researchers in conducting detailed color analysis and validation. Through case studies, researcher reviews, and user studies, we demonstrate that ColorNetVis can effectively help researchers discover knowledge of color relationships and potential color research directions.
C1 [Chen, Xiaojiao; Liu, Qinghua; Chen, Yonghao; Wang, Ruihan; You, Yang; Deng, Wanxin; Chen, Wei; Wang, Xiaosong] Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310000, Peoples R China.
   [Chen, Wei] Zhejiang Univ, State Key Lab, CAD & CG, Hangzhou 310000, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Chen, W; Wang, XS (corresponding author), Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310000, Peoples R China.
EM chenxiaojiao@zju.edu.cn; yazawaninico@163.com; chenyonghao@zju.edu.cn;
   ruihanwang@zju.edu.cn; 937659529@qq.com; 272293209@qq.com;
   chenvis@zju.edu.cn; wang64@zju.edu.cn
RI Liu, Qinghua/ABD-9106-2021
OI Liu, Qinghua/0000-0003-4644-5518; Chen, Wei/0000-0002-8365-4741
FU Interdisciplinary planning of philosophy and social sciences in Zhejiang
   Province [22JCXK03Z]; Major Projects of the National Social Science
   Foundation [19ZDA046]
FX This work was supported in part by the Key support project for
   interdisciplinary planning of philosophy and social sciences in Zhejiang
   Province under Grant 22JCXK03Z, and in part by the Major Projects of the
   National Social Science Foundation under Grant 19ZDA046. Recommended for
   acceptance by N. Elmqvist, S. Liu, and V. Pascucci.
CR Bonacich P, 2007, SOC NETWORKS, V29, P555, DOI 10.1016/j.socnet.2007.04.002
   Chan C, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P403, DOI 10.1109/PCCGA.2002.1167884
   Chang Y, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0482-x
   Chunaev P, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100286
   Feng ZL, 2018, NEUROCOMPUTING, V273, P395, DOI 10.1016/j.neucom.2017.07.043
   Flueckiger B, 2020, DIGIT HUMANITIES Q, V14
   Flueckiger B, 2017, MOV IMAGE, V17, P71
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Goldsmith L.T., 1992, Creativity Research Journal, V5, P281, DOI [10.1080/10400419209534441, DOI 10.1080/10400419209534441]
   Guancan Yang, 2021, Diversity, Divergence, Dialogue. 16th International Conference, iConference 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12645), P490, DOI 10.1007/978-3-030-71292-1_38
   Guillaume JL, 2006, PHYSICA A, V371, P795, DOI 10.1016/j.physa.2006.04.047
   Haghani S, 2019, ARTIF INTELL REV, V52, P1961, DOI 10.1007/s10462-017-9590-2
   Hu Dongfang., 1995, International Journal of Politics, Culture, and Society, V8, P453
   Jiang SQ, 2006, PATTERN RECOGN LETT, V27, P734, DOI 10.1016/j.patrec.2005.10.017
   Jin Z, 2023, FRONT INFORM TECH EL, V24, P1416, DOI 10.1631/FITEE.2200662
   Jingwena C., 2023, DESIGN STUDIES INTEL, V365, DOI [10.3233/fain220707, DOI 10.3233/FAIN220707]
   Johnson GM, 2010, COLOR RES APPL, V35, P387, DOI 10.1002/col.20561
   Kaneko A, 2020, VIS COMPUT IND BIOME, V3, DOI 10.1186/s42492-019-0040-7
   Kumar A, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124289
   Li M, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2021.12.006
   Li R, 2022, VIS INFORM, V6, P35, DOI 10.1016/j.visinf.2022.02.002
   Li Yu, 2019, Computer Integrated Manufacturing Systems, V25, P2355, DOI 10.13196/j.cims.2019.09.022
   Liang K., 2021, Front. Art Res., V3, DOI [10.25236/FAR.2021.030101, DOI 10.25236/FAR.2021.030101]
   Liu XJ, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-1437-6
   Liu Xiaojian, 2016, Computer Integrated Manufacturing Systems, V22, P899, DOI 10.13196/j.cims.2016.04.003
   Lonapalawong S, 2022, FRONT INFORM TECH EL, V23, P382, DOI 10.1631/FITEE.2000596
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   Mao X, 2023, VIS INFORM, V7, P110, DOI 10.1016/j.visinf.2023.10.006
   Pei SC, 2004, IEEE T IMAGE PROCESS, V13, P414, DOI 10.1109/TIP.2003.821347
   Pei SC, 2006, IEEE T IMAGE PROCESS, V15, P3230, DOI 10.1109/TIP.2006.877478
   Sari C, 2019, DIGIT SCHOLARSH HUM, V34, P156, DOI 10.1093/llc/fqz055
   SILBERGELD J, 1987, ART J, V46, P103, DOI 10.2307/776887
   Stepanova E, 2019, EMPIR ECON, V56, P755, DOI 10.1007/s00181-017-1413-4
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Thudt Alice, 2012, P SIGCHI C HUM FACT, P1461, DOI 10.1145/2207676.2208607
   Vartija DevinJ., 2021, COLOR EQUALITY RACE
   Wu MG, 2022, CARTOGR GEOGR INF SC, V49, P289, DOI 10.1080/15230406.2021.1982009
   Xu BQ, 2019, COLOR RES APPL, V44, P205, DOI 10.1002/col.22339
   Xu H, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581429
   [徐明慧 Xu Minghui], 2021, [纺织学报, Journal of Textile Research], V42, P137
   Yu R., 2022, P INT C MACH LEARN C, P251, DOI [10.1007/978-3-031-20102-8_20, DOI 10.1007/978-3-031-20102-8_20]
   Yun SA, 2019, COLOR RES APPL, V44, P115, DOI 10.1002/col.22288
   Zhang Chenyang, 2023, IEEE Trans Vis Comput Graph, V29, P767, DOI 10.1109/TVCG.2022.3209440
   Zhang JL, 2017, ADV INTEL SYS RES, V132, P300
   Zhang M, 2024, FRONT COMPUT SCI-CHI, V18, DOI 10.1007/s11704-022-2336-6
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhejiang University A, 2022, Comprehensive collection of ancient chinese paintings in national museum exhibition
   Zhou T, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.046115
   Zhu BT, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/1942046
   Zweig KA, 2011, SOC NETW ANAL MIN, V1, P187, DOI 10.1007/s13278-011-0021-0
NR 50
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2916
EP 2928
DI 10.1109/TVCG.2024.3388520
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500006
PM 38619944
DA 2024-08-05
ER

PT J
AU Chandio, Y
   Interrante, V
   Anwar, FM
AF Chandio, Yasra
   Interrante, Victoria
   Anwar, Fatima M.
TI Human Factors at Play: Understanding the Impact of Conditioning on
   Presence and Reaction Time in Mixed Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mixed Reality; Presence; Conditioning
ID VIRTUAL-REALITY; WORKING-MEMORY; EXPERIENCE; TASK; INFORMATION; BEHAVIOR
AB A prerequisite to improving the presence of a user in mixed reality (MR) is the ability to measure and quantify presence. Traditionally, subjective questionnaires have been used to assess the level of presence. However, recent studies have shown that presence is correlated with objective and systemic human performance measures such as reaction time. These studies analyze the correlation between presence and reaction time when technical factors such as object realism and plausibility of the object's behavior change. However, additional psychological and physiological human factors can also impact presence. It is unclear if presence can be mapped to and correlated with reaction time when human factors such as conditioning are involved. To answer this question, we conducted an exploratory study (N=60) where the relationship between presence and reaction time was assessed under three different conditioning scenarios: control, positive, and negative. We demonstrated that human factors impact presence. We found that presence scores and reaction times are significantly correlated (correlation coefficient of -0.64), suggesting that the impact of human factors on reaction time correlates with its effect on presence. In demonstrating that, our study takes another important step toward using objective and systemic measures like reaction time as a presence measure.
C1 [Chandio, Yasra; Anwar, Fatima M.] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
   [Interrante, Victoria] Univ Minnesota Twin Cities, Minneapolis, MN USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   University of Minnesota System; University of Minnesota Twin Cities
RP Chandio, Y (corresponding author), Univ Massachusetts Amherst, Amherst, MA 01003 USA.
EM ychandio@umass.edu; interran@umn.edu; fanwar@umass.edu
OI Interrante, Victoria/0000-0002-3313-6663; Chandio,
   Yasra/0000-0002-3436-6452
FU NSF
FX No Statement Available
CR [Anonymous], Hololens 2
   [Anonymous], Intractable objects.
   [Anonymous], Microsoft spatializer.
   Arthur K. W., 2000, PhD thesis
   Barfield S., 1993, Advances in Human FactorsErgonomics, V19
   BARGH JA, 1982, J PERS SOC PSYCHOL, V43, P437, DOI 10.1037/0022-3514.43.3.437
   Basdogan C.-H., 2000, ACMTransactions on Computer-Human Interaction, V7
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Berch DB, 1998, BRAIN COGNITION, V38, P317, DOI 10.1006/brcg.1998.1039
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bracken C., 2010, Journal of Media Psychology
   Bruce M, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P179, DOI 10.1109/VR.2009.4811020
   Chandio Yasra, 2024, IEEE Trans Vis Comput Graph, V30, P5976, DOI 10.1109/TVCG.2023.3319563
   Colomb B., T. D.
   Cook T. D., 1979, Quasi-experimentation: Design analysis issues for field settings, V351
   de Kort YAW, 2006, J ENVIRON PSYCHOL, V26, P309, DOI 10.1016/j.jenvp.2006.09.001
   de Tinguy X, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P580, DOI [10.1109/whc.2019.8816164, 10.1109/WHC.2019.8816164]
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   Festinger L., 1957, Conflict, decision, and dissonance, V16, P401
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Gaggioli A, 2003, EMERG COMMUNICAT, V5, P121
   Gandy R., 2010, IEEE INT S MIX AUG R
   Giesel M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78378-z
   Glotzbach-Schoon E., 2013, e-Neuroforum, V4, P63, DOI DOI 10.1007/S13295-013-0047-Z
   GRAHAM FK, 1992, ATTENTION AND INFORMATION PROCESSING IN INFANTS AND ADULTS, P3
   Grassini K., 2020, Frontiers in Psychol, V11
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Grillon C, 2006, BIOL PSYCHIAT, V60, P752, DOI 10.1016/j.biopsych.2006.03.072
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   IJsselsteijn W.A., 2004, Presence in Depth
   Jamalian N, 2022, INT SYM MIX AUGMENT, P768, DOI 10.1109/ISMAR55827.2022.00095
   Jang Y, 2019, TELEMAT INFORM, V42, DOI 10.1016/j.tele.2019.101239
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jicol C., 2023, P 2023 CHI C HUM FAC
   Jicol C., 2021, P 2021 CHI C HUM FAC
   Kahneman P.S. Daniel., 1982, JUDGMENT UNCERTAINTY
   Kane MJ, 2007, J EXP PSYCHOL LEARN, V33, P615, DOI 10.1037/0278-7393.33.3.615
   Kazdin AE, 2003, J CHILD PSYCHOL PSYC, V44, P1116, DOI 10.1111/1469-7610.00195
   Kim T. H., 2021, Electronics, V10
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Latoschik C., 2022, Frontiers in Virtual Reality, V3
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, DOI [10.1111/j.1083-6101.1997.tb0, 10.1111/j.1083-6101.1997.tb00072.x., 10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X, 10.1111/J.1083-6101.1997.TB00072.X/4080403]
   Meehan M, 2002, ACM Trans-actions on Graphics, V21
   Microsoft, 2023, Types of Mixed Reality Apps
   Microsoft, 2023, Direct hand manipulation in hololens2
   Milgram H., 1995, SPIE
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Nunez D, 2004, P 3 INT C COMP GRAPH
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Paes D, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103849
   Pavlov IP, 2010, ANN NEUROSCI, V17, P136, DOI 10.5214/ans.0972-7531.1017309
   Pimentel D, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.634520
   Prothero D.E., 1995, P C EXP MEAS SIT AW
   Putze D., 2020, P 2020 CHI C HUM FAC
   Regenbrecht H, 2021, Arxiv, DOI arXiv:2103.02831
   Rescorla R.A., 1972, PSYCHOL LEARNING MOT, V6, P1, DOI DOI 10.1016/S0079-7421(08)60383-7
   Riva F., 2003, Being there: Concepts,effects and measurement of user presence in synthetic environments, V5, P62
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Safikhani S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489884
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert T., 2003, Zeitschrift fur Medienpsychologie, V15
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Schwind V, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P507, DOI 10.1145/3116595.3116596
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709
   Sheridan ThomasB., 1992, Presence Teleoperators Virtual Environ, V1
   Skinner B. F., 1938, The Behavior of organisms: An experimental analysis
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1999, EUR WORKSH VIRT ENV
   Slater M., 1995, ACM Transactionson Computer-Human Interaction, V2
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater V., 1996, P ACM S VIRT REAL SO
   Steed Y., 2016, InIEEE Virtual Reality
   Steuer J., 1995, Communication in the age of virtual reality, V33, P37
   Stevens B, 2002, PRESENCE-TELEOP VIRT, V11, P79, DOI 10.1162/105474602317343677
   Stevens J., 2000, INT WORKSH HAPT COMP
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Szczurowski M., 2017, 23 INT C VIRT SYST M
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vroom V.H., 1964, Work and motivation
   Wagner W., 2009, Presence, V18
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Westermeier F., 2022, IEEE Transactions on Visualization andComputer Graphics, V28
   Westermeier F, 2023, IEEE T VIS COMPUT GR, V29, P2680, DOI 10.1109/TVCG.2023.3247046
   Wienrich P., 2021, Frontiers in Virtual Reality, V2
   Wiesing M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231152
   Wilson S., 1997, InHCI
   Witmer M. J., 1998, Presence: Teleoperators & VirtualEnvironments, V7
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 95
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2400
EP 2410
DI 10.1109/TVCG.2024.3372120
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400030
PM 38437088
DA 2024-08-05
ER

PT J
AU Seraji, MR
   Piray, P
   Zahednejad, V
   Stuerzlinger, W
AF Seraji, Mohammad Rajabi
   Piray, Parastoo
   Zahednejad, Vahid
   Stuerzlinger, Wolfgang
TI Analyzing User Behaviour Patterns in a Cross-Virtuality Immersive
   Analytics System
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Immersive Analytics; Cross-virtuality Analytics; Visualization;
   Human-computer Interaction
ID INFORMATION VISUALIZATION; REALITY; EXPLORATION
AB Recent work in immersive analytics suggests benefits for systems that support work across both 2D and 3D data visualizations, i.e., cross-virtuality analytics systems. Here, we introduce HybridAxes, an immersive visual analytics system that enables users to conduct their analysis either in 2D on desktop monitors or in 3D within an immersive AR environment - while enabling them to seamlessly switch and transfer their graphs between modes. Our user study results show that the cross-virtuality sub-systems in HybridAxes complement each other well in helping the users in their data-understanding journey. We show that users preferred using the AR component for exploring the data, while they used the desktop to work on more detail-intensive tasks. Despite encountering some minor challenges in switching between the two virtuality modes, users consistently rated the whole system as highly engaging, user-friendly, and helpful in streamlining their analytics processes. Finally, we present suggestions for designers of cross-virtuality visual analytics systems and identify avenues for future work.
C1 [Seraji, Mohammad Rajabi; Piray, Parastoo; Zahednejad, Vahid; Stuerzlinger, Wolfgang] Simon Fraser Univ, Burnaby, BC, Canada.
C3 Simon Fraser University
RP Seraji, MR (corresponding author), Simon Fraser Univ, Burnaby, BC, Canada.
EM mrajabis@sfu.ca; ppa35@sfu.ca; vahid_zahednejad@sfu.ca; w.s@sfu.ca
OI Stuerzlinger, Wolfgang/0000-0002-7110-5024
FU Canadian NRC for funding
FX No Statement Available
CR Akpan IJ, 2019, SIMUL-T SOC MOD SIM, V95, P145, DOI 10.1177/0037549718757039
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Batmaz W., 2019, 2019 CHI C HUM FACT, P1, DOI [10.1145/3290607.33127523[4]H, DOI 10.1145/3290607.33127523[4]H]
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Blum G., 2019, InComputer Science Research Notes. Zapadoceskauniverzita, DOI [10.24132/CSRN.2019.2902.2.93[8]M, DOI 10.24132/CSRN.2019.2902.2.93[8]M]
   Cavallo M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364242
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/VR.2019.8797733, 10.1109/vr.2019.8797733]
   Chakraborty S, 2021, LECT NOTES COMPUT SC, V12934, P610, DOI 10.1007/978-3-030-85613-7_39
   Concord-Consortium, 2014, Common online data analysis platform (CODAP)
   Cordeil B., 2020, Embodied Axes: Tangible, Actuated Interaction for3D Augmented Reality Data Spaces, V2, P1
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Dube T. J., 2019, International Conference on Human-Computer Interaction, P419
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Fisherkeller M., 1974, Science, V155, P279
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Garrido Daniel, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12742), P628, DOI 10.1007/978-3-030-77961-0_50
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Grasset Raphael, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P231, DOI 10.1109/ISMAR.2006.297819
   Hinckley K., 2010, Proceedings of the 23nd annual ACM symposium on User interface software and technology, P27, DOI [10.1145/1866029.1866036, DOI 10.1145/1866029.1866036]
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Jetter HC, 2021, ISS '21 COMPANION: COMPANION PROCEEDINGS OF THE 2021 CONFERENCE ON INTERACTIVE SURFACES AND SPACES SPONSORED, P46, DOI 10.1145/3447932.3487940
   Jo J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2660, DOI 10.1145/3025453.3025752
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Laramee RS, 2007, LECT NOTES COMPUT SC, V4417, P231
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee B, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P335, DOI 10.1145/3343055.3360746
   McIntire JP, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P1, DOI 10.1109/3DVis.2014.7160093
   Meseery El, 2018, S BIG DAT VIS AN BDV, P70, DOI [10.1109/BDVA.2018.85340193,5[19]B, DOI 10.1109/BDVA.2018.85340193,5[19]B]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Nielsen J, 2003, Usability 101: Introduction to Usability
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Reski N., 2020, P 11 NORD C HUM COMP
   Riegler A., 2020, XR@ISS, V11
   Rzeszotarski JM, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P897, DOI 10.1145/2556288.2557231
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Saffo D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581093
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Snowdon Dave., 2001, COLLABORATIVE VIRTUA, P3, DOI [10.1007/978-1-4471-0685-2_1, DOI 10.1007/978-1-4471-0685-2_1]
   Stuerzlinger W, 2018, LECT NOTES COMPUT SC, V11190, P139, DOI 10.1007/978-3-030-01388-2_5
   Thomas J. J., 2005, Illuminating the Path the Research and Development Agenda for Visual Analytics
   Tong W, 2023, Symposium Virtual Re, P387, DOI 10.1109/VR55154.2023.00054
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang L., 2020, Towards an Understanding of Augmented Reality Extensions forExisting 3D Data Analysis Tools, P1
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Zaman C., 2018, 2018 CHI C HUM FACT, P1, DOI [10.1145/3170427.31885934\n, DOI 10.1145/3170427.31885934]
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2613
EP 2623
DI 10.1109/TVCG.2024.3372129
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400037
PM 38470602
DA 2024-08-05
ER

PT J
AU Tian, N
   Boulic, R
AF Tian, Nana
   Boulic, Ronan
TI Who says you are so sick? An investigation on individual susceptibility
   to cybersickness triggers using EEG, EGG and ECG
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Gybersickness; Individual Susceptibility;
   Electrocardiogram; Electrogastrogram; Electroencephalogram
ID ELECTROGASTROGRAPHY
AB In this research paper, we conducted a study to investigate the connection between three objective measures: Electrocardiogram(EGG), Electrogastrogram (EGG), and Electroencephalogram (EEG), and individuals' susceptibility to cybersickness. Our primary objective was to identify which of these factors plays a central role in causing discomfort when experiencing rotations along three different axes: Roll, Pitch, and Yaw. This study involved 35 participants who were tasked with destroying asteroids using their eye gaze while undergoing passive rotations in four separate sessions. The results, when combined with subjective measurements (specifically, Fast motion sickness questionnaire (FMS) and Simulator sickness questionnaire (SSQ) score), demonstrated that EGG measurements were superior in detecting symptoms associated with nausea. As for ECG measurements, our observations did reveal significant changes in Heart Rate Variability (HRV) parameters. However, we caution against relying solely on ECG as a dependable indicator for assessing the extent of cybersickness. Most notably, EEG signals emerged as a crucial resource for discerning individual differences related to these rotational axes. Our findings were significant not only in the context of periodic activities but also underscored the potential of aperiodic activities in detecting the severity of cybersickness and an individual's susceptibility to rotational triggers.
C1 [Tian, Nana; Boulic, Ronan] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Tian, N (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM nana.tian@epfl.ch; ronan.boulic@epfl.ch
FU Fonds National Suisse de la Recherche Scientifique under the Sinergia
FX No Statement Available
CR Ahn MH, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.600839
   Andrievskaia P, 2023, EXP BRAIN RES, DOI 10.1007/s00221-023-06690-x
   Camargo A, 2008, SOURCE CODE BIOL MED, V3, DOI 10.1186/1751-0473-3-15
   Chang E, 2023, VIRTUAL REAL-LONDON, V27, P2073, DOI 10.1007/s10055-023-00795-y
   Chang E, 2022, VIRTUAL REAL-LONDON, V26, P1193, DOI 10.1007/s10055-021-00622-2
   CHEN J, 1991, MED BIOL ENG COMPUT, V29, P339, DOI 10.1007/BF02441653
   Chen YC, 2010, NEUROIMAGE, V49, P2862, DOI 10.1016/j.neuroimage.2009.10.005
   Choi MH, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P20
   Cortes CAT, 2023, Symposium Virtual Re, P94, DOI 10.1109/VR55154.2023.00025
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Donoghue T, 2020, NAT NEUROSCI, V23, P1655, DOI 10.1038/s41593-020-00744-x
   Farmer AD, 2015, J PHYSIOL-LONDON, V593, P1183, DOI 10.1113/jphysiol.2014.284240
   Garrido LE, 2022, VIRTUAL REAL-LONDON, V26, P1347, DOI 10.1007/s10055-022-00636-4
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Henry EH, 2022, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.809714
   Hill AT, 2022, DEV COGN NEUROS-NETH, V54, DOI 10.1016/j.dcn.2022.101076
   Hu R, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12040447
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Jang KM, 2022, APPL ERGON, V102, DOI 10.1016/j.apergo.2022.103731
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Khaitami, 2019, 2019 International Seminar on Intelligent Technology and Its Applications (ISITIA), P325, DOI 10.1109/ISITIA.2019.8937083
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kiryu T, 2007, LECT NOTES COMPUT SC, V4563, P262
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Koch KL, 2014, EXP BRAIN RES, V232, P2553, DOI 10.1007/s00221-014-4007-9
   Komorowski D, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0054-0
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Li G, 2023, Symposium Virtual Re, P328, DOI 10.1109/VR55154.2023.00048
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Luong T, 2022, INT SYM MIX AUGMENT, P307, DOI 10.1109/ISMAR55827.2022.00046
   MacArthur Cayley., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Nam S, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.857768
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Ozkan A, 2023, DISPLAYS, V78, DOI 10.1016/j.displa.2023.102415
   Park S, 2022, VIRTUAL REAL-LONDON, V26, P979, DOI 10.1007/s10055-021-00600-8
   Pham T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21123998
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Ribas Valdenilson Ribeiro, 2018, Dement. neuropsychol., V12, P264, DOI 10.1590/1980-57642018dn12-030007
   Riezzo G, 1998, DIGEST DIS SCI, V43, P1646, DOI 10.1023/A:1018894511181
   Riezzo G, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/282757
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Tian N, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P289, DOI 10.1109/VRW58643.2023.00068
   Tian P., 2022, VirtualReality, P1
   Watanabe H, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P210, DOI 10.1109/ISUC.2008.11
   Wibirama S, 2018, ENTERTAIN COMPUT, V26, P117, DOI 10.1016/j.entcom.2018.02.003
   Wilson LE, 2022, ELIFE, V11, DOI 10.7554/eLife.77348
   Yeo SS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21307-z
   Yin JY, 2013, J NEUROGASTROENTEROL, V19, P5, DOI 10.5056/jnm.2013.19.1.5
NR 50
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2379
EP 2389
DI 10.1109/TVCG.2024.3372066
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400050
PM 38437101
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Yin, TR
   Hoyet, L
   Christie, M
   Cani, MP
   Pettré, J
AF Yin, Tairan
   Hoyet, Ludovic
   Christie, Marc
   Cani, Marie-Paule
   Pettre, Julien
TI With or Without You: Effect of Contextual and Responsive Crowds on
   VR-based Crowd Motion Capture
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Trajectory; Motion capture; Recording; Pedestrians;
   Data models; Solid modeling; Crowd Simulation; Human Interaction;
   Virtual Reality
ID VIRTUAL-REALITY; PERSONAL-SPACE; PERCEPTION; BEHAVIORS; MODEL
AB While data is vital to better understand and model interactions within human crowds, capturing real crowd motions is extremely challenging. Virtual Reality (VR) demonstrated its potential to help, by immersing users into either simulated virtual crowds based on autonomous agents, or within motion-capture-based crowds. In the latter case, users' own captured motion can be used to progressively extend the size of the crowd, a paradigm called Record-and-Replay (2R). However, both approaches demonstrated several limitations which impact the quality of the acquired crowd data. In this paper, we propose the new concept of contextual crowds to leverage both crowd simulation and the 2R paradigm towards more consistent crowd data. We evaluate two different strategies to implement it, namely a Replace-Record-Replay (3R) paradigm where users are initially immersed into a simulated crowd whose agents are successively replaced by the user's captured-data, and a Replace-Record-Replay-Responsive (4R) paradigm where the pre-recorded agents are additionally endowed with responsive capabilities. These two paradigms are evaluated through two real-world-based scenarios replicated in VR. Our results suggest that the behaviors observed in VR users with surrounding agents from the beginning of the recording process are made much more natural, enabling 3R or 4R paradigms to improve the consistency of captured crowd datasets.
C1 [Yin, Tairan; Hoyet, Ludovic; Christie, Marc; Pettre, Julien] Univ Rennes, CNRS, Inria, IRISA, Rennes, France.
   [Cani, Marie-Paule] CNRS, Ecole Polytech, IP Paris, LIX, Palaiseau, France.
C3 Inria; Universite de Rennes; Centre National de la Recherche
   Scientifique (CNRS); Institut Polytechnique de Paris; Ecole
   Polytechnique; Centre National de la Recherche Scientifique (CNRS)
RP Yin, TR (corresponding author), Univ Rennes, CNRS, Inria, IRISA, Rennes, France.
EM tairan.yin@inria.fr; ludovic.hoyet@inria.fr; marc.christie@irisa.fr;
   marie-paule.cani@polytechnique.edu; julien.pettre@inria.fr
RI Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049; CANI,
   Marie-Paule/0000-0001-7752-9031; Yin, Tairan/0000-0001-6023-6507;
   Pettre, Julien/0000-0003-1812-1436
FU European Union's Horizon 2020 research and innovation programme
FX No Statement Available
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Araújo JP, 2023, Arxiv, DOI arXiv:2303.17912
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Banton T, 2005, PRESENCE-TELEOP VIRT, V14, P394, DOI 10.1162/105474605774785262
   Berton F, 2022, IEEE T VIS COMPUT GR, V28, P2589, DOI 10.1109/TVCG.2020.3041341
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Brscic D, 2013, IEEE T HUM-MACH SYST, V43, P522, DOI 10.1109/THMS.2013.2283945
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Daniel BC, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480136
   Cao SC, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa620d
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P95, DOI 10.1111/cgf.12403
   Conigliaro D, 2015, PROC CVPR IEEE, P2039, DOI 10.1109/CVPR.2015.7298815
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Echeverría-Huarte I, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79454-0
   Ezaki T., 2016, Collective Dynamics, V1, P1, DOI [10.17815/CD.2016.42, DOI 10.17815/CD.2016.42]
   Feldmann S, 2023, SAFETY SCI, V164, DOI 10.1016/j.ssci.2023.106173
   Feliciani C, 2020, TRANSPORT RES C-EMER, V114, P484, DOI 10.1016/j.trc.2020.02.019
   Feng Y, 2021, BUILD ENVIRON, V187, DOI 10.1016/j.buildenv.2020.107329
   Fink PW, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1227134.1227136
   Friston K, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P10, DOI 10.1016/B978-012372560-8/50002-4
   Garcia W, 2021, SAFETY SCI, V144, DOI 10.1016/j.ssci.2021.105453
   Geoerg P, 2019, J ADV TRANSPORT, DOI 10.1155/2019/9717208
   Gérin-Lajoie M, 2008, GAIT POSTURE, V27, P239, DOI 10.1016/j.gaitpost.2007.03.015
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hessels RS, 2022, ATTEN PERCEPT PSYCHO, V84, P2623, DOI 10.3758/s13414-022-02541-z
   Hessels RS, 2020, ATTEN PERCEPT PSYCHO, V82, P2482, DOI 10.3758/s13414-019-01952-9
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Kinateder M, 2021, PHYSICA A, V569, DOI 10.1016/j.physa.2021.125746
   Kwiatkowski A, 2023, COMPUT GRAPH-UK, V110, P28, DOI 10.1016/j.cag.2022.11.007
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Liu YJ, 2022, PROC CVPR IEEE, P17060, DOI 10.1109/CVPR52688.2022.01657
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Lynch SD, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI 10.1109/VR.2018.8446180
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Moussaïd M, 2009, P ROY SOC B-BIOL SCI, V276, P2755, DOI 10.1098/rspb.2009.0405
   Mullick P, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010210
   Nelson M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365709
   Nicolas A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36711-7
   Olivier A.-H., 2018, Collective Dynamics
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Patotskaya Y, 2023, COMPUT GRAPH-UK, V110, P162, DOI 10.1016/j.cag.2023.01.001
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI [DOI 10.1145/1599470.1599495, 10.1145/1599470.1599495]
   Podkosova I, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190845
   Raimbaud P, 2023, PROCEEDINGS OF THE ACM SYMPOSIUM ON APPLIED PERCEPTION, SAP 2023, DOI 10.1145/3605495.3605796
   Raimbaud P, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P281, DOI 10.1109/VR51125.2022.00047
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Ríos A, 2020, VIRTUAL REAL-LONDON, V24, P683, DOI 10.1007/s10055-020-00428-8
   Sanz FA, 2015, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2015.7223327
   Seyfried A, 2008, LECT NOTES COMPUT SC, V5191, P563, DOI 10.1007/978-3-540-79992-4_77
   Seyfried A, 2009, TRANSPORT SCI, V43, P395, DOI 10.1287/trsc.1090.0263
   Sharma A, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-01932-7
   Shi XM, 2018, J ADV TRANSPORT, DOI 10.1155/2018/1063043
   Sundararaman R, 2021, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR46437.2021.00386
   Trivedi H, 2023, COMPUT ANIMAT VIRT W, V34, DOI 10.1002/cav.2169
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll W, 2021, COMPUT GRAPH FORUM, V40, P731, DOI 10.1111/cgf.142664
   van Toll W, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384532
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Xu P, 2022, LECT NOTES COMPUT SC, V13664, P511, DOI 10.1007/978-3-031-19772-7_30
   Yersin B., 2009, ACM S INTERACTIVE 3D
   Yin TR, 2022, IEEE T VIS COMPUT GR, V28, P2245, DOI 10.1109/TVCG.2022.3150507
   Zhong JH, 2022, ACM T MODEL COMPUT S, V32, DOI 10.1145/3481299
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 68
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2785
EP 2795
DI 10.1109/TVCG.2024.3372038
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400058
PM 38437106
DA 2024-08-05
ER

PT J
AU Tian, XZ
   Günther, T
AF Tian, Xingze
   Guenther, Tobias
TI A Survey of Smooth Vector Graphics: Recent Advances in Repr esentation,
   Creation, Rasterization, and Image Vectorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graphics; Image color analysis; Shape; Mathematical models; Rendering
   (computer graphics); Splines (mathematics); Solids; Vector graphics;
   diffusion curves; gradient meshes; survey
ID COLOR TRANSFER; DIFFUSION CURVES; INTERPOLATION; SUBDIVISION;
   REPRESENTATION; COLORIZATION; OPTIMIZATION; COMPRESSION; PATCH; SHAPE
AB The field of smooth vector graphics explores the representation, creation, rasterization, and automatic generation of light-weight image representations, frequently used for scalable image content. Over the past decades, several conceptual approaches on the representation of images with smooth gradients have emerged that each led to separate research threads, including the popular gradient meshes and diffusion curves. As the computational models matured, the mathematical descriptions diverged and article started to focus more narrowly on subproblems, such as on the representation and creation of vector graphics, or the automatic vectorization from raster images. Most of the work concentrated on a specific mathematical model only. With this survey, we describe the established computational models in a consistent notation to spur further knowledge transfer, leveraging the recent advances in each field. We therefore categorize vector graphics article from the last decades based on their underlying mathematical representations as well as on their contribution to the vector graphics content creation pipeline, comprising representation, creation, rasterization, and automatic image vectorization. This survey is meant as an entry point for both artists and researchers. We conclude this survey with an outlook on promising research directions and challenges to overcome in the future.
C1 [Tian, Xingze; Guenther, Tobias] Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Günther, T (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
EM xingze.tian@fau.de; tobias.guenther@fau.de
OI Gunther, Tobias/0000-0002-3020-0930
CR Abadpour A, 2007, J VIS COMMUN IMAGE R, V18, P15, DOI 10.1016/j.jvcir.2006.08.001
   Dominici EA, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392401
   [Anonymous], 2010, P INT S NONPH AN REN
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Baksteen S. D., 2021, P SMART TOOLS APPS G, P91
   Bao B, 2019, COMPUT GRAPH-UK, V81, P73, DOI 10.1016/j.cag.2019.04.003
   Barendrecht PJ, 2018, VISUAL COMPUT, V34, P949, DOI 10.1007/s00371-018-1547-1
   Barla P., 2013, Image and Video-Based Artistic Stylisation, P149
   Battiato S, 2005, PROC SPIE, V5670, P1, DOI 10.1117/12.586802
   Battiato S., 2005, P 4 ANN C SCAL VECT, P1
   Battiato S., 2004, P 20 SPRING C COMP G, P185
   Beatson R, 2018, COMPUT AIDED GEOM D, V60, P18, DOI 10.1016/j.cagd.2018.01.002
   Bhunia AK, 2021, PROC CVPR IEEE, P5668, DOI 10.1109/CVPR46437.2021.00562
   Botsch M., 2005, Mathematics of Surfaces XI 11th IMA International Conference. Proceedings (Lecture Notes in Computer Science Vol. 3604), P62, DOI 10.1007/11537908_5
   Bowers JC, 2011, COMPUT GRAPH FORUM, V30, P1345, DOI 10.1111/j.1467-8659.2011.01994.x
   Boyé S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366192
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Briggs W. L., 2000, MULTIGRID TUTORIAL
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao J, 2019, COMPUT METHOD APPL M, V357, DOI 10.1016/j.cma.2019.112598
   Carlier A., 2020, P INT C NEUR INF PRO, p16 351
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Charrot P., 1984, Computer-Aided Geometric Design, V1, P87, DOI 10.1016/0167-8396(84)90006-2
   Chen KW, 2020, IEEE T MULTIMEDIA, V22, P15, DOI 10.1109/TMM.2019.2922126
   Chiyokura H., 1983, Computer Graphics, V17, P289, DOI 10.1145/964967.801160
   Dai W, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P922, DOI 10.1109/CISP.2013.6745296
   Davoine F, 1996, IEEE T IMAGE PROCESS, V5, P338, DOI 10.1109/83.480769
   Demaret L, 2006, SIGNAL PROCESS, V86, P1604, DOI 10.1016/j.sigpro.2005.09.003
   Douglas D. H., 1973, Can. Cartogr., V10, P112, DOI [10.3138/FM57-6770-U75U-7727, DOI 10.3138/FM57-6770-U75U-7727]
   DYN N, 1990, IMA J NUMER ANAL, V10, P137, DOI 10.1093/imanum/10.1.137
   Egiazarian V., 2020, EUROPEAN C COMPUTER, P582
   Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117
   Ellis K, 2018, ADV NEUR IN, V31
   Farin G., 2002, Curves and surfaces for CAGD, Vfifth
   Favreau JD, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130888
   Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FERGUSON J, 1964, J ACM, V11, P221, DOI 10.1145/321217.321225
   Finch M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024200
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Fraeijs de Veubeke B., 1974, International Journal for Numerical Methods in Engineering, V8, P783, DOI 10.1002/nme.1620080408
   Froumentin M, 2000, COMPUT GRAPH FORUM, V19, pC419, DOI 10.1111/1467-8659.00434
   Fu Q, 2021, IEEE COMPUT GRAPH, V41, P152, DOI 10.1109/MCG.2020.3024870
   Fu Q, 2019, COMPUT AIDED DESIGN, V115, P111, DOI 10.1016/j.cad.2019.05.005
   Fu Q, 2018, COMPUT AIDED DESIGN, V102, P1, DOI 10.1016/j.cad.2018.04.019
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Goodnight N., 2005, ACM SIGGRAPH 2005 Courses, P193
   Guo Y, 2019, COMPUT GRAPH FORUM, V38, P81, DOI 10.1111/cgf.13818
   He Y., 2022, PREPRINT, DOI [10.21203/rs.3.rs-1817017/v1, DOI 10.21203/RS.3.RS-1817017/V1]
   Hettinga G., 2021, P IT CHAPT C SMART T, P139
   Hettinga G. J., 2018, P 39 ANN EUR ASS COM, P45
   Hettinga GJ, 2022, COMPUT GRAPH-UK, V105, P119, DOI 10.1016/j.cag.2022.05.004
   Hettinga GJ, 2019, COMPUT AIDED GEOM D, V74, DOI 10.1016/j.cagd.2019.101769
   Hettinga GJ, 2019, GRAPH MODELS, V103, DOI 10.1016/j.gmod.2019.101024
   Hnaidi H, 2010, COMPUT GRAPH FORUM, V29, P2179, DOI 10.1111/j.1467-8659.2010.01806.x
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233
   Hoshyari S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201312
   Hou F., 2017, arXiv
   Hou F, 2020, IEEE T VIS COMPUT GR, V26, P1361, DOI 10.1109/TVCG.2018.2867478
   Hu ZY, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1889
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Ilbery P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508426
   Iu M.-Y., 2019, P 45 GRAPH INT C, P1
   Jacobson A, 2012, COMPUT GRAPH FORUM, V31, P1577, DOI 10.1111/j.1467-8659.2012.03163.x
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI [10.1016/S0146-664X(76)80003-2, DOI 10.1016/S0146-664X(76)80003-2]
   Jeschke S, 2011, COMPUT GRAPH FORUM, V30, P523, DOI 10.1111/j.1467-8659.2011.01877.x
   Jeschke S, 2016, COMPUT GRAPH FORUM, V35, P71, DOI 10.1111/cgf.12812
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618462
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618463
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644
   Lai YK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531391
   LASCAUX P, 1975, REV FR AUTOMAT INFOR, V9, P9
   Lawonn K, 2019, COMPUT GRAPH FORUM, V38, P221, DOI 10.1111/cgf.13526
   Lecot G., 2006, 17 EUROGRAPHICS S RE, P349
   Lee S-M., 2002, PhD dissertation
   Levenberg K., 1944, The Quarterly of Applied Mathematics, V2, P164, DOI [DOI 10.1090/QAM/10666, 10.1090/qam/10666, 10.1090/QAM/10666]
   Li TM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417871
   Li XY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461917
   Li YJ, 2021, IEEE T VIS COMPUT GR, V27, P228, DOI 10.1109/TVCG.2019.2929808
   Li YQ, 2022, IEEE T VIS COMPUT GR, V28, P3265, DOI 10.1109/TVCG.2021.3061131
   Liao ZC, 2012, IEEE T VIS COMPUT GR, V18, P1858, DOI 10.1109/TVCG.2012.76
   Lieng H, 2016, P ACM SIG GRAPH POST, P1
   Lieng H, 2017, COMPUT GRAPH FORUM, V36, P112, DOI 10.1111/cgf.12862
   Lieng H, 2015, COMPUT GRAPH FORUM, V34, P228, DOI 10.1111/cgf.12532
   Lin H., 2018, Comput. Vis. Media, V4
   Lin JC, 2015, 2015 NINTH INTERNATIONAL CONFERENCE ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY FCST 2015, P153, DOI 10.1109/FCST.2015.12
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Liu C, 2017, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2017.241
   Lopes RG, 2019, IEEE I CONF COMP VIS, P7929, DOI 10.1109/ICCV.2019.00802
   Lu SF, 2020, IEEE ACCESS, V8, P57158, DOI 10.1109/ACCESS.2020.2982457
   Lu SF, 2019, VISUAL COMPUT, V35, P1027, DOI 10.1007/s00371-019-01671-0
   Ma Xu, 2022, P IEEE CVF C COMP VI, P16314
   Maire M, 2008, PROC CVPR IEEE, P611
   Mao CY, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 4, PROCEEDINGS, P13, DOI 10.1109/WCSE.2009.182
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Niessner M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077347
   Nocedal J., 1999, Numerical optimization
   Noris G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421640
   Orzan A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360691
   Pang WM, 2012, IEEE COMPUT GRAPH, V32, P68, DOI 10.1109/MCG.2011.86
   Powell MJD., 1996, Computational_Techniques_and_Applications:_CTAC95,_RL_May_and_, P43
   Prévost R, 2015, COMPUT GRAPH FORUM, V34, P253, DOI 10.1111/cgf.12510
   Price B, 2006, VISUAL COMPUT, V22, P661, DOI 10.1007/s00371-006-0051-1
   Qi Y, 2022, COMPUT GRAPH FORUM, V41, P51, DOI 10.1111/cgf.14586
   Reddy P, 2021, PROC CVPR IEEE, P7338, DOI 10.1109/CVPR46437.2021.00726
   Ribeiro L.S.F., 2020, P IEEE CVF C COMP VI
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sawhney R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392374
   Schmidt TW, 2016, COMPUT GRAPH FORUM, V35, P216, DOI 10.1111/cgf.12721
   Schmitt D, 2019, LECT NOTES COMPUT SC, V11651, P335, DOI 10.1007/978-3-030-25027-0_23
   Schneider P.J., 1990, Graphics gems, V1, P612
   Shen IC, 2022, IEEE T VIS COMPUT GR, V28, P4211, DOI 10.1109/TVCG.2021.3084944
   Shewchuk J.R., 1996, APPL COMPUTATIONAL G, P203, DOI DOI 10.1007/BFB0014497
   Su D, 2004, COMPUT GRAPH FORUM, V23, P189, DOI 10.1111/j.1467-8659.2004.00752.x
   Su H, 2023, Arxiv, DOI arXiv:2110.04830
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Sun Q, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1611
   Sun T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601187
   Sun X, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185570
   Svergja J. K., 2017, P ACM SIGGRAPH POST, P1
   Swaminarayan Sriram, 2006, AIPR 06, P28
   Takayama K., 2010, P ACM SIGGRAPH AS, P1
   Várady T, 2016, COMPUT GRAPH FORUM, V35, P307, DOI 10.1111/cgf.12833
   Verstraaten TW, 2018, COMPUT GRAPH FORUM, V37, P373, DOI 10.1111/cgf.13575
   Wan L, 2018, MULTIMED TOOLS APPL, V77, P13753, DOI 10.1007/s11042-017-4987-0
   Wang CA, 2017, IEEE T IMAGE PROCESS, V26, P1833, DOI 10.1109/TIP.2017.2666742
   Weber O, 2012, COMPUT GRAPH FORUM, V31, P2409, DOI 10.1111/j.1467-8659.2012.03130.x
   Wei GS, 2019, COMPUT GRAPH FORUM, V38, P171, DOI 10.1111/cgf.13826
   Wolberg G, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P188, DOI 10.1109/CGI.1999.777953
   Xia T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618461
   Xiao CF, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480502
   Xiao Xuezhong, 2006, P 2006 ACM INT C VIR, P305
   Xiao YY, 2022, COMPUT GRAPH FORUM, V41, P23, DOI 10.1111/cgf.14495
   Xiao Y, 2015, COMPUT GRAPH FORUM, V34, P123, DOI 10.1111/cgf.12524
   Xiao Y, 2013, IEEE T MULTIMEDIA, V15, P549, DOI 10.1109/TMM.2012.2233725
   Xie GF, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661275
   Yang M, 2016, IEEE T VIS COMPUT GR, V22, P1063, DOI 10.1109/TVCG.2015.2440273
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yu XH, 2001, IEEE COMPUT GRAPH, V21, P62, DOI 10.1109/38.920628
   Yuksel C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731053
   Zhao S, 2018, IEEE T VIS COMPUT GR, V24, P2153, DOI 10.1109/TVCG.2017.2721400
   Zhou HL, 2014, IEEE T IMAGE PROCESS, V23, P3268, DOI 10.1109/TIP.2014.2327807
   Zhou J, 2022, COMPUT GRAPH FORUM, V41, P389, DOI 10.1111/cgf.14442
   Zhu HK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3513132
   Zorin D., 2006, ACM SIGGRAPH 2006 CO, P30, DOI DOI 10.1145/1185657.1185673
NR 147
TC 1
Z9 1
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1652
EP 1671
DI 10.1109/TVCG.2022.3220575
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500009
PM 36346866
OA hybrid
DA 2024-08-05
ER

PT J
AU Tu, YM
   Qiu, R
   Wang, YS
   Yen, PY
   Shen, HW
AF Tu, Yamei
   Qiu, Rui
   Wang, Yu-Shuen
   Yen, Po-Yin
   Shen, Han-Wei
TI PhraseMap: Attention-Based Keyphrases Recommendation for Information
   Seeking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Navigation; Bit error rate; Semantics; Computational
   modeling; Visual analytics; Task analysis; Textual data; machine
   learning; visual analytics; natural language processing;
   user-in-the-loop
ID VISUALIZATION
AB Many Information Retrieval (IR) approaches have been proposed to extract relevant information from a large corpus. Among these methods, phrase-based retrieval methods have been proven to capture more concrete and concise information than word-based and paragraph-based methods. However, due to the complex relationship among phrases and a lack of proper visual guidance, achieving user-driven interactive information-seeking and retrieval remains challenging. In this study, we present a visual analytic approach for users to seek information from an extensive collection of documents efficiently. The main component of our approach is a PhraseMap, where nodes and edges represent the extracted keyphrases and their relationships, respectively, from a large corpus. To build the PhraseMap, we extract keyphrases from each document and link the phrases according to word attention determined using modern language models, i.e., BERT. As can be imagined, the graph is complex due to the extensive volume of information and the massive amount of relationships. Therefore, we develop a navigation algorithm to facilitate information seeking. It includes (1) a question-answering (QA) model to identify phrases related to users' queries and (2) updating relevant phrases based on users' feedback. To better present the PhraseMap, we introduce a resource-controlled self-organizing map (RC-SOM) to evenly and regularly display phrases on grid cells while expecting phrases with similar semantics to stay close in the visualization. To evaluate our approach, we conducted case studies with three domain experts in diverse literature. The results and feedback demonstrate its effectiveness, usability, and intelligence.
C1 [Tu, Yamei; Qiu, Rui; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Wang, Yu-Shuen] Natl Chiao Tung Univ, Hsinchu 30010, Taiwan.
   [Yen, Po-Yin] Washington Univ, Sch Med, St Louis, MO 63110 USA.
C3 University System of Ohio; Ohio State University; National Yang Ming
   Chiao Tung University; Washington University (WUSTL)
RP Tu, YM (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM tu.253@osu.edu; qiu.580@osu.edu; yushuen@cs.nctu.edu.tw; yenp@wustl.edu;
   shen.94@osu.edu
RI Tu, Yamei/KSL-7529-2024
OI Qiu, Rui/0000-0002-3905-8926; Tu, Yamei/0000-0002-0722-837X; Wang,
   Yu-Shuen/0000-0003-2550-2990; Shen, Han-Wei/0000-0002-1211-2320
FU NSF
FX No Statement Available
CR Andrews K, 2002, Inf. Visualization, V1, P3
   [Anonymous], 2007, Scholarpedia, V2, P1568, DOI [10.4249/scholarpedia.1568, DOI 10.4249/SCHOLARPEDIA.1568]
   [Anonymous], 2012, Self-organizing maps
   Barratt A, 2008, PATIENT EDUC COUNS, V73, P407, DOI 10.1016/j.pec.2008.07.054
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Berglund E, 2006, IEEE T NEURAL NETWOR, V17, P305, DOI 10.1109/TNN.2006.871720
   Bier EA, 2010, IEEE T VIS COMPUT GR, V16, P178, DOI 10.1109/TVCG.2009.104
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borner Katy, 2010, Atlas of Science: Visualizing what We Know
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Burd R, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206531
   Cao W., 2016, Introduction to text visualization
   Chen SX, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814017740710
   Chen S, 2020, IEEE T VIS COMPUT GR, V26, P1204, DOI 10.1109/TVCG.2019.2934263
   Chen SM, 2016, IEEE CONF VIS ANAL, P41, DOI 10.1109/VAST.2016.7883510
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Coenen A, 2019, ADV NEUR IN, V32
   Couclelis H., 1998, CARTOGR GEOGR INF SC, V25, P209
   Cui L., 2020, Does bert solve commonsense task via commonsense knowledge, V4
   Cui YM, 2017, Arxiv, DOI arXiv:1607.04423
   Debiasi A, 2016, Study of visual clutter in geographic node-link diagrams
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding X., 2021, ACM Trans. Comput. Healthcare, V3, P1
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   Eftimov T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179488
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fried D, 2014, IEEE PAC VIS SYMP, P113, DOI 10.1109/PacificVis.2014.47
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Gansner ER, 2010, LECT NOTES COMPUT SC, V5849, P405, DOI 10.1007/978-3-642-11805-0_38
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Hoffmann M, 2022, CELL, V185, P447, DOI 10.1016/j.cell.2021.12.032
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kim T, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13042276
   Kim Y., 2013, P 6 INT JOINT C NATU, P864
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Lan Z., 2020, INT C LEARN REPR
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lee Jinhyuk, 2021, P 59 ANN M ASS COMPU, V1, P6634
   Lewis DD, 1996, COMMUN ACM, V39, P92, DOI 10.1145/234173.234210
   Li ZY, 2020, IEEE T VIS COMPUT GR, V26, P1182, DOI 10.1109/TVCG.2019.2934667
   Liu MC, 2016, IEEE T VIS COMPUT GR, V22, P250, DOI 10.1109/TVCG.2015.2467554
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P2482, DOI 10.1109/TVCG.2018.2834341
   Liu SX, 2014, IEEE CONF VIS ANAL, P183, DOI 10.1109/VAST.2014.7042494
   Liu Y., 2021, bioRxiv, DOI [10.1101/2021.12.22.473615, DOI 10.1101/2021.12.22.473615]
   Liu Yinhan, 2019, ROBERTA ROBUSTLY OPT
   Blei DM, 2009, Arxiv, DOI arXiv:0907.1013
   Ma DH, 2017, Arxiv, DOI arXiv:1709.00893
   Marecek D, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P263
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nemet I, 2022, NEW ENGL J MED, V386, P492, DOI 10.1056/NEJMc2119358
   Nishida K, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P647, DOI 10.1145/3269206.3271702
   Nocaj A, 2012, IEEE T VIS COMPUT GR, V18, P2546, DOI 10.1109/TVCG.2012.250
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Perera N, 2020, FRONT CELL DEV BIOL, V8, DOI 10.3389/fcell.2020.00673
   Vu PM, 2016, IEEE INT CONF AUTOM, P726, DOI 10.1145/2970276.2970365
   Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341
   Radford, 2018, OPENAI BLOG
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Santorini B., 1990, PART OF SPEECH TAGGI
   Sarracen Gretel Liz De La Pena, 2023, Personal and Ubiquitous Computing, P45, DOI 10.1007/s00779-021-01605-5
   Shahriar Hossain M., 2012, PROC 18 ACM SIGKDD I, P1375, DOI [10.1145/2339530 .2339742, DOI 10.1145/2339530.2339742]
   SKUPIN ANDRE., 2003, CARTOGR GEOGR INF SC, V30, P95, DOI [DOI 10.1559/152304003100011081, 10.1559/152304003100011081]
   Tang DY, 2016, Arxiv, DOI arXiv:1605.08900
   Tenney I., 2019, Bert rediscovers the classical nlp pipeline, DOI DOI 10.48550/ARXIV.1905.05950
   Tu YM, 2021, IEEE PAC VIS SYMP, P206, DOI 10.1109/PacificVis52677.2021.00034
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Waltl G., 2018, C IRIS 2018
   Wang S., 2021, Phrase-bert: Improved phrase embeddings from bert with an application to corpus exploration
   Wang XT, 2016, IEEE CONF VIS ANAL, P51, DOI 10.1109/VAST.2016.7883511
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86
   Xu QN, 2020, NEUROCOMPUTING, V388, P135, DOI 10.1016/j.neucom.2020.01.024
   Leow YY, 2019, Arxiv, DOI arXiv:1904.06915
   Yang W., 2022, Influenza Other Respir. Viruses, V16
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Zhang DC, 2021, LECT NOTES ARTIF INT, V12977, P762, DOI 10.1007/978-3-030-86523-8_46
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zuo H., 2022, Proceedings of the Design Society, V2, P821, DOI [https://doi.org/10.1017/pds.2022.84, DOI 10.1017/PDS.2022.84]
NR 88
TC 1
Z9 1
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1787
EP 1802
DI 10.1109/TVCG.2022.3225114
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500001
PM 36441879
DA 2024-08-05
ER

PT J
AU Yuan, J
   Barr, B
   Overton, K
   Bertini, E
AF Yuan, Jun
   Barr, Brian
   Overton, Kyle
   Bertini, Enrico
TI Visual Exploration of Machine Learning Model Behavior With Hierarchical
   Surrogate Rule Sets
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision trees; Data models; Behavioral sciences; Analytical models;
   Predictive models; Feature extraction; Data visualization;
   Visualization; rule set; surrogate model; model understanding
ID INTERPRETABILITY; VISUALIZATION; EXTRACTION
AB One of the potential solutions for model interpretation is to train a surrogate model: a more transparent model that approximates the behavior of the model to be explained. Typically, classification rules or decision trees are used due to their logic-based expressions. However, decision trees can grow too deep, and rule sets can become too large to approximate a complex model. Unlike paths on a decision tree that must share ancestor nodes (conditions), rules are more flexible. However, the unstructured visual representation of rules makes it hard to make inferences across rules. In this paper, we focus on tabular data and present novel algorithmic and interactive solutions to address these issues. First, we present Hierarchical Surrogate Rules (HSR), an algorithm that generates hierarchical rules based on user-defined parameters. We also contribute SuRE, a visual analytics (VA) system that integrates HSR and an interactive surrogate rule visualization, the Feature-Aligned Tree, which depicts rules as trees while aligning features for easier comparison. We evaluate the algorithm in terms of parameter sensitivity, time performance, and comparison with surrogate decision trees and find that it scales reasonably well and overcomes the shortcomings of surrogate decision trees. We evaluate the visualization and the system through a usability study and an observational study with domain experts. Our investigation shows that the participants can use feature-aligned trees to perform non-trivial tasks with very high accuracy. We also discuss many interesting findings, including a rule analysis task characterization, that can be used for visualization design and future research.
C1 [Yuan, Jun] NYU, New York 10012, NY USA.
   [Barr, Brian; Overton, Kyle] Capital One, Mclean, VA 22102 USA.
   [Bertini, Enrico] Northeastern Univ, Boston, MA 02115 USA.
C3 New York University; Northeastern University
RP Yuan, J (corresponding author), NYU, New York 10012, NY USA.
EM junyuan@nyu.edu; brian.barr@capitalone.com; kyle.overton@capitalone.com;
   e.bertini@northeastern.edu
OI Bertini, Enrico/0000-0002-9932-0551; Yuan, Jun/0000-0003-1952-5221;
   Barr, Brian/0000-0002-4424-3448
FU Capital One Financial Corporation
FX No Statement Available
CR Agrawal R., 1994, P INT C VERY LARGE D, V1215, P487
   Augasta MG, 2012, NEURAL PROCESS LETT, V35, P131, DOI 10.1007/s11063-011-9207-8
   Bastani O, 2019, Arxiv, DOI [arXiv:1705.08504, DOI 10.48550/ARXIV.1705.08504]
   Bénard C, 2021, ELECTRON J STAT, V15, P427, DOI 10.1214/20-EJS1792
   Cameron AC, 1997, J ECONOMETRICS, V77, P329
   Cohen WW, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P335
   Craven MW, 1996, ADV NEUR IN, V8, P24
   Dash S., 2018, P 32 INT C NEURAL IN, P4655
   Di Castro F., 2019, P IUI WORKSH
   Estivill-Castro V, 2020, IEEE SYS MAN CYBERN, P3852, DOI [10.1109/SMC42975.2020.9283240, 10.1109/smc42975.2020.9283240]
   FICO, 2018, EXPL MACH LEARN CHAL
   Flach PA, 2001, MACH LEARN, V42, P61, DOI 10.1023/A:1007656703224
   Fonteyn M.E., 1993, Qual Health Res, V3, P430, DOI [DOI 10.1177/104973239300300403, 10.1177/1049732393003004]
   Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P144
   Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148
   Goix Nicolas, 2020, Zenodo, DOI 10.5281/ZENODO.4316671
   Guidotti R, 2018, Arxiv, DOI arXiv:1805.10820
   Hastie T.J., 1990, Statistical Science, DOI [10.1214/ss/1177013604, DOI 10.1214/SS/1177013604]
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Thiagarajan JJ, 2016, Arxiv, DOI arXiv:1611.07429
   Lage Isaac, 2019, arXiv
   Lakkaraju H, 2017, Arxiv, DOI [arXiv:1707.01154, 10.48550/arXiv.1707.01154]
   Lakkaraju H, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P131, DOI 10.1145/3306618.3314229
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Lo LYH, 2022, COMPUT GRAPH FORUM, V41, P515, DOI 10.1111/cgf.14559
   Lundberg SM, 2017, ADV NEUR IN, V30
   Messalas A, 2019, INT CONF INFORM INTE, P220, DOI 10.1109/iisa.2019.8900669
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Molnar C., 2022, Interpretable Machine Learning, V2, DOI DOI 10.1007/S10290-014-0202-9
   Molnar C., 2018, Journal of Open Source Software, V3, P786, DOI DOI 10.21105/JOSS.00786
   Neto MP, 2020, Arxiv, DOI arXiv:2005.04289
   Pal NR, 2001, IEEE T SYST MAN CY B, V31, P745, DOI 10.1109/3477.956036
   Pei J., 2000, P 2000 ACM SIGMOD IN, V4, P21
   Poursabzi-Sangdeh F, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445315
   Quinlan J. R., 1987, Proceedings of the Tenth International Joint Conference of Artificial Intelligence, Milan, Italy, V87, P304
   Rajapaksha D, 2020, INFORM SCIENCES, V540, P221, DOI 10.1016/j.ins.2020.05.126
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261
   Szafir D. A., 2018, Interactions, V25, P26, DOI [DOI 10.1145/3231772, 10.1145/32317721, DOI 10.1145/32317721]
   Tam GKL, 2017, IEEE T VIS COMPUT GR, V23, P71, DOI 10.1109/TVCG.2016.2598829
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   Velmurugan Mythreyi, 2021, Intelligent Information Systems. CAiSE Forum 2021. Proceedings. Lecture Notes in Business Information Processing (LNBIP 424), P64, DOI 10.1007/978-3-030-79108-7_8
   Wang F, 2015, JMLR WORKSH CONF PRO, V38, P1013
   Wang T, 2017, J MACH LEARN RES, V18, P1
   Yang F., 2021, P ADV NEUR INF PROC
   Yuan J., 2021, An exploration and validation of visual factors in understanding classification rule sets
   Zarlenga ME, 2021, arXiv, DOI [DOI 10.48550/ARXIV.2111.12628, 10.48550/arXiv.2111.12628]
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zilke JR, 2016, LECT NOTES ARTIF INT, V9956, P457, DOI 10.1007/978-3-319-46307-0_29
NR 51
TC 2
Z9 2
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1470
EP 1488
DI 10.1109/TVCG.2022.3219232
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300006
PM 36327192
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Chen, ZT
   Chiappalupi, D
   Lin, TC
   Yang, YL
   Beyer, J
   Pfister, H
AF Chen, Zhutian
   Chiappalupi, Daniele
   Lin, Tica
   Yang, Yalong
   Beyer, Johanna
   Pfister, Hanspeter
TI RL-L: A Deep Reinforcement Learning Approach Intended for AR Label
   Placement in Dynamic Scenarios
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Layout; Dynamics; Visualization;
   Optimization; Task analysis; Sports; Augmented Reality; Reinforcement
   Learning; Label Placement; Dynamic Scenarios
ID VISUALIZATIONS
AB Labels are widely used in augmented reality (AR) to display digital information. Ensuring the readability of AR labels requires placing them in an occlusion-free manner while keeping visual links legible, especially when multiple labels exist in the scene. Although existing optimization-based methods, such as force-based methods, are effective in managing AR labels in static scenarios, they often struggle in dynamic scenarios with constantly moving objects. This is due to their focus on generating layouts optimal for the current moment, neglecting future moments and leading to sub-optimal or unstable layouts over time. In this work, we present RL-Label, a deep reinforcement learning-based method intended for managing the placement of AR labels in scenarios involving moving objects. RL-Label considers both the current and predicted future states of objects and labels, such as positions and velocities, as well as the user's viewpoint, to make informed decisions about label placement. It balances the trade-offs between immediate and long-term objectives. We tested RL-Label in simulated AR scenarios on two real-world datasets, showing that it effectively learns the decision-making process for long-term optimization, outperforming two baselines (i.e., no view management and a force-based method) by minimizing label occlusions, line intersections, and label movement distance. Additionally, a user study involving 18 participants indicates that, within our simulated environment, RL-Label excels over the baselines in aiding users to identify, compare, and summarize data on labels in dynamic scenes.
C1 [Chen, Zhutian; Chiappalupi, Daniele; Lin, Tica; Beyer, Johanna; Pfister, Hanspeter] Harvard John A Paulson Sch Engn & Appl Sci, Boston, MA 02134 USA.
   [Chiappalupi, Daniele] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Yang, Yalong] Virginia Tech, Blacksburg, VA USA.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Virginia
   Polytechnic Institute & State University
RP Chen, ZT (corresponding author), Harvard John A Paulson Sch Engn & Appl Sci, Boston, MA 02134 USA.
EM ztchen@seas.harvard.edu; daniele.chiappalupi@inf.ethz.ch;
   mlin@g.harvard.edu; yalongyang@hotmail.com; johanna.m.beyer@gmail.com;
   pfister@seas.harvard.edu
RI chen, ying/HHS-8254-2022
OI Pfister, Hanspeter/0000-0002-3620-2582; Beyer,
   Johanna/0000-0002-3505-9171; Lin, Tica/0000-0002-2860-0871; Yang,
   Yalong/0000-0001-9414-9911; Chiappalupi, Daniele/0000-0002-1026-4056
FU NSF
FX No Statement Available
CR Ahn J., 1984, CARTOGRAPHICA, V21, P101, DOI [10.1142/S0218001487000096, DOI 10.1142/S0218001487000096]
   Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Bekos MA, 2019, COMPUT GRAPH FORUM, V38, P833, DOI 10.1111/cgf.13729
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Chen CG, 2019, IEEE INT CONF ROBOT, P6015, DOI [10.1109/ICRA.2019.8794134, 10.1109/icra.2019.8794134]
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Dewey Daniel, 2014, 2014 AAAI SPRING S S
   Fender A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173843
   Fender A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P611, DOI 10.1145/3126594.3126621
   Gebhardt C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P197, DOI 10.1145/3332165.3347933
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Haarnoja Tuomas, 2018, P MACHINE LEARNING R, V80
   Hegde S, 2020, IEEE WINT CONF APPL, P1110, DOI 10.1109/WACV45572.2020.9093587
   Huang GP, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445283
   Jaakkola T., 1994, Adv Neural Inf Process Syst, V7, P345
   Juliani A, 2020, Arxiv, DOI [arXiv:1809.02627, 10.48550/ARXIV.1809.02627]
   Kiran BR, 2022, IEEE T INTELL TRANSP, V23, P4909, DOI 10.1109/TITS.2021.3054625
   Köppel T, 2021, IEEE PAC VIS SYMP, P91, DOI 10.1109/PacificVis52677.2021.00020
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lillicrap T.P., 2015, Continuous control with deep reinforcement learning
   Lin TC, 2022, Arxiv, DOI [arXiv:2209.00202, 10.48550/arXiv.2209.00202]
   Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511
   Lin Tica, 2021, P 2021 CHI C HUMAN F, DOI [DOI 10.1145/3411764.3445649, 10.1145/3411764.3445649]
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Liu RR, 2021, ROBOTICS, V10, DOI 10.3390/robotics10010022
   Madsen JB, 2016, IEEE T VIS COMPUT GR, V22, P1415, DOI 10.1109/TVCG.2016.2518318
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   N. O. Service, What is lidar?
   Narvekar S, 2020, Arxiv, DOI arXiv:2003.04960
   Nuernberger B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1233, DOI 10.1145/2858036.2858250
   Ouyang Long, 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI 10.1177/01454455830072006
   Paszke A., Pytorch: An imperative style, high-performance deep learning library
   Qian X, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517665
   Rakholia N, 2018, IEEE IMAGE PROC, P604, DOI 10.1109/ICIP.2018.8451052
   Esmaeeli MS, 2022, Arxiv, DOI arXiv:2209.08480
   Schulman J, 2018, Arxiv, DOI [arXiv:1506.02438, 10.48550/arXiv.1506.02438]
   Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]
   Shao K, 2019, Arxiv, DOI [arXiv:1912.10944, 10.48550/arXiv.1912.10944]
   SportVU, Papers with code-nba sportvu dataset
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tahara T, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P249, DOI 10.1109/ISMAR-Adjunct51615.2020.00072
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tong Wai, 2023, IEEE Trans Vis Comput Graph, V29, P418, DOI 10.1109/TVCG.2022.3209386
   Vemula A, 2018, IEEE INT CONF ROBOT, P4601
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yifei Cheng, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P282, DOI 10.1145/3472749.3474750
   Yu Fan Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P285, DOI 10.1109/ICRA.2017.7989037
   Zhou MY, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2389, DOI 10.1145/3447548.3467279
   Zhu YK, 2017, INT CONF ACOUST SPEE, P5335, DOI 10.1109/ICASSP.2017.7953175
NR 58
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1347
EP 1357
DI 10.1109/TVCG.2023.3326568
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500134
PM 37871050
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Holder, E
   Bearfield, CX
AF Holder, Eli
   Bearfield, Cindy Xiong
TI Polarizing Political Polls: How Visualization Design Choices Can Shape
   Public Opinion and Increase Political Polarization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Political Polarization; Public Opinion; Social Categorization; Survey
   Data; Social Influence; Attitude Change
ID DECISION-MAKING; COMMUNICATION; AMERICANS; JUDGMENT; IMPACT; PARTY
AB While we typically focus on data visualization as a tool for facilitating cognitive tasks (e.g. learning facts, making decisions), we know relatively little about their second-order impacts on our opinions, attitudes, and values. For example, could design or framing choices interact with viewers' social cognitive biases in ways that promote political polarization? When reporting on U.S. attitudes toward public policies, it is popular to highlight the gap between Democrats and Republicans (e.g. with blue vs red connected dot plots). But these charts may encourage social-normative conformity, influencing viewers' attitudes to match the divided opinions shown in the visualization. We conducted three experiments examining visualization framing in the context of social conformity and polarization. Crowdworkers viewed charts showing simulated polling results for public policy proposals. We varied framing (aggregating data as non-partisan "All US Adults," or partisan "Democrat" / "Republican") and the visualized groups' support levels. Participants then reported their own support for each policy. We found that participants' attitudes biased significantly toward the group attitudes shown in the stimuli and this can increase inter-party attitude divergence. These results demonstrate that data visualizations can induce social conformity and accelerate political polarization. Choosing to visualize partisan divisions can divide us further.
C1 [Holder, Eli] 3iap, New York, NY 10065 USA.
   [Bearfield, Cindy Xiong] Georgia Tech, Atlanta, GA USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Holder, E (corresponding author), 3iap, New York, NY 10065 USA.
EM eli@3iap.com; cindy.xiong@cs.umass.edu
FU NSF
FX No Statement Available
CR Abramowitz A., 2011, The Disappearing Center: Engaged Citizens, Polarization, and American Democracy
   Agley J, 2022, BEHAV RES METHODS, V54, P885, DOI 10.3758/s13428-021-01665-8
   Ahler DJ, 2018, J POLIT, V80, P964, DOI 10.1086/697253
   Allcott H, 2010, SCIENCE, V327, P1204, DOI 10.1126/science.1180775
   [Anonymous], 2012, A First Look at Communication Theory
   Atske S., 2019, Partisan antipathy: More intense, more personal
   Baekgaard M, 2019, BRIT J POLIT SCI, V49, P1117, DOI 10.1017/S0007123417000084
   Balietti S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2112552118
   BOCHNER S, 1966, J PERS SOC PSYCHOL, V4, P614, DOI 10.1037/h0021192
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Boukouras A, 2023, EUR J POLIT ECON, V78, DOI 10.1016/j.ejpoleco.2023.102383
   Burger JM, 2004, PERS SOC PSYCHOL B, V30, P35, DOI 10.1177/0146167203258838
   Cialdini R.B., 2006, Social Influence, V1, P3, DOI [10.1080/15534510500181459, DOI 10.1080/15534510500181459]
   Clifford S, 2021, AM POLIT SCI REV, V115, P1048, DOI 10.1017/S0003055421000241
   Cohen GL, 2003, J PERS SOC PSYCHOL, V85, P808, DOI 10.1037/0022-3514.85.5.808
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cosmides L, 1996, COGNITION, V58, P1, DOI 10.1016/0010-0277(95)00664-8
   Cwir D, 2011, J EXP SOC PSYCHOL, V47, P661, DOI 10.1016/j.jesp.2011.01.009
   DeSilver Drew, 2022, POLARIZATION TODAYS
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   DIgnazio C, 2020, STRONG IDEAS SERIES, P1
   DiMaggio P, 1996, AM J SOCIOL, V102, P690, DOI 10.1086/230995
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Druckman JN, 2021, NAT HUM BEHAV, V5, DOI 10.1038/s41562-020-01012-5
   Federico C.M., 2021, The Psychology of Political Polarization, P17
   Finkel EJ, 2020, SCIENCE, V370, P533, DOI 10.1126/science.abe1715
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Furrer RA, 2023, COGN RES, V8, DOI 10.1186/s41235-023-00465-2
   Gaba A., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1211
   Goldstein NJ, 2008, J CONSUM RES, V35, P472, DOI 10.1086/586910
   Grosser J, 2010, AM J POLIT SCI, V54, P700, DOI 10.1111/j.1540-5907.2010.00455.x
   Guilbeault D, 2018, P NATL ACAD SCI USA, V115, P9714, DOI 10.1073/pnas.1722664115
   Heyer J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376887
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Holder Eli, 2023, IEEE Trans Vis Comput Graph, V29, P624, DOI 10.1109/TVCG.2022.3209377
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Iyengar S, 2015, AM J POLIT SCI, V59, P690, DOI 10.1111/ajps.12152
   Iyengar S, 2012, PUBLIC OPIN QUART, V76, P405, DOI 10.1093/poq/nfs038
   Jacobson GC, 2016, ANN AM ACAD POLIT SS, V667, P226, DOI 10.1177/0002716216658921
   Jhangiani D. R., 2022, The many varieties of conformity
   Jhangiani D. R., 2022, Ingroup favoritism and prejudice
   Jhangiani D. R., 2022, Initial attraction
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Karduni A, 2021, IEEE T VIS COMPUT GR, V27, P978, DOI 10.1109/TVCG.2020.3029412
   Kennedy R, 2020, POLIT SCI RES METH, V8, P614, DOI 10.1017/psrm.2020.6
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Klein E., 2020, Why were polarized
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lau IYM, 2001, SOC COGNITION, V19, P350, DOI 10.1521/soco.19.3.350.21467
   Ledgerwood A, 2007, J PERS SOC PSYCHOL, V93, P940, DOI 10.1037/0022-3514.93.6.940
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Lees J, 2020, NAT HUM BEHAV, V4, P279, DOI 10.1038/s41562-019-0766-4
   Leppert R., 2022, Americans continue to express mixed views about nuclear power
   Levendusky M, 2016, POLIT COMMUN, V33, P283, DOI 10.1080/10584609.2015.1038455
   Levendusky MS, 2018, J POLIT, V80, P59, DOI 10.1086/693987
   Levendusky Matthew S., 2009, PARTISAN SORT LIBERA
   Luo Y, 2021, CURR OPIN BEHAV SCI, V42, P22, DOI 10.1016/j.cobeha.2021.02.010
   Madson G., 2018, All the best polls agree with me: Bias in evaluation of political polling
   Malka A, 2010, SOC JUSTICE RES, V23, P156, DOI 10.1007/s11211-010-0114-3
   Mason L, 2015, AM J POLIT SCI, V59, P128, DOI 10.1111/ajps.12089
   MILGRAM S, 1969, J PERS SOC PSYCHOL, V13, P79, DOI 10.1037/h0028070
   Milkman KL, 2021, NATURE, V600, P478, DOI 10.1038/s41586-021-04128-4
   Mueller FF, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445218
   Nadeem R., 2022, As partisan hostility grows, signs of frustration with the twoparty system
   N├a┬rland TU., 2020, DATA VISUALIZATION S, P63, DOI DOI 10.1515/9789048543137-008
   Newburger E., 2022, IEEE Transactions on Visualization and Computer Graphics
   Padilla L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05353-1
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Prooijen J.-W. v., 2021, The Psychology of Political Polarization
   Reyna VF, 2008, MED DECIS MAKING, V28, P850, DOI 10.1177/0272989X08327066
   Rothschild D, 2014, RES POLITICS, V1, DOI 10.1177/2053168014547667
   Sánchez-Holgado P, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1064184
   Schaeffer K., 2021, PEW RES CTR
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Sherif M., 1961, SOCIAL JUDGMENT ASSI
   Sherif M., 1936, The psychology of social norms
   Sloman SA, 2022, TOP COGN SCI, V14, P31, DOI 10.1111/tops.12580
   Smith A., 2017, Americans' attitudes toward driverless vehicles
   Sulzberger A., 2023, Columbia Journalism Review
   TAJFEL H, 1971, EUR J SOC PSYCHOL, V1, P149, DOI 10.1002/ejsp.2420010202
   Wesslen R, 2019, COMPUT GRAPH FORUM, V38, P161, DOI 10.1111/cgf.13679
   Wilmer J. B., 2022, What's really wrong with bar graphs of mean values: variable and inaccurate communication of evidence on three key dimensions
   Xiong C., 2022, CHI C HUMAN FACTORS, P1
   Xiong Cindy, 2023, IEEE Trans Vis Comput Graph, V29, P493, DOI 10.1109/TVCG.2022.3209405
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
NR 88
TC 0
Z9 0
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1446
EP 1456
DI 10.1109/TVCG.2023.3326512
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500021
PM 37871081
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Jeon, H
   Quadri, GJ
   Lee, H
   Rosen, P
   Szafir, DA
   Seo, J
AF Jeon, Hyeon
   Quadri, Ghulam Jilani
   Lee, Hyunwook
   Rosen, Paul
   Szafir, Danielle Albers
   Seo, Jinwook
TI : A Cluster Ambiguity Measure for Estimating Perceptual Variability in
   Visual Clustering&lt;italic/&gt;
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Reliability; Benchmark testing; Data
   analysis; Complexity theory; Clustering algorithms; Cluster;
   scatterplot; perception; cluster analysis; cluster ambiguity; visual
   quality measure
ID INDIVIDUAL-DIFFERENCES; DIMENSIONALITY REDUCTION; QUALITY METRICS;
   VISUALIZATION; GOODNESS; FIT
AB Visual clustering is a common perceptual task in scatterplots that supports diverse analytics tasks (e.g., cluster identification). However, even with the same scatterplot, the ways of perceiving clusters (i.e., conducting visual clustering) can differ due to the differences among individuals and ambiguous cluster boundaries. Although such perceptual variability casts doubt on the reliability of data analysis based on visual clustering, we lack a systematic way to efficiently assess this variability. In this research, we study perceptual variability in conducting visual clustering, which we call Cluster Ambiguity. To this end, we introduce CLAMS, a data-driven visual quality measure for automatically predicting cluster ambiguity in monochrome scatterplots. We first conduct a qualitative study to identify key factors that affect the visual separation of clusters (e.g., proximity or size difference between clusters). Based on study findings, we deploy a regression module that estimates the human-judged separability of two clusters. Then, CLAMS predicts cluster ambiguity by analyzing the aggregated results of all pairwise separability between clusters that are generated by the module. CLAMS outperforms widely-used clustering techniques in predicting ground truth cluster ambiguity. Meanwhile, CLAMS exhibits performance on par with human annotators. We conclude our work by presenting two applications for optimizing and benchmarking data mining techniques using CLAMS. The interactive demo of CLAMS is available at clusterambiguity.dev.
C1 [Jeon, Hyeon; Seo, Jinwook] Seoul Natl Univ, Seoul, South Korea.
   [Quadri, Ghulam Jilani; Szafir, Danielle Albers] Univ N Carolina, Chapel Hill, NC USA.
   [Lee, Hyunwook] UNIST, Ulsan, South Korea.
   [Rosen, Paul] Univ Utah, Salt Lake City, UT USA.
C3 Seoul National University (SNU); University of North Carolina;
   University of North Carolina Chapel Hill; Ulsan National Institute of
   Science & Technology (UNIST); Utah System of Higher Education;
   University of Utah
RP Jeon, H (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM hj@hcil.snu.ac.kr; jiquad@cs.unc.edu; gusdnr0916@unist.ac.kr;
   prosen@sci.utah.edu; danielle.szafir@cs.unc.edu; jseo@snu.ac.kr
RI Rosen, Paul/GXM-8609-2022
OI Rosen, Paul/0000-0002-0873-9518
FU NAVER Corporation (Cloud Data Box)
FX No Statement Available
CR Abbas M., 2021, Clustrank: a visual quality measure trained on perceptual data for sorting scatterplots by cluster patterns
   Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Ashby F. G, 1993, Advances in psychology, V99, P369, DOI [10.1016/S0166-4115(08)62778-82, DOI 10.1016/S0166-4115(08)62778-82, DOI 10.1016/S0166-4115(08)62778-8, 10.1016/S0166-4115(08)62778-8]
   Aupetit M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P141, DOI [10.1109/visual.2019.8933620, 10.1109/VISUAL.2019.8933620]
   Aupetit M, 2016, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2016.7465244
   Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Calinski Tadeusz, 1974, Communications in Statistics, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Cameron AC, 1997, J ECONOMETRICS, V77, P329
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Davis R., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2022.32264632
   Desjardins M, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P361
   Dillon A, 1996, INT J HUM-COMPUT ST, V45, P619, DOI 10.1006/ijhc.1996.0071
   Etemadpour Ronak, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P233
   Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617
   Feurer M, 2019, SPRING SER CHALLENGE, P113, DOI 10.1007/978-3-030-05318-5_6
   Fu C, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P176, DOI 10.1145/3292500.3330834
   Fujiwara T, 2022, Arxiv, DOI arXiv:2206.13891
   GOODMAN LA, 1961, ANN MATH STAT, V32, P148, DOI 10.1214/aoms/1177705148
   Halkidi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P187, DOI 10.1109/ICDM.2001.989517
   Hartwig S, 2024, Arxiv, DOI arXiv:2304.14185
   He X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106622
   Hoskin R, 2019, COGNITION, V182, P127, DOI 10.1016/j.cognition.2018.08.022
   Huang J, 2010, J VISION, V10, DOI 10.1167/10.2.24
   Jeon H., 2022, arXiv
   Jeon H., 2022, ARXIV
   Jeon H, 2022, IEEE VIS CONF, P80, DOI 10.1109/VIS54862.2022.00025
   Jeon H, 2022, IEEE T VIS COMPUT GR, V28, P551, DOI 10.1109/TVCG.2021.3114833
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lee J., 2007, Nonlinear Dimensionality Reduction, DOI [10.1007/978-0-387-39351-3 7, DOI 10.1007/978-0-387-39351-37]
   Lee JA, 2007, INFORM SCI STAT, P1, DOI 10.1007/978-0-387-39351-3
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Liu R, 2018, INFORM SCIENCES, V450, P200, DOI 10.1016/j.ins.2018.03.031
   Liu Y., 2010, 2010 IEEE 10th International Conference on Data Mining ICDM, P911, DOI 10.1109/icdm.2010.35
   Liu ZL, 2020, COMPUT GRAPH FORUM, V39, P693, DOI 10.1111/cgf.14033
   Lu M, 2020, IEEE T VIS COMPUT GR, V26, P770, DOI 10.1109/TVCG.2019.2934811
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   MAASSEN H, 1988, PHYS REV LETT, V60, P1103, DOI 10.1103/PhysRevLett.60.1103
   McInnes L., 2020, Umap: Uniform manifold approximation and projection for dimension reduction, V6, P7
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Milllner D., 2011, arXiv preprint, V8, P9
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Narayan A, 2021, NAT BIOTECHNOL, V39, P765, DOI 10.1038/s41587-020-00801-7
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Ons B, 2011, J EXP PSYCHOL HUMAN, V37, P422, DOI 10.1037/a0020405
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pelleg D., 2000, P 17 INT C MACH LEAR, V1, P727
   Pinna B., 2010, GESTALT THEORY, P11
   Prion S, 2014, CLIN SIMUL NURS, V10, P535, DOI 10.1016/j.ecns.2014.07.005
   Quadri G. J., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.31898832
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Rezaei M, 2016, IEEE T KNOWL DATA EN, V28, P2173, DOI 10.1109/TKDE.2016.2551240
   Rosenberg A., 2007, P 2007 JOINT C EMPIR, P410
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sadahiro Y., 1997, CARTOGRAPHICA, V34, P49, DOI [10.3138/Y308-2422-8615-1233, DOI 10.3138/Y308-2422-8615-1233]
   Sanchez-Rico M., 2020, EUROPEAN C METHODOLO
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Shannon W, 2003, PHARMACOGENOMICS, V4, P41, DOI 10.1517/phgs.4.1.41.22581
   Shi JL, 2010, COMPUT BIOL MED, V40, P723, DOI 10.1016/j.compbiomed.2010.06.007
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, P8
   Steinley D, 2004, PSYCHOL METHODS, V9, P386, DOI 10.1037/1082-989X.9.3.386
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Dang TN, 2014, IEEE T VIS COMPUT GR, V20, P1624, DOI 10.1109/TVCG.2014.2346572
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J, 2006, NEURAL NETWORKS, V19, P889, DOI 10.1016/j.neunet.2006.05.014
   Vinh NX, 2010, J MACH LEARN RES, V11, P2837
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Woolhouse LS, 2000, EUR J PERSONALITY, V14, P157, DOI 10.1002/(SICI)1099-0984(200003/04)14:2<157::AID-PER366>3.3.CO;2-C
   Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xiong H, 2014, CH CRC DATA MIN KNOW, P571
   Zaman J, 2021, PSYCHON B REV, V28, P1, DOI 10.3758/s13423-020-01780-1
   Zhang T., 1996, ACM sigmod record, V25, P103, DOI 10.1145/235968.233324
   Ziemkiewicz C, 2009, COMPUT GRAPH FORUM, V28, P911, DOI 10.1111/j.1467-8659.2009.01442.x
NR 86
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 770
EP 780
DI 10.1109/TVCG.2023.3327201
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500012
OA hybrid
DA 2024-08-05
ER

PT J
AU Nowak, S
   Bartram, L
AF Nowak, Stan
   Bartram, Lyn
TI Designing for Ambiguity in Visual Analytics: Lessons from Risk
   Assessment and Prediction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Forecasting; Hazards; Data visualization; Risk
   management; Uncertainty; Task analysis; Complex Systems; Risk
   Assessment; Sensemaking; Visualization Design
ID VISUALIZATION; UNCERTAINTY; TYPOLOGY; ELEMENTS; MODEL
AB Ambiguity is pervasive in the complex sensemaking domains of risk assessment and prediction but there remains little research on how to design visual analytics tools to accommodate it. We report on findings from a qualitative study based on a conceptual framework of sensemaking processes to investigate how both new visual analytics designs and existing tools, primarily data tables, support the cognitive work demanded in avalanche forecasting. While both systems yielded similar analytic outcomes we observed differences in ambiguous sensemaking and the analytic actions either afforded. Our findings challenge conventional visualization design guidance in both perceptual and interaction design, highlighting the need for data interfaces that encourage reflection, provoke alternative interpretations, and support the inherently ambiguous nature of sensemaking in this critical application. We review how different visual and interactive forms support or impede analytic processes and introduce "gisting" as a significant yet unexplored analytic action for visual analytics research. We conclude with design implications for enabling ambiguity in visual analytics tools to scaffold sensemaking in risk assessment.
C1 [Nowak, Stan; Bartram, Lyn] Simon Fraser Univ, Burnaby, BC, Canada.
C3 Simon Fraser University
RP Nowak, S (corresponding author), Simon Fraser Univ, Burnaby, BC, Canada.
EM snowak@sfu.ca; lyn@sfu.ca
FU Mitacs
FX No Statement Available
CR Adams L., 2005, A systems approach to human factors and expert decisionmaking within the Canadian avalanche phenomena, P2
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   [Anonymous], 2005, INT C INT AN MCLEAN
   [Anonymous], 2013, EUROGRAPHICS STARS, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bertini E, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P206, DOI 10.1109/VIS47514.2020.00048
   Beven K. J., 2018, Natural Hazards and Earth System Sciences,, DOI [10. 5194/nhess-2017-250 2, DOI 10.5194/NHESS-2017-2502]
   Boukhelifa N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3645, DOI 10.1145/3025453.3025738
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Canadian Avalanche Association, 1995, Observation guidelines and recording standards for weather, snowpack and avalanches, P2
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Crandall B., 2006, Working Minds: A Practitioner's Guide to Cognitive Task Analysis, P4
   Elfenbein A., 2018, The Gist of Reading, V2, P5
   Gamino JF, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00188
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Grabowski Franciszek, 2008, 2008 Conference on Human System Interactions, P570, DOI 10.1109/HSI.2008.4581503
   Haegeli P., 2018, Alpine Club of Canada's State of the Mountains Report, V1, P2
   Haegeli P., 2014, Proceedings of the 2014 International Snow Science Workshop, P910
   Heer J, 2007, IEEE CONF VIS ANAL, P171, DOI 10.1109/VAST.2007.4389011
   Hoffman RR, 2017, MINDING THE WEATHER: HOW EXPERT FORECASTERS THINK, P1
   Hollnagel E., 2005, Joint Cognitive Systems: Foundations of Cognitive Systems Engineering, P2
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Johansen IL, 2015, SAFETY SCI, V80, P243, DOI 10.1016/j.ssci.2015.07.028
   Ju Y, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00738
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kirsh D, 2010, AI SOC, V25, P441, DOI 10.1007/s00146-010-0272-8
   Klein G, 1999, HUM FAC ERG SOC P, P133
   Klein G., 2007, Expertise Out of Context, P118
   Klein G., 2005, COGN TECHNOL WORK, V7, P14, DOI DOI 10.1007/S10111-004-0166-Y
   Klein G., 2018, Local Applications of the Ecological Approach to Human-Machine Systems, P324
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Klein G, 2011, INFORMED BY KNOWLEDGE: EXPERT PERFORMANCE IN COMPLEX SITUATIONS, P235
   LACHAPELLE ER, 1980, J GLACIOL, V26, P75, DOI 10.3189/S0022143000010601
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   MacEachren A.M., 2015, EuroVis Workshop on Visual Analytics (EuroVA), DOI DOI 10.2312/EUROVA.20151104
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI DOI 10.1559/1523040054738936
   Maitlis S, 2014, ACAD MANAG ANN, V8, P57, DOI 10.1080/19416520.2014.873177
   McClung DM, 2002, NAT HAZARDS, V26, P111, DOI 10.1023/A:1015665432221
   McClung DM, 2002, NAT HAZARDS, V26, P131, DOI 10.1023/A:1015604600361
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Munzner T., 2014, Visualization analysis and design, P3
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Nowak S., 2022, Graphics Interface, V1
   Nowak S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P81, DOI 10.1109/VIS47514.2020.00023
   Panagiotidou G, 2022, IEEE T VIS COMPUT GR, V28, P4389, DOI 10.1109/TVCG.2021.3088339
   Pliske R. M., 2004, Psychological investigations of competence in decision making, V40, P2
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Rind A, 2016, INFORM VISUAL, V15, P288, DOI 10.1177/1473871615621602
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Saraiya P, 2006, IEEE T VIS COMPUT GR, V12, P1511, DOI 10.1109/TVCG.2006.85
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shrinivasan YB, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1237
   Smith P. J., 2017, Cognitive Systems Engineering: The Future for a Changing World, P2
   Smuc M, 2009, IEEE COMPUT GRAPH, V29, P29, DOI 10.1109/MCG.2009.53
   Statham G., 2010, INT SNOW SCI WORKSHO, P7
   Statham G., 2018, INT SNOW SCI WORKSHO, P1491
   Statham G, 2018, NAT HAZARDS, V90, P663, DOI 10.1007/s11069-017-3070-5
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Thomson J, 2005, P SOC PHOTO-OPT INS, V5669, P146, DOI 10.1117/12.587254
   Walny J, 2018, IEEE T VIS COMPUT GR, V24, P770, DOI 10.1109/TVCG.2017.2745958
   Ware C., 2022, Visual Thinking for Information Design, P2
   Weick Karl E., 1995, Sensemaking in organizations
   Zuk T, 2007, LECT NOTES COMPUT SC, V4569, P164
NR 66
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 924
EP 933
DI 10.1109/TVCG.2023.3326571
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500023
PM 37871061
DA 2024-08-05
ER

PT J
AU Falk, M
   Tobiasson, V
   Bock, A
   Hansen, C
   Ynnerman, A
AF Falk, Martin
   Tobiasson, Victor
   Bock, Alexander
   Hansen, Charles
   Ynnerman, Anders
TI A Visual Environment for Data Driven Protein Modeling and Validation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Proteins; Measurement; Visualization; Biological system modeling; Image
   reconstruction; Analytical models; Three-dimensional displays; Molecular
   visualization; cryo-EM; model validation; verification
ID CRYO-EM; VISUALIZATION; MICROSCOPY
AB In structural biology, validation and verification of new atomic models are crucial and necessary steps which limit the production of reliable molecular models for publications and databases. An atomic model is the result of meticulous modeling and matching and is evaluated using a variety of metrics that provide clues to improve and refine the model so it fits our understanding of molecules and physical constraints. In cryo electron microscopy (cryo-EM) the validation is also part of an iterative modeling process in which there is a need to judge the quality of the model during the creation phase. A shortcoming is that the process and results of the validation are rarely communicated using visual metaphors. This work presents a visual framework for molecular validation. The framework was developed in close collaboration with domain experts in a participatory design process. Its core is a novel visual representation based on 2D heatmaps that shows all available validation metrics in a linear fashion, presenting a global overview of the atomic model and provide domain experts with interactive analysis tools. Additional information stemming from the underlying data, such as a variety of local quality measures, is used to guide the user's attention toward regions of higher relevance. Linked with the heatmap is a three-dimensional molecular visualization providing the spatial context of the structures and chosen metrics. Additional views of statistical properties of the structure are included in the visual framework. We demonstrate the utility of the framework and its visual guidance with examples from cryo-EM.
C1 [Falk, Martin; Bock, Alexander; Hansen, Charles; Ynnerman, Anders] Linkoping Univ, S-58183 Linkoping, Sweden.
   [Falk, Martin; Bock, Alexander; Ynnerman, Anders] Swedish Esci Res Ctr SeRC, S-16429 Kista, Sweden.
   [Tobiasson, Victor] Stockholm Univ, Dept Biochem & Biophys, Sci Life Lab, S-17165 Solna, Sweden.
   [Hansen, Charles] Univ Utah, Kahlert Sch Comp, Salt Lake City, UT 84112 USA.
C3 Linkoping University; Stockholm University; Utah System of Higher
   Education; University of Utah
RP Falk, M (corresponding author), Linkoping Univ, S-58183 Linkoping, Sweden.
EM martin.falk@liu.se; victor.tobiasson@scilifelab.se;
   alexander.bock@liu.se; hansen@cs.utah.edu; anders.ynnerman@liu.se
RI Tobiasson, Victor/GRF-5270-2022
OI Tobiasson, Victor/0000-0001-8920-017X; Falk, Martin/0000-0003-1511-5006;
   Ynnerman, Anders/0000-0002-9466-9826; Bock,
   Alexander/0000-0002-2849-6146; Hansen, Charles/0000-0002-8480-2152
FU Excellence Center at Link#x00F6; ping and Lund in Information
   Technology; Swedish e-Science Research Centre (SeRC); Swedish Research
   Council (VR) [2015-05462]; NIH [R01EB023947, R01EB031872]; Knut and
   Alice Wallenberg Foundation [KAW 2019.0024]
FX No Statement Available
CR Bai XC, 2015, TRENDS BIOCHEM SCI, V40, P49, DOI 10.1016/j.tibs.2014.10.005
   Barad BA, 2015, NAT METHODS, V12, P943, DOI [10.1038/NMETH.3541, 10.1038/nmeth.3541]
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Bernstein HJ, 2000, TRENDS BIOCHEM SCI, V25, P453, DOI 10.1016/S0968-0004(00)01606-6
   Boerema AP, 2018, NAT PLANTS, V4, P212, DOI 10.1038/s41477-018-0129-6
   Burnley T, 2017, ACTA CRYSTALLOGR D, V73, P469, DOI 10.1107/S2059798317007859
   Carroni M, 2016, METHODS, V95, P78, DOI 10.1016/j.ymeth.2015.11.023
   Chen VB, 2010, ACTA CRYSTALLOGR D, V66, P12, DOI 10.1107/S0907444909042073
   Chen VB, 2009, PROTEIN SCI, V18, P2403, DOI 10.1002/pro.250
   Cheng Y, 2015, CELL, V161, P438, DOI 10.1016/j.cell.2015.03.050
   Cianfrocco MA., 2017, P PRACTICE EXPERIENC, DOI DOI 10.1145/3093338.3093390
   de la Rosa-Trevín JM, 2016, J STRUCT BIOL, V195, P93, DOI 10.1016/j.jsb.2016.04.010
   DeLano W.L., 2002, CCP4 Newsl Protein Crystallogr, V40, P82
   Desai N, 2017, SCIENCE, V355, P528, DOI 10.1126/science.aal2415
   Emsley P, 2010, ACTA CRYSTALLOGR D, V66, P486, DOI 10.1107/S0907444910007493
   Fernandez NF, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.151
   GehIenbor N., 2005, Information Visualization, V4, P164, DOI 10.1057/palgrave.ivs.9500094
   Gupta M, 2021, bioRxiv, DOI [10.1101/2021.05.10.443524, 10.1101/2021.05.10.443524, DOI 10.1101/2021.05.10.443524, 10.1101/2021.05.10.443524v1, DOI 10.1101/2021.05.10.443524V1]
   Herráez A, 2006, BIOCHEM MOL BIOL EDU, V34, P255, DOI 10.1002/bmb.2006.494034042644
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kimanius D, 2016, ELIFE, V5, DOI 10.7554/eLife.18722
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Kucukelbir A, 2014, NAT METHODS, V11, P63, DOI [10.1038/NMETH.2727, 10.1038/nmeth.2727]
   Kühlbrandt W, 2014, SCIENCE, V343, P1443, DOI 10.1126/science.1251652
   Lawson CL, 2021, NAT METHODS, V18, P156, DOI 10.1038/s41592-020-01051-w
   Lawson CL, 2016, NUCLEIC ACIDS RES, V44, pD396, DOI 10.1093/nar/gkv1126
   Liebschner D, 2019, ACTA CRYSTALLOGR D, V75, P861, DOI 10.1107/S2059798319011471
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   Pettersen EF, 2021, PROTEIN SCI, V30, P70, DOI 10.1002/pro.3943
   Prisant MG, 2020, PROTEIN SCI, V29, P315, DOI 10.1002/pro.3786
   Punjani A, 2017, NAT METHODS, V14, P290, DOI [10.1038/NMETH.4169, 10.1038/nmeth.4169]
   RAMACHANDRAN GN, 1963, J MOL BIOL, V7, P95, DOI 10.1016/S0022-2836(63)80023-6
   Ramírez-Aportela E, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20295-w
   Reina G., 2005, P EUROGRAPHICS IEEE, P177
   Scheres SHW, 2012, J STRUCT BIOL, V180, P519, DOI 10.1016/j.jsb.2012.09.006
   Skanberg R, 2018, WORKSH MOL GRAPH VIS, P19, DOI [DOI 10.2312/MOLVA.20181102, 10.2312/molva.20181102]
   Thompson RF, 2016, METHODS, V100, P3, DOI 10.1016/j.ymeth.2016.02.017
   Thorvaldsdóttir H, 2013, BRIEF BIOINFORM, V14, P178, DOI 10.1093/bib/bbs017
   Tobiasson V, 2020, ELIFE, V9, DOI 10.7554/eLife.59264
   van Heel M, 2005, J STRUCT BIOL, V151, P250, DOI 10.1016/j.jsb.2005.05.009
   Yamashita K, 2021, ACTA CRYSTALLOGR D, V77, P1282, DOI 10.1107/S2059798321009475
NR 43
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5063
EP 5073
DI 10.1109/TVCG.2023.3286582
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400069
PM 37327104
OA Green Published
DA 2024-08-05
ER

PT J
AU Finke, L
   Weitz, E
AF Finke, Lennart
   Weitz, Edmund
TI A Phenomenological Approach to Interactive Knot Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational topology; knot diagrams; user interfaces
ID CLASSIFICATION
AB Knot diagrams are among the most common visual tools in topology. Computer programs now make it possible to draw, manipulate and render them digitally, which proves to be useful in knot theory teaching and research. Still, an openly available tool to manipulate knot diagrams in a real-time, interactive way is yet to be developed. We introduce a method of operating on the geometry of the knot diagram itself without any underlying three-dimensional structure that can underpin such an application. This allows us to directly interact with vector graphics knot diagrams while at the same time computing knot invariants in ways proposed by previous work. An implementation of this method is provided.
C1 [Finke, Lennart] Georg August Univ Gottingen, D-37073 Gottingen, Germany.
   [Weitz, Edmund] Hsch Angew Wissensch Hamburg, D-20999 Hamburg, Germany.
C3 University of Gottingen; Hochschule Angewandte Wissenschaft Hamburg
RP Finke, L (corresponding author), Georg August Univ Gottingen, D-37073 Gottingen, Germany.
EM l.finke@stud.uni-goettingen.de; edmund.weitz@haw-hamburg.de
OI Weitz, Edmund/0000-0003-2368-6132; Finke, Lennart/0009-0003-6908-314X
CR Alam MJ, 2014, LECT NOTES COMPUT SC, V8392, P144
   Alexander JW, 1928, T AM MATH SOC, V30, P275, DOI 10.2307/1989123
   Bar-Natan D., 2005, KNOT ATLAS
   Brasher R, 2013, BIOCHEM SOC T, V41, P606, DOI 10.1042/BST20120278
   Catmull EE, 1974, COMPUT AIDED GEOM D, P317, DOI DOI 10.1016/B978-0-12-079050-0.50020-5
   Costagliola G., 2016, J. Vis. Lang. Sentient Syst., V2, P16
   Culler M., 2017, SnapPy, a com- puter program for studying the geometry and topology of 3-manifolds
   DOWKER CH, 1983, TOPOL APPL, V16, P19, DOI 10.1016/0166-8641(83)90004-4
   Eades P, 2023, Arxiv, DOI arXiv:2309.02852
   Horner William George, 1819, Philos. Trans. Roy. Soc. London, V109, P308
   Horowitz J., 2013, Knot identification tool
   Kindermann P., 2017, P INT S GRAPH DRAW N, P113
   Lackenby M, 2015, ANN MATH, V182, P491, DOI 10.4007/annals.2015.182.2.3
   Lehniand J., 2011, Paper.js
   Liu H, 2021, IEEE T VIS COMPUT GR, V27, P593, DOI 10.1109/TVCG.2020.3028893
   Livingston C., 2023, Knotinfo: Table of knot invariants
   Lopez R., 2003, The Alexander polynomial, coloring, and determinants of knots
   Miller K., 2022, Knotfolio
   PERKO KA, 1974, P AM MATH SOC, V45, P262, DOI 10.2307/2040074
   Reidemeister K., 1927, Abh. Math. Sem. Univ. Hamburg, V5, P24
   Rolfsen D., 2003, Knots and links
   Scharein RG, 2002, MATH VISUAL, P277
   Seed C., 2016, Knotkit
   Simonetto P, 2016, IEEE T VIS COMPUT GR, V22, P678, DOI 10.1109/TVCG.2015.2467992
   Stacey A., 2011, spath3
   Swenton F., 2021, Knot-like objects
   TAMASSIA R, 1987, SIAM J COMPUT, V16, P421, DOI 10.1137/0216030
   Vandermonde A.-T., 1771, Memoires de l'Academie Royale des Sci, V2, P566
   Yu C, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3439429
   Zhang H, 2012, IEEE T VIS COMPUT GR, V18, P2051, DOI 10.1109/TVCG.2012.242
   Zibrowius C., 2023, kht++, a program for computing Khovanov invariants for links and tangles
NR 31
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5901
EP 5907
DI 10.1109/TVCG.2024.3405369
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400099
PM 38787659
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ibarrola, F
   Lawton, T
   Grace, K
AF Ibarrola, Francisco
   Lawton, Tomas
   Grace, Kazjon
TI A Collaborative, Interactive and Context-Aware Drawing Agent for
   Co-Creative Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Collaboration; Computational modeling; Task analysis; Artificial
   intelligence; Creativity; Refining; Real-time systems; Human-computer
   interaction; computational creativity; image generation
AB Recent advances in text-conditioned generative models have provided us with neural networks capable of creating images of astonishing quality, be they realistic, abstract, or even creative. These models have in common that (more or less explicitly) they all aim to produce a high-quality one-off output given certain conditions, and in that they are not well suited for a creative collaboration framework. Drawing on theories from cognitive science that model how professional designers and artists think, we argue how this setting differs from the former and introduce CICADA: a Collaborative, Interactive Context-Aware Drawing Agent. CICADA uses a vector-based synthesis-by-optimisation method to take a partial sketch (such as might be provided by a user) and develop it towards a goal by adding and/or sensibly modifying traces. Given that this topic has been scarcely explored, we also introduce a way to evaluate desired characteristics of a model in this context by means of proposing a diversity measure. CICADA is shown to produce sketches of quality comparable to a human user's, enhanced diversity and most importantly to be able to cope with change by continuing the sketch minding the user's contributions in a flexible manner.
C1 [Ibarrola, Francisco; Lawton, Tomas; Grace, Kazjon] Univ Sydney, Sch Architecture Design & Planning, Camperdown, NSW 2006, Australia.
C3 University of Sydney
RP Ibarrola, F (corresponding author), Univ Sydney, Sch Architecture Design & Planning, Camperdown, NSW 2006, Australia.
EM francisco.ibarrola@sydney.edu.au; tlaw8603@uni.sydney.edu.au;
   kazjon.grace@sydney.edu.au
OI Lawton, Tomas/0000-0002-5079-7885; Ibarrola,
   Francisco/0000-0003-1146-7071
FU Australian Research Council [DP200101059]; University of Sydney;
   Australian Research Council [DP200101059] Funding Source: Australian
   Research Council
FX Thiswork was supported by Australian Research Council under Grant
   DP200101059 and University of Sydney (in particular the School of
   Architecture, Designand Planning) for their financial support of this
   project. Recommended foracceptance by L. Wei.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   Aickin M, 1996, AM J PUBLIC HEALTH, V86, P726, DOI 10.2105/AJPH.86.5.726
   Amabile T. M., 2018, Creativity in context: Update to the social psychology of creativity
   [Anonymous], 2000, Des. Stud., DOI DOI 10.1016/S0142-694X(99)00034-4
   Avrahami O, 2022, PROC CVPR IEEE, P18187, DOI 10.1109/CVPR52688.2022.01767
   Boden M. A., 2004, CREATIVE MIND MYTHS, DOI DOI 10.4324/9780203508527
   Cha MY, 1998, ARTIFICIAL INTELLIGENCE IN DESIGN '98, P169
   Cohen H., 1995, Stanford Humanities Rev., V4, P141
   Colton Simon, 2020, Artificial Intelligence in Music, Sound, Art and Design. 9th International Conference, EvoMUSART 2020. Held as Part of EvoStar 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12103), P17, DOI 10.1007/978-3-030-43859-3_2
   Colton S., 2012, Computers and Creativity, P3
   Das Ayan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P632, DOI 10.1007/978-3-030-58574-7_38
   Davis Nicholas, 2013, 9 ART INT INT DIG EN, V9, P9, DOI [10.1609/aiide.v9i6.12603, DOI 10.1609/AIIDE.V9I6.12603]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dixon D, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P897
   Dorst K, 2015, DES THINK DES THEOR, P1, DOI 10.7551/mitpress/10096.001.0001
   Fan JE, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P556, DOI 10.1145/3325480.3326578
   Frans K, 2021, Arxiv, DOI arXiv:2106.14843
   Gero JS, 2004, DESIGN STUD, V25, P373, DOI 10.1016/j.destud.2003.10.010
   GERO JS, 1990, AI MAG, V11, P26
   Ghosh A, 2019, IEEE I CONF COMP VIS, P1171, DOI 10.1109/ICCV.2019.00126
   Goldschmidt G., 1991, Creativity Research Journal, V4, P123, DOI [DOI 10.1080/10400419109534381, 10.1080/10400419109534381]
   Grace K, 2015, INT J DES CREAT INNO, V3, P125, DOI 10.1080/21650349.2014.943295
   Ha D, 2017, Arxiv, DOI arXiv:1704.03477
   Hanin B, 2018, ADV NEUR IN, V31
   Hensel M, 2017, ADV NEUR IN, V30
   Ibarrola F., 2022, P INT C COMP CREAT, P8821
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jansson D. G.., 1991, DESIGN STUDIES, V12, P3, DOI [10.1016/0142-694X(91)90003-F, DOI 10.1016/0142-694X(91)90003-F, 10.1016/0142-694x(91)90003-f]
   Karimi P, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2018.2881736
   Lawton Tomas, 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P264, DOI 10.1145/3581641.3584095
   Lee YJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964922
   Li TM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417871
   Lin YY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376258
   Lu J, 2019, ICVISP 2019: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING, DOI 10.1145/3387168.3387178
   McCormack J., 2022, arXiv
   Nichol A, 2022, Arxiv, DOI arXiv:2112.10741
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Poon J, 1997, ARTIF INTELL ENG, V11, P319, DOI 10.1016/S0954-1810(96)00047-7
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, Hierarchical text-conditional image generation with clip latents, DOI 10.48550/arXiv.2204.06125
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Ritchie G, 2006, NEW GENERAT COMPUT, V24, P241, DOI 10.1007/BF03037334
   Saharia C, 2022, Arxiv, DOI [arXiv:2205.11487, DOI 10.48550/ARXIV.2205.11487]
   Schon D.A., 1992, DESIGN STUD, V13, P135, DOI [DOI 10.1016/0142-694X(92)90268-F, 10.1016/0142-694X(92)90268-F]
   SCHON DA, 1992, KNOWL-BASED SYST, V5, P3, DOI 10.1016/0950-7051(92)90020-G
   Shannon C. E., 2001, Bell Sys. Technical J, V5, P3, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, 10.1145/584091.584093]
   Wiggins GA, 2006, KNOWL-BASED SYST, V19, P449, DOI 10.1016/j.knosys.2006.04.009
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang L, 2023, Arxiv, DOI [arXiv:2302.05543, 10.48550/ARXIV.2302.05543]
NR 49
TC 1
Z9 1
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5525
EP 5537
DI 10.1109/TVCG.2023.3293853
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400018
PM 37432831
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Yang, H
   Li, J
   Chen, SM
AF Yang, Huan
   Li, Jie
   Chen, Siming
TI TopicRefiner: Coherence-Guided Steerable LDA for Visual Topic
   Enhancement
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human-in-the-loop; LDA; mixed initiative; topic modeling; visual
   analytics; latent dirichlet allocation
ID LATENT DIRICHLET ALLOCATION; ALGORITHMS
AB This article presents a new Human-steerable Topic Modeling (HSTM) technique. Unlike existing techniques commonly relying on matrix decomposition-based topic models, we extend LDA as the fundamental component for extracting topics. LDA's high popularity and technical characteristics, such as better topic quality and no need to cherry-pick terms to construct the document-term matrix, ensure better applicability. Our research revolves around two inherent limitations of LDA. First, the principle of LDA is complex. Its calculation process is stochastic and difficult to control. We thus give a weighting method to incorporate users' refinements into the Gibbs sampling to control LDA. Second, LDA often runs on a corpus with massive terms and documents, forming a vast search space for users to find semantically relevant or irrelevant objects. We thus design a visual editing framework based on the coherence metric, proven to be the most consistent with human perception in assessing topic quality, to guide users' interactive refinements. Cases on two open real-world datasets, participants' performance in a user study, and quantitative experiment results demonstrate the usability and effectiveness of the proposed technique.
C1 [Yang, Huan; Li, Jie] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.
   [Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
C3 Tianjin University; Fudan University
RP Li, J (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.
EM yanghuan@tju.edu.cn; jie.li@tju.edu.cn; simingchen3@gmail.com
RI Li, Jie/X-4832-2018
OI Li, Jie/0000-0001-6511-4090
FU National Natural Science Foundation of China [61972278, 62202105];
   Natural Science Foundation of Tianjin [20JCQNJC01620]; Shanghai
   Municipal Science and Technology General Program [21ZR1403300]; Sailing
   Program [21YF1402900]
FX No Statement Available
CR AlSumait L, 2009, LECT NOTES ARTIF INT, V5781, P67, DOI 10.1007/978-3-642-04180-8_22
   Andrzejewski David, 2009, Proc Int Conf Mach Learn, V382, P25
   Blei DM, 2004, ADV NEUR IN, V16, P17
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boyd-Graber J., 2014, Handbook of Mixed Membership Models and Their Applications, P225
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chaney A., 2021, P INT AAAI C WEB SOC, V6, P419, DOI 10.1609/icwsm.v6i1.14321
   Chang J. D., 2009, Advances in Neural Information Processing Systems 22, P288, DOI DOI 10.5555/2984093.2984126
   Chen S, 2020, IEEE T VIS COMPUT GR, V26, P2775, DOI 10.1109/TVCG.2019.2904069
   Chen Y, 2019, KNOWL-BASED SYST, V163, P1, DOI 10.1016/j.knosys.2018.08.011
   Chen YX, 2016, J IEEE I C DEVELOP L, P217, DOI 10.1109/DEVLRN.2016.7846822
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Chuang J., 2013, P 30 INT C MACH LEAR, P612
   Chuang J, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P74, DOI 10.1145/2254556.2254572
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   El-Assady M, 2020, IEEE T VIS COMPUT GR, V26, P1001, DOI 10.1109/TVCG.2019.2934654
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   El-Assady M, 2018, IEEE T VIS COMPUT GR, V24, P382, DOI 10.1109/TVCG.2017.2745080
   Ganesan A., 2015, P TEXT VIS WORKSH IU
   Glueck M, 2018, IEEE T VIS COMPUT GR, V24, P371, DOI 10.1109/TVCG.2017.2745118
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Hoque E, 2019, INFORM VISUAL, V18, P318, DOI 10.1177/1473871618757228
   Hu YN, 2014, MACH LEARN, V95, P423, DOI 10.1007/s10994-013-5413-0
   Jänicke S, 2017, COMPUT GRAPH FORUM, V36, P226, DOI 10.1111/cgf.12873
   Kim H, 2021, IEEE T VIS COMPUT GR, V27, P3644, DOI 10.1109/TVCG.2020.2981456
   Kumar V, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6323
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee H, 2012, COMPUT GRAPH FORUM, V31, P1155, DOI 10.1111/j.1467-8659.2012.03108.x
   Lee TY, 2017, INT J HUM-COMPUT ST, V105, P28, DOI 10.1016/j.ijhcs.2017.03.007
   Li DC, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P940
   Li Jie, 2020, IEEE Trans Vis Comput Graph, V26, P1789, DOI 10.1109/TVCG.2018.2882449
   Liu SX, 2014, IEEE CONF VIS ANAL, P183, DOI 10.1109/VAST.2014.7042494
   Liu Z., 2011, ACM Trans. Intell. Syst. Technol., V2, P1
   Lund J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P896, DOI 10.18653/v1/P17-1083
   Mcauliffe J., 2007, NIPS, V20, P121, DOI DOI 10.5555/2981562.2981578
   Mimno D., 2011, P C EMP METH NAT LAN, P262, DOI DOI 10.5555/2145432.2145462
   Musialek C., "Distill-ery: Iterative topic modeling to improve the content analysis process
   Newman D., 2010, Human language technologies: The 2010 annual conference of the North American chapter of the association for computational linguistics, P100
   Newman D, 2009, J MACH LEARN RES, V10, P1801
   Sievert C., 2014, P WORKSH INT LANG LE, DOI [DOI 10.3115/V1/W14-3110, 10.3115/v1/W14-3110, 10.13140/2.1.1394.3043]
   Smith A., 2014, P WORKSH INT LANG LE, P71
   Smith A, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P293, DOI 10.1145/3172944.3172965
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Stevens K., 2012, P 2012 JOINT C EMP M, V2012, P952, DOI DOI 10.5555/2390948.2391052
   Suri P, 2017, 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT)
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Teneva N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P530, DOI 10.18653/v1/P17-2084
   von Landesberger T, 2012, IEEE CONF VIS ANAL, P183, DOI 10.1109/VAST.2012.6400553
   Wallach H. M., 2009, ICML, P1105
   Wang J., 2019, P INT US INT WORKSH
   Wang Y, 2009, LECT NOTES COMPUT SC, V5564, P301, DOI 10.1007/978-3-642-02158-9_26
   Xing LZ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3471
   Xing LZ, 2018, AAAI CONF ARTIF INTE, P6005
   Xue P, 2016, COMM COM INF SC, V626, P97, DOI 10.1007/978-981-10-2209-8_9
   Yang Y., 2015, P C EMP METH NAT LAN, P308
   Yanjun Jiang, 2012, 2012 Third International Conference on Networking and Distributed Computing (ICNDC 2012), P26, DOI 10.1109/ICNDC.2012.14
   Yao LM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P937
   Zhai K., 2012, WWW
   Zhao H, 2021, P INT JOINT C ART IN, P4713, DOI 10.24963/ijcai.2021/638
NR 63
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4542
EP 4557
DI 10.1109/TVCG.2023.3266890
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400039
PM 37053067
DA 2024-08-05
ER

PT J
AU Chen, HR
   Wei, LT
   Liu, HM
   Shi, BX
   Zhang, GF
   Zha, HB
AF Chen, Haoran
   Wei, Lantian
   Liu, Haomin
   Shi, Boxin
   Zhang, Guofeng
   Zha, Hongbin
TI MOUNT: Learning 6DoF Motion Prediction Based on Uncertainty Estimation
   for Delayed AR Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Uncertainty; Task analysis; Delays; Head;
   Hardware; Glass; Virtual and augmented reality; learning environments;
   learning technologies
ID LOCALIZATION; VERSATILE; TRACKING; VISION; ROBUST
AB The delay of rendering on AR devices requires prediction of head motion using sensor data acquired tens of even one hundred milliseconds ago to avoid misalignment between the virtual content and the physical world, where the misalignment will lead to a sense of time latency and dizziness for users. To solve the problem, we propose a method for the 6DoF motion prediction to compensate for the time latency. Compared with traditional hand-crafted methods, our method is based on deep learning, which has better motion prediction ability to deal with complex human motion. In particular, we propose a MOtion UNcerTainty encode decode network (MOUNT) that estimates the uncertainty of input data and predicts the uncertainty of output motion to improve the prediction accuracy and smoothness. Experiments on the EuRoC and our collected dataset demonstrate that our method significantly outperforms the traditional method and greatly improves AR visual effects.
C1 [Chen, Haoran] Peking Univ, AI Innovat Ctr, Sch Comp Sci, Beijing 100871, Peoples R China.
   [Wei, Lantian; Liu, Haomin; Zha, Hongbin] Peking Univ, Sch Intelligence Sci & Technol, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.
   [Liu, Haomin] Sense Time Res, Beijing 200233, Peoples R China.
   [Shi, Boxin] Peking Univ, Natl Engn Res Ctr Visual Technol, Sch Comp Sci, Beijing 100871, Peoples R China.
   [Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Peking University; Peking University; Peking University; Zhejiang
   University
RP Chen, HR (corresponding author), Peking Univ, AI Innovat Ctr, Sch Comp Sci, Beijing 100871, Peoples R China.
EM chrer@pku.edu.cn; weilantian@pku.edu.cn; liuhaomin@sensetime.com;
   shiboxin@pku.edu.cn; zhangguofeng@zju.edu.cn; zha@cis.pku.edu.cn
RI Liu, Haomin/IXW-5373-2023
OI Liu, Haomin/0000-0001-9511-2416; Zhang, Guofeng/0000-0001-5661-8430
FU National Key Research and Development Program of China [2020YFF0304300];
   National Natural Science Foundation of China [62136001, U22A2061]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFF0304300, and in part by
   the National Natural Science Foundation of China under Grants 62136001
   and U22A2061.
CR Agarwal Sameer, 2012, Google Inc, V2, P8
   Azuma R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P401, DOI 10.1145/218380.218496
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Brajdic A, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P225, DOI 10.1145/2493432.2493449
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen CH, 2021, IEEE T MOBILE COMPUT, V20, P1351, DOI 10.1109/TMC.2019.2960780
   Chen CH, 2018, AAAI CONF ARTIF INTE, P6468
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140
   Foxlin EM, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P527, DOI 10.1109/IRDS.2002.1041444
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Harle R, 2013, IEEE COMMUN SURV TUT, V15, P1281, DOI 10.1109/SURV.2012.121912.00075
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Herath S, 2020, IEEE INT CONF ROBOT, P3146, DOI 10.1109/icra40945.2020.9196860
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706
   Kingma D.P., 2014, Proc. of ICLR
   Klein George, 2007, P1
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   List U.H., 1983, Nonlinear prediction of head movements for helmet-mounted displays
   Liu HM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P219, DOI 10.1109/ISMAR-Adjunct51615.2020.00065
   Liu HM, 2018, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR.2018.00211
   Liu WX, 2020, IEEE ROBOT AUTOM LET, V5, P5653, DOI 10.1109/LRA.2020.3007421
   MAZURYK T, 1995, COMPUT GRAPH FORUM, V14, pC29, DOI 10.1111/j.1467-8659.1995.cgf143_0029.x
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Nützi G, 2011, J INTELL ROBOT SYST, V61, P287, DOI 10.1007/s10846-010-9490-z
   Oufqir Z., 2020, P INT C INT SYST COM, P1
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Pittelkau ME, 2003, J GUID CONTROL DYNAM, V26, P855, DOI 10.2514/2.6929
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Radwan N, 2018, IEEE ROBOT AUTOM LET, V3, P4407, DOI 10.1109/LRA.2018.2869640
   Rajagopal S., 2008, Personal dead reckoning system with shoe mounted inertial sensors
   Rambach J, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P109, DOI 10.1109/ISMAR-Adjunct.2017.43
   Rambach JR, 2016, INT SYM MIX AUGMENT, P71, DOI 10.1109/ISMAR.2016.19
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Suleiman A, 2019, IEEE J SOLID-ST CIRC, V54, P1106, DOI 10.1109/JSSC.2018.2886342
   Suto J, 2017, INT J COMPUT COMMUN, V12, P116
   van Waveren JMP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P37, DOI 10.1145/2993369.2993375
   Watson A., 1983, A look at motion in the frequency domain
   Weberruss J, 2017, I C FIELD PROG LOGIC
   Weyand PG, 2010, J APPL PHYSIOL, V108, P950, DOI 10.1152/japplphysiol.00947.2009
   WINOGRAD S, 1978, MATH COMPUT, V32, P175, DOI 10.1090/S0025-5718-1978-0468306-4
   Wu KJ, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Yan H, 2018, LECT NOTES COMPUT SC, V11217, P641, DOI 10.1007/978-3-030-01261-8_38
   Zhang Zhengdong., 2017, Visual-Inertial Odometry on Chip: An Algorithm-and-Hardware Co-design Approach
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3166
EP 3179
DI 10.1109/TVCG.2022.3228807
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700091
PM 37015352
DA 2024-08-05
ER

PT J
AU Lv, CL
   Lin, WS
   Zheng, JM
AF Lv, Chenlei
   Lin, Weisi
   Zheng, Jianmin
TI Adaptively Isotropic Remeshing Based on Curvature Smoothed Field
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optimization; Faces; Adaptation models; Aerospace electronics;
   Three-dimensional displays; Solid modeling; Histograms; Adaptively
   isotropic; remeshing; curvature smoothed field
ID SURFACES
AB With the development of 3D digital geometry technology, 3D triangular meshes are becoming more useful and valuable in industrial manufacturing and digital entertainment. A high quality triangular mesh can be used to represent a real world object with geometric and physical characteristics. While anisotropic meshes have advantages of representing shapes with sharp features (such as trimmed surfaces) more efficiently and accurately, isotropic meshes allow more numerically stable computations. When there is no anisotropic mesh requirement, isotropic triangles are always a good choice. In this paper, we propose a remeshing method to convert an input mesh into an adaptively isotropic one based on a curvature smoothed field (CSF). With the help of the CSF, adaptively isotropic remeshing can retain the curvature sensitivity, which enables more geometric features to be kept, and avoid the occurrence of obtuse triangles in the remeshed model as much as possible. The remeshed triangles with locally isotropic property benefit various geometric processes such as neighbor-based feature extraction and analysis. The experimental results show that our method achieves better balance between geometric feature preservation and mesh quality improvement compared to peers. We provide the implementation codes of our resampling method at github.com/vvvwo/Adaptively-Isotropic-Remeshing.
C1 [Lv, Chenlei; Lin, Weisi; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.
   [Lin, Weisi] Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Lin, WS (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.; Lin, WS (corresponding author), Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab, Singapore, Singapore.
EM chenleilv@mail.bnu.edu.cn; WSLin@ntu.edu.sg; asjmzheng@ntu.edu.sg
RI ; Lin, Weisi/A-3696-2011
OI Chenlei, Lv/0000-0002-8203-3118; Lin, Weisi/0000-0001-9866-1947
FU Ministry of Education, Singapore [RG14/21]; Industry Alignment Fund -
   Industry Collaboration Projects Funding Initiative [RIE2020]
FX This work was supported by the Ministry of Education, Singapore, under
   its Tier-1 Fund MOE2021, RG14/21, and RIE2020 Industry Alignment Fund -
   Industry Collaboration Projects Funding Initiative, as well as cash and
   in-kind contribution from Singapore Telecommunications Limited
   (Singtel), through Singtel Cognitive and Artificial Intelligence Lab for
   Enterprises, SCALE@NTU.
CR Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Alliez P, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P49
   Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   BAGNARA R, 1995, SIAM REV, V37, P93, DOI 10.1137/1037008
   Berger M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451246
   Botsch M., 2004, P 2004 EUROGRAPHICSA, P185, DOI [10.1145/1057432.1057457, DOI 10.1145/1057432.1057457]
   Botsch M, 2010, Polygon Mesh Processing, DOI DOI 10.1201/B10688
   Bronstein A., 2010, P EUR WORKSH 3D OBJ, V5, P1, DOI DOI 10.2312/3DOR/3DOR11/071-078
   Chen ZG, 2018, COMPUT AIDED DESIGN, V102, P12, DOI 10.1016/j.cad.2018.04.010
   Cheng XX, 2019, COMPUT GRAPH-UK, V82, P163, DOI 10.1016/j.cag.2019.05.019
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Dapogny C, 2014, J COMPUT PHYS, V262, P358, DOI 10.1016/j.jcp.2014.01.005
   Dassi F., 2015, New Challenges in Grid Generation and Adap- tivity for Scientific Computing, P19
   Dassi F, 2014, PROCEDIA ENGINEER, V82, P253, DOI 10.1016/j.proeng.2014.10.388
   de Goes F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602143
   Dunyach M., 2013, EUROGRAPHICS, P29
   Frey PJ, 1999, INT J NUMER METH ENG, V45, P101
   Guo YW, 2005, COMPUT GRAPH-UK, V29, P972, DOI 10.1016/j.cag.2005.09.013
   Hieber Simone E, 2004, Technol Health Care, V12, P305
   Hou WJ, 2022, COMPUT AIDED DESIGN, V144, DOI 10.1016/j.cad.2021.103166
   Hu BY, 2023, IEEE T VIS COMPUT GR, V29, P1318, DOI 10.1109/TVCG.2021.3112896
   Jiao XM, 2010, ENG COMPUT-GERMANY, V26, P363, DOI 10.1007/s00366-009-0170-1
   Jin M, 2008, IEEE T VIS COMPUT GR, V14, P1030, DOI 10.1109/TVCG.2008.57
   Lei N, 2019, COMPUT AIDED GEOM D, V68, P1, DOI 10.1016/j.cagd.2018.10.005
   Levy B., 2013, P 21 INT MESH ROUNDT, P349, DOI [DOI 10.1007/978-3-642-33573-021, DOI 10.1007/978-3-642-33573-0-21]
   Liu YJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818076
   Liu ZY, 2021, COMPUT AIDED DESIGN, V139, DOI 10.1016/j.cad.2021.103080
   Lv C., IEEE Trans. Pattern Anal. Mach. Intell., DOI 10.1109/ΡΑΙ.2022.3185644
   Lv CL, 2022, IEEE T MULTIMEDIA, V24, P1815, DOI 10.1109/TMM.2021.3073265
   Lv CL, 2019, MULTIMED TOOLS APPL, V78, P14753, DOI 10.1007/s11042-018-6839-y
   Lv CL, 2019, PATTERN RECOGN, V88, P458, DOI 10.1016/j.patcog.2018.12.006
   Meyer M, 2008, IEEE T VIS COMPUT GR, V14, P1539, DOI 10.1109/TVCG.2008.154
   Narain R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366171
   O'Sullivan C, 2011, INT J GEOMECH, V11, P449, DOI 10.1061/(ASCE)GM.1943-5622.0000024
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Shimada K, 2000, INT J COMPUT GEOM AP, V10, P417, DOI 10.1142/S0218195900000243
   Su KH, 2019, COMPUT AIDED DESIGN, V111, P1, DOI 10.1016/j.cad.2019.01.004
   Takamatsu Kenji, 2011, International Journal of Virtual Reality, V10, P29
   Verhoeven F, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3510002
   Wang YQ, 2019, IEEE T VIS COMPUT GR, V25, P2430, DOI 10.1109/TVCG.2018.2837115
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu QC, 2019, COMPUT GRAPH FORUM, V38, P755, DOI 10.1111/cgf.13877
   Yan DM, 2014, COMPUT GRAPH FORUM, V33, P167, DOI 10.1111/cgf.12442
   Yan DM, 2009, COMPUT GRAPH FORUM, V28, P1445, DOI 10.1111/j.1467-8659.2009.01521.x
   Ye ZP, 2019, Arxiv, DOI arXiv:1907.00523
   Yi R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275068
   Zhang WX, 2022, COMPUT GRAPH FORUM, V41, P237, DOI 10.1111/cgf.14471
   Zheng JQ, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384520
   Zhong SK, 2019, COMPUT AIDED GEOM D, V71, P43, DOI 10.1016/j.cagd.2019.04.011
   Zhong ZC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461946
NR 51
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3196
EP 3209
DI 10.1109/TVCG.2022.3227970
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700056
PM 37015489
DA 2024-08-05
ER

PT J
AU Seo, MY
   Kang, KE
   Kang, HY
AF Seo, Min Yeong
   Kang, Kyung Eun
   Kang, Hyeong Yeop
TI VR Blowing: A Physically Plausible Interaction Method for Blowing Air in
   Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Microphones; Fluid flow measurement; Navigation; Usability; Force;
   Tracking; Mouth; Blowing control; human-computer interaction; immersion;
   virtual reality
AB This article introduces an interaction method allowing virtual reality (VR) users to interact with virtual objects by blowing air. The proposed method allows users to interact with virtual objects in a physically plausible way by recognizing the intensity of the wind generated by the user's actual wind blowing activity in the physical world. This is expected to provide immersed VR experience since it enables users to interact with virtual objects in the same way they do in the real world. Three experiments were carried out to develop and improve this method. In the first experiment, we collected the user's blowing data and used it to model a formula to estimate the speed of the wind from the sound waves obtained through a microphone. In the second experiment, we investigated how much gain can be applied to the formula obtained in the first experiment. The aim is to reduce the lung capacity required to generate wind without compromising physical plausibility. In the third experiment, the advantages and disadvantages of the proposed method compared to the controller-based method were investigated in two scenarios of blowing a ball and a pinwheel. According to the experimental results and participant interview, participants felt a stronger sense of presence and found the VR experience more fun with the proposed blowing interaction method.
C1 [Seo, Min Yeong; Kang, Hyeong Yeop] Kyung Hee Univ, Dept Software Convergence, Yongin 130701, South Korea.
   [Kang, Kyung Eun] Kyung Hee Univ, Dept Elect & Software Convergence, Yongin 130701, South Korea.
C3 Kyung Hee University; Kyung Hee University
RP Kang, HY (corresponding author), Kyung Hee Univ, Dept Software Convergence, Yongin 130701, South Korea.
EM sminy98@khu.ac.kr; kyungh22@khu.ac.kr; siamiz@khu.ac.kr
OI Kang, HyeongYeop/0000-0001-5292-4342
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2020R1F1A1076528]
FX This work was supported in part by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education under Grant NRF-2020R1F1A1076528.
CR Abkarian M, 2020, P NATL ACAD SCI USA, V117, P25237, DOI 10.1073/pnas.2012156117
   Arora R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P463, DOI 10.1145/3332165.3347942
   Arroyo-Palacios Jorge, 2009, 2009 International IEEE Consumer Electronics Society's Games Innovations Conference (ICE-GIC 2009), P154, DOI 10.1109/ICEGIC.2009.5293588
   Arroyo-Palacios J, 2016, IEEE T AFFECT COMPUT, V7, P326, DOI 10.1109/TAFFC.2015.2472013
   Blum J, 2020, APPL PSYCHOPHYS BIOF, V45, P153, DOI 10.1007/s10484-020-09468-x
   Bouzbib E., 2021, P 32 C FRANC INT HOM, P1
   Brooke J., 1986, Reading UK: Digital Equipment Co Ltd, V43, P1
   Bruder G., 2014, P ACM S VIRT REAL SO, P177, DOI DOI 10.1145/2671015.2671026
   Chakraborty BK, 2018, IET COMPUT VIS, V12, P3, DOI 10.1049/iet-cvi.2017.0052
   Chen YQ, 2020, IEEE ACCESS, V8, P115486, DOI 10.1109/ACCESS.2020.3004349
   Cherni H., 2021, Int. J. Virtual Reality, V21, P1, DOI [10.20870/IJVR.2021.21.1.3046, DOI 10.20870/IJVR.2021.21.1.3046]
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   Davies C., 1996, Computer Graphics, V30, P25, DOI 10.1145/240806.240808
   Delrieu T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P266, DOI [10.1109/VR46266.2020.1581332505844, 10.1109/VR46266.2020.00-58]
   Desnoyers-Stewart E. R., 2019, P EXT ABSTR CHI C HU, P1
   Fahy F.J., 1989, SOUND INTENSITY
   Gupta A. E., 2019, Advanced ComputationalIntelligence Techniques for Virtual Reality in Healthcare, V875
   Höll M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P175, DOI 10.1109/VR.2018.8448284
   Hoppe M, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P7, DOI 10.1145/3282894.3282898
   Hoshikawa Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P464, DOI 10.1109/VR51125.2022.00066
   Huang K. N., 1999, Proceedings of the First Joint BMES/EMBS Conference. 1999 IEEE Engineering in Medicine and Biology 21st Annual Conference and the 1999 Annual Fall Meeting of the Biomedical Engineering Society (Cat. No.99CH37015), DOI 10.1109/IEMBS.1999.803946
   Inazawa M, 2019, SIGGRAPH ASIA 2019 EMERGING TECHNOLOGIES, P5, DOI 10.1145/3355049.3360523
   Ioannou C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300388
   Jain Dhruv., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P1563, DOI [10.1145/2851581.2892503, DOI 10.1145/2851581.2892503]
   Jovanov E, 2001, Biomed Sci Instrum, V37, P493
   Kim JS, 2019, IEEE INT C INT ROBOT, P3235, DOI [10.1109/iros40897.2019.8968088, 10.1109/IROS40897.2019.8968088]
   Kim M, 2020, INT J HUM-COMPUT INT, V36, P685, DOI 10.1080/10447318.2019.1680920
   Kim S.-G., 2018, P CHI C HUM FACT COM, P1
   Kleinbaum L. L., 2013, AppliedRegression Analysisand OtherMultivariable Methods, P33
   Korsi MJL, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P91, DOI 10.1145/2967934.2968110
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Li Y., 2019, Virtual Reality Intell. Hardw., V1, P84, DOI [10.3724/SP.J.2096-5796.2018.0006, DOI 10.3724/SP.J.2096-5796.2018.0006]
   Lin W., 2017, Human-Computer Interaction. User Interface Design, V10271, P584, DOI DOI 10.1007/978-3-319-58071-5_44
   Llorens M., 2016, J. Neuroengineering Rehabil., V13, P1
   Marill KA, 2004, ACAD EMERG MED, V11, P87, DOI 10.1197/S1069-6563(03)00600-6
   Marti-Puig P, 2014, FRONT ARTIF INTEL AP, V269, P257, DOI 10.3233/978-1-61499-452-7-257
   Mhetre MR, 2017, ENG SCI TECHNOL, V20, P332, DOI 10.1016/j.jestch.2016.06.012
   Mine M.R., 1995, Technical Report
   Montali N, 2018, "Definition of different calibration methods for digital memsmicrophones
   Moon HS, 2023, INT J HUM-COMPUT INT, V39, P2840, DOI 10.1080/10447318.2022.2087000
   Norman D.A., 2010, interactions, V17, P6, DOI DOI 10.1145/1744161.1744163
   Oo Jin Heng, 2020, BDIOT 2020: Proceedings of the 2020 4th International Conference on Big Data and Internet of Things, P33, DOI 10.1145/3421537.3421552
   Patibanda R, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P19, DOI 10.1145/3116595.3116621
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Prpa M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376183
   Qudsi H, 2013, PR SOUTH BIOMED ENG, P23, DOI 10.1109/SBEC.2013.20
   Re Guido Maria, 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P93, DOI 10.1007/978-3-319-07458-0_10
   Ritter KA, 2022, VIRTUAL REAL-LONDON, V26, P571, DOI 10.1007/s10055-021-00502-9
   Rockstroh C, 2021, VIRTUAL REAL-LONDON, V25, P539, DOI 10.1007/s10055-020-00471-5
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sampson H, 2018, INT CONF IMAG VIS
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schäfer A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060715
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith N. F., 1972, "Phys. Teacher, V10, P451, DOI DOI 10.1119/1.2352317
   Smus B., 2013, WEB AUDIO API ADV SO
   Sra X., 2018, P CHI C HUM FACT COM, P1
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stepanova ER, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P641, DOI 10.1145/3357236.3395532
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Tatzgern M., 2022, P CHI C HUM FACT COM, P1
   Tennent P, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Verschoor M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P183, DOI 10.1109/VR.2018.8447555
   Voigt-Antons J.N, 2020, P 12 INT C QUAL MULT, P1
   Waltemate T., 2015, P 21 ACM S VIRT REAL, P139, DOI DOI 10.1145/2821592.2821607
   Weerdmeester J, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P453, DOI 10.1145/31308593131299
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf K., 2020, P CHI C HUM FACT COM, P1
   Xu C, 2015, INDOOR AIR, V25, P198, DOI 10.1111/ina.12135
   Yan C. Yu, 2018, P CHI C HUM FACT COM, P1
   Yu D. A., 2018, Front.ICT, V5
   Yu Y, 2014, SIMUL MODEL PRACT TH, V45, P62, DOI 10.1016/j.simpat.2014.04.001
   Zenner A, 2020, IEEE T VIS COMPUT GR, V26, P2104, DOI 10.1109/TVCG.2020.2973476
   Zielasko D., 2015, P 3 ACM S SPAT US IN, P20
   Zielasko D, 2017, IEEE SYMP 3D USER, P40, DOI 10.1109/3DUI.2017.7893316
   Zielasko D, 2017, P IEEE VIRT REAL ANN, P319, DOI 10.1109/VR.2017.7892305
NR 84
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3680
EP 3692
DI 10.1109/TVCG.2023.3238478
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700095
PM 37022016
DA 2024-08-05
ER

PT J
AU Zhang, HL
   Cheng, S
   El Amm, C
   Kim, J
AF Zhang, Haoliang
   Cheng, Samuel
   El Amm, Christian
   Kim, Jonghoon
TI Efficient Pooling Operator for 3D Morphable Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Convolution; Faces; Three-dimensional displays; Shape; Task analysis;
   Computational modeling; Geometry; Latent representation; mesh
   reconstruction; morphable model
AB Learning the latent representation of three-dimensional (3D) morphable geometry is useful for several tasks, such as 3D face tracking, human motion analysis, and character generation and animation. For unstructured surface meshes, previous state-of-the-art methods focus on designing convolution operators and share the same pooling and unpooling operations to encode neighborhood information. Previous models use a mesh pooling operation based on edge contraction, which is based on the euclidean distance of vertices rather than the actual topology. In this study, we investigated whether such a pooling operation can be improved, introducing an improved pooling layer that combines the vertex normals and adjacent faces area. Furthermore, to prevent template overfitting, we increased the receptive field and improved low-resolution projection in the unpooling stage. This increase did not affect processing efficiency because the operation was implemented once on the mesh. We performed experiments to evaluate the proposed method, whose results indicated that the proposed operations outperformed Neural3DMM with 14% lower reconstruction errors and outperformed CoMA by 15% by modifying the pooling and unpooling matrices.
C1 [Zhang, Haoliang; Cheng, Samuel; El Amm, Christian] Univ Oklahoma, Norman, OK 73019 USA.
   [Kim, Jonghoon] Chungnam Natl Univ, Daejeon 34134, South Korea.
C3 University of Oklahoma System; University of Oklahoma - Norman; Chungnam
   National University
RP Kim, J (corresponding author), Chungnam Natl Univ, Daejeon 34134, South Korea.
EM mars_zhang@ou.edu; samuel.cheng@ou.edu; christianamm@hotmail.com;
   qwzxas@hanmail.net
OI Cheng, Samuel/0000-0002-5439-1137
CR Amberg R., 2008, P IEEE 8 INT C AUT F, P1
   Atwood J., 2016, Advances in neural information process- ing systems, P1993, DOI DOI 10.5555/3157096.3157320
   Bagautdinov T, 2018, PROC CVPR IEEE, P3877, DOI 10.1109/CVPR.2018.00408
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Boscaini Davide, 2016, Advances in neural information processing systems
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Bouritsas G, 2019, IEEE I CONF COMP VIS, P7212, DOI 10.1109/ICCV.2019.00731
   Brock A, 2016, Arxiv, DOI arXiv:1608.04236
   Chen T.-K., 2021, P IEEE CVF C COMP VI, p13 164
   Chung F. C., 1997, Spectral Graph Theory, P39
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Defferrard M, 2016, ADV NEUR IN, V29
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Garland M, 1998, VISUALIZATION '98, PROCEEDINGS, P263, DOI 10.1109/VISUAL.1998.745312
   GOURAUD H, 1971, IEEE T COMPUT, VC 20, P623, DOI 10.1109/T-C.1971.223313
   Hahner J., 2022, P IEEE CVF WINT C AP, P885
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kingma D. P., 2014, arXiv
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Li Y., 2018, Advances in neural information processing systems, P828, DOI DOI 10.48550/ARXIV.1801.07791
   Lim I, 2019, LECT NOTES COMPUT SC, V11131, P349, DOI 10.1007/978-3-030-11015-4_26
   Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202
   Liu Y, 2006, ACM T GRAPHIC, V25, P681, DOI 10.1145/1141911.1141941
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Malik J, 2018, INT CONF 3D VISION, P110, DOI 10.1109/3DV.2018.00023
   Maron H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073616
   Masci Jonathan, 2015, P IEEE INT C COMPUTE, P37
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Romero Javier, 2022, arXiv
   Shervashidze N, 2011, J MACH LEARN RES, V12, P2539
   Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang Chengcheng., 2014, ACM T GRAPHIC, V33, P70, DOI DOI 10.1145/2601097.2601213
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Tretschk Edgar, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P601, DOI 10.1007/978-3-030-58548-8_35
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Wang C-C, 2017, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1706.02216
   Xu Q., 2020, P IEEECVF C COMPUTER, P5661
   Yang J., 2011, ACM SIGGRAPH, P1
   Yao L, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/428917
   Zhou Yi, 2020, Advances in neural information processing systems, P9251
NR 52
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4225
EP 4233
DI 10.1109/TVCG.2023.3255820
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700007
PM 37028282
DA 2024-08-05
ER

PT J
AU Javerliat, C
   Villenave, S
   Raimbaud, P
   Lavoue, G
AF Javerliat, Charles
   Villenave, Sophie
   Raimbaud, Pierre
   Lavoue, Guillaume
TI PLUME: Record, Replay, Analyze and Share User Behavior in 6DoF XR
   Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Physiology; Three-dimensional displays; X reality;
   Visualization; Trajectory; Data visualization; Extended Reality; Virtual
   Reality; User Behavior; Human-Computer Interaction; Quality of
   Experience; Data Collection; Physiological Signals
ID VIRTUAL-REALITY; SICKNESS; TRACKING
AB From education to medicine to entertainment, a wide range of industrial and academic fields now utilize eXtended Reality (XR) technologies. This diversity and growing use are boosting research and leading to an increasing number of XR experiments involving human subjects. The main aim of these studies is to understand the user experience in the broadest sense, such as the user cognitive and emotional states. Behavioral data collected during XR experiments, such as user movements, gaze, actions, and physiological signals constitute precious assets for analyzing and understanding the user experience. While they contribute to overcome the intrinsic flaws of explicit data such as post-experiment questionnaires, the required acquisition and analysis tools are costly and challenging to develop, especially for 6DoF (Degrees of Freedom) XR experiments. Moreover, there is no common format for XR behavioral data, which restrains data-sharing, and thus hinders wide usages across the community, replicability of studies, and the constitution of large datasets or meta-analysis. In this context, we present PLUME, an open-source software toolbox (PLUME Recorder, PLUME Viewer, PLUME Python) that allows for the exhaustive record of XR behavioral data (including synchronous physiological signals), their offline interactive replay and analysis (with a standalone application), and their easy sharing due to our compact and interoperable data format. We believe that PLUME can greatly benefit the scientific community by making the use of behavioral and physiological data available for the greatest, contributing to the reproducibility and replicability of XR user studies, enabling the creation of large datasets, and contributing to a deeper understanding of user experience.
C1 [Javerliat, Charles; Villenave, Sophie; Raimbaud, Pierre; Lavoue, Guillaume] Ecole Cent Lyon, CNRS, ENISE, LIRIS UMR5025, Ecully, France.
C3 Centre National de la Recherche Scientifique (CNRS); Ecole Centrale de
   Lyon
RP Javerliat, C (corresponding author), Ecole Cent Lyon, CNRS, ENISE, LIRIS UMR5025, Ecully, France.
EM charles.javerliat@ec-lyon.fr; sophie.villenave@ec-lyon.fr;
   pierre.raimbaud.pr@gmail.com; guillaume.lavoue@enise.ec-lyon.fr
OI Javerliat, Charles/0000-0003-0748-5541; Villenave,
   Sophie/0000-0002-6152-9800; Raimbaud, Pierre/0000-0002-5584-8100
FU French National Research Agency as part of the RENFORCE
FX No Statement Available
CR Annett J, 2003, HUM FAC ER, P17
   Asish S M., 2022, Virtual Worlds, V1, P42
   Balan O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020496
   Beaton D. E., Guidelines for the Process of Cross-Cultural Adaptation of Self-Report Measures
   Bellazzi A, 2022, BUILD ENVIRON, V209, DOI 10.1016/j.buildenv.2021.108674
   Berton F, 2022, IEEE T VIS COMPUT GR, V28, P2589, DOI 10.1109/TVCG.2020.3041341
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Brunner C., Sig Viewer repository
   Buschel W., 2021, P 2021 CHI C HUM FAC, P1, DOI [DOI 10.1145/3411764.3445651, 10.1145/3411764.3445651]
   Choi Bernard C K, 2005, Prev Chronic Dis, V2, pA13
   Cignoni P., Meshlab website
   Cognitive3D, Collect and measure spatial data to bring visibility to user participation, and optimize simulations for success
   Cousins S., POINT CLOUD LIB
   David-John B, 2023, IEEE T VIS COMPUT GR, V29, P2774, DOI 10.1109/TVCG.2023.3247048
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Deuchler J, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P485, DOI 10.1109/VRW58643.2023.00105
   Ding XY, 2020, Arxiv, DOI arXiv:2005.13127
   Fincham E, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P501, DOI 10.1145/3303772.3303775
   Girardeau-Montaut D., CloudCompare: 3D point cloud and mesh processing software
   Gorisse G, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3534472
   Goude I., 2023, IEEE Transactions on Visualization and Computer Graphics, P3
   Graf S., 2020, P 26 ACM S VIRTUAL R, P1
   Guimard Q, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P252, DOI 10.1145/3524273.3532895
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   HART S G, 1988, P139
   Hepperle D, 2021, INT SYM MIX AUGMENT, P100, DOI 10.1109/ISMAR-Adjunct54149.2021.00030
   Homps F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P729, DOI [10.1109/VR46266.2020.1581269207852, 10.1109/VR46266.2020.000-8]
   Hu ZM, 2021, IEEE T VIS COMPUT GR, V27, P2681, DOI 10.1109/TVCG.2021.3067779
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Iop A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166067
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Koulieris GA, 2015, ACM T APPL PERCEPT, V11, DOI 10.1145/2637479
   Kurita K., 2012, Kansei Engineering International Journal, V11, P183
   Lanier M, 2019, COMPUT HUM BEHAV, V100, P70, DOI 10.1016/j.chb.2019.06.015
   Lavoué É, 2021, INT J HUM-COMPUT ST, V154, DOI 10.1016/j.ijhcs.2021.102670
   Lavoué G, 2018, COMPUT GRAPH FORUM, V37, P191, DOI 10.1111/cgf.13353
   Lemic F, 2022, IEEE GLOB COMM CONF, P6139, DOI 10.1109/GLOBECOM48099.2022.10001349
   Marañes C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P73, DOI [10.1109/VR46266.2020.00-79, 10.1109/VR46266.2020.1580727911717]
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Matthews S, 2020, SYMP VIRTUAL AUGMENT, P398, DOI 10.1109/SVR51698.2020.00066
   Maurus Michael., 2014, Proceedings of the Symposium on Eye Tracking Research and Applications, P295, DOI [10.1145/2578153.2578204, DOI 10.1145/2578153.25782043,8]
   McKinney W., Pandas Dataframe documentation
   Microsoft, MSDN Stopwatch documentation
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Murgia A, 2008, IEEE ACM DIS SIM, P252, DOI 10.1109/DS-RT.2008.25
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376330
   Nvidia, NVIDIA VCR
   Ojeda A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00121
   Pfeiffer T., 2012, Proceedings of the Symposium on Eye Tracking Research and Applications, P29, DOI [10.1145/2168556.2168560, DOI 10.1145/2168556.2168560]
   Pfeiffer T, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P95, DOI 10.1145/2857491.2857541
   Raimbaud P., 2020, PhD thesis, P3
   Raimbaud P, 2023, PROCEEDINGS OF THE ACM SYMPOSIUM ON APPLIED PERCEPTION, SAP 2023, DOI 10.1145/3605495.3605796
   Reipschläger P, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517676
   Rennes I., Virtual Crowds! CrowdMP is a Unity project used as an exper imentation platform
   Robert F, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2023, P14, DOI 10.1145/3573381.3596150
   Rossi S, 2023, PROCEEDINGS OF THE 2023 PROCEEDINGS OF THE 14TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2023, P39, DOI 10.1145/3587819.3590976
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   S. C. for Computational Neuroscience, A integration approach of the LabStreamingLayer framework for Unity3D
   S. C. for Computational Neuroscience, LabStreaminglayer super repository comprising submodules for LSL and associated apps
   Sitzmann V, 2017, Arxiv, DOI arXiv:1612.04335
   Slater M., 1994, Presence: teleoperators virtual environments, V3, P130, DOI [10.1162/pres.1994.3.2.130, DOI 10.1162/PRES.1994.3.2.130, 10.1162/pres.1994.3.2.1302]
   Steed A., 2022, Frontiers in Virtual Reality, V3
   Stellmach S., 2010, ACM S EYE TRACK RES, P109, DOI [DOI 10.1145/1743666, DOI 10.1145/1743666.1743693]
   Sundstedt V, 2022, FRONT NEUROERGONOM, V3, DOI 10.3389/fnrgo.2022.910019
   Systems B., Complete VR eye tracking system 1 user
   Tabbaa L, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3495002
   Tartarisco G, 2015, INTERACT COMPUT, V27, P521, DOI 10.1093/iwc/iwv010
   Tcha-Tokey K., 2016, International Journal of Virtual Reality, V16, P33, DOI [DOI 10.20870/IJVR.2016.16.1.2880, 10.20870/IJVR.2016.16.1.2880]
   Tobii, Tobii Ocumen software website
   Tremmel C, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00401
   Unity, Xr interaction toolkit
   Unity Technologies, Unity real-time development platform
   Villenave S, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P341, DOI 10.1145/3524273.3532909
   Wang JL, 2023, IEEE T VIS COMPUT GR, V29, P2478, DOI 10.1109/TVCG.2023.3247057
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu H.-Y., 2022, Proceedings of the ACM on Human-Computer Interaction, DOI [10.1145/35322083,4, DOI 10.1145/35322083,4]
   Yuksel C., 2008, Technical report, P7
NR 80
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2087
EP 2097
DI 10.1109/TVCG.2024.3372107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400028
PM 38437111
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Stranner, M
   Fleck, P
   Schmalstieg, D
   Arth, C
AF Stranner, Marco
   Fleck, Philipp
   Schmalstieg, Dieter
   Arth, Clemens
TI Instant Segmentation and Fitting of Excavations in Subsurface Utility
   Engineering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Excavation; Point cloud compression;
   Documentation; Fitting; Task analysis; Solid modeling; Augmented
   Reality; Localization; 3D Models; Geometric Constraints; Segmentation;
   Infrastructure
AB Using augmented reality for subsurface utility engineering (SUE) has benefited from recent advances in sensing hardware, enabling the first practical and commercial applications. However, this progress has uncovered a latent problem - the insufficient quality of existing SUE data in terms of completeness and accuracy. In this work, we present a novel approach to automate the process of aligning existing SUE databases with measurements taken during excavation works, with the potential to correct the deviation from the as-planned to as-built documentation, which is still a big challenge for traditional workers at sight. Our segmentation algorithm performs infrastructure segmentation based on the live capture of an excavation on site. Our fitting approach correlates the inferred position and orientation with the existing digital plan and registers the as-planned model into the as-built state. Our approach is the first to circumvent tedious postprocessing, as it corrects data online and on-site. In our experiments, we show the results of our proposed method on both synthetic data and a set of real excavations.
C1 [Stranner, Marco; Fleck, Philipp; Schmalstieg, Dieter; Arth, Clemens] Graz Univ Technol, Graz, Austria.
C3 Graz University of Technology
RP Fleck, P (corresponding author), Graz Univ Technol, Graz, Austria.
EM m.stranner@icg.tugraz.at; philipp.fleck@icg.tugraz.at;
   dieter@icg.tugraz.at; arth@icg.tugraz.at
FU European Union
FX No Statement Available
CR Agarwal S., 2022, Ceres Solver, V3, P5
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   Bellekens B., 2014, AMBIENT 2014 4 INT C
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Broome R., 2019, Utility strike damage report
   Covaciu Dinu, 2016, Applied Mechanics and Materials, V822, P321, DOI 10.4028/www.scientific.net/AMM.822.321
   Crevier D., 1993, 1993 Canadian Conference on Electrical and Computer Engineering (Cat. No.93TH0590-0), P1250, DOI 10.1109/CCECE.1993.332483
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dorninger P., 2007, International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Furgale P, 2012, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2012.6225005
   Gelfand N., 2004, PROCEEDING S GEOMETR, P219, DOI DOI 10.1145/1057432.10574612
   Green WR, 2015, PROCEEDINGS OF THE 2015 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH), P54, DOI 10.1109/RoboMech.2015.7359498
   Guerrero P, 2018, Arxiv, DOI arXiv:1710.04954
   Hansen L., 2021, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLVI-4/W4-2021, P25, DOI DOI 10.5194/ISPRS-ARCHIVES-XLVI-4-W4-2021-25-20212
   Hansen L., 2021, PhD thesis, DOI [10.54337/aau4664079953, DOI 10.54337/AAU4664079953]
   Hansen L., 2021, Workingpaper
   Hansen L., 2021, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLVI-4/W4-2021, P43, DOI [10.5194/isprs-archives-XLVI-4-W4-2021-43-2021, DOI 10.5194/ISPRS-ARCHIVES-XLVI-4-W4-2021-43-2021]
   Hansen LH, 2021, IEEE T VIS COMPUT GR, V27, P4119, DOI 10.1109/TVCG.2021.3106479
   HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063
   Hartley R., 2003, Multiple view geometry in computer vision, V2, P2
   Iannizzotto G, 2000, IEEE T IMAGE PROCESS, V9, P1232, DOI 10.1109/83.847835
   Kaganami Hassana Grema, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1217, DOI 10.1109/IIH-MSP.2009.13
   Kang ZZ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117341
   Krumm J., 2000, Intersection of two planes, V6
   Kundu A., 2020, COMPUTER VISIONECCV, P518, DOI [DOI 10.1007/978-3-030-58586-0_31, 10.1007/978-3-030-58586-0_31]
   Lafarge F, 2012, INT J COMPUT VISION, V99, P69, DOI 10.1007/s11263-012-0517-8
   Lari Z, 2014, ISPRS J PHOTOGRAMM, V93, P192, DOI 10.1016/j.isprsjprs.2013.12.001
   Li LX, 2019, PROC CVPR IEEE, P2647, DOI 10.1109/CVPR.2019.00276
   Low K.-L., 2004, Technical report, P2
   Makana LO, 2020, INFRASTRUCT ASSET MA, V7, P64, DOI 10.1680/jinam.17.00033
   Maurell IP, 2021, 2021 LATIN AMERICAN ROBOTICS SYMPOSIUM / 2021 BRAZILIAN SYMPOSIUM ON ROBOTICS / 2021 WORKSHOP OF ROBOTICS IN EDUCATION (LARS-SBR-WRE 2021), P108, DOI 10.1109/LARS/SBR/WRE54079.2021.9605458
   Min S, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P246
   Murtiyoso A., 2021, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLIIIB2-2021:201-206, DOI [10.5194/isprs-archives-XLIII-B2-2021-201-2021, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2021-201-2021]
   ODA K., 2004, Journal of the Japan society of photogrammetry and remote sensing, V43, P16, DOI [10.4287/jsprs.43.5162, DOI 10.4287/JSPRS.43.5162]
   Pellis E, 2022, INT ARCH PHOTOGRAMM, P429, DOI 10.5194/isprs-archives-XLVI-2-W1-2022-429-2022
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, Arxiv, DOI arXiv:1711.08488
   Rabbani T., 2005, PROC ISPRS WORKSHOP, V36, P2
   Romanengo C, 2023, COMPUT AIDED DESIGN, V157, DOI 10.1016/j.cad.2023.103479
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Schall G, 2013, PERS UBIQUIT COMPUT, V17, P1533, DOI 10.1007/s00779-012-0599-x
   Schall G, 2009, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2009.5336489
   Schall G, 2008, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2008.4637332
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203
   Segal A., 2009, Robotics: science and systems, DOI [10.15607/RSS.2009.V.0212, DOI 10.15607/RSS.2009.V.0212]
   Soria G, 2018, J COMPUT INF SCI ENG, V18, DOI 10.1115/1.4040460
   Spreafico A., 2021, Remote Sens. Spatial Inf. Sci., VXLIII-B1-2021, P63, DOI [10.5194/isprs-archives-XLIII-B1-2021-63, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B1-2021-63]
   Stranner M., 2023, Master's thesis, P3
   Strom J, 2010, IEEE INT C INT ROBOT, P2131, DOI 10.1109/IROS.2010.5650459
   Tang J., 2010, 2010 2 INT C COMP EN, V6, pV6, DOI [10.1109/ICCET.2010.5486012, DOI 10.1109/ICCET.2010.5486012]
   Tarsha-Kurdi F., 2007, ISPRS WORKSHOP LASER, VXXXVI, P2
   The CGAL Project, 2023, CGAL User and Reference Manual, V2, P5
   Tovari D., 2012, International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P2
   Trigo G., 2011, 2011 IEEE 73 VEHICUL, P1, DOI [10.1109/VETECS.2011.5956715, DOI 10.1109/VETECS.2011.5956715]
   Vogt M, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9020025
   Vosselman G., 2001, International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, VXXXIV, P2
   Xu JQ, 2021, FRONT BUILT ENVIRON, V7, DOI 10.3389/fbuil.2021.640732
   Xu Y., 2017, ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences, VIV-1/W1, P43, DOI [10.5194/isprs-annals-IV-1-W1-43-2017, DOI 10.5194/ISPRS-ANNALS-IV-1-W1-43-2017]
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yoon JH, 2010, PROCEEDINGS OF THE ASME DYNAMIC SYSTEMS AND CONTROL CONFERENCE 2010, VOL 2, P863
   Zhou Y, 2017, Arxiv, DOI arXiv:1711.06396
   Zollmann S., 2014, Image-based X-ray visualization techniques for spatial understanding in outdoor augmented reality, V12, DOI DOI 10.1145/2686612.2686642
NR 67
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2319
EP 2329
DI 10.1109/TVCG.2024.3372064
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400001
PM 38437110
OA hybrid
DA 2024-08-05
ER

PT J
AU Xu, SZ
   Chen, FXY
   Gong, R
   Zhang, FL
   Zhang, SH
AF Xu, Sen-Zhe
   Chen, Fiona Xiao Yu
   Gong, Ran
   Zhang, Fang-Lue
   Zhang, Song-Hai
TI BiRD: Using Bidirectional Rotation Gain Differences to Redirect Users
   during Back-and-forth Head Turns in Walking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Birds; Gain measurement; Rotation measurement; Task
   analysis; Turning; Navigation; Redirected walking; virtual reality;
   rotation gain; detection thresholds; simulator sickness
AB Redirected walking (RDW) facilitates user navigation within expansive virtual spaces despite the constraints of limited physical spaces. It employs discrepancies between human visual-proprioceptive sensations, known as gains, to enable the remapping of virtual and physical environments. In this paper, we explore how to apply rotation gain while the user is walking. We propose to apply a rotation gain to let the user rotate by a different angle when reciprocating from a previous head rotation, to achieve the aim of steering the user to a desired direction. To apply the gains imperceptibly based on such a Bidirectional Rotation gain Difference (BiRD), we conduct both measurement and verification experiments on the detection thresholds of the rotation gain for reciprocating head rotations during walking. Unlike previous rotation gains which are measured when users are turning around in place (standing or sitting), BiRD is measured during users' walking. Our study offers a critical assessment of the acceptable range of rotational mapping differences for different rotational orientations across the user's walking experience, contributing to an effective tool for redirecting users in virtual environments.
C1 [Xu, Sen-Zhe; Chen, Fiona Xiao Yu; Gong, Ran; Zhang, Song-Hai] Tsinghua Univ, Tsinghua, Peoples R China.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Wellington, New Zealand.
   [Zhang, Song-Hai] QingHai Univ, Xining, Peoples R China.
C3 Tsinghua University; Victoria University Wellington; Qinghai University
RP Xu, SZ (corresponding author), Tsinghua Univ, Tsinghua, Peoples R China.
EM xsz15@tsinghua.org.cn; xiaoyu-c23@mails.tsinghua.edu.cn;
   gongr19@mails.tsinghua.edu.cn; fanglue.zhang@vuw.ac.nz;
   shz@tsinghua.edu.cn
OI Xu, Sen-Zhe/0000-0003-2669-7814
FU National Key Research and Development Program of China
FX No Statement Available
CR Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Bruder F., 2009, Reorientation duringbody turns, P145, DOI [10.2312/EGVE/JVRC09/145-1523[6]Y., DOI 10.2312/EGVE/JVRC09/145-1523[6]Y]
   Bruder G., 2018, ICAT EGVE 2018 INT C, DOI [10.2312/egve.201813151,2[17]V, DOI 10.2312/EGVE.201813151,2[17]V]
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Dong TY, 2023, IEEE T VIS COMPUT GR, V29, P2315, DOI 10.1109/TVCG.2023.3247107
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Dong X.-M., 2019, ACM Trans. Graph., V38, DOI [10.1145/33455543[12]L, DOI 10.1145/33455543[12]L]
   Fan H. Li, 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.31792692[13]T, DOI 10.1109/TVCG.2022.31792692[13]T]
   Grechkin J., 2016, P ACM S APPL PERC SA, P113, DOI [10.1145/2931002.29310182[19]J, DOI 10.1145/2931002.2931018]
   Hamill J. Lim, 2020, Brain Sciences, V10, P2
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hutton S., Individualized Cal-ibration of Rotation Gain Thresholds for Redirected Walking
   Interrante B., 2007, IN2007 IEEE S 3D USE, DOI [10.1109/3DUI.2007.3407911,2[18]P.M., DOI 10.1109/3DUI.2007.3407911,2[18]P.M]
   Jaekl PM, 2005, EXP BRAIN RES, V163, P388, DOI 10.1007/s00221-004-2191-8
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.00-70, 10.1109/VR46266.2020.1581309443724]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Li HY, 2020, IEEE ACCESS, V8, P180210, DOI 10.1109/ACCESS.2020.3027985
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Linares D, 2016, R J, V8, P122
   Matsumoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P101, DOI [10.1109/VR46266.2020.00-76, 10.1109/VR46266.2020.1581262503135]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Neth CT, 2011, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2011.5759454
   Nguyen A, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225155
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Razzaque Z., 2001, InEurographics 2001-Short Presentations, DOI [10.2312/egs.200110361[38]M, DOI 10.2312/EGS.200110361[38]M]
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI DOI 10.1145/1450579.1450611
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Thomas J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P317, DOI [10.1109/VRW50115.2020.00071, 10.1109/VRW50115.2020.0-205]
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Wang S.-H., 2022, IEEEtransactions on visualization and computer graphics, V7
   Wang Z.-Y., 2022, IEEE Transac-tions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32240733[52]N.L., DOI 10.1109/TVCG.2022.32240733[52]N.L]
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Xu J.-H., 2023, IEEE Transactions on Visualization and Computer Graphics, V3
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   You C, 2022, INT SYM MIX AUGMENT, P603, DOI 10.1109/ISMAR55827.2022.00077
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P3327, DOI 10.1109/TVCG.2022.3158609
   Zhang SH, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P504, DOI 10.1109/VRW52623.2021.00134
NR 58
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2693
EP 2702
DI 10.1109/TVCG.2024.3372094
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400022
PM 38437103
DA 2024-08-05
ER

PT J
AU Tetzlaff, M
AF Tetzlaff, Michael
TI High-Fidelity Specular SVBRDF Acquisition From Flash Photographs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Reflectivity; Rendering (computer graphics); Three-dimensional displays;
   Optimization; Geometry; Image color analysis; Lighting; Computational
   photography; flash photography; image-based relighting; non-linear
   optimization; normal map refinement; photogrammetry; real-time
   rendering; SVBRDF acquisition
ID APPEARANCE
AB Obtaining accurate SVBRDFs from 2D photographs of shiny, heterogeneous 3D objects is a highly sought-after goal for domains like cultural heritage archiving, where it is critical to document color appearance in high fidelity. In prior work such as the promising framework by Nam et al., the problem is simplified by assuming that specular highlights exhibit symmetry and isotropy about an estimated surface normal. The present work builds on this foundation with several significant modifications. Recognizing the importance of the surface normal as an axis of symmetry, we compare nonlinear optimization for normals with a linear approximation proposed by Nam et al. and find that nonlinear optimization is superior to the linear approximation, while noting that the surface normal estimates generally have a very significant impact on the reconstructed color appearance of the object. We also examine the use of a monotonicity constraint for reflectance and develop a generalization that also enforces continuity and smoothness when optimizing continuous monotonic functions like a microfacet distribution. Finally, we explore the impact of simplifying from an arbitrary 1D basis function to a traditional parametric microfacet distribution (GGX), and we find this to be a reasonable approximation that trades some fidelity for practicality in certain applications. Both representations can be used in existing rendering architectures like game engines or online 3D viewers, while retaining accurate color appearance for fidelity-critical applications like cultural heritage or online sales.
C1 [Tetzlaff, Michael] Univ Wisconsin Stout, Dept Math Stat & Comp Sci, Menomonie, WI 54751 USA.
C3 University of Wisconsin System; University of Wisconsin Stout
RP Tetzlaff, M (corresponding author), Univ Wisconsin Stout, Dept Math Stat & Comp Sci, Menomonie, WI 54751 USA.
EM tetzlaffm@uwstout.edu
OI Tetzlaff, Michael/0000-0002-5163-069X
CR Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917
   Aittala M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766967
   Aittala M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461978
   Ashikhmin M., 2002, J GRAPHICS TOOLS, V7, P3
   Bagher MM, 2012, COMPUT GRAPH FORUM, V31, P1509, DOI 10.1111/j.1467-8659.2012.03147.x
   Bi S., 2020, ACM Trans. Graph., V38
   Bi Sai, 2020, ECCV, P294
   Boss M, 2020, PROC CVPR IEEE, P3981, DOI 10.1109/CVPR42600.2020.00404
   Cook RL, 1982, ACM Trans. Graph., V1, P7, DOI DOI 10.1145/357290.357293
   Debevec P., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P105
   Deschaintre V, 2021, PROC CVPR IEEE, P15562, DOI 10.1109/CVPR46437.2021.01531
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dong Y., 2014, ACM Trans. Graph., V33
   Dupuy J, 2015, COMPUT GRAPH FORUM, V34, P21, DOI 10.1111/cgf.12675
   Everitt C., 2001, WHITE PAPER NVIDIA, V2, P7
   Filip J, 2013, COMPUT GRAPH-UK, V37, P376, DOI 10.1016/j.cag.2013.02.010
   Fyffe G, 2016, COMPUT GRAPH FORUM, V35, P353, DOI 10.1111/cgf.12837
   Gao D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417767
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Ghosh A, 2009, COMPUT GRAPH FORUM, V28, P1161, DOI 10.1111/j.1467-8659.2009.01493.x
   Guo J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459854
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Heitz E., 2014, Journal of Computer Graphics Techniques, V3, P32
   Henzler P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480507
   Hui Z, 2017, IEEE I CONF COMP VIS, P5372, DOI 10.1109/ICCV.2017.573
   Kang KZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356492
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Khronos Group, 2014, smoothstep
   Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861
   Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891
   Levenberg K., 1944, The Quarterly of Applied Mathematics, V2, P164, DOI [DOI 10.1090/QAM/10666, 10.1090/qam/10666, 10.1090/QAM/10666]
   Li ZQ, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275055
   Ma XH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459679
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   McCamy C. S., 1976, Journal of Applied Photographic Engineering, V2, P95
   Meka A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323027
   Nam G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275017
   Nam G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980220
   Nishino K. Ikeuchi, 2005, Tech.Rep. DU-CS-05-12, P39
   Palma M., Comput. Graph. Forum, V31
   Paterson JA, 2005, COMPUT GRAPH FORUM, V24, P383, DOI 10.1111/j.1467-8659.2005.00863.x
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Riviere J, 2016, COMPUT GRAPH FORUM, V35, P191, DOI 10.1111/cgf.12719
   Riviere J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130894
   Sen P, 2009, COMPUT GRAPH FORUM, V28, P609, DOI 10.1111/j.1467-8659.2009.01401.x
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Tetzlaff Michael., 2016, Eurographics Workshop on Graphics and Cultural Heritage, P137
   TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531
   Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944
   Walter B., 2007, P 18 EUR C REND TECH, P195, DOI [10.2312/EGWR/EGSR07/195-206, DOI 10.2312/EGWR/EGSR07/195-206]
   Wang Y., 2009, ACM Trans. Graph., V28, p29:1
   Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925
   Xia R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980248
   Xu ZX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323007
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhou ZM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980247
   Zickler T, 2006, IEEE T PATTERN ANAL, V28, P1287, DOI 10.1109/TPAMI.2006.170
NR 61
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1885
EP 1896
DI 10.1109/TVCG.2023.3235277
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500012
PM 37018562
DA 2024-08-05
ER

PT J
AU Zabel, S
   Hennig, P
   Nieselt, K
AF Zabel, Susanne
   Hennig, Philipp
   Nieselt, Kay
TI VIPurPCA: Visualizing and Propagating Uncertainty in Principal Component
   Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Dimensionality reduction; visualization
AB Variables obtained by experimental measurements or statistical inference typically carry uncertainties. When an algorithm uses such quantities as input variables, this uncertainty should propagate to the algorithm's output. Concretely, we consider the classic notion of principal component analysis (PCA): If it is applied to a finite data matrix containing imperfect (i.e., uncertain) multidimensional measurements, its output-a lower-dimensional representation-is itself subject to uncertainty. We demonstrate that this uncertainty can be approximated by appropriate linearization of the algorithm's nonlinear functionality, using automatic differentiation. By itself, however, this structured, uncertain output is difficult to interpret for users. We provide an animation method that effectively visualizes the uncertainty of the lower dimensional map. Implemented as an open-source software package, it allows researchers to assess the reliability of PCA embeddings.
C1 [Zabel, Susanne] Univ Tubingen, Fac Sci, D-72076 Tubingen, Germany.
   [Hennig, Philipp] Univ Tubingen, Fac Sci, MPI Intelligent Syst, D-72076 Tubingen, Germany.
   [Hennig, Philipp; Nieselt, Kay] Max Planck Inst MPI Intelligent Syst, D-72076 Tubingen, Germany.
C3 Eberhard Karls University of Tubingen; Max Planck Society; Eberhard
   Karls University of Tubingen
RP Zabel, S (corresponding author), Univ Tubingen, Fac Sci, D-72076 Tubingen, Germany.
EM susanne.zabel@uni-tuebingen.de; philipp.hennig@uni-tuebingen.de;
   kay.nieselt@uni-tuebingen.de
RI Hennig, Philipp/KVY-3344-2024
OI Hennig, Philipp/0000-0001-7293-6092; Zabel, Susanne/0000-0003-3374-149X
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR Abadi M., 2015, TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, V1
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Athawale TM, 2021, IEEE T VIS COMPUT GR, V27, P1797, DOI 10.1109/TVCG.2020.3030394
   Barratt S, 2018, Arxiv, DOI [arXiv:1804.11010, DOI arXiv:1804.11010.v3]
   Baydin AG, 2018, J MACH LEARN RES, V18
   Bradbury J., 2018, JAX: composable transformations of Python+ NumPy programs
   Chan YH, 2013, IEEE T VIS COMPUT GR, V19, P1768, DOI 10.1109/TVCG.2013.20
   Deitrick S., 2012, PROC AUTOCARTO
   Denoeux T, 2004, IEEE T FUZZY SYST, V12, P336, DOI 10.1109/TFUZZ.2004.825990
   Dua D., 2017, UCI MACHINE LEARNING
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Görtler J, 2020, IEEE T VIS COMPUT GR, V26, P822, DOI 10.1109/TVCG.2019.2934812
   Gupta A.K., 2018, Matrix Variate Distributions
   Hasin Y, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1215-1
   Hennig P., 2013, Tec. Rep. 8
   Hennig Philipp, 2022, PROBABILISTIC NUMERI
   Higuera C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129126
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   IMAN RL, 1988, RISK ANAL, V8, P71, DOI 10.1111/j.1539-6924.1988.tb01155.x
   Janssen H, 2013, RELIAB ENG SYST SAFE, V109, P123, DOI 10.1016/j.ress.2012.08.003
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Lee JA, 2007, INFORM SCI STAT, P1
   Lee SH, 2009, STRUCT MULTIDISCIP O, V37, P239, DOI 10.1007/s00158-008-0234-7
   Levontin P., 2020, Visualising Uncertainty: A Short Introduction
   Li XH, 2020, NAT GENET, V52, P969, DOI 10.1038/s41588-020-0676-4
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu XJ, 2005, BIOINFORMATICS, V21, P3637, DOI 10.1093/bioinformatics/bti583
   Maclaurin D., 2016, THESIS
   Matthews M., 2008, DRDC Atlantic CR, V177
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Ochoa B., 2006, PROC WORKSHOP STAT M
   Paszke A., 2017, NEURIPS
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pearson R., 2020, Pumadata: Various data sets for use with the puma package
   Pearson RD, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-211
   Perez D. A., 2020, PROC IEEE INT INSTRU, P1
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Posth C, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abi7673
   Saul L. K., 2006, SEMISUPERVISED LEARN, V3, P1, DOI 10.1234/12345678
   Schenkendorf R., 2014, PROC PHM SOC EUR C, V2
   Schulz C, 2017, IEEE T VIS COMPUT GR, V23, P531, DOI 10.1109/TVCG.2016.2598919
   Seeger M., 2017, arXiv
   Skeels M, 2010, INFORM VISUAL, V9, P70, DOI 10.1057/ivs.2009.1
   Spearman C, 1904, AM J PSYCHOL, V15, P201, DOI 10.2307/1412107
   Spiegelhalter D, 2011, SCIENCE, V333, P1393, DOI 10.1126/science.1191181
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   Van Der Maaten L., 2009, Journal of Machine Learning Research, V10, P13, DOI DOI 10.1080/13506280444000102
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Dorp JR, 2003, METRIKA, V58, P85, DOI 10.1007/s001840200230
   Weiskopf D, 2022, FRONT BIOINFORM, V2, DOI 10.3389/fbinf.2022.793819
   Yu-Hsuan Chan, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P43, DOI 10.1109/VAST.2010.5652460
   Zhang DP, 2022, IEEE T VIS COMPUT GR, V28, P443, DOI 10.1109/TVCG.2021.3114679
NR 56
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 2011
EP 2022
DI 10.1109/TVCG.2023.3345532
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500005
PM 38127602
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Zhao, HN
   Bryant, GW
   Griffin, W
   Terrill, JE
   Chen, J
AF Zhao, Henan
   Bryant, Garnett W.
   Griffin, Wesley
   Terrill, Judith E.
   Chen, Jian
TI Evaluating Glyph Design for Showing Large-Magnitude-Range Quantum Spins
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Image color analysis; Visualization; Three-dimensional
   displays; Data visualization; Behavioral sciences; Shape; Bivariate
   glyph; 3D glyph; large-magnitude-range; quantitative visualization;
   separable and integral dimension pairs
ID VISUALIZATION; PERCEPTION; SEARCH
AB We present experimental results to explore a form of bivariate glyphs for representing large-magnitude-range vectors. The glyphs meet two conditions: (1) two visual dimensions are separable; and (2) one of the two visual dimensions uses a categorical representation (e.g., a categorical colormap). We evaluate how much these two conditions determine the bivariate glyphs' effectiveness. The first experiment asks participants to perform three local tasks requiring reading no more than two glyphs. The second experiment scales up the search space in global tasks when participants must look at the entire scene of hundreds of vector glyphs to get an answer. Our results support that the first condition is necessary for local tasks when a few items are compared. But it is not enough for understanding a large amount of data. The second condition is necessary for perceiving global structures of examining very complex datasets. Participants' comments reveal that the categorical features in the bivariate glyphs trigger emergent optimal viewers' behaviors. This work contributes to perceptually accurate glyph representations for revealing patterns from large scientific results. We release source code, quantum physics data, training documents, participants' answers, and statistical analyses for reproducible science at https://osf.io/4xcf5/?view_only=94123139df9c4ac984a1e0df811cd580.
C1 [Zhao, Henan] Univ Maryland, Baltimore, MD 21250 USA.
   [Bryant, Garnett W.; Terrill, Judith E.] NIST, Gaithersburg, MD 20899 USA.
   [Griffin, Wesley] Stellar Sci, Albuquerque, NM 87110 USA.
   [Chen, Jian] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Maryland; University of Maryland Baltimore;
   National Institute of Standards & Technology (NIST) - USA; University
   System of Ohio; Ohio State University
RP Chen, J (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM henan1@umbc.edu; garnett.bryant@nist.gov; griffin5@umbc.edu;
   judith.terrill@nist.gov; chen.8028@osu.edu
FU NSF
FX No Statement Available
CR Acevedo D., 2007, PROC IEEE VIS POSTER
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   [Anonymous], 2013, EUROGRAPHICS STARS, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   [Anonymous], 1996, ACM Transactions, DOI DOI 10.1145/230562.230563
   Ariely D, 2001, PSYCHOL SCI, V12, P157, DOI 10.1111/1467-9280.00327
   Bertin J., 1967, Semiology of Graphics: diagrams, networks, maps
   Biederman I., 1977, PROC ACM SIGGRAPH WO, P75, DOI DOI 10.1145/1024273.1024283
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Buetti S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56238-9
   Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005
   CALLAGHAN TC, 1989, PERCEPT PSYCHOPHYS, V46, P299, DOI 10.3758/BF03204984
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   Chen ZM, 2021, ATTEN PERCEPT PSYCHO, V83, P1240, DOI 10.3758/s13414-020-02067-2
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cohen J., 1988, Statistical power analysis for the behavioral sciences
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   Drew T, 2013, PSYCHOL SCI, V24, P1848, DOI 10.1177/0956797613479386
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   Eckstein MP, 2017, CURR BIOL, V27, P2827, DOI 10.1016/j.cub.2017.07.068
   Forsberg AS, 2009, IEEE T VIS COMPUT GR, V15, P1219, DOI 10.1109/TVCG.2009.126
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   GARNER WR, 1970, COGNITIVE PSYCHOL, V1, P225, DOI 10.1016/0010-0285(70)90016-2
   Gerrits T, 2017, IEEE T VIS COMPUT GR, V23, P980, DOI 10.1109/TVCG.2016.2598998
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Healey C. G., 1995, ACM Transactions on Modeling and Computer Simulation, V5, P190, DOI 10.1145/217853.217855
   Healey CG, 1999, IEEE T VIS COMPUT GR, V5, P145, DOI 10.1109/2945.773807
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Kindmann G, 2006, IEEE T VIS COMPUT GR, V12, P1329, DOI 10.1109/TVCG.2006.134
   Kundel HL, 2007, RADIOLOGY, V242, P396, DOI 10.1148/radiol.2422051997
   Li R, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P26, DOI 10.1109/SciVis.2018.8823764
   Lie A. E., 2009, PROC SPRING C COMPUT, P19, DOI [DOI 10.1145/1980462.1980470, 10.1145/1980462.1980470]
   Lleras A, 2020, ATTEN PERCEPT PSYCHO, V82, P394, DOI 10.3758/s13414-019-01928-9
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Maule J, 2014, J OPT SOC AM A, V31, pA93, DOI 10.1364/JOSAA.31.000A93
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nothelfer C, 2017, J EXP PSYCHOL HUMAN, V43, P1667, DOI 10.1037/xhp0000314
   O'Shea JP, 2010, J VISION, V10, DOI 10.1167/10.12.21
   Oliva Aude, 2005, P251, DOI 10.1016/B978-012375731-9/50045-8
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Ryan G, 2019, IEEE T VIS COMPUT GR, V25, P872, DOI 10.1109/TVCG.2018.2865264
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Sekimoto T., 2022, Sci. Rep., V12, P1
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P489, DOI 10.1109/TVCG.2015.2467759
   TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Urness T, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P115, DOI 10.1109/VISUAL.2003.1250362
   WARE C., 2012, INFORM VISUALIZATION
   Ware C, 2009, IEEE T VIS COMPUT GR, V15, P1523, DOI 10.1109/TVCG.2009.175
   Whitney D, 2018, ANNU REV PSYCHOL, V69, P105, DOI 10.1146/annurev-psych-010416-044232
   Wineland DJ, 2013, REV MOD PHYS, V85, P1103, DOI 10.1103/RevModPhys.85.1103
   Wolfe JM, 2021, PSYCHON B REV, V28, P1060, DOI 10.3758/s13423-020-01859-9
   Wolfe JM, 2019, CURR OPIN PSYCHOL, V29, P19, DOI 10.1016/j.copsyc.2018.11.005
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Zhang CG, 2016, IEEE T VIS COMPUT GR, V22, P797, DOI 10.1109/TVCG.2015.2467435
   Zhao HN, 2017, IEEE T VIS COMPUT GR, V23, P1691, DOI 10.1109/TVCG.2016.2539949
NR 59
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1868
EP 1884
DI 10.1109/TVCG.2022.3232591
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500007
PM 37015635
DA 2024-08-05
ER

PT J
AU Elavsky, F
   Nadolskis, L
   Moritz, D
AF Elavsky, Frank
   Nadolskis, Lucas
   Moritz, Dominik
TI Data Navigator: An Accessibility-Centered Data Navigation Toolkit
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE accessibility; visualization; tools; technical materials; platforms;
   data interaction
ID VISUALIZATION
AB Making data visualizations accessible for people with disabilities remains a significant challenge in current practitioner efforts. Existing visualizations often lack an underlying navigable structure, fail to engage necessary input modalities, and rely heavily on visual-only rendering practices. These limitations exclude people with disabilities, especially users of assistive technologies. To address these challenges, we present Data Navigator: a system built on a dynamic graph structure, enabling developers to construct navigable lists, trees, graphs, and flows as well as spatial, diagrammatic, and geographic relations. Data Navigator supports a wide range of input modalities: screen reader, keyboard, speech, gesture detection, and even fabricated assistive devices. We present 3 case examples with Data Navigator, demonstrating we can provide accessible navigation structures on top of raster images, integrate with existing toolkits at scale, and rapidly develop novel prototypes. Data Navigator is a step towards making accessible data visualizations easier to design and implement.
C1 [Elavsky, Frank; Nadolskis, Lucas; Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Elavsky, F (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM fje@cmu.edu; nadolskis@cmu.edu; domoritz@cmu.edu
OI Moritz, Dominik/0000-0002-3110-1053
FU Apple, Inc.
FX We want to take this time to express immense gratitude for Reviewer 1,
   whose generous and thorough feedback helped this project find its true
   vision. Elavsky also wants to thank the many folks who have encouraged
   this project's ideation and formation over the last few years. This work
   was supported by a grant from Apple, Inc. Any views, opinions, findings,
   and conclusions or recommendations expressed in this material are those
   of the authors and should not be interpreted as reflecting the views,
   policies or position, either expressed or implied, of Apple Inc.
CR [Anonymous], 1999, Design Studies, DOI [10.1016/s0142-694x(98)00044-1, DOI 10.1016/S0142-694X(98)00044-1]
   Blanco Matt, 2022, IEEE VIS Posters
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   BOYD LH, 1990, J VISUAL IMPAIR BLIN, V84, P496
   Chundury P, 2022, IEEE T VIS COMPUT GR, V28, P1084, DOI 10.1109/TVCG.2021.3114829
   de Greef L., 2021, 23 INT ACM SIGACCESS, DOI DOI 10.1145/3441852.34764688
   Dot Pad inc, 2020, Dot pad-the first tactile graphics display for the visually impaired
   Dourish P., 2003, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V12, P465, DOI 10.1023/A:1026149119426
   Durant E, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010622
   Elavsky F., 2021, Defensive Publication Series, V4220, P6
   Elavsky F, 2022, COMPUT GRAPH FORUM, V41, P57, DOI 10.1111/cgf.14522
   Fan DY, 2023, ACM T ACCESS COMPUT, V16, DOI 10.1145/3557899
   Gansner ER, 2000, SOFTWARE PRACT EXPER, V30, P1203, DOI 10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.0.CO;2-N
   Giraud S, 2016, LECT NOTES COMPUT SC, V9759, P61, DOI 10.1007/978-3-319-41267-2_9
   Godfrey AJR, 2018, LECT NOTES COMPUT SC, V10896, P590, DOI 10.1007/978-3-319-94277-3_92
   Highsoft, Highcharts: Render millions of chart points with the boost module
   Highsoft, 2018, Stacked column demo
   Highsoft, 2018, Highcharts accessibility module: information and demos
   Hurst A., 2013, P 12 INT C INT DES C, P635, DOI [DOI 10.1145/2485760.2485883, 10.1145/2485760.2485883]
   Jung C, 2022, IEEE T VIS COMPUT GR, V28, P1095, DOI 10.1109/TVCG.2021.3114846
   Kim JH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581532
   Kim NW, 2021, COMPUT GRAPH FORUM, V40, P173, DOI 10.1111/cgf.14298
   Lin CY, 2014, RES DEV DISABIL, V35, P1963, DOI 10.1016/j.ridd.2014.04.028
   Lundgard A, 2022, IEEE T VIS COMPUT GR, V28, P1073, DOI 10.1109/TVCG.2021.3114770
   Lundgard A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P16, DOI [10.1109/VISUAL.2019.8933762, 10.1109/visual.2019.8933762]
   Ma'ayan D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376253
   Marriott K., 2021, Interactions, V28, P47, DOI DOI 10.1145/3457875.1
   Reid B. E., 2022, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.4262991
   Rogers Y., 2014, P SIGCHI C HUM FACT, DOI DOI 10.1145/2556288.25571843,5
   Sarsenbayeva Z., 2022, ACM Computing Surveys, V55, P1, DOI DOI 10.1145/35435093
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Sharif A., 2021, 23 INT ACM SIGACCESS, DOI DOI 10.1145/3441852.34712022
   Sharif A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517431
   Sharif A, 2018, CONSUM COMM NETWORK
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siean A.-I., 2021, 23 INT ACM SIGACCESS, DOI DOI 10.1145/3441852.34712123
   Sorge V, 2016, LECT NOTES COMPUT SC, V9758, P43, DOI 10.1007/978-3-319-41264-1_6
   Thompson J, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581186
   Visa, 2022, Visa Chart Components
   WAI, 2016, WCAG standard
   WAI, 2017, WCAG standard
   WAI, 2017, Technical report
   WebAIM, WAVE, the web accessibility evaluation tool
   Wobbrock Jacob O., 2011, ACM Transactions on Accessible Computing, V3, P1, DOI [10.1145/1952383.1952384, DOI 10.1145/1952383.1952384]
   Ye K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392375
   Zong J, 2022, COMPUT GRAPH FORUM, V41, P15, DOI 10.1111/cgf.14519
NR 46
TC 1
Z9 1
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 803
EP 813
DI 10.1109/TVCG.2023.3327393
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500004
PM 37903045
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Herzberger, L
   Hadwiger, M
   Krüger, R
   Sorger, P
   Pfister, H
   Gröller, E
   Beyer, J
AF Herzberger, Lukas
   Hadwiger, Markus
   Krueger, Robert
   Sorger, Peter
   Pfister, Hanspeter
   Groeller, Eduard
   Beyer, Johanna
TI Residency Octree: A Hybrid Approach for Scalable Web-Based Multi-Volume
   Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Volume rendering; ray-guided rendering; large-scale data; out-of-core
   rendering; multi-resolution; multi-channel; web-based visualization
ID OF-THE-ART; EXPLORATION
AB We present a hybrid multi-volume rendering approach based on a novel Residency Octree that combines the advantages of out-of-core volume rendering using page tables with those of standard octrees. Octree approaches work by performing hierarchical tree traversal. However, in octree volume rendering, tree traversal and the selection of data resolution are intrinsically coupled. This makes fine-grained empty-space skipping costly. Page tables, on the other hand, allow access to any cached brick from any resolution. However, they do not offer a clear and efficient strategy for substituting missing high-resolution data with lower-resolution data. We enable flexible mixed-resolution out-of-core multi-volume rendering by decoupling the cache residency of multi-resolution data from a resolution-independent spatial subdivision determined by the tree. Instead of one-to-one node-to-brick correspondences, each residency octree node is mapped to a set of bricks from different resolution levels. This makes it possible to efficiently and adaptively choose and mix resolutions, adapt sampling rates, and compensate for cache misses. At the same time, residency octrees support fine-grained empty-space skipping, independent of the data subdivision used for caching. Finally, to facilitate collaboration and outreach, and to eliminate local data storage, our implementation is a web-based, pure client-side renderer using WebGPU and WebAssembly. Our method is faster than prior approaches and efficient for many data channels with a flexible and adaptive choice of data resolution.
C1 [Herzberger, Lukas; Groeller, Eduard] TU Wien, Vienna, Austria.
   [Hadwiger, Markus] King Abdullah Univ Sci & Technol KAUST, Thuwal, Saudi Arabia.
   [Krueger, Robert; Pfister, Hanspeter; Beyer, Johanna] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA USA.
   [Krueger, Robert; Sorger, Peter] Harvard Med Sch, Cambridge, MA USA.
C3 Technische Universitat Wien; King Abdullah University of Science &
   Technology; Harvard University
RP Herzberger, L (corresponding author), TU Wien, Vienna, Austria.
EM herzberger@cg.tuwien.ac.at; markus.hadwiger@kaust.edu.sa;
   robert_krueger@hms.harvard.edu; peter_sorger@hms.harvard.edu;
   pfister@seas.harvard.edu; groeller@cg.tuwien.ac.at; jbeyer@g.harvard.edu
RI Heinzl, Christoph/D-7272-2016; Herzberger, Lukas/HOA-6306-2023
OI Heinzl, Christoph/0000-0002-3173-8871; Herzberger,
   Lukas/0000-0002-9047-065X; Sorger, Peter/0000-0002-3364-1838; Pfister,
   Hanspeter/0000-0002-3620-2582; Beyer, Johanna/0000-0002-3505-9171;
   Krueger, Robert/0000-0002-6468-8356
FU NCI
FX No Statement Available
CR Adochiei FC, 2019, INT SYMP ADV TOP, DOI 10.1109/atee.2019.8724963
   Arbelaiz A, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338131
   Bethel E.W., 2012, HIGH PERFORMANCE VIS
   Beyer J., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P127, DOI 10.1109/LDAV.2011.6092332
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Brix T., 2014, arXiv
   Congote J., 2011, P 16 INT C 3D WEB TE, P137, DOI DOI 10.1145/2010425.2010449
   Cook AW, 2004, J FLUID MECH, V511, P333, DOI 10.1017/S0022112004009681
   Crassin C., 2009, P 2009 S INT 3D GRAP, P15, DOI DOI 10.1145/1507149.1507152
   Deakin L, 2019, SA'19: SIGGRAPH ASIA 2019 TECHNICAL BRIEFS, P25, DOI 10.1145/3355088.3365164
   Deakin LJ, 2020, COMPUT VIS MEDIA, V6, P53, DOI 10.1007/s41095-019-0155-y
   Díaz-García J, 2018, COMPUT GRAPH-UK, V73, P1, DOI 10.1016/j.cag.2018.02.007
   Drees D, 2022, Arxiv, DOI arXiv:2207.12746
   Faludi B., 2022, P C HIGH PERF GRAPH, P1, DOI [10.2312/hpg.20211279, DOI 10.2312/HPG.20211279]
   Fernandes IB, 2020, SIBGRAPI, P39, DOI 10.1109/SIBGRAPI51738.2020.00014
   Fogal T., 2010, P VIS MOD VIS WORKSH, P139, DOI DOI 10.2312/EGGH/HPG10/057-066
   Fogal Thomas, 2013, Proc IEEE Symp Large Scale Data Anal Vis, V2013, P43, DOI 10.1109/LDAV.2013.6675157
   Google, 2022, Neuroglancer: WebGL-Based Viewer for Volumetric Data
   Hadwiger M, 2018, IEEE T VIS COMPUT GR, V24, P974, DOI 10.1109/TVCG.2017.2744238
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Jessup J, 2022, IEEE T VIS COMPUT GR, V28, P259, DOI 10.1109/TVCG.2021.3114786
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Lin JR, 2023, CELL, V186, P363, DOI 10.1016/j.cell.2022.12.028
   Lin JR, 2018, ELIFE, V7, DOI 10.7554/eLife.31657
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Liu BQ, 2013, IEEE T VIS COMPUT GR, V19, P1732, DOI 10.1109/TVCG.2012.151
   Manz T, 2022, NAT METHODS, V19, P515, DOI 10.1038/s41592-022-01482-7
   Marton F, 2019, COMPUT GRAPH FORUM, V38, P53, DOI 10.1111/cgf.13671
   Maxfield M., 2023, W3C Working Draft
   Mobeen MM, 2012, IEEE I C EMBED SOFTW, P381, DOI 10.1109/HPCC.2012.58
   Moore J, 2021, NAT METHODS, V18, P1496, DOI 10.1038/s41592-021-01326-w
   Mwalongo F., 2018, P C VIS MOD VIS EG V, P147, DOI [10.2312/vmv.201812641,3, DOI 10.2312/VMV.201812641,3]
   Nirmal A. J., Cancer Discovery, V12
   Nystad J., 2012, P 4 ACM SIGGRAPH EUR, P105, DOI 10.2312/EGGH/HPG12/105-114
   Qiao L, 2017, INT J TELEMED APPL, V2017, DOI 10.1155/2017/4074137
   Raji M, 2017, SYMP LARG DATA ANAL, P45, DOI 10.1109/LDAV.2017.8231850
   Rashid R, 2022, NAT BIOMED ENG, V6, P515, DOI 10.1038/s41551-021-00789-8
   Rodríguez MB, 2014, COMPUT GRAPH FORUM, V33, P77, DOI 10.1111/cgf.12280
   Rossberg Andreas, 2019, Tech. Rep.
   Sarton J, 2020, LECT NOTES COMPUT SC, V11887, P623, DOI 10.1007/978-3-030-34356-9_47
   Sarton J, 2020, IEEE T VIS COMPUT GR, V26, P3008, DOI 10.1109/TVCG.2019.2912752
   Schneider J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P293, DOI 10.1109/VISUAL.2003.1250385
   Schubert N, 2011, COMPUT SCI-RES DEV, V26, P39, DOI 10.1007/s00450-010-0141-1
   Usher W, 2020, SYMP LARG DATA ANAL, P27, DOI 10.1109/LDAV51489.2020.00010
   Wang JM, 2021, J VISUAL-JAPAN, V24, P531, DOI 10.1007/s12650-020-00719-x
   Wangkaoom K., 2015, P 12 INT C ELECT ENG, P1, DOI [DOI 10.1109/ECTICON.2015.72070911,3, 10.1109/ECTICon.2015.72070911,3]
   Xue J, 2019, IEEE INT CONF MULTI, P599, DOI 10.1109/ICMEW.2019.00109
   Yang Y, 2015, WEB3D 2015, P65, DOI 10.1145/2775292.2775323
   Zellmann S., 2018, P S PAR GRAPH VIS EG, V2, P3
   Zellmann S., 2019, P IEEE C VIS 2019 OC, P1, DOI [10.1109/VISUAL.2019.89336312,3, DOI 10.1109/VISUAL.2019.89336312,3]
   Zellmann S, 2021, IEEE T VIS COMPUT GR, V27, P1904, DOI 10.1109/TVCG.2019.2938957
   Zellmann S, 2019, IEEE PAC VIS SYMP, P222, DOI 10.1109/PacificVis.2019.00033
NR 53
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1380
EP 1390
DI 10.1109/TVCG.2023.3327193
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500001
PM 37889813
OA Green Submitted, Green Accepted
DA 2024-08-05
ER

PT J
AU Jeon, H
   Kuo, YH
   Aupetit, M
   Ma, KL
   Seo, J
AF Jeon, Hyeon
   Kuo, Yun-Hsin
   Aupetit, Michael
   Ma, Kwan-Liu
   Seo, Jinwook
TI <i>Classes</i><i> are</i><i> not</i><i> Clusters:</i> Improving
   Label-based Evaluation of Dimensionality Reduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Distortion measurement; Reliability; Dimensionality reduction; Nonlinear
   distortion; Extraterrestrial measurements; Scalability; Degradation;
   Dimensionality Reduction; Clustering; Clustering Validation Measures;
   Dimensionality Reduction Evaluation
ID VISUALIZATION; PERCEPTION; TOPOLOGY; QUALITY
AB A common way to evaluate the reliability of dimensionality reduction (DR) embeddings is to quantify how well labeled classes form compact, mutually separated clusters in the embeddings. This approach is based on the assumption that the classes stay as clear clusters in the original high-dimensional space. However, in reality, this assumption can be violated; a single class can be fragmented into multiple separated clusters, and multiple classes can be merged into a single cluster. We thus cannot always assure the credibility of the evaluation using class labels. In this paper, we introduce two novel quality measures-Label-Trustworthiness and Label-Continuity (Label-T&C)-advancing the process of DR evaluation based on class labels. Instead of assuming that classes are well-clustered in the original space, Label-T&C work by (1) estimating the extent to which classes form clusters in the original and embedded spaces and (2) evaluating the difference between the two. A quantitative evaluation showed that Label-T&C outperform widely used DR evaluation measures (e.g., Trustworthiness and Continuity, Kullback-Leibler divergence) in terms of the accuracy in assessing how well DR embeddings preserve the cluster structure, and are also scalable. Moreover, we present case studies demonstrating that Label-T&C can be successfully used for revealing the intrinsic characteristics of DR techniques and their hyperparameters.
C1 [Jeon, Hyeon; Seo, Jinwook] Seoul Natl Univ, Seoul, South Korea.
   [Kuo, Yun-Hsin; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA USA.
   [Aupetit, Michael] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
C3 Seoul National University (SNU); University of California System;
   University of California Davis; Qatar Foundation (QF); Hamad Bin Khalifa
   University-Qatar; Qatar Computing Research Institute
RP Jeon, H (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM hj@hcil.snu.ac.kr; yskuo@ucdavis.edu; maupetit@hbku.edu.qa;
   klma@ucdavis.edu; jseo@snu.ac.kr
OI Ma, Kwan-Liu/0000-0001-8086-0366; Kuo, Yun-Hsin/0009-0000-1891-8993
FU National Research Foundation of Korea (NRF)
FX No Statement Available
CR Angelini M, 2022, IEEE T VIS COMPUT GR, V28, P4770, DOI 10.1109/TVCG.2021.3104879
   Aupetit M, 2005, NEUROCOMPUTING, V63, P139, DOI 10.1016/j.neucom.2004.04.009
   Aupetit M., 2022, arXiv
   Aupetit M, 2014, P 5 WORKSH TIM ERR N, P134
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Aupetit M, 2022, 2022 IEEE WORKSHOP ON TOPOLOGICAL DATA ANALYSIS AND VISUALIZATION (TOPOINVIS 2022), P70, DOI 10.1109/TopoInVis57755.2022.00014
   Aupetit M, 2014, IEEE CONF VIS ANAL, P221, DOI 10.1109/VAST.2014.7042500
   Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Ben-David S., 2008, Advances in Neural Information Processing Systems, V21, DOI [10.5555/2981780.2981796, DOI 10.5555/2981780.2981796]
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Brehmer M., 2014, P IEEE VIS WORKSH TI, P1, DOI DOI 10.1145/2669557.2669559
   Calinski Tadeusz, 1974, Communications in Statistics, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Cao YS, 2017, Arxiv, DOI arXiv:1708.03229
   Chazal F, 2018, J MACH LEARN RES, V18
   Chazal F, 2011, FOUND COMPUT MATH, V11, P733, DOI 10.1007/s10208-011-9098-0
   Colange B., 2020, Advances in Neural Information Processing Systems, V33, P13214, DOI [10.5555/3495724.3496832, DOI 10.5555/3495724.3496832]
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Di Caro L, 2010, LECT NOTES ARTIF INT, V6119, P125
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Etemadpour Ronak, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P51
   Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617
   Fadel SG, 2015, NEUROCOMPUTING, V150, P546, DOI 10.1016/j.neucom.2014.07.071
   François D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037
   Fujiwara T, 2022, Arxiv, DOI arXiv:2206.13891
   Gunnemann S., 2010, MULTICLUST
   Heulot N., 2013, EUROVIS WORKSHOP VIS, DOI [10.2312/PE.VAMP.VAMP2013.011-015, DOI 10.2312/PE.VAMP.VAMP2013.011-015]
   Jeon H., 2022, arXiv
   Jeon H, 2022, IEEE VIS CONF, P80, DOI 10.1109/VIS54862.2022.00025
   Jeon H, 2022, Arxiv, DOI arXiv:2209.10042
   Jeon H, 2022, IEEE T VIS COMPUT GR, V28, P551, DOI 10.1109/TVCG.2021.3114833
   Ji ZC, 2021, J AM STAT ASSOC, V116, P471, DOI 10.1080/01621459.2021.1880920
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Lai CH, 2022, IEEE VIS CONF, P75, DOI 10.1109/VIS54862.2022.00024
   Lam SK, 2015, P 2 WORKSH LLVM COMP, P1, DOI [10.1145/2833157.2833162, DOI 10.1145/2833157.2833162]
   Lee JA, 2007, INFORM SCI STAT, P1, DOI 10.1007/978-0-387-39351-3
   Lee JA, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM), P163, DOI 10.1109/CIDM.2014.7008663
   Lee JA, 2011, PROCEDIA COMPUT SCI, V4, P538, DOI 10.1016/j.procs.2011.04.056
   Lespinats S, 2007, IEEE T NEURAL NETWOR, V18, P1265, DOI 10.1109/TNN.2007.891682
   Lespinats S, 2011, COMPUT GRAPH FORUM, V30, P113, DOI 10.1111/j.1467-8659.2010.01835.x
   Liu Y., 2010, 2010 IEEE 10th International Conference on Data Mining ICDM, P911, DOI 10.1109/icdm.2010.35
   Liu YC, 2013, IEEE T CYBERNETICS, V43, P982, DOI 10.1109/TSMCB.2012.2220543
   Martins RM, 2014, COMPUT GRAPH-UK, V41, P26, DOI 10.1016/j.cag.2014.01.006
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Moor M., 2020, INT C MACH LEARN, P7045
   Motta R, 2015, NEUROCOMPUTING, V150, P583, DOI 10.1016/j.neucom.2014.09.063
   Narayan A, 2021, NAT BIOTECHNOL, V39, P765, DOI 10.1038/s41587-020-00801-7
   Nene S.A., 1996, Columbia object image library (COIL-100)
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Quadri GJ, 2023, IEEE T VIS COMPUT GR, V29, P4312, DOI 10.1109/TVCG.2022.3189883
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J, 2006, NEURAL NETWORKS, V19, P889, DOI 10.1016/j.neunet.2006.05.014
   Venna J, 2010, J MACH LEARN RES, V11, P451
   Vinh NX, 2009, P 26 ANN INT C MACH, P1073, DOI DOI 10.1145/1553374.1553511
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1828, DOI 10.1109/TVCG.2017.2701829
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Wattenberg M., 2016, Distill, V1, pe2
   Wenskovitch J, 2018, IEEE T VIS COMPUT GR, V24, P131, DOI 10.1109/TVCG.2017.2745258
   Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xiang RZ, 2021, FRONT GENET, V12, DOI 10.3389/fgene.2021.646936
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Yang Y, 2021, CELL REP, V36, DOI 10.1016/j.celrep.2021.109442
   Zubaroglu A., 2020, P 2019 3 INT C BIG D, P142, DOI [10.1145/3372454.3372481, DOI 10.1145/3372454.3372481]
NR 74
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 781
EP 791
DI 10.1109/TVCG.2023.3327187
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500104
PM 37922177
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Kay, M
AF Kay, Matthew
TI ggdist: Visualizations of Distributions and Uncertainty in the Grammar
   of Graphics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty visualization; probability distributions; confidence
   distributions; grammar of graphics
ID PARAMETER; DESIGN
AB The grammar of graphics is ubiquitous, providing the foundation for a variety of popular visualization tools and toolkits. Yet support for uncertainty visualization in the grammar graphics-beyond simple variations of error bars, uncertainty bands, and density plots-remains rudimentary. Research in uncertainty visualization has developed a rich variety of improved uncertainty visualizations, most of which are difficult to create in existing grammar of graphics implementations. ggdist, an extension to the popular ggplot2 grammar of graphics toolkit, is an attempt to rectify this situation. ggdist unifies a variety of uncertainty visualization types through the lens of distributional visualization, allowing functions of distributions to be mapped to directly to visual channels (aesthetics), making it straightforward to express a variety of (sometimes weird!) uncertainty visualization types. This distributional lens also offers a way to unify Bayesian and frequentist uncertainty visualization by formalizing the latter with the help of confidence distributions. In this paper, I offer a description of this uncertainty visualization paradigm and lessons learned from its development and adoption: ggdist has existed in some form for about six years (originally as part of the tidybayes R package for post-processing Bayesian models), and it has evolved substantially over that time, with several rewrites and API re-organizations as it changed in response to user feedback and expanded to cover increasing varieties of uncertainty visualization types. Ultimately, given the huge expressive power of the grammar of graphics and the popularity of tools built on it, I hope a catalog of my experience with ggdist will provide a catalyst for further improvements to formalizations and implementations of uncertainty visualization in grammar of graphics ecosystems. A free copy of this paper is available at https://osf.io/2gsz6. All supplemental materials are available at https://github.com/mjskay/ggdist-paper and are archived on Zenodo at doi:10.5281/zenodo.7770984.
C1 [Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Kay, M (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM mjskay@northwestern.edu
OI Kay, Matthew/0000-0001-9446-0419
FU NSF
FX No Statement Available
CR Allen M., 2019, Wellcome open research, V4, DOI [10.12688/wellcomeopenres.15191.11, DOI 10.12688/WELLCOMEOPENRES.15191.11]
   Amrhein V, 2022, J INF TECHNOL-UK, V37, P316, DOI 10.1177/02683962221105904
   Ancker JS, 2006, J AM MED INFORM ASSN, V13, P608, DOI 10.1197/jamia.M2115
   Barrowman NJ, 2003, AM STAT, V57, P268, DOI 10.1198/0003130032369
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowman AW, 2019, J ROY STAT SOC A, V182, P403, DOI 10.1111/rssa.12379
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   BURKNER P.-C., 2022, posterior: Tools for working with posterior distributions
   Cairo A., 2018, OpenNews-Source
   Codd E. F., 1990, Relational Journal, P3
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Csardi Gabor, 2019, CRAN
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Gilbert P., numderiv: Accurate numerical derivatives
   HABER RN, 1982, IEEE COMPUT GRAPH, V2, P23
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   HENDERSON HV, 1981, BIOMETRICS, V37, P391, DOI 10.2307/2530428
   Henry L., 2023, rlang: functions for base types and core R and 'Tidyverse' features
   Hornik K, 2012, WIRES COMPUT STAT, V4, P394, DOI 10.1002/wics.1212
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Huron S, 2013, IEEE T VIS COMPUT GR, V19, P2446, DOI 10.1109/TVCG.2013.227
   Hyndman RJ, 1996, AM STAT, V50, P120, DOI 10.2307/2684423
   Jackson CH, 2008, AM STAT, V62, P340, DOI 10.1198/000313008X370843
   Juul JL, 2021, NAT PHYS, V17, P5, DOI 10.1038/s41567-020-01121-y
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kay M., 2023, tidybayes: Tidy data and geoms for Bayesian models, DOI [10.5281/zenodo.13081511, DOI 10.5281/ZENODO.13081511]
   Kay M., 2023, ggdist: Visualizations of distributions and uncertainty, DOI [10.5281/zenodo.38796201, DOI 10.5281/ZENODO.38796201]
   Kay M., 2018, The Stan Forums
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kruschke JK, 2018, ADV METH PRACT PSYCH, V1, P270, DOI 10.1177/2515245918771304
   Liu L, 2019, IEEE T VIS COMPUT GR, V25, P882, DOI 10.1109/TVCG.2018.2865193
   Liu Y, 2015, STAT COMPUT, V25, P809, DOI 10.1007/s11222-015-9563-8
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murrell P., 2022, Vectorised pattern fills in R graphics, DOI [10.17608/k6.auckland.19945787, DOI 10.17608/K6.AUCKLAND.19945787]
   Newman GE, 2012, PSYCHON B REV, V19, P601, DOI 10.3758/s13423-012-0247-5
   O'Hara-Wild Mitchell., 2022, DISTRIBUTIONAL VECTO
   Pu XY, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580837
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   R Core Team, 2023, A language and environment for statistical computing
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Spiegelhalter DJ, 1999, J ROY STAT SOC A STA, V162, P45, DOI 10.1111/1467-985X.00120
   Sun Y, 2011, J COMPUT GRAPH STAT, V20, P316, DOI 10.1198/jcgs.2011.09224
   Tidyverse Team, 2020, Dot prefix. Tidyverse Design Guide
   Wickham H., 2019, Advanced R, V2nd ed.
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wickham H, 2011, IEEE T VIS COMPUT GR, V17, P2223, DOI 10.1109/TVCG.2011.227
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L, 1999, AM STAT, V53, P276, DOI 10.2307/2686111
   Wilkinson L., 2005, The Grammar of Graphics. Statistics and Computing, V1, P9
   Xie MG, 2013, INT STAT REV, V81, P3, DOI 10.1111/insr.12000
NR 55
TC 4
Z9 4
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 414
EP 424
DI 10.1109/TVCG.2023.3327195
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500117
PM 37883271
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lin, TC
   Aouididi, A
   Chen, ZT
   Beyer, J
   Pfister, H
   Wang, JH
AF Lin, Tica
   Aouididi, Alexandre
   Chen, Zhutian
   Beyer, Johanna
   Pfister, Hanspeter
   Wang, Jui-Hsien
TI VIRD: Immersive Match Video Analysis for High-Performance Badminton
   Coaching
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sports Analytics; Immersive Analytics; Data Visualization
ID VISUALIZATION; ENVIRONMENT; NAVIGATION
AB Badminton is a fast-paced sport that requires a strategic combination of spatial, temporal, and technical tactics. To gain a competitive edge at high-level competitions, badminton professionals frequently analyze match videos to gain insights and develop game strategies. However, the current process for analyzing matches is time-consuming and relies heavily on manual note-taking, due to the lack of automatic data collection and appropriate visualization tools. As a result, there is a gap in effectively analyzing matches and communicating insights among badminton coaches and players. This work proposes an end-to-end immersive match analysis pipeline designed in close collaboration with badminton professionals, including Olympic and national coaches and players. We present VIRD, a VR Bird (i.e., shuttle) immersive analysis tool, that supports interactive badminton game analysis in an immersive environment based on 3D reconstructed game views of the match video. We propose a top-down analytic workflow that allows users to seamlessly move from a high-level match overview to a detailed game view of individual rallies and shots, using situated 3D visualizations and video. We collect 3D spatial and dynamic shot data and player poses with computer vision models and visualize them in VR. Through immersive visualizations, coaches can interactively analyze situated spatial data (player positions, poses, and shot trajectories) with flexible viewpoints while navigating between shots and rallies effectively with embodied interaction. We evaluated the usefulness of VIRD with Olympic and national-level coaches and players in real matches. Results show that immersive analytics supports effective badminton match analysis with reduced context-switching costs and enhances spatial understanding with a high sense of presence.
C1 [Lin, Tica; Aouididi, Alexandre; Chen, Zhutian; Beyer, Johanna; Pfister, Hanspeter] Harvard John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Lin, Tica; Wang, Jui-Hsien] Adobe Res, San Jose, CA 95110 USA.
   [Aouididi, Alexandre] Ecole Polytech Fed Lausanne EPFL, Lausanne, Switzerland.
C3 Adobe Systems Inc.; Swiss Federal Institutes of Technology Domain; Ecole
   Polytechnique Federale de Lausanne
RP Lin, TC (corresponding author), Harvard John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.; Lin, TC (corresponding author), Adobe Res, San Jose, CA 95110 USA.
EM mlin@g.harvard.edu; alexandre.aouididi@gmail.com;
   ztchen@seas.harvard.edu; johanna.m.beyer@gmail.com;
   pfister@seas.harvard.edu; juiwang@alumni.stanford.edu
OI Beyer, Johanna/0000-0002-3505-9171; Lin, Tica/0000-0002-2860-0871;
   Pfister, Hanspeter/0000-0002-3620-2582
FU Adobe Research
FX No Statement Available
CR [Anonymous], 2023, XR Interaction Toolkit
   [Anonymous], 2023, 2021 Denmark Open-Final, Men Single, Kento Momota (JPN) vs Viktor Axelsen (DEN)
   [Anonymous], 2023, 2020 BWF World Tour Finals, Women Single, Tai Tzu Ying (TPE) vs. Carolina Marin (ESP)
   [Anonymous], 2022, Unity Technologies
   Bach B, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299019
   Baldonado MQW, 2000, P WORK C ADV VIS INT, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/GLOCOM.2015.7417476, 10.1109/ICSENS.2015.7370446]
   Chen HongHua Chen HongHua, 2011, China Condiment, P1
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Clutch, Ai-powered performance analysis for badminton
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Farin D., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5307, P80, DOI 10.1117/12.526813
   Hachet Martin., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, P587, DOI 10.1145/2047196.2047273
   Haq M. A., 2022, 2022 INT EL S IES, V8, DOI [10.1109/ies55876.2022.9888717, DOI 10.1109/IES55876.2022.9888717]
   Heaton C., 2023, MIT SLOAN SPORTS AN
   Helbig C, 2014, ENVIRON EARTH SCI, V72, P3767, DOI 10.1007/s12665-014-3136-6
   Huang YC, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909871
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   hudl, Tools to help every team, coach and athlete improve
   Kopania M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218098
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Li ZH, 2022, LECT NOTES COMPUT SC, V13665, P590, DOI 10.1007/978-3-031-20065-6_34
   Lin T., P ACM CHI WORKSHOP I, P2020, DOI DOI 10.48550/ARXIV.2004.08010
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Lin Tica, 2021, P 2021 CHI C HUMAN F, DOI [DOI 10.1145/3411764.3445649, 10.1145/3411764.3445649]
   Liu P, 2022, IEEE COMPUT SOC CONF, P3512, DOI 10.1109/CVPRW56347.2022.00395
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   López D, 2016, IEEE T VIS COMPUT GR, V22, P1616, DOI 10.1109/TVCG.2015.2440233
   Luyang Zhu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P177, DOI 10.1007/978-3-030-58558-7_11
   Lyu Y, 2021, J SENSORS, V2021, DOI 10.1155/2021/3803387
   Marin Carolina, 2023, BWF World Championship Quarter Final, Women Single, Akane Yamaguchi (JPN)
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Monet N., 2022, arXiv (Cornell University), V10, DOI [10.48550/arxiv.2210.14165, DOI 10.48550/ARXIV.2210.14165]
   Moran A., 2015, Proceedings of the 2015 IEEE high performance extreme computing conference (HPEC), P1, DOI [10.1109/HPEC.2015.7322473, DOI 10.1109/HPEC.2015.7322473]
   Owens N., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P182, DOI 10.1049/cp:20030517
   Patton A., 2021, MIT SLOAN SPORTS AN
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Pingali G, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1433, DOI 10.1109/ICME.2000.871036
   Plumlee Matthew., 2002, In Proceedings of AVI 2002, P59, DOI [10.1145/1556262.1556270, DOI 10.1145/1556262.1556270]
   Rahmad N. A., 2019, Indonesian Journal of Electrical Engineering and Computer Science, V14, P1330
   Ready M., 2018, WORKSH IMM AN EXPL F
   Rematas K, 2018, PROC CVPR IEEE, P4738, DOI 10.1109/CVPR.2018.00498
   Rezzil, 2020, About us
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Sumiya M, 2022, ADJUNCT PROCEEDINGS OF THE 35TH ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2022, DOI 10.1145/3526114.3558639
   Tuyls K, 2021, J ARTIF INTELL RES, V71, P41
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Zou LY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1289, DOI [10.1109/vr.2019.8798041, 10.1109/VR.2019.8798041]
   Zou SH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10976, DOI 10.1109/ICCV48922.2021.01081
NR 64
TC 0
Z9 0
U1 7
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 458
EP 468
DI 10.1109/TVCG.2023.3327161
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500067
PM 37878442
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Rauscher, J
   Buchmuller, R
   Keim, DA
   Miller, M
AF Rauscher, Julius
   Buchmuller, Raphael
   Keim, Daniel A.
   Miller, Matthias
TI SkiVis: Visual Exploration and Route Planning in Ski Resorts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geographic Visualization; Routing
ID MAP LAYOUT; DESIGN; PREFERENCES; NETWORKS; COLOR; RED
AB Optimal ski route selection is a challenge based on a multitude of factors, such as the steepness, compass direction, or crowdedness. The personal preferences of every skier towards these factors require individual adaptations, which aggravate this task. Current approaches within this domain do not combine automated routing capabilities with user preferences, missing out on the possibility of integrating domain knowledge in the analysis process. We introduce SkiVis, a visual analytics application to interactively explore ski slopes and provide routing recommendations based on user preferences. In collaboration with ski guides and enthusiasts, we elicited requirements and guidelines for such an application and propose different workflows depending on the skiers' familiarity with the resort. In a case study on the resort of Ski Arlberg, we illustrate how to leverage volunteered geographic information to enable a numerical comparison between slopes. We evaluated our approach through a pair-analytics study and demonstrate how it supports skiers in discovering relevant and preference-based ski routes. Besides the tasks investigated in the study, we derive additional use cases from the interviews that showcase the further potential of SkiVis, and contribute directions for further research opportunities.
C1 [Rauscher, Julius; Buchmuller, Raphael; Keim, Daniel A.; Miller, Matthias] Univ Konstanz, D-78457 Constance, Germany.
C3 University of Konstanz
RP Rauscher, J (corresponding author), Univ Konstanz, D-78457 Constance, Germany.
EM julius.rauscher@uni-konstanz.com; raphael.buchmuller@uni-konstanz.com;
   daniel.a.keim@uni-konstanz.com; matthias.miller@uni-konstanz.com
OI Buchmuller, Raphael/0000-0002-0612-8828
FU Deutsche Forschungsgemeinschaft (DFG)
FX No Statement Available
CR Alnes PK, 2021, J OUTDOOR REC TOUR, V35, DOI 10.1016/j.jort.2021.100409
   [Anonymous], 2016, Austrian Standards Int. ONORM S 4611-Signs for use in organised skiing areas-Requirements, design and classification
   Arias-Hernandez R., 2011, P IEEE HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.2011.339
   Balzarini R, 2015, INT ARCH PHOTOGRAMM, V40-3, P495, DOI 10.5194/isprsarchives-XL-3-W3-495-2015
   Bergfex GmbH, 2022, Bergfex
   Birch J, 2012, J OPT SOC AM A, V29, P313, DOI 10.1364/JOSAA.29.000313
   Bleisch Susanne, 2009, P353
   Bortnyk S., 2020, Geoinformatics: Theor. Appl. Aspects, P1, DOI DOI 10.3997/2214-4609.2020GEO104
   Breakpoint Studio, 2023, Slopes Ski & Snowboard-Track Your Winter Adventures
   Buckley A., 2004, Geogr. Inf. Sci. Mountain Geomorphol., V01, P8
   Carden T., 2017, Adv. Human Factors Sports Outdoor Recreat, P1
   Chaze B, 2008, NEUROL CLIN, V26, P325, DOI 10.1016/j.ncl.2007.11.009
   Cloudnine Weather LLC, 2023, OpenSnow: Weather Forecasts | Snow Reports & Conditions
   Deliba3ie B., 2022, Proc. Inst. Mech. Eng., Part P: J. Sports Eng. Technol., DOI DOI 10.1177/175433712211181939
   Deng Z., 2022, J. Visualization, P1
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Di Lorenzo G, 2016, IEEE T VIS COMPUT GR, V22, P1036, DOI 10.1109/TVCG.2015.2440259
   Dijkstra E. W., 1959, Numerische Mathematik, V1, P5
   Dunlop M., 2007, ACM INT C P SER, P375, DOI DOI 10.1145/1377999.13780402,5
   European Space Agency, 2021, Copernicus DEM-Global and European Digital Elevation Model (COP-DEM), DOI [10.5270/ESA-c5d3d654,9, DOI 10.5270/ESA-C5D3D654,9]
   Falk M, 2020, TOURISM ECON, V26, P1197, DOI 10.1177/1354816619868117
   Falk M, 2017, TOURISM MANAGE, V60, P92, DOI 10.1016/j.tourman.2016.11.008
   FATMAP, 2023, FATMAP 3D: Map & Guides for Skiing, Hiking and Biking
   Federal Ministry Republic of Austria, 2023, ehyd
   Fedosov A, 2016, 15TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2016), P141, DOI 10.1145/3012709.3012721
   Felicio S., 2022, Transp. Res. Procedia, V62, P189, DOI DOI 10.1016/J.TRPRO.2022.02.024
   Field K, 2010, CARTOGR J, V47, P222, DOI 10.1179/000870410X12849977317444
   Fonte C. C., 2017, MAPPING CITIZEN SENS, P137, DOI [10.5334/bbf, 10.5334/bbf.g8, DOI 10.5334/BBF.G8]
   Friedsam Wenzel, 2021, SIGSPATIAL '21: Proceedings of the 29th International Conference on Advances in Geographic Information Systems, P11, DOI 10.1145/3474717.3483628
   Ghaemi Z, 2022, CARTOGR GEOGR INF SC, V49, P205, DOI 10.1080/15230406.2021.2013946
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Guo CJ, 2020, VLDB J, V29, P1149, DOI 10.1007/s00778-020-00608-7
   Han B, 2012, INT CON DISTR COMP S, P142, DOI 10.1109/ICDCS.2012.31
   HART S G, 1988, P139
   Haugom E, 2021, EMPIR ECON, V61, P469, DOI 10.1007/s00181-020-01872-w
   Haugom E, 2019, COGENT SOC SCI, V5, DOI 10.1080/23311886.2019.1681246
   Haunert JH, 2011, IEEE T VIS COMPUT GR, V17, P2555, DOI 10.1109/TVCG.2011.191
   Hendrikx J, 2016, J OUTDO RECREAT TOUR, V13, P34, DOI 10.1016/j.jort.2015.11.004
   Hrncir J, 2017, IEEE T INTELL TRANSP, V18, P493, DOI 10.1109/TITS.2016.2577047
   Int. Organisation for Standardisation, 2013, ISO19157:2013 Geographic information-Data quality
   Jackson SB, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18052506
   Jensen C. S., 2009, ENCY DATABASE SYSTEM, P1692, DOI DOI 10.1007/978-0-387-39940-9_2154
   King MA, 2014, EXPERT SYST APPL, V41, P1176, DOI 10.1016/j.eswa.2013.08.002
   Konu H, 2011, TOURISM MANAGE, V32, P1096, DOI 10.1016/j.tourman.2010.09.010
   Korohoda N., 2021, Geoinformatics, P1, DOI DOI 10.3997/2214-4609.20215521024
   L'Yi S, 2021, IEEE T VIS COMPUT GR, V27, P1525, DOI 10.1109/TVCG.2020.3030419
   Lera I, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177712
   Leuschner W., 1971, FOR RECR S, P135
   Liu QQ, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P76, DOI 10.1109/VIS47514.2020.00022
   Malasevska I, 2020, J TRAVEL TOUR MARK, V37, P785, DOI 10.1080/10548408.2020.1835787
   McCurdy LE, 2010, CURR PROB PEDIATR AD, V40, P102, DOI 10.1016/j.cppeds.2010.02.003
   Molokác M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14116795
   Moreno-Gené J, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093012
   Mountain News LLC, 2023, Ski And Snow Reports, Webcams, Skiing Reviews
   OpenStreetMap, 2017, PLANET DUMP
   Owen R, 2024, J ADVENTURE EDUC OUT, V24, P474, DOI 10.1080/14729679.2022.2127113
   pgRouting Community, 2023, pgRouting
   Pickering CM, 2010, AMBIO, V39, P430, DOI 10.1007/s13280-010-0039-y
   Porter R., 2023, OpenSkiMap.org
   Pravossoudovitch K, 2014, ERGONOMICS, V57, P503, DOI 10.1080/00140139.2014.889220
   Ren XL, 2021, BIG DATA RES, V23, DOI 10.1016/j.bdr.2020.100178
   Riaz F., 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P142, DOI 10.1109/CICSyN.2011.40
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Schmid J., 2021, EUROVIS WORKSH VIS A, DOI DOI 10.2312/EUROVA.202110955
   Schmid L., 2011, Eingebettete Systeme, P71, DOI DOI 10.1007/978-3-642-16189-6_82
   Schobesberger D., 2008, Bull. Soc. Univ. Cartogr., V42, P8
   Scott DM, 2021, J TRANSP GEOGR, V90, DOI 10.1016/j.jtrangeo.2020.102903
   Shih C, 2009, J TRAVEL RES, V47, P359, DOI 10.1177/0047287508321207
   Ski Arlberg, 2022, The Cradle of Alpine Skiing
   Ski Arlberg, 2022, Interactive Map
   Song Q, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1781, DOI 10.1109/ITSC.2014.6957951
   Steiger R, 2020, ECOL ECON, V170, DOI 10.1016/j.ecolecon.2019.106589
   Sterchi R, 2019, NAT HAZARD EARTH SYS, V19, P269, DOI 10.5194/nhess-19-269-2019
   Stigsdotter UK, 2011, URBAN FOR URBAN GREE, V10, P295, DOI 10.1016/j.ufug.2011.07.001
   Storandt S., 2012, P 22 INT C AUT PLANN, P234, DOI 0.1609/icaps.v22i1.134953
   Strava Inc, 2023, Strava | Run and Cycling Tracking on the Social Network for Athletes
   Su JG, 2010, TRANSPORT RES A-POL, V44, P495, DOI 10.1016/j.tra.2010.03.015
   Sykes J, 2020, APPL GEOGR, V122, DOI 10.1016/j.apgeog.2020.102261
   Tait A., 2010, Cartogr. Perspect., P5, DOI DOI 10.14714/CP67.1102,8
   Tirla L., 2014, Journal of Environmental and Tourism Analyses, V2, P48
   Vanat L., 2021, Report
   Venter ZS, 2023, LANDSCAPE URBAN PLAN, V232, DOI 10.1016/j.landurbplan.2023.104686
   Wang Y, 2018, COMPUT GRAPH FORUM, V37, P63, DOI 10.1111/cgf.13401
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Wu HY, 2012, COMPUT GRAPH FORUM, V31, P925, DOI 10.1111/j.1467-8659.2012.03085.x
   Zhang XY, 2023, J VISUAL-JAPAN, V26, P231, DOI 10.1007/s12650-022-00861-8
   Zhu SY, 2022, TRANSP LETT, V14, P298, DOI 10.1080/19427867.2020.1860355
NR 88
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 869
EP 879
DI 10.1109/TVCG.2023.3326940
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500055
PM 37874714
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Straub, A
   Karadimitriou, N
   Reina, G
   Frey, S
   Steeb, H
   Ertl, T
AF Straub, Alexander
   Karadimitriou, Nikolaos
   Reina, Guido
   Frey, Steffen
   Steeb, Holger
   Ertl, Thomas
TI Visual Analysis of Displacement Processes in Porous Media using
   Spatio-Temporal Flow Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Comparative visualization; ensemble; graph; porous media
ID 2-PHASE FLOW; VISUALIZATION; EXPLORATION; MICROMODEL; TRANSPORT;
   FRAMEWORK
AB We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media. We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow. To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map. From this map, we generate a spatio-temporal flow graph covering the whole process. This graph is further simplified to only reflect topological changes in the movement of the invading fluid. Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics. We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium. We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations.
C1 [Straub, Alexander; Karadimitriou, Nikolaos; Reina, Guido; Steeb, Holger; Ertl, Thomas] Univ Stuttgart, Stuttgart, Germany.
   [Frey, Steffen] Univ Groningen, Groningen, Netherlands.
C3 University of Stuttgart; University of Groningen
RP Straub, A (corresponding author), Univ Stuttgart, Stuttgart, Germany.
EM alexander.straub@visus.uni-stuttgart.de;
   nikos.karadimitriou@mechbau.uni-stuttgart.de;
   guido.reina@visus.uni-stuttgart.de; s.d.frey@rug.nl;
   holger.steeb@mechbau.uni-stuttgart.de; thomas.ertl@vis.uni-stuttgart.de
RI Steeb, Holger/AAE-4537-2020
OI Steeb, Holger/0000-0001-7602-4920; Frey, Steffen/0000-0002-1872-6905;
   Reina, Guido/0000-0003-4127-1897; Straub, Alexander/0000-0002-6749-9710
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Aboulhassan A, 2015, COMPUT GRAPH FORUM, V34, P401, DOI 10.1111/cgf.12652
   Alzahid Y., 2017, SPE EUROPEC FEATURED, DOI DOI 10.2118/185832-MS1
   Andrew M, 2013, GEOPHYS RES LETT, V40, P3915, DOI 10.1002/grl.50771
   Andrews K, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P62, DOI 10.1109/IV.2009.108
   Armstrong RT, 2019, TRANSPORT POROUS MED, V130, P305, DOI 10.1007/s11242-018-1201-4
   Bartels W.-B., 2016, INT S SOC CORE ANALY
   Berg S, 2013, P NATL ACAD SCI USA, V110, P3755, DOI 10.1073/pnas.1221373110
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Chen YQ, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abj0960
   Cheng JT, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2003GL019282
   Corapcioglu MY, 1997, WATER RESOUR RES, V33, P2547, DOI 10.1029/97WR02115
   Darcy H., 1857, Impr. Imperiale, P2
   de Winter DAM, 2021, TRANSPORT POROUS MED, V136, P343, DOI 10.1007/s11242-020-01515-9
   Eulzer P, 2021, COMPUT GRAPH FORUM, V40, P435, DOI 10.1111/cgf.14319
   Favelier G., 2016, IEEE SCI VISUALIZATI, P2
   Frey S, 2022, COMPUT GRAPH FORUM, V41, P243, DOI 10.1111/cgf.14432
   Geveci B., 2016, Scientific visualization contest
   Gralka P., 2016, IEEE Computer Graphics and Applications, V38, P106
   GROSSER K, 1988, AICHE J, V34, P1850, DOI 10.1002/aic.690341111
   Grottel S., 2010, P SIGRAD 2010 CONTEN, P45
   Grottel S, 2015, IEEE T VIS COMPUT GR, V21, P201, DOI 10.1109/TVCG.2014.2350479
   Hao LH, 2016, IEEE T VIS COMPUT GR, V22, P787, DOI 10.1109/TVCG.2015.2468093
   Hasan S, 2020, P NATL ACAD SCI USA, V117, P23443, DOI 10.1073/pnas.2011716117
   HASSANIZADEH SM, 1993, WATER RESOUR RES, V29, P3389, DOI 10.1029/93WR01495
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P1716, DOI 10.1109/TVCG.2018.2879866
   Heinzl C, 2017, COMPUT GRAPH FORUM, V36, P647, DOI 10.1111/cgf.13214
   Hu Y., 2006, The Mathematica Journal, V10, P6
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Karadimitriou N., 2023, Visual characterization of displacement processes in porous media, DOI [10.18419/darus-36156, DOI 10.18419/DARUS-36156]
   Karadimitriou NK, 2014, WATER RESOUR RES, V50, P8125, DOI 10.1002/2014WR015388
   Karadimitriou NK, 2012, VADOSE ZONE J, V11, DOI 10.2136/vzj2011.0072
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kettle J, 2010, SURF COAT TECH, V204, P2103, DOI 10.1016/j.surfcoat.2009.10.035
   Khan FI, 2004, J ENVIRON MANAGE, V71, P95, DOI 10.1016/j.jenvman.2004.02.003
   Kumpf A, 2019, IEEE T VIS COMPUT GR, V25, P98, DOI 10.1109/TVCG.2018.2864901
   Kurzeja PS, 2014, PHYS FLUIDS, V26, DOI 10.1063/1.4871489
   LENORMAND R, 1988, J FLUID MECH, V189, P165, DOI 10.1017/S0022112088000953
   Luciani T, 2019, IEEE T VIS COMPUT GR, V25, P1225, DOI 10.1109/TVCG.2018.2864849
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Mattax C. C., 1961, Oil Gas Journal, V59, P2
   Naumov D, 2014, ENVIRON EARTH SCI, V72, P3795, DOI 10.1007/s12665-014-3445-9
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Schlüter S, 2016, WATER RESOUR RES, V52, P2194, DOI 10.1002/2015WR018254
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shaw H. S. H., 1898, Inst. N.A., P2
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   THOMPSON LF, 1983, ACS SYM SER, V219, P1
   Ushizima DM, 2012, IEEE T VIS COMPUT GR, V18, P2041, DOI 10.1109/TVCG.2012.200
   VANGENUCHTEN MT, 1980, SOIL SCI SOC AM J, V44, P892, DOI 10.2136/sssaj1980.03615995004400050002x
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   Widanagamaachchi W., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P9, DOI 10.1109/LDAV.2012.6378962
   Wills P, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228728
   Wilson RC, 2008, PATTERN RECOGN, V41, P2833, DOI 10.1016/j.patcog.2008.03.011
   Xia YN, 1998, ANNU REV MATER SCI, V28, P153, DOI 10.1146/annurev.matsci.28.1.153
   Xu JY, 2022, IEEE T VIS COMPUT GR, V28, P1514, DOI 10.1109/TVCG.2020.3017568
   Yiotis A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83065-8
   Zhang H, 2019, IEEE T VIS COMPUT GR, V25, P1060, DOI 10.1109/TVCG.2018.2864506
NR 61
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 759
EP 769
DI 10.1109/TVCG.2023.3326931
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500137
PM 37878453
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Croucher, C
   Powell, W
   Stevens, B
   Miller-Dicks, M
   Powell, V
   Wiltshire, TJ
   Spronck, P
AF Croucher, Charlotte
   Powell, Wendy
   Stevens, Brett
   Miller-Dicks, Matt
   Powell, Vaughan
   Wiltshire, Travis J.
   Spronck, Pieter
TI LoCoMoTe - A Framework for Classification of Natural Locomotion in VR by
   Task, Technique and Modality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human-computer interaction; machine learning; navigation; redirected
   walking; virtual reality
ID LARGE VIRTUAL ENVIRONMENTS; REDIRECTED WALKING; REALITY; ROTATION;
   TELEPRESENCE; SIMULATION; NAVIGATION; TAXONOMY; TRAVEL; GAINS
AB Virtual reality (VR) research has provided overviews of locomotion techniques, how they work, their strengths and overall user experience. Considerable research has investigated new methodologies, particularly machine learning to develop redirection algorithms. To best support the development of redirection algorithms through machine learning, we must understand how best to replicate human navigation and behaviour in VR, which can be supported by the accumulation of results produced through live-user experiments. However, it can be difficult to identify, select and compare relevant research without a pre-existing framework in an ever-growing research field. Therefore, this work aimed to facilitate the ongoing structuring and comparison of the VR-based natural walking literature by providing a standardised framework for researchers to utilise. We applied thematic analysis to study methodology descriptions from 140 VR-based papers that contained live-user experiments. From this analysis, we developed the LoCoMoTe framework with three themes: navigational decisions, technique implementation, and modalities. The LoCoMoTe framework provides a standardised approach to structuring and comparing experimental conditions. The framework should be continually updated to categorise and systematise knowledge and aid in identifying research gaps and discussions.
C1 [Croucher, Charlotte] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, NL-5037 AB Tilburg, Netherlands.
   [Powell, Wendy] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, NL-5037 AB Tilburg, Netherlands.
   [Stevens, Brett] Univ Portsmouth, Dept Creat Technol, Portsmouth PO1 2ER, England.
C3 Tilburg University; Tilburg University; University of Portsmouth
RP Croucher, C (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, NL-5037 AB Tilburg, Netherlands.
EM c.s.croucher@tilburguniversity.edu; w.a.powell@tilburguniversity.edu;
   brett.Stevens@port.ac.uk; matt.miller-dicks@port.ac.uk;
   v.powell@tilburguniversity.edu; t.j.wiltshire@tilburguniversity.edu;
   p.spronck@tilburguniversity.edu
RI Miller-Dicks, Matt/O-7489-2016
OI Miller-Dicks, Matt/0000-0001-6584-2733; Powell,
   Wendy/0000-0002-7234-5628; Stevens, Brett/0000-0003-1822-489X; Croucher,
   Charlotte/0000-0002-1378-396X; Wiltshire, Travis/0000-0001-7630-2695
FU Department of Cognitive Science and Artificial Intelligence at Tilburg
   University; Faculty of Creative and Cultural Industries at the
   University of Portsmouth
FX This work was supported in part by Department of Cognitive Science and
   Artificial Intelligence at Tilburg University and in part by the Faculty
   of Creative and Cultural Industries at the University of Portsmouth.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Agethen P, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3230648
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Nguyen A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281515
   Auda M., 2019, P CHI C HUM FACT COM, P1, DOI [10.1145/3290605.3300661.102E.R., DOI 10.1145/3290605.3300661.102E.R]
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2288, DOI 10.1109/TVCG.2022.3150466
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Baars N. M., Cognition, Brain, and Consciousness:Introduction to Cognitive Neuroscience
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Badillo S, 2020, CLIN PHARMACOL THER, V107, P871, DOI 10.1002/cpt.1796
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Bianchini S, 2022, RES POLICY, V51, DOI 10.1016/j.respol.2022.104604
   Birmingham U.K., 2012, P 18 INT C EV ASS SO, P375
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bolte B., 2011, P VIRT REAL INT C LA, P1
   Borrego A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0174-1
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bruder G., 2009, Proceedings of the 15th Joint virtual reality Eurographics conference on Virtual Environments, P145
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Bruder G, 2013, DISPLAYS, V34, P132, DOI 10.1016/j.displa.2012.10.007
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Buck LE, 2019, IEEE T VIS COMPUT GR, V25, P2123, DOI 10.1109/TVCG.2019.2899232
   Byrne D., 2022, INT J QUAL METH, V56, P1391, DOI [https://doi.org/10.1007/s11135-021-01182-y, DOI 10.1177/1609406917733847, 10.1177/1609406917733847]
   Byrne D., 2022, QUAL QUANTITY, V56, P1391, DOI [DOI 10.1007/S11135-021-01182-Y, 10.1007/s11135-021-01182-y]
   Cardoso JCS, 2019, COMPUT GRAPH-UK, V85, P55, DOI 10.1016/j.cag.2019.09.005
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Checa D, 2020, VIRTUAL REAL-LONDON, V24, P151, DOI 10.1007/s10055-019-00389-7
   Chen H., 2017, P 21 ACM SIGGRAPH S, P1, DOI [10.1145/3023368.3036844, DOI 10.1145/3023368.3036844]
   Chen WY, 2019, LECT NOTES COMPUT SC, V11883, P226, DOI 10.1007/978-3-030-31908-3_14
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Cirio G., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P155, DOI [10.1145/1643928.1643965.85L.A., DOI 10.1145/1643928.1643965.85L.A, DOI 10.1145/1643928.1643965]
   Cirio G, 2012, IEEE T VIS COMPUT GR, V18, P546, DOI 10.1109/TVCG.2012.60
   Congdon BJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364277
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Cowan K, 2019, J BUS RES, V100, P483, DOI 10.1016/j.jbusres.2018.10.063
   Oliveira VAD, 2018, LECT NOTES COMPUT SC, V10894, P500, DOI 10.1007/978-3-319-93399-3_43
   Dewez D, 2020, INT SYM MIX AUGMENT, P452, DOI 10.1109/ISMAR50242.2020.00070
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Dong ZC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3345554
   Doyen S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029081
   Engel David., 2008, P ACM S VIRTUAL REAL, P157, DOI [DOI 10.1145/1450579.1450612, 10.1145/1450579.1450612.51E., DOI 10.1145/1450579.1450612.51E]
   Farr AC, 2012, TRANSPORT REV, V32, P715, DOI 10.1080/01441647.2012.712555
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Felderer M., 2020, Methods in SoftwareEngineering, P477, DOI [10.1007/978-3-030-32489-617.32E, DOI 10.1007/978-3-030-32489-617.32E]
   Fisher S. S., 1987, Proceedings of the 1986 Workshop on Interactive 3D Graphics, P77, DOI 10.1145/319120.319127
   Flick U., 2018, Qualitative Data Collection, DOI [10.4135/9781526416070, DOI 10.4135/9781526416070]
   Fontan A, 2021, NEUROIMAGE, V244, DOI 10.1016/j.neuroimage.2021.118571
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Grechkin J., 2016, P ACM S APPL PERC SA, P113, DOI [10.1145/2931002.29310182[19]J, DOI 10.1145/2931002.2931018]
   Grechkin TY, 2014, IEEE T VIS COMPUT GR, V20, P596, DOI 10.1109/TVCG.2014.18
   Halilaj E, 2018, J BIOMECH, V81, P1, DOI 10.1016/j.jbiomech.2018.09.009
   Hayashi D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P386, DOI [10.1109/vr.2019.8797989, 10.1109/VR.2019.8797989]
   Hirt C, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P524, DOI 10.1109/VR51125.2022.00072
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2015, BEHAV RES METHODS, V47, P296, DOI 10.3758/s13428-014-0463-1
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hoshikawa Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P464, DOI 10.1109/VR51125.2022.00066
   Hutton S., 2018, P INT C ART REAL TEL, P61, DOI [10.2312/egve.20181315.70, DOI 10.2312/EGVE.20181315.70]
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Janeh O, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343119
   Joshi Y, 2020, IEEE ACCESS, V8, P39013, DOI 10.1109/ACCESS.2020.2975032
   Jung S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1085, DOI 10.1145/3332165.3347868
   Kim D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR50410.2021.00091
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P1379, DOI 10.1109/TVCG.2017.2657139
   Ko TY, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P201, DOI 10.1109/ISMAR-Adjunct51615.2020.00059
   KRIPPEND.K, 1970, EDUC PSYCHOL MEAS, V30, P61, DOI 10.1177/001316447003000105
   Krippendorff K., 2018, Content Analysis: An Introduction to Its Methodology, DOI [DOI 10.4135/9781071878781, https://doi.org/10.4135/9781071878781]
   Krippendorff K., 2011, Computing krippendorff's alpha-reliability
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Kyngäs H, 2020, APPLICATION OF CONTENT ANALYSIS IN NURSING SCIENCE RESEARCH, P41, DOI 10.1007/978-3-030-30199-6_5
   Langbehn E, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343125
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lazar J., 2017, Research methods in human-computer interaction, V2nd, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.00-70, 10.1109/VR46266.2020.1581309443724]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Lee J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092832
   Lemon LL, 2020, QUAL REP, V25, P604
   Li M., 2021, Virtual Reality Intell. Hardware, V3, P451, DOI [10.1016/j.vrih.2021.06.003.72, DOI 10.1016/J.VRIH.2021.06.003.72]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Liapis C., P CHI C HUM FACT COM
   Liu L., 2021, Virtual Reality Intell. Hardware, V3, P470, DOI [10.1016/j.vrih.2021.06.004.73Y, DOI 10.1016/J.VRIH.2021.06.004.73Y]
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Marín-Morales J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223881
   Marsh WE, 2013, PRESENCE-VIRTUAL AUG, V22, P216, DOI 10.1162/PRES_a_00152
   Matsumoto K, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365705
   Matsumoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P101, DOI [10.1109/VR46266.2020.00-76, 10.1109/VR46266.2020.1581262503135]
   Matsumoto K, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P105, DOI 10.1109/3DUI.2016.7460038
   Matsumoto T., 2017, ACM SIGGRAPH 2017 PO, P1, DOI [10.1145/3102163.3102227.152, DOI 10.1145/3102163.3102227.152]
   McCullough M, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P107, DOI 10.1145/2804408.2804416
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Meyer F., 2016, P SOUND MUS COMP C, P1
   Min DH, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P164, DOI [10.1109/VR46266.2020.00-69, 10.1109/VR46266.2020.1581308731108]
   Mohler Betty., 2007, 13th Eurographics Symposium on Virtual Environments and 10th Immersive Projection Technology Workshop (IPT-EGVE 2007), P85, DOI [DOI 10.2312/PE/VE2007SHORT/085-088.128, DOI 10.2312/PE/VE2007SHORT/085-088]
   Mon CS, 2019, 2019 IEEE 9TH SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P249, DOI [10.1109/ISCAIE.2019.8743738, 10.1109/iscaie.2019.8743738]
   Mousas C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P726, DOI [10.1109/vr.2019.8798043, 10.1109/VR.2019.8798043]
   Munn Z, 2018, BMC MED RES METHODOL, V18, DOI 10.1186/s12874-018-0611-x
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nelson M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365709
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Nguyen A., 2020, P 26 ACM S VIRT REAL, P1, DOI [10.1145/3385956.3418950, DOI 10.1145/3385956.3418950]
   Nguyen A, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407932
   Nguyen P., 2020, P 26 ACM S VIRT REAL, P1, DOI [10.1145/3385956.3422099.134M, DOI 10.1145/3385956.3422099.134M]
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nilsson NC, 2016, P IEEE VIRT REAL ANN, P241, DOI 10.1109/VR.2016.7504743
   Nitzsche N, 2004, PRESENCE-TELEOP VIRT, V13, P44, DOI 10.1162/105474604774048225
   Nogalski M, 2016, P IEEE VIRT REAL ANN, P245, DOI 10.1109/VR.2016.7504745
   Nordahl R, 2006, P 9 INT WORKSH PRES, P57
   Nordahl R, 2011, PSYCHNOLOGY J, V9, P245
   O'Connor S, 2019, CLIN NURS RES, V28, P523, DOI 10.1177/1054773819845824
   Ogawa K, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P635, DOI 10.1109/VR51125.2022.00084
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Paris RA, 2017, P IEEE VIRT REAL ANN, P261, DOI 10.1109/VR.2017.7892276
   Paul J, 2022, PSYCHOL MARKET, V39, P1099, DOI 10.1002/mar.21657
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Podkosova I, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190845
   Pyzer-Knapp EO, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00765-z
   Qi Sun, 2020, Real VR - Immersive Digital Reality: How to Import the Real World into Head-Mounted Immersive Displays. Lecture Notes in Computer Science (LNCS 11900), P285, DOI 10.1007/978-3-030-41816-8_12
   Ranasinghe N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174151
   Razzaque Z. Kohn, 2001, Redirected Walking, DOI [10.2312/egs.20011036.146M, DOI 10.2312/EGS.20011036.146M]
   Reimer D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P154, DOI [10.1109/VRW50115.2020.0-244, 10.1109/VRW50115.2020.00032]
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Roberts K, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0707-y
   Rocco T.S., 2009, HUM RESOUR DEV REV, V8, P120, DOI [10.1177/1534484309332617, DOI 10.1177/1534484309332617]
   Rothacher Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36035-6
   Ruddle RA, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2465780.2465785
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Samperi R., P 26 BCS C HUM COMP
   Saunders B, 2018, QUAL QUANT, V52, P1893, DOI 10.1007/s11135-017-0574-8
   Schmelter T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451264
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Shibayama W, 2020, LECT NOTES COMPUT SC, V12221, P33, DOI 10.1007/978-3-030-61864-3_4
   Simeone AL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P598, DOI [10.1109/VR46266.2020.00-22, 10.1109/VR46266.2020.1581330966612]
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sjolund LA, 2018, MEM COGNITION, V46, P89, DOI 10.3758/s13421-017-0747-7
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Srinagesh K., 2006, PRINCIPLES EXPT RES
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI DOI 10.1145/1450579.1450611
   Steinicke F, 2010, COMPUT GRAPH-UK, V34, P26, DOI 10.1016/j.cag.2009.12.003
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Steinicke Frank., 2009, Proc. ACM Symp. on Video Games, P111
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma E. A., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P35, DOI 10.1109/3DUI.2011.5759214
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Suma EA, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P27, DOI 10.1109/3DUI.2010.5444726
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Suma S., 2007, P IEEE S 3D US INT C, DOI [10.1109/3DUI.2007.340788.154R.A., DOI 10.1109/3DUI.2007.340788.154R.A]
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Tawfik GM, 2019, TROP MED HEALTH, V47, DOI 10.1186/s41182-019-0165-6
   Uematsu A, 2011, NEUROSCI LETT, V505, P291, DOI 10.1016/j.neulet.2011.10.057
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vaismoradi M, 2013, NURS HEALTH SCI, V15, P398, DOI 10.1111/nhs.12048
   van de Schoot R, 2021, NAT MACH INTELL, V3, P125, DOI 10.1038/s42256-020-00287-7
   Vasylevska K, 2017, IEEE COMPUT GRAPH, V37, P85, DOI 10.1109/MCG.2017.3621226
   Vasylevska K, 2017, IEEE SYMP 3D USER, P12, DOI 10.1109/3DUI.2017.7893312
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Wiener JM, 2009, SPAT COGN COMPUT, V9, P152, DOI 10.1080/13875860902906496
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Williams G., 2006, P 3 S APPL PERC GRAP, P21, DOI [10.1145/1140491.1140495, 10.1145/1140491.1140495.78, DOI 10.1145/1140491.1140495.78]
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Williams-Sanders B, 2019, LECT NOTES COMPUT SC, V11574, P277, DOI 10.1007/978-3-030-21607-8_22
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376243
   Xie X., 2010, P 7 S APPL PERC GRAP, P65, DOI [10.1145/1836248.1836260, DOI 10.1145/1836248.1836260]
   Xu W, 2020, INT J QUAL METH, V19, DOI 10.1177/1609406920918810
   Yang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1093, DOI 10.1145/3332165.3347875
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zank M, 2016, VISUAL COMPUT, V32, P1323, DOI 10.1007/s00371-016-1229-9
   Zank M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P49, DOI 10.1109/3DUI.2016.7460030
   Zhang B, 2011, VISION RES, V51, P2356, DOI 10.1016/j.visres.2011.09.008
   Zhang J, 2018, IEEE T VIS COMPUT GR, V24, P1671, DOI 10.1109/TVCG.2018.2793679
   Zhang R., 2014, Proc. Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P62, DOI DOI 10.1145/2659766.2659783.177M
   Zhang R., 2013, Proc. Proceedings of the ACM Symposium on Applied Perception (SAP), P71
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 201
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5765
EP 5781
DI 10.1109/TVCG.2023.3313439
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400017
PM 37695974
OA Bronze, Green Published
DA 2024-08-05
ER

PT J
AU Fang, Y
   Li, MC
   Cao, YD
   Li, X
   Wolper, J
   Yang, Y
   Jiang, CFF
AF Fang, Yu
   Li, Minchen
   Cao, Yadi
   Li, Xuan
   Wolper, Joshuah
   Yang, Yin
   Jiang, Chenfanfu
TI Augmented Incremental Potential Contact for Sticky Interactions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adhesives; Friction; Computational modeling; Deformation; Solids; Force;
   Deformable models; Physically based animation; optimization time
   integration
ID FORMULATION; FRICTION; ADHESION
AB We introduce a variational formulation for simulating sticky interactions between elastoplastic solids. Our method brings a wider range of material behaviors into the reach of the Incremental Potential Contact (IPC) solver recently developed by (Li et al. 2020). Extending IPC requires several contributions. We first augment IPC with the classical Raous-Cangemi-Cocou (RCC) adhesion model. This allows us to robustly simulate the sticky interactions between arbitrary codimensional-0, 1, and 2 geometries. To enable user-friendly practical adoptions of our method, we further introduce a physically parametrized, easily controllable normal adhesion formulation based on the unsigned distance, which is fully compatible with IPC's barrier formulation. Furthermore, we propose a smoothly clamped tangential adhesion model that naturally models intricate behaviors including debonding. Lastly, we perform benchmark studies comparing our method with the classical models as well as real-world experimental results to demonstrate the efficacy of our method.
C1 [Fang, Yu; Wolper, Joshuah] Univ Penn, Philadelphia, PA 19104 USA.
   [Fang, Yu; Li, Minchen; Cao, Yadi; Li, Xuan; Jiang, Chenfanfu] Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
   [Li, Minchen] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Yang, Yin] Univ Utah, Salt Lake City, UT 84112 USA.
C3 University of Pennsylvania; University of California System; University
   of California Los Angeles; Carnegie Mellon University; Utah System of
   Higher Education; University of Utah
RP Li, MC; Jiang, CFF (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
EM squarefk@gmail.com; minchernl@gmail.com; yadicao95@gmail.com;
   xuanli1@math.ucla.edu; joshwolper@gmail.com; yin.yang@utah.edu;
   chenfanfu.jiang@gmail.com
RI Fang, Yu/KFR-7871-2024
OI Fang, Yu/0009-0002-7474-2421; Yang, Yin/0000-0001-7645-5931; Li,
   Xuan/0000-0003-0677-8369; Wolper, Joshuah/0000-0001-5226-8330; Cao,
   Yadi/0000-0001-8872-5759
FU NSF [2153851, 2153863, 2023780, 2301040, 2008915, 2244651, 2008564]
FX No Statement Available
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Batty C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185609
   Belytschko T., 2000, NONLINEAR FINITE ELE
   Bergou M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778853
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995
   Chen YN, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530076
   Christensen PW, 1998, INT J NUMER METH ENG, V42, P145, DOI 10.1002/(SICI)1097-0207(19980515)42:1<145::AID-NME358>3.0.CO;2-L
   Clavet S., 2005, SCA 05 P 2005 ACM SI, P219, DOI DOI 10.1145/1073368.1073400
   DERJAGUIN BV, 1975, J COLLOID INTERF SCI, V53, P314, DOI 10.1016/0021-9797(75)90018-1
   Fang Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459757
   Fei Y., 2017, "ACMTrans.Graph, V36, P1
   Fei Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356532
   Fei Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201392
   Ferguson Z, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459802
   Gascon J., 2010, Proc. Symp. Comp. Anim, P39
   Guennebaud G, 2010, Eigen
   Harmon D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531393
   Hu LB, 2022, COMPUT METHOD APPL M, V390, DOI 10.1016/j.cma.2021.114478
   Hu L. B., 2021, P 14 WCCMECCOMAS C P, DOI [10.23967/wccm-eccomas.2020.206ff.ffhal-03267975, DOI 10.23967/WCCM-ECCOMAS.2020.206FF.FFHAL-03267975]
   Israelachvili J., 2000, Tribology Series, V38, P3
   Jiang YP, 2022, Arxiv, DOI arXiv:2108.02080
   Jiang ZS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130895
   Johnson K.L., 1987, Contact mechanics
   Kaldor JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360664
   Kloosterman G, 2001, INT J NUMER METH ENG, V51, P865, DOI 10.1002/nme.209.abs
   Lan L, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530064
   Lan L, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530069
   Lan L, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459753
   Leach Matthew., 2018, Proceedings of the Conference on Computer Graphics Visual Computing, P51
   Lennard-Jones JE, 1931, P PHYS SOC, V43, P461, DOI 10.1088/0959-5309/43/5/301
   Li J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201308
   Li M, 2020, "Robust and accurate simulation of elastodynamics and contact
   Li MC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459767
   Li MC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392425
   Li MC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322951
   Li X., 2021, Comput. Methods Appl. Mechanics Eng, V390
   Li X, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530072
   Ly M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392396
   Nocedal J., 1999, Numerical optimization
   Ortiz M, 1999, COMPUT METHOD APPL M, V171, P419, DOI 10.1016/S0045-7825(98)00219-9
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   Paggi M, 2020, MECH ADV MATER STRUC, V27, P1731, DOI 10.1080/15376494.2018.1525454
   Raous M, 1999, COMPUT METHOD APPL M, V177, P383, DOI 10.1016/S0045-7825(98)00389-2
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Schüller C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12179
   Smith J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766947
   Sonnerlind H., 2016, How to model adhesion and decohesion in COMSOL multiphysics
   Yu N, 2004, J COLLOID INTERF SCI, V278, P428, DOI 10.1016/j.jcis.2004.06.029
   Zhao YD, 2022, COMPUT METHOD APPL M, V393, DOI 10.1016/j.cma.2022.114820
NR 50
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5596
EP 5608
DI 10.1109/TVCG.2023.3295656
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400051
PM 37450362
DA 2024-08-05
ER

PT J
AU Sun, QW
   Nie, YW
   Zhang, Q
   Li, GQ
AF Sun, Qiwei
   Nie, Yongwei
   Zhang, Qing
   Li, Guiqing
TI Building Coarse to Fine Convex Hulls With Auxiliary Vertices for
   Palette-Based Image Recoloring
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Point cloud compression; Image reconstruction;
   Image decomposition; Three-dimensional displays; Task analysis; Sun;
   Color palette; image recoloring; convex hull; mesh deformation
ID COLOR; MODEL
AB Constructing a convex hull for the pixel colors of an image by viewing them as 3D points can extract a set of palette colors for the image, then image recoloring can be achieved by modifying the palette colors. For better recoloring effect, the convex hull should contain more pixels (inclusive) and be more compact. Otherwise, reconstruction error would occur or the extracted palette color would be less representative, yielding wrong recoloring results or less effective edit. We observe that convex hulls constructed by prior methods can contain all the image pixels, but are far from compact. Efforts have been made to optimize the vertices of convex hull to increase the compactness but are still not perfect. In this paper, we propose a novel coarse to fine convex hull construction scheme with auxiliary vertices. We start by constructing a coarse convex hull whose vertices are directly image pixels which is thus the most compact but cannot contain all pixels. We then make a remedy by adding auxiliary vertices into the coarse convex hull to obtain a fine convex hull. More auxiliary vertices are added, more image pixels will be contained into the fine convex hull. The auxiliary vertices are image pixels too so that the compactness can still be maintained. During editing, the auxiliary vertices are not allowed to be edited for edit convenience, but deformed as-rigid-as-possible with the adjusting of other vertices. Our convex hull is both inclusive and compact. Extensive experiments validate the effectiveness of the proposed method.
C1 [Sun, Qiwei; Nie, Yongwei; Li, Guiqing] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Zhang, Qing] Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China.
C3 South China University of Technology; Sun Yat Sen University
RP Li, GQ (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM qivigor@gmail.com; nieyongwei@scut.edu.cn; zhangq93@mail.sysu.edu.cn;
   ligq@scut.edu.cn
FU National Natural Science Foundation of China [61972160, 62072191]; NSF
   of Guangdong Province [2021A1515012301]
FX No Statement Available
CR Afifi M, 2021, PROC CVPR IEEE, P7937, DOI 10.1109/CVPR46437.2021.00785
   Aharoni-Mack Y., 2017, NPAR 17, P1
   Akimoto Naofumi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8274, DOI 10.1109/CVPR42600.2020.00830
   Aksoy Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3002176
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   Bahng H, 2018, LECT NOTES COMPUT SC, V11216, P443, DOI 10.1007/978-3-030-01258-8_27
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Delon J, 2005, IEEE IMAGE PROC, P1317
   Delos B, 2019, Arxiv, DOI arXiv:1912.04583
   Du ZJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459675
   Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Garland P. S., 1997, SIGGRAPH 97, P209
   Greenfield GR, 2003, WSCG'2003, VOL 11, NO 1, CONFERENCE PROCEEDINGS, P189
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hu XH, 2019, IEEE T COMPUT IMAG, V5, P649, DOI 10.1109/TCI.2019.2908291
   Hu XH, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356534
   Huang HZ, 2014, COMPUT GRAPH FORUM, V33, P299, DOI 10.1111/cgf.12498
   Huang YF, 2018, COMPUT GRAPH FORUM, V37, P421, DOI 10.1111/cgf.13579
   Iwasa S, 2018, IEEE IMAGE PROC, P2257, DOI 10.1109/ICIP.2018.8451712
   Jeong T, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13811
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Kang JM, 2018, IEEE IMAGE PROC, P2252, DOI 10.1109/ICIP.2018.8451526
   Khodadadeh S, 2021, IEEE WINT CONF APPL, P1487, DOI 10.1109/WACV48630.2021.00153
   Kuhn GR, 2008, IEEE T VIS COMPUT GR, V14, P1747, DOI 10.1109/TVCG.2008.112
   Kumar D., 2021, P 9 INT C LEARN REPR, P39
   Lei Chenyang., 2020, ADV NEURAL INFORM PR, V33, P1083
   Leung Y, 1997, IEEE T NEURAL NETWOR, V8, P601, DOI 10.1109/72.572099
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li ZQ, 2020, LECT NOTES COMPUT SC, V11961, P127, DOI 10.1007/978-3-030-37731-1_11
   Lin SR, 2017, Arxiv, DOI arXiv:1701.03754
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Pal S, 2007, IEEE T NEURAL NETWOR, V18, P600, DOI 10.1109/TNN.2007.891201
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ribeiro M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329118
   Shen WY, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925878
   Shugrina M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392461
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Tan J., 2016, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/2988229
   Tan JC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275054
   Tan JC, 2019, IEEE T VIS COMPUT GR, V25, P2791, DOI 10.1109/TVCG.2018.2858238
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Wang D, 2017, COMPUT GRAPH FORUM, V36, P93, DOI 10.1111/cgf.13275
   Wang YL, 2019, COMPUT GRAPH FORUM, V38, P11, DOI 10.1111/cgf.13812
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Xiao CF, 2020, COMPUT GRAPH FORUM, V39, P20, DOI 10.1111/cgf.13659
   Zhang Q, 2022, IEEE T MULTIMEDIA, V24, P1545, DOI 10.1109/TMM.2021.3067463
   Zhang Q, 2017, IEEE T IMAGE PROCESS, V26, P1952, DOI 10.1109/TIP.2017.2671779
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhao NX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447647
   Zhu ZY, 2022, IEEE T MULTIMEDIA, V24, P1721, DOI 10.1109/TMM.2021.3070108
   Zhu ZY, 2021, VISUAL COMPUT, V37, P2999, DOI 10.1007/s00371-021-02240-0
NR 56
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5581
EP 5595
DI 10.1109/TVCG.2023.3296386
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400060
PM 37463085
DA 2024-08-05
ER

PT J
AU Li, XL
   Liu, ZN
   Chen, T
   Mu, TJ
   Martin, RR
   Hu, SM
AF Li, Xiang-Li
   Liu, Zheng-Ning
   Chen, Tuo
   Mu, Tai-Jiang
   Martin, Ralph R.
   Hu, Shi-Min
TI Mesh Neural Networks Based on Dual Graph Pyramids
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural networks; Convolution; Three-dimensional displays; Feature
   extraction; Faces; Shape; Point cloud compression; Geometric
   understanding; mesh processing; neural networks; shape analysis
ID SHAPE
AB Deep neural networks (DNNs) have been widely used for mesh processing in recent years. However, current DNNs can not process arbitrary meshes efficiently. On the one hand, most DNNs expect 2-manifold, watertight meshes, but many meshes, whether manually designed or automatically generated, may have gaps, non-manifold geometry, or other defects. On the other hand, the irregular structure of meshes also brings challenges to building hierarchical structures and aggregating local geometric information, which is critical to conduct DNNs. In this paper, we present DGNet, an efficient, effective and generic deep neural mesh processing network based on dual graph pyramids; it can handle arbitrary meshes. First, we construct dual graph pyramids for meshes to guide feature propagation between hierarchical levels for both downsampling and upsampling. Second, we propose a novel convolution to aggregate local features on the proposed hierarchical graphs. By utilizing both geodesic neighbors and euclidean neighbors, the network enables feature aggregation both within local surface patches and between isolated mesh components. Experimental results demonstrate that DGNet can be applied to both shape analysis and large-scale scene understanding. Furthermore, it achieves superior performance on various benchmarks, including ShapeNetCore, HumanBody, ScanNet and Matterport3D. Code and models will be available at https://github.com/li-xl/DGNet.
C1 [Li, Xiang-Li; Chen, Tuo; Mu, Tai-Jiang; Hu, Shi-Min] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
   [Liu, Zheng-Ning] Fitten Tech Co Ltd, Beijing 100084, Peoples R China.
   [Martin, Ralph R.] Cardiff Univ, Sch Comp Sci Informat, Cardiff CF10 3AT, Wales.
C3 Tsinghua University; Cardiff University
RP Hu, SM (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
EM lixl19@mails.tsinghua.edu.cn; lzhengning@gmail.com; 2509976039@qq.com;
   taijiang@tsinghua.edu.cn; martinrr@cardiff.ac.uk; shimin@tsinghua.edu.cn
RI Mu, Tai-Jiang/JWO-1381-2024
OI Mu, Tai-Jiang/0000-0002-9197-346X; Hu, Shi-Min/0000-0001-7507-6542;
   Martin, Ralph/0000-0002-8495-8536; Liu, Zhengning/0000-0001-6643-6016
FU National Key R&D Program of China [2021ZD0112902]; Natural Science
   Foundation of China [62220106003]; Research Grant of Beijing Higher
   Institution Engineering Research Center; Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology
FX This work was supported in part by National Key R&D Program of China
   under Grant 2021ZD0112902, in part by the Natural Science Foundation of
   China under Grant 62220106003, in part by Research Grant of Beijing
   Higher Institution Engineering Research Center and Tsinghua-Tencent
   Joint Laboratory for Internet Innovation Technology.
CR [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   Boscaini Davide, 2016, Advances in neural information processing systems
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chen Y, 2021, IEEE T MULTIMEDIA, V23, P3098, DOI 10.1109/TMM.2020.3020693
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dong QJ, 2023, Arxiv, DOI arXiv:2202.00307
   Engel N, 2021, IEEE ACCESS, V9, P134826, DOI 10.1109/ACCESS.2021.3116304
   Ezuz D, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13244
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Guo MH, 2022, Arxiv, DOI arXiv:2209.08575
   Guo MH, 2022, Arxiv, DOI arXiv:2202.09741
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Haim N, 2019, IEEE I CONF COMP VIS, P632, DOI 10.1109/ICCV.2019.00072
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2018, SQUEEZE AND EXCITATI, P7132
   Hu SM, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3506694
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   HU ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15468, DOI 10.1109/ICCV48922.2021.01520
   Huang J, 2016, INT C PATT RECOG, P2670, DOI 10.1109/ICPR.2016.7900038
   Huang JW, 2019, PROC CVPR IEEE, P4435, DOI 10.1109/CVPR.2019.00457
   Lahav A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417806
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lei H, 2021, PROC CVPR IEEE, P13849, DOI 10.1109/CVPR46437.2021.01364
   Li Y., 2018, Advances in neural information processing systems, P828, DOI DOI 10.48550/ARXIV.1801.07791
   Liang YQ, 2022, Arxiv, DOI arXiv:2207.10228
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Maron H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073616
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Milano F., 2020, Advances in Neural Information Processing Systems, P952
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Pfaff T., 2021, P INT C LEARN REPR, P1
   Pfaff T, 2021, Arxiv, DOI [arXiv:2010.03409, DOI 10.48550/ARXIV.2010.03409]
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Rossignac J., 1993, Geometric Modeling in Computer Graphics, P455
   Sanchez-Gonzalez A., 2020, P 37 INT C MACHINE L, P8459, DOI DOI 10.48550/ARXIV.2002.09405
   Savva M., 2016, P EUR WORKSH 3D OBJ, V10
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schult Jonas, 2020, P IEEE CVF C COMP VI, P8612, DOI DOI 10.1109/CVPR42600.2020.00864
   Sharp N, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3507905
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Singh VV, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4883, DOI 10.1145/3474085.3475468
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Smirnov D, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459797
   Socher Richard, 2012, NIPS, P656
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Wang PS, 2020, IEEE COMPUT SOC CONF, P1074, DOI 10.1109/CVPRW50498.2020.00141
   Wang PS, 2021, AAAI CONF ARTIF INTE, V35, P2773
   Wang PS, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275050
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Yuqi Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13575, DOI 10.1109/CVPR42600.2020.01359
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
NR 70
TC 2
Z9 2
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4211
EP 4224
DI 10.1109/TVCG.2023.3257035
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700010
PM 37028344
DA 2024-08-05
ER

PT J
AU Suh, A
   Appleby, G
   Anderson, EW
   Finelli, L
   Chang, R
   Cashman, D
AF Suh, Ashley
   Appleby, Gabriel
   Anderson, Erik W.
   Finelli, Luca
   Chang, Remco
   Cashman, Dylan
TI Are Metrics Enough? Guidelines for Communicating and Visualizing
   Predictive Models to Subject Matter Experts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data models; Data visualization; Predictive models; Interviews; Data
   science; Guidelines; Stakeholders; Data communications aspects; human
   factors; modeling and prediction; visualization techniques and
   methodologies
ID DATA-SCIENCE; INNOVATIONS; CHALLENGES; ART
AB Presenting a predictive model's performance is a communication bottleneck that threatens collaborations between data scientists and subject matter experts. Accuracy and error metrics alone fail to tell the whole story of a model - its risks, strengths, and limitations - making it difficult for subject matter experts to feel confident in their decision to use a model. As a result, models may fail in unexpected ways or go entirely unused, as subject matter experts disregard poorly presented models in favor of familiar, yet arguably substandard methods. In this paper, we describe an iterative study conducted with both subject matter experts and data scientists to understand the gaps in communication between these two groups. We find that, while the two groups share common goals of understanding the data and predictions of the model, friction can stem from unfamiliar terms, metrics, and visualizations - limiting the transfer of knowledge to SMEs and discouraging clarifying questions being asked during presentations. Based on our findings, we derive a set of communication guidelines that use visualization as a common medium for communicating the strengths and weaknesses of a model. We provide a demonstration of our guidelines in a regression modeling scenario and elicit feedback on their use from subject matter experts. From our demonstration, subject matter experts were more comfortable discussing a model's performance, more aware of the trade-offs for the presented model, and better equipped to assess the model's risks - ultimately informing and contextualizing the model's use beyond text and numbers.
C1 [Suh, Ashley; Appleby, Gabriel; Chang, Remco] Tufts Univ, Medford, MA 02155 USA.
   [Anderson, Erik W.; Finelli, Luca; Cashman, Dylan] Novartis Pharmaceut, Data Sci & AI, CH-4033 Basel, Switzerland.
C3 Tufts University; Novartis
RP Suh, A (corresponding author), Tufts Univ, Medford, MA 02155 USA.
EM ashleysuh1@gmail.com; gabriel.appleby@tufts.edu;
   erik.anderson@novartis.com; luca.finelli@novartis.com;
   remco@cs.tufts.edu; dylancash88@yahoo.com
OI Chang, Remco/0000-0002-6484-6430; Cashman, Dylan/0000-0003-4853-5701;
   Suh, Ashley/0000-0001-6513-8447; Anderson, Erik/0000-0002-0334-8497
FU National Science Foundation [IIS1452977, OAC-1940175, OAC-1939945,
   OAC-2118201, NRT-2021874]; DOD [HQ0860-20-C-7137]
FX This work was supported in part by National Science Foundation under
   Grants IIS1452977, OAC-1940175, OAC-1939945, OAC-2118201, NRT-2021874,
   and in part by DOD under Grant HQ0860-20-C-7137.
CR Algorithmia, 2021, 2021 enterprise trends in machine learning
   Almenoff JS, 2007, DRUG SAFETY, V30, P631, DOI 10.2165/00002018-200730070-00013
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Bäuerle A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502102
   Berinato S, 2019, HARVARD BUS REV, V97, P126
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Bottinger M., 2020, Foundations of Data Visualization, P297, DOI [10.1007/978-3-030-34444-3, DOI 10.1007/978-3-030-34444-3]
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI 10.1191/1478088706qp063oa
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cresswell K, 2013, INT J MED INFORM, V82, pE73, DOI 10.1016/j.ijmedinf.2012.10.007
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   Davis B, 2020, 2020 IEEE WORKSHOP ON TRUST AND EXPERTISE IN VISUAL ANALYTICS (TREX 2020), P1, DOI 10.1109/TREX51495.2020.00005
   DeCuir-Gunby JT, 2011, FIELD METHOD, V23, P136, DOI 10.1177/1525822X10388468
   Donoho D., 1982, P VERS 2 15 18 AUG 1
   Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608, 10.48550/arXiv.1702.08608]
   Emanuel EJ, 2019, JAMA-J AM MED ASSOC, V321, P2281, DOI 10.1001/jama.2019.4914
   Evans SJW, 2000, STAT MED, V19, P3199, DOI 10.1002/1097-0258(20001215)19:23<3199::AID-SIM621>3.0.CO;2-Q
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Friendly M, 2013, STAT SCI, V28, P1, DOI 10.1214/12-STS402
   Frisch B., 2020, WHAT IT TAK RUN GREA
   Furman J, 2019, Innov Policy, V19, P161, DOI [DOI 10.1086/699936, 10.1086/699936]
   Harvey J, 2002, WORK STRESS, V16, P18, DOI 10.1080/02678370110113226
   Hohman F, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P151, DOI [10.1109/visual.2019.8933695, 10.1109/VISUAL.2019.8933695]
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Hong Sungsoo Ray, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392878
   Hopkins A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P134, DOI 10.1145/3461702.3462527
   Weerts HJP, 2019, Arxiv, DOI [arXiv:1907.03324, DOI 10.48550/ARXIV.1907.03324]
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kessler JS, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P85, DOI 10.18653/v1/P17-4015
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Lam H, 2008, IEEE T VIS COMPUT GR, V14, P1149, DOI 10.1109/TVCG.2008.109
   Lipton Z. C, 2018, Queue, V16, P31, DOI DOI 10.1145/3236386.3241340
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   MacQueen KM., 1998, Cultural Anthropology Methods, V10, P31, DOI [DOI 10.1177/1525822X980100020301, 10.1177/1525822X980100020301]
   Mohseni S, 2020, Arxiv, DOI arXiv:1811.11839
   Mosca A., 2019, Proc. EuroVis-Short Papers
   Nittas Vasileios, 2023, PLOS Digit Health, V2, pe0000189, DOI 10.1371/journal.pdig.0000189
   Pace RK, 1997, STAT PROBABIL LETT, V33, P291, DOI 10.1016/s0167-7152(96)00140-x
   Passi Samir, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274405
   Hoffman RR, 2019, Arxiv, DOI [arXiv:1812.04608, DOI 10.48550/ARXIV.1812.04608]
   Ransbotham S., 2020, MIT Sloan Management Review, P1
   Rudin C, 2022, STAT SURV, V16, P1, DOI 10.1214/21-SS133
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518
   Schelp C., 2018, An alternative way to plot the covariance ellipse
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seneviratne MG, 2020, BMJ INNOV, V6, P45, DOI 10.1136/bmjinnov-2019-000359
   Shah NH, 2019, JAMA-J AM MED ASSOC, V322, P1351, DOI 10.1001/jama.2019.10306
   Shilo S, 2020, NAT MED, V26, P29, DOI 10.1038/s41591-019-0727-5
   Sievert C, 2020, Interactive web-based data visualization with R, plotly, and shiny, V1st, DOI DOI 10.1201/9780429447273
   Smiciklas M., 2012, The power of infographics: Using pictures to communicate and connect with your audiences
   Suresh H, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P767, DOI 10.1145/3490099.3511160
   Suresh H, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445088
   Wang DD, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934212, 10.1145/3290605.3300831]
   Webb S, 2018, NATURE, V554, P555, DOI 10.1038/d41586-018-02174-z
   Yang FM, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P189, DOI 10.1145/3377325.3377480
   Yifan Wu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P152, DOI 10.1145/3379337.3415851
   Zytek A, 2022, IEEE T VIS COMPUT GR, V28, P1161, DOI 10.1109/TVCG.2021.3114864
NR 61
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4137
EP 4153
DI 10.1109/TVCG.2023.3259341
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700026
PM 37030764
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Xiong, K
   Xu, XY
   Fu, SW
   Weng, D
   Wang, YH
   Wu, YC
AF Xiong, Kai
   Xu, Xinyi
   Fu, Siwei
   Weng, Di
   Wang, Yongheng
   Wu, Yingcai
TI JsonCurer: Data Quality Management for JSON Based on an Aggregated
   Schema
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data integrity; Taxonomy; Monitoring; Usability;
   Data mining; Data analysis; Data quality; JSON; schema aggregation;
   visualization
ID VISUALIZATION; DESIGN; METHODOLOGY; SETS
AB High-quality data is critical to deriving useful and reliable information. However, real-world data often contains quality issues undermining the value of the derived information. Most existing research on data quality management focuses on tabular data, leaving semi-structured data under-exploited. Due to the schema-less and hierarchical features of semi-structured data, discovering and fixing quality issues is challenging and time-consuming. To address the challenge, this paper presents JsonCurer, an interactive visualization system to assist with data quality management in the context of JSON data. To have an overview of quality issues, we first construct a taxonomy based on interviews with data practitioners and a review of 119 real-world JSON files. Then we highlight a schema visualization that presents structural information, statistical features, and quality issues of JSON data. Based on a similarity-based aggregation technique, the visualization depicts the entire JSON data with a concise tree, where summary visualizations are given above each node, and quality issues are illustrated using Bubble Sets across nodes. We evaluate the effectiveness and usability of JsonCurer with two case studies. One is in the domain of data analysis while the other concerns quality assurance in MongoDB documents.
C1 [Xiong, Kai; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Xu, Xinyi; Weng, Di] Zhejiang Univ, Sch Software Technol, Hangzhou 310027, Peoples R China.
   [Fu, Siwei; Wang, Yongheng] Zhejiang Lab, Hangzhou 311121, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang Laboratory
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.; Fu, SW (corresponding author), Zhejiang Lab, Hangzhou 311121, Peoples R China.
EM kaixiong@zju.edu.cn; xinyixu@zju.edu.cn; fusiwei339@gmail.com;
   dweng@zju.edu.cn; wangyh@zhejianglab.com; ycwu@zju.edu.cn
OI Weng, Di/0000-0003-2712-7274; Wang, Yongheng/0000-0002-7675-2327; Xiong,
   Kai/0000-0002-8203-9667
FU NSFC
FX No Statement Available
CR Abedjan Z., 2018, SYNTH LECT DATA MANA, V10, P1
   Akbulut O, 2023, VIS INFORM, V7, P22, DOI 10.1016/j.visinf.2023.06.003
   Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsallakh B, 2017, IEEE T VIS COMPUT GR, V23, P361, DOI 10.1109/TVCG.2016.2598496
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   [Anonymous], 2023, JSON To CSV Converter
   [Anonymous], 2023, 2022 January Bitcoin Tweets
   [Anonymous], 2003, Exploratory Data Mining and Data Cleaning
   [Anonymous], 2023, JSON Crack-Crack your data into pieces
   [Anonymous], 2023, Tableau prepbuilder
   [Anonymous], 2023, Convert JSON to other formats and vice-versa
   [Anonymous], 2023, Flatten Complex Nested JSON
   [Anonymous], 2023, JSON Formatter, Validator, Viewer, Editor & Beautifier
   Arbesser C, 2017, IEEE T VIS COMPUT GR, V23, P641, DOI 10.1109/TVCG.2016.2598592
   Baazizi Mohamed-Amine, 2017, Movebank, V1, DOI 10.5441/002/edbt.2017.21
   Batini C., 2008, International Journal of Innovative Computing and Applications, V1, P205
   Batini Carlo., 2006, Data Quality: Concepts, DOI DOI 10.1007/3-540-33173-5
   Josko JMB, 2017, INFORM VISUAL, V16, P93, DOI 10.1177/1473871616629516
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boyer J., 2011, P W3C WORKSH DAT SER
   Byelas H., 2006, Proc. of SOFTVIS, P105
   Cai SJ, 2022, VIS INFORM, V6, P50, DOI 10.1016/j.visinf.2022.04.001
   Izquierdo JLC, 2016, KNOWL-BASED SYST, V103, P52, DOI 10.1016/j.knosys.2016.03.020
   Chen Ran, 2023, IEEE Trans Vis Comput Graph, V29, P128, DOI 10.1109/TVCG.2022.3209385
   Chu X, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2201, DOI 10.1145/2882903.2912574
   Chu X, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1247, DOI 10.1145/2723372.2749431
   Chu X, 2013, PROC INT CONF DATA, P458, DOI 10.1109/ICDE.2013.6544847
   Code Beautify, 2023, JSON cleaner online to clean messy JSON online
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Dallachiesa Michele, 2013, SIGMOD International Conference on Management of Data, SIGMOD '13, P541, DOI 10.1145/2463676.2465327
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Dinkla K, 2012, COMPUT GRAPH FORUM, V31, P875, DOI 10.1111/j.1467-8659.2012.03080.x
   Droettboom M, 2023, Understanding JSON Schema
   Durner D, 2021, INT CONF MANAGE DATA, P445, DOI 10.1145/3448016.3452809
   Ehrlinger L, 2022, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.850611
   Ehrlinger L, 2019, LECT NOTES COMPUT SC, V11235, P1, DOI 10.1007/978-3-030-19143-6_1
   Ehrlinger Lisa, 2017, P 22 MIT INT C INF Q
   Fletcher Sam, 2018, Australasian Journal of Information Systems, V22, P1
   Geerts F, 2013, PROC VLDB ENDOW, V6, P625, DOI 10.14778/2536360.2536363
   GitHub, 2023, about us
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   Jain A, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3561, DOI 10.1145/3394486.3406477
   Judah S., 2023, Magic quadrant for data quality tools
   kaggle, 2023, About us
   Kagkelidis K, 2021, J VISUAL-JAPAN, V24, P631, DOI 10.1007/s12650-020-00718-y
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kasica S, 2021, IEEE T VIS COMPUT GR, V27, P957, DOI 10.1109/TVCG.2020.3030462
   Khayyat Z, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1215, DOI 10.1145/2723372.2747646
   Kim W., 2002, J. Object Technol., V1, P39, DOI [10.5381/jot.2002.1.4.c3, DOI 10.5381/JOT.2002.1.4.C3]
   Kui XY, 2022, VIS INFORM, V6, P67, DOI 10.1016/j.visinf.2022.07.004
   Laranjeiro N, 2015, IEEE PAC RIM INT SYM, P179, DOI 10.1109/PRDC.2015.41
   Lee YW, 2002, INFORM MANAGE-AMSTER, V40, P133, DOI 10.1016/S0378-7206(02)00043-5
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Li GY, 2022, IEEE INFOCOM SER, P1, DOI [10.1109/INFOCOM48880.2022.9796694, 10.1109/TVCG.2022.3209354]
   LI L., 2011, GSTF International Journal on Computing, V1, P140
   Meulemans W, 2013, IEEE T VIS COMPUT GR, V19, P1846, DOI 10.1109/TVCG.2013.76
   Micic N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P155, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.28
   Moore S., 2023, How to create a business case for data quality improvement
   Moseler O, 2022, J VISUAL-JAPAN, V25, P1267, DOI 10.1007/s12650-022-00843-w
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Naumann F, 2013, SIGMOD REC, V42, P40, DOI 10.1145/2590989.2590995
   Oetting J., 2019, Data visualization 101: How to choose the right chart or graph for your data
   OpenRefine, 2023, about us
   Oracle Enterprise Data Quality, 2023, about us
   Papadakis G, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3377455
   Park H, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P577, DOI 10.1145/2588555.2610503
   Parra A. V., 2019, P INT C INF SYST, P1
   Rahm Erhard, 2000, proceedings of IEEE Bulletin of Technical Committee on Data Engineering, V23, P3, DOI DOI 10.1145/1317331.1317341
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Sandrih B, 2017, IPSI BDG TRANS INTER, V13
   Schmidt CO, 2021, BMC MED RES METHODOL, V21, DOI 10.1186/s12874-021-01252-7
   Sebastian-Coleman L., 2012, Measuring data quality for ongoing improvement: a data quality assessment framework
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Simoes G, 2013, PROC VLDB ENDOW, V6, P1462, DOI 10.14778/2536258.2536259
   Skoutas D, 2007, INT J SEMANT WEB INF, V3, P1, DOI 10.4018/jswis.2007100101
   Spoth W, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209908
   Stackoverflow, 2023, about us
   Tong YX, 2014, PROC INT CONF DATA, P1182, DOI 10.1109/ICDE.2014.6816736
   Tuura L, 2010, J PHYS CONF SER, V219, DOI 10.1088/1742-6596/219/7/072020
   Wang JN, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P457, DOI 10.1145/2588555.2610494
   Wang JN, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P469, DOI 10.1145/2588555.2610505
   Wang R. Y., 1996, Journal of Management Information Systems, V12, P5
   Wang RY, 1998, COMMUN ACM, V41, P58, DOI 10.1145/269012.269022
   Wang YC, 2022, VIS INFORM, V6, P12, DOI 10.1016/j.visinf.2022.09.001
   Wang ZY, 2017, PROC VLDB ENDOW, V10, P1897, DOI 10.14778/3137765.3137803
   Xiong Kai, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209470
   Xiong K, 2023, IEEE T VIS COMPUT GR, V29, P2950, DOI 10.1109/TVCG.2022.3144975
   Yang WK, 2023, Arxiv, DOI arXiv:2310.05771
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 91
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3008
EP 3021
DI 10.1109/TVCG.2024.3388556
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500009
PM 38625779
DA 2024-08-05
ER

PT J
AU Morgenstern, W
   Bagdasarian, MT
   Hilsmann, A
   Eisert, P
AF Morgenstern, Wieland
   Bagdasarian, Milena T.
   Hilsmann, Anna
   Eisert, Peter
TI Animatable Virtual Humans: Learning Pose-Dependent Human Representations
   in UV Space for Interactive Performance Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Geometry; Computational modeling; Shape;
   Real-time systems; X reality; Three-dimensional displays; Virtual
   Humans; Real-time Animation; Generative Neural Networks; Volumetric
   Video; XR Applications
AB We propose a novel representation of virtual humans for highly realistic real-time animation and rendering in 3D applications. We learn pose dependent appearance and geometry from highly accurate dynamic mesh sequences obtained from state-of-the-art multiview-video reconstruction. Learning pose-dependent appearance and geometry from mesh sequences poses significant challenges, as it requires the network to learn the intricate shape and articulated motion of a human body. However, statistical body models like SMPL provide valuable a-priori knowledge which we leverage in order to constrain the dimension of the search space, enabling more efficient and targeted learning and to define pose-dependency. Instead of directly learning absolute pose-dependent geometry, we learn the difference between the observed geometry and the fitted SMPL model. This allows us to encode both pose-dependent appearance and geometry in the consistent UV space of the SMPL model. This approach not only ensures a high level of realism but also facilitates streamlined processing and rendering of virtual humans in real-time scenarios.
C1 [Morgenstern, Wieland; Bagdasarian, Milena T.; Hilsmann, Anna; Eisert, Peter] Fraunhofer Heinrich Hertz Inst, HHI, Berlin, Germany.
   [Bagdasarian, Milena T.; Eisert, Peter] Humboldt Univ, Berlin, Germany.
C3 Fraunhofer Gesellschaft; Humboldt University of Berlin
RP Morgenstern, W (corresponding author), Fraunhofer Heinrich Hertz Inst, HHI, Berlin, Germany.
EM wieland.morgenstern@hhi.fraunhofer.de;
   milenat.bagdasarian@hhi.fraunhofer.de; anna.hilsmann@hhi.fraunhofer.de;
   peter.eisert@hhi.fraunhofer.de
FU European Union
FX No Statement Available
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   [Anonymous], 2021, Github, V3
   B. O. Community, 2024, Blender-a 3D modelling and rendering package
   Bai K., ONNX: Open Neural Network Exchange
   Boukhayma A, 2019, IEEE T VIS COMPUT GR, V25, P2270, DOI 10.1109/TVCG.2018.2831233
   Bradski G, 2000, DR DOBBS J, V25, P120
   Fechteler P, 2019, COMPUT GRAPH FORUM, V38, P91, DOI 10.1111/cgf.13608
   Feng Y, 2021, INT CONF 3D VISION, P792, DOI 10.1109/3DV53792.2021.00088
   Gafni G, 2021, PROC CVPR IEEE, P8645, DOI 10.1109/CVPR46437.2021.00854
   Grassal PW, 2022, PROC CVPR IEEE, P18632, DOI 10.1109/CVPR52688.2022.01810
   Haas K.J., 2014, DISS WORCESTER POLYT, P484
   Habermann M, 2023, P ACM COMPUT GRAPH, V6, DOI 10.1145/3606927
   Jiang X., 2023, InProc. IEEE/CVF Con-ference on Computer Vision and Pattern Recognition (CVPR), V3
   Kingma J. L. Ba., 2015, 3 INT C LEARNING REP, V6
   Knoll W., 2024, INPROC INT C COMPUTE
   Liu LJ, 2021, IEEE T VIS COMPUT GR, V27, P4009, DOI 10.1109/TVCG.2020.2996594
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Morgenstern A., 2019, INPROCEEDINGS CVMP 2, P1
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Paier W, 2020, IET COMPUT VIS, V14, P359, DOI 10.1049/iet-cvi.2019.0790
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Paszke A, 2019, ADV NEUR IN, V32
   Prokudin S, 2021, IEEE WINT CONF APPL, P1809, DOI 10.1109/WACV48630.2021.00185
   Regateiro J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.739010
   Sarkar L., 2021, arXiv, V3
   Schreer O, 2019, IEEE IMAGE PROC, P4310, DOI [10.1109/ICIP.2019.8803576, 10.1109/icip.2019.8803576]
   Shen KY, 2023, PROC CVPR IEEE, P16911, DOI 10.1109/CVPR52729.2023.01622
   Su SY, 2021, ADV NEUR IN, V34
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tretschk Edgar, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P601, DOI 10.1007/978-3-030-58548-8_35
   Wang X., 2022, arXiv, V3
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408
   Xu TH, 2022, PROC CVPR IEEE, P15862, DOI 10.1109/CVPR52688.2022.01542
   Zheng H., 2022, INPROC IEEECVFCONFER, ppag
   Zheng X. Zhao, 2023, ACM Trans. Graph., V42
   Zimmer A, 2023, COMPUT VIS MEDIA, V9, P123, DOI 10.1007/s41095-022-0272-x
NR 38
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2644
EP 2650
DI 10.1109/TVCG.2024.3372117
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400011
PM 38466595
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Canales, R
   Raveendranath, B
   Pagano, CC
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Roshan
   Venkatakrishnan, Rohith
   Canales, Ryan
   Raveendranath, Balagopal
   Pagano, Christopher C.
   Robb, Andrew C.
   Lin, Wen-Chieh
   Babu, Sabarish V.
TI Investigating the Effects of Avatarization and Interaction Techniques on
   Near-field Mixed Reality Interactions with Physical Components
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mixed Reality; Self-Avatars; Interactions in MR; Tangible entities
ID AUGMENTED REALITY; USER-INTERFACE; PERFORMANCE; ONLINE
AB Mixed reality (MR) interactions feature users interacting with a combination of virtual and physical components. Inspired by research investigating aspects associated with near-field interactions in augmented and virtual reality (AR & VR), we investigated how avatarization, the physicality of the interacting components, and the interaction technique used to manipulate a virtual object affected performance and perceptions of user experience in a mixed reality fundamentals of laparoscopic peg-transfer task wherein users had to transfer a virtual ring from one peg to another for a number of trials. We employed a 3 (Physicality of pegs) X 3 (Augmented Avatar Representation) X 2 (Interaction Technique) multi-factorial design, manipulating the physicality of the pegs as a between-subjects factor, the type of augmented self-avatar representation, and the type of interaction technique used for object-manipulation as within-subjects factors. Results indicated that users were significantly more accurate when the pegs were virtual rather than physical because of the increased salience of the task-relevant visual information. From an avatar perspective, providing users with a reach envelope-extending representation, though useful, was found to worsen performance, while co-located avatarization significantly improved performance. Choosing an interaction technique to manipulate objects depends on whether accuracy or efficiency is a priority. Finally, the relationship between the avatar representation and interaction technique dictates just how usable mixed reality interactions are deemed to be.
C1 [Venkatakrishnan, Roshan; Venkatakrishnan, Rohith] Univ Florida, Gainesville, FL 32611 USA.
   [Canales, Ryan; Raveendranath, Balagopal] Clemson Univ, Clemson, SC USA.
   [Pagano, Christopher C.] Clemson Univ, Dept Psychol, Clemson, SC USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC USA.
C3 State University System of Florida; University of Florida; Clemson
   University; Clemson University; National Yang Ming Chiao Tung
   University; Clemson University
RP Venkatakrishnan, R (corresponding author), Univ Florida, Gainesville, FL 32611 USA.
EM rvenkatakrishnan@ufl.edu; rohith.venkatakr@ufl.edu; rcanale@clemson.edu;
   braveen@g.clemson.edu; cpagano@clemson.edu; arobb@clemson.edu;
   wclin@cs.nctu.edu.tw; sbabu@clemson.edu
RI Venkatakrishnan, Rohith/JCE-8736-2023; Venkatakrishnan,
   Roshan/JDC-3508-2023
OI Venkatakrishnan, Rohith/0000-0002-8484-3915; Venkatakrishnan,
   Roshan/0000-0002-6538-627X; Pagano, Christopher/0000-0002-0110-2055;
   Robb, Andrew/0000-0002-0398-5576; Babu, Sabarish/0000-0002-8348-0534;
   Canales, Ryan/0000-0003-0554-7817
FU US National Science Foundation (CISE IIS HCC)
FX No Statement Available
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Badam S. K., 2017, 2 WORKSH IMM AN, P3
   Bowman D. A., 1999, Interaction techniques for common tasks in immersive virtual environments: design, evaluation, and application, P5
   Bozgeyikli E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P778, DOI 10.1109/VR50410.2021.00105
   Brickler D, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486583
   Brickler D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419986
   Brickler D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P28, DOI [10.1109/vr.2019.8797744, 10.1109/VR.2019.8797744]
   Bullock IM, 2015, IEEE ENG MED BIO, P5768, DOI 10.1109/EMBC.2015.7319703
   Canales Ryan, 2020, MIG '20: Motion, Interaction and Games, DOI 10.1145/3424636.3426897
   Chen ZR, 2017, IEEE SYS MAN CYBERN, P206, DOI 10.1109/SMC.2017.8122603
   Cheng KY, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1155
   Ebrahimi E, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225170
   Ehnes J, 2009, C HUM SYST INTERACT, P303, DOI 10.1109/HSI.2009.5090997
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.00-38, 10.1109/VR46266.2020.1581285352835]
   Fajen B. R., 2021, Visual control of locomotion, P8
   Feiner A. O. S., 2003, P 16 ANN ACM S US IN, V3, P81
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Fried GM, 2008, J GASTROINTEST SURG, V12, P210, DOI 10.1007/s11605-007-0355-0
   Frutos-Pascual M, 2019, LECT NOTES COMPUT SC, V11749, P287, DOI 10.1007/978-3-030-29390-1_16
   Genay A, 2022, IEEE T VIS COMPUT GR, V28, P5071, DOI 10.1109/TVCG.2021.3099290
   Gerini L, 2022, IEEE INT SYMP M AU R, P566, DOI 10.1109/ISMAR-Adjunct57072.2022.00118
   Gomez SR, 2010, LECT NOTES COMPUT SC, V6454, P373, DOI 10.1007/978-3-642-17274-8_37
   Ha T, 2014, INT SYM MIX AUGMENT, P219, DOI 10.1109/ISMAR.2014.6948431
   Ha T, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P91, DOI 10.1109/3DUI.2010.5444713
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Hettiarachchi A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1957, DOI 10.1145/2858036.2858134
   Hoang TN, 2013, PROCEEDINGS OF 2013 23RD INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE (ICAT 2013), P46
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Ishiyama H, 2016, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2016.7504716
   Issarter P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2014.6798839
   Johnson Adrian S., 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P169, DOI 10.1007/978-3-642-39405-8_20
   Kaiser E., 2003, ICMI 03, P12
   Kang HJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P275, DOI [10.1109/VR46266.2020.00047, 10.1109/VR46266.2020.00-57]
   Kohm K, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3561055
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kyriakou Panayiotis, 2019, Digital Applications in Archaeology and Cultural Heritage, V12, DOI 10.1016/j.daach.2018.e00088
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Lamounier E A., 2012, Journal of Bioengineering Biomedical Science, V1, P010, DOI [DOI 10.4172/2155-9538.S1-010, 10.4172/2155-9538.S1-010]
   Lewis JR, 2002, INT J HUM-COMPUT INT, V14, P463, DOI 10.1080/10447318.2002.9669130
   Li K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079400
   Li ZM, 2007, J BIOMECH, V40, P502, DOI 10.1016/j.jbiomech.2006.02.019
   Lu G, 2012, VIRTUAL REAL-LONDON, V16, P243, DOI 10.1007/s10055-011-0195-9
   Macaranas A, 2015, INTERACT COMPUT, V27, P357, DOI 10.1093/iwc/iwv003
   Marzke MW, 1997, AM J PHYS ANTHROPOL, V102, P91
   Merrill D, 2007, LECT NOTES COMPUT SC, V4480, P1
   Mifsud DM, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P581, DOI 10.1109/VRW55335.2022.00146
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nagel T., 2011, GEOVIZ 2011, P10
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Noh Seungtak., 2015, ICAT-EGVE, P61
   O'Connor TF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179766
   Otono R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P721, DOI 10.1109/VRW55335.2022.00216
   Piekarski W., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P19, DOI 10.1145/769953.769956
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   Piumsomboon Thammathip., 2011, Proc. Image and Vision Computing New Zealand (IVCNZ-2011), P161
   Poelman R., 2012, P ACM 2012 C COMP SU, P1267, DOI [10.1145/2145204.2145394, DOI 10.1145/2145204.2145394]
   Prilla Michael., 2019, AIS Transactions on Human-Computer Interaction, V11, P157, DOI DOI 10.17705/1THCI.00118
   Quandt M., 2020, DELIA@ EC-TEL
   Radkowski R., 2012, P 2012 INT C ADV COM, P303
   Robb A, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560818
   Rosa N, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P550, DOI 10.1145/2993148.2997618
   Schiettecatte B., 2008, Proceedings of the 2nd international conference on Tangible and embedded interaction, P3
   Schmidt S, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357591
   Serrano R, 2022, MULTIMED TOOLS APPL, V81, P31657, DOI 10.1007/s11042-022-12864-6
   Sibert L. E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P281, DOI 10.1145/332040.332445
   Snijders T.A.B., 1999, MULTILEVEL ANAL INTR
   Soares Alcimar Barbosa., 2012, Computational Intelligence in Electromyography Analysis-A Perspective on Current Applications and Future Challenges, P409
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Sroka G, 2010, AM J SURG, V199, P115, DOI 10.1016/j.amjsurg.2009.07.035
   Terrier R, 2018, LECT NOTES COMPUT SC, V11162, P190, DOI 10.1007/978-3-030-01790-3_12
   Valentini PP, 2018, INT J INTERACT DES M, V12, P1157, DOI 10.1007/s12008-018-0461-0
   Venkatakrishnan R, 2023, IEEE T VIS COMPUT GR, V29, P2412, DOI 10.1109/TVCG.2023.3247105
   Venkatakrishnan R, 2023, IEEE T VIS COMPUT GR, V29, P2258, DOI 10.1109/TVCG.2023.3247041
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Wen, 2023, Wen 3921 16-inch two-direction variable speed scroll saw
   Whitlock M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P41, DOI 10.1109/VR.2018.8446381
   Wither J, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P124, DOI 10.1109/ISWC.2004.18
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   Zhao HY, 2015, VISION RES, V110, P190, DOI 10.1016/j.visres.2014.10.008
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 84
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2756
EP 2766
DI 10.1109/TVCG.2024.3372050
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400039
PM 38437122
DA 2024-08-05
ER

PT J
AU Xiong, NC
   Liu, QQ
   Zhu, KN
AF Xiong, Ningchang
   Liu, Qingqin
   Zhu, Kening
TI PetPresence: Investigating the Integration of Real-World Pet Activities
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Visualization; Virtual environments; Urban areas;
   Three-dimensional displays; Portals; Media; Virtual Reality; Haptics;
   Distractions; Presence; Pet
AB For VR interaction, the home environment with complicated spatial setup and dynamics may hinder the VR user experience. In particular, pets' movement may be more unpredictable. In this paper, we investigate the integration of real-world pet activities into immersive VR interaction. Our pilot study showed that the active pet movements, especially dogs, could negatively impact users' performance and experience in immersive VR. We proposed three different types of pet integration, namely semitransparent real-world portal, non-interactive object in VR, and interactive object in VR. We conducted the user study with 16 pet owners and their pets. The results showed that compared to the baseline condition without any pet-integration technique, the approach of integrating the pet as interactive objects in VR yielded significantly higher participant ratings in perceived realism, joy, multisensory engagement, and connection with their pets in VR.
C1 [Xiong, Ningchang; Liu, Qingqin; Zhu, Kening] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Zhu, KN (corresponding author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
EM nxiong9-c@my.cityu.edu.hk; neoliu@cityu.edu.hk; keninzhu@cityu.edu.hk
OI Liu, Qingqin/0000-0002-2150-4078; ZHU, Kening/0000-0001-6740-4921
FU National Natural Science Foundation of China
FX No Statement Available
CR Applebaum JW, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10101882
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Basch CH, 2014, INJURY PREV, V20, DOI 10.1136/injuryprev-2013-041063
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Chung S, 2023, VISUAL COMPUT, V39, P3145, DOI 10.1007/s00371-022-02676-y
   Dao E., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445435
   Fang C. M., 2023, 2023 CHI C HUM FACT, P1
   Flavián C, 2021, J BUS RES, V123, P289, DOI 10.1016/j.jbusres.2020.09.036
   Garau M, 2008, PRESENCE-TELEOP VIRT, V17, P293, DOI 10.1162/pres.17.3.293
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Golbeck J., 2012, CHI 12 EXTENDED ABST, P211, DOI [10.1145/2212776.2212799, DOI 10.1145/2212776.2212799]
   Gonçalves G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3533377
   Gonçalves G, 2020, IEEE T VIS COMPUT GR, V26, P3231, DOI 10.1109/TVCG.2019.2926978
   Gottsacker M, 2021, INT SYM MIX AUGMENT, P310, DOI 10.1109/ISMAR52148.2021.00047
   Harley D, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P386, DOI 10.1145/3173225.3173241
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hirskyj-Douglas Ilyena, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020030
   Huard A, 2022, INT SYM MIX AUGMENT, P538, DOI 10.1109/ISMAR55827.2022.00070
   Insko B. E., 2001, PhD thesis
   Judistira A. D., 2023, International Journal of Advanced Information Technology, V6, DOI [10.25124/ijait.v6i02.4351, DOI 10.25124/IJAIT.V6I02.4351]
   Jukan A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3041960
   Kanat-Maymon Y, 2021, J HAPPINESS STUD, V22, P1441, DOI 10.1007/s10902-020-00279-9
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Kudo Yoshiki, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3486950
   Lee SP, 2006, PERS UBIQUIT COMPUT, V10, P301, DOI 10.1007/s00779-005-0051-6
   Lim S, 2023, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR59233.2023.00014
   Lin CL, 2017, INT CONF AFFECT, P362, DOI 10.1109/ACII.2017.8273625
   Liu Huimin., 2021, Graphics and Visual Computing, V4, P200020, DOI DOI 10.1016/J.GVC.2021.200020
   Mancini Clara, 2011, Interactions, V18, P69, DOI 10.1145/1978822.1978836
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Na HW, 2023, FRONT VET SCI, V10, DOI 10.3389/fvets.2023.1102937
   Na H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031159
   Norouzi N, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P400, DOI 10.1109/ISMAR-Adjunct.2019.000-1
   Norouzi N, 2019, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2019.000-8
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   Oh C, 2019, CYBERPSYCH BEH SOC N, V22, P365, DOI 10.1089/cyber.2018.0404
   Oxley JA, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.782023
   Piumsomboon T, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.943696
   Ritvo S., 2014, P 2014 WORKSH ADV CO, P1
   Rodriguez KE, 2021, FRONT VET SCI, V7, DOI 10.3389/fvets.2020.619600
   Shih YS, 2016, INT CONF SYST SCI EN
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., Enhancing our lives with immersive virtual reality
   Sra M., 2015, ADJ P 28 ANN ACM S U, P47, DOI [DOI 10.1145/2815585.2817802, 10.1145/2815585.2817802]
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Sra Misha., 2016, P 29 ANN S USER INTE, P29, DOI DOI 10.1145/2984751.2984788
   Tao YJ, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545682
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   VORMBROCK JK, 1988, J BEHAV MED, V11, P509, DOI 10.1007/BF00844843
   Wang CH, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545686
   Wu SX, 2023, Symposium Virtual Re, P631, DOI 10.1109/VR55154.2023.00078
   Zenner A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188505
NR 56
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2559
EP 2569
DI 10.1109/TVCG.2024.3372095
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400014
PM 38437107
DA 2024-08-05
ER

PT J
AU Chen, C
   Lee, BS
   Wang, YH
   Chang, YJ
   Liu, ZC
AF Chen, Chen
   Lee, Bongshin
   Wang, Yunhai
   Chang, Yunjeong
   Liu, Zhicheng
TI Mystique: Deconstructing SVG Charts for Layout Reuse
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Chart layout; Reuse; Reverse-engineering; Deconstruction
AB To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings. However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts. In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones, as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts). We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints. Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data. On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction. In a chart reproduction study, participants could easily reuse existing charts on new datasets. We discuss the current limitations of Mystique and future research directions.
C1 [Chen, Chen; Chang, Yunjeong; Liu, Zhicheng] Univ Maryland, College Pk 20742, MD USA.
   [Lee, Bongshin] Microsoft Res, Redmond, WA USA.
   [Wang, Yunhai] Shandong Univ, Qingdao, Shandong, Peoples R China.
C3 University System of Maryland; University of Maryland College Park;
   Microsoft; Shandong University
RP Chen, C (corresponding author), Univ Maryland, College Pk 20742, MD USA.
EM cchen24@umd.edu; bongshin@microsoft.com; cloudseawang@gmail.com;
   ychangs2@terpmail.umd.edu; leozcliu@umd.edu
RI Chen, Chen/IZQ-5537-2023
OI Liu, Zhicheng/0000-0002-1015-2759; Chen, Chen/0000-0003-3171-0657
FU NSF
FX No Statement Available
CR Bako Hannah K, 2023, IEEE Trans Vis Comput Graph, V29, P1048, DOI 10.1109/TVCG.2022.3209490
   Battle L, 2022, IEEE VIS CONF, P1, DOI 10.1109/VIS54862.2022.00009
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Bostock M., 2021, bl.ocks.org
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bruls M, 2000, SPRING COMP SCI, P33
   Chartmaker, 2021, The chartmaker directory
   Chen C, 2023, COMPUT GRAPH FORUM, V42, P449, DOI 10.1111/cgf.14855
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choudhury S. R., 2016, P INT WORKSH SEM BIG, V1, DOI DOI 10.1145/2928294.29283052
   Cui WW, 2022, IEEE T VIS COMPUT GR, V28, P173, DOI 10.1109/TVCG.2021.3114856
   Figma, 2021, Figma Charts and Infographics
   Given C., A bar chart composed of treemaps
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, P 27 ANN ACM S USER, V14, P253, DOI [10.1145/2642918.2647411, DOI 10.1145/2642918.26474112, DOI 10.1145/2642918.2647411]
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jiang WX, 2021, IEEE IMAGE PROC, P1204, DOI 10.1109/ICIP42928.2021.9506171
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Manolis Savva, 2011, P 24 ANN ACM S USER, P393
   Masson D., 2023, P 2023 CHI C HUM FAC, V147, DOI DOI 10.1145/3544548.35811132,3
   McNutt A. M., 2021, P 2021 CHI C HUM FAC, V17, DOI DOI 10.1145/3411764.34453562
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Nielsen F., 2016, Introduction to HPC with MPI for Data Science, DOI DOI 10.1007/978-3-319-21903-5_8
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Observable, 2023, Observable plot
   Po-Shen Lee, 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P79
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Shi XY, 2019, INT CONF ACOUST SPEE, P1343, DOI [10.1109/icassp.2019.8683824, 10.1109/ICASSP.2019.8683824]
   Shneiderman B, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P73, DOI 10.1109/INFVIS.2001.963283
   Shukla S, 2008, INT J DOC ANAL RECOG, V11, P111, DOI 10.1007/s10032-008-0065-5
   Tableau, 2022, Tableau Prep Builder
   Tableau, 2021, Tableau Public
   Trifacta, 2022, Designer Cloud Data Wrangling Software and Tools
   Walny J, 2020, IEEE T VIS COMPUT GR, V26, P12, DOI 10.1109/TVCG.2019.2934538
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wood J, 2008, IEEE T VIS COMPUT GR, V14, P1348, DOI 10.1109/TVCG.2008.165
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 447
EP 457
DI 10.1109/TVCG.2023.3327354
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500122
PM 37883270
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lee, B
   Sedlmair, M
   Schmalstieg, D
AF Lee, Benjamin
   Sedlmair, Michael
   Schmalstieg, Dieter
TI Design Patterns for Situated Visualization in Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; immersive analytics; situated visualization; design
   patterns; design space
ID DEPTH
AB Situated visualization has become an increasingly popular research area in the visualization community, fueled by advancements in augmented reality (AR) technology and immersive analytics. Visualizing data in spatial proximity to their physical referents affords new design opportunities and considerations not present in traditional visualization, which researchers are now beginning to explore. However, the AR research community has an extensive history of designing graphics that are displayed in highly physical contexts. In this work, we leverage the richness of AR research and apply it to situated visualization. We derive design patterns which summarize common approaches of visualizing data in situ. The design patterns are based on a survey of 293 papers published in the AR and visualization communities, as well as our own expertise. We discuss design dimensions that help to describe both our patterns and previous work in the literature. This discussion is accompanied by several guidelines which explain how to apply the patterns given the constraints imposed by the real world. We conclude by discussing future research directions that will help establish a complete understanding of the design of situated visualization, including the role of interactivity, tasks, and workflows.
C1 [Lee, Benjamin; Sedlmair, Michael; Schmalstieg, Dieter] Univ Stuttgart, Stuttgart, Germany.
   [Schmalstieg, Dieter] Graz Univ Technol, Graz, Austria.
C3 University of Stuttgart; Graz University of Technology
RP Lee, B (corresponding author), Univ Stuttgart, Stuttgart, Germany.
EM benjamin.lee@visus.uni-stuttgart.de;
   michael.sedlmair@visus.uni-stuttgart.de; schmalstieg@tugraz.at
OI Lee, Benjamin/0000-0002-1171-4741; Schmalstieg,
   Dieter/0000-0003-2813-2235
FU German Research Foundation (DFG)
FX No Statement Available
CR Alves J, 2019, IEEE INT CONF AUTON, P168
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Anderson F., 2013, Proceedings of the 26th annual ACM symposium on User interface software and technology, DOI [10.1145/2501988.2502045, DOI 10.1145/2501988.2502045]
   [Anonymous], 2005, Illuminating the path: The research and development agenda for visual analytics
   Assor A., 2023, P CHI EA, P1, DOI [10.1145/3544549.3583905, DOI 10.1145/3544549.3583905]
   Bach B., 2017, IEEE VIS WORKSH IMM
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Barakonyi I, 2005, LECT NOTES COMPUT SC, V3711, P345
   Belo J, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545651
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Bier E. A., 1993, Computer Graphics Proceedings, P73, DOI 10.1145/166117.166126
   Blattgerste J, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P133, DOI 10.1145/3197768.3197778
   Bork F, 2019, ANAT SCI EDUC, V12, P585, DOI 10.1002/ase.1864
   Bowman D. A., 2003, P ACM S VIRT REAL SO, P81, DOI [10.1145/1008653.1008669, DOI 10.1145/1008653.1008669]
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Büttner S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376720
   Buschel W., 2021, P 2021 CHI C HUM FAC, P1, DOI [DOI 10.1145/3411764.3445651, 10.1145/3411764.3445651]
   Cao YZ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P521, DOI 10.1145/3332165.3347902
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   Chang Wilson M, 2005, Neurosurgery, V56, P434, DOI 10.1227/01.NEU.0000156551.66538.6A
   Chintamani K, 2010, IEEE T SYST MAN CY A, V40, P29, DOI 10.1109/TSMCA.2009.2030166
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Dillman KR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173714
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Ens Barrett., 2014, Proceedings of the 2nd ACM symposium on Spatial user interaction (SUI'14), P2, DOI [10.1145/2659766.2659769, DOI 10.1145/2659766.2659769]
   Erick AO, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P190, DOI 10.1109/saupec/robmech/prasa48453.2020.9041002
   Feiner S. K., 1992, Visual Computer, V8, P292, DOI 10.1007/BF01897116
   Ferdous HS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300464
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Grubert J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3933, DOI 10.1145/2702123.2702331
   Guarese R, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399838
   Hansen LH, 2021, IEEE T VIS COMPUT GR, V27, P4119, DOI 10.1109/TVCG.2021.3106479
   Heinrich F, 2020, IEEE T VIS COMPUT GR, V26, P3568, DOI 10.1109/TVCG.2020.3023637
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Herr D, 2018, PROC CIRP, V72, P1112, DOI 10.1016/j.procir.2018.03.200
   Hertel J, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P122, DOI 10.1109/VR50410.2021.00033
   Heyen F., 2022, P ISMIR
   Hoang T. N., 2010, P ISWC, P1, DOI [10.1109/ISWC.2010.5665865, DOI 10.1109/ISWC.2010.5665865]
   Hou L, 2013, J COMPUT CIVIL ENG, V27, P439, DOI 10.1061/(ASCE)CP.1943-5487.0000184
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jo H, 2011, COMPUT GRAPH-UK, V35, P841, DOI 10.1016/j.cag.2011.04.005
   Kalkofen D., 2007, P INT S MIXED AUGMEN, P191, DOI [10.1109/ISMAR.2007.4538846, DOI 10.1109/ISMAR.2007.4538846]
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kawsar F, 2011, LECT NOTES COMPUT SC, V6696, P70, DOI 10.1007/978-3-642-21726-5_5
   Kohler Wolfgang, 1947, GESTALT PSYCHOL INTR
   Langerman D, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286182
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Ledermann F, 2005, P IEEE VIRT REAL ANN, P187
   Lee B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580754
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lilija K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300676
   Loch F, 2016, INT CONF INTEL ENVIR, P147, DOI 10.1109/IE.2016.31
   Looser J., 2007, P 2007 6 IEEE ACM IN, P1, DOI DOI 10.1109/ISMAR.2007.4538825
   Luo WZ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580715
   Luo WZ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501946
   Marriott Kim, 2018, Lecture Notes in Computer Science, DOI DOI 10.1007/978-3-030-01388-2
   Mendez E., 2009, Proc. ACM Sym. Vir. Real- ity Softw. Technol., P247, DOI [10.1145/1643928.1643988, DOI 10.1145/1643928.1643988]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mohr P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300815
   Mohr P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6547, DOI 10.1145/3025453.3025688
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Mori Shohei, 2017, IPSJ Transactions on Computer Vision and Applications, V9, P1, DOI [10.1186/s41074-017-0028-1, DOI 10.1186/S41074-017-0028-1]
   Mulloni H., 2011, P ACM C HUM COMP INT, P211, DOI [DOI 10.1145/2037373.2037406, 10.1145/2037373.2037406]
   Munzner Tamara, 2014, Visualization analysis and design
   Polys NF, 2011, INT J HUM-COMPUT ST, V69, P30, DOI 10.1016/j.ijhcs.2010.05.007
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Qian X, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517665
   Reipschläger P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P29, DOI 10.1145/3343055.3359718
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Reitinger B, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208
   Reitmayr G., 2004, P IBS TELECARTOGRAPH
   Rekimoto J, 1998, 3RD ASIA PACIFIC COMPUTER HUMAN INTERACTION, PROCEEDINGS, P63, DOI 10.1109/APCHI.1998.704151
   Ridel B, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2611376
   Rigling S., 2023, P CHI EA, P1, DOI [10.1145/3544549.3585912, DOI 10.1145/3544549.3585912]
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Samset E, 2008, PROC SPIE, V6806, DOI 10.1117/12.784155
   Sandor C, 2009, INT SYM MIX AUGMENT, P211, DOI 10.1109/ISMAR.2009.5336461
   Sareika M., 2007, P ISMAR, P27, DOI [10.1109/ISMAR.2007.4538821, DOI 10.1109/ISMAR.2007.4538821]
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Satriadi KA, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580952
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Schall G, 2008, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2008.4637332
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Schmalstieg D, 1999, PRESENCE-VIRTUAL AUG, V8, P449, DOI 10.1162/105474699566332
   Schoenfelder R, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P83
   Shin S, 2024, IEEE T VIS COMPUT GR, V30, P5147, DOI 10.1109/TVCG.2023.3285546
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Skreinig LR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P386, DOI 10.1109/VRW55335.2022.00086
   Smiley Jim, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488546
   Stanescu A, 2022, IEEE T VIS COMPUT GR, V28, P3821, DOI 10.1109/TVCG.2022.3203104
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Tainaka K, 2020, INT SYM MIX AUGMENT, P474, DOI 10.1109/ISMAR50242.2020.00077
   Tatzgern M., 2013, P JVRC EUR ASS DEC, P49, DOI [10.2312/EGVE.JVRC13.049-056, DOI 10.2312/EGVE.JVRC13.049-056]
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tong Wai, 2023, IEEE Trans Vis Comput Graph, V29, P418, DOI 10.1109/TVCG.2022.3209386
   Uratani K, 2005, P IEEE VIRT REAL ANN, P295
   Veas E, 2013, PERS UBIQUIT COMPUT, V17, P1515, DOI 10.1007/s00779-012-0597-z
   Veas E, 2012, IEEE T VIS COMPUT GR, V18, P565, DOI 10.1109/TVCG.2012.44
   Viega John., 1996, UIST 96, P51, DOI [10.1145/237091.237098, DOI 10.1145/237091.237098]
   Wagner D, 2005, LECT NOTES COMPUT SC, V3468, P208
   Werrlich S, 2018, INT SYM MIX AUGMENT, P134, DOI 10.1109/ISMAR.2018.00046
   White S. M., 2009, Interaction and Presentation Techniques for Situated Visualization
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Whitlock M, 2020, INT SYM MIX AUGMENT, P704, DOI 10.1109/ISMAR50242.2020.00101
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wither J, 2011, COMPUT GRAPH-UK, V35, P810, DOI 10.1016/j.cag.2011.04.010
   Wu LC, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P95, DOI 10.1145/2856400.2856416
   Yamaguchi Masahiro, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1010, DOI 10.1145/3379337.3415819
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu XY, 2020, INT SYM MIX AUGMENT, P577, DOI 10.1109/ISMAR50242.2020.00085
   Zheng MY, 2022, IEEE ACCESS, V10, P29543, DOI 10.1109/ACCESS.2022.3156697
   Zhu J, 2013, INT J ADV MANUF TECH, V66, P1699, DOI 10.1007/s00170-012-4451-2
   Zollmann S, 2014, IEEE T VIS COMPUT GR, V20, P560, DOI 10.1109/TVCG.2014.24
   Zollmann S, 2012, INT SYM MIX AUGMENT, P167, DOI 10.1109/ISMAR.2012.6402554
NR 124
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1324
EP 1335
DI 10.1109/TVCG.2023.3327398
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500116
PM 37883275
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Liu, GX
   Iuricich, F
AF Liu, Guoxi
   Iuricich, Federico
TI A Task-Parallel Approach for Localized Topological Data Structures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data structures; Task analysis; Faces; Memory management; Instruction
   sets; Computational modeling; Graphics processing units; parallel
   computation; topological data analysis; simplicial complex
ID COMPACT REPRESENTATION; MORSE COMPLEXES; COMPUTATION
AB Unstructured meshes are characterized by data points irregularly distributed in the Euclidian space. Due to the irregular nature of these data, computing connectivity information between the mesh elements requires much more time and memory than on uniformly distributed data. To lower storage costs, dynamic data structures have been proposed. These data structures compute connectivity information on the fly and discard them when no longer needed. However, on-the-fly computation slows down algorithms and results in a negative impact on the time performance. To address this issue, we propose a new task-parallel approach to proactively compute mesh connectivity. Unlike previous approaches implementing data-parallel models, where all threads run the same type of instructions, our task-parallel approach allows threads to run different functions. Specifically, some threads run the algorithm of choice while other threads compute connectivity information before they are actually needed. The approach was implemented in the new Accelerated Clustered TOPOlogical (ACTOPO) data structure, which can support any processing algorithm requiring mesh connectivity information. Our experiments show that ACTOPO combines the benefits of state-of-the-art memory-efficient (TTK CompactTriangulation) and time-efficient (TTK ExplicitTriangulation) topological data structures. It occupies a similar amount of memory as TTK CompactTriangulation while providing up to 5x speedup. Moreover, it achieves comparable time performance as TTK ExplicitTriangulation while using only half of the memory space.
C1 [Liu, Guoxi; Iuricich, Federico] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
C3 Clemson University
RP Liu, GX (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM guoxil@clemson.edu; fiurici@clemson.edu
OI Liu, Guoxi/0000-0002-8164-7185; Iuricich, Federico/0000-0003-1782-9715
CR Azpúrua H, 2021, IEEE INT CONF ROBOT, P2443, DOI 10.1109/ICRA48506.2021.9561099
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Bao X., 2022, EUROVIS 2022 SHORT P, DOI DOI 10.2312/EVS.202211041
   Bentley JL, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P360
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Boissonnat JD, 2014, ALGORITHMICA, V70, P406, DOI 10.1007/s00453-014-9887-3
   Canino D., 2014, P 22 INT MESHING ROU, P465, DOI DOI 10.1007/978-3-319-02335-9_262
   Canino D, 2011, COMPUT GRAPH-UK, V35, P747, DOI 10.1016/j.cag.2011.03.009
   Carr HA, 2022, SYMP LARG DATA ANAL, P15, DOI 10.1109/LDAV57265.2022.9966394
   Carr HA, 2021, IEEE T VIS COMPUT GR, V27, P2437, DOI 10.1109/TVCG.2019.2948616
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Chandra R, 2001, Parallel programming in OpenMP
   Codd AL, 2021, GEOPHYS J INT, V227, P2095, DOI 10.1093/gji/ggab323
   Dai A, 2019, PROC CVPR IEEE, P5559, DOI 10.1109/CVPR.2019.00572
   De Floriani L., 2010, P 19 INT MESHING ROU, P403, DOI DOI 10.1007/978-3-642-15414-0_24
   De Floriani L., 2004, P 2004 EUROGRAPHICSA, P83, DOI [10.1145/1057432.10574442, DOI 10.1145/1057432.10574442]
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Edelsbrunner H., 1987, Algorithms in combinatorial geometry, V10, DOI DOI 10.1007/978-3-642-61568-92
   Edelsbrunner H., 2003, P 19 ANN S COMP GEOM, P361, DOI [10.1145/777792.777846, DOI 10.1145/777792.777846]
   Fellegara R, 2021, COMPUT GRAPH-UK, V98, P322, DOI 10.1016/j.cag.2021.05.002
   Forman R., 2002, Seminaire Lotharingien de Combinatoire, V48, P5
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Gurung T, 2011, COMPUT GRAPH FORUM, V30, P355, DOI 10.1111/j.1467-8659.2011.01866.x
   Gurung Topraj, 2009, 2009 SIAM ACM JOINT, P79, DOI DOI 10.1145/1629255.16292662
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Gyulassy A, 2012, INT PARALL DISTRIB P, P484, DOI 10.1109/IPDPS.2012.52
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Heinecke A, 2014, INT CONF HIGH PERFOR, P3, DOI 10.1109/SC.2014.6
   Hilzer R. C.  Jr., 1992, Operating Systems Review, V26, P31, DOI 10.1145/130888.130891
   Hu H, 2021, IEEE INT C INT ROBOT, P384, DOI 10.1109/IROS51168.2021.9636067
   Huang X, 2021, PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, ICS 2021, P367, DOI 10.1145/3447818.3460358
   Kessler C., 2007, Mitteilungen-Gesellschaft far Informatik e.V., ParallelAlgorithmen und Rechnerstrukturen, V24, P1
   Klacansky P, 2020, IEEE T VIS COMPUT GR, V26, P173, DOI 10.1109/TVCG.2019.2934257
   Kremer Michael, 2013, P 21 INT MESH ROUNDT, P531, DOI [10.1007/978-3-642-33573-0_312, DOI 10.1007/978-3-642-33573-0_312]
   Lawson CL, 1997, MATH SOFTWARE, P161, DOI [DOI 10.1016/B978-0-12-587260-7.50011-X, 10.1016/B978-0-12-587260-7.50011-X]
   Liu GX, 2023, IEEE T VIS COMPUT GR, V29, P1506, DOI 10.1109/TVCG.2021.3121229
   Luffel M, 2014, IEEE T VIS COMPUT GR, V20, P84, DOI 10.1109/TVCG.2013.81
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Nielson G. M., 1997, Scientific Visualization: overviews, Methodologies and Techniques, P2
   PAOLUZZI A, 1993, ACM T GRAPHIC, V12, P56, DOI 10.1145/169728.169719
   Peterka T., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P105, DOI 10.1109/LDAV.2011.6092324
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Sahistan A, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P91, DOI [10.1109/VIS49827.2021.9623298, 10.1109/VIS49827.2021.00026]
   Samet H., 2005, The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling, P2
   Sathar S, 2015, IEEE ENG MED BIO, P8062, DOI 10.1109/EMBC.2015.7320264
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Shulga D, 2017, IEEE T MED IMAGING, V36, P972, DOI 10.1109/TMI.2016.2641500
   Subhash V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P36, DOI 10.1109/VIS47514.2020.00014
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Wald I, 2022, IEEE T VIS COMPUT GR, V28, P583, DOI 10.1109/TVCG.2021.3114869
   Weiss K., 2011, P 19 ACM SIGSPATIAL, P92, DOI DOI 10.1145/2093973.20939871,2,3,4
   Xu X, 2023, INT J APPL EARTH OBS, V116, DOI 10.1016/j.jag.2022.103145
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Zhao XL, 2020, COMPUT FLUIDS, V207, DOI 10.1016/j.compfluid.2020.104589
NR 59
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1271
EP 1281
DI 10.1109/TVCG.2023.3327182
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500086
PM 37906496
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Meng, LH
   van den Elzen, S
   Pezzotti, N
   Vilanova, A
AF Meng, Linhao
   van den Elzen, Stef
   Pezzotti, Nicola
   Vilanova, Anna
TI Class-Constrained t-SNE: Combining Data Features and Class Probabilities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data models; Visualization; Analytical models;
   Labeling; Cost function; Periodic structures; Dimensionality reduction;
   t-distributed stochastic neighbor embedding; constraint integration
AB Data features and class probabilities are two main perspectives when, e.g., evaluating model results and identifying problematic items. Class probabilities represent the likelihood that each instance belongs to a particular class, which can be produced by probabilistic classifiers or even human labeling with uncertainty. Since both perspectives are multi-dimensional data, dimensionality reduction (DR) techniques are commonly used to extract informative characteristics from them. However, existing methods either focus solely on the data feature perspective or rely on class probability estimates to guide the DR process. In contrast to previous work where separate views are linked to conduct the analysis, we propose a novel approach, class-constrained t-SNE, that combines data features and class probabilities in the same DR result. Specifically, we combine them by balancing two corresponding components in a cost function to optimize the positions of data points and iconic representation of classes - class landmarks. Furthermore, an interactive user-adjustable parameter balances these two components so that users can focus on the weighted perspectives of interest and also empowers a smooth visual transition between varying perspectives to preserve the mental map. We illustrate its application potential in model evaluation and visual-interactive labeling. A comparative analysis is performed to evaluate the DR results.
C1 [Meng, Linhao; van den Elzen, Stef; Pezzotti, Nicola; Vilanova, Anna] Eindhoven Univ Technol, Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Meng, LH (corresponding author), Eindhoven Univ Technol, Eindhoven, Netherlands.
EM l.meng1@tue.nl; s.j.v.d.elzen@tue.nl; n.pezzotti@tue.nl;
   a.vilanova@tue.nl
OI van den Elzen, Stef/0000-0003-1245-0503
CR Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Bengio Y., 2003, P NIPS, P3
   Bernard J., 2018, EUROVIS 2018 SHORT P, DOI [10.2312/eurovisshort.20181085, DOI 10.2312/EUROVISSHORT.20181085]
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122
   Bohm J. N., 2022, Journal of Machine Learning Research, V23, P2
   Cevikalp H, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P489
   Chae J., 2017, P WORKSHOP VISUAL AN
   Chegini M, 2019, VIS INFORM, V3, P9, DOI 10.1016/j.visinf.2019.03.002
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Colange B., 2020, Advances in Neural Information Processing Systems, V33, P3
   de Bodt C., 2019, PROC ESANN
   De Silva V., 2004, Technical report, P3
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Google, 2017, Facets
   Hajderanj L, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND INFORMATION ENGINEERING (ICSIE 2019), P232, DOI 10.1145/3328833.3328853
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Iwata T, 2007, NEURAL COMPUT, V19, P2536, DOI 10.1162/neco.2007.19.9.2536
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Kaski S, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-48
   Kim H., 2017, P AAAI C ARTIFICIAL, V31, DOI [10.1609/aaai.v31i1.106283, DOI 10.1609/AAAI.V31I1.106283]
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Kobak D, 2021, NAT BIOTECHNOL, V39, DOI 10.1038/s41587-020-00809-z
   Le Q. V., 2014, INT C MACHINE LEARNI, DOI 10.1145/2740908.2742760
   Le TMV, 2014, AAAI CONF ARTIF INTE, P1960
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Meng LH, 2022, COMPUT GRAPH FORUM, V41, P97, DOI 10.1111/cgf.14525
   Paiva JGS, 2011, IEEE T VIS COMPUT GR, V17, P2459, DOI 10.1109/TVCG.2011.212
   Pérez D, 2015, NEUROCOMPUTING, V150, P611, DOI 10.1016/j.neucom.2014.09.061
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Rauber P. E., 2016, P EUR IEEE VGTC C VI, P73, DOI DOI 10.2312/EUROVISSHORT.20161164
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Rheingans P, 2000, IEEE VISUAL, P493, DOI 10.1109/VISUAL.2000.885740
   Schneider B, 2017, 2017 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P15, DOI 10.1109/VDS.2017.8573444
   Schreck T, 2007, PROC SPIE, V6495, DOI 10.1117/12.697879
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Seifert C., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P418, DOI 10.1109/ICDMW.2010.181
   Seifert C, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P490, DOI 10.1109/IV.2009.45
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Tatu A, 2010, P INT C ADV VISUAL I, P49, DOI DOI 10.1145/1842993.1843002
   Van Der Maaten L., 2009, P MACHINE LEARNING R, P384
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vu Viet Minh, 2022, IEEE Transactions on Artificial Intelligence, V3, P944, DOI 10.1109/TAI.2022.3204734
   Vu VM, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534470
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xiao H., 2017, ARXIV
   Yan YY, 2019, IEEE PAC VIS SYMP, P148, DOI 10.1109/PacificVis.2019.00025
   Yang Y, 2017, VIS INFORM, V1, P40, DOI 10.1016/j.visinf.2017.01.005
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 60
TC 1
Z9 1
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 164
EP 174
DI 10.1109/TVCG.2023.3326600
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500052
PM 37874722
OA Green Published
DA 2024-08-05
ER

PT J
AU Shen, JY
   Shen, HW
AF Shen, Jingyi
   Shen, Han-Wei
TI PSRFlow: Probabilistic Super Resolution with Flow-Based Models for
   Scientific Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Super resolution; latent space; normalizing flow; uncertainty
   visualization
ID SUPERRESOLUTION; UNCERTAINTY
AB Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.
C1 [Shen, Jingyi; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Shen, JY (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM shen.1250@osu.edu; shen.94@osu.edu
OI Shen, Han-Wei/0000-0002-1211-2320
FU US Department of Energy SciDAC
FX No Statement Available
CR Aggarwal V, 2020, INT CONF ACOUST SPEE, P6179, DOI [10.1109/icassp40776.2020.9053678, 10.1109/ICASSP40776.2020.9053678]
   An YF, 2021, IEEE COMPUT GRAPH, V41, P122, DOI 10.1109/MCG.2021.3097555
   Ardizzone L, 2019, Arxiv, DOI arXiv:1808.04730
   Arjovsky M., 2017, INT C LEARNING REPRE
   Athawale T. M., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P2
   Athawale T. M., 2020, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Athawale TM, 2021, IEEE T VIS COMPUT GR, V27, P1797, DOI 10.1109/TVCG.2020.3030394
   Bogachev V. I., 2005, Sbornik Mathematics, V196, P2
   Correa Carlos D., 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P51, DOI 10.1109/VAST.2009.5332611
   Dinh L., 2017, Density Estimation using Real NVP, V1, P3
   Fout N., 2012, IEEE Transactions on Visualization and Computer Graphics, V18, P2
   Grigoryan G, 2004, IEEE T VIS COMPUT GR, V10, P564, DOI 10.1109/TVCG.2004.30
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Hagele David, 2023, IEEE Trans Vis Comput Graph, V29, P23, DOI 10.1109/TVCG.2022.3209420
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han M., 2022, Journal of Flow Visualization and Image Processing, V29, P2
   He K., 2015, Deep residual learning for image recognition
   Janosh R., Random TikZ Collection
   Jo Y, 2021, PROC CVPR IEEE, P16231, DOI 10.1109/CVPR46437.2021.01597
   Jo Y, 2021, IEEE COMPUT SOC CONF, P364, DOI 10.1109/CVPRW53098.2021.00046
   Kinga D., 2015, C TRACK P, V5, P6
   Kingma D. P., 2018, Advances in Neural Information Processing Systems, V1, P5
   Liang JY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4056, DOI 10.1109/ICCV48922.2021.00404
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Lugmayr Andreas, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P715, DOI 10.1007/978-3-030-58558-7_42
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Postels J, 2021, INT CONF 3D VISION, P1249, DOI 10.1109/3DV53792.2021.00132
   Pothkow K., 2010, IEEE Transactions on Visualization and Computer Graphics, V17, P2
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Sakhaee E, 2017, IEEE T VIS COMPUT GR, V23, P2509, DOI 10.1109/TVCG.2016.2637333
   Schlegel S, 2012, IEEE T VIS COMPUT GR, V18, P2305, DOI 10.1109/TVCG.2012.249
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Vietinghoff D, 2022, IEEE VIS CONF, P145, DOI 10.1109/VIS54862.2022.00038
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Wurster S. W., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.32144201
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yang G., 2019, P IEEECVF INT C COMP, V2, P4
NR 42
TC 0
Z9 0
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 986
EP 996
DI 10.1109/TVCG.2023.3327171
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500101
PM 37930921
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Sterzik, A
   Meuschke, M
   Cunningham, DW
   Lawonn, K
AF Sterzik, Anna
   Meuschke, Monique
   Cunningham, Douglas W.
   Lawonn, Kai
TI Perceptually Uniform Construction of Illustrative Textures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Illustrative Visualization; Perceptual Evaluation; Hatching; Stippling
ID VISUALIZATION; PERCEPTION; GOODNESS
AB Illustrative textures, such as stippling or hatching, were predominantly used as an alternative to conventional Phong rendering. Recently, the potential of encoding information on surfaces or maps using different densities has also been recognized. This has the significant advantage that additional color can be used as another visual channel and the illustrative textures can then be overlaid. Effectively, it is thus possible to display multiple information, such as two different scalar fields on surfaces simultaneously. In previous work, these textures were manually generated and the choice of density was unempirically determined. Here, we first want to determine and understand the perceptual space of illustrative textures. We chose a succession of simplices with increasing dimensions as primitives for our textures: Dots, lines, and triangles. Thus, we explore the texture types of stippling, hatching, and triangles. We create a range of textures by sampling the density space uniformly. Then, we conduct three perceptual studies in which the participants performed pairwise comparisons for each texture type. We use multidimensional scaling (MDS) to analyze the perceptual spaces per category. The perception of stippling and triangles seems relatively similar. Both are adequately described by a 1D manifold in 2D space. The perceptual space of hatching consists of two main clusters: Crosshatched textures, and textures with only one hatching direction. However, the perception of hatching textures with only one hatching direction is similar to the perception of stippling and triangles. Based on our findings, we construct perceptually uniform illustrative textures. Afterwards, we provide concrete application examples for the constructed textures.
C1 [Sterzik, Anna; Lawonn, Kai] Univ Jena, Jena, Germany.
   [Meuschke, Monique] Univ Magdeburg, Magdeburg, Germany.
   [Cunningham, Douglas W.] Brandenburg Tech Univ Cottbus, Cottbus, Germany.
C3 Friedrich Schiller University of Jena; Otto von Guericke University;
   Brandenburg University of Technology Cottbus
RP Sterzik, A (corresponding author), Univ Jena, Jena, Germany.
EM anna.sterzik@uni-jena.de; meuschke@isg.cs.uni-magdeburg.de;
   douglas.cunningham@b-tu.de; kai.lawonn@uni-jena.de
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Acevedo D, 2006, IEEE T VIS COMPUT GR, V12, P1133, DOI 10.1109/TVCG.2006.180
   [Anonymous], 2007, Computational Aesthetics in Graphics, Visualization, and Imaging, DOI [DOI 10.2312/COMPAESTH/COMPAESTH07/089-096, 10.2312/COMPAESTH/COMPAESTH07/089-096]
   Borg I., 2005, Modern Multidimensional Scaling, DOI [DOI 10.1007/0-387-28981-X, 10.1007/0-387-28981-X]
   CAELLI T, 1978, BIOL CYBERN, V28, P167, DOI 10.1007/BF00337138
   Coninx A., 2011, P ACM SIGGRAPH S APP, P59, DOI [10.1145/2077451.2077462, DOI 10.1145/2077451.2077462]
   Cunningham D., 2011, Experimental Design: From User Studies to Psychophysics, V1st, DOI DOI 10.1201/B113085
   Deussen O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130819
   Eulzer P., 2021, EUROGRAPHICS WORKSHO, DOI [DOI 10.2312/VCBM.20211347, 10.2312/vcbm.202113478, DOI 10.2312/VCBM.202113478]
   Eulzer Pepe, 2023, Zenodo
   Gadiraju Ujwal, 2017, Evaluation in the Crowd. Crowdsourcing and Human-Centered Experiments. Revised Contributions: LNCS 10264, P6, DOI 10.1007/978-3-319-66435-4_2
   Gerl M, 2013, COMPUT GRAPH-UK, V37, P65, DOI 10.1016/j.cag.2012.11.003
   Görtler J, 2019, IEEE T VIS COMPUT GR, V25, P2193, DOI 10.1109/TVCG.2019.2903945
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Interrante V, 1996, IEEE VISUAL, P211, DOI 10.1109/VISUAL.1996.568110
   Isenberg T, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1210862
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391
   KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873
   Kruger Jens, 2007, IADIS International Conference. Computer Graphics and Visualization 2007, P19
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lawonn K, 2013, COMPUT GRAPH FORUM, V32, P321, DOI 10.1111/cgf.12119
   Lawonn K., 2014, Bildverarbeitung fur die Medizin (BVM), P276, DOI DOI 10.1007/978-3-642-54111-7_522
   Lawonn K., 2016, Visualization in Medicine and Life Sciences III, P93, DOI DOI 10.1007/978-3-319-24523-2_52
   Lawonn K, 2019, COMPUT GRAPH FORUM, V38, P221, DOI 10.1111/cgf.13526
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lawonn K, 2017, COMPUT GRAPH-UK, V63, P37, DOI 10.1016/j.cag.2017.02.002
   Lawonn K, 2015, LECT NOTES COMPUT SC, V9350, P399, DOI 10.1007/978-3-319-24571-3_48
   Lawonn K, 2014, COMPUT GRAPH FORUM, V33, P16, DOI 10.1111/cgf.12355
   Lawonn K, 2014, COMPUT GRAPH FORUM, V33, P181, DOI 10.1111/cgf.12374
   Lettvin Jerome Y., 1976, The Sciences, V16, P10
   Liu J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130335
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Liu YJ, 2011, IEEE T PATTERN ANAL, V33, P1502, DOI 10.1109/TPAMI.2010.221
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Martín D, 2019, COMPUT GRAPH-UK, V80, P1, DOI 10.1016/j.cag.2019.02.001
   Martín D, 2017, COMPUT GRAPH-UK, V67, P24, DOI 10.1016/j.cag.2017.05.001
   Meuschke M, 2017, IEEE T VIS COMPUT GR, V23, P761, DOI 10.1109/TVCG.2016.2598795
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Randen T., Brodatz Textures
   Sajadi B, 2013, IEEE T VIS COMPUT GR, V19, P118, DOI 10.1109/TVCG.2012.93
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Secord A., 2002, P 2 INT S NONPH AN R, V1, P37, DOI [DOI 10.1145/508535.508537, DOI 10.1145/508530.508537]
   Spicker M., 2017, P S NONPHOTOREALISTI, DOI DOI 10.1145/3092919.3092923
   Sterzik A., IEEE Transactions on Visualization and Computer Graphics
   Sterzik A., 2022, EUROGRAPHICS WORKSHO, P41, DOI [DOI 10.2312/VCBM.202211862, 10.2312/vcbm.202211861,2,3,6,9, DOI 10.2312/VCBM.202211861,2,3,6,9]
   Sterzik A, 2023, COMPUT GRAPH-UK, V114, P401, DOI 10.1016/j.cag.2023.06.006
   Stoppel S, 2019, COMPUT GRAPH FORUM, V38, P110, DOI 10.1111/cgf.13609
   Sugathan S., 2021, EUROGRAPHICS WORKSHO, DOI DOI 10.2312/VCBM.20211346
   Sugathan S, 2022, COMPUT GRAPH-UK, V107, P208, DOI 10.1016/j.cag.2022.07.023
   Taylor R, 2002, IEEE COMPUT GRAPH, V22, P6, DOI 10.1109/MCG.2002.999781
   Timofeev V., 2010, Human Insulin, DOI DOI 10.2210/PDB3I40/PDB7
   Timofeev VI, 2010, ACTA CRYSTALLOGR F, V66, P259, DOI 10.1107/S1744309110000461
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Wills J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559760
   Xiao YY, 2022, COMPUT GRAPH FORUM, V41, P23, DOI 10.1111/cgf.14495
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1052
EP 1062
DI 10.1109/TVCG.2023.3326574
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500060
PM 37871076
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Peng, B
   Hu, J
   Zhou, JT
   Gao, X
   Zhang, JY
AF Peng, Bo
   Hu, Jun
   Zhou, Jingtao
   Gao, Xuan
   Zhang, Juyong
TI IntrinsicNGP: Intrinsic Coordinate Based Hash Encoding for Human NeRF
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural rendering; intrinsic representation; human performance capture
AB Recently, many works have been proposed to use the neural radiance field for novel view synthesis of human performers. However, most of these methods require hours of training, making them difficult for practical use. To address this challenging problem, we propose IntrinsicNGP, which can be trained from scratch and achieve high-fidelity results in a few minutes with videos of a human performer. To achieve this goal, we introduce a continuous and optimizable intrinsic coordinate instead of the original explicit euclidean coordinate in the hash encoding module of InstantNGP. With this novel intrinsic coordinate, IntrinsicNGP can aggregate interframe information for dynamic objects using proxy geometry shapes. Moreover, the results trained with the given rough geometry shapes can be further refined with an optimizable offset field based on the intrinsic coordinate. Extensive experimental results on several datasets demonstrate the effectiveness and efficiency of IntrinsicNGP. We also illustrate the ability of our approach to edit the shape of reconstructed objects.
C1 [Peng, Bo; Zhang, Juyong] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, JY (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
EM pb15881461858@mail.ustc.edu.cn; hu997372@mail.ustc.edu.cn;
   ustc_zjt@mail.ustc.edu.cn; gx2017@mail.ustc.edu.cn; juyong@ustc.edu.cn
OI Hu, Jun/0009-0007-4786-8455; Peng, Bo/0009-0005-1654-4605
FU National Natural Science Foundation of China [62122071, 62272433]
FX No Statement Available
CR Alldieck T, 2022, PROC CVPR IEEE, P1496, DOI 10.1109/CVPR52688.2022.00156
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Cao C, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530143
   Chen A., 2023, Comput. Vis. Pattern Recognit.
   Cheng HK, 2021, PROC CVPR IEEE, P5555, DOI 10.1109/CVPR46437.2021.00551
   Deng KL, 2022, PROC CVPR IEEE, P12872, DOI 10.1109/CVPR52688.2022.01254
   Dong ZJ, 2023, Arxiv, DOI arXiv:2305.02312
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Fangetal J., 2022, P SIGGRAPH AS C PAP, P1
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gao X, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555501
   Geng C, 2023, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR52729.2023.00846
   Github, Easymocap-make human motion capture easier
   Grassal PW, 2022, PROC CVPR IEEE, P18632, DOI 10.1109/CVPR52688.2022.01810
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Hess R, 2010, BLENDER FDN ESSENTIA
   Hong Y, 2022, PROC CVPR IEEE, P20342, DOI 10.1109/CVPR52688.2022.01973
   Hong Y, 2021, PROC CVPR IEEE, P535, DOI 10.1109/CVPR46437.2021.00060
   Isik M, 2023, Arxiv, DOI arXiv:2305.06356
   Jiang BY, 2022, PROC CVPR IEEE, P5595, DOI 10.1109/CVPR52688.2022.00552
   Jiang TJ, 2023, PROC CVPR IEEE, P16922, DOI 10.1109/CVPR52729.2023.01623
   Kingma D. P., 2015, P INT C LEARN REPR, P1
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Kwon D., 2021, Comput. Vis. Pattern Recognit., V34
   Kwon Youngjoong, 2021, ADV NEURAL INFORM PR, V34, P24741
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Lin SC, 2022, IEEE WINT CONF APPL, P3132, DOI 10.1109/WACV51458.2022.00319
   Liu Jia-Wei, 2022, arXiv, DOI DOI 10.48550/ARXIV.2205
   Liu L., 2021, ACM T GRAPHIC, V40, P1
   Liu Y., 2023, arXiv
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Muller Thomas, 2021, TINY CUDA NEURAL NET
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Parashar S, 2022, IEEE T PATTERN ANAL, V44, P6409, DOI 10.1109/TPAMI.2021.3089923
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Rosu RA, 2022, Arxiv, DOI arXiv:2211.12562
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Su S.-Y., 2021, ADV NEURAL INF PROCE, V34, P12278
   Sun C, 2022, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR52688.2022.00538
   Tanciket al., 2020, Comput. Vis. Pattern Recognit.
   Tang JX, 2022, Arxiv, DOI arXiv:2205.14870
   Tang Jiaxiang, 2022, Torch-ngp: a pytorch implementation of instant-ngp
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Tiwari G, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11688, DOI 10.1109/ICCV48922.2021.01150
   Wang H, 2022, LECT NOTES COMPUT SC, V13691, P612, DOI 10.1007/978-3-031-19821-2_35
   Wang S, 2023, "ARAH:Animatablevolumerendering of articulated human SDFs
   Wang SF, 2022, LECT NOTES COMPUT SC, V13692, P1, DOI 10.1007/978-3-031-19824-3_1
   Weng CY, 2023, PROC CVPR IEEE, P524, DOI 10.1109/CVPR52729.2023.00058
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Wu L., 2022, P IEEE CVF C COMP VI, P16200
   Xiu J., 2022, P IEEE CVF C COMP VI
   Xu H., 2021, ADV NEURAL INFORM PR, V34, P14955
   Xu TH, 2022, PROC CVPR IEEE, P15862, DOI 10.1109/CVPR52688.2022.01542
   Zhang J., 2022, Easymocap-make human motion capture easier
   Zhao FQ, 2022, PROC CVPR IEEE, P7733, DOI 10.1109/CVPR52688.2022.00759
   Zheng YF, 2023, PROC CVPR IEEE, P21057, DOI 10.1109/CVPR52729.2023.02017
   Zheng ZR, 2022, PROC CVPR IEEE, P15872, DOI 10.1109/CVPR52688.2022.01543
   Zhi S., 2022, P INT C 3DVIS, P1
   Zielonka W, 2023, PROC CVPR IEEE, P4574, DOI 10.1109/CVPR52729.2023.00444
   ZUFFI S, 2017, CVPR, DOI DOI 10.1109/CVPR.2017.586
NR 68
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5679
EP 5692
DI 10.1109/TVCG.2023.3306078
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400049
PM 37590116
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Fu, Q
   Zhang, F
   Li, XM
   Fu, HB
AF Fu, Qiang
   Zhang, Fan
   Li, Xueming
   Fu, Hongbo
TI Magic Furniture: Design Paradigm of Multi-Function Assembly
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Three-dimensional displays; Solid modeling; Urban areas; Rails;
   Merging; Media; Assembly-based modeling; multi-function design; shape
   reconfiguration
AB Assembly-based furniture with movable parts enables shape and structure reconfiguration, thus supporting multiple functions. Although a few attempts have been made for facilitating the creation of multi-function objects, designing such a multi-function assembly with the existing solutions often requires high imagination of designers. We develop the Magic Furniture system for users to easily create such designs simply given multiple cross-category objects. Our system automatically leverages the given objects as references to generate a 3D model with movable boards driven by back-and-forth movement mechanisms. By controlling the states of these mechanisms, a designed multi-function furniture object can be reconfigured to approximate the shapes and functions of the given objects. To ensure the designed furniture easy to transform between different functions, we perform an optimization algorithm to choose a proper number of movable boards and determine their shapes and sizes, following a set of design guidelines. We demonstrate the effectiveness of our system through various multi-function furniture designed with different sets of reference inputs and various movement constraints. We also evaluate the design results through several experiments including comparative and user studies.
C1 [Fu, Qiang; Zhang, Fan; Li, Xueming] Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing 100876, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Beijing University of Posts & Telecommunications; City University of
   Hong Kong
RP Fu, Q (corresponding author), Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing 100876, Peoples R China.
EM fu.john.qiang@gmail.com; zhangfan.kanv@gmail.com; lixm@bupt.edu.cn;
   fuplus@gmail.com
OI FU, Hongbo/0000-0002-0284-726X; Fu, Qiang/0000-0002-8944-8981; Zhang,
   Fan/0000-0003-3486-6040; LI, xueming/0000-0003-1058-2799
FU NSFC [61902032]
FX This work was supported by NSFC under Grant 61902032.
CR Alhashim I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601102
   Bennell JA, 2008, EUR J OPER RES, V184, P397, DOI 10.1016/j.ejor.2006.11.038
   Fu CW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766892
   Fu Q, 2017, IEEE T VIS COMPUT GR, V23, P2574, DOI 10.1109/TVCG.2017.2739159
   Fu Q, 2016, COMPUT GRAPH FORUM, V35, P27, DOI 10.1111/cgf.12808
   Gao B, 2016, COMPUT GRAPH-UK, V58, P102, DOI 10.1016/j.cag.2016.05.006
   Garg A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925900
   Hu RZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201287
   Hu RZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130811
   Hu RZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925870
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Huang SS, 2016, IEEE T VIS COMPUT GR, V22, P2024, DOI 10.1109/TVCG.2015.2473845
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2185520.2185551, 10.1145/2077341.2077342]
   Koo BJ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661289
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li HH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366177
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Mitra NJ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778795
   Saul G, 2011, TEI 2011: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION, P73
   Schulz A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601127
   Song P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130803
   Su XY, 2016, COMPUT GRAPH-UK, V54, P145, DOI 10.1016/j.cag.2015.06.009
   Suzuki R, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P143, DOI 10.1145/3374920.3374941
   Umetani N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185582
   Wang ZQ, 2021, COMPUT GRAPH FORUM, V40, P633, DOI 10.1111/cgf.142660
   Wang ZQ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356489
   Wang ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275034
   Wu RD, 2020, PROC CVPR IEEE, P826, DOI 10.1109/CVPR42600.2020.00091
   Xiong GM, 2021, IEEE T VIS COMPUT GR, V27, P4413, DOI 10.1109/TVCG.2020.3005680
   Zhou J, 2018, COMPUT GRAPH-UK, V70, P165, DOI 10.1016/j.cag.2017.07.033
NR 30
TC 2
Z9 2
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4068
EP 4079
DI 10.1109/TVCG.2023.3250488
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700057
PM 37028007
DA 2024-08-05
ER

PT J
AU Richer, G
   Pister, A
   Abdelaal, M
   Fekete, JD
   Sedlmair, M
   Weiskopf, D
AF Richer, Gaelle
   Pister, Alexis
   Abdelaal, Moataz
   Fekete, Jean-Daniel
   Sedlmair, Michael
   Weiskopf, Daniel
TI Scalability in Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scalability; Visualization; Computational modeling; Encoding;
   Psychology; Human computer interaction; Computer science; Conceptual
   framework; scalability; structured literature analysis; visualization
ID SCALE; EXPLORATION; CHALLENGES; DESIGN; GRAPHS; MEMORY
AB We introduce a conceptual model for scalability designed for visualization research. With this model, we systematically analyze over 120 visualization publications from 1990 to 2020 to characterize the different notions of scalability in these works. While many article have addressed scalability issues, our survey identifies a lack of consistency in the use of the term in the visualization research community. We address this issue by introducing a consistent terminology meant to help visualization researchers better characterize the scalability aspects in their research. It also helps in providing multiple methods for supporting the claim that a work is "scalable." Our model is centered around an effort function with inputs and outputs. The inputs are the problem size and resources, whereas the outputs are the actual efforts, for instance, in terms of computational run time or visual clutter. We select representative examples to illustrate different approaches and facets of what scalability can mean in visualization literature. Finally, targeting the diverse crowd of visualization researchers without a scalability tradition, we provide a set of recommendations for how scalability can be presented in a clear and consistent way to improve fair comparison between visualization techniques and systems and foster reproducibility.
C1 [Richer, Gaelle; Pister, Alexis; Fekete, Jean-Daniel] Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
   [Pister, Alexis] Inst Polytech Paris, CNRS, Telecom Paris, I3, Paris, France.
   [Abdelaal, Moataz; Sedlmair, Michael; Weiskopf, Daniel] Univ Stuttgart, Stuttgart, Germany.
C3 Inria; Centre National de la Recherche Scientifique (CNRS); Universite
   Paris Saclay; Universite Paris Cite; IMT - Institut Mines-Telecom;
   Institut Polytechnique de Paris; Telecom Paris; Centre National de la
   Recherche Scientifique (CNRS); University of Stuttgart
RP Richer, G (corresponding author), Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
EM gaelle.richer@inria.fr; alexis.pister@inria.fr;
   moataz.abdelaal@visus.uni-stuttgart.de; jean-daniel.fekete@inria.fr;
   michael.sedlmair@visus.uni-stuttgart.de;
   daniel.weiskopf@visus.uni-stuttgart.de
RI ; Fekete, Jean-Daniel/N-9175-2018
OI Abdelaal, MOATAZ/0000-0003-4630-7916; Weiskopf,
   Daniel/0000-0003-1174-1026; Fekete, Jean-Daniel/0000-0003-3770-8726
FU Deutsche Forschungsgemeinschaft(DFG, German Research Foundation) [EXC
   2120/1 - 390831618]; DFG [251654672 - TRR 161]; DATAIA Convergence
   Institute [ANR-17-CONV-0003]
FX The work of Moataz Abdelaal was supported by Deutsche
   Forschungsgemeinschaft(DFG, German Research Foundation) under Germany's
   Excellence Strategy -EXC 2120/1 - 390831618. The work of Michael
   Sedlmair and Daniel Weiskopf was supported by DFG - Project-ID 251654672
   - TRR 161. The work of Alexis Pister was supported by the DATAIA
   Convergence Institute, part of the Programmed'Investissement d'Avenir,
   under Grant ANR-17-CONV-0003, operated by Inria and Telecom Paris.
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   Aigner W, 2013, COMPUT GRAPH FORUM, V32, P41, DOI 10.1111/cgf.12091
   [Anonymous], 1952, Quart. J. Exp. Psy-chol., V4, P11
   Battle L, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1571, DOI 10.1145/3318464.3389732
   Bennett FM, 1954, PUBLIC OPIN QUART, V18, P303
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Bondi A. B., 2000, Proceedings Second International Workshop on Software and Performance. WOSP2000, P195, DOI 10.1145/350391.350432
   Brown Barry., 2017, INTERACTIONS, V24, P28, DOI DOI 10.1145/3125387
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Budiu Raluca., 2014, Scaling User Interfaces: An Information-Processing Approach to Multi--Device Design
   Card T. P., 1983, The Psychology of Human-Computer Interaction
   Charmaz K., 2014, Constructing grounded theory: A practical guide through qualitative analysis, V2nd ed.
   Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793
   Cockburn A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P627
   Deng J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3099, DOI 10.1145/2556288.2557011
   Duboc L., 2006, 28th International Conference on Software Engineering Proceedings, P949, DOI 10.1145/1134285.1134460
   Eick SG, 2002, J COMPUT GRAPH STAT, V11, P22, DOI 10.1198/106186002317375604
   Eiselmayer C., 2019, P SIGCHI C HUM FACT, P1
   Falk M, 2008, IEEE T VIS COMPUT GR, V14, P820, DOI 10.1109/TVCG.2008.25
   Fekete D., 2019, Dag-stuhl Rep., V8, P1, DOI [DOI 10.4230/DAGREP.8.10.1, 10.4230/DAGREP.8.10.1]
   Fekete JD, 2020, IEEE COMPUT GRAPH, V40, P108, DOI 10.1109/MCG.2020.3006412
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Georgii J, 2006, IEEE T VIS COMPUT GR, V12, P1345, DOI 10.1109/TVCG.2006.110
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Glémarec Y, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364784
   Guiard Y, 2001, BCS CONF SERIES, P573
   GUSTAFSON JL, 1988, COMMUN ACM, V31, P532, DOI 10.1145/42411.42415
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Healey CG, 1999, IEEE T VIS COMPUT GR, V5, P145, DOI 10.1109/2945.773807
   Heer J, 2010, IEEE T VIS COMPUT GR, V16, P1149, DOI 10.1109/TVCG.2010.144
   Hill M. D., 1990, Computer Architecture News, V18, P18, DOI 10.1145/121973.121975
   Howison M, 2012, IEEE T VIS COMPUT GR, V18, P17, DOI 10.1109/TVCG.2011.24
   Ip CY, 2011, IEEE T VIS COMPUT GR, V17, P1737, DOI 10.1109/TVCG.2011.231
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Jakobsen MR, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1451
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Keim J., 2010, Mastering the Information Age-Solving Problems with Visual Analyt-ics
   Khoury M, 2012, COMPUT GRAPH FORUM, V31, P975, DOI 10.1111/j.1467-8659.2012.03090.x
   Kurzhals K, 2016, IEEE T VIS COMPUT GR, V22, P1005, DOI 10.1109/TVCG.2015.2468091
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Ma KL, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.120
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Michael J. E., 2007, P IEEE INT PAR DISTR, P1, DOI DOI 10.1109/IPDPS.2007.370631
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Papadopoulos C, 2016, IEEE T VIS COMPUT GR, V22, P111, DOI 10.1109/TVCG.2015.2467954
   Perrot A, 2015, SYMP LARG DATA ANAL, P99, DOI 10.1109/LDAV.2015.7348077
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Plaisant C, 2008, IEEE T VIS COMPUT GR, V14, P120, DOI 10.1109/TVCG.2007.70412
   Qiao W, 2006, IEEE T VIS COMPUT GR, V12, P1061, DOI 10.1109/TVCG.2006.150
   Robertson G, 2009, INFORM VISUAL, V8, P247, DOI 10.1057/ivs.2009.23
   Ruthruff S. G., 2006, P INT S SOFTW TEST A, P49
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Schreiber F, 2022, IT-INF TECHNOL, V64, P119, DOI 10.1515/itit-2022-0048
   Schulz C, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P112, DOI 10.1145/2993901.2993907
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Slack J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P41, DOI 10.1109/INFVIS.2005.1532127
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P399, DOI 10.1109/TVCG.2015.2467911
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Thomas K. A., 2005, Illuminating the Path: TheResearch and Development Agenda for Visual Analytics
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9
   Veras R, 2020, IEEE T VIS COMPUT GR, V26, P749, DOI 10.1109/TVCG.2019.2934432
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P566, DOI 10.1109/TVCG.2018.2864911
   Weinstock J. B., 2006, Tech. Rep. CMU/SEI-2006-TN-012
   Wenwen Dou, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P231, DOI 10.1109/VAST.2011.6102461
   Wilkinson L, 2008, J COMPUT GRAPH STAT, V17, P473, DOI 10.1198/106186008X320465
   Wong PC, 2012, IEEE COMPUT GRAPH, V32, P63, DOI 10.1109/MCG.2012.87
   Yoghourdjian V, 2021, IEEE T VIS COMPUT GR, V27, P1677, DOI 10.1109/TVCG.2020.3030459
   Yost B, 2006, IEEE T VIS COMPUT GR, V12, P837, DOI 10.1109/TVCG.2006.184
NR 76
TC 6
Z9 6
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3314
EP 3330
DI 10.1109/TVCG.2022.3231230
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700008
PM 37015637
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Valdrighi, G
   Ferreira, N
   Poco, J
AF Valdrighi, Giovani
   Ferreira, Nivan
   Poco, Jorge
TI MoReVis: A Visual Summary for Spatiotemporal Moving Regions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatiotemporal visualization; spatial interactions; spatial abstraction
ID TRACKING; SYSTEMS; LINES; FIT
AB Spatial and temporal interactions are central and fundamental in many activities in our world. A common problem faced when visualizing this type of data is how to provide an overview that helps users navigate efficiently. Traditional approaches use coordinated views or 3D metaphors like the Space-time cube to tackle this problem. However, they suffer from overplotting and often lack spatial context, hindering data exploration. More recent techniques, such as MotionRugs, propose compact temporal summaries based on 1D projection. While powerful, these techniques do not support the situation for which the spatial extent of the objects and their intersections is relevant, such as the analysis of surveillance videos or tracking weather storms. In this article, we propose MoReVis, a visual overview of spatiotemporal data that considers the objects' spatial extent and strives to show spatial interactions among these objects by displaying spatial intersections. Like previous techniques, our method involves projecting the spatial coordinates to 1D to produce compact summaries. However, our solution's core consists of performing a layout optimization step that sets the size and positions of the visual marks on the summary to resemble the actual values on the original space. We also provide multiple interactive mechanisms to make interpreting the results more straightforward for the user. We perform an extensive experimental evaluation and usage scenarios. Moreover, we evaluated the usefulness of MoReVis in a study with 9 participants. The results point out the effectiveness and suitability of our method in representing different datasets compared to traditional techniques.
C1 [Valdrighi, Giovani; Ferreira, Nivan] Fundacao Getulio Vargas, BR-22250900 Rio De Janeiro, Brazil.
   [Ferreira, Nivan] Univ Fed Pernambuco, BR-50670901 Recife, Brazil.
C3 Getulio Vargas Foundation; Escola de Pos-Graduacao em Economia (EPGE);
   Universidade Federal de Pernambuco
RP Valdrighi, G (corresponding author), Fundacao Getulio Vargas, BR-22250900 Rio De Janeiro, Brazil.
EM giovani.valdrighi@fgv.br; nivan@cin.ufpe.br; jpocom@gmail.com
RI ; Poco, Jorge/F-3344-2016
OI Valdrighi, Giovani/0000-0003-0106-4789; Poco, Jorge/0000-0001-9096-6287;
   Ferreira, Nivan/0000-0001-6631-4609
FU CNPq-Brazil
FX No Statement Available
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Andrienko N, 2013, IEEE T VIS COMPUT GR, V19, P2169, DOI 10.1109/TVCG.2013.193
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   [Anonymous], 2013, Information Visualization: Perception for Design
   Arendt D, 2017, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2017.8585487
   Ayesha S, 2020, INFORM FUSION, V59, P44, DOI 10.1016/j.inffus.2020.01.005
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Bäuerle A, 2022, COMPUT GRAPH FORUM, V41, P235, DOI 10.1111/cgf.14536
   Bonchi F, 2009, LECT NOTES COMPUT SC, V5599, P190, DOI 10.1007/978-3-642-03511-1_9
   Buchmüller J, 2019, IEEE T VIS COMPUT GR, V25, P76, DOI 10.1109/TVCG.2018.2865049
   Buchmüller JF, 2021, COMPUT GRAPH-UK, V101, P23, DOI 10.1016/j.cag.2021.08.003
   Camargo SJ, 2007, J CLIMATE, V20, P3635, DOI 10.1175/JCLI4188.1
   Chavdarova T, 2018, PROC CVPR IEEE, P5030, DOI 10.1109/CVPR.2018.00528
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Diehl A, 2021, COMPUT GRAPH FORUM, V40, P299, DOI 10.1111/cgf.14308
   DIXON M, 1993, J ATMOS OCEAN TECH, V10, P785, DOI 10.1175/1520-0426(1993)010<0785:TTITAA>2.0.CO;2
   Domingo-Ferrer J, 2012, INFORM SCIENCES, V208, P55, DOI 10.1016/j.ins.2012.04.015
   Ferreira N, 2013, COMPUT GRAPH FORUM, V32, P201, DOI 10.1111/cgf.12107
   Fonseca CM, 2021, SIBGRAPI, P176, DOI 10.1109/SIBGRAPI54419.2021.00032
   Franke M, 2021, COMPUT GRAPH FORUM, V40, P335, DOI 10.1111/cgf.14311
   Guo DS, 2006, J INTELL INF SYST, V27, P243, DOI 10.1007/s10844-006-9952-8
   Harrower M., 2007, Cartographica, Int. J. Geographic Inf. Geovisualization, V42, P349, DOI [10.3138/carto.42.4.349, DOI 10.3138/CARTO.42.4.349]
   Höferlin M, 2013, IEEE T MULTIMEDIA, V15, P908, DOI 10.1109/TMM.2013.2238521
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Joshi K.A., 2012, International Journal of Soft Computing and Engineering, V2, P44
   Kraak M.-J., 2003, P 21 INT CART C ICC, P1988
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Landsea C., 2021, The revised atlantic hurricane database (HURDAT2)
   Lee J, 2012, IMA VOL MATH APPL, V154, P1, DOI 10.1007/978-1-4614-1927-3
   Lee TY, 2019, IEEE PAC VIS SYMP, P318, DOI 10.1109/PacificVis.2019.00045
   Li H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134419
   Li ZH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1989734.1989741
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Lu H., 1993, IEEE Data Eng. Bull., V16, P16
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Peña-Araya V, 2022, INFORM VISUAL, V21, P38, DOI 10.1177/14738716211045007
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Smith G., 2001, P GRAPH INT C OTT ON, P135
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Tejada E., 2003, Information Visualization, V2, P218, DOI 10.1057/palgrave.ivs.9500054
   Thudt A., 2013, Proc. Eurographics Conference on Visualization (EuroVis), P79
   Tripathi P. K., 2016, P 9 ACM INT C PERV T
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Dijk TC, 2016, LECT NOTES COMPUT SC, V9801, P382, DOI 10.1007/978-3-319-50106-2_30
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang ZJ, 2011, 2011 AASRI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INDUSTRY APPLICATION (AASRI-AIIA 2011), VOL 2, P37, DOI 10.1109/WiMOB.2011.6085392
   Wang ZC, 2014, INT CONF BIG DATA, P13, DOI 10.1109/BIGCOMP.2014.6741397
   Wulms J, 2021, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis52677.2021.00016
NR 56
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1927
EP 1941
DI 10.1109/TVCG.2023.3250166
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500006
PM 37028073
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Gan, WS
   Xu, HB
   Huang, Y
   Chen, SF
   Yokoya, N
AF Gan, Wanshui
   Xu, Hongbin
   Huang, Yi
   Chen, Shifeng
   Yokoya, Naoto
TI V4D: Voxel for 4D Novel View Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Rendering (computer graphics); Table lookup;
   Task analysis; Solid modeling; Geometry; Computational efficiency;
   Neural radiance field; novel view synthesis; neural rendering; 4D
   representation; look-up tables
AB Neural radiance fields have made a remarkable breakthrough in the novel view synthesis task at the 3D static scene. However, for the 4D circumstance (e.g., dynamic scene), the performance of the existing method is still limited by the capacity of the neural network, typically in a multilayer perceptron network (MLP). In this article, we utilize 3D Voxel to model the 4D neural radiance field, short as V4D, where the 3D voxel has two formats. The first one is to regularly model the 3D space and then use the sampled local 3D feature with the time index to model the density field and the texture field by a tiny MLP. The second one is in look-up tables (LUTs) format that is for the pixel-level refinement, where the pseudo-surface produced by the volume rendering is utilized as the guidance information to learn a 2D pixel-level refinement mapping. The proposed LUTs-based refinement module achieves the performance gain with little computational cost and could serve as the plug-and-play module in the novel view synthesis task. Moreover, we propose a more effective conditional positional encoding toward the 4D data that achieves performance gain with negligible computational burdens. Extensive experiments demonstrate that the proposed method achieves state-of-the-art performance at a low computational cost.
C1 [Gan, Wanshui; Yokoya, Naoto] Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan.
   [Gan, Wanshui; Yokoya, Naoto] RIKEN Ctr Adv Intelligence Project AIP, Geoinformat Team, Tokyo 1030027, Japan.
   [Xu, Hongbin] South China Univ Technol, Guangzhou 510641, Guangdong, Peoples R China.
   [Xu, Hongbin] Alibaba Grp, Hangzhou 311121, Zhejiang, Peoples R China.
   [Huang, Yi; Chen, Shifeng] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Comp Vis & Pattern Recognit, Shenzhen 518055, Guangdong, Peoples R China.
   [Huang, Yi; Chen, Shifeng] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
C3 University of Tokyo; RIKEN; South China University of Technology;
   Alibaba Group; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Yokoya, N (corresponding author), Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan.; Yokoya, N (corresponding author), RIKEN Ctr Adv Intelligence Project AIP, Geoinformat Team, Tokyo 1030027, Japan.
EM 1850255222@edu.k.u-tokyo.ac.jp; hongbinxu1013@gmail.com;
   yi.huang@siat.ac.cn; shifeng.chen@siat.ac.cn; yokoya@k.u-tokyo.ac.jp
RI Yokoya, Naoto/AAC-1530-2022
OI Huang, Yi/0000-0002-8443-6877; Xu, Hongbin/0000-0002-3455-1527
FU JST, FOREST
FX No Statement Available
CR Andersson P, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406183
   Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580
   Cai HR, 2022, Arxiv, DOI arXiv:2206.15258
   Chabra R., 2020, COMPUTER VISION ECCV, P608
   Chen AP, 2022, Arxiv, DOI arXiv:2203.09517
   Chen AP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14104, DOI 10.1109/ICCV48922.2021.01386
   Chibane J, 2021, PROC CVPR IEEE, P7907, DOI 10.1109/CVPR46437.2021.00782
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gao C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5692, DOI 10.1109/ICCV48922.2021.00566
   Garbin Stephan J, 2021, P IEEE CVF INT C COM
   Guo X, 2022, Arxiv, DOI arXiv:2206.07698
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Kingma D. P., 2014, arXiv
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Li JX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12558, DOI 10.1109/ICCV48922.2021.01235
   Li TY, 2022, Arxiv, DOI arXiv:2103.02597
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu L., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Liu Y., 2021, arXiv
   Lombardi S, 2019, Arxiv, DOI [arXiv:1906.07751, 10.1145/3306346.3323020, DOI 10.1145/3306346.3323020]
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Neff T., 2021, COMPUT GRAPH FORUM, V40, P45, DOI [DOI 10.1111/CGF.14340, 10.1111/cgf.14340]
   Niemeyer M, 2019, IEEE I CONF COMP VIS, P5378, DOI 10.1109/ICCV.2019.00548
   Oechsle M, 2021, Arxiv, DOI arXiv:2104.10078
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Peng S., 2020, COMPUTER VISION ECCV
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Rematas K, 2022, PROC CVPR IEEE, P12922, DOI 10.1109/CVPR52688.2022.01259
   Shao R., 2021, arXiv
   Shechtman Y, 2015, IEEE SIGNAL PROC MAG, V32, P87, DOI 10.1109/MSP.2014.2352673
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Sun C, 2022, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR52688.2022.00538
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tancik M, 2022, PROC CVPR IEEE, P8238, DOI 10.1109/CVPR52688.2022.00807
   Tewari Ayush, 2021, arXiv
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Trevithick A., 2021, P IEEE CVF INT C COM, p15 182
   Wang Longguang, 2022, P IEEE CVF C COMP VI
   Wang P, 2021, 35 C NEURAL INFORM P, V34
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Wang T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2451, DOI 10.1109/ICCV48922.2021.00247
   Wei Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5590, DOI 10.1109/ICCV48922.2021.00556
   Wizadwongsa S, 2021, PROC CVPR IEEE, P8530, DOI 10.1109/CVPR46437.2021.00843
   Xian WQ, 2021, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR46437.2021.00930
   Xiangli Yuanbo, 2021, arXiv
   Yao G., 2021, arXiv
   Yariv L, 2021, ADV NEUR IN
   Yi Taoran, 2022, arXiv, DOI DOI 10.48550/ARXIV.2205.15285.3,8
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002
   Zeng H, 2022, IEEE T PATTERN ANAL, V44, P2058, DOI 10.1109/TPAMI.2020.3026740
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhi SF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15818, DOI 10.1109/ICCV48922.2021.01554
NR 60
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1579
EP 1591
DI 10.1109/TVCG.2023.3312127
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300007
PM 37669213
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Qiu, R
   Tu, YM
   Wang, YS
   Yen, PY
   Shen, HW
AF Qiu, Rui
   Tu, Yamei
   Wang, Yu-Shuen
   Yen, Po-Yin
   Shen, Han-Wei
TI DocFlow: A Visual Analytics System for Question-Based Document Retrieval
   and Categorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Systematics; Visual analytics; Task analysis; Semantics; Human in the
   loop; Natural languages; Bit error rate; Biomedical systematic review;
   evidence-based-practice; human-in-the-loop information retrieval;
   question-based document categorization; question-based document
   retrieval
ID SCIENTIFIC LITERATURE; VISUALIZATION; METAANALYSES; GUIDELINES; REVIEWS
AB A systematic review (SR) is essential with up-to-date research evidence to support clinical decisions and practices. However, the growing literature volume makes it challenging for SR reviewers and clinicians to discover useful information efficiently. Many human-in-the-loop information retrieval approaches (HIR) have been proposed to rank documents semantically similar to users' queries and provide interactive visualizations to facilitate document retrieval. Given that the queries are mainly composed of keywords and keyphrases retrieving documents that are semantically similar to a query does not necessarily respond to the clinician's need. Clinicians still have to review many documents to find the solution. The problem motivates us to develop a visual analytics system, DocFlow, to facilitate information-seeking. One of the features of our DocFlow is accepting natural language questions. The detailed description enables retrieving documents that can answer users' questions. Additionally, clinicians often categorize documents based on their backgrounds and with different purposes (e.g., populations, treatments). Since the criteria are unknown and cannot be pre-defined in advance, existing methods can only achieve categorization by considering the entire information in documents. In contrast, by locating answers in each document, our DocFlow can intelligently categorize documents based on users' questions. The second feature of our DocFlow is a flexible interface where users can arrange a sequence of questions to customize their rules for document retrieval and categorization. The two features of this visual analytics system support a flexible information-seeking process. The case studies and the feedback from domain experts demonstrate the usefulness and effectiveness of our DocFlow.
C1 [Qiu, Rui; Tu, Yamei; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Wang, Yu-Shuen] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Yen, Po-Yin] Washington Univ, Inst Informat, Sch Med, St Louis, MO 63110 USA.
C3 University System of Ohio; Ohio State University; National Yang Ming
   Chiao Tung University; Washington University (WUSTL)
RP Qiu, R (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM qiu.580@buckeyemail.osu.edu; tu.253@osu.edu; yushuen@cs.nctu.edu.tw;
   yenp@wustl.edu; shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012; Tu, Yamei/KSL-7529-2024
OI Qiu, Rui/0000-0002-3905-8926; Wang, Yu-Shuen/0000-0003-2550-2990; Tu,
   Yamei/0000-0002-0722-837X; Shen, Han-Wei/0000-0002-1211-2320
CR Amati G, 2009, BM25, P257, DOI DOI 10.1007/978-0-387-39940-9921
   [Anonymous], 2014, P 23 ACM INT C CONFE, DOI DOI 10.1145/2661829.2661935
   Barbosa O., 2017, EvidenceSET: A tool for supporting analysis of evidence and synthesis of primary and secondary studies
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   Borlund P., 2013, J. Inf. Sci. Theory Pract., V1
   Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154
   Choe K, 2021, IEEE PAC VIS SYMP, P176, DOI 10.1109/PacificVis52677.2021.00037
   Cohen AM, 2006, J AM MED INFORM ASSN, V13, P206, DOI 10.1197/jamia.M1929
   Dai ZY, 2019, Arxiv, DOI arXiv:1910.10687
   Dattolo A, 2022, IEEE ACCESS, V10, P21631, DOI 10.1109/ACCESS.2022.3153027
   Dehghani M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/3077136.3080832
   Despins LA, 2018, CIN-COMPUT INFORM NU, V36, P323, DOI 10.1097/CIN.0000000000000430
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dias AG, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345401
   Dreisbach C, 2019, INT J MED INFORM, V125, P37, DOI 10.1016/j.ijmedinf.2019.02.008
   Federico P, 2017, IEEE T VIS COMPUT GR, V23, P2179, DOI 10.1109/TVCG.2016.2610422
   Haddaway NR, 2018, ENVIRON INT, V114, P357, DOI 10.1016/j.envint.2018.02.018
   Hassan H.A.M., 2019, RecSys, P6
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Humaira H., 2018, P 2 WORKSH MULT APPL, DOI [DOI 10.4108/EAI.24-1-2018.2292388, 10.4108/eai.24-1-2018.2292388]
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Ji XN, 2017, J BIOMED INFORM, V69, P33, DOI 10.1016/j.jbi.2017.03.007
   Ji Xiaonan, 2015, AMIA Annu Symp Proc, V2015, P1927
   Johnson J, 2017, Arxiv, DOI [arXiv:1702.08734, 10.48550/arXiv.1702.08734]
   Joshi M, 2017, Arxiv, DOI arXiv:1705.03551
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Martinic MK, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0855-0
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lee EK, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01330-8
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lee Y, 2018, HEALTHC INFORM RES, V24, P157, DOI 10.4258/hir.2018.24.3.157
   Wang LL, 2020, Arxiv, DOI [arXiv:2004.10706, 10.48550/arXiv.2004.10706, DOI 10.48550/ARXIV.2004.10706]
   Dai AM, 2015, Arxiv, DOI [arXiv:1507.07998, DOI 10.48550/ARXIV.1507.07998]
   Manchikanti L, 2009, PAIN PHYSICIAN, V12, P929
   McClellan E. N. M. B., 2008, Evidence-Based Medicine and the Changing Nature of Health Care: Meeting Summary IOM Roundtable on Evidence-Based Medicine
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Mitra B, 2016, Arxiv, DOI arXiv:1602.01137
   Munshi NC, 2011, CLIN CANCER RES, V17, P1234, DOI 10.1158/1078-0432.CCR-10-1843
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P486, DOI 10.1109/TVCG.2021.3114820
   Pai M, 2004, NATL MED J INDIA, V17, P86
   Palpacuer C, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1409-3
   Pampari A, 2018, Arxiv, DOI arXiv:1809.00732
   Pocco X, 2021, SIBGRAPI, P136, DOI 10.1109/SIBGRAPI54419.2021.00027
   Ponsard Antoine., 2016, Proceedings of the ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems, P2264
   Portenoy J, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501905
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rachamallu V, 2019, AM J THER, V26, pE406, DOI 10.1097/MJT.0000000000000894
   Radford A., 2019, OpenAI blog, V1, P9
   Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Rossanez A, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01341-5
   Schardt C, 2007, BMC MED INFORM DECIS, V7, DOI 10.1186/1472-6947-7-16
   Tendal B, 2009, BMJ-BRIT MED J, V339, DOI 10.1136/bmj.b3128
   van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]
   van Eck NJ, 2017, SCIENTOMETRICS, V111, P1053, DOI 10.1007/s11192-017-2300-7
   WANOUS JP, 1989, J APPL PSYCHOL, V74, P259, DOI 10.1037/0021-9010.74.2.259
   Wu Y, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007349
   Yang Jianji J, 2008, AMIA Annu Symp Proc, P825
   Zheng GQ, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P575, DOI 10.1145/2766462.2767700
NR 62
TC 1
Z9 1
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1533
EP 1548
DI 10.1109/TVCG.2022.3219762
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300005
PM 36331645
DA 2024-08-05
ER

PT J
AU Jamonnak, S
   Guo, JJ
   He, WB
   Gou, L
   Ren, L
AF Jamonnak, Suphanut
   Guo, Jiajing
   He, Wenbin
   Gou, Liang
   Ren, Liu
TI OW-Adapter: Human-Assisted Open-World Object Detection with a Few
   Examples
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Detectors; Automobiles; Proposals; Object detection; Object recognition;
   Visual analytics; Training; Open world learning; object detection;
   continuous learning; human-assisted AI
ID NOVELTY DETECTION; VISUAL ANALYSIS
AB Open-world object detection (OWOD) is an emerging computer vision problem that involves not only the identification of predefined object classes, like what general object detectors do, but also detects new unknown objects simultaneously. Recently, several end-to-end deep learning models have been proposed to address the OWOD problem. However, these approaches face several challenges: a) significant changes in both network architecture and training procedure are required; b) they are trained from scratch, which can not leverage existing pre-trained general detectors; c) costly annotations for all unknown classes are needed. To overcome these challenges, we present a visual analytic framework called OW-Adapter. It acts as an adaptor to enable pre-trained general object detectors to handle the OWOD problem. Specifically, OW-Adapter is designed to identify, summarize, and annotate unknown examples with minimal human effort. Moreover, we introduce a lightweight classifier to learn newly annotated unknown classes and plug the classifier into pre-trained general detectors to detect unknown objects. We demonstrate the effectiveness of our framework through two case studies of different domains, including common object recognition and autonomous driving. The studies show that a simple yet powerful adaptor can extend the capability of pre-trained general detectors to detect unknown objects and improve the performance on known classes simultaneously.
C1 [Jamonnak, Suphanut; Guo, Jiajing; He, Wenbin; Gou, Liang; Ren, Liu] Bosch Res North Amer, Sunnyvale, CA 94085 USA.
RP Jamonnak, S (corresponding author), Bosch Res North Amer, Sunnyvale, CA 94085 USA.
EM suphanut.jamonnak@us.bosch.com; jiajing.guo@us.bosch.com;
   wenbin.he2@us.bosch.com; liang.gou@us.bosch.com; liu.ren@us.bosch.com
OI He, Wenbin/0000-0002-5376-5803
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Bäuerle A, 2020, COMPUT GRAPH FORUM, V39, P195, DOI 10.1111/cgf.13973
   Behrisch M, 2014, IEEE CONF VIS ANAL, P43, DOI 10.1109/VAST.2014.7042480
   Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173
   Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799
   Bruneau Pierrick, 2013, 2013 17th International Conference on Information Visualisation, P168, DOI 10.1109/IV.2013.21
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cao N, 2016, IEEE T VIS COMPUT GR, V22, P280, DOI 10.1109/TVCG.2015.2467196
   Chalapathy R, 2019, Arxiv, DOI [arXiv:1901.03407, DOI 10.48550/ARXIV.1901.03407]
   Chen C., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P3
   Chen C., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhamija AR, 2020, IEEE WINT CONF APPL, P1010, DOI 10.1109/WACV45572.2020.9093355
   Everingham M., 2012, PASCAL VISUAL OBJECT
   Faria B, 2022, LECT NOTES ARTIF INT, V13566, P464, DOI 10.1007/978-3-031-16474-3_38
   Fort S., 2021, Advances in Neural Information Processing Systems, V34, P5
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gupta A, 2022, PROC CVPR IEEE, P9225, DOI 10.1109/CVPR52688.2022.00902
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He W., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoque Md Naimul, 2023, IEEE Trans Vis Comput Graph, V29, P74, DOI 10.1109/TVCG.2022.3209466
   Jain L. P., 2014, COMPUTER VISION ECCV, P2
   Jaunet T., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Jia S., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Joseph KJ, 2021, PROC CVPR IEEE, P5826, DOI 10.1109/CVPR46437.2021.00577
   Kahng M., 2018, IEEE transactions on visualization and computer graphics, V25, P3
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K, 2018, ADV NEUR IN, V31
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liang S., 2018, PROC INT C LEARNING, P2
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264
   Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019
   Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018
   McCloskey M., 1989, Catastrophic interference in connectionist networks: The sequential learning problem, V24, P2
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Melas-Kyriazi L, 2022, PROC CVPR IEEE, P8354, DOI 10.1109/CVPR52688.2022.00818
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ouyang Long, 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI 10.1177/01454455830072006
   Perera Pramuditha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11811, DOI 10.1109/CVPR42600.2020.01183
   Perez-Rua Juan-Manuel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13843, DOI 10.1109/CVPR42600.2020.01386
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren S., 2015, Advances in neural information processing systems, P6
   Ruff L, 2021, P IEEE, V109, P756, DOI 10.1109/JPROC.2021.3052449
   Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
   Shannon C. E., 1949, A mathematical theory of communication, P4
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Thom D, 2012, IEEE PAC VIS SYMP, P41, DOI 10.1109/PacificVis.2012.6183572
   Wang HZ, 2019, IEEE ACCESS, V7, P107964, DOI 10.1109/ACCESS.2019.2932769
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wilkinson L, 2018, IEEE T VIS COMPUT GR, V24, P256, DOI 10.1109/TVCG.2017.2744685
   Wu Y., 2019, Detectron2, V6
   Wu ZH, 2022, LECT NOTES COMPUT SC, V13670, P193, DOI 10.1007/978-3-031-20080-9_12
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xu H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3413, DOI 10.1145/3308558.3313644
   Yang W., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yoshihashi R, 2019, PROC CVPR IEEE, P4011, DOI 10.1109/CVPR.2019.00414
   Yue ZQ, 2021, PROC CVPR IEEE, P15399, DOI 10.1109/CVPR46437.2021.01515
   Zhang H, 2022, Arxiv, DOI [arXiv:2203.03605, DOI 10.48550/ARXIV.2203.03605, 10.48550/arXiv.2203.03605]
   Zhang J., 2018, IEEE transactions on visualization and computer graphics, V25, P3
   Zhao X., 2022, arXiv
NR 75
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 694
EP 704
DI 10.1109/TVCG.2023.3326577
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500066
PM 37871071
DA 2024-08-05
ER

PT J
AU Oral, E
   Chawla, R
   Wijkstra, M
   Mahyar, N
   Dimara, E
AF Oral, Emre
   Chawla, Ria
   Wijkstra, Michel
   Mahyar, Narges
   Dimara, Evanthia
TI From Information to Choice: A Critical Inquiry Into Visualization Tools
   for Decision Making
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision making; visualization; state of the art; review; survey;
   design; interaction; multi-criteria decision making; MCDM
ID VISUAL ANALYSIS; MCDM METHODS; UNCERTAINTY; COMMUNICATION; STRATEGIES;
   SUPPORT; DESIGN; MODELS
AB In the face of complex decisions, people often engage in a three-stage process that spans from (1) exploring and analyzing pertinent information (intelligence); (2) generating and exploring alternative options (design); and ultimately culminating in (3) selecting the optimal decision by evaluating discerning criteria (choice). We can fairly assume that all good visualizations aid in the "intelligence" stage by enabling data exploration and analysis. Yet, to what degree and how do visualization systems currently support the other decision making stages, namely "design" and "choice"? To further explore this question, we conducted a comprehensive review of decision-focused visualization tools by examining publications in major visualization journals and conferences, including VIS, EuroVis, and CHI, spanning all available years. We employed a deductive coding method and in-depth analysis to assess whether and how visualization tools support design and choice. Specifically, we examined each visualization tool by (i) its degree of visibility for displaying decision alternatives, criteria, and preferences, and (ii) its degree of flexibility for offering means to manipulate the decision alternatives, criteria, and preferences with interactions such as adding, modifying, changing mapping, and filtering. Our review highlights the opportunities and challenges that decision-focused visualization tools face in realizing their full potential to support all stages of the decision making process. It reveals a surprising scarcity of tools that support all stages, and while most tools excel in offering visibility for decision criteria and alternatives, the degree of flexibility to manipulate these elements is often limited, and the lack of tools that accommodate decision preferences and their elicitation is notable. Based on our findings, to better support the choice stage, future research could explore enhancing flexibility levels and variety, exploring novel visualization paradigms, increasing algorithmic support, and ensuring that this automation is user-controlled via the enhanced flexibility I evels. Our curated list of the 88 surveyed visualization tools is available in the OSF link (https://osf.io/nrasz/?view_only=b92a90a34ae241449b5f2cd33383bfcb).
C1 [Oral, Emre; Wijkstra, Michel; Dimara, Evanthia] Univ Utrecht, Utrecht, Netherlands.
   [Chawla, Ria] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
C3 Utrecht University; University of Massachusetts System; University of
   Massachusetts Amherst
RP Oral, E (corresponding author), Univ Utrecht, Utrecht, Netherlands.
EM e.oral@uu.nl; rchawla@umass.edu; m.wijkstra@uu.nl; nmahyar@cs.umass.edu;
   evanthia.dimara@gmail.com
OI Dimara, Evanthia/0000-0001-5212-7888
CR Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Alves T, 2023, COMPUT GRAPH-UK, V111, P47, DOI 10.1016/j.cag.2023.01.010
   Andrienko G, 2007, IEEE S VIS ANAL, P43, DOI 10.1109/VAST.2007.4388995
   Asahi T., 1995, P CHI, p405, DOI DOI 10.1145/223355.223747
   Aseniero BA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1479, DOI 10.1145/2702123.2702426
   Azuma R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P433, DOI 10.1109/VISUAL.1999.809923
   Bajracharya S, 2018, INT J INF TECH DECIS, V17, P1839, DOI 10.1142/S0219622018500384
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Baumer EPS, 2022, COMPUT GRAPH FORUM, V41, P1, DOI 10.1111/cgf.14518
   Bautista Jeanette., 2006, AVI '06, P217
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Brehmer M, 2022, IEEE T VIS COMPUT GR, V28, P1139, DOI 10.1109/TVCG.2021.3114760
   Cao AQ, 2023, IEEE T VIS COMPUT GR, V29, P5178, DOI 10.1109/TVCG.2022.3207147
   Carenini Giuseppe, 2004, Proceedings of the working conference on Advanced visual interfaces, P150
   Castro SC, 2022, IEEE T VIS COMPUT GR, V28, P411, DOI 10.1109/TVCG.2021.3114803
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chermack T.J., 2011, SCENARIO PLANNING OR
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dhurkari RK, 2022, RAIRO-OPER RES, V56, P2221, DOI 10.1051/ro/2022060
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Dy B, 2022, IEEE T VIS COMPUT GR, V28, P3405, DOI 10.1109/TVCG.2021.3065126
   Elo S, 2008, J ADV NURS, V62, P107, DOI 10.1111/j.1365-2648.2007.04569.x
   Feng ZZ, 2021, IEEE T VIS COMPUT GR, V27, P828, DOI 10.1109/TVCG.2020.3030469
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Figueira J, 2005, INT SER OPER RES MAN, V78, P1, DOI 10.1007/b100605
   Fleiss JL, 2013, Statistical methods for rates and proportions, DOI DOI 10.1002/0471445428
   Gettinger J, 2013, DECIS SUPPORT SYST, V54, P976, DOI 10.1016/j.dss.2012.10.023
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Greening LA, 2004, ENERG POLICY, V32, P721, DOI 10.1016/j.enpol.2003.08.017
   Guo SN, 2019, INT C POWER ELECT DR, DOI [10.1109/peds44367.2019.8998889, 10.1145/3290605.3300803]
   Ham C, 2009, J INTEGR CARE, V17, P3, DOI 10.1108/14769018200900040
   Han Y., 2022, PROC TREX, P16, DOI [10.1109/TREX57753.2022.00007, DOI 10.1109/TREX57753.2022.00007]
   Handler A, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3524025
   Hindalong Emily, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512896
   Huron S., 2021, ALTVIS WORKSHOP
   Jansen Y, 2013, IEEE T VIS COMPUT GR, V19, P2396, DOI 10.1109/TVCG.2013.134
   Jasim M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517649
   Jasim M, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P846, DOI 10.1145/3461778.3462132
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kandogan E, 2014, IEEE COMPUT GRAPH, V34, P42, DOI 10.1109/MCG.2014.62
   Keefe DF, 2010, IEEE COMPUT GRAPH, V30, P8, DOI 10.1109/MCG.2010.30
   KEENEY RL, 1982, OPER RES, V30, P803, DOI 10.1287/opre.30.5.803
   Keeney RL, 1993, Decisions With Multiple Objectives: Preferences and Value Trade-Offs
   Klein G, 2008, HUM FACTORS, V50, P456, DOI 10.1518/001872008X288385
   Kosara R, 2023, IEEE COMPUT GRAPH, V43, P91, DOI 10.1109/MCG.2022.3222024
   Kreiser J, 2018, IEEE T VIS COMPUT GR, V24, P873, DOI 10.1109/TVCG.2017.2744299
   Le Goc M, 2019, IEEE T VIS COMPUT GR, V25, P737, DOI 10.1109/TVCG.2018.2865159
   Lim NJ, 2016, INT J GEOGR INF SCI, V30, P240, DOI 10.1080/13658816.2015.1085539
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   MacQueen KM., 1998, Cultural Anthropology Methods, V10, P31, DOI [DOI 10.1177/1525822X980100020301, 10.1177/1525822X980100020301]
   Mahyar N, 2020, IEEE COMPUT GRAPH, V40, P76, DOI 10.1109/MCG.2020.3017405
   Mahyar N, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1171, DOI 10.1145/3322276.3322354
   Mahyar N, 2017, CSCW'17: COMPANION OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P17, DOI 10.1145/3022198.3023269
   Marriott K, 2011, IEEE T VIS COMPUT GR, V17, P290, DOI 10.1109/TVCG.2010.45
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   Muller J., 2021, PROC EUROVISEUROGRAP, DOI [10.2312/evm.20211075, DOI 10.2312/EVM.20211075]
   Nielsen Jakob, 2005, 10 Usability Heuristics for User Interface Design
   Norman D., 2013, The design of everyday things: Revised and expanded edition
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Park S, 2022, INFORM HEALTH SOC CA, V47, P175, DOI 10.1080/17538157.2021.1982949
   PAYNE JW, 1988, J EXP PSYCHOL LEARN, V14, P534, DOI 10.1037/0278-7393.14.3.534
   Payne JW., 2008, Blackwell Handbook of Judgment and Decision Making, P110
   Pu P., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P289, DOI 10.1145/332040.332446
   Reyna VF, 2011, DEV REV, V31, P180, DOI 10.1016/j.dr.2011.07.004
   Ribicic H, 2012, IEEE T VIS COMPUT GR, V18, P2255, DOI 10.1109/TVCG.2012.261
   Rudolph Stephen, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P195, DOI 10.1109/VAST.2009.5333920
   RUSSO JE, 1983, J EXP PSYCHOL LEARN, V9, P676, DOI 10.1037/0278-7393.9.4.676
   Savikhin A., 2011, S2011 44 HAWAII INT, P1, DOI 10.1109/HICSS.2011.54
   Siirtola H., 2014, PROC BCS HCI, P240, DOI [10.14236/ewic/hci2014.30, DOI 10.14236/EWIC/HCI2014.30]
   Simon HA., 1960, NEW SCI MANAGEMENT D, Vxii, DOI DOI 10.1037/13978-000
   Sorger J, 2016, IEEE T VIS COMPUT GR, V22, P290, DOI 10.1109/TVCG.2015.2468011
   Spence R, 1998, INTERACT COMPUT, V11, P137, DOI 10.1016/S0953-5438(98)00022-8
   Sperrle F, 2021, COMPUT GRAPH FORUM, V40, P543, DOI 10.1111/cgf.14329
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Talukder AKMKA, 2020, IEEE COMPUT INTELL M, V15, P36, DOI 10.1109/MCI.2020.2976184
   Tian ZL, 2021, INFORMATION, V12, DOI 10.3390/info12060239
   Tory M, 2023, IEEE COMPUT GRAPH, V43, P22, DOI 10.1109/MCG.2021.3136545
   Tovanich N, 2021, IEEE T VIS COMPUT GR, V27, P3135, DOI 10.1109/TVCG.2019.2963018
   van Pelt R, 2014, COMPUT GRAPH FORUM, V33, P131, DOI 10.1111/cgf.12369
   Velasquez M., 2013, INT J OPERATIONS RES, V10, P56
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wang Ruijie, 2023, Computers in Human Behavior, DOI 10.1016/j.chb.2022.107545
   Waser J, 2014, COMPUT GRAPH FORUM, V33, P281, DOI 10.1111/cgf.12384
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   Weistroffer H.R., 2016, MULTIPLE CRITERIA DE, P1301, DOI DOI 10.1007/978-1-4939-3094-4_29
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wittenburg K., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P51, DOI 10.1145/502348.502357
   Xia HJ, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186471
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zavadskas EK, 2011, TECHNOL ECON DEV ECO, V17, P397, DOI 10.3846/20294913.2011.593291
   Zhang YF, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2211, DOI 10.1145/2702123.2702239
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
   Zhao Y, 2019, IEEE T VIS COMPUT GR, V25, P12, DOI 10.1109/TVCG.2018.2865020
   Ziegler H., 2007, EUROVIS 2007, P19, DOI 10.2312/VisSym/EuroVis07/019-026
NR 106
TC 1
Z9 1
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 359
EP 369
DI 10.1109/TVCG.2023.3326593
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500056
PM 37871054
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Saffo, D
   Di Bartolomeo, S
   Crnovrsanin, T
   South, L
   Raynor, J
   Yildirim, C
   Dunne, C
AF Saffo, David
   Di Bartolomeo, Sara
   Crnovrsanin, Tarik
   South, Laura
   Raynor, Justin
   Yildirim, Caglar
   Dunne, Cody
TI Unraveling the Design Space of Immersive Analytics: A Systematic Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Three-dimensional displays; Surveys; Systematics;
   Taxonomy; Market research; Collaboration; Immersive Analytics;
   Systematic Review; Survey; Augmented Reality; Virtual Reality; Design
   Space
ID AUGMENTED REALITY; VISUALIZATION
AB Immersive analytics has emerged as a promising research area, leveraging advances in immersive display technologies and techniques, such as virtual and augmented reality, to facilitate data exploration and decision-making. This paper presents a systematic literature review of 73 studies published between 2013-2022 on immersive analytics systems and visualizations, aiming to identify and categorize the primary dimensions influencing their design. We identified five key dimensions: Academic Theory and Contribution, Immersive Technology, Data, Spatial Presentation, and Visual Presentation. Academic Theory and Contribution assess the motivations behind the works and their theoretical frameworks. Immersive Technology examines the display and input modalities, while Data dimension focuses on dataset types and generation. Spatial Presentation discusses the environment, space, embodiment, and collaboration aspects in IA, and Visual Presentation explores the visual elements, facet and position, and manipulation of views. By examining each dimension individually and cross-referencing them, this review uncovers trends and relationships that help inform the design of immersive systems visualizations. This analysis provides valuable insights for researchers and practitioners, offering guidance in designing future immersive analytics systems and shaping the trajectory of this rapidly evolving field. A free copy of this paper and all supplemental materials are available at osf.io/5ewaj.
C1 [Saffo, David; Di Bartolomeo, Sara; Crnovrsanin, Tarik; South, Laura; Raynor, Justin; Yildirim, Caglar; Dunne, Cody] Northeastern Univ, Boston, MA 02138 USA.
   [Saffo, David] JP Morgan Chase & Co, New York, NY 10017 USA.
C3 Northeastern University; JP Morgan Chase & Company
RP Saffo, D (corresponding author), Northeastern Univ, Boston, MA 02138 USA.; Saffo, D (corresponding author), JP Morgan Chase & Co, New York, NY 10017 USA.
EM david.saffo@jpmchase.com; dibartolomeo.s@northeastern.edu;
   t.crnovrsanin@northeastern.edu; south.l@northeastern.edu;
   raynor.j@northeastern.edu; c.yildirim@northeastern.edu;
   c.dunne@northeastern.edu
OI South, Laura/0000-0003-4444-6314; Di Bartolomeo,
   Sara/0000-0001-9517-3526; Dunne, Cody/0000-0002-1609-9776; Raynor,
   Justin/0000-0002-7678-0846
FU Northeastern University
FX No Statement Available
CR Ard T, 2017, P IEEE VIRT REAL ANN, P465, DOI 10.1109/VR.2017.7892381
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Barreiros C, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P72, DOI [10.1109/ISMAR-Adjunct.2016.0043, 10.1109/ISMAR-Adjunct.2016.36]
   Barrios dell'Olio Giuliana, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1027, DOI 10.1145/3472749.3474803
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Bhardwaj A, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489890
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Carmo MB, 2014, INT SYM MIX AUGMENT, P255, DOI 10.1109/ISMAR.2014.6948437
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/VR.2019.8797733, 10.1109/vr.2019.8797733]
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Crnovrsanin T., 2023, P IEEE VIS 2023
   Danyluk K, 2022, IEEE T VIS COMPUT GR, V28, P1930, DOI 10.1109/TVCG.2020.3023336
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Gall A, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489851
   Gold L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P428, DOI 10.1109/VR50410.2021.00066
   Hall BD, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545614
   Hayatpur D., 2020, P 33 ANN ACM S US IN, P818, DOI DOI 10.1145/3379337.3415878
   Hu H, 2022, IEEE INT SYMP M AU R, P131, DOI 10.1109/ISMAR-Adjunct57072.2022.00033
   Huang JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1485, DOI [10.1109/VR.2019.8797996, 10.1109/vr.2019.8797996]
   Huang JB, 2022, IEEE INT SYMP M AU R, P111, DOI 10.1109/ISMAR-Adjunct57072.2022.00030
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Nguyen H, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P87, DOI 10.1109/ISMAR-Adjunct.2017.38
   Ivanov A., 2018, 2018 CHI C HUM FACT, P1, DOI [10.1145/3170427.31885443, DOI 10.1145/3170427.31885443]
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Joos L, 2022, IEEE T VIS COMPUT GR, V28, P3651, DOI 10.1109/TVCG.2022.3203001
   Kimmel S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489852
   Knierim P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P170, DOI 10.1109/ISMAR-Adjunct.2018.00059
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Laera F, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P269, DOI 10.1109/ISMAR-Adjunct51615.2020.00076
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Leuze C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P377, DOI 10.1109/ISMAR-Adjunct.2018.00109
   Li N., 2014, CHI 14 EXTENDED ABST, P1291, DOI 10.1145/2559206.25811475
   Li RY, 2021, INT SYM MIX AUGMENT, P240, DOI 10.1109/ISMAR-Adjunct54149.2021.00056
   Li TM, 2022, IEEE INT SYMP M AU R, P124, DOI 10.1109/ISMAR-Adjunct57072.2022.00032
   Lin T., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34456495, DOI 10.1145/3411764.34456495]
   Liu JZ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580827
   Mahmood T, 2019, INT SYM MIX AUGMENT, P236, DOI 10.1109/ISMAR.2019.00021
   Marriott K., 2018, Immersive analytics
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P259, DOI 10.1007/978-3-030-01388-2_9
   Masai K, 2022, IEEE INT SYMP M AU R, P845, DOI 10.1109/ISMAR-Adjunct57072.2022.00182
   Merino L, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383017
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Munzner T., 2015, AK Peters Visualization series, P4
   Nam JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P747, DOI [10.1109/vr.2019.8797871, 10.1109/VR.2019.8797871]
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Pei YQ, 2019, I C VIRTUAL REALITY, P11, DOI 10.1109/ICVRV47840.2019.00011
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Ran LQ, 2016, I C VIRTUAL REALITY, P473, DOI 10.1109/ICVRV.2016.86
   Reichherzer C, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451839
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Romat H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376348
   Saffo David., 2021, P 2021 CHI C HUMAN F, DOI [10.1145/3411764.3445426, DOI 10.1145/3411764.3445426]
   Saffo David., 2023, Through Their Eyes and, DOI DOI 10.1145/3544548.3581093
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Schetinger V., 2023, Doom or deliciousness: Challenges and opportunities for visualization in the age of generative models, DOI [10.31219/osf.io/3jrcm9, DOI 10.31219/OSF.IO/3JRCM9]
   Schindler M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P1, DOI 10.1109/VIS47514.2020.00007
   Seraji MR, 2022, IEEE INT SYMP M AU R, P146, DOI 10.1109/ISMAR-Adjunct57072.2022.00035
   Siang CV, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING (ICOCO), P347, DOI 10.1109/ICOCO53166.2021.9673569
   Ssin SY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P210, DOI [10.1109/VR.2019.8797812, 10.1109/vr.2019.8797812]
   Subramonyam H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300628
   Sun ZD, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188551
   Suzuki Ryo, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P166, DOI 10.1145/3379337.3415892
   Tadeja SK, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313068
   Tatzgern M, 2013, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2013.6549347
   Tong W., 2023, Towards an understanding of distributed asymmetric collaborative visualization on problem-solving
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang H, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489923
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Wang Z, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489874
   Wen Zhen, 2023, IEEE Trans Vis Comput Graph, V29, P440, DOI 10.1109/TVCG.2022.3209475
   Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18
   Willett W, 2022, IEEE T VIS COMPUT GR, V28, P22, DOI 10.1109/TVCG.2021.3114844
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Zheng MY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P93, DOI 10.1109/ISMAR-Adjunct.2019.00039
   Zollmann S, 2014, IEEE T VIS COMPUT GR, V20, P560, DOI 10.1109/TVCG.2014.24
NR 87
TC 3
Z9 3
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 495
EP 506
DI 10.1109/TVCG.2023.3327368
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500084
PM 37878454
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Li, JC
   Lai, CF
   Wang, YF
   Luo, AL
   Yuan, XR
AF Li, Jincheng
   Lai, Chufan
   Wang, Youfen
   Luo, Ali
   Yuan, Xiaoru
TI SpectrumVA: Visual Analysis of Astronomical Spectra for Facilitating
   Classification Inspection
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Inspection; Pipelines; Stars; Surveys; Visual analytics; Telescopes;
   Task analysis; Spectral classification; visual parameter space analysis;
   decision-making; visual analytics
ID AUTOMATED CLASSIFICATION; PARAMETER SPACE; VISUALIZATION; GUIDANCE;
   ANALYTICS; SEQUENCE; STARS
AB In astronomical spectral analysis, class recognition is essential and fundamental for subsequent scientific research. The experts often perform the visual inspection after automatic classification to deal with low-quality spectra to improve accuracy. However, given the enormous spectral volume and inadequacy of the current inspection practice, such inspection is tedious and time-consuming. This article presents a visual analytics system named SpectrumVA to promote the efficiency of visual inspection while guaranteeing accuracy. We abstract inspection as a visual parameter space analysis process, using redshifts and spectral lines as parameters. Different navigation strategies are employed in the "selection-inspection-promotion" workflow. At the selection stage, we help the experts identify a spectrum of interest through spectral representations and auxiliary information. Several possible redshifts and corresponding important spectral lines are also recommended through a global-to-local strategy to provide an appropriate entry point for the inspection. The inspection stage adopts a variety of instant visual feedback to help the experts adjust the redshift and select spectral lines in an informed trial-and-error manner. Similar spectra to the inspected one rather than different ones are visualized at the promotion stage, making the inspection process more fluent. We demonstrate the effectiveness of SpectrumVA through a quantitative algorithmic assessment, a case study, interviews with domain experts, and a user study.
C1 [Li, Jincheng; Yuan, Xiaoru] Peking Univ, Sch Intelligence Sci & Technol, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
   [Lai, Chufan] Peking Univ, Sch Intelligence Sci & Technol, Beijing 100107, Peoples R China.
   [Wang, Youfen; Luo, Ali] Natl Astron Observ, CAS Key Lab Opt Astron, Beijing 101408, Peoples R China.
   [Luo, Ali; Yuan, Xiaoru] Natl Astron Observ, CAS Key Lab Opt Astron, Beijing 100871, Peoples R China.
C3 Peking University; Peking University; Chinese Academy of Sciences;
   National Astronomical Observatory, CAS; Chinese Academy of Sciences;
   National Astronomical Observatory, CAS
RP Yuan, XR (corresponding author), Peking Univ, Sch Intelligence Sci & Technol, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
EM jincheng.li@pku.edu.cn; chufan.lai@pku.edu.cn; yfwang@bao.ac.cn;
   lal@nao.ac.cn; xiaoru.yuan@pku.edu.cn
OI Yuan, Xiaoru/0000-0002-7233-980X; Li, Jincheng/0000-0003-2328-3624; Luo,
   A-Li/0000-0001-7865-2648
FU NSFC [62272012]
FX This work was supported by NSFC under Grant 62272012.
CR Abdurro'uf, 2022, ASTROPHYS J SUPPL S, V259, DOI 10.3847/1538-4365/ac4414
   Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Albers D, 2011, IEEE T VIS COMPUT GR, V17, P2392, DOI 10.1109/TVCG.2011.232
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   Bailer-Jones CAL, 1998, MON NOT R ASTRON SOC, V298, P361, DOI 10.1046/j.1365-8711.1998.01596.x
   Bazarghan M, 2008, Arxiv, DOI [arXiv:0804.2742, 10.48550/arXiv.0804.2742, DOI 10.48550/ARXIV.0804.2742]
   Bishop C. M., 1995, Neural Networks for Pattern Recognition
   Bittner A, 2019, ASTRON ASTROPHYS, V628, DOI 10.1051/0004-6361/201935829
   Bolton AS, 2012, ASTRON J, V144, DOI 10.1088/0004-6256/144/5/144
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   Ceneda D., 2018, P 9 INT EUROVIS WORK, P19, DOI [10.2312/eurova.20181107, DOI 10.2312/EUROVA.20181107]
   Ceneda D., 2018, P 9 INT EUROVIS WORK, P23
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chang K., d3.parcoords.js
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Correll M., 2011, 2011 IEEE Symposium on Biological Data Visualization, P135, DOI 10.1109/BioVis.2011.6094058
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cretignier M, 2020, ASTRON ASTROPHYS, V640, DOI 10.1051/0004-6361/202037722
   Few S., 2008, "Time on the horizon
   Geng Z, 2011, IEEE T VIS COMPUT GR, V17, P2572, DOI 10.1109/TVCG.2011.166
   Gisbrecht A, 2015, NEUROCOMPUTING, V147, P71, DOI 10.1016/j.neucom.2013.11.045
   [郭炎鑫 Guo Yanxin], 2019, [天文研究与技术, Astronomical Research & Technology], V16, P335
   Hassan A, 2011, PUBL ASTRON SOC AUST, V28, P150, DOI 10.1071/AS10031
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Heinrich Julian, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P594
   Hijikata Yoshinori., 2004, Proceedings of IUI, P198, DOI [DOI 10.1145/964442.964480, 10.1145/964442.964480]
   Ho IT, 2016, ASTROPHYS SPACE SCI, V361, DOI 10.1007/s10509-016-2865-2
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Kincaid R, 2010, IEEE T VIS COMPUT GR, V16, P900, DOI 10.1109/TVCG.2010.193
   Kirkpatrick JD, 1997, ASTRON J, V113, P1421, DOI 10.1086/118357
   Kreuseler M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P49, DOI 10.1109/INFVIS.2004.2
   lamost, LAMOST data release 7 v1.2
   Lan FF, 2021, COMPUT GRAPH FORUM, V40, P635, DOI 10.1111/cgf.14332
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Liu C, 2015, RES ASTRON ASTROPHYS, V15, P1137, DOI 10.1088/1674-4527/15/8/004
   Luciani TB, 2014, IEEE T VIS COMPUT GR, V20, P1048, DOI 10.1109/TVCG.2014.2312008
   Luo AL, 2015, RES ASTRON ASTROPHYS, V15, P1095, DOI 10.1088/1674-4527/15/8/002
   Manteiga M, 2009, ASTRON J, V137, P3245, DOI 10.1088/0004-6256/137/2/3245
   Monsell S, 2003, TRENDS COGN SCI, V7, P134, DOI 10.1016/S1364-6613(03)00028-7
   Morgan P. Keenan, 1943, An Atlas of Stellar Spectra: Withan Outline of Spectral Classification
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Pretorius J, 2011, IEEE T VIS COMPUT GR, V17, P2402, DOI 10.1109/TVCG.2011.253
   Prusti T, 2016, ASTRON ASTROPHYS, V595, DOI 10.1051/0004-6361/201629272
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Ribicic H, 2013, IEEE T VIS COMPUT GR, V19, P1062, DOI 10.1109/TVCG.2012.175
   Saito T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P173, DOI 10.1109/INFVIS.2005.1532144
   Sánchez SF, 2016, REV MEX ASTRON ASTR, V52, P171
   Sawada N, 2022, IEEE T VIS COMPUT GR, V28, P1917, DOI 10.1109/TVCG.2020.3025090
   SCHACTER DL, 1992, J COGNITIVE NEUROSCI, V4, P244, DOI 10.1162/jocn.1992.4.3.244
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Song YH, 2012, RES ASTRON ASTROPHYS, V12, P453, DOI 10.1088/1674-4527/12/4/009
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Tominski C, 2017, COMPUT GRAPH FORUM, V36, P173, DOI 10.1111/cgf.12871
   Torsney-Weir T, 2011, IEEE T VIS COMPUT GR, V17, P1892, DOI 10.1109/TVCG.2011.248
   TULVING E, 1990, SCIENCE, V247, P301, DOI 10.1126/science.2296719
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang K, 2017, MON NOT R ASTRON SOC, V465, P4311, DOI 10.1093/mnras/stw2894
   Wang YF, 2022, ASTRON ASTROPHYS, V660, DOI 10.1051/0004-6361/202142009
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiang M., 2016, Monthly Notices Roy. Astronomical Soc., V464, P3657
   Yang P, 2021, ARCH COMPUT METHOD E, V28, P917, DOI 10.1007/s11831-020-09401-9
   Yuan HL, 2013, ASTRON COMPUT, V3-4, P65, DOI 10.1016/j.ascom.2013.12.001
   Zhang HL, 2021, INFORM VISUAL, V20, P20, DOI 10.1177/1473871620978209
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
   Zheng ZP, 2020, PUBL ASTRON SOC PAC, V132, DOI 10.1088/1538-3873/ab5ed7
   Zicheng Liao, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P51, DOI 10.1109/VAST.2010.5652467
NR 70
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5386
EP 5403
DI 10.1109/TVCG.2023.3294958
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400078
PM 37440386
DA 2024-08-05
ER

PT J
AU Lv, P
   Pei, XM
   Ren, XY
   Zhang, YZ
   Li, CC
   Xu, ML
AF Lv, Pei
   Pei, Xinming
   Ren, Xinyu
   Zhang, Yuzhen
   Li, Chaochao
   Xu, Mingliang
TI TraInterSim: Adaptive and Planning-Aware Hybrid-Driven Traffic
   Intersection Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trajectory; Traffic control; Behavioral sciences; Planning;
   Optimization; Collision avoidance; Simulation; data-driven;
   heterogeneous multi-agent; traffic intersection; traffic simulation
ID CROWD SIMULATION; MODEL; DYNAMICS; FLOW; ANIMATION
AB Traffic intersections are important scenes that can be seen almost everywhere in the traffic system. Currently, most simulation methods perform well at highways and urban traffic networks. In intersection scenarios, the challenge lies in the lack of clearly defined lanes, where agents with various motion plannings converge in the central area from different directions. Traditional model-based methods are difficult to drive agents to move realistically at intersections without enough predefined lanes, while data-driven methods often require a large amount of high-quality input data. Simultaneously, tedious parameter tuning is inevitable involved to obtain the desired simulation results. In this paper, we present a novel adaptive and planning-aware hybrid-driven method (TraInterSim) to simulate traffic intersection scenarios. Our hybrid-driven method combines an optimization-based data-driven scheme with a velocity continuity model. It guides the agent's movements using real-world data and can generate those behaviors not present in the input data. Our optimization method fully considers velocity continuity, desired speed, direction guidance, and planning-aware collision avoidance. Agents can perceive others' motion plannings and relative distances to avoid possible collisions. To preserve the individual flexibility of different agents, the parameters in our method are automatically adjusted during the simulation. TraInterSim can generate realistic behaviors of heterogeneous agents in different traffic intersection scenarios in interactive rates. Through extensive experiments as well as user studies, we validate the effectiveness and rationality of the proposed simulation method.
C1 [Lv, Pei; Pei, Xinming; Ren, Xinyu; Zhang, Yuzhen; Li, Chaochao; Xu, Mingliang] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450001, Henan, Peoples R China.
C3 Zhengzhou University
RP Xu, ML (corresponding author), Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450001, Henan, Peoples R China.
EM ielvpei@zzu.edu.cn; kevinpeixinming@foxmail.com; renxinyu@gs.zzu.edu.cn;
   zyzzhang@gs.zzu.edu.cn; ieccli@zzu.edu.cn; iexumingliang@zzu.edu.cn
OI , Pei/0000-0002-2654-0561; Li, Chaochao/0000-0001-9694-832X; Pei,
   Xinming/0009-0001-3846-2986
FU Zhengzhou Major Science and Technology Project [2021KJZX0060]; National
   Natural Science Foundation of China [62036010]; Joint Fund of the
   Ministry of Education for Equipment Pre Research [8091B032257]
FX No Statement Available
CR [Anonymous], 2011, INTELLIGENT TRANSPOR
   Berseth Glen., 2014, Proceedings of the ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P113
   Bi H., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P149
   Bi HK, 2020, IEEE T VIS COMPUT GR, V26, P2335, DOI 10.1109/TVCG.2018.2889834
   Chao QW, 2023, IEEE T VIS COMPUT GR, V29, P1664, DOI 10.1109/TVCG.2021.3128286
   Chao QW, 2020, COMPUT GRAPH FORUM, V39, P287, DOI 10.1111/cgf.13803
   Chao QW, 2019, IEEE INT CONF ROBOT, P8298, DOI [10.1109/icra.2019.8794430, 10.1109/ICRA.2019.8794430]
   Chao QW, 2018, IEEE T VIS COMPUT GR, V24, P1167, DOI 10.1109/TVCG.2017.2648790
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Ettinger S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9690, DOI 10.1109/ICCV48922.2021.00957
   Guy S. J., 2011, P SCA ACM SIGGRAPH E, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Han Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1974
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Huang X, 2019, IEEE INT CONF ROBOT, P9718, DOI [10.1109/icra.2019.8794282, 10.1109/ICRA.2019.8794282]
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10
   Kesting A, 2008, TRANSPORT RES REC, P148, DOI 10.3141/2088-16
   Li WZ, 2019, IEEE INT CONF ROBOT, P7625, DOI [10.1109/icra.2019.8794239, 10.1109/ICRA.2019.8794239]
   Li WZ, 2018, IET INTELL TRANSP SY, V12, P875, DOI 10.1049/iet-its.2018.0007
   Li WZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130847
   Li WZ, 2017, IEEE INTEL TRANSP SY, V9, P100, DOI 10.1109/MITS.2017.2709804
   LIGHTHILL MJ, 1955, PROC R SOC LON SER-A, V229, P317, DOI 10.1098/rspa.1955.0089
   Lin L, 2022, IEEE INTEL TRANSP SY, V14, P197, DOI 10.1109/MITS.2021.3049404
   Lopez PA, 2018, IEEE INT C INTELL TR, P2575, DOI 10.1109/ITSC.2018.8569938
   Mao TL, 2015, COMPUT ANIMAT VIRT W, V26, P397, DOI 10.1002/cav.1642
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   NEWELL GF, 1961, OPER RES, V9, P209, DOI 10.1287/opre.9.2.209
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Park JH, 2013, COMPUT ANIMAT VIRT W, V24, P173, DOI 10.1002/cav.1504
   PIPES LA, 1953, J APPL PHYS, V24, P274, DOI 10.1063/1.1721265
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Sarkar A, 2017, IEEE INT C INTELL TR
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Shvetsov V, 1999, PHYS REV E, V59, P6328, DOI 10.1103/PhysRevE.59.6328
   Treiber M., 2001, Automatisierungstechnik, V49, P478, DOI 10.1524/auto.2001.49.11.478
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll W, 2021, COMPUT GRAPH FORUM, V40, P731, DOI 10.1111/cgf.142664
   Wang Y., 2014, Proceedings of the Symposium on Interactive 3D Graphics, P23
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Yang D, 2019, IEEE T INTELL TRANSP, V20, P1719, DOI 10.1109/TITS.2018.2834910
   Yang X, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1740
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
   Zhang YZ, 2022, LECT NOTES COMPUT SC, V13668, P522, DOI 10.1007/978-3-031-20074-8_30
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 53
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5750
EP 5764
DI 10.1109/TVCG.2023.3307882
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400088
PM 37610911
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Mavromatis, M
   Hoyet, L
   Lécuyer, A
   Dewez, D
   Argelaguet, F
AF Mavromatis, Mae
   Hoyet, Ludovic
   Lecuyer, Anatole
   Dewez, Diane
   Argelaguet, Ferran
TI To Stick or Not to Stick? Studying the Impact of Offset Recovery
   Techniques During Mid-Air Interactions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Avatars; Legged locomotion; Haptic interfaces; Springs;
   Delays; Behavioral sciences; Hand interactions; offset recovery; sticky
ID VISUAL INTERPENETRATION; AVATAR; SENSE; HAND; EMBODIMENT; APPEARANCE;
   PERCEPTION; DOMINANCE; EYE
AB During mid-air interactions, common approaches (such as the god-object method) typically rely on visually constraining the user's avatar to avoid visual interpenetrations with the virtual environment in the absence of kinesthetic feedback. This paper explores two methods which influence how the position mismatch (positional offset) between users' real and virtual hands is recovered when releasing the contact with virtual objects. The first method (sticky) constrains the user's virtual hand until the mismatch is recovered, while the second method (unsticky) employs an adaptive offset recovery method. In the first study, we explored the effect of positional offset and of motion alteration on users' behavioral adjustments and users' perception. In a second study, we evaluated variations in the sense of embodiment and the preference between the two control laws. Overall, both methods presented similar results in terms of performance and accuracy, yet, positional offsets strongly impacted motion profiles and users' performance. Both methods also resulted in comparable levels of embodiment. Finally, participants usually expressed strong preferences toward one of the two methods, but these choices were individual-specific and did not appear to be correlated solely with characteristics external to the individuals. Taken together, these results highlight the relevance of exploring the customization of motion control algorithms for avatars.
C1 [Mavromatis, Mae; Hoyet, Ludovic; Lecuyer, Anatole; Dewez, Diane; Argelaguet, Ferran] Univ Rennes, Inria, CNRS, IRISA, F-35042 Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   de Rennes
RP Mavromatis, M (corresponding author), Univ Rennes, Inria, CNRS, IRISA, F-35042 Rennes, France.
EM mae.mavromatis@inria.fr; ludovic.hoyet@inria.fr;
   anatole.lecuyer@inria.fr; diane.dewez@gmail.com;
   ferran.argelaguet@inria.fr
RI Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049; Lecuyer, Anatole/0000-0002-1409-244X
FU Region Bretagne and the Inria Avatar Challenge
FX This work was supported by the Region Bretagne and the Inria Avatar
   Challenge.
CR Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Burns E, 2006, PRESENCE-TELEOP VIRT, V15, P1, DOI 10.1162/pres.2006.15.1.1
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Burns E., 2007, Int. J. Vet. Res., V6, P11
   Burns F. P., 2006, P ACM S VIRT REAL SO, P3, DOI DOI 10.1145/1180495.1180499
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Clarence A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P150, DOI 10.1109/VR50410.2021.00036
   Dewez D, 2022, IEEE T VIS COMPUT GR, V28, P2047, DOI 10.1109/TVCG.2022.3150501
   Dewez L., 2021, P CHI C HUM FACT COM, P1
   Dominjon L, 2005, P IEEE VIRT REAL ANN, P19
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.00-38, 10.1109/VR46266.2020.1581285352835]
   Feuchtner T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P31, DOI 10.1145/3242587.3242594
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gloumeau PC, 2021, IEEE T VIS COMPUT GR, V27, P2488, DOI 10.1109/TVCG.2020.2987834
   Jáuregui DAG, 2014, IEEE T VIS COMPUT GR, V20, P654, DOI 10.1109/TVCG.2014.45
   Gonzalez EJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364248
   Hartfill J, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489866
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kohli L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P105, DOI 10.1109/3DUI.2012.6184193
   Kohm Kristopher., 2022, ACM Transactions on Applied Perception, V19, P1
   Koilias A, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020018
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Li JL, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P120, DOI 10.1145/3267782.3267797
   Li ZP, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3534590
   Lilija S., 2021, P IEEE VIRT REAL 3D, P1
   Lohse AL, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809587
   Mayer V., 2018, P CHI C HUM FACT COM, P1
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   MEYER DE, 1988, PSYCHOL REV, V95, P340, DOI 10.1037/0033-295X.95.3.340
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Pavlovych A, 2009, EICS'09: PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS, P187
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Porssut T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI [10.1109/vr.2019.8797716, 10.1109/VR.2019.8797716]
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Poupyrev I., 1996, Proceedings of the 9th Annual A CM Symposium on User Interface Software and Technology, P79, DOI DOI 10.1145/237091.237102
   Prachyabrued M., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P59, DOI 10.1109/3DUI.2011.5759218
   Prachyabrued M, 2016, IEEE T VIS COMPUT GR, V22, P1718, DOI 10.1109/TVCG.2015.2456917
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Razzaque S., 2005, Redirected walking
   Sait MSMY, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P64, DOI 10.1145/3191801.3191814
   Samad E., 2019, P CHI C HUM FACT COM, P1
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Toothman N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P756, DOI [10.1109/vr.2019.8798108, 10.1109/VR.2019.8798108]
   Vizcay S., 2021, P INT C ART REAL TEL
   Wegner DM, 1999, AM PSYCHOL, V54, P480, DOI 10.1037/0003-066X.54.7.480
   Wen W, 2019, CONSCIOUS COGN, V73, DOI 10.1016/j.concog.2019.05.007
   Wen W, 2015, CONSCIOUS COGN, V36, P87, DOI 10.1016/j.concog.2015.06.004
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Zenner A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P75, DOI 10.1109/VR50410.2021.00028
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
NR 57
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5493
EP 5506
DI 10.1109/TVCG.2023.3295209
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400015
PM 37440385
OA Green Published
DA 2024-08-05
ER

PT J
AU Bouzbib, E
   Teyssier, M
   Howard, T
   Pacchierotti, C
   Lecuyer, A
AF Bouzbib, Elodie
   Teyssier, Marc
   Howard, Thomas
   Pacchierotti, Claudio
   Lecuyer, Anatole
TI PalmEx: Adding Palmar Force-Feedback for 3D Manipulation With Haptic
   Exoskeleton Gloves
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Exoskeletons; Haptic interfaces; Three-dimensional displays; Taxonomy;
   Training; Wearable computers; Avatars; Artefact; encountered-type of
   haptic device; ETHD; exoskeleton; haptics; on-demand; virtual reality
AB Haptic exoskeleton gloves are a widespread solution for providing force-feedback in Virtual Reality (VR), especially for 3D object manipulations. However, they are still lacking an important feature regarding in-hand haptic sensations: the palmar contact. In this paper, we present PalmEx, a novel approach which incorporates palmar force-feedback into exoskeleton gloves to improve the overall grasping sensations and manual haptic interactions in VR. PalmEx's concept is demonstrated through a self-contained hardware system augmenting a hand exoskeleton with an encountered palmar contact interface - physically encountering the users' palm. We build upon current taxonomies to elicit PalmEx's capabilities for both the exploration and manipulation of virtual objects. We first conduct a technical evaluation optimising the delay between the virtual interactions and their physical counterparts. We then empirically evaluate PalmEx's proposed design space in a user study (n=12) to assess the potential of a palmar contact for augmenting an exoskeleton. Results show that PalmEx offers the best rendering capabilities to perform believable grasps in VR. PalmEx highlights the importance of the palmar stimulation, and provides a low-cost solution to augment existing high-end consumer hand exoskeletons.
C1 [Bouzbib, Elodie; Howard, Thomas; Pacchierotti, Claudio; Lecuyer, Anatole] Univ Rennes, Inria, CNRS, IRISA Rennes, F-35000 Rennes, France.
   [Teyssier, Marc] Leonard Vinci Pole Univ, Res Ctr Paris Def, F-92400 Courbevoie, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   de Rennes
RP Bouzbib, E (corresponding author), Univ Rennes, Inria, CNRS, IRISA Rennes, F-35000 Rennes, France.
EM elo.bouzbib@gmail.com; marc.teyssier@devinci.fr; thomas.howard@irisa.fr;
   claudio.pacchierotti@irisa.fr; anatole.lecuyer@inria.fr
RI Pacchierotti, Claudio/G-7304-2011
OI Pacchierotti, Claudio/0000-0002-8006-9168; Howard,
   Thomas/0000-0003-4904-375X; Bouzbib, Elodie/0000-0002-5221-2991;
   Teyssier, Marc/0000-0003-2950-7545
FU Inria (Associated Teams programme)
FX This work was supported by Inria (Associated Teams programme).
CR Achibet M, 2015, P IEEE VIRT REAL ANN, P63, DOI 10.1109/VR.2015.7223325
   Aggravi Marco, 2018, IEEE Robotics and Automation Letters, V3, P2166, DOI 10.1109/LRA.2018.2810887
   Blake J, 2009, IEEE-ASME T MECH, V14, P606, DOI 10.1109/TMECH.2008.2010934
   Bouzbib E., 2022, P IEEE C VIRT REAL 3, P1
   Bouzbib E., 2021, P 32 C FRANC INT HOM, DOI [10.1145/3450522.3451323, DOI 10.1145/3450522.3451323]
   Bouzit M, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P145, DOI 10.1109/HAPTIC.2002.998952
   Bratt M, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2716
   Bryson S., 2005, The Visualization Handbook, P413, DOI DOI 10.1016/B978-012387582-2/50023-X
   Choi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P986, DOI 10.1109/IROS.2016.7759169
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   CUTKOSKY MR, 1990, DEXTROUS ROBOT HANDS, P5
   Dragusanu M, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.706627
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   Feix T, 2016, IEEE T HUM-MACH SYST, V46, P66, DOI 10.1109/THMS.2015.2470657
   Gonzalez Eric J., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P732, DOI 10.1145/3472749.3474782
   Kovacs Robert, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1046, DOI 10.1145/3379337.3415854
   Lawrence D. A., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P441
   Lopes P, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P11, DOI 10.1145/2807442.2807443
   Minamizawa K, 2008, LECT NOTES COMPUT SC, V5024, P458, DOI 10.1007/978-3-540-69057-3_59
   Moon HS, 2023, INT J HUM-COMPUT INT, V39, P2840, DOI 10.1080/10447318.2022.2087000
   Nith R., 2021, The 34th annual ACM symposium on user interface software and technology, P414, DOI 10.1145/3472749.3474759
   Salvato M, 2022, IEEE ROBOT AUTOM LET, V7, P3851, DOI 10.1109/LRA.2022.3148458
   Son B, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P757, DOI 10.1145/3242587.3242656
   Son B, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P486, DOI 10.1145/3242969.3243030
   Steed A, 2020, Arxiv, DOI arXiv:2002.06093
   Teng SY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P5, DOI 10.1145/3242587.3242628
   Teyssier M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P307, DOI 10.1145/3332165.3347943
   Tinguy Xavier, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P262, DOI 10.1007/978-3-030-58147-3_29
   Trinitatova D, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P42, DOI 10.1145/3355355.3361896
   Yoshida S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376358
NR 30
TC 1
Z9 1
U1 10
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3973
EP 3980
DI 10.1109/TVCG.2023.3244076
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700061
PM 37022896
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Choi, J
   Oh, HJ
   Lee, H
   Kim, S
   Kwon, SK
   Jeong, WK
AF Choi, JunYoung
   Oh, Hyun-Jic
   Lee, Hakjun
   Kim, Suyeon
   Kwon, Seok-Kyu
   Jeong, Won-Ki
TI MitoVis: A Unified Visual Analytics System for End-to-End Neuronal
   Mitochondria Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Morphology; Neurons; Microscopy; Dendrites
   (neurons); Deep learning; Axons; Biomedical and medical visualization;
   machine learning; task and requirements analysis; user interfaces;
   intelligence analysis
ID VISUALIZATION; FISSION
AB Neurons have a polarized structure, with dendrites and axons, and compartment-specific functions can be affected by the dwelling mitochondria. Recent studies have shown that the morphology of mitochondria is closely related to the functions of neurons and neurodegenerative diseases. However, the conventional mitochondria analysis workflow mainly relies on manual annotations and generic image-processing software. Moreover, even though there have been recent developments in automatic mitochondria analysis using deep learning, the application of existing methods in a daily analysis remains challenging because the performance of a pretrained deep learning model can vary depending on the target data, and there are always errors in inference time, requiring human proofreading. To address these issues, we introduce MitoVis, a novel visualization system for end-to-end data processing and an interactive analysis of the morphology of neuronal mitochondria. MitoVis introduces a novel active learning framework based on recent contrastive learning, which allows accurate fine-tuning of the neural network model. MitoVis also provides novel visual guides for interactive proofreading so that users can quickly identify and correct errors in the result with minimal effort. We demonstrate the usefulness and efficacy of the system via case studies conducted by neuroscientists. The results show that MitoVis achieved up to 13.3x faster total analysis time in the case study compared to the conventional manual analysis workflow.
C1 [Choi, JunYoung; Oh, Hyun-Jic; Lee, Hakjun; Jeong, Won-Ki] Korea Univ, Dept Comp Sci & Engn, Seoul 02841, South Korea.
   [Kim, Suyeon; Kwon, Seok-Kyu] Korea Inst Sci & Technol, Brain Sci Inst, Seoul 02792, South Korea.
C3 Korea University; Korea Institute of Science & Technology (KIST)
RP Jeong, WK (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul 02841, South Korea.
EM juny0603@gmail.com; hyunjic0127@korea.ac.kr; hjlee0413@korea.ac.kr;
   imas3104@kist.re.kr; skkwon@kist.re.kr; wkjeong@korea.ac.kr
OI , hjoh/0000-0002-4599-151X
FU Bio & Medical Technology Development Program of the National Research
   Foundation of Korea (NRF) - Ministry of Science and ICT (MSIT)
   [NRF-2019M3E5D2A01063819, NRF-2019M3E5D2A01063794]; Basic Science
   Research Program through the NRF - Ministry of Education
   [NRF-2021R1A6A1A13044830]; Korea Health Technology R&D Project through
   the Korea Health Industry Development Institute (KHIDI) - Ministry of
   Health Welfare [HI18C0316]; ICT Creative Consilience program of the
   Institute for Information & communications Technology Planning&
   Evaluation (IITP) - MSIT [IITP-2023-2020-0-01819]; Korea Institute of
   Science and Technology (KIST) Institutional Program, Republic of Korea
   [2E31511]; Korea University Grant
FX This work was supported in part by the Bio & Medical Technology
   Development Program of the National Research Foundation of Korea
   (NRF)funded by the Ministry of Science and ICT (MSIT) under Grants
   NRF-2019M3E5D2A01063819 and NRF-2019M3E5D2A01063794, in part by the
   Basic Science Research Program through the NRF funded by the Ministry of
   Education under Grant NRF-2021R1A6A1A13044830, in part by a grant from
   the Korea Health Technology R&D Project through the Korea Health
   Industry Development Institute (KHIDI) funded by the Ministry of Health
   & Welfare under Grant HI18C0316, in part by the ICT Creative Consilience
   program under Grant IITP-2023-2020-0-01819 of the Institute for
   Information & communications Technology Planning& Evaluation (IITP)
   funded by MSIT, in part by the Korea Institute of Science and Technology
   (KIST) Institutional Program, Republic of Korea under Grant 2E31511, and
   in part by a Korea University Grant.
CR Agus M, 2019, COMPUT GRAPH FORUM, V38, P427, DOI 10.1111/cgf.13700
   Baek SH, 2017, J NEUROSCI, V37, P5099, DOI 10.1523/JNEUROSCI.2385-16.2017
   Bäuerle A, 2020, COMPUT GRAPH FORUM, V39, P195, DOI 10.1111/cgf.13973
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bernard J, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13406
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Bido F. N., 2017, Sci. Rep., V7, P1
   Boorboor S, 2019, IEEE T VIS COMPUT GR, V25, P1018, DOI 10.1109/TVCG.2018.2864852
   Bria A, 2015, I S BIOMED IMAGING, P520, DOI 10.1109/ISBI.2015.7163925
   Bro R, 2014, ANAL METHODS-UK, V6, P2812, DOI 10.1039/c3ay41907j
   Budd S, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102062
   Cho S, 2021, I S BIOMED IMAGING, P761, DOI 10.1109/ISBI48211.2021.9434105
   Du H, 2010, P NATL ACAD SCI USA, V107, P18670, DOI 10.1073/pnas.1006586107
   Fecher C, 2019, NAT NEUROSCI, V22, P1731, DOI 10.1038/s41593-019-0479-z
   Feng LQ, 2015, ENEURO, V2, DOI 10.1523/ENEURO.0049-14.2014
   Fischer CA, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101601
   Fogo GM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84528-8
   Ghahremani P, 2022, IEEE T VIS COMPUT GR, V28, P4951, DOI 10.1109/TVCG.2021.3109460
   Guo BH, 2020, NEUROBIOL AGING, V96, P223, DOI 10.1016/j.neurobiolaging.2020.09.011
   Hu HZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16271, DOI 10.1109/ICCV48922.2021.01598
   Jadhav S, 2019, IEEE T VIS COMPUT GR, V25, P2725, DOI 10.1109/TVCG.2018.2856744
   Jeong WK, 2010, IEEE COMPUT GRAPH, V30, P58, DOI 10.1109/MCG.2010.56
   Jun Young Choi, 2022, 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P604, DOI 10.1109/VRW55335.2022.00153
   Karimov A, 2015, COMPUT GRAPH FORUM, V34, P91, DOI 10.1111/cgf.12621
   Khosla P., 2020, Adv. Neural Inf. Process. Syst, P18661, DOI DOI 10.48550/ARXIV.2004.11362
   Kim GH, 2020, MOL BRAIN, V13, DOI 10.1186/s13041-020-00668-4
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Lamprecht MR, 2007, BIOTECHNIQUES, V42, P71, DOI 10.2144/000112257
   Lee A, 2018, CURR OPIN PHYSIOL, V3, P82, DOI 10.1016/j.cophys.2018.03.009
   Lekschas F, 2020, IEEE T VIS COMPUT GR, V26, P611, DOI 10.1109/TVCG.2019.2934555
   Lewis TL, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07416-2
   Lihavainen E, 2012, BIOINFORMATICS, V28, P1050, DOI 10.1093/bioinformatics/bts073
   Lin Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P399, DOI 10.1007/978-3-319-66179-7_46
   Liu YJ, 2020, MECH AGEING DEV, V186, DOI 10.1016/j.mad.2020.111212
   Magliaro C, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00036
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Merrill RA, 2017, NEUROMETHODS, V123, P31, DOI 10.1007/978-1-4939-6890-9_2
   Microsoft HoloLens, About us
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Ozdemir F, 2018, LECT NOTES COMPUT SC, V11045, P183, DOI 10.1007/978-3-030-00889-5_21
   Park C, 2021, I S BIOMED IMAGING, P1466, DOI 10.1109/ISBI48211.2021.9434102
   Paszke A, 2019, Arxiv, DOI [arXiv:1912.01703, DOI 10.48550/ARXIV.1912.01703, 10.48550/ARXIV.1912.01703]
   Peng HC, 2014, NAT PROTOC, V9, P193, DOI 10.1038/nprot.2014.011
   Pfister Hanspeter., 2014, Scientific Visualization, P221
   Popov V, 2005, J COMP NEUROL, V492, P50, DOI 10.1002/cne.20682
   Prism, About us
   R Core Team, 2023, A language and environment for statistical computing
   Ramonet D, 2013, CELL DEATH DIFFER, V20, P77, DOI 10.1038/cdd.2012.95
   Rangaraju V, 2019, J NEUROSCI, V39, P8200, DOI 10.1523/JNEUROSCI.1157-19.2019
   Rangaraju V, 2019, CELL, V176, P73, DOI 10.1016/j.cell.2018.12.013
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saalfeld S, 2009, BIOINFORMATICS, V25, P1984, DOI 10.1093/bioinformatics/btp266
   Schon EA, 2011, NEURON, V70, P1033, DOI 10.1016/j.neuron.2011.06.003
   Smailagic A, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P481, DOI 10.1109/ICMLA.2018.00078
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Toyama EQ, 2016, SCIENCE, V351, P275, DOI 10.1126/science.aab4138
   Varkuti BH, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaw8702
   Wan Y, 2012, IEEE PAC VIS SYMP, P201, DOI 10.1109/PacificVis.2012.6183592
   Wang WG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7283, DOI 10.1109/ICCV48922.2021.00721
   Wang XL, 2009, J NEUROSCI, V29, P9090, DOI 10.1523/JNEUROSCI.1357-09.2009
   Wiemerslage L, 2016, J NEUROSCI METH, V262, P56, DOI 10.1016/j.jneumeth.2016.01.008
   Wu YK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118482
   Zahedi A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34455-y
   Zeng HK, 2017, NAT REV NEUROSCI, V18, P530, DOI 10.1038/nrn.2017.85
   Zhou H, 2021, NEUROINFORMATICS, V19, P305, DOI 10.1007/s12021-020-09484-6
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
NR 68
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3457
EP 3473
DI 10.1109/TVCG.2022.3233548
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700077
DA 2024-08-05
ER

PT J
AU Dong, QJ
   Wang, ZX
   Li, MY
   Gao, JJ
   Chen, SM
   Shu, ZY
   Xin, SQ
   Tu, CH
   Wang, WP
AF Dong, Qiujie
   Wang, Zixiong
   Li, Manyi
   Gao, Junjie
   Chen, Shuangmin
   Shu, Zhenyu
   Xin, Shiqing
   Tu, Changhe
   Wang, Wenping
TI Laplacian2Mesh: Laplacian-Based Mesh Understanding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Task analysis; Convolution; Laplace equations; Three-dimensional
   displays; Deep learning; Kernel; Geometric deep learning; laplacian
   pooling; laplacian-beltrami space; mesh understanding
ID SHAPE; DESCRIPTORS
AB Geometric deep learning has sparked a rising interest in computer graphics to perform shape understanding tasks, such as shape classification and semantic segmentation. When the input is a polygonal surface, one has to suffer from the irregular mesh structure. Motivated by the geometric spectral theory, we introduce Laplacian2Mesh, a novel and flexible convolutional neural network (CNN) framework for coping with irregular triangle meshes (vertices may have any valence). By mapping the input mesh surface to the multi-dimensional Laplacian-Beltrami space, Laplacian2Mesh enables one to perform shape analysis tasks directly using the mature CNNs, without the need to deal with the irregular connectivity of the mesh structure. We further define a mesh pooling operation such that the receptive field of the network can be expanded while retaining the original vertex set as well as the connections between them. Besides, we introduce a channel-wise self-attention block to learn the individual importance of feature ingredients. Laplacian2Mesh not only decouples the geometry from the irregular connectivity of the mesh structure but also better captures the global features that are central to shape classification and segmentation. Extensive tests on various datasets demonstrate the effectiveness and efficiency of Laplacian2Mesh, particularly in terms of the capability of being vulnerable to noise to fulfill various learning tasks.
C1 [Dong, Qiujie; Wang, Zixiong; Gao, Junjie; Xin, Shiqing; Tu, Changhe] Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Shandong, Peoples R China.
   [Li, Manyi] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
   [Chen, Shuangmin] Qingdao Univ Sci & Technol, Sch Informat & Technol, Qingdao 266061, Shandong, Peoples R China.
   [Shu, Zhenyu] Zhejiang Univ, Ningbo Inst Technol, Sch Comp & Data Engn, Ningbo 315100, Zhejiang, Peoples R China.
   [Wang, Wenping] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.
C3 Shandong University; Shandong University; Qingdao University of Science
   & Technology; Zhejiang University; Texas A&M University System; Texas
   A&M University College Station
RP Xin, SQ (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Shandong, Peoples R China.
EM qiujie.jay.dong@gmail.com; zixiong_wang@outlook.com; manyili@sdu.edu.cn;
   gjjsdnu@163.com; csmqq@163.com; shuzhenyu@nit.zju.edu.cn;
   xinshiqing@sdu.edu.cn; chtu@sdu.edu.cn; wenping@cs.hku.hk
RI junjie, gao/AFW-1181-2022; Gao, Junjie/F-7601-2012; Tu,
   Changhe/H-5162-2013
OI Xin, Shiqing/0000-0001-8452-8723; Wang, Zixiong/0000-0002-6170-7339;
   shu, zhenyu/0000-0001-5733-6638; Dong, Qiujie/0000-0001-6271-2546
FU National Key R&D Program of China [2021YFB1715900]; National Natural
   Science Foundation of China [62002190, 62272277, 62172356, 62072284];
   Natural Science Foundation of Shandong Province [ZR2020MF036]; Zhejiang
   Provincial Natural Science Foundation of China [LY22F020026];
   Fundamental Research Funds of Shandong University
FX This work is supported by National Key R&D Program of China under Grant
   2021YFB1715900, in part by the National Natural Science Foundation of
   China under Grants 62002190, 62272277, 62172356, and 62072284, in part
   by the Natural Science Foundation of Shandong Province under Grant
   ZR2020MF036, and in part by the Zhejiang Provincial Natural Science
   Foundation of China under Grant LY22F020026 and the Fundamental Research
   Funds of Shandong University.
CR Adobe, 2006, Adobe fuse 3D characters
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boscaini D, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12693
   Brock A, 2016, Arxiv, DOI arXiv:1608.04236
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bronstein MM, 2011, IEEE T PATTERN ANAL, V33, P1065, DOI 10.1109/TPAMI.2010.210
   Bruna J., 2014, ABS13126203 CORR, P1, DOI DOI 10.48550/ARXIV.1312.6203
   Clevert DA, 2016, Arxiv, DOI [arXiv:1511.07289, DOI 10.48550/ARXIV.1511.07289]
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Defferrard M, 2016, ADV NEUR IN, V29
   Ezuz D, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13244
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Fey M, 2018, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2018.00097
   Giorgi D., 2007, SHREC Competition, V8, P7
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Haim N, 2019, IEEE I CONF COMP VIS, P632, DOI 10.1109/ICCV.2019.00072
   Hanocka H.-T. D., 2021, ACM SIGGRAPH 2021 CO, P1
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3267347
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   He WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2214, DOI 10.1145/3394486.3403272
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu SM, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3506694
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lahav A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417806
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Le T, 2017, COMPUT GRAPH-UK, V66, P103, DOI 10.1016/j.cag.2017.05.011
   Levy H., 2010, ACM SIGGRAPH COURS, P1
   Li R., 2018, INT C NEURAL INF PRO, V31
   Lian Z., 2011, P 3DOR EUR
   Litman R, 2014, IEEE T PATTERN ANAL, V36, P171, DOI 10.1109/TPAMI.2013.148
   Liu SL, 2021, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR46437.2021.00183
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Bronstein MMM, 2021, Arxiv, DOI [arXiv:2104.13478, DOI 10.48550/ARXIV.2104.13478]
   Maron H., 2017, ACM Trans. Graph, V36, P1
   Masci Jonathan, 2015, P IEEE INT C COMPUTE, P37
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Milano F, 2020, Arxiv, DOI arXiv:2010.12455
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Pinkall U., 1993, Exp. Math, P15, DOI [DOI 10.1080/10586458.1993.10504266, 10.1080/10586458.1993.10504266]
   Qi CR, 2017, ADV NEUR IN, V30
   Qiao YL, 2022, IEEE T VIS COMPUT GR, V28, P1317, DOI 10.1109/TVCG.2020.3014449
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rustamov R.M., 2007, P 5 EUR S GEOM PROC, V257, P225, DOI DOI 10.2312/SGP/SGP07/225-233
   Schonsheck S. C., 2018, arXiv
   Schult Jonas, 2020, P IEEE CVF C COMP VI, P8612, DOI DOI 10.1109/CVPR42600.2020.00864
   Sharp N, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3507905
   Sharp N, 2020, COMPUT GRAPH FORUM, V39, P69, DOI 10.1111/cgf.14069
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Smirnov D, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459797
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang PS, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275050
   WANG PS, 2017, TOG, V36, DOI DOI 10.1145/3072959.3073608
   Wang Y, 2019, HANDB NUM ANAL, V20, P41, DOI 10.1016/bs.hna.2019.08.003
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Xu M., 2017, IEEE INT C COMPUT VI, P2698
NR 70
TC 8
Z9 8
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4349
EP 4361
DI 10.1109/TVCG.2023.3259044
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700082
PM 37030768
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Boban, L
   Boulic, R
   Herbelin, B
AF Boban, Loen
   Boulic, Ronan
   Herbelin, Bruno
TI In Case of Doubt, One Follows One's Self: The Implicit Guidance of the
   Embodied Self-Avatar
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Distortion; Motors; Behavioral sciences; Task analysis;
   Visualization; Rubber; Virtual Reality; virtual embodiment; sense of
   body ownership; sense of agency; self-avatar follower effect
ID SENSE; BODY; MOVEMENT
AB The sense of embodiment in virtual reality (VR) is commonly understood as the subjective experience that one's physical body is substituted by a virtual counterpart, and is typically achieved when the avatar's body, seen from a first-person view, moves like one's physical body. Embodiment can also be experienced in other circumstances (e.g., in third-person view) or with imprecise or distorted visuo-motor coupling. It was moreover observed, in various cases of small or progressive temporal and spatial manipulations of avatars' movements, that participants may spontaneously follow the movement shown by the avatar. The present work investigates whether, in some specific contexts, participants would follow what their avatar does even when large movement discrepancies occur, thereby extending the scope of understanding of the self-avatar follower effect beyond subtle changes of motion or speed manipulations. We conducted an experimental study in which we introduced uncertainty about which movement to perform at specific times and analyzed participants' movements and subjective feedback after their avatar showed them an incorrect movement. Results show that, when in doubt, participants were influenced by their avatar's movements, leading them to perform that particular error twice more often than normal. Importantly, results of the embodiment score indicate that participants experienced a dissociation with their avatar at those times. Overall, these observations not only demonstrate the possibility of provoking situations in which participants follow the guidance of their avatar for large motor distortions, despite their awareness about the avatar movement disruption and on the possible influence it had on their choice, and, importantly, exemplify how the cognitive mechanism of embodiment is deeply rooted in the necessity of having a body.
C1 [Boban, Loen; Boulic, Ronan; Herbelin, Bruno] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Boban, L (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM loen.boban@epfl.ch; ronan.boulic@epfl.ch; bruno.herbelin@epfl.ch
OI Boban, Loen/0000-0001-6835-0056
FU Fonds National Suisse de la Recherche Scientifique
FX No Statement Available
CR Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Asai T, 2015, EXP BRAIN RES, V233, P777, DOI 10.1007/s00221-014-4153-0
   Atkinson R. C., 1968, The psychology of learning and motivation, V1st, P89, DOI [10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3]
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Blanke O, 2015, NEURON, V88, P145, DOI 10.1016/j.neuron.2015.09.029
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Boban L, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1073549
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Burin D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209899
   Cheymol A., 2023, IEEE Transactions on Visualizationand Computer Graphics, V1
   Cohn BA, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P74, DOI 10.1109/AIVR50618.2020.00024
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2018, COMPUT GRAPH-UK, V76, P142, DOI 10.1016/j.cag.2018.09.001
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Delahaye M, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0266212
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Haggard P, 2012, CURR BIOL, V22, pR390, DOI 10.1016/j.cub.2012.02.040
   Herbelin R., 2016, Technical report, V1
   Kalckert A, 2014, CONSCIOUS COGN, V30, P118, DOI 10.1016/j.concog.2014.08.022
   Kasahara S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6438, DOI 10.1145/3025453.3025962
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Lanillos P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02200-7
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Maselli A, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010095
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Pavone EF, 2016, J NEUROSCI, V36, P268, DOI 10.1523/JNEUROSCI.0494-15.2016
   Porssut T, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0282967
   Porssut T, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0255554
   Porssut T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI [10.1109/vr.2019.8797716, 10.1109/VR.2019.8797716]
   Porssut Y., 2021, IEEE Transactionson Visualization and Computer Graphics, V28, P3193
   Rietzler F., 2017, INPROCEEDINGS 23 ACM, P1, DOI [10.1145/3139131.31391451,2[44]N, DOI 10.1145/3139131.31391451,2[44]N]
   Sajid N, 2021, NEURAL COMPUT, V33, P674, DOI 10.1162/neco_a_01357
   Salomon R, 2016, SCI REP-UK, V6, DOI 10.1038/srep25847
   SMYTH MM, 1988, Q J EXP PSYCHOL-A, V40, P497, DOI 10.1080/02724988843000041
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Wachowicz F, 2011, DANCE RES, V29, P450, DOI 10.3366/drs.2011.0028
NR 47
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2109
EP 2118
DI 10.1109/TVCG.2024.3372042
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400008
PM 38437112
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Lee, Y
   Shin, H
   Gil, YH
AF Lee, Yongho
   Shin, Heesook
   Gil, Youn-Hee
TI Measurement of Empathy in Virtual Reality with Head-Mounted Displays: A
   Systematic Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; empathy; measurement; systematic review
ID COGNITIVE EMPATHY; ASPERGER-SYNDROME; STATE EMPATHY; SCALE;
   QUESTIONNAIRE; VALIDATION; DISTRESS; SYMPATHY; STUDENTS; BEHAVIOR
AB We present a systematic review of 111 papers that measure the impact of virtual experiences created through head-mounted displays (HMDs) on empathy. Our goal was to analyze the conditions and the extent to which virtual reality (VR) enhances empathy. To achieve this, we categorized the relevant literature according to measurement methods, correlated human factors, viewing experiences, topics, and participants. Meta-analysis was performed based on categorized themes, and under specified conditions, we found that VR can improve empathy. Emotional empathy increased temporarily after the VR experience and returned to its original level over time, whereas cognitive empathy remained enhanced. Furthermore, while VR did not surpass 2D video in improving emotional empathy, it did enhance cognitive empathy, which is associated with embodiment. Our results are consistent with existing research suggesting differentiation between cognitive empathy (influenced by environmental factors and learnable) and emotional empathy (highly heritable and less variable). Interactivity, target of empathy, and point of view were not found to significantly affect empathy, but participants' age and nationality were found to influence empathy levels. It can be concluded that VR enhances cognitive empathy by immersing individuals in the perspective of others and that storytelling and personal characteristics are more important than the composition of the VR scene. Our findings provide guiding information for creating empathy content in VR and designing experiments to measure empathy.
C1 [Lee, Yongho; Shin, Heesook; Gil, Youn-Hee] Elect & Telecommun Res Inst, Daejeon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Lee, Y (corresponding author), Elect & Telecommun Res Inst, Daejeon, South Korea.
EM jason0720@etri.re.kr; hsshin8@etri.re.kr; yhgil@etri.re.kr
OI Lee, Yongho/0009-0002-9511-992X
FU Electronics and Telecommunications Research Institute
FX No Statement Available
CR Aan Het Rot M, 2014, BRIT J PSYCHOL, V105, P173, DOI 10.1111/bjop.12029
   Abramson L, 2020, NEUROSCI BIOBEHAV R, V114, P113, DOI 10.1016/j.neubiorev.2020.03.023
   Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Ayache J, 2024, PERS INDIV DIFFER, V219, DOI 10.1016/j.paid.2023.112478
   Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Barreda-Angeles M, 2020, CYBERPSYCH BEH SOC N, V23, P683, DOI 10.1089/cyber.2019.0665
   BATSON CD, 1987, J PERS, V55, P19, DOI 10.1111/j.1467-6494.1987.tb00426.x
   Bernhardt BC, 2012, ANNU REV NEUROSCI, V35, P1, DOI 10.1146/annurev-neuro-062111-150536
   Bevan C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300736
   Blythe J, 2021, PEOPLE NAT, V3, P1284, DOI 10.1002/pan3.10253
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brooks C., 1959, Understanding fiction, P3
   BRYANT BK, 1982, CHILD DEV, V53, P413, DOI 10.1111/j.1467-8624.1982.tb01331.x
   Bucchioni G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125871
   Cao BL, 2015, COMPUT HUM BEHAV, V52, P458, DOI 10.1016/j.chb.2015.06.009
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chopik WJ, 2017, J CROSS CULT PSYCHOL, V48, P23, DOI 10.1177/0022022116673910
   Christofi M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01242
   Christov-Moore L, 2014, NEUROSCI BIOBEHAV R, V46, P604, DOI 10.1016/j.neubiorev.2014.09.001
   Collins K, 2017, J APPL RES INTELLECT, V30, P133, DOI 10.1111/jar.12226
   Curran MT, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300844
   D'Errico F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041196
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Du HY, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P687, DOI 10.1109/VRW58643.2023.00186
   EISENBERG N, 1989, J PERS SOC PSYCHOL, V57, P55, DOI 10.1037/0022-3514.57.1.55
   Eisenberg N, 2005, J RES ADOLESCENCE, V15, P235, DOI 10.1111/j.1532-7795.2005.00095.x
   Ekman P., 2007, Emotions revealed: Recognizing faces and feelings to improve communication and emotional life, P3
   Eres R, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00176
   Escalas JE, 2003, J CONSUM RES, V29, P566, DOI 10.1086/346251
   Fernandez-Pinto i, 2008, Tesi de empatia cognitiva y afectiva, P3
   Formosa NJ, 2018, AUST J PSYCHOL, V70, P57, DOI 10.1111/ajpy.12167
   Francis KB, 2018, BRIT J PSYCHOL, V109, P442, DOI 10.1111/bjop.12276
   Gardhouse K., 2013, CAMBRIDGE HDB HUMAN, P57, DOI DOI 10.1017/CBO9780511843716.005
   Hamilton-Giachritsis C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21036-2
   Harrer M., 2021, Doing meta-analysis with R: A hands-on guide, P9
   Hedges LV, 2004, PSYCHOL METHODS, V9, P426, DOI 10.1037/1082-989X.9.4.426
   Hojat M., 2007, Empathy in patient care: antecedents, development, measurement, and outcomes, V77
   Howard MC, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103707
   Iacoboni M, 2009, ANNU REV PSYCHOL, V60, P653, DOI 10.1146/annurev.psych.60.110707.163604
   Ingram KM, 2019, J ADOLESCENCE, V71, P72, DOI 10.1016/j.adolescence.2018.12.006
   Jacob ME, 2016, HAND CLINIC, V138, P3, DOI 10.1016/B978-0-12-802973-2.00001-X
   Jicol C, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502129
   Jolliffe D, 2006, J ADOLESCENCE, V29, P589, DOI 10.1016/j.adolescence.2005.08.010
   Käthner I, 2022, BRIT J HEALTH PSYCH, V27, P434, DOI 10.1111/bjhp.12553
   Kamas L, 2021, J BEHAV EXP ECON, V92, DOI 10.1016/j.socec.2020.101654
   Kim J, 2020, BMC PSYCHOL, V8, DOI 10.1186/s40359-020-00418-0
   Konrath SH, 2011, PERS SOC PSYCHOL REV, V15, P180, DOI 10.1177/1088868310377395
   KREHBIEL T.C., 2004, DECISION SCI J INNOV, V2, P97, DOI [10.1111/j.0011-7315.2004.00025.x, DOI 10.1111/J.0011-7315.2004.00025.X]
   Krznaric R., 2015, TarcherPerigee, P1
   Lam T. C. M., 2011, Journal of MultidisciplinaryEvaluation, V7, P1
   Lambe I.. J., 2022, International Journal of Bullying Prevention, P1
   Lamm C, 2015, NEUROSCI RES, V90, P15, DOI 10.1016/j.neures.2014.10.008
   Lee HM, 2023, INT J HUM-COMPUT ST, V176, DOI 10.1016/j.ijhcs.2023.103042
   Lenzner T, 2012, FIELD METHOD, V24, P409, DOI 10.1177/1525822X12448166
   Levett-Jones T, 2017, NURS EDUC TODAY, V59, P75, DOI 10.1016/j.nedt.2017.09.007
   Lima FFD, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.781346
   Martingano A. J., 2021, Technology, Mind, and Behavior, V1
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   Meta, 2023, Get teens started with parental supervision
   Michaels TM, 2014, PSYCHIAT RES, V220, P803, DOI 10.1016/j.psychres.2014.08.054
   Milk Chris., 2015, Ted Talk
   Morse J M, 1992, Image J Nurs Sch, V24, P273
   Muravevskaia Ekaterina, 2023, International Journal of Child-Computer Interaction, DOI 10.1016/j.ijcci.2022.100561
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   O'Brien E, 2013, J GERONTOL B-PSYCHOL, V68, P168, DOI 10.1093/geronb/gbs055
   Paananen V., 2022, arXiv
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1136/bmj.n160]
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Pommier E. A., 2010, doctoral dissertation, P3
   Pressgrove G, 2020, INT J NONPROFIT VOLU, DOI 10.1002/nvsm.1689
   Raz G, 2020, NEUROIMAGE, V207, DOI 10.1016/j.neuroimage.2019.116351
   Reid C, 2013, BRIT J DEV PSYCHOL, V31, P231, DOI 10.1111/bjdp.12002
   Reniers RLEP, 2011, J PERS ASSESS, V93, P84, DOI 10.1080/00223891.2010.528484
   Rueda J, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.506984
   Salminen M, 2022, IEEE T AFFECT COMPUT, V13, P746, DOI 10.1109/TAFFC.2019.2958657
   Sassenrath C, 2020, SOC PSYCHOL PERS SCI, V11, P752, DOI 10.1177/1948550619884566
   Schulte-Rüther M, 2008, NEUROIMAGE, V42, P393, DOI 10.1016/j.neuroimage.2008.04.180
   Shen LJ, 2010, WESTERN J COMM, V74, P504, DOI 10.1080/10570314.2010.512278
   Spreng RN, 2009, J PERS ASSESS, V91, P62, DOI 10.1080/00223890802484381
   Stargatt J, 2021, J ALZHEIMERS DIS, V84, P1247, DOI 10.3233/JAD-210723
   Stavroulia KE, 2023, COMPUT EDUC, V197, DOI 10.1016/j.compedu.2023.104739
   Stevens F, 2021, NEUROPSYCHOLOGIA, V159, DOI 10.1016/j.neuropsychologia.2021.107925
   Thériault R, 2021, Q J EXP PSYCHOL, V74, P2057, DOI 10.1177/17470218211024826
   van Rijn H, 2011, CODESIGN, V7, P65, DOI 10.1080/15710882.2011.609889
   Vargas EP, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.993162
   Ventura S., 2023, Empathy Advanced Research and Applications, P51
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Villalba EE, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107272
   Walewijns D, 2023, COMPUT HUM BEHAV, V145, DOI 10.1016/j.chb.2023.107758
   Wilding C, 2023, J APPL RES INTELLECT, V36, P132, DOI 10.1111/jar.13042
   Winkler N., 2020, Lose yourself in vr. exploring the effects of virtual reality on individuals immersion, P9
   Wohlin C., 2014, P 18 INT C EV ASS SO, P1, DOI [DOI 10.1145/2601248.2601268, 10.1145/2601248.2601268]
   Yang CY, 2009, BRAIN RES, V1251, P176, DOI 10.1016/j.brainres.2008.11.062
NR 95
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2485
EP 2495
DI 10.1109/TVCG.2024.3372076
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400017
PM 38437085
DA 2024-08-05
ER

PT J
AU Park, J
   Choi, Y
   Lee, KM
AF Park, Jieun
   Choi, Youjin
   Lee, Kyung Myun
TI Research Trends in Virtual Reality Music Concert Technology: A
   Systematic Literature Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Music Concert; Interaction; Evaluation Metric
ID SOCIAL PRESENCE; FLOW; PERFORMANCE; EXPERIENCE
AB Advances in virtual reality (VR) technology have sparked novel avenues of growth in the musical domain. Following the COVID-19 pandemic, the rise of VR technology has led to growing interest in VR music concerts as an alternative to traditional live concerts. These virtual settings can provide immersion like attending real concerts for physically distant audiences and performers, and also can offer new creative possibilities. VR music concert research is still in its infancy, and advances in technologies such as multimodal devices are rapidly expanding the diversity of research, requiring a unified understanding of the field. To identify trends in VR music concert technology, we conducted a PRISMA-based systematic literature review covering the period from 2018 to 2023. After a thorough screening process, a total of 27 papers were selected for review. The studies were classified and analyzed based on the research topic (audience, performer, concert venue), interaction type (user-environment, user-user), and hardware used (head-mounted display, additional hardware). Furthermore, we categorized the evaluation metrics into user experience, usability, and performance. Our review contributes to advancing the understanding of recent developments in VR music concert technology, shedding light on the diversification and potential of this emerging field.
C1 [Park, Jieun; Choi, Youjin; Lee, Kyung Myun] Korea Adv Inst Sci & Technol, Dajeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Park, J (corresponding author), Korea Adv Inst Sci & Technol, Dajeon, South Korea.
EM pjepsh@kaist.ac.kr; dbwls3363@kaist.ac.kr; kmlee2@kaist.ac.kr
OI Lee, Kyung Myun/0000-0003-4118-0979; Choi, Youjin/0009-0003-1326-3387;
   Park, Jieun/0009-0000-5985-7488
FU NRF
FX No Statement Available
CR Abe M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P827, DOI 10.1109/VRW55335.2022.00269
   Adeoye-Olatunde OA, 2021, J AM COLL CLIN PHARM, V4, P1358, DOI 10.1002/jac5.1441
   [Anonymous], 1998, 9241 ISO
   Athif M, 2020, IEEE ENG MED BIO, P3035, DOI 10.1109/EMBC44109.2020.9176022
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   BEVAN N, 1994, BEHAV INFORM TECHNOL, V13, P132, DOI 10.1080/01449299408914592
   Bevan N, 2015, LECT NOTES COMPUT SC, V9169, P143, DOI 10.1007/978-3-319-20901-2_13
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Bolarinwa Oladimeji Akeem, 2015, Niger Postgrad Med J, V22, P195, DOI 10.4103/1117-1936.173959
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brown SC, 2017, MUSIC SCI, V21, P233, DOI 10.1177/1029864916650719
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Cacciuttolo L., 2021, ACM SIGGRAPH 2021 IM, DOI [10.1145/3450615.34649501, DOI 10.1145/3450615.34649501]
   Caruelle D, 2019, J BUS RES, V104, P146, DOI 10.1016/j.jbusres.2019.06.041
   Chadegani A. A., 2013, Asian Social Science, V9, DOI [10.5539/ass.v9n5p182, DOI 10.5539/ASS.V9N5P182]
   Chen YX, 2023, SAGE OPEN, V13, DOI 10.1177/21582440231181585
   Chen YX, 2022, PERCEPTION, V51, P889, DOI 10.1177/03010066221125864
   Chen YX, 2023, PSYCHOL MUSIC, V51, P782, DOI 10.1177/03057356221110631
   Chen YX, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107544
   Cortellessa V., 2011, What Is Software Performance?, P1, DOI [10.1007/978-3-642-13621-4_17, DOI 10.1007/978-3-642-13621-4_17]
   Csikszentmihalyi M., 2014, Flow and the Foundations of Positive Psychology, P227, DOI DOI 10.1007/978-94-017-9088-8
   Czepiel A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-00492-3
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Dotov D, 2021, Q J EXP PSYCHOL, V74, P1037, DOI 10.1177/1747021821991793
   Droste M, 2018, PROCEEDINGS OF THE SECOND AFRICAN CONFERENCE FOR HUMAN COMPUTER INTERACTION: THRIVING COMMUNITIES (AFRICHI), P291, DOI 10.1145/3283458.3283501
   Engeser S, 2008, MOTIV EMOTION, V32, P158, DOI 10.1007/s11031-008-9102-4
   Frank Matthias, 2022, AM'22: AudioMostly 2022, P80, DOI 10.1145/3561212.3561216
   Hajika R, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P15, DOI 10.1145/3355355.3361894
   Hamilton R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1510, DOI [10.1109/vr.2019.8798166, 10.1109/VR.2019.8798166]
   Horie R, 2018, ADV INTELL SYST, V585, P276, DOI 10.1007/978-3-319-60495-4_30
   Hwang Y, 2015, TELEMAT INFORM, V32, P755, DOI 10.1016/j.tele.2015.03.006
   Ishiyama T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P990, DOI [10.1109/vr.2019.8797883, 10.1109/VR.2019.8797883]
   Jackson SA, 1996, J SPORT EXERCISE PSY, V18, P17, DOI 10.1123/jsep.18.1.17
   Jung KYE, 2024, VIRTUAL REAL-LONDON, V28, DOI 10.1007/s10055-023-00910-z
   Jung K, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P579, DOI 10.1109/VRW58643.2023.00132
   Kaneko T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P124, DOI 10.1109/AIVR.2018.00025
   Kasuya T, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811549
   Kim M, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548347
   Laeng B, 2012, PERSPECT PSYCHOL SCI, V7, P18, DOI 10.1177/1745691611427305
   Lalioti V, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489896
   Li Y., 2019, Virtual Reality Intell. Hardw., V1, P84, DOI [10.3724/SP.J.2096-5796.2018.0006, DOI 10.3724/SP.J.2096-5796.2018.0006]
   Martin AJ, 2008, MOTIV EMOTION, V32, P141, DOI 10.1007/s11031-008-9094-0
   Munoz-Gonzalez Angel, 2021, 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), P174, DOI 10.1109/GCCE53005.2021.9621854
   Munoz-Gonzalez A, 2022, IEEE T HUM-MACH SYST, V52, P248, DOI 10.1109/THMS.2021.3134555
   Onderdijk KE, 2023, VIRTUAL REAL-LONDON, V27, P2383, DOI 10.1007/s10055-023-00814-y
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1136/bmj.n160]
   Petrovic N, 2020, 2020 55TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATION, COMMUNICATION AND ENERGY SYSTEMS AND TECHNOLOGIES (IEEE ICEST 2020), P33, DOI [10.1109/icest49890.2020.9232713, 10.1109/ICEST49890.2020.9232713]
   Petrovic N, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P118, DOI [10.1109/ZINC50678.2020.9161792, 10.1109/zinc50678.2020.9161792]
   Ppali S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501922
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2023, VIRTUAL REAL-LONDON, V27, P651, DOI 10.1007/s10055-022-00685-9
   Son S, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P657, DOI 10.1109/VRW58643.2023.00171
   Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z
   Swarbrick D, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02682
   Tian Y, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01121
   Turchet L, 2021, IEEE ACCESS, V9, P15810, DOI 10.1109/ACCESS.2021.3052931
   Ulrich M, 2016, SOC COGN AFFECT NEUR, V11, P496, DOI 10.1093/scan/nsv133
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Van Kerrebroeck B, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.663725
   Wang MJ, 2022, APPL MATH NONLIN SCI, DOI 10.2478/amns.2022.2.0138
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf S, 2015, BIOL PSYCHOL, V105, P95, DOI 10.1016/j.biopsycho.2015.01.007
   Yakura H, 2020, INT SYM MIX AUGMENT, P555, DOI 10.1109/ISMAR50242.2020.00083
   Yamamoto T., 1999, IEEE SMC 99 C P 1999, V5, P8
   Yan S., 2020, SIGGRAPH AS 2020 POS, DOI [10.1145/3415264.34254663,4,8, DOI 10.1145/3415264.34254663,4,8]
   Yang T, 2012, INT J HUM-COMPUT INT, V28, P308, DOI 10.1080/10447318.2011.586320
NR 68
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2195
EP 2205
DI 10.1109/TVCG.2024.3372069
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400055
PM 38437121
DA 2024-08-05
ER

PT J
AU Yasui, M
   Iwataki, R
   Ishikawa, M
   Watanabe, Y
AF Yasui, Masahiko
   Iwataki, Ryota
   Ishikawa, Masatoshi
   Watanabe, Yoshihiro
TI Projection Mapping with a Brightly Lit Surrounding Using a Mixed Light
   Field Approach
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Light fields; Lenses; Electronic mail; Visualization;
   Photography; Optical imaging; Projection mapping; Ambient lighting;
   Light field; Integral photography
AB Projection mapping (PM) exhibits suboptimal performance in well-lit environments because of the interference caused by ambient light. This interference degrades the contrast of the projected images. Consequently, conventional methodologies restrict the application of PM to dimly lit settings, leading to an unnatural visual experience, as only the PM target is prominently illuminated. To overcome these limitations, we introduce an innovative approach that leverages a mixed light field, blending traditional PM with ray-controllable ambient lighting. This methodological combination, despite its simplicity, is effective because it ensures that the projector exclusively illuminates the PM target, preserving the optimal contrast. Precise control of ambient light rays is essential to prevent them from illuminating the PM target while adequately illuminating the surrounding environment. Furthermore, we propose the integration of a kaleidoscopic array with integral photography to generate dense light fields for ray-controllable ambient lighting. Additionally, we present an efficient binary-search-based calibration method tailored to this intricate optical system. Our optical simulations and the developed system collectively validate the effectiveness of our approach. Our results show that PM targets and ordinary objects coexist naturally in environments that are brightly lit as a result of our method, enhancing the overall visual experience.
C1 [Yasui, Masahiko; Iwataki, Ryota; Ishikawa, Masatoshi; Watanabe, Yoshihiro] Tokyo Inst Technol, Tokyo, Japan.
   [Yasui, Masahiko] Konica Minolta, Chiyoda City, Tokyo, Japan.
C3 Tokyo Institute of Technology; Konica Minolta Inc.
RP Yasui, M (corresponding author), Tokyo Inst Technol, Tokyo, Japan.; Yasui, M (corresponding author), Konica Minolta, Chiyoda City, Tokyo, Japan.
EM yasuimasahiko@gmail.com; iwataki.r.aa@m.titech.ac.jp;
   ishikawa@ishikawa-vision.org; watanabe.y.cl@m.titech.ac.jp
OI Ishikawa, Masatoshi/0000-0002-6096-830X
FU JSPS KAKENHI
FX No Statement Available
CR Akiyama R, 2021, IEEE T VIS COMPUT GR, V27, P2041, DOI 10.1109/TVCG.2019.2940453
   Amano T., 2022, EUROXR 2022, V1, P81
   [Anonymous], INORI (Prayer)
   [Anonymous], Light Barrier, VThird
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds, DOI [DOI 10.1201/B10624, 10.1201/b10624]
   Bokaris PA, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P21, DOI 10.1145/3355355.3361885
   Chen B, 2019, OPT EXPRESS, V27, P21999, DOI 10.1364/OE.27.021999
   Debevec P, 2002, ACM T GRAPHIC, V21, P547
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Fujigaki S, 2019, IEEE IMAGE PROC, P3532, DOI [10.1109/ICIP.2019.8803430, 10.1109/icip.2019.8803430]
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Han JY, 2003, ACM T GRAPHIC, V22, P741, DOI 10.1145/882262.882341
   Hashiomoto N., 2018, ACM SIGGRAPH 2018 PO, P1
   Hiratani K, 2023, IEEE T VIS COMPUT GR, V29, P2280, DOI 10.1109/TVCG.2023.3247104
   Hoang T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1419, DOI 10.1145/3025453.3025860
   Hong-Nien Chen, 2019, 2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media). Proceedings, P102, DOI 10.1109/Ubi-Media.2019.00028
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Iwai D., 2021, arXiv
   Kageyama Y, 2022, IEEE T VIS COMPUT GR, V28, P2223, DOI 10.1109/TVCG.2022.3150465
   Koshino S., 2021, SIGGRAPH Asia 2021 Real-Time Live!
   Kurth P, 2022, IEEE T VIS COMPUT GR, V28, P3607, DOI 10.1109/TVCG.2022.3203085
   LeGendre C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925934
   Lippmann G, 1908, CR HEBD ACAD SCI, V146, P446
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Mohan A, 2007, IEEE T VIS COMPUT GR, V13, P652, DOI 10.1109/TVCG.2007.1008
   Morimoto T, 2021, J VISION, V21, DOI 10.1167/jov.21.13.3
   Murmann L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980219
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Nomoto T., 2020, SIGGRAPH Asia 2020 Emerging Technologies, P1
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Okano F, 1997, APPL OPTICS, V36, P1598, DOI 10.1364/AO.36.001598
   Park MK, 2015, J COMPUT DES ENG, V2, P38, DOI 10.1016/j.jcde.2014.11.004
   Peers P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477929
   Radonjic A, 2011, CURR BIOL, V21, P1931, DOI 10.1016/j.cub.2011.10.013
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Sakai H., 2009, SID symposium digest of technical papers, V40, P611, DOI [10.1889/1.3256853, DOI 10.1889/1.3256853.(2009]
   Schmid M, 2021, OPT LETT, V46, P2485, DOI 10.1364/OL.423196
   Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Srikanth Manohar., 2014, Proceedings of the Workshop on Computational Aesthetics, P57
   Takeuchi M, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P653, DOI 10.1109/VRW58643.2023.00169
   Takeuchi Y, 2022, IEEE ACCESS, V10, P939, DOI 10.1109/ACCESS.2021.3139108
   Takeuchi Y, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P39, DOI 10.1145/2992154.2992188
   Thakur S, 2022, LECT NOTES COMPUT SC, V13303, P180, DOI 10.1007/978-3-031-05409-9_14
   Tsurumi N., 2023, International Federation of Societies of Cosmetic Chemists
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Wang JP, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531335
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yamamoto K, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545690
   Yamasaki M., 2009, Stereoscopic Displays and Applications XX, V7237, P3
   Yano H, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214917
   Yasui M, 2021, OPT EXPRESS, V29, P12066, DOI 10.1364/OE.418729
   Zhou Z, 2015, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2015.7223335
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2217
EP 2227
DI 10.1109/TVCG.2024.3372132
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400070
PM 38446649
OA hybrid
DA 2024-08-05
ER

PT J
AU Bauer, D
   Wu, Q
   Ma, KL
AF Bauer, David
   Wu, Qi
   Ma, Kwan-Liu
TI Photon Field Networks for Dynamic Real-Time Volumetric Global
   Illumination
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Photonics; Rendering (computer graphics); Lighting; Data visualization;
   Real-time systems; Light sources; Visualization; Volume data; volume
   rendering; volume visualization; deep learning; global illumination;
   neural rendering; path tracing
ID OCCLUSION SHADING MODEL; AMBIENT OCCLUSION
AB Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks-a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achieve interactive framerates even on large datasets. We conduct in-depth evaluations of the method's performance, including visual quality, stochastic noise, inference and rendering speeds, and accuracy regarding illumination and phase function awareness. Results are compared to ray marching, path tracing and photon mapping. Our findings show that Photon Field Networks can faithfully represent indirect global illumination within the boundaries of the trained phase spectrum while exhibiting less stochastic noise and rendering at a significantly faster rate than traditional methods.
C1 [Bauer, David; Wu, Qi; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Bauer, D (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM davbauer@ucdavis.edu; qadwu@ucdavis.edu; klma@ucdavis.edu
OI Ma, Kwan-Liu/0000-0001-8086-0366; Bauer, David/0000-0002-1327-3054
FU U.S. Department of Energy
FX No Statement Available
CR Bauer D, 2023, IEEE T VIS COMPUT GR, V29, P515, DOI 10.1109/TVCG.2022.3209498
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bi S, 2020, Arxiv, DOI arXiv:2008.03824
   Bitterli B, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073698
   Boss M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12664, DOI 10.1109/ICCV48922.2021.01245
   Dachsbacher C, 2014, COMPUT GRAPH FORUM, V33, P88, DOI 10.1111/cgf.12256
   Dappa E, 2016, INSIGHTS IMAGING, V7, P849, DOI 10.1007/s13244-016-0518-1
   Díaz J, 2010, COMPUT GRAPH-UK, V34, P337, DOI 10.1016/j.cag.2010.03.005
   Dodik A, 2022, COMPUT GRAPH FORUM, V41, P172, DOI 10.1111/cgf.14428
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Gao D., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32099633, DOI 10.1109/TVCG.2022.32099633]
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409083
   Hachisuka T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618487
   Han J., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.31972032
   Henyey LG, 1941, ASTROPHYS J, V93, P70, DOI 10.1086/144246
   Herholz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3230635
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Intel Corporation, 2022, OpenVKL
   Intel Corporation, 2020, oneTBB
   Jarosz W., 2008, ACM SIGGRAPH 2008 CL, p3:1, DOI DOI 10.1145/1401132.14011372,9
   Jarosz W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899409
   Jensen H. W., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P311, DOI 10.1145/280814.280925
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Jönsson D, 2017, IEEE T VIS COMPUT GR, V23, P901, DOI 10.1109/TVCG.2016.2598430
   Jönsson D, 2012, IEEE T VIS COMPUT GR, V18, P2364, DOI 10.1109/TVCG.2012.232
   Kallweit S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130880
   Kaplanyan AS, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451242
   Kingma D. P., 2014, arXiv
   Kniss J, 2003, IEEE T VIS COMPUT GR, V9, P150, DOI 10.1109/TVCG.2003.1196003
   Kniss J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P109, DOI 10.1109/VISUAL.2002.1183764
   Krivánek J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601219
   Kroes T., 2015, GPU Pro 6: Advanced Rendering Techniques, P475, DOI [DOI 10.1201/9781351052108-172, 10.1201/9781351052108-172]
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Liu N, 2016, COMPUT ANIMAT VIRT W, V27, P394, DOI 10.1002/cav.1706
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459812
   Muller Thomas, 2021, TINY CUDA NEURAL NET
   Paladini G., 2015, Industrial Talk, EG/VGTC EuroVis, P2
   Ropinski T, 2008, COMPUT GRAPH FORUM, V27, P567, DOI 10.1111/j.1467-8659.2008.01154.x
   Ruiz M., 2008, IEEE EG S VOLUME POI, P113, DOI [10.2312/VG/VG-PBG08/113-1202, 10.2312/VG/VG-PBG08/113-120, DOI 10.2312/VG/VG-PBG08/113-1202]
   Schott M, 2009, COMPUT GRAPH FORUM, V28, P855, DOI 10.1111/j.1467-8659.2009.01464.x
   Shih M, 2016, SYMP LARG DATA ANAL, P47, DOI 10.1109/LDAV.2016.7874309
   Sitzmann V., 2021, Advances in Neural Information Processing Systems, V34, P9
   Soltészová V, 2010, COMPUT GRAPH FORUM, V29, P883, DOI 10.1111/j.1467-8659.2009.01695.x
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Suhail M, 2022, PROC CVPR IEEE, P8259, DOI 10.1109/CVPR52688.2022.00809
   Sundén E, 2011, IEEE T VIS COMPUT GR, V17, P2125, DOI 10.1109/TVCG.2011.211
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Veach E., 1995, Photorealistic Rendering Techniques, P2
   Vorba Ji., 2019, ACM SIGGRAPH Courses, p18:1, DOI DOI 10.1145/3305366.3328091
   Wald I, 2022, Arxiv, DOI [arXiv:2210.12859, DOI 10.48550/ARXIV.2210.12859]
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Weber C., 2013, Vision, Modeling & Visualization, DOI [10.2312/PE.VMV.VMV13.195-202, DOI 10.2312/PE.VMV.VMV13.195-202]
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Woodcock E.R., 1965, PROC C APPL COMPUTIN, P557
   Wu Q., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32931212,3,5, DOI 10.1109/TVCG.2023.32931212,3,5]
   Zhang Y., 2013, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2448196.2448205, 10.1145/2448196.2448205]
   Zhang YB, 2013, IEEE T VIS COMPUT GR, V19, P1317, DOI 10.1109/TVCG.2013.17
   Zhu SL, 2020, COMPUT GRAPH FORUM, V39, P35, DOI 10.1111/cgf.14052
NR 65
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 975
EP 985
DI 10.1109/TVCG.2023.3327107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500015
PM 37883277
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Fygenson, R
   Franconeri, S
   Bertini, E
AF Fygenson, Racquel
   Franconeri, Steven
   Bertini, Enrico
TI The Arrangement of Marks Impacts Afforded Messages: Ordering,
   Partitioning, Spacing, and Coloring in Bar Charts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bars; Visualization; Data visualization; Task analysis; Affordances;
   COVID-19; Birds; Perception & cognition; Methodologies; Human-subjects
   qualitative studies; Human-subjects quantitative studies; Charts;
   diagrams and plots; General public
ID COGNITIVE FIT; SAMPLE-SIZE; SIMILARITY; INFORMATION; PROXIMITY; GRAPHS;
   PERCEPTION
AB Data visualizations present a massive number of potential messages to an observer. One might notice that one group's average is larger than another's, or that a difference in values is smaller than a difference between two others, or any of a combinatorial explosion of other possibilities. The message that a viewer tends to notice - the message that a visualization 'affords' - is strongly affected by how values are arranged in a chart, e.g., how the values are colored or positioned. Although understanding the mapping between a chart's arrangement and what viewers tend to notice is critical for creating guidelines and recommendation systems, current empirical work is insufficient to lay out clear rules. We present a set of empirical evaluations of how different messages-including ranking, grouping, and part-to-whole relationships-are afforded by variations in ordering, partitioning, spacing, and coloring of values, within the ubiquitous case study of bar graphs. In doing so, we introduce a quantitative method that is easily scalable, reviewable, and replicable, laying groundwork for further investigation of the effects of arrangement on message affordances across other visualizations and tasks. Pre-registration and all supplemental materials are available at https://osf.io/np3q7 and https://osf.io/bvy95, respectively.
C1 [Fygenson, Racquel; Franconeri, Steven; Bertini, Enrico] Northeastern Univ, Boston, MA 02138 USA.
C3 Northeastern University
RP Fygenson, R (corresponding author), Northeastern Univ, Boston, MA 02138 USA.
EM fygenson.r@northeastern.edu; franconeri@northwestern.edu;
   e.bertini@northeastern.edu
OI Fygenson, Racquel/0000-0002-0705-9000; Bertini,
   Enrico/0000-0002-9932-0551
FU National Science Foundation
FX No Statement Available
CR Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   BENAV MB, 1995, VISION RES, V35, P853, DOI 10.1016/0042-6989(94)00173-J
   Bertini E., 2008, CHI '08 extended abstracts on Human factors in computing systems, P3913
   Bertini E, 2021, Arxiv, DOI arXiv:2008.11310
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brooks J.L., 2015, The Oxford Handbook of Perceptual Organization
   Burns A., IEEE Transactions on Visualization amp; Computer Graphics, P1, DOI [10.1109/TVCG.2022.32317162, DOI 10.1109/TVCG.2022.32317162]
   Burns R, 2019, COMPUT INTELL-US, V35, P955, DOI 10.1111/coin.12227
   Cairo A, 2020, About that weird georgia chart
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dickinson CA, 2009, ATTEN PERCEPT PSYCHO, V71, P1251, DOI 10.3758/APP.71.6.1251
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Elzer S, 2006, USER MODEL USER-ADAP, V16, P1, DOI 10.1007/s11257-006-9002-9
   Feeney A., 2003, Smart Graphics, P4
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Gaba Aimen, 2023, IEEE Trans Vis Comput Graph, V29, P1211, DOI 10.1109/TVCG.2022.3209456
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   HOCHBERG J, 1956, AM J PSYCHOL, V69, P456, DOI 10.2307/1419052
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lidwell W., 2010, Affordance, P3
   Michal AL, 2016, PSYCHON B REV, V23, P1802, DOI 10.3758/s13423-016-1047-0
   Munzner Tamara, 2014, Visualization analysis and design
   Norman D., 2013, The Psychopathology Of Everyday Things, V1, P3
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Oyama T, 1999, PERCEPTION, V28, P739, DOI 10.1068/p2799
   Oyama T., 1961, Perceptual and Motor Skills, V13, P305, DOI DOI 10.2466/PMS.1961.13.3.305
   Padilla Lace, 2023, IEEE Trans Vis Comput Graph, V29, P12, DOI 10.1109/TVCG.2022.3209457
   Padilla L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05353-1
   Plaisant Catherine, 2004, Proceedings of the working conference on Advanced visual interfaces, P109, DOI DOI 10.1145/989863.989880
   Quinlan PT, 1998, PERCEPTION, V27, P417, DOI 10.1068/p270417
   Scimeca J., 2014, Wiley Interdisciplinary Reviews: Cognitive Science, V6, P12, DOI [10.1002/wcs.13286,7,8,9, DOI 10.1002/WCS.13286,7,8,9]
   Seabold S, 2010, STATSMODELS ECONOMET, DOI 10.25080/Majora-92bf1922-012
   Shah P, 1999, J EDUC PSYCHOL, V91, P690, DOI 10.1037/0022-0663.91.4.690
   SIMKIN D, 1987, J AM STAT ASSOC, V82, P454, DOI 10.2307/2289447
   SISON CP, 1995, J AM STAT ASSOC, V90, P366, DOI 10.2307/2291162
   South L, 2022, COMPUT GRAPH FORUM, V41, P43, DOI 10.1111/cgf.14521
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   THOMPSON SK, 1987, AM STAT, V41, P42, DOI 10.2307/2684318
   Tufte E.R., 2001, VISUAL DISPLAY QUANT, V2nd, P1
   TVERSKY B, 1991, COGNITIVE PSYCHOL, V23, P515, DOI 10.1016/0010-0285(91)90005-9
   VESSEY I, 1991, DECISION SCI, V22, P219, DOI 10.1111/j.1540-5915.1991.tb00344.x
   Vessey I, 1991, INFORM SYST RES, V2, P63, DOI 10.1287/isre.2.1.63
   Viénot F, 1999, COLOR RES APPL, V24, P243, DOI 10.1002/(SICI)1520-6378(199908)24:4<243::AID-COL5>3.0.CO;2-3
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Wall E, 2022, IEEE COMPUT GRAPH, V42, P29, DOI 10.1109/MCG.2022.3152676
   Walny J, 2015, COMPUT GRAPH FORUM, V34, P231, DOI 10.1111/cgf.12635
   Ware C, 2008, MORG KAUF SER INTER, P1
   Ware C., 2012, Morgan Kaufmann Series in Interactive Technologies, V3, P4
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Xiong C., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32329591,2, DOI 10.1109/TVCG.2022.32329591,2]
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xu YQ, 2015, PSYCHOL SCI, V26, P1241, DOI 10.1177/0956797615585002
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yu D, 2019, PSYCHOL SCI, V30, P376, DOI 10.1177/0956797618822798
   Yu D, 2019, COGNITION, V182, P8, DOI 10.1016/j.cognition.2018.08.006
   Zacks J, 1998, J EXP PSYCHOL-APPL, V4, P119
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Ziemkiewicz C, 2008, IEEE T VIS COMPUT GR, V14, P1269, DOI 10.1109/TVCG.2008.171
   Ziemkiewicz Caroline, 2010, P ADV VISUAL INTERFA, P215, DOI [10.1145/1842993.1843031, DOI 10.1145/1842993.1843031]
NR 66
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1008
EP 1018
DI 10.1109/TVCG.2023.3326590
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500033
PM 37871066
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Moritz, D
   Padilla, LM
   Nguyen, F
   Franconeri, SL
AF Moritz, Dominik
   Padilla, Lace M.
   Nguyen, Francis
   Franconeri, Steven L.
TI Average Estimates in Line Graphs Are Biased Toward Areas of Higher
   Variability
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Time series analysis; Encoding; Visualization; Task
   analysis; Ink; Market research; bias; lines graph; ensemble perception;
   average
AB We investigate variability overweighting, a previously undocumented bias in line graphs, where estimates of average value are biased toward areas of higher variability in that line. We found this effect across two preregistered experiments with 140 and 420 participants. These experiments also show that the bias is reduced when using a dot encoding of the same series. We can model the bias with the average of the data series and the average of the points drawn along the line. This bias might arise because higher variability leads to stronger weighting in the average calculation, either due to the longer line segments (even though those segments contain the same number of data values) or line segments with higher variability being otherwise more visually salient. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders, as the bias can adversely affect estimates of averages and trends.
C1 [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Padilla, Lace M.] Northeastern Univ, Boston, MA USA.
   [Nguyen, Francis] Northwestern Univ, Evanston, IL USA.
   [Franconeri, Steven L.] Univ British Columbia, Vancouver, BC, Canada.
C3 Carnegie Mellon University; Northeastern University; Northwestern
   University; University of British Columbia
RP Moritz, D (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM domoritz@cmu.edu; l.padilla@northeastern.edu;
   franconeri@northwestern.edu; frnguyen@cs.ubc.ca
OI Moritz, Dominik/0000-0002-3110-1053
FU NSF
FX No Statement Available
CR Adnan M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5444, DOI 10.1145/2858036.2858300
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Correll M, 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, DOI [DOI 10.1145/2207676.22085562, 10.1145/2207676.2208556, DOI 10.1145/2207676.2208556]
   FOX CR, 1995, Q J ECON, V110, P585, DOI 10.2307/2946693
   Gamer Matthias, 2019, CRAN
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Hastie T. J., 2017, Statistical models in S, P9
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Heinrich J, 2009, IEEE T VIS COMPUT GR, V15, P1531, DOI 10.1109/TVCG.2009.131
   Hong MH, 2022, IEEE T VIS COMPUT GR, V28, P987, DOI 10.1109/TVCG.2021.3114783
   Huff D., 2023, How to lie with statistics, P1
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   KIMBALL MS, 1993, ECONOMETRICA, V61, P589, DOI 10.2307/2951719
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Moritz D, 2018, Arxiv, DOI arXiv:1808.06019
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Playfair W., 1801, The commercial and political atlas: representing, by means of stained copper-plate charts, the progress of the commerce, revenues, expenditure and debts of england during the whole of the eighteenth century, P1
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Quinan PS, 2019, COMPUT GRAPH FORUM, V38, P363, DOI 10.1111/cgf.13695
   Raudenbush S. W., 2002, Hierarchical linear models: Applications and data analysis methods, DOI DOI 10.2307/20758235
   Szafir D. A., 2018, Interactions, V25, P26, DOI [DOI 10.1145/3231772, 10.1145/32317721, DOI 10.1145/32317721]
   Tufte E. R., 1985, The Journal for Healthcare Quality (JHQ), V7, P1
   VanRullen R, 2003, J PHYSIOL-PARIS, V97, P365, DOI 10.1016/j.jphysparis.2003.09.010
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wikipedia contributors, 2023, Geometric brownian motion-Wikipedia, the free encyclopedia
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
NR 34
TC 2
Z9 2
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 306
EP 315
DI 10.1109/TVCG.2023.3326589
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500042
PM 37871088
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ouyang, Y
   Wu, YC
   Wang, H
   Zhang, CY
   Cheng, FR
   Jiang, C
   Jin, LX
   Cao, YW
   Li, Q
AF Ouyang, Yang
   Wu, Yuchen
   Wang, He
   Zhang, Chenyang
   Cheng, Furui
   Jiang, Chang
   Jin, Lixia
   Cao, Yuanwu
   Li, Quan
TI Leveraging Historical Medical Records as a Proxy via Multimodal Modeling
   and Visualization to Enrich Medical Diagnostic Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multimodal Medical Dataset; Visual Analytics; Explainable Machine
   Learning
ID HEALTH-CARE; VISUAL ANALYTICS; SIMULATION; EDUCATION; EXPLORATION
AB Simulation-based Medical Education (SBME) has been developed as a cost-effective means of enhancing the diagnostic skills of novice physicians and interns, thereby mitigating the need for resource-intensive mentor-apprentice training. However, feedback provided in most SBME is often directed towards improving the operational proficiency of learners, rather than providing summative medical diagnoses that result from experience and time. Additionally, the multimodal nature of medical data during diagnosis poses significant challenges for interns and novice physicians, including the tendency to overlook or over-rely on data from certain modalities, and difficulties in comprehending potential associations between modalities. To address these challenges, we present DiagnosisAssistant, a visual analytics system that leverages historical medical records as a proxy for multimodal modeling and visualization to enhance the learning experience of interns and novice physicians. The system employs elaborately designed visualizations to explore different modality data, offer diagnostic interpretive hints based on the constructed model, and enable comparative analyses of specific patients. Our approach is validated through two case studies and expert interviews, demonstrating its effectiveness in enhancing medical training.
C1 [Ouyang, Yang; Wu, Yuchen; Wang, He; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Ouyang, Yang; Wu, Yuchen; Wang, He; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
   [Zhang, Chenyang] Univ Illinois, Dept Comp Sci, Champaign, IL USA.
   [Cheng, Furui] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   [Jiang, Chang; Jin, Lixia; Cao, Yuanwu] Fudan Univ, Zhongshan Hosp, Shanghai, Peoples R China.
C3 ShanghaiTech University; University of Illinois System; University of
   Illinois Urbana-Champaign; Swiss Federal Institutes of Technology
   Domain; ETH Zurich; Fudan University
RP Li, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.; Li, Q (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
EM ouyy@shanghaitech.edu.cn; wuych3@shanghaitech.edu.cn;
   wanghe1@shanghaitech.edu.cn; zhang414@illinois.edu;
   furui.cheng@inf.ethz.ch; cjiang_fdu@yeah.net;
   jin.lixia@zs-hospital.sh.cn; cao.yuanwu@zs-hospital.sh.cn;
   liquan@shanghaitech.edu.cn
OI Zhang, Chenyang/0009-0003-1116-4895; , Yang/0009-0000-5841-7659; Wang,
   He/0009-0003-2550-6139; Cheng, Furui/0000-0003-2329-6126
FU National Natural Science Foundation of China
FX No Statement Available
CR Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2
   Al-Elq AH, 2010, J FAM COMMUNITY MED, V17, P35, DOI 10.4103/1319-1683.68787
   Al-Ghareeb AZ, 2016, NURS EDUC TODAY, V36, P281, DOI 10.1016/j.nedt.2015.08.005
   Alsentzer E., 2019, P 2 CLIN NAT LANG PR, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909, 10.18653/v1/w19-1909]
   Ashuach T., 2021, bioRxiv, DOI [10.1101/2021.08.20.4570571, DOI 10.1101/2021.08.20.4570571]
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bastani O, 2018, Arxiv, DOI arXiv:1706.09773
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Bernard J, 2019, IEEE T VIS COMPUT GR, V25, P1615, DOI 10.1109/TVCG.2018.2803829
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burgess A, 2018, CLIN TEACH, V15, P197, DOI 10.1111/tct.12756
   Caban JJ, 2015, J AM MED INFORM ASSN, V22, P260, DOI 10.1093/jamia/ocv006
   Calisto FM, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI [10.1145/3544548.3580682, 10.1007/978-3-031-52038-9_1]
   Calisto FM, 2021, INT J HUM-COMPUT ST, V150, DOI 10.1016/j.ijhcs.2021.102607
   Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TT, 2019, I S BIOMED IMAGING, P1505, DOI [10.1109/isbi.2019.8759303, 10.1109/ISBI.2019.8759303]
   Chengoden R, 2023, IEEE ACCESS, V11, P12764, DOI 10.1109/ACCESS.2023.3241628
   Choi E, 2016, ADV NEUR IN, V29
   Cui C, 2023, Arxiv, DOI [arXiv:2203.15588, DOI 10.48550/ARXIV.2203.15588]
   Dinov ID, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157077
   Ensor K. B., 1997, Lectures in Applied Mathematics-American Mathematical Society, V33, P4
   Faris H., 2021, Inform. Med. Unlocked, V23, DOI [DOI 10.1016/J.IMU.2021.100513, 10.1016/j.imu.2021.100513]
   Goedhart J, 2021, MOL BIOL CELL, V32, P470, DOI 10.1091/mbc.E20-09-0583
   Guo WB, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P364, DOI 10.1145/3243734.3243792
   Guo Y., 2021, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/tvcg.2021.31004132, DOI 10.1109/TVCG.2021.31004132]
   Henelius A, 2014, DATA MIN KNOWL DISC, V28, P1503, DOI 10.1007/s10618-014-0368-8
   Holste G, 2021, IEEE INT CONF COMP V, P3287, DOI 10.1109/ICCVW54120.2021.00368
   Hoopes S, 2020, OBSTET GYNECOL, V136, P56, DOI 10.1097/AOG.0000000000003931
   Huang SC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78888-w
   Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z
   Huff DT, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abcd17
   Issenberg SB, 2011, SIMUL HEALTHC, V6, P155, DOI 10.1097/SIH.0b013e3182207c24
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kawahara J, 2019, IEEE J BIOMED HEALTH, V23, P538, DOI 10.1109/JBHI.2018.2824327
   Kazan R, 2016, SIMUL HEALTHC, V11, P60, DOI 10.1097/SIH.0000000000000124
   Kolb D., 1984, Englewood Cliffs, P31
   Konig Rikard, 2008, 2008 IEEE International Conference on Data Mining Workshops, P971, DOI 10.1109/ICDMW.2008.117
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Kuiper JS, 2015, AGEING RES REV, V22, P39, DOI 10.1016/j.arr.2015.04.006
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Li SQ, 2019, I S BIOMED IMAGING, P384, DOI 10.1109/ISBI.2019.8759385
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lutgendorf MA, 2017, MIL MED, V182, pE1762, DOI 10.7205/MILMED-D-16-00030
   Malik S., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10. 1145/2678025.2701407, 10.1145/2678025.2701407]
   McGaghie WC, 2016, MED EDUC, V50, P986, DOI 10.1111/medu.12795
   McGaghie WC, 2010, MED EDUC, V44, P50, DOI 10.1111/j.1365-2923.2009.03547.x
   Mörth E, 2020, COMPUT GRAPH FORUM, V39, P611, DOI 10.1111/cgf.14172
   Muhammad G, 2021, INFORM FUSION, V76, P355, DOI 10.1016/j.inffus.2021.06.007
   Payrovnaziri SN, 2020, J AM MED INFORM ASSN, V27, P1173, DOI 10.1093/jamia/ocaa053
   Piccialli F, 2021, INFORM FUSION, V66, P111, DOI 10.1016/j.inffus.2020.09.006
   Raidou RG, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13413
   Ribeiro M. T., 2018, P AAAI C ART INT, V32, DOI [10.1609/aaai.v32i1.114912, DOI 10.1609/AAAI.V32I1.114912]
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rooney MK, 2018, INT J RADIAT ONCOL, V102, P257, DOI 10.1016/j.ijrobp.2018.05.064
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Seropian MA, 2004, J NURS EDUC, V43, P164
   Shahar Y, 2006, ARTIF INTELL MED, V38, P115, DOI 10.1016/j.artmed.2005.03.001
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Sivaraman V, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581075
   Solares JRA, 2020, J BIOMED INFORM, V101, DOI 10.1016/j.jbi.2019.103337
   Srinivasan M, 2006, ACAD PSYCHIATR, V30, P505, DOI 10.1176/appi.ap.30.6.505
   Stewart W. J., 2009, Probability, Markov chains, queues, and simulation: the mathematical basis of performance modeling, DOI [10.1515/97814008328116, DOI 10.1515/97814008328116]
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Sugathan S, 2022, COMPUT GRAPH-UK, V107, P208, DOI 10.1016/j.cag.2022.07.023
   Tanya S, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.6604
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vozenilek J, 2004, ACAD EMERG MED, V11, P1149, DOI 10.1197/j.aem.2004.08.003
   Wang HZ, 2021, I S BIOMED IMAGING, P1169, DOI 10.1109/ISBI48211.2021.9433823
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P238, DOI 10.1109/TVCG.2021.3114840
   Zigmont JJ, 2011, SEMIN PERINATOL, V35, P47, DOI 10.1053/j.semperi.2011.01.002
NR 73
TC 2
Z9 2
U1 7
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1238
EP 1248
DI 10.1109/TVCG.2023.3326929
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500127
PM 37874707
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Subramonyam, H
   Hullman, J
AF Subramonyam, Hariharan
   Hullman, Jessica
TI Are We Closing the Loop Yet? Gaps in the Generalizability of VIS4ML
   Research
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Pipelines; Machine learning; Task analysis; Surveys; Human in the loop;
   Data visualization; Visual analytics; VIS4ML; Visualization;
   Human-in-the-loop; Human Knowledge; Generalizability; Survey
ID VISUAL ANALYTICS; DESIGN; SELECTION; MODEL
AB Visualization for machine learning (VIS4ML) research aims to help experts apply their prior knowledge to develop, understand, and improve the performance of machine learning models. In conceiving VIS4ML systems, researchers characterize the nature of human knowledge to support human-in-the-loop tasks, design interactive visualizations to make ML components interpretable and elicit knowledge, and evaluate the effectiveness of human-model interchange. We survey recent VIS4ML papers to assess the generalizability of research contributions and claims in enabling human-in-the-loop ML. Our results show potential gaps between the current scope of VIS4ML research and aspirations for its use in practice. We find that while papers motivate that VIS4ML systems are applicable beyond the specific conditions studied, conclusions are often overfitted to non-representative scenarios, are based on interactions with a small set of ML experts and well-understood datasets, fail to acknowledge crucial dependencies, and hinge on decisions that lack justification. We discuss approaches to close the gap between aspirations and research claims and suggest documentation practices to report generality constraints that better acknowledge the exploratory nature of VIS4ML research.
C1 [Subramonyam, Hariharan] Stanford Univ, Stanford, CA 94305 USA.
   [Hullman, Jessica] Northwestern Univ, Evanston, IL USA.
C3 Stanford University; Northwestern University
RP Subramonyam, H (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM harihars@stanford.edu; jhullman@northwestern.edu
FU NSF
FX No Statement Available
CR Akbaba D., 2023, Troubling collaboration: Matters of care for visualization design study
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Arora S., 2018, C LEARNING THEORY, V75, P1455, DOI DOI 10.48550/ARXIV.1803.01768
   Boukhelifa N, 2020, IEEE COMPUT GRAPH, V40, P88, DOI 10.1109/MCG.2020.3017064
   Brown E. T., 2016, P CHI WORKSH HUM CTR
   Cashman D, 2020, IEEE T VIS COMPUT GR, V26, P863, DOI 10.1109/TVCG.2019.2934261
   Chatzimparmpas A, 2021, COMPUT GRAPH FORUM, V40, P201, DOI 10.1111/cgf.14300
   Chatzimparmpas A, 2024, Arxiv, DOI arXiv:2203.15753
   Chatzimparmpas A, 2022, IEEE T VIS COMPUT GR, V28, P1773, DOI 10.1109/TVCG.2022.3141040
   Chaudhuri S., 2006, IEEE Data Eng. Bull., V29, P5
   Chen M., 2020, Foundations of Data Visualization, P9
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Das S, 2019, IEEE COMPUT GRAPH, V39, P20, DOI 10.1109/MCG.2019.2922592
   Devezer B., 2020, The case for formal methodology in scientific reform, DOI DOI 10.1101/2020.04.26.048306
   El-Assady M, 2020, IEEE T VIS COMPUT GR, V26, P1001, DOI 10.1109/TVCG.2019.2934654
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Endert A, 2014, J INTELL INF SYST, V43, P411, DOI 10.1007/s10844-014-0304-9
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Gomez O, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P31, DOI 10.1109/VIS49827.2021.9623271
   Haibe-Kains B, 2020, NATURE, V586, pE14, DOI 10.1038/s41586-020-2766-y
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hong Sungsoo Ray, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392878
   Huang J., 2022, IEEE Transactions on Visualization and Computer Graphics, V1
   Huang XY, 2021, COMPUT GRAPH FORUM, V40, P227, DOI 10.1111/cgf.14302
   Hullman J., 2022, arXiv preprint arXiv:2203.06498, P8
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Jaunet T, 2020, COMPUT GRAPH FORUM, V39, P49, DOI 10.1111/cgf.13962
   Jia S., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P4
   Jin Z., 2022, IEEE Transactions on Visualization and Computer Graphics
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kerrigan D, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5120073
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Liao T., 35 C NEUR INF PROC S
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   McKenna S, 2014, IEEE T VIS COMPUT GR, V20, P2191, DOI 10.1109/TVCG.2014.2346331
   MEEHL PE, 1990, PSYCHOL REP, V66, P195, DOI 10.2466/PR0.66.1.195-244
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   Meyer M, 2015, INFORM VISUAL, V14, P234, DOI 10.1177/1473871613510429
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116
   Neutatz F., 2021, IEEE Data Eng. Bull., V44, P2
   Nie SL, 2018, IEEE PAC VIS SYMP, P180, DOI 10.1109/PacificVis.2018.00031
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Park C., 2021, EUR C VIS EUROVIS SH
   Park H., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P4
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Rathore A, 2021, COMPUT GRAPH FORUM, V40, P382, DOI 10.1111/cgf.14195
   Sacha D., 2016, ESANN, V1, P2
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sietzen S, 2021, COMPUT GRAPH FORUM, V40, P253, DOI 10.1111/cgf.14418
   Simons DJ, 2017, PERSPECT PSYCHOL SCI, V12, P1123, DOI 10.1177/1745691617708630
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smilkov D, 2016, Arxiv, DOI arXiv:1611.05469
   Sperrle F, 2021, COMPUT GRAPH FORUM, V40, P543, DOI 10.1111/cgf.14329
   Sperrle F, 2020, Arxiv, DOI arXiv:2009.06433
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Tyagi A., 2022, IEEE Transactions on Visualization and Computer Graphics
   Tyagi A., 1912, IEEE Transactions on Visualization and Computer Graphics, V4
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   von Rueden L, 2021, Arxiv, DOI arXiv:1903.12394
   Wang JP, 2022, IEEE T VIS COMPUT GR, V28, P4141, DOI 10.1109/TVCG.2021.3076749
   Wang JP, 2020, IEEE PAC VIS SYMP, P51, DOI 10.1109/PacificVis48177.2020.3542
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang X., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P4
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wattenberg M., 2016, Distill, V1, P7
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wu TS, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P747
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yang W., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P4
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI DOI 10.1145/1377966.1377971
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
NR 93
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 672
EP 682
DI 10.1109/TVCG.2023.3326591
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500129
PM 37871059
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wetzels, F
   Pont, M
   Tierny, J
   Garth, C
AF Wetzels, Florian
   Pont, Mathieu
   Tierny, Julien
   Garth, Christoph
TI Merge Tree Geodesics and Barycenters with Path Mappings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topological data analysis; merge trees; scalar data; ensemble data
ID PERSISTENCE; DISTANCES; SYMMETRY; GRAPHS
AB Comparative visualization of scalar fields is often facilitated using similarity measures such as edit distances. In this paper, we describe a novel approach for similarity analysis of scalar fields that combines two recently introduced techniques: Wasserstein geodesics/barycenters as well as path mappings, a branch decomposition-independent edit distance. Effectively, we are able to leverage the reduced susceptibility of path mappings to small perturbations in the data when compared with the original Wasserstein distance. Our approach therefore exhibits superior performance and quality in typical tasks such as ensemble summarization, ensemble clustering, and temporal reduction of time series, while retaining practically feasible runtimes. Beyond studying theoretical properties of our approach and discussing implementation aspects, we describe a number of case studies that provide empirical insights into its utility for comparative visualization, and demonstrate the advantages of our method in both synthetic and real-world scenarios. We supply a C++ implementation that can be used to reproduce our results.
C1 [Wetzels, Florian; Garth, Christoph] Univ Kaiserslautern Landau, Kaiserslautern, Germany.
   [Pont, Mathieu; Tierny, Julien] Sorbonne Univ, CNRS, Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne Universite
RP Wetzels, F (corresponding author), Univ Kaiserslautern Landau, Kaiserslautern, Germany.
EM wetzels@rptu.de; mathieu.pont@sorbonne-universite.fr;
   julien.tierny@sorbonne-universite.fr; garth@rptu.de
OI Pont, Mathieu/0000-0002-0037-0314; Wetzels, Florian/0000-0002-5526-7138;
   Garth, Christoph/0000-0003-1669-8549
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Ahrens J., 2005, VISUALIZATION HDB, P717, DOI [10.1016/b978-012387582-2/50038-1, DOI 10.1016/B978-012387582-2/50038-1, 10.1016/B978-012387582-2/50038-1]
   [Anonymous], 2014, Topological Methods in Data Analysis and Visualization III, Theory, Algorithms, and Applications, DOI [DOI 10.1007/978-3-319-04099, 10.1007/978-3-319-04099-8]
   Bauer U., 2016, P EUROGRAPHICS 2016, DOI [DOI 10.2312/3DOR.20161084, 10.2312/3dor.20161084.2]
   Bauer U., 2014, P 30 ANN S COMPUTATI, P464
   Bollen B, 2023, IEEE T VIS COMPUT GR, V29, P1168, DOI 10.1109/TVCG.2022.3209395
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2010, IEEE T VIS COMPUT GR, V16, P248, DOI 10.1109/TVCG.2009.69
   Bronstein A. M., 2009, Monographs in Computer Science, DOI [10.1007/978-0-387-73301-26, DOI 10.1007/978-0-387-73301-26]
   Carr H., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P49
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Chazal F, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P237, DOI 10.1145/1542362.1542407
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cohen-Steiner D, 2010, FOUND COMPUT MATH, V10, P127, DOI 10.1007/s10208-010-9060-6
   Di Fabio B, 2016, DISCRETE COMPUT GEOM, V55, P423, DOI 10.1007/s00454-016-9758-6
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   Edelsbrunner H., 2010, American Mathematical Society, V2, P3
   Edelsbrunner H, 2008, COMP GEOM-THEOR APPL, V41, P149, DOI 10.1016/j.comgeo.2007.11.001
   Elkan C., 2003, MACH LEARN P 20 INT, P5
   Evers M., COMPUTER VISION IMAG
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Gasparovic E., 2019, arXiv, DOI 10.48550/arXiv.1908.000632
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kopp Wiebke, 2023, IEEE Trans Vis Comput Graph, V29, P1157, DOI 10.1109/TVCG.2022.3209387
   Kraus M, 2010, IMAGAPP & IVAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS, P132
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lohfink A. P., 2021, Source Code for Fuzzy Contour Trees: Alignment and Joint Layout of Multiple Contour Trees
   Lohfink AP, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P86, DOI [10.1109/VIS49827.2021.00025, 10.1109/VIS49827.2021.9623286]
   Lohfink AP, 2020, COMPUT GRAPH FORUM, V39, P343, DOI 10.1111/cgf.13985
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Lukasczyk J, 2017, COMPUT GRAPH FORUM, V36, P13, DOI 10.1111/cgf.13164
   Morozov D., 2014, TOPOINVIS
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Morozov Dmitriy, 2014, Topological Methods in Data Analysis and Visualization, VIII, P89, DOI [10.1007/978-3-319-04099-86, DOI 10.1007/978-3-319-04099-86]
   Narayanan V, 2015, IEEE PAC VIS SYMP, P263, DOI 10.1109/PACIFICVIS.2015.7156386
   Nilsson E, 2022, 2022 IEEE WORKSHOP ON TOPOLOGICAL DATA ANALYSIS AND VISUALIZATION (TOPOINVIS 2022), P92, DOI 10.1109/TopoInVis57755.2022.00016
   Oesterling P., 2017, Topological Methods in Data Analysis and Visualization IV, P87, DOI [DOI 10.1007/978-3-319-44684-4_5.2, 10.1007/978-3-319-44684-4_52, DOI 10.1007/978-3-319-44684-4_52]
   Pascucci V., 2004, IASTED
   Patchett J., The IEEE SciVis Contest
   Pont M, 2023, IEEE T VIS COMPUT GR, V29, P1573, DOI 10.1109/TVCG.2022.3215001
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Popinet S., 2004, ClusterWorld, V2, P7
   Saikia H, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13163
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Schnorr A, 2020, IEEE T VIS COMPUT GR, V26, P2219, DOI 10.1109/TVCG.2018.2883630
   Shu QY, 2016, IEEE PAC VIS SYMP, P56, DOI 10.1109/PACIFICVIS.2016.7465251
   Sridharamurthy R, 2023, IEEE T VIS COMPUT GR, V29, P1518, DOI 10.1109/TVCG.2021.3122176
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Takahashi S, 2004, GRAPH MODELS, V66, P24, DOI 10.1016/j.gmod.2003.08.002
   Taylor R., 2008, The IEEE SciVis Contest
   Thomas DM, 2013, IEEE T VIS COMPUT GR, V19, P2663, DOI 10.1109/TVCG.2013.148
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Turner K, 2014, DISCRETE COMPUT GEOM, V52, P44, DOI 10.1007/s00454-014-9604-7
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P1416, DOI 10.1109/TVCG.2007.70601
   Weinkauf T, 2010, IEEE T VIS COMPUT GR, V16, P1225, DOI 10.1109/TVCG.2010.198
   Wetzels F., Merge tree geodesics and barycenters with path mappings, DOI [10.5281/zenodo.8160990,2023.10, DOI 10.5281/ZENODO.8160990,2023.10]
   Wetzels F, 2022, 2022 IEEE WORKSHOP ON TOPOLOGICAL DATA ANALYSIS AND VISUALIZATION (TOPOINVIS 2022), P29, DOI 10.1109/TopoInVis57755.2022.00010
   Wetzels F, 2022, COMPUT GRAPH FORUM, V41, P367, DOI 10.1111/cgf.14547
   Widanagamaachchi W., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P9, DOI 10.1109/LDAV.2012.6378962
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2023, IEEE T VIS COMPUT GR, V29, P3489, DOI 10.1109/TVCG.2022.3163349
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
NR 68
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1095
EP 1105
DI 10.1109/TVCG.2023.3326601
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500090
PM 37878452
OA hybrid, Green Submitted, Green Published
DA 2024-08-05
ER

PT J
AU Xia, JZ
   Huang, LQ
   Sun, YP
   Deng, ZW
   Zhang, XL
   Zhu, MF
AF Xia, Jiazhi
   Huang, Linquan
   Sun, Yiping
   Deng, Zhiwei
   Zhang, Xiaolong Luke
   Zhu, Minfeng
TI A Parallel Framework for Streaming Dimensionality Reduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE High-dimensional data visualization; dimensionality reduction; streaming
   data visualization
ID VISUALIZATION
AB The visualization of streaming high-dimensional data often needs to consider the speed in dimensionality reduction algorithms, the quality of visualized data patterns, and the stability of view graphs that usually change over time with new data. Existing methods of streaming high-dimensional data visualization primarily line up essential modules in a serial manner and often face challenges in satisfying all these design considerations. In this research, we propose a novel parallel framework for streaming high-dimensional data visualization to achieve high data processing speed, high quality in data patterns, and good stability in visual presentations. This framework arranges all essential modules in parallel to mitigate the delays caused by module waiting in serial setups. In addition, to facilitate the parallel pipeline, we redesign these modules with a parametric non-linear embedding method for new data embedding, an incremental learning method for online embedding function updating, and a hybrid strategy for optimized embedding updating. We also improve the coordination mechanism among these modules. Our experiments show that our method has advantages in embedding speed, quality, and stability over other existing methods to visualize streaming high-dimensional data.
C1 [Xia, Jiazhi; Huang, Linquan; Sun, Yiping; Deng, Zhiwei] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhang, Xiaolong Luke] Penn State Univ, University Pk, PA USA.
   [Zhu, Minfeng] Zhejiang Univ, Hangzhou, Peoples R China.
C3 Central South University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Pennsylvania State University; Pennsylvania State
   University - University Park; Zhejiang University
RP Zhu, MF (corresponding author), Zhejiang Univ, Hangzhou, Peoples R China.
EM xiajiazhi@csu.edu.cn; lnquanhuang@csu.edu.cn; yipingsun@csu.edu.cn;
   dengzhiwei@csu.edu.cn; lzhang@ist.psu.edu; minfeng_zhu@zju.edu.cn
OI Zhu, Minfeng/0000-0002-6711-3099
FU National Natural Science Foundation of China
FX No Statement Available
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Ali M, 2019, VISUAL COMPUT, V35, P1013, DOI 10.1007/s00371-019-01673-y
   Allaoui M, 2020, IMAGE SIGNAL PROCESS, P317, DOI 10.1007/978-3-030-51935
   Alsakran J, 2011, IEEE PAC VIS SYMP, P131, DOI 10.1109/PACIFICVIS.2011.5742382
   Anguita D, 2013, ESANN
   Asuncion Arthur, 2007, UCI machine learning repository
   Blondel M., 2020, INT C MACHINE LEARNI, P950
   Boggs P.T., 1995, ACTA NUMER, V4, P1, DOI [DOI 10.1017/S0962492900002518, 10.1017/S0962492900002518]
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Cha Hyuntak, 2021, ICCV, P9516
   Chen X, 2022, IEEE T VIS COMPUT GR, V28, P593, DOI 10.1109/TVCG.2021.3114880
   Cheng S., 2016, NEW YORK SCI DATA SU, P1, DOI [10.1109/NYSDS.2016.77478082, DOI 10.1109/NYSDS.2016.77478082]
   Crnovrsanin T., 2015, An incremental layout method for visualizing online dynamic graphs, V21, P1629, DOI [10.1007/978-3-319-27261-0_22,8, DOI 10.1007/978-3-319-27261-0_22,8]
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Cunningham P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459665
   Dasgupta A, 2018, COMPUT GRAPH FORUM, V37, P254, DOI 10.1111/cgf.13264
   Neves TTDT, 2022, COMPUT GRAPH-UK, V102, P233, DOI 10.1016/j.cag.2021.08.009
   Dehvari M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104336
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fort S, 2021, ADV NEUR IN, V34
   Frishman Y, 2008, IEEE T VIS COMPUT GR, V14, P727, DOI 10.1109/TVCG.2008.11
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gansner Emden R., 2013, Journal of Graph Algorithms and Applications, V17, P515, DOI 10.7155/jgaa.00302
   Gorochowski TE, 2012, IEEE T VIS COMPUT GR, V18, P1343, DOI 10.1109/TVCG.2011.142
   Gorsuch R. L., 2013, Psychology press, V1
   Hinterreiter A., 2023, COMPUT GRAPH FORUM, DOI [10.1111/cgf.148342, DOI 10.1111/CGF.148342]
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jäckle D, 2016, IEEE T VIS COMPUT GR, V22, P141, DOI 10.1109/TVCG.2015.2467553
   Jia P, 2009, PATTERN RECOGN LETT, V30, P1457, DOI 10.1016/j.patrec.2009.08.005
   Jo J, 2020, IEEE T VIS COMPUT GR, V26, P1347, DOI 10.1109/TVCG.2018.2869149
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kaski S, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-48
   Ke Z., 2021, arXiv
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Krstajic Milos, 2013, 2013 IEEE International Conference on Big Data, P41, DOI 10.1109/BigData.2013.6691713
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Lai CH, 2022, IEEE VIS CONF, P75, DOI 10.1109/VIS54862.2022.00024
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li W, 2020, IEEE T KNOWL DATA EN, V32, P1475, DOI 10.1109/TKDE.2019.2909204
   Li Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P231, DOI [10.1109/IoTaIS47347.2019.8980418, 10.1109/iotais47347.2019.8980418]
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Lin CC, 2011, INFORM SCIENCES, V181, P4253, DOI 10.1016/j.ins.2011.06.005
   Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990
   Mahapatra S, 2017, IEEE INT CONF BIG DA, P716, DOI 10.1109/BigData.2017.8257987
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Miglani A., Corona virus tagged data
   Palumbo F, 2016, J AMB INTEL SMART EN, V8, P87, DOI 10.3233/AIS-160372
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Rauber P.E., 2016, P EUROGRAPHICS IEEE, P2016, DOI DOI 10.2312/EUROVISSHORT.201611642,4
   Ren J., 2019, Advances in Neural Information Processing Systems, V32, P14680
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sainburg T, 2021, NEURAL COMPUT, V33, P2881, DOI 10.1162/neco_a_01434
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Steiger M, 2014, COMPUT GRAPH FORUM, V33, P401, DOI 10.1111/cgf.12396
   Tang SX, 2021, AAAI CONF ARTIF INTE, V35, P2665
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thudumu S, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00320-x
   Van Der Maaten L., 2009, P MACHINE LEARNING R, P384
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vernier EF, 2021, COMPUT GRAPH FORUM, V40, P87, DOI 10.1111/cgf.14291
   Wang YQ, 2022, IEEE T VIS COMPUT GR, V28, P623, DOI 10.1109/TVCG.2021.3114765
   Webga K, 2015, IEEE SYM VIS CYB SEC
   Wei YT, 2024, IEEE T VIS COMPUT GR, V30, P3915, DOI 10.1109/TVCG.2023.3243228
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xia J, 2013, TSINGHUA SCI TECHNOL, V18, P196, DOI 10.1109/TST.2013.6509102
   Xiaotong Liu, 2013, 2013 IEEE International Conference on Big Data, P48, DOI 10.1109/BigData.2013.6691714
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Zhang L., 2016, IEEE Transactions on Systems, Man, and Cybernetics: Systems, V47, P6
NR 77
TC 0
Z9 0
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 142
EP 152
DI 10.1109/TVCG.2023.3326515
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500089
PM 37871057
DA 2024-08-05
ER

PT J
AU Fu, Q
   He, SH
   Li, XM
   Fu, HB
AF Fu, Qiang
   He, Shuhan
   Li, Xueming
   Fu, Hongbo
TI PlanNet: A Generative Model for Component-Based Plan Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Floors; Layout; Semantics; Three-dimensional displays; Wave functions;
   Buildings; Task analysis; Generative model; wave function collapse;
   floor plan synthesis
ID GAN
AB We propose a novel generative model named as PlanNet for component-based plan synthesis. The proposed model consists of three modules, a wave function collapse algorithm to create large-scale wireframe patterns as the embryonic forms of floor plans, and two deep neural networks to outline the plausible boundary from each squared pattern, and meanwhile estimate the potential semantic labels for the components. In this manner, we use PlanNet to generate a large-scale component-based plan dataset with 10 K examples. Given an input boundary, our method retrieves dataset plan examples with similar configurations to the input, and then transfers the space layout from a user-selected plan example to the input. Benefiting from our interactive workflow, users can recursively subdivide individual components of the plans to enrich the plan contents, thus designing more complex plans for larger scenes. Moreover, our method also adopts a random selection algorithm to make the variations on semantic labels of the plan components, aiming at enriching the 3D scenes that the output plans are suited for. To demonstrate the quality and versatility of our generative model, we conduct intensive experiments, including the analysis of plan examples and their evaluations, plan synthesis with both hard and soft boundary constraints, and 3D scenes designed with the plan subdivision on different scales. We also compare our results with the state-of-the-art floor plan synthesis methods to validate the feasibility and efficacy of the proposed generative model.
C1 [Fu, Qiang; He, Shuhan; Li, Xueming] Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing 100876, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Beijing University of Posts & Telecommunications; City University of
   Hong Kong
RP Fu, Q (corresponding author), Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing 100876, Peoples R China.
EM fu.john.qiang@gmail.com; heshuhan@bupt.edu.cn; lixm@bupt.edu.cn;
   fuplus@gmail.com
OI Fu, Qiang/0000-0002-8944-8981; LI, xueming/0000-0003-1058-2799; FU,
   Hongbo/0000-0002-0284-726X
FU National Natural Science Foundation of China [61902032]
FX No Statement Available
CR Aliaga DG, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409113
   Bao F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421644
   Chen XW, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P321, DOI 10.1145/2733373.2806274
   Douglas D. H., 1973, Can. Cartogr., V10, P112, DOI [10.3138/FM57-6770-U75U-7727, DOI 10.3138/FM57-6770-U75U-7727]
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929
   Fu Q, 2024, IEEE T VIS COMPUT GR, V30, P4068, DOI 10.1109/TVCG.2023.3250488
   Fu Q, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-019-2930-x
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gumin M., 2016, Wavefunction collapse
   Hendrikx M, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422957
   Hu RZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392391
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Li JN, 2021, IEEE T VIS COMPUT GR, V27, P4039, DOI 10.1109/TVCG.2020.2999335
   Li MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3303766
   Lin JJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024217
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Nauata N, 2021, PROC CVPR IEEE, P13627, DOI 10.1109/CVPR46437.2021.01342
   Nauata Nelson, 2020, COMPUTER VISION ECCV, P162
   Para W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6670, DOI 10.1109/ICCV48922.2021.00662
   Peng CH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925935
   Peng CH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601164
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schulz A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601127
   Shen CH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366199
   Su XY, 2016, COMPUT GRAPH-UK, V54, P145, DOI 10.1016/j.cag.2015.06.009
   Sun JH, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530135
   Vanegas CA, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366187
   Wang K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322941
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Wu WM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356556
   Wu WM, 2018, COMPUT GRAPH FORUM, V37, P511, DOI 10.1111/cgf.13380
   Xiong GM, 2021, IEEE T VIS COMPUT GR, V27, P4413, DOI 10.1109/TVCG.2020.3005680
   Xu H., 2014, P 27 ANN ACM S US IN, P243, DOI DOI 10.1145/2642918.2647398
   Xu K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601109
   Xu PF, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2787, DOI 10.1145/2702123.2702198
   Yang YL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508405
   Yu Dianhai, 2019, Frontiers of Data and Domputing, V1, P105
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zhang SK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P965, DOI 10.1145/3474085.3475194
   Zhang SH, 2022, IEEE T VIS COMPUT GR, V28, P3082, DOI 10.1109/TVCG.2021.3050143
   Zou CQ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925887
NR 43
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4739
EP 4751
DI 10.1109/TVCG.2023.3275200
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400087
PM 37167051
DA 2024-08-05
ER

PT J
AU Grubert, J
   Witzani, L
   Otte, A
   Gesslein, T
   Kranz, M
   Kristensson, PO
AF Grubert, Jens
   Witzani, Lukas
   Otte, Alexander
   Gesslein, Travis
   Kranz, Matthias
   Kristensson, Per Ola
TI Text Entry Performance and Situation Awareness of a Joint Optical
   See-Through Head-Mounted Display and Smartphone System
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; cross-device; head-mounted display; mobile;
   multi-display; optical see-through; text entry
ID PHONE; DISTRACTION; CHALLENGES; LEGIBILITY
AB Optical see-through head-mounted displays (OST HMDs) are a popular output medium for mobile Augmented Reality (AR) applications. To date, they lack efficient text entry techniques. Smartphones are a major text entry medium in mobile contexts but attentional demands can contribute to accidents while typing on the go. Mobile multi-display ecologies, such as combined OST HMD-smartphone systems, promise performance and situation awareness benefits over single-device use. We study the joint performance of text entry on mobile phones with text output on optical see-through head-mounted displays. A series of five experiments with a total of 86 participants indicate that, as of today, the challenges in such a joint interactive system outweigh the potential benefits.
C1 [Grubert, Jens] Coburg Univ Appl Sci & Arts, Human Comp Interact Internet Things, D-96450 Coburg, Germany.
   [Witzani, Lukas] Univ Passau, D-96450 Passau, Germany.
   [Otte, Alexander] Coburg Univ Appl Sci & Arts, D-94032 Coburg, Germany.
   [Gesslein, Travis] Coburg Univ Appl Sci & Arts, Coburg CB2 1TN, Germany.
C3 Klinikum Coburg; University of Passau; Klinikum Coburg
RP Grubert, J (corresponding author), Coburg Univ Appl Sci & Arts, Human Comp Interact Internet Things, D-96450 Coburg, Germany.
EM jens.grubert@hs-coburg.de; lukas.witzani@uni-passau.de;
   alexander.otte@hs-coburg.de; travis.gesslein@hs-coburg.de;
   matthias.kranz@uni-passau.de; pok21@cam.ac.uk
RI Kranz, Matthias/E-1703-2013; Grubert, Jens/B-1012-2018
OI Kranz, Matthias/0000-0003-3835-4974; Kristensson, Per
   Ola/0000-0002-7139-871X; Grubert, Jens/0000-0002-3858-2961
CR Aksit K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130892
   Arefin MS, 2022, IEEE T VIS COMPUT GR, V28, P2014, DOI 10.1109/TVCG.2022.3150503
   Arefin MS, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P571, DOI [10.1109/VRW50115.2020.0-139, 10.1109/VRW50115.2020.00137]
   Bai HD, 2021, COMPUT GRAPH-UK, V97, P42, DOI 10.1016/j.cag.2021.04.004
   Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Brun D, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382837
   Consolvo S, 2003, IEEE PERVAS COMPUT, V2, P24, DOI 10.1109/MPRV.2003.1203750
   Cook T., 2018, P IEEE C VIRT REAL 3, P1
   Darbar R., 2021, P GRAPH INT, P117, DOI 10.20380/GI2021.14
   Darius S, 2015, ZENTRALBLATT ARB ARB, V65, P203, DOI 10.1007/s40664-015-0026-z
   Drouot M, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P476, DOI 10.1109/VRW52623.2021.00120
   Dube T. J., 2019, International Conference on Human-Computer Interaction, P419
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Dudley JJ, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3232163
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Eiberger A, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357588
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Erickson A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3456874
   Foerster K.-T., 2014, P 13 INT C MOB UB MU, P68, DOI [10.1145/2677972.2677973, DOI 10.1145/2677972.2677973]
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Gabbard JL, 2019, IEEE T VIS COMPUT GR, V25, P2228, DOI 10.1109/TVCG.2018.2832633
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gattullo M, 2015, IEEE COMPUT GRAPH, V35, P52, DOI 10.1109/MCG.2015.36
   Goel Mayank, 2012, P SIGCHI C HUM FACT, P2687
   González G, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P109, DOI 10.1007/978-1-84882-352-5_11
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Grubert J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3933, DOI 10.1145/2702123.2702331
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P49, DOI 10.1145/2984511.2984576
   Gupta D., 2004, Ph.D. dissertation
   HART S G, 1988, P139
   Hincapie-Ramos J. D., 2013, P SIGCHI C HUM FACT, P3385, DOI DOI 10.1145/2470654.2466463
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Huckauf A., 2010, P 7 S APPL PERC GRAP, P41, DOI DOI 10.1145/1836248.1836255
   Imamov S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P851, DOI [10.1109/VR46266.2020.1581435674325, 10.1109/VR46266.2020.00110]
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Jiang HY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143063
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kim J. H., 2013, P INT C DIG HUM MOD, P239, DOI DOI 10.1007/978-3-642-39182-828
   Kim S., 2004, P ACM SIGGRAPH INT C, P336
   Knierim Pascal, 2021, i-com: Journal of Interactive Media, V20, P49, DOI 10.1515/icom-2021-0003
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kristensson PO, 2015, COMPUTER, V48, P84, DOI 10.1109/MC.2015.185
   Kristensson PO, 2009, AI MAG, V30, P85, DOI 10.1609/aimag.v30i4.2269
   Lakens D, 2018, ADV METH PRACT PSYCH, V1, P259, DOI 10.1177/2515245918770963
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Langner R., 2021, P CHI C HUM FACT COM, P1
   Liu XF, 2017, IEEE T MOBILE COMPUT, V16, P394, DOI 10.1109/TMC.2016.2550447
   Lucero A., 2014, P 11 C ADV COMP ENT, DOI DOI 10.1145/2663806.2663824
   Lyons K., 2004, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI'04, P671, DOI 10.1145/985692.985777
   Menzner T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1080, DOI 10.1109/VR.2019.8797754
   Messing R., 2005, ACM Transactions on Applied Perception, V2, P234, DOI [DOI 10.1145/1077399.1077403, 10.1145/1077399.10774032,3,9]
   Mohr P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300815
   Nasar JL, 2013, ACCIDENT ANAL PREV, V57, P91, DOI 10.1016/j.aap.2013.03.021
   Normand E, 2018, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2018.00043
   Norton W. J., 2021, P FUT TECHN C, P443
   Orlosky J., 2013, P INT C INT US INT, P363, DOI [DOI 10.1145/2449396, 10.1145/2449396.2449443, DOI 10.1145/2449396.2449443]
   Oshima K, 2016, P IEEE VIRT REAL ANN, P253, DOI 10.1109/VR.2016.7504749
   Otte A, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P387, DOI 10.1109/ISMAR-Adjunct.2019.000-4
   Otte A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1729, DOI 10.1109/VR.2019.8797740
   Oulasvirta A., 2005, P SIGCHI C HUM FACT, P919, DOI DOI 10.1145/1054972.1055101
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364265
   Rau PLP, 2021, INFORM LEARN SCI, V122, P464, DOI 10.1108/ILS-11-2020-0236
   Reyal S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P679, DOI 10.1145/2702123.2702597
   Rheinberg F., 2002, P 1 INT POS PSYCH SU
   Rzayev R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173619
   Schwebel DC, 2012, ACCIDENT ANAL PREV, V45, P266, DOI 10.1016/j.aap.2011.07.011
   SEARS A, 1993, BEHAV INFORM TECHNOL, V12, P17, DOI 10.1080/01449299308924362
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Taylor R.M., 2017, Situational Awareness, P111, DOI [10.4324/9781315087924, DOI 10.4324/9781315087924]
   Tuceryan M, 2002, PRESENCE-TELEOP VIRT, V11, P259, DOI 10.1162/105474602317473213
   Van Dam J, 2020, J TRANSP SAF SECUR, V12, P1007, DOI 10.1080/19439962.2018.1564947
   Vertanen K., 2011, P 13 INT C HUM COMP, P295, DOI [DOI 10.1145/2037373.2037418, 10.1145/2037373.20374183,5,9]
   Vertanen K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174200
   Vertanen K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P659, DOI 10.1145/2702123.2702135
   Wang YH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051582
   Weir D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2307
   Wen JQ, 2015, INT CONF PERVAS COMP, P105, DOI 10.1109/PERCOM.2015.7146516
   Wenig D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P716, DOI 10.1145/3025453.3025852
   Wilson A, 2018, PROC SPIE, V10676, DOI 10.1117/12.2315771
   Winterbottom MD, 2007, HUM FACTORS, V49, P907, DOI 10.1518/001872007X230253
   Wolf D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P347, DOI 10.1109/VR.2018.8448289
   Woodward J, 2023, IEEE T VIS COMPUT GR, V29, P2166, DOI 10.1109/TVCG.2022.3141585
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Xu WG, 2019, IEEE T VIS COMPUT GR, V25, P1991, DOI 10.1109/TVCG.2019.2898736
   Yadav AK, 2022, TRANSPORT RES F-TRAF, V91, P236, DOI 10.1016/j.trf.2022.10.008
   Zhu FY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376233
NR 89
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5830
EP 5846
DI 10.1109/TVCG.2023.3309316
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400041
PM 37639421
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hogräfer, M
   Schulz, HJ
AF Hografer, Marius
   Schulz, Hans-Jorg
TI Tailorable Sampling for Progressive Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Pipelines; Data visualization; Visual analytics;
   Switches; Data structures; Image color analysis; Progressive visual
   analytics; sampling; visual analytics
ID VISUALIZATIONS
AB Progressive visual analytics (PVA) allows analysts to maintain their flow during otherwise long-running computations by producing early, incomplete results that refine over time, for example, by running the computation over smaller partitions of the data. These partitions are created using sampling, whose goal it isto draw samples of the dataset such that the progressive visualization becomes as useful as possible as soon as possible. What makes the visualization useful depends on the analysis task and, accordingly, some task-specific sampling methods have been proposed for PVA to address this need. However, as analysts see more and more of their data during the progression, the analysis task at hand often changes, which means that analysts need to restart the computation to switch the sampling method, causing them to lose their analysis flow. This poses a clear limitation to the proposed benefits of PVA. Hence, we propose a pipeline for PVA-sampling that allows tailoring the data partitioning to analysis scenarios by switching out modules in a way that does not require restarting the analysis. To that end, we characterize the problem of PVA-sampling, formalize the pipeline in terms of data structures, discuss on-the-fly tailoring, and present additional examples demonstrating its usefulness.
C1 [Hografer, Marius; Schulz, Hans-Jorg] Aarhus Univ, Dept Comp Sci, DK-8000 Aarhus, Denmark.
C3 Aarhus University
RP Hogräfer, M (corresponding author), Aarhus Univ, Dept Comp Sci, DK-8000 Aarhus, Denmark.
EM mhograefer@cs.au.dk; hjschulz@cs.au.dk
RI Schulz, Hans-Jorg/G-1788-2013
OI Schulz, Hans-Jorg/0000-0001-9974-535X
FU Innovationsfonden
FX No Statement Available
CR Agarwal B., 2013, EUROSYS, P29
   Agarwal S, 2012, PROC VLDB ENDOW, V5, P1902, DOI 10.14778/2367502.2367533
   Angelini M., 2019, P 10 INT EUROVIS WOR, P25, DOI [10.2312/eu-rova.20191120, DOI 10.2312/EU-ROVA.20191120]
   Angelini M, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5030031
   Badam SK, 2017, COMPUT GRAPH FORUM, V36, P491, DOI 10.1111/cgf.13205
   Berg L, 2019, PROC VLDB ENDOW, V12, P1814, DOI 10.14778/3352063.3352073
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen X, 2022, IEEE T VIS COMPUT GR, V28, P593, DOI 10.1109/TVCG.2021.3114880
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Cui Z, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P48, DOI [10.1109/VDS48975.2019.8973384, 10.1109/vds48975.2019.8973384]
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Ding BL, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P679, DOI 10.1145/2882903.2915249
   Ellis Geoffrey., 2005, ACM SIGCHI C HUMAN F, P1351, DOI [10.1145/1056808.1056914, DOI 10.1145/1056808.1056914]
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Fekete JD, 2016, Arxiv, DOI arXiv:1607.05162
   Fisher D., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P73, DOI 10.1109/LDAV.2011.6092320
   Gu B., 2001, MACHINE LEARNING ECM, P192, DOI [10.1007/3-540-44795-4_17, DOI 10.1007/3-540-44795-4_17]
   Heer J, 2006, IEEE T VIS COMPUT GR, V12, P853, DOI 10.1109/TVCG.2006.178
   Hografer M., 2022, P EUROVIS WORKSH VIS, P49, DOI [10.2312/eurova.20221079, DOI 10.2312/EUROVA.20221079]
   Hogräfer M, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3531229
   Jo J, 2021, IEEE T VIS COMPUT GR, V27, P3109, DOI 10.1109/TVCG.2019.2962404
   Kwon BC, 2017, IEEE COMPUT GRAPH, V37, P100, DOI 10.1109/MCG.2017.6
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1151, DOI 10.1109/TVCG.2019.2934537
   Losing V, 2016, IEEE DATA MINING, P291, DOI [10.1109/ICDM.2016.141, 10.1109/ICDM.2016.0040]
   Micallef L., 2019, P EUROVIS SHORT PAP, P19, DOI [10.2312/evs.20191164, DOI 10.2312/EVS.20191164]
   OLKEN F, 1990, LECT NOTES COMPUT SC, V420, P92
   Onus M, 2007, SIAM PROC S, P99
   Patil Ameya, 2023, IEEE Trans Vis Comput Graph, V29, P407, DOI 10.1109/TVCG.2022.3209426
   Procopio M, 2022, IEEE T VIS COMPUT GR, V28, P3093, DOI 10.1109/TVCG.2021.3051013
   Procopio M, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6010014
   Provost FJ, 1999, Efficient progressive sampling, P23, DOI DOI 10.1145/312129.312188
   Rahman S, 2017, PROC VLDB ENDOW, V10, P1262, DOI 10.14778/3137628.3137637
   Schulz HJ, 2016, IEEE T VIS COMPUT GR, V22, P1830, DOI 10.1109/TVCG.2015.2462356
   Sculley D., 2010, P 19 INT C WORLD WID, P1177
   Settles B., 2009, Tech. Rep. 1649
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Turkay C, 2017, IEEE T VIS COMPUT GR, V23, P131, DOI 10.1109/TVCG.2016.2598470
   VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165
   Williams M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2004.60
   Yang J, 2003, VLDB J, V12, P262, DOI 10.1007/S00778-003-0107-Z
   Zgraggen E, 2017, IEEE T VIS COMPUT GR, V23, P1977, DOI 10.1109/TVCG.2016.2607714
   Zheng Y., 2013, P ACM SIGMOD INT C M, P433, DOI [DOI 10.1145/2463676,2465319, DOI 10.1145/2463676.2465319]
   Zheng Y, 2017, 2017 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P23, DOI 10.1109/VDS.2017.8573446
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
NR 45
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4809
EP 4824
DI 10.1109/TVCG.2023.3278084
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400020
PM 37204960
OA hybrid
DA 2024-08-05
ER

PT J
AU Wu, DY
   Le, TNH
   Yao, SY
   Lin, YC
   Lee, TY
AF Wu, Dong-Yi
   Le, Thi-Ngoc-Hanh
   Yao, Sheng-Yi
   Lin, Yun-Chen
   Lee, Tong-Yee
TI Image Collage on Arbitrary Shape via Shape-Aware Slicing and
   Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Layout; Visualization; Optimization; Partitioning algorithms;
   Task analysis; Social networking (online); Image collection
   visualization; image collage; irregular shape layout
ID DECOMPOSITION; PARTS; RULE
AB Image collage is a very useful tool for visualizing an image collection. Most of the existing methods and commercial applications for generating image collages are designed on simple shapes, such as rectangular and circular layouts. This greatly limits the use of image collages in some artistic and creative settings. Although there are some methods that can generate irregularly-shaped image collages, they often suffer from severe image overlapping and excessive blank space. This prevents such methods from being effective information communication tools. In this article, we present a shape slicing algorithm and an optimization scheme that can create image collages of arbitrary shapes in an informative and visually pleasing manner given an input shape and an image collection. To overcome the challenge of irregular shapes, we propose a novel algorithm, called Shape-Aware Slicing, which partitions the input shape into cells based on medial axis and binary slicing tree. Shape-Aware Slicing,which is designed specifically for irregular shapes, takes human perception and shape structure into account to generate visually pleasing partitions. Then, the layout is optimized by analyzing input images with the goal of maximizing the total salient regions of the images. To evaluate our method, we conduct extensive experiments and compare our results against previous work. The evaluations show that our proposed algorithm can efficiently arrange image collections on irregular shapes and create visually superior results than prior work and existing commercial tools.
C1 [Wu, Dong-Yi; Le, Thi-Ngoc-Hanh; Yao, Sheng-Yi; Lin, Yun-Chen; Lee, Tong-Yee] Natl Cheng Kung Univ, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Tainan 701, Taiwan.
EM cutechubbit@gmail.com; ngochanh.le1987@gmail.com;
   nd8081018@gs.ncku.edu.tw; f74042060@gmail.com; tonylee@mail.ncku.edu.tw
RI Hanh, Le Thi Ngoc/JQI-5639-2023
OI Hanh, Le Thi Ngoc/0000-0001-9667-9780; Yao,
   Sheng-Yi/0000-0002-7233-9615; , Dong-Yi/0000-0002-6889-5520
FU National Science and Technology Council [111-2221-E-006-112-MY3,
   110-2221-E-006-135-MY3]; Republic of China (ROC), Taiwan
FX This work was supported in part by the National Science and Technology
   Council under Grants 111-2221-E-006-112-MY3 and 110-2221-E-006-135-MY3,
   Republic of China (ROC), Taiwan.
CR Adobe, 2021, Photo collage
   [Anonymous], 1997, Pacific J. Math., V181, P57
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   De Winter J, 2006, COGNITION, V99, P275, DOI 10.1016/j.cognition.2005.03.004
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Han XT, 2016, IEEE T CYBERNETICS, V46, P1286, DOI 10.1109/TCYB.2015.2448236
   Hofer C., 2017, INT C NEURAL INF PRO, V30, P1634
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lekschas F, 2021, IEEE T VIS COMPUT GR, V27, P358, DOI 10.1109/TVCG.2020.3028948
   Lien JM, 2006, COMP GEOM-THEOR APPL, V35, P100, DOI 10.1016/j.comgeo.2005.10.005
   Liu LJ, 2018, IEEE T VIS COMPUT GR, V24, P1956, DOI 10.1109/TVCG.2017.2703853
   Liu SG, 2017, I C VIRTUAL REALITY, P454, DOI 10.1109/ICVRV.2017.00120
   Luo L, 2015, IEEE T IMAGE PROCESS, V24, P273, DOI 10.1109/TIP.2014.2376188
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   Papanelopoulos Y., 2022, Comput. Vis. Image Understanding, V179, P66
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Singh D. D., 2001, in Psychology, V130, P401
   Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P636, DOI 10.3758/BF03205536
   Song Y, 2023, IEEE T VIS COMPUT GR, V29, P1330, DOI 10.1109/TVCG.2021.3113031
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tan L, 2012, IEEE COMPUT GRAPH, V32, P46, DOI 10.1109/MCG.2011.89
   Wong D. F., 1986, 23rd ACM/IEEE Design Automation Conference. Proceedings 1986 (Cat. No.86CH2288-9), P101, DOI 10.1145/318013.318030
   Wu K., 2013, P AS PAC SIGN INF PR, P1
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Yu L., 2022, P IEEE CVF C COMP VI, P3729
   Zeng JT, 2008, LECT NOTES COMPUT SC, V5359, P682, DOI 10.1007/978-3-540-89646-3_67
NR 29
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4449
EP 4463
DI 10.1109/TVCG.2023.3262039
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400022
PM 37030778
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Liu, SQ
   Tao, MT
   Huang, YF
   Wang, CB
   Li, CH
AF Liu, Shuqi
   Tao, Mingtian
   Huang, Yifei
   Wang, Changbo
   Li, Chenhui
TI Image-Driven Harmonious Color Palette Generation for Diverse Information
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Data visualization; Visualization; Task analysis;
   Encoding; Visual perception; Media; Visualization design; color palette;
   color assignment; information visualization; visual perception
ID MAPS
AB Color has been widely used to encode data in all types of visualizations. Effective color palettes contain discriminable and harmonious colors, which allow information from visualizations to be accurately and aesthetically conveyed. However, predefined color palettes not only lack the flexibility of custom color palette generation but also ignore the context in which the visualizations are used. Designing an effective color palette is a time-consuming and challenging process for users, even experts. In this work, we propose the generation of an image-based visualization color palette to exploit the human perception of visually appealing images while considering visualization cognition. By analyzing color palette constraints, including harmony, discrimination, and context, we propose an image-driven color generation method. We design a color clustering method in the saliency-hue plane based on visual importance detection and then select the palette based on the visualization color constraints. In addition, we design two color optimization and assignment strategies for visualizations of different data types. Evaluations through numeric indicators and user experiments demonstrate that the palettes predicted by our method are visually related to the original images and are aesthetically pleasing, supporting diverse visualization contexts and data types in practical applications.
C1 [Liu, Shuqi; Tao, Mingtian; Huang, Yifei; Wang, Changbo; Li, Chenhui] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200050, Peoples R China.
C3 East China Normal University
RP Li, CH (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200050, Peoples R China.
EM shuqiliu234@gmail.com; 51205901082@stu.ecnu.edu.cn;
   yifeihuang17@gmail.com; cbwang@cs.ecnu.edu.cn; chli@cs.ecnu.edu.cn
OI Li, Chenhui/0000-0001-9835-2650; Wang, Changbo/0000-0001-8940-6418
FU NSFC [62072183]; Shanghai Committee of Science and Technology, China
   [22511104600]
FX This work was supported in part by NSFC under Grant 62072183 and in
   partby the Shanghai Committee of Science and Technology, China under
   Grant 22511104600.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Adobe color, 2022, About us
   Ahmad J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P56, DOI 10.1109/VIS49827.2021.9623314
   Aksoy Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3002176
   [Anonymous], 2022, Aliyun Luban color-recog
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Borland D, 2011, IEEE COMPUT GRAPH, V31, P7, DOI 10.1109/MCG.2011.55
   Brewer C. A., 2005, Designing Better Maps: A Guide for GIS Users, V1
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [10.1016/b978-0-08-042415-6.50014-4, DOI 10.1016/B978-0-08-042415-6.50014-4]
   Burchett KE, 2002, COLOR RES APPL, V27, P28, DOI 10.1002/col.10004
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Du ZJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459675
   Feng ZL, 2018, NEUROCOMPUTING, V273, P395, DOI 10.1016/j.neucom.2017.07.043
   Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398
   Gerstner T., 2012, P S NONPH AN REND, P29
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   Huang YF, 2018, COMPUT GRAPH FORUM, V37, P421, DOI 10.1111/cgf.13579
   Kim E., 2016, P 24 ACM INT C MULT, P1316
   Kim SYO, 2020, INT CONF INTERNET, P154, DOI [10.1145/3372278.3390685, 10.23919/ICITST51030.2020.9351315]
   Kita N, 2016, COMPUT GRAPH FORUM, V35, P127, DOI 10.1111/cgf.13010
   Lara-Alvarez C, 2019, COLOR RES APPL, V44, P106, DOI 10.1002/col.22292
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu KC, 2021, IEEE T VIS COMPUT GR, V27, P475, DOI 10.1109/TVCG.2020.3030406
   Matsuda Y., 1995, Asakura Shoten, V2
   Maxwell BA, 2000, CARTOGR J, V37, P93
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Ou LC, 2004, COLOR RES APPL, V29, P381, DOI 10.1002/col.20047
   Pan Q., 2018, COLOR IMAGING C, P110
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Samsel F, 2021, 2021 IEEE VIS ARTS PROGRAM (VISAP 2021), P20, DOI 10.1109/VISAP52981.2021.00009
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Tan JC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2988229
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tennekes M, 2014, IEEE T VIS COMPUT GR, V20, P2072, DOI 10.1109/TVCG.2014.2346277
   Tokumaru M, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P378, DOI 10.1109/FUZZ.2002.1005020
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Tu WC, 2018, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2018.00066
   Tufte E. R., 1990, Envisioning Information, V2
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   WARE C, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.7760
   Weingerl P, 2020, COLOR RES APPL, V45, P409, DOI 10.1002/col.22485
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Xinrui Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8087, DOI 10.1109/CVPR42600.2020.00811
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4252, DOI 10.1109/TVCG.2021.3085327
   Zeileis A, 2009, COMPUT STAT DATA AN, V53, P3259, DOI 10.1016/j.csda.2008.11.033
   Zeng Q, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P266, DOI [10.1109/visual.2019.8933764, 10.1109/VISUAL.2019.8933764]
   Zhang Q, 2017, IEEE T IMAGE PROCESS, V26, P1952, DOI 10.1109/TIP.2017.2671779
   Zhao NX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201355
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
NR 70
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3089
EP 3103
DI 10.1109/TVCG.2022.3226218
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700073
PM 36459606
DA 2024-08-05
ER

PT J
AU Hong, JY
   Hnatyshyn, R
   Santos, EAD
   Maciejewski, R
   Isenberg, T
AF Hong, Jiayi
   Hnatyshyn, Rostyslav
   Santos, Ebrar A. D.
   Maciejewski, Ross
   Isenberg, Tobias
TI A Survey of Designs for Combined 2D+3D Visual Representations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Data visualization; Visualization; Surveys;
   Two-dimensional displays; Layout; Task analysis; 2D visual
   representations; 3D visual representations; design space
ID DIRECT-TOUCH INTERACTION; COMBINED VISUALIZATION; WALL THICKNESS; 3D;
   EXPLORATION; FRAMEWORK; PERFORMANCE; TRACKING; TOOL; 2D
AB We examine visual representations of data that make use of combinations of both 2D and 3D data mappings. Combining 2D and 3D representations is a common technique that allows viewers to understand multiple facets of the data with which they are interacting. While 3D representations focus on the spatial character of the data or the dedicated 3D data mapping, 2D representations often show abstract data properties and take advantage of the unique benefits of mapping to a plane. Many systems have used unique combinations of both types of data mappings effectively. Yet there are no systematic reviews of the methods in linking 2D and 3D representations. We systematically survey the relationships between 2D and 3D visual representations in major visualization publications-IEEE VIS, IEEE TVCG, and EuroVis-from 2012 to 2022. We closely examined 105 articles where 2D and 3D representations are connected visually, interactively, or through animation. These approaches are designed based on their visual environment, the relationships between their visual representations, and their possible layouts. Through our analysis, we introduce a design space as well as provide design guidelines for effectively linking 2D and 3D visual representations.
C1 [Hong, Jiayi; Hnatyshyn, Rostyslav; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85287 USA.
   [Santos, Ebrar A. D.; Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, F-91190 Gif Sur Yvette, France.
C3 Arizona State University; Arizona State University-Tempe; Universite
   Paris Saclay; Inria; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Cite
RP Hong, JY (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM jhong76@asu.edu; rhnatysh@asu.edu; rmacieje@asu.edu;
   tobias.isenberg@inria.fr
RI ; Isenberg, Tobias/A-7575-2008
OI Hong, Jiayi/0000-0002-1332-5045; Isenberg, Tobias/0000-0001-7953-8644;
   Hnatyshyn, Rostyslav/0009-0006-0510-1152
FU U.S. Department of Homeland Security
FX No Statement Available
CR Abbasloo A, 2016, IEEE T VIS COMPUT GR, V22, P975, DOI 10.1109/TVCG.2015.2467031
   Aboulhassan A, 2015, COMPUT GRAPH FORUM, V34, P401, DOI 10.1111/cgf.12652
   Ageeli Amani, 2023, IEEE Trans Vis Comput Graph, V29, P646, DOI 10.1109/TVCG.2022.3209439
   Agus M, 2019, COMPUT GRAPH FORUM, V38, P427, DOI 10.1111/cgf.13700
   Al-Awami AK, 2016, IEEE T VIS COMPUT GR, V22, P738, DOI 10.1109/TVCG.2015.2467441
   Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   Axelsson E, 2017, COMPUT GRAPH FORUM, V36, P459, DOI 10.1111/cgf.13202
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Badam SK, 2019, INFORM VISUAL, V18, P68, DOI 10.1177/1473871617725907
   Bader R, 2020, IEEE T VIS COMPUT GR, V26, P259, DOI 10.1109/TVCG.2019.2934310
   Baldonado M. Q. W., 2000, Proceedings of the Conference on Advanced Visual Interfaces, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   BECKER RA, 1987, TECHNOMETRICS, V29, P127, DOI 10.2307/1269768
   Berge CSZ, 2014, IEEE T VIS COMPUT GR, V20, P2379, DOI 10.1109/TVCG.2014.2346317
   Besançon L, 2017, IEEE T VIS COMPUT GR, V23, P881, DOI 10.1109/TVCG.2016.2599217
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Biswas A, 2013, IEEE T VIS COMPUT GR, V19, P2683, DOI 10.1109/TVCG.2013.133
   Bock A, 2015, 2015 IEEE Scientific Visualization Conference (SciVis), P17, DOI 10.1109/SciVis.2015.7429487
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brath R, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P25, DOI 10.1109/3DVis.2014.7160096
   Bruckner S, 2019, IEEE T VIS COMPUT GR, V25, P2514, DOI 10.1109/TVCG.2018.2848906
   Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P156, DOI 10.1109/VISUAL.1991.175794
   Burchett JN, 2019, COMPUT GRAPH FORUM, V38, P491, DOI 10.1111/cgf.13705
   Byska J, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12612
   Chen CM, 2016, IEEE T VIS COMPUT GR, V22, P847, DOI 10.1109/TVCG.2015.2467952
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Cornel D, 2015, COMPUT GRAPH FORUM, V34, P331, DOI 10.1111/cgf.12645
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P5406, DOI 10.1109/TVCG.2022.3213565
   Doraiswamy H, 2021, IEEE T VIS COMPUT GR, V27, P561, DOI 10.1109/TVCG.2020.3030441
   Dübel S, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P11, DOI 10.1109/3DVis.2014.7160094
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   Elek O, 2021, IEEE T VIS COMPUT GR, V27, P806, DOI 10.1109/TVCG.2020.3030407
   Elvins T. T., 1992, Computer Graphics, V26, P194, DOI 10.1145/142413.142427
   Eulzer P, 2021, COMPUT GRAPH FORUM, V40, P435, DOI 10.1111/cgf.14319
   Eulzer P, 2021, IEEE T VIS COMPUT GR, V27, P700, DOI 10.1109/TVCG.2020.3030388
   Eulzer P, 2020, IEEE T VIS COMPUT GR, V26, P971, DOI 10.1109/TVCG.2019.2934337
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fröhler B, 2019, COMPUT GRAPH FORUM, V38, P273, DOI 10.1111/cgf.13688
   Fu CW, 2007, IEEE T VIS COMPUT GR, V13, P108, DOI 10.1109/TVCG.2007.2
   Furmanová K, 2020, IEEE T VIS COMPUT GR, V26, P843, DOI 10.1109/TVCG.2019.2934333
   Glasser S, 2014, IEEE T VIS COMPUT GR, V20, P2506, DOI 10.1109/TVCG.2014.2346406
   Gu Y, 2016, IEEE T VIS COMPUT GR, V22, P965, DOI 10.1109/TVCG.2015.2468031
   Guo HQ, 2016, IEEE T VIS COMPUT GR, V22, P827, DOI 10.1109/TVCG.2015.2466838
   Guo HQ, 2013, IEEE T VIS COMPUT GR, V19, P2733, DOI 10.1109/TVCG.2013.144
   Hadlak S., 2015, P EUROVIS STARS GOSL, P1, DOI [10.2312/eurovisstar,20151109, DOI 10.2312/EUROVISSTAR,20151109]
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Haehn D, 2014, IEEE T VIS COMPUT GR, V20, P2466, DOI 10.1109/TVCG.2014.2346371
   Halladjian S, 2020, IEEE T VIS COMPUT GR, V26, P654, DOI 10.1109/TVCG.2019.2934334
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hepperle D, 2019, COMPUT GRAPH-UK, V82, P321, DOI 10.1016/j.cag.2019.06.003
   Hermosilla P, 2017, IEEE T VIS COMPUT GR, V23, P731, DOI 10.1109/TVCG.2016.2598825
   Höllt T, 2012, IEEE T VIS COMPUT GR, V18, P2226, DOI 10.1109/TVCG.2012.259
   Hong F, 2014, IEEE T VIS COMPUT GR, V20, P2545, DOI 10.1109/TVCG.2014.2346416
   Hong J., 2021, P GRAPH INT MISS ON, P213, DOI [10.20380/G12021.33, DOI 10.20380/G12021.33, 10.20380/GI2021.33, DOI 10.20380/GI2021.33]
   Hong JY, 2022, COMPUT GRAPH FORUM, V41, P195, DOI 10.1111/cgf.14533
   Huang Jieying, 2023, IEEE Trans Vis Comput Graph, V29, P1200, DOI 10.1109/TVCG.2022.3209453
   Hubona G. S., 1997, Human Factors in Computing Systems. CHI 97 Extended Abstracts, P345
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jönsson D, 2016, IEEE T VIS COMPUT GR, V22, P896, DOI 10.1109/TVCG.2015.2467294
   Klein T, 2012, COMPUT GRAPH FORUM, V31, P1225, DOI 10.1111/j.1467-8659.2012.03115.x
   Klemm P, 2014, IEEE T VIS COMPUT GR, V20, P1673, DOI 10.1109/TVCG.2014.2346591
   Köhler B, 2018, COMPUT GRAPH FORUM, V37, P195, DOI 10.1111/cgf.13412
   Kolesár I, 2017, IEEE T VIS COMPUT GR, V23, P851, DOI 10.1109/TVCG.2016.2598870
   Kottravel S, 2019, COMPUT GRAPH FORUM, V38, P479, DOI 10.1111/cgf.13704
   Kretschmer J, 2014, IEEE T VIS COMPUT GR, V20, P2496, DOI 10.1109/TVCG.2014.2346405
   Kretschmer J, 2013, IEEE T VIS COMPUT GR, V19, P2828, DOI 10.1109/TVCG.2013.169
   Krone M, 2013, COMPUT GRAPH FORUM, V32, P331, DOI 10.1111/cgf.12120
   Krone M, 2017, IEEE T VIS COMPUT GR, V23, P701, DOI 10.1109/TVCG.2016.2598824
   Landge AG, 2012, IEEE T VIS COMPUT GR, V18, P2467, DOI 10.1109/TVCG.2012.286
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Langner R, 2018, IEEE T VIS COMPUT GR, V24, P626, DOI 10.1109/TVCG.2017.2744019
   Lawonn Kai, 2023, IEEE Trans Vis Comput Graph, V29, P526, DOI 10.1109/TVCG.2022.3209374
   Lawonn K, 2016, IEEE T VIS COMPUT GR, V22, P728, DOI 10.1109/TVCG.2015.2467961
   Le Goc M, 2019, IEEE T VIS COMPUT GR, V25, P737, DOI 10.1109/TVCG.2018.2865159
   Le Goc M, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/2984511.2984547
   LEDERMAN SJ, 1987, COGNITIVE PSYCHOL, V19, P342, DOI 10.1016/0010-0285(87)90008-9
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lichtenberg N, 2018, COMPUT GRAPH FORUM, V37, P379, DOI 10.1111/cgf.13427
   Lindow N, 2019, IEEE T VIS COMPUT GR, V25, P967, DOI 10.1109/TVCG.2018.2864507
   Liu H, 2021, IEEE T VIS COMPUT GR, V27, P593, DOI 10.1109/TVCG.2020.3028893
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.1581122519414, 10.1109/VR46266.2020.00-23]
   Liu XT, 2016, IEEE T VIS COMPUT GR, V22, P955, DOI 10.1109/TVCG.2015.2467431
   Luciani T, 2019, IEEE T VIS COMPUT GR, V25, P1225, DOI 10.1109/TVCG.2018.2864849
   Maries A, 2013, IEEE T VIS COMPUT GR, V19, P2916, DOI 10.1109/TVCG.2013.161
   Marriott K., 2018, Immersive Analytics, DOI [10.1515/itit-2022-0037, DOI 10.1515/ITIT-2022-0037]
   Marton F, 2019, COMPUT GRAPH FORUM, V38, P53, DOI 10.1111/cgf.13671
   Bin Masood T, 2021, COMPUT GRAPH FORUM, V40, P287, DOI 10.1111/cgf.14307
   Meuschke M, 2016, COMPUT GRAPH FORUM, V35, P351, DOI 10.1111/cgf.12911
   Meuschke M, 2023, IEEE T VIS COMPUT GR, V29, P1876, DOI 10.1109/TVCG.2021.3134083
   Meuschke M, 2019, IEEE T VIS COMPUT GR, V25, P997, DOI 10.1109/TVCG.2018.2864509
   Meuschke M, 2017, IEEE T VIS COMPUT GR, V23, P761, DOI 10.1109/TVCG.2016.2598795
   Miao H, 2018, COMPUT GRAPH FORUM, V37, P403, DOI 10.1111/cgf.13429
   Mistelbauer G, 2013, COMPUT GRAPH FORUM, V32, P231, DOI 10.1111/cgf.12110
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Mohenska M, 2022, J MOL CELL CARDIOL, V163, P20, DOI 10.1016/j.yjmcc.2021.09.011
   Munzner T., 2014, Visualization Analysis and Design, DOI [10.1201/617511, DOI 10.1201/617511]
   Nadeem S, 2017, IEEE T VIS COMPUT GR, V23, P751, DOI 10.1109/TVCG.2016.2598791
   Neugebauer M, 2013, COMPUT GRAPH FORUM, V32, P251, DOI 10.1111/cgf.12112
   Neuroth Tyson, 2023, IEEE Trans Vis Comput Graph, V29, P548, DOI 10.1109/TVCG.2022.3209473
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Nipu Nafiul, 2023, IEEE Trans Vis Comput Graph, V29, P798, DOI 10.1109/TVCG.2022.3209356
   Pálenik J, 2020, IEEE T VIS COMPUT GR, V26, P643, DOI 10.1109/TVCG.2019.2934258
   Palmas G, 2014, IEEE T VIS COMPUT GR, V20, P2359, DOI 10.1109/TVCG.2014.2346311
   Pavlopoulos GA, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-104
   Peng HC, 2014, NAT PROTOC, V9, P193, DOI 10.1038/nprot.2014.011
   Poco J, 2012, COMPUT GRAPH FORUM, V31, P1075, DOI 10.1111/j.1467-8659.2012.03100.x
   Rapp T, 2021, IEEE T VIS COMPUT GR, V27, P1580, DOI 10.1109/TVCG.2020.3030379
   Reh A, 2013, IEEE T VIS COMPUT GR, V19, P2906, DOI 10.1109/TVCG.2013.177
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Rieck B, 2012, IEEE T VIS COMPUT GR, V18, P2382, DOI 10.1109/TVCG.2012.248
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Rocha A, 2018, COMPUT GRAPH FORUM, V37, P465, DOI 10.1111/cgf.13434
   Sabando MV, 2021, IEEE T VIS COMPUT GR, V27, P891, DOI 10.1109/TVCG.2020.3030438
   Saffo D, 2020, COMPUT GRAPH FORUM, V39, P455, DOI 10.1111/cgf.13994
   Santos E. A. D., 2022, P POST IEEE VIS
   Satriadi Kadek Ananta, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427329
   Satriadi K. A., 2022, P ANN ACM C HUM FACT, DOI [10.1145/34911023517715, DOI 10.1145/34911023517715]
   Schindler M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P1, DOI 10.1109/VIS47514.2020.00007
   Schroeder D, 2014, IEEE T VIS COMPUT GR, V20, P2644, DOI 10.1109/TVCG.2014.2346451
   Schroeder WJ, 1996, IEEE VISUAL, P93, DOI 10.1109/VISUAL.1996.567752
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Sedlmair M, 2009, LECT NOTES COMPUT SC, V5531, P27
   Semmo A, 2012, COMPUT GRAPH FORUM, V31, P885, DOI 10.1111/j.1467-8659.2012.03081.x
   Siddiqui F, 2021, COMPUT GRAPH FORUM, V40, P411, DOI 10.1111/cgf.14317
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   Splechtna Rainer, 2023, IEEE Trans Vis Comput Graph, V29, P778, DOI 10.1109/TVCG.2022.3209478
   Sun MY, 2022, IEEE T VIS COMPUT GR, V28, P4741, DOI 10.1109/TVCG.2021.3102966
   Suzuki R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P493, DOI 10.1145/3332165.3347911
   Tao J, 2019, IEEE T VIS COMPUT GR, V25, P1236, DOI 10.1109/TVCG.2018.2864808
   Tavanti M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P139, DOI 10.1109/INFVIS.2001.963291
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Tory M, 2006, IEEE T VIS COMPUT GR, V12, P2, DOI 10.1109/TVCG.2006.17
   Troidl J, 2022, COMPUT GRAPH FORUM, V41, P183, DOI 10.1111/cgf.14532
   Ulbrich P, 2023, IEEE T VIS COMPUT GR, V29, P581, DOI 10.1109/TVCG.2022.3209411
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   Unger A, 2012, IEEE T VIS COMPUT GR, V18, P2216, DOI 10.1109/TVCG.2012.190
   Vázquez P, 2018, COMPUT GRAPH FORUM, V37, P391, DOI 10.1111/cgf.13428
   Viola I., 2020, Foundations of Data Visualization, P15, DOI DOI 10.1007/978-3-030-34444-3_2
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Ware C., 2019, Information Visualization: Perception for Design, V4th, DOI [DOI 10.1016/C2009-0-62432-6, 10.1016/C2009-0-62432-6]
   Waser J, 2014, COMPUT GRAPH FORUM, V33, P281, DOI 10.1111/cgf.12384
   Weissenböck J, 2019, IEEE T VIS COMPUT GR, V25, P1040, DOI 10.1109/TVCG.2018.2864510
   Wentzel A, 2020, IEEE T VIS COMPUT GR, V26, P949, DOI 10.1109/TVCG.2019.2934546
   Wills G., 2008, Handbook of Data Vi- sualization, P217, DOI [10.1007/978-3-540-33037-0_10, DOI 10.1007/978-3-540-33037-0_10]
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yu LY, 2010, IEEE T VIS COMPUT GR, V16, P1613, DOI 10.1109/TVCG.2010.157
   Zhang H, 2014, IEEE T VIS COMPUT GR, V20, P2575, DOI 10.1109/TVCG.2014.2346425
   Zhang H, 2012, IEEE T VIS COMPUT GR, V18, P2051, DOI 10.1109/TVCG.2012.242
   Zhou L, 2021, IEEE T VIS COMPUT GR, V27, P1591, DOI 10.1109/TVCG.2020.3030473
NR 162
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2888
EP 2902
DI 10.1109/TVCG.2024.3388516
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500012
PM 38648152
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Li, GZ
   Li, RF
   Feng, YS
   Zhang, Y
   Luo, YY
   Liu, CH
AF Li, Guozheng
   Li, Runfei
   Feng, Yunshan
   Zhang, Yu
   Luo, Yuyu
   Liu, Chi Harold
TI CoInsight: Visual Storytelling for Hierarchical Tables With Connected
   Insights
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Data mining; Task analysis; Europe;
   Usability; Natural languages; Data insight; hierarchical table; table
   data visualization; tabular data; visual storytelling
ID VISUALIZATION; DESIGN
AB Extracting data insights and generating visual data stories from tabular data are critical parts of data analysis. However, most existing studies primarily focus on tabular data stored as flat tables, typically without leveraging the relations between cells in the headers of hierarchical tables. When properly used, rich table headers can enable the extraction of many additional data stories. To assist analysts in visual data storytelling, an approach is needed to organize these data insights efficiently. In this work, we propose CoInsight, a system to facilitate visual storytelling for hierarchical tables by connecting insights. CoInsight extracts data insights from hierarchical tables and builds insight relations according to the structure of table headers. It further visualizes related data insights using a nested graph with edge bundling. We evaluate the CoInsight system through a usage scenario and a user experiment. The results demonstrate the utility and usability of CoInsight for converting data insights in hierarchical tables into visual data stories.
C1 [Li, Guozheng; Li, Runfei; Feng, Yunshan; Liu, Chi Harold] Beijing Inst Technol, Beijing 100811, Peoples R China.
   [Zhang, Yu] Univ Oxford, Oxford OX1 2JD, England.
   [Luo, Yuyu] Hong Kong Univ Sci & Technol, Clear Water Bay, Hong Kong, Peoples R China.
C3 Beijing Institute of Technology; University of Oxford; Hong Kong
   University of Science & Technology
RP Luo, YY (corresponding author), Hong Kong Univ Sci & Technol, Clear Water Bay, Hong Kong, Peoples R China.
EM guozheng.li@bit.edu.cn; chiliu@bit.edu.cn; yuyuluo@hkust-gz.edu.cn
OI Li, Guozheng/0000-0001-6663-6712; Zhang, Yu/0000-0002-9035-0463; Liu,
   Chi Harold/0000-0002-0252-329X
FU National Key R#x0026;D Program of China
FX No Statement Available
CR A. W. Services, 2012, Amazon quicksight
   Alper B., 2013, P 2013 ANN C HUM FAC, P483
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Brehmer M., 2019, P COMPUT JOURNALISM
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Chai CL, 2023, IEEE T KNOWL DATA EN, V35, P4646, DOI 10.1109/TKDE.2022.3148237
   Chai CL, 2022, PROC VLDB ENDOW, V15, P1466, DOI 10.14778/3523210.3523223
   Chen Z., 2013, P INT WORKSH SEM SEA, DOI DOI 10.1145/2509908.2509909
   Chen Z, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1126, DOI 10.1145/2623330.2623617
   Cheng ZJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1094
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Dou WS, 2018, IEEE INT CONF AUTOM, P498, DOI 10.1145/3238147.3238222
   Han Y, 2020, IEEE PAC VIS SYMP, P236, DOI [10.1109/PacificVis48177.2020.1027x, 10.1109/PasificVis48177.2020.1027x]
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Kim N. W., 2019, P ACM C HUM FACT COM, P1
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li GZ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383150
   Li GZ, 2020, IEEE T VIS COMPUT GR, V26, P1022, DOI 10.1109/TVCG.2019.2934535
   Li GY, 2022, IEEE INFOCOM SER, P1, DOI [10.1109/INFOCOM48880.2022.9796694, 10.1109/TVCG.2022.3209354]
   Li HT, 2024, Arxiv, DOI arXiv:2309.15723
   Lin QW, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P547, DOI 10.1145/3219819.3219867
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P1, DOI 10.1007/978-3-642-14267-3
   Luo YY, 2021, INT CONF MANAGE DATA, P1235, DOI 10.1145/3448016.3457261
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Luo YY, 2022, IEEE T KNOWL DATA EN, V34, P475, DOI 10.1109/TKDE.2020.2981464
   Luo YY, 2020, PROC VLDB ENDOW, V13, P2841, DOI 10.14778/3415478.3415489
   Luo YY, 2020, PROC VLDB ENDOW, V13, P2821, DOI 10.14778/3415478.3415484
   Luo YY, 2020, PROC INT CONF DATA, P733, DOI 10.1109/ICDE48307.2020.00069
   Luo YY, 2018, INT CONF MANAGE DATA, P1733, DOI 10.1145/3183713.3193545
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma PC, 2021, INT CONF MANAGE DATA, P1262, DOI 10.1145/3448016.3457267
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Min Lu, 2017, 2017 IEEE Pacific Visualization Symposium (PacificVis), P61, DOI 10.1109/PACIFICVIS.2017.8031580
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Mörth E, 2023, IEEE T VIS COMPUT GR, V29, P5165, DOI 10.1109/TVCG.2022.3205769
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Peng JL, 2021, INT CONF MANAGE DATA, P2271, DOI 10.1145/3448016.3457330
   Qin X., 2018, EDBT, P441
   Qin XD, 2022, VLDB J, V31, P753, DOI 10.1007/s00778-021-00714-0
   Qin XD, 2020, VLDB J, V29, P93, DOI 10.1007/s00778-019-00588-3
   Qinl XD, 2022, PROC INT CONF DATA, P2359, DOI 10.1109/ICDE53745.2022.00222
   Research M., 2016, Quickinsight
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Schaechtle U., 2013, P INT JOINT C ART IN, P1649
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Stolper C. D., 2016, MSRTR201614 MICR RES
   Sun Mengdi, 2023, IEEE Trans Vis Comput Graph, V29, P983, DOI 10.1109/TVCG.2022.3209428
   Tang B, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1509, DOI 10.1145/3035918.3035922
   Tang JW, 2022, INT CONF MANAGE DATA, P2353, DOI 10.1145/3514221.3520150
   Tian M, 2023, J VISUAL-JAPAN, V26, P1445, DOI 10.1007/s12650-023-00941-3
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wang X., 1996, Tech. Rep.
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang ZR, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1780, DOI 10.1145/3447548.3467434
   Ward Matthew O., 2010, Interactive Data Visualization : foundations, techniques, and applications
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu ZL, 2023, FRONT INFORM TECH EL, V24, P1007, DOI 10.1631/FITEE.2200409
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Yang W., 2023, Comput. Vis. Media.
   Zeng ZH, 2022, IEEE T VIS COMPUT GR, V28, P346, DOI 10.1109/TVCG.2021.3114814
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zhao ZP, 2023, IEEE COMPUT GRAPH, V43, P97, DOI 10.1109/MCG.2023.3269850
   Zhou MY, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2389, DOI 10.1145/3447548.3467279
NR 76
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3049
EP 3061
DI 10.1109/TVCG.2024.3388553
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500005
PM 38619943
DA 2024-08-05
ER

PT J
AU Biener, V
   Farzinnejad, F
   Schuster, R
   Tabaei, S
   Lindlein, L
   Hu, JH
   Nouri, N
   Dudley, JJ
   Krlstensson, PO
   Müller, J
   Grubert, J
AF Biener, Verena
   Farzinnejad, Forouzan
   Schuster, Rinaldo
   Tabaei, Seyedmasih
   Lindlein, Leon
   Hu, Jinghui
   Nouri, Negar
   Dudley, John J.
   Krlstensson, Per Ola
   Mueller, Joerg
   Grubert, Jens
TI Hold Tight: Identifying Behavioral Patterns During Prolonged Work in VR
   Through Video Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Resists; Task analysis; Headphones; Visualization;
   Keyboards; Human factors; virtual reality; video-analysis; productivity
   work; long-term; prolonged use; office work; future of work
AB VR devices have recently been actively promoted as tools for knowledge workers and prior work has demonstrated that VR can support some knowledge worker tasks. However, only a few studies have explored the effects of prolonged use of VR such as a study observing 16 participants working in VR and a physical environment for one work-week each and reporting mainly on subjective feedback. As a nuanced understanding of participants' behavior in VR and how it evolves over time is still missing, we report on the results from an analysis of 559 hours of video material obtained in this prior study. Among other findings, we report that (1) the frequency of actions related to adjusting the headset reduced by 46% and the frequency of actions related to supporting the headset reduced by 42% over the five days; (2) the HMD was removed 31% less frequently over the five days but for 41% longer periods; (3) wearing an HMD is disruptive to normal patterns of eating and drinking, but not to social interactions, such as talking. The combined findings in this work demonstrate the value of long-term studies of deployed VR systems and can be used to inform the design of better, more ergonomic VR systems as tools for knowledge workers.
C1 [Biener, Verena; Farzinnejad, Forouzan; Schuster, Rinaldo; Tabaei, Seyedmasih; Lindlein, Leon; Nouri, Negar; Grubert, Jens] Coburg Univ Appl Sci & Arts, Coburg, Germany.
   [Hu, Jinghui; Dudley, John J.; Krlstensson, Per Ola] Univ Cambridge, Cambridge, England.
   [Mueller, Joerg] Univ Bayreuth, Bayreuth, Germany.
C3 Klinikum Coburg; University of Cambridge; University of Bayreuth
RP Biener, V (corresponding author), Coburg Univ Appl Sci & Arts, Coburg, Germany.
EM verena.biener@hs-coburg.de; forouzan.farzinnejad@hs-coburg.de;
   Rinaldo.Schuster@stud.hs-coburg.de; Seyedmasih.Tabaei@stud.hs-coburg.de;
   Leon.Lindlein@stud.hs-coburg.de; jh2265@cam.ac.uk;
   negar.nouri@hs-coburg.de; jjd50@cam.ac.uk; pok21@cam.ac.uk;
   Joerg.Mueller@uni-bayreuth.de; jens.grubert@hs-coburg.de
OI Kristensson, Per Ola/0000-0002-7139-871X
CR Bai HD, 2021, COMPUT GRAPH-UK, V97, P42, DOI 10.1016/j.cag.2021.04.004
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Biener V, 2020, Arxiv, DOI arXiv:2008.04559
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P3810, DOI 10.1109/TVCG.2022.3203103
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P2069, DOI 10.1109/TVCG.2022.3150474
   Blanca MJ, 2023, PSICOTHEMA, V35, P21
   Brown E., 2018, IEEE VRS 4 WORKSH ON, V10, P3
   Brugman A. Russel, 2004, P LREC 2004 4 INT C, V3, P2065
   Chen YM, 2021, CCF T PERVAS COMPUT, V3, P99, DOI 10.1007/s42486-021-00062-6
   Ciccone BA, 2023, ERGON DES, V31, P24, DOI 10.1177/10648046211002578
   Das Thoondee K, 2017, 2017 COMPUTING CONFERENCE, P492, DOI 10.1109/SAI.2017.8252142
   Desai AP, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P217, DOI 10.1109/CRV.2017.16
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grajewski D, 2013, PROCEDIA COMPUT SCI, V25, P289, DOI 10.1016/j.procs.2013.11.035
   Grubert A., 2012, P 14 INT C HUM COMP, V3, P231
   Grubert D., 2013, P 15 INT C HUM COMP, V3, P99
   Grubert D., 2010, 2010 IEEE INT S MIX, P229
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2015, PERVASIVE MOB COMPUT, V18, P88, DOI 10.1016/j.pmcj.2014.08.005
   Guo J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P948, DOI 10.1109/vr.2019.8797972
   Guo J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P443, DOI [10.1109/VR46266.2020.00-39, 10.1109/VR46266.2020.1581306543750]
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hindmarsh J, 2007, SOCIOL COMPASS, V1, P156, DOI 10.1111/j.1751-9020.2007.00012.x
   Hirzle T, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3492802
   Hripcsak G, 2005, J AM MED INFORM ASSN, V12, P296, DOI 10.1197/jamia.M1733
   Kang S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376252
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Lee G, 2022, INT SYM MIX AUGMENT, P787, DOI 10.1109/ISMAR55827.2022.00097
   Li JY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040015
   Lu FY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P768, DOI 10.1109/VR50410.2021.00104
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Medeiros D, 2022, IEEE T VIS COMPUT GR, V28, P3640, DOI 10.1109/TVCG.2022.3203002
   Meng XR, 2022, INT SYM MIX AUGMENT, P74, DOI 10.1109/ISMAR55827.2022.00021
   Microsoft, 2023, Hololens 2-overview, features and specs.
   Ng A, 2021, INT SYM MIX AUGMENT, P265, DOI 10.1109/ISMAR52148.2021.00042
   Nordahl N. C., 2019, 2019 IEEE C VIRT REA, V2
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Ofek J., 2020, arXiv
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Pretsch E., 2021, Improvingemployee well-being by means of virtual reality-realex: an empirical casestudy, V2
   Ruvimova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376724
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Segura Marquez, 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764\n.34455923, DOI 10.1145/3411764]
   Shen RY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P124, DOI 10.1109/ISMAR-Adjunct.2019.00-65
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Steinicke G., 2014, P 2 ACM S SPAT US IN, P66
   Tao YJ, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545682
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Verma H., 2019, Personal and UbiquitousComputing, P1
   Wang CH, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545686
   Wentzel J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376687
   Whitman LE, 2004, PROCEEDINGS OF THE 2004 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1740
   Zhou Q, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501884
NR 57
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2796
EP 2806
DI 10.1109/TVCG.2024.3372048
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400040
PM 38437123
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lee, HJ
   Jeon, SB
   Cho, YH
   Lee, IK
AF Lee, Ho Jung
   Jeon, Sang-Bin
   Cho, Yong-Hun
   Lee, In-Kwon
TI Redirection Strategy Switching: Selective Redirection Controller for
   Dynamic Environment Adaptation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Redirected walking; Reinforcement learning
AB In this paper, we present the Selective Redirection Controller (SRC), which selects the optimal redirection controller based on the physical and virtual environment in Redirected Walking (RDW). The primary advantage of SRC over existing controllers is its dynamic switching among four different redirection controllers (S2C, TAPF, ARC, and SRL) based on the user's environment, as opposed to using a single fixed controller throughout the experience. By switching between redirection controllers based on the context around the user, SRC aims to optimize the advantages of each redirection strategy. The SRC model is trained using reinforcement learning to dynamically and instantaneously switch redirection controllers based on the user's environment. We evaluated the performance of SRC against traditional redirection controllers through simulations and user studies conducted in various physical and virtual environments. The findings indicate that SRC reduces the number of resets significantly compared to traditional redirection controllers. Heat map visualization was utilized during the development process to analyze which redirection controller SRC chooses based on the different environments around the user. SRC alternates between redirection techniques based on the user's environment, maximizing the advantages of each strategy for a superior RDW experience.
C1 [Lee, Ho Jung; Jeon, Sang-Bin; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
   [Cho, Yong-Hun] Korea Univ, Digital eXPerience Lab, Seoul, South Korea.
C3 Yonsei University; Korea University
RP Lee, HJ (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
EM dearshawn@yonsei.ac.kr; ludens0508@yonsei.ac.kr; maxburst88@gmail.com;
   iklee@yonsei.ac.kr
OI Lee, In-Kwon/0000-0002-1534-1882; Lee, Ho Jung/0009-0008-3122-8493
FU National Research Foundation of Korea
FX No Statement Available
CR Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]
   Sharma S., 2017, arXiv preprintarXiv:1702.06054, P447
   Shibayama W, 2020, LECT NOTES COMPUT SC, V12221, P33, DOI 10.1007/978-3-030-61864-3_4
   Stein N, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P493, DOI 10.1109/VR51125.2022.00069
   Steinicke F., 2009, JVRB-Journal of Virtual Reality and Broadcasting, V6
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma E. A., 2012, 2012 IEEE VIRT REAL, P154
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Sutton R. S., 1998, Introduction to reinforcement learning, V135, P255
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Usoh M., 2022, Walking>walking-in-place>flying, in virtual environmentsnon Visualization and Computer Graphics, V28, P3778, DOI [10.1109/TVCG.2022.3203095266S, DOI 10.1109/TVCG.2022.3203095266S]
   Zhang H., 2022, IEEE Transactions on Visualization andComputer Graphics, P1, DOI [10.1109/TVCG.2022.31586092,968, DOI 10.1109/TVCG.2022.31586092,968]
   Zhang H., 2022, IEEE Transactions on Visualization and Computer Graphics, V2, p967S
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 16
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2474
EP 2484
DI 10.1109/TVCG.2024.3372056
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400059
PM 38437097
DA 2024-08-05
ER

PT J
AU Chai, YJ
   Shao, TJ
   Weng, YL
   Zhou, K
AF Chai, Yujin
   Shao, Tianjia
   Weng, Yanlin
   Zhou, Kun
TI Personalized Audio-Driven 3D Facial Animation via Style-Content
   Disentanglement
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Audio-driven animation; facial animation; style learning; style-content
   disentanglement; facial motion decomposition
ID PLUS PLUS
AB We present a learning-based approach for generating 3D facial animations with the motion style of a specific subject from arbitrary audio inputs. The subject style is learned from a video clip (1-2 minutes) either downloaded from the Internet or captured through an ordinary camera. Traditional methods often require many hours of the subject's video to learn a robust audio-driven model and are thus unsuitable for this task. Recent research efforts aim to train a model from video collections of a few subjects but ignore the discrimination between the subject style and underlying speech content within facial motions, leading to inaccurate style or articulation. To solve the problem, we propose a novel framework that disentangles subject-specific style and speech content from facial motions. The disentanglement is enabled by two novel training mechanisms. One is two-pass style swapping between two random subjects, and the other is joint training of the decomposition network and audio-to-motion network with a shared decoder. After training, the disentangled style is combined with arbitrary audio inputs to generate stylized audio-driven 3D facial animations. Compared with start-of-the-art methods, our approach achieves better results qualitatively and quantitatively, especially in difficult cases like bilabial plosive and bilabial nasal phonemes.
C1 [Chai, Yujin; Shao, Tianjia; Weng, Yanlin; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Weng, YL (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM 11821001@zju.edu.cn; tjshao@zju.edu.cn; weng@cad.zju.edu.cn;
   kunzhou@acm.org
RI zhou, kun/KRP-1631-2024
OI Chai, Yujin/0000-0002-5525-6527
FU National Key Research and Development Program of China
FX No Statement Available
CR Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881
   Chai YJ, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0133-7
   Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034
   Deng Z., 2004, PROC IEEE COMPUT ANI, P267
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Fan YR, 2022, PROC CVPR IEEE, P18749, DOI 10.1109/CVPR52688.2022.01821
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   github, Mozilla
   Gong SW, 2019, IEEE INT CONF COMP V, P4141, DOI 10.1109/ICCVW.2019.00509
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Hannun A, 2014, Arxiv, DOI arXiv:1412.5567
   Ji XY, 2021, PROC CVPR IEEE, P14075, DOI 10.1109/CVPR46437.2021.01386
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kim H, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356500
   Kingma D., 2014, P INT C LEARN REPR, P1
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liu MY, 2017, ADV NEUR IN, V30
   Mittal G, 2020, IEEE WINT CONF APPL, P3279, DOI [10.1109/WACV45572.2020.9093527, 10.1109/wacv45572.2020.9093527]
   Pham HX, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361, DOI 10.1145/3242969.3243017
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Richard A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1153, DOI 10.1109/ICCV48922.2021.00121
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Senin Pavel., 2007, Science, P1
   Shimba T, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P100, DOI 10.1109/SII.2015.7404961
   Song LS, 2022, IEEE T INF FOREN SEC, V17, P585, DOI 10.1109/TIFS.2022.3146783
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Unterthiner T., 2019, PROC INT C LEARN REP, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Websdale D, 2018, INTERSPEECH, P2479, DOI 10.21437/Interspeech.2018-2066
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Wu HZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1478, DOI 10.1145/3474085.3475280
   Yao S., 2022, arXiv
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Zhang CX, 2023, IEEE T VIS COMPUT GR, V29, P1438, DOI 10.1109/TVCG.2021.3117484
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
   Zheng RB, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4255, DOI 10.1109/ICASSP39728.2021.9413472
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
   Zhu H, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2362
NR 48
TC 0
Z9 0
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1803
EP 1820
DI 10.1109/TVCG.2022.3230541
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500003
PM 37015450
DA 2024-08-05
ER

PT J
AU Atzberger, D
   Cech, T
   Trapp, M
   Richter, R
   Scheibel, W
   Döllner, J
   Schreck, T
AF Atzberger, Daniel
   Cech, Tim
   Trapp, Matthias
   Richter, Rico
   Scheibel, Willy
   Doellner, Jurgen
   Schreck, Tobias
TI Large-Scale Evaluation of Topic Models and Dimensionality Reduction
   Methods for 2D Text Spatialization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dimensionality reduction; Measurement; Visualization; Analytical models;
   Computational modeling; Layout; Semantics; Text visualization;
   spatialization; dimensionality reduction algorithms; topic modeling
ID VISUALIZATION; VIEWS
AB Topic models are a class of unsupervised learning algorithms for detecting the semantic structure within a text corpus. Together with a subsequent dimensionality reduction algorithm, topic models can be used for deriving spatializations for text corpora as two-dimensional scatter plots, reflecting semantic similarity between the documents and supporting corpus analysis. Although the choice of the topic model, the dimensionality reduction, and their underlying hyperparameters significantly impact the resulting layout, it is unknown which particular combinations result in high-quality layouts with respect to accuracy and perception metrics. To investigate the effectiveness of topic models and dimensionality reduction methods for the spatialization of corpora as two-dimensional scatter plots (or basis for landscape-type visualizations), we present a large-scale, benchmark-based computational evaluation. Our evaluation consists of (1) a set of corpora, (2) a set of layout algorithms that are combinations of topic models and dimensionality reductions, and (3) quality metrics for quantifying the resulting layout. The corpora are given as document-term matrices, and each document is assigned to a thematic class. The chosen metrics quantify the preservation of local and global properties and the perceptual effectiveness of the two-dimensional scatter plots. By evaluating the benchmark on a computing cluster, we derived a multivariate dataset with over 45 000 individual layouts and corresponding quality metrics. Based on the results, we propose guidelines for the effective design of text spatializations that are based on topic models and dimensionality reductions. As a main result, we show that interpretable topic models are beneficial for capturing the structure of text corpora. We furthermore recommend the use of t-SNE as a subsequent dimensionality reduction.
C1 [Atzberger, Daniel; Trapp, Matthias; Scheibel, Willy] Univ Potsdam, Hasso Plattner Inst, Digital Engn Fac, Potsdam, Germany.
   [Cech, Tim; Richter, Rico; Doellner, Jurgen] Univ Potsdam, Digital Engn Fac, Potsdam, Germany.
   [Schreck, Tobias] Graz Univ Technol, Graz, Austria.
C3 University of Potsdam; University of Potsdam; Graz University of
   Technology
RP Atzberger, D (corresponding author), Univ Potsdam, Hasso Plattner Inst, Digital Engn Fac, Potsdam, Germany.
EM daniel.atzberger@hpi.uni-potsdam.de; tcech@uni-potsdam.de;
   matthias.trapp@hpi.uni-potsdam.de; rico.richter.1@uni-potsdam.de;
   willy.scheibel@hpi.uni-potsdam.de; doellner@uni-potsdam.de;
   tobias.schreck@cgv.tugraz.at
OI Schreck, Tobias/0000-0003-0778-8665; Cech, Tim/0000-0001-8688-2419;
   Scheibel, Willy/0000-0002-7885-9857; Dollner, Jurgen/0000-0002-8981-8583
FU Federal Ministry of Education and Research, Germany
FX No Statement Available
CR Adam SP, 2019, SPRINGER OPTIM APPL, V145, P57, DOI 10.1007/978-3-030-12767-1_5
   Aggarwal C.C., 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4, DOI 10.1007/978-1-4614-3223-4_6, DOI 10.1007/978-1-4614-3223-4]
   Aggarwal CharuC., 2012, MINING TEXT DATA, DOI 10.1007/978-1-4614-3223-4_6
   Albuquerque G., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P13, DOI 10.1109/VAST.2011.6102437
   Alexander E, 2016, IEEE T VIS COMPUT GR, V22, P320, DOI 10.1109/TVCG.2015.2467618
   Appleby G, 2022, COMPUT GRAPH FORUM, V41, P169, DOI 10.1111/cgf.14531
   Atzberger D., 2022, PROC 15 INT S VISUAL, DOI DOI 10.1145/3554944.3554961
   Atzberger D, 2022, IEEE INT WORK C SO, P143, DOI 10.1109/SCAM55253.2022.00021
   Atzberger D, 2022, VISIGRAPP, P210, DOI 10.5220/0010991100003124
   Atzberger D, 2021, IVAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 3: IVAPP, P112, DOI 10.5220/0010267601120122
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Caillou P, 2021, IEEE COMPUT GRAPH, V41, P76, DOI 10.1109/MCG.2020.3033401
   Calinski Tadeusz, 1974, Communications in Statistics, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Chen TH, 2016, EMPIR SOFTW ENG, V21, P1843, DOI 10.1007/s10664-015-9402-8
   Chen YH, 2009, IEEE T VIS COMPUT GR, V15, P1161, DOI 10.1109/TVCG.2009.140
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Cox MA., 2008, Handbook of Data Visualization, P315, DOI [10.1007/978-3-540-33037-014, DOI 10.1007/978-3-540-33037-0_14, 10.1007/978-3-540-33037-0_14]
   Crain S.P., 2012, MINING TEXT DATA, P129, DOI [DOI 10.1007/978-1-4614-3223-4_52,4, DOI 10.1007/978-1-4614-3223-4_5]
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Dang T., 2019, P EUR IEEE VGTC C VI, P103, DOI DOI 10.2312/EVS.20191178
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Engel D., 2011, VISUALIZATION LARGE, V27, P135, DOI [DOI 10.4230/OASICS.VLUDS.2011.135, 10.4230/OASIcs.VLUDS.2011.1352, DOI 10.4230/OASICS.VLUDS.2011.1352]
   Espadoto M., 2020, PROC WORKSHOP GAP VI, P9, DOI DOI 10.2312/VISGAP20201105
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fodor I. K., 2002, Technical Report UCRL-ID-148494, P2
   Fried D, 2014, IEEE PAC VIS SYMP, P113, DOI 10.1109/PacificVis.2014.47
   Fujiwara T, 2022, IEEE T VIS COMPUT GR, V28, P758, DOI 10.1109/TVCG.2021.3114807
   Gansner Emden R., 2013, Journal of Graph Algorithms and Applications, V17, P515, DOI 10.7155/jgaa.00302
   Garcia Fernandez F. J., 2013, PROC WORKSHOP VISUAL, DOI DOI 10.2312/PE.VAMP.VAMP2013.005-009
   Gisbrecht A, 2015, WIRES DATA MIN KNOWL, V5, P51, DOI 10.1002/widm.1147
   Hogräfer M, 2020, COMPUT GRAPH FORUM, V39, P647, DOI 10.1111/cgf.14031
   Ingram S, 2015, NEUROCOMPUTING, V150, P557, DOI 10.1016/j.neucom.2014.07.073
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT, DOI 10.1016/0169-7439(87)80084-92
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Kohonen T, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, pPL1, DOI 10.1109/ICNN.1997.611622
   Kucher K., 2019, PROC EUROPEAN C VISU, P29, DOI DOI 10.2312/EURP.20191138
   Kucher K., 2018, P 11 INT S VISUAL IN, P97, DOI [DOI 10.1145/3231622.3231641.19,20, 10.1145/3231622.3231641.19,20]
   Kuhn A, 2010, J SOFTW MAINT EVOL-R, V22, P191, DOI 10.1002/smr.414
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lehmann DJ, 2016, IEEE T VIS COMPUT GR, V22, P609, DOI 10.1109/TVCG.2015.2467132
   Linstead E, 2009, DATA MIN KNOWL DISC, V18, P300, DOI 10.1007/s10618-008-0118-x
   Lipton Z. C, 2018, Queue, V16, P31, DOI DOI 10.1145/3236386.3241340
   Machado A., 2023, EUROVIS WORKSHOP VIS, DOI DOI 10.2312/EUROVA.202310889
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Melka J, 2019, STUD COMPUT INTELL, V829, P139, DOI 10.1007/978-3-030-16469-0_8
   Mishra S, 2020, Arxiv, DOI arXiv:2008.03964
   Morariu Cristina, 2023, IEEE Trans Vis Comput Graph, V29, P745, DOI 10.1109/TVCG.2022.3209449
   Nenkova A, 2012, Mining Text Data, P43, DOI 10.1007/978-1-4614-3223-4_3
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Paulovich FV, 2006, INFORMATION VISUALIZATION-BOOK, P245
   Peter J, 2015, IEEE CONF VIS ANAL, P207, DOI 10.1109/VAST.2015.7347681
   Riehmann P, 2019, IEEE T VIS COMPUT GR, V25, P1803, DOI 10.1109/TVCG.2018.2824822
   Röder M, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P399, DOI 10.1145/2684822.2685324
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Sievert C., 2014, P WORKSH INT LANG LE, DOI [DOI 10.3115/V1/W14-3110, 10.3115/v1/W14-3110, 10.13140/2.1.1394.3043]
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   Skupin A, 2004, P NATL ACAD SCI USA, V101, P5274, DOI 10.1073/pnas.0307654100
   van der Maaten L., 2009, Technical Report 009-005, P2
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J, 2006, PROC EUROPEAN S ARTI, P557
   Vernier EF, 2021, COMPUT GRAPH FORUM, V40, P87, DOI 10.1111/cgf.14291
   Vernier EF, 2020, COMPUT GRAPH FORUM, V39, P241, DOI 10.1111/cgf.13977
   Wallach H., 2009, Advances in neural information processing systems, V22, P1973, DOI DOI 10.1007/S10708-008-9161-9
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1828, DOI 10.1109/TVCG.2017.2701829
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Wilkinson L, 2006, IEEE T VIS COMPUT GR, V12, P1363, DOI 10.1109/TVCG.2006.94
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   Yan YY, 2019, IEEE PAC VIS SYMP, P148, DOI 10.1109/PacificVis.2019.00025
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
NR 81
TC 3
Z9 3
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 902
EP 912
DI 10.1109/TVCG.2023.3326569
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500044
PM 37871085
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Deng, ZK
   Chen, SF
   Schreck, T
   Deng, DZ
   Tang, T
   Xu, ML
   Weng, D
   Wu, YC
AF Deng, Zikun
   Chen, Shifu
   Schreck, Tobias
   Deng, Dazhen
   Tang, Tan
   Xu, Mingliang
   Weng, Di
   Wu, Yingcai
TI Visualizing Large-Scale Spatial Time Series with GeoChron
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatiotemporal visualization; spatial time series; Storyline
ID SPATIOTEMPORAL PATTERNS; AIR-POLLUTION; EXPLORATION; EVOLUTION
AB In geo-related fields such as urban informatics, atmospheric science, and geography, large-scale spatial time (ST) series (i.e., geo-referred time series) are collected for monitoring and understanding important spatiotemporal phenomena. ST series visualization is an effective means of understanding the data and reviewing spatiotemporal phenomena, which is a prerequisite for in-depth data analysis. However, visualizing these series is challenging due to their large scales, inherent dynamics, and spatiotemporal nature. In this study, we introduce the notion of patterns of evolution in ST series. Each evolution pattern is characterized by 1) a set of ST series that are close in space and 2) a time period when the trends of these ST series are correlated. We then leverage Storyline techniques by considering an analogy between evolution patterns and sessions, and finally design a novel visualization called GeoChron, which is capable of visualizing large-scale ST series in an evolution pattern-aware and narrative-preserving manner. GeoChron includes a mining framework to extract evolution patterns and two-level visualizations to enhance its visual scalability. We evaluate GeoChron with two case studies, an informal user study, an ablation study, parameter analysis, and running time analysis.
C1 [Deng, Zikun; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chen, Shifu; Deng, Dazhen; Weng, Di] Zhejiang Univ, Sch Software Technol, Hangzhou, Peoples R China.
   [Tang, Tan] Zhejiang Univ, Sch Art & Archaeol, Hangzhou, Peoples R China.
   [Schreck, Tobias] Graz Univ Technol, Graz, Austria.
   [Xu, Mingliang] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Hangzhou, Peoples R China.
   [Xu, Mingliang] Minist Educ, Engn Res Ctr Intelligent Swarm Syst, Hangzhou, Peoples R China.
   [Xu, Mingliang] Natl Supercomp Ctr, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Graz
   University of Technology; Zhengzhou University
RP Weng, D (corresponding author), Zhejiang Univ, Sch Software Technol, Hangzhou, Peoples R China.
EM zikun_rain@zju.edu.cn; sfchen@zju.edu.cn; tobias.schreck@cgv.tugraz.at;
   dengdazhen@zju.edu.cn; tangtan@zju.edu.cn; iexumingliang@zzu.edu.cn;
   dweng@zju.edu.cn; ycwu@zju.edu.cn
RI Weng, Di/ABG-7408-2020
OI Weng, Di/0000-0003-2712-7274; Deng, Dazhen/0000-0002-9057-8353; Tang,
   Tan/0000-0002-5260-3087; Schreck, Tobias/0000-0003-0778-8665; Deng,
   Zikun/0000-0002-4477-5292
FU National Key R&D Program of China
FX No Statement Available
CR Aghabozorgi S, 2015, INFORM SYST, V53, P16, DOI 10.1016/j.is.2015.04.007
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Andrienko G, 2008, INFORM VISUAL, V7, P173, DOI 10.1057/ivs.2008.23
   aqicn, The World Air Quality Index project. New York, USA Air Pollution: Real- time Air Quality index
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Chatzigeorgakidis G, 2019, BIG DATA RES, V15, P12, DOI 10.1016/j.bdr.2019.02.001
   Cormen T. H., 2001, Introduction to Algorithms, V4, P5
   Deng Z., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32299539, DOI 10.1109/TVCG.2022.32299539]
   Deng ZK, 2023, J VISUAL-JAPAN, V26, P385, DOI 10.1007/s12650-022-00884-1
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P2486, DOI 10.1109/TVCG.2021.3071387
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Dong Y, 2023, J VISUAL-JAPAN, V26, P403, DOI 10.1007/s12650-022-00882-3
   Evers M, 2021, COMPUT GRAPH FORUM, V40, P519, DOI 10.1111/cgf.14326
   Garcia G, 2021, IEEE T VIS COMPUT GR, V27, P2313, DOI 10.1109/TVCG.2019.2947515
   Guo H., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.32094142, DOI 10.1109/TVCG.2022.32094142]
   Hulstein Golina, 2023, IEEE Trans Vis Comput Graph, V29, P994, DOI 10.1109/TVCG.2022.3209480
   Karnick P, 2010, IEEE T VIS COMPUT GR, V16, P235, DOI 10.1109/TVCG.2009.65
   Köthur P, 2014, INFORM VISUAL, V13, P283, DOI 10.1177/1473871613481692
   Kothur P., 2012, P EUR C VIS EUR ASS, DOI [10.2312/PE/EuroVisShort/EuroVisShort2012/115-1191,2, DOI 10.2312/PE/EUROVISSHORT/EUROVISSHORT2012/115-1191,2]
   Lekschas F, 2020, IEEE T VIS COMPUT GR, V26, P611, DOI 10.1109/TVCG.2019.2934555
   Li CH, 2022, IEEE T VIS COMPUT GR, V28, P1062, DOI 10.1109/TVCG.2021.3114762
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Li J, 2014, IEEE CONF VIS ANAL, P133, DOI 10.1109/VAST.2014.7042489
   Li XC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1863, DOI 10.1145/3097983.3098090
   Li YX, 2023, VIS INFORM, V7, P41, DOI 10.1016/j.visinf.2023.02.002
   Liang YX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3428
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Shuhan, 2023, IEEE Trans Vis Comput Graph, V29, P1091, DOI 10.1109/TVCG.2022.3209430
   Liu YP, 2017, ECOL INDIC, V76, P344, DOI 10.1016/j.ecolind.2017.01.027
   Lu XY, 2023, J VISUAL-JAPAN, V26, P687, DOI 10.1007/s12650-022-00893-0
   Ma SM, 2019, J CLIMATE, V32, P1203, DOI 10.1175/JCLI-D-18-0234.1
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   Meshesha TW, 2020, J HYDROL, V587, DOI 10.1016/j.jhydrol.2020.124952
   Monmonier Mark., 1990, Cartographica, V27, P30
   Muthoni FK, 2019, THEOR APPL CLIMATOL, V137, P1869, DOI 10.1007/s00704-018-2712-1
   Ogawa M, 2010, SOFTVIS 2010: PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON SOFTWARE VISUALIZATION, P35
   Patel P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P370, DOI 10.1109/ICDM.2002.1183925
   Qin Y, 2021, SCI TOTAL ENVIRON, V792, DOI 10.1016/j.scitotenv.2021.148349
   Qu H, 2007, IEEE T VIS COMPUT GR, V13, P1408, DOI 10.1109/TVCG.2007.70523
   Rodrigues N., 2017, P INT S VIS INF COMM, P37, DOI [10.1145/3105971.31059821,2, DOI 10.1145/3105971.31059821,2]
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   Shirato G, 2023, VIS INFORM, V7, P77, DOI 10.1016/j.visinf.2023.01.001
   Spinoni J, 2015, INT J CLIMATOL, V35, P4197, DOI 10.1002/joc.4279
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   Tanahashi Y, 2015, IEEE T VIS COMPUT GR, V21, P730, DOI 10.1109/TVCG.2015.2392771
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Thakur S, 2010, IEEE INT CONF INF VI, P336, DOI 10.1109/IV.2010.54
   Traag VA, 2015, PHYS REV E, V92, DOI 10.1103/PhysRevE.92.032801
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang YC, 2022, VIS INFORM, V6, P12, DOI 10.1016/j.visinf.2022.09.001
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Wu XJ, 2020, INT J GEOGR INF SCI, V34, P1822, DOI 10.1080/13658816.2020.1726922
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Yagi S, 2015, 8th International Symposium on Visual Information Communication and Interaction (VINCI 2015), P156, DOI 10.1145/2801040.2801067
   Yang C, 2023, IEEE T VIS COMPUT GR, V29, P3586, DOI 10.1109/TVCG.2022.3165385
   Ye WF, 2018, SCI TOTAL ENVIRON, V631-632, P524, DOI 10.1016/j.scitotenv.2018.03.057
   Yi XW, 2022, IEEE T BIG DATA, V8, P1326, DOI 10.1109/TBDATA.2020.3047078
   Ying Lu, 2023, IEEE Trans Vis Comput Graph, V29, P331, DOI 10.1109/TVCG.2022.3209447
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Yu Yuncong, 2023, IEEE Trans Vis Comput Graph, V29, P33, DOI 10.1109/TVCG.2022.3209431
   Yue XW, 2020, IEEE T VIS COMPUT GR, V26, P601, DOI 10.1109/TVCG.2019.2934660
   Zeng W, 2017, IEEE T INTELL TRANSP, V18, P2271, DOI 10.1109/TITS.2016.2639320
   Zhao WX, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2022.06.002
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
   Zheng Y, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2267, DOI 10.1145/2783258.2788573
   Zhu JY, 2018, IEEE T BIG DATA, V4, P571, DOI 10.1109/TBDATA.2017.2723899
NR 76
TC 1
Z9 1
U1 7
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1194
EP 1204
DI 10.1109/TVCG.2023.3327162
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500016
PM 37883274
DA 2024-08-05
ER

PT J
AU Lai, SX
   Luan, WN
   Tao, J
AF Lai, Shaoxuan
   Luan, Wanna
   Tao, Jun
TI Explore Your Network in Minutes: A Rapid Prototyping Toolkit for
   Understanding Neural Networks with Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization model; toolkit; neural networks; visual diagnosis
ID VEGA
AB Neural networks attract significant attention in almost every field due to their widespread applications in various tasks. However, developers often struggle with debugging due to the black-box nature of neural networks. Visual analytics provides an intuitive way for developers to understand the hidden states and underlying complex transformations in neural networks. Existing visual analytics tools for neural networks have been demonstrated to be effective in providing useful hints for debugging certain network architectures. However, these approaches are often architecture-specific with strong assumptions of how the network should be understood. This limits their use when the network architecture or the exploration goal changes. In this paper, we present a general model and a programming toolkit, Neural Network Visualization Builder (NNVisBuilder), for prototyping visual analytics systems to understand neural networks. NNVisBuilder covers the common data transformation and interaction model involved in existing tools for exploring neural networks. It enables developers to customize a visual analytics interface for answering their specific questions about networks. NNVisBuilder is compatible with PyTorch so that developers can integrate the visualization code into their learning code seamlessly. We demonstrate the applicability by reproducing several existing visual analytics systems for networks with NNVisBuilder. The source code and some example cases can be found at https://github.com/sysuvis/NVB.
C1 [Lai, Shaoxuan; Luan, Wanna] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Tao, Jun] Sun Yat Sen Univ, Natl Supercomp Ctr Guangzhou, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Tao, Jun] Southern Marine Sci & Engn Guangdong Lab Zhuhai, Zhuhai, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Southern Marine Science
   & Engineering Guangdong Laboratory; Southern Marine Science &
   Engineering Guangdong Laboratory (Zhuhai)
RP Tao, J (corresponding author), Sun Yat Sen Univ, Natl Supercomp Ctr Guangzhou, Sch Comp Sci & Engn, Guangzhou, Peoples R China.; Tao, J (corresponding author), Southern Marine Sci & Engn Guangdong Lab Zhuhai, Zhuhai, Peoples R China.
EM laishx3@mail2.sysu.edu.cn; luanwn@mail2.sysu.edu.cn;
   taoj23@mail.sysu.edu.cn
FU National Key R&D Program of China
FX No Statement Available
CR Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002
   Amershi S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1357
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chae J., 2017, WORKSHOP VISUAL ANAL, P2
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Chung S., 2016, P ACM SIGKDD WORKSHO, V14, P2
   Das N, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P271, DOI 10.1109/VIS47514.2020.00061
   Erhan D, 2009, ISUALIZING HIGHER LA, V1341, P1
   Gomez O, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P31, DOI 10.1109/VIS49827.2021.9623271
   Harley AW, 2015, LECT NOTES COMPUT SC, V9474, P867, DOI 10.1007/978-3-319-27857-5_77
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Karpathy A, 2015, Arxiv, DOI [arXiv:1506.02078, DOI 10.48550/ARXIV.1506.02078]
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Li JK, 2021, IEEE T VIS COMPUT GR, V27, P380, DOI 10.1109/TVCG.2020.3030453
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1151, DOI 10.1109/TVCG.2019.2934537
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1548, DOI 10.1109/TVCG.2018.2871139
   Li Y., 2023, ACM Transactions on Interactive Intelligent Systems, DOI [10.1145/35874702, DOI 10.1145/35874702]
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   McKinney W., 2011, Python for high performance and scientific computing, V14, P1
   Migdal P., 2019, R. RV. torchviz: a package for neural network visualization and debugging
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ojo F, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2810, DOI 10.1145/3485447.3512001
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Park C., 2021, P EUROVIS SHORT PAPE, DOI [10.2312/evs.202110472, DOI 10.2312/EVS.202110472]
   Paszke A, 2019, ADV NEUR IN, V32
   Roeder L., Computer software
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Shen QM, 2020, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis48177.2020.2785
   Simonyan K., 2014, P INT C LEARNING REP, DOI [10.48550/arXiv.1312.60341,2, DOI 10.48550/ARXIV.1312.60341,2]
   Smilkov Daniel., Tensorflow playground
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sun GD, 2013, J COMPUT SCI TECH-CH, V28, P852, DOI 10.1007/s11390-013-1383-8
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   VanderPlas J., 2018, J OPEN SOURCE SOFTW, V3, P1057, DOI [DOI 10.21105/JOSS.01057, 10.21105/joss.01057]
   Vig J, 2019, Arxiv, DOI arXiv:1906.05714
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wang ZJ, 2021, Arxiv, DOI arXiv:2103.14625
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Xuan XW, 2022, IEEE T VIS COMPUT GR, V28, P2326, DOI 10.1109/TVCG.2022.3165347
   Yosinski J, 2015, Arxiv, DOI arXiv:1506.06579
   Zhao JH, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P286, DOI 10.1109/VIS47514.2020.00064
NR 50
TC 0
Z9 0
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 683
EP 693
DI 10.1109/TVCG.2023.3326575
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500087
PM 37922180
DA 2024-08-05
ER

PT J
AU Lo, LYH
   Cao, YF
   Yang, LN
   Qu, HM
AF Lo, Leo Yu-Ho
   Cao, Yifan
   Yang, Leni
   Qu, Huamin
TI Why Change My Design: Explaining Poorly Constructed Visualization
   Designs with Explorable Explanations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Best practices; Fake news; Social
   networking (online); Guidelines; Education; Information Visualization;
   Deceptive Visualization; Explorable Explanations
ID GRAPH LITERACY
AB Although visualization tools are widely available and accessible, not everyone knows the best practices and guidelines for creating accurate and honest visual representations of data. Numerous books and articles have been written to expose the misleading potential of poorly constructed charts and teach people how to avoid being deceived by them or making their own mistakes. These readings use various rhetorical devices to explain the concepts to their readers. In our analysis of a collection of books, online materials, and a design workshop, we identified six common explanation methods. To assess the effectiveness of these methods, we conducted two crowdsourced studies (each with $N=125$) to evaluate their ability to teach and persuade people to make design changes. In addition to these existing methods, we brought in the idea of Explorable Explanations, which allows readers to experiment with different chart settings and observe how the changes are reflected in the visualization. While we did not find significant differences across explanation methods, the results of our experiments indicate that, following the exposure to the explanations, the participants showed improved proficiency in identifying deceptive charts and were more receptive to proposed alterations of the visualization design. We discovered that participants were willing to accept more than 60% of the proposed adjustments in the persuasiveness assessment. Nevertheless, we found no significant differences among different explanation methods in convincing participants to accept the modifications.
C1 [Lo, Leo Yu-Ho; Cao, Yifan; Yang, Leni; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Lo, LYH (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM yhload@cse.ust.hk; ycaoaw@connect.ust.hk; lyangbb@cse.ust.hk;
   huamin@cse.ust.hk
OI Yang, Leni/0000-0003-4527-4905; Cao, Yifan/0000-0002-5892-5052; Lo, Leo
   Yu Ho/0000-0002-3660-3765
CR Bergstrom C. T., 2021, Random House Trade Paperbacks, V2
   Bergstrom C. T., 2017, Calling Bullshits. Data Reasoning in a Digital World
   Cairo A., 2019, How Charts Lie: Getting Smarter about Visual Information
   Camba JD, 2022, IEEE COMPUT GRAPH, V42, P116, DOI 10.1109/MCG.2021.3132004
   Case N., 2017, The evolution of trust
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Correll M., 2020, P 2020 CHI C HUM FAC, P1
   Correll M., 2017, WORKSH DEAL COGN BIA
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   explorabl, Explorable explanations
   Fan A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502138
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Garcia-Retamero R, 2016, MED DECIS MAKING, V36, P854, DOI 10.1177/0272989X16655334
   Ge LW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581406
   Harford T., 2022, The data detective: Ten easy rules to make sense of statistics, P3
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Huff D., 1954, How to lie with statistics, V1
   Jones G. E., 1995, How to lie with charts, V2, P3
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Levitin D. J., 2016, A field guide to lies: Critical thinking in the information age, P3
   Lisnic M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580910
   Lo LYH, 2022, COMPUT GRAPH FORUM, V41, P515, DOI 10.1111/cgf.14559
   Lo LYH, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P11, DOI [10.1109/visual.2019.8933751, 10.1109/VISUAL.2019.8933751]
   McKinney W., 2011, Python for high performance and scientific computing, V14, P1
   McNutt A., 2018, VISGUIDES 2 WORKSH C
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Monmonier M., 1991, How to lie with maps
   Muller M., 2014, Ways of Knowing in HCI, P3
   ourworldindata, Charts-our world in data
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ritchie J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300423
   Stephens-Davidowitz S., 2018, Everybody lies: What the internet can tell us about who we really are, P3
   Szafir D. A., 2018, Interactions, V25, P1
   VanderPlas J., 2018, Journal of Open Source Software, V3, P5
   Victor B., 2011, Explorable Explanations
   Wheelan C., 2013, Naked statistics: Stripping the dread from the data, P3
   Zheng W., 2019, Course Project
NR 40
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 955
EP 964
DI 10.1109/TVCG.2023.3327155
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500109
PM 37889814
OA Green Submitted
DA 2024-08-05
ER

PT J
AU In, S
   Lin, T
   North, C
   Pfister, H
   Yang, YL
AF In, Sungwon
   Lin, Tica
   North, Chris
   Pfister, Hanspeter
   Yang, Yalong
TI This is the Table I Want! Interactive Data Transformation on Desktop and
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data science; data transformation; empirical study; immersive analytics;
   interaction; virtual/augmented/mixed reality
ID DATA VISUALIZATION; EXPLORATION; FRAMEWORK
AB Data transformation is an essential step in data science. While experts primarily use programming to transform their data, there is an increasing need to support non-programmers with user interface-based tools. With the rapid development in interaction techniques and computing environments, we report our empirical findings about the effects of interaction techniques and environments on performing data transformation tasks. Specifically, we studied the potential benefits of direct interaction and virtual reality (VR) for data transformation. We compared gesture interaction versus a standard WIMP user interface, each on the desktop and in VR. With the tested data and tasks, we found time performance was similar between desktop and VR. Meanwhile, VR demonstrates preliminary evidence to better support provenance and sense-making throughout the data transformation process. Our exploration of performing data transformation in VR also provides initial affirmation for enabling an iterative and fully immersive data science workflow.
C1 [In, Sungwon; North, Chris; Yang, Yalong] Virginia Tech, Dept Comp Sci, Blacksburg, VA 24060 USA.
   [Yang, Yalong] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30309 USA.
   [Lin, Tica; Pfister, Hanspeter] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 30309 USA.
C3 Virginia Polytechnic Institute & State University; University System of
   Georgia; Georgia Institute of Technology; Harvard University
RP Yang, YL (corresponding author), Virginia Tech, Dept Comp Sci, Blacksburg, VA 24060 USA.
EM sungwoni@vt.edu; mlin@g.harvard.edu; north@cs.vt.edu;
   pfister@g.harvard.edu; yalong.yang@gatech.edu
OI In, Sungwon/0000-0002-5316-2922; Lin, Tica/0000-0002-2860-0871; Pfister,
   Hanspeter/0000-0002-3620-2582; Yang, Yalong/0000-0001-9414-9911
FU NSF I/UCRC via the NSF Center for Space, High-performance, and Resilient
   Computing (SHREC) [CNS-1822080]; NSF [III-2107328]
FX This work was supported in part by the NSF I/UCRC under Grant
   CNS-1822080 via the NSF Center for Space, High-performance, and
   Resilient Computing (SHREC) and in part by the NSF under Grant
   III-2107328.
CR Alteryx, 2022, US
   Amazon, 2022, AWS AUTOML SOLUTIONS
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   Arns L, 1999, P IEEE VIRT REAL ANN, P88, DOI 10.1109/VR.1999.756938
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Ball R, 2005, LECT NOTES COMPUT SC, V3585, P350, DOI 10.1007/11555261_30
   Ball R., 2005, CHI'05 extended abstracts on Human factors in computing systems, P1196
   Ball R, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P191
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bau O, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P37, DOI 10.1145/1449715.1449724
   Burley C. J., 2019, P C INN DAT SYST RES
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Chen J, 2012, IEEE T VIS COMPUT GR, V18, P2130, DOI 10.1109/TVCG.2012.216
   Cockburn A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2659796
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Crotty A, 2015, PROC VLDB ENDOW, V8, P2025
   Davidson K, 2023, IEEE T VIS COMPUT GR, V29, P5294, DOI 10.1109/TVCG.2022.3207357
   Desktop T., 2022, TABLEAU DESKTOP
   Drey T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376628
   Drosos I, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20)
   Drucker S.M., 2013, P OF THE SIGCHI C ON, P2301
   Dube T. J., 2019, International Conference on Human-Computer Interaction, P419
   Elmqvist N, 2007, IEEE CONF VIS ANAL, P187, DOI 10.1109/VAST.2007.4389013
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Field A., 2005, Discovering statistics using SAS, V2nd
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Google, 2022, About us
   Google, 2020, JAMBOARD
   Guo PJ, 2011, P 24 ANN ACM S USER, DOI [10.1145/2047196.2047205, DOI 10.1145/2047196.2047205]
   Hayatpur D., 2020, P 33 ANN ACM S US IN, P818, DOI DOI 10.1145/3379337.3415878
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Jakobsen MR, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1451
   Javed W, 2013, COMPUT GRAPH FORUM, V32, P441, DOI 10.1111/cgf.12131
   JetBrains, 2020, DATALORE
   Jiang LL, 2013, PROC VLDB ENDOW, V6, P1342, DOI 10.14778/2536274.2536311
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Jiazhou Liu, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3567729
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kasica S, 2021, IEEE T VIS COMPUT GR, V27, P957, DOI 10.1109/TVCG.2020.3030462
   Kirschthaler Philipp, 2020, CUI '20: Proceedings of the 2nd Conference on Conversational User Interfaces, DOI 10.1145/3405755.3406119
   Kodagoda Neesha, 2013, IEEE Trans Vis Comput Graph, V19, P2217, DOI 10.1109/TVCG.2013.211
   Kraska T, 2018, PROC VLDB ENDOW, V11, P2150, DOI 10.14778/3229863.3240493
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lekschas F, 2021, IEEE T VIS COMPUT GR, V27, P358, DOI 10.1109/TVCG.2020.3028948
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lisle L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P331, DOI [10.1109/VRW50115.2020.0-203, 10.1109/VRW50115.2020.00073]
   Lisle L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI 10.1109/VR50410.2021.00077
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.1581122519414, 10.1109/VR46266.2020.00-23]
   Luo WZ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501946
   Marrinan T, 2014, 2014 INTERNATIONAL CONFERENCE ON COLLABORATIVE COMPUTING: NETWORKING, APPLICATIONS AND WORKSHARING (COLLABORATECOM), P177, DOI 10.4108/icst.collaboratecom.2014.257337
   Marriott K., 2018, Immersive analytics
   McKinney W., 2010, P 9 PYTH SCI C AUST, P51, DOI DOI 10.25080/MAJORA-92BF1922-00A
   Mendes D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P261, DOI 10.1145/2993369.2993396
   Microsoft, 2020, WHITEBOARD
   Miro, 2020, MIRO
   Nacenta Miguel A., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, New York, NY, USA, P1099, DOI [10.1145/2470654.2466142, DOI 10.1145/2470654.2466142]
   Nandi A., 2013, P HUM FACT COMP SYST, P1203
   Nandi A, 2013, PROC VLDB ENDOW, V7, P289, DOI 10.14778/2732240.2732247
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Pirolli P., 1996, P WORKSH ADV VIS INT, P67
   Purchase H. C., 2006, Graph Drawing. 14th International Symposium, GD 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4372), P184
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   Reda K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2759, DOI 10.1145/2702123.2702406
   Rzeszotarski JM, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P897, DOI 10.1145/2556288.2557231
   Saket B, 2020, IEEE T VIS COMPUT GR, V26, P482, DOI 10.1109/TVCG.2019.2934534
   Saket B, 2018, IEEE T VIS COMPUT GR, V24, P1316, DOI 10.1109/TVCG.2017.2680452
   Sarvghad A, 2019, IEEE T VIS COMPUT GR, V25, P800, DOI 10.1109/TVCG.2018.2865075
   Satriadi Kadek Ananta, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427329
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Shang ZY, 2021, PROC VLDB ENDOW, V14, P2893, DOI 10.14778/3476311.3476370
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shneiderman B, 2000, IEEE INFOR VIS, P88, DOI 10.1109/IV.2000.859742
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Simmhan YL, 2005, SIGMOD REC, V34, P31, DOI 10.1145/1084805.1084812
   T. P. Builder, 2022, US
   Trifacta, 2022, US
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   Wang D., 2021, P CHI C HUM FACT COM, P1
   Wang JW, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2509, DOI 10.1109/BigData.2015.7364047
   Wang L., 2020, P CHI C HUM FACT COM, P1
   Wickham H., 2022, Tidyr: Tidy messy data
   Wickham H., 2022, dplyr: A Grammar of Data Manipulation
   Wickham H., 2016, R DATA SCI IMPORT TI
   Wright W., 2006, Conference on Human Factors in Computing Systems. CHI2006, P801
   Xiong K, 2023, IEEE T VIS COMPUT GR, V29, P2950, DOI 10.1109/TVCG.2022.3144975
   Yang FM, 2021, IEEE T VIS COMPUT GR, V27, P4359, DOI 10.1109/TVCG.2020.3009003
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Zagermann J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1899, DOI 10.1145/3025453.3026001
   Zhou G., 2022, P CHI C HUM FACT COM, P1
NR 98
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5635
EP 5650
DI 10.1109/TVCG.2023.3299602
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400089
PM 37506003
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Liu, C
   Guo, YH
   Yuan, XR
AF Liu, Can
   Guo, Yuhan
   Yuan, Xiaoru
TI AutoTitle: An Interactive Title Generator for Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Natural languages; Measurement; Task analysis;
   Semantics; Generators; Visualization; Deep learning; large language
   model; natural language; visualization title
AB We propose AutoTitle, an interactive visualization title generator satisfying multifarious user requirements. Factors making a good title, namely, the feature importance, coverage, preciseness, general information richness, conciseness, and non-technicality, are summarized based on the feedback from user interviews. Visualization authors need to trade off among these factors to fit specific scenarios, resulting in a wide design space of visualization titles. AutoTitle generates various titles through the process of visualization facts traversing, deep learning-based fact-to-title generation, and quantitative evaluation of the six factors. AutoTitle also provides users with an interactive interface to explore the desired titles by filtering the metrics. We conduct a user study to validate the quality of generated titles as well as the rationality and helpfulness of these metrics.
C1 [Liu, Can; Guo, Yuhan; Yuan, Xiaoru] Peking Univ, Sch Intelligence Sci & Technol, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
C3 Peking University; Peking University
RP Yuan, XR (corresponding author), Peking Univ, Sch Intelligence Sci & Technol, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
EM can.liu@pku.edu.cn; yuhan.guo@pku.edu.cn; xiaoru.yuan@pku.edu.cn
OI Guo, Yuhan/0009-0004-3857-7486; Yuan, Xiaoru/0000-0002-7233-980X; Liu,
   Can/0000-0002-1175-0734
FU National Natural Science Foundation of China [62272012]; Lenovo AI
   Master project
FX No Statement Available
CR Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, 10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bar-Hillel Y., 1952, RLE Technical Reports.
   Bertin Jacques, 1983, Semiology of graphics
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Chen ZY, 2020, Arxiv, DOI [arXiv:1904.09521, DOI 10.48550/ARXIV.1904.09521]
   Chen ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2096
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   D'Alfonso S, 2011, INFORMATION, V2, P61, DOI 10.3390/info2010061
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Edunov S, 2018, Arxiv, DOI [arXiv:1808.09381, DOI 10.48550/ARXIV.1808.09381]
   Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532
   Floridi L, 2004, MIND MACH, V14, P197, DOI 10.1023/B:MIND.0000021684.50925.c9
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hwang W, 2019, Arxiv, DOI arXiv:1902.01069
   Kahou S. E., 2018, P WORKSH TRACK PROC, P1
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lebret Remi, 2016, P 2016 C EMP METH NA, P1203, DOI [10.18653/v1/D16-1128, DOI 10.18653/V1/D16-1128]
   Liang P., 2009, P JOINT C 47 ANN M A, P91, DOI DOI 10.1007/978-3-642-02374-3_6
   Liang Xiaodan, 2017, P MACHINE LEARNING R, V70, P1587
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu TY, 2018, AAAI CONF ARTIF INTE, P4881
   Lundgard A, 2022, IEEE T VIS COMPUT GR, V28, P1073, DOI 10.1109/TVCG.2021.3114770
   Manolis Savva, 2011, P 24 ANN ACM S USER, P393
   Montemurro MA, 2010, ADV COMPLEX SYST, V13, P135, DOI 10.1142/S0219525910002530
   OpenAI, 2022, ChatGPTAPI.
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pitler E., 2008, P 2008 C EMPIRICAL M, P186
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Bowman SR, 2016, Arxiv, DOI [arXiv:1511.06349, 10.48550/ARXIV.1511.06349, DOI 10.48550/ARXIV.1511.06349]
   Radford, 2018, OPENAI BLOG
   Radford A., 2019, OpenAI blog, V1, P9
   Raffel C, 2023, Arxiv, DOI arXiv:1910.10683
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   Scharrer L, 2017, PUBLIC UNDERST SCI, V26, P1003, DOI 10.1177/0963662516680311
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4446
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wanzer DL, 2021, EVAL PROGRAM PLANN, V84, DOI 10.1016/j.evalprogplan.2020.101896
   Wiseman S, 2017, Arxiv, DOI arXiv:1707.08052
   Wu YH, 2016, Arxiv, DOI [arXiv:1609.08144, DOI 10.48550/ARXIV.1609.08144]
   Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911
NR 52
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5276
EP 5288
DI 10.1109/TVCG.2023.3290241
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400019
PM 37384476
DA 2024-08-05
ER

PT J
AU Zhang, SK
   Tam, H
   Li, YK
   Ren, KX
   Fu, HB
   Zhang, SH
AF Zhang, Shao-Kui
   Tam, Hou
   Li, Yike
   Ren, Ke-Xin
   Fu, Hongbo
   Zhang, Song-Hai
TI SceneDirector: Interactive Scene Synthesis by Simultaneously Editing
   Multiple Objects in Real-Time
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Three-dimensional displays; Solid modeling; Real-time systems;
   Process control; Tuning; Shape; 3D scene synthesis; 3D scene editing;
   interactive 3D modeling
AB Intelligent tools for creating synthetic scenes have been developed significantly in recent years. Existing techniques on interactive scene synthesis only incorporate a single object at every interaction, i.e., crafting a scene through a sequence of single-object insertions with user preferences. These techniques suggest objects by considering existent objects in the scene instead of fully picturing the eventual result, which is inherently problematic since the sets of objects to be inserted are seldom fixed during interactive processes. In this article, we introduce SceneDirector, a novel interactive scene synthesis tool to help users quickly picture various potential synthesis results by simultaneously editing groups of objects. Specifically, groups of objects are rearranged in real-time with respect to a position of an object specified by a mouse cursor or gesture, i.e., a movement of a single object would trigger the rearrangement of the existing object group, the insertions of potentially appropriate objects, and the removal of redundant objects. To achieve this, we first propose an idea of coherent group set which expresses various concepts of layout strategies. Subsequently, we present layout attributes, where users can adjust how objects are arranged by tuning the weights of the attributes. Thus, our method gives users intuitive control of both how to arrange groups of objects and where to place them. Through extensive experiments and two applications, we demonstrate the potentiality of our framework and how it enables concurrently effective and efficient interactions of editing groups of objects.
C1 [Zhang, Shao-Kui; Tam, Hou] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Li, Yike; Ren, Ke-Xin] Tsinghua Univ, Acad Arts & Design, Beijing 100084, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
   [Zhang, Song-Hai] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRist, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University; City University of Hong Kong;
   Tsinghua University
RP Zhang, SH (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRist, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM zhangsk18@mails.tsinghua.edu.cn; th21@mails.tsinghua.edu.cn;
   lyk20@mails.tsinghua.edu.cn; rkx20@mails.tsinghua.edu.cn;
   hongbofu@cityu.edu.hk; shz@tsinghua.edu.cn
OI FU, Hongbo/0000-0002-0284-726X; Zhang, Shao-Kui/0000-0003-0353-1977;
   Tam, Hou/0009-0009-3107-9552
FU Natural Science Foundation of China [62132012]; Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 62132012 and Tsinghua-Tencent Joint Laboratory for
   Internet Innovation Technology.
CR Chang AE, 2015, Arxiv, DOI arXiv:1505.06289
   Chen K., 2015, Comput. Vis. Media, V1, P267, DOI DOI 10.1007/S41095-015-0029-X
   Chen K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661239
   Ching F. D. K., 2018, INTERIOR DESIGN ILLU
   Dardas N. H., 2011, Res. Bull. Jordan, V2, P86
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Fisher M., 2011, P ACM SIGGRAPH PAP, P1
   Fisher M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818057
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10913, DOI 10.1109/ICCV48922.2021.01075
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   He Y, 2022, IEEE T VIS COMPUT GR, V28, P3986, DOI 10.1109/TVCG.2021.3111729
   Kela J, 2006, PERS UBIQUIT COMPUT, V10, P285, DOI 10.1007/s00779-005-0033-8
   Kim H., 2005, P 11 EUR C VIRT ENV, P191, DOI DOI 10.2312/EGVE/IPT_EGVE2005/191-199
   kujiale.com, 2020, Kujiale
   Li MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3303766
   Li WW, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P539, DOI [10.1109/VR46266.2020.00-29, 10.1109/VR46266.2020.1581008046739]
   Li Y., 2018, P AAAI C ART INT
   Li YR, 2020, COMPUT GRAPH-UK, V93, P1, DOI 10.1016/j.cag.2020.08.002
   Liang W, 2019, IEEE T VIS COMPUT GR, V25, P1836, DOI 10.1109/TVCG.2019.2898721
   Lu Hong-Li, 2010, RESIDENTIAL INTERIOR
   Luo A, 2020, PROC CVPR IEEE, P3753, DOI 10.1109/CVPR42600.2020.00381
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Mitton M., 2016, Residential interior design: A guide to planning spaces / Maureen Mitton, CID, NCIDO, Courtney Nystuen, AIA EMERITUS ; with CAD illustrations by Melissa Brewer, Shelley Pecha, and Jamey Bowe, VThird
   Peng Y.-G., 2008, Architectural Space Combination Theory
   planner5d.com, 2020, Planner5D
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   Ritchie D, 2019, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2019.00634
   Savva M, 2017, Arxiv, DOI arXiv:1703.00061
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Vasiliki Asaroglou A. B., 2013, Furniture Arrangement: In Residential Spaces
   Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201
   Wang K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322941
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Weiss T, 2019, IEEE T VIS COMPUT GR, V25, P3231, DOI 10.1109/TVCG.2018.2866436
   Xiong GM, 2021, IEEE T VIS COMPUT GR, V27, P4413, DOI 10.1109/TVCG.2020.3005680
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yan M, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095169
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2016, IEEE T VIS COMPUT GR, V22, P1138, DOI 10.1109/TVCG.2015.2417575
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Yuan Liang, 2017, Next Generation Computer Animation Techniques. Third International Workshop, AniNex 2017. Revised Selected Papers: LNCS 10582, P133, DOI 10.1007/978-3-319-69487-0_10
   Zhang SK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P965, DOI 10.1145/3474085.3475194
   Zhang SK, 2021, GRAPH MODELS, V116, DOI 10.1016/j.gmod.2021.101104
   Zhang SH, 2022, IEEE T VIS COMPUT GR, V28, P3082, DOI 10.1109/TVCG.2021.3050143
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
   Zhang SH, 2020, COMPUT VIS MEDIA, V6, P79, DOI 10.1007/s41095-020-0158-8
   Zhang SY, 2021, IEEE T VIS COMPUT GR, V27, P2250, DOI 10.1109/TVCG.2019.2949295
   Zhang SY, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P353, DOI 10.1145/3013971.3014002
   Zhang YY, 2021, ACTA GEOCHIM, V40, P1, DOI 10.1007/s11631-020-00439-x
   Zhang ZW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3381866
   Zheng Tao-Kai, 2011, INTERIOR DESIGN HOME
NR 53
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4558
EP 4569
DI 10.1109/TVCG.2023.3268115
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400034
PM 37083513
DA 2024-08-05
ER

PT J
AU Narciso, D
   Melo, M
   Rodrigues, S
   Cunha, JP
   Vasconcelos-Raposo, J
   Bessa, M
AF Narciso, David
   Melo, Miguel
   Rodrigues, Susana
   Cunha, Joao Paulo
   Vasconcelos-Raposo, Jose
   Bessa, Maximino
TI Studying the Influence of Multisensory Stimuli on a Firefighting
   Training Virtual Environment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Human factors; Heart rate variability; Visualization; Virtual
   environments; Market research; Cybersickness; Biofeedback; computer
   graphics; professional training; virtual reality
ID ENHANCES REALISTIC RESPONSE; STRESS ASSESSMENT
AB How we perceive and experience the world around us is inherently multisensory. Most of the Virtual Reality (VR) literature is based on the senses of sight and hearing. However, there is a lot of potential for integrating additional stimuli into Virtual Environments (VEs), especially in a training context. Identifying the relevant stimuli for obtaining a virtual experience that is perceptually equivalent to a real experience will lead users to behave the same across environments, which adds substantial value for several training areas, such as firefighters. In this article, we present an experiment aiming to assess the impact of different sensory stimuli on stress, fatigue, cybersickness, Presence and knowledge transfer of users during a firefighter training VE. The results suggested that the stimulus that significantly impacted the user's response was wearing a firefighter's uniform and combining all sensory stimuli under study: heat, weight, uniform, and mask. The results also showed that the VE did not induce cybersickness and that it was successful in the task of transferring knowledge.
C1 [Narciso, David; Cunha, Joao Paulo; Bessa, Maximino] Univ Tras os Montes & Alto Douro UTAD, P-5000801 Vila Real, Portugal.
   [Narciso, David; Melo, Miguel; Rodrigues, Susana; Cunha, Joao Paulo; Vasconcelos-Raposo, Jose; Bessa, Maximino] Inst Syst & Comp Engn Technol & Sci INESC TEC, P-4200465 Porto, Portugal.
   [Cunha, Joao Paulo] Fac Engn Univ Porto FEUP, P-4200465 Porto, Portugal.
C3 University of Tras-os-Montes & Alto Douro; INESC TEC; Universidade do
   Porto
RP Narciso, D (corresponding author), Univ Tras os Montes & Alto Douro UTAD, P-5000801 Vila Real, Portugal.
EM davidnarciso@utad.pt; mcmelo@inesctec.pt;
   susana.c.rodrigues@inesctec.pt; jpcunha@fe.up.pt; jvraposo@utad.pt;
   maxbessa@utad.pt
RI ; Branco VASCONCELOS-RAPOSO, JOSE Jacinto/G-3743-2010; Cunha, Joao
   Paulo/F-9039-2010
OI Rodrigues, Susana/0000-0001-6546-340X; Branco VASCONCELOS-RAPOSO, JOSE
   Jacinto/0000-0002-3456-9727; Bessa, Maximino/0000-0002-3002-704X; Cunha,
   Joao Paulo/0000-0003-4131-9045; Melo, Miguel/0000-0003-4050-3473
FU European Union [833573]; FCT-Fundacao para a Ciencia ea Tecnologia
   [SFRH/BD/147334/2019]
FX The research leading to these results has received funding fromt he
   European Union's Horizon 2020 - The EU Framework Programme for Research
   and Innovation 2014-2020, under Grant 833573. This work was also
   partially financed by the National funding by FCT-Fundacao para a
   Ciencia ea Tecnologia, through the PhD Research Scholarship
   SFRH/BD/147334/2019.
CR Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Biodevices, 2019, Biodevices Solucoes de engenharia biomedica
   Brogni A., 2007, Int. J. Virtual Reality, V6, P1
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Castaldo R, 2015, BIOMED SIGNAL PROCES, V18, P370, DOI 10.1016/j.bspc.2015.02.012
   Clifford GD., 2006, ADV METHODS TOOLS EC, DOI DOI 10.1186/1475-925X-6-18
   Deniaud C, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P739, DOI 10.1109/SAI.2015.7237225
   Dillon C., 2001, P 4 ANN INT WORKSH P, P21
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Egan D, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Engelbrecht H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00101
   Frohlich Julia, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P159, DOI 10.1007/978-3-642-39405-8_19
   Gardé A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188638
   George D., 2019, IBM SPSS Statistics 26 Step by Step, V16th, DOI DOI 10.4324/9780429056765
   Gonçalves G, 2020, IEEE T VIS COMPUT GR, V26, P3231, DOI 10.1109/TVCG.2019.2926978
   Gupta A, 2018, IEEE INT CON AUTO SC, P433, DOI 10.1109/COASE.2018.8560602
   Hulsmann F., 2014, Virtual Reality Broadcast, V11, P1
   Jang DP, 2002, CYBERPSYCHOL BEHAV, V5, P11, DOI 10.1089/109493102753685845
   Jones S, 2018, PROGR IS, P183, DOI 10.1007/978-3-319-64027-3_13
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Lesage FX, 2012, OCCUP MED-OXFORD, V62, P600, DOI 10.1093/occmed/kqs140
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, DOI [10.1111/j.1083-6101.1997.tb0, 10.1111/j.1083-6101.1997.tb00072.x., 10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X, 10.1111/J.1083-6101.1997.TB00072.X/4080403]
   Martin D, 2022, Arxiv, DOI arXiv:2101.07906
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Munyan BG III, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157568
   Narciso D., 2022, IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.20223156734, DOI 10.1109/TVCG.20223156734]
   Narciso D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3380903
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Sallnäs EL, 2010, LECT NOTES COMPUT SC, V6192, P178, DOI 10.1007/978-3-642-14075-4_26
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shaw E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300856
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Sobel-Fox RM, 2013, J PSYCHOSOC ONCOL, V31, P413, DOI 10.1080/07347332.2013.798760
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   Walter Hannah, 2019, DRUM
   Wheeler SG, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.671664
   Wiederhold B.K., 2001, CYBERPSYCHOLOGY MIND, P175
   Wiederhold BK, 2002, CYBERPSYCHOL BEHAV, V5, P77, DOI 10.1089/109493102753685908
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yu I, 2012, IEEE COMPUT GRAPH, V32, P36, DOI 10.1109/MCG.2012.121
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 46
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4122
EP 4136
DI 10.1109/TVCG.2023.3251188
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700031
PM 37028005
DA 2024-08-05
ER

PT J
AU Yang, ZP
   Wen, YH
   Chen, SY
   Liu, X
   Gao, Y
   Liu, YJ
   Gao, L
   Fu, HB
AF Yang, Zhipeng
   Wen, Yu-Hui
   Chen, Shu-Yu
   Liu, Xiao
   Gao, Yuan
   Liu, Yong-Jin
   Gao, Lin
   Fu, Hongbo
TI Keyframe Control of Music-Driven 3D Dance Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Humanities; Animation; Three-dimensional displays; Deep learning;
   Probabilistic logic; Interpolation; Task analysis; 3D animation;
   choreography; generative flows; multi-modal; music-driven
ID NETWORK; CAPTURE; MOTION
AB For 3D animators, choreography with artificial intelligence has attracted more attention recently. However, most existing deep learning methods mainly rely on music for dance generation and lack sufficient control over generated dance motions. To address this issue, we introduce the idea of keyframe interpolation for music-driven dance generation and present a novel transition generation technique for choreography. Specifically, this technique synthesizes visually diverse and plausible dance motions by using normalizing flows to learn the probability distribution of dance motions conditioned on a piece of music and a sparse set of key poses. Thus, the generated dance motions respect both the input musical beats and the key poses. To achieve a robust transition of varying lengths between the key poses, we introduce a time embedding at each timestep as an additional condition. Extensive experiments show that our model generates more realistic, diverse, and beat-matching dance motions than the compared state-of-the-art methods, both qualitatively and quantitatively. Our experimental results demonstrate the superiority of the keyframe-based control for improving the diversity of the generated dance motions.
C1 [Yang, Zhipeng; Chen, Shu-Yu; Gao, Lin] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Yang, Zhipeng; Chen, Shu-Yu; Gao, Lin] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
   [Wen, Yu-Hui; Liu, Yong-Jin] Tsinghua Univ, CS Dept, BNRist, Beijing 100190, Peoples R China.
   [Liu, Xiao; Gao, Yuan] Tomorrow Adv Life Educ Grp, Beijing 100190, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Tsinghua University; City University of Hong Kong
RP Gao, L (corresponding author), Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100190, Peoples R China.; Liu, YJ (corresponding author), Tsinghua Univ, CS Dept, BNRist, Beijing 100190, Peoples R China.
EM yangzhipeng19s@ict.ac.cn; wenyh1616@tsinghua.edu.cn;
   chenshuyu@ict.ac.cn; liuxiao15@tal.com; gaoyuan23@tal.com;
   liuyongjin@tsinghua.edu.cn; gaolin@ict.ac.cn; hongbofu@cityu.edu.hk
OI Wen, Yu-Hui/0000-0001-6195-9782; FU, Hongbo/0000-0002-0284-726X
FU National Key R&D Program of China [2020AAA0104500]; National Natural
   Science Foundation of China [62102403, 61725204, 62202257]; Beijing
   Natural Science Foundation [L222008]; Beijing Municipal Natural Science
   Foundation for Distinguished Young Scholars [JQ21013]; China
   Postdoctoral Science Foundation [2021M701891, 2022M713205]; Youth
   Innovation Promotion Association CAS
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2020AAA0104500, in part by the National Natural Science
   Foundation of China under Grants 62102403, 61725204, and 62202257, in
   part by Beijing Natural Science Foundation under Grant L222008, in part
   by the Beijing Municipal Natural Science Foundation for Distinguished
   Young Scholars under Grant JQ21013, in part by China Postdoctoral
   Science Foundation under Grants 2021M701891 and 2022M713205, and in part
   by Youth Innovation Promotion Association CAS.
CR Aksan E, 2019, IEEE I CONF COMP VIS, P7143, DOI 10.1109/ICCV.2019.00724
   Alemi O., 2017, networks, V8, P26
   Aristidou A, 2023, IEEE T VIS COMPUT GR, V29, P3519, DOI 10.1109/TVCG.2022.3163676
   Chai YJ, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0133-7
   Chen K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459932
   Choi B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925970
   Ciccone L, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099570
   Ciccone L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322938
   Du XX, 2019, IEEE ROBOT AUTOM LET, V4, P1501, DOI 10.1109/LRA.2019.2895266
   Ferreira JP, 2021, COMPUT GRAPH-UK, V94, P11, DOI 10.1016/j.cag.2020.09.009
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Harvey FG, 2018, SA'18: SIGGRAPH ASIA 2018 TECHNICAL BRIEFS, DOI 10.1145/3283254.3283277
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Heusel M., 2017, P ADV NEUR INF PROC, P6629
   Holden D., 2015, SIGGRAPH Asia 2015 Technical Briefs, SA'15, P1, DOI [DOI 10.1145/2820903.2820918, 10.1145/2820903.2820918]
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   Izani M, 2004, IEEE INFOR VIS, P849, DOI 10.1109/IV.2004.1320239
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Kingma D.P., 2016, Advances in neural information processing systems, V29
   Kingma DP, 2018, ADV NEUR IN, V31
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee H. Y., 2019, P ADV NEUR INF PROC, P3581
   Li RL, 2021, Arxiv, DOI arXiv:2101.08779
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lucic M, 2018, ADV NEUR IN, V31
   McFee B., 2015, P PYTH SCI C, P18
   Moghaddam ER, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P253, DOI 10.1109/CW.2014.42
   Mou T.-Y., 2018, EURASIA J. Math., Sci. Technol. Educ
   Neagle R. J., 2004, AISB 2004 Convention: Motion, Emotion and Cognition. Symposium on Language, Speech and Gesture for Expressive Characters, P86
   Paszke A, 2019, ADV NEUR IN, V32
   Qiao YL, 2022, IEEE T VIS COMPUT GR, V28, P1906, DOI 10.1109/TVCG.2020.3028961
   Ren XC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P46, DOI 10.1145/3394171.3413932
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Ruiz AH, 2019, IEEE I CONF COMP VIS, P7133, DOI 10.1109/ICCV.2019.00723
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Sebastian Grassia F., 1998, Journal of graphics tools, V3, P29, DOI [DOI 10.1080/10867651.1998.10487493, 10.1080/10867651.1998.10487493]
   Sun GF, 2021, IEEE T MULTIMEDIA, V23, P497, DOI 10.1109/TMM.2020.2981989
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Valle-Pérez G, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480570
   Vaswani A., 2017, Advances in neural information processing systems, P5998
   Wen YH, 2021, PROC CVPR IEEE, P13607, DOI 10.1109/CVPR46437.2021.01340
   Xia SH, 2017, J COMPUT SCI TECH-CH, V32, P536, DOI 10.1007/s11390-017-1742-y
   Yalta N, 2019, IEEE IJCNN
   Ye ZJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P744, DOI 10.1145/3394171.3414005
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhang XY, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274502
   Zhuang WL, 2020, Arxiv, DOI [arXiv:2006.05743, 10.48550/arXiv.2006.05743]
   Zhuang WL, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3485664
NR 54
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3474
EP 3486
DI 10.1109/TVCG.2023.3235538
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700020
PM 37021894
DA 2024-08-05
ER

PT J
AU Aoki, H
   Tochimoto, T
   Hiroi, Y
   Itoh, Y
AF Aoki, Hiroto
   Tochimoto, Takumi
   Hiroi, Yuichi
   Itoh, Yuta
TI Towards Co-Operative Beaming Displays: Dual Steering Projectors for
   Extended Projection Volume and Head Orientation Range
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Near-eye display; Augmented reality; Projectors
AB Existing near-eye displays (NEDs) have trade-offs related to size, weight, computational resources, battery life, and body temperature. A recent paradigm, beaming display, addresses these trade-offs by separating the NED into a steering projector (SP) for image presentation and a passive headset worn by the user. However, the beaming display has issues with the projection area of a single SP and has severe limitations on the head orientation and pose that the user can move. In this study, we distribute dual steering projectors in the scene to extend the head orientation and pose of the beaming display by coordinating the dual projections on a passive headset. For cooperative control of each SP, we define a geometric model of the SPs and propose a calibration and projection control method designed for multiple projectors. We present implementations of the system along with evaluations showing that the precision and delay are 1.8 similar to 5.7 mm and 14.46 ms, respectively, at a distance of about 1 m from the SPs. From this result, our prototype with multiple SPs can project images in the projection area (20 mm x 30mm) of the passive headset while extending the projectable head orientation. Furthermore, as applications of cooperative control by multiple SPs, we show the possibility of multiple users, improving dynamic range and binocular presentation.
C1 [Aoki, Hiroto; Itoh, Yuta] Univ Tokyo, Tokyo, Japan.
   [Tochimoto, Takumi] Tokyo Inst Technol, Tokyo, Japan.
   [Hiroi, Yuichi] Cluster Metaverse Lab, Tokyo, Japan.
C3 University of Tokyo; Tokyo Institute of Technology
RP Aoki, H (corresponding author), Univ Tokyo, Tokyo, Japan.
EM aoki-hiroto633@g.ecc.u-tokyo.ac.jp; takumi.tochimoto@ar.c.titech.ac.jp;
   y.hiroi@cluster.mu; yuta.itoh@iii.u-tokyo.ac.jp
OI Hiroi, Yuichi/0000-0001-8567-6947; Itoh, Yuta/0000-0002-5901-797X
FU JST FOREST
FX No Statement Available
CR Aksit K, 2023, Arxiv, DOI arXiv:2212.05057
   Blate A, 2019, IEEE T VIS COMPUT GR, V25, P1970, DOI 10.1109/TVCG.2019.2899233
   Bradski G, 2000, DR DOBBS J, V25, P120
   Chakravarthula P, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417846
   Forsyth D. A., 2003, printice hall, P3
   Hiroi Y, 2023, IEEE T VIS COMPUT GR, V29, P4761, DOI 10.1109/TVCG.2023.3320212
   Itoh Y, 2021, IEEE T VIS COMPUT GR, V27, P2659, DOI 10.1109/TVCG.2021.3067764
   Iwai D, 2015, IEEE T CIRC SYST VID, V25, P547, DOI 10.1109/TCSVT.2014.2352500
   Kitajima Y, 2017, IEEE T VIS COMPUT GR, V23, P2419, DOI 10.1109/TVCG.2017.2734478
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kress B, 2013, PROC SPIE, V8720, DOI 10.1117/12.2015654
   Kress BC, 2019, PROC SPIE, V11062, DOI 10.1117/12.2527680
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Maruyama M, 2018, IEEE WINT CONF APPL, P921, DOI 10.1109/WACV.2018.00106
   Mikawa Y, 2022, IEEE T VIS COMPUT GR, V28, P4016, DOI 10.1109/TVCG.2021.3111085
   Mikawa Y, 2021, 2021 60TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P137
   Mikawa Y, 2018, SA'18: SIGGRAPH ASIA 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3275476.3275481
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Munoz-Salinas R., Aruco library
   Nitta M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281535
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Okumura K, 2013, IEEE INT CON MULTI
   Okumura K, 2011, IEEE INT CONF ROBOT, DOI 10.1109/ICRA.2011.5980080
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Sueishi T, 2015, IEEE INT C INT ROBOT, P3064, DOI 10.1109/IROS.2015.7353800
   Sueishi T, 2015, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2015.7223330
   Sugimoto M, 2021, IEEE T VIS COMPUT GR, V27, P4161, DOI 10.1109/TVCG.2021.3106511
   Wan DR, 2008, COMPUT VIS IMAGE UND, V112, P184, DOI 10.1016/j.cviu.2008.02.005
   Wang LH, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3408333
   Wang LH, 2014, OPT EXPRESS, V22, P19448, DOI 10.1364/OE.22.019448
   Watanabe Y., 2015, 22 INT DISPL WORKSH, P1421
   Wilson AD, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P413
   Yamamoto K., 2022, IEEE TVCG, P1
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 36
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2309
EP 2318
DI 10.1109/TVCG.2024.3372118
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400064
PM 38530726
DA 2024-08-05
ER

PT J
AU Liu, WY
   Zhang, YY
   Zhang, BQ
   Xiong, QQ
   Zhao, H
   Li, S
   Liu, J
   Bian, YL
AF Liu, Weiying
   Zhang, Yanyan
   Zhang, Baiqiao
   Xiong, Qianqian
   Zhao, Hong
   Li, Sheng
   Liu, Juan
   Bian, Yulong
TI Self-Guided DMT: Exploring a Novel Paradigm of Dance Movement Therapy in
   Mixed Reality for Children with ASD
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Autism spectrum disorder; dance movement therapy; mixed reality;
   self-guided; virtual agent
ID AUTISM SPECTRUM DISORDER; EFFICACY; IDENTIFICATION; PERFORMANCE;
   ADOLESCENTS; SIMILARITY; MOTOR
AB Children diagnosed with Autism Spectrum Disorder (ASD) often exhibit motor disorders. Dance Movement Therapy (DMT) has shown great potential for improving the motor control ability of children with ASD. However, traditional DMT methods often lack vividness and are difficult to implement effectively. To address this issue, we propose a Mixed Reality DMT approach, utilizing interactive virtual agents. This approach offers immersive training content and multi-sensory feedback. To improve the training performance of children with ASD, we introduce a novel training paradigm featuring a self-guided mode. This paradigm enables the rapid creation of a virtual twin agent of the child with ASD using a single photo to embody oneself, which can then guide oneself during training. We conducted an experiment with the participation of 24 children diagnosed with ASD (or ASD propensity), recording their training performance under various experimental conditions. Through expert rating, behavior coding of training sessions, and statistical analysis, our findings revealed that the use of the twin agent for self-guidance resulted in noticeable improvements in the training performance of children with ASD. These improvements were particularly evident in terms of enhancing movement quality and refining overall target-related responses. Our study holds clinical potential in the field of medical treatment and rehabilitation for children with ASD.
C1 [Liu, Weiying; Zhang, Baiqiao; Xiong, Qianqian; Zhao, Hong; Liu, Juan; Bian, Yulong] Shandong Univ, Weihai 264209, Peoples R China.
   [Zhang, Yanyan] Weihai Maternal Child Hlth Care Hosp, Weihai, Peoples R China.
   [Li, Sheng] Peking Univ, Beijing 100871, Peoples R China.
C3 Shandong University; Peking University
RP Liu, J (corresponding author), Shandong Univ, Weihai 264209, Peoples R China.; Li, S (corresponding author), Peking Univ, Beijing 100871, Peoples R China.
EM 202237565@mail.sdu.edu.cn; 270700475@qq.com; baiqiao@mail.sdu.edu.cn;
   causeimbatman@mail.sdu.edu.cn; zhaohong1229@sdu.edu.cn;
   lisheng@pku.edu.cn; zzzliujuan@sdu.edu.cn; bianyulong@sdu.edu.cn
OI Li, Sheng/0000-0002-8901-2184
FU National Key R&D Program of China
FX No Statement Available
CR Abbasi J, 2017, JAMA-J AM MED ASSOC, V317, P346, DOI 10.1001/jama.2016.18122
   Aithal S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.588418
   Andsager JL, 2006, COMMUN RES, V33, P3, DOI 10.1177/0093650205283099
   [Anonymous], 1997, Journal of Computer-Mediated Communication, DOI [DOI 10.1111/J.1083-6101.1997.TB00070.X, 10.1111/j.1083-6101.1997.tb00070.x]
   Bai Z, 2015, IEEE T VIS COMPUT GR, V21, P598, DOI 10.1109/TVCG.2014.2385092
   Bailenson JN, 2008, J APPL SOC PSYCHOL, V38, P2673, DOI 10.1111/j.1559-1816.2008.00409.x
   BANDURA A, 1961, J ABNORM SOC PSYCH, V63, P311, DOI 10.1037/h0040351
   Bandura A, 2001, MEDIA PSYCHOL, V3, P265, DOI 10.1207/S1532785XMEP0303_03
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Bandura A., 1977, Social learning theory, V1, P2
   Banire B, 2021, UNIVERSAL ACCESS INF, V20, P785, DOI 10.1007/s10209-020-00749-0
   Bekele E, 2013, IEEE T VIS COMPUT GR, V19, P711, DOI 10.1109/TVCG.2013.42
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   Bian YL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018)
   Cassidy A., 2021, Encyclopedia of AutismSpectrum Disorders, P462, DOI [10.1007/978-3-319-91280-6_1367, DOI 10.1007/978-3-319-91280-6_1367]
   Chen Xinyu, 2022, 2022 Asia-Pacific Computer Technologies Conference (APCT), P7, DOI 10.1109/APCT55107.2022.00016
   Constantin A, 2017, COMPUT HUM BEHAV, V75, P404, DOI 10.1016/j.chb.2017.05.030
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   de Natale ER, 2017, NEUROREHABILITATION, V40, P141, DOI 10.3233/NRE-161399
   Dechsling A, 2022, J AUTISM DEV DISORD, V52, P4692, DOI 10.1007/s10803-021-05338-5
   DeJesus BM, 2020, COMPLEMENT THER MED, V49, DOI 10.1016/j.ctim.2020.102299
   Delabary MD, 2018, AGING CLIN EXP RES, V30, P727, DOI 10.1007/s40520-017-0836-2
   Dowrick P. W., 2022, Self-modeling: Falling a sleep following a picture-basedplan, P151, DOI [10.1007/978-3-030-99134-0_112, DOI 10.1007/978-3-030-99134-0_112]
   Dowrick PW, 2012, PSYCHOL SCHOOLS, V49, P30, DOI 10.1002/pits.20613
   Dowrick PW, 1999, APPL PREV PSYCHOL, V8, P23, DOI 10.1016/S0962-1849(99)80009-2
   Eberhard-Kaechele M., 2020, Trauma in the Creative and Embodied Therapies, DOI [10.4324/9781351066266-82, DOI 10.4324/9781351066266-82]
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Franklin S., 1997, Intelligent Agents III. Agent Theories, Architectures, and Languages. ECAI '96 Workshop (ATAL) Proceedings, P21, DOI 10.1007/BFb0013570
   Fraser DW, 2020, FOCUS AUTISM DEV DIS, V35, P3, DOI 10.1177/1088357619844696
   Frith U., 2003, Autism: Explaining the enigma, P8
   Happé F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2
   Hatch B, 2023, PSYCHOL SCHOOLS, V60, P295, DOI 10.1002/pits.22808
   Hilmert CJ, 2006, J PERS SOC PSYCHOL, V90, P440, DOI 10.1037/0022-3514.90.3.440
   Huang YC, 2019, LECT NOTES COMPUT SC, V11575, P283, DOI 10.1007/978-3-030-21565-1_19
   Jackson JW, 2002, J EXP EDUC, V70, P243, DOI 10.1080/00220970209599508
   Jennings N. R., 1998, Autonomous Agents Multi-Agent Systems, V1, P7, DOI DOI 10.1023/A:1010090405266
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Karkou V, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00936
   Kita Y, 2011, BRAIN DEV-JPN, V33, P494, DOI 10.1016/j.braindev.2010.11.007
   Ko KS, 2023, ART PSYCHOTHER, V85, DOI 10.1016/j.aip.2023.102062
   Kumazaki H, 2019, J AUTISM DEV DISORD, V49, P1700, DOI 10.1007/s10803-018-3841-1
   Li S, 2022, IEEE T VIS COMPUT GR, V28, P3035, DOI 10.1109/TVCG.2020.3044563
   Liu J, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-2941-7
   Liu WY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135799
   Maenner MJ, 2021, MMWR SURVEILL SUMM, V70, DOI 10.15585/mmwr.ss7011a1
   Mei C, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P155, DOI 10.1145/2700648.2809863
   Mei C, 2015, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2015.7223382
   MEICHENBAUM DH, 1971, J PERS SOC PSYCHOL, V17, P298, DOI 10.1037/h0030593
   Miller SA, 2015, J APPL BEHAV ANAL, V48, P194, DOI 10.1002/jaba.187
   Mosher MA, 2022, REV J AUTISM DEV DIS, V9, P334, DOI 10.1007/s40489-021-00259-6
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L., 2001, Enhanced perceptual functioning in thedevelopment of autism, DOI [10.4324/9781410600196-148, DOI 10.4324/9781410600196-148]
   Mulligan J., 2022, Childand Adolescent Psychiatry and Mental Health, V16, P1, DOI [10.1186/s13034-022-00495-64, DOI 10.1186/S13034-022-00495-64]
   Niswanger R., IN2023 IEEEACMCONFER
   Perkins R., Psychology and Psychotherapy
   Ridderinkhof A, 2020, J ATTEN DISORD, V24, P681, DOI 10.1177/1087054718797428
   Scotland E., 1969, Advances in experimental social psychology, V4, P271, DOI [DOI 10.1016/S0065-2601(08)60080-5, 10.1016/s0065-2601(08)60080-53]
   Souza-Santos C, 2018, CLIN NEUROPSYCHIATR, V15, P284
   Spitzer R. L., 1994, DSM-IV casebook: A learning companion to the Diagnostic and Statistical Manual of Mental Disorders, DOI [10.1176/appi.books.97815856226651, DOI 10.1176/APPI.BOOKS.97815856226651]
   Stajkovic AD, 1998, PSYCHOL BULL, V124, P240, DOI 10.1037/0033-2909.124.2.240
   Takahashi H, 2019, AM J DANCE THER, V41, P55, DOI 10.1007/s10465-019-09296-5
   Tanaka H, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2937757
   Valencia K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204485
   Vishwakarma A., 2019, Unfold-An Interactive Experience on Mixed Reality Platform to Solve Communication Problems Faced by Children with ASD in the Age Group of 4-7 Years, V1, P2
   Wilson CE, 2011, Q J EXP PSYCHOL, V64, P1939, DOI 10.1080/17470218.2011.603052
   Zhang L., 2020, IEEE transactions on learning technologies, V14, P338
   Zhang L, 2021, IEEE T LEARN TECHNOL, V14, P338, DOI [10.1109/TLT.2020.3029223, 10.1109/tlt.2020.3029223]
   Zhao WB, 2020, COMPUTER, V53, P26, DOI 10.1109/MC.2019.2915979
NR 68
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2119
EP 2128
DI 10.1109/TVCG.2024.3372063
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400034
PM 38457325
DA 2024-08-05
ER

PT J
AU Ning, B
   Pei, MT
AF Ning, Bing
   Pei, Mingtao
TI Task and Environment-Aware Virtual Scene Rearrangement for Enhanced
   Safety in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Layout; Visualization; Virtual environments; User
   experience; Solid modeling; Navigation; VR safety; scene rearrangement;
   scene synthesis
ID REDIRECTED WALKING
AB Emerging VR applications have revolutionized user experiences by immersing individuals in digitally crafted environments. However, fully immersive experiences introduce new challenges, notably the risk of physical hazards when users are unaware of their surroundings. Existing solutions, including guardian spaces and locomotion systems, present trade-offs that either disrupt the immersive experience or risk inducing motion sickness. To address these challenges, we propose a novel approach that dynamically rearranges VR scenes according to users' physical spaces, seamlessly embedding physical constraints and interaction tasks into the virtual environment. We design a computational model to optimize the rearranged scene through a cost function, ensuring collision-free interactions while maintaining visual fidelity and the goal of interaction tasks. The experiments demonstrate improvements in user experience and safety, presenting an innovative solution to harmonize physical and virtual environments in VR applications.
C1 [Ning, Bing; Pei, Mingtao] Beijing Inst Technol, Beijing, Peoples R China.
   [Ning, Bing] Beijing Inst Fash Technol, Beijing, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Fashion Technology
RP Ning, B (corresponding author), Beijing Inst Technol, Beijing, Peoples R China.; Ning, B (corresponding author), Beijing Inst Fash Technol, Beijing, Peoples R China.
EM designbox@163.com; peimt@bit.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Azmandian M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P65, DOI 10.1109/VR.2014.6802053
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Fan L., 2022, IEEE Transactions on Visualization and Computer Graphics
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Handa A, 2016, IEEE INT CONF ROBOT, P5737, DOI 10.1109/ICRA.2016.7487797
   Hassan M, 2021, PROC CVPR IEEE, P14703, DOI 10.1109/CVPR46437.2021.01447
   Huang S, 2023, PROC CVPR IEEE, P16750, DOI 10.1109/CVPR52729.2023.01607
   Kanamori K, 2018, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR.2018.00033
   Kim SW, 2023, PROC CVPR IEEE, P8496, DOI 10.1109/CVPR52729.2023.00821
   Kosiorek A.R., 2021, P INT C MACH LEARN, P5742
   Lang YN, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P767, DOI [10.1109/VR.2019.8798018, 10.1109/vr.2019.8798018]
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Li CJ, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P665, DOI 10.1109/VRW52623.2021.00215
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Liang W., 2021, CHI C HUM FACT COMP, P1
   Liang W, 2019, IEEE T VIS COMPUT GR, V25, P1836, DOI 10.1109/TVCG.2019.2898721
   Lucero A., 2014, P C ADV COMP ENT TEC, P1
   Matsumoto K, 2021, INT SYM MIX AUGMENT, P498, DOI 10.1109/ISMAR52148.2021.00067
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Medeiros D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P21, DOI 10.1109/VR50410.2021.00022
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Nguyen A., 2021, PhD thesis
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Po RY, 2023, Arxiv, DOI arXiv:2303.12218
   Purkait Pulak, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P155, DOI 10.1007/978-3-030-58586-0_10
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   Sayyad E, 2020, INT SYM MIX AUGMENT, P608, DOI 10.1109/ISMAR50242.2020.00088
   Schäfer A, 2022, LECT NOTES COMPUT SC, V13484, P191, DOI 10.1007/978-3-031-16234-3_11
   Schulz P., 2019, CHI C HUM FACT COMP, P1
   Shapira L, 2016, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2016.23
   Shimizu M, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489897
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Talton JO, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944851
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.1581503942658, 10.1109/VR46266.2020.00-82]
   Wang WB, 2019, PROC CVPR IEEE, P8180, DOI 10.1109/CVPR.2019.00838
   Wang Z., 2022, Advances in Neural Information Processing Systems, V35, P14959
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   Yan YK, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3380983
   Yang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1093, DOI 10.1145/3332165.3347875
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zhang YR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P674, DOI 10.1109/VR51125.2022.00088
NR 51
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2517
EP 2526
DI 10.1109/TVCG.2024.3372115
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400043
PM 38437138
DA 2024-08-05
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Raveendranath, B
   Canales, R
   Sarno, DM
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Rohith
   Venkatakrishnan, Roshan
   Raveendranath, Balagopal
   Canales, Ryan
   Sarno, Dawn M.
   Robb, Andrew C.
   Lin, Wen-Chieh
   Babu, Sabarish V.
TI The Effects of Secondary Task Demands on Cybersickness in Active
   Exploration Virtual Reality Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Cybersickness; Navigation; Motion sickness;
   Visualization; Skin; Virtual environments; Virtual Reality; Secondary
   Task Demand; Active Exploration; Electrodermal Activity
ID N-BACK TASK; MOTION SICKNESS; DRIVER DISTRACTION; WORKING-MEMORY;
   QUESTIONNAIRE; PERFORMANCE; SUSCEPTIBILITY; METAANALYSIS; MUSIC; SPEED
AB Active exploration in virtual reality (VR) involves users navigating immersive virtual environments, going from one place to another. While navigating, users often engage in secondary tasks that require attentional resources, as in the case of distracted driving. Inspired by research generally studying the effects of task demands on cybersickness (CS), we investigated how the attentional demands specifically associated with secondary tasks performed during exploration affect CS. Downstream of this, we studied how increased attentional demands from secondary tasks affect spatial memory and navigational performance. We discuss the results of a multi-factorial between-subjects study, manipulating a secondary task's demand across two levels and studying its effects on CS in two different sickness-inducing levels of an exploration experience. The secondary task's demand was manipulated by parametrically varying n in an aural n-back working memory task and the provocativeness of the experience was manipulated by varying how frequently users experienced a yaw-rotational reorientation effect during the exploration. Results revealed that increases in the secondary task's demand increased sickness levels, also resulting in a higher temporal onset rate, especially when the experience was not already highly sickening. Increased attentional demand from the secondary task also vitiated navigational performance and spatial memory. Overall, increased demands from secondary tasks performed during navigation produce deleterious effects on the VR experience.
C1 [Venkatakrishnan, Rohith; Venkatakrishnan, Roshan] Univ Florida, Res Associates, Gainesville, FL 32611 USA.
   [Raveendranath, Balagopal; Canales, Ryan] Clemson Univ, Clemson, SC USA.
   [Sarno, Dawn M.] Clemson Univ, Dept Psychol, Clemson, SC USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC USA.
C3 State University System of Florida; University of Florida; Clemson
   University; Clemson University; National Yang Ming Chiao Tung
   University; Clemson University
RP Venkatakrishnan, R (corresponding author), Univ Florida, Res Associates, Gainesville, FL 32611 USA.
EM rohith.venkatakr@ufl.edu; rvenkatakrishnan@ufl.edu;
   braveen@g.clemson.edu; rcanale@g.clemson.edu; dmsarno@clemson.edu;
   wclin@cs.nctu.edu.tw; arobb@clemson.edu; sbabu@clemson.edu
RI Venkatakrishnan, Roshan/JDC-3508-2023; Venkatakrishnan,
   Rohith/JCE-8736-2023
OI Venkatakrishnan, Roshan/0000-0002-6538-627X; Venkatakrishnan,
   Rohith/0000-0002-8484-3915; Sarno, Dawn/0000-0001-5605-5957; Babu,
   Sabarish/0000-0002-8348-0534; Robb, Andrew/0000-0002-0398-5576; Canales,
   Ryan/0000-0003-0554-7817
FU US National Science Foundation (CISE IIS HCC)
FX No Statement Available
CR Açikel BY, 2018, SIMULAT GAMING, V49, P27, DOI 10.1177/1046878117750417
   Ang S, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P428, DOI 10.1109/VR51125.2022.00062
   [Anonymous], 1973, Attention and effort
   Blanco M, 2006, ACCIDENT ANAL PREV, V38, P895, DOI 10.1016/j.aap.2006.02.015
   Bos JE, 2005, AVIAT SPACE ENVIR MD, V76, P1111
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Bowman D. A., 1998, Virtual Reality, V3, P120, DOI 10.1007/BF01417673
   Braithwaite J.J., 2013, PSYCHOPHYSIOLOGY, P1
   Burte H., 2012, P ANN M COGN SCI SOC, V34
   Burte H, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0057-4
   Collet C, 2009, APPL ERGON, V40, P1041, DOI 10.1016/j.apergo.2009.01.007
   Davis S., 2014, P 2014 C INT ENT, P1
   Dawson ME., 2017, The electrodermal system
   Fang J, 2014, TRANSPORT RES REC, P26, DOI 10.3141/2434-04
   Farmani Y., 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI201 8.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Ferdinand AO, 2014, AM J PUBLIC HEALTH, V104, pE39, DOI 10.2105/AJPH.2013.301750
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fisher DL, 2006, INJURY PREV, V12, P25, DOI 10.1136/ip.2006.012021
   Galvez-Garcia G, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102931
   Garrido LE, 2022, VIRTUAL REAL-LONDON, V26, P1347, DOI 10.1007/s10055-022-00636-4
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   GUEDRY F E Jr, 1964, Acta Otolaryngol, V58, P377, DOI 10.3109/00016486409121398
   Heinrichs WL, 2008, WORLD J SURG, V32, P161, DOI 10.1007/s00268-007-9354-2
   Hettinger J., 1992, Presence, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Hong Y, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281519
   Horberry T, 2006, ACCIDENT ANAL PREV, V38, P185, DOI 10.1016/j.aap.2005.09.007
   HU S, 1991, AVIAT SPACE ENVIR MD, V62, P53
   HU S, 1988, PSYCHOPHYSIOLOGY, V25, P456
   Johnson Malcolm H, 2005, Curr Pain Headache Rep, V9, P90, DOI 10.1007/s11916-005-0044-1
   JungHa Park, 2020, The International Journal of Advanced Culture Technology, V8, P89
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Keshavarz B., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications, P648
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kwok KKK, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P91, DOI 10.1109/ISMAR-Adjunct.2018.00041
   Kye S, 2022, IEEE SENSOR, DOI 10.1109/SENSORS52175.2022.9967138
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lampton DR., 1994, Presence: Teleoperators and Virtual Environments, V3, P145, DOI 10.1162/pres.1994.3.2.145
   Lansdown T, 2004, ERGONOMICS, V47, P91, DOI 10.1080/00140130310001629775
   Legrain V, 2009, PAIN, V144, P230, DOI 10.1016/j.pain.2009.03.020
   Lier EJ, 2022, SCAND J PAIN, V22, P385, DOI 10.1515/sjpain-2021-0119
   Lin YX, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419984
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   McCauley M. E., 1992, Teleoperators and Virtual Environments, V1, P311, DOI [10.1162/pres.1992.1.3.311, DOI 10.1162/PRES.1992.1.3.311]
   Meusel C. R., 2014, Exploring mental effort and nausea via electrodermal activity within scenario-based tasks
   Miller JamesC., 1993, Autonomic physiological data associated with simulator discomfort
   Mohammed S, 2017, J COGN ENHANCE, V1, P491, DOI 10.1007/s41465-017-0047-y
   MONEY KE, 1970, PHYSIOL REV, V50, P1, DOI 10.1152/physrev.1970.50.1.1
   Monk AF, 2011, BEHAV RES METHODS, V43, P888, DOI 10.3758/s13428-011-0074-z
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Osborne J.W., 2000, Practical Assessment, Research, Evaluation, V7, DOI DOI 10.7275/PMGN-ZX89
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Pohlmann K. M. T., 2023, P 2023 CHI C HUM FAC, P1
   Ranney T.A., 2001, NHTSA DRIVER DISTRAC
   Reason J. T., 1975, Motion Sickness
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Rebenitsch L., 2015, XRDS: Crossroads, The ACM Magazine for Students, V22, P46
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Salgado DP, 2019, PROCEDIA COMPUT SCI, V160, P665, DOI 10.1016/j.procs.2019.11.030
   Samson MM, 2001, AGING CLIN EXP RES, V13, P16, DOI 10.1007/BF03351489
   Sang FDYP, 2003, J TRAVEL MED, V10, P108, DOI 10.2310/7060.2003.31768
   Sang FDYP, 2003, AVIAT SPACE ENVIR MD, V74, P998
   Sepich NC, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.943409
   Sherman CR, 2002, J TRAVEL MED, V9, P251
   Snijders TA, 2012, MULTILEVEL ANAL INTR
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Stein Michael., 2012, Aviation Psychology and Applied Human Factors
   Strayer DL, 2011, PSYCHOL LEARN MOTIV, V54, P29, DOI 10.1016/B978-0-12-385527-5.00002-4
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Tu F. K., 2020, Smooth locomotion in vr: Comparing head orientation and controller orientation locomotion
   Vallat-Azouvi C, 2012, NEUROPSYCHOL REHABIL, V22, P634, DOI 10.1080/09602011.2012.681110
   Venkatakrishnan R., 2023, The effects of primary and secondary task workloads on cybersickness in immersive virtual active exploration experiences
   Venkatakrishnan R., 2023, IEEE Transactions on Visualization and Computer Graphics
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Venkatakrishnan R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1201, DOI [10.1109/vr.2019.8797728, 10.1109/VR.2019.8797728]
   Venkatakrishnan R, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560817
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P672, DOI [10.1109/VR46266.2020.1581256520838, 10.1109/VR46266.2020.00-14]
   von Janczewski N, 2021, TRANSPORT RES F-TRAF, V76, P269, DOI 10.1016/j.trf.2020.11.014
   Wald J, 2000, J BEHAV THER EXP PSY, V31, P249, DOI 10.1016/S0005-7916(01)00009-X
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wickens C.D., 1984, Varieties of Attention, P63
   Wickens C. D., 1980, Attention and performance VIII, V8, P239
   Wickens C.D., 2021, Handbook of Human Factors and Ergonmics, P114, DOI [DOI 10.1002/9781119636113.CH5, 10.1002/9781119636113.ch5]
   Wu F., 2021, P 2021 ACM S SPAT US, P1
   Wu F, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P103, DOI 10.1109/VR51125.2022.00028
   Young K., 2007, Distracted Driving, P379
   Zhou C, 2019, IEEE INT CONF MOB, P72, DOI 10.1109/MASSW.2019.00021
NR 96
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2745
EP 2755
DI 10.1109/TVCG.2024.3372080
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400046
PM 38437100
DA 2024-08-05
ER

PT J
AU Neto, MP
   Paulovich, FV
AF Neto, Mario Popolin
   Paulovich, Fernando V.
TI Multivariate Data Explanation by Jumping Emerging Patterns Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data explanation; jumping emerging patterns; random decision trees;
   exploratory analysis
ID INTERACTIVE VISUAL ANALYSIS; GENERATION; DISCOVERY; SPACE
AB Multivariate or multidimensional visualization plays an essential role in exploratory data analysis by allowing users to derive insights and formulate hypotheses. Despite their popularity, it is usually users' responsibility to (visually) discover the data patterns, which can be cumbersome and time-consuming. Visual Analytics (VA) and machine learning techniques can be instrumental in mitigating this problem by automatically discovering and representing such patterns. One example is the integration of classification models with (visual) interpretability strategies, where models are used as surrogates for data patterns so that understanding a model enables understanding the phenomenon represented by the data. Although useful and inspiring, the few proposed solutions are based on visual representations of so-called black-box models, so the interpretation of the patterns captured by the models is not straightforward, requiring mechanisms to transform them into human-understandable pieces of information. This paper presents multiVariate dAta eXplanation (VAX), a new VA method to support identifying and visual interpreting patterns in multivariate datasets. Unlike the existing similar approaches, VAX uses the concept of Jumping Emerging Patterns, inherent interpretable logic statements representing class-variable relationships (patterns) derived from random Decision Trees. The potential of VAX is shown through use cases employing two real-world datasets covering different scenarios where intricate patterns are discovered and represented, something challenging to be done using usual exploratory approaches.
C1 [Neto, Mario Popolin] Univ Sao Paulo, Fed Inst Sao Paulo IFSP, BR-05508060 Sao Paulo, Brazil.
   [Paulovich, Fernando V.] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
C3 Universidade de Sao Paulo; Instituto Federal de Sao Paulo (IFSP);
   Eindhoven University of Technology
RP Paulovich, FV (corresponding author), Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
EM mariopopolin@ifsp.edu.br; f.paulovich@tue.nl
RI ; Paulovich, Fernando/G-1329-2010
OI Popolin Neto, Mario/0000-0002-8379-2458; Paulovich,
   Fernando/0000-0002-2316-760X
FU Qualification Program of the Federal Institute of Sao Paulo (IFSP)
FX The authors wish to thank the valuable comments and suggestions obtained
   from the reviewers, as well as the supportreceived from the
   Qualification Program of the Federal Institute of Sao Paulo (IFSP).
CR Anwar N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND COMPUTATIONAL INTELLIGENCE (CYBERNETICSCOM), P11, DOI 10.1109/CYBERNETICSCOM.2017.8311714
   Bernard J, 2014, COMPUT GRAPH FORUM, V33, P291, DOI 10.1111/cgf.12385
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boulesteix AL, 2003, BIOINFORMATICS, V19, P2465, DOI 10.1093/bioinformatics/btg361
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cao F, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P256, DOI 10.1109/VIS47514.2020.00058
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Chan G. Y. -Y., 2020, Melody: Generating and visualizing machine learning model summary to understand data and classifiers together
   Chen CH, 2004, COMPSTAT 2004: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P85
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   De Silva Vin, 2004, Sparse multidimensional scaling using landmark points
   Di Castro F., 2019, P IUI WORKSH
   Dong G., 1999, KDD 1999: Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining, P43, DOI [10.1145/312129.312191, 10.1145/312129., DOI 10.1145/312129]
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Furnkranz J., 2012, Foundations of Rule Learning
   Gamberger D., 2002, P INT WORKSH INT DAT, P31
   García-Borroto M, 2015, EXPERT SYST APPL, V42, P4859, DOI 10.1016/j.eswa.2015.02.028
   García-Vico AM, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1231
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2042, DOI 10.1109/TVCG.2013.157
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Guidotti R, 2018, Arxiv, DOI arXiv:1805.10820
   Helliwell J., 2019, World Happiness Report 2019
   Huysmans J, 2011, DECIS SUPPORT SYST, V51, P141, DOI 10.1016/j.dss.2010.12.003
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1
   Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767, DOI 10.1111/j.1467-8659.2009.01475.x
   Kane B, 2015, LECT NOTES ARTIF INT, V9077, P722, DOI 10.1007/978-3-319-18038-0_56
   Keim D., 2010, Mastering the information age solving problems with visual analytics, DOI [10.2312/14803, DOI 10.2312/14803]
   Knittel J, 2021, IEEE T VIS COMPUT GR, V27, P1374, DOI 10.1109/TVCG.2020.3030420
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Li Jie, 2023, IEEE Trans Vis Comput Graph, V29, P723, DOI 10.1109/TVCG.2022.3209382
   Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58
   Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376590
   Liu Qiangqiang, 2023, IEEE Trans Vis Comput Graph, V29, P701, DOI 10.1109/TVCG.2022.3209463
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Loekito E, 2009, LECT NOTES ARTIF INT, V5476, P483, DOI 10.1007/978-3-642-01307-2_44
   Loyola-González O, 2020, J GRID COMPUT, V18, P797, DOI 10.1007/s10723-020-09526-y
   Loyola-González O, 2019, INFORM FUSION, V46, P91, DOI 10.1016/j.inffus.2018.05.004
   Lundberg SM, 2017, ADV NEUR IN, V30
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Mazumdar D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222862
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Michalski R., 1982, Machine Learning, V10
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Miranda TZ, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113811
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Novak PK, 2009, J MACH LEARN RES, V10, P377
   Paja W, 2018, LECT NOTES ARTIF INT, V10933, P230, DOI 10.1007/978-3-319-95786-9_17
   Paulovich FV, 2010, IEEE T VIS COMPUT GR, V16, P1281, DOI 10.1109/TVCG.2010.207
   Pérez D, 2015, NEUROCOMPUTING, V150, P611, DOI 10.1016/j.neucom.2014.09.061
   Piringer H, 2008, IEEE INT CONF INF VI, P240, DOI 10.1109/IV.2008.17
   Popolin Neto M, 2021, IEEE T VIS COMPUT GR, V27, P1427, DOI 10.1109/TVCG.2020.3030354
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Salman R, 2012, IEEE SOUTHEASTCON
   Talbot J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1283
   Tan P-N, 2005, INTRO DATA MINING
   Teoh S.T., 2003, Proc. ninth ACM SIGKDD Int. Conf. Knowledge discovery and data mining, P667, DOI [https://doi.org/10.1145/956750.956837, DOI 10.1145/956750.956837]
   Tompson T., 2018, AP votecast 2018
   Dang TN, 2014, IEEE PAC VIS SYMP, P73, DOI 10.1109/PacificVis.2014.42
   Turkay C, 2012, IEEE T VIS COMPUT GR, V18, P2621, DOI 10.1109/TVCG.2012.256
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2023, IEEE T VIS COMPUT GR, V29, P3809, DOI 10.1109/TVCG.2022.3172107
   Wang LS, 2005, THEOR COMPUT SCI, V335, P15, DOI 10.1016/j.tcs.2004.12.014
   Wu H.-M., 2008, Handbook of data visualization, P681
   Yamamoto CH, 2007, ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P87, DOI 10.1109/ICMLA.2007.45
   Yamamoto CH, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1212
   Yuan XR, 2013, IEEE T VIS COMPUT GR, V19, P2625, DOI 10.1109/TVCG.2013.150
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
NR 80
TC 4
Z9 4
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1549
EP 1563
DI 10.1109/TVCG.2022.3223529
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300003
PM 36409810
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lei, F
   Ma, YX
   Fotheringham, AS
   Mack, EA
   Li, ZQ
   Sachdeva, M
   Bardin, S
   Maciejewski, R
AF Lei, Fan
   Ma, Yuxin
   Fotheringham, A. Stewart
   Mack, Elizabeth A.
   Li, Ziqi
   Sachdeva, Mehak
   Bardin, Sarah
   Maciejewski, Ross
TI GeoExplainer: A Visual Analytics Framework for Spatial Modeling
   Contextualization and Report Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial data analysis; local models; multiscale geographically weighted
   regression; model explanation; visual analytics
ID GEOGRAPHICALLY WEIGHTED REGRESSION; VISUALIZATION; EXPLORATION;
   PREDICTION; STORIES; TIME
AB Geographic regression models of various descriptions are often applied to identify patterns and anomalies in the determinants of spatially distributed observations. These types of analyses focus on answering why questions about underlying spatial phenomena, e.g., why is crime higher in this locale, why do children in one school district outperform those in another, etc.? Answers to these questions require explanations of the model structure, the choice of parameters, and contextualization of the findings with respect to their geographic context. This is particularly true for local forms of regression models which are focused on the role of locational context in determining human behavior. In this paper, we present GeoExplainer, a visual analytics framework designed to support analysts in creating explanative documentation that summarizes and contextualizes their spatial analyses. As analysts create their spatial models, our framework flags potential issues with model parameter selections, utilizes template-based text generation to summarize model outputs, and links with external knowledge repositories to provide annotations that help to explain the model results. As analysts explore the model results, all visualizations and annotations can be captured in an interactive report generation widget. We demonstrate our framework using a case study modeling the determinants of voting in the 2016 US Presidential Election.
C1 [Lei, Fan; Fotheringham, A. Stewart; Sachdeva, Mehak; Bardin, Sarah; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85287 USA.
   [Ma, Yuxin] Southern Univ Sci & Technol, Shenzhen, Guangdong, Peoples R China.
   [Mack, Elizabeth A.] Michigan State Univ, E Lansing, MI USA.
   [Li, Ziqi] Florida State Univ, Tallahassee, FL 32306 USA.
C3 Arizona State University; Arizona State University-Tempe; Southern
   University of Science & Technology; Michigan State University; State
   University System of Florida; Florida State University
RP Ma, YX (corresponding author), Southern Univ Sci & Technol, Shenzhen, Guangdong, Peoples R China.
EM flei5@asu.edu; mayx@sustech.edu.cn; sfotheri@asu.edu; emack@msu.edu;
   liziqi1992@gmail.com; msachde1@asu.edu; sfbardin@asu.edu;
   rmacieje@asu.edu
OI Lei, Fan/0000-0003-4244-0971
FU National Science Foundation
FX No Statement Available
CR Anselin L, 2006, GEOGR ANAL, V38, P5, DOI 10.1111/j.0016-7363.2005.00671.x
   Anselin L., 1996, Regional Research Institute Working Papers, V200, P3
   Behera S, 2018, INT CONF UBIQ FUTUR, P448, DOI 10.1109/ICUFN.2018.8437001
   Bertini E., 2009, Proceedings of the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery: Integrating Automated Analysis with Interactive Exploration, P12
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brock AM, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P1, DOI 10.1145/3152832.3152833
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen Y., 2010, Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), P3703
   Choudhry A, 2021, IEEE T VIS COMPUT GR, V27, P1332, DOI 10.1109/TVCG.2020.3030358
   Cook RD, 2000, TECHNOMETRICS, V42, P65, DOI 10.2307/1271434
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Eccles R, 2008, INFORM VISUAL, V7, P3, DOI 10.1057/palgrave.ivs.9500173
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Fotheringham A., 2008, The SAGE Handbook of Spatial Analysis, P3
   Fotheringham A. S., 2003, Geographically Weighted Regression: The Analysis of Spatially Varying Relationships, P1
   Fotheringham AS, 2017, ANN AM ASSOC GEOGR, V107, P1247, DOI 10.1080/24694452.2017.1352480
   Gao T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3005, DOI 10.1145/2556288.2557228
   Gareth J., 2013, An Introduction to Statistical Learning with Applications, P4
   Gil J., 2015, INT SPACE SYNTAX S, V10
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Guo DS, 2006, IEEE T VIS COMPUT GR, V12, P1461, DOI 10.1109/TVCG.2006.84
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kanevski M., 2009, Machine Learning for Spatial Environmental Data: Theory, Applications, and Software, P2
   Kastanakis B., 2016, Mapbox Cookbook, P3
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   KRAMER W, 1987, J AM STAT ASSOC, V82, P577, DOI 10.2307/2289467
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Latif S, 2021, COMPUT GRAPH FORUM, V40, P311, DOI 10.1111/cgf.14309
   Latif S, 2019, VIS INFORM, V3, P27, DOI 10.1016/j.visinf.2019.03.004
   Li J, 2011, ENVIRON MODELL SOFTW, V26, P1647, DOI 10.1016/j.envsoft.2011.07.004
   Li X, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820792
   Li ZQ, 2020, INT J GEOGR INF SCI, V34, P1378, DOI 10.1080/13658816.2020.1720692
   Liess M, 2012, GEODERMA, V170, P70, DOI 10.1016/j.geoderma.2011.10.010
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Lovelace R., 2019, Geocomputation with R. Chapman and Hall/CRC, P2
   Lu JH, 2017, FRONT COMPUT SCI-CHI, V11, P192, DOI 10.1007/s11704-016-6028-y
   Lu YF, 2017, COMPUT GRAPH FORUM, V36, P539, DOI 10.1111/cgf.13210
   Lundblad Patrik, 2013, 2013 17th International Conference on Information Visualisation, P263, DOI 10.1109/IV.2013.35
   Meta Platforms Inc, 2022, React official page
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Nathan Paco, 2021, Zenodo
   Nusrat S, 2018, IEEE T VIS COMPUT GR, V24, P2675, DOI 10.1109/TVCG.2017.2765330
   Oshan TM, 2019, ISPRS INT GEO-INF, V8, DOI 10.3390/ijgi8060269
   Ozturk D., 2016, AGU FALL M ABSTRACTS, pIN53A
   Pace RK, 1997, J REAL ESTATE FINANC, V14, P333, DOI 10.1023/A:1007762613901
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Rey S. J., 2021, Geographical Analysis, DOI [10.1111/gean.122762, DOI 10.1111/GEAN.122762]
   Rey SJ, 2007, REV REG STUD, V37, P5
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Scott L. M., 2010, Handbook of Applied Spatial Analysis: Software Tools, Methods and Applications, P27, DOI [10.1007/978-3-642-03647-72, DOI 10.1007/978-3-642-03647-72]
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shabrina Z, 2021, GEOGR ANAL, V53, P686, DOI 10.1111/gean.12259
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Fotheringham AS, 2021, ANN AM ASSOC GEOGR, V111, P1602, DOI 10.1080/24694452.2020.1835459
   Strode G., 2020, Cartographic Perspectives, V94, P5, DOI [10.14714/CP94.1538, DOI 10.14714/CP94.1538]
   Takatsuka M, 2002, COMPUT GEOSCI-UK, V28, P1131, DOI 10.1016/S0098-3004(02)00031-6
   Talbot J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1283
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Traag VA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41695-z
   Vittinghoff E., 2006, Regression Methods in Biostatistics: Linear, Logistic, Survival, and Repeated Measures Models, V4, P6
   Yang Chen, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P155, DOI 10.1109/VAST.2010.5652885
   Zhu AX, 2018, ANN GIS, V24, P225, DOI 10.1080/19475683.2018.1534890
NR 71
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1391
EP 1401
DI 10.1109/TVCG.2023.3327359
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500068
PM 37883268
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Teng, X
   Ahn, Y
   Lin, YR
AF Teng, Xian
   Ahn, Yongsu
   Lin, Yu-Ru
TI V: Visual Aids for Identifying and Interpreting Spurious Associations in
   Data-Driven Decisions&lt;sc/&gt;
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Decision making; Training; Interviews; Cognition;
   Machine learning; Systematics; Causal Analysis; Simpson's Paradox;
   Spurious Associations; Machine Learning; Decision Making
ID PROPENSITY SCORE; CAUSAL INFERENCE; SIMPSONS PARADOX; EXPLORATION; BIAS
AB Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose Vispur, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a Confounder Dashboard, which can automatically identify possible confounding factors, and a Subgroup Viewer, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of causality. Additionally, we propose a Reasoning Storyboard, which uses a flow-based approach to illustrate paradoxical phenomena, as well as an interactive Decision Diagnosis panel that helps ensure accountable decision-making. Through an expert interview and a controlled user experiment, our qualitative and quantitative results demonstrate that the proposed "de-paradox" workflow and the designed visual analytic system are effective in helping human users to identify and understand spurious associations, as well as to make accountable causal decisions.
C1 [Teng, Xian; Ahn, Yongsu; Lin, Yu-Ru] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Teng, X (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.
EM xit22@pitt.edu; yongsu.ahn@pitt.edu; yurulin@pitt.edu
OI Lin, Yu-Ru/0000-0002-8497-3015; Ahn, Yongsu/0000-0002-5797-5445
FU AFOSR
FX No Statement Available
CR Ahn Y, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3484509
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Armstrong Z, 2014, IEEE T VIS COMPUT GR, V20, P2132, DOI 10.1109/TVCG.2014.2346297
   Athey S, 2019, ANN STAT, V47, P1148, DOI 10.1214/18-AOS1709
   Athey S, 2016, P NATL ACAD SCI USA, V113, P7353, DOI 10.1073/pnas.1510489113
   Austin PC, 2019, STAT METHODS MED RES, V28, P1365, DOI 10.1177/0962280218756159
   Austin PC, 2015, STAT MED, V34, P3661, DOI 10.1002/sim.6607
   Baker SG, 2001, J WOMEN HEALTH GEN-B, V10, P867, DOI 10.1089/152460901753285769
   Battocchi K., 2019, EconML: A Python Package for ML-Based Heterogeneous Treatment Effects Estimation
   BICKEL PJ, 1975, SCIENCE, V187, P398, DOI 10.1126/science.187.4175.398
   Blumenschein M, 2018, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST.2018.8802486
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Cao N, 2018, INFORM VISUAL, V17, P22, DOI 10.1177/1473871616686635
   Chen HG, 2020, Arxiv, DOI arXiv:2002.11631
   Chen M, 2011, COMPUTER, V44, P83, DOI 10.1109/MC.2011.313
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Clark WR, 2015, PS-POLIT SCI POLIT, V48, P65, DOI 10.1017/S1049096514001759
   Cole SR, 2009, EPIDEMIOLOGY, V20, P3, DOI 10.1097/EDE.0b013e31818ef366
   Cookson R, 2021, J HEALTH ORGAN MANAG, V35, P665, DOI 10.1108/JHOM-07-2020-0275
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   DeGrave AJ, 2021, NAT MACH INTELL, V3, P610, DOI 10.1038/s42256-021-00338-7
   Dehejia RH, 1999, J AM STAT ASSOC, V94, P1053, DOI 10.2307/2669919
   Dehejia RH, 2002, REV ECON STAT, V84, P151, DOI 10.1162/003465302317331982
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Fong C, 2018, ANN APPL STAT, V12, P156, DOI 10.1214/17-AOAS1101
   Friendly M, 2013, STAT SCI, V28, P1, DOI 10.1214/12-STS402
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Gerring J, 2005, J THEOR POLIT, V17, P163, DOI 10.1177/0951629805050859
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Greenland S, 2003, EPIDEMIOLOGY, V14, P300, DOI 10.1097/00001648-200305000-00009
   Greifer N, 2023, cobalt: Covariate Balance Tables and Plots
   Guo G., 2023, Photonics, P1
   Guo G, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P21, DOI 10.1109/VIS49827.2021.9623285
   Heckman JJ, 1997, REV ECON STUD, V64, P605, DOI 10.2307/2971733
   Hernan Miguel A., 2020, Causal inference: what if
   Ho DE, 2011, J STAT SOFTW, V42
   Imai K, 2014, J R STAT SOC B, V76, P243, DOI 10.1111/rssb.12027
   Imbens GW., 2010, Microeconometrics. The new Palgrave economics collection, DOI [10.1057/9780230280816_282,4, 10.1057/9780230280816, DOI 10.1057/9780230280816]
   Inselberg A., 2009, IEEE Trans Hum Mach Syst, P199, DOI [10.1007/978-0-387-68628-8, DOI 10.1007/978-0-387-68628-8]
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Joshi Nitish, 2022, arXiv
   Kale A., 2021, IEEE Trans. Visual Comput. Graphics, DOI DOI 10.1109/TVCG.2021.31148242,3
   Kery Mary Beth, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383085
   Kiciman E., NEURIPS 2022 WORKSHO, V3
   Kievit RA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00513
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Künzel SR, 2019, P NATL ACAD SCI USA, V116, P4156, DOI 10.1073/pnas.1804597116
   Kwon BC, 2022, IEEE VIS CONF, P50, DOI 10.1109/VIS54862.2022.00019
   Kwon BC, 2021, IEEE T VIS COMPUT GR, V27, P3685, DOI 10.1109/TVCG.2020.2985689
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   LALONDE RJ, 1986, AM ECON REV, V76, P604
   Lerman K, 2018, J COMPUT SOC SCI, V1, P49, DOI 10.1007/s42001-017-0007-4
   Lesser L. M., 2001, Representations of reversal: An exploration of Simpson's paradox
   Microsoft Research, 2022, Introduction to ShowWhy, user interfaces for causal decision making
   Moris J., 2021, Israeli data: How can efficacy vs. severe disease be strong when 60% of hospitalized are vaccinated?
   Norton H. J., 2015, Significance, V12, P40
   Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342
   Oprescu M, 2019, PR MACH LEARN RES, V97
   Park Y, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.3909
   Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.2307/2337329
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   ROSENBAUM PR, 1983, BIOMETRIKA, V70, P41, DOI 10.1093/biomet/70.1.41
   Rücker G, 2008, BMC MED RES METHODOL, V8, DOI 10.1186/1471-2288-8-79
   RuM F., 1980, Math. Mag., V53, P106, DOI [DOI 10.2307/26899592,3,12,13, 10.2307/26899593,12,13]
   Sharma A, 2020, Arxiv, DOI [arXiv:2011.04216, DOI 10.48550/ARXIV.2011.04216]
   Shimoni Y, 2019, Arxiv, DOI arXiv:1906.00442
   Syrgkanis V., 2019, NeurIPS, V32, DOI DOI 10.48550/ARXIV.1905.10176
   VanderWeele TJ, 2013, J CAUSAL INFERENCE, V1, P1, DOI 10.1515/jci-2012-0002
   Wager S, 2018, J AM STAT ASSOC, V113, P1228, DOI 10.1080/01621459.2017.1319839
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wang ZJ, 2022, Arxiv, DOI arXiv:2205.03963
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Xie X, 2020, Arxiv, DOI arXiv:2008.11899
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
NR 76
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 219
EP 229
DI 10.1109/TVCG.2023.3326587
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500009
PM 37871075
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Vieth, A
   Kroes, T
   Thijssen, J
   van Lew, B
   Eggermont, J
   Basu, S
   Eisemann, E
   Vilanova, A
   Höllt, T
   Lelieveldt, B
AF Vieth, Alexander
   Kroes, Thomas
   Thijssen, Julian
   van Lew, Baldur
   Eggermont, Jeroen
   Basu, Soumyadeep
   Eisemann, Elmar
   Vilanova, Anna
   Hollt, Thomas
   Lelieveldt, Boudewijn
TI ManiVault: A Flexible and Extensible Visual Analytics Framework for
   High-Dimensional Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visual analytics; Software; Graphical user
   interfaces; Task analysis; Spatial databases; Python; High-dimensional
   data; Visualization framework; Progressive analytics; Prototyping system
ID INTERACTIVE VISUALIZATION; EXPLORATION; DESIGN; SYSTEM; LYRA
AB Exploration and analysis of high-dimensional data are important tasks in many fields that produce large and complex data, like the financial sector, systems biology, or cultural heritage. Tailor-made visual analytics software is developed for each specific application, limiting their applicability in other fields. However, as diverse as these fields are, their characteristics and requirements for data analysis are conceptually similar. Many applications share abstract tasks and data types and are often constructed with similar building blocks. Developing such applications, even when based mostly on existing building blocks, requires significant engineering efforts. We developed ManiVault, a flexible and extensible open-source visual analytics framework for analyzing high-dimensional data. The primary objective of ManiVault is to facilitate rapid prototyping of visual analytics workflows for visualization software developers and practitioners alike. ManiVault is built using a plugin-based architecture that offers easy extensibility. While our architecture deliberately keeps plugins self-contained, to guarantee maximum flexibility and re-usability, we have designed and implemented a messaging API for tight integration and linking of modules to support common visual analytics design patterns. We provide several visualization and analytics plugins, and ManiVault's API makes the integration of new plugins easy for developers. ManiVault facilitates the distribution of visualization and analysis pipelines and results for practitioners through saving and reproducing complete application states. As such, ManiVault can be used as a communication tool among researchers to discuss workflows and results.
C1 [Vieth, Alexander; Eisemann, Elmar; Hollt, Thomas; Lelieveldt, Boudewijn] Delft Univ Technol, Delft, Netherlands.
   [Kroes, Thomas; Thijssen, Julian; van Lew, Baldur; Eggermont, Jeroen; Basu, Soumyadeep; Lelieveldt, Boudewijn] Leiden Univ, Med Ctr, Leiden, Netherlands.
   [Vilanova, Anna] TU Eindhoven, Eindhoven, Netherlands.
C3 Delft University of Technology; Leiden University - Excl LUMC; Leiden
   University; Leiden University Medical Center (LUMC); Eindhoven
   University of Technology
RP Vieth, A (corresponding author), Delft Univ Technol, Delft, Netherlands.
EM A.Vieth@tudelft.nl; T.Kroes@lumc.nl; J.G.L.Thijssen@lumc.nl;
   B.van_Lew@lumc.nl; J.Eggermont@lumc.nl; S.Basu@lumc.nl;
   E.Eisemann@tudelft.nl; A.Vilanova@tue.nl; T.Hollt-1@tudelft.nl;
   B.P.F.Lelieveldt@lumc.nl
RI ; Lelieveldt, Boudewijn/B-6501-2008
OI /0000-0001-8125-1650; Thijssen, Julian/0009-0007-7585-6451; van Lew,
   Baldur/0000-0003-0628-1264; Kroes, Thomas/0000-0002-0658-2203;
   Lelieveldt, Boudewijn/0000-0001-8269-7603; Vilanova,
   Anna/0000-0002-1034-737X; Vieth, Alexander/0000-0002-5809-4316
FU NWO
FX No Statement Available
CR Ahlberg C., 1996, SIGMOD Record, V25, P25, DOI 10.1145/245882.245893
   AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P313, DOI 10.1145/191666.191775
   Ahrens J., 2005, Visualization handbook, P717, DOI DOI 10.1016/B978-012387582-2/50038-1
   [Anonymous], 3D SLICER
   [Anonymous], 2005, Illuminating the path: The research and development agenda for visual analytics
   Badam SK, 2017, COMPUT GRAPH FORUM, V36, P491, DOI 10.1111/cgf.13205
   Bakken TE, 2021, NATURE, V598, P111, DOI 10.1038/s41586-021-03465-8
   Bavoil L, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P135, DOI 10.1109/visual.2005.1532788
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P156, DOI 10.1109/VISUAL.1991.175794
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Childs H., 2012, VisIt: An EndUser Tool for Visualizing and Analyzing Very Large Data, DOI [10.1201/b12985-29, DOI 10.1201/B12985-29]
   Cui QG, 2006, IEEE T VIS COMPUT GR, V12, P709, DOI 10.1109/TVCG.2006.161
   Cui WQ, 2019, IEEE ACCESS, V7, P81555, DOI 10.1109/ACCESS.2019.2923736
   Eggermont J., Cytosplore Viewer
   Fekete JD, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P167, DOI 10.1109/INFVIS.2004.64
   Fuchs R, 2009, COMPUT GRAPH FORUM, V28, P1670, DOI 10.1111/j.1467-8659.2009.01429.x
   Gahegan M, 2009, CH CRC DATA MIN KNOW, P291
   Ghosh A, 2018, VIS INFORM, V2, P235, DOI 10.1016/j.visinf.2018.12.004
   githubuser0xFFFF, Advanced docking system for Qt
   Heer J., 2005, P ACM CHI, P421
   Höllt T, 2016, COMPUT GRAPH FORUM, V35, P171, DOI 10.1111/cgf.12893
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kerren A, 2014, LECT NOTES COMPUT SC, V8380, P1, DOI 10.1007/978-3-319-06793-3_1
   Kitware, Trame
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Lam H, 2018, IEEE T VIS COMPUT GR, V24, P435, DOI 10.1109/TVCG.2017.2744319
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Landgrebe D. A., HYDICE image of washington dc mall
   Li C, 2023, bioRxiv, DOI [10.1101/2023.03.20.532934, 10.1101/2023.03.20.532934, DOI 10.1101/2023.03.20.532934]
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   Matkovic K, 2008, IEEE INT CONF INF VI, P215, DOI 10.1109/IV.2008.87
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Pezzotti Nicola, 2018, Zenodo, DOI 10.5281/ZENODO.1303855
   Pi M, 2021, IEEE T VIS COMPUT GR, V27, P2186, DOI 10.1109/TVCG.2019.2940580
   Piringer H, 2008, IEEE INT CONF INF VI, P240, DOI 10.1109/IV.2008.17
   Piringer H, 2009, IEEE T VIS COMPUT GR, V15, P1113, DOI 10.1109/TVCG.2009.110
   PLAISANT C, 1995, IEEE SOFTWARE, V12, P21, DOI 10.1109/52.368260
   Plotly Technologies Inc, About us
   Popa A., 2022, PROC GCH, DOI [10.2312/gch.20221233, DOI 10.2312/GCH.20221233]
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sakamoto N, 2015, J ADV SIMUL SCI ENG, V2, P76, DOI 10.15748/jasse.2.76
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Schroeder W., 2006, VISUALIZATION TOOLKI, DOI DOI 10.1016/B978-012387582-2/50003-4
   Sorger J., 2015, PROC VMV, P57, DOI DOI 10.2312/VMV.20151258
   Stalling D, 2005, Visualizat. Handbook, V38, P749
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Swayne DF, 2003, COMPUT STAT DATA AN, V43, P423, DOI 10.1016/S0167-9473(02)00286-4
   Tableau Software LLC, About us
   The Qt Company, About us
   Thermo-Fisher Scientific, About us
   Thijssen J., 2023, PROC EUROVA, DOI [10.2312/eurova.20231098, DOI 10.2312/EUROVA.20231098]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vieth A, 2022, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis53943.2022.00010
   Visplore GmbH, About us
   Ward M. O., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P326, DOI 10.1109/VISUAL.1994.346302
   Wolfe J.D, 2018, Technical report
   Wong P. C., 1994, Scientific Visualization, Overviews, Methodologies, and Techniques, P3
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yang J, 2003, COMPUT GRAPH-UK, V27, P265, DOI 10.1016/S0097-8493(02)00283-2
   Yang J., 2003, PROC VISSYM, DOI [10.2312/VisSym/VisSym03/019-028, DOI 10.2312/VISSYM/VISSYM03/019-028]
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 73
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 175
EP 185
DI 10.1109/TVCG.2023.3326582
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500070
PM 37871056
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Xing, YW
   Dondi, C
   Borgo, R
   Abdul-Rahman, A
AF Xing, Yiwen
   Dondi, Cristina
   Borgo, Rita
   Abdul-Rahman, Alfie
TI Visualizing Historical Book Trade Data: An Iterative Design Study with
   Close Collaboration with Domain Experts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Design study; application motivated visualization; geospatial data
ID REFLECTIONS; PATTERNS
AB The circulation of historical books has always been an area of interest for historians. However, the data used to represent the journey of a book across different places and times can be difficult for domain experts to digest due to buried geographical and chronological features within text-based presentations. This situation provides an opportunity for collaboration between visualization researchers and historians. This paper describes a design study where a variant of the Nine-Stage Framework [46] was employed to develop a Visual Analytics (VA) tool called DanteExploreVis. This tool was designed to aid domain experts in exploring, explaining, and presenting book trade data from multiple perspectives. We discuss the design choices made and how each panel in the interface meets the domain requirements. We also present the results of a qualitative evaluation conducted with domain experts. The main contributions of this paper include: 1) the development of a VA tool to support domain experts in exploring, explaining, and presenting book trade data; 2) a comprehensive documentation of the iterative design, development, and evaluation process following the variant Nine-Stage Framework; 3) a summary of the insights gained and lessons learned from this design study in the context of the humanities field; and 4) reflections on how our approach could be applied in a more generalizable way.
C1 [Xing, Yiwen; Borgo, Rita; Abdul-Rahman, Alfie] Kings Coll London, London, England.
   [Dondi, Cristina] Univ Oxford, Oxford, England.
C3 University of London; King's College London; University of Oxford
RP Xing, YW (corresponding author), Kings Coll London, London, England.
EM yiwen.xing@kcl.ac.uk; cristina.dondi@mod-langs.ox.ac.uk;
   rita.borgo@kcl.ac.uk; alfie.abdulrahman@kcl.ac.uk
OI Xing, Yiwen/0000-0003-1521-6616; Abdul-Rahman,
   Alfie/0000-0002-6257-876X; Dondi, Cristina/0000-0001-9478-216X
FU King's-China Scholarship Council PhD Scholarship programme (K-CSC)
FX No Statement Available
CR Abdul-Rahman A., 2014, EuroVis-Short Papers, DOI [10.2312/eurovisshort.20141165, DOI 10.2312/EUROVISSHORT.20141165]
   Abras C., 2004, Encyclopedia of Human-Computer Interaction, V37, P2
   Agafonkin V., 2021, Leaflet: A JavaScript library for interactive maps
   Arnold T, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P30, DOI 10.1109/VIS4DH51463.2020.00010
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M., 2016, Why Visualization? Task Abstraction for Analysis and Design
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brhel M, 2015, INFORM SOFTWARE TECH, V61, P163, DOI 10.1016/j.infsof.2015.01.004
   Brinck T., 2001, Usability for the web: Designing web sites that work, P3
   Buxton B., 2010, Sketching user experiences: getting the design right and the right design, P2
   C. CERL, 2021, MEI map
   C. CERL, Material Evidence in Incunabula
   Camburn B, 2017, DES SCI, V3, DOI 10.1017/dsj.2017.10
   Cavalcante R. P. G., 2021, React-leaflet-ant-path
   Chang D., Visualizing the republic of letters
   Chenjun Ling, 2016, Annals of GIS, V22, P173, DOI 10.1080/19475683.2016.1191545
   Ciula A., 2021, 2021 IEEE 6 WORKSHOP, P1, DOI [10.48550/arXiv.2110.093492, DOI 10.48550/ARXIV.2110.093492]
   Dingman B, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3476526
   Dondi C., From the 15cBOOKTRADE Project website
   Dondi C., 2013, Gazette du livre medieval, V60, P83, DOI [10.3406/galim.2013.20352, DOI 10.3406/GALIM.2013.20352]
   Dumas B, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P65, DOI 10.1145/2598153.2598159
   Edelstein D, 2017, AM HIST REV, V122, P400, DOI 10.1093/ahr/122.2.400
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   Etikan I., 2017, Biometrics Biostatistics International Journal, V5, DOI [DOI 10.15406/BBIJ.2017.05.00149, 10.15406/bbij.2017.05.00149]
   Etikan I., 2016, American Journal of Theoretical and Applied Statistics, V5, P1, DOI [DOI 10.11648/J.AJTAS.20160501.11, 10.11648/j.ajtas.20160501.11, https://doi.org/10.11648/j.ajtas.20160501.11]
   Fonteyn M.E., 1993, Qual Health Res, V3, P430, DOI [DOI 10.1177/104973239300300403, 10.1177/1049732393003004]
   Forsell C, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P608, DOI 10.1145/2254556.2254668
   Guo D, 2007, INT J GEOGR INF SCI, V21, P859, DOI 10.1080/13658810701349037
   He J, 2019, IEEE ACCESS, V7, P143646, DOI 10.1109/ACCESS.2019.2942844
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Huang W., 2014, Handbook of Human Centric Visualization, V1, DOI [10.1007/978-1-4614-7485-2, DOI 10.1007/978-1-4614-7485-2]
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   Mayhew D.J., 1999, CHI '99 Extended Abstracts on Human Factors in Computing Systems, P147, DOI [10.1145/632716.632805, DOI 10.1145/632716.632805]
   McKenna S, 2014, IEEE T VIS COMPUT GR, V20, P2191, DOI 10.1109/TVCG.2014.2346331
   Müller V, 2021, 2021 IEEE 6TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2021), P12, DOI 10.1109/VIS4DH53644.2021.00007
   Munzner T., 2014, AK Peters Visualization Series, V3, P5
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nielsen J., 1994, Usability Engineering, V3, P8
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P1543, DOI 10.1109/TVCG.2018.2811488
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Prickman G. J., ATLAS EARLY PRINTING
   Qualtrics, 2005, Qualtrics
   Redin D., 2017, 2017 SUSTAINABLE INT, P1, DOI [10.23919/SustainIT.2017.8379814, DOI 10.23919/SUSTAINIT.2017.8379814]
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Silva da Silva T., 2011, Proceedings of the 2011 Agile Conference, P77, DOI 10.1109/AGILE.2011.24
   Simon R., 2016, Code4Lib Journal, P3
   Skupin A, 2005, GEOINFORMATICA, V9, P159, DOI 10.1007/s10707-005-6670-2
   Sobral T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020332
   Syeda UH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376829
   Tory M, 2005, IEEE COMPUT GRAPH, V25, P8, DOI 10.1109/MCG.2005.102
   Vancisin T, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P36, DOI 10.1109/VIS4DH51463.2020.00011
   Winter M, 2021, IEEE ENG MED BIO, P2215, DOI 10.1109/EMBC46164.2021.9630949
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Xing Y., 2022, EuroVis 2022-Short Papers, DOI [10.2312/evs.202211001,2, DOI 10.2312/EVS.202211001,2]
   Ye Y, 2020, IEEE T VIS COMPUT GR, V26, P2192, DOI 10.1109/TVCG.2020.2970525
   Zhang P., 2005, Communications of the Association for Information Systems, V15, P29
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
NR 59
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 540
EP 550
DI 10.1109/TVCG.2023.3326923
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500110
PM 37871084
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Bearfield, CX
   Stokes, C
   Lovett, A
   Franconeri, S
AF Bearfield, Cindy Xiong
   Stokes, Chase
   Lovett, Andrew
   Franconeri, Steven
TI What Does the Chart Say? Grouping Cues Guide Viewer Comparisons and
   Conclusions in Bar Charts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bars; Visualization; Data visualization; Color; Task analysis; Taxonomy;
   Noise level; Comparison; perception; visual grouping; bar charts; verbal
   conclusions
ID GRAPH COMPREHENSION; TOP-DOWN; SEARCH; COLOR; COMMONALITIES; PERCEPTION
AB Reading a visualization is like reading a paragraph. Each sentence is a comparison: the mean of these is higher than those; this difference is smaller than that. What determines which comparisons are made first? The viewer's goals and expertise matter, but the way that values are visually grouped together within the chart also impacts those comparisons. Research from psychology suggests that comparisons involve multiple steps. First, the viewer divides the visualization into a set of units. This might include a single bar or a grouped set of bars. Then the viewer selects and compares two of these units, perhaps noting that one pair of bars is longer than another. Viewers might take an additional third step and perform a second-order comparison, perhaps determining that the difference between one pair of bars is greater than the difference between another pair. We create a visual comparison taxonomy that allows us to develop and test a sequence of hypotheses about which comparisons people are more likely to make when reading a visualization. We find that people tend to compare two groups before comparing two individual bars and that second-order comparisons are rare. Visual cues like spatial proximity and color can influence which elements are grouped together and selected for comparison, with spatial proximity being a stronger grouping cue. Interestingly, once the viewer grouped together and compared a set of bars, regardless of whether the group is formed by spatial proximity or color similarity, they no longer consider other possible groupings in their comparisons.
C1 [Bearfield, Cindy Xiong] Georgia Tech, Atlanta, GA 30332 USA.
   [Stokes, Chase] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Lovett, Andrew] US Naval Res Lab, Washington, DC 20375 USA.
   [Franconeri, Steven] Northwestern Univ, Evanston, IL USA.
C3 University System of Georgia; Georgia Institute of Technology;
   University of California System; University of California Berkeley;
   United States Department of Defense; United States Navy; Naval Research
   Laboratory; Northwestern University
RP Bearfield, CX (corresponding author), Georgia Tech, Atlanta, GA 30332 USA.
EM cxiong@gatech.edu; cstokes@ischool.berkeley.edu;
   andrew.lovett@nrl.navy.mil; franconeri@northwestern.edu
OI Lovett, Andrew/0009-0007-4463-1946; Xiong Bearfield,
   Cindy/0000-0002-1451-4083; Stokes, Chase/0000-0001-7644-9021
FU NSF [IIS-2237585, IIS-2311575]
FX This work was partly supported by NSF awards under Grants IIS-2237585
   and IIS-2311575. Recommended for acceptance by R. Metoyer.
CR Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011
   ALLIK J, 1991, PERCEPT PSYCHOPHYS, V49, P303, DOI 10.3758/BF03205986
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Baluchi F, 2011, TRENDS NEUROSCI, V34, P210, DOI 10.1016/j.tins.2011.02.003
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Brewer C.A., 2003, Cartography and Geographic Information Science, V30, P5
   Brooks J. L, 2015, Traditional and New Principles of Perceptual Grouping
   Burlinson D, 2018, IEEE T VIS COMPUT GR, V24, P574, DOI 10.1109/TVCG.2017.2745086
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Bylinskii Z, 2017, MATH VIS, P235, DOI 10.1007/978-3-319-47024-5_14
   Chalbi A, 2020, IEEE T VIS COMPUT GR, V26, P386, DOI 10.1109/TVCG.2019.2934288
   Ciccione Lorenzo, 2020, Open Mind (Camb), V4, P102, DOI 10.1162/opmi_a_00037
   CLARK HH, 1972, COGNITIVE PSYCHOL, V3, P472, DOI 10.1016/0010-0285(72)90019-9
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cozby P. C., 2007, Methods in Behavioral Research
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   Egeth HE, 2010, ACTA PSYCHOL, V135, P130, DOI 10.1016/j.actpsy.2010.05.012
   Folk CL, 2010, PSYCHON B REV, V17, P421, DOI 10.3758/PBR.17.3.421
   Franconeri SL, 2009, COGNITION, V113, P1, DOI 10.1016/j.cognition.2009.07.002
   Franconeri SL, 2007, J EXP PSYCHOL HUMAN, V33, P1003, DOI 10.1037/0096-1523.33.5.1003
   Friel SN, 2001, J RES MATH EDUC, V32, P124, DOI 10.2307/749671
   GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702_3
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Halberda J, 2006, PSYCHOL SCI, V17, P572, DOI 10.1111/j.1467-9280.2006.01746.x
   Halford GS, 2005, PSYCHOL SCI, V16, P70, DOI 10.1111/j.0956-7976.2005.00782.x
   Hegdé J, 1999, NEUROREPORT, V10, P143, DOI 10.1097/00001756-199901180-00027
   Hsieh FY, 1998, STAT MED, V17, P1623, DOI 10.1002/(SICI)1097-0258(19980730)17:14<1623::AID-SIM871>3.0.CO;2-S
   Huang LQ, 2007, PSYCHOL REV, V114, P599, DOI 10.1037/0033-295X.114.3.599
   Huang LQ, 2020, J VISION, V20, DOI 10.1167/jov.20.4.10
   Huang LQ, 2002, VISION RES, V42, P1421, DOI 10.1016/S0042-6989(02)00059-7
   Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037/0033-295X.104.3.427
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Jung C, 2022, IEEE T VIS COMPUT GR, V28, P1095, DOI 10.1109/TVCG.2021.3114846
   Kim L. A., 2019, P CHI C HUM FACT COM, P1
   Kim NW, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3131275
   Kim Z., 2015, P 33 ANN ACM C EXT A, P1349, DOI [10.1145/2702613.2732934, DOI 10.1145/2702613.2732934]
   Lamy D, 2004, J EXP PSYCHOL HUMAN, V30, P1019, DOI 10.1037/0096-1523.30.6.1019
   Levinthal BR, 2011, PSYCHOL SCI, V22, P1132, DOI 10.1177/0956797611418346
   Love BC, 1999, COGNITIVE PSYCHOL, V38, P291, DOI 10.1006/cogp.1998.0697
   Lovett A, 2017, PSYCHOL REV, V124, P60, DOI 10.1037/rev0000039
   Lovett A, 2011, COGNITION, V121, P281, DOI 10.1016/j.cognition.2011.06.012
   Lovett A, 2009, COGNITIVE SCI, V33, P1192, DOI 10.1111/j.1551-6709.2009.01052.x
   Lovett K., 2012, P ANN M COGN SCI SOC, P701
   Mantri Prateek, 2023, IEEE Trans Vis Comput Graph, V29, P1005, DOI 10.1109/TVCG.2022.3209467
   Markman AB, 1996, MEM COGNITION, V24, P235, DOI 10.3758/BF03200884
   Michal AL, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0059-2
   Michal AL, 2016, PSYCHON B REV, V23, P1802, DOI 10.3758/s13423-016-1047-0
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Picon E., 2017, J VISION, V17, P1284
   Pinker S., 1990, Artificial intelligence and the future of testing S
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Ripley B, 2016, R Package Version, V7, P700
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Shah P, 2002, EDUC PSYCHOL REV, V14, P47, DOI 10.1023/A:1013180410169
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Shin Sungbok, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209472
   Snow M., 2013, Qualtrics Survey Software: Handbook for ResearchProfessionals
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Srinivasan N., 2021, P CHI C HUM FACT COM, P1
   Stokes C, 2022, Arxiv, DOI arXiv:2209.10789
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Theeuwes J, 1996, ACTA PSYCHOL, V94, P291, DOI 10.1016/S0001-6918(96)00003-0
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Wolfe JM, 1998, PSYCHOL SCI, V9, P33, DOI 10.1111/1467-9280.00006
   Xiong A., 2022, P CHI C HUM FACT COM, P1
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yu D, 2019, PSYCHOL SCI, V30, P376, DOI 10.1177/0956797618822798
   Yu D, 2019, COGNITION, V182, P8, DOI 10.1016/j.cognition.2018.08.006
NR 74
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5097
EP 5110
DI 10.1109/TVCG.2023.3289292
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400042
PM 37792647
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Gao, QZ
   Wang, YM
   Liu, LB
   Liu, LJ
   Theobalt, C
   Chen, BQ
AF Gao, Qingzhe
   Wang, Yiming
   Liu, Libin
   Liu, Lingjie
   Theobalt, Christian
   Chen, Baoquan
TI Neural Novel Actor: Learning a Generalized Animatable Neural
   Representation for Human Actors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural rendering; neural radiance field; human synthesis
AB We propose a new method for learning a generalized animatable neural human representation from a sparse set of multi-view imagery of multiple persons. The learned representation can be used to synthesize novel view images of an arbitrary person and further animate them with the user's pose control. While most existing methods can either generalize to new persons or synthesize animations with user control, none of them can achieve both at the same time. We attribute this accomplishment to the employment of a 3D proxy for a shared multi-person human model, and further the warping of the spaces of different poses to a shared canonical pose space, in which we learn a neural field and predict the person- and pose-dependent deformations, as well as appearance with the features extracted from input images. To cope with the complexity of the large variations in body shapes, poses, and clothing deformations, we design our neural human model with disentangled geometry and appearance. Furthermore, we utilize the image features both at the spatial point and on the surface points of the 3D proxy for predicting person- and pose-dependent properties. Experiments show that our method significantly outperforms the state-of-the-arts on both tasks.
C1 [Gao, Qingzhe] Shandong Univ, Sch Comp Sci & technol, Jinan 250100, Peoples R China.
   [Wang, Yiming] Peking Univ, Beijing 100871, Peoples R China.
   [Liu, Libin; Chen, Baoquan] Peking Univ, Natl Key Lab Gen Artificial Intelligence, Beijing 100871, Peoples R China.
   [Liu, Lingjie; Theobalt, Christian] Max Planck Inst Informat, Graph Vis & Video Grp, D-66123 Saarbrucken, Germany.
C3 Shandong University; Peking University; Peking University; Max Planck
   Society
RP Chen, BQ (corresponding author), Peking Univ, Natl Key Lab Gen Artificial Intelligence, Beijing 100871, Peoples R China.
EM gaoqingzhe97@gmail.com; wym12416@pku.edu.cn; libin.liu@pku.edu.cn;
   lliu@mpi-inf.mpg.de; theobalt@mpi-inf.mpg.de; baoquan@pku.edu.cn
OI Liu, Libin/0000-0003-2280-6817; Wang, Yiming/0009-0002-7585-6201; Gao,
   Qingzhe/0000-0002-6239-571X
FU NSFC Projects of International Cooperation and Exchanges [62161146002];
   ERC Consolidator Grant 4DReply [770784]; Lise Meitner Postdoctoral
   Fellowship
FX This work was supported by the NSFC Projects of International
   Cooperation and Exchanges under Grant 62161146002. The work of Christian
   Theobalt was supported in part by ERC Consolidator Grant 4DReply under
   Grant 770784. The work of Lingjie Liu was supported in part by Lise
   Meitner Postdoctoral Fellowship.
CR Aliev Kara-Ali, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P696, DOI 10.1007/978-3-030-58542-6_42
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Chen A., 2021, P IEEE CVF INT C COM, P14124
   Chen JC, 2021, Arxiv, DOI arXiv:2106.13629
   Chen MF, 2022, LECT NOTES COMPUT SC, V13683, P222
   Chen X., 2021, arXiv
   Chibane J, 2021, PROC CVPR IEEE, P7907, DOI 10.1109/CVPR46437.2021.00782
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755
   Gao C, 2021, Arxiv, DOI arXiv:2012.05903
   Habermann L., 2023, ACM SIGGRAPH EUROGRA
   Yao G., 2021, arXiv
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhou TH, 2018, Arxiv, DOI arXiv:1805.09817
NR 17
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5719
EP 5732
DI 10.1109/TVCG.2023.3305433
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400040
PM 37585333
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Peck, TC
   Good, JJ
AF Peck, Tabitha C.
   Good, Jessica J.
TI Measuring Embodiment: Movement Complexity and the Impact of Personal
   Characteristics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Avatars; Particle measurements; Atmospheric
   measurements; Mathematical models; STEM; Virtual environments; Age;
   avatars; behavior; embodiment; gender; structural equation modeling
ID IMMERSIVE VIRTUAL-REALITY; OVERT HEAD MOVEMENTS; ILLUSORY OWNERSHIP;
   SELF-AVATAR; GENDER; BODY; REPRESENTATION; MASCULINITY; PERCEPTION;
   PERSUASION
AB A user's personal experiences and characteristics may impact the strength of an embodiment illusion and affect resulting behavioral changes in unknown ways. This paper presents a novel re-analysis of two fully-immersive embodiment user-studies (n = 189 and n = 99) using structural equation modeling, to test the effects of personal characteristics on subjective embodiment. Results demonstrate that individual characteristics (gender, participation in science, technology, engineering or math - Experiment 1, age, video gaming experience - Experiment 2) predicted differing self-reported experiences of embodiment Results also indicate that increased self-reported embodiment predicts environmental response, in this case faster and more accurate responses within the virtual environment. Importantly, head-tracking data is shown to be an effective objective measure for predicting embodiment, without requiring researchers to utilize additional equipment.
C1 [Peck, Tabitha C.] Davidson Coll, Davidson, NC 28035 USA.
C3 Davidson College
RP Peck, TC (corresponding author), Davidson Coll, Davidson, NC 28035 USA.
EM tapeck@davidson.edu; jegood@davidson.edu
OI Good, Jessica/0000-0003-3009-1903; Peck, Tabitha/0000-0002-3667-7713
FU National Science Foundation [1942146]
FX No Statement Available
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Banakou D, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201848
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bianchi-Berthouze N, 2007, LECT NOTES COMPUT SC, V4738, P102
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Briñol P, 2003, J PERS SOC PSYCHOL, V84, P1123, DOI 10.1037/0022-3514.84.6.1123
   Bugg JM, 2006, BRAIN COGNITION, V62, P9, DOI 10.1016/j.bandc.2006.02.006
   Carrasco S., 2017, P 29 AUSTR C COMP HU, P218
   Cheng LK, 2014, VIRTUAL REAL-LONDON, V18, P173, DOI 10.1007/s10055-014-0244-2
   Cheung GW, 2002, STRUCT EQU MODELING, V9, P233, DOI 10.1207/S15328007SEM0902_5
   COHEN H, 1986, PERCEPT MOTOR SKILL, V63, P83, DOI 10.2466/pms.1986.63.1.83
   Cohn A., 2006, PSYCHOL MEN MASCULIN, V7, P179, DOI [DOI 10.1037/1524-9220.7.4.179, 10.1037/15249220.7.4.179, DOI 10.1037/15249220.7.4.179]
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   EA MCMANUS., 2011, P ACM SIGGRAPH S APP, P37
   Fausto-Sterling Anne., 2000, Sexing the Body: Gender Politics and the Construction of Sexuality
   Fazio RH, 2003, ANNU REV PSYCHOL, V54, P297, DOI 10.1146/annurev.psych.54.101601.145225
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Garbarini F, 2014, CURR BIOL, V24, pR738, DOI 10.1016/j.cub.2014.07.023
   Gonzalez R, 2001, PSYCHOL METHODS, V6, P258, DOI 10.1037/1082-989X.6.3.258
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2014, EXP BRAIN RES, V232, P875, DOI 10.1007/s00221-013-3800-1
   Hamilton-Giachritsis C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21036-2
   Herrera F, 2021, NEW MEDIA SOC, V23, P2189, DOI 10.1177/1461444821993121
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kim SY, 2014, COMPUT HUM BEHAV, V36, P376, DOI 10.1016/j.chb.2014.03.067
   Kubota JT, 2017, SOC NEUROSCI-UK, V12, P468, DOI 10.1080/17470919.2016.1182585
   Lehdonvirta M, 2012, GAMES CULT, V7, P29, DOI 10.1177/1555412012440307
   Little T.D., 2013, LONGITUDINAL STRUCTU, DOI DOI 10.1007/978-94-007-0753-5_1701
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Moakler MW, 2014, CAREER DEV Q, V62, P128, DOI 10.1002/j.2161-0045.2014.00075.x
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Oransky M, 2009, J ADOLESCENT RES, V24, P218, DOI 10.1177/0743558408329951
   Pan Y, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364270
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Peck J. J., 2020, P CHI C HUM FACT COM, P1
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2021, IEEE T VIS COMPUT GR, V27, P2502, DOI 10.1109/TVCG.2021.3067767
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1964, DOI 10.1109/TVCG.2020.2973061
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Pollack W., 2000, Real Boys Voices: Boys Speak Out About Drugs, Sex, Violence, Bullying, Sports, School, Parents, and So Much More
   Puri S., 2017, P 29 AUSTR C COMP HU, P503
   Quinn PC, 2002, PERCEPTION, V31, P1109, DOI 10.1068/p3331
   Reimann M, 2012, J NEUROSCI PSYCHOL E, V5, P104, DOI 10.1037/a0026855
   Ries B., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, VRST '09, P59, DOI [10.1145/1643928.1643943, DOI 10.1145/1643928.16439433, DOI 10.1145/1643928.1643943]
   Schmader T, 2002, J EXP SOC PSYCHOL, V38, P194, DOI 10.1006/jesp.2001.1500
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Simon RM, 2017, J RES SCI TEACH, V54, P299, DOI 10.1002/tea.21345
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M., 1993, VR93 Virtual Reality International 93. Proceedings of the Third Annual Conference on Virtual Reality, P34
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   STETS JE, 1995, SOCIOL PERSPECT, V38, P129, DOI 10.2307/1389287
   Tieri G, 2015, SCI REP-UK, V5, DOI 10.1038/srep17139
   TOM G, 1991, BASIC APPL SOC PSYCH, V12, P281, DOI 10.1207/s15324834basp1203_3
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Wang X., 2019, Structural Equation Modeling: Applications UsingMplus
   WEISS R, 1995, IEEE MULTIMEDIA, V2, P12, DOI 10.1109/93.368596
   Wells GL, 1980, BASIC APPL SOC PSYCH, V1, P219, DOI 10.1207/s15324834basp0103_2
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P773
NR 73
TC 2
Z9 2
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4588
EP 4600
DI 10.1109/TVCG.2023.3270725
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400063
PM 37099457
OA Bronze
DA 2024-08-05
ER

PT J
AU Tehrani, MA
   Ibrahim, MT
   Majumder, A
   Gopi, M
AF Tehrani, Mahdi Abbaspour
   Ibrahim, Muhammad Twaha
   Majumder, Aditi
   Gopi, M.
TI 3D Gamut Morphing for Non-Rectangular Multi-Projector Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Three-dimensional displays; Real-time systems;
   Transfer functions; Geometry; Dynamic range; Brightness;
   Color-correction; gamut morphing; multi-projector displays; photometric
   correction
ID SEAMLESSNESS
AB In a spatially augmented reality system, multiple projectors are tiled on a complex shaped surface to create a seamless display on it. This has several applications in visualization, gaming, education and entertainment. The main challenges in creating seamless and undistorted imagery on such complex shaped surfaces are geometric registration and color correction. Prior methods that provide solutions for the spatial color variation in multi-projector displays assume rectangular overlap regions across the projectors that is possible only on flat surfaces with extremely constrained projector placement. In this article, we present a novel and fully automated method for removing color variations in a multi-projector display on arbitrary shaped smooth surfaces using a general color gamut morphing algorithm that can handle any arbitrarily shaped overlap between the projectors and assures imperceptible color variations across the display surface.
C1 [Tehrani, Mahdi Abbaspour] Genentech Inc, South San Francisco, CA 94080 USA.
   [Ibrahim, Muhammad Twaha; Majumder, Aditi; Gopi, M.] Univ Calif Irvine, Irvine, CA 92697 USA.
C3 Roche Holding; Genentech; University of California System; University of
   California Irvine
RP Ibrahim, MT (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.
EM ma.tehrani86@gmail.com; muhammti@uci.edu; majumder@ics.uci.edu;
   gopi@ics.uci.edu
RI Ibrahim, Muhammad Twaha/ADD-8310-2022
OI Ibrahim, Muhammad Twaha/0000-0001-9286-6124; Meenakshisundaram,
   Gopi/0000-0003-2326-8029
CR Aliaga DG, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P53
   Aliaga DanielG., 2008, COMPUTER VISION PATT, P1
   Aliaga Y. H., 2012, inACM Trans. Graph., V31, P1
   Bern D., 2003, P 19 ANN S COMP GEOM, P274
   Giorgianni T. E. M., 2009, Digital Color Management:Encoding Solutions, V2nd
   Goldstein J., 2016, inCengageLearning
   Hasker ES, 2006, IEEE T VIS COMPUT GR, V12, P1101, DOI 10.1109/TVCG.2006.121
   Hereld M, 2000, IEEE COMPUT GRAPH, V20, P22, DOI 10.1109/38.851746
   Ibrahim M., 2020, P 26 ACM S VIRT REAL, P1, DOI [10.1145/33859563418970.10M.T., DOI 10.1145/33859563418970.10M.T]
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Kurth Philipp, 2020, 2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), P174, DOI 10.1109/ISMAR50242.2020.00039
   Law AJ, 2011, COMPUT GRAPH FORUM, V30, P2288, DOI 10.1111/j.1467-8659.2011.02035.x
   Majumder A, 2005, ACM T GRAPHIC, V24, P118, DOI 10.1145/1037957.1037964
   Majumder A, 2000, IEEE VISUAL, P117, DOI 10.1109/VISUAL.2000.885684
   Majumder A., 2002, Proc. SID Eurodisplay, P1
   Majumder M., 2018, Introduction to Visual Computing: CoreConcepts in Computer Vision, Graphics, and Image Processing
   Majumder R., 2004, Trans. Vis Comput. Graph., V10
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Pailthorpe B., 2001, Proceedings Asia Display IDW, P1295
   Pjanic P, 2018, IEEE T VIS COMPUT GR, V24, P2963, DOI 10.1109/TVCG.2018.2868597
   Raij A, 2004, INT C PATT RECOG, P14, DOI 10.1109/ICPR.2004.1333994
   Raij G., 2003, IEEE INT WORKSH PROJ, P203
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Raskar Ramesh., 1998, Proceedings of the 25th annual conference on Computer graphics and interactive techniques, P179, DOI DOI 10.1145/280814.280861
   Sajadi B., 2015, P 3D TV C IMM INT 3D, P1
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1317, DOI 10.1109/TVCG.2009.124
   Tehrani MA, 2021, IEEE T VIS COMPUT GR, V27, P2265, DOI 10.1109/TVCG.2019.2950942
   Wallace H. Chen, 2003, P IMM PROJ TECHN WOR
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
NR 29
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4724
EP 4738
DI 10.1109/TVCG.2023.3277436
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400086
PM 37200131
DA 2024-08-05
ER

PT J
AU Xie, LX
   Ouyang, Y
   Chen, LF
   Wu, ZM
   Li, Q
AF Xie, Laixin
   Ouyang, Yang
   Chen, Longfei
   Wu, Ziming
   Li, Quan
TI Towards Better Modeling With Missing Data: A Contrastive Learning-Based
   Visual Analytics Perspective
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data models; Predictive models; Training; Task analysis; Analytical
   models; Data visualization; Numerical models; Explainable AI; missing
   data; data imputation; contrastive learning
ID DIAGNOSIS
AB Missing data can pose a challenge for machine learning (ML) modeling. To address this, current approaches are categorized into feature imputation and label prediction and are primarily focused on handling missing data to enhance ML performance. These approaches rely on the observed data to estimate the missing values and therefore encounter three main shortcomings in imputation, including the need for different imputation methods for various missing data mechanisms, heavy dependence on the assumption of data distribution, and potential introduction of bias. This study proposes a Contrastive Learning (CL) framework to model observed data with missing values, where the ML model learns the similarity between an incomplete sample and its complete counterpart and the dissimilarity between other samples. Our proposed approach demonstrates the advantages of CL without requiring any imputation. To enhance interpretability, we introduce CIVis, a visual analytics system that incorporates interpretable techniques to visualize the learning process and diagnose the model status. Users can leverage their domain knowledge through interactive sampling to identify negative and positive pairs in CL. The output of CIVis is an optimized model that takes specified features and predicts downstream tasks. We provide two usage scenarios in regression and classification tasks and conduct quantitative experiments, expert interviews, and a qualitative user study to demonstrate the effectiveness of our approach. In short, this study offers a valuable contribution to addressing the challenges associated with ML modeling in the presence of missing data by providing a practical solution that achieves high predictive accuracy and model interpretability.
C1 [Xie, Laixin; Ouyang, Yang; Chen, Longfei; Li, Quan] ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Wu, Ziming] Tencent Inc, Shenzhen 518054, Guangdong, Peoples R China.
   ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Sch Informat Sci & Technol, Shanghai, Peoples R China.
C3 ShanghaiTech University; Tencent; ShanghaiTech University
RP Li, Q (corresponding author), ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
EM xielx@shanghaitech.edu.cn; ouyy@shanghaitech.edu.cn;
   chenlf@shanghaitech.edu.cn; jimmyzmwu@tencent.com;
   liquan@shanghaitech.edu.cn
OI , Yang/0009-0000-5841-7659; Chen, Longfei/0009-0002-4596-8093; Xie,
   Laixin/0000-0002-7748-2971
CR Angelini M, 2022, SCIENTOMETRICS, V127, P6827, DOI 10.1007/s11192-022-04399-2
   Bors C, 2018, ACM J DATA INF QUAL, V10, DOI 10.1145/3190578
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Chen S., 2020, PMLR, P1597, DOI DOI 10.48550/ARXIV.2002.05709
   Credit card, 2016, About us
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Echihabi K, 2023, VLDB J, V32, P763, DOI 10.1007/s00778-022-00771-z
   Feng SY, 2021, Arxiv, DOI arXiv:2105.03075
   Gillies M., 2016, P C HUM FACT COMP, P3558, DOI DOI 10.1145/2851581.2856492
   Gondara L, 2018, Arxiv, DOI arXiv:1705.02737
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Grill J.B., 2020, P 34 INT C NEUR INF, V33, P21271, DOI [10.48550/arXiv.2006.07733, DOI 10.48550/ARXIV.2006.07733]
   Hastie T, 2015, J MACH LEARN RES, V16, P3367
   Honaker J, 2011, J STAT SOFTW, V45, P1
   Imputation, 2007, About us
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   kaggle, 2016, House price
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kim KY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-160
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Li QB, 2021, PROC CVPR IEEE, P10708, DOI 10.1109/CVPR46437.2021.01057
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI 10.1109/TKDE.2021.3090866
   McKinney W., 2011, Python for high performance and scientific computing, V14, P1
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Robinson Joshua, 2020, arXiv
   Rubin DB., 2004, Multiple imputation for nonresponse in surveys, DOI 10.1002/9780470316696
   Sarma Abhraneel, 2023, IEEE Trans Vis Comput Graph, V29, P602, DOI 10.1109/TVCG.2022.3209348
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Smieja M, 2019, Arxiv, DOI arXiv:1805.07405
   Song WP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1161, DOI 10.1145/3357384.3357925
   Suh Y, 2019, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2019.00742
   Tian Y., 2020, Advances in neural information processing systems, V33, P6827, DOI DOI 10.5555/3495724.3496297
   Turkay C, 2019, Arxiv, DOI arXiv:1812.08032
   van Buuren S, 2011, J STAT SOFTW, V45, P1
   van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang T., 2020, International Conference on Machine Learning, P9929
   Weibelzahl S, 2020, UMAP'20: PROCEEDINGS OF THE 28TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P394, DOI 10.1145/3340631.3398668
   Wells T. T., 1990, RELCJ, V21, P95
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xia J, 2017, PATTERN RECOGN, V69, P52, DOI 10.1016/j.patcog.2017.04.005
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xuan H, 2020, IEEE WINT CONF APPL, P2463, DOI 10.1109/WACV45572.2020.9093432
   Yao Lewei, 2021, P IEEECVF INT C COMP, P3591
   Yoon J, 2018, PR MACH LEARN RES, V80
   You JX, 2020, Arxiv, DOI arXiv:2010.16418
   You Yuning, 2020, Adv Neural Inf Process Syst
   Zhang K., 2022, arXiv
   Zhou C, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3985, DOI 10.1145/3447548.3467102
   Zhu R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10286, DOI 10.1109/ICCV48922.2021.01014
NR 60
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5129
EP 5146
DI 10.1109/TVCG.2023.3285210
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400052
PM 37310838
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhang, YS
   Zhu, JH
   Xue, MF
   Zhang, XP
   Cao, XC
AF Zhang, Yushu
   Zhu, Jiahao
   Xue, Mingfu
   Zhang, Xinpeng
   Cao, Xiaochun
TI Adaptive 3D Mesh Steganography Based on Feature-Preserving Distortion
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Steganography; Distortion; Feature
   extraction; Solid modeling; Smoothing methods; Electronic mail; 3D mesh;
   3D mesh steganography; syndrome trellis code; 3D steganalysis
ID CAPACITY; STEGANALYSIS; ALGORITHM
AB Current 3D mesh steganography algorithms relying on geometric modification are prone to detection by steganalyzers. In traditional steganography, adaptive steganography has proven to be an efficient means of enhancing steganography security. Taking inspiration from this, we propose a highly adaptive embedding algorithm, guided by the principle of minimizing a carefully crafted distortion through efficient steganography codes. Specifically, we tailor a payload-limited embedding optimization problem for 3D settings and devise a feature-preserving distortion (FPD) to measure the impact of message embedding. The distortion takes on an additive form and is defined as a weighted difference of the effective steganalytic subfeatures utilized by the current 3D steganalyzers. With practicality in mind, we refine the distortion to enhance robustness and computational efficiency. By minimizing the FPD, our algorithm can preserve mesh features to a considerable extent, including steganalytic and geometric features, while achieving a high embedding capacity. During the practical embedding phase, we employ the Q-layered syndrome trellis code (STC). However, calculating the bit modification probability (BMP) for each layer of the Q-layered STC, given the variation of Q, can be cumbersome. To address this issue, we design a universal and automatic approach for the BMP calculation. The experimental results demonstrate that our algorithm achieves state-of-the-art performance in countering 3D steganalysis.
C1 [Zhang, Yushu; Xue, Mingfu] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Zhang, Yushu; Xue, Mingfu] Zhengzhou Xinda Inst Adv Technol, Zhengzhou 450001, Peoples R China.
   [Zhu, Jiahao] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Zhang, Xinpeng] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
   [Cao, Xiaochun] Sun Yat Sen Univ, Sch Cyber Sci & Technol, Shenzhen 518107, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Sun Yat Sen
   University; Fudan University; Sun Yat Sen University
RP Zhu, JH (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM yushu@nuaa.edu.cn; zhujh59@mail2.sysu.edu.cn; mingfu.xue@nuaa.edu.cn;
   zhangxinpeng@fudan.edu.cn; caoxiaochun@mail.sysu.edu.cn
OI Xue, Mingfu/0000-0003-2408-503X; zhang, yushu/0000-0001-8183-8435
FU National Key R&D Program of China [2021YFB3100400]; Open Foundation of
   Henan Key Laboratory of Cyber space Situation Awareness [HNTS2022013]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2021YFB3100400, and in part by the Open Foundation of Henan
   Key Laboratory of Cyber space Situation Awareness under Grant
   HNTS2022013.
CR Aspert N, 2002, PROC SPIE, V4790, P211, DOI 10.1117/12.455358
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J., STEGANOGRAPHY DIGITA
   Fridrich T., 2007, Int. Soc. Opt.Photon., P650
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang NC, 2009, IEEE SIGNAL PROC LET, V16, P802, DOI 10.1109/LSP.2009.2024794
   Itier V, 2017, MULTIMED TOOLS APPL, V76, P26421, DOI 10.1007/s11042-016-4163-y
   Kaveh H, 2015, SECUR COMMUN NETW, V8, P159, DOI 10.1002/sec.968
   Kim D, 2017, LECT NOTES ELECTR EN, V424, P358, DOI 10.1007/978-981-10-4154-9_42
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li NN, 2017, IEEE ACCESS, V5, P24457, DOI 10.1109/ACCESS.2017.2767072
   Li ZY, 2020, INFORM SCIENCES, V522, P164, DOI 10.1016/j.ins.2020.02.061
   Li ZY, 2020, IEEE T CYBERNETICS, V50, P1989, DOI 10.1109/TCYB.2018.2883082
   Li ZY, 2018, IEEE IMAGE PROC, P1683, DOI 10.1109/ICIP.2018.8451643
   Li ZY, 2017, IEEE IMAGE PROC, P510, DOI 10.1109/ICIP.2017.8296333
   Li ZY, 2017, INFORM SCIENCES, V415, P85, DOI 10.1016/j.ins.2017.06.011
   Li ZY, 2016, INT CONF ACOUST SPEE, P2144, DOI 10.1109/ICASSP.2016.7472056
   Maret T., 2004, P MULT SEC WORKSH MA, P68
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Tu H., 2010, Int.J.VirtualReality, V9, P55
   Tu SC, 2012, COMPUT GRAPH-UK, V36, P767, DOI 10.1016/j.cag.2012.06.002
   Tu SC, 2010, VISUAL COMPUT, V26, P1177, DOI 10.1007/s00371-009-0398-1
   Wagner M. G., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P201, DOI 10.1109/GMAP.2000.838252
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang L., 2019, IEEEAccess, V7
   Yang I., 2014, ACM Trans. Multimedia Comput. Commun. Appl., V10
   Yang Y, 2013, IEEE T VIS COMPUT GR, V19, P45, DOI 10.1109/TVCG.2012.106
   Zhou H, 2022, IEEE T VIS COMPUT GR, V28, P5006, DOI 10.1109/TVCG.2021.3075136
   Zhou H, 2021, IEEE T VIS COMPUT GR, V27, P57, DOI 10.1109/TVCG.2019.2929041
   Zhou H, 2019, IEEE T MULTIMEDIA, V21, P1384, DOI 10.1109/TMM.2018.2882088
NR 39
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5299
EP 5312
DI 10.1109/TVCG.2023.3289234
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400046
PM 37363849
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wu, HY
   Sun, XX
   Tu, HW
   Zhang, XL
AF Wu, Huiyue
   Sun, Xiaoxuan
   Tu, Huawei
   Zhang, Xiaolong
TI ClockRay: A Wrist-Rotation Based Technique for Occluded-Target Selection
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Three-dimensional displays; Wrist; Visualization;
   Input devices; Virtual reality; Usability; object selection; RayCasting;
   disambiguation; wrist rotation; 3D data visualization
ID 3D SELECTION; DESIGN
AB Target selection is one of essential operation made available by interaction techniques in virtual reality (VR) environments. However, effectively positioning or selecting occluded objects is under-investigated in VR, especially in the context of high-density or a high-dimensional data visualization with VR. In this paper, we propose ClockRay, an occluded-object selection technique that can maximize the intrinsic human wrist rotation skills through the integration of emerging ray selection techniques in VR environments. We describe the design space of the ClockRay technique and then evaluate its performance in a series of user studies. Drawing on the experimental results, we discuss the benefits of ClockRay compared to two popular ray selection techniques - RayCursor and RayCasting. Our findings can inform the design of VR-based interactive visualization systems for high-density data.
C1 [Wu, Huiyue] Sun Yat Sen Univ, Sch Journalism & Commun, Guangzhou 510275, Guangdong, Peoples R China.
   [Wu, Huiyue] Guangdong Key Lab Big Data Anal & Simulat Publ Opi, Guangzhou 510275, Guangdong, Peoples R China.
   [Sun, Xiaoxuan] Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China.
   [Tu, Huawei] La Trobe Univ, Melbourne, Vic 3086, Australia.
   [Zhang, Xiaolong] Penn State Univ, University Pk, PA 16802 USA.
C3 Sun Yat Sen University; Sun Yat Sen University; La Trobe University;
   Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park
RP Wu, HY (corresponding author), Sun Yat Sen Univ, Sch Journalism & Commun, Guangzhou 510275, Guangdong, Peoples R China.; Wu, HY (corresponding author), Guangdong Key Lab Big Data Anal & Simulat Publ Opi, Guangzhou 510275, Guangdong, Peoples R China.
EM wuhuiyue@mail.sysu.edu.cn; quantalion@163.com; h.tu@latrobe.edu.au;
   lzhang@ist.psu.edu
OI Wu, Huiyue/0000-0001-7027-518X
FU National Natural Science Foundation of China [62272500, 61772564];
   Guangdong Basic and Applied Basic Research Foundation [2021A1515011990];
   Guangdong Key Laboratory for Big Data Analysis and Simulation of Public
   Opinion [2017B030301003]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 62272500 and 61772564, in part by the Guangdong Basic
   and Applied Basic Research Foundation under Grant 2021A1515011990, and
   in part by the Guangdong Key Laboratory for Big Data Analysis and
   Simulation of Public Opinion under Grant 2017B030301003.
CR Bacim F, 2013, INT J HUM-COMPUT ST, V71, P785, DOI 10.1016/j.ijhcs.2013.03.003
   Baloup M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300331, 10.1109/africon46755.2019.9133906]
   Bowman D. A., 2002, Virtual Reality, V6, P122, DOI 10.1007/s100550200013
   Bowman DA, 2001, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2001.913781
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Cashion J, 2012, IEEE T VIS COMPUT GR, V18, P634, DOI 10.1109/TVCG.2012.40
   Casiez G., 2012, P SIGCHI C HUM FACT, P2527
   Crossan A., 2008, P 10 INT C HUM COMP, P435
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI DOI 10.2312/EGVE/IPT_EGVE2005/201-209
   Debarba HG, 2013, LECT NOTES COMPUT SC, V8119, P388
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Feiner A. O. S., 2003, P 16 ANN ACM S US IN, V3, P81
   Grandjean E., 1969, Fitting the Task to the Man: An Ergonomic Approach
   Grossman T., 2006, P 19 ACM S US INT SO, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Guo AH, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P17, DOI 10.1145/2935334.2935345
   Haque F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3653, DOI 10.1145/2702123.2702133
   LaViola J.J., 2017, 3D user interfaces: theory and practice
   Lilija K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300676
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.00-83, 10.1109/VR46266.2020.1581165829725]
   Lyu F, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-2999-y
   Man-Systems Integration Standards, 2015, NASA-STD-3000
   Mendes D, 2017, COMPUT GRAPH-UK, V67, P95, DOI 10.1016/j.cag.2017.06.003
   Mendes D, 2017, IEEE SYMP 3D USER, P237, DOI 10.1109/3DUI.2017.7893359
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Ni T, 2011, INT J HUM-COMPUT ST, V69, P551, DOI 10.1016/j.ijhcs.2011.05.001
   Oakley I, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P40
   Poupyrev I., 1996, Proceedings of the 9th Annual A CM Symposium on User Interface Software and Technology, P79, DOI DOI 10.1145/237091.237102
   Rahman M, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1943
   Ramos G., 2004, Proceedings of the CHI '04 Conference on Human Factors in Computing Systems, P487, DOI DOI 10.1145/985692.985754
   Rekimoto J., 1996, Proc. UIST, P167
   Ro H, 2017, IEEE SYS MAN CYBERN, P2873, DOI 10.1109/SMC.2017.8123063
   Shi K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1295
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yeo HS, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340130
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Yu LY, 2012, IEEE T VIS COMPUT GR, V18, P2245, DOI 10.1109/TVCG.2012.217
NR 38
TC 0
Z9 0
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3767
EP 3778
DI 10.1109/TVCG.2023.3239951
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700024
PM 37022075
DA 2024-08-05
ER

PT J
AU Zhao, JQ
   Wang, YX
   Mancenido, MV
   Chiou, EK
   Maciejewski, R
AF Zhao, Jieqiong
   Wang, Yixuan
   Mancenido, Michelle V.
   Chiou, Erin K.
   Maciejewski, Ross
TI Evaluating the Impact of Uncertainty Visualization on Model Reliance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Predictive models; Task analysis; Data visualization; Data
   models; Computational modeling; Prediction algorithms; Human-machine
   collaborations; model reliance; trust; uncertainty
ID DECISION-MAKING; AUTOMATION; TRUST; ERROR; COMPLACENCY; ALGORITHMS;
   ENCODINGS; HUMANS; DESIGN; BIAS
AB Machine learning models have gained traction as decision support tools for tasks that require processing copious amounts of data. However, to achieve the primary benefits of automating this part of decision-making, people must be able to trust the machine learning model's outputs. In order to enhance people's trust and promote appropriate reliance on the model, visualization techniques such as interactive model steering, performance analysis, model comparison, and uncertainty visualization have been proposed. In this study, we tested the effects of two uncertainty visualization techniques in a college admissions forecasting task, under two task difficulty levels, using Amazon's Mechanical Turk platform. Results show that (1) people's reliance on the model depends on the task difficulty and level of machine uncertainty and (2) ordinal forms of expressing model uncertainty are more likely to calibrate model usage behavior. These outcomes emphasize that reliance on decision support tools can depend on the cognitive accessibility of the visualization technique and perceptions of model performance and task difficulty.
C1 [Zhao, Jieqiong; Wang, Yixuan; Maciejewski, Ross] Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85281 USA.
   [Mancenido, Michelle V.] Arizona State Univ, Sch Math & Nat Sci, Tempe, AZ 85281 USA.
   [Chiou, Erin K.] Arizona State Univ, Human Syst Engn Polytech Sch, Tempe, AZ 85281 USA.
C3 Arizona State University; Arizona State University-Tempe; Arizona State
   University; Arizona State University-Tempe; Arizona State University;
   Arizona State University-Tempe
RP Maciejewski, R (corresponding author), Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85281 USA.
EM Jieqiong.Zhao@asu.edu; ywan1290@asu.edu; mickey.mancenido@asu.edu;
   Erin.Chiou@asu.edu; rmacieje@asu.edu
OI Wang, Yixuan/0000-0003-0195-1193; Zhao, Jieqiong/0000-0002-4303-7722;
   Chiou, Erin/0000-0002-7201-8483
FU U.S. Department of Homeland Security [2017-ST-061-QA0001,
   17STQAC00001-03-03]; National Science Foundation Program on Fairness;
   Amazon [1939725]
FX This work was supported in part by the U.S. Department of Homeland
   Security under Grants 2017-ST-061-QA0001 and 17STQAC00001-03-03, and in
   part by the National Science Foundation Program on Fairness in AI in
   collaboration with Amazon under Grant 1939725.
CR Alberdi E, 2004, ACAD RADIOL, V11, P909, DOI 10.1016/j.acra.2004.05.012
   Alberdi E, 2008, INT J COMPUT ASS RAD, V3, P115, DOI 10.1007/s11548-008-0213-x
   Bahner J. Elin, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P1330
   Belia S, 2005, PSYCHOL METHODS, V10, P389, DOI 10.1037/1082-989X.10.4.389
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3
   Brodlie K, 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [DOI 10.1007/978-1-4471-2804-56, 10.1007/978-1-4471-2804-5_6, DOI 10.1007/978-1-4471-2804-5_6]
   Bussone A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2015), P160, DOI 10.1109/ICHI.2015.26
   Cai H., 2010, P HUMAN FACTORS ERGO, V54, P2437
   Conway D., 2016, P ACM C HUM FACT COM, P3035
   Correa Carlos D., 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P51, DOI 10.1109/VAST.2009.5332611
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Dietvorst BJ, 2018, MANAGE SCI, V64, P1155, DOI 10.1287/mnsc.2016.2643
   Dietvorst BJ, 2015, J EXP PSYCHOL GEN, V144, P114, DOI 10.1037/xge0000033
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Dzindolet MT, 2003, INT J HUM-COMPUT ST, V58, P697, DOI 10.1016/S1071-5819(03)00038-7
   Eroglu C, 2010, INT J FORECASTING, V26, P116, DOI 10.1016/j.ijforecast.2009.02.005
   Eyal P, 2022, BEHAV RES METHODS, V54, P1643, DOI 10.3758/s13428-021-01694-3
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fildes R, 2007, INTERFACES, V37, P570, DOI 10.1287/inte.1070.0309
   Fox G. R., 2011, Perspectives on Thinking, Judging, and Decision Making, P21
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Guo SN, 2019, INT C POWER ELECT DR, DOI [10.1109/peds44367.2019.8998889, 10.1145/3290605.3300803]
   Gutzwiller Robert S., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P217, DOI 10.1177/1071181319631201
   Highhouse S, 2008, IND ORGAN PSYCHOL-US, V1, P333, DOI 10.1111/j.1754-9434.2008.00058.x
   Hoekstra R, 2014, PSYCHON B REV, V21, P1157, DOI 10.3758/s13423-013-0572-3
   Hüllermeier E, 2021, MACH LEARN, V110, P457, DOI 10.1007/s10994-021-05946-3
   Hullman J., 2016, PLoS One, V10, P1
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Jacobs M, 2021, TRANSL PSYCHIAT, V11, DOI 10.1038/s41398-021-01224-x
   Jian Jiun-Yin, 2000, INT J COGNITIVE ERGO, V4, P53, DOI DOI 10.1207/S15327566IJCE0401_04
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kohn SC, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.604977
   Lai V, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P29, DOI 10.1145/3287560.3287590
   Lawrence M, 2006, INT J FORECASTING, V22, P493, DOI 10.1016/j.ijforecast.2006.03.007
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Logg JM, 2019, ORGAN BEHAV HUM DEC, V151, P90, DOI 10.1016/j.obhdp.2018.12.005
   Mancenido M., 2021, P IISE ANN C, P175
   Manzey D, 2012, J COGN ENG DECIS MAK, V6, P57, DOI 10.1177/1555343411433844
   Merritt SM, 2013, HUM FACTORS, V55, P520, DOI 10.1177/0018720812465081
   Mohseni Sina., 2021, Proceedings of the International AAAI Conference on Web and Social Media, V15, P421, DOI DOI 10.1609/ICWSM.V15I1.18072
   Montgomery D. C., 2021, INTRO LINEAR REGRESS
   Mosier K.L., 2018, Automation and Human Performance: Theory and Applications, P201
   MOSIER KL, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P7, DOI 10.1177/154193129203600104
   Mosier KL, 1998, INT J AVIAT PSYCHOL, V8, P47, DOI 10.1207/s15327108ijap0801_3
   MUIR BM, 1987, INT J MAN MACH STUD, V27, P527, DOI 10.1016/S0020-7373(87)80013-5
   Myers R.H., 2016, Response surface methodology, process and product optimization using designed experiments
   Neuburger J, 2017, BMJ QUAL SAF, V26, P919, DOI 10.1136/bmjqs-2016-005526
   Newman GE, 2012, PSYCHON B REV, V19, P601, DOI 10.3758/s13423-012-0247-5
   Padilla LMK, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.579267
   Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886
   Parasuraman R, 2010, HUM FACTORS, V52, P381, DOI 10.1177/0018720810376055
   Potter K, 2010, COMPUT GRAPH FORUM, V29, P823, DOI 10.1111/j.1467-8659.2009.01677.x
   Procopio M, 2022, IEEE T VIS COMPUT GR, V28, P3093, DOI 10.1109/TVCG.2021.3051013
   Reynolds MR, 1999, J QUAL TECHNOL, V31, P87
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Stahler GJ, 2013, CRIM JUSTICE BEHAV, V40, P690, DOI 10.1177/0093854812469609
   Stevens NT, 2019, J QUAL TECHNOL, V51, P109, DOI 10.1080/00224065.2019.1571344
   Stroup W.W., 2012, Generalized Linear Mixed Models
   Tomsett R, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100049
   Tsai TL, 2003, J AM MED INFORM ASSN, V10, P478, DOI 10.1197/jamia.M1279
   Visser Ewart J., 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P251, DOI 10.1007/978-3-319-07458-0_24
   Vrieze SI, 2009, PROF PSYCHOL-RES PR, V40, P525, DOI 10.1037/a0014693
   Wickens CD, 2015, HUM FACTORS, V57, P728, DOI 10.1177/0018720815581940
   Yang FM, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P189, DOI 10.1145/3377325.3377480
   Zhang DC, 2019, J BEHAV DECIS MAKING, V32, P152, DOI 10.1002/bdm.2102
NR 68
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 4093
EP 4107
DI 10.1109/TVCG.2023.3251950
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700055
PM 37028077
DA 2024-08-05
ER

PT J
AU Friedl-Knirsch, J
   Stach, C
   Pointecker, F
   Anthes, C
   Roth, D
AF Friedl-Knirsch, Judith
   Stach, Christian
   Pointecker, Fabian
   Anthes, Christoph
   Roth, Daniel
TI A Study on Collaborative Visual Data Analysis in Augmented Reality with
   Asymmetric Display Types
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Collaboration; Data analysis; Three-dimensional displays; Augmented
   reality; Stereo image processing; Visualization; Resists; Augmented
   Reality; Empirical Studies
ID VISUALIZATION
AB Collaboration is a key aspect of immersive visual data analysis. Due to its inherent benefit of seeing co-located collaborators, augmented reality is often useful in such collaborative scenarios. However, to enable the augmentation of the real environment, there are different types of technology available. While there are constant developments in specific devices, each of these device types provide different premises for collaborative visual data analysis. In our work we combine handheld, optical see-through and video see-through displays to explore and understand the impact of these different device types in collaborative immersive analytics. We conducted a mixed-methods collaborative user study where groups of three performed a shared data analysis task in augmented reality with each user working on a different device, to explore differences in collaborative behaviour, user experience and usage patterns. Both quantitative and qualitative data revealed differences in user experience and usage patterns. For collaboration, the different display types influenced how well participants could participate in the collaborative data analysis, nevertheless, there was no measurable effect in verbal communication.
C1 [Friedl-Knirsch, Judith] Tech Univ Munich, Human Ctr Comp & Extended Real Lab, Munich, Germany.
   [Friedl-Knirsch, Judith; Stach, Christian; Pointecker, Fabian; Anthes, Christoph] Univ Appl Sci Upper Austria, Wels, Austria.
   [Roth, Daniel] Tech Univ Munich, Sch Med, Munich, Germany.
   [Roth, Daniel] Tech Univ Munich, Dept Clin Med Orthoped & Sports Orthoped, Hlth Human Ctr Comp & Extended Real Lab, Machine Intelligence Orthoped,Klinikum Rechts Isar, Munich, Germany.
C3 Technical University of Munich; Technical University of Munich;
   Technical University of Munich
RP Friedl-Knirsch, J (corresponding author), Tech Univ Munich, Human Ctr Comp & Extended Real Lab, Munich, Germany.; Friedl-Knirsch, J (corresponding author), Univ Appl Sci Upper Austria, Wels, Austria.
EM judith.friedl-knirsch@fh-ooe.at; christian.stach@fh-ooe.at;
   fabian.pointecker@fh-ooe.at; christoph.anthes@fh-ooe.at;
   daniel.roth@tum.de
OI Friedl-Knirsch, Judith/0000-0002-8350-0996
FU Government of Upper Austria
FX No Statement Available
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Benko A. D., 2014, P 27 ANN ACM S USER, P645, DOI DOI 10.1145/2642918.2647402
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Billinghurst M, 1999, MIXED REALITY, P261
   Billinghurst M., 1998, Virtual Reality, V3, P25, DOI 10.1007/BF01409795
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Butz A., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P35, DOI 10.1109/IWAR.1999.803804
   do Carmo RMC, 2007, IEEE INT CONF INF VI, P156
   Cavallo M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364242
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Das H., 1995, Telemanipulatorand Telepresence Technologies, P293, DOI [10.1117/12.1973221,2,3[40]D, DOI 10.1117/12.1973221,2,3[40]D]
   Friedl-Knirsch C., IN2023 IEEE IN TERNA, P65, DOI [10.1109/ISMAR-Adjunct60411.2023.000215[15]B, DOI 10.1109/ISMAR-ADJUNCT60411.2023.000215[15]B]
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Haller M., 2005, INPROCEEDINGS 2005IN, P40, DOI [DOI 10.1145/1152399.11524082, DOI 10.1145/1152399.1152408]
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Henrysson A, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P80
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Johansen R., 1988, Groupware: Computer support for business teams
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kiyokawa K, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P139, DOI 10.1109/ISMAR.2002.1115083
   Langner M., 2021, INPROCEEDINGS 2021 C, P1, DOI [10.1145/3411764.34455931,2[24]B, DOI 10.1145/3411764.34455931,2[24]B]
   Laugwitz T., Construction and Evaluation of aUser Experience Questionnaire
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   MacWilliams A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P123, DOI 10.1109/ISMAR.2003.1240695
   Mahmood E., 2018, IN2018 INT S BIG DAT, P1, DOI [10.1109/BDVA.2018.85338932[28]P, DOI 10.1109/BDVA.2018.85338932[28]P]
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Möhring M, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P252, DOI 10.1109/ISMAR.2004.63
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   Ohshima T, 1998, P IEEE VIRT REAL ANN, P268, DOI 10.1109/VRAIS.1998.658505
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Pidel C, 2020, LECT NOTES COMPUT SC, V12242, P141, DOI 10.1007/978-3-030-58465-8_10
   Pointecker F., 2021, ISS 21 WORKSHOP P TR, DOI [10.18148/KOPS/352-2-1L3L2WNCU3TGB5, DOI 10.18148/KOPS/352-2-1L3L2WNCU3TGB5]
   Radu Iulian, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432944
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Rekimoto J., 1996, P VIRTUAL SYSTEMS MU, P2
   Riegler A., 2020, INT WORKSHOP CROSS R
   Rolland R. L., Comparison of optical andvideo see-through, head-mounted displays
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Seraji MR, 2022, IEEE INT SYMP M AU R, P146, DOI 10.1109/ISMAR-Adjunct57072.2022.00035
   Sereno L., 2019, EuroVis 2019-Posters, DOI [10.2312/EURP.201911362[43]M, DOI 10.2312/EURP.201911362[43]M]
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Smiley B., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, p501:1, DOI [10.1145/34885465[46]T.A., DOI 10.1145/34885465[46]T.A]
   Syed TA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010146
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2633
EP 2643
DI 10.1109/TVCG.2024.3372103
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400052
PM 38437119
OA hybrid
DA 2024-08-05
ER

PT J
AU Takeuchi, M
   Kusuyama, H
   Iwai, D
   Sato, K
AF Takeuchi, Masaki
   Kusuyama, Hiroki
   Iwai, Daisuke
   Sato, Kosuke
TI Projection Mapping under Environmental Lighting by Replacing Room Lights
   with Heterogeneous Projectors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; projection mapping; cooperative distributed projector
   optimization; large-aperture projector
ID LAMPS
AB Projection mapping (PM) is a technique that enhances the appearance of real-world surfaces using projected images, enabling multiple people to view augmentations simultaneously, thereby facilitating communication and collaboration. However, PM typically requires a dark environment to achieve high-quality projections, limiting its practicality. In this paper, we overcome this limitation by replacing conventional room lighting with heterogeneous projectors. These projectors replicate environmental lighting by selectively illuminating the scene, excluding the projection target. Our contributions include a distributed projector optimization framework designed to effectively replicate environmental lighting and the incorporation of a large-aperture projector, in addition to standard projectors, to reduce high-luminance emitted rays and hard shadows-undesirable factors for collaborative tasks in PM. We conducted a series of quantitative and qualitative experiments, including user studies, to validate our approach. Our findings demonstrate t hat our projector-based lighting system significantly enhancesthe contrast and realism of PM results even under e nvironmental lighting compared to typical lights. Furthermore, our method facilitates a substantial shift in the perceived color mode from the undesirable aperture-color mode, where observers perceive the projected object as self-luminous, to the surface-color mode in PM.
C1 [Takeuchi, Masaki; Kusuyama, Hiroki; Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
C3 Osaka University
RP Takeuchi, M (corresponding author), Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
EM m.takeuchi@sens.sys.es.osaka-u.ac.jp;
   hiroki.kusuyama@sens.sys.es.osaka-u.ac.jp;
   daisuke.iwai.es@osaka-u.ac.jp; sato@sys.es.osaka-u.ac.jp
OI Sato, Kosuke/0000-0003-1429-9990; Takeuchi, Masaki/0000-0002-0773-7705
FU JSPS KAKENHI
FX No Statement Available
CR Abdelhamed A, 2021, PROC CVPR IEEE, P6633, DOI 10.1109/CVPR46437.2021.00657
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O, 2005, IEEE MULTIMEDIA, V12, P16, DOI 10.1109/MMUL.2005.9
   Bimber O, 2005, COMPUTER, V38, P48, DOI 10.1109/MC.2005.17
   Bimber O, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P186, DOI 10.1109/ISMAR.2002.1115088
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Boyd Stephen, 2015, About us
   Cascini G, 2020, COMPUT IND, V123, DOI 10.1016/j.compind.2020.103308
   Erel Yotam, 2023, IEEE Trans Vis Comput Graph, V29, P4339, DOI 10.1109/TVCG.2023.3320256
   Fender AR, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P106, DOI 10.1145/3132272.3134117
   Flagg M., 2006, P 19 ANN ACM S USER, P235, DOI DOI 10.1145/1166253.1166290
   Grundhöfer A, 2015, IEEE T IMAGE PROCESS, V24, P5086, DOI 10.1109/TIP.2015.2478388
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Guarnera G. C., 2022, EUROGRAPHICS S RENDE, DOI [10.2312/sr.20221150, DOI 10.2312/SR.20221150]
   Hiratani K, 2023, IEEE T VIS COMPUT GR, V29, P2280, DOI 10.1109/TVCG.2023.3247104
   Huang BY, 2022, IEEE T PATTERN ANAL, V44, P2953, DOI 10.1109/TPAMI.2021.3050124
   Iwai D., 2006, P ACM S VIRTUAL REAL, P112, DOI DOI 10.1145/1180495.1180519
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Iwai D, 2011, VIRTUAL REAL-LONDON, V15, P147, DOI 10.1007/s10055-010-0159-5
   Jaynes C, 2004, IEEE T VIS COMPUT GR, V10, P290, DOI 10.1109/TVCG.2004.1272728
   Jones B., 2014, P 27 ANN ACM S US IN, P637, DOI DOI 10.1145/2642918.2647383
   Katz D., 1935, The World of Colour, P6
   Kitajima Y., 2017, IEEE Transactions on Visualization andComputer Graphics, V23, P1
   LeGendre C., 2022, DIGITAL PRODUCTION S, DOI [10.1145/3543664.35436812, DOI 10.1145/3543664.35436812]
   LeGendre C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925934
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Marner MR, 2014, IEEE COMPUT GRAPH, V34, P74, DOI 10.1109/MCG.2014.117
   Matsushita K., 2011, P 2NDAUGMENTED HUMAN
   Menk C, 2013, IEEE T VIS COMPUT GR, V19, P236, DOI 10.1109/TVCG.2012.146
   Morimoto T, 2021, J VISION, V21, DOI 10.1167/jov.21.13.3
   Nagase M., 2011, Virtual Reality, V15, P3
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Nomoto T, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3407297
   Park MK, 2015, J COMPUT DES ENG, V2, P38, DOI 10.1016/j.jcde.2014.11.004
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Raskar R, 2004, ACM T GRAPHIC, V23, P406, DOI 10.1145/1015706.1015738
   Raskar Ramesh., 1998, Proceedings of the 25th annual conference on Computer graphics and interactive techniques, P179, DOI DOI 10.1145/280814.280861
   Rivers A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366176
   Schmidt S, 2019, COMPUT GRAPH-UK, V83, P1, DOI 10.1016/j.cag.2019.06.002
   Shi JS, 2014, PROC SPIE, V9273, DOI 10.1117/12.2071915
   Siegl C., 2017, Computational Visual Media, V3, P263, DOI [10.1007/s41095-017-0090-82,3, DOI 10.1007/S41095-017-0090-82,3]
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Sukthankar R, 2001, PROC CVPR IEEE, P151
   Takeuchi Y, 2022, IEEE ACCESS, V10, P939, DOI 10.1109/ACCESS.2021.3139108
   Takeuchi Y, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P39, DOI 10.1145/2992154.2992188
   Takezawa T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI [10.1109/VR.2019.8797923, 10.1109/vr.2019.8797923]
   Tsukamoto J, 2015, IEEE T VIS COMPUT GR, V21, P1221, DOI 10.1109/TVCG.2015.2459905
   UCHIKAWA H, 1989, VISION RES, V29, P881, DOI 10.1016/0042-6989(89)90099-0
   Uchikawa K, 2001, J OPT SOC AM A, V18, P737, DOI 10.1364/JOSAA.18.000737
   Underkoffler J., 1999, P SIGCHI C HUM FACT, P386, DOI DOI 10.1145/302979.303114
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yasui M., 2021, SIGGRAPH ASIA 2021 P, DOI [10.1145/3476124.34886243, DOI 10.1145/3476124.34886243]
   Zhong FC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480513
   Zhou Z, 2015, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2015.7223335
NR 58
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2151
EP 2161
DI 10.1109/TVCG.2024.3372031
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400054
PM 38437091
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Chundury, P
   Reyazuddin, Y
   Jordan, JB
   Lazar, J
   Elmqvist, N
AF Chundury, Pramod
   Reyazuddin, Yasmin
   Jordan, J. Bern
   Lazar, Jonathan
   Elmqvist, Niklas
TI TactualPlot: Spatializing Data as Sound Using Sensory Substitution for
   Touchscreen Accessibility
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sonification; Data visualization; Smart phones; Touch sensitive screens;
   Blindness; Haptic interfaces; Electronic mail; Accessibility;
   sonification; multimodal interaction; crossmodal interaction;
   visualization
ID VISUALIZATION
AB Tactile graphics are one of the best ways for a blind person to perceive a chart using touch, but their fabrication is often costly, time-consuming, and does not lend itself to dynamic exploration. Refreshable haptic displays tend to be expensive and thus unavailable to most blind individuals. We propose TactualPlot, an approach to sensory substitution where touch interaction yields auditory (sonified) feedback. The technique relies on embodied cognition for spatial awareness-i.e., individuals can perceive 2D touch locations of their fingers with reference to other 2D locations such as the relative locations of other fingers or chart characteristics that are visualized on touchscreens. Combining touch and sound in this way yields a scalable data exploration method for scatterplots where the data density under the user's fingertips is sampled. The sample regions can optionally be scaled based on how quickly the user moves their hand. Our development of TactualPlot was informed by formative design sessions with a blind collaborator, whose practice while using tactile scatterplots caused us to expand the technique for multiple fingers. We present results from an evaluation comparing our TactualPlot interaction technique to tactile graphics printed on swell touch paper.
C1 [Chundury, Pramod; Jordan, J. Bern; Lazar, Jonathan; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Reyazuddin, Yasmin] Natl Federat Blind, Baltimore, MD USA.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
C3 University System of Maryland; University of Maryland College Park;
   Aarhus University
RP Chundury, P (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM pchundur@umd.edu; yasmin81065@gmail.com; jbjordan@umd.edu;
   jlazar@umd.edu; elm@cs.au.dk
OI Jordan, J. Bern/0000-0002-0386-9137; Elmqvist,
   Niklas/0000-0001-5805-5301
FU U.S. National Science Foundation
FX No Statement Available
CR Abraham CH, 2022, ASSIST TECHNOL, V34, P611, DOI 10.1080/10400435.2021.1907485
   Al-Zaidy RA., 2015, P ACM C KNOWL CAPT, P30, DOI DOI 10.1145/2815833.28169562
   Alexander J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173873
   Bach-y-Rita P, 2003, TRENDS COGN SCI, V7, P541, DOI 10.1016/j.tics.2003.10.013
   Batch A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376733
   Baudisch P., 2003, P CHI, P481, DOI [DOI 10.1145/642611.6426951,2, 10.1145/642611.642695]
   Blanco M., 2022, IEEE VIS POST
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cantrell S., 2021, P INT C AUD DISPL
   Carter T., 2013, P 26 ANN ACM S US IN, P505
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Chundury P, 2022, IEEE T VIS COMPUT GR, V28, P1084, DOI 10.1109/TVCG.2021.3114829
   Cook A. M., 2014, Assistive Technologies: Principles and Practice, V1
   Deroy O., 2012, Frontiers in Psychology, V3, DOI [10.3389/fpsyg.2012.004572,3, DOI 10.3389/FPSYG.2012.004572,3]
   Drogemuller A., 2021, PROC CHI ACM, DOI [10.1145/3411764.34457041, DOI 10.1145/3411764.3445704]
   Elavsky F, 2022, COMPUT GRAPH FORUM, V41, P57, DOI 10.1111/cgf.14522
   Elmqvist N., 2023, Interactions, V30, P52, DOI [10.1145/3571737, DOI 10.1145/3571737]
   Enge K., 2022, P EUR C VIS SHORT PA, P67, DOI [10.2312/evs.20221095, DOI 10.2312/EVS.20221095]
   Fan D., 2022, P ACM C HUM FACT COM, DOI [10.1145/3491102.35177902, DOI 10.1145/3491102.35177902]
   Gaver B., 1999, ACM Interactions, V6, P21, DOI DOI 10.1145/291224.291235
   Gleason C, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P549, DOI 10.1145/3308558.3313605
   Gorlewicz JL, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3403933
   Guinness D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P318, DOI 10.1145/3308561.3353804
   Hermann T., 2011, The Sonification Handbook, P2
   Holloway L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173772
   Hoque MN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581087
   Janicke S., 2020, P EUR WORKSH GAP VIS, P35, DOI DOI 10.2312/VISGAP.20201108
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jung C, 2022, IEEE T VIS COMPUT GR, V28, P1095, DOI 10.1109/TVCG.2021.3114846
   Kim G, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581139
   Kim JH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581532
   Kramer G., 1994, Santa Fe Institute Studies in the Sciences of Complexity, VXVIII, P2
   Kramer G., SONIFICATION REPORT
   Lundgard A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P16, DOI [10.1109/VISUAL.2019.8933762, 10.1109/visual.2019.8933762]
   Nakagaki K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2764, DOI 10.1145/2858036.2858104
   Nanay B, 2017, PERCEPTION, V46, P1014, DOI 10.1177/0301006617699225
   Nicolau Hugo., 2015, P 12 WEB ALL C 301 3, DOI [DOI 10.1145/2745555.27466439, 10.1145/2745555.2746643, DOI 10.1145/2745555.2746643]
   Nikitenko D, 2014, PROCEDIA COMPUT SCI, V34, P360, DOI 10.1016/j.procs.2014.07.038
   Oh Uran, 2013, P ACM SIGACCESS C CO, DOI [10.1145/2513383.2513455, 10.1145/2513383.2513455event-place, DOI 10.1145/2513383.2513455]
   Osinski D., 2021, Sensors, V21, DOI [10.3390/s212173512, DOI 10.3390/S212173512]
   Palani HP, 2020, INT J HUM-COMPUT INT, V36, P1393, DOI 10.1080/10447318.2020.1752464
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Potluri V, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545700
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sharif A., 2022, P 24 INT ACM SIGACCE, DOI 10.1145/3517428.3550360
   Sharif A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517431
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Siu A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517678
   Taher F, 2017, IEEE T VIS COMPUT GR, V23, P451, DOI 10.1109/TVCG.2016.2598498
   Thompson J, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581186
   Tory M, 2005, IEEE COMPUT GRAPH, V25, P8, DOI 10.1109/MCG.2005.102
   Wagner J., 2012, Proc. of CHI '12, P2317
   Walker B.N., 2010, ACM TRANS ACCESS COM, V2, P1, DOI DOI 10.1145/1714458.1714459
   Walker B. N., 2005, ACM Transactions on Applied Perception, V2, P407, DOI DOI 10.1145/1101530.1101534
   Wallace Jayne, 2013, P SIGCHI C HUM FACT, P3441, DOI DOI 10.1145/2470654.2466473
   Wang R, 2022, COMPUT GRAPH FORUM, V41, P71, DOI 10.1111/cgf.14523
   Yau D, 2007, DIGIT CREAT, V18, P121, DOI 10.1080/14626260701401510
   Zhao H, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1352782.1352786
   Zong J, 2022, COMPUT GRAPH FORUM, V41, P15, DOI 10.1111/cgf.14519
NR 61
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 836
EP 846
DI 10.1109/TVCG.2023.3326937
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500010
PM 37922170
DA 2024-08-05
ER

PT J
AU Lan, XY
   Wu, YQ
   Cao, N
AF Lan, Xingyu
   Wu, Yanqiu
   Cao, Nan
TI Affective Visualization Design: Leveraging the Emotional Impact of Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information Visualization; Affective Design; Visual Communication; User
   Experience; Storytelling
ID STORIES
AB In recent years, more and more researchers have reflected on the undervaluation of emotion in data visualization and highlighted the importance of considering human emotion in visualization design. Meanwhile, an increasing number of studies have been conducted to explore emotion-related factors. However, so far, this research area is still in its early stages and faces a set of challenges, such as the unclear definition of key concepts, the insufficient justification of why emotion is important in visualization design, and the lack of characterization of the design space of affective visualization design. To address these challenges, first, we conducted a literature review and identified three research lines that examined both emotion and data visualization. We clarified the differences between these research lines and kept 109 papers that studied or discussed how data visualization communicates and influences emotion. Then, we coded the 109 papers in terms of how they justified the legitimacy of considering emotion in visualization design (i.e., why emotion is important) and identified five argumentative perspectives. Based on these papers, we also identified 61 projects that practiced affective visualization design. We coded these design projects in three dimensions, including design fields (where), design tasks (what), and design methods (how), to explore the design space of affective visualization design.
C1 [Lan, Xingyu] Fudan Univ, Shanghai, Peoples R China.
   [Lan, Xingyu] Res Grp Computat & AI Commun Inst Global Commun &, Shanghai, Peoples R China.
   [Wu, Yanqiu; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
C3 Fudan University; Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
EM xingyulan96@gmail.com; wuyanqiu.idvx@gmail.com; nan.cao@gmail.com
OI Cao, Nan/0000-0003-1316-7515; Lan, Xingyu/0000-0001-7331-2433
FU NSFC
FX No Statement Available
CR affaireclimat, About Us
   Aitken S., 2011, The Map Reader: Theories of Mapping Practice and Cartographic Representation, V4, P278
   Ajani K., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Alamalhodaei A., 2020, Data Visualization in Society, P5
   Anderson CL, 2022, IEEE T VIS COMPUT GR, V28, P2867, DOI 10.1109/TVCG.2021.3050118
   Aragon C., 2021, Creativity and Cognition, P1
   Aseniero BA, 2022, 2022 IEEE VIS ARTS PROGRAM (VISAP 2022), P105, DOI 10.1109/VISAP57411.2022.00021
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Beale R, 2008, LECT NOTES COMPUT SC, V4868, P1, DOI 10.1007/978-3-540-85099-1_1
   Bloom P., 2014, Against empathy
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Braun V., 2012, Thematic analysis, V3
   Campbell S., 2018, Feeling numbers: the rhetoric of pathos in visualization, V4, P5
   Carpendale S., 2017, Information Design Journal, V23, P3
   Cartwright W., 2008, Geospatial Vision, P4
   Chen Q., 2023, IEEE Transactions on Visualization and Computer Graphics, V9
   Claes S, 2017, LEONARDO, V50, P90, DOI 10.1162/LEON_a_01224
   Concannon S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376462
   Craine J., 2011, Rethinking Maps, P4
   Cummins P., 2014, Blood Swept Lands and Seas of Red
   DIgnazio C, 2020, STRONG IDEAS SERIES, P1
   Dragga S, 2001, TECH COMMUN, V48, P265
   Elli T, 2020, 2020 IEEE VIS ARTS PROGRAM (VISAP 2020), P29, DOI 10.1109/VISAP51628.2020.00010
   FloydMueller F., 2021, P CHI C HUMAN FACTOR, P1
   Gardener J., 2017, P INT CARTOGRAPHIC A, P1
   GILMARTIN P, 1991, CARTOGR J, V28, P145
   Gough P, 2014, IEEE PAC VIS SYMP, P335, DOI 10.1109/PacificVis.2014.39
   Harrison L., 2013, P CHI C HUMAN FACTOR, P2
   ieeevis, Area model for vis
   images.webofknowledge, Web of science research areas
   InfoDesignLab, 2012, The water we eat
   Iturrioz T., 2011, Mapping Different Geographies, P3
   Ivanov A, 2019, IEEE COMPUT GRAPH, V39, P19, DOI 10.1109/MCG.2019.2898941
   Johnson D, 2003, ERGONOMICS, V46, P1332, DOI 10.1080/00140130310001610865
   Jorgenson L., 1995, IEEE VISUALIZATION C, P2
   Kauer T., 2021, P CHI C HUMAN FACTOR, P1
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kennedy H, 2016, INFORM COMMUN SOC, V19, P715, DOI 10.1080/1369118X.2016.1153126
   Kent A., 2013, Cartographic Perspectives, V73, P9
   Kosara R, 2007, IEEE INT CONF INF VI, P631
   Kostelnick C, 2016, TECH COMMUN-STC, V63, P116
   Kuznetsov S, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P237
   Lan X., 2022, P CHI C HUMAN FACTOR, P1
   Lan X., 2022, arXiv
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Le Bon G., 1897, The crowd: A study of the popular mind, P9
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Lewis M., 2010, Handbook of emotions, P1
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Lupi G., 2017, Data humanism: The revolutionary future of data visualization
   Lupi G., 2016, Chronicle books, V6, P7
   Lupi Giorgia, 2015, Dear Data
   McCleary G., 2003, P INT CARTOGRAPHIC C, P5
   Morais L, 2022, COMPUT GRAPH FORUM, V41, P441, DOI 10.1111/cgf.14553
   Morais L., 2021, P CHI C HUMAN FACTOR, P1
   Muehlenhaus I, 2012, CARTOGR J, V49, P361, DOI 10.1179/1743277412Y.0000000032
   Nietzsche F., 2022, DigiCat, P1
   Norman D.A., 2004, EMOTIONAL DESIGN WHY
   Padilla L., 2022, IEEE transactions on visualization and computer graphics, V29, P2
   Periscopic, Revealing the overwhelming magnitude of loss from U.S. gun deaths
   Periscopic, 2013, U.S. gun deaths
   Perovich LJ, 2021, IEEE T VIS COMPUT GR, V27, P913, DOI 10.1109/TVCG.2020.3030472
   Picard R. W., 2000, Affective computing, V1, P2
   Pinilla A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.630731
   PolicyViz, 2016, Episode #31: Rees & Mushon on DataViz empathy
   Porter T. M., 1996, Trust in Numbers, P2
   Qin CY, 2020, 2020 IEEE VIS ARTS PROGRAM (VISAP 2020), P1, DOI 10.1109/VISAP51628.2020.00007
   Rebelo SM, 2022, 2022 IEEE VIS ARTS PROGRAM (VISAP 2022), P70, DOI 10.1109/VISAP57411.2022.00017
   Romat H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376348
   Sallam S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517727
   Samsel F, 2021, 2021 IEEE VIS ARTS PROGRAM (VISAP 2021), P20, DOI 10.1109/VISAP52981.2021.00009
   Scarr S., 2011, Iraq's bloody toll
   Segal A., 2015, Grewingk glacier
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi Y., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P972
   Shi Y., 2021, P CHI C HUMAN FACTOR, P1
   Thoresen JC, 2016, NEUROBIOL LEARN MEM, V132, P1, DOI 10.1016/j.nlm.2016.04.008
   Tiles J., 2014, Interview: Paul cummins-blood swept lands & seas of red
   Tufte E. R., 2001, The visual display of quantitative information, P2
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   van Koningsbruggen R., 2021, CREATIVITY COGNITION, P1, DOI [10.1145/3450741.3465257, DOI 10.1145/3450741.3465257]
   van Lammeren R, 2010, COMPUT ENVIRON URBAN, V34, P465, DOI 10.1016/j.compenvurbsys.2010.07.001
   Viégas FB, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P105, DOI 10.1109/INFVIS.2004.8
   Viégas FB, 2009, IEEE T VIS COMPUT GR, V15, P1137, DOI 10.1109/TVCG.2009.171
   Walter A., 2011, A Book Apart, P2
   Wang X., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Xie L., 2023, IEEE Transactions on Visualization and Computer Graphics, P9
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Yu B, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P333, DOI 10.1145/3064663.3064729
   Zeller S, 2022, 2022 IEEE VIS ARTS PROGRAM (VISAP 2022), P127, DOI 10.1109/VISAP57411.2022.00025
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
NR 96
TC 1
Z9 1
U1 25
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1
EP 11
DI 10.1109/TVCG.2023.3327385
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500048
PM 37903043
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Sterzik, A
   Lichtenberg, N
   Wilms, J
   Krone, M
   Cunningham, DW
   Lawonn, K
AF Sterzik, Anna
   Lichtenberg, Nils
   Wilms, Jana
   Krone, Michael
   Cunningham, Douglas W.
   Lawonn, Kai
TI Perception of Line Attributes for Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Data visualization; Visualization; Encoding; Task analysis;
   Shape; Image color analysis; Line Drawings; Line Stylization; Perceptual
   Evaluation; Uncertainty Visualization
ID WEBERS LAW; UNCERTAINTY; ILLUSTRATION
AB Line attributes such as width and dashing are commonly used to encode information. However, many questions on the perception of line attributes remain, such as how many levels of attribute variation can be distinguished or which line attributes are the preferred choices for which tasks. We conducted three studies to develop guidelines for using stylized lines to encode scalar data. In our first study, participants drew stylized lines to encode uncertainty information. Uncertainty is usually visualized alongside other data. Therefore, alternative visual channels are important for the visualization of uncertainty. Additionally, uncertainty-e.g., in weather forecasts-is a familiar topic to most people. Thus, we picked it for our visualization scenarios in study 1. We used the results of our study to determine the most common line attributes for drawing uncertainty: Dashing, luminance, wave amplitude, and width. While those line attributes were especially common for drawing uncertainty, they are also commonly used in other areas. In studies 2 and 3, we investigated the discriminability of the line attributes determined in study 1. Studies 2 and 3 did not require specific application areas; thus, their results apply to visualizing any scalar data in line attributes. We evaluated the just-noticeable differences (JND) and derived recommendations for perceptually distinct line levels. We found that participants could discriminate considerably more levels for the line attribute width than for wave amplitude, dashing, or luminance.
C1 [Sterzik, Anna; Wilms, Jana; Lawonn, Kai] Univ Jena, Jena, Germany.
   [Lichtenberg, Nils; Krone, Michael] Univ Tubingen, Tubingen, Germany.
   [Cunningham, Douglas W.] Brandenburg Tech Univ Cottbus, Cottbus, Germany.
C3 Friedrich Schiller University of Jena; Eberhard Karls University of
   Tubingen; Brandenburg University of Technology Cottbus
RP Sterzik, A (corresponding author), Univ Jena, Jena, Germany.
EM anna.sterzik@uni-jena.de; nils.lichtenberg@uni-tuebingen.de;
   jana.wilms@uni-jena.de; michael.krone@uni-tuebingen.de;
   douglas.cunningham@b-tu.de; kai.lawonn@uni-jena.de
OI Krone, Michael/0000-0002-1445-7568; Sterzik, Anna/0000-0002-0544-5397;
   Wilms, Jana/0009-0003-4078-5287
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR [Anonymous], 1992, Cartogr. Perspect, DOI DOI 10.14714/CP13.1000
   Appel Arthur., 1967, Proceedings of the ACM National Conference, P387
   Balestrucci P., 2022, bioRxiv, DOI [10.1101/2022.06.20.4968556, DOI 10.1101/2022.06.20.4968556]
   Benard P., 2012, P S NONPHOTOREALISTI, P2
   Bénard P, 2019, FOUND TRENDS COMPUT, V11, P1, DOI 10.1561/0600000075
   Bénard P, 2011, COMPUT GRAPH FORUM, V30, P2367, DOI 10.1111/j.1467-8659.2011.02075.x
   Boukhelifa N, 2012, IEEE T VIS COMPUT GR, V18, P2769, DOI 10.1109/TVCG.2012.220
   Buchholz N., 2011, P S NONPH AN REND, P85
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360687, 10.1145/1360612.1360657]
   Cole F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531334
   Cunningham D. W., 2011, Experimental Design: From User Studies to Psychophysics, V2, P7
   Deussen O, 1999, PROC GRAPH INTERF, P175
   Dooley D., 1990, Computer Graphics, V24, P77, DOI 10.1145/91394.91422
   Gillmann C, 2021, COMPUT GRAPH FORUM, V40, P665, DOI 10.1111/cgf.14333
   Görtler J, 2018, IEEE T VIS COMPUT GR, V24, P719, DOI 10.1109/TVCG.2017.2743959
   Granit AR, 1921, B J PSYCHOL-GEN SECT, V12, P223
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Kalnins RD, 2003, ACM T GRAPHIC, V22, P856, DOI 10.1145/882262.882355
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Lawonn K, 2013, COMPUT GRAPH FORUM, V32, P321, DOI 10.1111/cgf.12119
   Lawonn K., 2016, Visualization in Medicine and Life Sciences III, P93, DOI DOI 10.1007/978-3-319-24523-2_52
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lawonn K, 2017, COMPUT GRAPH-UK, V63, P37, DOI 10.1016/j.cag.2017.02.002
   Lawonn K, 2015, LECT NOTES COMPUT SC, V9350, P399, DOI 10.1007/978-3-319-24571-3_48
   Lawonn K, 2014, COMPUT GRAPH FORUM, V33, P181, DOI 10.1111/cgf.12374
   Lechner VE, 2020, LECT NOTES ARTIF INT, V12169, P110, DOI 10.1007/978-3-030-54249-8_9
   Lichtenberg N, 2020, COMPUT GRAPH FORUM, V39, P497, DOI 10.1111/cgf.13888
   Lichtenberg N, 2018, COMPUT GRAPH-UK, V74, P137, DOI 10.1016/j.cag.2018.04.008
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Pang A., 2001, P WORKSHOP INTERSECT, P2
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Samatey F., 2001, Crystal Structure of F41 Fragment of Flagellin, DOI [10.2210/pdb1io1/pdb3, DOI 10.2210/PDB1IO1/PDB3]
   Samatey FA, 2001, NATURE, V410, P331, DOI 10.1038/35066504
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   Sterzik A., 2022, EUROGRAPHICS WORKSHO, P41, DOI [DOI 10.2312/VCBM.202211862, 10.2312/vcbm.202211861,2,3,6,9, DOI 10.2312/VCBM.202211861,2,3,6,9]
   Sterzik A., IEEE Transactions on Visualization and Computer Graphics
   Sterzik A, 2023, COMPUT GRAPH-UK, V114, P401, DOI 10.1016/j.cag.2023.06.006
   Strothotte T, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P36, DOI 10.1109/CGI.1999.777901
   Tak S, 2014, IEEE T VIS COMPUT GR, V20, P935, DOI 10.1109/TVCG.2013.247
   TREISMAN M, 1964, PSYCHOL REV, V71, P314, DOI 10.1037/h0042445
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Winkenbach G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P91, DOI 10.1145/192161.192184
   Zahan G.M. H., 2021, Graphics Interface 2021
   Zhao WX, 2019, J COMPUT LANG, V53, P1, DOI 10.1016/j.cola.2019.01.001
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1041
EP 1051
DI 10.1109/TVCG.2023.3326523
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500059
PM 37871078
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Wang, YF
   Qian, YF
   Qi, XY
   Cao, N
   Wang, DS
AF Wang, Yifang
   Qian, Yifan
   Qi, Xiaoyu
   Cao, Nan
   Wang, Dashun
TI <i>InnovationInsights:</i> A Visual Analytics Approach for Understanding
   the Dual Frontiers of Science and Technology
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Science of Science; Innovation; Academic Profiles; Patent Data;
   Publication Data; Visual Analytics
ID VISUALIZATION; COLLECTION; DESIGN; SYSTEM
AB Science has long been viewed as a key driver of economic growth and rising standards of living. Knowledge about how scientific advances support marketplace inventions is therefore essential for understanding the role of science in propelling real-world applications and technological progress. The increasing availability of large-scale datasets tracing scientific publications and patented inventions and the complex interactions among them offers us new opportunities to explore the evolving dual frontiers of science and technology at an unprecedented level of scale and detail. However, we lack suitable visual analytics approaches to analyze such complex interactions effectively. Here we introduce InnovationInsights, an interactive visual analysis system for researchers, research institutions, and policymakers to explore the complex linkages between science and technology, and to identify critical innovations, inventors, and potential partners. The system first identifies important associations between scientific papers and patented inventions through a set of statistical measures introduced by our experts from the field of the Science of Science. A series of visualization views are then used to present these associations in the data context. In particular, we introduce the Interplay Graph to visualize patterns and insights derived from the data, helping users effectively navigate citation relationships between papers and patents. This visualization thereby helps them identify the origins of technical inventions and the impact of scientific research. We evaluate the system through two case studies with experts followed by expert interviews. We further engage a premier research institution to test-run the system, helping its institution leaders to extract new insights for innovation. Through both the case studies and the engagement project, we find that our system not only meets our original goals of design, allowing users to better identify the sources of technical inventions and to understand the broad impact of scientific research; it also goes beyond these purposes to enable an array of new applications for researchers and research institutions, ranging from identifying untapped innovation potential within an institution to forging new collaboration opportunities between science and industry.
C1 [Wang, Yifang; Qian, Yifan; Wang, Dashun] Northwestern Univ, Ctr Sci Sci & Innovat, Evanston, IL 60201 USA.
   [Qi, Xiaoyu; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
C3 Northwestern University; Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
EM yifang.wang@kellogg.northwestern.edu;
   yifan.qian1@kellogg.northwestern.edu; qixiaoyu@tongji.edu.cn;
   nan.cao@tongji.edu.cn; dashun.wang@kellogg.northwestern.edu
RI Qian, Yifan/ABB-2914-2020; Wang, Dashun/KHE-1484-2024
OI Qian, Yifan/0000-0002-3914-1981; Wang, Dashun/0000-0002-7054-2206; Wang,
   Yifang/0000-0001-6267-9440
FU Air Force Office of Scientific Research
FX No Statement Available
CR Abdelaal Moataz, 2023, IEEE Trans Vis Comput Graph, V29, P896, DOI 10.1109/TVCG.2022.3209427
   Ahmadpoor M, 2017, SCIENCE, V357, P583, DOI 10.1126/science.aam9527
   Angelini M, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5030031
   Ankam E., 2012, P CHI C HUM FACT COM
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Borner K., 2010, Atlas of science: Visualizing what we know, DOI [10.1007/s11192-011-0409-7, DOI 10.1007/S11192-011-0409-7]
   Boyack K. W., 2000, Technical report, P2
   Burch Michael, 2013, 2013 17th International Conference on Information Visualisation, P66, DOI 10.1109/IV.2013.8
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Bush V., 1990, Science-the Endless Frontier: a Report to the President on a Program for Postwar Scientific Research, V90, P1
   Cao HC, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581108
   Chan GYY, 2019, IEEE T VIS COMPUT GR, V25, P321, DOI 10.1109/TVCG.2018.2864826
   Chen C, 2013, Mapping science, DOI DOI 10.1007/978-1-4471-5128-9
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Cohan A., 2020, ACL, DOI [10.48550/arXiv.2004.07180 5, DOI 10.48550/ARXIV.2004.071805]
   Dattolo A, 2022, IEEE ACCESS, V10, P21631, DOI 10.1109/ACCESS.2022.3153027
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Deng ZW, 2022, IEEE-CAA J AUTOMATIC, DOI 10.1109/JAS.2022.105407
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Dong A, 2019, PROCEEDINGS OF THE 12TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION, VINCI 2019, DOI 10.1145/3356422.3356430
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Fattal R, 2001, IEEE VISUAL, P403, DOI 10.1109/VISUAL.2001.964539
   Federico P, 2017, IEEE T VIS COMPUT GR, V23, P2179, DOI 10.1109/TVCG.2016.2610422
   Fekete J.-D., 2019, Progressive data analysis and visualization, DOI [10.4230/DagRep.8.10.19, DOI 10.4230/DAGREP.8.10.19]
   Fey M., 2019, ICLR WORKSH REPR LEA, DOI [10.48550/arXiv.1903.02428 5, DOI 10.48550/ARXIV.1903.024285]
   Fortunato S, 2018, SCIENCE, V359, DOI 10.1126/science.aao0185
   Gonzalez-Marquez R., 2023, bioRxiv, P2023, DOI DOI 10.1101/2023.04.10.5362082
   Guo Z., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/VCG.2022.3163727, DOI 10.1109/VCG.2022.3163727]
   Hao H., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1016
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jones B.F., 2021, Rebuilding the Post-Pandemic Economy
   Karimi F, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P53, DOI 10.1145/2872518.2889385
   Kim YG, 2008, EXPERT SYST APPL, V34, P1804, DOI 10.1016/j.eswa.2007.01.033
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Koch S, 2011, IEEE T VIS COMPUT GR, V17, P557, DOI 10.1109/TVCG.2010.85
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Kutz DO, 2004, IEEE INFOR VIS, P983, DOI 10.1109/IV.2004.1320261
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   Li G., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32150702, DOI 10.1109/TVCG.2022.32150702]
   Li ZY, 2020, IEEE T VIS COMPUT GR, V26, P1182, DOI 10.1109/TVCG.2019.2934667
   Liang WX, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100584
   Liu L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25477-8
   Marx M, 2020, STRATEGIC MANAGE J, V41, P1572, DOI 10.1002/smj.3145
   Marx M, 2022, J ECON MANAGE STRAT, V31, P369, DOI 10.1111/jems.12455
   Morris S, 2002, COMPUT IND ENG, V43, P841, DOI 10.1016/S0360-8352(02)00143-2
   Mühlbacher T, 2018, IEEE T VIS COMPUT GR, V24, P174, DOI 10.1109/TVCG.2017.2745158
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P486, DOI 10.1109/TVCG.2021.3114820
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P544, DOI 10.1109/TVCG.2018.2865149
   OpenAlex, ABOUT US
   Pandey A, 2022, IEEE T VIS COMPUT GR, V28, P3563, DOI 10.1109/TVCG.2021.3064037
   PatentsView, ABOUT US
   Phan D, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P219, DOI 10.1109/INFVIS.2005.1532150
   Qian YF, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100237
   Qian YF, 2022, IEEE T NEUR NET LEAR, V33, P1663, DOI 10.1109/TNNLS.2020.3043196
   Sarvghad A, 2023, IEEE T VIS COMPUT GR, V29, P3340, DOI 10.1109/TVCG.2022.3158236
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sun MY, 2019, IEEE T VIS COMPUT GR, V25, P2983, DOI 10.1109/TVCG.2018.2861397
   Tovanich N, 2022, IEEE T VIS COMPUT GR, V28, P497, DOI 10.1109/TVCG.2021.3114787
   USPTO, ABOUT US
   uspto, Cooperative Patent Classification (CPC)
   Uzzi B, 2013, SCIENCE, V342, P468, DOI 10.1126/science.1240474
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   Verbeek K, 2011, IEEE T VIS COMPUT GR, V17, P2536, DOI 10.1109/TVCG.2011.202
   Wang D., 2021, The science of science, DOI [10.1017/97811086108341, DOI 10.1017/97811086108341]
   Wang DS, 2013, SCIENCE, V342, P127, DOI 10.1126/science.1237825
   Wang KS, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00045
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang Y, 2019, J VISUAL-JAPAN, V22, P941, DOI 10.1007/s12650-019-00585-2
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P475, DOI 10.1109/TVCG.2021.3114790
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P3441, DOI 10.1109/TVCG.2021.3067200
   Windhager Florian, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P268
   Wu A., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1026, DOI [10.1109/TVCG.2022.32093602, DOI 10.1109/TVCG.2022.32093602]
   Wu LF, 2019, NATURE, V566, P378, DOI 10.1038/s41586-019-0941-9
   Wu YH, 2016, IEEE T VIS COMPUT GR, V22, P260, DOI [10.1109/TVCG.2015.2468151, 10.1109/TVCG.2015.2465151]
   Ye YL, 2024, IEEE T VIS COMPUT GR, V30, P3224, DOI 10.1109/TVCG.2022.3229023
   Yin YA, 2022, NAT HUM BEHAV, V6, P1344, DOI 10.1038/s41562-022-01397-5
   Yin Y, 2021, SCIENCE, V371, P128, DOI 10.1126/science.abe3084
NR 78
TC 0
Z9 0
U1 10
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 518
EP 528
DI 10.1109/TVCG.2023.3327387
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500079
PM 37878444
DA 2024-08-05
ER

PT J
AU Wu, YC
   Xu, YS
   Gao, SH
   Wang, XB
   Song, WK
   Nie, ZH
   Fan, XM
   Li, Q
AF Wu, Yuchen
   Xu, Yuansong
   Gao, Shenghan
   Wang, Xingbo
   Song, Wenkai
   Nie, Zhiheng
   Fan, Xiaomeng
   Li, Quan
TI LiveRetro: Visual Analytics for Strategic Retrospect in Livestream
   E-Commerce
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Livestream E-commerce; Visual Analytics; Multimodal Video Analysis;
   Marketing Strategy; Time-series Modeling
ID LIVE; EVOLUTION; BEHAVIOR; CURVES; TIME
AB Livestream e-commerce integrates live streaming and online shopping, allowing viewers to make purchases while watching. However, effective marketing strategies remain a challenge due to limited empirical research and subjective biases from the absence of quantitative data. Current tools fail to capture the interdependence between live performances and feedback. This study identified computational features, formulated design requirements, and developed LiveRetro, an interactive visual analytics system. It enables comprehensive retrospective analysis of livestream e-commerce for streamers, viewers, and merchandise. LiveRetro employs enhanced visualization and time-series forecasting models to align performance features and feedback, identifying influences at channel, merchandise, feature, and segment levels. Through case studies and expert interviews, the system provides deep insights into the relationship between live performance and streaming statistics, enabling efficient strategic analysis from multiple perspectives.
C1 [Wu, Yuchen; Xu, Yuansong; Gao, Shenghan; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Wu, Yuchen; Xu, Yuansong; Gao, Shenghan; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
   [Song, Wenkai; Fan, Xiaomeng] ShanghaiTech Univ, Sch Entrepreneurship & Management, Shanghai, Peoples R China.
   [Wang, Xingbo] Cornell Univ, Weill Cornell Med Coll, Ithaca, NY USA.
   [Nie, Zhiheng] Be Friends Holding Ltd, Beijing, Peoples R China.
C3 ShanghaiTech University; ShanghaiTech University; Cornell University;
   Weill Cornell Medicine
RP Li, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.; Li, Q (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
EM wuych3@shanghaitech.edu.cn; xuys1@shanghaitech.edu.cn;
   gaoshh1@shanghaitech.edu.cn; xingbo.wang@med.cornell.edu;
   songwk@shanghaitech.edu.cn; 815194445@qq.com; fanxm@shanghaitech.edu.cn;
   liquan@shanghaitech.edu.cn
OI Wang, Xingbo/0000-0001-5693-1128; Shenghan, Gao/0009-0008-3397-0341
FU Shanghai Frontiers Science Center of Human-centered Artificial
   Intelligence (ShangHAI); Key Laboratory of Intelligent Perception and
   Human-Machine Collaboration (ShanghaiTech University), Ministry of
   Education
FX This work is partially supported by the Shanghai Frontiers Science
   Center of Human-centered Artificial Intelligence (ShangHAI) and Key
   Laboratory of Intelligent Perception and Human-Machine Collaboration
   (ShanghaiTech University), Ministry of Education.
CR Ariely D, 2003, Q J ECON, V118, P73, DOI 10.1162/00335530360535153
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Batch A., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2023.32415812,3, DOI 10.1109/TVCG.2023.32415812,3]
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bonoma T. V., 1985, The marketing edge: Making strategies work, DOI [10.2307/12516052, DOI 10.2307/12516052]
   Brown T. A., 2015, Confirmatory Factor Analysis for Applied Research, P3
   Cai J, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2548
   Cespedes FrankV., 1996, J MARKET MANAG, V12, P135
   Chen L., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1070, DOI DOI 10.1109/TVCG.2022.32093513
   Chen S, 2022, COMPUT GRAPH FORUM, V41, P429, DOI 10.1111/cgf.14552
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fei MQ, 2021, DECIS SUPPORT SYST, V142, DOI 10.1016/j.dss.2020.113466
   Gauri DK, 2021, J RETAILING, V97, P42, DOI 10.1016/j.jretai.2020.11.002
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guo LY, 2021, INTERNET RES, V31, P1718, DOI 10.1108/INTR-02-2020-0078
   Guo YY, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102786
   Haenlein M, 2020, CALIF MANAGE REV, V63, P5, DOI 10.1177/0008125620958166
   Hamel G., 1990, Mckinsey quarterly, P2
   Hou FF, 2020, INTERNET RES, V30, P141, DOI 10.1108/INTR-04-2018-0177
   Hu MY, 2020, INTERNET RES, V30, P1019, DOI 10.1108/INTR-03-2019-0082
   HUTT MD, 1988, J MARKETING, V52, P4, DOI 10.2307/1251682
   Jacoby J, 2002, J CONSUM PSYCHOL, V12, P51, DOI 10.1207/S15327663JCP1201_05
   John M, 2019, IEEE INT CON INF VIS, P241, DOI 10.1109/IV.2019.00048
   Kang K, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102251
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Lee CH, 2021, INFORMATION, V12, DOI 10.3390/info12060241
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li Y, 2021, J RETAIL CONSUM SERV, V60, DOI 10.1016/j.jretconser.2021.102478
   Lin Y, 2021, J MARKETING RES, V58, P417, DOI 10.1177/00222437211002477
   Lu BJ, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103509
   Lu CYR, 2020, INT J ONLINE MARKET, V10, P1, DOI 10.4018/IJOM.2020070101
   Lu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174040
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma CX, 2020, J COMPUT SCI TECH-CH, V35, P576, DOI 10.1007/s11390-020-0271-2
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   MARKUS ML, 1987, COMMUN RES, V14, P491, DOI 10.1177/009365087014005003
   MCGUIRE WJ, 1984, PREV MED, V13, P299, DOI 10.1016/0091-7435(84)90086-0
   Meng L, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102733
   Ming JL, 2021, INT J WEB INF SYST, V17, P300, DOI 10.1108/IJWIS-02-2021-0012
   Morgan NA, 2019, J ACAD MARKET SCI, V47, P4, DOI 10.1007/s11747-018-0598-1
   Nickerson R, 1998, REV GEN PSYCHOL, V2, DOI DOI 10.1037/1089-2680.2.2.175
   NUTT PC, 1983, ACAD MANAGE REV, V8, P600, DOI 10.2307/258261
   Park HJ, 2020, J RETAIL CONSUM SERV, V52, DOI 10.1016/j.jretconser.2019.101934
   Parkhi O. M., 2015, Deep face recognition, DOI [10.5244/C.29.415, DOI 10.5244/C.29.415]
   Piercy N. F., 2016, Market-Led Strategic Change: Transforming the Process of Going to Market, P2
   Ram J., 2019, Journal Europeen Des Systemes Automatises, V52, P1, DOI DOI 10.18280/JESA.520101
   Shen QM, 2020, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis48177.2020.2785
   Shi CL, 2015, IEEE PAC VIS SYMP, P159, DOI 10.1109/PACIFICVIS.2015.7156373
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Song D., 2021, P 14 CHIN SUMM WORKS, P225
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Sun Y, 2021, Arxiv, DOI arXiv:2107.02137
   Sun Y, 2019, ELECTRON COMMER R A, V37, DOI 10.1016/j.elerap.2019.100886
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wohn DY, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174048
   Wong K. K., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32456092, DOI 10.1109/TVCG.2023.32456092]
   Wongkitrungrueng A, 2020, J MARKET MANAG-UK, V36, P488, DOI 10.1080/0267257X.2020.1748895
   Wongkitrungrueng A, 2020, J BUS RES, V117, P543, DOI 10.1016/j.jbusres.2018.08.032
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Wu C.-C., 2021, Forming the strategy for live streaming e-commerce: An Action Research, DOI [10.24251/HICSS.2021.3382, DOI 10.24251/HICSS.2021.3382]
   Wu Q., 2022, ACM Transactions on Computer-Human Interaction, DOI [10.1145/35771992, DOI 10.1145/35771992]
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Xu XY, 2020, J ELECTRON COMMER RE, V21, P144
   Yang X, 2023, J RETAIL CONSUM SERV, V70, DOI 10.1016/j.jretconser.2022.103155
   Yuan KH, 2007, HANDB STAT, V26, P297, DOI 10.1016/S0169-7161(06)26010-3
   Yuanda Ling, 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873038
   Zeng H., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.31691752,3, DOI 10.1109/TVCG.2022.31691752,3]
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang C., 2022, IEEE Trans. Vis. Comput. Graphics, V29, P767
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
   Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7
   Zhang SL, 2022, SERV IND J, V42, P1001, DOI 10.1080/02642069.2022.2068530
NR 79
TC 2
Z9 2
U1 16
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1117
EP 1127
DI 10.1109/TVCG.2023.3326911
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500113
PM 37874716
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Popescu, V
   Sacks, E
   Cui, J
   Ashok, R
AF Popescu, Voicu
   Sacks, Elisha
   Cui, Jian
   Ashok, Rohan
TI Efficient and Robust From-Point Visibility
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE From-point visibility; aggressive visibility; exact visibility; triangle
   visibility; particle visibility; image generalization
AB This article presents two from-point visibility algorithms: one aggressive and one exact. The aggressive algorithm efficiently computes a nearly complete visible set, with the guarantee of finding all triangles of a front surface, no matter how small their image footprint. The exact algorithm starts from the aggressive visible set and finds the remaining visible triangles efficiently and robustly. The algorithms are based on the idea of generalizing the set of sampling locations defined by the pixels of an image. Starting from a conventional image with one sampling location at each pixel center, the aggressive algorithm adds sampling locations to make sure that a triangle is sampled at all the pixels it touches. Thereby, the aggressive algorithm finds all triangles that are completely visible at a pixel regardless of geometric level of detail, distance from viewpoint, or view direction. The exact algorithm builds an initial visibility subdivision from the aggressive visible set, which it then uses to find most of the hidden triangles. The triangles whose visibility status is yet to be determined are processed iteratively, with the help of additional sampling locations. Since the initial visible set is almost complete, and since each additional sampling location finds a new visible triangle, the algorithm converges in a few iterations.
C1 [Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
   [Sacks, Elisha] Purdue Univ, W Lafayette, IN 95014 USA.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University
RP Popescu, V (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM popescu@purdue.edu; eps@cs.purdue.edu; michaelcui1986@gmail.com;
   ashokr@purdue.edu
OI Sacks, ELISHA/0009-0002-6955-2754
FU National Science Foundation [2212200, 2219842]
FX This work was supported by the National Science Foundation under Grants
   2212200 and 2219842.
CR Apostu O, 2012, COMPUT GRAPH-UK, V36, P727, DOI 10.1016/j.cag.2012.04.008
   Auzinger T, 2013, COMPUT GRAPH FORUM, V32, P409, DOI 10.1111/cgf.12061
   Bittner J, 2004, COMPUT GRAPH FORUM, V23, P615, DOI 10.1111/j.1467-8659.2004.00793.x
   Bittner J, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P207, DOI 10.1109/CGI.1998.694268
   Bittner J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531400
   Carpenter L., 1984, Computers & Graphics, V18, P103
   Catmull Edwin., 1978, ACM SIGGRAPH Computer Graphics, V12, P6
   Chandak A, 2008, IEEE T VIS COMPUT GR, V14, P1707, DOI 10.1109/TVCG.2008.111
   Charneau S, 2007, VISUAL COMPUT, V23, P773, DOI 10.1007/s00371-007-0129-4
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Cui JA, 2010, IEEE T VIS COMPUT GR, V16, P1235, DOI 10.1109/TVCG.2010.127
   de Berg O., 2008, Computa-tional Geometry Algorithms and Applications, Vthird
   Decoret X., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P281
   Durand F, 2002, ACM T GRAPHIC, V21, P176, DOI 10.1145/508357.508362
   Durand F, 2000, COMP GRAPH, P239, DOI 10.1145/344779.344891
   Durand F., 2010, PhD thesis
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Furnas George W, 1986, Acm Sigchi Bulletin, P16, DOI DOI 10.1145/22339.22342
   Goodman J. E., 2004, Computational Geometry, P927
   GOODRICH MT, 1992, CVGIP-GRAPH MODEL IM, V54, P1, DOI 10.1016/1049-9652(92)90029-W
   Gribel CJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964949
   Haumont Denis., 2005, Proceedings of the Sixteenth Eurographics Conference on Rendering Techniques, P211
   Heckbert P. S., 1984, Computers & Graphics, V18, P119
   Hladky J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356530
   Hunt W, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203191
   Johnson GS, 2005, ACM T GRAPHIC, V24, P1462, DOI 10.1145/1095878.1095889
   Jones TR, 2000, SPRING COMP SCI, P197
   Katz M. J., 1992, Computational Geometry: Theory and Applications, V2, P223, DOI 10.1016/0925-7721(92)90024-M
   Koch T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451266
   Max N, 1995, SPRING COMP SCI, P74
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   MEHLHORN K, 1990, ALGORITHMICA, V5, P215, DOI 10.1007/BF01840386
   Milenkovic V., 2022, Int. J. Comput. Geometry Appl., V32, P39
   Mora F, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P191
   Nirenstein S., 2004, P 15 EUR C REND TECH, P207
   Overbeck R., 2007, EGSR 07, P85
   Palka S., 2014, Comput. Sci., V15
   Popescu V, 2000, COMP GRAPH, P433, DOI 10.1145/344779.344979
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   SHARIR M, 1992, ACM T GRAPHIC, V11, P1, DOI 10.1145/102377.112141
   Weiler K., 1977, ACM SIGGRAPH COMPUTE, V11, P214, DOI DOI 10.1145/965141.563896
   Wonka P, 2006, ACM T GRAPHIC, V25, P494, DOI 10.1145/1141911.1141914
   Yu JY, 2004, LECT NOTES COMPUT SC, V3022, P14
   Zhang H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P77, DOI 10.1145/258734.258781
   Zhou Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3452097
NR 46
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5313
EP 5327
DI 10.1109/TVCG.2023.3291138
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400006
PM 37390001
DA 2024-08-05
ER

PT J
AU Schier, F
   Zeidler, D
   Chandran, K
   Yu, ZY
   Mcginity, M
AF Schier, Florian
   Zeidler, Daniel
   Chandran, Krishnan
   Yu, Zhongyuan
   Mcginity, Matthew
TI ViewR: Architectural-Scale Multi-User Mixed Reality With Mobile
   Head-Mounted Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Mixed reality; Visualization; Collaboration;
   Head-mounted displays; Cameras; Resists; Visualization systems; mixed /
   augmented reality; virtual reality; collaborative systems; co-located
   systems
AB The emergence of mobile head-mounted displays with robust "inside-out" markerless tracking and video-passthrough permits the creation of novel mixed reality (MR) experiences in which architectural spaces of arbitrary size can be transformed into immersive multi-user visualisation arenas. Here we outline ViewR, an open-source framework for rapidly constructing and deploying architectural-scale multi-user MR experiences. ViewR includes tools for rapid alignment of real and virtual worlds, tracking loss detection and recovery, user trajectory visualisation and world state synchronisation between users with persistence across sessions. ViewR also provides control over the blending of the real and the virtual, specification of site-specific blending zones, and video-passthrough avatars, allowing users to see and interact with one another directly. Using ViewR, we explore the transformation of large architectural structures into immersive arenas by creating a range of experiences in various locations, with a particular focus on architectural affordances such as mezzanines, stairs, gangways and elevators. Our tests reveal that ViewR allows for experiences that would not be possible with pure virtual reality, and indicate that, with certain strategies for recovering from tracking errors, it is possible to construct large scale multi-user MR experiences using contemporary consumer virtual reality head-mounted displays.
C1 [Schier, Florian; Zeidler, Daniel; Chandran, Krishnan; Yu, Zhongyuan; Mcginity, Matthew] Tech Univ Dresden, Fac Comp Sci, D-01062 Dresden, Germany.
C3 Technische Universitat Dresden
RP Schier, F (corresponding author), Tech Univ Dresden, Fac Comp Sci, D-01062 Dresden, Germany.
EM florian.schier@tu-dresden.de; daniel.zeidler@tu-dresden.de;
   krishnan.chandran@tu-dresden.de; zhongyuan.yu@tu-dresden.de;
   matthew.mcginity@tu-dresden.de
OI Schier, Florian/0000-0002-3611-8719; Zeidler,
   Daniel/0000-0003-4954-4896; Peringottukurussi Chandran,
   Krishnan/0000-0002-5718-7043; Yu, Zhongyuan/0000-0002-3671-1619;
   McGinity, Matthew/0000-0002-8923-6284
FU Else Kroner Fresenius Center for Digital Health [612,024]
FX This work was supported by Else Kroner Fresenius Center for Digital
   Health under Grant # 612,024.
CR Abdlkarim D, 2024, BEHAV RES METHODS, V56, P1052, DOI 10.3758/s13428-022-02051-8
   Anhong Guo, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351241
   Billinghurst M., 1998, Virtual Reality, V3, P25, DOI 10.1007/BF01409795
   Carnevale A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155511
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/VR.2019.8797733, 10.1109/vr.2019.8797733]
   de Belen R. A. J., 2019, AIMS Electronics and Electrical, V3, P181, DOI [10.3934/electreng.2019.2.181, 10.3934/ElectrEng.2019.2.181]
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   Friston S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489871
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Gruenefeld U, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501821
   He WN, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P255, DOI 10.1109/VR50410.2021.00047
   He ZY, 2020, INT SYM MIX AUGMENT, P542, DOI 10.1109/ISMAR50242.2020.00082
   Holzwarth Valentin, 2021, ICVARS 2021: 2021 the 5th International Conference on Virtual and Augmented Reality Simulations, P42, DOI 10.1145/3463914.3463921
   Jinyu L., 2019, VIRTUAL REALITY INTE, V1, P386, DOI [10.1016/j.vrih.2019.07.002, DOI 10.1016/J.VRIH.2019.07.002]
   KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Luo WZ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501946
   Barros AM, 2022, ROBOTICS, V11, DOI 10.3390/robotics11010024
   Mahmood T, 2019, INT SYM MIX AUGMENT, P236, DOI 10.1109/ISMAR.2019.00021
   Maier JRA, 2009, DESIGN STUD, V30, P393, DOI 10.1016/j.destud.2009.01.002
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miller J, 2020, INT J ADV MANUF TECH, V109, P1741, DOI 10.1007/s00170-020-05768-y
   Mulvany G., 2020, ser. CHI PLAY, V20, P321, DOI [10.1145/3383668.3419875, DOI 10.1145/3383668.3419875]
   Pan Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P759, DOI [10.1109/VRW50115.2020.00-45, 10.1109/VRW50115.2020.00230]
   Pereira N, 2021, INT SYM MIX AUGMENT, P479, DOI 10.1109/ISMAR52148.2021.00065
   Radu Iulian, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449243
   Reimer D, 2021, COMPUTERS, V10, DOI 10.3390/computers10050058
   Rompapas D. C., 2019, Ph.D. dissertation
   Schier F, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P274, DOI 10.1109/VRW55335.2022.00064
   Servières M, 2021, J SENSORS, V2021, DOI 10.1155/2021/2054828
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Zafari F, 2019, IEEE COMMUN SURV TUT, V21, P2568, DOI 10.1109/COMST.2019.2911558
NR 34
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5609
EP 5622
DI 10.1109/TVCG.2023.3299781
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400044
PM 37549094
OA hybrid
DA 2024-08-05
ER

PT J
AU Li, ZM
   Menon, H
   Mohror, K
   Liu, SS
   Guo, LZ
   Bremer, PT
   Pascucci, V
AF Li, Zhimin
   Menon, Harshitha
   Mohror, Kathryn
   Liu, Shusen
   Guo, Luanzheng
   Bremer, Peer-Timo
   Pascucci, Valerio
TI A Visual Comparison of Silent Error Propagation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Fault tolerance boundary; information visualization; graph
   visualization; error propagation; silent data corruption
ID VISUALIZATION; GRAPHS
AB High-performance computing (HPC) systems play a critical role in facilitating scientific discoveries. Their scale and complexity (e.g., the number of computational units and software stack) continue to grow as new systems are expected to process increasingly more data and reduce computing time. However, with more processing elements, the probability that these systems will experience a random bit-flip error that corrupts a program's output also increases, which is often recognized as silent data corruption. Analyzing the resiliency of HPC applications in extreme-scale computing to silent data corruption is crucial but difficult. An HPC application often contains a large number of computation units that need to be tested, and error propagation caused by error corruption is complex and difficult to interpret. To accommodate this challenge, we propose an interactive visualization system that helps HPC researchers understand the resiliency of HPC applications and compare their error propagation. Our system models an application's error propagation to study a program's resiliency by constructing and visualizing its fault tolerance boundary. Coordinating with multiple interactive designs, our system enables domain experts to efficiently explore the complicated spatial and temporal correlation between error propagations. At the end, the system integrated a nonmonotonic error propagation analysis with an adjustable graph propagation visualization to help domain experts examine the details of error propagation and answer such questions as why an error is mitigated or amplified by program execution.
C1 [Li, Zhimin; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
   [Menon, Harshitha; Mohror, Kathryn; Liu, Shusen; Bremer, Peer-Timo] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
   [Guo, Luanzheng] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
C3 Utah System of Higher Education; University of Utah; United States
   Department of Energy (DOE); Lawrence Livermore National Laboratory;
   United States Department of Energy (DOE); Pacific Northwest National
   Laboratory
RP Li, ZM (corresponding author), Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
EM zhimin@sci.utah.edu; gopalakrishn1@llnl.gov; mohror1@llnl.gov;
   liu42@llnl.gov; lenny.guo@pnnl.gov; bremer5@llnl.gov;
   pascucci@sci.utah.edu
RI pascucci, Valerio/GXF-0616-2022
OI pascucci, Valerio/0000-0002-8877-2042; Bremer,
   Peer-Timo/0000-0003-4107-3831; Guo, Luanzheng/0000-0001-8266-0923
FU U.S. Department of Energy, Office of Science, Office of Advanced
   Scientific Computing Research [DE-SC0014098]; Lawrence Livermore
   National Laboratory, U.S. Department of Energy [DE-AC52-07NA27344
   (LLNL-JRNL-843184)]
FX This work was supported in part by the U.S. Department of Energy, Office
   of Science, Office of Advanced Scientific Computing Research under Award
   DE-SC0014098 and Lawrence Livermore National Laboratory, U.S. Department
   of Energy, under Contract DE-AC52-07NA27344 (LLNL-JRNL-843184).
CR Anwer AR, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00092
   Bautista-Gomez L., 2015, P 22 EUR MPI US GROU, P1
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Benacchio T., 2020, Int. J. High Perform. Comput. Appl., V35, P85
   Berrocal Eduardo., 2015, P 24 INT S HIGH PERF, P275
   Buja A, 2008, J COMPUT GRAPH STAT, V17, P444, DOI 10.1198/106186008X318440
   Burtini G., 2013, P IEEE 26 CAN C EL C, P1
   Calhoun J, 2017, HPDC'17: PROCEEDINGS OF THE 26TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P131, DOI 10.1145/3078597.3078617
   Cappello F., 2017, P EUR C PAR PROC, P545
   Chen ZT, 2021, I C DEPEND SYS NETWO, P1, DOI 10.1109/DSN48987.2021.00018
   Chiang WF, 2017, ACM SIGPLAN NOTICES, V52, P300, DOI 10.1145/3093333.3009846
   Di S, 2015, IEEE ACM INT SYMP, P271, DOI 10.1109/CCGrid.2015.17
   Di S, 2016, INT PARALL DISTRIB P, P730, DOI 10.1109/IPDPS.2016.11
   Dixit H.D., 2021, arXiv
   Feng SG, 2010, ASPLOS XV: FIFTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P385
   Geist Al, 2016, IEEE Spectrum, V53, P30, DOI 10.1109/MSPEC.2016.7420396
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Guhur PL, 2017, IEEE INT C CL COMP, P592, DOI 10.1109/CLUSTER.2017.13
   Guo H., 2018, P S PAR GRAPH VIS, P91, DOI 10.5555/3293524.3293533
   Guo LZ, 2021, J PARALLEL DISTR COM, V152, P111, DOI 10.1016/j.jpdc.2021.02.015
   Guo LZ, 2019, INT PARALL DISTRIB P, P878, DOI 10.1109/IPDPS.2019.00096
   Guo LZ, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18), DOI 10.1109/SC.2018.00011
   Hari SKS, 2012, ACM SIGPLAN NOTICES, V47, P123, DOI 10.1145/2189750.2150990
   Hari SKS, 2014, CONF PROC INT SYMP C, P61, DOI 10.1109/ISCA.2014.6853212
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Isaacs K. E., 2014, P EUR C VIS, P141
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Jugel U, 2014, PROC VLDB ENDOW, V7, P797, DOI 10.14778/2732951.2732953
   Jugel U, 2014, PROC VLDB ENDOW, V7, P1705, DOI 10.14778/2733004.2733066
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kim A, 2015, PROC VLDB ENDOW, V8, P521, DOI 10.14778/2735479.2735485
   Laguna I, 2016, INT SYM CODE GENER, P227, DOI 10.1145/2854038.2854059
   Leveugle R, 2009, DES AUT TEST EUROPE, P502
   Li GP, 2018, I C DEPEND SYS NETWO, P27, DOI 10.1109/DSN.2018.00016
   Li ZM, 2021, IEEE T VIS COMPUT GR, V27, P3938, DOI 10.1109/TVCG.2020.2994954
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Longabaugh WJR, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-275
   Lu QN, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3014586
   MAY TC, 1979, IEEE T ELECTRON DEV, V26, P2, DOI 10.1109/T-ED.1979.19370
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Menon H, 2018, ACM SIGPLAN NOTICES, V53, P195, DOI 10.1145/3200691.3178502
   Mukherjee SS, 2005, INT S HIGH PERF COMP, P243, DOI 10.1109/HPCA.2005.37
   Nobre C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376381
   Rakthanmanon Thanawin, 2012, KDD, V2012, P262, DOI 10.1145/2339530.2339576
   Ruta N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P236, DOI [10.1109/visual.2019.8933618, 10.1109/VISUAL.2019.8933618]
   Siddiqui T, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P51, DOI 10.1145/3318464.3389722
   Snir M, 2014, INT J HIGH PERFORM C, V28, P129, DOI 10.1177/1094342014522573
   Sorzano COS, 2014, Arxiv, DOI [arXiv:1403.2877, DOI 10.48550/ARXIV.1403.2877]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Venkatagiri R, 2016, INT SYMP MICROARCH
   Venkatagiri R, 2019, I C DEPEND SYS NETWO, P214, DOI 10.1109/DSN.2019.00033
   Watson B., 2008, Visualizing very large layered graphs with quilts
   Wei JS, 2014, I C DEPEND SYS NETWO, P375, DOI 10.1109/DSN.2014.2
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Zhimin Li, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P362, DOI 10.1145/3437801.3441589
NR 59
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3268
EP 3282
DI 10.1109/TVCG.2022.3230636
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700085
PM 37015425
DA 2024-08-05
ER

PT J
AU Shen, LX
   Tai, ZW
   Shen, EY
   Wang, JM
AF Shen, Leixian
   Tai, Zhiwei
   Shen, Enya
   Wang, Jianmin
TI Graph Exploration With Embedding-Guided Layouts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graph embedding; graph exploration; graph layout
ID OF-THE-ART; VISUALIZATION; ALGORITHM
AB Node-link diagrams are widely used to visualize graphs. Most graph layout algorithms only use graph topology for aesthetic goals (e.g., minimize node occlusions and edge crossings) or use node attributes for exploration goals (e.g., preserve visible communities). Existing hybrid methods that bind the two perspectives still suffer from various generation restrictions (e.g., limited input types and required manual adjustments and prior knowledge of graphs) and the imbalance between aesthetic and exploration goals. In this article, we propose a flexible embedding-based graph exploration pipeline to enjoy the best of both graph topology and node attributes. First, we leverage embedding algorithms for attributed graphs to encode the two perspectives into latent space. Then, we present an embedding-driven graph layout algorithm, GEGraph, which can achieve aesthetic layouts with better community preservation to support an easy interpretation of the graph structure. Next, graph explorations are extended based on the generated graph layout and insights extracted from the embedding vectors. Illustrated with examples, we build a layout-preserving aggregation method with Focus+Context interaction and a related nodes searching approach with multiple proximity strategies. Finally, we conduct quantitative and qualitative evaluations, a user study, and two case studies to validate our approach.
C1 [Shen, Leixian; Tai, Zhiwei; Shen, Enya; Wang, Jianmin] Tsinghua Univ, Beijing 100190, Peoples R China.
C3 Tsinghua University
RP Shen, EY (corresponding author), Tsinghua Univ, Beijing 100190, Peoples R China.
EM slx20@mails.tsinghua.edu.cn; tzw20@mails.tsinghua.edu.cn;
   shenenya@tsinghua.edu.cn; jimwang@tsinghua.edu.cn
OI Shen, Leixian/0000-0003-1084-4912
FU National Natural Science Foundation of China [71690231]; Beijing Key
   Laboratory of Industrial Bigdata System and Application
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 71690231 and in part by the Beijing Key
   Laboratory of Industrial Bigdata System and Application.
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   Ahmed NK, 2022, IEEE T KNOWL DATA EN, V34, P2401, DOI 10.1109/TKDE.2020.3006475
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Bannister Michael J., 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P414, DOI 10.1007/978-3-642-36763-2_37
   Barsky A, 2008, IEEE T VIS COMPUT GR, V14, P1253, DOI 10.1109/TVCG.2008.117
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Bharadwaj A, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3479196
   Börner K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039464
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Büschel W, 2019, IEEE COMPUT GRAPH, V39, P29, DOI 10.1109/MCG.2019.2897927
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Chen Y, 2019, J VISUAL-JAPAN, V22, P625, DOI 10.1007/s12650-019-00551-y
   Cohen J. D., 1997, ACM Transactions on Computer-Human Interaction, V4, P197, DOI 10.1145/264645.264657
   Craven M, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P509
   Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036
   Dork S., 2011, P C VIS DAT AN, V17
   Dunne C, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2411412
   Fischer MT, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P81, DOI 10.1109/VIS49827.2021.9623305
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gajer P., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P211
   Gao HC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3364
   Gehlenborg N, 2010, NAT METHODS, V7, pS56, DOI [10.1038/NMETH.1436, 10.1038/nmeth.1436]
   Ghani S, 2013, IEEE T VIS COMPUT GR, V19, P2032, DOI 10.1109/TVCG.2013.223
   Gibson H, 2017, Arxiv, DOI arXiv:1712.05644
   Gibson H, 2016, APPL SOFT COMPUT, V42, P80, DOI 10.1016/j.asoc.2016.01.036
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo DS, 2009, IEEE T VIS COMPUT GR, V15, P1041, DOI 10.1109/TVCG.2009.143
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Harel D., 2004, J. Graph Algorithms Appl., V8, P195, DOI [10.7155/jgaa.00089, DOI 10.7155/JGAA.00089]
   Henderson K., 2012, P 18 ACM SIGKDD INT, P1231, DOI [DOI 10.1145/2339530.2339723, 10.1145/2339530.2339723]
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Itoh T, 2015, IEEE COMPUT GRAPH, V35, P30, DOI 10.1109/MCG.2015.115
   Jusufi Ilir, 2013, 2013 17th International Conference on Information Visualisation, P19, DOI 10.1109/IV.2013.3
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kerren A., 2014, Lecture Notes in Computer Science, V8380
   KNUTH DE, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P41
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Lee C., 2006, P AVI WROKSH TIM ERR, P1
   Lehtinen M., 2012, Systems Reference Library, P46
   Leow T., 2019, P INT C LEARN REPR
   Leskovec J., 2012, Advances in neural information processing systems, V25
   Liao LZ, 2018, IEEE T KNOWL DATA EN, V30, P2257, DOI 10.1109/TKDE.2018.2819980
   Lu L., 2003, ICML, P496
   Martins J. F., 2017, P 19 EG VGTC C VIS, P10
   Meyer M, 2009, IEEE T VIS COMPUT GR, V15, P897, DOI 10.1109/TVCG.2009.167
   Neuweger Heiko, 2009, BMC Syst Biol, V3, P82, DOI 10.1186/1752-0509-3-82
   Noack A, 2004, LECT NOTES COMPUT SC, V2912, P425
   Noack A., 2005, SoftVis '05: Proceedings of the 2005 ACM symposium on Software visualization, P155
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Partl C, 2014, IEEE T VIS COMPUT GR, V20, P1883, DOI 10.1109/TVCG.2014.2346752
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Pretorius AJ, 2008, COMPUT GRAPH FORUM, V27, P967, DOI 10.1111/j.1467-8659.2008.01231.x
   Ribeiro LFR, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P385, DOI 10.1145/3097983.3098061
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Shen L, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104146
   Shi L, 2014, IEEE PAC VIS SYMP, P89, DOI 10.1109/PacificVis.2014.44
   Shneiderman B, 2006, IEEE T VIS COMPUT GR, V12, P733, DOI 10.1109/TVCG.2006.166
   Spanurattana S., 2011, 2011 IEEE International Conference on Data Mining Workshops, P833, DOI 10.1109/ICDMW.2011.175
   Spritzer A. S., 2008, P WORK C ADV VIS INT, P271
   Spritzer AS, 2012, IEEE T VIS COMPUT GR, V18, P822, DOI 10.1109/TVCG.2011.106
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Walshaw C., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P171
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Wang YH, 2020, IEEE T VIS COMPUT GR, V26, P687, DOI 10.1109/TVCG.2019.2934805
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wu M., 2006, P 2006 AS PAC S INF, P77
   Wu YH, 2016, IEEE T VIS COMPUT GR, V22, P260, DOI [10.1109/TVCG.2015.2468151, 10.1109/TVCG.2015.2465151]
   Wu YX, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P223
   Xue ML, 2023, IEEE T VIS COMPUT GR, V29, P4256, DOI 10.1109/TVCG.2022.3187425
   Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2111
   Yang H, 2018, IEEE DATA MINING, P1476, DOI [10.1109/ICDM.2018.8626170, 10.1109/ICDM.2018.00207]
   Yang J, 2014, P IEEE, V102, P1892, DOI 10.1109/JPROC.2014.2364018
   Zhang DK, 2018, LECT NOTES ARTIF INT, V10938, P196, DOI 10.1007/978-3-319-93037-4_16
   Zhang DK, 2016, IEEE DATA MINING, P609, DOI [10.1109/ICDM.2016.0072, 10.1109/ICDM.2016.139]
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhu DY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2827, DOI 10.1145/3219819.3220052
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 92
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3693
EP 3708
DI 10.1109/TVCG.2023.3238909
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700041
PM 37022062
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Cao, X
   Li, J
   Zhao, PP
   Li, JC
   Qin, XY
AF Cao, Xin
   Li, Jia
   Zhao, Panpan
   Li, Jiachen
   Qin, Xueying
TI Corr-Track: Category-Level 6D Pose Tracking with Soft-Correspondence
   Matrix Estimation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Category-level object pose estimation; object tracking
ID SURFACE
AB Category-level pose tracking methods can continuously track the pose of objects without requiring any prior knowledge of the specific shape of the tracked instance. This makes them advantageous in augmented reality and virtual reality applications. The key challenge is how to train neural networks to accurately predict the poses of objects they have never seen before and exhibit strong generalization performance. We propose a novel category-level 6D pose tracking method Corr-Track, which is capable of accurately tracking objects belonging to the same category from depth video streams. Our approach utilizes direct soft correspondence constraints to train a neural network, which estimates bidirectional soft correspondences between sparsely sampled point clouds of objects in two frames. We first introduce a soft correspondence matrix for pose tracking tasks and establish effective constraints through direct spatial point-to-point correspondence representations in the sparse point cloud correspondence matrix. We propose the "point cloud expansion" strategy to address the "point cloud shrinkage" problem resulting from soft correspondences. This strategy ensures that the corresponding point cloud accurately reproduces the shape of the target point cloud, leading to precise pose tracking results. We evaluated our approach on the NOCS-REAL275 and Wild6D dataset and observed superior performance compared to previous methods. Additionally, we conducted cross-category experiments that further demonstrated its generalization capability.
C1 [Cao, Xin; Li, Jia; Zhao, Panpan; Qin, Xueying] Shandong Univ, Sch Software, Jinan, Peoples R China.
   [Cao, Xin; Li, Jia; Zhao, Panpan; Qin, Xueying] Minist Educ, Engn Res Ctr Digital Media Technol, Beijing, Peoples R China.
   [Li, Jiachen] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Shandong University; Zhejiang University
RP Cao, X (corresponding author), Shandong Univ, Sch Software, Jinan, Peoples R China.; Cao, X (corresponding author), Minist Educ, Engn Res Ctr Digital Media Technol, Beijing, Peoples R China.
EM sdu_cx@mail.sdu.edu.cn; lirity1024@outlook.com;
   zhaopanpan@mail.sdu.edu.cn; lijiachen93@zju.edu.cn; qxy@sdu.edu.cn
FU National Key R&D Program of China
FX No Statement Available
CR Aoki Y., 2019, IEEE C COMP VIS PATT, P2
   Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Chen K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2753, DOI 10.1109/ICCV48922.2021.00277
   Chen Wang, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10059, DOI 10.1109/ICRA40945.2020.9196679
   Chen W, 2021, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR46437.2021.00163
   Cuturi M., 2013, Ad-vances in Neural Information Processing Systems, V26, P1
   Dai QY, 2022, LECT NOTES COMPUT SC, V13699, P374, DOI 10.1007/978-3-031-19842-7_22
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Dengsheng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11970, DOI 10.1109/CVPR42600.2020.01199
   Di Y, 2022, PROC CVPR IEEE, P6771, DOI 10.1109/CVPR52688.2022.00666
   Dong Z, 2017, ISPRS J PHOTOGRAMM, V130, P431, DOI 10.1016/j.isprsjprs.2017.06.012
   Fan Z., 2021, arXiv
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Li B, 2022, COMPUT METH PROG BIO, V220, DOI 10.1016/j.cmpb.2022.106782
   Li ZY, 2023, Arxiv, DOI [arXiv:2312.02284, 10.48550/ARXIV.2312.022849]
   Lin HT, 2022, PROC CVPR IEEE, P6697, DOI 10.1109/CVPR52688.2022.00659
   Lin JH, 2022, LECT NOTES COMPUT SC, V13669, P19, DOI 10.1007/978-3-031-20077-9_2
   Lin JH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3540, DOI 10.1109/ICCV48922.2021.00354
   Lin Yunzhi, 2022, 2022 International Conference on Robotics and Automation (ICRA), P1258, DOI 10.1109/ICRA46639.2022.9811720
   Lindenberger P, 2023, Arxiv, DOI [arXiv:2306.13643, DOI 10.48550/ARXIV.2306.13643]
   Liu JH, 2023, Arxiv, DOI arXiv:2303.13479
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Luo ZX, 2019, PROC CVPR IEEE, P2522, DOI 10.1109/CVPR.2019.00263
   Pan Y, 2018, INT CONF 3D VISION, P180, DOI 10.1109/3DV.2018.00030
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Sajjan S, 2020, IEEE INT CONF ROBOT, P3634, DOI 10.1109/ICRA40945.2020.9197518
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarode V, 2019, Arxiv, DOI arXiv:1908.07906
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343
   Sun JM, 2021, PROC CVPR IEEE, P8918, DOI 10.1109/CVPR46437.2021.00881
   Sun JT, 2022, IEEE INT C INT ROBOT, P1556, DOI 10.1109/IROS47612.2022.9982183
   Tian M., 2020, ECCV, V12366, P2
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wang JZ, 2021, IEEE INT C INT ROBOT, P4807, DOI 10.1109/IROS51168.2021.9636212
   Wang Y, 2019, 33 C NEURAL INFORM P, V32
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wen BW, 2021, IEEE INT C INT ROBOT, P8067, DOI 10.1109/IROS51168.2021.9635991
   Weng YJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13189, DOI 10.1109/ICCV48922.2021.01296
   Xie YY, 2021, INT C PATT RECOG, P2779, DOI 10.1109/ICPR48806.2021.9413319
   Yew Z. J., 2020, 2020 IEEE CVF C COMP, P1
   Ze Y., 2022, P C NEUR INF PROC SY, V35, P27469
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang JH, 2022, IEEE T PATTERN ANAL, V44, P3110, DOI 10.1109/TPAMI.2020.3048013
   Zhang R, 2022, LECT NOTES COMPUT SC, V13661, P655, DOI 10.1007/978-3-031-19769-7_38
   Zheng LF, 2023, PROC CVPR IEEE, P17163, DOI 10.1109/CVPR52729.2023.01646
   Zhu LY, 2021, PROC CVPR IEEE, P4647, DOI 10.1109/CVPR46437.2021.00462
   Zodage T, 2020, INT CONF 3D VISION, P603, DOI 10.1109/3DV50981.2020.00070
NR 55
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2173
EP 2183
DI 10.1109/TVCG.2024.3372111
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400062
PM 38437129
DA 2024-08-05
ER

PT J
AU Do, TD
   Protko, CI
   Mcmahan, RP
AF Do, Tiffany D.
   Protko, Camille Isabella
   Mcmahan, Ryan P.
TI Stepping into the Right Shoes: The Effects of User-Matched Avatar
   Ethnicity and Gender on Sense of Embodiment in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; User experience; Statistics; Sociology; Particle measurements;
   Games; Atmospheric measurements; Virtual reality; sense of embodiment;
   avatars; diversity
ID BODY; IMPACT; REPRESENTATION
AB In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice. We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR. We conducted a 2 x 2 within-subjects experiment (n = 32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment. Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership. We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender. Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership.
C1 [Do, Tiffany D.; Protko, Camille Isabella; Mcmahan, Ryan P.] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Do, TD (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM tiffany.do@ucf.edu; ca916041@ucf.edu; rpm@ucf.edu
OI McMahan, Ryan/0000-0001-9357-9696; Do, Tiffany D./0000-0003-3323-4586
FU The University of Central Florida
FX No Statement Available
CR Ambron E, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.884189
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Ash E, 2016, GAMES CULT, V11, P422, DOI 10.1177/1555412014568870
   Bartl A, 2022, INT SYM MIX AUGMENT, P260, DOI 10.1109/ISMAR55827.2022.00041
   Chang F, 2019, CYBERPSYCH BEH SOC N, V22, P634, DOI 10.1089/cyber.2019.0106
   Chen VHH, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5080042
   Cheymol A, 2023, IEEE T VIS COMPUT GR, V29, P4426, DOI 10.1109/TVCG.2023.3320209
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Do TD, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1248915
   Döllinger N, 2023, INT SYM MIX AUGMENT, P483, DOI 10.1109/ISMAR59233.2023.00063
   Eubanks JC, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647896
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Fiedler ML, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P799, DOI 10.1109/VRW58643.2023.00242
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Herrera F, 2021, NEW MEDIA SOC, V23, P2189, DOI 10.1177/1461444821993121
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim H, 2023, IEEE T VIS COMPUT GR, V29, P4794, DOI 10.1109/TVCG.2023.3320240
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lopez S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300787
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   Mal D, 2023, IEEE T VIS COMPUT GR, V29, P2358, DOI 10.1109/TVCG.2023.3247089
   Marini M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.989582
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Ome M.T., 2009, Artifacts in Behavioral Research, P110
   Peck TC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376419
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pohl H, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.719506
   Radiah R, 2023, MULTIMODAL TECHNOLOG, V7, DOI 10.3390/mti7040038
   Ries B., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, VRST '09, P59, DOI [10.1145/1643928.1643943, DOI 10.1145/1643928.16439433, DOI 10.1145/1643928.1643943]
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salagean A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581182
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Schulze S, 2019, LECT NOTES COMPUT SC, V11574, P361, DOI 10.1007/978-3-030-21607-8_28
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seitz KR, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P607, DOI [10.1109/VRW50115.2020.00154, 10.1109/VRW50115.2020.0-121]
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wu LF, 2024, HUM FACTORS, V66, P1504, DOI 10.1177/00187208221145264
NR 50
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2434
EP 2443
DI 10.1109/TVCG.2024.3372067
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400073
PM 38437125
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Gómez, V
   Figueroa, P
AF Gomez, Vivian
   Figueroa, Pablo
TI ProtoColVR: Requirements Gathering and Collaborative Rapid Prototyping
   of VR Training Simulators for Multidisciplinary Teams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Simulation; Prototyping; Multidisciplinary;
   Methodology; Training
AB We present ProtoColVR, a methodology and a plugin designed for gathering requirements and collaborative rapid prototyping of virtual reality training simulators. Our methodology outlines the utilization of current technologies, the involvement of stakeholders during design and development, and the implementation of simulator creation through multiple iterations. We incorporate open-source tools and freely available environments like Twine and Unity to establish a reference implementation for requirements gathering and rapid prototyping. ProtoColVR is the outcome of our collaboration with a hospital and our Navy, and it has undergone testing in a development Jam. From these tests, we have gained valuable insights, including the ability to create functional prototypes within multidisciplinary teams, enhance communication among different roles, and streamline requirements gathering while improving our understanding of the virtualized environment.
C1 [Gomez, Vivian; Figueroa, Pablo] Univ los Andes, Bogota, Colombia.
C3 Universidad de los Andes (Colombia)
RP Gómez, V (corresponding author), Univ los Andes, Bogota, Colombia.
EM vn.gomez@uniandes.edu.co; pfiguero@uniandes.edu.co
OI Figueroa, Pablo/0000-0001-5412-8630; Gomez, Vivian/0000-0002-1713-9311
CR Abbas Y, 2023, INTERACT LEARN ENVIR, V31, P3698, DOI 10.1080/10494820.2021.1940215
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Barreto FM, 2017, XXXI BRAZILIAN SYMPOSIUM ON SOFTWARE ENGINEERING (SBES 2017), P261, DOI 10.1145/3131151.3131193
   Barreto S., 2014, P 24 ANN INT C COMP, P106
   BenMahmoud-Jouini C., 2020, Creativity andInnovation Management, DOI [10.1111/caim.123583[6]K, DOI 10.1111/CAIM.123583[6]K]
   Couperus K, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8062
   Dalladaku Y., 2020, Assessing the effectiveness of virtual reality in the training of army aviators
   Davis MJ, 2021, J TECHNOL HUMAN SERV, V39, P295, DOI 10.1080/15228835.2021.1915928
   DeMarco M. C., 2021, About entwee. m. c. de marco
   Di Loreto C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P281, DOI 10.1109/VR.2018.8448292
   Doneda A. L., 2020, Helicopter visual signaling simulation: Integrating vr and ml into a low-cost solution to optimize brazilian navy training, DOI [10.1109/SVR51698.2020.00071, DOI 10.1109/SVR51698.2020.00071]
   E. Games, 2024, Unreal engine-game development platform
   Garcia C. S/n, 2004, Gdesk: Game discrete eventsimulation kernel, P121
   Girardi R., 2019, Virtual reality in army artillery observer training, DOI [10.1109/SVR.2019.000211,2, DOI 10.1109/SVR.2019.000211,2]
   Gomez V., 2022, Tweenity
   Gomez V., 2021, Virtual Reality and Intelligent Hardware, V3, P407, DOI [10.1016/j.vrih.2021.09.0022,3,5, DOI 10.1016/J.VRIH.2021.09.0022,3,5]
   Gómez V, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P452, DOI 10.1109/VRW52623.2021.00108
   Greunke L, 2016, IEEE T VIS COMPUT GR, V22, P1482, DOI 10.1109/TVCG.2016.2518098
   Gunn T, 2018, INTERACT LEARN ENVIR, V26, P613, DOI 10.1080/10494820.2017.1374981
   Hafsia M, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234298
   InkleStudios, 2024, Inklewriter-an online tool for writing and sharing interactive stories
   JamVR, 2022, Jamvr: The simulators to build
   JamVR, 2022, Jamvr: The built simulators
   Jeon SG, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364268
   King A., 2017, Practical game design
   Kraub A., 2021, Current practices, challenges, and design impli-cations for collaborative ar/vr application development, DOI [10.1145/3411764.34453351,2,3,4,9[28]C.D., DOI 10.1145/3411764.34453351,2,3,4,9[28]C.D]
   Mozilla, 2024, Mozilla hubs-virtual reality chatrooms
   Mozilla, 2024, Spoke-create social vr spaces
   N. N. Group, 2018, Beyond the nps: Measuring perceived usability with the sus, nasa-tlx, and the single ease question after tasks and usability tests
   Nebeling M., 2018, The trouble with augmented reality/virtualreality authoring tools, DOI [10.1109/ISMAR-Adjunct.2018.000981[32]I, DOI 10.1109/ISMAR-ADJUNCT.2018.000981[32]I]
   Nowak W., 2021, INPROCEEDINGS THE202, DOI [10.1145/3437378.34426933[17]L, DOI 10.1145/3437378.34426933[17]L]
   Petukhov I., 2019, Design model of a training simulator in virtual reality, P1
   Spatial, 2024, Spatial-virtual reality workspace
   Twinery, 2024, Twine-an open-source tool for interactive storytelling
   U. Technologies, 2024, Unity-game development platform
   Wikipedia, 2024, Altspacevr
   Wikipedia contributors, 2023, Game jam
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
NR 38
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2549
EP 2558
DI 10.1109/TVCG.2024.3372057
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400020
PM 38437073
DA 2024-08-05
ER

PT J
AU Qu, Q
   Liang, HX
   Chen, XM
   Chung, YY
   Shen, YR
AF Qu, Qiang
   Liang, Hanxue
   Chen, Xiaoming
   Chung, Yuk Ying
   Shen, Yiran
TI NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF
   and Neural View Synthesis Methods
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Perceptual Quality Assessment; Quality of Experience (QoE); Immersive
   Experience; No-Reference Quality Assessment; Novel View Synthesis; 3D
   Reconstruction; Neural Radiance Fields (NeRF)
AB Neural View Synthesis (NVS) has demonstrated efficacy in generating high-fidelity dense viewpoint videos using a image set with sparse views. However, existing quality assessment methods like PSNR, SSIM, and LPIPS are not tailored for the scenes with dense viewpoints synthesized by NVS and NeRF variants, thus, they often fall short in capturing the perceptual quality, including spatial and angular aspects of NVS-synthesized scenes. Furthermore, the lack of dense ground truth views makes the full reference quality assessment on NVS-synthesized scenes challenging. For instance, datasets such as LLFF provide only sparse images, insufficient for complete full-reference assessments. To address the issues above, we propose NeRF-NQA, the first no-reference quality assessment method for densely-observed scenes synthesized from the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment strategy, integrating both viewwise and pointwise approaches, to evaluate the quality of NVS-generated scenes. The viewwise approach assesses the spatial quality of each individual synthesized view and the overall inter-views consistency, while the pointwise approach focuses on the angular qualities of scene surface points and their compound inter-point quality. Extensive evaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality assessment methods (from fields of image, video, and light-field assessment). The results demonstrate NeRF-NQA outperforms the existing assessment methods significantly and it shows substantial superiority on assessing NVS-synthesized scenes without references. An implementation of this paper are available at https://github.com/VincentQQu/NeRF-NQA.
C1 [Qu, Qiang; Chung, Yuk Ying] Univ Sydney, Sch Comp Sci, Sydney, Australia.
   [Liang, Hanxue] Univ Cambridge, Dept Comp Sci & Technol, Cambridge, England.
   [Chen, Xiaoming] Beijing Technol & Business Univ, Sch Comp & Artificial Intelligence, Beijing, Peoples R China.
   [Shen, Yiran] Shandong Univ, Sch Software, Shandong, Peoples R China.
C3 University of Sydney; University of Cambridge; Beijing Technology &
   Business University; Shandong University
RP Shen, YR (corresponding author), Shandong Univ, Sch Software, Shandong, Peoples R China.
EM vincent.qu@sydney.edu.au; hl589@cam.ac.uk; xiaoming.chen@btbu.edu.cn;
   vera.chung@sydney.edu.au; yiran.shen@sdu.edu
OI Chen, Xiaoming/0000-0002-7503-3021; Qu, Qiang/0000-0002-6648-5050; Shen,
   Yiran/0000-0003-1385-1480
FU Beijing Natural Science Foundation
FX No Statement Available
NR 0
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2129
EP 2139
DI 10.1109/TVCG.2024.3372037
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400041
PM 38437095
DA 2024-08-05
ER

PT J
AU Raikwar, A
   Mifsud, D
   Wickens, CD
   Batmaz, AU
   Warden, AC
   Kelley, B
   Clegg, BA
   Ortega, FR
AF Raikwar, Aditya
   Mifsud, Domenick
   Wickens, Christopher D.
   Batmaz, Anil Ufuk
   Warden, Amelia C.
   Kelley, Brendan
   Clegg, Benjamin A.
   Ortega, Francisco R.
TI Beyond the Wizard of Oz: Negative Effects of Imperfect Machine Learning
   to Examine the Impact of Reliability of Augmented Reality Cues on Visual
   Search Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Automation; Reliability; Machine learning; Task analysis;
   Search problems; Resists; Augmented Reality; Visual Search; Automation
   Bias; Imperfect Cues
ID AUTOMATION; TRUST; ALLOCATION; ATTENTION
AB Despite knowing exactly what an object looks like, searching for it in a person's visual field is a time-consuming and error-prone experience. In Augmented Reality systems, new algorithms are proposed to speed up search time and reduce human errors. However, these algorithms might not always provide 100% accurate visual cues, which might affect users' perceived reliability of the algorithm and, thus, search performance. Here, we examined the detrimental effects of automation bias caused by imperfect cues presented in the Augmented Reality head-mounted display using the YOLOv5 machine learning model. 53 participants in the two groups received either 100% accurate visual cues or 88.9% accurate visual cues. Their performance was compared with the control condition, which did not include any additional cues. The results show how cueing may increase performance and shorten search times. The results also showed that performance with imperfect automation was much worse than perfect automation and that, consistent with automation bias, participants were frequently enticed by incorrect cues.
C1 [Raikwar, Aditya; Warden, Amelia C.; Kelley, Brendan; Ortega, Francisco R.] Colorado State Univ, Ft Collins, CO 80523 USA.
   [Mifsud, Domenick] Georgia Inst Technol, Atlanta, GA USA.
   [Wickens, Christopher D.; Batmaz, Anil Ufuk] Concordia Univ, Montreal, PQ, Canada.
   [Clegg, Benjamin A.] Montana State Univ, Bozeman, MT USA.
C3 Colorado State University; University System of Georgia; Georgia
   Institute of Technology; Concordia University - Canada; Montana State
   University System; Montana State University Bozeman
RP Raikwar, A (corresponding author), Colorado State Univ, Ft Collins, CO 80523 USA.
EM adityaraikwar@gmail.com; dmifsud3@gatech.edu;
   chris.wickens@colostate.edu; ufuk.batmaz@concordia.ca;
   acwarden@colostate.edu; brendan.kelley@colostate.edu;
   benjamin.clegg@montana.edu; fortega@colostate.edu
RI Batmaz, Anil Ufuk/ABE-7803-2021
OI Batmaz, Anil Ufuk/0000-0001-7948-8093; Warden, Amelia
   C./0000-0002-8916-1825; Wickens, Christopher/0000-0002-6789-4446; Clegg,
   Benjamin/0000-0001-6026-5076; RAIKWAR, ADITYA/0009-0005-9427-9253
FU NSF
FX No Statement Available
CR Barbotin N, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P213, DOI 10.1109/VR51125.2022.00040
   Bartlett ML, 2017, HUM FACTORS, V59, P881, DOI 10.1177/0018720817700258
   Beyer L, 2020, Arxiv, DOI [arXiv:2006.07159, DOI 10.48550/ARXIV.2006.07159]
   Biocca F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1115
   Bitner MJ, 2002, ACAD MANAGE EXEC, V16, P96, DOI 10.5465/AME.2002.8951333
   Boskemper MM, 2022, HUM FACTORS, V64, P945, DOI 10.1177/0018720820983632
   Chun MM, 2000, TRENDS COGN SCI, V4, P170, DOI 10.1016/S1364-6613(00)01476-5
   Dodge S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017)
   Drury C., 1990, Visual search in industrial inspection
   Goh J., 2005, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V49, P492, DOI [10.1177/154193120504900359, DOI 10.1177/154193120504900359]
   Gramopadhye AK, 2002, INT J IND ERGONOM, V30, P181, DOI 10.1016/S0169-8141(02)00099-9
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Hoff KA, 2015, HUM FACTORS, V57, P407, DOI 10.1177/0018720814547570
   Honda T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00760
   Jocher Glenn, 2022, Zenodo
   Kumaran R, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581413
   LEE J, 1992, ERGONOMICS, V35, P1243, DOI 10.1080/00140139208967392
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Lu WQ, 2014, IEEE T VIS COMPUT GR, V20, P404, DOI 10.1109/TVCG.2013.241
   Mifsud Domenick, 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P2198, DOI 10.1177/1071181322661143
   Phan MT, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1298, DOI 10.1109/ITSC.2016.7795724
   Mosier KL, 1999, HUM FAC ERG SOC P, P344
   NEISSER U, 1964, SCI AM, V210, P94, DOI 10.1038/scientificamerican0664-94
   openfoam, about Us
   Parasuraman R, 2010, HUM FACTORS, V52, P381, DOI 10.1177/0018720810376055
   Patil D. K., 2022, PhD thesis
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Posner MI, 2016, Q J EXP PSYCHOL, V69, P1864, DOI 10.1080/17470218.2014.937446
   Sargent R., 2023, Human-Computer Interaction
   Schemmer M., 2022, On the influence of explainable ai on automation bias
   Seeliger A, 2024, INT J HUM-COMPUT INT, V40, P761, DOI 10.1080/10447318.2022.2122114
   Shneiderman B, 2021, ISSUES SCI TECHNOL, V37, P56
   shop.mattel, Mega bloks
   store.opencv, Oak-1
   Syiem BV., 2021, C HUMAN FACTORS COMP, DOI DOI 10.1145/3411764.3445580
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   varjo, Varjo xr-3
   Warden Amelia C., 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P373, DOI 10.1177/1071181322661260
   Warden AC, 2023, IEEE T HUM-MACH SYST, V53, P1061, DOI 10.1109/THMS.2023.3302152
   Wickens C. D., 2023, Applied attention theory
   Wolfe JM, 2021, PSYCHON B REV, V28, P1060, DOI 10.3758/s13423-020-01859-9
   Wu Chia-Chien, 2019, Vision (Basel), V3, DOI 10.3390/vision3020032
   Yantis S., 1993, CURR DIR PSYCHOL SCI, V2, P156
   Yeh M, 2001, HUM FACTORS, V43, P355, DOI 10.1518/001872001775898269
   Yeh M, 2003, HUM FACTORS, V45, P390, DOI 10.1518/hfes.45.3.390.27249
   Yeh M, 1999, HUM FACTORS, V41, P524, DOI 10.1518/001872099779656752
NR 47
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2662
EP 2670
DI 10.1109/TVCG.2024.3372062
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400048
PM 38437133
DA 2024-08-05
ER

PT J
AU Li, CL
   Gao, Y
   He, JY
   Cheng, TW
   Li, S
   Hao, AM
   Qin, H
AF Li, Chunlei
   Gao, Yang
   He, Jiayi
   Cheng, Tianwei
   Li, Shuai
   Hao, Aimin
   Qin, Hong
TI A Unified Particle-Based Solver for Non-Newtonian Behaviors Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deformable solid; non-newtonian material; physically based animation;
   SPH; viscous fluid
ID SPH; FLUIDS; MODEL
AB In this article, we present a unified framework to simulate non-Newtonian behaviors. We combine viscous and elasto-plastic stress into a unified particle solver to achieve various non-Newtonian behaviors ranging from fluid-like to solid-like. Our constitutive model is based on a Generalized Maxwell model, which incorporates viscosity, elasticity and plasticity in one non-linear framework by a unified way. On the one hand, taking advantage of the viscous term, we construct a series of strain-rate dependent models for classical non-Newtonian behaviors such as shear-thickening, shear-thinning, Bingham plastic, etc. On the other hand, benefiting from the elasto-plastic model, we empower our framework with the ability to simulate solid-like non-Newtonian behaviors, i.e., visco-elasticity/plasticity. In addition, we enrich our method with a heat diffusion model to make our method flexible in simulating phase change. Through sufficient experiments, we demonstrate a wide range of non-Newtonian behaviors ranging from viscous fluid to deformable objects. We believe this non-Newtonian model will enhance the realism of physically-based animation, which has great potential for computer graphics.
C1 [Li, Chunlei; Gao, Yang; He, Jiayi; Cheng, Tianwei; Li, Shuai; Hao, Aimin] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Li, Chunlei; Gao, Yang; He, Jiayi; Cheng, Tianwei] Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg, 2019RU004, Beijing 100050, Peoples R China.
   [Li, Shuai; Hao, Aimin] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Li, Shuai] Zhongguancun Lab, Beijing 100094, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, 2424 USA, New York, NY 11794 USA.
C3 Beihang University; Chinese Academy of Medical Sciences - Peking Union
   Medical College; Peng Cheng Laboratory; Zhongguancun Laboratory; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Gao, Y (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.; Gao, Y (corresponding author), Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg, 2019RU004, Beijing 100050, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Dept Comp Sci, 2424 USA, New York, NY 11794 USA.
EM li_cl@foxmail.com; gaoyangvr@buaa.edu.cn; jiayihe1104@gmail.com;
   ctw@buaa.edu.cn; lishuaiouc@126.com; ham@buaa.edu.cn;
   qin@cs.stonybrook.edu
RI Gao, Yang/JQV-9627-2023
OI Gao, Yang/0000-0002-9149-3554; He, Jiayi/0009-0000-8202-0520
FU National Key R#x0026;D Program of China
FX No Statement Available
CR Bargteil Adam W., 2007, ACM Transactions on Graphics, V26, P1, DOI 10.1145/1276377.1276397
   Batty C., 2008, S COMP AN, P219
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   BOTTIGLIERI P, 1991, J FOOD QUALITY, V14, P497, DOI 10.1111/j.1745-4557.1991.tb00089.x
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   Chhabra RP, 2010, RHEOLOGY OF COMPLEX FLUIDS, P3, DOI 10.1007/978-1-4419-6494-6_1
   Cleary PW, 1999, J COMPUT PHYS, V148, P227, DOI 10.1006/jcph.1998.6118
   CROSS MM, 1965, J COLL SCI IMP U TOK, V20, P417, DOI 10.1016/0095-8522(65)90022-X
   Andrade LFD, 2015, COMPUT GRAPH-UK, V52, P106, DOI 10.1016/j.cag.2015.07.021
   Fang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322968
   Fujisawa M, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P249
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201309
   Gao Y, 2021, IEEE T VIS COMPUT GR, V27, P4483, DOI 10.1109/TVCG.2021.3107597
   Gao Y, 2019, VISUAL COMPUT, V35, P1741, DOI 10.1007/s00371-018-1569-8
   Gao Y, 2017, GRAPH MODELS, V94, P14, DOI 10.1016/j.gmod.2017.09.001
   Gissler C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392431
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Goldade R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322939
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Koschier D., 2019, PROC EUROGRAPHICS, P1
   Koschier D, 2022, COMPUT GRAPH FORUM, V41, P737, DOI 10.1111/cgf.14508
   Larionov E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073628
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Markus Becker, 2009, Nph, V9, P27, DOI DOI 10.2312/EG/DL/CONF/EG2009/NPH/027-034
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2004, P 2004 ACM SIGGRAPH, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Orthmann J, 2012, COMPUT GRAPH FORUM, V31, P2436, DOI 10.1111/j.1467-8659.2012.03186.x
   Ozgen O, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1870
   Peer A, 2017, IEEE T VIS COMPUT GR, V23, P2656, DOI 10.1109/TVCG.2016.2636144
   Peer A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766925
   Phan Thien N., 2017, Understanding Viscoelasticity: An Introduction to Rheology, P95
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Shao H, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530109
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Stomakhin A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601176
   Stora D, 1999, PROC GRAPH INTERF, P203
   Su HZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459820
   Takahashi T, 2015, COMPUT GRAPH FORUM, V34, P493, DOI 10.1111/cgf.12578
   Terzopoulos D., 1991, Journal of Visualization and Computer Animation, V2, P68, DOI 10.1002/vis.4340020208
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Wojtan C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360646
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
   Zhu B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766981
NR 49
TC 0
Z9 0
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1998
EP 2010
DI 10.1109/TVCG.2023.3341453
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500002
PM 38090860
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Batch, A
   Butcher, PWS
   Ritsos, PD
   Elmqvist, N
AF Batch, Andrea
   Butcher, Peter W. S.
   Ritsos, Panagiotis D.
   Elmqvist, Niklas
TI Wizualization: A "Hard Magic" Visualization System for Immersive and
   Ubiquitous Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Immersive analytics; situated analytics; ubiquitous analytics; gestural
   interaction; voice interaction
ID HAND; MANIPULATION; EXPLORATION; INTERFACE; GESTURES; GRAMMAR; SPEECH;
   VEGA
AB What if magic could be used as an effective metaphor to perform data visualization and analysis using speech and gestures while mobile and on-the-go? In this paper, we introduce Wizualization, a visual analytics system for eXtended Reality (XR) that enables an analyst to author and interact with visualizations using such a magic system through gestures, speech commands, and touch interaction. Wizualization is a rendering system for current XR headsets that comprises several components: a cross-device (or Arcane Focuses) infrastructure for signalling and view control (Weave), a code notebook (Spellbook), and a grammar of graphics for XR (Optomancy). The system offers users three modes of input: gestures, spoken commands, and materials. We demonstrate Wizualization and its components using a motivating scenario on collaborative data analysis of pandemic data across time and space.
C1 [Batch, Andrea] US Bur Econ Anal, Washington, DC 20233 USA.
   [Butcher, Peter W. S.; Ritsos, Panagiotis D.] Bangor Univ, Bangor, Wales.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
   [Elmqvist, Niklas] Univ Maryland, College Pk, MD USA.
C3 Bangor University; Aarhus University; University System of Maryland;
   University of Maryland College Park
RP Batch, A (corresponding author), US Bur Econ Anal, Washington, DC 20233 USA.
EM andrea.c.batch@gmail.com; p.butcher@bangor.ac.uk; p.ritsos@bangor.ac.uk;
   elm@cs.au.dk
OI Butcher, Peter/0000-0002-3361-627X; Ritsos,
   Panagiotis/0000-0001-9308-3885; Elmqvist, Niklas/0000-0001-5805-5301
FU U.S. National Science Foundation
FX No Statement Available
CR Ahlberg C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P619, DOI 10.1145/142750.143054
   [Anonymous], 1986, User Centered System Design: New Perspectives on Human-Computer Interaction
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Badam S. K., 2017, PROC IEEE VIS WORKSH
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Batch A, 2023, COMPUT GRAPH FORUM, V42, P349, DOI 10.1111/cgf.14835
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Berndt D.J., 1994, P 3 INT C KNOWL DISC
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Buschel W., 2021, PROC ACM CHI, DOI [10.1145/3411764.34456512, DOI 10.1145/3411764.34456512]
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Chin-Shyurng F, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030528
   Clarke A. C., 1972, Profiles of the Future: An Inquiry Into the Limits of the Possible, P1
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Csikszentmihalyi M., 1991, Flow: The Psychology of Optimal Experience, P2
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Elmqvist N, 2013, COMPUTER, V46, P86, DOI 10.1109/MC.2013.147
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Elmqvist N, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1769
   Fennedy K, 2021, IEEE T VIS COMPUT GR, V27, P4425, DOI 10.1109/TVCG.2021.3101854
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Hall BD, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545614
   HAUPTMANN AG, 1993, INT J MAN MACH STUD, V38, P231, DOI 10.1006/imms.1993.1011
   He SZ, 2015, IEEE INT CONF INF VI, P83, DOI 10.1109/iV.2015.25
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Jang SJ, 2016, IEEE T VIS COMPUT GR, V22, P21, DOI 10.1109/TVCG.2015.2468292
   Kallio S., 2006, PROC ACM AVI, P480, DOI [10.1145/1133265.1133363, DOI 10.1145/1133265.1133363]
   Keefe DF, 2008, IEEE T VIS COMPUT GR, V14, P835, DOI 10.1109/TVCG.2008.31
   Kim C, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P319, DOI 10.1145/3343055.3360742
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Ledo D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173610
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee B, 2012, IEEE T VIS COMPUT GR, V18, P2689, DOI 10.1109/TVCG.2012.204
   Li HH, 2020, INFORM SCIENCES, V534, P97, DOI 10.1016/j.ins.2020.04.009
   Liao J, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545702
   Lobo Maria Jesus, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427323
   Luo YQ, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369458
   Maguire E, 2013, IEEE T VIS COMPUT GR, V19, P2576, DOI 10.1109/TVCG.2013.225
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   Marriott Kim, 2018, Lecture Notes in Computer Science, DOI DOI 10.1007/978-3-030-01388-2
   McCormack J, 2018, LECT NOTES COMPUT SC, V11190, P57, DOI 10.1007/978-3-030-01388-2_3
   Muller M., 2007, Information Retrieval for Music and Motion, DOI [10.1007/978-3-540-74048-3, DOI 10.1007/978-3-540-74048-3_4]
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Nebeling M., 2020, PROC ACM CHI, P1
   Nielsen M, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010951
   Norman D.A., 2010, interactions, V17, P6, DOI DOI 10.1145/1744161.1744163
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   Reipschläger P, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383138
   Roberts JC, 2014, IEEE COMPUT GRAPH, V34, P26, DOI 10.1109/MCG.2014.82
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Sanderson B., Sanderson's first law of magics
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schroeder D, 2016, IEEE T VIS COMPUT GR, V22, P877, DOI 10.1109/TVCG.2015.2467153
   Shin S, 2024, IEEE T VIS COMPUT GR, V30, P5147, DOI 10.1109/TVCG.2023.3285546
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Thomas BH, 2018, LECT NOTES COMPUT SC, V11190, P185, DOI 10.1007/978-3-030-01388-2_7
   W3C, 2017, WebXR
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wagner J, 2021, IEEE T VIS COMPUT GR, V27, P2513, DOI 10.1109/TVCG.2021.3067759
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L., 1999, The Grammar of Graphics, P3
   Willett W, 2022, IEEE T VIS COMPUT GR, V28, P22, DOI 10.1109/TVCG.2021.3114844
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 82
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 507
EP 517
DI 10.1109/TVCG.2023.3326580
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500054
PM 37874715
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Feng, YCJ
   Wang, XB
   Wong, KK
   Wang, SJ
   Lu, YH
   Zhu, MF
   Wang, BC
   Chen, W
AF Feng, Yingchaojie
   Wang, Xingbo
   Wong, Kam Kwai
   Wang, Sijia
   Lu, Yuhong
   Zhu, Minfeng
   Wang, Baicheng
   Chen, Wei
TI PromptMagician: Interactive Prompt Engineering for Text-to-Image
   Creation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Semantics; Interviews; Task analysis; Electronic mail;
   Computational modeling; Natural language processing; Prompt engineering;
   text-to-image generation; image visualization
ID MODELS
AB Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts. However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language. This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts. The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords. To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration. Two usage scenarios, a user study, and expert interviews demonstrate the effectiveness and usability of our system, suggesting it facilitates prompt engineering and improves the creativity support of the generative text-to-image model.
C1 [Feng, Yingchaojie] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Lab Artand Archaeol Image, Minist Educ, Zhejiang, Peoples R China.
   [Wang, Xingbo; Wong, Kam Kwai] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wang, Sijia; Zhu, Minfeng] Zhejiang Univ, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University; Hong Kong University of
   Science & Technology; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, Lab Artand Archaeol Image, Minist Educ, Zhejiang, Peoples R China.
EM fycj@zju.edu.cn; xwangeg@connect.ust.hk; wangbaicheng@zju.edu.cn;
   sijiawang@zju.edu.cn; luyuhong@zju.edu.cn; minfeng_zhu@zju.edu.cn;
   kkwongar@connect.ust.hk; chenvis@zju.edu.cn
OI Chen, Wei/0000-0002-8365-4741; Feng, Yingchaojie/0000-0002-1418-4635;
   WONG, Kam Kwai/0000-0002-2813-1972; Zhu, Minfeng/0000-0002-6711-3099
FU National Natural Science Foundation of China
FX No Statement Available
CR Achlioptas P, 2021, PROC CVPR IEEE, P11564, DOI 10.1109/CVPR46437.2021.01140
   Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425
   Bird S., 2009, arXiv, DOI DOI 10.48550/ARXIV.CS/0205028
   Brown T. B., 2020, P 34 INT C NEURAL IN, P1
   Büring T, 2006, IEEE T VIS COMPUT GR, V12, P829
   Chambon P, 2022, Arxiv, DOI arXiv:2210.04133
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen ZT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1109/TENCON55691.2022.9978005, 10.1145/3491102.3517485]
   Cheon M, 2021, IEEE COMPUT SOC CONF, P433, DOI 10.1109/CVPRW53098.2021.00054
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P3813, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Feng YCJ, 2022, J VISUAL-JAPAN, V25, P671, DOI 10.1007/s12650-021-00780-0
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Hao Y., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.09611
   He JB, 2023, Arxiv, DOI arXiv:2308.00401
   Ho J., 2020, Adv. Neural. Inf. Process. Syst, V33, P6840, DOI DOI 10.48550/ARXIV.2006.11239
   Ho JAT, 2022, Arxiv, DOI [arXiv:2210.02303, DOI 10.48550/ARXIV.2210.02303]
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045
   Liang P. P., 2022, P ICLR
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Liu V, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545621
   Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825
   Longabaugh WJR, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-275
   Luca FD, 2019, Arxiv, DOI arXiv:1906.05996
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   MacQueen J., 1967, 5 BERKELEY S MATH ST, P4
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   OpenAI, 2023, GPT-4 technical report, P2303
   Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988
   Ouyang L., 2022, arXiv
   Pan XG, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591500
   Panda R, 2018, LECT NOTES COMPUT SC, V11206, P594, DOI 10.1007/978-3-030-01216-8_36
   Perlin K., 1993, Computer Graphics Proceedings, P57, DOI 10.1145/166117.166125
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, Hierarchical text-conditional image generation with clip latents, DOI 10.48550/arXiv.2204.06125
   Ramesh P, 2022, 38 INT C MACHINE LEA
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song J., 2021, INT C LEARN REPR, DOI [10.48550/arXiv.2010.02502, DOI 10.48550/ARXIV.2010.02502]
   Sparck-Jones K, 2004, J DOC, V60, P493, DOI [10.1108/00220410410560573, 10.1108/eb026526]
   Srinivasan A, 2020, IEEE COMPUT GRAPH, V40, P96, DOI 10.1109/MCG.2020.2986902
   Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang J., 2022, PROC AAAI, DOI [10.48550/arXiv.2207.123966, DOI 10.48550/ARXIV.2207.123966]
   Wang XB, 2022, Arxiv, DOI arXiv:2201.04868
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang XM, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-023-2691-y
   Wang YL, 2023, Arxiv, DOI arXiv:2302.09466
   Wang ZJ, 2022, Arxiv, DOI [arXiv:2210.14896, DOI 10.48550/ARXIV.2210.14896]
   Weng LX, 2023, Arxiv, DOI arXiv:2304.05011
   Wong K. K., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32456092, DOI 10.1109/TVCG.2023.32456092]
   Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zeng HP, 2023, IEEE T VIS COMPUT GR, V29, P3685, DOI 10.1109/TVCG.2022.3169175
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2023, Arxiv, DOI [arXiv:2302.05543, 10.48550/ARXIV.2302.05543]
   Zhang W, 2023, Arxiv, DOI arXiv:2307.14227
   Zhang W, 2024, Arxiv, DOI arXiv:2306.08834
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhou JH, 2023, IEEE T VIS COMPUT GR, V29, P809, DOI 10.1109/TVCG.2022.3209391
   Zhu HY, 2021, VIS INFORM, V5, P51, DOI 10.1016/j.visinf.2021.06.002
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 77
TC 5
Z9 5
U1 26
U2 30
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 295
EP 305
DI 10.1109/TVCG.2023.3327168
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500102
PM 37878445
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Gao, L
   Shao, ZK
   Luo, ZQ
   Hu, HB
   Turkay, C
   Chen, SM
AF Gao, Lin
   Shao, Zekai
   Luo, Ziqin
   Hu, Haibo
   Turkay, Cagatay
   Chen, Siming
TI TransforLearn: Interactive Visual Tutorial for the Transformer Model
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deep learning; Transformer; Visual tutorial; Explorable explanations
ID NEURAL-NETWORKS
AB The widespread adoption of Transformers in deep learning, serving as the core framework for numerous large-scale language models, has sparked significant interest in understanding their underlying mechanisms. However, beginners face difficulties in comprehending and learning Transformers due to its complex structure and abstract data representation. We present TransforLearn, the first interactive visual tutorial designed for deep learning beginners and non-experts to comprehensively learn about Transformers. TransforLearn supports interactions for architecture-driven exploration and task-driven exploration, providing insight into different levels of model details and their working processes. It accommodates interactive views of each layer's operation and mathematical formula, helping users to understand the data flow of long text sequences. By altering the current decoder-based recursive prediction results and combining the downstream task abstractions, users can deeply explore model processes. Our user study revealed that the interactions of TransforLearn are positively received. We observe that TransforLearn facilitates users' accomplishment of study tasks and a grasp of key concepts in Transformer effectively.
C1 [Gao, Lin; Shao, Zekai; Luo, Ziqin; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Gao, Lin; Shao, Zekai; Luo, Ziqin; Chen, Siming] Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
   [Hu, Haibo] Chongqing Univ, Chongqing, Peoples R China.
   [Turkay, Cagatay] Univ Warwick, Warwick, England.
C3 Fudan University; Chongqing University; University of Warwick
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.; Chen, SM (corresponding author), Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM leenagao0430@gmail.com; haibo.hu@cqu.edu.cn;
   Cagatay.Turkay@warwick.ac.uk; simingchen@fudan.edu.cn
OI Turkay, Cagatay/0000-0001-6788-251X; Gao, Lin/0009-0004-1613-1774
FU Natural Science Foundation of China (NSFC)
FX No Statement Available
CR Abnar S., 2019, From attention in transformers to dynamic routing in capsule nets
   Alammar J., 2022, The illustrated retrieval transformer
   Alammar J., 2019, A visual guide to using bert for the first time
   Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, 10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Bertviz J. Vig., 2019, ICLR WORKSHOP DEBUGG, DOI [10.18653/v1/.D17-2021, DOI 10.18653/V1/.D17-2021]
   Biggs J. B., 1982, EVALUATING QUALITY L
   Bloem Peter., 2019, Transformers from scratch
   Brasoveanu AMP, 2020, IEEE INT CONF INF VI, P270, DOI 10.1109/IV51561.2020.00051
   Bruce G. S., 2004, Evidence-Based Educational Methods, Educational Psychology, P267, DOI [10.1016/B978-012506041-7/50016-4, DOI 10.1016/B978-012506041-7/50016-4]
   CodeEmporium, 2022, Transformer neural networks-explained! (attention is all you need)
   Coenen A, 2019, Arxiv, DOI arXiv:1906.02715
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   DeRose JF, 2020, Arxiv, DOI arXiv:2009.07053
   Guan Chaoyu, 2019, INT C MACH LEARN, P2454
   Gunning D., 2016, Technical report
   H. NLP, 2018, The annotated transformer
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hundhausen CD, 2002, J VISUAL LANG COMPUT, V13, P259, DOI 10.1006/S1045-926X(02)00028-9
   Jin ZH, 2024, IEEE T VIS COMPUT GR, V30, P3594, DOI 10.1109/TVCG.2023.3236380
   Kahng M., 2019, IEEE VIS 2019 WORKSH
   Kahng M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P266, DOI 10.1109/VIS47514.2020.00060
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Li Yixuan, 2023, IEEE Trans Vis Comput Graph, V29, P95, DOI 10.1109/TVCG.2022.3209461
   Li Z, 2022, Arxiv, DOI [arXiv:2206.09355, 10.48550/ARXIV.2206.09355, DOI 10.48550/ARXIV.2206.09355]
   Lin Y., 2021, AI open, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001
   Liu DY, 2018, Arxiv, DOI [arXiv:1808.08531, 10.48550/ARXIV.1808.08531, DOI 10.48550/ARXIV.1808.08531]
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, Arxiv, DOI arXiv:1702.01226
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, DOI 10.48550/ARXIV.1511.08458]
   Olah C., 2020, Olah's blogs
   Ouyang L., 2022, arXiv
   Radford, 2018, OPENAI BLOG
   Radford A., 2019, OpenAI blog, V1, P9
   Seifert C, 2017, STUD BIG DATA, V32, P123, DOI 10.1007/978-3-319-54024-5_6
   Shao ZK, 2024, IEEE T VIS COMPUT GR, V30, P3779, DOI 10.1109/TVCG.2023.3243676
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Skrlj B, 2020, Arxiv, DOI arXiv:2005.05716
   Smilkov D, 2017, Arxiv, DOI arXiv:1708.03788
   Strobelt H, 2017, Arxiv, DOI arXiv:1606.07461
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang JH, 2023, IEEE T VIS COMPUT GR, V29, P5033, DOI 10.1109/TVCG.2022.3201101
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang Zijian, 2021, CORR
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2018, IEEE T VIS COMPUT GR, V24, P236, DOI 10.1109/TVCG.2017.2744098
   Yang ZL, 2019, ADV NEUR IN, V32
   Yosinski J, 2015, Arxiv, DOI arXiv:1506.06579
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yuan J, 2020, Arxiv, DOI [arXiv:2008.09632, 10.48550/ARXIV.2008.09632, DOI 10.48550/ARXIV.2008.09632]
   Zhao Yuheng, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579473
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
NR 62
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 891
EP 901
DI 10.1109/TVCG.2023.3327353
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500097
PM 37883278
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Giovannangeli, L
   Lalanne, F
   Giot, R
   Bourqui, R
AF Giovannangeli, Loann
   Lalanne, Frederic
   Giot, Romain
   Bourqui, Romain
TI Guaranteed Visibility in Scatterplots with Tolerance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Guaranteed visibility; Layout adjustment; Overlap removal; Scatterplots
ID LAYOUT ADJUSTMENT; OVERLAP REMOVAL; ALGORITHM
AB In 2D visualizations, visibility of every datum's representation is crucial to ease the completion of visual tasks. Such a guarantee is barely respected in complex visualizations, mainly because of overdraws between datum representations that hide parts of the information (e.g., outliers). The literature proposes various Layout Adjustment algorithms to improve the readability of visualizations that suffer from this issue. Manipulating the data in high-dimensional, geometric or visual space; they rely on different strategies with their own strengths and weaknesses. Moreover, most of these algorithms are computationally expensive as they search for an exact solution in the geometric space and do not scale well to large datasets. This article proposes GIST, a layout adjustment algorithm that aims at optimizing three criteria: (i) node visibility guarantee (at least 1 pixel), (ii) node size maximization, and (iii) the original layout preservation. This is achieved by combining a search for the maximum node size that enables to draw all the data points without overlaps, with a limited budget of movements (i.e., limiting the distortions of the original layout). The method's basis relies on the idea that it is not necessary for two data representations to be strictly not overlapping in order to guarantee their visibility in visual space. Our algorithm therefore uses a tolerance in the geometric space to determine the overlaps between pairs of data. The tolerance is optimized such that the approximation computed in the geometric space can lead to visualization without noticeable overdraw after the data rendering rasterization. In addition, such an approximation helps to ease the algorithm's convergence as it reduces the number of constraints to resolve, enabling it to handle large datasets. We demonstrate the effectiveness of our approach by comparing its results to those of state-of-the-art methods on several large datasets.
C1 [Giovannangeli, Loann; Lalanne, Frederic; Giot, Romain; Bourqui, Romain] Univ Bordeaux, LaBRI, CNRS, Bordeaux INP,UMR 5800,INRIA, Talence, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS); Inria
RP Giovannangeli, L (corresponding author), Univ Bordeaux, LaBRI, CNRS, Bordeaux INP,UMR 5800,INRIA, Talence, France.
EM loann.giovannangeli@u-bordeaux.fr; frederic.lalanne@u-bordeaux.fr;
   romain.giot@u-bordeaux.fr; romain.bourqui@u-bordeaux.fr
OI Giovannangeli, Loann/0000-0002-9395-6495; Giot,
   Romain/0000-0002-0638-7504
FU ANR
FX No Statement Available
CR Bertini E, 2004, IEEE INFOR VIS, P622, DOI 10.1109/IV.2004.1320207
   Brandes U, 2009, LECT NOTES COMPUT SC, V5417, P218, DOI 10.1007/978-3-642-00219-9_21
   Chen F., 2020, J. Graph Algorithms Appl., V24, P683, DOI [10.7155/jgaa.00532, DOI 10.7155/JGAA.00532]
   Chen FT, 2019, LECT NOTES COMPUT SC, V11904, P179, DOI 10.1007/978-3-030-35802-0_14
   Chen X, 2020, IEEE T VIS COMPUT GR, V26, P729, DOI 10.1109/TVCG.2019.2934541
   Cutura Rene, 2021, VINCI 2021: The 14th International Symposium on Visual Information Communication and Interaction, DOI 10.1145/3481549.3481569
   Dwyer T, 2006, LECT NOTES COMPUT SC, V3843, P153
   Dwyer T, 2007, LECT NOTES COMPUT SC, V4372, P446
   Gansner E., 2010, J. Graph Algorithms Appl., V14, P53
   Giovannangeli L., 2023, Guaranteed Visibility in Scatterplots with Tolerance
   Giovannangeli L, 2023, LECT NOTES COMPUT SC, V13764, P61, DOI 10.1007/978-3-031-22203-0_6
   Gomez Tristan, 2022, Pattern Recognition and Artificial Intelligence: Third International Conference, ICPRAI 2022, Proceedings, Part I. Lecture Notes in Computer Science (13363), P84, DOI 10.1007/978-3-031-09037-0_8
   Halnaut A, 2022, IEEE INT CONF INF VI, P11, DOI 10.1109/IV56949.2022.00012
   Hayashi K, 1998, LECT NOTES COMPUT SC, V1547, P183
   Hilasaca GM, 2021, Arxiv, DOI arXiv:1903.06262
   Huang XD, 2007, INFORM SCIENCES, V177, P2821, DOI 10.1016/j.ins.2007.02.016
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kruskal JB., 1978, Multidimensional Scaling, DOI DOI 10.4135/9781412985130
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Zeyu, 2023, IEEE Trans Vis Comput Graph, V29, P657, DOI 10.1109/TVCG.2022.3209459
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Meulemans W, 2019, COMPUT GRAPH FORUM, V38, P713, DOI 10.1111/cgf.13722
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Nachmanson L., 2007, Microsoft Automatic Graph Layout
   Nachmanson L, 2016, LECT NOTES COMPUT SC, V9801, P33, DOI 10.1007/978-3-319-50106-2_3
   Ortmann M, 2016, LECT NOTES COMPUT SC, V9801, P18, DOI 10.1007/978-3-319-50106-2_2
   Strobelt H, 2012, COMPUT GRAPH FORUM, V31, P1135, DOI 10.1111/j.1467-8659.2012.03106.x
   Strong G, 2014, IEEE T MULTIMEDIA, V16, P1045, DOI 10.1109/TMM.2014.2306183
   Van Der Maaten L., 2009, Technical report, P5
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wei LY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778816
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 40
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 792
EP 802
DI 10.1109/TVCG.2023.3326596
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500080
PM 37871063
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hoque, MN
   Elmqvist, N
AF Hoque, Md Naimul
   Elmqvist, Niklas
TI Dataopsy: Scalable and Fluid Visual Exploration using Aggregate Query
   Sculpting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multidimensional data visualization; multivariate graphs; visual
   queries; visual exploration
ID TABULAR DATA; VISUALIZATION; SEARCH
AB We present aggregate query sculpting (AQS), a faceted visual query technique for large-scale multidimensional data. As a "born scalable" query technique, AQS starts visualization with a single visual mark representing an aggregation of the entire dataset. The user can then progressively explore the dataset through a sequence of operations abbreviated as P6: pivot (facet an aggregate based on an attribute), partition (lay out a facet in space), peek (see inside a subset using an aggregate visual representation), pile (merge two or more subsets), project (extracting a subset into a new substrate), and prune (discard an aggregate not currently of interest). We validate AQS with Dataopsy, a prototype implementation of AQS that has been designed for fluid interaction on desktop and touch-based mobile devices. We demonstrate AQS and Dataopsy using two case studies and three application examples.
C1 [Hoque, Md Naimul; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
C3 University System of Maryland; University of Maryland College Park;
   Aarhus University
RP Hoque, MN (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM nhoque@umd.edu; elm@cs.au.dk
FU U.S. National Science Foundation
FX No Statement Available
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P365, DOI 10.1145/191666.191790
   Aris A., 2007, Information Visualization, V6, P281, DOI [10.1057/palgrave.ivs.95001622,3, DOI 10.1057/PALGRAVE.IVS.95001622,3, DOI 10.1057/palgrave.ivs.9500162]
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411-35/SUS-QUICK-DIRTY-USABILITY-SCALE-JOHN-BROOKE
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Choi J, 2015, IEEE T VIS COMPUT GR, V21, P1087, DOI 10.1109/TVCG.2015.2414454
   Csikszentmihalyi M., 1991, Flow: The Psychology of Optimal Experience, P3
   Dachselt R, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1353
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Drucker S., 2015, Technical Report MSR-TR-2015-65, P2
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Ghai B, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P3082, DOI 10.1145/3511808.3557155
   Ghai Bhavya, 2023, IEEE Trans Vis Comput Graph, V29, P473, DOI 10.1109/TVCG.2022.3209484
   Ghani S, 2013, IEEE T VIS COMPUT GR, V19, P2032, DOI 10.1109/TVCG.2013.223
   Google People + AI Research, Facets-visualization for ML datasets
   Harrison C, 2010, COMPUTER, V43, P86, DOI 10.1109/MC.2010.158
   Hart SG., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Javed W, 2013, COMPUT GRAPH FORUM, V32, P441, DOI 10.1111/cgf.12131
   Kairam S, 2015, COMPUT GRAPH FORUM, V34, P301, DOI 10.1111/cgf.12642
   Kumar S, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P933, DOI 10.1145/3178876.3186141
   Lee B., 2021, AK Peters Visulization Series, P1
   Lee B, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1293
   Liu ZC, 2014, INFORM VISUAL, V13, P59, DOI 10.1177/1473871613488591
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Munzner T., 2014, AK Peters Visualization Series, P2
   New York City Taxi & Limousine Commission, 2023, TLC trip record data
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Norman D. A., 1986, User Centered System Design: New Perspectives on Human-Computer Interaction, P3
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Pandey Aditeya, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209421
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Rosario G. E., 2004, Information Visualization, V3, P80, DOI 10.1057/palgrave.ivs.9500072
   Sarvghad A, 2023, IEEE T VIS COMPUT GR, V29, P3340, DOI 10.1109/TVCG.2022.3158236
   Seo J, 2002, COMPUTER, V35, P80
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Shneiderman B, 2006, IEEE T VIS COMPUT GR, V12, P733, DOI 10.1109/TVCG.2006.166
   Smith G, 2006, IEEE T VIS COMPUT GR, V12, P797, DOI 10.1109/TVCG.2006.142
   Stolte C, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P5, DOI 10.1109/INFVIS.2000.885086
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wexler J., Facets: An open source visualization tool for machine learning training data
   WILLIAMSON C, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P338
   Yalçin MA, 2016, IEEE T VIS COMPUT GR, V22, P688, DOI 10.1109/TVCG.2015.2467051
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yee K.-P., 2003, P SIGCHI C HUM FACT, P401, DOI DOI 10.1145/642611.642681
   Zhang ZY, 2012, IEEE PAC VIS SYMP, P17
NR 54
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 186
EP 196
DI 10.1109/TVCG.2023.3326594
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500125
PM 37871052
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Pérez-Messina, I
   Ceneda, D
   Miksch, S
AF Perez-Messina, Ignacio
   Ceneda, Davide
   Miksch, Silvia
TI Guided Visual Analytics for Image Selection in Time and Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Application Motivated Visualization; Geospatial Data; Mixed Initiative
   Human-Machine Analysis; Process/Workflow Design; Task Abstractions &
   Application Domains; Temporal Data
ID INTERACTIVE OPTIMIZATION; GUIDANCE; TASKS; TYPOLOGY
AB Unexploded Ordnance (UXO) detection, the identification of remnant active bombs buried underground from archival aerial images, implies a complex workflow involving decision-making at each stage. An essential phase in UXO detection is the task of image selection, where a small subset of images must be chosen from archives to reconstruct an area of interest (AOI) and identify craters. The selected image set must comply with good spatial and temporal coverage over the AOI, particularly in the temporal vicinity of recorded aerial attacks, and do so with minimal images for resource optimization. This paper presents a guidance-enhanced visual analytics prototype to select images for UXO detection. In close collaboration with domain experts, our design process involved analyzing user tasks, eliciting expert knowledge, modeling quality metrics, and choosing appropriate guidance. We report on a user study with two real-world scenarios of image selection performed with and without guidance. Our solution was well-received and deemed highly usable. Through the lens of our task-based design and developed quality measures, we observed guidance-driven changes in user behavior and improved quality of analysis results. An expert evaluation of the study allowed us to improve our guidance-enhanced prototype further and discuss new possibilities for user-adaptive guidance.
C1 [Perez-Messina, Ignacio; Ceneda, Davide; Miksch, Silvia] TU Wien, Vienna, Austria.
C3 Technische Universitat Wien
RP Pérez-Messina, I (corresponding author), TU Wien, Vienna, Austria.
EM ignacio.messina@tuwien.ac.at; davide.ceneda@tuwien.ac.at;
   silvia.miksch@tuwien.ac.at
FU Vienna Science and Technology Fund (WWTF)
FX No Statement Available
CR Abuzuraiq A. M., 2020, RE ANTHROPOCENE PROC, V1, P485, DOI DOI 10.52842/CONF.CAADRIA.2020.1.4852
   Amor-Amoros A., 2017, EUROVA EUROVIS, P55, DOI [10.2312/eurova.20171120, DOI 10.2312/EUROVA.20171120]
   Bao F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461977
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cibulski L, 2022, 2022 IEEE 4TH WORKSHOP ON VISUALIZATION GUIDELINES IN RESEARCH, DESIGN, AND EDUCATION (VISGUIDES 2022), P8, DOI 10.1109/VisGuides57787.2022.00007
   Dayama NR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376553
   de Luz Palomino Valdivia F., 2023, ADV INFORM COMMUNICA, V1, P391, DOI [10.1007/978-3-031-28076-4_29, DOI 10.1007/978-3-031-28076-4_29]
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Federico P, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P104, DOI 10.1145/2993901.2993915
   Horn B, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P277
   Ip CY, 2011, IEEE T VIS COMPUT GR, V17, P1737, DOI 10.1109/TVCG.2011.231
   Khan S, 2019, OCEAN ENG, V191, DOI 10.1016/j.oceaneng.2019.106462
   Koyama Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392444
   Liu J., 2022, ACM Transactions on Computer-Human Interaction, DOI [10.1145/35034617,9, DOI 10.1145/35034617,9]
   Liu J, 2021, IEEE T VIS COMPUT GR, V27, P1764, DOI 10.1109/TVCG.2020.3030364
   Liu J, 2018, IEEE T VIS COMPUT GR, V24, P319, DOI 10.1109/TVCG.2017.2744418
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Perez-Messina I, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14555
   Perez-Messina I., 2023, A Methodology for TaskDriven Guidance Design, DOI [10.2312/eurova.202310943,4,9, DOI 10.2312/EUROVA.202310943,4,9]
   Puchinger J, 2010, INFORMS J COMPUT, V22, P250, DOI 10.1287/ijoc.1090.0344
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Schulz A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201385
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shepherd EJ, 2016, MATER CULT MOD CONFL, P205
   Sperrle F., 2018, 2018 IEEE WORKSHOP M, DOI [10.1109/MLUI52768.2018.10075559, DOI 10.1109/MLUI52768.2018.10075559]
   Sperrle F., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.48550/arXiv.2208.044342, DOI 10.48550/ARXIV.2208.044342]
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/VAST47406.2019.8986917, 10.1109/vast47406.2019.8986917]
   Umentani N, 2015, COMMUN ACM, V58, P116, DOI 10.1145/2801945
   Van der Baan S., 2019, 1 C GEOPHYS INFRASTR, P1
   Wagner M, 2017, COMPUT SECUR, V67, P1, DOI 10.1016/j.cose.2017.02.003
   Walch A, 2020, IEEE T VIS COMPUT GR, V26, P569, DOI 10.1109/TVCG.2019.2934658
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
NR 37
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 66
EP 75
DI 10.1109/TVCG.2023.3326572
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500092
PM 37922176
OA hybrid
DA 2024-08-05
ER

PT J
AU Mao, AH
   Yang, Z
   Chen, WX
   Yi, R
   Liu, YJ
AF Mao, Aihua
   Yang, Zhi
   Chen, Wanxin
   Yi, Ran
   Liu, Yong-Jin
TI Complete 3D Relationships Extraction Modality Alignment Network for 3D
   Dense Captioning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 3D dense captioning; multi-modal learning; 3D spatial relationship;
   modality alignment
AB 3D dense captioning aims to semantically describe each object detected in a 3D scene, which plays a significant role in 3D scene understanding. Previous works lack a complete definition of 3D spatial relationships and the directly integrate visual and language modalities, thus ignoring the discrepancies between the two modalities. To address these issues, we propose a novel complete 3D relationship extraction modality alignment network, which consists of three steps: 3D object detection, complete 3D relationships extraction, and modality alignment caption. To comprehensively capture the 3D spatial relationship features, we define a complete set of 3D spatial relationships, including the local spatial relationship between objects and the global spatial relationship between each object and the entire scene. To this end, we propose a complete 3D relationships extraction module based on message passing and self-attention to mine multi-scale spatial relationship features and inspect the transformation to obtain features in different views. In addition, we propose the modality alignment caption module to fuse multi-scale relationship features and generate descriptions to bridge the semantic gap from the visual space to the language space with the prior information in the word embedding, and help generate improved descriptions for the 3D scene. Extensive experiments demonstrate that the proposed model outperforms the state-of-the-art methods on the ScanRefer and Nr3D datasets.
C1 [Mao, Aihua; Yang, Zhi; Chen, Wanxin] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Yi, Ran] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, BNRist, Beijing 100190, Peoples R China.
C3 South China University of Technology; Shanghai Jiao Tong University;
   Tsinghua University
RP Mao, AH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.; Yi, R (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM ahmao@scut.edu.cn; 202021044575@mail.scut.edu.cn;
   adrien.chenwx@gmail.com; ranyi@sjtu.edu.cn; liuyongjin@tsinghua.edu.cn
OI Yang, Zhi/0000-0002-9768-2356; Yi, Ran/0000-0003-1858-3358; Aihua,
   Mao/0000-0001-6861-9414
FU NSF of Guangdong Province [2022A1515011573]; Beijing Natural Science
   Foundation [L222008]; Shanghai Sailing Program [22YF1420300];
   CCF-Tencent Open Research Fund [RAGR20220121]; Young Elite Scientists
   Sponsorship Program by CAST [2022QNRC001]; National Natural Science
   Foundation of China [62272447]
FX This work was supported in part by the NSF of Guangdong Province under
   Grant 2022A1515011573, in part by the Beijing Natural Science Foundation
   under Grant L222008, in part by the Shanghai Sailing Program under Grant
   22YF1420300, in part by CCF-Tencent Open Research Fund under Grant
   RAGR20220121, in part by the Young Elite Scientists Sponsorship Program
   by CAST under Grant 2022QNRC001, and in part by the National Natural
   Science Foundation of China under Grant 62272447.
CR Achlioptas Panos, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P422, DOI 10.1007/978-3-030-58452-8_25
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Azuma D., 2021, arXiv, DOI 10.48550/arXiv.2112.10482
   Banerjee S., 2005, ACL WORKSH INTR EXTR, P65
   Chen D. Z., 2020, EUR C COMP VIS, P202, DOI DOI 10.1007/978-3-030-58565-513
   Chen DZ, 2021, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR46437.2021.00321
   Chen K, 2019, LECT NOTES COMPUT SC, V11363, P100, DOI 10.1007/978-3-030-20893-6_7
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong XZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2615, DOI 10.1145/3474085.3475439
   Feng Y, 2019, PROC CVPR IEEE, P4120, DOI 10.1109/CVPR.2019.00425
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gu J., 2018, P AAAI C ART INT
   Han ZZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1018, DOI 10.1145/3394171.3413889
   He DL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2344, DOI 10.1145/3474085.3475397
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang PH, 2021, AAAI CONF ARTIF INTE, V35, P1610
   Kant Yash, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P715, DOI 10.1007/978-3-030-58545-7_41
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li PG, 2021, IEEE T MULTIMEDIA, V24, P3455, DOI 10.1109/TMM.2021.3098988
   Li X., 2020, Lecture Notes in Computer Science, P121, DOI DOI 10.1007/978-3-030-58577-8_8
   Li Y., 2021, IEEE Trans.Multimedia, V25, P543
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150
   Lu JS, 2019, ADV NEUR IN, V32
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Pennington J., 2014, GLOVE GLOBAL VECTORS, DOI DOI 10.3115/V1/D14-1162
   Qi C. R., 2017, ADV NEURAL INFORM PR, P5099, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qu LG, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1047, DOI 10.1145/3394171.3413961
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vo N, 2019, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2019.00660
   Wang J, 2021, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR46437.2021.00136
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan X, 2023, Arxiv, DOI [arXiv:2112.11691, 10.48550/arXiv.2112.11691]
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Ye SQ, 2022, Arxiv, DOI arXiv:2112.08359
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yuan Z., 2021, ICCV, P1791
   Yuan Z., 2022, arXiv
   Zhang ZW, 2021, IEEE T MULTIMEDIA, V23, P1799, DOI 10.1109/TMM.2020.3003592
NR 53
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4867
EP 4880
DI 10.1109/TVCG.2023.3279204
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400050
PM 37220037
DA 2024-08-05
ER

PT J
AU Ogawa, K
   Fujita, K
   Sakamoto, S
   Takashima, K
   Kitamura, Y
AF Ogawa, Kumpei
   Fujita, Kazuyuki
   Sakamoto, Shuichi
   Takashima, Kazuki
   Kitamura, Yoshifumi
TI Exploring Visual-Auditory Redirected Walking Using Auditory Cues in
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Legged locomotion; Location awareness; Ear; Urban areas;
   Rivers; Reliability; Redirected walking; room-scale VR; visual-auditory
   redirection
ID THRESHOLDS; ROTATION; CAPTURE; MOTION
AB We examine the effect of auditory cues occurring in reality on redirection. Specifically, we set two hypotheses: the auditory cues emanating from fixed positions in reality (Fixed sound, FS) increase the noticeability of redirection, while the auditory cues whose positions are manipulated consistently with the visual manipulation (Redirected sound, RDS) decrease the noticeability of redirection. To verify these hypotheses, we implemented an experimental environment that virtually reproduced FS and RDS conditions using binaural recording, and then we conducted a user study (N=18) to investigate the detection thresholds (DTs) for rotational manipulation and the sound localization accuracy of the auditory cues under FS and RDS, as well as the baseline condition without auditory cues (No sound, NS). The results show, against the hypotheses, FS gave a wider range of DTs than NS, while RDS gave a similar range of DTs to NS. Combining these results with those of sound localization accuracy reveals that, rather than the auditory cues affecting the participants' spatial perception in VR, the visual manipulation made their sound localization less accurate, which would be a reason for the increased range of DTs under FS. Furthermore, we conducted a follow-up user study (N=11) to measure the sound localization accuracy of FS where the auditory cues were actually placed in a real setting, and we found that the accuracy tended to be similar to that of virtually reproduced FS, suggesting the validity of the auditory cues used in this study. Given these findings, we also discuss potential applications.
C1 [Ogawa, Kumpei; Fujita, Kazuyuki; Sakamoto, Shuichi; Takashima, Kazuki; Kitamura, Yoshifumi] Tohoku Univ, Res Inst Elect Commun, Sendai, Miyagi 9808577, Japan.
C3 Tohoku University
RP Fujita, K (corresponding author), Tohoku Univ, Res Inst Elect Commun, Sendai, Miyagi 9808577, Japan.
EM kumpei.ogawa.r5@dc.tohoku.ac.jp; k-fujita@riec.tohoku.ac.jp;
   saka@ais.riec.tohoku.ac.jp; takashima@riec.tohoku.ac.jp;
   kitamura@riec.tohoku.ac.jp
OI Ogawa, Kumpei/0000-0002-5757-7578; Fujita, Kazuyuki/0000-0002-1039-0167
FU JSPS [22H00523]
FX No Statement Available
CR Congdon BJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364277
   Dichgans J., 1978, HDB SENSORY PHYSL, P755, DOI [DOI 10.1007/978-3-642-46354-9_25, DOI 10.1007/978-3-642-46354-9253F]
   Dodge R, 1923, J EXP PSYCHOL, V6, P107, DOI 10.1037/h0076105
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Feigl E., 2017, P S VIRT REAL SOFTW, p45:1, DOI [10.1145/3139131.314120529R, DOI 10.1145/3139131.314120529R]
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   GARDNER MB, 1969, J ACOUST SOC AM, V45, P47, DOI 10.1121/1.1911372
   Goldstein E. B., 2010, Sensation and perception, V8th ed.
   Gotoh T., 1977, Journal of the Acoustical Society of Japan, V33, P667
   Grechkin J., 2016, P ACM S APPL PERC SA, P113, DOI [10.1145/2931002.29310182[19]J, DOI 10.1145/2931002.2931018]
   Honda A, 2022, I-PERCEPTION, V13, DOI 10.1177/20416695211070616
   Iwaya Y., 2003, Acoustical Science and Technology, V24, P322, DOI 10.1250/ast.24.322
   Junker A, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P358, DOI 10.1109/VRW52623.2021.00071
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kitajima N, 1999, PERCEPT MOTOR SKILL, V89, P1139, DOI 10.2466/PMS.89.7.1139-1158
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   LACKNER JR, 1977, AVIAT SPACE ENVIR MD, V48, P129
   Larsson P., 2004, Proceedings of 7th Annual Workshop of Presence, P252
   Lee S., 2022, P CHI C HUM FACT COM, p446:1, DOI [10.1145/3491101.351971932, DOI 10.1145/3491101.351971932]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Rayleigh,, 1907, PHILOS MAG, V13, P214, DOI 10.1080/14786440709463595
   MATEEFF S, 1985, PERCEPTION, V14, P721, DOI 10.1068/p140721
   Meyer M., 2016, P SOUND MUS COMP C, P293
   Nguyen A, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225155
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nilsson NC, 2016, P IEEE VIRT REAL ANN, P241, DOI 10.1109/VR.2016.7504743
   Nogalski M, 2016, P IEEE VIRT REAL ANN, P245, DOI 10.1109/VR.2016.7504745
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Razzaque Z., 2001, EUROGRAPHICS 2001 SH, P289, DOI 10.2312/egs.20011036
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Riecke BE, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P147
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strybel TZ, 2000, J ACOUST SOC AM, V108, P3092, DOI 10.1121/1.1323720
   Thompson S.P., 1882, PHILOS MAG, V13, P406, DOI DOI 10.1080/14786448208627205
   THURLOW WR, 1970, AM J PSYCHOL, V83, P112, DOI 10.2307/1420861
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Weller R, 2022, VISUAL COMPUT, V38, P3475, DOI 10.1007/s00371-022-02565-4
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Zhang J, 2018, IEEE T VIS COMPUT GR, V24, P1671, DOI 10.1109/TVCG.2018.2793679
NR 40
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5782
EP 5794
DI 10.1109/TVCG.2023.3309267
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400057
PM 37639419
OA hybrid
DA 2024-08-05
ER

PT J
AU Petrov, D
   Gadelha, M
   Mech, R
   Kalogerakis, E
AF Petrov, Dmitry
   Gadelha, Matheus
   Mech, Radomir
   Kalogerakis, Evangelos
TI ANISE: Assembly-Based Neural Implicit Surface Reconstruction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 3D shape representations; single-view reconstruction; neural networks;
   implicit functions; shape modeling
AB We present ANISE, a method that reconstructs a 3D shape from partial observations (images or sparse point clouds) using a part-aware neural implicit shape representation. The shape is formulated as an assembly of neural implicit functions, each representing a different part instance. In contrast to previous approaches, the prediction of this representation proceeds in a coarse-to-fine manner. Our model first reconstructs a structural arrangement of the shape in the form of geometric transformations of its part instances. Conditioned on them, the model predicts part latent codes encoding their surface geometry. Reconstructions can be obtained in two ways: (i) by directly decoding the part latent codes to part implicit functions, then combining them into the final shape; or (ii) by using part latents to retrieve similar part instances in a part database and assembling them in a single shape. We demonstrate that, when performing reconstruction by decoding part representations into implicit functions, our method achieves state-of-the-art part-aware reconstruction results from both images and sparse point clouds. When reconstructing shapes by assembling parts retrieved from a dataset, our approach significantly outperforms traditional shape retrieval methods even when significantly restricting the database size. We present our results in well-known sparse point cloud reconstruction and single-view reconstruction benchmarks.
C1 [Petrov, Dmitry] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
   [Gadelha, Matheus] Adobe Res, San Jose, CA 95110 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   Adobe Systems Inc.
RP Petrov, D (corresponding author), Univ Massachusetts Amherst, Amherst, MA 01003 USA.
EM dmitry.petrov@gmail.com; gadelha@adobe.com; rmech@adobe.com;
   kalo@cs.umass.edu
OI Petrov, Dmitry/0000-0003-0445-3923; Mech, Radomir/0000-0002-5558-0327
FU Adobe Research Internship; Adobe Research gift
FX No Statement Available
CR Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bokhovkin A, 2021, PROC CVPR IEEE, P7480, DOI 10.1109/CVPR46437.2021.00740
   Chabra R., 2020, COMPUTER VISION ECCV, P608
   Chaudhuri S., 2013, P 26 ANN ACM S USER, P193, DOI [DOI 10.1145/2501988.2502008, 10.1145/2501988.2502008]
   Chaudhuri S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964930
   Chen ZQ, 2020, PROC CVPR IEEE, P42, DOI 10.1109/CVPR42600.2020.00012
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Deng BY, 2020, PROC CVPR IEEE, P31, DOI 10.1109/CVPR42600.2020.00011
   Dubrovina A, 2019, IEEE I CONF COMP VIS, P8139, DOI 10.1109/ICCV.2019.00823
   Erler Philipp, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P108, DOI 10.1007/978-3-030-58558-7_7
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gadelha M, 2020, PROC CVPR IEEE, P399, DOI 10.1109/CVPR42600.2020.00048
   Gal R, 2021, IEEE INT CONF COMP V, P2039, DOI 10.1109/ICCVW54120.2021.00231
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Genova K, 2019, IEEE I CONF COMP VIS, P7153, DOI 10.1109/ICCV.2019.00725
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Hanocka R, 2020, Arxiv, DOI arXiv:2005.11084
   Hertz A, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530084
   Huang HB, 2015, COMPUT GRAPH FORUM, V34, P25, DOI 10.1111/cgf.12694
   Jiang C., 2020, ADV NEURAL INFORM PR, V33, P9745
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2185520.2185551, 10.1145/2077341.2077342]
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Li J., 2020, P AAAI C ART INT, p11 362
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li MY, 2021, PROC CVPR IEEE, P10241, DOI 10.1109/CVPR46437.2021.01011
   Li YY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818071
   Littwin G, 2019, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2019.00191
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Mo KC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356527
   Museth K, 2002, ACM T GRAPHIC, V21, P330, DOI 10.1145/566570.566585
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156
   Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Paschalidou D, 2021, PROC CVPR IEEE, P3203, DOI 10.1109/CVPR46437.2021.00322
   Peng S., 2020, COMPUTER VISION ECCV
   Peng Songyou, 2021, NEURIPS, V34, P13032
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Reiner T, 2011, COMPUT GRAPH-UK, V35, P596, DOI 10.1016/j.cag.2011.03.010
   Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207
   Schulz A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983618
   Stutz D, 2018, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2018.00209
   Sung M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130821
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tian Y., 2019, P INT C LEARN REPR
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   ukta Prasad M., 2006, CVPR'06: Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1345, DOI 10.1109/CVPR.2006.281
   Uy MA, 2021, PROC CVPR IEEE, P11708, DOI 10.1109/CVPR46437.2021.01154
   Wang WY, 2019, ADV NEUR IN, V32
   Williams F, 2019, PROC CVPR IEEE, P10122, DOI 10.1109/CVPR.2019.01037
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu RD, 2020, PROC CVPR IEEE, P826, DOI 10.1109/CVPR42600.2020.00091
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103
NR 59
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4514
EP 4526
DI 10.1109/TVCG.2023.3265306
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400002
PM 37023153
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Shin, S
   Batch, A
   Butcher, PWS
   Ritsos, PD
   Elmqvist, N
AF Shin, Sungbok
   Batch, Andrea
   Butcher, Peter William Scott
   Ritsos, Panagiotis D.
   Elmqvist, Niklas
TI The Reality of the Situation: A Survey of Situated Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; data visualization; immersive analytics; situated
   visualization; situated analytics
ID MOBILE AUGMENTED REALITY; VISUALIZATION; TAXONOMY; HAND; SYSTEM
AB The advent of low-cost, accessible, and high-performance augmented reality (AR) has shed light on a situated form of analytics where in-situ visualizations embedded in the real world can facilitate sensemaking based on the user's physical location. In this work, we identify prior literature in this emerging field with a focus on situated analytics. After collecting 47 relevant situated analytics systems, we classify them using a taxonomy of three dimensions: situating triggers, view situatedness, and data depiction. We then identify four archetypical patterns in our classification using an ensemble cluster analysis. We also assess the level which these systems support the sensemaking process. Finally, we discuss insights and design guidelines that we learned from our analysis.
C1 [Shin, Sungbok; Batch, Andrea; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Butcher, Peter William Scott; Ritsos, Panagiotis D.] Bangor Univ, Bangor LL57 2DG, Wales.
C3 University System of Maryland; University of Maryland College Park;
   Bangor University
RP Elmqvist, N (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM sbshin90@umd.edu; ajulca@umd.edu; p.butcher@bangor.ac.uk;
   p.ritsos@bangor.ac.uk; elm@umd.edu
OI Shin, Sungbok/0000-0001-6777-8843; Elmqvist, Niklas/0000-0001-5805-5301;
   Ritsos, Panagiotis/0000-0001-9308-3885; Butcher,
   Peter/0000-0002-3361-627X
FU U.S. National Science Foundation [IIS-1908605]; DSP Centre - European
   Regional Development Fund; North Wales Growth Deal through Ambition
   North Wales, Welsh Government; North Wales Growth Deal through Ambition
   North Wales, U.K. Government
FX This work was supported in part by the U.S. National Science Foundation
   under Grant IIS-1908605, and in part by the DSP Centre, which has been
   partly funded by the European Regional Development Fund through Welsh
   Government and also by the North Wales Growth Deal through Ambition
   North Wales, Welsh Government and U.K. Government.
CR Abao Roland P., 2018, Procedia Computer Science, V135, P186, DOI 10.1016/j.procs.2018.08.165
   Ahn J, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808207
   Alqahtani M., 2017, P INT C COMP AUT ENG, P1, DOI [10.1145/3057039.3057062, DOI 10.1145/3057039.3057062]
   [Anonymous], 2010, Int. J. Virtual Reality, V9, P1, DOI [10.20870/IJVR.2010.9.2.2767.141, DOI 10.20870/IJVR.2010.9.2.2767.141]
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Bach B, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P529, DOI 10.1145/2992154.2996365
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P586, DOI 10.1109/TVCG.2018.2865144
   Balduini M, 2012, J WEB SEMANT, V16, P33, DOI 10.1016/j.websem.2012.06.004
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Barba E, 2012, P IEEE, V100, P929, DOI 10.1109/JPROC.2011.2182070
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Behzadan AH, 2005, PROCEEDINGS OF THE 2005 WINTER SIMULATION CONFERENCE, VOLS 1-4, P1914, DOI 10.1109/WSC.2005.1574469
   Behzadan AH, 2015, ADV ENG INFORM, V29, P252, DOI 10.1016/j.aei.2015.03.005
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Bichlmeier C., 2007, Proc. IEEE ACM Int. Sym. on Mix. Aug. Reality, P1, DOI [DOI 10.1109/ISMAR.2007.4538837, DOI 10.1109/ISMAR.2007.4538837.18M]
   Bichlmeier C, 2009, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2009.5336474
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bonada S, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P83, DOI 10.1145/3009939.3009953
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Brown T. B., 2020, P 34 INT C NEURAL IN
   Büschel W, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P62, DOI 10.1145/3132272.3134125
   Büschel W, 2019, IEEE COMPUT GRAPH, V39, P29, DOI 10.1109/MCG.2019.2897927
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Caggianese Giuseppe, 2019, 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS), P390, DOI 10.1109/SITIS.2019.00069
   Calinski Tadeusz, 1974, Communications in Statistics, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Cavallo M, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P160, DOI [10.1109/ISMAR-Adjunct.2016.60, 10.1109/ISMAR-Adjunct.2016.0068]
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/GLOCOM.2015.7417476, 10.1109/ICSENS.2015.7370446]
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Datcu D., 2016, P ACM C SUPP GROUP W, DOI [DOI 10.1145/2957276.2957302, DOI 10.1145/2957276.2957302.39D.L]
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dixon BJ, 2013, SURG ENDOSC, V27, P454, DOI 10.1007/s00464-012-2457-3
   Doil F., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P71, DOI 10.1145/769953.769962
   Doshi A, 2017, INT J ADV MANUF TECH, V89, P1279, DOI 10.1007/s00170-016-9164-5
   Dünser A, 2012, COMPUT GRAPH-UK, V36, P1084, DOI 10.1016/j.cag.2012.10.001
   Elmqvist N., 2023, COMMUN ACM
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Elmqvist N, 2013, COMPUTER, V46, P86, DOI 10.1109/MC.2013.147
   ElSayed NAM, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P203, DOI [10.1109/ISMAR-Adjunct.2016.68, 10.1109/ISMAR-Adjunct.2016.0077]
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   Engelke U, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365715
   Ens B., 2021, P ACM C HUMAN FACTOR, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Fjukstad Bard, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P321
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Giiven Sinem, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P155
   Gillet A, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P235, DOI 10.1109/VISUAL.2004.7
   Gomez P., 2008, P ACM S VIRT REAL SO, P267, DOI [10.1145/1450579.1450646.60R, DOI 10.1145/1450579.1450646.60R]
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Güven S, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P111, DOI 10.1109/TRIDUI.2006.1618280
   Haynes PS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P243, DOI 10.1109/3DUI.2016.7460061
   Heller F, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P615, DOI 10.1145/2556288.2557021
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Henderson S, 2010, IEEE T VIS COMPUT GR, V16, P4, DOI 10.1109/TVCG.2009.91
   Hollerer T., 1999, Digest of Papers. Third International Symposium on Wearable Computers, P79, DOI 10.1109/ISWC.1999.806664
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   Hube M., 2018, P ACM AVI WORKSH VIS, P12
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   IKEA Corporation, 2017, IKEA Place
   Imottesjo H, 2018, COMPUT ENVIRON URBAN, V71, P120, DOI 10.1016/j.compenvurbsys.2018.05.003
   Jain D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P241, DOI 10.1145/2702123.2702393
   Jiang SY, 2020, PROCEEDINGS OF IDC 2020, P349, DOI 10.1145/3392063.3394406
   Joo-Nagata J, 2017, COMPUT EDUC, V111, P1, DOI 10.1016/j.compedu.2017.04.003
   Julier S, 2002, IEEE COMPUT GRAPH, V22, P12, DOI 10.1109/MCG.2002.1028721
   Kalkofen D, 2013, INT SYM MIX AUGMENT, P1
   Ketchell W., 2019, P INT C VIRT REAL CO, P1, DOI [10.1145/3359997.3365681.79D.H, DOI 10.1145/3359997.3365681.79D.H]
   Kim H, 2018, IEEE T VIS COMPUT GR, V24, P1515, DOI 10.1109/TVCG.2018.2793680
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim V., 2021, P ACM C HUM FACT COM, DOI [10.1145/3411764.3445443.80H, DOI 10.1145/3411764.3445443.80H]
   King GR, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P52
   Kobak D, 2021, NAT BIOTECHNOL, V39, DOI 10.1038/s41587-020-00809-z
   Kobak G. C., 2021, Nat. Biotechnol., V39, P1464, DOI [10.1109/5.58325., DOI 10.1109/5.58325]
   Kotranza A, 2009, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2009.5336485
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lanier J., 2001, Sci. Amer., V284, P75
   Lee B, 2019, IEEE COMPUT GRAPH, V39, P16, DOI 10.1109/MCG.2019.2906513
   Lee G. A., 2012, 2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH), P57, DOI 10.1109/ISMAR-AMH.2012.6483989
   Lee S, 2015, COMPUT GEOSCI-UK, V76, P41, DOI 10.1016/j.cageo.2014.12.005
   Liestol G, 2014, P I CON VIR SYS MULT, P251, DOI 10.1109/VSMM.2014.7136657
   Lin Tica, 2021, P 2021 CHI C HUMAN F, DOI [DOI 10.1145/3411764.3445649, 10.1145/3411764.3445649]
   Livingston M. A., 2002, Tech. Rep.
   Lk'Stol Gunnar, 2009, International Journal of Interactive Mobile Technologies, V3, P33, DOI 10.3991/ijim.v3s1.963
   Luboschik M, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P47, DOI 10.1145/3009939.3009947
   Luchetti G, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6020041
   Marriott K., 2018, Immersive Analytics: Time to Reconsider the Value of 3D for Information Visualisation, P55, DOI [10.1007/978-3-030-01388-2_2, DOI 10.1007/978]
   Mathews NS, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P146, DOI [10.1109/VIS49827.2021.00037, 10.1109/VIS49827.2021.9623287]
   Miles LK, 2010, PSYCHOL SCI, V21, P222, DOI 10.1177/0956797609359333
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Morrison A, 2011, COMPUT GRAPH-UK, V35, P789, DOI 10.1016/j.cag.2011.04.009
   Mulloni H., 2011, P ACM C HUM COMP INT, P211, DOI [DOI 10.1145/2037373.2037406, 10.1145/2037373.2037406]
   Munzner T., 2014, Visualization analysis and design, DOI DOI 10.1201/B17511
   Nassani A, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139199
   Okur A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P211, DOI 10.1109/ISMAR.2011.6092388
   Panëels S, 2010, IEEE T HAPTICS, V3, P119, DOI 10.1109/ToH.2009.44
   Park JH, 2018, IEEE COMPUT GRAPH, V38, P67, DOI 10.1109/MCG.2018.2879066
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Pirolli P., 2005, Proceedings of International Conference on Intelligence Analysis, V5, P2
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Rabbi I., 2013, ACTA GRAPH, V24, P29, DOI DOI 10.9790/0661-0222329
   Rekimoto J, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P68, DOI 10.1109/ISWC.1998.729531
   Roberts JC, 2014, IEEE COMPUT GRAPH, V34, P26, DOI 10.1109/MCG.2014.82
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Rollo ME, 2017, INT J BEHAV NUTR PHY, V14, DOI 10.1186/s12966-017-0516-9
   Roodaki H, 2017, IEEE T VIS COMPUT GR, V23, P2366, DOI 10.1109/TVCG.2017.2734327
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Schmalstieg T., 2016, Augmented Reality: Principles andPractice
   Schoenfelder R, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P83
   Seichter H, 2007, COMPUTER-AIDED ARCHITECTURAL DESIGN FUTURES (CAAD FUTURES) 2007, P3, DOI 10.1007/978-1-4020-6528-6_1
   Shapiro L, 2014, ROUTLEDGE HBK PHILOS, P1
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shneiderman B, 2021, ISSUES SCI TECHNOL, V37, P56
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Simpson J., 2017, P IEEE VIS WORKSH IM, P1
   Skulmowski A, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0092-9
   Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400
   Stoakley R., 1995, Proceedings of the 1995 SIGCHI Conference on Human Factors in Computing Systems, CHI, (New York, NY, USA), P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Tanveer E., 2015, P ACM C INT US INT N, P286, DOI [DOI 10.1145/2678025.2701386.138M, DOI 10.1145/2678025.2701386]
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Vanoni D, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P44, DOI 10.1109/ISM.2012.17
   Veas E, 2012, IEEE T VIS COMPUT GR, V18, P565, DOI 10.1109/TVCG.2012.44
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Whitlock M, 2020, INT SYM MIX AUGMENT, P704, DOI 10.1109/ISMAR50242.2020.00101
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Whitlock M, 2020, IEEE T VIS COMPUT GR, V26, P503, DOI 10.1109/TVCG.2019.2934282
   Wigdor D, 2011, BRAVE NUI WORLD: DESIGNING NATURAL USER INTERFACES FOR TOUCH AND GESTURE, P1
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Williams K. Yao, P BRIT HUM COMP INT
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xi MZ, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365721
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zhao MQ, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139309
   Zheng MY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P93, DOI 10.1109/ISMAR-Adjunct.2019.00039
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zollmann S, 2021, IEEE T VIS COMPUT GR, V27, P3808, DOI 10.1109/TVCG.2020.2986247
NR 154
TC 5
Z9 5
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5147
EP 5164
DI 10.1109/TVCG.2023.3285546
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400038
PM 37310839
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Xie, LWH
   Shu, XH
   Su, JC
   Wang, Y
   Chen, SM
   Qu, HM
AF Xie, Liwenhan
   Shu, Xinhuan
   Su, Jeon Cheol
   Wang, Yun
   Chen, Siming
   Qu, Huamin
TI Creating Emordle: Animating Word Cloud for Emotion Expression
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Data visualization; Visualization; Videos; Tag clouds; Image
   color analysis; Entropy; Wordle; animation; affective visualization;
   authoring; casual visualization
ID VISUALIZATION; DESIGN
AB We propose emordle, a conceptual design that animates wordles (compact word clouds) to deliver their emotional context to audiences. To inform the design, we first reviewed online examples of animated texts and animated wordles, and summarized strategies for injecting emotion into the animations. We introduced a composite approach that extends an existing animation scheme for one word to multiple words in a wordle with two global factors: the randomness of text animation (entropy) and the animation speed (speed). To create an emordle, general users can choose one predefined animated scheme that matches the intended emotion class and fine-tune the emotion intensity with the two parameters. We designed proof-of-concept emordle examples for four basic emotion classes, namely happiness, sadness, anger, and fear. We conducted two controlled crowdsourcing studies to evaluate our approach. The first study confirmed that people generally agreed on the conveyed emotions from well-crafted animations, and the second one demonstrated that our identified factors helped fine-tune the extent of the emotion delivered. We also invited general users to create their own emordles based on our proposed framework. Through this user study, we confirmed the effectiveness of the approach. We concluded with implications for future research opportunities of supporting emotion expression in visualizations.
C1 [Xie, Liwenhan; Shu, Xinhuan; Su, Jeon Cheol; Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Xie, Liwenhan] Fudan Univ, Shanghai 200437, Peoples R China.
   [Wang, Yun] Microsoft Res Asia, Beijing, Peoples R China.
   [Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
   [Chen, Siming] Shanghai Key Lab Data Sci, Shanghai 200437, Peoples R China.
C3 Hong Kong University of Science & Technology; Fudan University;
   Microsoft; Microsoft Research Asia; Fudan University
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.; Chen, SM (corresponding author), Shanghai Key Lab Data Sci, Shanghai 200437, Peoples R China.
EM liwenhan.xie@connect.ust.hk; xinhuan.shu@gmail.com;
   csjeon@connect.ust.hk; wangyun@microsoft.com; simingchen3@gmail.com;
   huamin@cse.ust.hk
RI Xie, Liwenhan/HLV-8177-2023
OI Xie, Liwenhan/0000-0002-2601-6313; Shu, Xinhuan/0000-0002-9736-4454
FU HKRGC General Research Fund [16210722]; Natural Science Foundation of
   China (NSFC) [62202105]; Shanghai Municipal Science and Technology
   [21ZR1403300, 21YF1402900]
FX This work was supported in part by HKRGC General Research Fund under
   Grant 16210722, in part by the Natural Science Foundation of China
   (NSFC) under Grant 62202105, and in part by Shanghai Municipal Science
   and Technology under Grants 21ZR1403300 and 21YF1402900.
CR Adobe Inc, 2022, After Effects.
   Anderson CL, 2022, IEEE T VIS COMPUT GR, V28, P2867, DOI 10.1109/TVCG.2021.3050118
   [Anonymous], 2003, Measuring Emotion- Development and Application of an Instrument To Measure Emotional Responses To Products, DOI DOI 10.1007/1-4020-2967-5_12
   [Anonymous], 2022, Pixar Animation Studios
   Aoki T, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501920
   Bartram L., 2009, P 5 EUR C COMP AESTH, P129, DOI [DOI 10.2312/COM, 10.2312/COMPAESTH/COMPAESTH09/129-136, DOI 10.2312/COMPAESTH/COMPAESTH09/129-136]
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Bay-Wei Chang, 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P123, DOI 10.1145/288392.288585
   Brath R., 2020, Visualizing With Text., P42, DOI DOI 10.1201/9780429290565
   Chen Q, 2024, IEEE T VIS COMPUT GR, V30, P4429, DOI 10.1109/TVCG.2023.3261320
   Chevalier F., 2016, P INT WORK C ADV VIS, P280, DOI 10.1145/2909132.2909255
   Chevalier F, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P683
   Chi MT, 2015, IEEE T VIS COMPUT GR, V21, P1415, DOI 10.1109/TVCG.2015.2440241
   Dang T., 2019, P EUR IEEE VGTC C VI, P103, DOI DOI 10.2312/EVS.20191178
   Davis Felecia, 2015, P ACM C CREAT C, P23, DOI DOI 10.1145/2757226.2757231
   Desai R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300599
   Felix C, 2018, IEEE T VIS COMPUT GR, V24, P657, DOI 10.1109/TVCG.2017.2746018
   Feng C., 2014, Proceedings of the ACM Symposium on Applied Perception-SAP'14, P23, DOI DOI 10.1145/2628257.2628264
   Feng C, 2017, LEONARDO, V50, P205, DOI 10.1162/LEON_a_01229
   Fisher D., 2010, Beautiful Visualization-Looking at Data Through the Eyes of Experts, P329
   Forlizzi J., 2003, P ACM C HUM FACT COM, P377, DOI DOI 10.1145/642611.642677
   Hearst MA, 2020, IEEE T VIS COMPUT GR, V26, P2748, DOI 10.1109/TVCG.2019.2904683
   Hicke R. M., 2022, arXiv
   Ishizaki S., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P347, DOI 10.1145/238386.238566
   Jo J, 2015, IEEE COMPUT GRAPH, V35, P20, DOI 10.1109/MCG.2015.113
   Joonhwan Lee, 2006, Designing Interactive Systems. DIS2006, P41
   Kalra A, 2005, LECT NOTES COMPUT SC, V3585, P966, DOI 10.1007/11555261_81
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300309
   Koh K, 2010, IEEE T VIS COMPUT GR, V16, P1190, DOI 10.1109/TVCG.2010.175
   Koyama Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392444
   Krcadinac U, 2016, IEEE T HUM-MACH SYST, V46, P370, DOI 10.1109/THMS.2015.2504081
   Kucher K, 2018, COMPUT GRAPH FORUM, V37, P71, DOI 10.1111/cgf.13217
   Kulahcioglu T, 2020, ACM T INTERACT INTEL, V10, DOI 10.1145/3370928
   Lan X., 2022, arXiv
   Lan XY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517530
   Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Lee B, 2010, IEEE T VIS COMPUT GR, V16, P1182, DOI 10.1109/TVCG.2010.194
   Lee D. G., 2007, ACM Comput. Entertainment, V5, p11:1, DOI [10.1145/1279540.1279551, DOI 10.1145/1279540.1279551]
   Lee J.C., 2002, P ACM S US INT SOFTW, P81, DOI DOI 10.1145/571985.571997
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   Li JB, 2023, CURR PSYCHOL, V42, P3349, DOI 10.1007/s12144-021-01693-9
   Li WC, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581470
   lipsum.com, 2022, Lorem ipsum
   Ma HW, 2023, IEEE T AFFECT COMPUT, V14, P1655, DOI 10.1109/TAFFC.2021.3104512
   Maharik R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964995
   Malik S, 2009, VISUAL COMMUNIC, V8, P469, DOI 10.1177/1470357209343375
   Méndez GG, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174212
   Minakuchi M., 2005, P ACM C ADV COMP ENT, P221, DOI DOI 10.1145/1178477.1178512
   O'Donovan P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601110
   Ortony A., 1988, The cognitive structure of emotions, DOI DOI 10.1017/CBO9780511571299
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Rivadeneira AW, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P995
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K. R., 2013, Components of emotional meaning: A sourcebook
   Schetinger V, 2023, COMPUT GRAPH FORUM, V42, P423, DOI 10.1111/cgf.14841
   Shin M, 2023, IEEE T VIS COMPUT GR, V29, P2980, DOI 10.1109/TVCG.2022.3146329
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Shu XH, 2021, J VISUAL-JAPAN, V24, P85, DOI 10.1007/s12650-020-00689-0
   Stone R. B., 2004, Design and Emotion, P212, DOI DOI 10.1201/9780203608173
   Sturdee M., 2022, P DES RES SOC JUN 25, DOI DOI 10.21606/DRS.2022.257
   Thomas Frank, 1995, ILLUSION LIFE DISNEY
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI [10.1006/ijhc.2002.1017, 10.1006/ijhc.1017]
   Urquhart LWR, 2017, INT CONF ENG DES, P109
   VanGorp T, 2012, DESIGN FOR EMOTION, P1
   Viégas FB, 2009, IEEE T VIS COMPUT GR, V15, P1137, DOI 10.1109/TVCG.2009.171
   Wang H., 2004, P HUM FACT COMP SYST, P1171, DOI [DOI 10.1145/985921.986016, 10.1145/985921.986016]
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Wang YH, 2020, IEEE T VIS COMPUT GR, V26, P991, DOI 10.1109/TVCG.2019.2934783
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P647, DOI 10.1109/TVCG.2017.2745859
   Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1
   Wood J., 2022, P 2 WORKSH ALT VIS, P1
   WordArts, 2022, about us
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Wu YC, 2011, COMPUT GRAPH FORUM, V30, P741, DOI 10.1111/j.1467-8659.2011.01923.x
   Xu J, 2016, IEEE PAC VIS SYMP, P239, DOI 10.1109/PACIFICVIS.2016.7465278
   Yeo Z., 2008, P HUM FACT COMP SYST, P3729, DOI DOI 10.1145/1358628.1358921
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zou CQ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925887
NR 83
TC 1
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5198
EP 5211
DI 10.1109/TVCG.2023.3286392
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400059
PM 37318965
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhou, TS
   Huang, J
   Yu, T
   Shao, RZ
   Li, K
AF Zhou, Tiansong
   Huang, Jing
   Yu, Tao
   Shao, Ruizhi
   Li, Kun
TI HDhuman: High-Quality Human Novel-View Rendering From Sparse Views
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image-based rendering; neural rendering; human reconstruction;
   transformer; visibility reasoning
AB In this paper, we aim to address the challenge of novel view rendering of human performers that wear clothes with complex texture patterns using a sparse set of camera views. Although some recent works have achieved remarkable rendering quality on humans with relatively uniform textures using sparse views, the rendering quality remains limited when dealing with complex texture patterns as they are unable to recover the high-frequency geometry details that are observed in the input views. To this end, we propose HDhuman, which uses a human reconstruction network with a pixel-aligned spatial transformer and a rendering network with geometry-guided pixel-wise feature integration to achieve high-quality human reconstruction and rendering. The designed pixel-aligned spatial transformer calculates the correlations between the input views and generates human reconstruction results with high-frequency details. Based on the surface reconstruction results, the geometry-guided pixel-wise visibility reasoning provides guidance for multi-view feature integration, enabling the rendering network to render high-quality images at 2k resolution on novel views. Unlike previous neural rendering works that always need to train or fine-tune an independent network for a different scene, our method is a general framework that is able to generalize to novel subjects. Experiments show that our approach outperforms all the prior generic or specific methods on both synthetic data and real-world data. Source code and test data will be made publicly available for research purposes at http://cic.tju.edu.cn/faculty/likun/projects/HDhuman/index.html.
C1 [Zhou, Tiansong; Huang, Jing; Li, Kun] Tianjin Univ, Tianjin 300072, Peoples R China.
   [Yu, Tao; Shao, Ruizhi] Tsinghua Univ, Beijing 100190, Peoples R China.
C3 Tianjin University; Tsinghua University
RP Li, K (corresponding author), Tianjin Univ, Tianjin 300072, Peoples R China.
EM tiansong97@tju.edu.cn; hj00@tju.edu.cn; ytrock@126.com;
   shaorz20@mails.tsinghua.edu.cn; lik@tju.edu.cn
OI Shao, Ruizhi/0000-0003-2188-1348; Huang, Jing/0009-0003-3833-7629
FU National Natural Science Foundation of China [62122058, 62171255,
   62171317]; Guoqiang Institute of Tsinghua University [2021GQG0001]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62122058, 62171255, and 62171317, and
   in part by the Guoqiang Institute of Tsinghua University under Grant
   2021GQG0001.
CR Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Corona E, 2021, PROC CVPR IEEE, P11870, DOI 10.1109/CVPR46437.2021.01170
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Feng Q., 2022, Adv. Neural Inf. Process. Syst., V35, P7397
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Guo KW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083722
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Kingma D. P., 2014, arXiv
   Li K, 2021, IEEE T IMAGE PROCESS, V30, P5239, DOI 10.1109/TIP.2021.3080177
   Li XZ, 2023, IEEE T VIS COMPUT GR, V29, P5083, DOI 10.1109/TVCG.2022.3202240
   Liu L., 2020, P INT C NEUR INF PRO
   Liu LJ, 2021, IEEE T VIS COMPUT GR, V27, P4009, DOI 10.1109/TVCG.2020.2996594
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPR.2009.5206712, 10.1109/CVPRW.2009.5206712]
   Liu YB, 2010, IEEE T VIS COMPUT GR, V16, P407, DOI 10.1109/TVCG.2009.88
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Riegler Gernot, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P623, DOI 10.1007/978-3-030-58529-7_37
   Riegler G, 2021, PROC CVPR IEEE, P12211, DOI 10.1109/CVPR46437.2021.01204
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Shuai Q., 2022, P ACM SIGGRAIPH C
   Suo X, 2021, PROC CVPR IEEE, P6222, DOI 10.1109/CVPR46437.2021.00616
   Thies J, 2020, Arxiv, DOI arXiv:1811.10720
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   twindom, 2023, About us
   Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Xiang DL, 2020, INT CONF 3D VISION, P322, DOI 10.1109/3DV50981.2020.00042
   Xu TH, 2022, PROC CVPR IEEE, P15862, DOI 10.1109/CVPR52688.2022.01542
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yu T, 2021, PROC CVPR IEEE, P5742, DOI 10.1109/CVPR46437.2021.00569
   Zhao FQ, 2022, PROC CVPR IEEE, P7733, DOI 10.1109/CVPR52688.2022.00759
   Zheng Y., 2021, arXiv
   Zheng ZR, 2022, PROC CVPR IEEE, P15872, DOI 10.1109/CVPR52688.2022.01543
   Zhou TH, 2018, Arxiv, DOI arXiv:1805.09817
   Zins P, 2021, INT CONF 3D VISION, P494, DOI 10.1109/3DV53792.2021.00059
NR 47
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 5328
EP 5338
DI 10.1109/TVCG.2023.3290543
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400045
PM 37384477
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Batch, A
   Ji, YP
   Fan, MM
   Zhao, J
   Elmqvist, N
AF Batch, Andrea
   Ji, Yipeng
   Fan, Mingming
   Zhao, Jian
   Elmqvist, Niklas
TI uxSense: Supporting User Experience Analysis with Visualization and
   Computer Vision
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Annotations; Data visualization; Feature extraction; Usability;
   Measurement; Gaze tracking; Visualization; visual analytics; evaluation;
   video analytics; machine learning; deep learning; computer vision
AB Analyzing user behavior from usability evaluation can be a challenging and time-consuming task, especially as the number of participants and the scale and complexity of the evaluation grows. We propose uxSense, a visual analytics system using machine learning methods to extract user behavior from audio and video recordings as parallel time-stamped data streams. Our implementation draws on pattern recognition, computer vision, natural language processing, and machine learning to extract user sentiment, actions, posture, spoken words, and other features from such recordings. These streams are visualized as parallel timelines in a web-based front-end, enabling the researcher to search, filter, and annotate data across time and space. We present the results of a user study involving professional UX researchers evaluating user data using uxSense. In fact, we used uxSense itself to evaluate their sessions.
C1 [Batch, Andrea; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Ji, Yipeng; Zhao, Jian] Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
   [Fan, Mingming] Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511453, Peoples R China.
   [Fan, Mingming] Hong Kong Univ Sci & Technol, Hong Kong 511453, Peoples R China.
C3 University System of Maryland; University of Maryland College Park;
   University of Waterloo; Hong Kong University of Science & Technology
   (Guangzhou); Hong Kong University of Science & Technology
RP Batch, A (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM ajulca@umd.edu; y43ji@edu.uwaterloo.ca; mingmingfan@ust.hk;
   jianzhao@edu.uwaterloo.ca; elm@umd.edu
OI Fan, Mingming/0000-0002-0356-4712; Elmqvist, Niklas/0000-0001-5805-5301;
   Zhao, Jian/0000-0001-5008-4319
FU U.S. National Science Foundation [IIS-1908605]; Natural Sciences and
   Engineering Research Council of Canada
FX This work was supported in part by U.S. National Science Foundation
   under Grant IIS-1908605, and in part by the Natural Sciences and
   Engineering Research Council of Canada through the Discovery Grant
   program. Any opinions, findings, and conclusions or recommendations
   expressed here are those of the authors and do not necessarily reflect
   the views of the funding agencies.
CR Ahmed AAE, 2007, IEEE T DEPEND SECURE, V4, P165, DOI 10.1109/TDSC.2007.70207
   Truong A, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P497, DOI 10.1145/2984511.2984569
   Arriaga O, 2017, Arxiv, DOI arXiv:1710.07557
   Batch A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P1, DOI 10.1109/AIVR.2018.00009
   Batch N., 2019, P MACH LEARN US INT, P1
   Blascheck T, 2017, COMPUT GRAPH FORUM, V36, P260, DOI 10.1111/cgf.13079
   Blascheck T, 2016, IEEE T VIS COMPUT GR, V22, P61, DOI 10.1109/TVCG.2015.2467871
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chandrasegaran S, 2017, INT J HUM-COMPUT ST, V100, P66, DOI 10.1016/j.ijhcs.2016.12.007
   Franco RYD, 2019, INFORMATION, V10, DOI 10.3390/info10120366
   Dou WW, 2009, IEEE COMPUT GRAPH, V29, P52, DOI 10.1109/MCG.2009.49
   Fan MM, 2020, ACM T INTERACT INTEL, V10, DOI 10.1145/3385732
   Fan MM, 2020, J USABILITY STUD, V15, P85
   Fan MM, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3325281
   Fan MM, 2020, IEEE T VIS COMPUT GR, V26, P343, DOI 10.1109/TVCG.2019.2934797
   Fan Q. Zhao, 2021, P ACM C HUM FACT COM, DOI [10.1145/3411764.344568065M.Bostock,V.Ogievetsky,andJ, DOI 10.1145/3411764.344568065M.BOSTOCK,V.OGIEVETSKY,ANDJ]
   Felix C, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P153, DOI 10.1145/3242587.3242596
   Gotz D, 2008, IEEE S VIS ANAL, P123, DOI 10.1109/VAST.2008.4677365
   Halter G, 2019, COMPUT GRAPH FORUM, V38, P119, DOI 10.1111/cgf.13676
   Harezlak K, 2014, C HUM SYST INTERACT, P95, DOI 10.1109/HSI.2014.6860455
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Higuch K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6536, DOI 10.1145/3025453.3025821
   Holtzblatt H., 2014, Contextual Design: Evolved
   Kerdvibulvech C, 2007, I C COMP GRAPH IM VI, P419, DOI 10.1109/CGIV.2007.88
   Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Leake M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376519
   Lipford H. R., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P187, DOI 10.1109/VAST.2010.5653598
   Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493
   Marqués G, 2015, PROCEEDINGS IEEE/IFIP 13TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING 2015, P132, DOI 10.1109/EUC.2015.25
   Matteson DS, 2014, J AM STAT ASSOC, V109, P334, DOI 10.1080/01621459.2013.849605
   Meng HY, 2016, IEEE T CYBERNETICS, V46, P916, DOI 10.1109/TCYB.2015.2418092
   Mingming Fan, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512943
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819
   Munim I., 2017, P IEEE INT C EL INF, P1, DOI [10.1109/EICT.2017.827522752R.Y.da, DOI 10.1109/EICT.2017.827522752R.Y.DA]
   Nunnally D., 2016, UX Research: Practical Techniques for De-signing Better Products, P62
   Pavel A, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P517, DOI 10.1145/2984511.2984552
   Pavel C., 2014, P 27 ANN ACM S US IN, P573, DOI [DOI 10.1145/2642918.2647400, 10.1145/2642918.264740012A]
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Ramakant, 2015, IEEE INT ADV COMPUT, P639, DOI 10.1109/IADCC.2015.7154785
   Robinson C., 2006, P WORKSH VIS AN SPAT, P1
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Shi H, 2014, I C VIRTUAL REALITY, P350, DOI 10.1109/ICVRV.2014.6
   Silva N, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204546
   Sloetjes H, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P816
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Staiano J., 2012, Proceedings of the Designing Interactive Systems Conference (DIS '12), Newcastle, UK, P741, DOI DOI 10.1145/2317956.2318068
   Suja P, 2015, INT CONF CONTEMP, P348, DOI 10.1109/IC3.2015.7346705
   Tan S., 2014, P ACM C INT ENT, P1, DOI [10.1145/2677758.267776551K.M., DOI 10.1145/2677758.267776551K.M]
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Tullis B Albert T., 2013, Measuring the User Experience: Collecting,Analyzing, and Presenting Usability Metrics
   van de Wolfshaar J, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P188, DOI 10.1109/SSCI.2015.37
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P340, DOI 10.1109/TVCG.2017.2745279
   Zhao J, 2017, IEEE T VIS COMPUT GR, V23, P261, DOI 10.1109/TVCG.2016.2598543
NR 57
TC 1
Z9 1
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3841
EP 3856
DI 10.1109/TVCG.2023.3241581
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700050
PM 37022364
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Hirao, Y
   Narumi, T
   Argelaguet, F
   Lécuyer, A
AF Hirao, Yutaro
   Narumi, Takuji
   Argelaguet, Ferran
   Lecuyer, Anatole
TI Revisiting Walking-in-Place by Introducing Step-Height Control, Elastic
   Input, and Pseudo-Haptic Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Haptic interfaces; Frequency control; Force;
   Mathematical models; Foot; Visualization; Walking-in-place;
   pseudo-haptics; passive haptics; elastic input; virtual reality;
   locomotion
ID LOCOMOTION
AB Walking-in-place (WIP) is a locomotion technique that enables users to "walk infinitely" through vast virtual environments using walking-like gestures within a limited physical space. This article investigates alternative interaction schemes for WIP, addressing successively the control, input, and output of WIP. First, we introduce a novel height-based control to increase advanced speed. Second, we introduce a novel input system for WIP based on elastic and passive strips. Third, we introduce the use of pseudo-haptic feedback as a novel output for WIP meant to alter walking sensations. The results of a series of user studies show that height and frequency based control of WIP can facilitate higher virtual speed with greater efficacy and ease than in frequency-based WIP. Second, using an upward elastic input system can result in a stable virtual speed control, although excessively strong elastic forces may impact the usability and user experience. Finally, using a pseudo-haptic approach can improve the perceived realism of virtual slopes. Taken together, our results suggest that, for future VR applications, there is value in further research into the use of alternative interaction schemes for walking-in-place.
C1 [Hirao, Yutaro] Univ Tokyo, Tokyo 1138654, Japan.
   [Narumi, Takuji] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138654, Japan.
   [Argelaguet, Ferran; Lecuyer, Anatole] Univ Rennes, Inria, IRISA, CNRS, F-35000 Rennes, France.
C3 University of Tokyo; University of Tokyo; Inria; Centre National de la
   Recherche Scientifique (CNRS); Universite de Rennes
RP Hirao, Y (corresponding author), Univ Tokyo, Tokyo 1138654, Japan.
EM hirao@cyber.t.u-tokyo.ac.jp; narumi@cyber.t.u-tokyo.ac.jp;
   ferran.argelaguet@inria.fr; anatole.lecuyer@inria.fr
RI Narumi, Takuji/K-3925-2014
OI Narumi, Takuji/0000-0002-9010-1491
FU MEXT Grant-in-Aid for Scientific Research(S) [19H05661]; JSPS Fellows
   [21J12284]; Grants-in-Aid for Scientific Research [21J12284, 22H03628]
   Funding Source: KAKEN
FX This work was supported by the MEXT Grant-in-Aid for Scientific
   Research(S) under Grant 19H05661 and JSPS Fellows under Grant 21J12284.
CR Achibet M, 2015, P IEEE VIRT REAL ANN, P63, DOI 10.1109/VR.2015.7223325
   Achibet M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2014.6798843
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Bouguila L., 2003, P 13 INT C ART REAL
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Bruno L, 2013, LECT NOTES COMPUT SC, V8119, P370
   Cybershoes Inc., 2016, Cybershoes: VR locomotion interface
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   DEAN GA, 1965, ERGONOMICS, V8, P31, DOI 10.1080/00140136508930772
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Hanson S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P367, DOI [10.1109/vr.2019.8797751, 10.1109/VR.2019.8797751]
   Hejrati B, 2015, IEEE T HAPTICS, V8, P176, DOI 10.1109/TOH.2015.2404357
   Hoppe M., 2019, P CHI C HUM FACT COM, P1
   Ishikawa R, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P559, DOI 10.1145/3292147.3292234
   Iwata H, 2005, IEEE COMPUT GRAPH, V25, P64, DOI 10.1109/MCG.2005.5
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Kim W, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102648
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   Law AW, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P126, DOI 10.1109/HAVE.2008.4685311
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Magaña M, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P114, DOI 10.1109/HAVE.2008.4685309
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Matsumoto K., 2017, P ACM SIGGRAPH POST, P1
   Nguyen A, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225155
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Nilsson N. C., 2013, P MOT GAM, P155, DOI DOI 10.1145/2522628.2522655
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2014, IEEE T VIS COMPUT GR, V20, P569, DOI 10.1109/TVCG.2014.21
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Paljic A, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P216, DOI 10.1109/HAPTIC.2004.1287199
   Paljic A., 2004, P INT C EUROHAPTICS, P82
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Pusch A., 2011, P 13 INT C MULT INT, P57
   Shimamura R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1154, DOI [10.1109/VR.2019.8797960, 10.1109/vr.2019.8797960]
   Slater M., 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI [10.1145/210079.210084, DOI 10.1145/210079.210084]
   Son H., 2018, P CHI C HUM FACT COM, P1
   Swanson D. K., 2002, PhD thesis
   Templeman JN, 2007, IEEE Virtual Reality 2007, Proceedings, P285
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Tremblay L, 2004, PERCEPTION, V33, P329, DOI 10.1068/p5209
   Virtuix Inc., 2014, "Virtuix Omni: VR locomotion interface
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Wang CZ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281536
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   ZHAI SM, 1993, P SOC PHOTO-OPT INS, V2057, P130, DOI 10.1117/12.164895
NR 47
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3210
EP 3223
DI 10.1109/TVCG.2022.3228171
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700080
PM 37015485
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Jin, ZH
   Wang, XB
   Cheng, FR
   Sun, CH
   Liu, Q
   Qu, HM
AF Jin, Zhihua
   Wang, Xingbo
   Cheng, Furui
   Sun, Chunhui
   Liu, Qun
   Qu, Huamin
TI ShortcutLens: A Visual Analytics Approach for Exploring Shortcuts in
   Natural Language Understanding Dataset
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Benchmark testing; Task analysis; Natural language processing;
   Cognition; Guidelines; Predictive models; Computational modeling;
   Natural language understanding; shortcut; visual analytics
AB Benchmark datasets play an important role in evaluating Natural Language Understanding (NLU) models. However, shortcuts-unwanted biases in the benchmark datasets-can damage the effectiveness of benchmark datasets in revealing models' real capabilities. Since shortcuts vary in coverage, productivity, and semantic meaning, it is challenging for NLU experts to systematically understand and avoid them when creating benchmark datasets. In this paper, we develop a visual analytics system, ShortcutLens, to help NLU experts explore shortcuts in NLU benchmark datasets. The system allows users to conduct multi-level exploration of shortcuts. Specifically, Statistics View helps users grasp the statistics such as coverage and productivity of shortcuts in the benchmark dataset. Template View employs hierarchical and interpretable templates to summarize different types of shortcuts. Instance View allows users to check the corresponding instances covered by the shortcuts. We conduct case studies and expert interviews to evaluate the effectiveness and usability of the system. The results demonstrate that ShortcutLens supports users in gaining a better understanding of benchmark dataset issues through shortcuts, inspiring them to create challenging and pertinent benchmark datasets.
C1 [Jin, Zhihua; Wang, Xingbo; Cheng, Furui; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Cheng, Furui] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
   [Sun, Chunhui] Peking Univ, Beijing 100871, Peoples R China.
   [Liu, Qun] Huawei, Noahs Ark Lab, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Swiss Federal Institutes
   of Technology Domain; ETH Zurich; Peking University; Huawei Technologies
RP Jin, ZH (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM zjinak@cse.ust.hk; xwangeg@cse.ust.hk; furui.cheng@inf.ethz.ch;
   sch@pku.edu.cn; qun.liu@huawei.com; huamin@cse.ust.hk
OI Wang, Xingbo/0000-0001-5693-1128; Cheng, Furui/0000-0003-2329-6126
FU Hong Kong Theme-based Research Scheme [T41-709/17N]
FX This work was supported in part by the Hong Kong Theme-based Research
   Scheme under Grant T41-709/17N.
CR Alemzadeh S, 2020, COMPUT GRAPH FORUM, V39, P63, DOI 10.1111/cgf.13662
   Bender, 2018, T ASSOC COMPUT LING, V6, P587, DOI [10.1162/tacl_a_00041, DOI 10.1162/TACL_A_00041, DOI 10.1162/TACLA00041, 10.1162/tacla00041]
   Bors C, 2019, IEEE COMPUT GRAPH, V39, P61, DOI 10.1109/MCG.2019.2941856
   Bowman SR, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4843
   Branco R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1504
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Clements D.H., 1992, Handbook of research on mathematics teaching and learning: A project of the National Council of Teachers of Mathematics, P420
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ethayarajh K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4846
   EVERITT B, 1980, QUAL QUANT, V14, P75, DOI 10.1007/BF00154794
   Gebru T., 2021, Commun. ACM, V64, P92
   Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z
   Guan J, 2020, T ASSOC COMPUT LING, V8, P93, DOI 10.1162/tacl_a_00302
   Gururangan S., 2018, P C N AM CHAPT ASS C, P107, DOI [DOI 10.18653/V1/N18-2017, 10.18653/v1/N18-2017]
   Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018
   Jin Y., IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3148107.33, DOI 10.1109/TVCG.2022.3148107.33]
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kiela D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4110
   Lai YX, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P989
   Lakshminarayanan B., 2017, Advances in neural information processing systems, P6405
   Laughlin B, 2019, IEEE SYM VIS CYB SEC, DOI 10.1109/vizsec48167.2019.9161563
   Le Bras R, 2020, PR MACH LEARN RES, V119
   Lee Kimin, 2018, P INT C LEARN REPR
   Liu ALS, 2022, Arxiv, DOI arXiv:2201.05955
   Liu SS, 2019, IEEE T VIS COMPUT GR, V25, P651, DOI 10.1109/TVCG.2018.2865230
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Mirzaee R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4582
   Mishra S, 2020, Arxiv, DOI arXiv:2005.00816
   Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4658
   Paullada A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100336
   Poliak Adam, 2018, Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, P180, DOI [DOI 10.18653/V1/S18-2023, 10.18653/v1/S18-2023]
   Rogers M. Gardner, 2021, QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension
   Sakaguchi K, 2020, AAAI CONF ARTIF INTE, V34, P8732
   Schick T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6943
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Tenney I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P107
   Wang A., 2019, P ADV NEUR INF PROC, P3275
   Wang Alex, 2019, P INT C LEARN REPR
   Wang B., 2021, P NEUR INF PROC SYST, P13
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290
   Wu K., 2020, P CHI C HUM FACT COM, P1
   Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   ZANG Y., 2020, P 58 ANN M ASS COMP, P6066, DOI DOI 10.18653/V1/2020.ACL-MAIN.540
   Zeng GY, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P363
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhao M., 2022, P FIND ASS COMP LING, P675
NR 58
TC 4
Z9 4
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3594
EP 3608
DI 10.1109/TVCG.2023.3236380
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700068
PM 37018729
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Le, TNH
   Yao, SY
   Wu, CT
   Lee, TY
AF Le, Thi-Ngoc-Hanh
   Yao, Sheng-Yi
   Wu, Chun-Te
   Lee, Tong-Yee
TI Regenerating Arbitrary Video Sequences With Distillation Path-Finding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Feature extraction; Correlation; Shape; Video sequences;
   Prediction algorithms; Measurement; sequencing; RSFNet; distillation;
   SDPF
AB If the video has long been mentioned as a widespread visualization form, the animation sequence in the video is mentioned as storytelling for people. Producing an animation requires intensive human labor from skilled professional artists to obtain plausible animation in both content and motion direction, incredibly for animations with complex content, multiple moving objects, and dense movement. This article presents an interactive framework to generate new sequences according to the users' preference on the starting frame. The critical contrast of our approach versus prior work and existing commercial applications is that novel sequences with arbitrary starting frame are produced by our system with a consistent degree in both content and motion direction. To achieve this effectively, we first learn the feature correlation on the frameset of the given video through a proposed network called RSFNet. Then, we develop a novel path-finding algorithm, SDPF, which formulates the knowledge of motion directions of the source video to estimate the smooth and plausible sequences. The extensive experiments show that our framework can produce new animations on the cartoon and natural scenes and advance prior works and commercial applications to enable users to obtain more predictable results.
C1 [Le, Thi-Ngoc-Hanh; Yao, Sheng-Yi; Wu, Chun-Te; Lee, Tong-Yee] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
EM ngochanh.le1987@gmail.com; nd8081018@gs.ncku.edu.tw;
   oojimda3838@hotmail.com; tonylee@mail.ncku.edu.tw
RI Hanh, Le Thi Ngoc/JQI-5639-2023
OI Hanh, Le Thi Ngoc/0000-0001-9667-9780
FU National Science and Technology Council, Taiwan [111-2221-E-006-112-MY3,
   110-2221-E-006-135-MY3]
FX This work was supported in part by the National Science and Technology
   Council under Grants 111-2221-E-006-112-MY3 and 110-2221-E-006-135-MY3,
   Taiwan.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Chen Y, 2020, IEEE T CIRC SYST VID, V30, P3282, DOI 10.1109/TCSVT.2019.2931589
   de Juan Christina., 2004, SCA 2004: Proceedings of the 2004 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P267, DOI DOI 10.1145/1028523.1028559
   Eng E., 1996, Linux J., P2
   Fried O, 2017, COMPUT GRAPH FORUM, V36, P183, DOI 10.1111/cgf.13284
   Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P148
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I., 2016, Deep Learn., V1
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Holden D., 2015, SIGGRAPH Asia 2015 Technical Briefs, SA'15, P1, DOI [DOI 10.1145/2820903.2820918, 10.1145/2820903.2820918]
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jiao Y, 2021, IEEE IMAGE PROC, P2558, DOI 10.1109/ICIP42928.2021.9506523
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Khan A, 2022, Arxiv, DOI arXiv:2112.01641
   Kingma D. P., 2014, arXiv
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Morace CC, 2022, MULTIMED TOOLS APPL, V81, P23687, DOI 10.1007/s11042-022-12251-1
   Nwankpa C, 2021, INT C COMP SCI TEC, P124, DOI DOI 10.48550/ARXIV.1811.03378
   Osadchy M, 2007, J MACH LEARN RES, V8, P1197
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Schodl A., 2002, SCA 02 P 2002 ACM SI, P121, DOI DOI 10.1145/545261.545281
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Xu C, 2023, IEEE T VIS COMPUT GR, V29, P4001, DOI 10.1109/TVCG.2022.3174656
   Yang Y, 2010, IEEE T CIRC SYST VID, V20, P1745, DOI 10.1109/TCSVT.2010.2087452
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
   Yu J, 2012, IEEE T SYST MAN CY B, V42, P1413, DOI 10.1109/TSMCB.2012.2192108
   Yu J, 2011, MULTIMEDIA SYST, V17, P409, DOI 10.1007/s00530-010-0225-6
   Zhang J, 2018, IEEE T IMAGE PROCESS, V27, P2420, DOI 10.1109/TIP.2018.2804218
   Zhang L, 2012, IEEE T VIS COMPUT GR, V18, P1156, DOI 10.1109/TVCG.2011.111
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang S.-W., 2019, P SIGGRAPH AS, P1
NR 33
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3622
EP 3635
DI 10.1109/TVCG.2023.3237739
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700083
PM 37021849
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ruddle, RA
   Cheshire, J
   Fernstad, SJ
AF Ruddle, Roy A.
   Cheshire, James
   Fernstad, Sara Johansson
TI Tasks and Visualizations Used for Data Profiling: A Survey and Interview
   Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Data integrity; Interviews;
   Visualization; Bars; Industries; Data profiling; data quality; survey;
   interview
ID DATA QUALITY ASSESSMENT; VISUAL ANALYTICS
AB The use of good-quality data to inform decision making is entirely dependent on robust processes to ensure it is fit for purpose. Such processes vary between organisations, and between those tasked with designing and following them. In this article we report on a survey of 53 data analysts from many industry sectors, 24 of whom also participated in in-depth interviews, about computational and visual methods for characterizing data and investigating data quality. The paper makes contributions in two key areas. The first is to data science fundamentals, because our lists of data profiling tasks and visualization techniques are more comprehensive than those published elsewhere. The second concerns the application question "what does good profiling look like to those who routinely perform it?", which we answer by highlighting the diversity of profiling tasks, unusual practice and exemplars of visualization, and recommendations about formalizing processes and creating rulebooks.
C1 [Ruddle, Roy A.] Univ Leeds, Leeds LS2 9JT, England.
   [Cheshire, James] UCL, London LS2 9JT, England.
   [Fernstad, Sara Johansson] Newcastle Univ, Newcastle Upon Tyne NE1 7RU, England.
C3 University of Leeds; University of London; University College London;
   Newcastle University - UK
RP Ruddle, RA (corresponding author), Univ Leeds, Leeds LS2 9JT, England.
EM R.A.Ruddle@leeds.ac.uk; james.cheshire@ucl.ac.uk;
   sara.fernstad@newcastle.ac.uk
OI Johansson Fernstad, Sara/0000-0003-4518-5144
FU Alan Turing Institute
FX This research was supported by the Alan Turing Institute.
CR Abedjan Z, 2015, VLDB J, V24, P557, DOI 10.1007/s00778-015-0389-y
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   ANSCOMBE FJ, 1973, AM STAT, V27, P17, DOI 10.2307/2682899
   Arbesser C, 2017, IEEE T VIS COMPUT GR, V23, P641, DOI 10.1109/TVCG.2016.2598592
   Batch A, 2018, IEEE T VIS COMPUT GR, V24, P278, DOI 10.1109/TVCG.2017.2743990
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Bigelow A., 2020, IEEE Trans. Vis. Comput. Graph., V27, P1503
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   D. V. Society, 2021, Data visualization state of the industry survey
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Eaton C, 2005, LECT NOTES COMPUT SC, V3585, P861, DOI 10.1007/11555261_68
   Estiri Hossein, 2016, AMIA Jt Summits Transl Sci Proc, V2016, P60
   Fernstad SJ, 2019, INFORM VISUAL, V18, P230, DOI 10.1177/1473871618785387
   gartner, 2022, Data preparation tools reviews and ratings
   Gschwandtner T., 2014, P 14 INT C KNOWL TEC, P1
   Gschwandtner T, 2018, IEEE PAC VIS SYMP, P205, DOI 10.1109/PacificVis.2018.00034
   Hynes N., 2017, P 31 C NEUR INF PROC
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Little RJ., 2014, Statistical analysis with missing data
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   Liu SX, 2018, VIS INFORM, V2, P191, DOI 10.1016/j.visinf.2018.12.001
   Matejka J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1290, DOI 10.1145/3025453.3025912
   Menon S., 2019, Market guide for data preparation tools
   Mosca A., 2019, P 21 EUR C VIS, P73
   Naumann F, 2013, SIGMOD REC, V42, P40, DOI 10.1145/2590989.2590995
   Milani AMP, 2020, INFORM VISUAL, V19, P273, DOI 10.1177/1473871619896101
   Ruddle RA, 2019, HEALTHINF: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL 5: HEALTHINF, P230, DOI 10.5220/0007354802300238
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shome Arumoy, 2022, P 1 INT C AI ENG SOF, P205
   Song H, 2019, IEEE T VIS COMPUT GR, V25, P914, DOI 10.1109/TVCG.2018.2864914
   Weiskopf NG, 2013, J AM MED INFORM ASSN, V20, P144, DOI 10.1136/amiajnl-2011-000681
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Zernichow Bjorn Marius, 2017, On the Move to Meaningful Internet Systems. OTM 2017 Conferences. Confederated International Conferences: CoopIS, C&TC, and ODBASE 2017. Proceedings: LNCS 10574, P480, DOI 10.1007/978-3-319-69459-7_32
NR 36
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3400
EP 3412
DI 10.1109/TVCG.2023.3234337
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700028
PM 37018563
OA Green Published, Green Accepted
DA 2024-08-05
ER

PT J
AU Taka, E
   Stein, S
   Williamson, JH
AF Taka, Evdoxia
   Stein, Sebastian
   Williamson, John H.
TI Does Interactive Conditioning Help Users Better Understand the Structure
   of Probabilistic Models?
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Probabilistic logic; Mathematical models; Temperature distribution;
   Visualization; Computational modeling; Shape; Bayes methods;
   Brushing-and-linking; empirical study; interactive conditioning; prior
   distribution; probabilistic models; scatter plot matrix
ID VISUALIZATION
AB Despite growing interest in probabilistic modeling approaches and availability of learning tools, people are hesitant to use them. There is a need for tools to communicate probabilistic models more intuitively and help users build, validate, use effectively or trust probabilistic models. We focus on visual representations of probabilistic models and introduce the Interactive Pair Plot (IPP) for visualization of a model's uncertainty, a scatter plot matrix of a probabilistic model allowing interactive conditioning on the model's variables. We investigate whether the use of interactive conditioning in a scatter plot matrix of a model helps users better understand variables' relations. We conducted a user study and the findings suggest that improvements in the understanding of the interaction group are the most pronounced for more exotic structures, such as hierarchical models or unfamiliar parameterizations, in comparison to the understanding of the static group. As the detail of the inferred information increases, interactive conditioning does not lead to considerably longer response times. Finally, interactive conditioning improves participants' confidence about their responses.
C1 [Taka, Evdoxia; Stein, Sebastian; Williamson, John H.] Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Scotland.
C3 University of Glasgow
RP Taka, E (corresponding author), Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Scotland.
EM e.taka.1@research.gla.ac.uk; sebastian.stein@glasgow.ac.uk;
   johnh.williamson@glasgow.ac.uk
OI Williamson, John/0000-0001-8085-7853; Taka, Evdoxia/0000-0001-7011-3367;
   Stein, Sebastian/0000-0003-1828-4008
FU EPSRC [EP/R018634/1]
FX This work was supported by the Closed-Loop Data Science for Complex,
   Computationally- and Data-Intensive Analytics, EPSRC Project under Grant
   EP/R018634/1.
CR BECKER RA, 1987, TECHNOMETRICS, V29, P127, DOI 10.2307/1269768
   Brase GL, 2009, APPL COGNITIVE PSYCH, V23, P369, DOI 10.1002/acp.1460
   Breslav S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P245, DOI 10.1145/2598153.2598168
   Cole W. G., 1989, SIGCHI Bulletin, P381, DOI 10.1145/67450.67522
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Ellson J, 2004, MATH VIS, P127
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Gabry J., Bayesplot
   github, Interactive Probabilistic Models Explorer
   github, ArviZ Point Estimate Pairplot
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Kay M, Tidybayes
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4521, DOI 10.1145/2858036.2858465
   Khan A, 2018, HUM-COMPUT INTERACT, V33, P207, DOI 10.1080/07370024.2016.1203264
   Koller N.F. Daphne., 2009, Probabilistic Graphical Models: Principles and Techniques
   Kruschke J., 2014, Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, V2nd
   Kulesza T., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces. IUI'15, P126, DOI [10.1145/2678025.2701399, DOI 10.1145/2678025.2701399]
   Kumar C., 2019, J. Open Source Softw., V4
   Lambert B, 2018, "12.3. The difficulty with real-life Bayesian inference,"inA Student's Guide to Bayesian Statistics, P265
   Martin AR, 1995, VISUALIZATION '95 - PROCEEDINGS, P271, DOI 10.1109/VISUAL.1995.485139
   McDonald J. A., 1982, Ph.D.dissertation
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Mosca A., 2021, P CHI C HUM FACT COM, P1
   Newton C. M., 1978, "Graphics: From alpha to omega in data analysis,"inGraphical Representation of Multivariate Data, P59
   Nguyen Q.V, 2016, P INT S VIS INF COMM, P43
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Ottley B., 2012, Tech. Rep.
   Phelan J., 2019, P CHI C HUM FACT COM, P1
   Nguyen QV, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.09.004
   Sankaran K, 2018, J COMPUT GRAPH STAT, V27, P553, DOI 10.1080/10618600.2017.1392866
   Sarma M., 2020, P CHI C HUM FACT COM, P1
   Spiegelhalter D., 2003, WinBUGS Ver-sion 2.0 Users Manual
   Stan Develop. Team, Shinystan
   Taka E, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.567344
   Taka S., 2022, University of Glasgow enlighten repository, DOI [10.5525/gla.researchdata.1248 n, DOI 10.5525/GLA.RESEARCHDATA.1248N]
   Tsai S., 2011, P HUM FACT ERG SOC A, P385, DOI [10.1177/1071181311551079, DOI 10.1177/1071181311551079]
NR 38
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3256
EP 3267
DI 10.1109/TVCG.2022.3231967
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700030
PM 37018342
OA Green Accepted
DA 2024-08-05
ER

PT J
AU Rezaie, M
   Tory, M
   Carpendale, S
AF Rezaie, Maryam
   Tory, Melanie
   Carpendale, Sheelagh
TI Struggles and Strategies in Understanding Information Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Encoding; Training;
   Bars; Standards; Information visualization; qualitative study;
   visualization sensemaking
ID CONCEPTUAL-FRAMEWORK; INSIGHT; SPACE
AB While the visualization community is increasingly aware that people often find visualizations difficult to understand, there is less information about what we need to do to create comprehensible visualizations. To help visualization creators and designers improve their visualizations, we need to better understand what kind of support people are looking for in their sensemaking process. Empirical studies are needed to tease apart the details of what makes the process of understanding difficult for visualization viewers. We conducted a qualitative study with 14 participants, observing them as they described how they were trying to make sense of 20 information visualizations. We identified the challenges participants faced throughout their sensemaking process and the strategies they employed to help themselves in overcoming the challenges. Our findings show how details and nuances within visualizations can impact comprehensibility and offer research suggestions to help us move toward more understandable visualizations.
C1 [Rezaie, Maryam; Carpendale, Sheelagh] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
   [Tory, Melanie] Northeastern Univ, Boston, MA 02115 USA.
C3 Simon Fraser University; Northeastern University
RP Rezaie, M (corresponding author), Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
EM maryam_rezaie@sfu.ca; m.tory@northeastern.edu; sheelagh@sfu.ca
OI Rezaie, Maryam/0000-0002-0708-8020; Tory, Melanie/0000-0002-6806-9253;
   Carpendale, Sheelagh/0000-0002-5127-9780
FU NSERC
FX No Statement Available
CR Ainsworth S, 2006, LEARN INSTR, V16, P183, DOI 10.1016/j.learninstruc.2006.03.001
   Alsaiari A., 2020, EUROVIS SHORT PAPERS, P91, DOI DOI 10.2312/EVS.20201054
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Baldonado MQW, 2000, P WORK C ADV VIS INT, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P1407, DOI 10.1109/TVCG.2018.2802520
   Bloom B. S., 1956, Cognitive Domain, DOI [10.1007/978-1-4419-1428-6, DOI 10.1007/978-1-4419-1428-6]
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Burns A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581524
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Campbell JL, 2013, SOCIOL METHOD RES, V42, P294, DOI 10.1177/0049124113500475
   Canham M, 2010, LEARN INSTR, V20, P155, DOI 10.1016/j.learninstruc.2009.02.014
   Card S.K., 1999, Readings in Information Visualization: Using Vision to Think. The Morgan Kaufmann series in interactive technologies
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Collins C, 2007, IEEE T VIS COMPUT GR, V13, P1192, DOI 10.1109/TVCG.2007.70521
   Convertino G., 2017, P CHI C HUM FACT COM, P1075, DOI [10.1145/3027063.3053359, DOI 10.1145/3027063.3053359]
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Dasgupta A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1193, DOI 10.1145/3025453.3025882
   Davidson K, 2023, IEEE T VIS COMPUT GR, V29, P5294, DOI 10.1109/TVCG.2022.3207357
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Edsall R. M., 1997, Gis/Lis, V97, P28
   Elgendi M, 2017, NAT BIOTECHNOL, V35, P990, DOI 10.1038/nbt.3986
   Erete S, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1273, DOI 10.1145/2818048.2820068
   Freedman EG, 2002, LECT NOTES ARTIF INT, V2317, P18
   Göbel F, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204544
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Grolemund G, 2014, INT STAT REV, V82, P184, DOI 10.1111/insr.12028
   Grossman T, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1515
   Guo H, 2016, IEEE T VIS COMPUT GR, V22, P51, DOI 10.1109/TVCG.2015.2467613
   Haider Johanna Doppler, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P193, DOI 10.1177/1541931213601532
   He C, 2021, IEEE T VIS COMPUT GR, V27, P3410, DOI 10.1109/TVCG.2020.2977634
   Isenberg P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1217
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Karer B, 2021, IEEE T VIS COMPUT GR, V27, P1011, DOI 10.1109/TVCG.2020.3030376
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lo LYH, 2022, COMPUT GRAPH FORUM, V41, P515, DOI 10.1111/cgf.14559
   LOWE R, 1988, RES SCI ED, V18, P112, DOI 10.1007/BF02356586
   Luo WH, 2023, J COMPUT INFORM SYST, V63, P81, DOI 10.1080/08874417.2021.2023338
   Ma J, 2020, IEEE T VIS COMPUT GR, V26, P472, DOI 10.1109/TVCG.2019.2934401
   Mahmud S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376414
   Masson D, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501895
   Mayr E., 2010, P 3 WORKSH TIM ERR N, P8, DOI [10.1145/2110192.2110194, DOI 10.1145/2110192.2110194]
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Novick DG, 2009, SIGDOC'09: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P97
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Perkhofer LM, 2019, J APPL ACCOUNT RES, V20, P497, DOI 10.1108/JAAR-10-2017-0114
   Pirolli P., 2005, Proceedings of International Conference on Intelligence Analysis, V5, P2
   Rosenthal S., 2022, P IEEE S VIS LANG HU, P1, DOI [10.1109/VL/HCC53370.2022.9833097, DOI 10.1109/VL/HCC53370.2022.9833097]
   Russell D. M., 2008, P HUM FACT COMP SYST, P3981, DOI [10.1145/1358628.1358972, DOI 10.1145/1358628.1358972]
   Saket B, 2015, Arxiv, DOI arXiv:1503.00582
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Stoiber C, 2022, VIS INFORM, V6, P34, DOI 10.1016/j.visinf.2022.07.001
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Tobiasz M, 2009, IEEE T VIS COMPUT GR, V15, P1065, DOI 10.1109/TVCG.2009.162
   Todorovic D., 2008, Gestalt principles, V3, P5345, DOI DOI 10.4249/SCHOLARPEDIA.5345
   Tory M, 2023, IEEE COMPUT GRAPH, V43, P22, DOI 10.1109/MCG.2021.3136545
   Vears DF, 2022, FOCUS HEALTH PROF ED, V23, P111
   Viau C, 2012, COMPUT GRAPH FORUM, V31, P1285, DOI 10.1111/j.1467-8659.2012.03121.x
   Wang JC, 2022, J VISUAL-JAPAN, V25, P59, DOI 10.1007/s12650-021-00778-8
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI DOI 10.1145/1377966.1377971
   Zgraggen E, 2014, IEEE T VIS COMPUT GR, V20, P2112, DOI 10.1109/TVCG.2014.2346293
NR 66
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3035
EP 3048
DI 10.1109/TVCG.2024.3388560
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500001
PM 38619946
DA 2024-08-05
ER

PT J
AU Chen, JJ
   Hung, HC
   Sun, YR
   Chuang, JH
AF Chen, Jun-Jie
   Hung, Huan-Chang
   Sun, Yu-Ru
   Chuang, Jung-Hong
TI APF-S2T: Steering to Target Redirection Walking Based on Artificial
   Potential Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Aerospace electronics; Virtual environments; Force;
   Vectors; Layout; Robots; Redirected walking; artificial potential field;
   locomotion; virtual reality
AB Redirected walking (RDW) enables users to walk naturally within a virtual environment that is larger than the physical environment. Recently, several artificial potential field (APF) and alignment-based redirected controllers have been developed and have been demonstrated to significantly outperform conventional controllers. APF Steer-to-Gradient (APF-S2G) and APF Redirected Walking (APF-RDW) utilize the negative gradient and the total force vector, respectively, which are localized to the user's position. These vectors usually point towards the opposite wall when the user is in corridors, resulting in frequent resets within those regions. This paper introduces the APF Steer-to-Target (APF-S2T), a redirected controller that first finds the target sample point with the lowest score in the user's walkable area in both physical and virtual environments. The score of a sample point is determined by the APF value at the point and the distance from the user's position. The direction from the user's position to the target point is then used as the steering direction for setting RDW gains. We conducted a simulation-based evaluation to compare APF-S2T, APF-S2G, APF-RDW, Visibility Polygon-based alignment (Vis.-Poly.) and Alignment-Optimized controllers in terms of the number of resets and the average distance between resets. The results indicated that APF-S2T significantly outperformed the state-of-the-art controllers.
C1 [Chen, Jun-Jie; Hung, Huan-Chang; Sun, Yu-Ru; Chuang, Jung-Hong] Natl Yang Ming Chiao Tung Univ, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, JJ (corresponding author), Natl Yang Ming Chiao Tung Univ, Hsinchu, Taiwan.
EM jay8832791@gmail.com; hchung.cs10@nycu.edu.tw;
   yuru1219.cs11@nycu.edu.tw; jhchuang@cs.nycu.edu.tw
FU National Science and Technology Council, R.O.C.
FX No Statement Available
CR [Anonymous], 2024, HMD geometry database
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2277, DOI 10.1109/TVCG.2022.3150500
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2288, DOI 10.1109/TVCG.2022.3150466
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bolas E. A., 2015, ICAT EGVE 2015 INT C, P93, DOI DOI 10.2312/EGVE.20151315
   Croucher W., 2023, IEEE Transac-tions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.33134393[8]T, DOI 10.1109/TVCG.2023.33134393[8]T]
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Fan CW, 2023, Symposium Virtual Re, P53, DOI 10.1109/VR55154.2023.00021
   Hirt Y., 2022, IN2022 IEEECONFERENC
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Kwon SU, 2022, INT SYM MIX AUGMENT, P758, DOI 10.1109/ISMAR55827.2022.00094
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.00-70, 10.1109/VR46266.2020.1581309443724]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Razzaque Z., 2001, InProceedings of Eurographics, V1, P2
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Suri S., 1986, 2 S COMPUTATIONAL GE, P14
   Thomas C. Hutton, 2020, INPROCEEDINGS 26 ACM, DOI [10.1145/3385956.34189663[33]J, DOI 10.1145/3385956.34189663[33]J]
   Thomas J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P317, DOI [10.1109/VRW50115.2020.00071, 10.1109/VRW50115.2020.0-205]
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Wu XL, 2023, IEEE T VIS COMPUT GR, V29, P4556, DOI 10.1109/TVCG.2023.3320208
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Zanbaka B. C., 2005, IEEE Transactions on Visualizationand Computer Graphics, V11, P1
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 43
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2464
EP 2473
DI 10.1109/TVCG.2024.3372052
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400061
PM 38437126
DA 2024-08-05
ER

PT J
AU Lee, S
   Viola, I
   Rossi, S
   Guo, ZR
   Reimat, I
   Lawicka, K
   Striner, A
   Cesar, P
AF Lee, Sueyoon
   Viola, Irene
   Rossi, Silvia
   Guo, Zhirui
   Reimat, Ignacio
   Lawicka, Kinga
   Striner, Alina
   Cesar, Pablo
TI Designing and Evaluating a VR Lobby for a Socially Enriching Remote
   Opera Watching Experience
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE User experience; Art; Motion pictures; Prototypes; Cultural differences;
   Usability; Training; Perfoming arts; Virtual reality; Collaborative
   interaction; Empirical studies in HCI; User studies
ID VIRTUAL-REALITY; MIXED REALITY
AB The latest social VR technologies have enabled users to attend traditional media and arts performances together while being geographically removed, making such experiences accessible despite budget, distance, and other restrictions. In this work, we aim at improving the way remote performances are shared by designing and evaluating a VR theatre lobby which serves as a space for users to gather, interact, and relive the common experience of watching a virtual opera. We conducted an initial test with experts (N=10, i.e., designers and opera enthusiasts) in pairs using our VR lobby prototype, developed based on the theoretical lobby design concept. A unique aspect of our experience is its highly realistic representation of users in the virtual space. The test results guided refinements to the VR lobby structure and implementation, aiming to improve the user experience and align it more closely with the social VR lobby's intended purpose. With the enhanced prototype, we ran a between-subject controlled study (N=40) to compare the user experience in the social VR lobby between individuals and paired participants. To do so, we designed and validated a questionnaire to measure the user experience in the VR lobby. Results of our mixed-methods analysis, including interviews, questionnaire results, and user behavior, reveal the strength of our social VR lobby in connecting with other users, consuming the opera in a deeper manner, and exploring new possibilities beyond what is common in real life. All supplemental materials are available at https://github.com/cwi-dis/IEEEVR2024-VRLobby.
C1 [Lee, Sueyoon; Viola, Irene; Rossi, Silvia; Guo, Zhirui; Reimat, Ignacio; Lawicka, Kinga; Striner, Alina; Cesar, Pablo] Ctr Wiskunde & Informat, Amsterdam, Netherlands.
   [Cesar, Pablo] Delft Univ Technol, Delft, Netherlands.
C3 Delft University of Technology
RP Lee, S (corresponding author), Ctr Wiskunde & Informat, Amsterdam, Netherlands.
EM sueyoon.lee@cwi.nl; irene.viola@cwi.nl; silvia.rossi@cwi.nl;
   zhirui.guo@cwi.nl; ignacio.reimat@cwi.nl; kinga.lawicka@cwi.nl;
   alina.striner@cwi.nl; pablo.cesar@cwi.nl
OI Guo, Zhirui/0009-0001-4495-5357; Lee, Sueyoon/0000-0001-5924-1704;
   Rossi, Silvia/0000-0002-2779-2314
FU European Union
FX No Statement Available
CR Arlati S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020261
   Benford S, 2001, COMMUN ACM, V44, P79, DOI 10.1145/379300.379322
   Benford S., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P242
   Benford S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P709
   Benzecry CE, 2009, QUAL SOCIOL, V32, P131, DOI 10.1007/s11133-009-9123-7
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Caro A., 2007, CONSUMING EXPERIENCE
   Cesar P., 2021, P 2021 CHI C HUMAN F, P1
   Charters E., 2003, Brock Educ J., V12, DOI [10.26522/brocked.v12i2.38, DOI 10.26522/BROCKED.V12I2.38]
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Costello A.B., 2005, Practical Assessment, Research Evaluation, V10, P1, DOI [DOI 10.7275/JYJ1-4868, 10.7275/jyj1-4868]
   Debska M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16193673
   Dembin R. M., 2016, Where the show begins in the lobby
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fontaine J.R. J., 2005, ENCY SOCIAL MEASUREM, P803, DOI [DOI 10.1016/B0-12-369398-5/00116-X, 10.1016/B0-12-369398-5/00116-X]
   Gunkel S, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P233, DOI 10.1145/3210825.3213566
   Hall E. T., 1969, The Hidden Dimension: Man's Use of Space in Public and Private
   Hansen AH, 2013, ELGAR ORIG REF, P209
   He LJ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281508
   Howard MC, 2016, INT J HUM-COMPUT INT, V32, P51, DOI 10.1080/10447318.2015.1087664
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Jansen J, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P341, DOI 10.1145/3339825.3393578
   Jie Li, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382836
   Kennedy R.S., 1993, Int. J. Aviat. Psy, P203
   Kilpatrick D. R., 2010, The theatre lobby experience: the audience's perspective
   Le DA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P485, DOI [10.1109/VRW50115.2020.0-175, 10.1109/VRW50115.2020.00101]
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Lee S, 2022, PROCEEDINGS OF THE 2022 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2022, P293, DOI 10.1145/3505284.3532980
   Lemmens JS, 2022, VIRTUAL REAL-LONDON, V26, P223, DOI 10.1007/s10055-021-00555-w
   Li J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375160
   Li J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300897
   Maguire M., 2017, All Ireland Journal of Higher Education, V9, DOI DOI 10.1109/TIA.2014.2306979
   Maslow A., 1943, Index of DOCS/Teacing {sp} Collection/Honolulu
   Matarasso F., 2013, UNESCO OBSERVATORY M, V3, P1
   McIntyre M. H., 2007, Audience knowledge digest: Why people visit museums and galleries, and what can be done to attract them
   Mekuria R, 2015, PROC SPIE, V9599, DOI 10.1117/12.2203312
   Montagud M, 2022, VIRTUAL REAL-LONDON, V26, P1593, DOI 10.1007/s10055-022-00651-5
   Monteiro D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P53, DOI 10.1109/AIVR.2018.00015
   Moreira C., 2022, IEEE Access
   Mueser D, 2018, INT J EVENT FESTIV M, V9, P183, DOI 10.1108/IJEFM-05-2018-0030
   Mystakidis S, 2020, INT CONF INFORM INTE, P365, DOI 10.1109/iisa50023.2020.9284417
   neill S., 2016, Participations: International Journal of Energy Research, V13, P24
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Pittarello F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399919
   Pitts SE, 2016, PSYCHOL MUSIC, V44, P1175, DOI 10.1177/0305735615615420
   Ramey HL, 2015, J ADOLESCENCE, V45, P237, DOI 10.1016/j.adolescence.2015.09.006
   Reidy B. K., 2016, Arts Council England, V11
   Reimat I, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P6955, DOI 10.1145/3503161.3547732
   Rossi S, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL WORKSHOP ON IMMERSIVE MIXED AND VIRTUAL ENVIRONMENT SYSTEMS (MMVE '21), P1, DOI 10.1145/3458307.3463371
   Rostami A, 2022, PROCEEDINGS OF THE 2022 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2022, P95, DOI 10.1145/3505284.3529966
   Rothe S, 2021, VIRTUAL REAL-LONDON, V25, P613, DOI 10.1007/s10055-020-00472-4
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Scorolli C, 2023, COMPUT HUM BEHAV, V149, DOI 10.1016/j.chb.2023.107910
   Sedan CI, 2013, SIMULAT GAMING, V44, P821, DOI 10.1177/1046878113514807
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Striner A., 2021, CHI 21, DOI DOI 10.1145/3411764.3445511
   Tcha-Tokey K, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927955
   Van Schaik P, 2004, CYBERPSYCHOL BEHAV, V7, P540, DOI 10.1089/1094931042403145
   Vinayagamoorthy V., 2004, 7 ANN INT PRESENCE W, P148
   Viola I, 2023, IEEE MULTIMEDIA, V30, P48, DOI 10.1109/MMUL.2023.3263943
   Walmsley Ben., 2011, J CUSTOMER BEHAV, V10, P335
   Webb AM, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P432, DOI 10.1145/2818048.2819974
   Weber S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628298
   Williamson J., 2021, P 2021 CHI C HUMAN F, P1
   Zheleva A., 2021, Augmented Reality and Virtual Reality, P125, DOI DOI 10.1007/978-3-030-68086-2_10
   Zhou Q., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI DOI 10.1145/3411764.3445804
   Zizza C, 2018, CONSUM COMM NETWORK
NR 69
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2055
EP 2065
DI 10.1109/TVCG.2024.3372081
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400009
PM 38437080
DA 2024-08-05
ER

PT J
AU Alebri, M
   Costanza, E
   Panagiotidou, G
   Brumby, DP
AF Alebri, Muna
   Costanza, Enrico
   Panagiotidou, Georgia
   Brumby, Duncan P.
TI Embellishments Revisited: Perceptions of Embellished Visualisations
   Through the Viewer's Lens
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualizations; Embellishments; Non-experts in visualisation and design
ID INFORMATION VISUALIZATION
AB Embellishments are features commonly used in everyday visualisations which are demonstrated to enhance assimilation and memorability. Despite their popularity, little is known about their impact on enticing readers to explore visualisations. To address this gap, we conducted 18 interviews with a diverse group of participants who were consumers of news media but non-experts in visualisation and design. Participants were shown ten embellished and plain visualisations collected from the news and asked to rank them based on enticement and ease of understanding. Extending prior work, our interview results suggest that visualisations with multiple embellishment types might make a visualisation perceived as more enticing. An important finding from our study is that the widespread of certain embellishments in the media might have made them part of visualisation conventions, making a visualisation appear more objective but less enticing. Based on these findings, we ran a follow-up online user study showing participants variations of the visualisations with multiple embellishments to isolate each embellishment type and investigate its effect. We found that variations with salient embellishments were perceived as more enticing. We argue that to unpack the concept of embellishments; we must consider two factors: embellishment saliency and editorial styles. Our study contributes concept and design considerations to the literature concerned with visualisation design for non-experts in visualisation and design.
C1 [Alebri, Muna; Costanza, Enrico; Panagiotidou, Georgia; Brumby, Duncan P.] UCL, London, England.
   [Alebri, Muna] United Arab Emirates Univ, Al Ain, U Arab Emirates.
C3 University of London; University College London; United Arab Emirates
   University
RP Alebri, M (corresponding author), UCL, London, England.; Alebri, M (corresponding author), United Arab Emirates Univ, Al Ain, U Arab Emirates.
EM muna.alebri.19@ucl.ac.uk; e.costanza@ucl.ac.uk;
   georgia.panagiotidou@kcl.ac.uk; d.brumpy@ucl.ac.uk
OI Panagiotidou, Georgia/0000-0003-4408-6371; Alebri,
   Muna/0000-0002-6471-6206
FU United Arab Emirates University and the Engineering and Physical
   Sciences Research Council BIP project
FX No Statement Available
CR Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Akbaba D., 2021, ALTVIS IEEE VIS, P1, DOI [10.48550/arXiv.2109.10132, DOI 10.48550/ARXIV.2109.10132]
   Andry T., 2021, P CHI, P1, DOI [10.1145/3411764.34457391,2,3,8,9, DOI 10.1145/3411764.34457391,2,3,8,9]
   [Anonymous], 2017, P CHI C HUM FACT COM, DOI [DOI 10.1145/3027063.3053113, 10.1145, 10.1145/3027063, DOI 10.1145/3027063]
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2018, COMPUT GRAPH FORUM, V37, P573, DOI 10.1111/cgf.13444
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Braun V., 2021, Thematic Analysis A Practical Guide, Vfirst, DOI [10.1177/1035719X211058254,5, DOI 10.1177/1035719X211058254,5]
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Cleveland W. S., 1985, The Elements of Graphing Data, P2
   de Haan Y, 2018, JOURNALISM STUD, V19, P1293, DOI 10.1080/1461670X.2016.1267592
   Garreton M., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32483191, DOI 10.1109/TVCG.2023.32483191]
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Hill S., 2018, Journal of Information System Applied Research, V11, P2
   KELLY JD, 1989, JOURNALISM QUART, V66, P632, DOI 10.1177/107769908906600315
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kennedy H, 2016, INFORM COMMUN SOC, V19, P715, DOI 10.1080/1369118X.2016.1153126
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Li Huiyang, 2014, P HUMAN FACTORS ERGO, V58, P1516
   Mahyar N., 2015, WORKSHOP PERSONAL VI, V3, P2
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Park JH, 2018, IEEE COMPUT GRAPH, V38, P67, DOI 10.1109/MCG.2018.2879066
   Parsons P, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P211, DOI 10.1109/VIS47514.2020.00049
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Peer E, 2014, BEHAV RES METHODS, V46, P1023, DOI 10.3758/s13428-013-0434-y
   Pena A., 2020, Interdisciplinary Journal of Signage and Wayfinding, V4, P19, DOI [10.15763/issn.2470-9670.2020.v4.i1.a541,2,8, DOI 10.15763/ISSN.2470-9670.2020.V4.I1.A541,2,8]
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Salminen J., 2021, P CHI, P1, DOI [10.1145/3411764.34453609, DOI 10.1145/3411764.34453609]
   Shukla P., 2022, VISCOMM IEEE VIS, P1, DOI [10.31219/osf.io/ayvq58, DOI 10.31219/OSF.IO/AYVQ58]
   Skau Drew., 2017, P EUROGRAPHICS C VIS, P91, DOI DOI 10.2312/EUROVISSHORT.20171139
   Sprague D, 2012, INFORM VISUAL, V11, P106, DOI 10.1177/1473871611433710
   Su YS, 2008, COMPUT STAT DATA AN, V52, P4594, DOI 10.1016/j.csda.2008.03.007
   Tufte E., 1983, The Visual Display of Quantitative Information, DOI [10.5555/334041,2,8, DOI 10.5555/334041,2,8]
   U. Government, 2022, The National Minimum Wage in 2022, P3
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Watson A., 2022, Leading News Websites in the United Kingdom (UK) 2021, by Monthly Visits, P3
   Wu K., 2021, P CHI, P1, DOI [10.1145/3411764.34457431, DOI 10.1145/3411764.34457431]
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yi C, 2015, J MANAGE INFORM SYST, V31, P213, DOI [10.1080/07421222.2014.1001270, 10.1080/0742222.2014.1001270]
   Zhang YX, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445381
NR 47
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1424
EP 1434
DI 10.1109/TVCG.2023.3326914
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500035
PM 37874724
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Epperson, W
   Gorantla, V
   Moritz, D
   Perer, A
AF Epperson, Will
   Gorantla, Vaishnavi
   Moritz, Dominik
   Perer, Adam
TI Dead or Alive: Continuous Data Profiling for Interactive Data Science
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Codes; Data visualization; Data models; Visualization; Programming;
   Manuals; Data science; Data Profiling; Data Quality; Exploratory Data
   Analysis; Interactive Data Science
ID VISUALIZATION
AB Profiling data by plotting distributions and analyzing summary statistics is a critical step throughout data analysis. Currently, this process is manual and tedious since analysts must write extra code to examine their data after every transformation. This inefficiency may lead to data scientists profiling their data infrequently, rather than after each transformation, making it easy for them to miss important errors or insights. We propose continuous data profiling as a process that allows analysts to immediately see interactive visual summaries of their data throughout their data analysis to facilitate fast and thorough analysis. Our system, AutoProfiler, presents three ways to support continuous data profiling: (1) it automatically displays data distributions and summary statistics to facilitate data comprehension; (2) it is live, so visualizations are always accessible and update automatically as the data updates; (3) it supports follow up analysis and documentation by authoring code for the user in the notebook. In a user study with 16 participants, we evaluate two versions of our system that integrate different levels of automation: both automatically show data profiles and facilitate code authoring, however, one version updates reactively ("live") and the other updates only on demand ("dead"). We find that both tools, dead or alive, facilitate insight discovery with 91% of user-generated insights originating from the tools rather than manual profiling code written by users. Participants found live updates intuitive and felt it helped them verify their transformations while those with on-demand profiles liked the ability to look at past visualizations. We also present a longitudinal case study on how AutoProfiler helped domain scientists find serendipitous insights about their data through automatic, live data profiles. Our results have implications for the design of future tools that offer automated data analysis support.
C1 [Epperson, Will; Gorantla, Vaishnavi; Moritz, Dominik; Perer, Adam] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Epperson, W (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM willepp@cmu.edu; vaishnag@andrew.cmu.edu; domoritz@cmu.edu;
   adamperer@cmu.edu
OI Moritz, Dominik/0000-0002-3110-1053; Perer, Adam/0000-0002-8369-3847
FU Brookhaven National Laboratory
FX No Statement Available
CR 8080 Labs, 2020, bamboolib
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Anaconda Foundation, 2020, The state of data science 2020: Moving from hype toward maturity
   Apache Arrow, 2023, Pyarrow-apache arrow python bindings
   Bailis P. D., 2017, 8 BIENN C INN DAT SY, P1
   Bertrand F., sweetviz
   DeLine R, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P111, DOI 10.1109/VLHCC.2015.7357205
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   EPPerson W, 2022, COMPUT GRAPH FORUM, V41, P145, DOI 10.1111/cgf.14529
   Epperson W, 2022, 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2022), P243, DOI [10.1109/ICSE-SEIP55303.2022.9793945, 10.1145/3510457.3513042]
   Fisher Danyel, 2012, Interactions, V19, P50, DOI 10.1145/2168931.2168943
   Forsgren Nicole, 2021, ACM Queue, V19, P20, DOI 10.1145/3454122.3454124
   Github, Github copilot-your ai pair programmer
   Head A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300500
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hellerstein J. M., 2008, Quantitative data cleaning for large databases, P2
   Hermans F, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 5, P56, DOI 10.1109/SANER.2016.86
   Hohman F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376177
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kery MB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1265, DOI 10.1145/3025453.3025626
   Kery Mary Beth, 2020, UIST, P140
   Kiapour MH, 2014, IEEE WINT CONF APPL, P933, DOI 10.1109/WACV.2014.6836004
   Kim M, 2018, IEEE T SOFTWARE ENG, V44, P1024, DOI 10.1109/TSE.2017.2754374
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Li XJ, 2023, ACM T INTERACT INTEL, V13, DOI 10.1145/3545995
   Maloney J. H., 1995, ACM S US INT SOFTW T
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   pandas, pandas-Python Data Analysis Library [Website]. pandas.pydata. Retrieved 2022-04-20
   Pandas-Profiling, pandas-profiling
   Peng JL, 2021, INT CONF MANAGE DATA, P2271, DOI 10.1145/3448016.3457330
   Pennington K., Bay area craigslist posts, 2000-2018
   Perkel J. M., 2018, Nature News, DOI DOI 10.1038/D41586-018-07196-11,2,3
   Ono JP, 2021, COMPUT SCI ENG, V23, P99, DOI 10.1109/MCSE.2021.3052619
   Pimentel Joao Felipe, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P507, DOI 10.1109/MSR.2019.00077
   Polars, Polars, lightning-fast dataframe library
   Raasveldt M., 2021, Efficient SQL on Pandas with DuckDB-duckdb.org
   Rill Data, Rill developer
   Rose A., PandasGUI
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518
   Seltman H., 2018, Experimental design and analysis, P2
   Shankar S, 2022, Arxiv, DOI [arXiv:2209.09125, DOI 10.48550/ARXIV.2209.09125]
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Sveltejs, 2016, Svelte: cybernetically enhanced web apps
   TUKEY JW, 1980, AM STAT, V34, P23, DOI 10.2307/2682991
   Wang AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502123
   Wongsuphasawat K, 2019, Arxiv, DOI arXiv:1911.00568
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu Y., 2020, ACM USER INTERFACE S, DOI DOI 10.1145/3379337.34158513,4
NR 51
TC 2
Z9 2
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 197
EP 207
DI 10.1109/TVCG.2023.3327367
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500006
PM 37903042
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Heer, J
   Moritz, D
AF Heer, Jeffrey
   Moritz, Dominik
TI Mosaic: An Architecture for Scalable & Interoperable Data Views
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Interaction; Grammar of Graphics; Software Architecture
ID INTERACTIVE VISUALIZATION; GRAMMAR; VEGA
AB Mosaic is an architecture for greater scalability, extensibility, and interoperability of interactive data views. Mosaic decouples data processing from specification logic: clients publish their data needs as declarative queries that are then managed and automatically optimized by a coordinator that proxies access to a scalable data store. Mosaic generalizes Vegalite's selection abstraction to enable rich integration and linking across visualizations and components such as menus, text search, and tables. We demonstrate Mosaic's expressiveness, extensibility, and interoperability through examples that compose diverse visualization, interaction, and optimization techniques-many constructed using vgplot, a grammar of interactive graphics in which graphical marks act as Mosaic clients. To evaluate scalability, we present benchmark studies with order-of-magnitude performance improvements over existing web-based visualization systems-enabling flexible, real-time visual exploration of billion+ record datasets. We conclude by discussing Mosaic's potential as an open platform that bridges visualization languages, scalable visualization, and interactive data systems more broadly.
C1 [Heer, Jeffrey] Univ Washington, Seattle, WA 98195 USA.
   [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA USA.
C3 University of Washington; University of Washington Seattle; Carnegie
   Mellon University
RP Heer, J (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM jheer@uw.edu; domoritz@cmu.edu
OI Heer, Jeffrey/0000-0002-6175-1655; Moritz, Dominik/0000-0002-3110-1053
FU Moore Foundation
FX No Statement Available
CR [Anonymous], 1994, J. Comput. Graph. Stat, DOI [DOI 10.1080/10618600.1994.10474656, 10.1080/10618600.1994.10474656, DOI 10.2307/1390904]
   [Anonymous], Observable Plot
   Apache Arrow, ABOUT US..
   Battle L, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1571, DOI 10.1145/3318464.3389732
   Battle L, 2021, IEEE T VIS COMPUT GR, V27, P1128, DOI 10.1109/TVCG.2020.3028891
   Battle L, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1363, DOI 10.1145/2882903.2882919
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bureau of Transportation Statistics, On-Time Performance
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chen R, 2022, IEEE T VIS COMPUT GR, V28, P4127, DOI 10.1109/TVCG.2021.3076222
   Chen YR, 2022, INT CONF MANAGE DATA, P1711, DOI 10.1145/3514221.3526166
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Deriche R., 1993, Tech Report, P5
   github, Observable Inputs
   glueviz, Glue: multi-dimensional linked-data exploration
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Heer J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P11, DOI 10.1109/VIS49827.2021.9623323
   JONES MC, 1983, J STAT COMPUT SIM, V17, P133, DOI 10.1080/00949658308810650
   Jugel U, 2014, PROC VLDB ENDOW, V7, P797, DOI 10.14778/2732951.2732953
   Kohn A, 2023, Arxiv, DOI arXiv:2306.03714
   Kohn A, 2022, PROC VLDB ENDOW, V15, P3574, DOI 10.14778/3554821.3554847
   Kruchten N, 2022, IEEE VIS CONF, P11, DOI 10.1109/VIS54862.2022.00011
   Lampe OD, 2011, COMPUT GRAPH FORUM, V30, P633, DOI 10.1111/j.1467-8659.2011.01912.x
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Livny M., 1997, PROC 1997 ACM SIGMOD, P301, DOI [10.1145/253262.2533352, DOI 10.1145/253262.2533352]
   Mohammed H, 2020, PROC VLDB ENDOW, V13, P2297, DOI 10.14778/3407790.3407826
   Moritz D., 2015, IEEE VIS DAT SYST IN, P9
   Moritz D, 2018, Arxiv, DOI arXiv:1808.06019
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   North C., 2000, P WORK C ADV VIS INT, DOI [10.1145/345513.3452822, DOI 10.1145/345513.3452822]
   Raasveldt M., 2019, P 2019 INT C MAN DAT, DOI [10.1145/3299869.33202122,3, DOI 10.1145/3299869.33202122,3]
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Tao WB, 2021, IEEE T VIS COMPUT GR, V27, P401, DOI 10.1109/TVCG.2020.3030372
   Tao WB, 2019, COMPUT GRAPH FORUM, V38, P529, DOI 10.1111/cgf.13708
   Vallenari A., 2022, arXiv
   VanderPlas J., 2018, J OPEN SOURCE SOFTW, V3, P1057, DOI [DOI 10.21105/JOSS.01057, 10.21105/joss.01057]
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Wickham H., 2013, Tech Report, P2
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L., 2011, The Grammar of Graphics, P375, DOI [10.1007/978-3-642-21551-3_132,4, DOI 10.1007/978-3-642-21551-3_132,4]
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu E, 2014, PROC VLDB ENDOW, V7, P903, DOI 10.14778/2732951.2732964
   Wu YF, 2022, IEEE T VIS COMPUT GR, V28, P737, DOI 10.1109/TVCG.2021.3114796
   Yang JR, 2022, INT CONF MANAGE DATA, P2425, DOI 10.1145/3514221.3520168
NR 49
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 436
EP 446
DI 10.1109/TVCG.2023.3327189
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500085
PM 37883269
DA 2024-08-05
ER

PT J
AU Huang, YS
   Zhang, ZR
   Jiao, A
   Ma, YX
   Cheng, R
AF Huang, Yansong
   Zhang, Zherui
   Jiao, Ao
   Ma, Yuxin
   Cheng, Ran
TI A Comparative Visual Analytics Framework for Evaluating Evolutionary
   Processes in Multi-Objective Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; evolutionary multi-objective optimization
ID MODEL SELECTION; VISUALIZATION; ALGORITHM; SETS
AB Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms.
C1 [Huang, Yansong; Zhang, Zherui; Jiao, Ao; Ma, Yuxin; Cheng, Ran] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
C3 Southern University of Science & Technology
RP Ma, YX (corresponding author), Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
EM huangys2019@mail.sustech.edu.cn; zhangzr32021@mail.sustech.edu.cn;
   jiaoa2020@mail.sustech.edu.cn; mayx@sustech.edu.cn;
   chengr@sustech.edu.cn
RI Zhang, Zherui/KTI-1299-2024; Cheng, Ran/V-1486-2018
OI Cheng, Ran/0000-0001-9410-8263
FU National Natural Science Foundation of China
FX No Statement Available
CR Abdolmaleki A, 2020, PR MACH LEARN RES, V119
   Andrienko N., 2021, Visual Informatics, V5, P2
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Blank J, 2020, IEEE ACCESS, V8, P89497, DOI 10.1109/ACCESS.2020.2990567
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Chatzimparmpas A, 2021, COMPUT GRAPH FORUM, V40, P201, DOI 10.1111/cgf.14300
   Chen SH, 2013, IEEE PAC VIS SYMP, P153, DOI 10.1109/PacificVis.2013.6596140
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   Coello CAC, 2004, LECT NOTES COMPUT SC, V2972, P688
   Deb K, 2002, IEEE C EVOL COMPUTAT, P825, DOI 10.1109/CEC.2002.1007032
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Feydy Jean, 2019, 22 INT C ART INT STA, P2681
   Geatpy, About us
   Gleicher M., 2020, Computer Graphics Forum, V39, P2
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gong MG, 2007, IEEE C EVOL COMPUTAT, P15
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   He C, 2020, COMPLEX INTELL SYST, V6, P189, DOI 10.1007/s40747-019-00126-2
   He ZA, 2016, IEEE T EVOLUT COMPUT, V20, P386, DOI 10.1109/TEVC.2015.2472283
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Ibrahim A, 2016, IEEE C EVOL COMPUTAT, P736, DOI 10.1109/CEC.2016.7743865
   Kahng M., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P2
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kim H, 2017, AAAI CONF ARTIF INTE, P1001
   Kotthoff L, 2019, SPRING SER CHALLENGE, P81, DOI 10.1007/978-3-030-05318-5_4
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Li K, 2018, IEEE ACCESS, V6, P26194, DOI 10.1109/ACCESS.2018.2832181
   Li MQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3300148
   Li MQ, 2017, IEEE COMPUT INTELL M, V12, P88, DOI 10.1109/MCI.2017.2742869
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Lotov A., 2004, Interactive Decision Maps: Approximation and Visualization of Pareto Frontier, P2
   Lu K., 2023, P ACM CHI C HUM FACT
   Lu Y., 2017, Computer Graphics Forum, V36, P2
   Lu ZC, 2024, IEEE T EVOLUT COMPUT, V28, P323, DOI 10.1109/TEVC.2022.3233364
   Ma Y., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P3
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Mouret J.-B., 2011, NEW HORIZONS EVOLUTI, P8
   Mühlbacher T, 2014, IEEE T VIS COMPUT GR, V20, P1643, DOI 10.1109/TVCG.2014.2346578
   Murugesan S, 2019, IEEE COMPUT GRAPH, V39, P47, DOI 10.1109/MCG.2019.2919033
   Nagar D, 2023, SWARM EVOL COMPUT, V76, DOI 10.1016/j.swevo.2022.101202
   Ono JP, 2021, IEEE T VIS COMPUT GR, V27, P390, DOI 10.1109/TVCG.2020.3030361
   Pister A, 2021, IEEE T VIS COMPUT GR, V27, P1775, DOI 10.1109/TVCG.2020.3030347
   Pohlheim H, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P533
   Raschka S, 2020, Arxiv, DOI arXiv:1811.12808
   Reddy M. J., 2006, Water Resources Management, V20, P1
   Schott J. R., 1995, Fault tolerant design using single and multicriteria genetic algorithm optimization, P4
   Sener O., 2018, Advances in neural information processing systems, V31, P2
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Talukder AKMKA, 2020, IEEE COMPUT INTELL M, V15, P36, DOI 10.1109/MCI.2020.2976184
   Tian Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3470971
   Tian Y, 2017, IEEE COMPUT INTELL M, V12, P73, DOI 10.1109/MCI.2017.2742868
   Tusar T, 2015, IEEE T EVOLUT COMPUT, V19, P225, DOI 10.1109/TEVC.2014.2313407
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vincalek Jakub, 2021, GECCO '21: Proceedings of the Genetic and Evolutionary Computation Conference Companion, P231, DOI 10.1145/3449726.3459483
   Walker DJ, 2013, IEEE T EVOLUT COMPUT, V17, P165, DOI 10.1109/TEVC.2012.2225064
   Wang J., 2022, IEEE Transactions on Visualization and Computer Graphics
   Wang Q., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Wang Q., 2019, P ACM CHI C HUM FACT, P1
   Wang XM, 2020, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST50239.2020.00006
   Wang Y., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P6
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Xie T., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Xuan X., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Yadav D, 2023, EUR J OPER RES, V309, P1183, DOI 10.1016/j.ejor.2023.01.062
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Ye Y., 2022, IEEE Transactions on Visualization and Computer Graphics, P1
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
   Zeng H., 2017, P WORKSH VIS AN DEEP
   Zhang J., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P2
   Zitzler E, 1998, LECT NOTES COMPUT SC, V1498, P292, DOI 10.1007/BFb0056872
   Zitzler E, 2004, Metaheuristics for multiobjective optimisation, P3
   Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202
NR 79
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 661
EP 671
DI 10.1109/TVCG.2023.3326921
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500017
PM 37874721
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lukasczyk, J
   Will, M
   Wetzels, F
   Weber, GH
   Garth, C
AF Lukasczyk, Jonas
   Will, Michael
   Wetzels, Florian
   Weber, Gunther H.
   Garth, Christoph
TI ExTreeM: Scalable Augmented Merge Tree Computation via Extremum Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scalar field topology; merge trees; persistence pairs; high performance
   computing
ID SIMULATION; TOPOLOGY
AB Over the last decade merge trees have been proven to support a plethora of visualization and analysis tasks since they effectively abstract complex datasets. This paper describes the ExTreeM-Algorithm: a scalable algorithm for the computation of merge trees via extremum graphs. The core idea of ExTreeM is to first derive the extremum graph G of an input scalar fi eldf defined on a cell complex K, and subsequently compute the unaugmented merge tree of f on G instead of K; which are equivalent. Any merge tree algorithm can be carried out significantly faster on G , since K in general contains substantially more cells than G . To further speed up computation, ExTreeM includes a tailored procedure to derive merge trees of extremum graphs. The computation of the fully augmented merge tree, i.e., a merge tree domain segmentation of K, can then be performed in an optional post-processing step. All steps of ExTreeM consist of procedures with high parallel efficiency, and we provide a formal proof of its correctness. Our experiments, performed on publicly available datasets, report a speedup of up to one order of magnitude over the state-of-the-art algorithms included in the TTK and VTK-m software libraries, while also requiring significantly less memory and exhibiting excellent scaling behavior.
C1 [Lukasczyk, Jonas; Will, Michael; Wetzels, Florian; Garth, Christoph] RPTU Kaiserslautern Landau, Kaiserslautern, Germany.
   [Weber, Gunther H.] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
C3 United States Department of Energy (DOE); Lawrence Berkeley National
   Laboratory
RP Lukasczyk, J (corresponding author), RPTU Kaiserslautern Landau, Kaiserslautern, Germany.
EM lukasczyk@rptu.de; mswill@rptu.de; wetzels@rptu.de; ghweber@lbl.gov;
   garth@rptu.de
RI Weber, Gunther/AAA-9678-2019
OI Weber, Gunther/0000-0002-1794-1398; Garth,
   Christoph/0000-0003-1669-8549; Wetzels, Florian/0000-0002-5526-7138;
   Will, Michael/0009-0007-1344-3694
FU Exascale Computing Project
FX No Statement Available
CR Ahrens J., 2005, The Visualization Handbook, P9
   Ande A, 2023, COMPUT GRAPH FORUM, V42, DOI 10.1111/cgf.14784
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Carr H. A., 2003, Computational Geometry, V24, P3
   Carr H, 2009, MATH VIS, P59, DOI 10.1007/978-3-540-88606-8_5
   Carr HA, 2022, IEEE T VIS COMPUT GR, V28, P3471, DOI 10.1109/TVCG.2021.3064385
   Carr HA, 2021, IEEE T VIS COMPUT GR, V27, P2437, DOI 10.1109/TVCG.2019.2948616
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Chiang Y.-J., 2005, Computational Geometry, V30, P3
   Cohen RH, 2002, PHYS FLUIDS, V14, P3692, DOI 10.1063/1.1504452
   Cook AW, 2004, J FLUID MECH, V511, P333, DOI 10.1017/S0022112004009681
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2009, American Mathematical Society, V2, P3
   Edelsbrunner H, 2012, DISCRETE COMPUT GEOM, V47, P393, DOI 10.1007/s00454-011-9382-4
   Federer F., Pyramidal neurons in the marmoset primary visual cortex
   Freudenthal H, 1942, ANN MATH, V43, P580, DOI 10.2307/1968813
   Grout RW, 2012, J FLUID MECH, V706, P351, DOI 10.1017/jfm.2012.257
   Gueunet C, 2017, SYMP LARG DATA ANAL, P6, DOI 10.1109/LDAV.2017.8231846
   Guo F, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.155005
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Klacansky P., 2023, Open Scientific Visualization Datasets
   Klacansky P, 2020, IEEE T VIS COMPUT GR, V26, P173, DOI 10.1109/TVCG.2019.2934257
   Kreeger K., Ct scan of a backpack filled with items
   Kruskal J. B., 1956, Proceedings of the American Mathematical society, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.1090/S0002-9939-1956-0078686-7]
   Maack R. G., 2023, IEEE Transactions on Visualization and Computer Graphics, V4
   Maadasamy S, 2012, INT C HIGH PERFORM
   Masood T. B., 2019, TopoInVis 2019-Topological Methods in Data Analysis and Visualization, V1, P3
   Moreland K, 2016, IEEE COMPUT GRAPH, V36, P48, DOI 10.1109/MCG.2016.48
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Nigmetov A., 2022, 2022 TOPOLOGICAL DAT, P1
   Nigmetov A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356188
   OpenMP Architecture Review Board, 2008, OpenMP application program interface version 3.0
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Perlin K., 1985, ACM Siggraph Computer Graphics, V19, P8
   Rowe T., Digimorph-Lampropeltis getula (common kingsnake)-digimorph.org
   Schroeder W. J., 2004, The Visualization Toolkit: An Object Oriented Approach to 3D Graphics, V1, P8
   Smirnov D., 2020, Topological Methods in Data Analysis and Visualization V: Theory, Algorithms, and Applications, V7, P19
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   TTK Contributers, TTK data examples
NR 41
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1085
EP 1094
DI 10.1109/TVCG.2023.3326526
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500119
PM 37871087
DA 2024-08-05
ER

PT J
AU Magri, VAP
   Lindstrom, P
AF Magri, Victor A. P.
   Lindstrom, Peter
TI A General Framework for Progressive Data Compression and Retrieval
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lossy to lossless compression; progressive precision; multi-component
   expansion; floating-point data
ID EFFICIENT; PRECISION; SIMULATION; REDUCTION; MODEL
AB In scientific simulations, observations, and experiments, the transfer of data to and from disk and across networks has become a major bottleneck for data analysis and visualization. Compression techniques have been employed to tackle this challenge, but traditional lossy methods often demand conservative error tolerances to meet the numerical accuracy requirements of both anticipated and unknown data analysis tasks. Progressive data compression and retrieval has emerged as a promising solution, where each analysis task dictates its own accuracy needs. However, few analysis algorithms inherently support progressive data processing, and adapting compression techniques, file formats, client/server frameworks, and APIs to support progressivity can be challenging. This paper presents a framework that enables progressive-precision data queries for any data compressor or numerical representation. Our strategy hinges on a multi-component representation that successively reduces the error between the original and compressed field, allowing each field in the progressive sequence to be expressed as a partial sum of components. We have implemented this approach with four established scientific data compressors and assessed its effectiveness using real-world data sets from the SDRBench collection. The results show that our framework competes in accuracy with the standalone compressors it is based upon. Additionally, (de)compression time is proportional to the number of components requested by the user. Finally, our framework allows for fully lossless compression using lossy compressors when a sufficient number of components are employed.
C1 [Magri, Victor A. P.; Lindstrom, Peter] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
C3 United States Department of Energy (DOE); Lawrence Livermore National
   Laboratory
RP Magri, VAP (corresponding author), Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
EM paludettomag1@llnl.gov; pl@llnl.gov
OI Lindstrom, Peter/0000-0003-3817-4199
FU U.S. Department of Energy by Lawrence Livermore National Laboratory
   under Contract
FX No Statement Available
CR Ainsworth M, 2019, SIAM J SCI COMPUT, V41, pA2146, DOI [10.1137/18M1208885, 10.1137/18M1166651]
   [Anonymous], 2019, The Astrophysical Journal, DOI [DOI 10.3847/1538-4357/AB042C1, 10.3847/1538-4357/ab042c1]
   Antcheva I, 2009, COMPUT PHYS COMMUN, V180, P2499, DOI 10.1016/j.cpc.2009.08.005
   Ballard G, 2020, ACM T MATH SOFTWARE, V46, DOI 10.1145/3378445
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Barbarioli Bruno, 2023, Proceedings of the ACM on Management of Data, V1, DOI 10.1145/3588953
   Bhatia H, 2022, IEEE T VIS COMPUT GR, V28, P2350, DOI 10.1109/TVCG.2022.3165392
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen JY, 2021, INT PARALL DISTRIB P, P859, DOI 10.1109/IPDPS49936.2021.00095
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Clyne J., 2012, High Performance Visualization, P145, DOI DOI 10.1201/B12985-191
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P305, DOI 10.1109/TVCG.2009.105
   DEKKER TJ, 1971, NUMER MATH, V18, P224, DOI 10.1007/BF01397083
   Diffenderfer J, 2019, SIAM J SCI COMPUT, V41, pA1867, DOI 10.1137/18M1168832
   Hoang D, 2019, IEEE T VIS COMPUT GR, V25, P1193, DOI 10.1109/TVCG.2018.2864853
   Eyring V, 2016, GEOSCI MODEL DEV, V9, P1937, DOI 10.5194/gmd-9-1937-2016
   Folk M., 2011, Proceedings of the EDBT/ICDT 2011 Workshop on Array Databases, P36
   Fout N, 2007, IEEE T VIS COMPUT GR, V13, P1600, DOI 10.1109/TVCG.2007.70516
   Godoy WF, 2020, SOFTWAREX, V12, DOI 10.1016/j.softx.2020.100561
   Gong Q., 2022, INT C SCI STAT DATAB, DOI DOI 10.1145/3538712.3538717
   Graham J, 2016, J TURBUL, V17, P181, DOI 10.1080/14685248.2015.1088656
   Grout RW, 2012, J FLUID MECH, V706, P351, DOI 10.1017/jfm.2012.257
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Guthe S., 2016, Vision, Modeling and Visualization, P77, DOI DOI 10.2312/VMV.20161345
   Hida Y, 2001, P S COMP ARITHM, P155, DOI 10.1109/ARITH.2001.930115
   Hoang D, 2021, IEEE T VIS COMPUT GR, V27, P603, DOI 10.1109/TVCG.2020.3030381
   Hong ES, 2001, CONF REC ASILOMAR C, P769, DOI 10.1109/ACSSC.2001.987028
   Kay JE, 2015, B AM METEOROL SOC, V96, P1333, DOI 10.1175/BAMS-D-13-00255.1
   Li S, 2018, COMPUT GRAPH FORUM, V37, P422, DOI 10.1111/cgf.13336
   Li SM, 2023, INT PARALL DISTRIB P, P1007, DOI 10.1109/IPDPS54959.2023.00104
   Li SM, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10090488
   Liang X, 2023, IEEE T BIG DATA, V9, P485, DOI 10.1109/TBDATA.2022.3201176
   Liang X, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476179
   Lindstrom P, 2022, LECT NOTES COMPUT SC, V13253, P66, DOI 10.1007/978-3-031-09779-9_5
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   NING P., 1992, P 1992 WORKSH VOL VI, P69, DOI [10.1145/147130.147152, DOI 10.1145/147130.147152]
   Noordsij L, 2020, EUROMICRO WORKSHOP P, P245, DOI 10.1109/PDP50117.2020.00045
   Pascucci V., 2001, ACMIEEE C SUPERCOMPU, P1, DOI DOI 10.1145/582034.5820362
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Peters AJ, 2011, J PHYS CONF SER, V331, DOI 10.1088/1742-6596/331/5/052015
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sauer T., 2018, Numerical Analysis, V8
   Schneider J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P293, DOI 10.1109/VISUAL.2003.1250385
   Shadden SC, 2005, PHYSICA D, V212, P271, DOI 10.1016/j.physd.2005.10.007
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Shewchuk JR, 1997, DISCRETE COMPUT GEOM, V18, P305, DOI 10.1007/PL00009321
   Tian JN, 2020, INT CONFER PARA, P3, DOI 10.1145/3410463.3414624
   Wilkinson JH., 2023, Rounding errors in algebraic processes, DOI DOI 10.1137/1.9781611977523
   Zhang JL, 2019, IEEE S MASS STOR SYS, P79, DOI 10.1109/MSST.2019.00-14
   Zhao K, 2020, IEEE INT CONF BIG DA, P2716, DOI 10.1109/BigData50022.2020.9378449
NR 53
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1358
EP 1368
DI 10.1109/TVCG.2023.3327186
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500031
PM 37922179
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zeng, ZH
   Yang, JR
   Moritz, D
   Heer, J
   Battle, L
AF Zeng, Zehua
   Yang, Junran
   Moritz, Dominik
   Heer, Jeffrey
   Battle, Leilani
TI Too Many Cooks: Exploring How Graphical Perception Studies Influence
   Visualization Recommendations in Draco
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graphical Perception Studies; Visualization Recommendation Algorithms
AB Findings from graphical perception can guide visualization recommendation algorithms in identifying effective visualization designs. However, existing algorithms use knowledge from, at best, a few studies, limiting our understanding of how complementary (or contradictory) graphical perception results influence generated recommendations. In this paper, we present a pipeline of applying a large body of graphical perception results to develop new visualization recommendation algorithms and conduct an exploratory study to investigate how results from graphical perception can alter the behavior of downstream algorithms. Specifically, we model graphical perception results from 30 papers in Draco-a framework to model visualization knowledge-to develop new recommendation algorithms. By analyzing Draco-generated algorithms, we showcase the feasibility of our method to (1) identify gaps in existing graphical perception literature informing recommendation algorithms, (2) cluster papers by their preferred design rules and constraints, and (3) investigate why certain studies can dominate Draco's recommendations, whereas others may have little influence. Given our findings, we discuss the potential for mutually reinforcing advancements in graphical perception and visualization recommendation research.
C1 [Zeng, Zehua] Univ Maryland, College Pk, MD 20742 USA.
   [Yang, Junran; Heer, Jeffrey; Battle, Leilani] Univ Washington, Seattle, WA USA.
   [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA USA.
C3 University System of Maryland; University of Maryland College Park;
   University of Washington; University of Washington Seattle; Carnegie
   Mellon University
RP Zeng, ZH (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM zhzeng@umd.edu; junran@uw.edu; domoritz@cmu.edu; jheer@uw.edu;
   leibatt@uw.edu
RI Zeng, Zehua/HME-2717-2023
OI Zeng, Zehua/0000-0002-5153-3865; Heer, Jeffrey/0000-0002-6175-1655;
   Battle, Leilani/0000-0003-3870-636X; Moritz, Dominik/0000-0002-3110-1053
FU Moore Foundation
FX No Statement Available
CR Bertin J., 1983, Semiology of Graphics, P2
   Burlinson D, 2018, IEEE T VIS COMPUT GR, V24, P574, DOI 10.1109/TVCG.2017.2745086
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Donoho D., 1982, Primdata: Data sets for use with prim-h
   Gebser M, 2014, Arxiv, DOI arXiv:1405.3694
   Gebser M, 2011, AI COMMUN, V24, P107, DOI 10.3233/AIC-2011-0491
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Herbrich R, 2000, ADV NEUR IN, P115
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Key Alicia, 2012, P 2012 ACM SIGMOD IN, P681, DOI [10.1145/2213836.2213931, DOI 10.1145/2213836.2213931]
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Leis V, 2015, PROC VLDB ENDOW, V9, P204
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   Menne MJ, 2012, J ATMOS OCEAN TECH, V29, P897, DOI 10.1175/JTECH-D-11-00103.1
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Panavas L, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501893
   Peña-Araya V, 2020, IEEE T VIS COMPUT GR, V26, P375, DOI 10.1109/TVCG.2019.2934807
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Ryan G, 2019, IEEE T VIS COMPUT GR, V25, P872, DOI 10.1109/TVCG.2018.2865264
   Saket, 2018, ABS180706641 CORR
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siddiqui T., 2017, 8 BIENN C INN DAT SY
   Sutton A. J., 2000, Methods for meta-analysis in medical research, V348, P9
   T. S. community, 2008, Scipy hierarchical clustering, P6
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Ware C., 2012, Information Visualization: Perception for Design, P2
   Wongsuphasawat K, 2016, P WORKSH HUM IN THE, P1, DOI [10.1145/2939502.2939506, 10.1145/2939502.29395061,2,3,9, DOI 10.1145/2939502.29395061,2,3,9]
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Yang J., 2023, IN PRESS
   Zeng Z., 2022, A Multi-Faceted Approach for Evaluating Visualization Recommendation Algorithms, DOI [10.13016/eyde-ceok1,2, DOI 10.13016/EYDE-CEOK1,2]
   Zeng ZH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581349
   Zeng ZH, 2022, IEEE T VIS COMPUT GR, V28, P346, DOI 10.1109/TVCG.2021.3114814
   Zhao M., 2019, P 2019 CHI C HUM FAC, P1, DOI DOI 10.1145/3290605.33004623
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 51
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1063
EP 1073
DI 10.1109/TVCG.2023.3326527
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500041
PM 37871053
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Cabaret, PA
   Howard, T
   Gicquel, G
   Pacchierotti, C
   Babel, M
   Marchal, M
AF Cabaret, Pierre-Antoine
   Howard, Thomas
   Gicquel, Guillaume
   Pacchierotti, Claudio
   Babel, Marie
   Marchal, Maud
TI Does Multi-Actuator Vibrotactile Feedback Within Tangible Objects Enrich
   VR Manipulation?
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Actuators; Rendering (computer graphics); Vibrations;
   Prototypes; Grasping; Wearable computers; Haptics; vibrotactile;
   tangible; VR; manipulation
ID DISCRIMINATION; PERCEPTION; DISPLAY; TEXTURE; TOUCH
AB Rich, informative and realistic haptic feedback is key to enhancing Virtual Reality (VR) manipulation. Tangible objects provide convincing grasping and manipulation interactions with haptic feedback of e.g., shape, mass and texture properties. But these properties are static, and cannot respond to interactions in the virtual environment. On the other hand, vibrotactile feedback provides the opportunity for delivering dynamic cues rendering many different contact properties, such as impacts, object vibrations or textures. Handheld objects or controllers in VR are usually restricted to vibrating in a monolithic fashion. In this article, we investigate how spatialiazing vibrotactile cues within handheld tangibles could enable a wider range of sensations and interactions. We conduct a set of perception studies, investigating the extent to which spatialization of vibrotactile feedback within tangible objects is possible as well as the benefits of proposed rendering schemes leveraging multiple actuators in VR. Results show that vibrotactile cues from localized actuators can be discriminated and are beneficial for certain rendering schemes.
C1 [Cabaret, Pierre-Antoine; Howard, Thomas; Gicquel, Guillaume; Babel, Marie; Marchal, Maud] Univ Rennes, INSA Rennes, IRISA, INRIA,Inria,CNRS Rennes, F-35000 Rennes, France.
   [Cabaret, Pierre-Antoine; Howard, Thomas; Gicquel, Guillaume; Babel, Marie; Marchal, Maud] Inst Univ France Paris, F-35000 Rennes, France.
   [Pacchierotti, Claudio] Univ Rennes, CNRS, Inria, IRISA Rennes, F-35000 Rennes, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Institut National des Sciences Appliquees de Rennes; Inria;
   Institut Universitaire de France; Inria; Universite de Rennes; Centre
   National de la Recherche Scientifique (CNRS)
RP Cabaret, PA (corresponding author), Univ Rennes, INSA Rennes, IRISA, INRIA,Inria,CNRS Rennes, F-35000 Rennes, France.
EM pierre-antoine.cabaret@irisa.fr; thomas.howard@inria.fr;
   guillaume.gicquel@irisa.fr; claudio.pacchierotti@irisa.fr;
   marie.babel@irisa.fr; maud.marchal@irisa.fr
RI Pacchierotti, Claudio/G-7304-2011
OI Pacchierotti, Claudio/0000-0002-8006-9168; Howard,
   Thomas/0000-0003-4904-375X; Cabaret, Pierre-Antoine/0000-0003-3444-7970;
   Babel, Marie/0000-0001-6425-389X; Marchal, Maud/0000-0002-6080-7178
FU Inria D#x00E9;fi project; ANR project "MIMESIS"; European Union
   [801413]; Project "H-Reality"
FX No Statement Available
CR Aggravi Marco, 2018, IEEE Robotics and Automation Letters, V3, P2166, DOI 10.1109/LRA.2018.2810887
   ALLES DS, 1970, IEEE T MAN MACHINE, VMM11, P85, DOI 10.1109/TMMS.1970.299967
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Bae Y, 2020, INT J CONTROL AUTOM, V18, P1335, DOI 10.1007/s12555-018-0882-3
   Brument H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1409, DOI 10.1109/vr.2019.8797848
   Cabaret P.-A., 2022, P INT C HUM HAPT SEN, P273
   Cheng LP, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186482
   Chinello F, 2018, IEEE T HAPTICS, V11, P39, DOI 10.1109/TOH.2017.2755015
   Choi I, 2021, IEEE T VIS COMPUT GR, V27, P4387, DOI 10.1109/TVCG.2020.3002245
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Culbertson Heather, 2012, 2012 IEEE Haptics Symposium (HAPTICS), P385, DOI 10.1109/HAPTIC.2012.6183819
   Culbertson H., 2014, "The penn haptic texture toolkit for modeling, rendering, and evaluating haptic virtual textures
   Culbertson H, 2018, ANNU REV CONTR ROBOT, V1, P385, DOI 10.1146/annurev-control-060117-105043
   Culbertson H, 2017, IEEE T HAPTICS, V10, P63, DOI 10.1109/TOH.2016.2598751
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   de Tinguy X, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P580, DOI [10.1109/whc.2019.8816164, 10.1109/WHC.2019.8816164]
   Delazio A., 2018, P CHI C HUM FACT COM, P12
   Dunkelberger N, 2018, LECT NOTES COMPUT SC, V10894, P289, DOI 10.1007/978-3-319-93399-3_26
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Guruswamy VL, 2011, IEEE T INSTRUM MEAS, V60, P93, DOI 10.1109/TIM.2010.2065751
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Hollins M, 2000, PERCEPT PSYCHOPHYS, V62, P695, DOI 10.3758/BF03206916
   Hollins M, 2001, SOMATOSENS MOT RES, V18, P253
   Ito K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3340961
   Kaul OB, 2017, LECT NOTES COMPUT SC, V10516, P289, DOI 10.1007/978-3-319-68059-0_19
   Keef CV, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000018
   Khoudja M. B., 2004, "VITAL: A vibrotactile interface with thermal feedback
   Kildal Johan, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P191, DOI 10.1007/978-3-642-31404-9_33
   Kovacs R., 2020, P 33 ANN ACM S US IN, P1059
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   LEDERMAN SJ, 1972, PERCEPT PSYCHOPHYS, V12, P401, DOI 10.3758/BF03205850
   Li-Te Cheng, 1996, Proceedings ACM Multimedia 96, P243, DOI 10.1145/244130.244220
   Maereg AT, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00042
   McDonald CG, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P307, DOI 10.1109/WHC.2013.6548426
   Mercado VR, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P373, DOI 10.1109/WHC49131.2021.9517250
   Okamoto S, 2013, IEEE T HAPTICS, V6, P81, DOI [10.1109/TOH.2012.32, 10.1109/ToH.2012.32]
   Okamura AM, 1998, IEEE INT CONF ROBOT, P674, DOI 10.1109/ROBOT.1998.677050
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Pantera L, 2020, IEEE T HAPTICS, V13, P493, DOI 10.1109/TOH.2020.2981307
   Passalenti A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1116, DOI [10.1109/vr.2019.8798168, 10.1109/VR.2019.8798168]
   Perez CA, 1998, P ANN INT IEEE EMBS, V20, P2542, DOI 10.1109/IEMBS.1998.744968
   Perez CA, 2000, MED BIOL ENG COMPUT, V38, P74, DOI 10.1007/BF02344692
   Pezent E, 2021, IEEE T HAPTICS, V14, P225, DOI 10.1109/TOH.2020.3002696
   Pezent E, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P1, DOI [10.1109/WHC.2019.8816098, 10.1109/whc.2019.8816098]
   Popescu G. V., 2002, Handbook of Virtual Environments, P475
   Saal HP, 2014, TRENDS NEUROSCI, V37, P689, DOI 10.1016/j.tins.2014.08.012
   Sagheb S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P751, DOI 10.1145/3332165.3347870
   SHERRICK CE, 1990, J ACOUST SOC AM, V88, P169, DOI 10.1121/1.399937
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   Sinclair M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P815, DOI 10.1145/3332165.3347891
   Sun MM, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P42, DOI 10.1109/ISMAR-Adjunct.2019.00026
   Tinguy Xavier, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P262, DOI 10.1007/978-3-030-58147-3_29
   VONBEKESY G, 1958, J ACOUST SOC AM, V30, P399
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   WEINSTEIN SIDNEY, 1968, P195
   Wellman Parris., 1995, PROC ASME DYNAMIC SY, V57, P713
   Wolf D, 2019, IEEE T VIS COMPUT GR, V25, P3169, DOI 10.1109/TVCG.2019.2932215
   Yang S., 2014, P HUM FACT ERG SOC A, P1720
   Yem V, 2017, P IEEE VIRT REAL ANN, P99, DOI 10.1109/VR.2017.7892236
   Zhong X., 2017, P INT C INT ROB APPL, P372
NR 62
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4767
EP 4779
DI 10.1109/TVCG.2023.3279398
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400093
PM 37224347
OA Green Published
DA 2024-08-05
ER

PT J
AU Chen, Q
   Cao, SX
   Wang, JZ
   Cao, N
AF Chen, Qing
   Cao, Shixiong
   Wang, Jiazhe
   Cao, Nan
TI How Does Automation Shape the Process of Narrative Visualization: A
   Survey of Tools
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Automation; Authoring systems;
   Videos; Flowcharts; Taxonomy; Authoring tools; automatic visualization;
   data visualization; design space; narrative visualization; survey
ID DESIGN; GENERATION; INFOGRAPHICS; STORIES; IMAGES; EVOLUTION; CHARTS
AB In recent years, narrative visualization has gained much attention. Researchers have proposed different design spaces for various narrative visualization genres and scenarios to facilitate the creation process. As users' needs grow and automation technologies advance, increasingly more tools have been designed and developed. In this study, we summarized six genres of narrative visualization (annotated charts, infographics, timelines & storylines, data comics, scrollytelling & slideshow, and data videos) based on previous research and four types of tools (design spaces, authoring tools, ML/AI-supported tools and ML/AI-generator tools) based on the intelligence and automation level of the tools. We surveyed 105 papers and tools to study how automation can progressively engage in visualization design and narrative processes to help users easily create narrative visualizations. This research aims to provide an overview of current research and development in the automation involvement of narrative visualization tools. We discuss key research problems in each category and suggest new opportunities to encourage further research in the related domain.
C1 [Chen, Qing; Cao, Shixiong; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai 200070, Peoples R China.
   [Wang, Jiazhe] Ant Grp, Shanghai Hangzhou 310000, Peoples R China.
C3 Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai 200070, Peoples R China.
EM qingchen@tongji.edu.cn; caoshixiong@tongji.edu.cn;
   jiazhe.wjz@antgroup.com; nan.cao@tongji.edu.cn
OI Cao, ShiXiong/0009-0002-9640-7771; Cao, Nan/0000-0003-1316-7515
FU NSFC [62002267, 62072338, 62061136003]; NSF Shanghai [23ZR1464700];
   Shanghai Education Development Foundation "Chen-Guang Project" [21CGA75]
FX This work was supported in part by the NSFC under Grants 62002267,
   62072338, and 62061136003, in part by NSF Shanghai under Grant
   23ZR1464700, and in part by Shanghai Education Development Foundation
   "Chen-Guang Project" under Grant 21CGA75.
CR Adobe Systems Incorporated, 2023, Adobe illustrator
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2021, Cartographic J, V58, P83
   [Anonymous], 2016, Microsoft Powerpoint
   AppleKeynote, 2003, ABOUT US
   Bach B, 2017, IEEE COMPUT GRAPH, V37, P6, DOI 10.1109/MCG.2017.33
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bach Z., 2018, P CHI C HUM FACT COM, P1
   Bocklandt S, 2021, LECT NOTES COMPUT SC, V12822, P445, DOI 10.1007/978-3-030-86331-9_29
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Botero K.-H., 2010, P DES COMPL DRS INT, P1
   Brand A, 2019, ANN INTERN MED, V170, P579, DOI 10.7326/M18-2976
   Brath M., 2018, P IEEE VIS WORKSH VI, P1
   Brehmer M., 2019, P COMP JOURN S, P1
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Canva, 2018, ABOUT US
   Cao RC, 2020, VIS INFORM, V4, P8, DOI 10.1016/j.visinf.2019.12.002
   Chen Y., 2010, Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), P3703
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Cmeciu M., 2016, Stud. Media Commun., V4, P54
   Coding B., 2010, Sketch-professional digital design for mac
   Coelho D, 2020, COMPUT GRAPH FORUM, V39, P593, DOI 10.1111/cgf.14004
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Cui WW, 2022, IEEE T VIS COMPUT GR, V28, P173, DOI 10.1109/TVCG.2021.3114856
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Di Giacomo Emilio, 2020, Graph Drawing and Network Visualization. 28th International Symposium, GD 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12590), P324, DOI 10.1007/978-3-030-68766-3_25
   Diakopoulos N, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1717
   Dragicevic Y., 2020, of Human Computer Interaction, P1, DOI DOI 10.1007/978-3-319-27648-9_94-1
   Dukes D., 2010, Dipity
   Dunlap J., 2016, J. Vis. Lit., V35, P42, DOI [10.1080/1051144X.2016.1205832, 10.1080/1051144x.2016.1205832]
   Elias M, 2018, LECT NOTES COMPUT SC, V10896, P172, DOI 10.1007/978-3-319-94277-3_29
   Fan Y., 2022, P CHI C HUM FACT COM, P1
   Fischer G, 2006, HUM COM INT, V9, P427
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Ge B., 2021, P CHI C HUM FACT COM, P1
   Genette G., 1983, Narrative Discourse: An Essay in Method, V3
   Godulla C., 2017, Digitale Langformen Im Journalismus UndCorporate Publishing
   Gomez-Rubio V., 2017, J STAT SOFTW, V77, P1
   Gronemann M, 2016, LECT NOTES COMPUT SC, V9801, P367, DOI 10.1007/978-3-319-50106-2_29
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Hasan A., 2022, P CHI C HUM FACT COM, P1
   Heer J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1029
   Hogan T, 2017, INTERACT COMPUT, V29, P147, DOI 10.1093/iwc/iww015
   Hullman J., 2013, P 2013 CHI C HUM FAC, P2707, DOI DOI 10.1145/2470654.2481374
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Infogram, 2012, ABOUT US
   Isenberg P, 2018, LECT NOTES COMPUT SC, V11190, P165, DOI 10.1007/978-3-030-01388-2_6
   Kandogan E, 2012, IEEE CONF VIS ANAL, P73, DOI 10.1109/VAST.2012.6400487
   Kang T., 2021, P CHI C HUM FACT COM, P1
   Karyda M, 2021, IEEE COMPUT GRAPH, V41, P74, DOI 10.1109/MCG.2020.3025078
   Kashan O., 2012, Timeline of the universe
   Kim N. W., 2019, P CHI C HUM FACT COM, P1
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300309
   Kim NW, 2018, IEEE T VIS COMPUT GR, V24, P595, DOI 10.1109/TVCG.2017.2744118
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kim Y, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P201, DOI [10.1109/VIS49827.2021.9623291, 10.1109/VIS49827.2021.00048]
   Kittivorawong C, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P101, DOI 10.1109/VIS47514.2020.00027
   Kong HK, 2017, COMPUT GRAPH FORUM, V36, P515, DOI 10.1111/cgf.13207
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   Leake H. Valentina, 2020, P CHI C HUM FACT COM, P1
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee T., 2021, P CHI C HUM FACT COM, P1
   Li WC, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P141, DOI 10.1109/VIS47514.2020.00035
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Z., 2018, P CHI C HUM FACT COM, P1
   Lu JH, 2021, IEEE PAC VIS SYMP, P21, DOI 10.1109/PacificVis52677.2021.00011
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Lyra KT, 2016, IEEE INT CONF ADV LE, P366, DOI 10.1109/ICALT.2016.83
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Marshall CC, 1997, ACM DIGITAL LIBRARIES '97, P131
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   McKenna S, 2014, IEEE T VIS COMPUT GR, V20, P2191, DOI 10.1109/TVCG.2014.2346331
   MichaelAlbers J., 2017, Int. J. Multimedia Appl., V9, P1
   Naparin A. Binti, 2017, Int.J.Multimedia Appl., V9, P15
   Nguyen PH, 2016, INFORM VISUAL, V15, P253, DOI 10.1177/1473871615605347
   Nieto GMF, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P219, DOI 10.1145/3506860.3506895
   Northwestern University Knight Lab, 2013, Timelinejs
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Otten JJ, 2015, HEALTH AFFAIR, V34, P1901, DOI 10.1377/hlthaff.2015.0642
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Sallam Y., 2022, P CHI C HUM FACT COM, P1
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Schulz Hans-Jorg, 2010, PhD dissertation
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075
   Shaw J., 2011, Time line setter
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi X., 2021, P CHI C HUM FACT COM, P1
   Shrinivasan Yedendra B., 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P123, DOI 10.1109/VAST.2009.5333023
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Subramonyam H, 2019, IEEE T VIS COMPUT GR, V25, P597, DOI 10.1109/TVCG.2018.2865231
   Suh S, 2022, Arxiv, DOI arXiv:2208.12981
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Suprata F., 2019, J. Metris, V20, P1
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2020, J VISUAL-JAPAN, V23, P707, DOI 10.1007/s12650-020-00644-z
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974
   Thompson Z., 2021, P CHI C HUM FACT COM, P1
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Tyagi J., 2021, arXiv
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Visme, 2013, ABOUT US
   Wang H., 2019, P CHI C HUM FACT COM, P1
   Wang J., 2020, IEEE Trans. Vis. Comput. Graph., V27, P967
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang S., 2019, P CHI C HUM FACT COM, P1
   Wang Y, 2021, COMPUT GRAPH FORUM, V40, P507, DOI 10.1111/cgf.14325
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang Z., 2016, P S VIS, P1
   Wang ZZ, 2022, IEEE T VIS COMPUT GR, V28, P944, DOI 10.1109/TVCG.2021.3114849
   Webalon, 2011, Tiki-toki
   Westerlund B., 2005, P NORD RES C, P1
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Winters T, 2019, LECT NOTES COMPUT SC, V11453, P127, DOI 10.1007/978-3-030-16667-0_9
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xia N. H., 2018, P CHI C HUM FACT COM, P1
   Xu L., 2022, P CHI C HUM FACT COM, P1
   Yang Chen, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P155, DOI 10.1109/VAST.2010.5652885
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4252, DOI 10.1109/TVCG.2021.3085327
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhao J, 2021, Arxiv, DOI arXiv:2103.03996
   Zhao R. Marr, 2015, Tech. Rep. HCIL-2015-15
   Zhenpeng Zhao, 2019, Information in Contemporary Society. 14th International Conference, iConference 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11420), P327, DOI 10.1007/978-3-030-15742-5_32
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
   Zikas P, 2020, VISUAL COMPUT, V36, P1965, DOI 10.1007/s00371-020-01919-0
NR 149
TC 7
Z9 7
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG
PY 2024
VL 30
IS 8
BP 4429
EP 4448
DI 10.1109/TVCG.2023.3261320
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XP6C3
UT WOS:001262914400016
PM 37030780
OA Green Submitted, Bronze
DA 2024-08-05
ER

PT J
AU Palacios-Ibáñez, A
   Pirault, S
   Ochando-Martí, F
   Contero, M
   Camba, JD
AF Palacios-Ibanez, Almudena
   Pirault, Simon
   Ochando-Marti, Francesc
   Contero, Manuel
   Camba, Jorge D.
TI An Examination of the Relationship Between Visualization Media and
   Consumer Product Evaluation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Media; Visualization; Telephone sets; Prototypes; Electronic mail; Solid
   modeling; Rendering (computer graphics); Artificial; augmented; and
   virtual realities; consumer products; perception and psychophysics;
   virtual reality
ID GENDER-DIFFERENCES; VIRTUAL-REALITY; ONLINE; PERCEPTION; DESIGN; USER;
   REPRESENTATIONS; CUSTOMERS; RESPONSES; HAPTICS
AB Virtual product presentations that rely on static images and text are often insufficient to communicate all the information that is necessary to accurately evaluate a product. Technologies such as Virtual Reality (VR) or Augmented Reality (AR) have enabled more sophisticated representation methods, but certain product characteristics are difficult to assess and may result in perceptual differences when a product is evaluated in different visual media. In this article, we report two case studies in which a group of participants evaluated three designs of two product typologies (i.e., a desktop telephone and a coffee maker) as presented in three different visual media (i.e., photorealistic renderings, AR, and VR for the first case study; and photographs, a non-immersive virtual environment, and AR for the second case study) using eight semantic scales. An inferential statistical method using Aligned Rank Transform (ART) proceedings was applied to determine perceptual differences between groups. Our results show that in both cases product attributes in Jordan's physio-pleasure category are the most affected by the presentation media. The socio-pleasure category was also affected for the case of the coffee makers. The level of immersion afforded by the medium significantly affects product evaluation.
C1 [Palacios-Ibanez, Almudena; Contero, Manuel] Univ Politecn Valencia, HUMAN Tech, Valencia 46022, Spain.
   [Pirault, Simon; Ochando-Marti, Francesc] Univ Politecn Valencia, Valencia 46022, Spain.
   [Camba, Jorge D.] Purdue Univ, Sch Engn Technol, W Lafayette, IN 47907 USA.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de
   Valencia; Purdue University System; Purdue University
RP Palacios-Ibáñez, A (corresponding author), Univ Politecn Valencia, HUMAN Tech, Valencia 46022, Spain.
EM alpaib@upv.es; sipi@etsii.upv.es; fraocmar@etsii.upv.es;
   mcontero@upv.es; jdorribo@purdue.edu
RI Palacios-Ibáñez, Almudena/AFX-0246-2022; Contero, Manuel/F-4276-2010
OI Palacios-Ibáñez, Almudena/0000-0002-1115-0720; Contero,
   Manuel/0000-0002-6081-9988
FU Spanish Ministry of Education and Vocational Training under a FPU
   fellowship [FPU19/03878]
FX This research work was supported in part by the Spanish Ministry of
   Education and Vocational Training under a FPU fellowship under Grant
   FPU19/03878.
CR Achiche S., 2014, Systems, Design, and Complexity, P1, DOI [10.1115/IMECE2014-40443, DOI 10.1115/IMECE2014-40443]
   Agost Maria-Jesus, 2021, Human Interface and the Management of Information Information Presentation and Visualization. Thematic Area, HIMI 2021. Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12765), P3, DOI 10.1007/978-3-030-78321-1_1
   Agost M. J., 2020, P 24 INT C PROJ MAN, P1827
   Agost M.-J., 2021, The Use of New Presentation Technologies in Electronic Sales Environments and Their Influence On Product Perception
   [Anonymous], 2002, Designing emotions
   Arrighi PA, 2019, J INTELL MANUF, V30, P743, DOI 10.1007/s10845-016-1276-0
   Artacho-Ramírez MA, 2008, INT J IND ERGONOM, V38, P942, DOI 10.1016/j.ergon.2008.02.020
   Arvanitis TN, 2009, PERS UBIQUIT COMPUT, V13, P243, DOI 10.1007/s00779-007-0187-7
   Banerjee NT, 2022, IEEE T VIS COMPUT GR, V28, P4787, DOI 10.1109/TVCG.2021.3105606
   Beck M, 2018, J RETAIL CONSUM SERV, V40, P279, DOI 10.1016/j.jretconser.2016.08.006
   Berni A., 2020, P SCO C, P1607, DOI [10.1017/dsd.2020.296, DOI 10.1017/DSD.2020.296]
   Berni A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071064
   Bimber O., 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Bordegoni M, 2011, INNOVATION IN PRODUCT DESIGN: FROM CAD TO VIRTUAL PROTOTYPING, P117, DOI 10.1007/978-0-85729-775-4_7
   Cecil J, 2007, INT J ADV MANUF TECH, V31, P846, DOI 10.1007/s00170-005-0267-7
   Cho JS, 2004, INFORM MANAGE-AMSTER, V41, P827, DOI 10.1016/j.im.2003.08.013
   Chu CH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144723
   Desmet P., 2011, P C INT UZ KANS PRAK, P8
   Desmet Pieter, 2001, Des. J., V4, P32, DOI DOI 10.2752/146069201789378496
   Dittmar H, 2004, SEX ROLES, V50, P423, DOI 10.1023/B:SERS.0000018896.35251.c7
   Donald N., 2004, Why We Love (or Hate) Everyday Things
   Engelbrektsson P., 2000, P INT PROD DEV MAN C, P29
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Felip F., 2021, P INT C PROJ MAN EG, P980
   Felip F, 2020, VIRTUAL REAL-LONDON, V24, P439, DOI 10.1007/s10055-019-00406-9
   Forbes T., 2018, DS 91 P NORD DES
   Galán J, 2021, INT J INTERACT MULTI, V6, P196, DOI 10.9781/ijimai.2021.01.001
   Galán J, 2021, J COMPUT DES ENG, V8, P330, DOI 10.1093/jcde/qwaa081
   Greengard S., 2022, Where augmented reality is going and why you should care
   Grohmann B, 2007, J RETAILING, V83, P237, DOI 10.1016/j.jretai.2006.09.001
   Hagtvedt H, 2017, J CONSUM RES, V44, P396, DOI 10.1093/jcr/ucx039
   Hannah R, 2012, J ENG DESIGN, V23, P443, DOI 10.1080/09544828.2011.615302
   Hasan B, 2010, COMPUT HUM BEHAV, V26, P597, DOI 10.1016/j.chb.2009.12.012
   Heineken E, 2007, HUM FACTORS, V49, P136, DOI 10.1518/001872007779598028
   Higgins J. J., 1990, P 34 ANN ACM S US IN, P754, DOI DOI 10.4148/2475-7772.1443
   Hoermann M, 2015, LECT NOTES COMPUT SC, V9179, P470, DOI 10.1007/978-3-319-21067-4_48
   Hsu CC, 2017, DISPLAYS, V50, P21, DOI 10.1016/j.displa.2017.09.002
   Hsu SH, 2000, INT J IND ERGONOM, V25, P375, DOI 10.1016/S0169-8141(99)00026-8
   Jeong SW, 2009, INTERNET RES, V19, P105, DOI 10.1108/10662240910927858
   Jiang ZJ, 2007, MIS QUART, V31, P475
   Jordan P.W., 2002, Designing pleasurable products: An introduction to the new human factors
   Kelly JW, 2023, IEEE T VIS COMPUT GR, V29, P4978, DOI 10.1109/TVCG.2022.3196606
   Kim TH, 2021, FASH TEXT, V8, DOI 10.1186/s40691-021-00261-w
   Kinzinger A, 2022, INFORM SYST J, V32, P1034, DOI 10.1111/isj.12382
   Li SM, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9040337
   Lin XL, 2019, INFORM SYST FRONT, V21, P1187, DOI 10.1007/s10796-018-9831-1
   Liu X, 2022, J ENG DESIGN, V33, P412, DOI 10.1080/09544828.2022.2078660
   Mansouri H, 2004, COMMUN STAT-THEOR M, V33, P2217, DOI 10.1081/STA-200026599
   Mata MP, 2017, RES ENG DES, V28, P357, DOI 10.1007/s00163-016-0244-1
   Meta, 2021, Meta Press Release
   Ortiz Nicolas J. C., 2013, P 5 INT ASS SOC RES, P5546
   Osgood C. E., 1957, MEASUREMENT MEANING
   Ozer M, 1999, J PROD INNOVAT MANAG, V16, P77, DOI 10.1111/1540-5885.1610077
   Ozok AA, 2009, INT J HUM-COMPUT INT, V25, P243, DOI 10.1080/10447310802546724
   Palacios-Ibáñez A, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4055952
   Palacios-Ibáñez A, 2023, COMPUT IND, V144, DOI 10.1016/j.compind.2022.103780
   Park H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311510
   Qu QX, 2019, INT J IND ERGONOM, V72, P281, DOI 10.1016/j.ergon.2019.06.006
   Ray S, 2017, INT CONF ENG DES, P563
   Reid TN, 2013, J MECH DESIGN, V135, DOI 10.1115/1.4024724
   Roy R, 2009, CIRP J MANUF SCI TEC, V1, P172, DOI 10.1016/j.cirpj.2008.10.007
   SCHOORMANS JPL, 1995, J PROD INNOVAT MANAG, V12, P153, DOI 10.1111/1540-5885.1220153
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Singh Jitender, 2022, Advances in Mechanical Engineering and Material Science: Select Proceedings of ICAMEMS-2022. Lecture Notes in Mechanical Engineering, P149, DOI 10.1007/978-981-19-0676-3_12
   Söderman M, 2005, J ENG DESIGN, V16, P311, DOI 10.1080/09544820500128967
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Tesch A, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2673, DOI 10.1145/3394171.3413980
   Tiainen T, 2014, VIRTUAL PHYS PROTOTY, V9, P169, DOI 10.1080/17452759.2014.934573
   Tiger L., 1992, The Pursuit of Pleasure
   Van Slyke C, 2002, COMMUN ACM, V45, P82, DOI 10.1145/545151.545155
   Virzi R. A., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P236, DOI 10.1145/238386.238516
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wodehouse A., 2019, P SOC INT C ENG, P1313, DOI [10.1017/dsi.2019.137, DOI 10.1017/DSI.2019.137]
   Ye J, 2007, LECT NOTES COMPUT SC, V4553, P1190
   Yoo J, 2014, J BUS RES, V67, P2464, DOI 10.1016/j.jbusres.2014.03.006
NR 75
TC 4
Z9 4
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3636
EP 3649
DI 10.1109/TVCG.2023.3238428
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700034
PM 37022017
OA hybrid
DA 2024-08-05
ER

PT J
AU Krasner, A
   Gabbard, J
AF Krasner, Alexander
   Gabbard, Joseph
TI MusiKeys: Exploring Haptic-to-Auditory Sensory Substitution to Improve
   Mid-Air Text-Entry
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Extended reality; Spatial computing; Mid-air
   text-entry; Sensory substitution; Human-computer interaction (HCI)
AB Physical QWERTY keyboards are the current standard for performing precision text-entry with extended reality devices. Ideally, there would exist a comparable, self-contained solution that works anywhere, without requiring external keyboards. Unfortunately, when physical keyboards are recreated virtually, we currently lose critical haptic feedback information from the sense of touch, which impedes typing. In this paper, we introduce the MusiKeys Technique, which uses auditory feedback in virtual reality to communicate missing haptic feedback information typists normally receive when using a physical keyboard. To examine this concept, we conducted a user study with 24 participants which encompassed four mid-air virtual keyboards augmented with increasing amounts of feedback information, along with a fifth physical keyboard for reference. Results suggest that providing clicking feedback on key-press and key-release improves typing performance compared to not providing auditory feedback, which is consistent with the literature. We also found that audio can serve as a substitute for information contained in haptic feedback, in that users can accurately perceive the presented information. However, under our specific study conditions, this awareness of the feedback information did not yield significant differences in typing performance. Our results suggest this kind of feedback replacement can be perceived by users but needs more research to tune and improve the specific techniques.
C1 [Krasner, Alexander; Gabbard, Joseph] Virginia Tech, Blacksburg, VA 24061 USA.
C3 Virginia Polytechnic Institute & State University
RP Krasner, A (corresponding author), Virginia Tech, Blacksburg, VA 24061 USA.
EM akrasner@vt.edu; jgabbard@vt.edu
OI Krasner, Alexander/0000-0002-1017-0332
CR Batmaz A. U., 2022, P 2022 ACM S SPAT US, V12, DOI DOI 10.1145/3565970.3567702
   Batmaz AU, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P189, DOI 10.1109/VRW52623.2021.00042
   Belardinelli MO, 2009, LECT NOTES COMPUT SC, V5615, P557, DOI 10.1007/978-3-642-02710-9_62
   Bermejo C., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, P26, DOI [10.1145/34571413, DOI 10.1145/34571413]
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Brooke J., 1996, SUS-a quick and dirty usability scale, DOI [DOI 10.1201/9781498710411-35, DOI 10.1201/9781498710411]
   Chuah S. H.-W., 2018, SSRN Electronic Journal, V12, DOI [10.2139/SSRN.33004691, DOI 10.2139/SSRN.33004691]
   Dube T. J., 2019, International Conference on Human-Computer Interaction, P419
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Fashimpaur J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382888
   Gil H., 2020, P ACM S VIRT REAL SO, V11, DOI [10.1145/3385956.34189631,2, DOI 10.1145/3385956.34189631,2]
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   HART S G, 1988, P139
   Kim JR, 2014, IEEE HAPTICS SYM, P227, DOI 10.1109/HAPTICS.2014.6775459
   Lee LH, 2019, INT CONF PERVAS COMP, DOI 10.1109/percom.2019.8767420
   Loomis J. M., 2002, Converging technologies for improving human performance, V213
   Mackenzie I.S., 2003, P ACM C HUMAN FACTOR, P113
   Pujari V., 2019, Journal of Advanced Medical and Dental Sciences Research
   Sand Antti., 2015, Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology, P51, DOI [DOI 10.1145/2821592.2821593, 10.1145/2821592.28215932[19]J]
   Shen JX, 2022, INT SYM MIX AUGMENT, P702, DOI 10.1109/ISMAR55827.2022.00088
   Shull PB, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0055-z
   Simeone A, 2023, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-031-05804-2_1
   Singhal R. H., 2022, C HUMAN FACTORS COMP, V4, DOI [10.1145/3491102.35021001,2[23]R.W., DOI 10.1145/3491102.35021001,2[23]R.W]
   Soukoreff R.W., 2001, CHI '01 extended abstracts on Human factors in computing systems, CHI EA '01, P319, DOI DOI 10.1145/634067.634256
   Thome C.-T., 2006, BME, V200, P300
   Wang W. C., 2015, MOBILEHCI 2015 P 17, P153, DOI [DOI 10.1145/2785830.27858862, 10.1145/2785830.2785886]
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yildirim C., 2022, International Journal of HumanComputer Interaction, V2, P8, DOI [10.1080/10447318.2022.21073302,8, DOI 10.1080/10447318.2022.21073302,8]
   Zhang R., 2005, P 21 SPRING C COMP G, DOI [10.1145/10901222,8 \n, DOI 10.1145/10901222,8]
NR 31
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2247
EP 2256
DI 10.1109/TVCG.2024.3372065
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400015
PM 38437075
DA 2024-08-05
ER

PT J
AU Lee, G
   Lee, DY
   Su, GM
   Manocha, D
AF Lee, Geonsun
   Lee, Dae Yeol
   Su, Guan-Ming
   Manocha, Dinesh
TI "May I Speak?": Multi-Modal Attention Guidance in Social VR Group
   Conversations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Social VR; Attention Guidance; Multi-modal Interaction; Group
   Conversations; Turn-taking
AB In this paper, we present a novel multi-modal attention guidance method designed to address the challenges of turn-taking dynamics in meetings and enhance group conversations within virtual reality (VR) environments. Recognizing the difficulties posed by a confined field of view and the absence of detailed gesture tracking in VR, our proposed method aims to mitigate the challenges of noticing new speakers attempting to join the conversation. This approach tailors attention guidance, providing a nuanced experience for highly engaged participants while offering subtler cues for those less engaged, thereby enriching the overall meeting dynamics. Through group interview studies, we gathered insights to guide our design, resulting in a prototype that employs light as a diegetic guidance mechanism, complemented by spatial audio. The combination creates an intuitive and immersive meeting environment, effectively directing users' attention to new speakers. An evaluation study, comparing our method to state-of-the-art attention guidance approaches, demonstrated significantly faster response times (p < 0.001), heightened perceived conversation satisfaction (p < 0.001), and preference (p < 0.001) for our method. Our findings contribute to the understanding of design implications for VR social attention guidance, opening avenues for future research and development.
C1 [Lee, Geonsun; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
   [Lee, Dae Yeol; Su, Guan-Ming] Dolby Labs, San Francisco, CA USA.
C3 University System of Maryland; University of Maryland College Park;
   Dolby Laboratories, Inc.
RP Lee, G (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM gsunlee@cs.umd.edu; DaeYeol.Lee@dolby.com; guanming.su@dolby.com;
   dmanocha@cs.umd.edu
OI Manocha, Dinesh/0000-0001-7047-9801; Lee, Dae Yeol/0000-0001-9990-5253;
   Lee, Geonsun/0000-0001-9401-8559
CR Yassien A., INPROCEEDINGS 11 NOR
   Zhang X., 2020, INPROCEEDINGS 4 INT, P31
NR 2
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2287
EP 2297
DI 10.1109/TVCG.2024.3372119
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400024
PM 38451772
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zhang, GF
   Yuan, J
   Liu, HM
   Peng, Z
   Li, CL
   Wang, ZB
   Bao, HJ
AF Zhang, Guofeng
   Yuan, Jin
   Liu, Haomin
   Peng, Zhen
   Li, Chunlei
   Wang, Zibin
   Bao, Hujun
TI 100-Phones: A Large VI-SLAM Dataset for Augmented Reality Towards Mass
   Deployment on Mobile Phones
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented Reality; Dataset; Benchmark; VI-SLAM
ID MONOCULAR SLAM; ROBUST; VERSATILE; ODOMETRY
AB Visual-inertial SLAM (VI-SLAM) is a key technology for Augmented Reality (AR), which allows the AR device to recover its 6-DoF motion in real-time in order to render the virtual content with the corresponding pose. Nowadays, smartphones are still the mainstream devices for ordinary users to experience AR. However the current VI-SLAM methods, although performing well on high-end phones, still face robustness challenges when deployed on a larger stock of mid- and low-end phones. Existing VI-SLAM datasets use either very ideal sensors or only a limited number of devices for data collection, which cannot reflect the capability gaps that VI-SLAM methods need to solve when deployed on a large variety of phone models. This work proposes 100-Phones. the first VI-SLAM dataset covering a wide range of mainstream phones in the market. The dataset consists of 350 sequences collected by 100 different models of phones. Through analysis and experiments on the collected data, we conclude that the quality of visual-inertial data vary greatly among the mainstream phones, and the current open source VI-SLAM methods still have serious robustness issues when it comes to mass deployment on mobile phones. We release the dataset to facilitate the robustness improvement of VI-SLAM and to promote the mass popularization of AR. Project page: https://github.com/zju3dv/100-Phones.
C1 [Zhang, Guofeng; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Yuan, Jin; Liu, Haomin; Peng, Zhen; Li, Chunlei; Wang, Zibin] SenseTime, Hong Kong, Peoples R China.
C3 Zhejiang University
RP Bao, HJ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM zhangguofeng@zju.edu.cn; yuanjin1@sensetime.com; 172753015@qq.com;
   pengzhen1@sensetime.com; lichunlei@sensetime.com;
   wangzibin@sensetime.com; baohujun@zju.edu.cn
OI Zhang, Guofeng/0000-0001-5661-8430; Bao, Hujun/0000-0002-2662-0334
FU NSF of China
FX No Statement Available
CR Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chen DP, 2021, INT SYM MIX AUGMENT, P275, DOI 10.1109/ISMAR52148.2021.00043
   Delmerico J, 2018, IEEE INT CONF ROBOT, P2502
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geneva P, 2020, IEEE INT CONF ROBOT, P4666, DOI [10.1109/icra40945.2020.9196524, 10.1109/ICRA40945.2020.9196524]
   Hartley R, 2003, Multiple view geometry in computer vision, DOI [10.1016/S0143-8166(01)00145-2, DOI 10.1017/CBO9780511811685]
   He YJ, 2023, PROC CVPR IEEE, P739, DOI 10.1109/CVPR52729.2023.00078
   Holzwarth Valentin, 2021, ICVARS 2021: 2021 the 5th International Conference on Virtual and Augmented Reality Simulations, P42, DOI 10.1145/3463914.3463921
   Ichikari R., 2017, INT C ARTIFICIAL REA, P229
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Klein George, 2007, P1
   Lee D, 2021, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR46437.2021.00324
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li J., 2019, Virtual Reality & Intelligent Hardware, V1, P386, DOI 10.1016/j.vrih.2019.07.002
   Li PL, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P11, DOI 10.1109/ISMAR.2017.18
   Liu H., 2023, IEEE Transactions on Circuits and Systems for Video Technology, DOI [10.1109/TCSVT.2023.33061602,6, DOI 10.1109/TCSVT.2023.33061602,6]
   Liu HM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P219, DOI 10.1109/ISMAR-Adjunct51615.2020.00065
   Liu HM, 2018, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR.2018.00211
   Liu HM, 2016, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2016.24
   Liu WX, 2020, IEEE ROBOT AUTOM LET, V5, P5653, DOI 10.1109/LRA.2020.3007421
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Olson E, 2011, IEEE INT CONF ROBOT
   Oth L, 2013, PROC CVPR IEEE, P1360, DOI 10.1109/CVPR.2013.179
   Pfrommer Bernd, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3847, DOI 10.1109/ICRA.2017.7989443
   Qin T, 2018, IEEE INT C INT ROBOT, P3662, DOI 10.1109/IROS.2018.8593603
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Rosinol A, 2023, IEEE INT C INT ROBOT, P3437, DOI 10.1109/IROS55552.2023.10341922
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sarlin PE, 2022, LECT NOTES COMPUT SC, V13667, P686, DOI 10.1007/978-3-031-20071-7_40
   Schönberger JL, 2017, LECT NOTES COMPUT SC, V10111, P321, DOI 10.1007/978-3-319-54181-5_21
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schubert D, 2018, IEEE INT C INT ROBOT, P1680, DOI 10.1109/IROS.2018.8593419
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Spera E, 2021, IEEE T CIRC SYST VID, V31, P1253, DOI 10.1109/TCSVT.2019.2941040
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Teed Z, 2021, ADV NEUR IN, V34
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   von Stumberg L, 2022, IEEE ROBOT AUTOM LET, V7, P1408, DOI 10.1109/LRA.2021.3140129
   Wang C, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P366, DOI 10.1109/ISMAR-Adjunct.2019.00-10
   Wu Kejian J., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5155, DOI 10.1109/ICRA.2017.7989603
   Wu KJ, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Xue F, 2019, PROC CVPR IEEE, P8567, DOI 10.1109/CVPR.2019.00877
   Zhu Z., 2023, arXiv
NR 58
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2098
EP 2108
DI 10.1109/TVCG.2024.3372133
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400045
PM 38437081
DA 2024-08-05
ER

PT J
AU Xu, SZ
   Liu, JH
   Wang, M
   Zhang, FL
   Zhang, SH
AF Xu, Sen-Zhe
   Liu, Jia-Hong
   Wang, Miao
   Zhang, Fang-Lue
   Zhang, Song-Hai
TI Multi-User Redirected Walking in Separate Physical Spaces for Online VR
   Scenarios
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Redirected walking; multi-user; online VR; fairness
AB With the recent rise of Metaverse, online multiplayer VR applications are becoming increasingly prevalent worldwide. However, as multiple users are located in different physical environments, different reset frequencies and timings can lead to serious fairness issues for online collaborative/competitive VR applications. For the fairness of online VR apps/games, an ideal online RDW strategy must make the locomotion opportunities of different users equal, regardless of different physical environment layouts. The existing RDW methods lack the scheme to coordinate multiple users in different PEs, and thus have the issue of triggering too many resets for all the users under the locomotion fairness constraint. We propose a novel multi-user RDW method that is able to significantly reduce the overall reset number and give users a better immersive experience by providing a fair exploration. Our key idea is to first find out the "bottleneck" user that may cause all users to be reset and estimate the time to reset given the users' next targets, and then redirect all the users to favorable poses during that maximized bottleneck time to ensure the subsequent resets can be postponed as much as possible. More particularly, we develop methods to estimate the time of possibly encountering obstacles and the reachable area for a specific pose to enable the prediction of the next reset caused by any user. Our experiments and user study found that our method outperforms existing RDW methods in online VR applications.
C1 [Xu, Sen-Zhe] Tsinghua Univ, YMSC, Beijing 100190, Peoples R China.
   [Liu, Jia-Hong; Zhang, Song-Hai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
   [Liu, Jia-Hong; Zhang, Song-Hai] Tsinghua Univ, BNRist, Beijing 100190, Peoples R China.
   [Wang, Miao] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6012, New Zealand.
C3 Tsinghua University; Tsinghua University; Tsinghua University; Beihang
   University; Victoria University Wellington
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.; Zhang, SH (corresponding author), Tsinghua Univ, BNRist, Beijing 100190, Peoples R China.
EM xsz15@tsinghua.org.cn; liujiaho19@mails.tsinghua.edu.cn;
   miaowang.me@gmail.com; z.fanglue@gmail.com; shz@tsinghua.edu.cn
OI Xu, Sen-Zhe/0000-0003-2669-7814; Liu, JiaHong/0000-0001-9166-9364
FU National Natural Science Foundation of China
FX No Statement Available
CR Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Bolas E. A., 2015, ICAT EGVE 2015 INT C, P93, DOI DOI 10.2312/EGVE.20151315
   Chang Y., 2019, arXiv
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Dong ZC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3345554
   Fan LW, 2023, IEEE T VIS COMPUT GR, V29, P4104, DOI 10.1109/TVCG.2022.3179269
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI DOI 10.1207/S15327108IJAP02012
   Williams NL, 2021, Arxiv, DOI arXiv:2106.06807
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.00-70, 10.1109/VR46266.2020.1581309443724]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/VR.2019.8798121, 10.1109/vr.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Ondrejka C., 2004, NEW YORK LAW SCH LAW, V49, P81
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Razzaque S., 2005, Redirected walking
   Razzaque S., 2001, Redirected walking, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Steinicke G., 2009, JVRB-J. Virtual Reality Broadcast., V6
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Thomas C. Hutton, 2020, P 26 ACM S VIRT REAL, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/VR.2019.8797983, 10.1109/vr.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams A., IEEETrans.Vis.Comput.Graph., V27, P2535
   Williams G., 2006, P 3 S APPL PERC GRAP, P21, DOI [10.1145/1140491.1140495, 10.1145/1140491.1140495.78, DOI 10.1145/1140491.1140495.78]
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
NR 36
TC 6
Z9 6
U1 15
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1916
EP 1926
DI 10.1109/TVCG.2023.3251648
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500008
PM 37028008
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Zang, ZL
   Cheng, SH
   Xia, HC
   Li, LY
   Sun, YT
   Xu, YJ
   Shang, L
   Sun, BG
   Li, SZ
AF Zang, Zelin
   Cheng, Shenghui
   Xia, Hanchen
   Li, Liangyu
   Sun, Yaoting
   Xu, Yongjie
   Shang, Lei
   Sun, Baigui
   Li, Stan Z.
TI DMT-EV: An Explainable Deep Network for Dimension Reduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dimension reduction; explainability of DR models; deep learning;
   parametric model
AB Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the poor generalisation performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called DMT-EV, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. DMT-EV starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained DMT-EV parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust DMT-EV to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that DMT-EV consistently outperforms the state-of-the-art methods in both performance measures and explainability.
C1 [Zang, Zelin; Cheng, Shenghui; Xia, Hanchen; Li, Liangyu; Sun, Yaoting; Xu, Yongjie; Li, Stan Z.] Westlake Univ, Sch Engn, AI Div, Hangzhou 310024, Zhejiang, Peoples R China.
   [Shang, Lei; Sun, Baigui] Alibaba Grp, Hangzhou 311121, Peoples R China.
C3 Westlake University; Alibaba Group
RP Li, SZ (corresponding author), Westlake Univ, Sch Engn, AI Div, Hangzhou 310024, Zhejiang, Peoples R China.
EM zangzelin@westlake.edu.cn; chengshenghui@westlake.edu.cn;
   573375794@qq.com; liliangyu@westlake.edu.cn; sunyaoting@westlake.edu.cn;
   xuyongjie@westlake.edu.cn; sl172005@alibaba-inc.com;
   baigui.sbg@alibaba-inc.com; stan.zq.li@westlake.edu.cn
RI cheng, shenghui/KIJ-8262-2024
OI Xu, Yongjie/0000-0002-6045-1626; Cheng, Shenghui/0000-0002-3767-8371;
   Zang, Zelin/0000-0003-2831-5437
FU National Natural Science Foundation of China
FX No Statement Available
CR Adler P, 2018, KNOWL INF SYST, V54, P95, DOI 10.1007/s10115-017-1116-3
   Andrews TS, 2021, NAT PROTOC, V16, P1, DOI 10.1038/s41596-020-00409-w
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belkina AC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13055-y
   Björklund A, 2022, Arxiv, DOI [arXiv:2201.04455, 10.48550/ARXIV.2201.04455, DOI 10.48550/ARXIV.2201.04455]
   Chatzimparmpas A, 2020, IEEE T VIS COMPUT GR, V26, P2696, DOI 10.1109/TVCG.2020.2986996
   Chen C, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21082873
   Chen T, 2020, Arxiv, DOI [arXiv:2002.05709, DOI 10.48550/ARXIV.2002.05709]
   Cheng SH, 2016, IEEE T VIS COMPUT GR, V22, P121, DOI 10.1109/TVCG.2015.2467552
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Duque AF, 2020, IEEE INT CONF BIG DA, P5027, DOI 10.1109/BigData50022.2020.9378049
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Ghosh A, 2022, IEEE T KNOWL DATA EN, V34, P2227, DOI 10.1109/TKDE.2020.3005878
   Ghosh A, 2022, IEEE T VIS COMPUT GR, V28, P2791, DOI 10.1109/TVCG.2020.3039106
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   HARDLE W, 1993, ANN STAT, V21, P1926, DOI 10.1214/aos/1176349403
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2002, ADV NEURAL INFORM PR, V15, P857, DOI DOI 10.5555/2968618.2968725
   Kobak D., 2019, UMAP does not preserve global structure any better than t-SNE when using the same initialization, DOI DOI 10.1101/2019.12.19.877522
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694
   Kumar A, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391361
   Lähnemann D, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-1926-6
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Loshchilov I, 2019, Arxiv, DOI [arXiv:1711.05101, 10.48550/arXiv.1711.05101, DOI 10.48550/ARXIV.1711.05101]
   Lundberg SM, 2017, ADV NEUR IN, V30
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861]
   Molnar C, 2020, COMM COM INF SC, V1323, P417, DOI 10.1007/978-3-030-65965-3_28
   Moon KR, 2019, NAT BIOTECHNOL, V37, P1482, DOI 10.1038/s41587-019-0336-3
   Moor M., 2020, INT C MACH LEARN, P7045
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pagliosa L, 2016, SIBGRAPI, P297, DOI [10.1109/SIBGRAPI.2016.048, 10.1109/SIBGRAPI.2016.45]
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sainburg T, 2021, Arxiv, DOI [arXiv:2009.12981, DOI 10.48550/ARXIV.2009.12981, 10.48550/arXiv.2009.12981]
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]
   Sohns J.-T., 2021, arXiv
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Suhre K, 2021, NAT REV GENET, V22, P19, DOI 10.1038/s41576-020-0268-2
   Szubert B, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45301-0
   Tang J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P287, DOI 10.1145/2872427.2883041
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Ribeiro MT, 2016, Arxiv, DOI [arXiv:1602.04938, DOI 10.48550/ARXIV.1602.04938]
   Van Der Maaten L., 2009, P MACHINE LEARNING R, P384
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Unen V, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01689-9
   Verma S, 2020, Arxiv, DOI arXiv:2010.10596
   [王瑛 Wang Ying], 2021, [空军工程大学学报. 自然科学版, Journal of Air Force Engineering University. Natural Science Edition], V22, P1
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Zang ZL, 2022, LECT NOTES COMPUT SC, V13681, P576, DOI 10.1007/978-3-031-19803-8_34
NR 55
TC 2
Z9 2
U1 7
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1710
EP 1727
DI 10.1109/TVCG.2022.3223399
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500013
PM 36409811
OA hybrid
DA 2024-08-05
ER

PT J
AU Lei, F
   Fan, AR
   Maceachren, AM
   Maciejewski, R
AF Lei, Fan
   Fan, Arlen
   Maceachren, Alan M.
   Maciejewski, Ross
TI GeoLinter: A Linting Framework for Choropleth Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Image color analysis; Geology; Recommender systems;
   Guidelines; Bars; Visualization; Choropleth maps; visualization linting;
   automated visualization design; visualization recommendation
ID COLOR SCHEMES; SELECTION
AB Visualization linting is a proven effective tool in assisting users to follow established visualization guidelines. Despite its success, visualization linting for choropleth maps, one of the most popular visualizations on the internet, has yet to be investigated. In this paper, we present GeoLinter, a linting framework for choropleth maps that assists in creating accurate and robust maps. Based on a set of design guidelines and metrics drawing upon a collection of best practices from the cartographic literature, GeoLinter detects potentially suboptimal design decisions and provides further recommendations on design improvement with explanations at each step of the design process. We perform a validation study to evaluate the proposed framework's functionality with respect to identifying and fixing errors and apply its results to improve the robustness of GeoLinter. Finally, we demonstrate the effectiveness of the GeoLinter - validated through empirical studies - by applying it to a series of case studies using real-world datasets.
C1 [Lei, Fan; Fan, Arlen; Maciejewski, Ross] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA.
   [Maceachren, Alan M.] Penn State Univ, State Coll, PA 16801 USA.
C3 Arizona State University; Arizona State University-Tempe; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); Pennsylvania State
   University
RP Maciejewski, R (corresponding author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA.
EM flei5@asu.edu; afan5@asu.edu; maceachren@psu.edu; rmacieje@asu.edu
RI Lei, Fan/KFB-0896-2024
OI Lei, Fan/0000-0003-4244-0971; Fan, Arlen/0000-0002-8376-2881
FU National Science Foundation
FX No Statement Available
CR A. of American Geographers U. C. for Geographic Information Science M. C. T. Force and B. of Knowledge Advisory Board, 2006, Geographic information science and technology body of knowledge
   [Anonymous], 2014, THEMATIC CARTOGRAPHY
   Anselin L., 2010, HDB APPL SPATIAL ANA, P73, DOI [DOI 10.1007/978-3-642-03647-7_5, 10.1007/978-3-642-03647-7_5]
   Anselin L, 2020, CONTIGUITY BASED SPA
   ArcGIS Pro 3.1 Esri, 2023, ArcGIS Pro geoprocessing tool reference, spatial autocorrelation (global Moran's I)(spatial statistics)
   Barowy DW, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276518
   Barowy DW, 2014, ACM SIGPLAN NOTICES, V49, P507, DOI [10.1145/2714064.2660207, 10.1145/2660193.2660207]
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brewer CA, 1997, ANN ASSOC AM GEOGR, V87, P411, DOI 10.1111/1467-8306.00061
   Brewer CA, 2002, ANN ASSOC AM GEOGR, V92, P662, DOI 10.1111/1467-8306.00310
   Brychtova A., 2015, Int. J. Cartography, V1, P62
   Brychtová A, 2017, CARTOGR GEOGR INF SC, V44, P229, DOI 10.1080/15230406.2016.1140074
   Brychtova A, 2016, CARTOGR J, V53, P202, DOI 10.1179/1743277414Y.0000000103
   Chang K.-T, 2008, Introduction to Geographic Information Systems, V4
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   CLEVELAND WS, 1983, AM STAT, V37, P101, DOI 10.2307/2685868
   Cromley R. G., 1995, Cartographica Int. J. Geographic Inf. Geovisualization, V32, P15, DOI DOI 10.3138/J610-13NU-5537-0483
   Declerq F, 1995, P 17 C 10 GEN ASS IN, P918
   Dent B.D., 1999, CARTOGRAPHY THEMATIC
   Duke D, 2001, P ACM INT C P SER, P11
   Duque JC, 2012, J REGIONAL SCI, V52, P397, DOI 10.1111/j.1467-9787.2011.00743.x
   EVANS IS, 1977, T I BRIT GEOGR, V2, P98, DOI 10.2307/622195
   Golebiowska IM, 2022, IEEE T VIS COMPUT GR, V28, P2722, DOI 10.1109/TVCG.2020.3035823
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hegarty M., 2009, CARTOGRAPHICA, V44, P171, DOI [DOI 10.3138/CARTO.44.3.171, https://doi.org/10.3138/carto.44.3.171]
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   JENKS GF, 1971, ANN ASSOC AM GEOGR, V61, P217, DOI 10.1111/j.1467-8306.1971.tb00779.x
   Jiang B, 2013, PROF GEOGR, V65, P482, DOI 10.1080/00330124.2012.700499
   Kang C., 2003, P ANN NAT C DIG GOV, P1
   Kessler FC, 2017, LECT NOTES GEOINF CA, P117, DOI 10.1007/978-3-319-51835-0_4
   Kraak F., 2020, Cartography: Visualization of GeospatialData
   LASKOWSKI PH, 1989, AM CARTOGRAPHER, V16, P123, DOI 10.1559/152304089783875497
   León GM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P91, DOI 10.1109/VIS47514.2020.00025
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   MCGRANAGHAN M, 1989, AM CARTOGRAPHER, V16, P279, DOI 10.1559/152304089783813918
   McNutt G., 2018, P 2 WORKSH CREAT CUR, P1
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.1093/biomet/37.1-2.17
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Mu  slu K., 2015, ISSTA 15, P373, DOI [10.1145/27717 83.2771792, DOI 10.1145/2771783.2771792]
   Perry D. B., 2013, P ISCHOOL C
   Qian X, 2020, Arxiv, DOI arXiv:2009.12316
   Rey SJ, 2022, GEOGR ANAL, V54, P467, DOI 10.1111/gean.12276
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savric B, 2019, INT J GEOGR INF SCI, V33, P454, DOI 10.1080/13658816.2018.1504949
   Savric B, 2016, CARTOGR J, V53, P177, DOI 10.1080/00087041.2015.1131938
   Savric B, 2011, CARTOGR GEOGR INF SC, V38, P363, DOI 10.1559/15230406384363
   Schiewe J., 2019, KN-Journal of Cartography and Geographic Information, V69, P217, DOI [DOI 10.1007/S42489-019-00026-Y4, DOI 10.1007/S42489-019-00026-Y]
   SMITH RM, 1986, PROF GEOGR, V38, P62, DOI 10.1111/j.0033-0124.1986.00062.x
   Snyder J. P, 1982, Tech. Rep. 1354
   SNYDER JP, 1978, ANN ASSOC AM GEOGR, V68, P373, DOI 10.1111/j.1467-8306.1978.tb01201.x
   Stern B., 2011, Geographic Inf. Technol. Training Alliance
   Stone M., 2014, COL IM C, V2014, P253
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Usery LE., 2001, Cartogr. Geogr. Inf. Sci, V28(3), P183, DOI [10.1559/152304001782153053, DOI 10.1559/152304001782153053]
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xiao NC, 2006, GEOGR ANAL, V38, P102, DOI 10.1111/j.0016-7363.2005.00678.x
   Zhang YF, 2017, IEEE T VIS COMPUT GR, V23, P371, DOI 10.1109/TVCG.2016.2598541
NR 62
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1592
EP 1607
DI 10.1109/TVCG.2023.3322372
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300009
PM 37801373
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Chen, CJ
   Guo, YK
   Tian, FY
   Liu, SL
   Yang, WK
   Wang, ZW
   Wu, J
   Su, H
   Pfister, H
   Liu, SX
AF Chen, Changjian
   Guo, Yukai
   Tian, Fengyuan
   Liu, Shilong
   Yang, Weikai
   Wang, Zhaowei
   Wu, Jing
   Su, Hang
   Pfister, Hanspeter
   Liu, Shixia
TI A Unified Interactive Model Evaluation for Classification, Object
   Detection, and Instance Segmentation in Computer Vision
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Model evaluation; computer vision; classification; object detection;
   instance segmentation
AB Existing model evaluation tools mainly focus on evaluating classification models, leaving a gap in evaluating more complex models, such as object detection. In this paper, we develop an open-source visual analysis tool, Uni-Evaluator, to support a unified model evaluation for classification, object detection, and instance segmentation in computer vision. The key idea behind our method is to formulate both discrete and continuous predictions in different tasks as unified probability distributions. Based on these distributions, we develop 1) a matrix-based visualization to provide an overview of model performance; 2) a table visualization to identify the problematic data subsets where the model performs poorly; 3) a grid visualization to display the samples of interest. These visualizations work together to facilitate the model evaluation from a global overview to individual samples. Two case studies demonstrate the effectiveness of Uni-Evaluator in evaluating model performance and making informed improvements.
C1 [Chen, Changjian; Guo, Yukai; Tian, Fengyuan; Yang, Weikai; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
   [Liu, Shilong; Su, Hang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Wu, Jing] Cardiff Univ, Cardiff, Wales.
   [Pfister, Hanspeter] Harvard Univ, Cambridge, MA USA.
C3 Tsinghua University; Tsinghua University; Cardiff University; Harvard
   University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
EM ccj17@mails.edu.cn; gyj22@mails.edu.cn; tianfy21@mails.edu.cn;
   slongliu86@gmail.com; yangwk21@mails.edu.cn; wzw20@mails.edu.cn;
   wuj11@cardiff.ac.uk; suhangss@tsinghua.edu.cn; pfister@seas.harvard.edu;
   shixia@tsinghua.edu.cn
RI Chen, Changjian/KBA-9462-2024
OI Chen, Changjian/0000-0003-2715-8839; Guo, Yukai/0009-0000-9651-3617
FU National Natural Science Foundation of China
FX No Statement Available
CR Abadi M., 2016, arXiv
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Arias-Hernandez R., 2011, P IEEE HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.2011.339
   Bar-Joseph Z, 2001, Bioinformatics, V17, pS22, DOI [DOI 10.1093/BIOINFORMATICS/17.SUPPL_1.S22, 10.1093/bioinformatics/17.suppl1.S22, 10.1093/bioinformatics/17.suppl_1.s22]
   Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425
   Biewald L., 2020, Weights & Biases
   Bolya Daniel, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P558, DOI 10.1007/978-3-030-58580-8_33
   Borji A, 2019, Arxiv, DOI arXiv:1911.12451
   Boullé M, 2006, MACH LEARN, V65, P131, DOI 10.1007/s10994-006-8364-x
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Fang YX, 2023, PROC CVPR IEEE, P19358, DOI 10.1109/CVPR52729.2023.01855
   Ghiasi G, 2021, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR46437.2021.00294
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Görtler J, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501823
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Heyen F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399814
   Hinterreiter A, 2022, IEEE T VIS COMPUT GR, V28, P1222, DOI 10.1109/TVCG.2020.3012063
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hou LP, 2022, AAAI CONF ARTIF INTE, P923
   Jadhav D, 2009, J RISK MODEL VALIDAT, V3, P51
   Jiale Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11482, DOI 10.1109/CVPR42600.2020.01150
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kervadec H, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101851
   Lei N, 2020, ENGINEERING-PRC, V6, P361, DOI 10.1016/j.eng.2019.09.010
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu Y, 2024, Arxiv, DOI [arXiv:2111.11057, 10.48550/arXiv.2111.11057]
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Nakkiran P, 2021, J STAT MECH-THEORY E, V2021, DOI 10.1088/1742-5468/ac3a74
   Pastor E, 2021, INT CONF MANAGE DATA, P1400, DOI 10.1145/3448016.3457284
   Pentico DW, 2007, EUR J OPER RES, V176, P774, DOI 10.1016/j.ejor.2005.09.014
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Rottmann Peter, 2023, IEEE Trans Vis Comput Graph, V29, P875, DOI 10.1109/TVCG.2022.3209485
   Schroeder W, 2008, J USABILITY STUD, V3, P173
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   TOWNSEND JT, 1971, PERCEPT PSYCHOPHYS, V9, P40, DOI 10.3758/BF03213026
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang QW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581127
   Wang WH, 2023, PROC CVPR IEEE, P14408, DOI 10.1109/CVPR52729.2023.01385
   WaqasZamir S., 2019, P IEEE CVF C COMP VI, P28
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796, DOI 10.1109/TPAMI.1987.4767986
   Xenopoulos Peter, 2023, IEEE Trans Vis Comput Graph, V29, P853, DOI 10.1109/TVCG.2022.3209489
   Yang J., 2022, Advances in Neural Information Processing Systems, V35, P4203, DOI DOI 10.31525/CT1-NCT039466188
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang H., 2023, P INT C LEARNING REP, P1
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zhang Y, 2018, NATL SCI REV, V5, P30, DOI 10.1093/nsr/nwx105
NR 69
TC 4
Z9 4
U1 9
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 76
EP 86
DI 10.1109/TVCG.2023.3326588
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500088
PM 37883267
OA Green Submitted, Green Accepted
DA 2024-08-05
ER

PT J
AU Cui, Y
   Ge, LW
   Ding, YR
   Yang, FM
   Harrison, L
   Kay, M
AF Cui, Yuan
   Ge, Lily W.
   Ding, Yiren
   Yang, Fumeng
   Harrison, Lane
   Kay, Matthew
TI Adaptive Assessment of Visualization Literacy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization literacy; computerized adaptive testing; item response
   theory
ID TEST-RETEST RELIABILITY
AB Visualization literacy is an essential skill for accurately interpreting data to inform critical decisions. Consequently, it is vital to understand the evolution of this ability and devise targeted interventions to enhance it, requiring concise and repeatable assessments of visualization literacy for individuals. However, current assessments, such as the Visualization Literacy Assessment Test (vlat), are time-consuming due to their fixed, lengthy format. To address this limitation, we develop two streamlined computerized adaptive tests (cats) for visualization literacy, a-vlat and a-calvi, which measure the same set of skills as their original versions in half the number of questions. Specifically, we (1) employ item response theory (IRT) and non-psychometric constraints to construct adaptive versions of the assessments, (2) finalize the configurations of adaptation through simulation, (3) refine the composition of test items of a-calvi via a qualitative study, and (4) demonstrate the test-retest reliability (ICC: 0.98 and 0.98) and convergent validity (correlation: 0.81 and 0.66) of both CATS via four online studies. We discuss practical recommendations for using our CATS and opportunities for further customization to leverage the full potential of adaptive assessments. All supplemental materials are available at https://osf.io/a6258/.
C1 [Cui, Yuan; Ge, Lily W.; Yang, Fumeng; Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
   [Ding, Yiren; Harrison, Lane] Worcester Polytech Inst, Worcester, MA USA.
C3 Northwestern University; Worcester Polytechnic Institute
RP Cui, Y (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM charlescui@u.northwestern.edu; wanqian.ge@northwestern.edu;
   yding5@wpi.edu; fy@northwestern.edu; ltharrison@wpi.edu;
   mjskay@northwestern.edu
OI Harrison, Lane/0000-0003-3029-2799; Ding, Yiren/0000-0001-8983-9117; Ge,
   Lily/0000-0003-2350-8686; Cui, Yuan/0000-0002-2681-6441; Kay,
   Matthew/0000-0001-9446-0419
FU National Science Foundation
FX No Statement Available
CR Aoyama K., 2003, Mathematics Education Research Journal, V15, P207
   Baker Frank., 2001, The basics of item response theory
   Beiser D, 2016, PSYCHIAT SERV, V67, P1039, DOI 10.1176/appi.ps.201500304
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Carlson KD, 2012, ORGAN RES METHODS, V15, P17, DOI 10.1177/1094428110392383
   Chin C.-L., 2014, Encyclopedia of Quality of Life and Well-Being Research, P1275, DOI [DOI 10.1007/978-94-007-0753-5_573, DOI 10.1007/978-94-007-0753-5573, 10.1007/978-94-007-0753-5573]
   Cicchetti DV, 1994, Psychol Assess, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]
   Cohen RJ., 2022, Psychological testing and assessment an introduction to tests and measurement, V10th
   CollegeBoard, 2022, Transitioning to a digital SAT
   DelMas R., 2005, 4 FOR STAT REAS THIN, P2
   ETS, 2023, GRE general test structure
   Foorman B., 2016, Regional Educational Laboratory Southeast (REL 2016-149), P2
   Ge LW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581406
   Ghio F. B., 2022, European Journal of Science and Mathematics Education, V10, P352, DOI [10.30935/scimath/119682, DOI 10.30935/SCIMATH/119682]
   Gibbons C, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6053
   Gibbons RD, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1053-9
   Gibbons RD, 2014, AM J PSYCHIAT, V171, P187, DOI 10.1176/appi.ajp.2013.13020178
   GREEN BF, 1984, J EDUC MEAS, V21, P347, DOI 10.1111/j.1745-3984.1984.tb01039.x
   Guinart D, 2021, SCHIZOPHRENIA BULL, V47, P644, DOI 10.1093/schbul/sbaa168
   Kandula S, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-52
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Liljequist D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219854
   Matheson GJ, 2019, PEERJ, V7, DOI 10.7717/peerj.6918
   Peterman K, 2015, INT J SCI EDUC, V37, P2787, DOI 10.1080/09500693.2015.1105399
   Polit DF, 2014, QUAL LIFE RES, V23, P1713, DOI 10.1007/s11136-014-0632-9
   Rezaie M., 2015, INT J ED INVESTIGATI, V2, P128
   Rudner LM, 2010, STAT SOC BEHAV SC, P151, DOI 10.1007/978-0-387-85461-8_8
   Segall D. O., 2005, Encyclopedia of social measurement, V1, P4
   Thompson N. A., 2011, Practical Assessment, Research, and Evaluation, V16, DOI [10.7275/wqzt-94271,2, DOI 10.7275/WQZT-94271,2]
   Wainer H., 2000, Computerized Adaptive Testing: A Primer, V2nd, DOI [10.4324/97814106059314, DOI 10.4324/97814106059314]
   Walter OB, 2007, QUAL LIFE RES, V16, P143, DOI 10.1007/s11136-007-9191-7
   Wilms R, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00825
NR 33
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 628
EP 637
DI 10.1109/TVCG.2023.3327165
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500038
PM 37878447
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Kim, H
   Rossi, R
   Hullman, J
   Hoffswell, J
AF Kim, Hyeok
   Rossi, Ryan
   Hullman, Jessica
   Hoffswell, Jane
TI Dupo: A Mixed-Initiative Authoring Tool for Responsive Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; responsive visualization; mixed-initiative authoring
AB Designing responsive visualizations for various screen types can be tedious as authors must manage multiple chart versions across design iterations. Automated approaches for responsive visualization must take into account the user's need for agency in exploring possible design ideas and applying customizations based on their own goals. We design and implement Dupo, a mixedinitiative approach to creating responsive visualizations that combines the agency afforded by a manual interface with automation provided by a recommender system. Given an initial design, users can browse automated design suggestions for a different screen type and make edits to a chosen design, thereby supporting quick prototyping and customizability. Dupo employs a two-step recommender pipeline that first suggests significant design changes (Exploration) followed by more subtle changes (Alteration). We evaluated Dupo with six expert responsive visualization authors. While creating responsive versions of a source design in Dupo, participants could reason about different design suggestions without having to manually prototype them, and thus avoid prematurely fixating on a particular design. This process led participants to create designs that they were satisfied with but which they had previously overlooked.
C1 [Kim, Hyeok; Hullman, Jessica] Northwestern Univ, Skokie, IL 60208 USA.
   [Rossi, Ryan; Hoffswell, Jane] Adobe Res, Washington, DC USA.
C3 Northwestern University; Adobe Systems Inc.
RP Kim, H (corresponding author), Northwestern Univ, Skokie, IL 60208 USA.
EM hyeok@northwestern.edu; rrossi@adobe.com; jhullman@northwestern.edu;
   jhoffs@adobe.com
RI ; Rossi, Ryan/C-7974-2013
OI Hullman, Jessica/0000-0001-6826-3550; Hoffswell,
   Jane/0000-0002-9871-4575; Rossi, Ryan/0000-0001-9758-0635
CR Andrews K., 2018, MOBILEVIS 18 WORKSH
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI 10.1191/1478088706qp063oa
   Cook K, 2015, IEEE CONF VIS ANAL, P9, DOI 10.1109/VAST.2015.7347625
   Cui WW, 2022, IEEE T VIS COMPUT GR, V28, P173, DOI 10.1109/TVCG.2021.3114856
   Datawrapper GmbH, 2013, Datawrapper
   Di Giacomo E., 2015, P IISA, P1, DOI DOI 10.1109/IISA.2015.73880951,2
   Ellis G, 2006, IEEE T VIS COMPUT GR, V12, P717, DOI 10.1109/TVCG.2006.138
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Flourish, About us
   Gebser M, 2014, Arxiv, DOI arXiv:1405.3694
   Gebser M, 2011, AI COMMUN, V24, P107, DOI 10.3233/AIC-2011-0491
   GitHub, Copilot
   Harper Jonathan, 2014, P 27 ANN ACM S USER, V14, P253, DOI [10.1145/2642918.2647411, DOI 10.1145/2642918.26474112, DOI 10.1145/2642918.2647411]
   Healey CG, 2008, IEEE T VIS COMPUT GR, V14, P396, DOI 10.1109/TVCG.2007.70436
   Hinderman B., 2015, Building Responsive Data Visualization for the Web, P1
   Hoffswell J., 2020, P CHI, P1, DOI [10.1145/3313831.33767771,2,3,4,5, DOI 10.1145/3313831.33767771,2,3,4,5]
   Kim H, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517455
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P129, DOI 10.1109/TVCG.2021.3114782
   Kim H, 2021, COMPUT GRAPH FORUM, V40, P459, DOI 10.1111/cgf.14321
   Kolodner J. L., 1996, Design Studies, V17, P385, DOI 10.1016/S0142-694X(96)00021-X
   Kolodner J. L., 1993, Technical Report SS-93-01, P2
   Korner C., 2016, Learning Responsive Data Visualization, P1
   Leclaire J., 2015, WORKSH DAT EXPL INT, P16
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Linsey JS, 2010, J MECH DESIGN, V132, DOI 10.1115/1.4001110
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Microsoft, 2011, Power bi
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ramirez S., FastAPI
   Rollup, About us
   Rosenbaum R, 2012, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2012.6183570
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Svelte, About us
   Swearngin A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376593
   Tableau Software, 2003, Tableu
   Tse A., 2011, ai2html
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Wu YC, 2013, IEEE T VIS COMPUT GR, V19, P278, DOI 10.1109/TVCG.2012.114
   ZingSoft, 2009, Zingchart
NR 45
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 934
EP 943
DI 10.1109/TVCG.2023.3326583
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500138
PM 37871074
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Pan, B
   Lu, JY
   Li, HX
   Chen, WF
   Wang, YY
   Zhu, MF
   Yu, CH
   Chen, W
AF Pan, Bo
   Lu, Jiaying
   Li, Haoxuan
   Chen, Weifeng
   Wang, Yiyao
   Zhu, Minfeng
   Yu, Chenhao
   Chen, Wei
TI Differentiable Design Galleries: A Differentiable Approach to Explore
   the Design Space of Transfer Functions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Transfer function; direct volume rendering; deep learning; generative
   models; differentiable rendering
ID HISTOGRAMS
AB The transfer function is crucial for direct volume rendering (DVR) to create an informative visual representation of volumetric data. However, manually adjusting the transfer function to achieve the desired DVR result can be time-consuming and unintuitive. In this paper, we propose Differentiable Design Galleries, an image-based transfer function design approach to help users explore the design space of transfer functions by taking advantage of the recent advances in deep learning and differentiable rendering. Specifically, we leverage neural rendering to learn a latent design space, which is a continuous manifold representing various types of implicit transfer functions. We further provide a set of interactive tools to support intuitive query, navigation, and modification to obtain the target design, which is represented as a neural-rendered design exemplar. The explicit transfer function can be reconstructed from the target design with a differentiable direct volume renderer. Experimental results on real volumetric data demonstrate the effectiveness of our method.
C1 [Pan, Bo; Lu, Jiaying; Li, Haoxuan; Wang, Yiyao; Yu, Chenhao; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Minist Educ, Lab Art & Archaeol Image, Hangzhou, Peoples R China.
   [Chen, Weifeng] Zhejiang Univ Finance & Econ, Hangzhou, Peoples R China.
   [Zhu, Minfeng] Zhejiang Univ, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University of Finance
   & Economics; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.; Chen, W (corresponding author), Zhejiang Univ, Minist Educ, Lab Art & Archaeol Image, Hangzhou, Peoples R China.; Chen, WF (corresponding author), Zhejiang Univ Finance & Econ, Hangzhou, Peoples R China.
EM bopan@zju.edu.cn; jiangyinglu@zju.edu.cn; lihaoxuan@zju.edu.cn;
   cwf818@zufe.edu.cn; wangyiyao@zju.edu.cn; minfeng_zhu@zju.edu.cn;
   ych20@zju.edu.cn; chenvis@zju.edu.cn
OI Chen, Wei/0000-0002-8365-4741; Zhu, Minfeng/0000-0002-6711-3099; Lu,
   Jiaying/0009-0008-3578-346X
FU National Natural Science Foundation of China
FX No Statement Available
CR Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P192, DOI 10.1109/TVCG.2010.35
   Correa CD, 2009, IEEE T VIS COMPUT GR, V15, P1465, DOI 10.1109/TVCG.2009.189
   Dupont E, 2018, ADV NEUR IN, V31
   Engel K., 2006, Real-Time Volume Graphics, DOI [10.1201/b106291, DOI 10.1201/B106291]
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow J., 2014, arXiv, DOI DOI 10.48550/ARXIV.1406.2661
   Guo HQ, 2014, IEEE PAC VIS SYMP, P262, DOI 10.1109/PacificVis.2014.24
   Guo HQ, 2011, IEEE T VIS COMPUT GR, V17, P2106, DOI 10.1109/TVCG.2011.261
   Haidacher Martin., 2008, P EUROGRAPHICS WORKS, P101, DOI DOI 10.2312/VCBM/VCBM08/101-108
   He TS, 1996, IEEE VISUAL, P227, DOI 10.1109/VISUAL.1996.568113
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jönsson D, 2016, IEEE T VIS COMPUT GR, V22, P896, DOI 10.1109/TVCG.2015.2467294
   Kato H, 2020, Arxiv, DOI arXiv:2006.12057
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Kingma D. P., 2014, arXiv
   Kniss J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P497, DOI 10.1109/VISUAL.2003.1250412
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Kniss JM, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P287
   Kwan-Liu Ma, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P81, DOI 10.1109/VISUAL.1999.809871
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Lundström C, 2006, IEEE T VIS COMPUT GR, V12, P1570, DOI 10.1109/TVCG.2006.100
   Maciejewski R, 2009, IEEE T VIS COMPUT GR, V15, P1473, DOI 10.1109/TVCG.2009.185
   Marks J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P389, DOI 10.1145/258734.258887
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pfister H, 2001, IEEE COMPUT GRAPH, V21, P16, DOI 10.1109/38.920623
   Pinto FD, 2008, COMPUT GRAPH-UK, V32, P420, DOI 10.1016/j.cag.2008.04.004
   Pinto Franciscode Moura., 2007, Eurographics IEEE-VGTC Symposium on Visualization, P131
   Prauchner JL, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P265
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salama CR, 2006, IEEE T VIS COMPUT GR, V12, P1021, DOI 10.1109/TVCG.2006.148
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Tzeng F.-Y., 2004, A cluster-space visual interface for arbitrary dimensional classification of volume data, P338, DOI [10.2312/VisSym/VisSym04/017-0242, DOI 10.2312/VISSYM/VISSYM04/017-0242]
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Wang YH, 2012, COMPUT GRAPH FORUM, V31, P1295, DOI 10.1111/j.1467-8659.2012.03122.x
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Weiss J., 2021, Deep direct volume rendering: Learning visual feature mappings from exemplary images, DOI DOI 10.48550/ARXIV.2106.05429
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P562, DOI 10.1109/TVCG.2021.3114769
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Wong H.-C., 2009, P INT C INFORM COMMU, P1, DOI [10.1109/ICICS.2009.5397587, DOI 10.1109/ICICS.2009.5397587]
   Wu YC, 2007, IEEE T VIS COMPUT GR, V13, P1027, DOI 10.1109/TVCG.2007.1051
NR 50
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1369
EP 1379
DI 10.1109/TVCG.2023.3327371
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500071
PM 37878449
DA 2024-08-05
ER

PT J
AU Yang, FM
   Cai, MD
   Mortenson, C
   Fakhari, H
   Lokmanoglu, AD
   Hullman, J
   Franconeri, S
   Diakopoulos, N
   Nisbet, EC
   Kay, M
AF Yang, Fumeng
   Cai, Mandi
   Mortenson, Chloe
   Fakhari, Hoda
   Lokmanoglu, Ayse D.
   Hullman, Jessica
   Franconeri, Steven
   Diakopoulos, Nicholas
   Nisbet, Erik C.
   Kay, Matthew
TI Swaying the Public? Impacts of Election Forecast Visualizations on
   Emotion, Trust, and Intention in the 2022 US Midterms
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty visualization; Probabilistic forecasts; Elections; Emotions;
   Trust; Political participation; Longitudinal study
ID VOTER TURNOUT; UNCERTAINTY; OPINION; POLLS
AB We conducted a longitudinal study during the 2022 U.S. midterm elections, investigating the real-world impacts of uncertainty visualizations. Using our forecast model of the governor elections in 33 states, we created a website and deployed four uncertainty visualizations for the election forecasts: single quantile dotplot (1-Dotplot), dual quantile dotplots (2-Dotplot), dual histogram intervals (2-Interval), and Plinko quantile dotplot (Plinko), an animated design with a physical and probabilistic analogy. Our online experiment ran from Oct. 18, 2022, to Nov. 23, 2022, involving 1,327 participants from 15 states. We use Bayesian multilevel modeling and post-stratification to produce demographically-representative estimates of people's emotions, trust in forecasts, and political participation intention. We find that election forecast visualizations can heighten emotions, increase trust, and slightly affect people's intentions to participate in elections. 2-Interval shows the strongest effects across all measures; 1-Dotplot increases trust the most after elections. Both visualizations create emotional and trust gaps between different partisan identities, especially when a Republican candidate is predicted to win. Our qualitative analysis uncovers the complex political and social contexts of election forecast visualizations, showcasing that visualizations may provoke polarization. This intriguing interplay between visualization types, partisanship, and trust exemplifies the fundamental challenge of disentangling visualization from its context, underscoring a need for deeper investigation into the real-world impacts of visualizations. Our preprint and supplements are available at https://doi.org/osf.io/ajq8f.
C1 [Yang, Fumeng; Cai, Mandi; Mortenson, Chloe; Fakhari, Hoda; Lokmanoglu, Ayse D.; Hullman, Jessica; Franconeri, Steven; Diakopoulos, Nicholas; Nisbet, Erik C.; Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Yang, FM (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM fy@northwestern.edu; mandicai2028@u.northwestern.edu;
   chloemortenson2026@u.northwestern.edu; hoda@u.northwestern.edu;
   ayse.lokmanoglu@northwestern.edu; jhullman@northwestern.edu;
   franconeri@northwestern.edu; nad@northwestern.edu;
   erik.nisbet@northwestern.edu; mjskay@northwestern.edu
OI Hullman, Jessica/0000-0001-6826-3550
FU NSF
FX No Statement Available
CR Agranov M, 2018, J EUR ECON ASSOC, V16, P825, DOI 10.1093/jeea/jvx023
   Anderson CJ, 2002, BRIT J POLIT SCI, V32, P335, DOI 10.1017/S0007123402000133
   [Anonymous], Party Affiliation
   ANSOLABEHERE S, 1994, POLIT COMMUN, V11, P413, DOI 10.1080/10584609.1994.9963048
   Barnfield M, 2020, POLIT STUD REV, V18, P553, DOI 10.1177/1478929919870691
   Blais A., 2000, University of Pittsburgh Pre, V2, P8
   Blankenship BT, 2019, POLIT GROUPS IDENTIT, V7, P724, DOI 10.1080/21565503.2019.1633932
   Boudreau C, 2010, J POLIT, V72, P513, DOI 10.1017/S0022381609990946
   Brown J. D., 2011, Statistics, V15, P6
   Cancela J, 2016, ELECT STUD, V42, P264, DOI 10.1016/j.electstud.2016.03.005
   Christmann A, 2006, J MULTIVARIATE ANAL, V97, P1660, DOI 10.1016/j.jmva.2005.05.012
   Christofoletti M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18147477
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cosmides L, 1996, COGNITION, V58, P1, DOI 10.1016/0010-0277(95)00664-8
   de Visser EJ, 2020, INT J SOC ROBOT, V12, P459, DOI 10.1007/s12369-019-00596-x
   Diakopoulos N., 2022, Predictive journalism: On the role of computational prospection in news media, P2
   Duffy J, 2008, AM J POLIT SCI, V52, P603, DOI 10.1111/j.1540-5907.2008.00332.x
   economist, Forecasting the U.S. elections
   economistgroup, The Economist's German election model forecasts three possible governing coalitions
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Finn C, 2010, ANAL SOC ISS PUB POL, V10, P262, DOI 10.1111/j.1530-2415.2010.01206.x
   fivethirtyeight, How good are FiveThirtyEight forecasts?
   fivethirtyeight, Latest polls
   fivethirtyeight, 2020 Election Forecast
   fivethirtyeight, 2022 Election Forecast
   FREEMAN J, 1986, POLIT SCI QUART, V101, P327, DOI 10.2307/2151619
   Galton F., 1889
   Gelman A., 2016, Using multilevel regression and poststratification to estimate dynamic public opinion, V2, P6
   Gelman A., 2020, Judgment and Decision Making, V15, DOI [10.1017/S19302975000079812,9, DOI 10.1017/S19302975000079812,9]
   Gerber A, 2020, AM ECON J-APPL ECON, V12, P287, DOI 10.1257/app.20180574
   Gerber AS, 2008, AM POLIT SCI REV, V102, P33, DOI 10.1017/S000305540808009X
   google, Attacking discrimination with smarter machine learning
   Groenendyk EW, 2014, POLIT PSYCHOL, V35, P359, DOI 10.1111/pops.12045
   Gu YY, 2020, NEURAL PLAST, V2020, DOI 10.1155/2020/8866386
   Han PKJ, 2012, PATIENT EDUC COUNS, V86, P106, DOI 10.1016/j.pec.2011.01.033
   Harpe SE, 2015, CURR PHARM TEACH LEA, V7, P836, DOI 10.1016/j.cptl.2015.08.001
   Hart PS, 2011, SCI COMMUN, V33, P28, DOI 10.1177/1075547010366400
   Heidemanns M., 2020, Harvard Data Science Review, V2, P10, DOI 10.1162/99608f92.fc62f1-1
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Iyengar S, 2015, AM J POLIT SCI, V59, P690, DOI 10.1111/ajps.12152
   Iyengar S, 2012, PUBLIC OPIN QUART, V76, P405, DOI 10.1093/poq/nfs038
   Iyer A, 2007, PERS SOC PSYCHOL B, V33, P572, DOI 10.1177/0146167206297402
   Jordan A, 2019, J STAT SOFTW, V90, P1, DOI 10.18637/jss.v090.i12
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kastellec J. P., 2010, Estimating state public opinion with multi-level regression and poststratification using R, P6
   Kastellec JP, 2015, J POLIT, V77, P787, DOI 10.1086/681261
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kennedy L, 2021, PSYCHOL METHODS, V26, P547, DOI 10.1037/met0000362
   Khandkar S. H., 2009, University of Calgary, V23, P8
   Koval M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502010
   Kuru O, 2017, PUBLIC OPIN QUART, V81, P422, DOI 10.1093/poq/nfx018
   Lax JR, 2009, AM POLIT SCI REV, V103, P367, DOI 10.1017/S0003055409990050
   Lee TT, 2010, AM BEHAV SCI, V54, P8, DOI 10.1177/0002764210376308
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Linzer DA, 2013, J AM STAT ASSOC, V108, P124, DOI 10.1080/01621459.2012.737735
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Madsen M., 2000, P 11 AUSTR C INF SYS, V53, P6
   Madson GJ, 2020, POLIT BEHAV, V42, P1055, DOI 10.1007/s11109-019-09532-1
   Manski CF, 2020, ECON PHILOS, V36, P216, DOI 10.1017/S0266267119000105
   Marinovic I, 2013, HBK ECON, P691, DOI 10.1016/B978-0-444-62731-5.00012-9
   MCALLISTER DJ, 1995, ACAD MANAGE J, V38, P24, DOI 10.5465/256727
   McCright AM, 2013, ENVIRON RES LETT, V8, DOI 10.1088/1748-9326/8/4/044029
   Merritt SM, 2013, HUM FACTORS, V55, P520, DOI 10.1177/0018720812465081
   metaculus, Metaculus track record
   Nisbet EC, 2015, ANN AM ACAD POLIT SS, V658, P36, DOI 10.1177/0002716214555474
   Oleskog Tryggvason P., 2021, Under the influence? Understanding medias coverage of opinion polls and their effects on citizens and politicians, P2
   Padilla Lace, 2023, IEEE Trans Vis Comput Graph, V29, P12, DOI 10.1109/TVCG.2022.3209457
   Padilla L, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.579207
   Patterson TE, 2005, PUBLIC OPIN QUART, V69, P716, DOI 10.1093/poq/nfi065
   pewresearch, Party affiliation by state
   priceisright, The Price is Right
   researcher-help, How do I set up a longitudinal / multi-part study?
   Rushton G., 2006, AM J PREV MED, V30, P16, DOI DOI 10.1111/J.1478-9299.2006.00034
   Sarma Abhraneel, 2023, IEEE Trans Vis Comput Graph, V29, P602, DOI 10.1109/TVCG.2022.3209348
   Shirani-Mehr H, 2018, J AM STAT ASSOC, V113, P607, DOI 10.1080/01621459.2018.1448823
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Valentino NA, 2011, J POLIT, V73, P156, DOI 10.1017/S0022381610000939
   Van Deth J. W., 2001, JOINT SESS WORKSH EU, P5
   Walker K., 2023, Tidycensus: Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready Data Frames
   washingtonpost, Where voter turnout exceeded 2018 highs
   washingtonpost, What you need to know about the measles outbreak
   Watson D., 1994, The PANAS-X: Manual for the positive and negative affect schedule-expanded form, P4
   Weber C, 2013, POLIT RES QUART, V66, P414, DOI 10.1177/1065912912449697
   Westwood SJ, 2020, J POLIT, V82, P1530, DOI 10.1086/708682
   Witzenberger B, 2024, INFORM COMMUN SOC, V27, P951, DOI 10.1080/1369118X.2023.2230267
   Xiong C., 2022, ACM CHI, DOI [10.1145/3491102.35018742, DOI 10.1145/3491102.35018742]
   Yang FM, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580998
   Yang FM, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P189, DOI 10.1145/3377325.3377480
   Zamo M, 2018, MATH GEOSCI, V50, P209, DOI 10.1007/s11004-017-9709-7
   Zhang DP, 2022, IEEE T VIS COMPUT GR, V28, P443, DOI 10.1109/TVCG.2021.3114679
NR 92
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 23
EP 33
DI 10.1109/TVCG.2023.3327356
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500024
PM 37930916
OA Green Submitted
DA 2024-08-05
ER

EF